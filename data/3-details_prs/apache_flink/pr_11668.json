{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDAwNzE3ODA4", "number": 11668, "title": "[FLINK-17013][python] Support Python UDTF in old planner under batch mode", "bodyText": "What is the purpose of the change\nThis pull request will support Python UDTF in old planner under batch mode\nBrief change log\n\nAdd rules to convert RelNode to DataSetPythonCorrelate Node.\nAdd PythonTableFunctionFlatMap function to invoke Python TableFunctions for the legacy planner\n\nVerifying this change\nThis change added tests and can be verified as follows:\n\nAdded integration tests PyFlinkBatchUserDefinedTableFunctionTests in test_udtf.py\n\nDoes this pull request potentially affect one of the following parts:\n\nDependencies (does it add or upgrade a dependency): (no)\nThe public API, i.e., is any changed class annotated with @Public(Evolving): (no)\nThe serializers: (no)\nThe runtime per-record code paths (performance sensitive): (no)\nAnything that affects deployment or recovery: JobManager (and its components), Checkpointing, Kubernetes/Yarn/Mesos, ZooKeeper: (no)\nThe S3 file system connector: (no)\n\nDocumentation\n\nDoes this pull request introduce a new feature? (no)\nIf yes, how is the feature documented? (not applicable)", "createdAt": "2020-04-08T08:55:51Z", "url": "https://github.com/apache/flink/pull/11668", "merged": true, "mergeCommit": {"oid": "bda9b7765471f62665fd1823be527ed0c9c9bb48"}, "closed": true, "closedAt": "2020-04-21T05:00:58Z", "author": {"login": "HuangXingBo"}, "timelineItems": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcYHXPTgFqTM5NDMxNTMzMw==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcZeIAQgH2gAyNDAwNzE3ODA4OjVmMjAzZjI5MzhmMDk0Y2NmYTIyZjA1ZDNkZmRkZGJjZmEyMTBlODE=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk0MzE1MzMz", "url": "https://github.com/apache/flink/pull/11668#pullrequestreview-394315333", "createdAt": "2020-04-16T05:49:18Z", "commit": {"oid": "48fe02ae72da140602cba512125240025d54d0c0"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwNTo0OToxOFrOGGVgfg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwNjozMTowM1rOGGWb8w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI5NzAyMg==", "bodyText": "I'm thinking to avoid these code duplications. Most parts of the code are the same, we only have to extract the different parts into methods and override the methods in the child classes. For example, we can add a base method named get_output in the UserDefinedTableFunctionTests and override the method in PyFlinkBatchUserDefinedTableFunctionTests.", "url": "https://github.com/apache/flink/pull/11668#discussion_r409297022", "createdAt": "2020-04-16T05:49:18Z", "author": {"login": "hequn8128"}, "path": "flink-python/pyflink/table/tests/test_udtf.py", "diffHunk": "@@ -81,6 +81,42 @@ class PyFlinkBlinkStreamUserDefinedFunctionTests(UserDefinedTableFunctionTests,\n     pass\n \n \n+class PyFlinkBatchUserDefinedTableFunctionTests(PyFlinkBatchTableTestCase):\n+\n+    def test_table_function(self):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "48fe02ae72da140602cba512125240025d54d0c0"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTMxMjI0Mw==", "bodyText": "Maybe add some base classes for the two classes, i.e., DataSetPythonCorrelateRule and DataStreamPythonCorrelateRule to avoid the code duplications.", "url": "https://github.com/apache/flink/pull/11668#discussion_r409312243", "createdAt": "2020-04-16T06:31:03Z", "author": {"login": "hequn8128"}, "path": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/plan/rules/batch/DataSetPythonCorrelateRule.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.plan.rules.batch;\n+\n+import org.apache.flink.table.plan.nodes.FlinkConventions;\n+import org.apache.flink.table.plan.nodes.dataset.DataSetPythonCorrelate;\n+import org.apache.flink.table.plan.nodes.logical.FlinkLogicalCalc;\n+import org.apache.flink.table.plan.nodes.logical.FlinkLogicalCorrelate;\n+import org.apache.flink.table.plan.nodes.logical.FlinkLogicalTableFunctionScan;\n+import org.apache.flink.table.plan.util.CorrelateUtil;\n+import org.apache.flink.table.plan.util.PythonUtil;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.plan.RelTraitSet;\n+import org.apache.calcite.plan.volcano.RelSubset;\n+import org.apache.calcite.rel.RelNode;\n+import org.apache.calcite.rel.convert.ConverterRule;\n+import org.apache.calcite.rex.RexNode;\n+\n+import scala.Option;\n+import scala.Some;\n+\n+/**\n+ * The physical rule is responsible for convert {@link FlinkLogicalCorrelate} to\n+ * {@link DataSetPythonCorrelate}.\n+ */\n+public class DataSetPythonCorrelateRule extends ConverterRule {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "48fe02ae72da140602cba512125240025d54d0c0"}, "originalPosition": 44}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "65362f1595f7e068fe680adc16e7fa82fd84aff7", "author": {"user": {"login": "HuangXingBo", "name": null}}, "url": "https://github.com/apache/flink/commit/65362f1595f7e068fe680adc16e7fa82fd84aff7", "committedDate": "2020-04-16T07:33:19Z", "message": "[FLINK-17013][python] Support Python UDTF in old planner under batch mode"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7d2e31fab3e7e023346cbec86fbb239c80310895", "author": {"user": {"login": "HuangXingBo", "name": null}}, "url": "https://github.com/apache/flink/commit/7d2e31fab3e7e023346cbec86fbb239c80310895", "committedDate": "2020-04-17T11:36:25Z", "message": "fix"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "48fe02ae72da140602cba512125240025d54d0c0", "author": {"user": {"login": "HuangXingBo", "name": null}}, "url": "https://github.com/apache/flink/commit/48fe02ae72da140602cba512125240025d54d0c0", "committedDate": "2020-04-08T08:45:27Z", "message": "[FLINK-17013][python] Support Python UDTF in old planner under batch mode"}, "afterCommit": {"oid": "7d2e31fab3e7e023346cbec86fbb239c80310895", "author": {"user": {"login": "HuangXingBo", "name": null}}, "url": "https://github.com/apache/flink/commit/7d2e31fab3e7e023346cbec86fbb239c80310895", "committedDate": "2020-04-17T11:36:25Z", "message": "fix"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk2MjAwNDky", "url": "https://github.com/apache/flink/pull/11668#pullrequestreview-396200492", "createdAt": "2020-04-20T07:25:10Z", "commit": {"oid": "7d2e31fab3e7e023346cbec86fbb239c80310895"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQwNzoyNToxMFrOGIGw8w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQwNzozNzozMVrOGIHL3g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTE1MjYyNw==", "bodyText": "How about making this two as the default implementation in the base class and only override them in the PyFlinkBatchUserDefinedTableFunctionTests?", "url": "https://github.com/apache/flink/pull/11668#discussion_r411152627", "createdAt": "2020-04-20T07:25:10Z", "author": {"login": "hequn8128"}, "path": "flink-python/pyflink/table/tests/test_udtf.py", "diffHunk": "@@ -41,44 +41,67 @@ def test_table_function(self):\n                              DataTypes.BIGINT()))\n \n         t = self.t_env.from_elements([(1, 1, 3), (2, 1, 6), (3, 2, 9)], ['a', 'b', 'c'])\n-        t.join_lateral(\"multi_emit(a, multi_num(b)) as (x, y)\") \\\n+        t = t.join_lateral(\"multi_emit(a, multi_num(b)) as (x, y)\") \\\n             .left_outer_join_lateral(\"condition_multi_emit(x, y) as m\") \\\n-            .select(\"x, y, m\") \\\n-            .insert_into(\"Results\")\n-        self.t_env.execute(\"test\")\n-        actual = source_sink_utils.results()\n+            .select(\"x, y, m\")\n+        actual = self._get_output(t)\n         self.assert_equals(actual,\n                            [\"1,0,null\", \"1,1,null\", \"2,0,null\", \"2,1,null\", \"3,0,0\", \"3,0,1\",\n                             \"3,0,2\", \"3,1,1\", \"3,1,2\", \"3,2,2\", \"3,3,null\"])\n \n     def test_table_function_with_sql_query(self):\n-        table_sink = source_sink_utils.TestAppendSink(\n+        self._register_table_sink(\n             ['a', 'b', 'c'],\n             [DataTypes.BIGINT(), DataTypes.BIGINT(), DataTypes.BIGINT()])\n-        self.t_env.register_table_sink(\"Results\", table_sink)\n+\n         self.t_env.register_function(\n             \"multi_emit\", udtf(MultiEmit(), [DataTypes.BIGINT(), DataTypes.BIGINT()],\n                                [DataTypes.BIGINT(), DataTypes.BIGINT()]))\n \n         t = self.t_env.from_elements([(1, 1, 3), (2, 1, 6), (3, 2, 9)], ['a', 'b', 'c'])\n         self.t_env.register_table(\"MyTable\", t)\n-        self.t_env.sql_query(\n+        t = self.t_env.sql_query(\n             \"SELECT a, x, y FROM MyTable LEFT JOIN LATERAL TABLE(multi_emit(a, b)) as T(x, y)\"\n-            \" ON TRUE\") \\\n-            .insert_into(\"Results\")\n-        self.t_env.execute(\"test\")\n-        actual = source_sink_utils.results()\n+            \" ON TRUE\")\n+        actual = self._get_output(t)\n         self.assert_equals(actual, [\"1,1,0\", \"2,2,0\", \"3,3,0\", \"3,3,1\"])\n \n+    def _register_table_sink(self, field_names: list, field_types: list):\n+        pass\n+\n+    def _get_output(self, t):\n+        pass\n+\n \n class PyFlinkStreamUserDefinedTableFunctionTests(UserDefinedTableFunctionTests,\n                                                  PyFlinkStreamTableTestCase):\n-    pass\n+\n+    def _register_table_sink(self, field_names: list, field_types: list):\n+        table_sink = source_sink_utils.TestAppendSink(field_names, field_types)\n+        self.t_env.register_table_sink(\"Results\", table_sink)\n+\n+    def _get_output(self, t):\n+        t.insert_into(\"Results\")\n+        self.t_env.execute(\"test\")\n+        return source_sink_utils.results()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d2e31fab3e7e023346cbec86fbb239c80310895"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTE1NzQ3NQ==", "bodyText": "responsible for converting", "url": "https://github.com/apache/flink/pull/11668#discussion_r411157475", "createdAt": "2020-04-20T07:33:45Z", "author": {"login": "hequn8128"}, "path": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/plan/rules/AbstractPythonCorrelateRuleBase.java", "diffHunk": "@@ -39,16 +40,14 @@\n import scala.Some;\n \n /**\n- * The physical rule is responsible for convert {@link FlinkLogicalCorrelate} to\n- * {@link DataStreamPythonCorrelate}.\n+ * The abstract physical rule base is responsible for convert {@link FlinkLogicalCorrelate} to physical", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d2e31fab3e7e023346cbec86fbb239c80310895"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTE1NzYzOQ==", "bodyText": "is responsible for creating", "url": "https://github.com/apache/flink/pull/11668#discussion_r411157639", "createdAt": "2020-04-20T07:34:06Z", "author": {"login": "hequn8128"}, "path": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/plan/rules/AbstractPythonCorrelateRuleBase.java", "diffHunk": "@@ -69,35 +67,29 @@ public boolean matches(RelOptRuleCall call) {\n \t\treturn false;\n \t}\n \n-\t@Override\n-\tpublic RelNode convert(RelNode rel) {\n-\t\tDataStreamPythonCorrelateFactory factory = new DataStreamPythonCorrelateFactory(rel);\n-\t\treturn factory.convertToCorrelate();\n-\t}\n-\n \t/**\n-\t * The factory is responsible to creating {@link DataStreamPythonCorrelate}.\n+\t * The abstract factory is responsible to creating {@link DataSetPythonCorrelate} or {@link DataStreamPythonCorrelate}.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d2e31fab3e7e023346cbec86fbb239c80310895"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTE1Nzg4NA==", "bodyText": "responsible for converting", "url": "https://github.com/apache/flink/pull/11668#discussion_r411157884", "createdAt": "2020-04-20T07:34:31Z", "author": {"login": "hequn8128"}, "path": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/plan/rules/stream/DataStreamPythonCorrelateRule.java", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.plan.rules.stream;\n+\n+import org.apache.flink.table.plan.nodes.FlinkConventions;\n+import org.apache.flink.table.plan.nodes.datastream.DataStreamPythonCorrelate;\n+import org.apache.flink.table.plan.nodes.logical.FlinkLogicalCorrelate;\n+import org.apache.flink.table.plan.nodes.logical.FlinkLogicalTableFunctionScan;\n+import org.apache.flink.table.plan.rules.AbstractPythonCorrelateRuleBase;\n+import org.apache.flink.table.plan.schema.RowSchema;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.rel.RelNode;\n+import org.apache.calcite.rex.RexNode;\n+\n+import scala.Option;\n+\n+/**\n+ * The physical rule is responsible for convert {@link FlinkLogicalCorrelate} to", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d2e31fab3e7e023346cbec86fbb239c80310895"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTE1ODAxOA==", "bodyText": "responsible for creating", "url": "https://github.com/apache/flink/pull/11668#discussion_r411158018", "createdAt": "2020-04-20T07:34:46Z", "author": {"login": "hequn8128"}, "path": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/plan/rules/stream/DataStreamPythonCorrelateRule.java", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.plan.rules.stream;\n+\n+import org.apache.flink.table.plan.nodes.FlinkConventions;\n+import org.apache.flink.table.plan.nodes.datastream.DataStreamPythonCorrelate;\n+import org.apache.flink.table.plan.nodes.logical.FlinkLogicalCorrelate;\n+import org.apache.flink.table.plan.nodes.logical.FlinkLogicalTableFunctionScan;\n+import org.apache.flink.table.plan.rules.AbstractPythonCorrelateRuleBase;\n+import org.apache.flink.table.plan.schema.RowSchema;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.rel.RelNode;\n+import org.apache.calcite.rex.RexNode;\n+\n+import scala.Option;\n+\n+/**\n+ * The physical rule is responsible for convert {@link FlinkLogicalCorrelate} to\n+ * {@link DataStreamPythonCorrelate}.\n+ */\n+public class DataStreamPythonCorrelateRule extends AbstractPythonCorrelateRuleBase {\n+\n+\tpublic static final RelOptRule INSTANCE = new DataStreamPythonCorrelateRule();\n+\n+\tprivate DataStreamPythonCorrelateRule() {\n+\t\tsuper(FlinkConventions.DATASTREAM(), \"DataStreamPythonCorrelateRule\");\n+\t}\n+\n+\t@Override\n+\tpublic RelNode convert(RelNode rel) {\n+\t\tDataStreamPythonCorrelateFactory factory = new DataStreamPythonCorrelateFactory(rel);\n+\t\treturn factory.convertToCorrelate();\n+\t}\n+\n+\t/**\n+\t * The factory is responsible to creating {@link DataStreamPythonCorrelate}.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d2e31fab3e7e023346cbec86fbb239c80310895"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTE1ODIxOQ==", "bodyText": "responsible for converting", "url": "https://github.com/apache/flink/pull/11668#discussion_r411158219", "createdAt": "2020-04-20T07:35:09Z", "author": {"login": "hequn8128"}, "path": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/plan/rules/batch/DataSetPythonCorrelateRule.java", "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.plan.rules.batch;\n+\n+import org.apache.flink.table.plan.nodes.FlinkConventions;\n+import org.apache.flink.table.plan.nodes.dataset.DataSetPythonCorrelate;\n+import org.apache.flink.table.plan.nodes.logical.FlinkLogicalCorrelate;\n+import org.apache.flink.table.plan.nodes.logical.FlinkLogicalTableFunctionScan;\n+import org.apache.flink.table.plan.rules.AbstractPythonCorrelateRuleBase;\n+\n+import org.apache.calcite.rel.RelNode;\n+import org.apache.calcite.rex.RexNode;\n+\n+import scala.Option;\n+\n+/**\n+ * The physical rule is responsible for convert {@link FlinkLogicalCorrelate} to", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d2e31fab3e7e023346cbec86fbb239c80310895"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTE1ODM0Mw==", "bodyText": "responsible for creating", "url": "https://github.com/apache/flink/pull/11668#discussion_r411158343", "createdAt": "2020-04-20T07:35:20Z", "author": {"login": "hequn8128"}, "path": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/plan/rules/batch/DataSetPythonCorrelateRule.java", "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.plan.rules.batch;\n+\n+import org.apache.flink.table.plan.nodes.FlinkConventions;\n+import org.apache.flink.table.plan.nodes.dataset.DataSetPythonCorrelate;\n+import org.apache.flink.table.plan.nodes.logical.FlinkLogicalCorrelate;\n+import org.apache.flink.table.plan.nodes.logical.FlinkLogicalTableFunctionScan;\n+import org.apache.flink.table.plan.rules.AbstractPythonCorrelateRuleBase;\n+\n+import org.apache.calcite.rel.RelNode;\n+import org.apache.calcite.rex.RexNode;\n+\n+import scala.Option;\n+\n+/**\n+ * The physical rule is responsible for convert {@link FlinkLogicalCorrelate} to\n+ * {@link DataSetPythonCorrelate}.\n+ */\n+public class DataSetPythonCorrelateRule extends AbstractPythonCorrelateRuleBase {\n+\n+\tpublic static final DataSetPythonCorrelateRule INSTANCE = new DataSetPythonCorrelateRule();\n+\n+\tprivate DataSetPythonCorrelateRule() {\n+\t\tsuper(FlinkConventions.DATASET(), \"DataSetPythonCorrelateRule\");\n+\t}\n+\n+\t@Override\n+\tpublic RelNode convert(RelNode rel) {\n+\t\tDataSetPythonCorrelateFactory factory = new DataSetPythonCorrelateFactory(rel);\n+\t\treturn factory.convertToCorrelate();\n+\t}\n+\n+\t/**\n+\t * The factory is responsible to creating {@link DataSetPythonCorrelate}.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d2e31fab3e7e023346cbec86fbb239c80310895"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTE1ODg3OQ==", "bodyText": "Add a blank here, i.e., PythonCorrelateFactoryBase {", "url": "https://github.com/apache/flink/pull/11668#discussion_r411158879", "createdAt": "2020-04-20T07:36:14Z", "author": {"login": "hequn8128"}, "path": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/plan/rules/stream/DataStreamPythonCorrelateRule.java", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.plan.rules.stream;\n+\n+import org.apache.flink.table.plan.nodes.FlinkConventions;\n+import org.apache.flink.table.plan.nodes.datastream.DataStreamPythonCorrelate;\n+import org.apache.flink.table.plan.nodes.logical.FlinkLogicalCorrelate;\n+import org.apache.flink.table.plan.nodes.logical.FlinkLogicalTableFunctionScan;\n+import org.apache.flink.table.plan.rules.AbstractPythonCorrelateRuleBase;\n+import org.apache.flink.table.plan.schema.RowSchema;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.rel.RelNode;\n+import org.apache.calcite.rex.RexNode;\n+\n+import scala.Option;\n+\n+/**\n+ * The physical rule is responsible for convert {@link FlinkLogicalCorrelate} to\n+ * {@link DataStreamPythonCorrelate}.\n+ */\n+public class DataStreamPythonCorrelateRule extends AbstractPythonCorrelateRuleBase {\n+\n+\tpublic static final RelOptRule INSTANCE = new DataStreamPythonCorrelateRule();\n+\n+\tprivate DataStreamPythonCorrelateRule() {\n+\t\tsuper(FlinkConventions.DATASTREAM(), \"DataStreamPythonCorrelateRule\");\n+\t}\n+\n+\t@Override\n+\tpublic RelNode convert(RelNode rel) {\n+\t\tDataStreamPythonCorrelateFactory factory = new DataStreamPythonCorrelateFactory(rel);\n+\t\treturn factory.convertToCorrelate();\n+\t}\n+\n+\t/**\n+\t * The factory is responsible to creating {@link DataStreamPythonCorrelate}.\n+\t */\n+\tprivate static class DataStreamPythonCorrelateFactory extends PythonCorrelateFactoryBase{", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d2e31fab3e7e023346cbec86fbb239c80310895"}, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTE1OTUxOA==", "bodyText": "Maybe more details that why we always copy the input Row. What do you think?", "url": "https://github.com/apache/flink/pull/11668#discussion_r411159518", "createdAt": "2020-04-20T07:37:31Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/table/runtime/functions/python/PythonTableFunctionFlatMap.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.functions.python;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.functions.RichFlatMapFunction;\n+import org.apache.flink.api.java.typeutils.RowTypeInfo;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.python.PythonFunctionRunner;\n+import org.apache.flink.table.functions.TableFunction;\n+import org.apache.flink.table.functions.python.PythonEnv;\n+import org.apache.flink.table.functions.python.PythonFunctionInfo;\n+import org.apache.flink.table.runtime.runners.python.table.PythonTableFunctionRunner;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.table.types.utils.TypeConversions;\n+import org.apache.flink.types.Row;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.beam.sdk.fn.data.FnDataReceiver;\n+import org.apache.calcite.rel.core.JoinRelType;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+/**\n+ * The {@link RichFlatMapFunction} used to invoke Python {@link TableFunction} functions for the\n+ * old planner.\n+ */\n+@Internal\n+public final class PythonTableFunctionFlatMap extends AbstractPythonStatelessFunctionFlatMap {\n+\n+\tprivate static final long serialVersionUID = 1L;\n+\n+\t/**\n+\t * The Python {@link TableFunction} to be executed.\n+\t */\n+\tprivate final PythonFunctionInfo tableFunction;\n+\n+\t/**\n+\t * The correlate join type.\n+\t */\n+\tprivate final JoinRelType joinType;\n+\n+\tpublic PythonTableFunctionFlatMap(\n+\t\tConfiguration config,\n+\t\tPythonFunctionInfo tableFunction,\n+\t\tRowType inputType,\n+\t\tRowType outputType,\n+\t\tint[] udtfInputOffsets,\n+\t\tJoinRelType joinType) {\n+\t\tsuper(config, inputType, outputType, udtfInputOffsets);\n+\t\tthis.tableFunction = Preconditions.checkNotNull(tableFunction);\n+\t\tPreconditions.checkArgument(\n+\t\t\tjoinType == JoinRelType.INNER || joinType == JoinRelType.LEFT,\n+\t\t\t\"The join type should be inner join or left join\");\n+\t\tthis.joinType = joinType;\n+\t}\n+\n+\t@Override\n+\tpublic void open(Configuration parameters) throws Exception {\n+\t\tRowTypeInfo forwardedInputTypeInfo = (RowTypeInfo) TypeConversions.fromDataTypeToLegacyInfo(\n+\t\t\tTypeConversions.fromLogicalToDataType(inputType));\n+\t\tforwardedInputSerializer = forwardedInputTypeInfo.createSerializer(getRuntimeContext().getExecutionConfig());\n+\n+\t\tList<RowType.RowField> udtfOutputDataFields = new ArrayList<>(\n+\t\t\toutputType.getFields().subList(inputType.getFieldCount(), outputType.getFieldCount()));\n+\t\tuserDefinedFunctionOutputType = new RowType(udtfOutputDataFields);\n+\n+\t\tsuper.open(parameters);\n+\t}\n+\n+\t@Override\n+\tpublic PythonEnv getPythonEnv() {\n+\t\treturn tableFunction.getPythonFunction().getPythonEnv();\n+\t}\n+\n+\t@Override\n+\tpublic PythonFunctionRunner<Row> createPythonFunctionRunner() throws IOException {\n+\t\tFnDataReceiver<byte[]> userDefinedFunctionResultReceiver = input -> {\n+\t\t\t// handover to queue, do not block the result receiver thread\n+\t\t\tuserDefinedFunctionResultQueue.put(input);\n+\t\t};\n+\n+\t\treturn new PythonTableFunctionRunner(\n+\t\t\tgetRuntimeContext().getTaskName(),\n+\t\t\tuserDefinedFunctionResultReceiver,\n+\t\t\ttableFunction,\n+\t\t\tcreatePythonEnvironmentManager(),\n+\t\t\tuserDefinedFunctionInputType,\n+\t\t\tuserDefinedFunctionOutputType,\n+\t\t\tjobOptions,\n+\t\t\tgetFlinkMetricContainer());\n+\t}\n+\n+\t@Override\n+\tpublic void bufferInput(Row input) {\n+\t\t// always copy the input Row", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d2e31fab3e7e023346cbec86fbb239c80310895"}, "originalPosition": 114}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5f203f2938f094ccfa22f05d3dfdddbcfa210e81", "author": {"user": {"login": "HuangXingBo", "name": null}}, "url": "https://github.com/apache/flink/commit/5f203f2938f094ccfa22f05d3dfdddbcfa210e81", "committedDate": "2020-04-20T12:20:05Z", "message": "fix-2"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1973, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}