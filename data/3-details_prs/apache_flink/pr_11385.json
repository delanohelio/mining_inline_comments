{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg2OTg2ODI1", "number": 11385, "title": "[FLINK-11395][formats] Support for Avro StreamingFileSink", "bodyText": "What is the purpose of the change\nThis PR supports Avro writers to the StreamingFileSink.\nBrief change log\n\nf5daa5c add the avro writer.\n\nVerifying this change\n\nAdded unit test to verify the Avro writer creates right files.\n\nDoes this pull request potentially affect one of the following parts:\n\nDependencies (does it add or upgrade a dependency): no\nThe public API, i.e., is any changed class annotated with @Public(Evolving): no\nThe serializers: no\nThe runtime per-record code paths (performance sensitive): no\nAnything that affects deployment or recovery: JobManager (and its components), Checkpointing, Kubernetes/Yarn/Mesos, ZooKeeper: no\nThe S3 file system connector: no\n\nDocumentation\n\nDoes this pull request introduce a new feature? no\nIf yes, how is the feature documented? not applicable", "createdAt": "2020-03-12T00:53:41Z", "url": "https://github.com/apache/flink/pull/11385", "merged": true, "mergeCommit": {"oid": "965c1018454ab438e4500cf68a9cfa820298e1c6"}, "closed": true, "closedAt": "2020-05-15T12:39:38Z", "author": {"login": "gaoyunhaii"}, "timelineItems": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcMxQ4xABqjMxMjEwNzQ0NTk=", "endCursor": "Y3Vyc29yOnYyOpPPAAABchcfvwABqjMzMzk2MTUzMDU=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f878f74b9dd6bd4794f070960cc77c15f2ed94f7", "author": {"user": null}, "url": "https://github.com/apache/flink/commit/f878f74b9dd6bd4794f070960cc77c15f2ed94f7", "committedDate": "2020-03-12T00:49:59Z", "message": "[FLINK-11395][formats] Support for Avro StreamingFileSink"}, "afterCommit": {"oid": "9e1bbeafa1a4d0f673ebba7f87ef9032253a29f0", "author": {"user": null}, "url": "https://github.com/apache/flink/commit/9e1bbeafa1a4d0f673ebba7f87ef9032253a29f0", "committedDate": "2020-03-12T01:16:37Z", "message": "[FLINK-11395][formats] Support for Avro StreamingFileSink"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9e1bbeafa1a4d0f673ebba7f87ef9032253a29f0", "author": {"user": null}, "url": "https://github.com/apache/flink/commit/9e1bbeafa1a4d0f673ebba7f87ef9032253a29f0", "committedDate": "2020-03-12T01:16:37Z", "message": "[FLINK-11395][formats] Support for Avro StreamingFileSink"}, "afterCommit": {"oid": "f5daa5c0432bbc64add6d302841f26e9d919ce98", "author": {"user": null}, "url": "https://github.com/apache/flink/commit/f5daa5c0432bbc64add6d302841f26e9d919ce98", "committedDate": "2020-03-13T05:40:35Z", "message": "[FLINK-11395][formats] Support for Avro StreamingFileSink"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA5OTYwNDQ1", "url": "https://github.com/apache/flink/pull/11385#pullrequestreview-409960445", "createdAt": "2020-05-12T11:48:32Z", "commit": {"oid": "f5daa5c0432bbc64add6d302841f26e9d919ce98"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxMTo0ODozMlrOGUCzVg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxMTo1MTo0NVrOGUC5vQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzY3MDYxNA==", "bodyText": "To configure what? This interface looks weird to me.", "url": "https://github.com/apache/flink/pull/11385#discussion_r423670614", "createdAt": "2020-05-12T11:48:32Z", "author": {"login": "JingsongLi"}, "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroWriters.java", "diffHunk": "@@ -0,0 +1,197 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.formats.avro;\n+\n+import org.apache.avro.Schema;\n+import org.apache.avro.file.DataFileWriter;\n+import org.apache.avro.generic.GenericDatumWriter;\n+import org.apache.avro.generic.GenericRecord;\n+import org.apache.avro.io.DatumWriter;\n+import org.apache.avro.reflect.ReflectData;\n+import org.apache.avro.reflect.ReflectDatumWriter;\n+import org.apache.avro.specific.SpecificData;\n+import org.apache.avro.specific.SpecificDatumWriter;\n+import org.apache.avro.specific.SpecificRecord;\n+import org.apache.avro.specific.SpecificRecordBase;\n+\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.io.Serializable;\n+\n+/**\n+ * Convenience builder to create {@link AvroWriterFactory} instances for the different Avro types.\n+ */\n+public class AvroWriters {\n+\n+\t/**\n+\t * A configurator to set the properties of the writer.\n+\t */\n+\tpublic interface WriterConfigurator<T> extends Serializable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f5daa5c0432bbc64add6d302841f26e9d919ce98"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzY3MTY5MA==", "bodyText": "Pass a Function<Schema, DatumWriter>?", "url": "https://github.com/apache/flink/pull/11385#discussion_r423671690", "createdAt": "2020-05-12T11:50:42Z", "author": {"login": "JingsongLi"}, "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroWriters.java", "diffHunk": "@@ -0,0 +1,197 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.formats.avro;\n+\n+import org.apache.avro.Schema;\n+import org.apache.avro.file.DataFileWriter;\n+import org.apache.avro.generic.GenericDatumWriter;\n+import org.apache.avro.generic.GenericRecord;\n+import org.apache.avro.io.DatumWriter;\n+import org.apache.avro.reflect.ReflectData;\n+import org.apache.avro.reflect.ReflectDatumWriter;\n+import org.apache.avro.specific.SpecificData;\n+import org.apache.avro.specific.SpecificDatumWriter;\n+import org.apache.avro.specific.SpecificRecord;\n+import org.apache.avro.specific.SpecificRecordBase;\n+\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.io.Serializable;\n+\n+/**\n+ * Convenience builder to create {@link AvroWriterFactory} instances for the different Avro types.\n+ */\n+public class AvroWriters {\n+\n+\t/**\n+\t * A configurator to set the properties of the writer.\n+\t */\n+\tpublic interface WriterConfigurator<T> extends Serializable {\n+\n+\t\t/**\n+\t\t * Modifies the properties of the writer.\n+\t\t *\n+\t\t * @param dataFileWriter The writer to modify.\n+\t\t */\n+\t\tvoid configureWriter(DataFileWriter<T> dataFileWriter);\n+\n+\t}\n+\n+\t/**\n+\t * Creates an {@link AvroWriterFactory} for an Avro specific type. The Avro writers\n+\t * will use the schema of that specific type to build and write the records.\n+\t *\n+\t * @param type The class of the type to write.\n+\t */\n+\tpublic static <T extends SpecificRecordBase> AvroWriterFactory<T> forSpecificRecord(Class<T> type) {\n+\t\treturn forSpecificRecord(type, writer -> {});\n+\t}\n+\n+\t/**\n+\t * Creates an {@link AvroWriterFactory} for an Avro specific type and given <tt>configurator</tt>.\n+\t * The Avro writers will use the schema of that specific type to build and write the records.\n+\t *\n+\t * @param type The class of the type to write.\n+\t * @param configurator The configurator to modify the writer properties.\n+\t */\n+\tpublic static <T extends SpecificRecordBase> AvroWriterFactory<T> forSpecificRecord(\n+\t\tClass<T> type,\n+\t\tWriterConfigurator<T> configurator) {\n+\n+\t\tString schemaString = SpecificData.get().getSchema(type).toString();\n+\t\tAvroBuilder<T> builder = (out) -> createAvroDataFileWriter(\n+\t\t\tschemaString,\n+\t\t\tAvroRecordType.SPECIFIC,\n+\t\t\tconfigurator,\n+\t\t\tout);\n+\t\treturn new AvroWriterFactory<>(builder);\n+\t}\n+\n+\t/**\n+\t * Creates an {@link AvroWriterFactory} that accepts and writes Avro generic types.\n+\t * The Avro writers will use the given schema to build and write the records.\n+\t *\n+\t * @param schema The schema of the generic type.\n+\t */\n+\tpublic static AvroWriterFactory<GenericRecord> forGenericRecord(Schema schema) {\n+\t\treturn forGenericRecord(schema, writer -> {});\n+\t}\n+\n+\t/**\n+\t * Creates an {@link AvroWriterFactory} that accepts and writes Avro generic types\n+\t * and given <tt>configurator</tt>. The Avro writers will use the given schema to\n+\t * build and write the records.\n+\t *\n+\t * @param schema The schema of the generic type.\n+\t * @param configurator The configurator to modify the writer properties.\n+\t */\n+\tpublic static AvroWriterFactory<GenericRecord> forGenericRecord(\n+\t\tSchema schema,\n+\t\tWriterConfigurator<GenericRecord> configurator) {\n+\n+\t\tString schemaString = schema.toString();\n+\t\tAvroBuilder<GenericRecord> builder = (out) -> createAvroDataFileWriter(\n+\t\t\tschemaString,\n+\t\t\tAvroRecordType.GENERIC,\n+\t\t\tconfigurator,\n+\t\t\tout);\n+\t\treturn new AvroWriterFactory<>(builder);\n+\t}\n+\n+\t/**\n+\t * Creates an {@link AvroWriterFactory} for the given type. The Avro writers will\n+\t * use reflection to create the schema for the type and use that schema to write\n+\t * the records.\n+\t *\n+\t * @param type The class of the type to write.\n+\t */\n+\tpublic static <T> AvroWriterFactory<T> forReflectRecord(Class<T> type) {\n+\t\treturn forReflectRecord(type, writer -> {});\n+\t}\n+\n+\t/**\n+\t * Creates an {@link AvroWriterFactory} for the given type and given <tt>configurator</tt>.\n+\t * The Avro writers will use reflection to create the schema for the type and use that schema\n+\t * to write the records.\n+\t *\n+\t * @param type The class of the type to write.\n+\t * @param configurator The configurator to modify the writer properties.\n+\t */\n+\tpublic static <T> AvroWriterFactory<T> forReflectRecord(\n+\t\tClass<T> type,\n+\t\tWriterConfigurator<T> configurator) {\n+\n+\t\tString schemaString = ReflectData.get().getSchema(type).toString();\n+\t\tAvroBuilder<T> builder = (out) -> createAvroDataFileWriter(\n+\t\t\tschemaString,\n+\t\t\tAvroRecordType.REFLECT,\n+\t\t\tconfigurator,\n+\t\t\tout);\n+\t\treturn new AvroWriterFactory<>(builder);\n+\t}\n+\n+\tprivate static <T> DataFileWriter<T> createAvroDataFileWriter(\n+\t\tString schemaString,\n+\t\tAvroRecordType recordType,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f5daa5c0432bbc64add6d302841f26e9d919ce98"}, "originalPosition": 151}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzY3MjI1Mw==", "bodyText": "Just Schema?", "url": "https://github.com/apache/flink/pull/11385#discussion_r423672253", "createdAt": "2020-05-12T11:51:45Z", "author": {"login": "JingsongLi"}, "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroWriters.java", "diffHunk": "@@ -0,0 +1,197 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.formats.avro;\n+\n+import org.apache.avro.Schema;\n+import org.apache.avro.file.DataFileWriter;\n+import org.apache.avro.generic.GenericDatumWriter;\n+import org.apache.avro.generic.GenericRecord;\n+import org.apache.avro.io.DatumWriter;\n+import org.apache.avro.reflect.ReflectData;\n+import org.apache.avro.reflect.ReflectDatumWriter;\n+import org.apache.avro.specific.SpecificData;\n+import org.apache.avro.specific.SpecificDatumWriter;\n+import org.apache.avro.specific.SpecificRecord;\n+import org.apache.avro.specific.SpecificRecordBase;\n+\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.io.Serializable;\n+\n+/**\n+ * Convenience builder to create {@link AvroWriterFactory} instances for the different Avro types.\n+ */\n+public class AvroWriters {\n+\n+\t/**\n+\t * A configurator to set the properties of the writer.\n+\t */\n+\tpublic interface WriterConfigurator<T> extends Serializable {\n+\n+\t\t/**\n+\t\t * Modifies the properties of the writer.\n+\t\t *\n+\t\t * @param dataFileWriter The writer to modify.\n+\t\t */\n+\t\tvoid configureWriter(DataFileWriter<T> dataFileWriter);\n+\n+\t}\n+\n+\t/**\n+\t * Creates an {@link AvroWriterFactory} for an Avro specific type. The Avro writers\n+\t * will use the schema of that specific type to build and write the records.\n+\t *\n+\t * @param type The class of the type to write.\n+\t */\n+\tpublic static <T extends SpecificRecordBase> AvroWriterFactory<T> forSpecificRecord(Class<T> type) {\n+\t\treturn forSpecificRecord(type, writer -> {});\n+\t}\n+\n+\t/**\n+\t * Creates an {@link AvroWriterFactory} for an Avro specific type and given <tt>configurator</tt>.\n+\t * The Avro writers will use the schema of that specific type to build and write the records.\n+\t *\n+\t * @param type The class of the type to write.\n+\t * @param configurator The configurator to modify the writer properties.\n+\t */\n+\tpublic static <T extends SpecificRecordBase> AvroWriterFactory<T> forSpecificRecord(\n+\t\tClass<T> type,\n+\t\tWriterConfigurator<T> configurator) {\n+\n+\t\tString schemaString = SpecificData.get().getSchema(type).toString();\n+\t\tAvroBuilder<T> builder = (out) -> createAvroDataFileWriter(\n+\t\t\tschemaString,\n+\t\t\tAvroRecordType.SPECIFIC,\n+\t\t\tconfigurator,\n+\t\t\tout);\n+\t\treturn new AvroWriterFactory<>(builder);\n+\t}\n+\n+\t/**\n+\t * Creates an {@link AvroWriterFactory} that accepts and writes Avro generic types.\n+\t * The Avro writers will use the given schema to build and write the records.\n+\t *\n+\t * @param schema The schema of the generic type.\n+\t */\n+\tpublic static AvroWriterFactory<GenericRecord> forGenericRecord(Schema schema) {\n+\t\treturn forGenericRecord(schema, writer -> {});\n+\t}\n+\n+\t/**\n+\t * Creates an {@link AvroWriterFactory} that accepts and writes Avro generic types\n+\t * and given <tt>configurator</tt>. The Avro writers will use the given schema to\n+\t * build and write the records.\n+\t *\n+\t * @param schema The schema of the generic type.\n+\t * @param configurator The configurator to modify the writer properties.\n+\t */\n+\tpublic static AvroWriterFactory<GenericRecord> forGenericRecord(\n+\t\tSchema schema,\n+\t\tWriterConfigurator<GenericRecord> configurator) {\n+\n+\t\tString schemaString = schema.toString();\n+\t\tAvroBuilder<GenericRecord> builder = (out) -> createAvroDataFileWriter(\n+\t\t\tschemaString,\n+\t\t\tAvroRecordType.GENERIC,\n+\t\t\tconfigurator,\n+\t\t\tout);\n+\t\treturn new AvroWriterFactory<>(builder);\n+\t}\n+\n+\t/**\n+\t * Creates an {@link AvroWriterFactory} for the given type. The Avro writers will\n+\t * use reflection to create the schema for the type and use that schema to write\n+\t * the records.\n+\t *\n+\t * @param type The class of the type to write.\n+\t */\n+\tpublic static <T> AvroWriterFactory<T> forReflectRecord(Class<T> type) {\n+\t\treturn forReflectRecord(type, writer -> {});\n+\t}\n+\n+\t/**\n+\t * Creates an {@link AvroWriterFactory} for the given type and given <tt>configurator</tt>.\n+\t * The Avro writers will use reflection to create the schema for the type and use that schema\n+\t * to write the records.\n+\t *\n+\t * @param type The class of the type to write.\n+\t * @param configurator The configurator to modify the writer properties.\n+\t */\n+\tpublic static <T> AvroWriterFactory<T> forReflectRecord(\n+\t\tClass<T> type,\n+\t\tWriterConfigurator<T> configurator) {\n+\n+\t\tString schemaString = ReflectData.get().getSchema(type).toString();\n+\t\tAvroBuilder<T> builder = (out) -> createAvroDataFileWriter(\n+\t\t\tschemaString,\n+\t\t\tAvroRecordType.REFLECT,\n+\t\t\tconfigurator,\n+\t\t\tout);\n+\t\treturn new AvroWriterFactory<>(builder);\n+\t}\n+\n+\tprivate static <T> DataFileWriter<T> createAvroDataFileWriter(\n+\t\tString schemaString,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f5daa5c0432bbc64add6d302841f26e9d919ce98"}, "originalPosition": 150}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f5daa5c0432bbc64add6d302841f26e9d919ce98", "author": {"user": null}, "url": "https://github.com/apache/flink/commit/f5daa5c0432bbc64add6d302841f26e9d919ce98", "committedDate": "2020-03-13T05:40:35Z", "message": "[FLINK-11395][formats] Support for Avro StreamingFileSink"}, "afterCommit": {"oid": "f7b6b1a8fa6eb65d34a8020a154e0d94c86cc4e6", "author": {"user": {"login": "gaoyunhaii", "name": "Yun Gao"}}, "url": "https://github.com/apache/flink/commit/f7b6b1a8fa6eb65d34a8020a154e0d94c86cc4e6", "committedDate": "2020-05-13T04:16:08Z", "message": "Address comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDExNDI0MzY4", "url": "https://github.com/apache/flink/pull/11385#pullrequestreview-411424368", "createdAt": "2020-05-14T02:30:46Z", "commit": {"oid": "55bbaced3ca77aecde372a75505363cceb280fb6"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "55bbaced3ca77aecde372a75505363cceb280fb6", "author": {"user": {"login": "gaoyunhaii", "name": "Yun Gao"}}, "url": "https://github.com/apache/flink/commit/55bbaced3ca77aecde372a75505363cceb280fb6", "committedDate": "2020-05-14T01:57:05Z", "message": "Remove data file writer configuror"}, "afterCommit": {"oid": "88eb4f91c72b735fe947ea5beb4ab430138a6077", "author": {"user": {"login": "gaoyunhaii", "name": "Yun Gao"}}, "url": "https://github.com/apache/flink/commit/88eb4f91c72b735fe947ea5beb4ab430138a6077", "committedDate": "2020-05-15T03:18:38Z", "message": "Remove data file writer configuror"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bd4df28b75f51afcf7d1bac5ee1a1e686f064c4a", "author": {"user": null}, "url": "https://github.com/apache/flink/commit/bd4df28b75f51afcf7d1bac5ee1a1e686f064c4a", "committedDate": "2020-05-15T06:57:22Z", "message": "[FLINK-11395][formats] Support for Avro StreamingFileSink"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cab7822e2f7a63daa2a5eab32426790519764e6d", "author": {"user": {"login": "gaoyunhaii", "name": "Yun Gao"}}, "url": "https://github.com/apache/flink/commit/cab7822e2f7a63daa2a5eab32426790519764e6d", "committedDate": "2020-05-15T06:57:22Z", "message": "Address comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "06c125ce79d2719ac9d217aa90a2ce9881fec3da", "author": {"user": {"login": "gaoyunhaii", "name": "Yun Gao"}}, "url": "https://github.com/apache/flink/commit/06c125ce79d2719ac9d217aa90a2ce9881fec3da", "committedDate": "2020-05-15T06:57:22Z", "message": "Remove data file writer configuror"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "88eb4f91c72b735fe947ea5beb4ab430138a6077", "author": {"user": {"login": "gaoyunhaii", "name": "Yun Gao"}}, "url": "https://github.com/apache/flink/commit/88eb4f91c72b735fe947ea5beb4ab430138a6077", "committedDate": "2020-05-15T03:18:38Z", "message": "Remove data file writer configuror"}, "afterCommit": {"oid": "06c125ce79d2719ac9d217aa90a2ce9881fec3da", "author": {"user": {"login": "gaoyunhaii", "name": "Yun Gao"}}, "url": "https://github.com/apache/flink/commit/06c125ce79d2719ac9d217aa90a2ce9881fec3da", "committedDate": "2020-05-15T06:57:22Z", "message": "Remove data file writer configuror"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2713, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}