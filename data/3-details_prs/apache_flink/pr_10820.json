{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzYxMTAyNjI0", "number": 10820, "title": "[FLINK-15512][statebackend] Refactor the mechanism to calculate the cache capacity shared among RocksDB instance(s)", "bodyText": "What is the purpose of the change\nDue to the implemenation of write buffer manager of RocksDB and the issue cannot create stric capacity limit cache, we need to refactor the mechanism to calculate the cache capacity shared among RocksDB instance(s).\nBrief change log\n\nIntroduce RocksDBOperationUtils.java#calculateActualCacheSize to calculate actual cache size.\nAdd test testCreateSharedResourcesWithExpectedCapacity to verify the capacity of cache created is what we want.\n\nVerifying this change\nThis change added tests and can be verified as follows:\n\nAdded testCreateSharedResourcesWithExpectedCapacity to verify the capacity of cache created is what we want.\n\nDoes this pull request potentially affect one of the following parts:\n\nDependencies (does it add or upgrade a dependency): no\nThe public API, i.e., is any changed class annotated with @Public(Evolving): no\nThe serializers: no\nThe runtime per-record code paths (performance sensitive): no\nAnything that affects deployment or recovery: JobManager (and its components), Checkpointing, Yarn/Mesos, ZooKeeper: no\nThe S3 file system connector: no\n\nDocumentation\n\nDoes this pull request introduce a new feature? no\nIf yes, how is the feature documented? not applicable", "createdAt": "2020-01-09T18:44:22Z", "url": "https://github.com/apache/flink/pull/10820", "merged": true, "mergeCommit": {"oid": "346e2e02af385d7482376c25d2c3de09b89c1111"}, "closed": true, "closedAt": "2020-01-13T03:47:40Z", "author": {"login": "Myasuka"}, "timelineItems": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABb4uDFAgH2gAyMzYxMTAyNjI0OmJmYzZjNGE0ZjdiYWEwYmVjODVhOTEwNWI5NjAxNGJiMWZhNWNlODc=", "endCursor": "Y3Vyc29yOnYyOpPPAAABb5nKMvgH2gAyMzYxMTAyNjI0OjU4NGIwNGMzNzU2ZGZkODcyM2ExMDNiOGYxNTAyYjRiY2NmM2E2YTY=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "bfc6c4a4f7baa0bec85a9105b96014bb1fa5ce87", "author": {"user": {"login": "Myasuka", "name": "Yun Tang"}}, "url": "https://github.com/apache/flink/commit/bfc6c4a4f7baa0bec85a9105b96014bb1fa5ce87", "committedDate": "2020-01-09T18:13:41Z", "message": "[FLINK-15512][statebackend] Refactor the mechanism to calculate the cache capacity shared among RocksDB instance(s)\n\nDue to the implemenation of write buffer manager of RocksDB and the issue cannot create stric capacity limit cache, we need to refactor the mechanism to calculate the cache capacity shared among RocksDB instance(s)."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQxMDE4MTcx", "url": "https://github.com/apache/flink/pull/10820#pullrequestreview-341018171", "createdAt": "2020-01-10T08:42:26Z", "commit": {"oid": "bfc6c4a4f7baa0bec85a9105b96014bb1fa5ce87"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQwODo0MjoyNlrOFcNW6w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQxMzoxNTo0MlrOFcTvmw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTEyMzMwNw==", "bodyText": "Wondering why this description need to be changed, please clarify, thanks.", "url": "https://github.com/apache/flink/pull/10820#discussion_r365123307", "createdAt": "2020-01-10T08:42:26Z", "author": {"login": "carp84"}, "path": "docs/_includes/generated/rocks_db_configuration.html", "diffHunk": "@@ -30,7 +30,7 @@\n             <td><h5>state.backend.rocksdb.memory.high-prio-pool-ratio</h5></td>\n             <td style=\"word-wrap: break-word;\">0.1</td>\n             <td>Double</td>\n-            <td>The fraction of cache memory that is reserved for high-priority data like index, filter, and compression dictionary blocks. This option only has an effect when 'state.backend.rocksdb.memory.managed' or 'state.backend.rocksdb.memory.fixed-per-slot' are configured.</td>\n+            <td>The fraction of total shared memory that is reserved for high-priority data like index, filter, and compression dictionary blocks. This option only has an effect when 'state.backend.rocksdb.memory.managed' or 'state.backend.rocksdb.memory.fixed-per-slot' are configured.</td>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bfc6c4a4f7baa0bec85a9105b96014bb1fa5ce87"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTEyNzU2OQ==", "bodyText": "Suggest to add a TODO comment here, mentioning that we will change the strictCapacityLimit flag to true after rocksdb#6247 is resolved.", "url": "https://github.com/apache/flink/pull/10820#discussion_r365127569", "createdAt": "2020-01-10T08:53:15Z", "author": {"login": "carp84"}, "path": "flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOperationUtils.java", "diffHunk": "@@ -213,4 +211,40 @@ public static void addColumnFamilyOptionsToCloseLater(\n \t\t\tthrow new IOException(\"Failed to acquire shared cache resource for RocksDB\", e);\n \t\t}\n \t}\n+\n+\t@VisibleForTesting\n+\tstatic RocksDBSharedResources allocateRocksDBSharedResources(long size, double writeBufferRatio, double highPriorityPoolRatio) {\n+\t\tlong calculatedCacheSize = calculateActualCacheSize(size, writeBufferRatio);\n+\t\tfinal Cache cache = createCache(calculatedCacheSize, highPriorityPoolRatio);\n+\t\tfinal WriteBufferManager wbm = new WriteBufferManager((long) (writeBufferRatio * size), cache);\n+\t\treturn new RocksDBSharedResources(cache, wbm);\n+\t}\n+\n+\t/**\n+\t * Calculate the actual calculated memory size of cache, which would be shared among rocksDB instance(s).\n+\t * We introduce this method because:\n+\t * a) We cannot create a strict capacity limit cache util FLINK-15532 resolved.\n+\t * b) Regardless of the memory usage of blocks pinned by RocksDB iterators,\n+\t * which is difficult to calculate and only happened when we iterator entries in RocksDBMapState, the overuse of memory is mainly occupied by at most half of the write buffer usage.\n+\t * (see <a href=\"https://github.com/dataArtisans/frocksdb/blob/958f191d3f7276ae59b270f9db8390034d549ee0/include/rocksdb/write_buffer_manager.h#L51\">the flush implementation of write buffer manager</a>).\n+\t * Thus, we have four equations below:\n+\t *   write_buffer_manager_memory = 1.5 * write_buffer_manager_capacity\n+\t *   write_buffer_manager_memory = total_memory_size * write_buffer_ratio\n+\t *   write_buffer_manager_memory + other_part = total_memory_size\n+\t *   write_buffer_manager_capacity + other_part = cache_size\n+\t * And we would deduce the formula: cache_size = 3 * total_memory_size / (3 + write_buffer_ratio)\n+\t *\n+\t * @param totalMemorySize  Total off-heap memory size reserved for RocksDB instance(s).\n+\t * @param writeBufferRatio The ratio of memory size which could be reserved for write buffer manager to control the memory usage.\n+\t * @return The actual calculated memory size.\n+\t */\n+\t@VisibleForTesting\n+\tstatic long calculateActualCacheSize(long totalMemorySize, double writeBufferRatio) {\n+\t\treturn (long) (3 * totalMemorySize / (3 + writeBufferRatio));\n+\t}\n+\n+\t@VisibleForTesting\n+\tstatic Cache createCache(long cacheSize, double highPriorityPoolRatio) {\n+\t\treturn new LRUCache(cacheSize, -1, false, highPriorityPoolRatio);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bfc6c4a4f7baa0bec85a9105b96014bb1fa5ce87"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTEyNzkyNA==", "bodyText": "Ditto, please revert this change if no rational reason.", "url": "https://github.com/apache/flink/pull/10820#discussion_r365127924", "createdAt": "2020-01-10T08:54:07Z", "author": {"login": "carp84"}, "path": "flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOptions.java", "diffHunk": "@@ -121,7 +121,7 @@\n \t\t.doubleType()\n \t\t.defaultValue(0.1)\n \t\t.withDescription(String.format(\n-\t\t\t\t\"The fraction of cache memory that is reserved for high-priority data like index, filter, and \" +\n+\t\t\t\t\"The fraction of total shared memory that is reserved for high-priority data like index, filter, and \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bfc6c4a4f7baa0bec85a9105b96014bb1fa5ce87"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTIyNjkxMA==", "bodyText": "The WriteBufferManager size should also be calculated with the deduced formula: 2 * total_memory_size * write_buffer_ratio / 3", "url": "https://github.com/apache/flink/pull/10820#discussion_r365226910", "createdAt": "2020-01-10T13:12:41Z", "author": {"login": "carp84"}, "path": "flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOperationUtils.java", "diffHunk": "@@ -213,4 +211,40 @@ public static void addColumnFamilyOptionsToCloseLater(\n \t\t\tthrow new IOException(\"Failed to acquire shared cache resource for RocksDB\", e);\n \t\t}\n \t}\n+\n+\t@VisibleForTesting\n+\tstatic RocksDBSharedResources allocateRocksDBSharedResources(long size, double writeBufferRatio, double highPriorityPoolRatio) {\n+\t\tlong calculatedCacheSize = calculateActualCacheSize(size, writeBufferRatio);\n+\t\tfinal Cache cache = createCache(calculatedCacheSize, highPriorityPoolRatio);\n+\t\tfinal WriteBufferManager wbm = new WriteBufferManager((long) (writeBufferRatio * size), cache);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bfc6c4a4f7baa0bec85a9105b96014bb1fa5ce87"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTIyNzkzMQ==", "bodyText": "The design of this test seems to be tightly coupled with the implementation, while it's true that we cannot get the actual cache size through RocksDB's JNI (not exposed so reflection couldn't get it, either)", "url": "https://github.com/apache/flink/pull/10820#discussion_r365227931", "createdAt": "2020-01-10T13:15:42Z", "author": {"login": "carp84"}, "path": "flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBResourceContainerTest.java", "diffHunk": "@@ -145,12 +160,34 @@ public void testGetColumnFamilyOptionsWithSharedResources() throws Exception {\n \t\tcontainer.close();\n \t}\n \n+\t@Test\n+\tpublic void testCreateSharedResourcesWithExpectedCapacity() throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bfc6c4a4f7baa0bec85a9105b96014bb1fa5ce87"}, "originalPosition": 61}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "64d8a9a6821c95f904ca567afd7a056be7f04f3a", "author": {"user": {"login": "Myasuka", "name": "Yun Tang"}}, "url": "https://github.com/apache/flink/commit/64d8a9a6821c95f904ca567afd7a056be7f04f3a", "committedDate": "2020-01-10T17:25:47Z", "message": "address comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQxNTU5NjY3", "url": "https://github.com/apache/flink/pull/10820#pullrequestreview-341559667", "createdAt": "2020-01-12T08:11:48Z", "commit": {"oid": "64d8a9a6821c95f904ca567afd7a056be7f04f3a"}, "state": "APPROVED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMlQwODoxMTo0OVrOFcoUKA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMlQwODoxMjozOVrOFcoUUg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTU2NDk2OA==", "bodyText": "I suggest to either remove this test, or also add a verification of write buffer manager size.", "url": "https://github.com/apache/flink/pull/10820#discussion_r365564968", "createdAt": "2020-01-12T08:11:49Z", "author": {"login": "carp84"}, "path": "flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBResourceContainerTest.java", "diffHunk": "@@ -145,12 +160,34 @@ public void testGetColumnFamilyOptionsWithSharedResources() throws Exception {\n \t\tcontainer.close();\n \t}\n \n+\t@Test\n+\tpublic void testCreateSharedResourcesWithExpectedCapacity() throws Exception {\n+\t\tPowerMockito.spy(RocksDBOperationUtils.class);\n+\t\tfinal AtomicLong actualCacheCapacity = new AtomicLong(0L);\n+\t\t// the `createCache` wrapper is introduced due to PowerMockito cannot mock on native static method easily.\n+\t\tPowerMockito.when(RocksDBOperationUtils.createCache(anyLong(), anyDouble()))\n+\t\t\t.thenAnswer((Answer<LRUCache>) invocation -> {\n+\t\t\t\tObject[] arguments = invocation.getArguments();\n+\t\t\t\tactualCacheCapacity.set((long) arguments[0]);\n+\t\t\t\treturn (LRUCache) invocation.callRealMethod();\n+\t\t\t});\n+\n+\t\tlong totalMemorySize = 2048L;\n+\t\tdouble writeBufferRatio = 0.5;\n+\t\tdouble highPriPoolRatio = 0.1;\n+\t\tcreateSharedResources(totalMemorySize, writeBufferRatio, highPriPoolRatio);\n+\t\tlong expectedCacheCapacity = RocksDBOperationUtils.calculateActualCacheCapacity(totalMemorySize, writeBufferRatio);\n+\t\tassertThat(actualCacheCapacity.get(), is(expectedCacheCapacity));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "64d8a9a6821c95f904ca567afd7a056be7f04f3a"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTU2NTAxMA==", "bodyText": "Minor: the actual calculated memory size -> the actual memory size", "url": "https://github.com/apache/flink/pull/10820#discussion_r365565010", "createdAt": "2020-01-12T08:12:39Z", "author": {"login": "carp84"}, "path": "flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOperationUtils.java", "diffHunk": "@@ -213,4 +211,49 @@ public static void addColumnFamilyOptionsToCloseLater(\n \t\t\tthrow new IOException(\"Failed to acquire shared cache resource for RocksDB\", e);\n \t\t}\n \t}\n+\n+\t@VisibleForTesting\n+\tstatic RocksDBSharedResources allocateRocksDBSharedResources(long memorySize, double writeBufferRatio, double highPriorityPoolRatio) {\n+\t\tlong calculatedCacheCapacity = calculateActualCacheCapacity(memorySize, writeBufferRatio);\n+\t\tfinal Cache cache = createCache(calculatedCacheCapacity, highPriorityPoolRatio);\n+\t\tlong writeBufferManagerCapacity = calculateWriteBufferManagerCapacity(memorySize, writeBufferRatio);\n+\t\tfinal WriteBufferManager wbm = new WriteBufferManager(writeBufferManagerCapacity, cache);\n+\t\treturn new RocksDBSharedResources(cache, wbm);\n+\t}\n+\n+\t/**\n+\t * Calculate the actual calculated memory size of cache, which would be shared among rocksDB instance(s).", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "64d8a9a6821c95f904ca567afd7a056be7f04f3a"}, "originalPosition": 37}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2d9edb24152bed26f717b6f87725efaa796d64e9", "author": {"user": {"login": "Myasuka", "name": "Yun Tang"}}, "url": "https://github.com/apache/flink/commit/2d9edb24152bed26f717b6f87725efaa796d64e9", "committedDate": "2020-01-12T12:44:26Z", "message": "address comments\n\n1. Add tests for wirte buffer manager\n2. Refactor RocksDBMemoryControllerUtils and its tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "584b04c3756dfd8723a103b8f1502b4bccf3a6a6", "author": {"user": {"login": "Myasuka", "name": "Yun Tang"}}, "url": "https://github.com/apache/flink/commit/584b04c3756dfd8723a103b8f1502b4bccf3a6a6", "committedDate": "2020-01-12T12:46:03Z", "message": "minor fix on docs"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4632, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}