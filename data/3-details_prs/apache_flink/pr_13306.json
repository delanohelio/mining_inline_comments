{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDc3NzkxMTk1", "number": 13306, "title": "[FLINK-17779][Connectors/ORC]Orc file format support filter push down", "bodyText": "What is the purpose of the change\nCurrently OrcFileSystemFormatFactory does not support filter pushdown, this PR implements this feature\nBrief change log\ncreate the conversion between CallExpression and Orc FilterPredicate\nVerifying this change\nThis change is already covered by existing tests\nDoes this pull request potentially affect one of the following parts:\n\nDependencies (does it add or upgrade a dependency): ( no)\nThe public API, i.e., is any changed class annotated with @Public(Evolving): (no)\nThe serializers: (no)\nThe runtime per-record code paths (performance sensitive): (no)\nAnything that affects deployment or recovery: JobManager (and its components), Checkpointing, Kubernetes/Yarn/Mesos, ZooKeeper: (no)\nThe S3 file system connector: (no)\n\nDocumentation\n\nDoes this pull request introduce a new feature? (yes)\nThe list of expressions that support filter pushdown:\n\nis null \nis not null \n= \n<>\n>\n>=\n<\n<=", "createdAt": "2020-09-02T12:39:29Z", "url": "https://github.com/apache/flink/pull/13306", "merged": true, "mergeCommit": {"oid": "cbda1f90faed90d6f6cbd9a7f16fecf004e1245d"}, "closed": true, "closedAt": "2020-09-10T04:09:56Z", "author": {"login": "meetjunsu"}, "timelineItems": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdFcU86gFqTQ4MjMyNTExOQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdHYzMwgFqTQ4NTU1MDkzMg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDgyMzI1MTE5", "url": "https://github.com/apache/flink/pull/13306#pullrequestreview-482325119", "createdAt": "2020-09-04T02:58:40Z", "commit": {"oid": "8048b8f9ded32203cb0ca0761414ef7186a68e5f"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQwMjo1ODo0MFrOHM91OQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQwMzowNTo1MVrOHM97yQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzM1ODAwOQ==", "bodyText": "Can you move these codes to a class: OrcFilters", "url": "https://github.com/apache/flink/pull/13306#discussion_r483358009", "createdAt": "2020-09-04T02:58:40Z", "author": {"login": "JingsongLi"}, "path": "flink-formats/flink-orc/src/main/java/org/apache/flink/orc/OrcFileSystemFormatFactory.java", "diffHunk": "@@ -83,14 +96,227 @@ private static Properties getOrcProperties(ReadableConfig options) {\n \t\treturn orcProperties;\n \t}\n \n+\tprivate boolean isUnaryValid(CallExpression callExpression) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8048b8f9ded32203cb0ca0761414ef7186a68e5f"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzM1ODk4Nw==", "bodyText": "Maybe we can have a static final ImmutableMap<FunctionDefinition, Function<CallExpression, Expression>> FILTERS. The function style can make codes better.", "url": "https://github.com/apache/flink/pull/13306#discussion_r483358987", "createdAt": "2020-09-04T03:02:43Z", "author": {"login": "JingsongLi"}, "path": "flink-formats/flink-orc/src/main/java/org/apache/flink/orc/OrcFileSystemFormatFactory.java", "diffHunk": "@@ -83,14 +96,227 @@ private static Properties getOrcProperties(ReadableConfig options) {\n \t\treturn orcProperties;\n \t}\n \n+\tprivate boolean isUnaryValid(CallExpression callExpression) {\n+\t\treturn callExpression.getChildren().size() == 1 && callExpression.getChildren().get(0) instanceof FieldReferenceExpression;\n+\t}\n+\n+\tprivate boolean isBinaryValid(CallExpression callExpression) {\n+\t\treturn callExpression.getChildren().size() == 2 && ((callExpression.getChildren().get(0) instanceof FieldReferenceExpression && callExpression.getChildren().get(1) instanceof ValueLiteralExpression) ||\n+\t\t\t\t(callExpression.getChildren().get(0) instanceof ValueLiteralExpression && callExpression.getChildren().get(1) instanceof FieldReferenceExpression));\n+\t}\n+\n+\tpublic OrcSplitReader.Predicate toOrcPredicate(Expression expression) {\n+\t\tif (expression instanceof CallExpression) {\n+\t\t\tCallExpression callExp = (CallExpression) expression;\n+\t\t\tFunctionDefinition funcDef = callExp.getFunctionDefinition();\n+\n+\t\t\tif (funcDef == BuiltInFunctionDefinitions.IS_NULL || funcDef == BuiltInFunctionDefinitions.IS_NOT_NULL || funcDef == BuiltInFunctionDefinitions.NOT) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8048b8f9ded32203cb0ca0761414ef7186a68e5f"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzM1OTY4OQ==", "bodyText": "Looks like bug here? We should add more cases.", "url": "https://github.com/apache/flink/pull/13306#discussion_r483359689", "createdAt": "2020-09-04T03:05:51Z", "author": {"login": "JingsongLi"}, "path": "flink-formats/flink-orc/src/main/java/org/apache/flink/orc/OrcFileSystemFormatFactory.java", "diffHunk": "@@ -83,14 +96,227 @@ private static Properties getOrcProperties(ReadableConfig options) {\n \t\treturn orcProperties;\n \t}\n \n+\tprivate boolean isUnaryValid(CallExpression callExpression) {\n+\t\treturn callExpression.getChildren().size() == 1 && callExpression.getChildren().get(0) instanceof FieldReferenceExpression;\n+\t}\n+\n+\tprivate boolean isBinaryValid(CallExpression callExpression) {\n+\t\treturn callExpression.getChildren().size() == 2 && ((callExpression.getChildren().get(0) instanceof FieldReferenceExpression && callExpression.getChildren().get(1) instanceof ValueLiteralExpression) ||\n+\t\t\t\t(callExpression.getChildren().get(0) instanceof ValueLiteralExpression && callExpression.getChildren().get(1) instanceof FieldReferenceExpression));\n+\t}\n+\n+\tpublic OrcSplitReader.Predicate toOrcPredicate(Expression expression) {\n+\t\tif (expression instanceof CallExpression) {\n+\t\t\tCallExpression callExp = (CallExpression) expression;\n+\t\t\tFunctionDefinition funcDef = callExp.getFunctionDefinition();\n+\n+\t\t\tif (funcDef == BuiltInFunctionDefinitions.IS_NULL || funcDef == BuiltInFunctionDefinitions.IS_NOT_NULL || funcDef == BuiltInFunctionDefinitions.NOT) {\n+\t\t\t\tif (!isUnaryValid(callExp)) {\n+\t\t\t\t\t// not a valid predicate\n+\t\t\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\t\t\treturn null;\n+\t\t\t\t}\n+\n+\t\t\t\tPredicateLeaf.Type colType = toOrcType(((FieldReferenceExpression) callExp.getChildren().get(0)).getOutputDataType());\n+\t\t\t\tif (colType == null) {\n+\t\t\t\t\t// unsupported type\n+\t\t\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcTableSource.\", callExp);\n+\t\t\t\t\treturn null;\n+\t\t\t\t}\n+\n+\t\t\t\tString colName = getColumnName(callExp);\n+\n+\t\t\t\tif (funcDef == BuiltInFunctionDefinitions.IS_NULL) {\n+\t\t\t\t\treturn new OrcSplitReader.IsNull(colName, colType);\n+\t\t\t\t} else if (funcDef == BuiltInFunctionDefinitions.IS_NOT_NULL) {\n+\t\t\t\t\treturn new OrcSplitReader.Not(\n+\t\t\t\t\t\t\tnew OrcSplitReader.IsNull(colName, colType));\n+\t\t\t\t} else {\n+\t\t\t\t\tOrcSplitReader.Predicate c = toOrcPredicate(callExp.getChildren().get(0));\n+\t\t\t\t\tif (c == null) {\n+\t\t\t\t\t\treturn null;\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\treturn new OrcSplitReader.Not(c);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t} else if (funcDef == BuiltInFunctionDefinitions.OR) {\n+\t\t\t\tif (callExp.getChildren().size() < 2) {\n+\t\t\t\t\treturn null;\n+\t\t\t\t}\n+\t\t\t\tExpression left = callExp.getChildren().get(0);\n+\t\t\t\tExpression right = callExp.getChildren().get(1);\n+\n+\t\t\t\tOrcSplitReader.Predicate c1 = toOrcPredicate(left);\n+\t\t\t\tOrcSplitReader.Predicate c2 = toOrcPredicate(right);\n+\t\t\t\tif (c1 == null || c2 == null) {\n+\t\t\t\t\treturn null;\n+\t\t\t\t} else {\n+\t\t\t\t\treturn new OrcSplitReader.Or(c1, c2);\n+\t\t\t\t}\n+\t\t\t} else {\n+\t\t\t\tif (!isBinaryValid(callExp)) {\n+\t\t\t\t\t// not a valid predicate\n+\t\t\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\t\t\treturn null;\n+\t\t\t\t}\n+\n+\t\t\t\tPredicateLeaf.Type litType = getLiteralType(callExp);\n+\t\t\t\tif (litType == null) {\n+\t\t\t\t\t// unsupported literal type\n+\t\t\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", expression);\n+\t\t\t\t\treturn null;\n+\t\t\t\t}\n+\n+\t\t\t\tboolean literalOnRight = literalOnRight(callExp);\n+\t\t\t\tString colName = getColumnName(callExp);\n+\n+\t\t\t\t// fetch literal and ensure it is serializable\n+\t\t\t\tObject literalObj = getLiteral(callExp).get();\n+\t\t\t\tSerializable literal;\n+\t\t\t\t// validate that literal is serializable\n+\t\t\t\tif (literalObj instanceof Serializable) {\n+\t\t\t\t\tliteral = (Serializable) literalObj;\n+\t\t\t\t} else {\n+\t\t\t\t\tLOG.warn(\"Encountered a non-serializable literal of type {}. \" +\n+\t\t\t\t\t\t\t\t\t\"Cannot push predicate [{}] into OrcFileSystemFormatFactory. \" +\n+\t\t\t\t\t\t\t\t\t\"This is a bug and should be reported.\",\n+\t\t\t\t\t\t\tliteralObj.getClass().getCanonicalName(), expression);\n+\t\t\t\t\treturn null;\n+\t\t\t\t}\n+\n+\t\t\t\tif (funcDef == BuiltInFunctionDefinitions.EQUALS) {\n+\t\t\t\t\treturn new OrcSplitReader.Equals(colName, litType, literal);\n+\t\t\t\t} else if (funcDef == BuiltInFunctionDefinitions.NOT_EQUALS) {\n+\t\t\t\t\treturn new OrcSplitReader.Not(\n+\t\t\t\t\t\t\tnew OrcSplitReader.Equals(colName, litType, literal));\n+\t\t\t\t} else if (funcDef == BuiltInFunctionDefinitions.GREATER_THAN) {\n+\t\t\t\t\tif (literalOnRight) {\n+\t\t\t\t\t\treturn new OrcSplitReader.Not(\n+\t\t\t\t\t\t\t\tnew OrcSplitReader.LessThanEquals(colName, litType, literal));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8048b8f9ded32203cb0ca0761414ef7186a68e5f"}, "originalPosition": 138}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDgyMzI3NTM0", "url": "https://github.com/apache/flink/pull/13306#pullrequestreview-482327534", "createdAt": "2020-09-04T03:07:52Z", "commit": {"oid": "8048b8f9ded32203cb0ca0761414ef7186a68e5f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQwMzowNzo1M1rOHM99cw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQwMzowNzo1M1rOHM99cw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzM2MDExNQ==", "bodyText": "You can use switch... case...", "url": "https://github.com/apache/flink/pull/13306#discussion_r483360115", "createdAt": "2020-09-04T03:07:53Z", "author": {"login": "JingsongLi"}, "path": "flink-formats/flink-orc/src/main/java/org/apache/flink/orc/OrcFileSystemFormatFactory.java", "diffHunk": "@@ -83,14 +96,227 @@ private static Properties getOrcProperties(ReadableConfig options) {\n \t\treturn orcProperties;\n \t}\n \n+\tprivate boolean isUnaryValid(CallExpression callExpression) {\n+\t\treturn callExpression.getChildren().size() == 1 && callExpression.getChildren().get(0) instanceof FieldReferenceExpression;\n+\t}\n+\n+\tprivate boolean isBinaryValid(CallExpression callExpression) {\n+\t\treturn callExpression.getChildren().size() == 2 && ((callExpression.getChildren().get(0) instanceof FieldReferenceExpression && callExpression.getChildren().get(1) instanceof ValueLiteralExpression) ||\n+\t\t\t\t(callExpression.getChildren().get(0) instanceof ValueLiteralExpression && callExpression.getChildren().get(1) instanceof FieldReferenceExpression));\n+\t}\n+\n+\tpublic OrcSplitReader.Predicate toOrcPredicate(Expression expression) {\n+\t\tif (expression instanceof CallExpression) {\n+\t\t\tCallExpression callExp = (CallExpression) expression;\n+\t\t\tFunctionDefinition funcDef = callExp.getFunctionDefinition();\n+\n+\t\t\tif (funcDef == BuiltInFunctionDefinitions.IS_NULL || funcDef == BuiltInFunctionDefinitions.IS_NOT_NULL || funcDef == BuiltInFunctionDefinitions.NOT) {\n+\t\t\t\tif (!isUnaryValid(callExp)) {\n+\t\t\t\t\t// not a valid predicate\n+\t\t\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\t\t\treturn null;\n+\t\t\t\t}\n+\n+\t\t\t\tPredicateLeaf.Type colType = toOrcType(((FieldReferenceExpression) callExp.getChildren().get(0)).getOutputDataType());\n+\t\t\t\tif (colType == null) {\n+\t\t\t\t\t// unsupported type\n+\t\t\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcTableSource.\", callExp);\n+\t\t\t\t\treturn null;\n+\t\t\t\t}\n+\n+\t\t\t\tString colName = getColumnName(callExp);\n+\n+\t\t\t\tif (funcDef == BuiltInFunctionDefinitions.IS_NULL) {\n+\t\t\t\t\treturn new OrcSplitReader.IsNull(colName, colType);\n+\t\t\t\t} else if (funcDef == BuiltInFunctionDefinitions.IS_NOT_NULL) {\n+\t\t\t\t\treturn new OrcSplitReader.Not(\n+\t\t\t\t\t\t\tnew OrcSplitReader.IsNull(colName, colType));\n+\t\t\t\t} else {\n+\t\t\t\t\tOrcSplitReader.Predicate c = toOrcPredicate(callExp.getChildren().get(0));\n+\t\t\t\t\tif (c == null) {\n+\t\t\t\t\t\treturn null;\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\treturn new OrcSplitReader.Not(c);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t} else if (funcDef == BuiltInFunctionDefinitions.OR) {\n+\t\t\t\tif (callExp.getChildren().size() < 2) {\n+\t\t\t\t\treturn null;\n+\t\t\t\t}\n+\t\t\t\tExpression left = callExp.getChildren().get(0);\n+\t\t\t\tExpression right = callExp.getChildren().get(1);\n+\n+\t\t\t\tOrcSplitReader.Predicate c1 = toOrcPredicate(left);\n+\t\t\t\tOrcSplitReader.Predicate c2 = toOrcPredicate(right);\n+\t\t\t\tif (c1 == null || c2 == null) {\n+\t\t\t\t\treturn null;\n+\t\t\t\t} else {\n+\t\t\t\t\treturn new OrcSplitReader.Or(c1, c2);\n+\t\t\t\t}\n+\t\t\t} else {\n+\t\t\t\tif (!isBinaryValid(callExp)) {\n+\t\t\t\t\t// not a valid predicate\n+\t\t\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\t\t\treturn null;\n+\t\t\t\t}\n+\n+\t\t\t\tPredicateLeaf.Type litType = getLiteralType(callExp);\n+\t\t\t\tif (litType == null) {\n+\t\t\t\t\t// unsupported literal type\n+\t\t\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", expression);\n+\t\t\t\t\treturn null;\n+\t\t\t\t}\n+\n+\t\t\t\tboolean literalOnRight = literalOnRight(callExp);\n+\t\t\t\tString colName = getColumnName(callExp);\n+\n+\t\t\t\t// fetch literal and ensure it is serializable\n+\t\t\t\tObject literalObj = getLiteral(callExp).get();\n+\t\t\t\tSerializable literal;\n+\t\t\t\t// validate that literal is serializable\n+\t\t\t\tif (literalObj instanceof Serializable) {\n+\t\t\t\t\tliteral = (Serializable) literalObj;\n+\t\t\t\t} else {\n+\t\t\t\t\tLOG.warn(\"Encountered a non-serializable literal of type {}. \" +\n+\t\t\t\t\t\t\t\t\t\"Cannot push predicate [{}] into OrcFileSystemFormatFactory. \" +\n+\t\t\t\t\t\t\t\t\t\"This is a bug and should be reported.\",\n+\t\t\t\t\t\t\tliteralObj.getClass().getCanonicalName(), expression);\n+\t\t\t\t\treturn null;\n+\t\t\t\t}\n+\n+\t\t\t\tif (funcDef == BuiltInFunctionDefinitions.EQUALS) {\n+\t\t\t\t\treturn new OrcSplitReader.Equals(colName, litType, literal);\n+\t\t\t\t} else if (funcDef == BuiltInFunctionDefinitions.NOT_EQUALS) {\n+\t\t\t\t\treturn new OrcSplitReader.Not(\n+\t\t\t\t\t\t\tnew OrcSplitReader.Equals(colName, litType, literal));\n+\t\t\t\t} else if (funcDef == BuiltInFunctionDefinitions.GREATER_THAN) {\n+\t\t\t\t\tif (literalOnRight) {\n+\t\t\t\t\t\treturn new OrcSplitReader.Not(\n+\t\t\t\t\t\t\t\tnew OrcSplitReader.LessThanEquals(colName, litType, literal));\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\treturn new OrcSplitReader.LessThan(colName, litType, literal);\n+\t\t\t\t\t}\n+\t\t\t\t} else if (funcDef == BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL) {\n+\t\t\t\t\tif (literalOnRight) {\n+\t\t\t\t\t\treturn new OrcSplitReader.Not(\n+\t\t\t\t\t\t\t\tnew OrcSplitReader.LessThan(colName, litType, literal));\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\treturn new OrcSplitReader.LessThanEquals(colName, litType, literal);\n+\t\t\t\t\t}\n+\t\t\t\t} else if (funcDef == BuiltInFunctionDefinitions.LESS_THAN) {\n+\t\t\t\t\tif (literalOnRight) {\n+\t\t\t\t\t\treturn new OrcSplitReader.LessThan(colName, litType, literal);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\treturn new OrcSplitReader.Not(\n+\t\t\t\t\t\t\t\tnew OrcSplitReader.LessThanEquals(colName, litType, literal));\n+\t\t\t\t\t}\n+\t\t\t\t} else if (funcDef == BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL) {\n+\t\t\t\t\tif (literalOnRight) {\n+\t\t\t\t\t\treturn new OrcSplitReader.LessThanEquals(colName, litType, literal);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\treturn new OrcSplitReader.Not(\n+\t\t\t\t\t\t\t\tnew OrcSplitReader.LessThan(colName, litType, literal));\n+\t\t\t\t\t}\n+\t\t\t\t} else {\n+\t\t\t\t\t// unsupported predicate\n+\t\t\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", expression);\n+\t\t\t\t\treturn null;\n+\t\t\t\t}\n+\t\t\t}\n+\t\t} else {\n+\t\t\t// unsupported predicate\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", expression);\n+\t\t\treturn null;\n+\t\t}\n+\t}\n+\n+\tprivate String getColumnName(CallExpression comp) {\n+\t\tif (literalOnRight(comp)) {\n+\t\t\treturn ((FieldReferenceExpression) comp.getChildren().get(0)).getName();\n+\t\t} else {\n+\t\t\treturn ((FieldReferenceExpression) comp.getChildren().get(1)).getName();\n+\t\t}\n+\t}\n+\n+\tprivate boolean literalOnRight(CallExpression comp) {\n+\t\tif (comp.getChildren().size() == 1 && comp.getChildren().get(0) instanceof FieldReferenceExpression) {\n+\t\t\treturn true;\n+\t\t} else if (comp.getChildren().get(0) instanceof ValueLiteralExpression\n+\t\t\t\t&& comp.getChildren().get(1) instanceof FieldReferenceExpression) {\n+\t\t\treturn false;\n+\t\t} else if (comp.getChildren().get(0) instanceof FieldReferenceExpression\n+\t\t\t\t&& comp.getChildren().get(1) instanceof ValueLiteralExpression) {\n+\t\t\treturn true;\n+\t\t} else {\n+\t\t\tthrow new RuntimeException(\"Invalid binary comparison.\");\n+\t\t}\n+\t}\n+\n+\tprivate PredicateLeaf.Type getLiteralType(CallExpression comp) {\n+\t\tif (literalOnRight(comp)) {\n+\t\t\treturn toOrcType(((ValueLiteralExpression) comp.getChildren().get(1)).getOutputDataType());\n+\t\t} else {\n+\t\t\treturn toOrcType(((ValueLiteralExpression) comp.getChildren().get(0)).getOutputDataType());\n+\t\t}\n+\t}\n+\n+\tprivate Optional<?> getLiteral(CallExpression comp) {\n+\t\tif (literalOnRight(comp)) {\n+\t\t\tValueLiteralExpression valueLiteralExpression = (ValueLiteralExpression) comp.getChildren().get(1);\n+\t\t\treturn valueLiteralExpression.getValueAs(valueLiteralExpression.getOutputDataType().getConversionClass());\n+\t\t} else {\n+\t\t\tValueLiteralExpression valueLiteralExpression = (ValueLiteralExpression) comp.getChildren().get(0);\n+\t\t\treturn valueLiteralExpression.getValueAs(valueLiteralExpression.getOutputDataType().getConversionClass());\n+\t\t}\n+\t}\n+\n+\tpublic PredicateLeaf.Type toOrcType(DataType type) {\n+\t\tLogicalTypeRoot ltype = type.getLogicalType().getTypeRoot();\n+\n+\t\tif (ltype == LogicalTypeRoot.TINYINT ||", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8048b8f9ded32203cb0ca0761414ef7186a68e5f"}, "originalPosition": 219}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDgzMjI2MDA3", "url": "https://github.com/apache/flink/pull/13306#pullrequestreview-483226007", "createdAt": "2020-09-07T03:50:17Z", "commit": {"oid": "c7628fc4b97f68c44d7f5e9cf316814c9f73db18"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 13, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wN1QwMzo1MDoxN1rOHNvWug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wN1QwNDoxNzowMlrOHNvqzw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDE2OTQwMg==", "bodyText": "NIT: List<OrcSplitReader.Predicate> is OK", "url": "https://github.com/apache/flink/pull/13306#discussion_r484169402", "createdAt": "2020-09-07T03:50:17Z", "author": {"login": "JingsongLi"}, "path": "flink-formats/flink-orc/src/main/java/org/apache/flink/orc/OrcFileSystemFormatFactory.java", "diffHunk": "@@ -85,12 +86,22 @@ private static Properties getOrcProperties(ReadableConfig options) {\n \n \t@Override\n \tpublic InputFormat<RowData, ?> createReader(ReaderContext context) {\n+\t\tArrayList<OrcSplitReader.Predicate> orcPredicates = new ArrayList<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c7628fc4b97f68c44d7f5e9cf316814c9f73db18"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDE3MDExMQ==", "bodyText": "The two lines are too long... Line breaks can be appropriate.", "url": "https://github.com/apache/flink/pull/13306#discussion_r484170111", "createdAt": "2020-09-07T03:54:11Z", "author": {"login": "JingsongLi"}, "path": "flink-formats/flink-orc/src/main/java/org/apache/flink/orc/OrcFilters.java", "diffHunk": "@@ -0,0 +1,372 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.orc;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.api.java.tuple.Tuple3;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.Expression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.flink.table.functions.FunctionDefinition;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.logical.LogicalTypeRoot;\n+\n+import org.apache.flink.shaded.curator4.com.google.common.collect.ImmutableMap;\n+\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.Serializable;\n+import java.util.Optional;\n+import java.util.function.Function;\n+\n+/**\n+ * Utility class that provides helper methods to work with Orc Filter PushDown.\n+ */\n+public class OrcFilters {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(OrcFileSystemFormatFactory.class);\n+\n+\tprivate static final ImmutableMap<FunctionDefinition, Function<CallExpression, OrcSplitReader.Predicate>> FILTERS =\n+\t\t\tnew ImmutableMap.Builder<FunctionDefinition, Function<CallExpression, OrcSplitReader.Predicate>>()\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.IS_NULL, createIsNullPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.IS_NOT_NULL, createIsNotNullPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.NOT, createNotPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.OR, createOrPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.EQUALS, createEqualsPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.NOT_EQUALS, createNotEqualsPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.GREATER_THAN, createGreaterThanPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, createGreaterThanEqualsPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.LESS_THAN, createLessThanPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, createLessThanEqualsPredicateConverter())\n+\t\t\t\t\t.build();\n+\n+\tprivate static boolean isUnaryValid(CallExpression callExpression) {\n+\t\treturn callExpression.getChildren().size() == 1 && callExpression.getChildren().get(0) instanceof FieldReferenceExpression;\n+\t}\n+\n+\tprivate static boolean isBinaryValid(CallExpression callExpression) {\n+\t\treturn callExpression.getChildren().size() == 2 && ((callExpression.getChildren().get(0) instanceof FieldReferenceExpression && callExpression.getChildren().get(1) instanceof ValueLiteralExpression) ||", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c7628fc4b97f68c44d7f5e9cf316814c9f73db18"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDE3MDQyNQ==", "bodyText": "Can have a isRef(Expression) and isLit(Expr)", "url": "https://github.com/apache/flink/pull/13306#discussion_r484170425", "createdAt": "2020-09-07T03:55:43Z", "author": {"login": "JingsongLi"}, "path": "flink-formats/flink-orc/src/main/java/org/apache/flink/orc/OrcFilters.java", "diffHunk": "@@ -0,0 +1,372 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.orc;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.api.java.tuple.Tuple3;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.Expression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.flink.table.functions.FunctionDefinition;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.logical.LogicalTypeRoot;\n+\n+import org.apache.flink.shaded.curator4.com.google.common.collect.ImmutableMap;\n+\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.Serializable;\n+import java.util.Optional;\n+import java.util.function.Function;\n+\n+/**\n+ * Utility class that provides helper methods to work with Orc Filter PushDown.\n+ */\n+public class OrcFilters {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(OrcFileSystemFormatFactory.class);\n+\n+\tprivate static final ImmutableMap<FunctionDefinition, Function<CallExpression, OrcSplitReader.Predicate>> FILTERS =\n+\t\t\tnew ImmutableMap.Builder<FunctionDefinition, Function<CallExpression, OrcSplitReader.Predicate>>()\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.IS_NULL, createIsNullPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.IS_NOT_NULL, createIsNotNullPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.NOT, createNotPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.OR, createOrPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.EQUALS, createEqualsPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.NOT_EQUALS, createNotEqualsPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.GREATER_THAN, createGreaterThanPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, createGreaterThanEqualsPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.LESS_THAN, createLessThanPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, createLessThanEqualsPredicateConverter())\n+\t\t\t\t\t.build();\n+\n+\tprivate static boolean isUnaryValid(CallExpression callExpression) {\n+\t\treturn callExpression.getChildren().size() == 1 && callExpression.getChildren().get(0) instanceof FieldReferenceExpression;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c7628fc4b97f68c44d7f5e9cf316814c9f73db18"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDE3MDkyMA==", "bodyText": "Inline this method to createIsNullPredicateConverter.", "url": "https://github.com/apache/flink/pull/13306#discussion_r484170920", "createdAt": "2020-09-07T03:58:13Z", "author": {"login": "JingsongLi"}, "path": "flink-formats/flink-orc/src/main/java/org/apache/flink/orc/OrcFilters.java", "diffHunk": "@@ -0,0 +1,372 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.orc;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.api.java.tuple.Tuple3;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.Expression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.flink.table.functions.FunctionDefinition;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.logical.LogicalTypeRoot;\n+\n+import org.apache.flink.shaded.curator4.com.google.common.collect.ImmutableMap;\n+\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.Serializable;\n+import java.util.Optional;\n+import java.util.function.Function;\n+\n+/**\n+ * Utility class that provides helper methods to work with Orc Filter PushDown.\n+ */\n+public class OrcFilters {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(OrcFileSystemFormatFactory.class);\n+\n+\tprivate static final ImmutableMap<FunctionDefinition, Function<CallExpression, OrcSplitReader.Predicate>> FILTERS =\n+\t\t\tnew ImmutableMap.Builder<FunctionDefinition, Function<CallExpression, OrcSplitReader.Predicate>>()\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.IS_NULL, createIsNullPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.IS_NOT_NULL, createIsNotNullPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.NOT, createNotPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.OR, createOrPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.EQUALS, createEqualsPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.NOT_EQUALS, createNotEqualsPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.GREATER_THAN, createGreaterThanPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, createGreaterThanEqualsPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.LESS_THAN, createLessThanPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, createLessThanEqualsPredicateConverter())\n+\t\t\t\t\t.build();\n+\n+\tprivate static boolean isUnaryValid(CallExpression callExpression) {\n+\t\treturn callExpression.getChildren().size() == 1 && callExpression.getChildren().get(0) instanceof FieldReferenceExpression;\n+\t}\n+\n+\tprivate static boolean isBinaryValid(CallExpression callExpression) {\n+\t\treturn callExpression.getChildren().size() == 2 && ((callExpression.getChildren().get(0) instanceof FieldReferenceExpression && callExpression.getChildren().get(1) instanceof ValueLiteralExpression) ||\n+\t\t\t\t(callExpression.getChildren().get(0) instanceof ValueLiteralExpression && callExpression.getChildren().get(1) instanceof FieldReferenceExpression));\n+\t}\n+\n+\tprivate static Tuple2<String, PredicateLeaf.Type> getTuple2Args(CallExpression callExp){", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c7628fc4b97f68c44d7f5e9cf316814c9f73db18"}, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDE3MTMzNQ==", "bodyText": "You can create a method: convertIsNull, and:\n.put(BuiltInFunctionDefinitions.IS_NULL, OrcFilters::convertIsNull.\nOthers can be the same.", "url": "https://github.com/apache/flink/pull/13306#discussion_r484171335", "createdAt": "2020-09-07T04:00:23Z", "author": {"login": "JingsongLi"}, "path": "flink-formats/flink-orc/src/main/java/org/apache/flink/orc/OrcFilters.java", "diffHunk": "@@ -0,0 +1,372 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.orc;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.api.java.tuple.Tuple3;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.Expression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.flink.table.functions.FunctionDefinition;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.logical.LogicalTypeRoot;\n+\n+import org.apache.flink.shaded.curator4.com.google.common.collect.ImmutableMap;\n+\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.Serializable;\n+import java.util.Optional;\n+import java.util.function.Function;\n+\n+/**\n+ * Utility class that provides helper methods to work with Orc Filter PushDown.\n+ */\n+public class OrcFilters {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(OrcFileSystemFormatFactory.class);\n+\n+\tprivate static final ImmutableMap<FunctionDefinition, Function<CallExpression, OrcSplitReader.Predicate>> FILTERS =\n+\t\t\tnew ImmutableMap.Builder<FunctionDefinition, Function<CallExpression, OrcSplitReader.Predicate>>()\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.IS_NULL, createIsNullPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.IS_NOT_NULL, createIsNotNullPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.NOT, createNotPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.OR, createOrPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.EQUALS, createEqualsPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.NOT_EQUALS, createNotEqualsPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.GREATER_THAN, createGreaterThanPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, createGreaterThanEqualsPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.LESS_THAN, createLessThanPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, createLessThanEqualsPredicateConverter())\n+\t\t\t\t\t.build();\n+\n+\tprivate static boolean isUnaryValid(CallExpression callExpression) {\n+\t\treturn callExpression.getChildren().size() == 1 && callExpression.getChildren().get(0) instanceof FieldReferenceExpression;\n+\t}\n+\n+\tprivate static boolean isBinaryValid(CallExpression callExpression) {\n+\t\treturn callExpression.getChildren().size() == 2 && ((callExpression.getChildren().get(0) instanceof FieldReferenceExpression && callExpression.getChildren().get(1) instanceof ValueLiteralExpression) ||\n+\t\t\t\t(callExpression.getChildren().get(0) instanceof ValueLiteralExpression && callExpression.getChildren().get(1) instanceof FieldReferenceExpression));\n+\t}\n+\n+\tprivate static Tuple2<String, PredicateLeaf.Type> getTuple2Args(CallExpression callExp){\n+\t\tif (!isUnaryValid(callExp)) {\n+\t\t\t// not a valid predicate\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tPredicateLeaf.Type colType = toOrcType(((FieldReferenceExpression) callExp.getChildren().get(0)).getOutputDataType());\n+\t\tif (colType == null) {\n+\t\t\t// unsupported type\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tString colName = getColumnName(callExp);\n+\n+\t\treturn Tuple2.of(colName, colType);\n+\t}\n+\n+\tprivate static Tuple3<String, PredicateLeaf.Type, Serializable> getTuple3Args(CallExpression callExp){\n+\t\tif (!isBinaryValid(callExp)) {\n+\t\t\t// not a valid predicate\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tPredicateLeaf.Type litType = getLiteralType(callExp);\n+\t\tif (litType == null) {\n+\t\t\t// unsupported literal type\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tString colName = getColumnName(callExp);\n+\n+\t\t// fetch literal and ensure it is serializable\n+\t\tObject literalObj = getLiteral(callExp).get();\n+\t\tSerializable literal;\n+\t\t// validate that literal is serializable\n+\t\tif (literalObj instanceof Serializable) {\n+\t\t\tliteral = (Serializable) literalObj;\n+\t\t} else {\n+\t\t\tLOG.warn(\"Encountered a non-serializable literal of type {}. \" +\n+\t\t\t\t\t\t\t\"Cannot push predicate [{}] into OrcFileSystemFormatFactory. \" +\n+\t\t\t\t\t\t\t\"This is a bug and should be reported.\",\n+\t\t\t\t\tliteralObj.getClass().getCanonicalName(), callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\treturn Tuple3.of(colName, litType, literal);\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createIsNullPredicateConverter(){", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c7628fc4b97f68c44d7f5e9cf316814c9f73db18"}, "originalPosition": 124}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDE3MTQ0OQ==", "bodyText": "Can be convertNot(convertIsNull(call))", "url": "https://github.com/apache/flink/pull/13306#discussion_r484171449", "createdAt": "2020-09-07T04:00:58Z", "author": {"login": "JingsongLi"}, "path": "flink-formats/flink-orc/src/main/java/org/apache/flink/orc/OrcFilters.java", "diffHunk": "@@ -0,0 +1,372 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.orc;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.api.java.tuple.Tuple3;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.Expression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.flink.table.functions.FunctionDefinition;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.logical.LogicalTypeRoot;\n+\n+import org.apache.flink.shaded.curator4.com.google.common.collect.ImmutableMap;\n+\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.Serializable;\n+import java.util.Optional;\n+import java.util.function.Function;\n+\n+/**\n+ * Utility class that provides helper methods to work with Orc Filter PushDown.\n+ */\n+public class OrcFilters {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(OrcFileSystemFormatFactory.class);\n+\n+\tprivate static final ImmutableMap<FunctionDefinition, Function<CallExpression, OrcSplitReader.Predicate>> FILTERS =\n+\t\t\tnew ImmutableMap.Builder<FunctionDefinition, Function<CallExpression, OrcSplitReader.Predicate>>()\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.IS_NULL, createIsNullPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.IS_NOT_NULL, createIsNotNullPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.NOT, createNotPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.OR, createOrPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.EQUALS, createEqualsPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.NOT_EQUALS, createNotEqualsPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.GREATER_THAN, createGreaterThanPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, createGreaterThanEqualsPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.LESS_THAN, createLessThanPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, createLessThanEqualsPredicateConverter())\n+\t\t\t\t\t.build();\n+\n+\tprivate static boolean isUnaryValid(CallExpression callExpression) {\n+\t\treturn callExpression.getChildren().size() == 1 && callExpression.getChildren().get(0) instanceof FieldReferenceExpression;\n+\t}\n+\n+\tprivate static boolean isBinaryValid(CallExpression callExpression) {\n+\t\treturn callExpression.getChildren().size() == 2 && ((callExpression.getChildren().get(0) instanceof FieldReferenceExpression && callExpression.getChildren().get(1) instanceof ValueLiteralExpression) ||\n+\t\t\t\t(callExpression.getChildren().get(0) instanceof ValueLiteralExpression && callExpression.getChildren().get(1) instanceof FieldReferenceExpression));\n+\t}\n+\n+\tprivate static Tuple2<String, PredicateLeaf.Type> getTuple2Args(CallExpression callExp){\n+\t\tif (!isUnaryValid(callExp)) {\n+\t\t\t// not a valid predicate\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tPredicateLeaf.Type colType = toOrcType(((FieldReferenceExpression) callExp.getChildren().get(0)).getOutputDataType());\n+\t\tif (colType == null) {\n+\t\t\t// unsupported type\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tString colName = getColumnName(callExp);\n+\n+\t\treturn Tuple2.of(colName, colType);\n+\t}\n+\n+\tprivate static Tuple3<String, PredicateLeaf.Type, Serializable> getTuple3Args(CallExpression callExp){\n+\t\tif (!isBinaryValid(callExp)) {\n+\t\t\t// not a valid predicate\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tPredicateLeaf.Type litType = getLiteralType(callExp);\n+\t\tif (litType == null) {\n+\t\t\t// unsupported literal type\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tString colName = getColumnName(callExp);\n+\n+\t\t// fetch literal and ensure it is serializable\n+\t\tObject literalObj = getLiteral(callExp).get();\n+\t\tSerializable literal;\n+\t\t// validate that literal is serializable\n+\t\tif (literalObj instanceof Serializable) {\n+\t\t\tliteral = (Serializable) literalObj;\n+\t\t} else {\n+\t\t\tLOG.warn(\"Encountered a non-serializable literal of type {}. \" +\n+\t\t\t\t\t\t\t\"Cannot push predicate [{}] into OrcFileSystemFormatFactory. \" +\n+\t\t\t\t\t\t\t\"This is a bug and should be reported.\",\n+\t\t\t\t\tliteralObj.getClass().getCanonicalName(), callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\treturn Tuple3.of(colName, litType, literal);\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createIsNullPredicateConverter(){\n+\t\treturn callExp -> {\n+\t\t\t\tTuple2<String, PredicateLeaf.Type> tuple2 = getTuple2Args(callExp);\n+\n+\t\t\t\tif (tuple2 == null){\n+\t\t\t\t\treturn null;\n+\t\t\t\t}\n+\n+\t\t\t\treturn new OrcSplitReader.IsNull(tuple2.f0, tuple2.f1);\n+\t\t};\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createIsNotNullPredicateConverter(){\n+\t\treturn callExp -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c7628fc4b97f68c44d7f5e9cf316814c9f73db18"}, "originalPosition": 137}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDE3MTU1NQ==", "bodyText": "Can be c == null ? null : new OrcSplitReader.Not(c)", "url": "https://github.com/apache/flink/pull/13306#discussion_r484171555", "createdAt": "2020-09-07T04:01:35Z", "author": {"login": "JingsongLi"}, "path": "flink-formats/flink-orc/src/main/java/org/apache/flink/orc/OrcFilters.java", "diffHunk": "@@ -0,0 +1,372 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.orc;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.api.java.tuple.Tuple3;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.Expression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.flink.table.functions.FunctionDefinition;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.logical.LogicalTypeRoot;\n+\n+import org.apache.flink.shaded.curator4.com.google.common.collect.ImmutableMap;\n+\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.Serializable;\n+import java.util.Optional;\n+import java.util.function.Function;\n+\n+/**\n+ * Utility class that provides helper methods to work with Orc Filter PushDown.\n+ */\n+public class OrcFilters {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(OrcFileSystemFormatFactory.class);\n+\n+\tprivate static final ImmutableMap<FunctionDefinition, Function<CallExpression, OrcSplitReader.Predicate>> FILTERS =\n+\t\t\tnew ImmutableMap.Builder<FunctionDefinition, Function<CallExpression, OrcSplitReader.Predicate>>()\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.IS_NULL, createIsNullPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.IS_NOT_NULL, createIsNotNullPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.NOT, createNotPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.OR, createOrPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.EQUALS, createEqualsPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.NOT_EQUALS, createNotEqualsPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.GREATER_THAN, createGreaterThanPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, createGreaterThanEqualsPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.LESS_THAN, createLessThanPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, createLessThanEqualsPredicateConverter())\n+\t\t\t\t\t.build();\n+\n+\tprivate static boolean isUnaryValid(CallExpression callExpression) {\n+\t\treturn callExpression.getChildren().size() == 1 && callExpression.getChildren().get(0) instanceof FieldReferenceExpression;\n+\t}\n+\n+\tprivate static boolean isBinaryValid(CallExpression callExpression) {\n+\t\treturn callExpression.getChildren().size() == 2 && ((callExpression.getChildren().get(0) instanceof FieldReferenceExpression && callExpression.getChildren().get(1) instanceof ValueLiteralExpression) ||\n+\t\t\t\t(callExpression.getChildren().get(0) instanceof ValueLiteralExpression && callExpression.getChildren().get(1) instanceof FieldReferenceExpression));\n+\t}\n+\n+\tprivate static Tuple2<String, PredicateLeaf.Type> getTuple2Args(CallExpression callExp){\n+\t\tif (!isUnaryValid(callExp)) {\n+\t\t\t// not a valid predicate\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tPredicateLeaf.Type colType = toOrcType(((FieldReferenceExpression) callExp.getChildren().get(0)).getOutputDataType());\n+\t\tif (colType == null) {\n+\t\t\t// unsupported type\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tString colName = getColumnName(callExp);\n+\n+\t\treturn Tuple2.of(colName, colType);\n+\t}\n+\n+\tprivate static Tuple3<String, PredicateLeaf.Type, Serializable> getTuple3Args(CallExpression callExp){\n+\t\tif (!isBinaryValid(callExp)) {\n+\t\t\t// not a valid predicate\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tPredicateLeaf.Type litType = getLiteralType(callExp);\n+\t\tif (litType == null) {\n+\t\t\t// unsupported literal type\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tString colName = getColumnName(callExp);\n+\n+\t\t// fetch literal and ensure it is serializable\n+\t\tObject literalObj = getLiteral(callExp).get();\n+\t\tSerializable literal;\n+\t\t// validate that literal is serializable\n+\t\tif (literalObj instanceof Serializable) {\n+\t\t\tliteral = (Serializable) literalObj;\n+\t\t} else {\n+\t\t\tLOG.warn(\"Encountered a non-serializable literal of type {}. \" +\n+\t\t\t\t\t\t\t\"Cannot push predicate [{}] into OrcFileSystemFormatFactory. \" +\n+\t\t\t\t\t\t\t\"This is a bug and should be reported.\",\n+\t\t\t\t\tliteralObj.getClass().getCanonicalName(), callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\treturn Tuple3.of(colName, litType, literal);\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createIsNullPredicateConverter(){\n+\t\treturn callExp -> {\n+\t\t\t\tTuple2<String, PredicateLeaf.Type> tuple2 = getTuple2Args(callExp);\n+\n+\t\t\t\tif (tuple2 == null){\n+\t\t\t\t\treturn null;\n+\t\t\t\t}\n+\n+\t\t\t\treturn new OrcSplitReader.IsNull(tuple2.f0, tuple2.f1);\n+\t\t};\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createIsNotNullPredicateConverter(){\n+\t\treturn callExp -> {\n+\n+\t\t\tTuple2<String, PredicateLeaf.Type> tuple2 = getTuple2Args(callExp);\n+\n+\t\t\tif (tuple2 == null){\n+\t\t\t\treturn null;\n+\t\t\t}\n+\n+\t\t\treturn new OrcSplitReader.Not(\n+\t\t\t\t\tnew OrcSplitReader.IsNull(tuple2.f0, tuple2.f1));\n+\t\t};\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createNotPredicateConverter(){\n+\t\treturn callExp -> {\n+\t\t\tif (callExp.getChildren().size() != 1) {\n+\t\t\t\t// not a valid predicate\n+\t\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\t\treturn null;\n+\t\t\t}\n+\n+\t\t\tOrcSplitReader.Predicate c = toOrcPredicate(callExp.getChildren().get(0));\n+\t\t\tif (c == null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c7628fc4b97f68c44d7f5e9cf316814c9f73db18"}, "originalPosition": 159}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDE3MjEyNw==", "bodyText": "You can remove all **Predicate** in methods of this class.", "url": "https://github.com/apache/flink/pull/13306#discussion_r484172127", "createdAt": "2020-09-07T04:04:22Z", "author": {"login": "JingsongLi"}, "path": "flink-formats/flink-orc/src/main/java/org/apache/flink/orc/OrcFilters.java", "diffHunk": "@@ -0,0 +1,372 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.orc;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.api.java.tuple.Tuple3;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.Expression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.flink.table.functions.FunctionDefinition;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.logical.LogicalTypeRoot;\n+\n+import org.apache.flink.shaded.curator4.com.google.common.collect.ImmutableMap;\n+\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.Serializable;\n+import java.util.Optional;\n+import java.util.function.Function;\n+\n+/**\n+ * Utility class that provides helper methods to work with Orc Filter PushDown.\n+ */\n+public class OrcFilters {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(OrcFileSystemFormatFactory.class);\n+\n+\tprivate static final ImmutableMap<FunctionDefinition, Function<CallExpression, OrcSplitReader.Predicate>> FILTERS =\n+\t\t\tnew ImmutableMap.Builder<FunctionDefinition, Function<CallExpression, OrcSplitReader.Predicate>>()\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.IS_NULL, createIsNullPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.IS_NOT_NULL, createIsNotNullPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.NOT, createNotPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.OR, createOrPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.EQUALS, createEqualsPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.NOT_EQUALS, createNotEqualsPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.GREATER_THAN, createGreaterThanPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, createGreaterThanEqualsPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.LESS_THAN, createLessThanPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, createLessThanEqualsPredicateConverter())\n+\t\t\t\t\t.build();\n+\n+\tprivate static boolean isUnaryValid(CallExpression callExpression) {\n+\t\treturn callExpression.getChildren().size() == 1 && callExpression.getChildren().get(0) instanceof FieldReferenceExpression;\n+\t}\n+\n+\tprivate static boolean isBinaryValid(CallExpression callExpression) {\n+\t\treturn callExpression.getChildren().size() == 2 && ((callExpression.getChildren().get(0) instanceof FieldReferenceExpression && callExpression.getChildren().get(1) instanceof ValueLiteralExpression) ||\n+\t\t\t\t(callExpression.getChildren().get(0) instanceof ValueLiteralExpression && callExpression.getChildren().get(1) instanceof FieldReferenceExpression));\n+\t}\n+\n+\tprivate static Tuple2<String, PredicateLeaf.Type> getTuple2Args(CallExpression callExp){\n+\t\tif (!isUnaryValid(callExp)) {\n+\t\t\t// not a valid predicate\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tPredicateLeaf.Type colType = toOrcType(((FieldReferenceExpression) callExp.getChildren().get(0)).getOutputDataType());\n+\t\tif (colType == null) {\n+\t\t\t// unsupported type\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tString colName = getColumnName(callExp);\n+\n+\t\treturn Tuple2.of(colName, colType);\n+\t}\n+\n+\tprivate static Tuple3<String, PredicateLeaf.Type, Serializable> getTuple3Args(CallExpression callExp){\n+\t\tif (!isBinaryValid(callExp)) {\n+\t\t\t// not a valid predicate\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tPredicateLeaf.Type litType = getLiteralType(callExp);\n+\t\tif (litType == null) {\n+\t\t\t// unsupported literal type\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tString colName = getColumnName(callExp);\n+\n+\t\t// fetch literal and ensure it is serializable\n+\t\tObject literalObj = getLiteral(callExp).get();\n+\t\tSerializable literal;\n+\t\t// validate that literal is serializable\n+\t\tif (literalObj instanceof Serializable) {\n+\t\t\tliteral = (Serializable) literalObj;\n+\t\t} else {\n+\t\t\tLOG.warn(\"Encountered a non-serializable literal of type {}. \" +\n+\t\t\t\t\t\t\t\"Cannot push predicate [{}] into OrcFileSystemFormatFactory. \" +\n+\t\t\t\t\t\t\t\"This is a bug and should be reported.\",\n+\t\t\t\t\tliteralObj.getClass().getCanonicalName(), callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\treturn Tuple3.of(colName, litType, literal);\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createIsNullPredicateConverter(){\n+\t\treturn callExp -> {\n+\t\t\t\tTuple2<String, PredicateLeaf.Type> tuple2 = getTuple2Args(callExp);\n+\n+\t\t\t\tif (tuple2 == null){\n+\t\t\t\t\treturn null;\n+\t\t\t\t}\n+\n+\t\t\t\treturn new OrcSplitReader.IsNull(tuple2.f0, tuple2.f1);\n+\t\t};\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createIsNotNullPredicateConverter(){\n+\t\treturn callExp -> {\n+\n+\t\t\tTuple2<String, PredicateLeaf.Type> tuple2 = getTuple2Args(callExp);\n+\n+\t\t\tif (tuple2 == null){\n+\t\t\t\treturn null;\n+\t\t\t}\n+\n+\t\t\treturn new OrcSplitReader.Not(\n+\t\t\t\t\tnew OrcSplitReader.IsNull(tuple2.f0, tuple2.f1));\n+\t\t};\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createNotPredicateConverter(){\n+\t\treturn callExp -> {\n+\t\t\tif (callExp.getChildren().size() != 1) {\n+\t\t\t\t// not a valid predicate\n+\t\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\t\treturn null;\n+\t\t\t}\n+\n+\t\t\tOrcSplitReader.Predicate c = toOrcPredicate(callExp.getChildren().get(0));\n+\t\t\tif (c == null) {\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\treturn new OrcSplitReader.Not(c);\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createOrPredicateConverter(){", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c7628fc4b97f68c44d7f5e9cf316814c9f73db18"}, "originalPosition": 167}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDE3Mjg3OA==", "bodyText": "You can pass a TriFunction to a convertBinary:\npublic OrcSplitReader.Predicate convertBinary(CallExpression call,\n   TriFunction<String, PredicateLeaf.Type, Serializable, OrcSplitReader.Predicate> func,\n   TriFunction<String, PredicateLeaf.Type, Serializable, OrcSplitReader.Predicate> reverseFunc) {\n   // move codes from getTuple3Args to here\n   // For example, func is LessThan, reverseFunc is greaterThanOrEqual\n   return literalOnRight ? func.apply(name, type, literal) : reverseFunc.apply(name, type, literal);\n}", "url": "https://github.com/apache/flink/pull/13306#discussion_r484172878", "createdAt": "2020-09-07T04:08:23Z", "author": {"login": "JingsongLi"}, "path": "flink-formats/flink-orc/src/main/java/org/apache/flink/orc/OrcFilters.java", "diffHunk": "@@ -0,0 +1,372 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.orc;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.api.java.tuple.Tuple3;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.Expression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.flink.table.functions.FunctionDefinition;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.logical.LogicalTypeRoot;\n+\n+import org.apache.flink.shaded.curator4.com.google.common.collect.ImmutableMap;\n+\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.Serializable;\n+import java.util.Optional;\n+import java.util.function.Function;\n+\n+/**\n+ * Utility class that provides helper methods to work with Orc Filter PushDown.\n+ */\n+public class OrcFilters {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(OrcFileSystemFormatFactory.class);\n+\n+\tprivate static final ImmutableMap<FunctionDefinition, Function<CallExpression, OrcSplitReader.Predicate>> FILTERS =\n+\t\t\tnew ImmutableMap.Builder<FunctionDefinition, Function<CallExpression, OrcSplitReader.Predicate>>()\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.IS_NULL, createIsNullPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.IS_NOT_NULL, createIsNotNullPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.NOT, createNotPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.OR, createOrPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.EQUALS, createEqualsPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.NOT_EQUALS, createNotEqualsPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.GREATER_THAN, createGreaterThanPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, createGreaterThanEqualsPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.LESS_THAN, createLessThanPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, createLessThanEqualsPredicateConverter())\n+\t\t\t\t\t.build();\n+\n+\tprivate static boolean isUnaryValid(CallExpression callExpression) {\n+\t\treturn callExpression.getChildren().size() == 1 && callExpression.getChildren().get(0) instanceof FieldReferenceExpression;\n+\t}\n+\n+\tprivate static boolean isBinaryValid(CallExpression callExpression) {\n+\t\treturn callExpression.getChildren().size() == 2 && ((callExpression.getChildren().get(0) instanceof FieldReferenceExpression && callExpression.getChildren().get(1) instanceof ValueLiteralExpression) ||\n+\t\t\t\t(callExpression.getChildren().get(0) instanceof ValueLiteralExpression && callExpression.getChildren().get(1) instanceof FieldReferenceExpression));\n+\t}\n+\n+\tprivate static Tuple2<String, PredicateLeaf.Type> getTuple2Args(CallExpression callExp){\n+\t\tif (!isUnaryValid(callExp)) {\n+\t\t\t// not a valid predicate\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tPredicateLeaf.Type colType = toOrcType(((FieldReferenceExpression) callExp.getChildren().get(0)).getOutputDataType());\n+\t\tif (colType == null) {\n+\t\t\t// unsupported type\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tString colName = getColumnName(callExp);\n+\n+\t\treturn Tuple2.of(colName, colType);\n+\t}\n+\n+\tprivate static Tuple3<String, PredicateLeaf.Type, Serializable> getTuple3Args(CallExpression callExp){\n+\t\tif (!isBinaryValid(callExp)) {\n+\t\t\t// not a valid predicate\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tPredicateLeaf.Type litType = getLiteralType(callExp);\n+\t\tif (litType == null) {\n+\t\t\t// unsupported literal type\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tString colName = getColumnName(callExp);\n+\n+\t\t// fetch literal and ensure it is serializable\n+\t\tObject literalObj = getLiteral(callExp).get();\n+\t\tSerializable literal;\n+\t\t// validate that literal is serializable\n+\t\tif (literalObj instanceof Serializable) {\n+\t\t\tliteral = (Serializable) literalObj;\n+\t\t} else {\n+\t\t\tLOG.warn(\"Encountered a non-serializable literal of type {}. \" +\n+\t\t\t\t\t\t\t\"Cannot push predicate [{}] into OrcFileSystemFormatFactory. \" +\n+\t\t\t\t\t\t\t\"This is a bug and should be reported.\",\n+\t\t\t\t\tliteralObj.getClass().getCanonicalName(), callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\treturn Tuple3.of(colName, litType, literal);\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createIsNullPredicateConverter(){\n+\t\treturn callExp -> {\n+\t\t\t\tTuple2<String, PredicateLeaf.Type> tuple2 = getTuple2Args(callExp);\n+\n+\t\t\t\tif (tuple2 == null){\n+\t\t\t\t\treturn null;\n+\t\t\t\t}\n+\n+\t\t\t\treturn new OrcSplitReader.IsNull(tuple2.f0, tuple2.f1);\n+\t\t};\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createIsNotNullPredicateConverter(){\n+\t\treturn callExp -> {\n+\n+\t\t\tTuple2<String, PredicateLeaf.Type> tuple2 = getTuple2Args(callExp);\n+\n+\t\t\tif (tuple2 == null){\n+\t\t\t\treturn null;\n+\t\t\t}\n+\n+\t\t\treturn new OrcSplitReader.Not(\n+\t\t\t\t\tnew OrcSplitReader.IsNull(tuple2.f0, tuple2.f1));\n+\t\t};\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createNotPredicateConverter(){\n+\t\treturn callExp -> {\n+\t\t\tif (callExp.getChildren().size() != 1) {\n+\t\t\t\t// not a valid predicate\n+\t\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\t\treturn null;\n+\t\t\t}\n+\n+\t\t\tOrcSplitReader.Predicate c = toOrcPredicate(callExp.getChildren().get(0));\n+\t\t\tif (c == null) {\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\treturn new OrcSplitReader.Not(c);\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createOrPredicateConverter(){\n+\t\treturn callExp -> {\n+\t\t\tif (callExp.getChildren().size() < 2) {\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\tExpression left = callExp.getChildren().get(0);\n+\t\t\tExpression right = callExp.getChildren().get(1);\n+\n+\t\t\tOrcSplitReader.Predicate c1 = toOrcPredicate(left);\n+\t\t\tOrcSplitReader.Predicate c2 = toOrcPredicate(right);\n+\t\t\tif (c1 == null || c2 == null) {\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\treturn new OrcSplitReader.Or(c1, c2);\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createEqualsPredicateConverter(){\n+\t\treturn callExp -> {\n+\t\t\tTuple3<String, PredicateLeaf.Type, Serializable> tuple3 = getTuple3Args(callExp);\n+\n+\t\t\tif (tuple3 == null){\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\treturn new OrcSplitReader.Equals(tuple3.f0, tuple3.f1, tuple3.f2);\n+\t\t};\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createNotEqualsPredicateConverter(){", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c7628fc4b97f68c44d7f5e9cf316814c9f73db18"}, "originalPosition": 196}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDE3NDAyNQ==", "bodyText": "Can be OrcFileSystemFilterTest", "url": "https://github.com/apache/flink/pull/13306#discussion_r484174025", "createdAt": "2020-09-07T04:14:26Z", "author": {"login": "JingsongLi"}, "path": "flink-formats/flink-orc/src/test/java/org/apache/flink/orc/OrcFileSystemFormatFactoryTest.java", "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.orc;\n+\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.junit.Test;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+import static org.junit.Assert.assertTrue;\n+\n+\n+/**\n+ * Unit Tests for {@link OrcFileSystemFormatFactory}.\n+ */\n+public class OrcFileSystemFormatFactoryTest {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c7628fc4b97f68c44d7f5e9cf316814c9f73db18"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDE3NDM2MQ==", "bodyText": "Add case CHAR: to STRING too.", "url": "https://github.com/apache/flink/pull/13306#discussion_r484174361", "createdAt": "2020-09-07T04:16:01Z", "author": {"login": "JingsongLi"}, "path": "flink-formats/flink-orc/src/main/java/org/apache/flink/orc/OrcFilters.java", "diffHunk": "@@ -0,0 +1,372 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.orc;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.api.java.tuple.Tuple3;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.Expression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.flink.table.functions.FunctionDefinition;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.logical.LogicalTypeRoot;\n+\n+import org.apache.flink.shaded.curator4.com.google.common.collect.ImmutableMap;\n+\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.Serializable;\n+import java.util.Optional;\n+import java.util.function.Function;\n+\n+/**\n+ * Utility class that provides helper methods to work with Orc Filter PushDown.\n+ */\n+public class OrcFilters {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(OrcFileSystemFormatFactory.class);\n+\n+\tprivate static final ImmutableMap<FunctionDefinition, Function<CallExpression, OrcSplitReader.Predicate>> FILTERS =\n+\t\t\tnew ImmutableMap.Builder<FunctionDefinition, Function<CallExpression, OrcSplitReader.Predicate>>()\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.IS_NULL, createIsNullPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.IS_NOT_NULL, createIsNotNullPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.NOT, createNotPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.OR, createOrPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.EQUALS, createEqualsPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.NOT_EQUALS, createNotEqualsPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.GREATER_THAN, createGreaterThanPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, createGreaterThanEqualsPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.LESS_THAN, createLessThanPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, createLessThanEqualsPredicateConverter())\n+\t\t\t\t\t.build();\n+\n+\tprivate static boolean isUnaryValid(CallExpression callExpression) {\n+\t\treturn callExpression.getChildren().size() == 1 && callExpression.getChildren().get(0) instanceof FieldReferenceExpression;\n+\t}\n+\n+\tprivate static boolean isBinaryValid(CallExpression callExpression) {\n+\t\treturn callExpression.getChildren().size() == 2 && ((callExpression.getChildren().get(0) instanceof FieldReferenceExpression && callExpression.getChildren().get(1) instanceof ValueLiteralExpression) ||\n+\t\t\t\t(callExpression.getChildren().get(0) instanceof ValueLiteralExpression && callExpression.getChildren().get(1) instanceof FieldReferenceExpression));\n+\t}\n+\n+\tprivate static Tuple2<String, PredicateLeaf.Type> getTuple2Args(CallExpression callExp){\n+\t\tif (!isUnaryValid(callExp)) {\n+\t\t\t// not a valid predicate\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tPredicateLeaf.Type colType = toOrcType(((FieldReferenceExpression) callExp.getChildren().get(0)).getOutputDataType());\n+\t\tif (colType == null) {\n+\t\t\t// unsupported type\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tString colName = getColumnName(callExp);\n+\n+\t\treturn Tuple2.of(colName, colType);\n+\t}\n+\n+\tprivate static Tuple3<String, PredicateLeaf.Type, Serializable> getTuple3Args(CallExpression callExp){\n+\t\tif (!isBinaryValid(callExp)) {\n+\t\t\t// not a valid predicate\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tPredicateLeaf.Type litType = getLiteralType(callExp);\n+\t\tif (litType == null) {\n+\t\t\t// unsupported literal type\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tString colName = getColumnName(callExp);\n+\n+\t\t// fetch literal and ensure it is serializable\n+\t\tObject literalObj = getLiteral(callExp).get();\n+\t\tSerializable literal;\n+\t\t// validate that literal is serializable\n+\t\tif (literalObj instanceof Serializable) {\n+\t\t\tliteral = (Serializable) literalObj;\n+\t\t} else {\n+\t\t\tLOG.warn(\"Encountered a non-serializable literal of type {}. \" +\n+\t\t\t\t\t\t\t\"Cannot push predicate [{}] into OrcFileSystemFormatFactory. \" +\n+\t\t\t\t\t\t\t\"This is a bug and should be reported.\",\n+\t\t\t\t\tliteralObj.getClass().getCanonicalName(), callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\treturn Tuple3.of(colName, litType, literal);\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createIsNullPredicateConverter(){\n+\t\treturn callExp -> {\n+\t\t\t\tTuple2<String, PredicateLeaf.Type> tuple2 = getTuple2Args(callExp);\n+\n+\t\t\t\tif (tuple2 == null){\n+\t\t\t\t\treturn null;\n+\t\t\t\t}\n+\n+\t\t\t\treturn new OrcSplitReader.IsNull(tuple2.f0, tuple2.f1);\n+\t\t};\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createIsNotNullPredicateConverter(){\n+\t\treturn callExp -> {\n+\n+\t\t\tTuple2<String, PredicateLeaf.Type> tuple2 = getTuple2Args(callExp);\n+\n+\t\t\tif (tuple2 == null){\n+\t\t\t\treturn null;\n+\t\t\t}\n+\n+\t\t\treturn new OrcSplitReader.Not(\n+\t\t\t\t\tnew OrcSplitReader.IsNull(tuple2.f0, tuple2.f1));\n+\t\t};\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createNotPredicateConverter(){\n+\t\treturn callExp -> {\n+\t\t\tif (callExp.getChildren().size() != 1) {\n+\t\t\t\t// not a valid predicate\n+\t\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\t\treturn null;\n+\t\t\t}\n+\n+\t\t\tOrcSplitReader.Predicate c = toOrcPredicate(callExp.getChildren().get(0));\n+\t\t\tif (c == null) {\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\treturn new OrcSplitReader.Not(c);\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createOrPredicateConverter(){\n+\t\treturn callExp -> {\n+\t\t\tif (callExp.getChildren().size() < 2) {\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\tExpression left = callExp.getChildren().get(0);\n+\t\t\tExpression right = callExp.getChildren().get(1);\n+\n+\t\t\tOrcSplitReader.Predicate c1 = toOrcPredicate(left);\n+\t\t\tOrcSplitReader.Predicate c2 = toOrcPredicate(right);\n+\t\t\tif (c1 == null || c2 == null) {\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\treturn new OrcSplitReader.Or(c1, c2);\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createEqualsPredicateConverter(){\n+\t\treturn callExp -> {\n+\t\t\tTuple3<String, PredicateLeaf.Type, Serializable> tuple3 = getTuple3Args(callExp);\n+\n+\t\t\tif (tuple3 == null){\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\treturn new OrcSplitReader.Equals(tuple3.f0, tuple3.f1, tuple3.f2);\n+\t\t};\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createNotEqualsPredicateConverter(){\n+\t\treturn callExp -> {\n+\t\t\tTuple3<String, PredicateLeaf.Type, Serializable> tuple3 = getTuple3Args(callExp);\n+\n+\t\t\tif (tuple3 == null){\n+\t\t\t\treturn null;\n+\t\t\t}\n+\n+\t\t\treturn new OrcSplitReader.Not(\n+\t\t\t\t\tnew OrcSplitReader.Equals(tuple3.f0, tuple3.f1, tuple3.f2));\n+\t\t};\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createGreaterThanPredicateConverter(){\n+\t\treturn callExp -> {\n+\n+\t\t\tTuple3<String, PredicateLeaf.Type, Serializable> tuple3 = getTuple3Args(callExp);\n+\n+\t\t\tif (tuple3 == null){\n+\t\t\t\treturn null;\n+\t\t\t}\n+\n+\t\t\tboolean literalOnRight = literalOnRight(callExp);\n+\n+\t\t\tif (literalOnRight) {\n+\t\t\t\treturn new OrcSplitReader.Not(\n+\t\t\t\t\t\tnew OrcSplitReader.LessThanEquals(tuple3.f0, tuple3.f1, tuple3.f2));\n+\t\t\t} else {\n+\t\t\t\treturn new OrcSplitReader.LessThan(tuple3.f0, tuple3.f1, tuple3.f2);\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createGreaterThanEqualsPredicateConverter(){\n+\t\treturn callExp -> {\n+\n+\t\t\tTuple3<String, PredicateLeaf.Type, Serializable> tuple3 = getTuple3Args(callExp);\n+\n+\t\t\tif (tuple3 == null){\n+\t\t\t\treturn null;\n+\t\t\t}\n+\n+\t\t\tboolean literalOnRight = literalOnRight(callExp);\n+\n+\t\t\tif (literalOnRight) {\n+\t\t\t\treturn new OrcSplitReader.Not(\n+\t\t\t\t\t\tnew OrcSplitReader.LessThan(tuple3.f0, tuple3.f1, tuple3.f2));\n+\t\t\t} else {\n+\t\t\t\treturn new OrcSplitReader.LessThanEquals(tuple3.f0, tuple3.f1, tuple3.f2);\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createLessThanPredicateConverter(){\n+\t\treturn callExp -> {\n+\n+\t\t\tTuple3<String, PredicateLeaf.Type, Serializable> tuple3 = getTuple3Args(callExp);\n+\n+\t\t\tif (tuple3 == null){\n+\t\t\t\treturn null;\n+\t\t\t}\n+\n+\t\t\tboolean literalOnRight = literalOnRight(callExp);\n+\n+\t\t\tif (literalOnRight) {\n+\t\t\t\treturn new OrcSplitReader.LessThan(tuple3.f0, tuple3.f1, tuple3.f2);\n+\t\t\t} else {\n+\t\t\t\treturn new OrcSplitReader.Not(\n+\t\t\t\t\t\tnew OrcSplitReader.LessThanEquals(tuple3.f0, tuple3.f1, tuple3.f2));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createLessThanEqualsPredicateConverter(){\n+\t\treturn callExp -> {\n+\n+\t\t\tTuple3<String, PredicateLeaf.Type, Serializable> tuple3 = getTuple3Args(callExp);\n+\n+\t\t\tif (tuple3 == null){\n+\t\t\t\treturn null;\n+\t\t\t}\n+\n+\t\t\tboolean literalOnRight = literalOnRight(callExp);\n+\n+\t\t\tif (literalOnRight) {\n+\t\t\t\treturn new OrcSplitReader.LessThanEquals(tuple3.f0, tuple3.f1, tuple3.f2);\n+\t\t\t} else {\n+\t\t\t\treturn new OrcSplitReader.Not(\n+\t\t\t\t\t\tnew OrcSplitReader.LessThan(tuple3.f0, tuple3.f1, tuple3.f2));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tpublic static OrcSplitReader.Predicate toOrcPredicate(Expression expression) {\n+\t\tif (expression instanceof CallExpression) {\n+\t\t\tCallExpression callExp = (CallExpression) expression;\n+\t\t\tif (FILTERS.get(callExp.getFunctionDefinition()) == null) {\n+\t\t\t\t// unsupported predicate\n+\t\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", expression);\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\treturn FILTERS.get(callExp.getFunctionDefinition()).apply(callExp);\n+\t\t} else {\n+\t\t\t// unsupported predicate\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", expression);\n+\t\t\treturn null;\n+\t\t}\n+\t}\n+\n+\tprivate static String getColumnName(CallExpression comp) {\n+\t\tif (literalOnRight(comp)) {\n+\t\t\treturn ((FieldReferenceExpression) comp.getChildren().get(0)).getName();\n+\t\t} else {\n+\t\t\treturn ((FieldReferenceExpression) comp.getChildren().get(1)).getName();\n+\t\t}\n+\t}\n+\n+\tprivate static boolean literalOnRight(CallExpression comp) {\n+\t\tif (comp.getChildren().size() == 1 && comp.getChildren().get(0) instanceof FieldReferenceExpression) {\n+\t\t\treturn true;\n+\t\t} else if (comp.getChildren().get(0) instanceof ValueLiteralExpression\n+\t\t\t\t&& comp.getChildren().get(1) instanceof FieldReferenceExpression) {\n+\t\t\treturn false;\n+\t\t} else if (comp.getChildren().get(0) instanceof FieldReferenceExpression\n+\t\t\t\t&& comp.getChildren().get(1) instanceof ValueLiteralExpression) {\n+\t\t\treturn true;\n+\t\t} else {\n+\t\t\tthrow new RuntimeException(\"Invalid binary comparison.\");\n+\t\t}\n+\t}\n+\n+\tprivate static PredicateLeaf.Type getLiteralType(CallExpression comp) {\n+\t\tif (literalOnRight(comp)) {\n+\t\t\treturn toOrcType(((ValueLiteralExpression) comp.getChildren().get(1)).getOutputDataType());\n+\t\t} else {\n+\t\t\treturn toOrcType(((ValueLiteralExpression) comp.getChildren().get(0)).getOutputDataType());\n+\t\t}\n+\t}\n+\n+\tprivate static Optional<?> getLiteral(CallExpression comp) {\n+\t\tif (literalOnRight(comp)) {\n+\t\t\tValueLiteralExpression valueLiteralExpression = (ValueLiteralExpression) comp.getChildren().get(1);\n+\t\t\treturn valueLiteralExpression.getValueAs(valueLiteralExpression.getOutputDataType().getConversionClass());\n+\t\t} else {\n+\t\t\tValueLiteralExpression valueLiteralExpression = (ValueLiteralExpression) comp.getChildren().get(0);\n+\t\t\treturn valueLiteralExpression.getValueAs(valueLiteralExpression.getOutputDataType().getConversionClass());\n+\t\t}\n+\t}\n+\n+\tprivate static PredicateLeaf.Type toOrcType(DataType type) {\n+\t\tLogicalTypeRoot ltype = type.getLogicalType().getTypeRoot();\n+\t\tswitch (ltype){\n+\t\t\tcase TINYINT:\n+\t\t\tcase SMALLINT:\n+\t\t\tcase INTEGER:\n+\t\t\tcase BIGINT:\n+\t\t\t\treturn PredicateLeaf.Type.LONG;\n+\t\t\tcase FLOAT:\n+\t\t\tcase DOUBLE:\n+\t\t\t\treturn PredicateLeaf.Type.FLOAT;\n+\t\t\tcase BOOLEAN:\n+\t\t\t\treturn PredicateLeaf.Type.BOOLEAN;\n+\t\t\tcase VARCHAR:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c7628fc4b97f68c44d7f5e9cf316814c9f73db18"}, "originalPosition": 358}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDE3NDQ1MQ==", "bodyText": "Remove this one TIMESTAMP_WITH_TIME_ZONE", "url": "https://github.com/apache/flink/pull/13306#discussion_r484174451", "createdAt": "2020-09-07T04:16:29Z", "author": {"login": "JingsongLi"}, "path": "flink-formats/flink-orc/src/main/java/org/apache/flink/orc/OrcFilters.java", "diffHunk": "@@ -0,0 +1,372 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.orc;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.api.java.tuple.Tuple3;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.Expression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.flink.table.functions.FunctionDefinition;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.logical.LogicalTypeRoot;\n+\n+import org.apache.flink.shaded.curator4.com.google.common.collect.ImmutableMap;\n+\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.Serializable;\n+import java.util.Optional;\n+import java.util.function.Function;\n+\n+/**\n+ * Utility class that provides helper methods to work with Orc Filter PushDown.\n+ */\n+public class OrcFilters {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(OrcFileSystemFormatFactory.class);\n+\n+\tprivate static final ImmutableMap<FunctionDefinition, Function<CallExpression, OrcSplitReader.Predicate>> FILTERS =\n+\t\t\tnew ImmutableMap.Builder<FunctionDefinition, Function<CallExpression, OrcSplitReader.Predicate>>()\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.IS_NULL, createIsNullPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.IS_NOT_NULL, createIsNotNullPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.NOT, createNotPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.OR, createOrPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.EQUALS, createEqualsPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.NOT_EQUALS, createNotEqualsPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.GREATER_THAN, createGreaterThanPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, createGreaterThanEqualsPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.LESS_THAN, createLessThanPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, createLessThanEqualsPredicateConverter())\n+\t\t\t\t\t.build();\n+\n+\tprivate static boolean isUnaryValid(CallExpression callExpression) {\n+\t\treturn callExpression.getChildren().size() == 1 && callExpression.getChildren().get(0) instanceof FieldReferenceExpression;\n+\t}\n+\n+\tprivate static boolean isBinaryValid(CallExpression callExpression) {\n+\t\treturn callExpression.getChildren().size() == 2 && ((callExpression.getChildren().get(0) instanceof FieldReferenceExpression && callExpression.getChildren().get(1) instanceof ValueLiteralExpression) ||\n+\t\t\t\t(callExpression.getChildren().get(0) instanceof ValueLiteralExpression && callExpression.getChildren().get(1) instanceof FieldReferenceExpression));\n+\t}\n+\n+\tprivate static Tuple2<String, PredicateLeaf.Type> getTuple2Args(CallExpression callExp){\n+\t\tif (!isUnaryValid(callExp)) {\n+\t\t\t// not a valid predicate\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tPredicateLeaf.Type colType = toOrcType(((FieldReferenceExpression) callExp.getChildren().get(0)).getOutputDataType());\n+\t\tif (colType == null) {\n+\t\t\t// unsupported type\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tString colName = getColumnName(callExp);\n+\n+\t\treturn Tuple2.of(colName, colType);\n+\t}\n+\n+\tprivate static Tuple3<String, PredicateLeaf.Type, Serializable> getTuple3Args(CallExpression callExp){\n+\t\tif (!isBinaryValid(callExp)) {\n+\t\t\t// not a valid predicate\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tPredicateLeaf.Type litType = getLiteralType(callExp);\n+\t\tif (litType == null) {\n+\t\t\t// unsupported literal type\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tString colName = getColumnName(callExp);\n+\n+\t\t// fetch literal and ensure it is serializable\n+\t\tObject literalObj = getLiteral(callExp).get();\n+\t\tSerializable literal;\n+\t\t// validate that literal is serializable\n+\t\tif (literalObj instanceof Serializable) {\n+\t\t\tliteral = (Serializable) literalObj;\n+\t\t} else {\n+\t\t\tLOG.warn(\"Encountered a non-serializable literal of type {}. \" +\n+\t\t\t\t\t\t\t\"Cannot push predicate [{}] into OrcFileSystemFormatFactory. \" +\n+\t\t\t\t\t\t\t\"This is a bug and should be reported.\",\n+\t\t\t\t\tliteralObj.getClass().getCanonicalName(), callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\treturn Tuple3.of(colName, litType, literal);\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createIsNullPredicateConverter(){\n+\t\treturn callExp -> {\n+\t\t\t\tTuple2<String, PredicateLeaf.Type> tuple2 = getTuple2Args(callExp);\n+\n+\t\t\t\tif (tuple2 == null){\n+\t\t\t\t\treturn null;\n+\t\t\t\t}\n+\n+\t\t\t\treturn new OrcSplitReader.IsNull(tuple2.f0, tuple2.f1);\n+\t\t};\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createIsNotNullPredicateConverter(){\n+\t\treturn callExp -> {\n+\n+\t\t\tTuple2<String, PredicateLeaf.Type> tuple2 = getTuple2Args(callExp);\n+\n+\t\t\tif (tuple2 == null){\n+\t\t\t\treturn null;\n+\t\t\t}\n+\n+\t\t\treturn new OrcSplitReader.Not(\n+\t\t\t\t\tnew OrcSplitReader.IsNull(tuple2.f0, tuple2.f1));\n+\t\t};\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createNotPredicateConverter(){\n+\t\treturn callExp -> {\n+\t\t\tif (callExp.getChildren().size() != 1) {\n+\t\t\t\t// not a valid predicate\n+\t\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\t\treturn null;\n+\t\t\t}\n+\n+\t\t\tOrcSplitReader.Predicate c = toOrcPredicate(callExp.getChildren().get(0));\n+\t\t\tif (c == null) {\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\treturn new OrcSplitReader.Not(c);\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createOrPredicateConverter(){\n+\t\treturn callExp -> {\n+\t\t\tif (callExp.getChildren().size() < 2) {\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\tExpression left = callExp.getChildren().get(0);\n+\t\t\tExpression right = callExp.getChildren().get(1);\n+\n+\t\t\tOrcSplitReader.Predicate c1 = toOrcPredicate(left);\n+\t\t\tOrcSplitReader.Predicate c2 = toOrcPredicate(right);\n+\t\t\tif (c1 == null || c2 == null) {\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\treturn new OrcSplitReader.Or(c1, c2);\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createEqualsPredicateConverter(){\n+\t\treturn callExp -> {\n+\t\t\tTuple3<String, PredicateLeaf.Type, Serializable> tuple3 = getTuple3Args(callExp);\n+\n+\t\t\tif (tuple3 == null){\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\treturn new OrcSplitReader.Equals(tuple3.f0, tuple3.f1, tuple3.f2);\n+\t\t};\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createNotEqualsPredicateConverter(){\n+\t\treturn callExp -> {\n+\t\t\tTuple3<String, PredicateLeaf.Type, Serializable> tuple3 = getTuple3Args(callExp);\n+\n+\t\t\tif (tuple3 == null){\n+\t\t\t\treturn null;\n+\t\t\t}\n+\n+\t\t\treturn new OrcSplitReader.Not(\n+\t\t\t\t\tnew OrcSplitReader.Equals(tuple3.f0, tuple3.f1, tuple3.f2));\n+\t\t};\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createGreaterThanPredicateConverter(){\n+\t\treturn callExp -> {\n+\n+\t\t\tTuple3<String, PredicateLeaf.Type, Serializable> tuple3 = getTuple3Args(callExp);\n+\n+\t\t\tif (tuple3 == null){\n+\t\t\t\treturn null;\n+\t\t\t}\n+\n+\t\t\tboolean literalOnRight = literalOnRight(callExp);\n+\n+\t\t\tif (literalOnRight) {\n+\t\t\t\treturn new OrcSplitReader.Not(\n+\t\t\t\t\t\tnew OrcSplitReader.LessThanEquals(tuple3.f0, tuple3.f1, tuple3.f2));\n+\t\t\t} else {\n+\t\t\t\treturn new OrcSplitReader.LessThan(tuple3.f0, tuple3.f1, tuple3.f2);\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createGreaterThanEqualsPredicateConverter(){\n+\t\treturn callExp -> {\n+\n+\t\t\tTuple3<String, PredicateLeaf.Type, Serializable> tuple3 = getTuple3Args(callExp);\n+\n+\t\t\tif (tuple3 == null){\n+\t\t\t\treturn null;\n+\t\t\t}\n+\n+\t\t\tboolean literalOnRight = literalOnRight(callExp);\n+\n+\t\t\tif (literalOnRight) {\n+\t\t\t\treturn new OrcSplitReader.Not(\n+\t\t\t\t\t\tnew OrcSplitReader.LessThan(tuple3.f0, tuple3.f1, tuple3.f2));\n+\t\t\t} else {\n+\t\t\t\treturn new OrcSplitReader.LessThanEquals(tuple3.f0, tuple3.f1, tuple3.f2);\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createLessThanPredicateConverter(){\n+\t\treturn callExp -> {\n+\n+\t\t\tTuple3<String, PredicateLeaf.Type, Serializable> tuple3 = getTuple3Args(callExp);\n+\n+\t\t\tif (tuple3 == null){\n+\t\t\t\treturn null;\n+\t\t\t}\n+\n+\t\t\tboolean literalOnRight = literalOnRight(callExp);\n+\n+\t\t\tif (literalOnRight) {\n+\t\t\t\treturn new OrcSplitReader.LessThan(tuple3.f0, tuple3.f1, tuple3.f2);\n+\t\t\t} else {\n+\t\t\t\treturn new OrcSplitReader.Not(\n+\t\t\t\t\t\tnew OrcSplitReader.LessThanEquals(tuple3.f0, tuple3.f1, tuple3.f2));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createLessThanEqualsPredicateConverter(){\n+\t\treturn callExp -> {\n+\n+\t\t\tTuple3<String, PredicateLeaf.Type, Serializable> tuple3 = getTuple3Args(callExp);\n+\n+\t\t\tif (tuple3 == null){\n+\t\t\t\treturn null;\n+\t\t\t}\n+\n+\t\t\tboolean literalOnRight = literalOnRight(callExp);\n+\n+\t\t\tif (literalOnRight) {\n+\t\t\t\treturn new OrcSplitReader.LessThanEquals(tuple3.f0, tuple3.f1, tuple3.f2);\n+\t\t\t} else {\n+\t\t\t\treturn new OrcSplitReader.Not(\n+\t\t\t\t\t\tnew OrcSplitReader.LessThan(tuple3.f0, tuple3.f1, tuple3.f2));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tpublic static OrcSplitReader.Predicate toOrcPredicate(Expression expression) {\n+\t\tif (expression instanceof CallExpression) {\n+\t\t\tCallExpression callExp = (CallExpression) expression;\n+\t\t\tif (FILTERS.get(callExp.getFunctionDefinition()) == null) {\n+\t\t\t\t// unsupported predicate\n+\t\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", expression);\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\treturn FILTERS.get(callExp.getFunctionDefinition()).apply(callExp);\n+\t\t} else {\n+\t\t\t// unsupported predicate\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", expression);\n+\t\t\treturn null;\n+\t\t}\n+\t}\n+\n+\tprivate static String getColumnName(CallExpression comp) {\n+\t\tif (literalOnRight(comp)) {\n+\t\t\treturn ((FieldReferenceExpression) comp.getChildren().get(0)).getName();\n+\t\t} else {\n+\t\t\treturn ((FieldReferenceExpression) comp.getChildren().get(1)).getName();\n+\t\t}\n+\t}\n+\n+\tprivate static boolean literalOnRight(CallExpression comp) {\n+\t\tif (comp.getChildren().size() == 1 && comp.getChildren().get(0) instanceof FieldReferenceExpression) {\n+\t\t\treturn true;\n+\t\t} else if (comp.getChildren().get(0) instanceof ValueLiteralExpression\n+\t\t\t\t&& comp.getChildren().get(1) instanceof FieldReferenceExpression) {\n+\t\t\treturn false;\n+\t\t} else if (comp.getChildren().get(0) instanceof FieldReferenceExpression\n+\t\t\t\t&& comp.getChildren().get(1) instanceof ValueLiteralExpression) {\n+\t\t\treturn true;\n+\t\t} else {\n+\t\t\tthrow new RuntimeException(\"Invalid binary comparison.\");\n+\t\t}\n+\t}\n+\n+\tprivate static PredicateLeaf.Type getLiteralType(CallExpression comp) {\n+\t\tif (literalOnRight(comp)) {\n+\t\t\treturn toOrcType(((ValueLiteralExpression) comp.getChildren().get(1)).getOutputDataType());\n+\t\t} else {\n+\t\t\treturn toOrcType(((ValueLiteralExpression) comp.getChildren().get(0)).getOutputDataType());\n+\t\t}\n+\t}\n+\n+\tprivate static Optional<?> getLiteral(CallExpression comp) {\n+\t\tif (literalOnRight(comp)) {\n+\t\t\tValueLiteralExpression valueLiteralExpression = (ValueLiteralExpression) comp.getChildren().get(1);\n+\t\t\treturn valueLiteralExpression.getValueAs(valueLiteralExpression.getOutputDataType().getConversionClass());\n+\t\t} else {\n+\t\t\tValueLiteralExpression valueLiteralExpression = (ValueLiteralExpression) comp.getChildren().get(0);\n+\t\t\treturn valueLiteralExpression.getValueAs(valueLiteralExpression.getOutputDataType().getConversionClass());\n+\t\t}\n+\t}\n+\n+\tprivate static PredicateLeaf.Type toOrcType(DataType type) {\n+\t\tLogicalTypeRoot ltype = type.getLogicalType().getTypeRoot();\n+\t\tswitch (ltype){\n+\t\t\tcase TINYINT:\n+\t\t\tcase SMALLINT:\n+\t\t\tcase INTEGER:\n+\t\t\tcase BIGINT:\n+\t\t\t\treturn PredicateLeaf.Type.LONG;\n+\t\t\tcase FLOAT:\n+\t\t\tcase DOUBLE:\n+\t\t\t\treturn PredicateLeaf.Type.FLOAT;\n+\t\t\tcase BOOLEAN:\n+\t\t\t\treturn PredicateLeaf.Type.BOOLEAN;\n+\t\t\tcase VARCHAR:\n+\t\t\t\treturn PredicateLeaf.Type.STRING;\n+\t\t\tcase TIMESTAMP_WITHOUT_TIME_ZONE:\n+\t\t\tcase TIMESTAMP_WITH_LOCAL_TIME_ZONE:\n+\t\t\tcase TIMESTAMP_WITH_TIME_ZONE:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c7628fc4b97f68c44d7f5e9cf316814c9f73db18"}, "originalPosition": 362}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDE3NDU0Mw==", "bodyText": "It is not BINARY", "url": "https://github.com/apache/flink/pull/13306#discussion_r484174543", "createdAt": "2020-09-07T04:17:02Z", "author": {"login": "JingsongLi"}, "path": "flink-formats/flink-orc/src/main/java/org/apache/flink/orc/OrcFilters.java", "diffHunk": "@@ -0,0 +1,372 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.orc;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.api.java.tuple.Tuple3;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.Expression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.flink.table.functions.FunctionDefinition;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.logical.LogicalTypeRoot;\n+\n+import org.apache.flink.shaded.curator4.com.google.common.collect.ImmutableMap;\n+\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.Serializable;\n+import java.util.Optional;\n+import java.util.function.Function;\n+\n+/**\n+ * Utility class that provides helper methods to work with Orc Filter PushDown.\n+ */\n+public class OrcFilters {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(OrcFileSystemFormatFactory.class);\n+\n+\tprivate static final ImmutableMap<FunctionDefinition, Function<CallExpression, OrcSplitReader.Predicate>> FILTERS =\n+\t\t\tnew ImmutableMap.Builder<FunctionDefinition, Function<CallExpression, OrcSplitReader.Predicate>>()\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.IS_NULL, createIsNullPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.IS_NOT_NULL, createIsNotNullPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.NOT, createNotPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.OR, createOrPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.EQUALS, createEqualsPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.NOT_EQUALS, createNotEqualsPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.GREATER_THAN, createGreaterThanPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, createGreaterThanEqualsPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.LESS_THAN, createLessThanPredicateConverter())\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, createLessThanEqualsPredicateConverter())\n+\t\t\t\t\t.build();\n+\n+\tprivate static boolean isUnaryValid(CallExpression callExpression) {\n+\t\treturn callExpression.getChildren().size() == 1 && callExpression.getChildren().get(0) instanceof FieldReferenceExpression;\n+\t}\n+\n+\tprivate static boolean isBinaryValid(CallExpression callExpression) {\n+\t\treturn callExpression.getChildren().size() == 2 && ((callExpression.getChildren().get(0) instanceof FieldReferenceExpression && callExpression.getChildren().get(1) instanceof ValueLiteralExpression) ||\n+\t\t\t\t(callExpression.getChildren().get(0) instanceof ValueLiteralExpression && callExpression.getChildren().get(1) instanceof FieldReferenceExpression));\n+\t}\n+\n+\tprivate static Tuple2<String, PredicateLeaf.Type> getTuple2Args(CallExpression callExp){\n+\t\tif (!isUnaryValid(callExp)) {\n+\t\t\t// not a valid predicate\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tPredicateLeaf.Type colType = toOrcType(((FieldReferenceExpression) callExp.getChildren().get(0)).getOutputDataType());\n+\t\tif (colType == null) {\n+\t\t\t// unsupported type\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tString colName = getColumnName(callExp);\n+\n+\t\treturn Tuple2.of(colName, colType);\n+\t}\n+\n+\tprivate static Tuple3<String, PredicateLeaf.Type, Serializable> getTuple3Args(CallExpression callExp){\n+\t\tif (!isBinaryValid(callExp)) {\n+\t\t\t// not a valid predicate\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tPredicateLeaf.Type litType = getLiteralType(callExp);\n+\t\tif (litType == null) {\n+\t\t\t// unsupported literal type\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tString colName = getColumnName(callExp);\n+\n+\t\t// fetch literal and ensure it is serializable\n+\t\tObject literalObj = getLiteral(callExp).get();\n+\t\tSerializable literal;\n+\t\t// validate that literal is serializable\n+\t\tif (literalObj instanceof Serializable) {\n+\t\t\tliteral = (Serializable) literalObj;\n+\t\t} else {\n+\t\t\tLOG.warn(\"Encountered a non-serializable literal of type {}. \" +\n+\t\t\t\t\t\t\t\"Cannot push predicate [{}] into OrcFileSystemFormatFactory. \" +\n+\t\t\t\t\t\t\t\"This is a bug and should be reported.\",\n+\t\t\t\t\tliteralObj.getClass().getCanonicalName(), callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\treturn Tuple3.of(colName, litType, literal);\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createIsNullPredicateConverter(){\n+\t\treturn callExp -> {\n+\t\t\t\tTuple2<String, PredicateLeaf.Type> tuple2 = getTuple2Args(callExp);\n+\n+\t\t\t\tif (tuple2 == null){\n+\t\t\t\t\treturn null;\n+\t\t\t\t}\n+\n+\t\t\t\treturn new OrcSplitReader.IsNull(tuple2.f0, tuple2.f1);\n+\t\t};\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createIsNotNullPredicateConverter(){\n+\t\treturn callExp -> {\n+\n+\t\t\tTuple2<String, PredicateLeaf.Type> tuple2 = getTuple2Args(callExp);\n+\n+\t\t\tif (tuple2 == null){\n+\t\t\t\treturn null;\n+\t\t\t}\n+\n+\t\t\treturn new OrcSplitReader.Not(\n+\t\t\t\t\tnew OrcSplitReader.IsNull(tuple2.f0, tuple2.f1));\n+\t\t};\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createNotPredicateConverter(){\n+\t\treturn callExp -> {\n+\t\t\tif (callExp.getChildren().size() != 1) {\n+\t\t\t\t// not a valid predicate\n+\t\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\t\treturn null;\n+\t\t\t}\n+\n+\t\t\tOrcSplitReader.Predicate c = toOrcPredicate(callExp.getChildren().get(0));\n+\t\t\tif (c == null) {\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\treturn new OrcSplitReader.Not(c);\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createOrPredicateConverter(){\n+\t\treturn callExp -> {\n+\t\t\tif (callExp.getChildren().size() < 2) {\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\tExpression left = callExp.getChildren().get(0);\n+\t\t\tExpression right = callExp.getChildren().get(1);\n+\n+\t\t\tOrcSplitReader.Predicate c1 = toOrcPredicate(left);\n+\t\t\tOrcSplitReader.Predicate c2 = toOrcPredicate(right);\n+\t\t\tif (c1 == null || c2 == null) {\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\treturn new OrcSplitReader.Or(c1, c2);\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createEqualsPredicateConverter(){\n+\t\treturn callExp -> {\n+\t\t\tTuple3<String, PredicateLeaf.Type, Serializable> tuple3 = getTuple3Args(callExp);\n+\n+\t\t\tif (tuple3 == null){\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\treturn new OrcSplitReader.Equals(tuple3.f0, tuple3.f1, tuple3.f2);\n+\t\t};\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createNotEqualsPredicateConverter(){\n+\t\treturn callExp -> {\n+\t\t\tTuple3<String, PredicateLeaf.Type, Serializable> tuple3 = getTuple3Args(callExp);\n+\n+\t\t\tif (tuple3 == null){\n+\t\t\t\treturn null;\n+\t\t\t}\n+\n+\t\t\treturn new OrcSplitReader.Not(\n+\t\t\t\t\tnew OrcSplitReader.Equals(tuple3.f0, tuple3.f1, tuple3.f2));\n+\t\t};\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createGreaterThanPredicateConverter(){\n+\t\treturn callExp -> {\n+\n+\t\t\tTuple3<String, PredicateLeaf.Type, Serializable> tuple3 = getTuple3Args(callExp);\n+\n+\t\t\tif (tuple3 == null){\n+\t\t\t\treturn null;\n+\t\t\t}\n+\n+\t\t\tboolean literalOnRight = literalOnRight(callExp);\n+\n+\t\t\tif (literalOnRight) {\n+\t\t\t\treturn new OrcSplitReader.Not(\n+\t\t\t\t\t\tnew OrcSplitReader.LessThanEquals(tuple3.f0, tuple3.f1, tuple3.f2));\n+\t\t\t} else {\n+\t\t\t\treturn new OrcSplitReader.LessThan(tuple3.f0, tuple3.f1, tuple3.f2);\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createGreaterThanEqualsPredicateConverter(){\n+\t\treturn callExp -> {\n+\n+\t\t\tTuple3<String, PredicateLeaf.Type, Serializable> tuple3 = getTuple3Args(callExp);\n+\n+\t\t\tif (tuple3 == null){\n+\t\t\t\treturn null;\n+\t\t\t}\n+\n+\t\t\tboolean literalOnRight = literalOnRight(callExp);\n+\n+\t\t\tif (literalOnRight) {\n+\t\t\t\treturn new OrcSplitReader.Not(\n+\t\t\t\t\t\tnew OrcSplitReader.LessThan(tuple3.f0, tuple3.f1, tuple3.f2));\n+\t\t\t} else {\n+\t\t\t\treturn new OrcSplitReader.LessThanEquals(tuple3.f0, tuple3.f1, tuple3.f2);\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createLessThanPredicateConverter(){\n+\t\treturn callExp -> {\n+\n+\t\t\tTuple3<String, PredicateLeaf.Type, Serializable> tuple3 = getTuple3Args(callExp);\n+\n+\t\t\tif (tuple3 == null){\n+\t\t\t\treturn null;\n+\t\t\t}\n+\n+\t\t\tboolean literalOnRight = literalOnRight(callExp);\n+\n+\t\t\tif (literalOnRight) {\n+\t\t\t\treturn new OrcSplitReader.LessThan(tuple3.f0, tuple3.f1, tuple3.f2);\n+\t\t\t} else {\n+\t\t\t\treturn new OrcSplitReader.Not(\n+\t\t\t\t\t\tnew OrcSplitReader.LessThanEquals(tuple3.f0, tuple3.f1, tuple3.f2));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tprivate static Function<CallExpression, OrcSplitReader.Predicate> createLessThanEqualsPredicateConverter(){\n+\t\treturn callExp -> {\n+\n+\t\t\tTuple3<String, PredicateLeaf.Type, Serializable> tuple3 = getTuple3Args(callExp);\n+\n+\t\t\tif (tuple3 == null){\n+\t\t\t\treturn null;\n+\t\t\t}\n+\n+\t\t\tboolean literalOnRight = literalOnRight(callExp);\n+\n+\t\t\tif (literalOnRight) {\n+\t\t\t\treturn new OrcSplitReader.LessThanEquals(tuple3.f0, tuple3.f1, tuple3.f2);\n+\t\t\t} else {\n+\t\t\t\treturn new OrcSplitReader.Not(\n+\t\t\t\t\t\tnew OrcSplitReader.LessThan(tuple3.f0, tuple3.f1, tuple3.f2));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tpublic static OrcSplitReader.Predicate toOrcPredicate(Expression expression) {\n+\t\tif (expression instanceof CallExpression) {\n+\t\t\tCallExpression callExp = (CallExpression) expression;\n+\t\t\tif (FILTERS.get(callExp.getFunctionDefinition()) == null) {\n+\t\t\t\t// unsupported predicate\n+\t\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", expression);\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\treturn FILTERS.get(callExp.getFunctionDefinition()).apply(callExp);\n+\t\t} else {\n+\t\t\t// unsupported predicate\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", expression);\n+\t\t\treturn null;\n+\t\t}\n+\t}\n+\n+\tprivate static String getColumnName(CallExpression comp) {\n+\t\tif (literalOnRight(comp)) {\n+\t\t\treturn ((FieldReferenceExpression) comp.getChildren().get(0)).getName();\n+\t\t} else {\n+\t\t\treturn ((FieldReferenceExpression) comp.getChildren().get(1)).getName();\n+\t\t}\n+\t}\n+\n+\tprivate static boolean literalOnRight(CallExpression comp) {\n+\t\tif (comp.getChildren().size() == 1 && comp.getChildren().get(0) instanceof FieldReferenceExpression) {\n+\t\t\treturn true;\n+\t\t} else if (comp.getChildren().get(0) instanceof ValueLiteralExpression\n+\t\t\t\t&& comp.getChildren().get(1) instanceof FieldReferenceExpression) {\n+\t\t\treturn false;\n+\t\t} else if (comp.getChildren().get(0) instanceof FieldReferenceExpression\n+\t\t\t\t&& comp.getChildren().get(1) instanceof ValueLiteralExpression) {\n+\t\t\treturn true;\n+\t\t} else {\n+\t\t\tthrow new RuntimeException(\"Invalid binary comparison.\");\n+\t\t}\n+\t}\n+\n+\tprivate static PredicateLeaf.Type getLiteralType(CallExpression comp) {\n+\t\tif (literalOnRight(comp)) {\n+\t\t\treturn toOrcType(((ValueLiteralExpression) comp.getChildren().get(1)).getOutputDataType());\n+\t\t} else {\n+\t\t\treturn toOrcType(((ValueLiteralExpression) comp.getChildren().get(0)).getOutputDataType());\n+\t\t}\n+\t}\n+\n+\tprivate static Optional<?> getLiteral(CallExpression comp) {\n+\t\tif (literalOnRight(comp)) {\n+\t\t\tValueLiteralExpression valueLiteralExpression = (ValueLiteralExpression) comp.getChildren().get(1);\n+\t\t\treturn valueLiteralExpression.getValueAs(valueLiteralExpression.getOutputDataType().getConversionClass());\n+\t\t} else {\n+\t\t\tValueLiteralExpression valueLiteralExpression = (ValueLiteralExpression) comp.getChildren().get(0);\n+\t\t\treturn valueLiteralExpression.getValueAs(valueLiteralExpression.getOutputDataType().getConversionClass());\n+\t\t}\n+\t}\n+\n+\tprivate static PredicateLeaf.Type toOrcType(DataType type) {\n+\t\tLogicalTypeRoot ltype = type.getLogicalType().getTypeRoot();\n+\t\tswitch (ltype){\n+\t\t\tcase TINYINT:\n+\t\t\tcase SMALLINT:\n+\t\t\tcase INTEGER:\n+\t\t\tcase BIGINT:\n+\t\t\t\treturn PredicateLeaf.Type.LONG;\n+\t\t\tcase FLOAT:\n+\t\t\tcase DOUBLE:\n+\t\t\t\treturn PredicateLeaf.Type.FLOAT;\n+\t\t\tcase BOOLEAN:\n+\t\t\t\treturn PredicateLeaf.Type.BOOLEAN;\n+\t\t\tcase VARCHAR:\n+\t\t\t\treturn PredicateLeaf.Type.STRING;\n+\t\t\tcase TIMESTAMP_WITHOUT_TIME_ZONE:\n+\t\t\tcase TIMESTAMP_WITH_LOCAL_TIME_ZONE:\n+\t\t\tcase TIMESTAMP_WITH_TIME_ZONE:\n+\t\t\t\treturn PredicateLeaf.Type.TIMESTAMP;\n+\t\t\tcase DATE:\n+\t\t\t\treturn PredicateLeaf.Type.DATE;\n+\t\t\tcase BINARY:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c7628fc4b97f68c44d7f5e9cf316814c9f73db18"}, "originalPosition": 366}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDgzNzU2Mzc2", "url": "https://github.com/apache/flink/pull/13306#pullrequestreview-483756376", "createdAt": "2020-09-08T02:21:48Z", "commit": {"oid": "174d9d69aa825ce53661c38b2bf9c7e71440c687"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQwMjoyMTo0OFrOHOKkTg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQwMjoyNTo0OFrOHOKn3w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDYxNTI0Ng==", "bodyText": "I have some concern about literal structure..\nEspecially timestamp and date, Flink is LocalTimestamp, and LocalDate, I don't know what is ORC. You verify this in ITCase.", "url": "https://github.com/apache/flink/pull/13306#discussion_r484615246", "createdAt": "2020-09-08T02:21:48Z", "author": {"login": "JingsongLi"}, "path": "flink-formats/flink-orc/src/main/java/org/apache/flink/orc/OrcFilters.java", "diffHunk": "@@ -0,0 +1,273 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.orc;\n+\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.Expression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.flink.table.functions.FunctionDefinition;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.logical.LogicalTypeRoot;\n+import org.apache.flink.util.function.TriFunction;\n+\n+import org.apache.flink.shaded.curator4.com.google.common.collect.ImmutableMap;\n+\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.Serializable;\n+import java.util.Optional;\n+import java.util.function.Function;\n+\n+/**\n+ * Utility class that provides helper methods to work with Orc Filter PushDown.\n+ */\n+public class OrcFilters {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(OrcFileSystemFormatFactory.class);\n+\n+\tprivate static final ImmutableMap<FunctionDefinition, Function<CallExpression, OrcSplitReader.Predicate>> FILTERS =\n+\t\t\tnew ImmutableMap.Builder<FunctionDefinition, Function<CallExpression, OrcSplitReader.Predicate>>()\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.IS_NULL, OrcFilters::convertIsNull)\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.IS_NOT_NULL, OrcFilters::convertIsNotNull)\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.NOT, OrcFilters::convertNot)\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.OR, OrcFilters::convertOr)\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.EQUALS, call -> convertBinary(call, OrcFilters::convertEquals, OrcFilters::convertEquals))\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.NOT_EQUALS, call -> convertBinary(call, OrcFilters::convertNotEquals, OrcFilters::convertNotEquals))\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.GREATER_THAN, call -> convertBinary(call, OrcFilters::convertGreaterThan, OrcFilters::convertLessThanEquals))\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, call -> convertBinary(call, OrcFilters::convertGreaterThanEquals, OrcFilters::convertLessThan))\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.LESS_THAN, call -> convertBinary(call, OrcFilters::convertLessThan, OrcFilters::convertGreaterThanEquals))\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, call -> convertBinary(call, OrcFilters::convertLessThanEquals, OrcFilters::convertGreaterThan))\n+\t\t\t\t\t.build();\n+\n+\tprivate static boolean isRef(Expression expression) {\n+\t\treturn expression instanceof FieldReferenceExpression;\n+\t}\n+\n+\tprivate static boolean isLit(Expression expression) {\n+\t\treturn expression instanceof ValueLiteralExpression;\n+\t}\n+\n+\tprivate static boolean isUnaryValid(CallExpression callExpression) {\n+\t\treturn callExpression.getChildren().size() == 1 && isRef(callExpression.getChildren().get(0));\n+\t}\n+\n+\tprivate static boolean isBinaryValid(CallExpression callExpression) {\n+\t\treturn callExpression.getChildren().size() == 2 && (\n+\t\t\t\tisRef(callExpression.getChildren().get(0)) && isLit(callExpression.getChildren().get(1)) ||\n+\t\t\t\t\t\tisLit(callExpression.getChildren().get(0)) && isRef(callExpression.getChildren().get(1))\n+\t\t);\n+\t}\n+\n+\tprivate static OrcSplitReader.Predicate convertIsNull(CallExpression callExp) {\n+\t\tif (!isUnaryValid(callExp)) {\n+\t\t\t// not a valid predicate\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tPredicateLeaf.Type colType = toOrcType(((FieldReferenceExpression) callExp.getChildren().get(0)).getOutputDataType());\n+\t\tif (colType == null) {\n+\t\t\t// unsupported type\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tString colName = getColumnName(callExp);\n+\n+\t\treturn new OrcSplitReader.IsNull(colName, colType);\n+\t}\n+\n+\tprivate static OrcSplitReader.Predicate convertIsNotNull(CallExpression callExp) {\n+\t\treturn new OrcSplitReader.Not(convertIsNull(callExp));\n+\t}\n+\n+\tprivate static OrcSplitReader.Predicate convertNot(CallExpression callExp) {\n+\t\tif (callExp.getChildren().size() != 1) {\n+\t\t\t// not a valid predicate\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tOrcSplitReader.Predicate c = toOrcPredicate(callExp.getChildren().get(0));\n+\t\treturn c == null ? null : new OrcSplitReader.Not(c);\n+\t}\n+\n+\tprivate static OrcSplitReader.Predicate convertOr(CallExpression callExp) {\n+\t\tif (callExp.getChildren().size() < 2) {\n+\t\t\treturn null;\n+\t\t}\n+\t\tExpression left = callExp.getChildren().get(0);\n+\t\tExpression right = callExp.getChildren().get(1);\n+\n+\t\tOrcSplitReader.Predicate c1 = toOrcPredicate(left);\n+\t\tOrcSplitReader.Predicate c2 = toOrcPredicate(right);\n+\t\tif (c1 == null || c2 == null) {\n+\t\t\treturn null;\n+\t\t} else {\n+\t\t\treturn new OrcSplitReader.Or(c1, c2);\n+\t\t}\n+\t}\n+\n+\tpublic static OrcSplitReader.Predicate convertBinary(CallExpression callExp,\n+\t\t\tTriFunction<String, PredicateLeaf.Type, Serializable, OrcSplitReader.Predicate> func,\n+\t\t\tTriFunction<String, PredicateLeaf.Type, Serializable, OrcSplitReader.Predicate> reverseFunc) {\n+\t\tif (!isBinaryValid(callExp)) {\n+\t\t\t// not a valid predicate\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tPredicateLeaf.Type litType = getLiteralType(callExp);\n+\t\tif (litType == null) {\n+\t\t\t// unsupported literal type\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tString colName = getColumnName(callExp);\n+\n+\t\t// fetch literal and ensure it is serializable\n+\t\tObject literalObj = getLiteral(callExp).get();\n+\t\tSerializable literal;\n+\t\t// validate that literal is serializable\n+\t\tif (literalObj instanceof Serializable) {\n+\t\t\tliteral = (Serializable) literalObj;\n+\t\t} else {\n+\t\t\tLOG.warn(\"Encountered a non-serializable literal of type {}. \" +\n+\t\t\t\t\t\t\t\"Cannot push predicate [{}] into OrcFileSystemFormatFactory. \" +\n+\t\t\t\t\t\t\t\"This is a bug and should be reported.\",\n+\t\t\t\t\tliteralObj.getClass().getCanonicalName(), callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\treturn literalOnRight(callExp) ? func.apply(colName, litType, literal) : reverseFunc.apply(colName, litType, literal);\n+\t}\n+\n+\tprivate static OrcSplitReader.Predicate convertEquals(String colName, PredicateLeaf.Type litType, Serializable literal) {\n+\t\treturn new OrcSplitReader.Equals(colName, litType, literal);\n+\t}\n+\n+\tprivate static OrcSplitReader.Predicate convertNotEquals(String colName, PredicateLeaf.Type litType, Serializable literal) {\n+\t\treturn new OrcSplitReader.Not(convertEquals(colName, litType, literal));\n+\t}\n+\n+\tprivate static OrcSplitReader.Predicate convertGreaterThan(String colName, PredicateLeaf.Type litType, Serializable literal) {\n+\t\treturn new OrcSplitReader.Not(\n+\t\t\t\tnew OrcSplitReader.LessThanEquals(colName, litType, literal));\n+\t}\n+\n+\tprivate static OrcSplitReader.Predicate convertGreaterThanEquals(String colName, PredicateLeaf.Type litType, Serializable literal) {\n+\t\treturn new OrcSplitReader.Not(\n+\t\t\t\tnew OrcSplitReader.LessThan(colName, litType, literal));\n+\t}\n+\n+\tprivate static OrcSplitReader.Predicate convertLessThan(String colName, PredicateLeaf.Type litType, Serializable literal) {\n+\t\treturn new OrcSplitReader.LessThan(colName, litType, literal);\n+\t}\n+\n+\tprivate static OrcSplitReader.Predicate convertLessThanEquals(String colName, PredicateLeaf.Type litType, Serializable literal) {\n+\t\treturn new OrcSplitReader.LessThanEquals(colName, litType, literal);\n+\t}\n+\n+\tpublic static OrcSplitReader.Predicate toOrcPredicate(Expression expression) {\n+\t\tif (expression instanceof CallExpression) {\n+\t\t\tCallExpression callExp = (CallExpression) expression;\n+\t\t\tif (FILTERS.get(callExp.getFunctionDefinition()) == null) {\n+\t\t\t\t// unsupported predicate\n+\t\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", expression);\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\treturn FILTERS.get(callExp.getFunctionDefinition()).apply(callExp);\n+\t\t} else {\n+\t\t\t// unsupported predicate\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", expression);\n+\t\t\treturn null;\n+\t\t}\n+\t}\n+\n+\tprivate static String getColumnName(CallExpression comp) {\n+\t\tif (literalOnRight(comp)) {\n+\t\t\treturn ((FieldReferenceExpression) comp.getChildren().get(0)).getName();\n+\t\t} else {\n+\t\t\treturn ((FieldReferenceExpression) comp.getChildren().get(1)).getName();\n+\t\t}\n+\t}\n+\n+\tprivate static boolean literalOnRight(CallExpression comp) {\n+\t\tif (comp.getChildren().size() == 1 && comp.getChildren().get(0) instanceof FieldReferenceExpression) {\n+\t\t\treturn true;\n+\t\t} else if (isLit(comp.getChildren().get(0)) && isRef(comp.getChildren().get(1))) {\n+\t\t\treturn false;\n+\t\t} else if (isRef(comp.getChildren().get(0)) && isLit(comp.getChildren().get(1))) {\n+\t\t\treturn true;\n+\t\t} else {\n+\t\t\tthrow new RuntimeException(\"Invalid binary comparison.\");\n+\t\t}\n+\t}\n+\n+\tprivate static PredicateLeaf.Type getLiteralType(CallExpression comp) {\n+\t\tif (literalOnRight(comp)) {\n+\t\t\treturn toOrcType(((ValueLiteralExpression) comp.getChildren().get(1)).getOutputDataType());\n+\t\t} else {\n+\t\t\treturn toOrcType(((ValueLiteralExpression) comp.getChildren().get(0)).getOutputDataType());\n+\t\t}\n+\t}\n+\n+\tprivate static Optional<?> getLiteral(CallExpression comp) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "174d9d69aa825ce53661c38b2bf9c7e71440c687"}, "originalPosition": 236}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDYxNjA1NA==", "bodyText": "You can remove TIMESTAMP_WITH_LOCAL_TIME_ZONE, it is hard to test it.", "url": "https://github.com/apache/flink/pull/13306#discussion_r484616054", "createdAt": "2020-09-08T02:25:19Z", "author": {"login": "JingsongLi"}, "path": "flink-formats/flink-orc/src/main/java/org/apache/flink/orc/OrcFilters.java", "diffHunk": "@@ -0,0 +1,273 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.orc;\n+\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.Expression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.flink.table.functions.FunctionDefinition;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.logical.LogicalTypeRoot;\n+import org.apache.flink.util.function.TriFunction;\n+\n+import org.apache.flink.shaded.curator4.com.google.common.collect.ImmutableMap;\n+\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.Serializable;\n+import java.util.Optional;\n+import java.util.function.Function;\n+\n+/**\n+ * Utility class that provides helper methods to work with Orc Filter PushDown.\n+ */\n+public class OrcFilters {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(OrcFileSystemFormatFactory.class);\n+\n+\tprivate static final ImmutableMap<FunctionDefinition, Function<CallExpression, OrcSplitReader.Predicate>> FILTERS =\n+\t\t\tnew ImmutableMap.Builder<FunctionDefinition, Function<CallExpression, OrcSplitReader.Predicate>>()\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.IS_NULL, OrcFilters::convertIsNull)\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.IS_NOT_NULL, OrcFilters::convertIsNotNull)\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.NOT, OrcFilters::convertNot)\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.OR, OrcFilters::convertOr)\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.EQUALS, call -> convertBinary(call, OrcFilters::convertEquals, OrcFilters::convertEquals))\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.NOT_EQUALS, call -> convertBinary(call, OrcFilters::convertNotEquals, OrcFilters::convertNotEquals))\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.GREATER_THAN, call -> convertBinary(call, OrcFilters::convertGreaterThan, OrcFilters::convertLessThanEquals))\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, call -> convertBinary(call, OrcFilters::convertGreaterThanEquals, OrcFilters::convertLessThan))\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.LESS_THAN, call -> convertBinary(call, OrcFilters::convertLessThan, OrcFilters::convertGreaterThanEquals))\n+\t\t\t\t\t.put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, call -> convertBinary(call, OrcFilters::convertLessThanEquals, OrcFilters::convertGreaterThan))\n+\t\t\t\t\t.build();\n+\n+\tprivate static boolean isRef(Expression expression) {\n+\t\treturn expression instanceof FieldReferenceExpression;\n+\t}\n+\n+\tprivate static boolean isLit(Expression expression) {\n+\t\treturn expression instanceof ValueLiteralExpression;\n+\t}\n+\n+\tprivate static boolean isUnaryValid(CallExpression callExpression) {\n+\t\treturn callExpression.getChildren().size() == 1 && isRef(callExpression.getChildren().get(0));\n+\t}\n+\n+\tprivate static boolean isBinaryValid(CallExpression callExpression) {\n+\t\treturn callExpression.getChildren().size() == 2 && (\n+\t\t\t\tisRef(callExpression.getChildren().get(0)) && isLit(callExpression.getChildren().get(1)) ||\n+\t\t\t\t\t\tisLit(callExpression.getChildren().get(0)) && isRef(callExpression.getChildren().get(1))\n+\t\t);\n+\t}\n+\n+\tprivate static OrcSplitReader.Predicate convertIsNull(CallExpression callExp) {\n+\t\tif (!isUnaryValid(callExp)) {\n+\t\t\t// not a valid predicate\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tPredicateLeaf.Type colType = toOrcType(((FieldReferenceExpression) callExp.getChildren().get(0)).getOutputDataType());\n+\t\tif (colType == null) {\n+\t\t\t// unsupported type\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tString colName = getColumnName(callExp);\n+\n+\t\treturn new OrcSplitReader.IsNull(colName, colType);\n+\t}\n+\n+\tprivate static OrcSplitReader.Predicate convertIsNotNull(CallExpression callExp) {\n+\t\treturn new OrcSplitReader.Not(convertIsNull(callExp));\n+\t}\n+\n+\tprivate static OrcSplitReader.Predicate convertNot(CallExpression callExp) {\n+\t\tif (callExp.getChildren().size() != 1) {\n+\t\t\t// not a valid predicate\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tOrcSplitReader.Predicate c = toOrcPredicate(callExp.getChildren().get(0));\n+\t\treturn c == null ? null : new OrcSplitReader.Not(c);\n+\t}\n+\n+\tprivate static OrcSplitReader.Predicate convertOr(CallExpression callExp) {\n+\t\tif (callExp.getChildren().size() < 2) {\n+\t\t\treturn null;\n+\t\t}\n+\t\tExpression left = callExp.getChildren().get(0);\n+\t\tExpression right = callExp.getChildren().get(1);\n+\n+\t\tOrcSplitReader.Predicate c1 = toOrcPredicate(left);\n+\t\tOrcSplitReader.Predicate c2 = toOrcPredicate(right);\n+\t\tif (c1 == null || c2 == null) {\n+\t\t\treturn null;\n+\t\t} else {\n+\t\t\treturn new OrcSplitReader.Or(c1, c2);\n+\t\t}\n+\t}\n+\n+\tpublic static OrcSplitReader.Predicate convertBinary(CallExpression callExp,\n+\t\t\tTriFunction<String, PredicateLeaf.Type, Serializable, OrcSplitReader.Predicate> func,\n+\t\t\tTriFunction<String, PredicateLeaf.Type, Serializable, OrcSplitReader.Predicate> reverseFunc) {\n+\t\tif (!isBinaryValid(callExp)) {\n+\t\t\t// not a valid predicate\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tPredicateLeaf.Type litType = getLiteralType(callExp);\n+\t\tif (litType == null) {\n+\t\t\t// unsupported literal type\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tString colName = getColumnName(callExp);\n+\n+\t\t// fetch literal and ensure it is serializable\n+\t\tObject literalObj = getLiteral(callExp).get();\n+\t\tSerializable literal;\n+\t\t// validate that literal is serializable\n+\t\tif (literalObj instanceof Serializable) {\n+\t\t\tliteral = (Serializable) literalObj;\n+\t\t} else {\n+\t\t\tLOG.warn(\"Encountered a non-serializable literal of type {}. \" +\n+\t\t\t\t\t\t\t\"Cannot push predicate [{}] into OrcFileSystemFormatFactory. \" +\n+\t\t\t\t\t\t\t\"This is a bug and should be reported.\",\n+\t\t\t\t\tliteralObj.getClass().getCanonicalName(), callExp);\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\treturn literalOnRight(callExp) ? func.apply(colName, litType, literal) : reverseFunc.apply(colName, litType, literal);\n+\t}\n+\n+\tprivate static OrcSplitReader.Predicate convertEquals(String colName, PredicateLeaf.Type litType, Serializable literal) {\n+\t\treturn new OrcSplitReader.Equals(colName, litType, literal);\n+\t}\n+\n+\tprivate static OrcSplitReader.Predicate convertNotEquals(String colName, PredicateLeaf.Type litType, Serializable literal) {\n+\t\treturn new OrcSplitReader.Not(convertEquals(colName, litType, literal));\n+\t}\n+\n+\tprivate static OrcSplitReader.Predicate convertGreaterThan(String colName, PredicateLeaf.Type litType, Serializable literal) {\n+\t\treturn new OrcSplitReader.Not(\n+\t\t\t\tnew OrcSplitReader.LessThanEquals(colName, litType, literal));\n+\t}\n+\n+\tprivate static OrcSplitReader.Predicate convertGreaterThanEquals(String colName, PredicateLeaf.Type litType, Serializable literal) {\n+\t\treturn new OrcSplitReader.Not(\n+\t\t\t\tnew OrcSplitReader.LessThan(colName, litType, literal));\n+\t}\n+\n+\tprivate static OrcSplitReader.Predicate convertLessThan(String colName, PredicateLeaf.Type litType, Serializable literal) {\n+\t\treturn new OrcSplitReader.LessThan(colName, litType, literal);\n+\t}\n+\n+\tprivate static OrcSplitReader.Predicate convertLessThanEquals(String colName, PredicateLeaf.Type litType, Serializable literal) {\n+\t\treturn new OrcSplitReader.LessThanEquals(colName, litType, literal);\n+\t}\n+\n+\tpublic static OrcSplitReader.Predicate toOrcPredicate(Expression expression) {\n+\t\tif (expression instanceof CallExpression) {\n+\t\t\tCallExpression callExp = (CallExpression) expression;\n+\t\t\tif (FILTERS.get(callExp.getFunctionDefinition()) == null) {\n+\t\t\t\t// unsupported predicate\n+\t\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", expression);\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\treturn FILTERS.get(callExp.getFunctionDefinition()).apply(callExp);\n+\t\t} else {\n+\t\t\t// unsupported predicate\n+\t\t\tLOG.debug(\"Unsupported predicate [{}] cannot be pushed into OrcFileSystemFormatFactory.\", expression);\n+\t\t\treturn null;\n+\t\t}\n+\t}\n+\n+\tprivate static String getColumnName(CallExpression comp) {\n+\t\tif (literalOnRight(comp)) {\n+\t\t\treturn ((FieldReferenceExpression) comp.getChildren().get(0)).getName();\n+\t\t} else {\n+\t\t\treturn ((FieldReferenceExpression) comp.getChildren().get(1)).getName();\n+\t\t}\n+\t}\n+\n+\tprivate static boolean literalOnRight(CallExpression comp) {\n+\t\tif (comp.getChildren().size() == 1 && comp.getChildren().get(0) instanceof FieldReferenceExpression) {\n+\t\t\treturn true;\n+\t\t} else if (isLit(comp.getChildren().get(0)) && isRef(comp.getChildren().get(1))) {\n+\t\t\treturn false;\n+\t\t} else if (isRef(comp.getChildren().get(0)) && isLit(comp.getChildren().get(1))) {\n+\t\t\treturn true;\n+\t\t} else {\n+\t\t\tthrow new RuntimeException(\"Invalid binary comparison.\");\n+\t\t}\n+\t}\n+\n+\tprivate static PredicateLeaf.Type getLiteralType(CallExpression comp) {\n+\t\tif (literalOnRight(comp)) {\n+\t\t\treturn toOrcType(((ValueLiteralExpression) comp.getChildren().get(1)).getOutputDataType());\n+\t\t} else {\n+\t\t\treturn toOrcType(((ValueLiteralExpression) comp.getChildren().get(0)).getOutputDataType());\n+\t\t}\n+\t}\n+\n+\tprivate static Optional<?> getLiteral(CallExpression comp) {\n+\t\tif (literalOnRight(comp)) {\n+\t\t\tValueLiteralExpression valueLiteralExpression = (ValueLiteralExpression) comp.getChildren().get(1);\n+\t\t\treturn valueLiteralExpression.getValueAs(valueLiteralExpression.getOutputDataType().getConversionClass());\n+\t\t} else {\n+\t\t\tValueLiteralExpression valueLiteralExpression = (ValueLiteralExpression) comp.getChildren().get(0);\n+\t\t\treturn valueLiteralExpression.getValueAs(valueLiteralExpression.getOutputDataType().getConversionClass());\n+\t\t}\n+\t}\n+\n+\tprivate static PredicateLeaf.Type toOrcType(DataType type) {\n+\t\tLogicalTypeRoot ltype = type.getLogicalType().getTypeRoot();\n+\t\tswitch (ltype) {\n+\t\t\tcase TINYINT:\n+\t\t\tcase SMALLINT:\n+\t\t\tcase INTEGER:\n+\t\t\tcase BIGINT:\n+\t\t\t\treturn PredicateLeaf.Type.LONG;\n+\t\t\tcase FLOAT:\n+\t\t\tcase DOUBLE:\n+\t\t\t\treturn PredicateLeaf.Type.FLOAT;\n+\t\t\tcase BOOLEAN:\n+\t\t\t\treturn PredicateLeaf.Type.BOOLEAN;\n+\t\t\tcase CHAR:\n+\t\t\tcase VARCHAR:\n+\t\t\t\treturn PredicateLeaf.Type.STRING;\n+\t\t\tcase TIMESTAMP_WITHOUT_TIME_ZONE:\n+\t\t\tcase TIMESTAMP_WITH_LOCAL_TIME_ZONE:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "174d9d69aa825ce53661c38b2bf9c7e71440c687"}, "originalPosition": 263}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDYxNjE1OQ==", "bodyText": "It is better to add timestamp, date, decimal too.", "url": "https://github.com/apache/flink/pull/13306#discussion_r484616159", "createdAt": "2020-09-08T02:25:48Z", "author": {"login": "JingsongLi"}, "path": "flink-formats/flink-orc/src/test/java/org/apache/flink/orc/OrcFileSystemITCase.java", "diffHunk": "@@ -85,4 +88,59 @@ public void testNonPartition() {\n \t\t\tthrow new RuntimeException(e);\n \t\t}\n \t}\n+\n+\t@Override\n+\tpublic void before() {\n+\t\tsuper.before();\n+\t\tsuper.tableEnv().executeSql(String.format(\n+\t\t\t\t\"create table orcFilterTable (\" +\n+\t\t\t\t\t\t\"x string,\" +\n+\t\t\t\t\t\t\"y int,\" +\n+\t\t\t\t\t\t\"a int,\" +\n+\t\t\t\t\t\t\"b bigint,\" +\n+\t\t\t\t\t\t\"c boolean,\" +\n+\t\t\t\t\t\t\"d string\" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "174d9d69aa825ce53661c38b2bf9c7e71440c687"}, "originalPosition": 38}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f0fc75a3e8c45cb9ada6571c56b978af7ed99b6b", "author": {"user": null}, "url": "https://github.com/apache/flink/commit/f0fc75a3e8c45cb9ada6571c56b978af7ed99b6b", "committedDate": "2020-09-08T10:17:22Z", "message": "[FLINK-17779][Connectors/ORC]Orc file format support filter push down"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ea9e1f404d62be4926a29ac9c64b72a388db4a4a", "author": {"user": null}, "url": "https://github.com/apache/flink/commit/ea9e1f404d62be4926a29ac9c64b72a388db4a4a", "committedDate": "2020-09-08T10:17:22Z", "message": "[FLINK-17779][Connectors/ORC] Add test cases for OrcFileSystemFormatFactory"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d48cfb01b6cbb5a170e82f4caf58dbe529c6258e", "author": {"user": null}, "url": "https://github.com/apache/flink/commit/d48cfb01b6cbb5a170e82f4caf58dbe529c6258e", "committedDate": "2020-09-08T10:17:22Z", "message": "[FLINK-17779][Connectors/ORC] normalize description of class"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cdaf01cb0072f6afa6176915f67a2cddd9780c0a", "author": {"user": null}, "url": "https://github.com/apache/flink/commit/cdaf01cb0072f6afa6176915f67a2cddd9780c0a", "committedDate": "2020-09-08T10:17:22Z", "message": "[FLINK-17779][Connectors/ORC]Orc file format support filter push down"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "13eff0ef80c62deb18948ffe965efe8c55e350d0", "author": {"user": null}, "url": "https://github.com/apache/flink/commit/13eff0ef80c62deb18948ffe965efe8c55e350d0", "committedDate": "2020-09-08T10:17:22Z", "message": "[hotfix][Connectors/ORC] refactor code to function style"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cb433f17845f7dd326c21bd10072ce3971100145", "author": {"user": null}, "url": "https://github.com/apache/flink/commit/cb433f17845f7dd326c21bd10072ce3971100145", "committedDate": "2020-09-08T10:17:22Z", "message": "[hotfix][Connectors/ORC] Adapt date and timestamp data types between Flink and Orc"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "507fa0a64dc561fca0e16161d4a325d97785fe2b", "author": {"user": null}, "url": "https://github.com/apache/flink/commit/507fa0a64dc561fca0e16161d4a325d97785fe2b", "committedDate": "2020-09-08T10:24:40Z", "message": "[hotfix][Connectors/ORC] Adapt date and timestamp data types between Flink and Orc"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg1NTUwOTMy", "url": "https://github.com/apache/flink/pull/13306#pullrequestreview-485550932", "createdAt": "2020-09-10T04:08:21Z", "commit": {"oid": "507fa0a64dc561fca0e16161d4a325d97785fe2b"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4369, "cost": 1, "resetAt": "2021-10-28T16:48:13Z"}}}