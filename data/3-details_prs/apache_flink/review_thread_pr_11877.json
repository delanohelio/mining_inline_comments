{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDA3NzY2MTA0", "number": 11877, "reviewThreads": {"totalCount": 58, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wOVQwNzo1NDoyN1rOD614JQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0xMlQxMDowNTo1NFrOGUwxyA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYzMDI2NzI1OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wOVQwNzo1NDoyN1rOGS5SjA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMVQxMToyNzoxMVrOGTYMzA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjQ2NjE4OA==", "bodyText": "Make the following condition out of synchronized part, then we do not need to touch the lock for most of the cases.\nCheckpointOptions options = barrier.getCheckpointOptions();\nif (!(initialCredit == 0 && options.isExactlyOnceMode() && !options.isUnalignedCheckpoint()))  {\n     return;\n}", "url": "https://github.com/apache/flink/pull/11877#discussion_r422466188", "createdAt": "2020-05-09T07:54:27Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "diffHunk": "@@ -428,6 +423,23 @@ public void notifyBufferDestroyed() {\n \t\t// Nothing to do actually.\n \t}\n \n+\t@Override\n+\tpublic void onCheckpointBarrier(CheckpointBarrier barrier) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca6f75c37da358874cc38d7998bce5c4445feff5"}, "originalPosition": 100}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjk3MDcyOQ==", "bodyText": "It might be better to trigger this action by netty thread when received this barrier immediately. Otherwise the task processing might delay much time to better reuse the floating buffers for other channels.", "url": "https://github.com/apache/flink/pull/11877#discussion_r422970729", "createdAt": "2020-05-11T11:23:23Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "diffHunk": "@@ -428,6 +423,23 @@ public void notifyBufferDestroyed() {\n \t\t// Nothing to do actually.\n \t}\n \n+\t@Override\n+\tpublic void onCheckpointBarrier(CheckpointBarrier barrier) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjQ2NjE4OA=="}, "originalCommit": {"oid": "ca6f75c37da358874cc38d7998bce5c4445feff5"}, "originalPosition": 100}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjk3MjYyMA==", "bodyText": "Considering the race condition between this operation and canceler task, it might involve in potential conflicts and deadlock case if removeBufferListener and adjust isWaitingForFloatingBuffers here. Let me think whether we can lazy remove the listener and adjust isWaitingForFloatingBuffers by reusing the existing process RemoteInputChannel#notifyBufferAvailable.", "url": "https://github.com/apache/flink/pull/11877#discussion_r422972620", "createdAt": "2020-05-11T11:27:11Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "diffHunk": "@@ -428,6 +423,23 @@ public void notifyBufferDestroyed() {\n \t\t// Nothing to do actually.\n \t}\n \n+\t@Override\n+\tpublic void onCheckpointBarrier(CheckpointBarrier barrier) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjQ2NjE4OA=="}, "originalCommit": {"oid": "ca6f75c37da358874cc38d7998bce5c4445feff5"}, "originalPosition": 100}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYzMzIxNTY0OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/PartitionRequestQueue.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMVQwNzo0Nzo0NVrOGTQjvw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMVQwNzo0Nzo0NVrOGTQjvw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjg0NzQyMw==", "bodyText": "The different message path is distinguished in both PartitionRequestQueue and CreditBasedSequenceNumberingViewReader now. We can improve it to judge only in one place instead.\n\nIntroduce ServerOutboundMessage class to extend NettyMessage and make AddBacklog and BufferResponse both extend ServerOutboundMessage.\nIntroduce NetworkSequenceViewReader#getNextMessage instead of existing NetworkSequenceViewReader#getNextBuffer. And inside CreditBasedSequenceNumberingViewReader implementation, we can judge the condition for distinguish.\n\npublic NettyMessage.ServerOutboundMessage getNextMessage() throws IOException {\n\t\tif (numCreditsAvailable == 0 && initialCredit == 0 && !subpartitionView.isAvailable(numCreditsAvailable)) {\n\t\t\treturn getBacklogMessage();\n\t\t} else {\n\t\t\treturn getNextBufferResponse();\n\t\t}\n\t}\n\nTo do so we can also reduce the necessary transformation between BufferAndAvailability and BufferResponse.", "url": "https://github.com/apache/flink/pull/11877#discussion_r422847423", "createdAt": "2020-05-11T07:47:45Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/PartitionRequestQueue.java", "diffHunk": "@@ -234,11 +236,16 @@ private void writeAndFlushNextMessageIfPossible(final Channel channel) throws IO\n \t\t\t\t\t\tregisterAvailableReader(reader);\n \t\t\t\t\t}\n \n-\t\t\t\t\tBufferResponse msg = new BufferResponse(\n-\t\t\t\t\t\tnext.buffer(),\n-\t\t\t\t\t\treader.getSequenceNumber(),\n-\t\t\t\t\t\treader.getReceiverId(),\n-\t\t\t\t\t\tnext.buffersInBacklog());\n+\t\t\t\t\tObject msg;\n+\t\t\t\t\tif (next.buffer() != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca6f75c37da358874cc38d7998bce5c4445feff5"}, "originalPosition": 86}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYzMzMyMTU5OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMVQwODoxNjozMlrOGTRjTw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMVQwODoxNjozMlrOGTRjTw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjg2MzY5NQ==", "bodyText": "The previous buffersInBacklog variable should be replaced by this new variable, to avoid maintaining two variables.", "url": "https://github.com/apache/flink/pull/11877#discussion_r422863695", "createdAt": "2020-05-11T08:16:32Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java", "diffHunk": "@@ -70,6 +70,10 @@\n \t@GuardedBy(\"buffers\")\n \tprivate int buffersInBacklog;\n \n+\t/** The number of non-event buffers to be announced to the downstream. */\n+\t@GuardedBy(\"buffers\")\n+\tprivate int unannouncedBacklog;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca6f75c37da358874cc38d7998bce5c4445feff5"}, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYzMzMzMDEwOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/ResultSubpartition.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMVQwODoxODo0NFrOGTRoVA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMVQwODoxODo0NFrOGTRoVA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjg2NDk4MA==", "bodyText": "buffersInBacklog and unannouncedBacklog should be retained only one finally.", "url": "https://github.com/apache/flink/pull/11877#discussion_r422864980", "createdAt": "2020-05-11T08:18:44Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/ResultSubpartition.java", "diffHunk": "@@ -158,11 +158,18 @@ public boolean add(BufferConsumer bufferConsumer) throws IOException {\n \t\tprivate final Buffer buffer;\n \t\tprivate final boolean isDataAvailable;\n \t\tprivate final int buffersInBacklog;\n+\t\tprivate final int unannouncedBacklog;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca6f75c37da358874cc38d7998bce5c4445feff5"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYzMzM1NTQ3OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/CreditBasedSequenceNumberingViewReader.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMVQwODoyNToyM1rOGTR39w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQwNjo1MTo0MVrOGT4aiw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjg2ODk4Mw==", "bodyText": "why we need to trigger announce backlog while adding credit?\nI assume since the added creditDeltas is always more than zero, then we have the chance to announce the backlog later via sending BufferResponse.", "url": "https://github.com/apache/flink/pull/11877#discussion_r422868983", "createdAt": "2020-05-11T08:25:23Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/CreditBasedSequenceNumberingViewReader.java", "diffHunk": "@@ -94,13 +99,27 @@ public void requestSubpartitionView(\n \t}\n \n \t@Override\n-\tpublic void addCredit(int creditDeltas) {\n+\tpublic boolean addCredit(int creditDeltas) {\n \t\tnumCreditsAvailable += creditDeltas;\n+\t\treturn shouldAnnounceBacklog();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca6f75c37da358874cc38d7998bce5c4445feff5"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzUwMDQyNw==", "bodyText": "You are right shouldAnnounceBacklog always return false, I will replace the function call with return false. The reason why we need to change return type of addCredit is that we can't identify whether we are calling addCredit or resumeConsumption in PartitionRequestQueue.", "url": "https://github.com/apache/flink/pull/11877#discussion_r423500427", "createdAt": "2020-05-12T06:51:41Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/CreditBasedSequenceNumberingViewReader.java", "diffHunk": "@@ -94,13 +99,27 @@ public void requestSubpartitionView(\n \t}\n \n \t@Override\n-\tpublic void addCredit(int creditDeltas) {\n+\tpublic boolean addCredit(int creditDeltas) {\n \t\tnumCreditsAvailable += creditDeltas;\n+\t\treturn shouldAnnounceBacklog();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjg2ODk4Mw=="}, "originalCommit": {"oid": "ca6f75c37da358874cc38d7998bce5c4445feff5"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYzMzQ1NzIwOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/InputChannel.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMVQwODo1MTowMVrOGTS0xg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMVQwODo1MTowMVrOGTS0xg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjg4NDU1MA==", "bodyText": "We can also avoid introducing nullable buffer by this comment https://github.com/apache/flink/pull/11877/files#r422847423", "url": "https://github.com/apache/flink/pull/11877#discussion_r422884550", "createdAt": "2020-05-11T08:51:01Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/InputChannel.java", "diffHunk": "@@ -305,19 +311,18 @@ protected CheckpointBarrier parseCheckpointBarrierOrNull(Buffer buffer) throws I\n \n \t/**\n \t * A combination of a {@link Buffer} and a flag indicating availability of further buffers,\n-\t * and the backlog length indicating how many non-event buffers are available in the\n-\t * subpartition.\n+\t * and the backlog length indicating how many credits the subpartition.\n \t */\n \tpublic static final class BufferAndAvailability {\n \n \t\tprivate final Buffer buffer;\n \t\tprivate final boolean moreAvailable;\n-\t\tprivate final int buffersInBacklog;\n+\t\tprivate final int backlog;\n \n-\t\tpublic BufferAndAvailability(Buffer buffer, boolean moreAvailable, int buffersInBacklog) {\n-\t\t\tthis.buffer = checkNotNull(buffer);\n+\t\tpublic BufferAndAvailability(@Nullable Buffer buffer, boolean moreAvailable, int backlog) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca6f75c37da358874cc38d7998bce5c4445feff5"}, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYzMzQ4NjE1OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/CreditBasedSequenceNumberingViewReader.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMVQwODo1Nzo1NlrOGTTGPg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMVQwODo1Nzo1NlrOGTTGPg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjg4OTAyMg==", "bodyText": "I guess this check is not necessary or invalid.", "url": "https://github.com/apache/flink/pull/11877#discussion_r422889022", "createdAt": "2020-05-11T08:57:56Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/CreditBasedSequenceNumberingViewReader.java", "diffHunk": "@@ -94,13 +99,27 @@ public void requestSubpartitionView(\n \t}\n \n \t@Override\n-\tpublic void addCredit(int creditDeltas) {\n+\tpublic boolean addCredit(int creditDeltas) {\n \t\tnumCreditsAvailable += creditDeltas;\n+\t\treturn shouldAnnounceBacklog();\n+\t}\n+\n+\t@Override\n+\tpublic boolean shouldAnnounceBacklog() {\n+\t\treturn initialCredit == 0 && numCreditsAvailable == 0 && subpartitionView.isAvailable(Integer.MAX_VALUE);\n \t}\n \n \t@Override\n-\tpublic void resumeConsumption() {\n+\tpublic boolean resumeConsumption(int availableCredit, int unfulfilledBacklog) {\n+\t\tif (initialCredit > 0) {\n+\t\t\tcheckState(numCreditsAvailable == availableCredit, \"Illegal number of available credit.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca6f75c37da358874cc38d7998bce5c4445feff5"}, "originalPosition": 45}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYzMzg3NzU3OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMVQxMDo0NDozNVrOGTW3Ng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMVQxMDo0NDozNVrOGTW3Ng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjk1MDcxMA==", "bodyText": "nit: might rename to numRequiredFloatingBuffers for better reflecting the current semantic.", "url": "https://github.com/apache/flink/pull/11877#discussion_r422950710", "createdAt": "2020-05-11T10:44:35Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "diffHunk": "@@ -99,7 +100,7 @@\n \t/** The number of available buffers that have not been announced to the producer yet. */\n \tprivate final AtomicInteger unannouncedCredit = new AtomicInteger(0);\n \n-\t/** The number of required buffers that equals to sender's backlog plus initial credit. */\n+\t/** The number of buffers to requested that equals to unfulfilled sender's backlog. */\n \t@GuardedBy(\"bufferQueue\")\n \tprivate int numRequiredBuffers;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca6f75c37da358874cc38d7998bce5c4445feff5"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0MTM1MzI0OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QwMzo0NjoyM1rOGUgdDQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QwMzo0NjoyM1rOGUgdDQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDE1NjQyOQ==", "bodyText": "fix the javadoc accordingly.", "url": "https://github.com/apache/flink/pull/11877#discussion_r424156429", "createdAt": "2020-05-13T03:46:23Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "diffHunk": "@@ -127,7 +127,7 @@ private boolean shouldContinueRequest(BufferPool bufferPool) {\n \t/**\n \t * Requests exclusive buffers from the provider and returns the number of requested amount.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a9dba521dd41e70cb5c4be10669372b1c674d22"}, "originalPosition": 2}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0MTM1Nzk2OnYy", "diffSide": "LEFT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QwMzo0OTozNlrOGUgf4Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QwMzo0OTozNlrOGUgf4Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDE1NzE1Mw==", "bodyText": "It is better to supplement the similar check to avoid this action is called multiple times in practice.\nMaybe we can check the available exclusive buffers should be 0 in BufferManager instead?", "url": "https://github.com/apache/flink/pull/11877#discussion_r424157153", "createdAt": "2020-05-13T03:49:36Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "diffHunk": "@@ -122,10 +124,7 @@ public RemoteInputChannel(\n \t * after this input channel is created.\n \t */\n \tvoid assignExclusiveSegments() throws IOException {\n-\t\tcheckState(initialCredit == 0, \"Bug in input channel setup logic: exclusive buffers have \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a9dba521dd41e70cb5c4be10669372b1c674d22"}, "originalPosition": 27}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0MTM5NjY0OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/buffer/NetworkBufferPool.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QwNDoxNjoyOFrOGUg3OQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QwNDoxNjoyOFrOGUg3OQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDE2MzEyOQ==", "bodyText": "numberOfSegmentsToRequest  should never be negative because we already check this argument in constructor.\nif (numberOfSegmentsToRequest == 0) instead?", "url": "https://github.com/apache/flink/pull/11877#discussion_r424163129", "createdAt": "2020-05-13T04:16:28Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/buffer/NetworkBufferPool.java", "diffHunk": "@@ -162,6 +162,10 @@ public void recycle(MemorySegment segment) {\n \n \t@Override\n \tpublic List<MemorySegment> requestMemorySegments() throws IOException {\n+\t\tif (numberOfSegmentsToRequest <= 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "708b2ceb97564084900c555d6f38e6ba1174d735"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0MTM5ODU1OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/CreditBasedPartitionRequestClientHandler.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QwNDoxNzo0OFrOGUg4ZQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QwNDoxNzo0OFrOGUg4ZQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDE2MzQyOQ==", "bodyText": "nit: import NettyMessage.AddBacklog because it occurs many times in this part.", "url": "https://github.com/apache/flink/pull/11877#discussion_r424163429", "createdAt": "2020-05-13T04:17:48Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/CreditBasedPartitionRequestClientHandler.java", "diffHunk": "@@ -291,6 +290,11 @@ private void decodeMsg(Object msg) throws Throwable {\n \t\t\t\t\t}\n \t\t\t\t}\n \t\t\t}\n+\t\t} else if (msgClazz == NettyMessage.AddBacklog.class) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "708b2ceb97564084900c555d6f38e6ba1174d735"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0MTQwNTAwOnYy", "diffSide": "LEFT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QwNDoyMjowN1rOGUg8Kw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNFQwNzowMDoyN1rOGVOkHQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDE2NDM5NQ==", "bodyText": "this change should be together with the previous hotfix commit \" making initialCredit as final\"", "url": "https://github.com/apache/flink/pull/11877#discussion_r424164395", "createdAt": "2020-05-13T04:22:07Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "diffHunk": "@@ -129,7 +132,6 @@ private boolean shouldContinueRequest(BufferPool bufferPool) {\n \t */\n \tvoid requestExclusiveBuffers() throws IOException {\n \t\tCollection<MemorySegment> segments = globalPool.requestMemorySegments();\n-\t\tcheckArgument(!segments.isEmpty(), \"The number of exclusive buffers per channel should be larger than 0.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "708b2ceb97564084900c555d6f38e6ba1174d735"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDI4NDM4Nw==", "bodyText": "Before the last commit, we can't set numExclusive buffers to 0, so the check should be reserved before the last commit.", "url": "https://github.com/apache/flink/pull/11877#discussion_r424284387", "createdAt": "2020-05-13T09:02:11Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "diffHunk": "@@ -129,7 +132,6 @@ private boolean shouldContinueRequest(BufferPool bufferPool) {\n \t */\n \tvoid requestExclusiveBuffers() throws IOException {\n \t\tCollection<MemorySegment> segments = globalPool.requestMemorySegments();\n-\t\tcheckArgument(!segments.isEmpty(), \"The number of exclusive buffers per channel should be larger than 0.\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDE2NDM5NQ=="}, "originalCommit": {"oid": "708b2ceb97564084900c555d6f38e6ba1174d735"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDkxMTkwMQ==", "bodyText": "Got it. So do you think we add the if (initialCredit > 0) before calling this method inside RemoteInputChannel#assignExclusiveSegments?  Just for not necessary to synchronized below for empty segments.", "url": "https://github.com/apache/flink/pull/11877#discussion_r424911901", "createdAt": "2020-05-14T07:00:27Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "diffHunk": "@@ -129,7 +132,6 @@ private boolean shouldContinueRequest(BufferPool bufferPool) {\n \t */\n \tvoid requestExclusiveBuffers() throws IOException {\n \t\tCollection<MemorySegment> segments = globalPool.requestMemorySegments();\n-\t\tcheckArgument(!segments.isEmpty(), \"The number of exclusive buffers per channel should be larger than 0.\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDE2NDM5NQ=="}, "originalCommit": {"oid": "708b2ceb97564084900c555d6f38e6ba1174d735"}, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0MTQwOTUwOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QwNDoyNToxMlrOGUg-7g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QwNDoyNToxMlrOGUg-7g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDE2NTEwMg==", "bodyText": "This renaming is not necessary.\nBufferManager is abstracted as a general purpose, not coupled with credit-based process, so it is better to not define a argument strongly related to credit-based purpose. numRequired seems more general to describe the semantic.", "url": "https://github.com/apache/flink/pull/11877#discussion_r424165102", "createdAt": "2020-05-13T04:25:12Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "diffHunk": "@@ -139,10 +141,10 @@ void requestExclusiveBuffers() throws IOException {\n \t}\n \n \t/**\n-\t * Requests floating buffers from the buffer pool based on the given required amount, and returns the actual\n+\t * Requests floating buffers from the buffer pool based on the given backlog, and returns the actual\n \t * requested amount. If the required amount is not fully satisfied, it will register as a listener.\n \t */\n-\tint requestFloatingBuffers(int numRequired) throws IOException {\n+\tint requestFloatingBuffers(int backlog) throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "708b2ceb97564084900c555d6f38e6ba1174d735"}, "originalPosition": 51}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0MTQyNTU1OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QwNDozNzowN1rOGUhJEg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QwNDozNzowN1rOGUhJEg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDE2NzY5OA==", "bodyText": "Keep in mind that BufferManager is only for buffer request/release related operations, so it should not understand the other specific logics which should be done inside the respective InputChannel. Otherwise we would dirty this component and have ambiguous definition what is the role of this component.\nIn detail, the following should be done inside RemoteInputChannel\nCheckpointOptions options = barrier.getCheckpointOptions();\nif (initialCredit == 0 && options.isExactlyOnceMode() && !options.isUnalignedCheckpoint()) \n\nAnd rename  the method onCheckpointBarrier to distinguish with existing releaseFloatingBuffers(). From the perspective of outside caller, we should give a clear semantic method naming in order to be reused future.", "url": "https://github.com/apache/flink/pull/11877#discussion_r424167698", "createdAt": "2020-05-13T04:37:07Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "diffHunk": "@@ -151,23 +153,63 @@ int requestFloatingBuffers(int numRequired) throws IOException {\n \t\t\t\treturn numRequestedBuffers;\n \t\t\t}\n \n-\t\t\tnumRequiredBuffers = numRequired;\n+\t\t\tnumRequiredBuffers += backlog;\n+\t\t\tnumRequestedBuffers = internalRequestFloatingBuffers(numRequiredBuffers);\n+\t\t\tnumRequiredBuffers -= numRequestedBuffers;\n+\t\t}\n+\t\treturn numRequestedBuffers;\n+\t}\n \n-\t\t\twhile (bufferQueue.getAvailableBufferSize() < numRequiredBuffers && !isWaitingForFloatingBuffers) {\n-\t\t\t\tBufferPool bufferPool = inputChannel.inputGate.getBufferPool();\n-\t\t\t\tBuffer buffer = bufferPool.requestBuffer();\n-\t\t\t\tif (buffer != null) {\n-\t\t\t\t\tbufferQueue.addFloatingBuffer(buffer);\n-\t\t\t\t\tnumRequestedBuffers++;\n-\t\t\t\t} else if (bufferPool.addBufferListener(this)) {\n-\t\t\t\t\tisWaitingForFloatingBuffers = true;\n-\t\t\t\t\tbreak;\n-\t\t\t\t}\n+\tprivate int internalRequestFloatingBuffers(int numBuffersToRequest) throws IOException {\n+\t\tassert Thread.holdsLock(bufferQueue);\n+\n+\t\tint numRequestedBuffers = 0;\n+\t\twhile (numRequestedBuffers < numBuffersToRequest && !isWaitingForFloatingBuffers) {\n+\t\t\tBufferPool bufferPool = inputChannel.inputGate.getBufferPool();\n+\t\t\tBuffer buffer = bufferPool.requestBuffer();\n+\t\t\tif (buffer != null) {\n+\t\t\t\tbufferQueue.addFloatingBuffer(buffer);\n+\t\t\t\tnumRequestedBuffers++;\n+\t\t\t} else if (bufferPool.addBufferListener(this)) {\n+\t\t\t\tisWaitingForFloatingBuffers = true;\n+\t\t\t\tbreak;\n \t\t\t}\n \t\t}\n \t\treturn numRequestedBuffers;\n \t}\n \n+\tpublic NettyMessage.ResumeConsumption resumeAndGetResumptionMessage(\n+\t\t\tInputChannelID channelID,\n+\t\t\tint initialCredit) throws IOException {\n+\t\tsynchronized (bufferQueue) {\n+\t\t\tcheckState(numRequiredBuffers >= 0, \"Number of required buffers should be non-negative.\");\n+\t\t\tcheckState(bufferQueue.getAvailableBufferSize() == initialCredit, \"Illegal number of available buffers.\");\n+\n+\t\t\tif (initialCredit > 0) {\n+\t\t\t\treturn new NettyMessage.ResumeConsumption(channelID, initialCredit, numRequiredBuffers);\n+\t\t\t}\n+\n+\t\t\tint numCredit = internalRequestFloatingBuffers(numRequiredBuffers);\n+\t\t\tnumRequiredBuffers -= numCredit;\n+\t\t\treturn new NettyMessage.ResumeConsumption(channelID, numCredit, numRequiredBuffers);\n+\t\t}\n+\t}\n+\n+\tpublic void onCheckpointBarrier(CheckpointBarrier barrier, int initialCredit) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "708b2ceb97564084900c555d6f38e6ba1174d735"}, "originalPosition": 112}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0MTQyOTA2OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QwNDozOTo0NlrOGUhLSA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QwNDozOTo0NlrOGUhLSA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDE2ODI2NA==", "bodyText": "As mentioned in 708b2ce#r424167698, this logic should be done inside RemoteInputChannel, because the BufferManager should not understand the specific logics unless buffer request/release.", "url": "https://github.com/apache/flink/pull/11877#discussion_r424168264", "createdAt": "2020-05-13T04:39:46Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "diffHunk": "@@ -151,23 +153,63 @@ int requestFloatingBuffers(int numRequired) throws IOException {\n \t\t\t\treturn numRequestedBuffers;\n \t\t\t}\n \n-\t\t\tnumRequiredBuffers = numRequired;\n+\t\t\tnumRequiredBuffers += backlog;\n+\t\t\tnumRequestedBuffers = internalRequestFloatingBuffers(numRequiredBuffers);\n+\t\t\tnumRequiredBuffers -= numRequestedBuffers;\n+\t\t}\n+\t\treturn numRequestedBuffers;\n+\t}\n \n-\t\t\twhile (bufferQueue.getAvailableBufferSize() < numRequiredBuffers && !isWaitingForFloatingBuffers) {\n-\t\t\t\tBufferPool bufferPool = inputChannel.inputGate.getBufferPool();\n-\t\t\t\tBuffer buffer = bufferPool.requestBuffer();\n-\t\t\t\tif (buffer != null) {\n-\t\t\t\t\tbufferQueue.addFloatingBuffer(buffer);\n-\t\t\t\t\tnumRequestedBuffers++;\n-\t\t\t\t} else if (bufferPool.addBufferListener(this)) {\n-\t\t\t\t\tisWaitingForFloatingBuffers = true;\n-\t\t\t\t\tbreak;\n-\t\t\t\t}\n+\tprivate int internalRequestFloatingBuffers(int numBuffersToRequest) throws IOException {\n+\t\tassert Thread.holdsLock(bufferQueue);\n+\n+\t\tint numRequestedBuffers = 0;\n+\t\twhile (numRequestedBuffers < numBuffersToRequest && !isWaitingForFloatingBuffers) {\n+\t\t\tBufferPool bufferPool = inputChannel.inputGate.getBufferPool();\n+\t\t\tBuffer buffer = bufferPool.requestBuffer();\n+\t\t\tif (buffer != null) {\n+\t\t\t\tbufferQueue.addFloatingBuffer(buffer);\n+\t\t\t\tnumRequestedBuffers++;\n+\t\t\t} else if (bufferPool.addBufferListener(this)) {\n+\t\t\t\tisWaitingForFloatingBuffers = true;\n+\t\t\t\tbreak;\n \t\t\t}\n \t\t}\n \t\treturn numRequestedBuffers;\n \t}\n \n+\tpublic NettyMessage.ResumeConsumption resumeAndGetResumptionMessage(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "708b2ceb97564084900c555d6f38e6ba1174d735"}, "originalPosition": 95}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0MTUyNDc4OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QwNTozNjoxN1rOGUiEdg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QwNTozNjoxN1rOGUiEdg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDE4MjkwMg==", "bodyText": "resumeAndGetResumptionMessage() -> getResumeConsumptionMessage()", "url": "https://github.com/apache/flink/pull/11877#discussion_r424182902", "createdAt": "2020-05-13T05:36:17Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "diffHunk": "@@ -334,6 +335,15 @@ public void resumeConsumption() {\n \t\tpartitionRequestClient.resumeConsumption(this);\n \t}\n \n+\t/**\n+\t * Called by netty thread to request buffers and generate {@link NettyMessage.ResumeConsumption} message.\n+\t */\n+\tpublic NettyMessage.ResumeConsumption resumeAndGetResumptionMessage() throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "708b2ceb97564084900c555d6f38e6ba1174d735"}, "originalPosition": 48}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0MTU0NzEyOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QwNTo0ODoxNFrOGUiRxA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QwNTo0ODoxNFrOGUiRxA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDE4NjMwOA==", "bodyText": "Make this change a separate hotfix?", "url": "https://github.com/apache/flink/pull/11877#discussion_r424186308", "createdAt": "2020-05-13T05:48:14Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "diffHunk": "@@ -415,11 +425,8 @@ public Buffer requestBuffer() {\n \t *\n \t * @param backlog The number of unsent buffers in the producer's sub partition.\n \t */\n-\tvoid onSenderBacklog(int backlog) throws IOException {\n-\t\tint numRequestedBuffers = bufferManager.requestFloatingBuffers(backlog + initialCredit);\n-\t\tif (numRequestedBuffers > 0 && unannouncedCredit.getAndAdd(numRequestedBuffers) == 0) {\n-\t\t\tnotifyCreditAvailable();\n-\t\t}\n+\tpublic void onSenderBacklog(int backlog) throws IOException {\n+\t\tnotifyBufferAvailable(bufferManager.requestFloatingBuffers(backlog));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "708b2ceb97564084900c555d6f38e6ba1174d735"}, "originalPosition": 67}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0MjU3NzY1OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/PartitionRequestQueue.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QxMTowNDo0NVrOGUsenw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QxMTowNTo1NFrOGUsgmg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDM1MzQzOQ==", "bodyText": "Actually the logic for adding credit does not need needAnnounceBacklog, so it might bring trouble to understand the logic of addCredit by reusing the common codes here.\nOne possible solution is to call enqueueAvailableReader in reader stack while applying the function, then the NetworkSequenceViewReader#addCredit and NetworkSequenceViewReader#resumeConsumption can judge the separate conditions before calling enqueueAvailableReader.", "url": "https://github.com/apache/flink/pull/11877#discussion_r424353439", "createdAt": "2020-05-13T11:04:45Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/PartitionRequestQueue.java", "diffHunk": "@@ -145,20 +148,20 @@ public void close() throws IOException {\n \t * checkpoint and enqueues the corresponding reader for this consumer (if not enqueued yet).\n \t *\n \t * @param receiverId The input channel id to identify the consumer.\n-\t * @param operation The operation to be performed (add credit or resume data consumption).\n+\t * @param function The operation to be performed (add credit or resume data consumption).\n \t */\n \tvoid addCreditOrResumeConsumption(\n \t\t\tInputChannelID receiverId,\n-\t\t\tConsumer<NetworkSequenceViewReader> operation) throws Exception {\n+\t\t\tFunction<NetworkSequenceViewReader, Boolean> function) throws Exception {\n \t\tif (fatalError) {\n \t\t\treturn;\n \t\t}\n \n \t\tNetworkSequenceViewReader reader = allReaders.get(receiverId);\n \t\tif (reader != null) {\n-\t\t\toperation.accept(reader);\n+\t\t\tboolean needAnnounceBacklog = function.apply(reader);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "59b651c070adcca2b7e4e4a78e6b10411429c589"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDM1Mzk0Ng==", "bodyText": "To do so we can also avoid adjusting to return unnecessary boolean value for NetworkSequenceViewReader#addCredit", "url": "https://github.com/apache/flink/pull/11877#discussion_r424353946", "createdAt": "2020-05-13T11:05:54Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/PartitionRequestQueue.java", "diffHunk": "@@ -145,20 +148,20 @@ public void close() throws IOException {\n \t * checkpoint and enqueues the corresponding reader for this consumer (if not enqueued yet).\n \t *\n \t * @param receiverId The input channel id to identify the consumer.\n-\t * @param operation The operation to be performed (add credit or resume data consumption).\n+\t * @param function The operation to be performed (add credit or resume data consumption).\n \t */\n \tvoid addCreditOrResumeConsumption(\n \t\t\tInputChannelID receiverId,\n-\t\t\tConsumer<NetworkSequenceViewReader> operation) throws Exception {\n+\t\t\tFunction<NetworkSequenceViewReader, Boolean> function) throws Exception {\n \t\tif (fatalError) {\n \t\t\treturn;\n \t\t}\n \n \t\tNetworkSequenceViewReader reader = allReaders.get(receiverId);\n \t\tif (reader != null) {\n-\t\t\toperation.accept(reader);\n+\t\t\tboolean needAnnounceBacklog = function.apply(reader);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDM1MzQzOQ=="}, "originalCommit": {"oid": "59b651c070adcca2b7e4e4a78e6b10411429c589"}, "originalPosition": 79}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0MjU4NTM1OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/PartitionRequestQueue.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QxMTowNzoyN1rOGUsjew==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QxMTowNzoyN1rOGUsjew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDM1NDY4Mw==", "bodyText": "Based on this comment, we might not need to bring announceBacklog argument in this method, to understand all the related processes together.", "url": "https://github.com/apache/flink/pull/11877#discussion_r424354683", "createdAt": "2020-05-13T11:07:27Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/PartitionRequestQueue.java", "diffHunk": "@@ -94,10 +96,11 @@ void notifyReaderNonEmpty(final NetworkSequenceViewReader reader) {\n \t * <p>NOTE: Only one thread would trigger the actual enqueue after checking the reader's\n \t * availability, so there is no race condition here.\n \t */\n-\tprivate void enqueueAvailableReader(final NetworkSequenceViewReader reader) throws Exception {\n-\t\tif (reader.isRegisteredAsAvailable() || !reader.isAvailable()) {\n+\tprivate void enqueueAvailableReader(final NetworkSequenceViewReader reader, boolean announceBacklog) throws Exception {\n+\t\tif (reader.isRegisteredAsAvailable() || (!reader.isAvailable() && !announceBacklog)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "59b651c070adcca2b7e4e4a78e6b10411429c589"}, "originalPosition": 45}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0MjcxMjQ3OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/CreditBasedSequenceNumberingViewReader.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QxMTo0ODozNFrOGUtyvw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QxMTo0ODozNFrOGUtyvw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDM3NDk3NQ==", "bodyText": "Renaming it to a boolean type withoutExclusiveCredits seems more direct to understand", "url": "https://github.com/apache/flink/pull/11877#discussion_r424374975", "createdAt": "2020-05-13T11:48:34Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/CreditBasedSequenceNumberingViewReader.java", "diffHunk": "@@ -45,6 +47,8 @@\n \n \tprivate final PartitionRequestQueue requestQueue;\n \n+\tprivate final int initialCredit;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "59b651c070adcca2b7e4e4a78e6b10411429c589"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0NTcyNTk0OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNFQwNDoxNDozMlrOGVLdDA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNFQwNDoxNDozMlrOGVLdDA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDg2MDk0MA==", "bodyText": "nit: bufferReleased  -> numReleasedBuffers", "url": "https://github.com/apache/flink/pull/11877#discussion_r424860940", "createdAt": "2020-05-14T04:14:32Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "diffHunk": "@@ -151,23 +150,43 @@ int requestFloatingBuffers(int numRequired) throws IOException {\n \t\t\t\treturn numRequestedBuffers;\n \t\t\t}\n \n-\t\t\tnumRequiredBuffers = numRequired;\n+\t\t\tnumRequiredBuffers += numRequired;\n+\t\t\tnumRequestedBuffers = internalRequestFloatingBuffers(numRequiredBuffers);\n+\t\t\tnumRequiredBuffers -= numRequestedBuffers;\n+\t\t}\n+\t\treturn numRequestedBuffers;\n+\t}\n \n-\t\t\twhile (bufferQueue.getAvailableBufferSize() < numRequiredBuffers && !isWaitingForFloatingBuffers) {\n-\t\t\t\tBufferPool bufferPool = inputChannel.inputGate.getBufferPool();\n-\t\t\t\tBuffer buffer = bufferPool.requestBuffer();\n-\t\t\t\tif (buffer != null) {\n-\t\t\t\t\tbufferQueue.addFloatingBuffer(buffer);\n-\t\t\t\t\tnumRequestedBuffers++;\n-\t\t\t\t} else if (bufferPool.addBufferListener(this)) {\n-\t\t\t\t\tisWaitingForFloatingBuffers = true;\n-\t\t\t\t\tbreak;\n-\t\t\t\t}\n+\tprivate int internalRequestFloatingBuffers(int numBuffersToRequest) throws IOException {\n+\t\tassert Thread.holdsLock(bufferQueue);\n+\n+\t\tint numRequestedBuffers = 0;\n+\t\twhile (numRequestedBuffers < numBuffersToRequest && !isWaitingForFloatingBuffers) {\n+\t\t\tBufferPool bufferPool = inputChannel.inputGate.getBufferPool();\n+\t\t\tBuffer buffer = bufferPool.requestBuffer();\n+\t\t\tif (buffer != null) {\n+\t\t\t\tbufferQueue.addFloatingBuffer(buffer);\n+\t\t\t\tnumRequestedBuffers++;\n+\t\t\t} else if (bufferPool.addBufferListener(this)) {\n+\t\t\t\tisWaitingForFloatingBuffers = true;\n+\t\t\t\tbreak;\n \t\t\t}\n \t\t}\n \t\treturn numRequestedBuffers;\n \t}\n \n+\tpublic void unregisterBufferListenerAndReleaseFloatingBuffers() {\n+\t\tsynchronized (bufferQueue) {\n+\t\t\tif (isWaitingForFloatingBuffers) {\n+\t\t\t\tinputChannel.inputGate.getBufferPool().removeBufferListener(this);\n+\t\t\t\tisWaitingForFloatingBuffers = false;\n+\t\t\t}\n+\n+\t\t\tint bufferReleased = bufferQueue.releaseFloatingBuffers();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "59b651c070adcca2b7e4e4a78e6b10411429c589"}, "originalPosition": 73}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0NTc0MjgxOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNFQwNDoyNTo0NFrOGVLnIg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNFQwNDoyNTo0NFrOGVLnIg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDg2MzUyMg==", "bodyText": "This method should be placed into the below section Buffer recycle.\nI think it is better to integrate this method with existing #releaseFloatingBuffers to provide a general one, otherwise it might bring confusing to understand the difference among them, especially for the different handle of numRequiredBuffers, to make them seem customized logic.\nThe integration is as below\nvoid releaseFloatingBuffers(boolean isTemporaryRelease) {\n\t\tsynchronized (bufferQueue) {\n\t\t\tif (isWaitingForFloatingBuffers) {\n\t\t\t\tinputChannel.inputGate.getBufferPool().removeBufferListener(this);\n\t\t\t\tisWaitingForFloatingBuffers = false;\n\t\t\t}\n\n\t\t\tint numReleasedBuffers = bufferQueue.releaseFloatingBuffers();\n\t\t\tif (isTemporaryRelease) {\n\t\t\t\tnumRequiredBuffers += numReleasedBuffers;\n\t\t\t} else {\n\t\t\t\tnumRequiredBuffers = 0;\n\t\t\t}\n\t\t}\n\t}", "url": "https://github.com/apache/flink/pull/11877#discussion_r424863522", "createdAt": "2020-05-14T04:25:44Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "diffHunk": "@@ -151,23 +149,42 @@ int requestFloatingBuffers(int numRequired) throws IOException {\n \t\t\t\treturn numRequestedBuffers;\n \t\t\t}\n \n-\t\t\tnumRequiredBuffers = numRequired;\n+\t\t\tnumRequiredBuffers += numRequired;\n+\t\t\tnumRequestedBuffers = internalRequestFloatingBuffers(numRequiredBuffers);\n+\t\t\tnumRequiredBuffers -= numRequestedBuffers;\n+\t\t}\n+\t\treturn numRequestedBuffers;\n+\t}\n \n-\t\t\twhile (bufferQueue.getAvailableBufferSize() < numRequiredBuffers && !isWaitingForFloatingBuffers) {\n-\t\t\t\tBufferPool bufferPool = inputChannel.inputGate.getBufferPool();\n-\t\t\t\tBuffer buffer = bufferPool.requestBuffer();\n-\t\t\t\tif (buffer != null) {\n-\t\t\t\t\tbufferQueue.addFloatingBuffer(buffer);\n-\t\t\t\t\tnumRequestedBuffers++;\n-\t\t\t\t} else if (bufferPool.addBufferListener(this)) {\n-\t\t\t\t\tisWaitingForFloatingBuffers = true;\n-\t\t\t\t\tbreak;\n-\t\t\t\t}\n+\tprivate int internalRequestFloatingBuffers(int numBuffersToRequest) throws IOException {\n+\t\tassert Thread.holdsLock(bufferQueue);\n+\n+\t\tint numRequestedBuffers = 0;\n+\t\twhile (numRequestedBuffers < numBuffersToRequest && !isWaitingForFloatingBuffers) {\n+\t\t\tBufferPool bufferPool = inputChannel.inputGate.getBufferPool();\n+\t\t\tBuffer buffer = bufferPool.requestBuffer();\n+\t\t\tif (buffer != null) {\n+\t\t\t\tbufferQueue.addFloatingBuffer(buffer);\n+\t\t\t\tnumRequestedBuffers++;\n+\t\t\t} else if (bufferPool.addBufferListener(this)) {\n+\t\t\t\tisWaitingForFloatingBuffers = true;\n+\t\t\t\tbreak;\n \t\t\t}\n \t\t}\n \t\treturn numRequestedBuffers;\n \t}\n \n+\tpublic void unregisterBufferListenerAndReleaseFloatingBuffers() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e033307ba22ee660cd6c39063896500075b60671"}, "originalPosition": 74}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0NTc1OTQ5OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNFQwNDozNjozM1rOGVLxHA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNFQwNDozNjozM1rOGVLxHA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDg2NjA3Ng==", "bodyText": "It should not be changed here. If the numRequiredBuffers is 0, getAvailableBufferSize() must be more than it. If numRequiredBuffers is 1 or something else, as long as the getAvailableBufferSize() is more than it, we also need to release a floating buffer.", "url": "https://github.com/apache/flink/pull/11877#discussion_r424866076", "createdAt": "2020-05-14T04:36:33Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "diffHunk": "@@ -349,7 +373,7 @@ int unsynchronizedGetFloatingBuffersAvailable() {\n \t\t */\n \t\tint addExclusiveBuffer(Buffer buffer, int numRequiredBuffers) {\n \t\t\texclusiveBuffers.add(buffer);\n-\t\t\tif (getAvailableBufferSize() > numRequiredBuffers) {\n+\t\t\tif (numRequiredBuffers == 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e033307ba22ee660cd6c39063896500075b60671"}, "originalPosition": 152}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0NTk3MTA2OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNFQwNjozMjoxOVrOGVNzvQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNFQwNjozMjoxOVrOGVNzvQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDg5OTUxNw==", "bodyText": "make it only private method inside RemoteInputChannel, because it is never used outside.", "url": "https://github.com/apache/flink/pull/11877#discussion_r424899517", "createdAt": "2020-05-14T06:32:19Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "diffHunk": "@@ -327,6 +322,14 @@ public void notifyBufferAvailable(int numAvailableBuffers) {\n \t\t}\n \t}\n \n+\t@Override\n+\tpublic void onCheckpointBarrier(CheckpointBarrier barrier) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "10deae9993244cb215af6f0bb3bd6a9b0f9ef9fd"}, "originalPosition": 57}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0NTk4Njk4OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNFQwNjozODoyNVrOGVN9iA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNFQwNjozODoyNVrOGVN9iA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDkwMjAyNA==", "bodyText": "nit: also adjust the javadoc of this method accordingly.", "url": "https://github.com/apache/flink/pull/11877#discussion_r424902024", "createdAt": "2020-05-14T06:38:25Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "diffHunk": "@@ -418,8 +437,8 @@ public Buffer requestBuffer() {\n \t *\n \t * @param backlog The number of unsent buffers in the producer's sub partition.\n \t */\n-\tvoid onSenderBacklog(int backlog) throws IOException {\n-\t\tnotifyBufferAvailable(bufferManager.requestFloatingBuffers(backlog + initialCredit));\n+\tpublic void onSenderBacklog(int backlog) throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "10deae9993244cb215af6f0bb3bd6a9b0f9ef9fd"}, "originalPosition": 96}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0NjAxOTU3OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNFQwNjo0OTozMFrOGVOQ3A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNFQwNjo0OTozMFrOGVOQ3A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDkwNjk3Mg==", "bodyText": "unsynchronizedGetAvailableExclusiveBuffers?", "url": "https://github.com/apache/flink/pull/11877#discussion_r424906972", "createdAt": "2020-05-14T06:49:30Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "diffHunk": "@@ -313,7 +313,7 @@ int getNumberOfAvailableBuffers() {\n \t\t}\n \t}\n \n-\tint unsynchronizedGetExclusiveBuffersUsed() {\n+\tint unsynchronizedGetExclusiveBuffers() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2ea543cf392fb1f2d8d7691fa358a93b6765d195"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0NzAzMjY0OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/PartitionRequestQueue.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNFQxMTo0MToyM1rOGVYV1A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNFQxMTo0MToyM1rOGVYV1A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTA3MjA4NA==", "bodyText": "remove moreAvailable argument from the constructor, because it seems strange for AddBacklogMessage, then we can give false in below super instead.", "url": "https://github.com/apache/flink/pull/11877#discussion_r425072084", "createdAt": "2020-05-14T11:41:23Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/PartitionRequestQueue.java", "diffHunk": "@@ -328,4 +325,67 @@ public void operationComplete(ChannelFuture future) throws Exception {\n \t\t\t}\n \t\t}\n \t}\n+\n+\t/**\n+\t * Outbound message to be sent to the client.\n+\t */\n+\tpublic static abstract class ServerOutboundMessage {\n+\t\tprotected final InputChannelID receiverId;\n+\t\tprotected final int backlog;\n+\t\tprivate final boolean moreAvailable;\n+\n+\t\tServerOutboundMessage(InputChannelID receiverId, int backlog, boolean moreAvailable) {\n+\t\t\tcheckArgument(backlog >= 0, \"Number of backlog must be non-negative.\");\n+\t\t\tthis.receiverId = checkNotNull(receiverId);\n+\t\t\tthis.backlog = backlog;\n+\t\t\tthis.moreAvailable = moreAvailable;\n+\t\t}\n+\n+\t\tabstract Object build();\n+\n+\t\tpublic boolean isMoreAvailable() {\n+\t\t\treturn moreAvailable;\n+\t\t}\n+\n+\t\tvoid recycleBufferIfNeeded() {\n+\t\t}\n+\t}\n+\n+\tstatic class BufferResponseMessage extends ServerOutboundMessage {\n+\t\tprivate final Buffer buffer;\n+\t\tprivate final int sequenceNumber;\n+\n+\t\tBufferResponseMessage(\n+\t\t\t\tBuffer buffer,\n+\t\t\t\tInputChannelID receiverId,\n+\t\t\t\tint sequenceNumber,\n+\t\t\t\tint backlog,\n+\t\t\t\tboolean moreAvailable) {\n+\t\t\tsuper(receiverId, backlog, moreAvailable);\n+\t\t\tthis.buffer = checkNotNull(buffer);\n+\t\t\tthis.sequenceNumber = sequenceNumber;\n+\t\t}\n+\n+\t\t@Override\n+\t\tObject build() {\n+\t\t\treturn new BufferResponse(buffer, sequenceNumber, receiverId, backlog);\n+\t\t}\n+\n+\t\t@Override\n+\t\tvoid recycleBufferIfNeeded() {\n+\t\t\tbuffer.recycleBuffer();\n+\t\t}\n+\t}\n+\n+\tstatic class AddBacklogMessage extends ServerOutboundMessage {\n+\n+\t\tAddBacklogMessage(InputChannelID receiverId, int backlog, boolean moreAvailable) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ae90bc7d6d3753da3e9bbadcc99c80a152801e43"}, "originalPosition": 198}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0NzAzODYzOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/PartitionRequestQueue.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNFQxMTo0MzoxNVrOGVYZqg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNFQxMTo0MzoxNVrOGVYZqg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTA3MzA2Ng==", "bodyText": "Adjust the javadoc accordingly", "url": "https://github.com/apache/flink/pull/11877#discussion_r425073066", "createdAt": "2020-05-14T11:43:15Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/PartitionRequestQueue.java", "diffHunk": "@@ -94,10 +97,11 @@ void notifyReaderNonEmpty(final NetworkSequenceViewReader reader) {\n \t * <p>NOTE: Only one thread would trigger the actual enqueue after checking the reader's\n \t * availability, so there is no race condition here.\n \t */\n-\tprivate void enqueueAvailableReader(final NetworkSequenceViewReader reader) throws Exception {\n-\t\tif (reader.isRegisteredAsAvailable() || !reader.isAvailable()) {\n+\tvoid enqueueAvailableReader(final NetworkSequenceViewReader reader, BooleanSupplier condition) throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ae90bc7d6d3753da3e9bbadcc99c80a152801e43"}, "originalPosition": 46}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0NzA3MzE1OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/CreditBasedSequenceNumberingViewReader.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNFQxMTo1Mzo0OFrOGVYu-g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNFQxMzowMToyOFrOGVbF0A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTA3ODUyMg==", "bodyText": "I guess we should not expect null return here. As long as the code path enters getAddBacklogMessage, then we should guarantee that the respective backlog should be more than 0.\nMaybe add assert backlog instead?", "url": "https://github.com/apache/flink/pull/11877#discussion_r425078522", "createdAt": "2020-05-14T11:53:48Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/CreditBasedSequenceNumberingViewReader.java", "diffHunk": "@@ -163,8 +172,15 @@ boolean hasBuffersAvailable() {\n \t\treturn subpartitionView.isAvailable(Integer.MAX_VALUE);\n \t}\n \n-\t@Override\n-\tpublic BufferAndAvailability getNextBuffer() throws IOException {\n+\tprivate AddBacklogMessage getAddBacklogMessage() {\n+\t\tint backlog = subpartitionView.getAndResetUnannouncedBacklog();\n+\t\tif (backlog > 0) {\n+\t\t\treturn new AddBacklogMessage(receiverId, backlog, false);\n+\t\t}\n+\t\treturn null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ae90bc7d6d3753da3e9bbadcc99c80a152801e43"}, "originalPosition": 81}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTExNzEzNg==", "bodyText": "It can be null because of redundant data available notification.", "url": "https://github.com/apache/flink/pull/11877#discussion_r425117136", "createdAt": "2020-05-14T13:01:28Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/CreditBasedSequenceNumberingViewReader.java", "diffHunk": "@@ -163,8 +172,15 @@ boolean hasBuffersAvailable() {\n \t\treturn subpartitionView.isAvailable(Integer.MAX_VALUE);\n \t}\n \n-\t@Override\n-\tpublic BufferAndAvailability getNextBuffer() throws IOException {\n+\tprivate AddBacklogMessage getAddBacklogMessage() {\n+\t\tint backlog = subpartitionView.getAndResetUnannouncedBacklog();\n+\t\tif (backlog > 0) {\n+\t\t\treturn new AddBacklogMessage(receiverId, backlog, false);\n+\t\t}\n+\t\treturn null;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTA3ODUyMg=="}, "originalCommit": {"oid": "ae90bc7d6d3753da3e9bbadcc99c80a152801e43"}, "originalPosition": 81}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0NzA3NDMwOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/CreditBasedSequenceNumberingViewReader.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNFQxMTo1NDoxNFrOGVYvsw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNFQxMTo1NDoxNFrOGVYvsw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTA3ODcwNw==", "bodyText": "initialCredit  == 0", "url": "https://github.com/apache/flink/pull/11877#discussion_r425078707", "createdAt": "2020-05-14T11:54:14Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/CreditBasedSequenceNumberingViewReader.java", "diffHunk": "@@ -69,6 +73,7 @@\n \t\tthis.receiverId = receiverId;\n \t\tthis.numCreditsAvailable = initialCredit;\n \t\tthis.requestQueue = requestQueue;\n+\t\tthis.withoutExclusiveCredits = initialCredit > 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ae90bc7d6d3753da3e9bbadcc99c80a152801e43"}, "originalPosition": 29}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0NzA3ODI3OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/CreditBasedSequenceNumberingViewReader.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNFQxMTo1NToyNVrOGVYyKw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNFQxMTo1NToyNVrOGVYyKw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTA3OTMzOQ==", "bodyText": "nit: availableCredit -> availableCredits", "url": "https://github.com/apache/flink/pull/11877#discussion_r425079339", "createdAt": "2020-05-14T11:55:25Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/CreditBasedSequenceNumberingViewReader.java", "diffHunk": "@@ -94,13 +99,22 @@ public void requestSubpartitionView(\n \t}\n \n \t@Override\n-\tpublic void addCredit(int creditDeltas) {\n+\tpublic void addCredit(int creditDeltas) throws Exception {\n \t\tnumCreditsAvailable += creditDeltas;\n+\t\trequestQueue.enqueueAvailableReader(this, this::isAvailable);\n+\t}\n+\n+\t@Override\n+\tpublic boolean shouldAnnounceBacklog() {\n+\t\treturn !withoutExclusiveCredits && numCreditsAvailable == 0 && subpartitionView.isAvailable(Integer.MAX_VALUE);\n \t}\n \n \t@Override\n-\tpublic void resumeConsumption() {\n+\tpublic void resumeConsumption(int availableCredit, boolean hasUnfulfilledBacklog) throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ae90bc7d6d3753da3e9bbadcc99c80a152801e43"}, "originalPosition": 50}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkNDIwMjA4OTQwOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/CreditBasedPartitionRequestClientHandler.java", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNi0zMFQxNDo0Njo0MlrOJ25nvA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wN1QwMjo0MjozOVrOJ6MXVw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTU0Njk0MA==", "bodyText": "Before these changes where this buffer was recycled? or was it the bug?", "url": "https://github.com/apache/flink/pull/11877#discussion_r661546940", "createdAt": "2021-06-30T14:46:42Z", "author": {"login": "akalash"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/CreditBasedPartitionRequestClientHandler.java", "diffHunk": "@@ -340,7 +355,15 @@ private void decodeBufferOrEvent(\n             RemoteInputChannel inputChannel, NettyMessage.BufferResponse bufferOrEvent)\n             throws Throwable {\n         if (bufferOrEvent.isBuffer() && bufferOrEvent.bufferSize == 0) {\n-            inputChannel.onEmptyBuffer(bufferOrEvent.sequenceNumber, bufferOrEvent.backlog);\n+            try {\n+                inputChannel.onEmptyBuffer(bufferOrEvent.sequenceNumber, bufferOrEvent.backlog);\n+            } finally {\n+                // recycle the empty buffer directly\n+                Buffer buffer = bufferOrEvent.getBuffer();\n+                if (buffer != null) {\n+                    buffer.recycleBuffer();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTk4NjgxMg==", "bodyText": "It is not a bug. The empty buffer will not be sent to the downstream before. However, after this change, the empty buffer will be sent to the downstream task to release the credit already allocated for it. If we do not send the empty buffer to the downstream, the corresponding downstream channel will occupy more credits than needed.", "url": "https://github.com/apache/flink/pull/11877#discussion_r661986812", "createdAt": "2021-07-01T05:32:32Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/CreditBasedPartitionRequestClientHandler.java", "diffHunk": "@@ -340,7 +355,15 @@ private void decodeBufferOrEvent(\n             RemoteInputChannel inputChannel, NettyMessage.BufferResponse bufferOrEvent)\n             throws Throwable {\n         if (bufferOrEvent.isBuffer() && bufferOrEvent.bufferSize == 0) {\n-            inputChannel.onEmptyBuffer(bufferOrEvent.sequenceNumber, bufferOrEvent.backlog);\n+            try {\n+                inputChannel.onEmptyBuffer(bufferOrEvent.sequenceNumber, bufferOrEvent.backlog);\n+            } finally {\n+                // recycle the empty buffer directly\n+                Buffer buffer = bufferOrEvent.getBuffer();\n+                if (buffer != null) {\n+                    buffer.recycleBuffer();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTU0Njk0MA=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDUwMzUyNw==", "bodyText": "What do you mean by that @wsry ? That previously bufferOrEevnt.getBuffer() was always null?\nIf so why do we need to keep suport for sending both empty buffers or null buffer?", "url": "https://github.com/apache/flink/pull/11877#discussion_r664503527", "createdAt": "2021-07-06T12:20:31Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/CreditBasedPartitionRequestClientHandler.java", "diffHunk": "@@ -340,7 +355,15 @@ private void decodeBufferOrEvent(\n             RemoteInputChannel inputChannel, NettyMessage.BufferResponse bufferOrEvent)\n             throws Throwable {\n         if (bufferOrEvent.isBuffer() && bufferOrEvent.bufferSize == 0) {\n-            inputChannel.onEmptyBuffer(bufferOrEvent.sequenceNumber, bufferOrEvent.backlog);\n+            try {\n+                inputChannel.onEmptyBuffer(bufferOrEvent.sequenceNumber, bufferOrEvent.backlog);\n+            } finally {\n+                // recycle the empty buffer directly\n+                Buffer buffer = bufferOrEvent.getBuffer();\n+                if (buffer != null) {\n+                    buffer.recycleBuffer();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTU0Njk0MA=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDk5NzIxOA==", "bodyText": "Yes, you are right. Previously, bufferOrEevnt.getBuffer() was always null. And currently, it should be never null. So we do not need to support null buffer now.", "url": "https://github.com/apache/flink/pull/11877#discussion_r664997218", "createdAt": "2021-07-07T02:34:08Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/CreditBasedPartitionRequestClientHandler.java", "diffHunk": "@@ -340,7 +355,15 @@ private void decodeBufferOrEvent(\n             RemoteInputChannel inputChannel, NettyMessage.BufferResponse bufferOrEvent)\n             throws Throwable {\n         if (bufferOrEvent.isBuffer() && bufferOrEvent.bufferSize == 0) {\n-            inputChannel.onEmptyBuffer(bufferOrEvent.sequenceNumber, bufferOrEvent.backlog);\n+            try {\n+                inputChannel.onEmptyBuffer(bufferOrEvent.sequenceNumber, bufferOrEvent.backlog);\n+            } finally {\n+                // recycle the empty buffer directly\n+                Buffer buffer = bufferOrEvent.getBuffer();\n+                if (buffer != null) {\n+                    buffer.recycleBuffer();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTU0Njk0MA=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDk5OTc2Nw==", "bodyText": "I think I can keep this logic unchanged and release the buffer in decoder", "url": "https://github.com/apache/flink/pull/11877#discussion_r664999767", "createdAt": "2021-07-07T02:42:39Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/CreditBasedPartitionRequestClientHandler.java", "diffHunk": "@@ -340,7 +355,15 @@ private void decodeBufferOrEvent(\n             RemoteInputChannel inputChannel, NettyMessage.BufferResponse bufferOrEvent)\n             throws Throwable {\n         if (bufferOrEvent.isBuffer() && bufferOrEvent.bufferSize == 0) {\n-            inputChannel.onEmptyBuffer(bufferOrEvent.sequenceNumber, bufferOrEvent.backlog);\n+            try {\n+                inputChannel.onEmptyBuffer(bufferOrEvent.sequenceNumber, bufferOrEvent.backlog);\n+            } finally {\n+                // recycle the empty buffer directly\n+                Buffer buffer = bufferOrEvent.getBuffer();\n+                if (buffer != null) {\n+                    buffer.recycleBuffer();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTU0Njk0MA=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 40}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkNDIwMjEzNDU4OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/PartitionRequestQueue.java", "isResolved": false, "comments": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNi0zMFQxNDo1Mzo1NlrOJ26DbQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wOFQxNToxMjoxOFrOJ7a5PA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTU1NDAyOQ==", "bodyText": "as I understand, the backlog can not be less or equal to 0 here. So maybe convert it to checkArgument? Or I missed something?", "url": "https://github.com/apache/flink/pull/11877#discussion_r661554029", "createdAt": "2021-06-30T14:53:56Z", "author": {"login": "akalash"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/PartitionRequestQueue.java", "diffHunk": "@@ -164,6 +168,27 @@ void addCreditOrResumeConsumption(\n         }\n     }\n \n+    /**\n+     * Announces remaining backlog to the consumer after the available data notification or data\n+     * consumption resumption.\n+     */\n+    private void announceBacklog(NetworkSequenceViewReader reader) {\n+        int backlog = reader.getRemainingBacklog();\n+        if (backlog > 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTk5MDgyNQ==", "bodyText": "The backlog can be 0. For example, after resumption from checkpoint, if there is no pending data in the subpartition.", "url": "https://github.com/apache/flink/pull/11877#discussion_r661990825", "createdAt": "2021-07-01T05:44:15Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/PartitionRequestQueue.java", "diffHunk": "@@ -164,6 +168,27 @@ void addCreditOrResumeConsumption(\n         }\n     }\n \n+    /**\n+     * Announces remaining backlog to the consumer after the available data notification or data\n+     * consumption resumption.\n+     */\n+    private void announceBacklog(NetworkSequenceViewReader reader) {\n+        int backlog = reader.getRemainingBacklog();\n+        if (backlog > 0) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTU1NDAyOQ=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDY0ODA4NA==", "bodyText": "Have you tested this @wsry ? After all it seems like if reader is available, it should have backlog > 0, shouldn't it?", "url": "https://github.com/apache/flink/pull/11877#discussion_r664648084", "createdAt": "2021-07-06T15:13:14Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/PartitionRequestQueue.java", "diffHunk": "@@ -164,6 +168,27 @@ void addCreditOrResumeConsumption(\n         }\n     }\n \n+    /**\n+     * Announces remaining backlog to the consumer after the available data notification or data\n+     * consumption resumption.\n+     */\n+    private void announceBacklog(NetworkSequenceViewReader reader) {\n+        int backlog = reader.getRemainingBacklog();\n+        if (backlog > 0) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTU1NDAyOQ=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDY2OTg1NA==", "bodyText": "Secondly, getRemainingBacklog() is a very costly operation (additional synchronisation) that I think could have been avoided:\n\nBacklog can go up only as a result of org.apache.flink.runtime.io.network.netty.PartitionRequestQueue#notifyReaderNonEmpty(reader).\nBacklog can go down, only as a result of polling the data from the reader.\nSo instead of using thread safe reader.getRemainingBacklog(), we could re-use existing synchronisation in 1. and 2., to maintain remainingBacklog in the netty thread (in the PartitionRequestQueue.\n\nBut it would be even better to completely avoid this check (my comment above).", "url": "https://github.com/apache/flink/pull/11877#discussion_r664669854", "createdAt": "2021-07-06T15:38:50Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/PartitionRequestQueue.java", "diffHunk": "@@ -164,6 +168,27 @@ void addCreditOrResumeConsumption(\n         }\n     }\n \n+    /**\n+     * Announces remaining backlog to the consumer after the available data notification or data\n+     * consumption resumption.\n+     */\n+    private void announceBacklog(NetworkSequenceViewReader reader) {\n+        int backlog = reader.getRemainingBacklog();\n+        if (backlog > 0) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTU1NDAyOQ=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTAxMjQ0Mw==", "bodyText": "You are right, we can do some optimization here.", "url": "https://github.com/apache/flink/pull/11877#discussion_r665012443", "createdAt": "2021-07-07T03:25:20Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/PartitionRequestQueue.java", "diffHunk": "@@ -164,6 +168,27 @@ void addCreditOrResumeConsumption(\n         }\n     }\n \n+    /**\n+     * Announces remaining backlog to the consumer after the available data notification or data\n+     * consumption resumption.\n+     */\n+    private void announceBacklog(NetworkSequenceViewReader reader) {\n+        int backlog = reader.getRemainingBacklog();\n+        if (backlog > 0) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTU1NDAyOQ=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTA3MzQ2Mw==", "bodyText": "I think there is one thing blocking us from reusing the backlog from PartitionRequestQueue#notifyReaderNonEmpty(reader): we have duplicated availability notifications. We may get outdated backlog.", "url": "https://github.com/apache/flink/pull/11877#discussion_r665073463", "createdAt": "2021-07-07T06:17:03Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/PartitionRequestQueue.java", "diffHunk": "@@ -164,6 +168,27 @@ void addCreditOrResumeConsumption(\n         }\n     }\n \n+    /**\n+     * Announces remaining backlog to the consumer after the available data notification or data\n+     * consumption resumption.\n+     */\n+    private void announceBacklog(NetworkSequenceViewReader reader) {\n+        int backlog = reader.getRemainingBacklog();\n+        if (backlog > 0) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTU1NDAyOQ=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTIyNTkzMg==", "bodyText": "Maybe we can reuse the return value of is available. Instead of just return a bool flag, we may also return the backlog. I will give it a try.", "url": "https://github.com/apache/flink/pull/11877#discussion_r665225932", "createdAt": "2021-07-07T09:58:38Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/PartitionRequestQueue.java", "diffHunk": "@@ -164,6 +168,27 @@ void addCreditOrResumeConsumption(\n         }\n     }\n \n+    /**\n+     * Announces remaining backlog to the consumer after the available data notification or data\n+     * consumption resumption.\n+     */\n+    private void announceBacklog(NetworkSequenceViewReader reader) {\n+        int backlog = reader.getRemainingBacklog();\n+        if (backlog > 0) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTU1NDAyOQ=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTkwMDUxNQ==", "bodyText": "NetworkSequenceViewReader#isAvailable() has the same problem of synchronisation costs.\n\nI think there is one thing blocking us from reusing the backlog from PartitionRequestQueue#notifyReaderNonEmpty(reader): we have duplicated availability notifications. We may get outdated backlog.\n\nWhat is the problem?  Keep in mind that spurious notifications shouldn't be that big of a problem. If we sometimes wake up too many times, and we rarely send incorrect backlog information that should be fine, as long as we always over estimate the backlog.\nAfter all even in your version I think there can be a race condition where PartitionRequestQueue is notified reader is non empty, you check the getRemainingBacklog() and send the BacklogAnnouncement message, while before it gets processed by the receiver, some buffer is polled from this reader and backlog goes down to 0. And as a result, receiver assigns as a credit to a sender that doesn't have any data anymore?", "url": "https://github.com/apache/flink/pull/11877#discussion_r665900515", "createdAt": "2021-07-08T06:19:13Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/PartitionRequestQueue.java", "diffHunk": "@@ -164,6 +168,27 @@ void addCreditOrResumeConsumption(\n         }\n     }\n \n+    /**\n+     * Announces remaining backlog to the consumer after the available data notification or data\n+     * consumption resumption.\n+     */\n+    private void announceBacklog(NetworkSequenceViewReader reader) {\n+        int backlog = reader.getRemainingBacklog();\n+        if (backlog > 0) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTU1NDAyOQ=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTkzMzA2Nw==", "bodyText": "NetworkSequenceViewReader#isAvailable() has already been called by PartitionRequestQueue#enqueueAvailableReader:\nprivate void enqueueAvailableReader(final NetworkSequenceViewReader reader) throws Exception {\nif (reader.isRegisteredAsAvailable() || !reader.isAvailable()) {\nreturn;\n}\n......\n}\n\nI think we can change it to:\n    private void enqueueAvailableReader(final NetworkSequenceViewReader reader) throws Exception {\n        if (reader.isRegisteredAsAvailable()) {\n            return;\n        }\n\n        ResultSubpartitionView.AvailabilityWithBacklog availabilityWithBacklog =\n                reader.getAvailabilityAndBacklog();\n        if (!availabilityWithBacklog.isAvailable()) {\n            int backlog = availabilityWithBacklog.getBacklog();\n            if (backlog > 0 && reader.needAnnounceBacklog()) {\n                announceBacklog(reader, backlog);\n            }\n            return;\n        }\n......\n}\n\nWhat do you think?\n\nAfter all even in your version I think there can be a race condition where PartitionRequestQueue is notified reader is non empty, you check the getRemainingBacklog() and send the BacklogAnnouncement message, while before it gets processed by the receiver, some buffer is polled from this reader and backlog goes down to 0. And as a result, receiver assigns as a credit to a sender that doesn't have any data anymore?\n\nI think there is no such problem. One reason is that getRemainingBacklog() is in netty thread and we can guarantee the order, the downstream will always process the BacklogAnnouncement before the buffer. The other reason is that we only announce credit when there is no credit available which means if there is credit available, only buffer with backlog will be sent, if there is no credit available, only BacklogAnnouncement will be send, buffer will be always wait for credit. It is also not a problem if we announce the same credit twice because we can guarantee the process order.", "url": "https://github.com/apache/flink/pull/11877#discussion_r665933067", "createdAt": "2021-07-08T07:18:34Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/PartitionRequestQueue.java", "diffHunk": "@@ -164,6 +168,27 @@ void addCreditOrResumeConsumption(\n         }\n     }\n \n+    /**\n+     * Announces remaining backlog to the consumer after the available data notification or data\n+     * consumption resumption.\n+     */\n+    private void announceBacklog(NetworkSequenceViewReader reader) {\n+        int backlog = reader.getRemainingBacklog();\n+        if (backlog > 0) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTU1NDAyOQ=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NjI4NjM5Ng==", "bodyText": "Yes you are right. reader.isAvailable() is already being called. I'm not sure why I've missed that.\nreader.getAvailabilityAndBacklog(); should work fine :)", "url": "https://github.com/apache/flink/pull/11877#discussion_r666286396", "createdAt": "2021-07-08T15:12:18Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/PartitionRequestQueue.java", "diffHunk": "@@ -164,6 +168,27 @@ void addCreditOrResumeConsumption(\n         }\n     }\n \n+    /**\n+     * Announces remaining backlog to the consumer after the available data notification or data\n+     * consumption resumption.\n+     */\n+    private void announceBacklog(NetworkSequenceViewReader reader) {\n+        int backlog = reader.getRemainingBacklog();\n+        if (backlog > 0) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTU1NDAyOQ=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkNDIwMjE1NjkwOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/BoundedBlockingSubpartitionDirectTransferReader.java", "isResolved": true, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNi0zMFQxNDo1Nzo0OFrOJ26Rcg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wOFQwNjowODoyMlrOJ7DCUA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTU1NzYxOA==", "bodyText": "Is it also a bug? Or why do we distinguish EVENT_BUFFER and DATA_BUFFER now?", "url": "https://github.com/apache/flink/pull/11877#discussion_r661557618", "createdAt": "2021-06-30T14:57:48Z", "author": {"login": "akalash"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/BoundedBlockingSubpartitionDirectTransferReader.java", "diffHunk": "@@ -91,10 +91,14 @@ public BufferAndBacklog getNextBuffer() throws IOException {\n \n         updateStatistics(current);\n \n-        // We simply assume all the data are non-events for batch jobs to avoid pre-fetching the\n-        // next header\n-        Buffer.DataType nextDataType =\n-                numDataAndEventBuffers > 0 ? Buffer.DataType.DATA_BUFFER : Buffer.DataType.NONE;\n+        // We simply assume all the data except for the last one (EndOfPartitionEvent)\n+        // are non-events for batch jobs to avoid pre-fetching the next header\n+        Buffer.DataType nextDataType = Buffer.DataType.NONE;\n+        if (numDataBuffers > 0) {\n+            nextDataType = Buffer.DataType.DATA_BUFFER;\n+        } else if (numDataAndEventBuffers > 0) {\n+            nextDataType = Buffer.DataType.EVENT_BUFFER;\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTk5MjQ1OQ==", "bodyText": "An EVENT_BUFFER does not need any credit to be sent. The BoundedBlockingSubpartitionDirectTransferReader Implementation does not distinguish EVENT_BUFFER and DATA_BUFFER for simplicity. However, after this change, we need to distinguish EVENT_BUFFER and DATA_BUFFER because we do not want to allocate any credit at downstream for an EVENT_BUFFER.", "url": "https://github.com/apache/flink/pull/11877#discussion_r661992459", "createdAt": "2021-07-01T05:48:25Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/BoundedBlockingSubpartitionDirectTransferReader.java", "diffHunk": "@@ -91,10 +91,14 @@ public BufferAndBacklog getNextBuffer() throws IOException {\n \n         updateStatistics(current);\n \n-        // We simply assume all the data are non-events for batch jobs to avoid pre-fetching the\n-        // next header\n-        Buffer.DataType nextDataType =\n-                numDataAndEventBuffers > 0 ? Buffer.DataType.DATA_BUFFER : Buffer.DataType.NONE;\n+        // We simply assume all the data except for the last one (EndOfPartitionEvent)\n+        // are non-events for batch jobs to avoid pre-fetching the next header\n+        Buffer.DataType nextDataType = Buffer.DataType.NONE;\n+        if (numDataBuffers > 0) {\n+            nextDataType = Buffer.DataType.DATA_BUFFER;\n+        } else if (numDataAndEventBuffers > 0) {\n+            nextDataType = Buffer.DataType.EVENT_BUFFER;\n+        }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTU1NzYxOA=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDY1NDk0OQ==", "bodyText": "But what would be a problem with requesting for a credit for the EndOfPartitionEvent? In other words, what's wrong with doing it as it was done previously: always returning DATA_BUFFER or NONE?", "url": "https://github.com/apache/flink/pull/11877#discussion_r664654949", "createdAt": "2021-07-06T15:21:25Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/BoundedBlockingSubpartitionDirectTransferReader.java", "diffHunk": "@@ -91,10 +91,14 @@ public BufferAndBacklog getNextBuffer() throws IOException {\n \n         updateStatistics(current);\n \n-        // We simply assume all the data are non-events for batch jobs to avoid pre-fetching the\n-        // next header\n-        Buffer.DataType nextDataType =\n-                numDataAndEventBuffers > 0 ? Buffer.DataType.DATA_BUFFER : Buffer.DataType.NONE;\n+        // We simply assume all the data except for the last one (EndOfPartitionEvent)\n+        // are non-events for batch jobs to avoid pre-fetching the next header\n+        Buffer.DataType nextDataType = Buffer.DataType.NONE;\n+        if (numDataBuffers > 0) {\n+            nextDataType = Buffer.DataType.DATA_BUFFER;\n+        } else if (numDataAndEventBuffers > 0) {\n+            nextDataType = Buffer.DataType.EVENT_BUFFER;\n+        }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTU1NzYxOA=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTA1OTAyNw==", "bodyText": "I think this is just an optimization. Without this change, the backlog announced to the downstream does not include the event and EVENT_BUFFER and DATA_BUFFER are not distinguished, this means the event buffer also need a credit to send. If there is no exclusive buffer, no enough buffer will be allocated for the event, because we only announce the data buffer backlog to the downstream. As a result, some tests will hang for there is no credit for the event buffer. To solve this dead lock, there are two simple ways:\n\nAnnounce both data buffer and event buffer backlog to the downstream, this lead to allocate more buffers than needed, these buffers will be released when the EOF is received at the downstream task.\nDistinguish EVENT_BUFFER and DATA_BUFFER just like what is doing now.\n\nThese choices are both acceptable to me. I chose the second one because EVENT_BUFFER and DATA_BUFFER are distinguished at the downstream task and we can allocate one less buffer.\nBoth of the choices need to do some change to BoundedBlockingSubpartitionDirectTransferReader. Which one do you prefer? I think both are acceptable for me.", "url": "https://github.com/apache/flink/pull/11877#discussion_r665059027", "createdAt": "2021-07-07T05:42:23Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/BoundedBlockingSubpartitionDirectTransferReader.java", "diffHunk": "@@ -91,10 +91,14 @@ public BufferAndBacklog getNextBuffer() throws IOException {\n \n         updateStatistics(current);\n \n-        // We simply assume all the data are non-events for batch jobs to avoid pre-fetching the\n-        // next header\n-        Buffer.DataType nextDataType =\n-                numDataAndEventBuffers > 0 ? Buffer.DataType.DATA_BUFFER : Buffer.DataType.NONE;\n+        // We simply assume all the data except for the last one (EndOfPartitionEvent)\n+        // are non-events for batch jobs to avoid pre-fetching the next header\n+        Buffer.DataType nextDataType = Buffer.DataType.NONE;\n+        if (numDataBuffers > 0) {\n+            nextDataType = Buffer.DataType.DATA_BUFFER;\n+        } else if (numDataAndEventBuffers > 0) {\n+            nextDataType = Buffer.DataType.EVENT_BUFFER;\n+        }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTU1NzYxOA=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTgzMDY5MA==", "bodyText": "After rethink about it, the first choice can support more events type in the future and the second choice make the assumption that we only have one event at the end of the data. Maybe the first choice is better?", "url": "https://github.com/apache/flink/pull/11877#discussion_r665830690", "createdAt": "2021-07-08T02:46:07Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/BoundedBlockingSubpartitionDirectTransferReader.java", "diffHunk": "@@ -91,10 +91,14 @@ public BufferAndBacklog getNextBuffer() throws IOException {\n \n         updateStatistics(current);\n \n-        // We simply assume all the data are non-events for batch jobs to avoid pre-fetching the\n-        // next header\n-        Buffer.DataType nextDataType =\n-                numDataAndEventBuffers > 0 ? Buffer.DataType.DATA_BUFFER : Buffer.DataType.NONE;\n+        // We simply assume all the data except for the last one (EndOfPartitionEvent)\n+        // are non-events for batch jobs to avoid pre-fetching the next header\n+        Buffer.DataType nextDataType = Buffer.DataType.NONE;\n+        if (numDataBuffers > 0) {\n+            nextDataType = Buffer.DataType.DATA_BUFFER;\n+        } else if (numDataAndEventBuffers > 0) {\n+            nextDataType = Buffer.DataType.EVENT_BUFFER;\n+        }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTU1NzYxOA=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTg5NTUwNA==", "bodyText": "Let's stay with the option 2 (as you have currently implemented)", "url": "https://github.com/apache/flink/pull/11877#discussion_r665895504", "createdAt": "2021-07-08T06:08:22Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/BoundedBlockingSubpartitionDirectTransferReader.java", "diffHunk": "@@ -91,10 +91,14 @@ public BufferAndBacklog getNextBuffer() throws IOException {\n \n         updateStatistics(current);\n \n-        // We simply assume all the data are non-events for batch jobs to avoid pre-fetching the\n-        // next header\n-        Buffer.DataType nextDataType =\n-                numDataAndEventBuffers > 0 ? Buffer.DataType.DATA_BUFFER : Buffer.DataType.NONE;\n+        // We simply assume all the data except for the last one (EndOfPartitionEvent)\n+        // are non-events for batch jobs to avoid pre-fetching the next header\n+        Buffer.DataType nextDataType = Buffer.DataType.NONE;\n+        if (numDataBuffers > 0) {\n+            nextDataType = Buffer.DataType.DATA_BUFFER;\n+        } else if (numDataAndEventBuffers > 0) {\n+            nextDataType = Buffer.DataType.EVENT_BUFFER;\n+        }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTU1NzYxOA=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkNDIwMjE5MjExOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/BoundedBlockingSubpartitionDirectTransferReader.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNi0zMFQxNTowNDowNlrOJ26nqA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wMVQwNTo1MToyOFrOJ3U4qw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTU2MzMwNA==", "bodyText": "Does this mean that we don't need the credit for sending the event?", "url": "https://github.com/apache/flink/pull/11877#discussion_r661563304", "createdAt": "2021-06-30T15:04:06Z", "author": {"login": "akalash"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/BoundedBlockingSubpartitionDirectTransferReader.java", "diffHunk": "@@ -110,7 +114,12 @@ private void updateStatistics(Buffer buffer) {\n     public boolean isAvailable(int numCreditsAvailable) {\n         // We simply assume there are no events except EndOfPartitionEvent for bath jobs,\n         // then it has no essential effect to ignore the judgement of next event buffer.\n-        return numCreditsAvailable > 0 && numDataAndEventBuffers > 0;\n+        return (numCreditsAvailable > 0 || numDataBuffers == 0) && numDataAndEventBuffers > 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTk5MzY0Mw==", "bodyText": "Yes, you are right. At the downstream task, no credit is needed when decoding an event.", "url": "https://github.com/apache/flink/pull/11877#discussion_r661993643", "createdAt": "2021-07-01T05:51:28Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/BoundedBlockingSubpartitionDirectTransferReader.java", "diffHunk": "@@ -110,7 +114,12 @@ private void updateStatistics(Buffer buffer) {\n     public boolean isAvailable(int numCreditsAvailable) {\n         // We simply assume there are no events except EndOfPartitionEvent for bath jobs,\n         // then it has no essential effect to ignore the judgement of next event buffer.\n-        return numCreditsAvailable > 0 && numDataAndEventBuffers > 0;\n+        return (numCreditsAvailable > 0 || numDataBuffers == 0) && numDataAndEventBuffers > 0;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTU2MzMwNA=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkNDIwMjM2MDM5OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java", "isResolved": false, "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNi0zMFQxNTozMzoxNFrOJ28Oug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wNVQwMTo0MDozMlrOJ42ZdQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTU4OTY5MA==", "bodyText": "I don't really get the idea of these changes.\nLet's suppose PipelindedSubpartition#buffers contain several but the first one is empty and finished already.\nHow it was before the changes:\n\nPartitionRequestQueue requests the buffer.\nin any case, PipelindedSubpartition#pollBuffer returns a buffer(it skip the first one because it is empty and finished but it returns the buffer from the next consumer)\nPartitionRequestQueue continues to request from this Reader until PipelindedSubpartition#buffers is not empty.\n\nAfter the changes:\n\nPartitionRequestQueue requests the buffer.\nPipelindedSubpartition#pollBuffer returns null.\nPartitionRequestQueue remove this reader from the available readers\nOther buffers from PipelindedSubpartition#buffers will be sent only when timeout happens and this reader is added to the available list again.\n\nWhat the point to delay the sending if we already have credit for it and we have the buffer ready to be sent?", "url": "https://github.com/apache/flink/pull/11877#discussion_r661589690", "createdAt": "2021-06-30T15:33:14Z", "author": {"login": "akalash"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java", "diffHunk": "@@ -288,9 +288,7 @@ BufferAndBacklog pollBuffer() {\n \n             if (buffers.isEmpty()) {\n                 flushRequested = false;\n-            }\n-\n-            while (!buffers.isEmpty()) {\n+            } else {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTk5ODg4NQ==", "bodyText": "After the changes, if the first buffer is finished and empty. The empty buffer will be sent to the downstream to release the allocated credit for it instead of recycled directly.", "url": "https://github.com/apache/flink/pull/11877#discussion_r661998885", "createdAt": "2021-07-01T05:59:12Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java", "diffHunk": "@@ -288,9 +288,7 @@ BufferAndBacklog pollBuffer() {\n \n             if (buffers.isEmpty()) {\n                 flushRequested = false;\n-            }\n-\n-            while (!buffers.isEmpty()) {\n+            } else {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTU4OTY5MA=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MjIxNzkxNA==", "bodyText": "Ok, I think I understand it now. Please, tell me I indeed understand the scenario right:\n\nSuppose the buffers contain one unfinished Buffer.\nThe flush was requested\nWhen pollBuffer() was called it collects all readable bytes from this unfinished buffer and getBuffersInBacklog returns 1(because flushRequested set to true)\nOne more credit is requested from downstream because getBuffersInBacklog equal to 1.\nWhen pollBuffer() was called again it reads nothing because all data was read last time. But it already has one credit that should be released(it is exactly what you told about?).", "url": "https://github.com/apache/flink/pull/11877#discussion_r662217914", "createdAt": "2021-07-01T11:46:27Z", "author": {"login": "akalash"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java", "diffHunk": "@@ -288,9 +288,7 @@ BufferAndBacklog pollBuffer() {\n \n             if (buffers.isEmpty()) {\n                 flushRequested = false;\n-            }\n-\n-            while (!buffers.isEmpty()) {\n+            } else {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTU4OTY5MA=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MjY4ODEyMA==", "bodyText": "If there is only one buffer in the buffer queue, after all data is read, the flushRequested flag will be turned off. Consider the following scenario (correct me if I am wrong):\n\nThere is an unfinished buffer in the queue and all data is read.\nThen the buffer is finished but no new data is appended. Note appending data and finish buffer is not an atomic operation.\nNew buffer or event is added to the buffer queue.\nWhen polling buffer, an empty buffer is at the head of the queue and we already allocate a credit for it.", "url": "https://github.com/apache/flink/pull/11877#discussion_r662688120", "createdAt": "2021-07-02T02:01:09Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java", "diffHunk": "@@ -288,9 +288,7 @@ BufferAndBacklog pollBuffer() {\n \n             if (buffers.isEmpty()) {\n                 flushRequested = false;\n-            }\n-\n-            while (!buffers.isEmpty()) {\n+            } else {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTU4OTY5MA=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2Mjc3ODA1NQ==", "bodyText": "appending data and finish buffer is not an atomic operation.\n\nIt is exactly what I want to emphasize. As I understand, we need the empty buffer only because appending data and finish buffer is not an atomic operation. which happens because BufferBuilder has a gap between commit and finish. So I propose to rewrite BufferBuilder in such a way that if it commits the current state and size == capacity it finishes it immediately(so there is no explicit finish call needed). These changes allow us to avoid all logic with an empty buffer which I think pretty untransparent.\nOne more time, my proposal:\n\nRewriting the BufferBuilder in such a way that it will be impossible to have the empty finished buffer(it just requires removing the gap between the last commit and finish).\nDon't send the empty buffer(after changes described above there won't be any empty buffers)\n\n@wsry WDYT?\n@pnowojski What is your opinion, is it safe to finish BufferBuilder immediately when it becomes full? I mean not to wait for call explicit finish but finish in the commit if it is full?", "url": "https://github.com/apache/flink/pull/11877#discussion_r662778055", "createdAt": "2021-07-02T06:49:47Z", "author": {"login": "akalash"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java", "diffHunk": "@@ -288,9 +288,7 @@ BufferAndBacklog pollBuffer() {\n \n             if (buffers.isEmpty()) {\n                 flushRequested = false;\n-            }\n-\n-            while (!buffers.isEmpty()) {\n+            } else {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTU4OTY5MA=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MjgxNjg1OA==", "bodyText": "Does that mean that the BufferBuilder can not finish a partial buffer, for example the last piece of data of the batch execution mode? Besides, there is another case which may lead to the empty buffer: in PipelinedApproximateSubpartition, if a partial record takes more than one buffer in the queue, those partial data will be dropped when recovering.", "url": "https://github.com/apache/flink/pull/11877#discussion_r662816858", "createdAt": "2021-07-02T07:57:45Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java", "diffHunk": "@@ -288,9 +288,7 @@ BufferAndBacklog pollBuffer() {\n \n             if (buffers.isEmpty()) {\n                 flushRequested = false;\n-            }\n-\n-            while (!buffers.isEmpty()) {\n+            } else {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTU4OTY5MA=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2Mjg0MTM3NA==", "bodyText": "Yes, the batch execution mode still requires the manual calling of finish which brokes my idea.  The same about PipelinedApproximateSubpartition. As I understand, it is impossible to know that a partial record will be sent or not before the request the credit.\nSo I still believe that it would be better to avoid sending the empty buffer if it is possible. But perhaps you right and it will be not so easy to do so in the current implementation, especially because of the scenarios which you described.", "url": "https://github.com/apache/flink/pull/11877#discussion_r662841374", "createdAt": "2021-07-02T08:36:12Z", "author": {"login": "akalash"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java", "diffHunk": "@@ -288,9 +288,7 @@ BufferAndBacklog pollBuffer() {\n \n             if (buffers.isEmpty()) {\n                 flushRequested = false;\n-            }\n-\n-            while (!buffers.isEmpty()) {\n+            } else {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTU4OTY5MA=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzExOTk1Ng==", "bodyText": "How common is that case? Can we measure how many those empty buffers are being sent? Is this an issue of 0.1% more messages or 50%? If it's hard to say or can vary, would it be difficult/would it complicate the code to send the empty buffers only if #exclusiveBuffers == 0 to make sure that there is no performance regression?", "url": "https://github.com/apache/flink/pull/11877#discussion_r663119956", "createdAt": "2021-07-02T16:13:03Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java", "diffHunk": "@@ -288,9 +288,7 @@ BufferAndBacklog pollBuffer() {\n \n             if (buffers.isEmpty()) {\n                 flushRequested = false;\n-            }\n-\n-            while (!buffers.isEmpty()) {\n+            } else {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTU4OTY5MA=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzU5MTI4NQ==", "bodyText": "It is pretty simple to send empty buffer only when  #exclusiveBuffers == 0.", "url": "https://github.com/apache/flink/pull/11877#discussion_r663591285", "createdAt": "2021-07-05T01:40:32Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java", "diffHunk": "@@ -288,9 +288,7 @@ BufferAndBacklog pollBuffer() {\n \n             if (buffers.isEmpty()) {\n                 flushRequested = false;\n-            }\n-\n-            while (!buffers.isEmpty()) {\n+            } else {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTU4OTY5MA=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkNDIwMjM3ODY2OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNi0zMFQxNTozNjoxN1rOJ28Zkg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wMVQwNjowMToyNlrOJ3VQfQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTU5MjQ2Ng==", "bodyText": "So dangerous, why you so sure that buffers contain at least one object?", "url": "https://github.com/apache/flink/pull/11877#discussion_r661592466", "createdAt": "2021-06-30T15:36:17Z", "author": {"login": "akalash"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java", "diffHunk": "@@ -513,19 +514,20 @@ private void increaseBuffersInBacklog(BufferConsumer buffer) {\n         }\n     }\n \n-    /**\n-     * Gets the number of non-event buffers in this subpartition.\n-     *\n-     * <p><strong>Beware:</strong> This method should only be used in tests in non-concurrent access\n-     * scenarios since it does not make any concurrency guarantees.\n-     */\n-    @SuppressWarnings(\"FieldAccessNotGuarded\")\n-    @VisibleForTesting\n+    /** Gets the number of non-event buffers in this subpartition. */\n     public int getBuffersInBacklog() {\n-        if (flushRequested || isFinished) {\n-            return buffersInBacklog;\n-        } else {\n-            return Math.max(buffersInBacklog - 1, 0);\n+        synchronized (buffers) {\n+            if (isBlocked || buffers.isEmpty()) {\n+                return 0;\n+            }\n+\n+            if (flushRequested\n+                    || isFinished\n+                    || !checkNotNull(buffers.peekLast()).getBufferConsumer().isBuffer()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTk5OTc0MQ==", "bodyText": "In the previous if block in this method, we have already filtered the case when the buffer queue is empty.", "url": "https://github.com/apache/flink/pull/11877#discussion_r661999741", "createdAt": "2021-07-01T06:01:26Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java", "diffHunk": "@@ -513,19 +514,20 @@ private void increaseBuffersInBacklog(BufferConsumer buffer) {\n         }\n     }\n \n-    /**\n-     * Gets the number of non-event buffers in this subpartition.\n-     *\n-     * <p><strong>Beware:</strong> This method should only be used in tests in non-concurrent access\n-     * scenarios since it does not make any concurrency guarantees.\n-     */\n-    @SuppressWarnings(\"FieldAccessNotGuarded\")\n-    @VisibleForTesting\n+    /** Gets the number of non-event buffers in this subpartition. */\n     public int getBuffersInBacklog() {\n-        if (flushRequested || isFinished) {\n-            return buffersInBacklog;\n-        } else {\n-            return Math.max(buffersInBacklog - 1, 0);\n+        synchronized (buffers) {\n+            if (isBlocked || buffers.isEmpty()) {\n+                return 0;\n+            }\n+\n+            if (flushRequested\n+                    || isFinished\n+                    || !checkNotNull(buffers.peekLast()).getBufferConsumer().isBuffer()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTU5MjQ2Ng=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 61}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkNDIwMjQwOTIxOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNi0zMFQxNTo0MjowNVrOJ28tKg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wMVQwNjowOTo1M1rOJ3Vdcg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTU5NzQ4Mg==", "bodyText": "It seems that it is the wrong place for such condition. Logically, even if the subpartition is blocked it still has the buffers. But as I understand, specifically for the case where 'initialCredit == 0' it should return 0. So it needs to think how does it do better.", "url": "https://github.com/apache/flink/pull/11877#discussion_r661597482", "createdAt": "2021-06-30T15:42:05Z", "author": {"login": "akalash"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java", "diffHunk": "@@ -513,19 +514,20 @@ private void increaseBuffersInBacklog(BufferConsumer buffer) {\n         }\n     }\n \n-    /**\n-     * Gets the number of non-event buffers in this subpartition.\n-     *\n-     * <p><strong>Beware:</strong> This method should only be used in tests in non-concurrent access\n-     * scenarios since it does not make any concurrency guarantees.\n-     */\n-    @SuppressWarnings(\"FieldAccessNotGuarded\")\n-    @VisibleForTesting\n+    /** Gets the number of non-event buffers in this subpartition. */\n     public int getBuffersInBacklog() {\n-        if (flushRequested || isFinished) {\n-            return buffersInBacklog;\n-        } else {\n-            return Math.max(buffersInBacklog - 1, 0);\n+        synchronized (buffers) {\n+            if (isBlocked || buffers.isEmpty()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MjAwMzA1OA==", "bodyText": "After the channel is blocked, we do not need to allocated any credit at the downstream, because no buffer will be sent. As mentioned in your comment, if the initialCredit is 0, it should return 0. If the initialCredit is not 0, we always have exclusive credits, we still do not need allocate any floating credit. Maybe returning the actual value instead of 0 is a small improvement.", "url": "https://github.com/apache/flink/pull/11877#discussion_r662003058", "createdAt": "2021-07-01T06:09:53Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java", "diffHunk": "@@ -513,19 +514,20 @@ private void increaseBuffersInBacklog(BufferConsumer buffer) {\n         }\n     }\n \n-    /**\n-     * Gets the number of non-event buffers in this subpartition.\n-     *\n-     * <p><strong>Beware:</strong> This method should only be used in tests in non-concurrent access\n-     * scenarios since it does not make any concurrency guarantees.\n-     */\n-    @SuppressWarnings(\"FieldAccessNotGuarded\")\n-    @VisibleForTesting\n+    /** Gets the number of non-event buffers in this subpartition. */\n     public int getBuffersInBacklog() {\n-        if (flushRequested || isFinished) {\n-            return buffersInBacklog;\n-        } else {\n-            return Math.max(buffersInBacklog - 1, 0);\n+        synchronized (buffers) {\n+            if (isBlocked || buffers.isEmpty()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTU5NzQ4Mg=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 55}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkNDIwMjQyMTA4OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNi0zMFQxNTo0NDozMFrOJ2804A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wMVQwNjoxMDo1MFrOJ3VfFQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTU5OTQ1Ng==", "bodyText": "As I understand, initialCredit is an unchangeable value, and BufferManager and AvailableBufferQueue know this value so maybe it is better to avoid this parameter?", "url": "https://github.com/apache/flink/pull/11877#discussion_r661599456", "createdAt": "2021-06-30T15:44:30Z", "author": {"login": "akalash"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "diffHunk": "@@ -83,8 +84,13 @@ public BufferManager(\n     // ------------------------------------------------------------------------\n \n     @Nullable\n-    Buffer requestBuffer() {\n+    Buffer requestBuffer(int initialCredit) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MjAwMzQ3Nw==", "bodyText": "You are right, we can avoid this parameter.", "url": "https://github.com/apache/flink/pull/11877#discussion_r662003477", "createdAt": "2021-07-01T06:10:50Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "diffHunk": "@@ -83,8 +84,13 @@ public BufferManager(\n     // ------------------------------------------------------------------------\n \n     @Nullable\n-    Buffer requestBuffer() {\n+    Buffer requestBuffer(int initialCredit) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTU5OTQ1Ng=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkNDIwMjQzNzUzOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNi0zMFQxNTo0NzoxNVrOJ28_QQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wMVQwNjoxMjo0NlrOJ3ViVw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTYwMjExMw==", "bodyText": "I don't understand why initialCredit == 0 should be handled differently here. Even if initialCredit == 1 and the Buffer is requested we should decrease this value, or am I wrong?", "url": "https://github.com/apache/flink/pull/11877#discussion_r661602113", "createdAt": "2021-06-30T15:47:15Z", "author": {"login": "akalash"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "diffHunk": "@@ -83,8 +84,13 @@ public BufferManager(\n     // ------------------------------------------------------------------------\n \n     @Nullable\n-    Buffer requestBuffer() {\n+    Buffer requestBuffer(int initialCredit) {\n         synchronized (bufferQueue) {\n+            // decrease the number of buffers require to avoid the possibility of\n+            // allocating more than required buffers after the buffer is taken\n+            if (initialCredit == 0) {\n+                --numRequiredBuffers;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MjAwNDMxMQ==", "bodyText": "You are right, we should always decrease this value.", "url": "https://github.com/apache/flink/pull/11877#discussion_r662004311", "createdAt": "2021-07-01T06:12:46Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "diffHunk": "@@ -83,8 +84,13 @@ public BufferManager(\n     // ------------------------------------------------------------------------\n \n     @Nullable\n-    Buffer requestBuffer() {\n+    Buffer requestBuffer(int initialCredit) {\n         synchronized (bufferQueue) {\n+            // decrease the number of buffers require to avoid the possibility of\n+            // allocating more than required buffers after the buffer is taken\n+            if (initialCredit == 0) {\n+                --numRequiredBuffers;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTYwMjExMw=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 18}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkNDIwMjQ0NzM3OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNi0zMFQxNTo0OTowMlrOJ29FTA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wMVQwNjoxNToyOVrOJ3VnHQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTYwMzY2MA==", "bodyText": "As I understand, the negative number is still illegal. So maybe it makes sense to add checkArgument for numExclusiveBuffers < 0?", "url": "https://github.com/apache/flink/pull/11877#discussion_r661603660", "createdAt": "2021-06-30T15:49:02Z", "author": {"login": "akalash"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "diffHunk": "@@ -130,11 +136,11 @@ private boolean shouldContinueRequest(BufferPool bufferPool) {\n \n     /** Requests exclusive buffers from the provider. */\n     void requestExclusiveBuffers(int numExclusiveBuffers) throws IOException {\n-        Collection<MemorySegment> segments = globalPool.requestMemorySegments(numExclusiveBuffers);\n-        checkArgument(\n-                !segments.isEmpty(),\n-                \"The number of exclusive buffers per channel should be larger than 0.\");\n+        if (numExclusiveBuffers <= 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MjAwNTUzMw==", "bodyText": "You are right, I will add a checkArgument.", "url": "https://github.com/apache/flink/pull/11877#discussion_r662005533", "createdAt": "2021-07-01T06:15:29Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "diffHunk": "@@ -130,11 +136,11 @@ private boolean shouldContinueRequest(BufferPool bufferPool) {\n \n     /** Requests exclusive buffers from the provider. */\n     void requestExclusiveBuffers(int numExclusiveBuffers) throws IOException {\n-        Collection<MemorySegment> segments = globalPool.requestMemorySegments(numExclusiveBuffers);\n-        checkArgument(\n-                !segments.isEmpty(),\n-                \"The number of exclusive buffers per channel should be larger than 0.\");\n+        if (numExclusiveBuffers <= 0) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTYwMzY2MA=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkNDIwMjQ1Njg0OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNi0zMFQxNTo1MDo0OVrOJ29LNQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wMlQwMjowNDozM1rOJ3_VTw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTYwNTE3Mw==", "bodyText": "Can you explain what kind of deadlock can happen? Between LocalBufferPool and BufferManager?", "url": "https://github.com/apache/flink/pull/11877#discussion_r661605173", "createdAt": "2021-06-30T15:50:49Z", "author": {"login": "akalash"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "diffHunk": "@@ -215,9 +221,15 @@ public void recycle(MemorySegment segment) {\n     }\n \n     void releaseFloatingBuffers() {\n+        Queue<Buffer> buffers;\n         synchronized (bufferQueue) {\n             numRequiredBuffers = 0;\n-            bufferQueue.releaseFloatingBuffers();\n+            buffers = bufferQueue.clearFloatingBuffers();\n+        }\n+\n+        // recycle all buffers out of the synchronization block to avoid dead lock", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MjAxMDQ0NA==", "bodyText": "Each RemoteInputChannel has its own BufferManager and bufferQueue, floating buffers recycled by one RemoteInputChannel can be assigned to other RemoteInputChannels directly and the buffer assignment also need to sync the bufferQueue object. Besides, different RemoteInputChannels may recycle buffers simultaneously, which means we may need to lock two bufferQueue objects of different RemoteInputChannels simultaneously in the reverse order. I already encountered this dead lock when running test.", "url": "https://github.com/apache/flink/pull/11877#discussion_r662010444", "createdAt": "2021-07-01T06:26:06Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "diffHunk": "@@ -215,9 +221,15 @@ public void recycle(MemorySegment segment) {\n     }\n \n     void releaseFloatingBuffers() {\n+        Queue<Buffer> buffers;\n         synchronized (bufferQueue) {\n             numRequiredBuffers = 0;\n-            bufferQueue.releaseFloatingBuffers();\n+            buffers = bufferQueue.clearFloatingBuffers();\n+        }\n+\n+        // recycle all buffers out of the synchronization block to avoid dead lock", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTYwNTE3Mw=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MjIzOTA2Mg==", "bodyText": "As I understand from your explanation, it relates to this BufferManager#notifyBufferAvailable. But I still don't get which threads can call the releaseFloatingBuffers simultaneously. It is not so important, but just for curiosity if you have the stacktrace of this deadlock can you share it with me(or just tell me which test)?\nAnyway, your changes look correct here.", "url": "https://github.com/apache/flink/pull/11877#discussion_r662239062", "createdAt": "2021-07-01T12:19:58Z", "author": {"login": "akalash"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "diffHunk": "@@ -215,9 +221,15 @@ public void recycle(MemorySegment segment) {\n     }\n \n     void releaseFloatingBuffers() {\n+        Queue<Buffer> buffers;\n         synchronized (bufferQueue) {\n             numRequiredBuffers = 0;\n-            bufferQueue.releaseFloatingBuffers();\n+            buffers = bufferQueue.clearFloatingBuffers();\n+        }\n+\n+        // recycle all buffers out of the synchronization block to avoid dead lock", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTYwNTE3Mw=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MjY4OTEwMw==", "bodyText": "It is the new logic added by this PR causes the problem. RemoteInputChannel#onBlockingUpstream will call BufferManager#releaseFloatingBuffers in netty thread and different RemoteInputChannels can have different netty thread.", "url": "https://github.com/apache/flink/pull/11877#discussion_r662689103", "createdAt": "2021-07-02T02:04:33Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "diffHunk": "@@ -215,9 +221,15 @@ public void recycle(MemorySegment segment) {\n     }\n \n     void releaseFloatingBuffers() {\n+        Queue<Buffer> buffers;\n         synchronized (bufferQueue) {\n             numRequiredBuffers = 0;\n-            bufferQueue.releaseFloatingBuffers();\n+            buffers = bufferQueue.clearFloatingBuffers();\n+        }\n+\n+        // recycle all buffers out of the synchronization block to avoid dead lock", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTYwNTE3Mw=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 50}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkNDIwMjQ2NTA4OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/LocalInputChannel.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNi0zMFQxNTo1MjoxN1rOJ29QZg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wMVQwNjoyNzoyOVrOJ3V_Eg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTYwNjUwMg==", "bodyText": "The same question that earlier - is this bug? or where did we recycle the buffer before this changes?", "url": "https://github.com/apache/flink/pull/11877#discussion_r661606502", "createdAt": "2021-06-30T15:52:17Z", "author": {"login": "akalash"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/LocalInputChannel.java", "diffHunk": "@@ -265,6 +265,13 @@ public void run() {\n                 channelInfo,\n                 channelStatePersister,\n                 next.getSequenceNumber());\n+\n+        // ignore the empty buffer directly\n+        if (buffer.readableBytes() == 0) {\n+            buffer.recycleBuffer();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MjAxMTY2Ng==", "bodyText": "Before this change, the buffer is recycled in the pollBuffer method of Subpartition because no empty buffer is sent.", "url": "https://github.com/apache/flink/pull/11877#discussion_r662011666", "createdAt": "2021-07-01T06:27:29Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/LocalInputChannel.java", "diffHunk": "@@ -265,6 +265,13 @@ public void run() {\n                 channelInfo,\n                 channelStatePersister,\n                 next.getSequenceNumber());\n+\n+        // ignore the empty buffer directly\n+        if (buffer.readableBytes() == 0) {\n+            buffer.recycleBuffer();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTYwNjUwMg=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkNDIwMjQ5MDgzOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/LocalInputChannel.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNi0zMFQxNTo1NzowNlrOJ29glw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wMVQwNjoyODozNFrOJ3WC-w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTYxMDY0Nw==", "bodyText": "How is it even possible to get an empty buffer? Who is sending it?", "url": "https://github.com/apache/flink/pull/11877#discussion_r661610647", "createdAt": "2021-06-30T15:57:06Z", "author": {"login": "akalash"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/LocalInputChannel.java", "diffHunk": "@@ -265,6 +265,13 @@ public void run() {\n                 channelInfo,\n                 channelStatePersister,\n                 next.getSequenceNumber());\n+\n+        // ignore the empty buffer directly\n+        if (buffer.readableBytes() == 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MjAxMjY2Nw==", "bodyText": "After this change, we can poll an empty buffer from the Subpartition of the upstream task.", "url": "https://github.com/apache/flink/pull/11877#discussion_r662012667", "createdAt": "2021-07-01T06:28:34Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/LocalInputChannel.java", "diffHunk": "@@ -265,6 +265,13 @@ public void run() {\n                 channelInfo,\n                 channelStatePersister,\n                 next.getSequenceNumber());\n+\n+        // ignore the empty buffer directly\n+        if (buffer.readableBytes() == 0) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTYxMDY0Nw=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkNDIwMjUwNzA1OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNi0zMFQxNjowMDoyMFrOJ29qkQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wMVQwNjozMzoyNFrOJ3WQnA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTYxMzIwMQ==", "bodyText": "Why can not we do the same thing for any number of credits not only for initialCredit == 0? Or does it slow down the load after resuming?", "url": "https://github.com/apache/flink/pull/11877#discussion_r661613201", "createdAt": "2021-06-30T16:00:20Z", "author": {"login": "akalash"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "diffHunk": "@@ -357,11 +359,26 @@ public void resumeConsumption() throws IOException {\n         checkState(!isReleased.get(), \"Channel released.\");\n         checkPartitionRequestQueueInitialized();\n \n+        if (initialCredit == 0) {\n+            unannouncedCredit.set(0);\n+        }\n+\n         // notifies the producer that this channel is ready to\n         // unblock from checkpoint and resume data consumption\n         partitionRequestClient.resumeConsumption(this);\n     }\n \n+    private void onBlockingUpstream() {\n+        if (initialCredit == 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MjAxNjE1Ng==", "bodyText": "I think it does not slow down the load after resuming. It is just for the simplicity of handling unannounced credit. Maybe we have already announced the credits to the producer.", "url": "https://github.com/apache/flink/pull/11877#discussion_r662016156", "createdAt": "2021-07-01T06:33:24Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "diffHunk": "@@ -357,11 +359,26 @@ public void resumeConsumption() throws IOException {\n         checkState(!isReleased.get(), \"Channel released.\");\n         checkPartitionRequestQueueInitialized();\n \n+        if (initialCredit == 0) {\n+            unannouncedCredit.set(0);\n+        }\n+\n         // notifies the producer that this channel is ready to\n         // unblock from checkpoint and resume data consumption\n         partitionRequestClient.resumeConsumption(this);\n     }\n \n+    private void onBlockingUpstream() {\n+        if (initialCredit == 0) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTYxMzIwMQ=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkNDIwMjUxNjgwOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "isResolved": false, "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNi0zMFQxNjowMjoxNFrOJ29wrw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wOFQxNjoxMTowNlrOJ7d1Kg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTYxNDc2Nw==", "bodyText": "Do we need to do so because we released all buffers in onBlockingUpstream? If so can we hold this code in one place, ex. to move it into onBlockingUpstream?", "url": "https://github.com/apache/flink/pull/11877#discussion_r661614767", "createdAt": "2021-06-30T16:02:14Z", "author": {"login": "akalash"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "diffHunk": "@@ -357,11 +359,26 @@ public void resumeConsumption() throws IOException {\n         checkState(!isReleased.get(), \"Channel released.\");\n         checkPartitionRequestQueueInitialized();\n \n+        if (initialCredit == 0) {\n+            unannouncedCredit.set(0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MjAyMDQ3Mg==", "bodyText": "Doing this in the onBlockingUpstream method can guarantee that after resumeConsumption the unannouncedCredit is in a clean state. Because the unannouncedCredit may get increased after that if there is any new available floating credit.", "url": "https://github.com/apache/flink/pull/11877#discussion_r662020472", "createdAt": "2021-07-01T06:42:26Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "diffHunk": "@@ -357,11 +359,26 @@ public void resumeConsumption() throws IOException {\n         checkState(!isReleased.get(), \"Channel released.\");\n         checkPartitionRequestQueueInitialized();\n \n+        if (initialCredit == 0) {\n+            unannouncedCredit.set(0);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTYxNDc2Nw=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDY4Mjk4OA==", "bodyText": "But how can this floating credit be assigned to this blocked RemoteInputChannel? Wouldn't it cause the same deadlock, when floating buffers are assigned to blocked channels and job/task can not make any progress?\nIt sounds like maybe this should have been handled sooner when trying to increase unannouncedCredit?", "url": "https://github.com/apache/flink/pull/11877#discussion_r664682988", "createdAt": "2021-07-06T15:54:48Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "diffHunk": "@@ -357,11 +359,26 @@ public void resumeConsumption() throws IOException {\n         checkState(!isReleased.get(), \"Channel released.\");\n         checkPartitionRequestQueueInitialized();\n \n+        if (initialCredit == 0) {\n+            unannouncedCredit.set(0);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTYxNDc2Nw=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTA2ODA0OA==", "bodyText": "This because RemoteInputChannel#notifyBufferAvailable which increases unannouncedCredit and floating buffer assignment is not an atomic operation. There is a possibility:\n\nthe floating buffer is assigned;\nthe floating buffer is released because of receiving an event which blocks the channel;\nthe notifyBufferAvailable is called and the unannouncedCredit is increased.\n\nDo you mean we should make RemoteInputChannel#notifyBufferAvailable and floating buffer assignment an atomic operation?", "url": "https://github.com/apache/flink/pull/11877#discussion_r665068048", "createdAt": "2021-07-07T06:04:44Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "diffHunk": "@@ -357,11 +359,26 @@ public void resumeConsumption() throws IOException {\n         checkState(!isReleased.get(), \"Channel released.\");\n         checkPartitionRequestQueueInitialized();\n \n+        if (initialCredit == 0) {\n+            unannouncedCredit.set(0);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTYxNDc2Nw=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTM5NDU1MA==", "bodyText": "Something sounds wrong here. The race condition that you described above, does it mean that unannouncedCredit can be out of sync? That we in reality have released all floating buffers, channel is blocked, but actually unannouncedCredit > 0? And it's only fixed after calling resumeConsumption()?\nAnd as I understand it, without your change, this problem doesn't exist, as floating buffers are kept assigned to the blocked channel and the unannouncedCredit (or maybe even assigned AddCredit that might have been sent to the upstream node)  are consistent with the reality. Also those assigned floating buffers are not used because channel is blocked, but that is not a big issue, because thanks to the exclusive buffers, other channels can make a progress?", "url": "https://github.com/apache/flink/pull/11877#discussion_r665394550", "createdAt": "2021-07-07T13:54:39Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "diffHunk": "@@ -357,11 +359,26 @@ public void resumeConsumption() throws IOException {\n         checkState(!isReleased.get(), \"Channel released.\");\n         checkPartitionRequestQueueInitialized();\n \n+        if (initialCredit == 0) {\n+            unannouncedCredit.set(0);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTYxNDc2Nw=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTgxNDMzNg==", "bodyText": "Something sounds wrong here. The race condition that you described above, does it mean that unannouncedCredit can be out of sync? That we in reality have released all floating buffers, channel is blocked, but actually unannouncedCredit > 0? And it's only fixed after calling resumeConsumption()?\n\nYes, exactly.\n\nAnd as I understand it, without your change, this problem doesn't exist, as floating buffers are kept assigned to the blocked channel and the unannouncedCredit (or maybe even assigned AddCredit that might have been sent to the upstream node) are consistent with the reality. Also those assigned floating buffers are not used because channel is blocked, but that is not a big issue, because thanks to the exclusive buffers, other channels can make a progress?\n\nThat only happens when the exclusive credit is 0. If the exclusive credit is not 0, the allocated floating buffers will not be released and if the exclusive credit is 0, we release the floating buffers allocated to let other channel use them to avoid deadlock, an extreme case is that we only have 1 floating buffer and no exclusive buffer. At downstream, the unannounced credit will be reset, at the upstream, the available credit is also reset to 0 when resume consumption.", "url": "https://github.com/apache/flink/pull/11877#discussion_r665814336", "createdAt": "2021-07-08T01:53:10Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "diffHunk": "@@ -357,11 +359,26 @@ public void resumeConsumption() throws IOException {\n         checkState(!isReleased.get(), \"Channel released.\");\n         checkPartitionRequestQueueInitialized();\n \n+        if (initialCredit == 0) {\n+            unannouncedCredit.set(0);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTYxNDc2Nw=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NjMzNDUwNg==", "bodyText": "Ok, can you at least add a comment explaining why this is set to 0 here?", "url": "https://github.com/apache/flink/pull/11877#discussion_r666334506", "createdAt": "2021-07-08T16:11:06Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "diffHunk": "@@ -357,11 +359,26 @@ public void resumeConsumption() throws IOException {\n         checkState(!isReleased.get(), \"Channel released.\");\n         checkPartitionRequestQueueInitialized();\n \n+        if (initialCredit == 0) {\n+            unannouncedCredit.set(0);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTYxNDc2Nw=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkNDIwMjUzNDIwOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/CreditBasedSequenceNumberingViewReader.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNi0zMFQxNjowNTo0NVrOJ297dg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wMVQwNjo0MzowNVrOJ3Wilw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTYxNzUyNg==", "bodyText": "Do we do it because we know that all floating buffers would be released before the checkpoint when initialCredit == 0?", "url": "https://github.com/apache/flink/pull/11877#discussion_r661617526", "createdAt": "2021-06-30T16:05:45Z", "author": {"login": "akalash"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/CreditBasedSequenceNumberingViewReader.java", "diffHunk": "@@ -100,8 +106,19 @@ public void addCredit(int creditDeltas) {\n         numCreditsAvailable += creditDeltas;\n     }\n \n+    @Override\n+    public boolean needAnnounceBacklog() {\n+        return initialCredit == 0 && numCreditsAvailable == 0;\n+    }\n+\n     @Override\n     public void resumeConsumption() {\n+        if (initialCredit == 0) {\n+            // reset available credit if no exclusive buffer is available at the\n+            // consumer side for all floating buffers must have been released\n+            numCreditsAvailable = 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MjAyMDc1OQ==", "bodyText": "Yes, you are right.", "url": "https://github.com/apache/flink/pull/11877#discussion_r662020759", "createdAt": "2021-07-01T06:43:05Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/CreditBasedSequenceNumberingViewReader.java", "diffHunk": "@@ -100,8 +106,19 @@ public void addCredit(int creditDeltas) {\n         numCreditsAvailable += creditDeltas;\n     }\n \n+    @Override\n+    public boolean needAnnounceBacklog() {\n+        return initialCredit == 0 && numCreditsAvailable == 0;\n+    }\n+\n     @Override\n     public void resumeConsumption() {\n+        if (initialCredit == 0) {\n+            // reset available credit if no exclusive buffer is available at the\n+            // consumer side for all floating buffers must have been released\n+            numCreditsAvailable = 0;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MTYxNzUyNg=="}, "originalCommit": {"oid": "2c49d1a8cee6485e8f367190f152e58960c901ff"}, "originalPosition": 43}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkNDIyMzA2NTY0OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/CreditBasedPartitionRequestClientHandler.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wNlQxNTowODo0NlrOJ52p7A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wN1QwNjozMToxOVrOJ6RSsQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDY0NDA3Ng==", "bodyText": "Why is this an issue? Is this an independent optimisation or is it relate with the other parts of the PR?", "url": "https://github.com/apache/flink/pull/11877#discussion_r664644076", "createdAt": "2021-07-06T15:08:46Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/CreditBasedPartitionRequestClientHandler.java", "diffHunk": "@@ -433,8 +459,8 @@ public void operationComplete(ChannelFuture future) throws Exception {\n \n         @Override\n         public Object buildMessage() {\n-            return new AddCredit(\n-                    inputChannel.getAndResetUnannouncedCredit(), inputChannel.getInputChannelId());\n+            int credits = inputChannel.getAndResetUnannouncedCredit();\n+            return credits > 0 ? new AddCredit(credits, inputChannel.getInputChannelId()) : null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "028f2185c0bb15c542006065550d04f69b0b06bd"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDY1MDU4Nw==", "bodyText": "Secondly, return type of the buildMessage() is not annotated @Nullable, so if we need this code for correctness we need to add this annotation (but it would be better to avoid null here)", "url": "https://github.com/apache/flink/pull/11877#discussion_r664650587", "createdAt": "2021-07-06T15:16:14Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/CreditBasedPartitionRequestClientHandler.java", "diffHunk": "@@ -433,8 +459,8 @@ public void operationComplete(ChannelFuture future) throws Exception {\n \n         @Override\n         public Object buildMessage() {\n-            return new AddCredit(\n-                    inputChannel.getAndResetUnannouncedCredit(), inputChannel.getInputChannelId());\n+            int credits = inputChannel.getAndResetUnannouncedCredit();\n+            return credits > 0 ? new AddCredit(credits, inputChannel.getInputChannelId()) : null;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDY0NDA3Ng=="}, "originalCommit": {"oid": "028f2185c0bb15c542006065550d04f69b0b06bd"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTA4MDE2NA==", "bodyText": "It is relevant to this PR, it is because we add the reset logic in RemoteInputChannel#resumeConsumption method.\n        if (initialCredit == 0) {\n            unannouncedCredit.set(0);\n        }", "url": "https://github.com/apache/flink/pull/11877#discussion_r665080164", "createdAt": "2021-07-07T06:30:48Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/CreditBasedPartitionRequestClientHandler.java", "diffHunk": "@@ -433,8 +459,8 @@ public void operationComplete(ChannelFuture future) throws Exception {\n \n         @Override\n         public Object buildMessage() {\n-            return new AddCredit(\n-                    inputChannel.getAndResetUnannouncedCredit(), inputChannel.getInputChannelId());\n+            int credits = inputChannel.getAndResetUnannouncedCredit();\n+            return credits > 0 ? new AddCredit(credits, inputChannel.getInputChannelId()) : null;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDY0NDA3Ng=="}, "originalCommit": {"oid": "028f2185c0bb15c542006065550d04f69b0b06bd"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTA4MDQ5Nw==", "bodyText": "I will add a @nullable annotation.", "url": "https://github.com/apache/flink/pull/11877#discussion_r665080497", "createdAt": "2021-07-07T06:31:19Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/CreditBasedPartitionRequestClientHandler.java", "diffHunk": "@@ -433,8 +459,8 @@ public void operationComplete(ChannelFuture future) throws Exception {\n \n         @Override\n         public Object buildMessage() {\n-            return new AddCredit(\n-                    inputChannel.getAndResetUnannouncedCredit(), inputChannel.getInputChannelId());\n+            int credits = inputChannel.getAndResetUnannouncedCredit();\n+            return credits > 0 ? new AddCredit(credits, inputChannel.getInputChannelId()) : null;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDY0NDA3Ng=="}, "originalCommit": {"oid": "028f2185c0bb15c542006065550d04f69b0b06bd"}, "originalPosition": 63}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkNDIyMzExNDg4OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/NetworkBufferAllocator.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wNlQxNToxNzo0NVrOJ53IIA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wN1QwNjozNToyNFrOJ6RbNg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDY1MTgwOA==", "bodyText": "@Nullable\nDo we really need to support null here? Can not we return empty Buffer?", "url": "https://github.com/apache/flink/pull/11877#discussion_r664651808", "createdAt": "2021-07-06T15:17:45Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/NetworkBufferAllocator.java", "diffHunk": "@@ -69,6 +69,9 @@ Buffer allocatePooledNetworkBuffer(InputChannelID receiverId) {\n      * @return The un-pooled network buffer.\n      */\n     Buffer allocateUnPooledNetworkBuffer(int size, Buffer.DataType dataType) {\n+        if (size <= 0) {\n+            return null;\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "028f2185c0bb15c542006065550d04f69b0b06bd"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTA4MjY3OA==", "bodyText": "This method is used to allocate unpooled buffer for event, the size must be positive. I will replace it with a argument check.", "url": "https://github.com/apache/flink/pull/11877#discussion_r665082678", "createdAt": "2021-07-07T06:35:24Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/NetworkBufferAllocator.java", "diffHunk": "@@ -69,6 +69,9 @@ Buffer allocatePooledNetworkBuffer(InputChannelID receiverId) {\n      * @return The un-pooled network buffer.\n      */\n     Buffer allocateUnPooledNetworkBuffer(int size, Buffer.DataType dataType) {\n+        if (size <= 0) {\n+            return null;\n+        }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDY1MTgwOA=="}, "originalCommit": {"oid": "028f2185c0bb15c542006065550d04f69b0b06bd"}, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkNDIyMzE2NTg1OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java", "isResolved": true, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wNlQxNToyNzoxNlrOJ53oGw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wOFQwMjo0MjowMFrOJ6_ACw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDY1OTk5NQ==", "bodyText": "Instead of this check here, can not we add similar check outside of the while (...) loop? For example replace:\nif (buffer == null) {\n    return null;\n}\n\nwith something like:\nif (buffer == null) {\n   if (buffersPerChannel == 0) {\n       return EMPTY_BUFFER;\n    }\n    else {\n       return null;\n    }\n}\n\n?\nThat way, we would avoid sending empty buffer if there are still more buffers in the backlog that are already enqueued?", "url": "https://github.com/apache/flink/pull/11877#discussion_r664659995", "createdAt": "2021-07-06T15:27:16Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java", "diffHunk": "@@ -315,6 +326,17 @@ BufferAndBacklog pollBuffer() {\n                 if (buffer.readableBytes() > 0) {\n                     break;\n                 }\n+\n+                // if we have an empty finished buffer and the exclusive credit is 0, we just return\n+                // the empty buffer so that the downstream task can release the allocated credit for\n+                // this empty buffer, this happens in two main scenarios currently:\n+                // 1. all data of a buffer builder has been read and after that the buffer builder\n+                // is finished\n+                // 2. in approximate recovery mode, a partial record takes a whole buffer builder\n+                if (buffersPerChannel == 0 && bufferConsumer.isFinished()) {\n+                    break;\n+                }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "028f2185c0bb15c542006065550d04f69b0b06bd"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTA4NDYyOQ==", "bodyText": "I am afraid we can not skip the empty buffer is the exclusive credit is 0, because we may already allocate the floating credit for it and we can not just release the floating credit because we may already announce the credit to the upstream.", "url": "https://github.com/apache/flink/pull/11877#discussion_r665084629", "createdAt": "2021-07-07T06:39:16Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java", "diffHunk": "@@ -315,6 +326,17 @@ BufferAndBacklog pollBuffer() {\n                 if (buffer.readableBytes() > 0) {\n                     break;\n                 }\n+\n+                // if we have an empty finished buffer and the exclusive credit is 0, we just return\n+                // the empty buffer so that the downstream task can release the allocated credit for\n+                // this empty buffer, this happens in two main scenarios currently:\n+                // 1. all data of a buffer builder has been read and after that the buffer builder\n+                // is finished\n+                // 2. in approximate recovery mode, a partial record takes a whole buffer builder\n+                if (buffersPerChannel == 0 && bufferConsumer.isFinished()) {\n+                    break;\n+                }\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDY1OTk5NQ=="}, "originalCommit": {"oid": "028f2185c0bb15c542006065550d04f69b0b06bd"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTA5MjA4NA==", "bodyText": "I was not suggesting that. I was suggesting to:\n\nwe would avoid sending empty buffer if there are still more buffers in the backlog that are already enqueued", "url": "https://github.com/apache/flink/pull/11877#discussion_r665092084", "createdAt": "2021-07-07T06:52:53Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java", "diffHunk": "@@ -315,6 +326,17 @@ BufferAndBacklog pollBuffer() {\n                 if (buffer.readableBytes() > 0) {\n                     break;\n                 }\n+\n+                // if we have an empty finished buffer and the exclusive credit is 0, we just return\n+                // the empty buffer so that the downstream task can release the allocated credit for\n+                // this empty buffer, this happens in two main scenarios currently:\n+                // 1. all data of a buffer builder has been read and after that the buffer builder\n+                // is finished\n+                // 2. in approximate recovery mode, a partial record takes a whole buffer builder\n+                if (buffersPerChannel == 0 && bufferConsumer.isFinished()) {\n+                    break;\n+                }\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDY1OTk5NQ=="}, "originalCommit": {"oid": "028f2185c0bb15c542006065550d04f69b0b06bd"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTIyMjQ5Nw==", "bodyText": "I guess I did not fully understand the comment, could you please explain a bit more? From my understand, even there are multiple buffers in the queue and the first is empty, if we do not send the first empty buffer out, how could we guarantee the downstream tasks are not allocating too many buffers if the exclusive credit is 0? For example, if there is two buffers, the first one is empty and the second one is an event, we may already announce 1 backlog to the downstream task and if we send the event directly, dose that mean we can not release the credit already allocated? Correct me if I am wrong.", "url": "https://github.com/apache/flink/pull/11877#discussion_r665222497", "createdAt": "2021-07-07T09:54:11Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java", "diffHunk": "@@ -315,6 +326,17 @@ BufferAndBacklog pollBuffer() {\n                 if (buffer.readableBytes() > 0) {\n                     break;\n                 }\n+\n+                // if we have an empty finished buffer and the exclusive credit is 0, we just return\n+                // the empty buffer so that the downstream task can release the allocated credit for\n+                // this empty buffer, this happens in two main scenarios currently:\n+                // 1. all data of a buffer builder has been read and after that the buffer builder\n+                // is finished\n+                // 2. in approximate recovery mode, a partial record takes a whole buffer builder\n+                if (buffersPerChannel == 0 && bufferConsumer.isFinished()) {\n+                    break;\n+                }\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDY1OTk5NQ=="}, "originalCommit": {"oid": "028f2185c0bb15c542006065550d04f69b0b06bd"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTM0MjA3NQ==", "bodyText": "If there are two buffers, first is empty the second one can be:\n\nnon empty buffer\nempty buffer\nevent\n\nIn all cases, instead of sending this first empty buffer with the backlog information, as far as I understand, it should be possible to just send any of the above instead with the updated backlog information. From the downstream node perspective, it should make no difference if we hide this empty buffer. If this is 2nd or 3rd case, we should be able to release the floating buffer regardless of that, shouldn't we?", "url": "https://github.com/apache/flink/pull/11877#discussion_r665342075", "createdAt": "2021-07-07T12:54:29Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java", "diffHunk": "@@ -315,6 +326,17 @@ BufferAndBacklog pollBuffer() {\n                 if (buffer.readableBytes() > 0) {\n                     break;\n                 }\n+\n+                // if we have an empty finished buffer and the exclusive credit is 0, we just return\n+                // the empty buffer so that the downstream task can release the allocated credit for\n+                // this empty buffer, this happens in two main scenarios currently:\n+                // 1. all data of a buffer builder has been read and after that the buffer builder\n+                // is finished\n+                // 2. in approximate recovery mode, a partial record takes a whole buffer builder\n+                if (buffersPerChannel == 0 && bufferConsumer.isFinished()) {\n+                    break;\n+                }\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDY1OTk5NQ=="}, "originalCommit": {"oid": "028f2185c0bb15c542006065550d04f69b0b06bd"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTgyOTM4Nw==", "bodyText": "Let's maybe focus on the 3rd case first and we assume that the exclusive credit is 0.\n\nThere are only one data buffer in the queue.\nFlush triggered.\nAll data of the first buffer is committed but the buffer is still not finished.\nAll data of the buffer is consumed by pollBuffer and the available credit becomes 0.\nThe first buffer is finished, the second event is added and the data available notification is triggered.\nThe upstream announces backlog to the downstream to request a credit.\nThe upstream receives available credit and start to pollBuffer.\nSkip the first empty buffer and send the second event.\nThe downstream receive the event but the event does not consume any credit.\n\nDo you mean we should change the current logic and release the floating buffer for event in some cases (including reduce the available credit by 1 at the upstream, currently the available credit is not decreased for event)? If there are multiple empty buffers, should we just skip the first one or should we skip all?", "url": "https://github.com/apache/flink/pull/11877#discussion_r665829387", "createdAt": "2021-07-08T02:42:00Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java", "diffHunk": "@@ -315,6 +326,17 @@ BufferAndBacklog pollBuffer() {\n                 if (buffer.readableBytes() > 0) {\n                     break;\n                 }\n+\n+                // if we have an empty finished buffer and the exclusive credit is 0, we just return\n+                // the empty buffer so that the downstream task can release the allocated credit for\n+                // this empty buffer, this happens in two main scenarios currently:\n+                // 1. all data of a buffer builder has been read and after that the buffer builder\n+                // is finished\n+                // 2. in approximate recovery mode, a partial record takes a whole buffer builder\n+                if (buffersPerChannel == 0 && bufferConsumer.isFinished()) {\n+                    break;\n+                }\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDY1OTk5NQ=="}, "originalCommit": {"oid": "028f2185c0bb15c542006065550d04f69b0b06bd"}, "originalPosition": 49}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkNDIyMzE3OTg0OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wNlQxNToyOTo0MVrOJ53wiQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wN1QwNjozOTo0OFrOJ6RjzQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDY2MjE1Mw==", "bodyText": "pollBuffer() would be acquiring the lock twice, wouldn't it? If you really need to make this method public you should keep private int getBuffersInBacklogUnsafe() without any synchronisation.", "url": "https://github.com/apache/flink/pull/11877#discussion_r664662153", "createdAt": "2021-07-06T15:29:41Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java", "diffHunk": "@@ -517,19 +539,20 @@ private void increaseBuffersInBacklog(BufferConsumer buffer) {\n         }\n     }\n \n-    /**\n-     * Gets the number of non-event buffers in this subpartition.\n-     *\n-     * <p><strong>Beware:</strong> This method should only be used in tests in non-concurrent access\n-     * scenarios since it does not make any concurrency guarantees.\n-     */\n-    @SuppressWarnings(\"FieldAccessNotGuarded\")\n-    @VisibleForTesting\n+    /** Gets the number of non-event buffers in this subpartition. */\n     public int getBuffersInBacklog() {\n-        if (flushRequested || isFinished) {\n-            return buffersInBacklog;\n-        } else {\n-            return Math.max(buffersInBacklog - 1, 0);\n+        synchronized (buffers) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "028f2185c0bb15c542006065550d04f69b0b06bd"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTA4NDg3Nw==", "bodyText": "I will add a private int getBuffersInBacklogUnsafe() method", "url": "https://github.com/apache/flink/pull/11877#discussion_r665084877", "createdAt": "2021-07-07T06:39:48Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java", "diffHunk": "@@ -517,19 +539,20 @@ private void increaseBuffersInBacklog(BufferConsumer buffer) {\n         }\n     }\n \n-    /**\n-     * Gets the number of non-event buffers in this subpartition.\n-     *\n-     * <p><strong>Beware:</strong> This method should only be used in tests in non-concurrent access\n-     * scenarios since it does not make any concurrency guarantees.\n-     */\n-    @SuppressWarnings(\"FieldAccessNotGuarded\")\n-    @VisibleForTesting\n+    /** Gets the number of non-event buffers in this subpartition. */\n     public int getBuffersInBacklog() {\n-        if (flushRequested || isFinished) {\n-            return buffersInBacklog;\n-        } else {\n-            return Math.max(buffersInBacklog - 1, 0);\n+        synchronized (buffers) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDY2MjE1Mw=="}, "originalCommit": {"oid": "028f2185c0bb15c542006065550d04f69b0b06bd"}, "originalPosition": 71}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkNDIyMzI2NzMyOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wNlQxNTo0NjowOFrOJ54mGw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wNlQxNTo0NjowOFrOJ54mGw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDY3NTg2Nw==", "bodyText": "add the backlog value to the error message?", "url": "https://github.com/apache/flink/pull/11877#discussion_r664675867", "createdAt": "2021-07-06T15:46:08Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "diffHunk": "@@ -468,6 +485,11 @@ public void onBuffer(Buffer buffer, int sequenceNumber, int backlog) throws IOEx\n                 return;\n             }\n \n+            if (buffer.getDataType().isBlockingUpstream()) {\n+                onBlockingUpstream();\n+                checkArgument(backlog == 0, \"Illegal number of backlog.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "028f2185c0bb15c542006065550d04f69b0b06bd"}, "originalPosition": 60}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkNDIzMzg0ODg0OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wOFQxNTozMToyMlrOJ7b42A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wOFQxNTozMToyMlrOJ7b42A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NjMwMjY4MA==", "bodyText": "nit: Rename to getBuffersInBacklogUnsafe() (previously it was a private method just made @VisibleForTesting)", "url": "https://github.com/apache/flink/pull/11877#discussion_r666302680", "createdAt": "2021-07-08T15:31:22Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java", "diffHunk": "@@ -517,16 +520,16 @@ private void increaseBuffersInBacklog(BufferConsumer buffer) {\n         }\n     }\n \n-    /**\n-     * Gets the number of non-event buffers in this subpartition.\n-     *\n-     * <p><strong>Beware:</strong> This method should only be used in tests in non-concurrent access\n-     * scenarios since it does not make any concurrency guarantees.\n-     */\n-    @SuppressWarnings(\"FieldAccessNotGuarded\")\n-    @VisibleForTesting\n+    /** Gets the number of non-event buffers in this subpartition. */\n+    @Override\n     public int getBuffersInBacklog() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c9956bc098175364585e5661d5d4ca097b2fe876"}, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkNDIzNDA4ODQzOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java", "isResolved": false, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wOFQxNjoxOToyN1rOJ7eNow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wOVQwODoxMzo1MlrOJ7343g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NjM0MDc3MQ==", "bodyText": "I can not seem to respond in the previous thread, so I need to start a new one.\n\nLet's maybe focus on the 3rd case first and we assume that the exclusive credit is 0.\n\nThere are only one data buffer in the queue.\nFlush triggered.\nAll data of the first buffer is committed but the buffer is still not finished.\nAll data of the buffer is consumed by pollBuffer and the available credit becomes 0.\nThe first buffer is finished, the second event is added and the data available notification is triggered.\nThe upstream announces backlog to the downstream to request a credit.\nThe upstream receives available credit and start to pollBuffer.\nSkip the first empty buffer and send the second event.\nThe downstream receive the event but the event does not consume any credit.\n\nDo you mean we should change the current logic and release the floating buffer for event in some cases (including reduce the available credit by 1 at the upstream, currently the available credit is not decreased for event)?\n\nNo, but I think we could send this regardless if any is credit available or not as we are doing right now. I think we are also already attaching information about the backlog to such event. One thing to add (unless we are not doing it already) would be to use this backlog information, to maybe release floating buffers if backlog dropped to 0?\n\nIf there are multiple empty buffers, should we just skip the first one or should we skip all?\n\nWe could skip all of them, until we reach one of the three options:\n\nnon empty data buffer\nevent (check above)\nlast empty buffer, without any events after it - here we would indeed need to send that empty buffer", "url": "https://github.com/apache/flink/pull/11877#discussion_r666340771", "createdAt": "2021-07-08T16:19:27Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java", "diffHunk": "@@ -312,6 +323,16 @@ BufferAndBacklog pollBuffer() {\n                     decreaseBuffersInBacklogUnsafe(bufferConsumer.isBuffer());\n                 }\n \n+                // if we have an empty finished buffer and the exclusive credit is 0, we just return\n+                // the empty buffer so that the downstream task can release the allocated credit for\n+                // this empty buffer, this happens in two main scenarios currently:\n+                // 1. all data of a buffer builder has been read and after that the buffer builder\n+                // is finished\n+                // 2. in approximate recovery mode, a partial record takes a whole buffer builder\n+                if (buffersPerChannel == 0 && bufferConsumer.isFinished()) {\n+                    break;\n+                }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "faee760500feb1a2f793a6d691a1d061b1d17917"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NjYyNjg4Ng==", "bodyText": "One thing to add (unless we are not doing it already) would be to use this backlog information, to maybe release floating buffers if backlog dropped to 0?\n\nCurrently, we are not doing that. Actually, I think it is a little complicated to do so. Because we need to keep consistency between the sender side available credit and the receiver side floating buffers. If we just release the floating buffers at the receiver side, if the sender side available credit is not reset, then there is may data sent out without buffers at receiver side to receive them. If we also reset the available credit at the sender side when the backlog is 0, there is a possibility that some AddCredit messages are on the way and we are not resetting this part. Maybe one way is to not sending any data out after sending a buffer with 0 backlog at sender side, then the receivers clear all floating credits and send a reset message to the senders. Then the senders reset all available credits. This process is similar to the channel blocking and resumption. I think this is a little complicated and can incur extra overhead.\nWhat do you think? Or is there any simple way?", "url": "https://github.com/apache/flink/pull/11877#discussion_r666626886", "createdAt": "2021-07-09T02:19:00Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java", "diffHunk": "@@ -312,6 +323,16 @@ BufferAndBacklog pollBuffer() {\n                     decreaseBuffersInBacklogUnsafe(bufferConsumer.isBuffer());\n                 }\n \n+                // if we have an empty finished buffer and the exclusive credit is 0, we just return\n+                // the empty buffer so that the downstream task can release the allocated credit for\n+                // this empty buffer, this happens in two main scenarios currently:\n+                // 1. all data of a buffer builder has been read and after that the buffer builder\n+                // is finished\n+                // 2. in approximate recovery mode, a partial record takes a whole buffer builder\n+                if (buffersPerChannel == 0 && bufferConsumer.isFinished()) {\n+                    break;\n+                }\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NjM0MDc3MQ=="}, "originalCommit": {"oid": "faee760500feb1a2f793a6d691a1d061b1d17917"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NjY3Nzk5Nw==", "bodyText": "Yes, you are right. It wouldn't be that simple. In that case, how complicated would it be to optimise the code to skip the all of the empty buffers until:\n\nnon empty data buffer\nevent (then send empty buffer first)\nlast empty buffer, without any events after it - here we would indeed need to send that empty buffer\n\n?", "url": "https://github.com/apache/flink/pull/11877#discussion_r666677997", "createdAt": "2021-07-09T05:21:06Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java", "diffHunk": "@@ -312,6 +323,16 @@ BufferAndBacklog pollBuffer() {\n                     decreaseBuffersInBacklogUnsafe(bufferConsumer.isBuffer());\n                 }\n \n+                // if we have an empty finished buffer and the exclusive credit is 0, we just return\n+                // the empty buffer so that the downstream task can release the allocated credit for\n+                // this empty buffer, this happens in two main scenarios currently:\n+                // 1. all data of a buffer builder has been read and after that the buffer builder\n+                // is finished\n+                // 2. in approximate recovery mode, a partial record takes a whole buffer builder\n+                if (buffersPerChannel == 0 && bufferConsumer.isFinished()) {\n+                    break;\n+                }\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NjM0MDc3MQ=="}, "originalCommit": {"oid": "faee760500feb1a2f793a6d691a1d061b1d17917"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NjcyMzU0Mw==", "bodyText": "Currently, I can only come up with the following way, which depends on the downstream to reset the available credit of the upstream. This at least needs to add a special network message and propagating this message can incur extra overhead. If you think this is really important, I will spend some time to rethink about it and see if I can find a better way to solve it.\n\nMaybe one way is to not sending any data out after sending a buffer with 0 backlog at sender side, then the receivers clear all floating credits and send a reset message to the senders. Then the senders reset all available credits. This process is similar to the channel blocking and resumption.", "url": "https://github.com/apache/flink/pull/11877#discussion_r666723543", "createdAt": "2021-07-09T07:10:34Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java", "diffHunk": "@@ -312,6 +323,16 @@ BufferAndBacklog pollBuffer() {\n                     decreaseBuffersInBacklogUnsafe(bufferConsumer.isBuffer());\n                 }\n \n+                // if we have an empty finished buffer and the exclusive credit is 0, we just return\n+                // the empty buffer so that the downstream task can release the allocated credit for\n+                // this empty buffer, this happens in two main scenarios currently:\n+                // 1. all data of a buffer builder has been read and after that the buffer builder\n+                // is finished\n+                // 2. in approximate recovery mode, a partial record takes a whole buffer builder\n+                if (buffersPerChannel == 0 && bufferConsumer.isFinished()) {\n+                    break;\n+                }\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NjM0MDc3MQ=="}, "originalCommit": {"oid": "faee760500feb1a2f793a6d691a1d061b1d17917"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2Njc1MjExMw==", "bodyText": "Ok, let's go with the current way for now, as with buffersPerChannel == 0 check it's not that critical. But it would be nice if you could spend a little time thinking if we can improve this.", "url": "https://github.com/apache/flink/pull/11877#discussion_r666752113", "createdAt": "2021-07-09T07:58:53Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java", "diffHunk": "@@ -312,6 +323,16 @@ BufferAndBacklog pollBuffer() {\n                     decreaseBuffersInBacklogUnsafe(bufferConsumer.isBuffer());\n                 }\n \n+                // if we have an empty finished buffer and the exclusive credit is 0, we just return\n+                // the empty buffer so that the downstream task can release the allocated credit for\n+                // this empty buffer, this happens in two main scenarios currently:\n+                // 1. all data of a buffer builder has been read and after that the buffer builder\n+                // is finished\n+                // 2. in approximate recovery mode, a partial record takes a whole buffer builder\n+                if (buffersPerChannel == 0 && bufferConsumer.isFinished()) {\n+                    break;\n+                }\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NjM0MDc3MQ=="}, "originalCommit": {"oid": "faee760500feb1a2f793a6d691a1d061b1d17917"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2Njc2MTQzOA==", "bodyText": "OK, thanks a lot. I will spend some time thinking if we can improve it.", "url": "https://github.com/apache/flink/pull/11877#discussion_r666761438", "createdAt": "2021-07-09T08:13:52Z", "author": {"login": "wsry"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java", "diffHunk": "@@ -312,6 +323,16 @@ BufferAndBacklog pollBuffer() {\n                     decreaseBuffersInBacklogUnsafe(bufferConsumer.isBuffer());\n                 }\n \n+                // if we have an empty finished buffer and the exclusive credit is 0, we just return\n+                // the empty buffer so that the downstream task can release the allocated credit for\n+                // this empty buffer, this happens in two main scenarios currently:\n+                // 1. all data of a buffer builder has been read and after that the buffer builder\n+                // is finished\n+                // 2. in approximate recovery mode, a partial record takes a whole buffer builder\n+                if (buffersPerChannel == 0 && bufferConsumer.isFinished()) {\n+                    break;\n+                }\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NjM0MDc3MQ=="}, "originalCommit": {"oid": "faee760500feb1a2f793a6d691a1d061b1d17917"}, "originalPosition": 48}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkNDIzNjgwMzAwOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/ResultPartitionFactory.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wOVQwODowNToyOVrOJ73kkQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wOVQwODowNToyOVrOJ73kkQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2Njc1NjI0MQ==", "bodyText": "rename networkBuffersPerChannel -> configuredNetworkBuffersPerChannel to better reflect that we are actually overriding this value for the output?", "url": "https://github.com/apache/flink/pull/11877#discussion_r666756241", "createdAt": "2021-07-09T08:05:29Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/ResultPartitionFactory.java", "diffHunk": "@@ -156,15 +155,16 @@ public ResultPartition create(\n                             bufferCompressor,\n                             bufferPoolFactory);\n \n-            BiFunction<Integer, PipelinedResultPartition, PipelinedSubpartition> factory;\n-            if (type == ResultPartitionType.PIPELINED_APPROXIMATE) {\n-                factory = PipelinedApproximateSubpartition::new;\n-            } else {\n-                factory = PipelinedSubpartition::new;\n-            }\n-\n             for (int i = 0; i < subpartitions.length; i++) {\n-                subpartitions[i] = factory.apply(i, pipelinedPartition);\n+                if (type == ResultPartitionType.PIPELINED_APPROXIMATE) {\n+                    subpartitions[i] =\n+                            new PipelinedApproximateSubpartition(\n+                                    i, networkBuffersPerChannel, pipelinedPartition);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3f6a9f67fcb3429ce0b086c3384f14ff4a31b29"}, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkNDIzNjgwNzcwOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wOVQwODowNjo0OVrOJ73ngw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0wOVQwODowNjo0OVrOJ73ngw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2Njc1Njk5NQ==", "bodyText": "Can we rename this property to something like receiverExclusiveBuffersPerChannel?  Because actually this is not the number of buffersPerChannel for the sender.", "url": "https://github.com/apache/flink/pull/11877#discussion_r666756995", "createdAt": "2021-07-09T08:06:49Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java", "diffHunk": "@@ -112,8 +120,11 @@\n \n     // ------------------------------------------------------------------------\n \n-    PipelinedSubpartition(int index, ResultPartition parent) {\n+    PipelinedSubpartition(int index, int buffersPerChannel, ResultPartition parent) {\n         super(index, parent);\n+\n+        checkArgument(buffersPerChannel >= 0, \"Buffers per channel must be non-negative.\");\n+        this.buffersPerChannel = buffersPerChannel;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3f6a9f67fcb3429ce0b086c3384f14ff4a31b29"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkNDI0NDIzODgwOnYy", "diffSide": "RIGHT", "path": "docs/layouts/shortcodes/generated/all_taskmanager_network_section.html", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0xMlQxMDowNTo1NFrOJ83LoA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNy0xMlQxMDowNTo1NFrOJ83LoA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2Nzc5ODQzMg==", "bodyText": "Maybe a minor reword to:\n\nThe minimum valid value that can be configured is 0. When 0 buffers-per-channel is configured, the exclusive network buffers used per downstream incoming channel will be 0, but for each upstream outgoing channel, max(1, configured value) will be used. In other words we ensure that, for performance reasons, there is at least one buffer per outgoing channel regardless of the configuration.", "url": "https://github.com/apache/flink/pull/11877#discussion_r667798432", "createdAt": "2021-07-12T10:05:54Z", "author": {"login": "pnowojski"}, "path": "docs/layouts/shortcodes/generated/all_taskmanager_network_section.html", "diffHunk": "@@ -30,7 +30,7 @@\n             <td><h5>taskmanager.network.memory.buffers-per-channel</h5></td>\n             <td style=\"word-wrap: break-word;\">2</td>\n             <td>Integer</td>\n-            <td>Number of exclusive network buffers to use for each outgoing/incoming channel (subpartition/inputchannel) in the credit-based flow control model. It should be configured at least 2 for good performance. 1 buffer is for receiving in-flight data in the subpartition and 1 buffer is for parallel serialization.</td>\n+            <td>Number of exclusive network buffers to use for each outgoing/incoming channel (subpartition/input channel) in the credit-based flow control model. It should be configured at least 2 for good performance. 1 buffer is for receiving in-flight data in the subpartition and 1 buffer is for parallel serialization. The minimum valid value can be configured is 0 and when 0 is configured, the exclusive network buffers used per downstream incoming channel will be 0, but for each upstream outgoing channel, max(1, configured value) will be used which means that at least one buffer is needed and this behavior is for performance. If it's not guaranteed that each outgoing channel can get at least one buffer, more partial buffers with little data will be outputted to network/disk and recycled to be used by other channels which can not get a buffer for data caching.</td>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da81fde5fc9e110075cff4982048b7f7ee3a0d61"}, "originalPosition": 5}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1588, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}