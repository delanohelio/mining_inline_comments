{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE1OTE2Njgx", "number": 12073, "reviewThreads": {"totalCount": 21, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwMTo1Njo0N1rOD9IOZg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QxMTowOToyM1rOD9KHaA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NDI0NDg2OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwMTo1Njo0N1rOGWdrhA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwMTo1Njo0N1rOGWdrhA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIwODEzMg==", "bodyText": "rename to jobTerminated", "url": "https://github.com/apache/flink/pull/12073#discussion_r426208132", "createdAt": "2020-05-17T01:56:47Z", "author": {"login": "KurtYoung"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,343 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\tprivate JobClient jobClient;\n+\tprivate boolean terminated;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca26d6edd7772ee46d24b05c01952a10887eb3f7"}, "originalPosition": 65}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NDI1Mjk2OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwMjoxNjoyNFrOGWdvcA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwMjoxNjoyNFrOGWdvcA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIwOTEzNg==", "bodyText": "doesn't see any tests relying on this method", "url": "https://github.com/apache/flink/pull/12073#discussion_r426209136", "createdAt": "2020-05-17T02:16:24Z", "author": {"login": "KurtYoung"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,343 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\tprivate JobClient jobClient;\n+\tprivate boolean terminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\t@VisibleForTesting", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca26d6edd7772ee46d24b05c01952a10887eb3f7"}, "originalPosition": 79}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NDI1MzYyOnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwMjoxNzo1MlrOGWdvvQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwMjoxNzo1MlrOGWdvvQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIwOTIxMw==", "bodyText": "init closed variable", "url": "https://github.com/apache/flink/pull/12073#discussion_r426209213", "createdAt": "2020-05-17T02:17:52Z", "author": {"login": "KurtYoung"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,343 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\tprivate JobClient jobClient;\n+\tprivate boolean terminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\t@VisibleForTesting\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca26d6edd7772ee46d24b05c01952a10887eb3f7"}, "originalPosition": 90}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NDI1Mzc3OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwMjoxODoxOVrOGWdv0Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwMjoxODoxOVrOGWdv0Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIwOTIzMw==", "bodyText": "add @Nullable", "url": "https://github.com/apache/flink/pull/12073#discussion_r426209233", "createdAt": "2020-05-17T02:18:19Z", "author": {"login": "KurtYoung"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,343 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\tprivate JobClient jobClient;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca26d6edd7772ee46d24b05c01952a10887eb3f7"}, "originalPosition": 64}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NDI1Mzk3OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwMjoxOToxOFrOGWdv7w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwMjoxOToxOFrOGWdv7w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIwOTI2Mw==", "bodyText": "use another field to save CoordinationRequestGateway, can save some casting in the future", "url": "https://github.com/apache/flink/pull/12073#discussion_r426209263", "createdAt": "2020-05-17T02:19:18Z", "author": {"login": "KurtYoung"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,343 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\tprivate JobClient jobClient;\n+\tprivate boolean terminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\t@VisibleForTesting\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.terminated = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca26d6edd7772ee46d24b05c01952a10887eb3f7"}, "originalPosition": 98}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NDI1NDY0OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwMjoyMDoyNFrOGWdwPA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwMjoyMDoyNFrOGWdwPA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIwOTM0MA==", "bodyText": "how about userVisibleHead", "url": "https://github.com/apache/flink/pull/12073#discussion_r426209340", "createdAt": "2020-05-17T02:20:24Z", "author": {"login": "KurtYoung"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,343 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\tprivate JobClient jobClient;\n+\tprivate boolean terminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\t@VisibleForTesting\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.terminated = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (terminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tterminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (terminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\t// still no results, but job is still running, retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void close() {\n+\t\tif (closed) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tcancelJob();\n+\t\tclosed = true;\n+\t}\n+\n+\t@Override\n+\tprotected void finalize() throws Throwable {\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\tclose();\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tprivate CollectCoordinationResponse<T> sendRequest(\n+\t\t\tString version,\n+\t\t\tlong offset) throws InterruptedException, ExecutionException {\n+\t\tcheckJobClientConfigured();\n+\t\tCoordinationRequestGateway gateway = (CoordinationRequestGateway) jobClient;\n+\n+\t\tOperatorID operatorId = operatorIdFuture.getNow(null);\n+\t\tPreconditions.checkNotNull(operatorId, \"Unknown operator ID. This is a bug.\");\n+\n+\t\tCollectCoordinationRequest request = new CollectCoordinationRequest(version, offset);\n+\t\treturn (CollectCoordinationResponse) gateway.sendCoordinationRequest(operatorId, request).get();\n+\t}\n+\n+\t@Nullable\n+\tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tJobExecutionResult executionResult;\n+\t\ttry {\n+\t\t\t// this timeout is sort of hack, see comments in isJobTerminated for explanation\n+\t\t\texecutionResult = jobClient.getJobExecutionResult(getClass().getClassLoader()).get(\n+\t\t\t\tDEFAULT_ACCUMULATOR_GET_MILLIS, TimeUnit.MILLISECONDS);\n+\t\t} catch (InterruptedException | ExecutionException | TimeoutException e) {\n+\t\t\tthrow new RuntimeException(\"Failed to fetch job execution result\", e);\n+\t\t}\n+\n+\t\tArrayList<byte[]> accResults = executionResult.getAccumulatorResult(accumulatorName);\n+\t\tif (accResults == null) {\n+\t\t\t// job terminates abnormally\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tList<byte[]> serializedResults =\n+\t\t\t\tSerializedListAccumulator.deserializeList(accResults, BytePrimitiveArraySerializer.INSTANCE);\n+\t\t\tbyte[] serializedResult = serializedResults.get(0);\n+\t\t\treturn CollectSinkFunction.deserializeAccumulatorResult(serializedResult);\n+\t\t} catch (ClassNotFoundException | IOException e) {\n+\t\t\t// this is impossible\n+\t\t\tthrow new RuntimeException(\"Failed to deserialize accumulator results\", e);\n+\t\t}\n+\t}\n+\n+\tprivate boolean isJobTerminated() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\ttry {\n+\t\t\tJobStatus status = jobClient.getJobStatus().get();\n+\t\t\treturn status.isGloballyTerminalState();\n+\t\t} catch (Exception e) {\n+\t\t\t// TODO\n+\t\t\t//  This is sort of hack.\n+\t\t\t//  Currently different execution environment will have different behaviors\n+\t\t\t//  when fetching a finished job status.\n+\t\t\t//  For example, standalone session cluster will return a normal FINISHED,\n+\t\t\t//  while mini cluster will throw IllegalStateException,\n+\t\t\t//  and yarn per job will throw ApplicationNotFoundException.\n+\t\t\t//  We have to assume that job has finished in this case.\n+\t\t\t//  Change this when these behaviors are unified.\n+\t\t\tLOG.warn(\"Failed to get job status so we assume that the job has terminated. Some data might be lost.\", e);\n+\t\t\treturn true;\n+\t\t}\n+\t}\n+\n+\tprivate void cancelJob() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tif (!isJobTerminated()) {\n+\t\t\tjobClient.cancel();\n+\t\t}\n+\t}\n+\n+\tprivate void sleepBeforeRetry() {\n+\t\tif (retryMillis <= 0) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\t// TODO a more proper retry strategy?\n+\t\t\tThread.sleep(retryMillis);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tLOG.warn(\"Interrupted when sleeping before a retry\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void checkJobClientConfigured() {\n+\t\tPreconditions.checkNotNull(jobClient, \"Job client must be configured before first use.\");\n+\t}\n+\n+\tprivate class ResultBuffer {\n+\n+\t\tprivate static final String INIT_VERSION = \"\";\n+\n+\t\tprivate final LinkedList<T> buffer;\n+\t\tprivate final TypeSerializer<T> serializer;\n+\n+\t\tprivate String version;\n+\t\tprivate long offset;\n+\t\tprivate long lastCheckpointedOffset;\n+\t\tprivate long userHead;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca26d6edd7772ee46d24b05c01952a10887eb3f7"}, "originalPosition": 269}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NDI2MjU5OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwMjozODoyNVrOGWd0Bw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwNjowOTowMFrOGWegfA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIxMDMxMQ==", "bodyText": "I don't think we should eat this exception, we should throw this out to show something is going wrong", "url": "https://github.com/apache/flink/pull/12073#discussion_r426210311", "createdAt": "2020-05-17T02:38:25Z", "author": {"login": "KurtYoung"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,343 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\tprivate JobClient jobClient;\n+\tprivate boolean terminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\t@VisibleForTesting\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.terminated = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (terminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tterminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (terminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\t// still no results, but job is still running, retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void close() {\n+\t\tif (closed) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tcancelJob();\n+\t\tclosed = true;\n+\t}\n+\n+\t@Override\n+\tprotected void finalize() throws Throwable {\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\tclose();\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tprivate CollectCoordinationResponse<T> sendRequest(\n+\t\t\tString version,\n+\t\t\tlong offset) throws InterruptedException, ExecutionException {\n+\t\tcheckJobClientConfigured();\n+\t\tCoordinationRequestGateway gateway = (CoordinationRequestGateway) jobClient;\n+\n+\t\tOperatorID operatorId = operatorIdFuture.getNow(null);\n+\t\tPreconditions.checkNotNull(operatorId, \"Unknown operator ID. This is a bug.\");\n+\n+\t\tCollectCoordinationRequest request = new CollectCoordinationRequest(version, offset);\n+\t\treturn (CollectCoordinationResponse) gateway.sendCoordinationRequest(operatorId, request).get();\n+\t}\n+\n+\t@Nullable\n+\tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tJobExecutionResult executionResult;\n+\t\ttry {\n+\t\t\t// this timeout is sort of hack, see comments in isJobTerminated for explanation\n+\t\t\texecutionResult = jobClient.getJobExecutionResult(getClass().getClassLoader()).get(\n+\t\t\t\tDEFAULT_ACCUMULATOR_GET_MILLIS, TimeUnit.MILLISECONDS);\n+\t\t} catch (InterruptedException | ExecutionException | TimeoutException e) {\n+\t\t\tthrow new RuntimeException(\"Failed to fetch job execution result\", e);\n+\t\t}\n+\n+\t\tArrayList<byte[]> accResults = executionResult.getAccumulatorResult(accumulatorName);\n+\t\tif (accResults == null) {\n+\t\t\t// job terminates abnormally\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tList<byte[]> serializedResults =\n+\t\t\t\tSerializedListAccumulator.deserializeList(accResults, BytePrimitiveArraySerializer.INSTANCE);\n+\t\t\tbyte[] serializedResult = serializedResults.get(0);\n+\t\t\treturn CollectSinkFunction.deserializeAccumulatorResult(serializedResult);\n+\t\t} catch (ClassNotFoundException | IOException e) {\n+\t\t\t// this is impossible\n+\t\t\tthrow new RuntimeException(\"Failed to deserialize accumulator results\", e);\n+\t\t}\n+\t}\n+\n+\tprivate boolean isJobTerminated() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\ttry {\n+\t\t\tJobStatus status = jobClient.getJobStatus().get();\n+\t\t\treturn status.isGloballyTerminalState();\n+\t\t} catch (Exception e) {\n+\t\t\t// TODO\n+\t\t\t//  This is sort of hack.\n+\t\t\t//  Currently different execution environment will have different behaviors\n+\t\t\t//  when fetching a finished job status.\n+\t\t\t//  For example, standalone session cluster will return a normal FINISHED,\n+\t\t\t//  while mini cluster will throw IllegalStateException,\n+\t\t\t//  and yarn per job will throw ApplicationNotFoundException.\n+\t\t\t//  We have to assume that job has finished in this case.\n+\t\t\t//  Change this when these behaviors are unified.\n+\t\t\tLOG.warn(\"Failed to get job status so we assume that the job has terminated. Some data might be lost.\", e);\n+\t\t\treturn true;\n+\t\t}\n+\t}\n+\n+\tprivate void cancelJob() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tif (!isJobTerminated()) {\n+\t\t\tjobClient.cancel();\n+\t\t}\n+\t}\n+\n+\tprivate void sleepBeforeRetry() {\n+\t\tif (retryMillis <= 0) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\t// TODO a more proper retry strategy?\n+\t\t\tThread.sleep(retryMillis);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tLOG.warn(\"Interrupted when sleeping before a retry\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void checkJobClientConfigured() {\n+\t\tPreconditions.checkNotNull(jobClient, \"Job client must be configured before first use.\");\n+\t}\n+\n+\tprivate class ResultBuffer {\n+\n+\t\tprivate static final String INIT_VERSION = \"\";\n+\n+\t\tprivate final LinkedList<T> buffer;\n+\t\tprivate final TypeSerializer<T> serializer;\n+\n+\t\tprivate String version;\n+\t\tprivate long offset;\n+\t\tprivate long lastCheckpointedOffset;\n+\t\tprivate long userHead;\n+\t\tprivate long userTail;\n+\n+\t\tprivate ResultBuffer(TypeSerializer<T> serializer) {\n+\t\t\tthis.buffer = new LinkedList<>();\n+\t\t\tthis.serializer = serializer;\n+\n+\t\t\tthis.version = INIT_VERSION;\n+\t\t\tthis.offset = 0;\n+\t\t\tthis.lastCheckpointedOffset = 0;\n+\t\t\tthis.userHead = 0;\n+\t\t\tthis.userTail = 0;\n+\t\t}\n+\n+\t\tprivate T next() {\n+\t\t\tif (userHead == userTail) {\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\tT ret = buffer.removeFirst();\n+\t\t\tuserHead++;\n+\n+\t\t\tsanityCheck();\n+\t\t\treturn ret;\n+\t\t}\n+\n+\t\tprivate void dealWithResponse(CollectCoordinationResponse<T> response) {\n+\t\t\tdealWithResponse(response, offset);\n+\t\t}\n+\n+\t\tprivate void dealWithResponse(CollectCoordinationResponse<T> response, long responseOffset) {\n+\t\t\tString responseVersion = response.getVersion();\n+\t\t\tlong responseLastCheckpointedOffset = response.getLastCheckpointedOffset();\n+\t\t\tList<T> results;\n+\t\t\ttry {\n+\t\t\t\tresults = response.getResults(serializer);\n+\t\t\t} catch (IOException e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca26d6edd7772ee46d24b05c01952a10887eb3f7"}, "originalPosition": 304}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyMTY5Mg==", "bodyText": "I would prefer to throw it out", "url": "https://github.com/apache/flink/pull/12073#discussion_r426221692", "createdAt": "2020-05-17T06:09:00Z", "author": {"login": "KurtYoung"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,343 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\tprivate JobClient jobClient;\n+\tprivate boolean terminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\t@VisibleForTesting\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.terminated = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (terminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tterminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (terminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\t// still no results, but job is still running, retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void close() {\n+\t\tif (closed) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tcancelJob();\n+\t\tclosed = true;\n+\t}\n+\n+\t@Override\n+\tprotected void finalize() throws Throwable {\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\tclose();\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tprivate CollectCoordinationResponse<T> sendRequest(\n+\t\t\tString version,\n+\t\t\tlong offset) throws InterruptedException, ExecutionException {\n+\t\tcheckJobClientConfigured();\n+\t\tCoordinationRequestGateway gateway = (CoordinationRequestGateway) jobClient;\n+\n+\t\tOperatorID operatorId = operatorIdFuture.getNow(null);\n+\t\tPreconditions.checkNotNull(operatorId, \"Unknown operator ID. This is a bug.\");\n+\n+\t\tCollectCoordinationRequest request = new CollectCoordinationRequest(version, offset);\n+\t\treturn (CollectCoordinationResponse) gateway.sendCoordinationRequest(operatorId, request).get();\n+\t}\n+\n+\t@Nullable\n+\tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tJobExecutionResult executionResult;\n+\t\ttry {\n+\t\t\t// this timeout is sort of hack, see comments in isJobTerminated for explanation\n+\t\t\texecutionResult = jobClient.getJobExecutionResult(getClass().getClassLoader()).get(\n+\t\t\t\tDEFAULT_ACCUMULATOR_GET_MILLIS, TimeUnit.MILLISECONDS);\n+\t\t} catch (InterruptedException | ExecutionException | TimeoutException e) {\n+\t\t\tthrow new RuntimeException(\"Failed to fetch job execution result\", e);\n+\t\t}\n+\n+\t\tArrayList<byte[]> accResults = executionResult.getAccumulatorResult(accumulatorName);\n+\t\tif (accResults == null) {\n+\t\t\t// job terminates abnormally\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tList<byte[]> serializedResults =\n+\t\t\t\tSerializedListAccumulator.deserializeList(accResults, BytePrimitiveArraySerializer.INSTANCE);\n+\t\t\tbyte[] serializedResult = serializedResults.get(0);\n+\t\t\treturn CollectSinkFunction.deserializeAccumulatorResult(serializedResult);\n+\t\t} catch (ClassNotFoundException | IOException e) {\n+\t\t\t// this is impossible\n+\t\t\tthrow new RuntimeException(\"Failed to deserialize accumulator results\", e);\n+\t\t}\n+\t}\n+\n+\tprivate boolean isJobTerminated() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\ttry {\n+\t\t\tJobStatus status = jobClient.getJobStatus().get();\n+\t\t\treturn status.isGloballyTerminalState();\n+\t\t} catch (Exception e) {\n+\t\t\t// TODO\n+\t\t\t//  This is sort of hack.\n+\t\t\t//  Currently different execution environment will have different behaviors\n+\t\t\t//  when fetching a finished job status.\n+\t\t\t//  For example, standalone session cluster will return a normal FINISHED,\n+\t\t\t//  while mini cluster will throw IllegalStateException,\n+\t\t\t//  and yarn per job will throw ApplicationNotFoundException.\n+\t\t\t//  We have to assume that job has finished in this case.\n+\t\t\t//  Change this when these behaviors are unified.\n+\t\t\tLOG.warn(\"Failed to get job status so we assume that the job has terminated. Some data might be lost.\", e);\n+\t\t\treturn true;\n+\t\t}\n+\t}\n+\n+\tprivate void cancelJob() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tif (!isJobTerminated()) {\n+\t\t\tjobClient.cancel();\n+\t\t}\n+\t}\n+\n+\tprivate void sleepBeforeRetry() {\n+\t\tif (retryMillis <= 0) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\t// TODO a more proper retry strategy?\n+\t\t\tThread.sleep(retryMillis);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tLOG.warn(\"Interrupted when sleeping before a retry\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void checkJobClientConfigured() {\n+\t\tPreconditions.checkNotNull(jobClient, \"Job client must be configured before first use.\");\n+\t}\n+\n+\tprivate class ResultBuffer {\n+\n+\t\tprivate static final String INIT_VERSION = \"\";\n+\n+\t\tprivate final LinkedList<T> buffer;\n+\t\tprivate final TypeSerializer<T> serializer;\n+\n+\t\tprivate String version;\n+\t\tprivate long offset;\n+\t\tprivate long lastCheckpointedOffset;\n+\t\tprivate long userHead;\n+\t\tprivate long userTail;\n+\n+\t\tprivate ResultBuffer(TypeSerializer<T> serializer) {\n+\t\t\tthis.buffer = new LinkedList<>();\n+\t\t\tthis.serializer = serializer;\n+\n+\t\t\tthis.version = INIT_VERSION;\n+\t\t\tthis.offset = 0;\n+\t\t\tthis.lastCheckpointedOffset = 0;\n+\t\t\tthis.userHead = 0;\n+\t\t\tthis.userTail = 0;\n+\t\t}\n+\n+\t\tprivate T next() {\n+\t\t\tif (userHead == userTail) {\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\tT ret = buffer.removeFirst();\n+\t\t\tuserHead++;\n+\n+\t\t\tsanityCheck();\n+\t\t\treturn ret;\n+\t\t}\n+\n+\t\tprivate void dealWithResponse(CollectCoordinationResponse<T> response) {\n+\t\t\tdealWithResponse(response, offset);\n+\t\t}\n+\n+\t\tprivate void dealWithResponse(CollectCoordinationResponse<T> response, long responseOffset) {\n+\t\t\tString responseVersion = response.getVersion();\n+\t\t\tlong responseLastCheckpointedOffset = response.getLastCheckpointedOffset();\n+\t\t\tList<T> results;\n+\t\t\ttry {\n+\t\t\t\tresults = response.getResults(serializer);\n+\t\t\t} catch (IOException e) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIxMDMxMQ=="}, "originalCommit": {"oid": "ca26d6edd7772ee46d24b05c01952a10887eb3f7"}, "originalPosition": 304}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NDI2NDI3OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwMjo0MjoxNlrOGWd01w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwNDo0Njo0NlrOGWeNuA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIxMDUxOQ==", "bodyText": "when will responseLastCheckpointedOffset < lastCheckpointedOffset(I can understand when they are equal), and what would you do with this situation?", "url": "https://github.com/apache/flink/pull/12073#discussion_r426210519", "createdAt": "2020-05-17T02:42:16Z", "author": {"login": "KurtYoung"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,343 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\tprivate JobClient jobClient;\n+\tprivate boolean terminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\t@VisibleForTesting\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.terminated = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (terminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tterminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (terminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\t// still no results, but job is still running, retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void close() {\n+\t\tif (closed) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tcancelJob();\n+\t\tclosed = true;\n+\t}\n+\n+\t@Override\n+\tprotected void finalize() throws Throwable {\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\tclose();\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tprivate CollectCoordinationResponse<T> sendRequest(\n+\t\t\tString version,\n+\t\t\tlong offset) throws InterruptedException, ExecutionException {\n+\t\tcheckJobClientConfigured();\n+\t\tCoordinationRequestGateway gateway = (CoordinationRequestGateway) jobClient;\n+\n+\t\tOperatorID operatorId = operatorIdFuture.getNow(null);\n+\t\tPreconditions.checkNotNull(operatorId, \"Unknown operator ID. This is a bug.\");\n+\n+\t\tCollectCoordinationRequest request = new CollectCoordinationRequest(version, offset);\n+\t\treturn (CollectCoordinationResponse) gateway.sendCoordinationRequest(operatorId, request).get();\n+\t}\n+\n+\t@Nullable\n+\tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tJobExecutionResult executionResult;\n+\t\ttry {\n+\t\t\t// this timeout is sort of hack, see comments in isJobTerminated for explanation\n+\t\t\texecutionResult = jobClient.getJobExecutionResult(getClass().getClassLoader()).get(\n+\t\t\t\tDEFAULT_ACCUMULATOR_GET_MILLIS, TimeUnit.MILLISECONDS);\n+\t\t} catch (InterruptedException | ExecutionException | TimeoutException e) {\n+\t\t\tthrow new RuntimeException(\"Failed to fetch job execution result\", e);\n+\t\t}\n+\n+\t\tArrayList<byte[]> accResults = executionResult.getAccumulatorResult(accumulatorName);\n+\t\tif (accResults == null) {\n+\t\t\t// job terminates abnormally\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tList<byte[]> serializedResults =\n+\t\t\t\tSerializedListAccumulator.deserializeList(accResults, BytePrimitiveArraySerializer.INSTANCE);\n+\t\t\tbyte[] serializedResult = serializedResults.get(0);\n+\t\t\treturn CollectSinkFunction.deserializeAccumulatorResult(serializedResult);\n+\t\t} catch (ClassNotFoundException | IOException e) {\n+\t\t\t// this is impossible\n+\t\t\tthrow new RuntimeException(\"Failed to deserialize accumulator results\", e);\n+\t\t}\n+\t}\n+\n+\tprivate boolean isJobTerminated() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\ttry {\n+\t\t\tJobStatus status = jobClient.getJobStatus().get();\n+\t\t\treturn status.isGloballyTerminalState();\n+\t\t} catch (Exception e) {\n+\t\t\t// TODO\n+\t\t\t//  This is sort of hack.\n+\t\t\t//  Currently different execution environment will have different behaviors\n+\t\t\t//  when fetching a finished job status.\n+\t\t\t//  For example, standalone session cluster will return a normal FINISHED,\n+\t\t\t//  while mini cluster will throw IllegalStateException,\n+\t\t\t//  and yarn per job will throw ApplicationNotFoundException.\n+\t\t\t//  We have to assume that job has finished in this case.\n+\t\t\t//  Change this when these behaviors are unified.\n+\t\t\tLOG.warn(\"Failed to get job status so we assume that the job has terminated. Some data might be lost.\", e);\n+\t\t\treturn true;\n+\t\t}\n+\t}\n+\n+\tprivate void cancelJob() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tif (!isJobTerminated()) {\n+\t\t\tjobClient.cancel();\n+\t\t}\n+\t}\n+\n+\tprivate void sleepBeforeRetry() {\n+\t\tif (retryMillis <= 0) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\t// TODO a more proper retry strategy?\n+\t\t\tThread.sleep(retryMillis);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tLOG.warn(\"Interrupted when sleeping before a retry\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void checkJobClientConfigured() {\n+\t\tPreconditions.checkNotNull(jobClient, \"Job client must be configured before first use.\");\n+\t}\n+\n+\tprivate class ResultBuffer {\n+\n+\t\tprivate static final String INIT_VERSION = \"\";\n+\n+\t\tprivate final LinkedList<T> buffer;\n+\t\tprivate final TypeSerializer<T> serializer;\n+\n+\t\tprivate String version;\n+\t\tprivate long offset;\n+\t\tprivate long lastCheckpointedOffset;\n+\t\tprivate long userHead;\n+\t\tprivate long userTail;\n+\n+\t\tprivate ResultBuffer(TypeSerializer<T> serializer) {\n+\t\t\tthis.buffer = new LinkedList<>();\n+\t\t\tthis.serializer = serializer;\n+\n+\t\t\tthis.version = INIT_VERSION;\n+\t\t\tthis.offset = 0;\n+\t\t\tthis.lastCheckpointedOffset = 0;\n+\t\t\tthis.userHead = 0;\n+\t\t\tthis.userTail = 0;\n+\t\t}\n+\n+\t\tprivate T next() {\n+\t\t\tif (userHead == userTail) {\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\tT ret = buffer.removeFirst();\n+\t\t\tuserHead++;\n+\n+\t\t\tsanityCheck();\n+\t\t\treturn ret;\n+\t\t}\n+\n+\t\tprivate void dealWithResponse(CollectCoordinationResponse<T> response) {\n+\t\t\tdealWithResponse(response, offset);\n+\t\t}\n+\n+\t\tprivate void dealWithResponse(CollectCoordinationResponse<T> response, long responseOffset) {\n+\t\t\tString responseVersion = response.getVersion();\n+\t\t\tlong responseLastCheckpointedOffset = response.getLastCheckpointedOffset();\n+\t\t\tList<T> results;\n+\t\t\ttry {\n+\t\t\t\tresults = response.getResults(serializer);\n+\t\t\t} catch (IOException e) {\n+\t\t\t\tLOG.warn(\"An exception occurs when deserializing query results. Some results might be lost.\", e);\n+\t\t\t\tresults = Collections.emptyList();\n+\t\t\t}\n+\n+\t\t\tif (responseLastCheckpointedOffset > lastCheckpointedOffset) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca26d6edd7772ee46d24b05c01952a10887eb3f7"}, "originalPosition": 309}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIxNjg4OA==", "bodyText": "It is impossible for responseLastCheckpointedOffset to be smaller than lastCheckpointedOffset, offsets are always non-decreasing.", "url": "https://github.com/apache/flink/pull/12073#discussion_r426216888", "createdAt": "2020-05-17T04:46:46Z", "author": {"login": "tsreaper"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,343 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\tprivate JobClient jobClient;\n+\tprivate boolean terminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\t@VisibleForTesting\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.terminated = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (terminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tterminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (terminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\t// still no results, but job is still running, retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void close() {\n+\t\tif (closed) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tcancelJob();\n+\t\tclosed = true;\n+\t}\n+\n+\t@Override\n+\tprotected void finalize() throws Throwable {\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\tclose();\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tprivate CollectCoordinationResponse<T> sendRequest(\n+\t\t\tString version,\n+\t\t\tlong offset) throws InterruptedException, ExecutionException {\n+\t\tcheckJobClientConfigured();\n+\t\tCoordinationRequestGateway gateway = (CoordinationRequestGateway) jobClient;\n+\n+\t\tOperatorID operatorId = operatorIdFuture.getNow(null);\n+\t\tPreconditions.checkNotNull(operatorId, \"Unknown operator ID. This is a bug.\");\n+\n+\t\tCollectCoordinationRequest request = new CollectCoordinationRequest(version, offset);\n+\t\treturn (CollectCoordinationResponse) gateway.sendCoordinationRequest(operatorId, request).get();\n+\t}\n+\n+\t@Nullable\n+\tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tJobExecutionResult executionResult;\n+\t\ttry {\n+\t\t\t// this timeout is sort of hack, see comments in isJobTerminated for explanation\n+\t\t\texecutionResult = jobClient.getJobExecutionResult(getClass().getClassLoader()).get(\n+\t\t\t\tDEFAULT_ACCUMULATOR_GET_MILLIS, TimeUnit.MILLISECONDS);\n+\t\t} catch (InterruptedException | ExecutionException | TimeoutException e) {\n+\t\t\tthrow new RuntimeException(\"Failed to fetch job execution result\", e);\n+\t\t}\n+\n+\t\tArrayList<byte[]> accResults = executionResult.getAccumulatorResult(accumulatorName);\n+\t\tif (accResults == null) {\n+\t\t\t// job terminates abnormally\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tList<byte[]> serializedResults =\n+\t\t\t\tSerializedListAccumulator.deserializeList(accResults, BytePrimitiveArraySerializer.INSTANCE);\n+\t\t\tbyte[] serializedResult = serializedResults.get(0);\n+\t\t\treturn CollectSinkFunction.deserializeAccumulatorResult(serializedResult);\n+\t\t} catch (ClassNotFoundException | IOException e) {\n+\t\t\t// this is impossible\n+\t\t\tthrow new RuntimeException(\"Failed to deserialize accumulator results\", e);\n+\t\t}\n+\t}\n+\n+\tprivate boolean isJobTerminated() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\ttry {\n+\t\t\tJobStatus status = jobClient.getJobStatus().get();\n+\t\t\treturn status.isGloballyTerminalState();\n+\t\t} catch (Exception e) {\n+\t\t\t// TODO\n+\t\t\t//  This is sort of hack.\n+\t\t\t//  Currently different execution environment will have different behaviors\n+\t\t\t//  when fetching a finished job status.\n+\t\t\t//  For example, standalone session cluster will return a normal FINISHED,\n+\t\t\t//  while mini cluster will throw IllegalStateException,\n+\t\t\t//  and yarn per job will throw ApplicationNotFoundException.\n+\t\t\t//  We have to assume that job has finished in this case.\n+\t\t\t//  Change this when these behaviors are unified.\n+\t\t\tLOG.warn(\"Failed to get job status so we assume that the job has terminated. Some data might be lost.\", e);\n+\t\t\treturn true;\n+\t\t}\n+\t}\n+\n+\tprivate void cancelJob() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tif (!isJobTerminated()) {\n+\t\t\tjobClient.cancel();\n+\t\t}\n+\t}\n+\n+\tprivate void sleepBeforeRetry() {\n+\t\tif (retryMillis <= 0) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\t// TODO a more proper retry strategy?\n+\t\t\tThread.sleep(retryMillis);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tLOG.warn(\"Interrupted when sleeping before a retry\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void checkJobClientConfigured() {\n+\t\tPreconditions.checkNotNull(jobClient, \"Job client must be configured before first use.\");\n+\t}\n+\n+\tprivate class ResultBuffer {\n+\n+\t\tprivate static final String INIT_VERSION = \"\";\n+\n+\t\tprivate final LinkedList<T> buffer;\n+\t\tprivate final TypeSerializer<T> serializer;\n+\n+\t\tprivate String version;\n+\t\tprivate long offset;\n+\t\tprivate long lastCheckpointedOffset;\n+\t\tprivate long userHead;\n+\t\tprivate long userTail;\n+\n+\t\tprivate ResultBuffer(TypeSerializer<T> serializer) {\n+\t\t\tthis.buffer = new LinkedList<>();\n+\t\t\tthis.serializer = serializer;\n+\n+\t\t\tthis.version = INIT_VERSION;\n+\t\t\tthis.offset = 0;\n+\t\t\tthis.lastCheckpointedOffset = 0;\n+\t\t\tthis.userHead = 0;\n+\t\t\tthis.userTail = 0;\n+\t\t}\n+\n+\t\tprivate T next() {\n+\t\t\tif (userHead == userTail) {\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\tT ret = buffer.removeFirst();\n+\t\t\tuserHead++;\n+\n+\t\t\tsanityCheck();\n+\t\t\treturn ret;\n+\t\t}\n+\n+\t\tprivate void dealWithResponse(CollectCoordinationResponse<T> response) {\n+\t\t\tdealWithResponse(response, offset);\n+\t\t}\n+\n+\t\tprivate void dealWithResponse(CollectCoordinationResponse<T> response, long responseOffset) {\n+\t\t\tString responseVersion = response.getVersion();\n+\t\t\tlong responseLastCheckpointedOffset = response.getLastCheckpointedOffset();\n+\t\t\tList<T> results;\n+\t\t\ttry {\n+\t\t\t\tresults = response.getResults(serializer);\n+\t\t\t} catch (IOException e) {\n+\t\t\t\tLOG.warn(\"An exception occurs when deserializing query results. Some results might be lost.\", e);\n+\t\t\t\tresults = Collections.emptyList();\n+\t\t\t}\n+\n+\t\t\tif (responseLastCheckpointedOffset > lastCheckpointedOffset) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIxMDUxOQ=="}, "originalCommit": {"oid": "ca26d6edd7772ee46d24b05c01952a10887eb3f7"}, "originalPosition": 309}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NDI2NTIzOnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwMjo0NDozMlrOGWd1Rw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwMjo0NDozMlrOGWd1Rw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIxMDYzMQ==", "bodyText": "We need some document about these variables and ResultBuffer, I'm quite confused now even if I know the algorithm...", "url": "https://github.com/apache/flink/pull/12073#discussion_r426210631", "createdAt": "2020-05-17T02:44:32Z", "author": {"login": "KurtYoung"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,343 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\tprivate JobClient jobClient;\n+\tprivate boolean terminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\t@VisibleForTesting\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.terminated = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (terminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tterminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (terminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\t// still no results, but job is still running, retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void close() {\n+\t\tif (closed) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tcancelJob();\n+\t\tclosed = true;\n+\t}\n+\n+\t@Override\n+\tprotected void finalize() throws Throwable {\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\tclose();\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tprivate CollectCoordinationResponse<T> sendRequest(\n+\t\t\tString version,\n+\t\t\tlong offset) throws InterruptedException, ExecutionException {\n+\t\tcheckJobClientConfigured();\n+\t\tCoordinationRequestGateway gateway = (CoordinationRequestGateway) jobClient;\n+\n+\t\tOperatorID operatorId = operatorIdFuture.getNow(null);\n+\t\tPreconditions.checkNotNull(operatorId, \"Unknown operator ID. This is a bug.\");\n+\n+\t\tCollectCoordinationRequest request = new CollectCoordinationRequest(version, offset);\n+\t\treturn (CollectCoordinationResponse) gateway.sendCoordinationRequest(operatorId, request).get();\n+\t}\n+\n+\t@Nullable\n+\tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tJobExecutionResult executionResult;\n+\t\ttry {\n+\t\t\t// this timeout is sort of hack, see comments in isJobTerminated for explanation\n+\t\t\texecutionResult = jobClient.getJobExecutionResult(getClass().getClassLoader()).get(\n+\t\t\t\tDEFAULT_ACCUMULATOR_GET_MILLIS, TimeUnit.MILLISECONDS);\n+\t\t} catch (InterruptedException | ExecutionException | TimeoutException e) {\n+\t\t\tthrow new RuntimeException(\"Failed to fetch job execution result\", e);\n+\t\t}\n+\n+\t\tArrayList<byte[]> accResults = executionResult.getAccumulatorResult(accumulatorName);\n+\t\tif (accResults == null) {\n+\t\t\t// job terminates abnormally\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tList<byte[]> serializedResults =\n+\t\t\t\tSerializedListAccumulator.deserializeList(accResults, BytePrimitiveArraySerializer.INSTANCE);\n+\t\t\tbyte[] serializedResult = serializedResults.get(0);\n+\t\t\treturn CollectSinkFunction.deserializeAccumulatorResult(serializedResult);\n+\t\t} catch (ClassNotFoundException | IOException e) {\n+\t\t\t// this is impossible\n+\t\t\tthrow new RuntimeException(\"Failed to deserialize accumulator results\", e);\n+\t\t}\n+\t}\n+\n+\tprivate boolean isJobTerminated() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\ttry {\n+\t\t\tJobStatus status = jobClient.getJobStatus().get();\n+\t\t\treturn status.isGloballyTerminalState();\n+\t\t} catch (Exception e) {\n+\t\t\t// TODO\n+\t\t\t//  This is sort of hack.\n+\t\t\t//  Currently different execution environment will have different behaviors\n+\t\t\t//  when fetching a finished job status.\n+\t\t\t//  For example, standalone session cluster will return a normal FINISHED,\n+\t\t\t//  while mini cluster will throw IllegalStateException,\n+\t\t\t//  and yarn per job will throw ApplicationNotFoundException.\n+\t\t\t//  We have to assume that job has finished in this case.\n+\t\t\t//  Change this when these behaviors are unified.\n+\t\t\tLOG.warn(\"Failed to get job status so we assume that the job has terminated. Some data might be lost.\", e);\n+\t\t\treturn true;\n+\t\t}\n+\t}\n+\n+\tprivate void cancelJob() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tif (!isJobTerminated()) {\n+\t\t\tjobClient.cancel();\n+\t\t}\n+\t}\n+\n+\tprivate void sleepBeforeRetry() {\n+\t\tif (retryMillis <= 0) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\t// TODO a more proper retry strategy?\n+\t\t\tThread.sleep(retryMillis);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tLOG.warn(\"Interrupted when sleeping before a retry\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void checkJobClientConfigured() {\n+\t\tPreconditions.checkNotNull(jobClient, \"Job client must be configured before first use.\");\n+\t}\n+\n+\tprivate class ResultBuffer {\n+\n+\t\tprivate static final String INIT_VERSION = \"\";\n+\n+\t\tprivate final LinkedList<T> buffer;\n+\t\tprivate final TypeSerializer<T> serializer;\n+\n+\t\tprivate String version;\n+\t\tprivate long offset;\n+\t\tprivate long lastCheckpointedOffset;\n+\t\tprivate long userHead;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca26d6edd7772ee46d24b05c01952a10887eb3f7"}, "originalPosition": 269}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NDM2OTUxOnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwNjozMjo0MVrOGWenlw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwNjozMjo0MVrOGWenlw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyMzUxMQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t\t\t\tCollectCoordinationResponse<T> response;\n          \n          \n            \n            \t\t\t\ttry {\n          \n          \n            \n            \t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n          \n          \n            \n            \t\t\t\t} catch (Exception e) {\n          \n          \n            \n            \t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n          \n          \n            \n            \t\t\t\t\tsleepBeforeRetry();\n          \n          \n            \n            \t\t\t\t\tcontinue;\n          \n          \n            \n            \t\t\t\t}\n          \n          \n            \n            \t\t\t\tbuffer.dealWithResponse(response);\n          \n          \n            \n            \t\t\t\tlong requestOffset = buffer.offset;\n          \n          \n            \n            \t\t\t\tCollectCoordinationResponse<T> response;\n          \n          \n            \n            \t\t\t\ttry {\n          \n          \n            \n            \t\t\t\t\tresponse = sendRequest(buffer.version, requestOffset);\n          \n          \n            \n            \t\t\t\t} catch (Exception e) {\n          \n          \n            \n            \t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n          \n          \n            \n            \t\t\t\t\tsleepBeforeRetry();\n          \n          \n            \n            \t\t\t\t\tcontinue;\n          \n          \n            \n            \t\t\t\t}\n          \n          \n            \n            \t\t\t\t// the response will contain data (if any) starting exactly from requested offset\n          \n          \n            \n            \t\t\t\tbuffer.dealWithResponse(response, requestOffset);", "url": "https://github.com/apache/flink/pull/12073#discussion_r426223511", "createdAt": "2020-05-17T06:32:41Z", "author": {"login": "KurtYoung"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,359 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\t@Nullable\n+\tprivate JobClient jobClient;\n+\t@Nullable\n+\tprivate CoordinationRequestGateway gateway;\n+\n+\tprivate boolean jobTerminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\tCollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.jobTerminated = false;\n+\t\tthis.closed = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t\tthis.gateway = (CoordinationRequestGateway) jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (jobTerminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tjobTerminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ad199a9f0a8db9ce82493af6e180af602774e29"}, "originalPosition": 139}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NDM3MDMwOnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwNjozMzozMFrOGWen9Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwNjozMzozMFrOGWen9Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyMzYwNQ==", "bodyText": "delete this method", "url": "https://github.com/apache/flink/pull/12073#discussion_r426223605", "createdAt": "2020-05-17T06:33:30Z", "author": {"login": "KurtYoung"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,359 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\t@Nullable\n+\tprivate JobClient jobClient;\n+\t@Nullable\n+\tprivate CoordinationRequestGateway gateway;\n+\n+\tprivate boolean jobTerminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\tCollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.jobTerminated = false;\n+\t\tthis.closed = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t\tthis.gateway = (CoordinationRequestGateway) jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (jobTerminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tjobTerminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (jobTerminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\t// still no results, but job is still running, retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void close() {\n+\t\tif (closed) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tcancelJob();\n+\t\tclosed = true;\n+\t}\n+\n+\t@Override\n+\tprotected void finalize() throws Throwable {\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\tclose();\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tprivate CollectCoordinationResponse<T> sendRequest(\n+\t\t\tString version,\n+\t\t\tlong offset) throws InterruptedException, ExecutionException {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tOperatorID operatorId = operatorIdFuture.getNow(null);\n+\t\tPreconditions.checkNotNull(operatorId, \"Unknown operator ID. This is a bug.\");\n+\n+\t\tCollectCoordinationRequest request = new CollectCoordinationRequest(version, offset);\n+\t\treturn (CollectCoordinationResponse) gateway.sendCoordinationRequest(operatorId, request).get();\n+\t}\n+\n+\t@Nullable\n+\tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tJobExecutionResult executionResult;\n+\t\ttry {\n+\t\t\t// this timeout is sort of hack, see comments in isJobTerminated for explanation\n+\t\t\texecutionResult = jobClient.getJobExecutionResult(getClass().getClassLoader()).get(\n+\t\t\t\tDEFAULT_ACCUMULATOR_GET_MILLIS, TimeUnit.MILLISECONDS);\n+\t\t} catch (InterruptedException | ExecutionException | TimeoutException e) {\n+\t\t\tthrow new RuntimeException(\"Failed to fetch job execution result\", e);\n+\t\t}\n+\n+\t\tArrayList<byte[]> accResults = executionResult.getAccumulatorResult(accumulatorName);\n+\t\tif (accResults == null) {\n+\t\t\t// job terminates abnormally\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tList<byte[]> serializedResults =\n+\t\t\t\tSerializedListAccumulator.deserializeList(accResults, BytePrimitiveArraySerializer.INSTANCE);\n+\t\t\tbyte[] serializedResult = serializedResults.get(0);\n+\t\t\treturn CollectSinkFunction.deserializeAccumulatorResult(serializedResult);\n+\t\t} catch (ClassNotFoundException | IOException e) {\n+\t\t\t// this is impossible\n+\t\t\tthrow new RuntimeException(\"Failed to deserialize accumulator results\", e);\n+\t\t}\n+\t}\n+\n+\tprivate boolean isJobTerminated() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\ttry {\n+\t\t\tJobStatus status = jobClient.getJobStatus().get();\n+\t\t\treturn status.isGloballyTerminalState();\n+\t\t} catch (Exception e) {\n+\t\t\t// TODO\n+\t\t\t//  This is sort of hack.\n+\t\t\t//  Currently different execution environment will have different behaviors\n+\t\t\t//  when fetching a finished job status.\n+\t\t\t//  For example, standalone session cluster will return a normal FINISHED,\n+\t\t\t//  while mini cluster will throw IllegalStateException,\n+\t\t\t//  and yarn per job will throw ApplicationNotFoundException.\n+\t\t\t//  We have to assume that job has finished in this case.\n+\t\t\t//  Change this when these behaviors are unified.\n+\t\t\tLOG.warn(\"Failed to get job status so we assume that the job has terminated. Some data might be lost.\", e);\n+\t\t\treturn true;\n+\t\t}\n+\t}\n+\n+\tprivate void cancelJob() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tif (!isJobTerminated()) {\n+\t\t\tjobClient.cancel();\n+\t\t}\n+\t}\n+\n+\tprivate void sleepBeforeRetry() {\n+\t\tif (retryMillis <= 0) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\t// TODO a more proper retry strategy?\n+\t\t\tThread.sleep(retryMillis);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tLOG.warn(\"Interrupted when sleeping before a retry\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void checkJobClientConfigured() {\n+\t\tPreconditions.checkNotNull(jobClient, \"Job client must be configured before first use.\");\n+\t}\n+\n+\t/**\n+\t * A buffer which encapsulates the logic of dealing with the response from the {@link CollectSinkFunction}.\n+\t * See Java doc of {@link CollectSinkFunction} for explanation of this communication protocol.\n+\t */\n+\tprivate class ResultBuffer {\n+\n+\t\tprivate static final String INIT_VERSION = \"\";\n+\n+\t\tprivate final LinkedList<T> buffer;\n+\t\tprivate final TypeSerializer<T> serializer;\n+\n+\t\t// for detailed explanation of the following 3 variables, see Java doc of CollectSinkFunction\n+\t\t// `version` is to check if the sink restarts\n+\t\tprivate String version;\n+\t\t// `offset` is the offset of the next result we want to fetch\n+\t\tprivate long offset;\n+\n+\t\t// userVisibleHead <= user visible results offset < userVisibleTail\n+\t\tprivate long userVisibleHead;\n+\t\tprivate long userVisibleTail;\n+\n+\t\tprivate ResultBuffer(TypeSerializer<T> serializer) {\n+\t\t\tthis.buffer = new LinkedList<>();\n+\t\t\tthis.serializer = serializer;\n+\n+\t\t\tthis.version = INIT_VERSION;\n+\t\t\tthis.offset = 0;\n+\n+\t\t\tthis.userVisibleHead = 0;\n+\t\t\tthis.userVisibleTail = 0;\n+\t\t}\n+\n+\t\tprivate T next() {\n+\t\t\tif (userVisibleHead == userVisibleTail) {\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\tT ret = buffer.removeFirst();\n+\t\t\tuserVisibleHead++;\n+\n+\t\t\tsanityCheck();\n+\t\t\treturn ret;\n+\t\t}\n+\n+\t\tprivate void dealWithResponse(CollectCoordinationResponse<T> response) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ad199a9f0a8db9ce82493af6e180af602774e29"}, "originalPosition": 304}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NDM3MTMzOnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwNjozNToxM1rOGWeofQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwNzo0Njo0OFrOGWe_XQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyMzc0MQ==", "bodyText": "add a sanity check that responseLastCheckpointedOffset is less than offset.\nand also checks that this buffer still contains data starting from responseLastCheckpointedOffset", "url": "https://github.com/apache/flink/pull/12073#discussion_r426223741", "createdAt": "2020-05-17T06:35:13Z", "author": {"login": "KurtYoung"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,359 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\t@Nullable\n+\tprivate JobClient jobClient;\n+\t@Nullable\n+\tprivate CoordinationRequestGateway gateway;\n+\n+\tprivate boolean jobTerminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\tCollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.jobTerminated = false;\n+\t\tthis.closed = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t\tthis.gateway = (CoordinationRequestGateway) jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (jobTerminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tjobTerminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (jobTerminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\t// still no results, but job is still running, retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void close() {\n+\t\tif (closed) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tcancelJob();\n+\t\tclosed = true;\n+\t}\n+\n+\t@Override\n+\tprotected void finalize() throws Throwable {\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\tclose();\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tprivate CollectCoordinationResponse<T> sendRequest(\n+\t\t\tString version,\n+\t\t\tlong offset) throws InterruptedException, ExecutionException {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tOperatorID operatorId = operatorIdFuture.getNow(null);\n+\t\tPreconditions.checkNotNull(operatorId, \"Unknown operator ID. This is a bug.\");\n+\n+\t\tCollectCoordinationRequest request = new CollectCoordinationRequest(version, offset);\n+\t\treturn (CollectCoordinationResponse) gateway.sendCoordinationRequest(operatorId, request).get();\n+\t}\n+\n+\t@Nullable\n+\tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tJobExecutionResult executionResult;\n+\t\ttry {\n+\t\t\t// this timeout is sort of hack, see comments in isJobTerminated for explanation\n+\t\t\texecutionResult = jobClient.getJobExecutionResult(getClass().getClassLoader()).get(\n+\t\t\t\tDEFAULT_ACCUMULATOR_GET_MILLIS, TimeUnit.MILLISECONDS);\n+\t\t} catch (InterruptedException | ExecutionException | TimeoutException e) {\n+\t\t\tthrow new RuntimeException(\"Failed to fetch job execution result\", e);\n+\t\t}\n+\n+\t\tArrayList<byte[]> accResults = executionResult.getAccumulatorResult(accumulatorName);\n+\t\tif (accResults == null) {\n+\t\t\t// job terminates abnormally\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tList<byte[]> serializedResults =\n+\t\t\t\tSerializedListAccumulator.deserializeList(accResults, BytePrimitiveArraySerializer.INSTANCE);\n+\t\t\tbyte[] serializedResult = serializedResults.get(0);\n+\t\t\treturn CollectSinkFunction.deserializeAccumulatorResult(serializedResult);\n+\t\t} catch (ClassNotFoundException | IOException e) {\n+\t\t\t// this is impossible\n+\t\t\tthrow new RuntimeException(\"Failed to deserialize accumulator results\", e);\n+\t\t}\n+\t}\n+\n+\tprivate boolean isJobTerminated() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\ttry {\n+\t\t\tJobStatus status = jobClient.getJobStatus().get();\n+\t\t\treturn status.isGloballyTerminalState();\n+\t\t} catch (Exception e) {\n+\t\t\t// TODO\n+\t\t\t//  This is sort of hack.\n+\t\t\t//  Currently different execution environment will have different behaviors\n+\t\t\t//  when fetching a finished job status.\n+\t\t\t//  For example, standalone session cluster will return a normal FINISHED,\n+\t\t\t//  while mini cluster will throw IllegalStateException,\n+\t\t\t//  and yarn per job will throw ApplicationNotFoundException.\n+\t\t\t//  We have to assume that job has finished in this case.\n+\t\t\t//  Change this when these behaviors are unified.\n+\t\t\tLOG.warn(\"Failed to get job status so we assume that the job has terminated. Some data might be lost.\", e);\n+\t\t\treturn true;\n+\t\t}\n+\t}\n+\n+\tprivate void cancelJob() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tif (!isJobTerminated()) {\n+\t\t\tjobClient.cancel();\n+\t\t}\n+\t}\n+\n+\tprivate void sleepBeforeRetry() {\n+\t\tif (retryMillis <= 0) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\t// TODO a more proper retry strategy?\n+\t\t\tThread.sleep(retryMillis);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tLOG.warn(\"Interrupted when sleeping before a retry\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void checkJobClientConfigured() {\n+\t\tPreconditions.checkNotNull(jobClient, \"Job client must be configured before first use.\");\n+\t}\n+\n+\t/**\n+\t * A buffer which encapsulates the logic of dealing with the response from the {@link CollectSinkFunction}.\n+\t * See Java doc of {@link CollectSinkFunction} for explanation of this communication protocol.\n+\t */\n+\tprivate class ResultBuffer {\n+\n+\t\tprivate static final String INIT_VERSION = \"\";\n+\n+\t\tprivate final LinkedList<T> buffer;\n+\t\tprivate final TypeSerializer<T> serializer;\n+\n+\t\t// for detailed explanation of the following 3 variables, see Java doc of CollectSinkFunction\n+\t\t// `version` is to check if the sink restarts\n+\t\tprivate String version;\n+\t\t// `offset` is the offset of the next result we want to fetch\n+\t\tprivate long offset;\n+\n+\t\t// userVisibleHead <= user visible results offset < userVisibleTail\n+\t\tprivate long userVisibleHead;\n+\t\tprivate long userVisibleTail;\n+\n+\t\tprivate ResultBuffer(TypeSerializer<T> serializer) {\n+\t\t\tthis.buffer = new LinkedList<>();\n+\t\t\tthis.serializer = serializer;\n+\n+\t\t\tthis.version = INIT_VERSION;\n+\t\t\tthis.offset = 0;\n+\n+\t\t\tthis.userVisibleHead = 0;\n+\t\t\tthis.userVisibleTail = 0;\n+\t\t}\n+\n+\t\tprivate T next() {\n+\t\t\tif (userVisibleHead == userVisibleTail) {\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\tT ret = buffer.removeFirst();\n+\t\t\tuserVisibleHead++;\n+\n+\t\t\tsanityCheck();\n+\t\t\treturn ret;\n+\t\t}\n+\n+\t\tprivate void dealWithResponse(CollectCoordinationResponse<T> response) {\n+\t\t\tdealWithResponse(response, offset);\n+\t\t}\n+\n+\t\tprivate void dealWithResponse(CollectCoordinationResponse<T> response, long responseOffset) {\n+\t\t\tString responseVersion = response.getVersion();\n+\t\t\tlong responseLastCheckpointedOffset = response.getLastCheckpointedOffset();\n+\t\t\tList<T> results;\n+\t\t\ttry {\n+\t\t\t\tresults = response.getResults(serializer);\n+\t\t\t} catch (IOException e) {\n+\t\t\t\tthrow new RuntimeException(e);\n+\t\t\t}\n+\n+\t\t\t// we first check version in the response to decide whether we should throw away dirty results\n+\t\t\tif (!version.equals(responseVersion)) {\n+\t\t\t\t// sink restarted, we revert back to where the sink tells us\n+\t\t\t\tfor (long i = 0; i < offset - responseLastCheckpointedOffset; i++) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ad199a9f0a8db9ce82493af6e180af602774e29"}, "originalPosition": 321}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyOTU5Nw==", "bodyText": "\"less than offset\" should be \"less than or equal to offset\", because sink may have restarted before client fetches more results.", "url": "https://github.com/apache/flink/pull/12073#discussion_r426229597", "createdAt": "2020-05-17T07:46:48Z", "author": {"login": "tsreaper"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,359 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\t@Nullable\n+\tprivate JobClient jobClient;\n+\t@Nullable\n+\tprivate CoordinationRequestGateway gateway;\n+\n+\tprivate boolean jobTerminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\tCollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.jobTerminated = false;\n+\t\tthis.closed = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t\tthis.gateway = (CoordinationRequestGateway) jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (jobTerminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tjobTerminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (jobTerminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\t// still no results, but job is still running, retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void close() {\n+\t\tif (closed) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tcancelJob();\n+\t\tclosed = true;\n+\t}\n+\n+\t@Override\n+\tprotected void finalize() throws Throwable {\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\tclose();\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tprivate CollectCoordinationResponse<T> sendRequest(\n+\t\t\tString version,\n+\t\t\tlong offset) throws InterruptedException, ExecutionException {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tOperatorID operatorId = operatorIdFuture.getNow(null);\n+\t\tPreconditions.checkNotNull(operatorId, \"Unknown operator ID. This is a bug.\");\n+\n+\t\tCollectCoordinationRequest request = new CollectCoordinationRequest(version, offset);\n+\t\treturn (CollectCoordinationResponse) gateway.sendCoordinationRequest(operatorId, request).get();\n+\t}\n+\n+\t@Nullable\n+\tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tJobExecutionResult executionResult;\n+\t\ttry {\n+\t\t\t// this timeout is sort of hack, see comments in isJobTerminated for explanation\n+\t\t\texecutionResult = jobClient.getJobExecutionResult(getClass().getClassLoader()).get(\n+\t\t\t\tDEFAULT_ACCUMULATOR_GET_MILLIS, TimeUnit.MILLISECONDS);\n+\t\t} catch (InterruptedException | ExecutionException | TimeoutException e) {\n+\t\t\tthrow new RuntimeException(\"Failed to fetch job execution result\", e);\n+\t\t}\n+\n+\t\tArrayList<byte[]> accResults = executionResult.getAccumulatorResult(accumulatorName);\n+\t\tif (accResults == null) {\n+\t\t\t// job terminates abnormally\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tList<byte[]> serializedResults =\n+\t\t\t\tSerializedListAccumulator.deserializeList(accResults, BytePrimitiveArraySerializer.INSTANCE);\n+\t\t\tbyte[] serializedResult = serializedResults.get(0);\n+\t\t\treturn CollectSinkFunction.deserializeAccumulatorResult(serializedResult);\n+\t\t} catch (ClassNotFoundException | IOException e) {\n+\t\t\t// this is impossible\n+\t\t\tthrow new RuntimeException(\"Failed to deserialize accumulator results\", e);\n+\t\t}\n+\t}\n+\n+\tprivate boolean isJobTerminated() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\ttry {\n+\t\t\tJobStatus status = jobClient.getJobStatus().get();\n+\t\t\treturn status.isGloballyTerminalState();\n+\t\t} catch (Exception e) {\n+\t\t\t// TODO\n+\t\t\t//  This is sort of hack.\n+\t\t\t//  Currently different execution environment will have different behaviors\n+\t\t\t//  when fetching a finished job status.\n+\t\t\t//  For example, standalone session cluster will return a normal FINISHED,\n+\t\t\t//  while mini cluster will throw IllegalStateException,\n+\t\t\t//  and yarn per job will throw ApplicationNotFoundException.\n+\t\t\t//  We have to assume that job has finished in this case.\n+\t\t\t//  Change this when these behaviors are unified.\n+\t\t\tLOG.warn(\"Failed to get job status so we assume that the job has terminated. Some data might be lost.\", e);\n+\t\t\treturn true;\n+\t\t}\n+\t}\n+\n+\tprivate void cancelJob() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tif (!isJobTerminated()) {\n+\t\t\tjobClient.cancel();\n+\t\t}\n+\t}\n+\n+\tprivate void sleepBeforeRetry() {\n+\t\tif (retryMillis <= 0) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\t// TODO a more proper retry strategy?\n+\t\t\tThread.sleep(retryMillis);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tLOG.warn(\"Interrupted when sleeping before a retry\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void checkJobClientConfigured() {\n+\t\tPreconditions.checkNotNull(jobClient, \"Job client must be configured before first use.\");\n+\t}\n+\n+\t/**\n+\t * A buffer which encapsulates the logic of dealing with the response from the {@link CollectSinkFunction}.\n+\t * See Java doc of {@link CollectSinkFunction} for explanation of this communication protocol.\n+\t */\n+\tprivate class ResultBuffer {\n+\n+\t\tprivate static final String INIT_VERSION = \"\";\n+\n+\t\tprivate final LinkedList<T> buffer;\n+\t\tprivate final TypeSerializer<T> serializer;\n+\n+\t\t// for detailed explanation of the following 3 variables, see Java doc of CollectSinkFunction\n+\t\t// `version` is to check if the sink restarts\n+\t\tprivate String version;\n+\t\t// `offset` is the offset of the next result we want to fetch\n+\t\tprivate long offset;\n+\n+\t\t// userVisibleHead <= user visible results offset < userVisibleTail\n+\t\tprivate long userVisibleHead;\n+\t\tprivate long userVisibleTail;\n+\n+\t\tprivate ResultBuffer(TypeSerializer<T> serializer) {\n+\t\t\tthis.buffer = new LinkedList<>();\n+\t\t\tthis.serializer = serializer;\n+\n+\t\t\tthis.version = INIT_VERSION;\n+\t\t\tthis.offset = 0;\n+\n+\t\t\tthis.userVisibleHead = 0;\n+\t\t\tthis.userVisibleTail = 0;\n+\t\t}\n+\n+\t\tprivate T next() {\n+\t\t\tif (userVisibleHead == userVisibleTail) {\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\tT ret = buffer.removeFirst();\n+\t\t\tuserVisibleHead++;\n+\n+\t\t\tsanityCheck();\n+\t\t\treturn ret;\n+\t\t}\n+\n+\t\tprivate void dealWithResponse(CollectCoordinationResponse<T> response) {\n+\t\t\tdealWithResponse(response, offset);\n+\t\t}\n+\n+\t\tprivate void dealWithResponse(CollectCoordinationResponse<T> response, long responseOffset) {\n+\t\t\tString responseVersion = response.getVersion();\n+\t\t\tlong responseLastCheckpointedOffset = response.getLastCheckpointedOffset();\n+\t\t\tList<T> results;\n+\t\t\ttry {\n+\t\t\t\tresults = response.getResults(serializer);\n+\t\t\t} catch (IOException e) {\n+\t\t\t\tthrow new RuntimeException(e);\n+\t\t\t}\n+\n+\t\t\t// we first check version in the response to decide whether we should throw away dirty results\n+\t\t\tif (!version.equals(responseVersion)) {\n+\t\t\t\t// sink restarted, we revert back to where the sink tells us\n+\t\t\t\tfor (long i = 0; i < offset - responseLastCheckpointedOffset; i++) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyMzc0MQ=="}, "originalCommit": {"oid": "4ad199a9f0a8db9ce82493af6e180af602774e29"}, "originalPosition": 321}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NDM3NDQ4OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwNjo0MDoxOVrOGWeqDg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwNzoyNDozOFrOGWe4AA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyNDE0Mg==", "bodyText": "what about if responseOffset + results.size() still less than offset, which means you get a fully duplicated data?", "url": "https://github.com/apache/flink/pull/12073#discussion_r426224142", "createdAt": "2020-05-17T06:40:19Z", "author": {"login": "KurtYoung"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,359 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\t@Nullable\n+\tprivate JobClient jobClient;\n+\t@Nullable\n+\tprivate CoordinationRequestGateway gateway;\n+\n+\tprivate boolean jobTerminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\tCollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.jobTerminated = false;\n+\t\tthis.closed = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t\tthis.gateway = (CoordinationRequestGateway) jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (jobTerminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tjobTerminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (jobTerminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\t// still no results, but job is still running, retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void close() {\n+\t\tif (closed) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tcancelJob();\n+\t\tclosed = true;\n+\t}\n+\n+\t@Override\n+\tprotected void finalize() throws Throwable {\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\tclose();\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tprivate CollectCoordinationResponse<T> sendRequest(\n+\t\t\tString version,\n+\t\t\tlong offset) throws InterruptedException, ExecutionException {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tOperatorID operatorId = operatorIdFuture.getNow(null);\n+\t\tPreconditions.checkNotNull(operatorId, \"Unknown operator ID. This is a bug.\");\n+\n+\t\tCollectCoordinationRequest request = new CollectCoordinationRequest(version, offset);\n+\t\treturn (CollectCoordinationResponse) gateway.sendCoordinationRequest(operatorId, request).get();\n+\t}\n+\n+\t@Nullable\n+\tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tJobExecutionResult executionResult;\n+\t\ttry {\n+\t\t\t// this timeout is sort of hack, see comments in isJobTerminated for explanation\n+\t\t\texecutionResult = jobClient.getJobExecutionResult(getClass().getClassLoader()).get(\n+\t\t\t\tDEFAULT_ACCUMULATOR_GET_MILLIS, TimeUnit.MILLISECONDS);\n+\t\t} catch (InterruptedException | ExecutionException | TimeoutException e) {\n+\t\t\tthrow new RuntimeException(\"Failed to fetch job execution result\", e);\n+\t\t}\n+\n+\t\tArrayList<byte[]> accResults = executionResult.getAccumulatorResult(accumulatorName);\n+\t\tif (accResults == null) {\n+\t\t\t// job terminates abnormally\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tList<byte[]> serializedResults =\n+\t\t\t\tSerializedListAccumulator.deserializeList(accResults, BytePrimitiveArraySerializer.INSTANCE);\n+\t\t\tbyte[] serializedResult = serializedResults.get(0);\n+\t\t\treturn CollectSinkFunction.deserializeAccumulatorResult(serializedResult);\n+\t\t} catch (ClassNotFoundException | IOException e) {\n+\t\t\t// this is impossible\n+\t\t\tthrow new RuntimeException(\"Failed to deserialize accumulator results\", e);\n+\t\t}\n+\t}\n+\n+\tprivate boolean isJobTerminated() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\ttry {\n+\t\t\tJobStatus status = jobClient.getJobStatus().get();\n+\t\t\treturn status.isGloballyTerminalState();\n+\t\t} catch (Exception e) {\n+\t\t\t// TODO\n+\t\t\t//  This is sort of hack.\n+\t\t\t//  Currently different execution environment will have different behaviors\n+\t\t\t//  when fetching a finished job status.\n+\t\t\t//  For example, standalone session cluster will return a normal FINISHED,\n+\t\t\t//  while mini cluster will throw IllegalStateException,\n+\t\t\t//  and yarn per job will throw ApplicationNotFoundException.\n+\t\t\t//  We have to assume that job has finished in this case.\n+\t\t\t//  Change this when these behaviors are unified.\n+\t\t\tLOG.warn(\"Failed to get job status so we assume that the job has terminated. Some data might be lost.\", e);\n+\t\t\treturn true;\n+\t\t}\n+\t}\n+\n+\tprivate void cancelJob() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tif (!isJobTerminated()) {\n+\t\t\tjobClient.cancel();\n+\t\t}\n+\t}\n+\n+\tprivate void sleepBeforeRetry() {\n+\t\tif (retryMillis <= 0) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\t// TODO a more proper retry strategy?\n+\t\t\tThread.sleep(retryMillis);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tLOG.warn(\"Interrupted when sleeping before a retry\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void checkJobClientConfigured() {\n+\t\tPreconditions.checkNotNull(jobClient, \"Job client must be configured before first use.\");\n+\t}\n+\n+\t/**\n+\t * A buffer which encapsulates the logic of dealing with the response from the {@link CollectSinkFunction}.\n+\t * See Java doc of {@link CollectSinkFunction} for explanation of this communication protocol.\n+\t */\n+\tprivate class ResultBuffer {\n+\n+\t\tprivate static final String INIT_VERSION = \"\";\n+\n+\t\tprivate final LinkedList<T> buffer;\n+\t\tprivate final TypeSerializer<T> serializer;\n+\n+\t\t// for detailed explanation of the following 3 variables, see Java doc of CollectSinkFunction\n+\t\t// `version` is to check if the sink restarts\n+\t\tprivate String version;\n+\t\t// `offset` is the offset of the next result we want to fetch\n+\t\tprivate long offset;\n+\n+\t\t// userVisibleHead <= user visible results offset < userVisibleTail\n+\t\tprivate long userVisibleHead;\n+\t\tprivate long userVisibleTail;\n+\n+\t\tprivate ResultBuffer(TypeSerializer<T> serializer) {\n+\t\t\tthis.buffer = new LinkedList<>();\n+\t\t\tthis.serializer = serializer;\n+\n+\t\t\tthis.version = INIT_VERSION;\n+\t\t\tthis.offset = 0;\n+\n+\t\t\tthis.userVisibleHead = 0;\n+\t\t\tthis.userVisibleTail = 0;\n+\t\t}\n+\n+\t\tprivate T next() {\n+\t\t\tif (userVisibleHead == userVisibleTail) {\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\tT ret = buffer.removeFirst();\n+\t\t\tuserVisibleHead++;\n+\n+\t\t\tsanityCheck();\n+\t\t\treturn ret;\n+\t\t}\n+\n+\t\tprivate void dealWithResponse(CollectCoordinationResponse<T> response) {\n+\t\t\tdealWithResponse(response, offset);\n+\t\t}\n+\n+\t\tprivate void dealWithResponse(CollectCoordinationResponse<T> response, long responseOffset) {\n+\t\t\tString responseVersion = response.getVersion();\n+\t\t\tlong responseLastCheckpointedOffset = response.getLastCheckpointedOffset();\n+\t\t\tList<T> results;\n+\t\t\ttry {\n+\t\t\t\tresults = response.getResults(serializer);\n+\t\t\t} catch (IOException e) {\n+\t\t\t\tthrow new RuntimeException(e);\n+\t\t\t}\n+\n+\t\t\t// we first check version in the response to decide whether we should throw away dirty results\n+\t\t\tif (!version.equals(responseVersion)) {\n+\t\t\t\t// sink restarted, we revert back to where the sink tells us\n+\t\t\t\tfor (long i = 0; i < offset - responseLastCheckpointedOffset; i++) {\n+\t\t\t\t\tbuffer.removeLast();\n+\t\t\t\t}\n+\t\t\t\tversion = responseVersion;\n+\t\t\t\toffset = responseLastCheckpointedOffset;\n+\t\t\t}\n+\n+\t\t\t// we now check if more results can be seen by the user\n+\t\t\tif (responseLastCheckpointedOffset > userVisibleTail) {\n+\t\t\t\t// lastCheckpointedOffset increases, this means that more results have been\n+\t\t\t\t// checkpointed, and we can give these results to the user\n+\t\t\t\tuserVisibleTail = responseLastCheckpointedOffset;\n+\t\t\t}\n+\n+\t\t\tif (!results.isEmpty()) {\n+\t\t\t\t// response contains some data, add them to buffer\n+\t\t\t\tint addStart = (int) (offset - responseOffset);\n+\t\t\t\tList<T> addedResults = results.subList(addStart, results.size());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ad199a9f0a8db9ce82493af6e180af602774e29"}, "originalPosition": 338}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyNzcxMg==", "bodyText": "This is impossible. Because if this happens then the sink must have restarted, and we must have gone back to the last checkpointed offset. But I'll add a sanity check here.", "url": "https://github.com/apache/flink/pull/12073#discussion_r426227712", "createdAt": "2020-05-17T07:24:38Z", "author": {"login": "tsreaper"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,359 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\t@Nullable\n+\tprivate JobClient jobClient;\n+\t@Nullable\n+\tprivate CoordinationRequestGateway gateway;\n+\n+\tprivate boolean jobTerminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\tCollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.jobTerminated = false;\n+\t\tthis.closed = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t\tthis.gateway = (CoordinationRequestGateway) jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (jobTerminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tjobTerminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (jobTerminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\t// still no results, but job is still running, retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void close() {\n+\t\tif (closed) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tcancelJob();\n+\t\tclosed = true;\n+\t}\n+\n+\t@Override\n+\tprotected void finalize() throws Throwable {\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\tclose();\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tprivate CollectCoordinationResponse<T> sendRequest(\n+\t\t\tString version,\n+\t\t\tlong offset) throws InterruptedException, ExecutionException {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tOperatorID operatorId = operatorIdFuture.getNow(null);\n+\t\tPreconditions.checkNotNull(operatorId, \"Unknown operator ID. This is a bug.\");\n+\n+\t\tCollectCoordinationRequest request = new CollectCoordinationRequest(version, offset);\n+\t\treturn (CollectCoordinationResponse) gateway.sendCoordinationRequest(operatorId, request).get();\n+\t}\n+\n+\t@Nullable\n+\tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tJobExecutionResult executionResult;\n+\t\ttry {\n+\t\t\t// this timeout is sort of hack, see comments in isJobTerminated for explanation\n+\t\t\texecutionResult = jobClient.getJobExecutionResult(getClass().getClassLoader()).get(\n+\t\t\t\tDEFAULT_ACCUMULATOR_GET_MILLIS, TimeUnit.MILLISECONDS);\n+\t\t} catch (InterruptedException | ExecutionException | TimeoutException e) {\n+\t\t\tthrow new RuntimeException(\"Failed to fetch job execution result\", e);\n+\t\t}\n+\n+\t\tArrayList<byte[]> accResults = executionResult.getAccumulatorResult(accumulatorName);\n+\t\tif (accResults == null) {\n+\t\t\t// job terminates abnormally\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tList<byte[]> serializedResults =\n+\t\t\t\tSerializedListAccumulator.deserializeList(accResults, BytePrimitiveArraySerializer.INSTANCE);\n+\t\t\tbyte[] serializedResult = serializedResults.get(0);\n+\t\t\treturn CollectSinkFunction.deserializeAccumulatorResult(serializedResult);\n+\t\t} catch (ClassNotFoundException | IOException e) {\n+\t\t\t// this is impossible\n+\t\t\tthrow new RuntimeException(\"Failed to deserialize accumulator results\", e);\n+\t\t}\n+\t}\n+\n+\tprivate boolean isJobTerminated() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\ttry {\n+\t\t\tJobStatus status = jobClient.getJobStatus().get();\n+\t\t\treturn status.isGloballyTerminalState();\n+\t\t} catch (Exception e) {\n+\t\t\t// TODO\n+\t\t\t//  This is sort of hack.\n+\t\t\t//  Currently different execution environment will have different behaviors\n+\t\t\t//  when fetching a finished job status.\n+\t\t\t//  For example, standalone session cluster will return a normal FINISHED,\n+\t\t\t//  while mini cluster will throw IllegalStateException,\n+\t\t\t//  and yarn per job will throw ApplicationNotFoundException.\n+\t\t\t//  We have to assume that job has finished in this case.\n+\t\t\t//  Change this when these behaviors are unified.\n+\t\t\tLOG.warn(\"Failed to get job status so we assume that the job has terminated. Some data might be lost.\", e);\n+\t\t\treturn true;\n+\t\t}\n+\t}\n+\n+\tprivate void cancelJob() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tif (!isJobTerminated()) {\n+\t\t\tjobClient.cancel();\n+\t\t}\n+\t}\n+\n+\tprivate void sleepBeforeRetry() {\n+\t\tif (retryMillis <= 0) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\t// TODO a more proper retry strategy?\n+\t\t\tThread.sleep(retryMillis);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tLOG.warn(\"Interrupted when sleeping before a retry\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void checkJobClientConfigured() {\n+\t\tPreconditions.checkNotNull(jobClient, \"Job client must be configured before first use.\");\n+\t}\n+\n+\t/**\n+\t * A buffer which encapsulates the logic of dealing with the response from the {@link CollectSinkFunction}.\n+\t * See Java doc of {@link CollectSinkFunction} for explanation of this communication protocol.\n+\t */\n+\tprivate class ResultBuffer {\n+\n+\t\tprivate static final String INIT_VERSION = \"\";\n+\n+\t\tprivate final LinkedList<T> buffer;\n+\t\tprivate final TypeSerializer<T> serializer;\n+\n+\t\t// for detailed explanation of the following 3 variables, see Java doc of CollectSinkFunction\n+\t\t// `version` is to check if the sink restarts\n+\t\tprivate String version;\n+\t\t// `offset` is the offset of the next result we want to fetch\n+\t\tprivate long offset;\n+\n+\t\t// userVisibleHead <= user visible results offset < userVisibleTail\n+\t\tprivate long userVisibleHead;\n+\t\tprivate long userVisibleTail;\n+\n+\t\tprivate ResultBuffer(TypeSerializer<T> serializer) {\n+\t\t\tthis.buffer = new LinkedList<>();\n+\t\t\tthis.serializer = serializer;\n+\n+\t\t\tthis.version = INIT_VERSION;\n+\t\t\tthis.offset = 0;\n+\n+\t\t\tthis.userVisibleHead = 0;\n+\t\t\tthis.userVisibleTail = 0;\n+\t\t}\n+\n+\t\tprivate T next() {\n+\t\t\tif (userVisibleHead == userVisibleTail) {\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\tT ret = buffer.removeFirst();\n+\t\t\tuserVisibleHead++;\n+\n+\t\t\tsanityCheck();\n+\t\t\treturn ret;\n+\t\t}\n+\n+\t\tprivate void dealWithResponse(CollectCoordinationResponse<T> response) {\n+\t\t\tdealWithResponse(response, offset);\n+\t\t}\n+\n+\t\tprivate void dealWithResponse(CollectCoordinationResponse<T> response, long responseOffset) {\n+\t\t\tString responseVersion = response.getVersion();\n+\t\t\tlong responseLastCheckpointedOffset = response.getLastCheckpointedOffset();\n+\t\t\tList<T> results;\n+\t\t\ttry {\n+\t\t\t\tresults = response.getResults(serializer);\n+\t\t\t} catch (IOException e) {\n+\t\t\t\tthrow new RuntimeException(e);\n+\t\t\t}\n+\n+\t\t\t// we first check version in the response to decide whether we should throw away dirty results\n+\t\t\tif (!version.equals(responseVersion)) {\n+\t\t\t\t// sink restarted, we revert back to where the sink tells us\n+\t\t\t\tfor (long i = 0; i < offset - responseLastCheckpointedOffset; i++) {\n+\t\t\t\t\tbuffer.removeLast();\n+\t\t\t\t}\n+\t\t\t\tversion = responseVersion;\n+\t\t\t\toffset = responseLastCheckpointedOffset;\n+\t\t\t}\n+\n+\t\t\t// we now check if more results can be seen by the user\n+\t\t\tif (responseLastCheckpointedOffset > userVisibleTail) {\n+\t\t\t\t// lastCheckpointedOffset increases, this means that more results have been\n+\t\t\t\t// checkpointed, and we can give these results to the user\n+\t\t\t\tuserVisibleTail = responseLastCheckpointedOffset;\n+\t\t\t}\n+\n+\t\t\tif (!results.isEmpty()) {\n+\t\t\t\t// response contains some data, add them to buffer\n+\t\t\t\tint addStart = (int) (offset - responseOffset);\n+\t\t\t\tList<T> addedResults = results.subList(addStart, results.size());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyNDE0Mg=="}, "originalCommit": {"oid": "4ad199a9f0a8db9ce82493af6e180af602774e29"}, "originalPosition": 338}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NDM3ODEwOnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwNjo0NjoyOVrOGWer6Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwNjo0NjoyOVrOGWer6Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyNDYxNw==", "bodyText": "also check the gateway", "url": "https://github.com/apache/flink/pull/12073#discussion_r426224617", "createdAt": "2020-05-17T06:46:29Z", "author": {"login": "KurtYoung"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,359 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\t@Nullable\n+\tprivate JobClient jobClient;\n+\t@Nullable\n+\tprivate CoordinationRequestGateway gateway;\n+\n+\tprivate boolean jobTerminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\tCollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.jobTerminated = false;\n+\t\tthis.closed = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t\tthis.gateway = (CoordinationRequestGateway) jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (jobTerminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tjobTerminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (jobTerminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\t// still no results, but job is still running, retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void close() {\n+\t\tif (closed) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tcancelJob();\n+\t\tclosed = true;\n+\t}\n+\n+\t@Override\n+\tprotected void finalize() throws Throwable {\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\tclose();\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tprivate CollectCoordinationResponse<T> sendRequest(\n+\t\t\tString version,\n+\t\t\tlong offset) throws InterruptedException, ExecutionException {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tOperatorID operatorId = operatorIdFuture.getNow(null);\n+\t\tPreconditions.checkNotNull(operatorId, \"Unknown operator ID. This is a bug.\");\n+\n+\t\tCollectCoordinationRequest request = new CollectCoordinationRequest(version, offset);\n+\t\treturn (CollectCoordinationResponse) gateway.sendCoordinationRequest(operatorId, request).get();\n+\t}\n+\n+\t@Nullable\n+\tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tJobExecutionResult executionResult;\n+\t\ttry {\n+\t\t\t// this timeout is sort of hack, see comments in isJobTerminated for explanation\n+\t\t\texecutionResult = jobClient.getJobExecutionResult(getClass().getClassLoader()).get(\n+\t\t\t\tDEFAULT_ACCUMULATOR_GET_MILLIS, TimeUnit.MILLISECONDS);\n+\t\t} catch (InterruptedException | ExecutionException | TimeoutException e) {\n+\t\t\tthrow new RuntimeException(\"Failed to fetch job execution result\", e);\n+\t\t}\n+\n+\t\tArrayList<byte[]> accResults = executionResult.getAccumulatorResult(accumulatorName);\n+\t\tif (accResults == null) {\n+\t\t\t// job terminates abnormally\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tList<byte[]> serializedResults =\n+\t\t\t\tSerializedListAccumulator.deserializeList(accResults, BytePrimitiveArraySerializer.INSTANCE);\n+\t\t\tbyte[] serializedResult = serializedResults.get(0);\n+\t\t\treturn CollectSinkFunction.deserializeAccumulatorResult(serializedResult);\n+\t\t} catch (ClassNotFoundException | IOException e) {\n+\t\t\t// this is impossible\n+\t\t\tthrow new RuntimeException(\"Failed to deserialize accumulator results\", e);\n+\t\t}\n+\t}\n+\n+\tprivate boolean isJobTerminated() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\ttry {\n+\t\t\tJobStatus status = jobClient.getJobStatus().get();\n+\t\t\treturn status.isGloballyTerminalState();\n+\t\t} catch (Exception e) {\n+\t\t\t// TODO\n+\t\t\t//  This is sort of hack.\n+\t\t\t//  Currently different execution environment will have different behaviors\n+\t\t\t//  when fetching a finished job status.\n+\t\t\t//  For example, standalone session cluster will return a normal FINISHED,\n+\t\t\t//  while mini cluster will throw IllegalStateException,\n+\t\t\t//  and yarn per job will throw ApplicationNotFoundException.\n+\t\t\t//  We have to assume that job has finished in this case.\n+\t\t\t//  Change this when these behaviors are unified.\n+\t\t\tLOG.warn(\"Failed to get job status so we assume that the job has terminated. Some data might be lost.\", e);\n+\t\t\treturn true;\n+\t\t}\n+\t}\n+\n+\tprivate void cancelJob() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tif (!isJobTerminated()) {\n+\t\t\tjobClient.cancel();\n+\t\t}\n+\t}\n+\n+\tprivate void sleepBeforeRetry() {\n+\t\tif (retryMillis <= 0) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\t// TODO a more proper retry strategy?\n+\t\t\tThread.sleep(retryMillis);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tLOG.warn(\"Interrupted when sleeping before a retry\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void checkJobClientConfigured() {\n+\t\tPreconditions.checkNotNull(jobClient, \"Job client must be configured before first use.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ad199a9f0a8db9ce82493af6e180af602774e29"}, "originalPosition": 258}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NDM4MTE4OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwNjo1MTozM1rOGWetcQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwNjo1MTozM1rOGWetcQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyNTAwOQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {\n          \n          \n            \n            \tprivate Tuple2<Long, CollectCoordinationResponse<T>> getAccumulatorResults() {", "url": "https://github.com/apache/flink/pull/12073#discussion_r426225009", "createdAt": "2020-05-17T06:51:33Z", "author": {"login": "KurtYoung"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,359 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\t@Nullable\n+\tprivate JobClient jobClient;\n+\t@Nullable\n+\tprivate CoordinationRequestGateway gateway;\n+\n+\tprivate boolean jobTerminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\tCollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.jobTerminated = false;\n+\t\tthis.closed = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t\tthis.gateway = (CoordinationRequestGateway) jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (jobTerminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tjobTerminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (jobTerminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\t// still no results, but job is still running, retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void close() {\n+\t\tif (closed) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tcancelJob();\n+\t\tclosed = true;\n+\t}\n+\n+\t@Override\n+\tprotected void finalize() throws Throwable {\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\tclose();\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tprivate CollectCoordinationResponse<T> sendRequest(\n+\t\t\tString version,\n+\t\t\tlong offset) throws InterruptedException, ExecutionException {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tOperatorID operatorId = operatorIdFuture.getNow(null);\n+\t\tPreconditions.checkNotNull(operatorId, \"Unknown operator ID. This is a bug.\");\n+\n+\t\tCollectCoordinationRequest request = new CollectCoordinationRequest(version, offset);\n+\t\treturn (CollectCoordinationResponse) gateway.sendCoordinationRequest(operatorId, request).get();\n+\t}\n+\n+\t@Nullable\n+\tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ad199a9f0a8db9ce82493af6e180af602774e29"}, "originalPosition": 186}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NDM4NjY0OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwNzowMDoxMVrOGWewFA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwNzowMDoxMVrOGWewFA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyNTY4NA==", "bodyText": "throw IOException istead", "url": "https://github.com/apache/flink/pull/12073#discussion_r426225684", "createdAt": "2020-05-17T07:00:11Z", "author": {"login": "KurtYoung"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,359 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\t@Nullable\n+\tprivate JobClient jobClient;\n+\t@Nullable\n+\tprivate CoordinationRequestGateway gateway;\n+\n+\tprivate boolean jobTerminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\tCollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.jobTerminated = false;\n+\t\tthis.closed = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t\tthis.gateway = (CoordinationRequestGateway) jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (jobTerminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tjobTerminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (jobTerminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\t// still no results, but job is still running, retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void close() {\n+\t\tif (closed) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tcancelJob();\n+\t\tclosed = true;\n+\t}\n+\n+\t@Override\n+\tprotected void finalize() throws Throwable {\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\tclose();\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tprivate CollectCoordinationResponse<T> sendRequest(\n+\t\t\tString version,\n+\t\t\tlong offset) throws InterruptedException, ExecutionException {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tOperatorID operatorId = operatorIdFuture.getNow(null);\n+\t\tPreconditions.checkNotNull(operatorId, \"Unknown operator ID. This is a bug.\");\n+\n+\t\tCollectCoordinationRequest request = new CollectCoordinationRequest(version, offset);\n+\t\treturn (CollectCoordinationResponse) gateway.sendCoordinationRequest(operatorId, request).get();\n+\t}\n+\n+\t@Nullable\n+\tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tJobExecutionResult executionResult;\n+\t\ttry {\n+\t\t\t// this timeout is sort of hack, see comments in isJobTerminated for explanation\n+\t\t\texecutionResult = jobClient.getJobExecutionResult(getClass().getClassLoader()).get(\n+\t\t\t\tDEFAULT_ACCUMULATOR_GET_MILLIS, TimeUnit.MILLISECONDS);\n+\t\t} catch (InterruptedException | ExecutionException | TimeoutException e) {\n+\t\t\tthrow new RuntimeException(\"Failed to fetch job execution result\", e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ad199a9f0a8db9ce82493af6e180af602774e29"}, "originalPosition": 195}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NDM4NzUwOnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwNzowMToxOVrOGWewiA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwNzowMToxOVrOGWewiA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyNTgwMA==", "bodyText": "should let user know this is a abnormal case, throw an exception?", "url": "https://github.com/apache/flink/pull/12073#discussion_r426225800", "createdAt": "2020-05-17T07:01:19Z", "author": {"login": "KurtYoung"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,359 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\t@Nullable\n+\tprivate JobClient jobClient;\n+\t@Nullable\n+\tprivate CoordinationRequestGateway gateway;\n+\n+\tprivate boolean jobTerminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\tCollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.jobTerminated = false;\n+\t\tthis.closed = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t\tthis.gateway = (CoordinationRequestGateway) jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (jobTerminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tjobTerminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (jobTerminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\t// still no results, but job is still running, retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void close() {\n+\t\tif (closed) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tcancelJob();\n+\t\tclosed = true;\n+\t}\n+\n+\t@Override\n+\tprotected void finalize() throws Throwable {\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\tclose();\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tprivate CollectCoordinationResponse<T> sendRequest(\n+\t\t\tString version,\n+\t\t\tlong offset) throws InterruptedException, ExecutionException {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tOperatorID operatorId = operatorIdFuture.getNow(null);\n+\t\tPreconditions.checkNotNull(operatorId, \"Unknown operator ID. This is a bug.\");\n+\n+\t\tCollectCoordinationRequest request = new CollectCoordinationRequest(version, offset);\n+\t\treturn (CollectCoordinationResponse) gateway.sendCoordinationRequest(operatorId, request).get();\n+\t}\n+\n+\t@Nullable\n+\tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tJobExecutionResult executionResult;\n+\t\ttry {\n+\t\t\t// this timeout is sort of hack, see comments in isJobTerminated for explanation\n+\t\t\texecutionResult = jobClient.getJobExecutionResult(getClass().getClassLoader()).get(\n+\t\t\t\tDEFAULT_ACCUMULATOR_GET_MILLIS, TimeUnit.MILLISECONDS);\n+\t\t} catch (InterruptedException | ExecutionException | TimeoutException e) {\n+\t\t\tthrow new RuntimeException(\"Failed to fetch job execution result\", e);\n+\t\t}\n+\n+\t\tArrayList<byte[]> accResults = executionResult.getAccumulatorResult(accumulatorName);\n+\t\tif (accResults == null) {\n+\t\t\t// job terminates abnormally", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ad199a9f0a8db9ce82493af6e180af602774e29"}, "originalPosition": 200}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NDM5MDQxOnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwNzowNjo0NVrOGWeyJQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwNzowNjo0NVrOGWeyJQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyNjIxMw==", "bodyText": "Before we throw any exception, we should also try to cancel the job", "url": "https://github.com/apache/flink/pull/12073#discussion_r426226213", "createdAt": "2020-05-17T07:06:45Z", "author": {"login": "KurtYoung"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,359 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\t@Nullable\n+\tprivate JobClient jobClient;\n+\t@Nullable\n+\tprivate CoordinationRequestGateway gateway;\n+\n+\tprivate boolean jobTerminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\tCollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.jobTerminated = false;\n+\t\tthis.closed = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t\tthis.gateway = (CoordinationRequestGateway) jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (jobTerminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tjobTerminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (jobTerminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\t// still no results, but job is still running, retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void close() {\n+\t\tif (closed) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tcancelJob();\n+\t\tclosed = true;\n+\t}\n+\n+\t@Override\n+\tprotected void finalize() throws Throwable {\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\tclose();\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tprivate CollectCoordinationResponse<T> sendRequest(\n+\t\t\tString version,\n+\t\t\tlong offset) throws InterruptedException, ExecutionException {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tOperatorID operatorId = operatorIdFuture.getNow(null);\n+\t\tPreconditions.checkNotNull(operatorId, \"Unknown operator ID. This is a bug.\");\n+\n+\t\tCollectCoordinationRequest request = new CollectCoordinationRequest(version, offset);\n+\t\treturn (CollectCoordinationResponse) gateway.sendCoordinationRequest(operatorId, request).get();\n+\t}\n+\n+\t@Nullable\n+\tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tJobExecutionResult executionResult;\n+\t\ttry {\n+\t\t\t// this timeout is sort of hack, see comments in isJobTerminated for explanation\n+\t\t\texecutionResult = jobClient.getJobExecutionResult(getClass().getClassLoader()).get(\n+\t\t\t\tDEFAULT_ACCUMULATOR_GET_MILLIS, TimeUnit.MILLISECONDS);\n+\t\t} catch (InterruptedException | ExecutionException | TimeoutException e) {\n+\t\t\tthrow new RuntimeException(\"Failed to fetch job execution result\", e);\n+\t\t}\n+\n+\t\tArrayList<byte[]> accResults = executionResult.getAccumulatorResult(accumulatorName);\n+\t\tif (accResults == null) {\n+\t\t\t// job terminates abnormally\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tList<byte[]> serializedResults =\n+\t\t\t\tSerializedListAccumulator.deserializeList(accResults, BytePrimitiveArraySerializer.INSTANCE);\n+\t\t\tbyte[] serializedResult = serializedResults.get(0);\n+\t\t\treturn CollectSinkFunction.deserializeAccumulatorResult(serializedResult);\n+\t\t} catch (ClassNotFoundException | IOException e) {\n+\t\t\t// this is impossible\n+\t\t\tthrow new RuntimeException(\"Failed to deserialize accumulator results\", e);\n+\t\t}\n+\t}\n+\n+\tprivate boolean isJobTerminated() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\ttry {\n+\t\t\tJobStatus status = jobClient.getJobStatus().get();\n+\t\t\treturn status.isGloballyTerminalState();\n+\t\t} catch (Exception e) {\n+\t\t\t// TODO\n+\t\t\t//  This is sort of hack.\n+\t\t\t//  Currently different execution environment will have different behaviors\n+\t\t\t//  when fetching a finished job status.\n+\t\t\t//  For example, standalone session cluster will return a normal FINISHED,\n+\t\t\t//  while mini cluster will throw IllegalStateException,\n+\t\t\t//  and yarn per job will throw ApplicationNotFoundException.\n+\t\t\t//  We have to assume that job has finished in this case.\n+\t\t\t//  Change this when these behaviors are unified.\n+\t\t\tLOG.warn(\"Failed to get job status so we assume that the job has terminated. Some data might be lost.\", e);\n+\t\t\treturn true;\n+\t\t}\n+\t}\n+\n+\tprivate void cancelJob() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ad199a9f0a8db9ce82493af6e180af602774e29"}, "originalPosition": 236}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NDM5NDA0OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwNzoxMjo0MVrOGWez_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QwNzoxMjo0MVrOGWez_g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyNjY4Ng==", "bodyText": "change this to do {} while, maybe we can reuse these statements with line 110 - line 117?", "url": "https://github.com/apache/flink/pull/12073#discussion_r426226686", "createdAt": "2020-05-17T07:12:41Z", "author": {"login": "KurtYoung"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,359 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\t@Nullable\n+\tprivate JobClient jobClient;\n+\t@Nullable\n+\tprivate CoordinationRequestGateway gateway;\n+\n+\tprivate boolean jobTerminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\tCollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.jobTerminated = false;\n+\t\tthis.closed = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t\tthis.gateway = (CoordinationRequestGateway) jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (jobTerminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tjobTerminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (jobTerminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ad199a9f0a8db9ce82493af6e180af602774e29"}, "originalPosition": 150}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NDU1NDAyOnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QxMTowODoyMVrOGWgHkg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QxMTowODoyMVrOGWgHkg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjI0ODA4Mg==", "bodyText": "how about throw IOException instead?", "url": "https://github.com/apache/flink/pull/12073#discussion_r426248082", "createdAt": "2020-05-17T11:08:21Z", "author": {"login": "KurtYoung"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,358 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\t@Nullable\n+\tprivate JobClient jobClient;\n+\t@Nullable\n+\tprivate CoordinationRequestGateway gateway;\n+\n+\tprivate boolean jobTerminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\tCollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.jobTerminated = false;\n+\t\tthis.closed = false;\n+\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\t// this is only an insurance,\n+\t\t// it's the user's responsibility to close the iterator if he does not need it anymore\n+\t\tRuntime.getRuntime().addShutdownHook(new Thread(this::close));\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t\tthis.gateway = (CoordinationRequestGateway) jobClient;\n+\t}\n+\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// this is to avoid sleeping before first try\n+\t\tboolean beforeFirstTry = true;\n+\t\tdo {\n+\t\t\tT res = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// we still have user-visible results, just use them\n+\t\t\t\treturn res;\n+\t\t\t} else if (jobTerminated) {\n+\t\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else if (!beforeFirstTry) {\n+\t\t\t\t// no results but job is still running, sleep before retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t\tbeforeFirstTry = false;\n+\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tjobTerminated = true;\n+\t\t\t\ttry {\n+\t\t\t\t\tTuple2<Long, CollectCoordinationResponse<T>> accResults = getAccumulatorResults();\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t} catch (IOException e) {\n+\t\t\t\t\tclose();\n+\t\t\t\t\tthrow new RuntimeException(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc45779cd014b587a2fbed2393683ff4fe73a38b"}, "originalPosition": 138}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NDU1NDY0OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QxMTowOToyM1rOGWgH5w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QxMTowOToyM1rOGWgH5w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjI0ODE2Nw==", "bodyText": "ditto", "url": "https://github.com/apache/flink/pull/12073#discussion_r426248167", "createdAt": "2020-05-17T11:09:23Z", "author": {"login": "KurtYoung"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,358 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\t@Nullable\n+\tprivate JobClient jobClient;\n+\t@Nullable\n+\tprivate CoordinationRequestGateway gateway;\n+\n+\tprivate boolean jobTerminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\tCollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.jobTerminated = false;\n+\t\tthis.closed = false;\n+\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\t// this is only an insurance,\n+\t\t// it's the user's responsibility to close the iterator if he does not need it anymore\n+\t\tRuntime.getRuntime().addShutdownHook(new Thread(this::close));\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t\tthis.gateway = (CoordinationRequestGateway) jobClient;\n+\t}\n+\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// this is to avoid sleeping before first try\n+\t\tboolean beforeFirstTry = true;\n+\t\tdo {\n+\t\t\tT res = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// we still have user-visible results, just use them\n+\t\t\t\treturn res;\n+\t\t\t} else if (jobTerminated) {\n+\t\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else if (!beforeFirstTry) {\n+\t\t\t\t// no results but job is still running, sleep before retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t\tbeforeFirstTry = false;\n+\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tjobTerminated = true;\n+\t\t\t\ttry {\n+\t\t\t\t\tTuple2<Long, CollectCoordinationResponse<T>> accResults = getAccumulatorResults();\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t} catch (IOException e) {\n+\t\t\t\t\tclose();\n+\t\t\t\t\tthrow new RuntimeException(\n+\t\t\t\t\t\t\"Failed to deal with final accumulator results, final batch of results are lost\", e);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tlong requestOffset = buffer.offset;\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, requestOffset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\t// the response will contain data (if any) starting exactly from requested offset\n+\t\t\t\ttry {\n+\t\t\t\t\tbuffer.dealWithResponse(response, requestOffset);\n+\t\t\t\t} catch (IOException e) {\n+\t\t\t\t\tclose();\n+\t\t\t\t\tthrow new RuntimeException(\"Failed to deal with response from sink\", e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc45779cd014b587a2fbed2393683ff4fe73a38b"}, "originalPosition": 157}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1396, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}