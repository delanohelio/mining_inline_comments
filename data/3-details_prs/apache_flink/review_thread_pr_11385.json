{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg2OTg2ODI1", "number": 11385, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxMTo0ODozMlrOD7nRPg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxMTo1MTo0NVrOD7nVKQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYzODM1OTY2OnYy", "diffSide": "RIGHT", "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroWriters.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxMTo0ODozMlrOGUCzVg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QwNDoxMToxNVrOGUgy8w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzY3MDYxNA==", "bodyText": "To configure what? This interface looks weird to me.", "url": "https://github.com/apache/flink/pull/11385#discussion_r423670614", "createdAt": "2020-05-12T11:48:32Z", "author": {"login": "JingsongLi"}, "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroWriters.java", "diffHunk": "@@ -0,0 +1,197 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.formats.avro;\n+\n+import org.apache.avro.Schema;\n+import org.apache.avro.file.DataFileWriter;\n+import org.apache.avro.generic.GenericDatumWriter;\n+import org.apache.avro.generic.GenericRecord;\n+import org.apache.avro.io.DatumWriter;\n+import org.apache.avro.reflect.ReflectData;\n+import org.apache.avro.reflect.ReflectDatumWriter;\n+import org.apache.avro.specific.SpecificData;\n+import org.apache.avro.specific.SpecificDatumWriter;\n+import org.apache.avro.specific.SpecificRecord;\n+import org.apache.avro.specific.SpecificRecordBase;\n+\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.io.Serializable;\n+\n+/**\n+ * Convenience builder to create {@link AvroWriterFactory} instances for the different Avro types.\n+ */\n+public class AvroWriters {\n+\n+\t/**\n+\t * A configurator to set the properties of the writer.\n+\t */\n+\tpublic interface WriterConfigurator<T> extends Serializable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f5daa5c0432bbc64add6d302841f26e9d919ce98"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDE2MjAzNQ==", "bodyText": "It should be used to configure DataFileWriter, I have changed the name to DataFileWriterConfigurator.", "url": "https://github.com/apache/flink/pull/11385#discussion_r424162035", "createdAt": "2020-05-13T04:11:15Z", "author": {"login": "gaoyunhaii"}, "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroWriters.java", "diffHunk": "@@ -0,0 +1,197 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.formats.avro;\n+\n+import org.apache.avro.Schema;\n+import org.apache.avro.file.DataFileWriter;\n+import org.apache.avro.generic.GenericDatumWriter;\n+import org.apache.avro.generic.GenericRecord;\n+import org.apache.avro.io.DatumWriter;\n+import org.apache.avro.reflect.ReflectData;\n+import org.apache.avro.reflect.ReflectDatumWriter;\n+import org.apache.avro.specific.SpecificData;\n+import org.apache.avro.specific.SpecificDatumWriter;\n+import org.apache.avro.specific.SpecificRecord;\n+import org.apache.avro.specific.SpecificRecordBase;\n+\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.io.Serializable;\n+\n+/**\n+ * Convenience builder to create {@link AvroWriterFactory} instances for the different Avro types.\n+ */\n+public class AvroWriters {\n+\n+\t/**\n+\t * A configurator to set the properties of the writer.\n+\t */\n+\tpublic interface WriterConfigurator<T> extends Serializable {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzY3MDYxNA=="}, "originalCommit": {"oid": "f5daa5c0432bbc64add6d302841f26e9d919ce98"}, "originalPosition": 45}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYzODM2NjMyOnYy", "diffSide": "RIGHT", "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroWriters.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxMTo1MDo0MlrOGUC3ig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxMTo1MDo0MlrOGUC3ig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzY3MTY5MA==", "bodyText": "Pass a Function<Schema, DatumWriter>?", "url": "https://github.com/apache/flink/pull/11385#discussion_r423671690", "createdAt": "2020-05-12T11:50:42Z", "author": {"login": "JingsongLi"}, "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroWriters.java", "diffHunk": "@@ -0,0 +1,197 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.formats.avro;\n+\n+import org.apache.avro.Schema;\n+import org.apache.avro.file.DataFileWriter;\n+import org.apache.avro.generic.GenericDatumWriter;\n+import org.apache.avro.generic.GenericRecord;\n+import org.apache.avro.io.DatumWriter;\n+import org.apache.avro.reflect.ReflectData;\n+import org.apache.avro.reflect.ReflectDatumWriter;\n+import org.apache.avro.specific.SpecificData;\n+import org.apache.avro.specific.SpecificDatumWriter;\n+import org.apache.avro.specific.SpecificRecord;\n+import org.apache.avro.specific.SpecificRecordBase;\n+\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.io.Serializable;\n+\n+/**\n+ * Convenience builder to create {@link AvroWriterFactory} instances for the different Avro types.\n+ */\n+public class AvroWriters {\n+\n+\t/**\n+\t * A configurator to set the properties of the writer.\n+\t */\n+\tpublic interface WriterConfigurator<T> extends Serializable {\n+\n+\t\t/**\n+\t\t * Modifies the properties of the writer.\n+\t\t *\n+\t\t * @param dataFileWriter The writer to modify.\n+\t\t */\n+\t\tvoid configureWriter(DataFileWriter<T> dataFileWriter);\n+\n+\t}\n+\n+\t/**\n+\t * Creates an {@link AvroWriterFactory} for an Avro specific type. The Avro writers\n+\t * will use the schema of that specific type to build and write the records.\n+\t *\n+\t * @param type The class of the type to write.\n+\t */\n+\tpublic static <T extends SpecificRecordBase> AvroWriterFactory<T> forSpecificRecord(Class<T> type) {\n+\t\treturn forSpecificRecord(type, writer -> {});\n+\t}\n+\n+\t/**\n+\t * Creates an {@link AvroWriterFactory} for an Avro specific type and given <tt>configurator</tt>.\n+\t * The Avro writers will use the schema of that specific type to build and write the records.\n+\t *\n+\t * @param type The class of the type to write.\n+\t * @param configurator The configurator to modify the writer properties.\n+\t */\n+\tpublic static <T extends SpecificRecordBase> AvroWriterFactory<T> forSpecificRecord(\n+\t\tClass<T> type,\n+\t\tWriterConfigurator<T> configurator) {\n+\n+\t\tString schemaString = SpecificData.get().getSchema(type).toString();\n+\t\tAvroBuilder<T> builder = (out) -> createAvroDataFileWriter(\n+\t\t\tschemaString,\n+\t\t\tAvroRecordType.SPECIFIC,\n+\t\t\tconfigurator,\n+\t\t\tout);\n+\t\treturn new AvroWriterFactory<>(builder);\n+\t}\n+\n+\t/**\n+\t * Creates an {@link AvroWriterFactory} that accepts and writes Avro generic types.\n+\t * The Avro writers will use the given schema to build and write the records.\n+\t *\n+\t * @param schema The schema of the generic type.\n+\t */\n+\tpublic static AvroWriterFactory<GenericRecord> forGenericRecord(Schema schema) {\n+\t\treturn forGenericRecord(schema, writer -> {});\n+\t}\n+\n+\t/**\n+\t * Creates an {@link AvroWriterFactory} that accepts and writes Avro generic types\n+\t * and given <tt>configurator</tt>. The Avro writers will use the given schema to\n+\t * build and write the records.\n+\t *\n+\t * @param schema The schema of the generic type.\n+\t * @param configurator The configurator to modify the writer properties.\n+\t */\n+\tpublic static AvroWriterFactory<GenericRecord> forGenericRecord(\n+\t\tSchema schema,\n+\t\tWriterConfigurator<GenericRecord> configurator) {\n+\n+\t\tString schemaString = schema.toString();\n+\t\tAvroBuilder<GenericRecord> builder = (out) -> createAvroDataFileWriter(\n+\t\t\tschemaString,\n+\t\t\tAvroRecordType.GENERIC,\n+\t\t\tconfigurator,\n+\t\t\tout);\n+\t\treturn new AvroWriterFactory<>(builder);\n+\t}\n+\n+\t/**\n+\t * Creates an {@link AvroWriterFactory} for the given type. The Avro writers will\n+\t * use reflection to create the schema for the type and use that schema to write\n+\t * the records.\n+\t *\n+\t * @param type The class of the type to write.\n+\t */\n+\tpublic static <T> AvroWriterFactory<T> forReflectRecord(Class<T> type) {\n+\t\treturn forReflectRecord(type, writer -> {});\n+\t}\n+\n+\t/**\n+\t * Creates an {@link AvroWriterFactory} for the given type and given <tt>configurator</tt>.\n+\t * The Avro writers will use reflection to create the schema for the type and use that schema\n+\t * to write the records.\n+\t *\n+\t * @param type The class of the type to write.\n+\t * @param configurator The configurator to modify the writer properties.\n+\t */\n+\tpublic static <T> AvroWriterFactory<T> forReflectRecord(\n+\t\tClass<T> type,\n+\t\tWriterConfigurator<T> configurator) {\n+\n+\t\tString schemaString = ReflectData.get().getSchema(type).toString();\n+\t\tAvroBuilder<T> builder = (out) -> createAvroDataFileWriter(\n+\t\t\tschemaString,\n+\t\t\tAvroRecordType.REFLECT,\n+\t\t\tconfigurator,\n+\t\t\tout);\n+\t\treturn new AvroWriterFactory<>(builder);\n+\t}\n+\n+\tprivate static <T> DataFileWriter<T> createAvroDataFileWriter(\n+\t\tString schemaString,\n+\t\tAvroRecordType recordType,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f5daa5c0432bbc64add6d302841f26e9d919ce98"}, "originalPosition": 151}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYzODM2OTY5OnYy", "diffSide": "RIGHT", "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroWriters.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxMTo1MTo0NVrOGUC5vQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QwNDoxNTo1MlrOGUg2zg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzY3MjI1Mw==", "bodyText": "Just Schema?", "url": "https://github.com/apache/flink/pull/11385#discussion_r423672253", "createdAt": "2020-05-12T11:51:45Z", "author": {"login": "JingsongLi"}, "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroWriters.java", "diffHunk": "@@ -0,0 +1,197 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.formats.avro;\n+\n+import org.apache.avro.Schema;\n+import org.apache.avro.file.DataFileWriter;\n+import org.apache.avro.generic.GenericDatumWriter;\n+import org.apache.avro.generic.GenericRecord;\n+import org.apache.avro.io.DatumWriter;\n+import org.apache.avro.reflect.ReflectData;\n+import org.apache.avro.reflect.ReflectDatumWriter;\n+import org.apache.avro.specific.SpecificData;\n+import org.apache.avro.specific.SpecificDatumWriter;\n+import org.apache.avro.specific.SpecificRecord;\n+import org.apache.avro.specific.SpecificRecordBase;\n+\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.io.Serializable;\n+\n+/**\n+ * Convenience builder to create {@link AvroWriterFactory} instances for the different Avro types.\n+ */\n+public class AvroWriters {\n+\n+\t/**\n+\t * A configurator to set the properties of the writer.\n+\t */\n+\tpublic interface WriterConfigurator<T> extends Serializable {\n+\n+\t\t/**\n+\t\t * Modifies the properties of the writer.\n+\t\t *\n+\t\t * @param dataFileWriter The writer to modify.\n+\t\t */\n+\t\tvoid configureWriter(DataFileWriter<T> dataFileWriter);\n+\n+\t}\n+\n+\t/**\n+\t * Creates an {@link AvroWriterFactory} for an Avro specific type. The Avro writers\n+\t * will use the schema of that specific type to build and write the records.\n+\t *\n+\t * @param type The class of the type to write.\n+\t */\n+\tpublic static <T extends SpecificRecordBase> AvroWriterFactory<T> forSpecificRecord(Class<T> type) {\n+\t\treturn forSpecificRecord(type, writer -> {});\n+\t}\n+\n+\t/**\n+\t * Creates an {@link AvroWriterFactory} for an Avro specific type and given <tt>configurator</tt>.\n+\t * The Avro writers will use the schema of that specific type to build and write the records.\n+\t *\n+\t * @param type The class of the type to write.\n+\t * @param configurator The configurator to modify the writer properties.\n+\t */\n+\tpublic static <T extends SpecificRecordBase> AvroWriterFactory<T> forSpecificRecord(\n+\t\tClass<T> type,\n+\t\tWriterConfigurator<T> configurator) {\n+\n+\t\tString schemaString = SpecificData.get().getSchema(type).toString();\n+\t\tAvroBuilder<T> builder = (out) -> createAvroDataFileWriter(\n+\t\t\tschemaString,\n+\t\t\tAvroRecordType.SPECIFIC,\n+\t\t\tconfigurator,\n+\t\t\tout);\n+\t\treturn new AvroWriterFactory<>(builder);\n+\t}\n+\n+\t/**\n+\t * Creates an {@link AvroWriterFactory} that accepts and writes Avro generic types.\n+\t * The Avro writers will use the given schema to build and write the records.\n+\t *\n+\t * @param schema The schema of the generic type.\n+\t */\n+\tpublic static AvroWriterFactory<GenericRecord> forGenericRecord(Schema schema) {\n+\t\treturn forGenericRecord(schema, writer -> {});\n+\t}\n+\n+\t/**\n+\t * Creates an {@link AvroWriterFactory} that accepts and writes Avro generic types\n+\t * and given <tt>configurator</tt>. The Avro writers will use the given schema to\n+\t * build and write the records.\n+\t *\n+\t * @param schema The schema of the generic type.\n+\t * @param configurator The configurator to modify the writer properties.\n+\t */\n+\tpublic static AvroWriterFactory<GenericRecord> forGenericRecord(\n+\t\tSchema schema,\n+\t\tWriterConfigurator<GenericRecord> configurator) {\n+\n+\t\tString schemaString = schema.toString();\n+\t\tAvroBuilder<GenericRecord> builder = (out) -> createAvroDataFileWriter(\n+\t\t\tschemaString,\n+\t\t\tAvroRecordType.GENERIC,\n+\t\t\tconfigurator,\n+\t\t\tout);\n+\t\treturn new AvroWriterFactory<>(builder);\n+\t}\n+\n+\t/**\n+\t * Creates an {@link AvroWriterFactory} for the given type. The Avro writers will\n+\t * use reflection to create the schema for the type and use that schema to write\n+\t * the records.\n+\t *\n+\t * @param type The class of the type to write.\n+\t */\n+\tpublic static <T> AvroWriterFactory<T> forReflectRecord(Class<T> type) {\n+\t\treturn forReflectRecord(type, writer -> {});\n+\t}\n+\n+\t/**\n+\t * Creates an {@link AvroWriterFactory} for the given type and given <tt>configurator</tt>.\n+\t * The Avro writers will use reflection to create the schema for the type and use that schema\n+\t * to write the records.\n+\t *\n+\t * @param type The class of the type to write.\n+\t * @param configurator The configurator to modify the writer properties.\n+\t */\n+\tpublic static <T> AvroWriterFactory<T> forReflectRecord(\n+\t\tClass<T> type,\n+\t\tWriterConfigurator<T> configurator) {\n+\n+\t\tString schemaString = ReflectData.get().getSchema(type).toString();\n+\t\tAvroBuilder<T> builder = (out) -> createAvroDataFileWriter(\n+\t\t\tschemaString,\n+\t\t\tAvroRecordType.REFLECT,\n+\t\t\tconfigurator,\n+\t\t\tout);\n+\t\treturn new AvroWriterFactory<>(builder);\n+\t}\n+\n+\tprivate static <T> DataFileWriter<T> createAvroDataFileWriter(\n+\t\tString schemaString,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f5daa5c0432bbc64add6d302841f26e9d919ce98"}, "originalPosition": 150}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDE2MzAyMg==", "bodyText": "We cannot directly pass schema because schema is not serializable, and since shcemaString (or schema) is reference by the anonymous function builder, it must be serializable.", "url": "https://github.com/apache/flink/pull/11385#discussion_r424163022", "createdAt": "2020-05-13T04:15:52Z", "author": {"login": "gaoyunhaii"}, "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroWriters.java", "diffHunk": "@@ -0,0 +1,197 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.formats.avro;\n+\n+import org.apache.avro.Schema;\n+import org.apache.avro.file.DataFileWriter;\n+import org.apache.avro.generic.GenericDatumWriter;\n+import org.apache.avro.generic.GenericRecord;\n+import org.apache.avro.io.DatumWriter;\n+import org.apache.avro.reflect.ReflectData;\n+import org.apache.avro.reflect.ReflectDatumWriter;\n+import org.apache.avro.specific.SpecificData;\n+import org.apache.avro.specific.SpecificDatumWriter;\n+import org.apache.avro.specific.SpecificRecord;\n+import org.apache.avro.specific.SpecificRecordBase;\n+\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.io.Serializable;\n+\n+/**\n+ * Convenience builder to create {@link AvroWriterFactory} instances for the different Avro types.\n+ */\n+public class AvroWriters {\n+\n+\t/**\n+\t * A configurator to set the properties of the writer.\n+\t */\n+\tpublic interface WriterConfigurator<T> extends Serializable {\n+\n+\t\t/**\n+\t\t * Modifies the properties of the writer.\n+\t\t *\n+\t\t * @param dataFileWriter The writer to modify.\n+\t\t */\n+\t\tvoid configureWriter(DataFileWriter<T> dataFileWriter);\n+\n+\t}\n+\n+\t/**\n+\t * Creates an {@link AvroWriterFactory} for an Avro specific type. The Avro writers\n+\t * will use the schema of that specific type to build and write the records.\n+\t *\n+\t * @param type The class of the type to write.\n+\t */\n+\tpublic static <T extends SpecificRecordBase> AvroWriterFactory<T> forSpecificRecord(Class<T> type) {\n+\t\treturn forSpecificRecord(type, writer -> {});\n+\t}\n+\n+\t/**\n+\t * Creates an {@link AvroWriterFactory} for an Avro specific type and given <tt>configurator</tt>.\n+\t * The Avro writers will use the schema of that specific type to build and write the records.\n+\t *\n+\t * @param type The class of the type to write.\n+\t * @param configurator The configurator to modify the writer properties.\n+\t */\n+\tpublic static <T extends SpecificRecordBase> AvroWriterFactory<T> forSpecificRecord(\n+\t\tClass<T> type,\n+\t\tWriterConfigurator<T> configurator) {\n+\n+\t\tString schemaString = SpecificData.get().getSchema(type).toString();\n+\t\tAvroBuilder<T> builder = (out) -> createAvroDataFileWriter(\n+\t\t\tschemaString,\n+\t\t\tAvroRecordType.SPECIFIC,\n+\t\t\tconfigurator,\n+\t\t\tout);\n+\t\treturn new AvroWriterFactory<>(builder);\n+\t}\n+\n+\t/**\n+\t * Creates an {@link AvroWriterFactory} that accepts and writes Avro generic types.\n+\t * The Avro writers will use the given schema to build and write the records.\n+\t *\n+\t * @param schema The schema of the generic type.\n+\t */\n+\tpublic static AvroWriterFactory<GenericRecord> forGenericRecord(Schema schema) {\n+\t\treturn forGenericRecord(schema, writer -> {});\n+\t}\n+\n+\t/**\n+\t * Creates an {@link AvroWriterFactory} that accepts and writes Avro generic types\n+\t * and given <tt>configurator</tt>. The Avro writers will use the given schema to\n+\t * build and write the records.\n+\t *\n+\t * @param schema The schema of the generic type.\n+\t * @param configurator The configurator to modify the writer properties.\n+\t */\n+\tpublic static AvroWriterFactory<GenericRecord> forGenericRecord(\n+\t\tSchema schema,\n+\t\tWriterConfigurator<GenericRecord> configurator) {\n+\n+\t\tString schemaString = schema.toString();\n+\t\tAvroBuilder<GenericRecord> builder = (out) -> createAvroDataFileWriter(\n+\t\t\tschemaString,\n+\t\t\tAvroRecordType.GENERIC,\n+\t\t\tconfigurator,\n+\t\t\tout);\n+\t\treturn new AvroWriterFactory<>(builder);\n+\t}\n+\n+\t/**\n+\t * Creates an {@link AvroWriterFactory} for the given type. The Avro writers will\n+\t * use reflection to create the schema for the type and use that schema to write\n+\t * the records.\n+\t *\n+\t * @param type The class of the type to write.\n+\t */\n+\tpublic static <T> AvroWriterFactory<T> forReflectRecord(Class<T> type) {\n+\t\treturn forReflectRecord(type, writer -> {});\n+\t}\n+\n+\t/**\n+\t * Creates an {@link AvroWriterFactory} for the given type and given <tt>configurator</tt>.\n+\t * The Avro writers will use reflection to create the schema for the type and use that schema\n+\t * to write the records.\n+\t *\n+\t * @param type The class of the type to write.\n+\t * @param configurator The configurator to modify the writer properties.\n+\t */\n+\tpublic static <T> AvroWriterFactory<T> forReflectRecord(\n+\t\tClass<T> type,\n+\t\tWriterConfigurator<T> configurator) {\n+\n+\t\tString schemaString = ReflectData.get().getSchema(type).toString();\n+\t\tAvroBuilder<T> builder = (out) -> createAvroDataFileWriter(\n+\t\t\tschemaString,\n+\t\t\tAvroRecordType.REFLECT,\n+\t\t\tconfigurator,\n+\t\t\tout);\n+\t\treturn new AvroWriterFactory<>(builder);\n+\t}\n+\n+\tprivate static <T> DataFileWriter<T> createAvroDataFileWriter(\n+\t\tString schemaString,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzY3MjI1Mw=="}, "originalCommit": {"oid": "f5daa5c0432bbc64add6d302841f26e9d919ce98"}, "originalPosition": 150}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 764, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}