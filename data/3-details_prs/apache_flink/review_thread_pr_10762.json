{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzU5MDA4NDE2", "number": 10762, "reviewThreads": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQxNjoyODoxMlrODXNHGA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQxNjo1MzozN1rODXNkkA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1NjU4NjQ4OnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-connector-kafka-0.9/src/test/java/org/apache/flink/streaming/connectors/kafka/internal/KafkaConsumerThreadTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQxNjoyODoxMlrOFcZTMA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMlQyMTo1MjozN1rOFcrS_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTMxODk2MA==", "bodyText": "Should we throw UnsupportedOperationException here in order to avoid NPE somewhere else in the code?", "url": "https://github.com/apache/flink/pull/10762#discussion_r365318960", "createdAt": "2020-01-10T16:28:12Z", "author": {"login": "tillrohrmann"}, "path": "flink-connectors/flink-connector-kafka-0.9/src/test/java/org/apache/flink/streaming/connectors/kafka/internal/KafkaConsumerThreadTest.java", "diffHunk": "@@ -875,109 +878,194 @@ void reassignPartitions(List<KafkaTopicPartitionState<TopicPartition>> newPartit\n \t}\n \n \t@SuppressWarnings(\"unchecked\")\n-\tprivate static KafkaConsumer<byte[], byte[]> createMockConsumer(\n+\tprivate static TestConsumer createMockConsumer(\n \t\t\tfinal Map<TopicPartition, Long> mockConsumerAssignmentAndPosition,\n \t\t\tfinal Map<TopicPartition, Long> mockRetrievedPositions,\n \t\t\tfinal boolean earlyWakeup,\n \t\t\tfinal OneShotLatch midAssignmentLatch,\n \t\t\tfinal OneShotLatch continueAssignmentLatch) {\n \n-\t\tfinal KafkaConsumer<byte[], byte[]> mockConsumer = mock(KafkaConsumer.class);\n+\t\treturn new TestConsumer(mockConsumerAssignmentAndPosition, mockRetrievedPositions, earlyWakeup, midAssignmentLatch, continueAssignmentLatch);\n+\t}\n \n-\t\twhen(mockConsumer.assignment()).thenAnswer(new Answer<Object>() {\n-\t\t\t@Override\n-\t\t\tpublic Object answer(InvocationOnMock invocationOnMock) throws Throwable {\n-\t\t\t\tif (midAssignmentLatch != null) {\n-\t\t\t\t\tmidAssignmentLatch.trigger();\n-\t\t\t\t}\n+\tprivate static class TestConsumer implements Consumer<byte[], byte[]> {\n+\t\tprivate final Map<TopicPartition, Long> mockConsumerAssignmentAndPosition;\n+\t\tprivate final Map<TopicPartition, Long> mockRetrievedPositions;\n+\t\tprivate final boolean earlyWakeup;\n+\t\tprivate final OneShotLatch midAssignmentLatch;\n+\t\tprivate final OneShotLatch continueAssignmentLatch;\n+\n+\t\tprivate int numWakeupCalls = 0;\n+\n+\t\tprivate TestConsumer(Map<TopicPartition, Long> mockConsumerAssignmentAndPosition, Map<TopicPartition, Long> mockRetrievedPositions, boolean earlyWakeup, OneShotLatch midAssignmentLatch, OneShotLatch continueAssignmentLatch) {\n+\t\t\tthis.mockConsumerAssignmentAndPosition = mockConsumerAssignmentAndPosition;\n+\t\t\tthis.mockRetrievedPositions = mockRetrievedPositions;\n+\t\t\tthis.earlyWakeup = earlyWakeup;\n+\t\t\tthis.midAssignmentLatch = midAssignmentLatch;\n+\t\t\tthis.continueAssignmentLatch = continueAssignmentLatch;\n+\t\t}\n \n-\t\t\t\tif (continueAssignmentLatch != null) {\n+\t\t@Override\n+\t\tpublic Set<TopicPartition> assignment() {\n+\t\t\tif (midAssignmentLatch != null) {\n+\t\t\t\tmidAssignmentLatch.trigger();\n+\t\t\t}\n+\n+\t\t\tif (continueAssignmentLatch != null) {\n+\t\t\t\ttry {\n \t\t\t\t\tcontinueAssignmentLatch.await();\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tThread.currentThread().interrupt();\n \t\t\t\t}\n-\t\t\t\treturn mockConsumerAssignmentAndPosition.keySet();\n \t\t\t}\n-\t\t});\n+\t\t\treturn mockConsumerAssignmentAndPosition.keySet();\n+\t\t}\n \n-\t\twhen(mockConsumer.poll(anyLong())).thenReturn(mock(ConsumerRecords.class));\n+\t\t@Override\n+\t\tpublic Set<String> subscription() {\n+\t\t\treturn null;\n+\t\t}\n \n-\t\tif (!earlyWakeup) {\n-\t\t\twhen(mockConsumer.position(any(TopicPartition.class))).thenAnswer(new Answer<Object>() {\n-\t\t\t\t@Override\n-\t\t\t\tpublic Object answer(InvocationOnMock invocationOnMock) throws Throwable {\n-\t\t\t\t\treturn mockConsumerAssignmentAndPosition.get(invocationOnMock.getArgument(0));\n-\t\t\t\t}\n-\t\t\t});\n-\t\t} else {\n-\t\t\twhen(mockConsumer.position(any(TopicPartition.class))).thenThrow(new WakeupException());\n+\t\t@Override\n+\t\tpublic void subscribe(List<String> list) {\n \t\t}\n \n-\t\tdoAnswer(new Answer() {\n-\t\t\t@Override\n-\t\t\tpublic Object answer(InvocationOnMock invocationOnMock) throws Throwable {\n-\t\t\t\tmockConsumerAssignmentAndPosition.clear();\n+\t\t@Override\n+\t\tpublic void subscribe(List<String> list, ConsumerRebalanceListener consumerRebalanceListener) {\n+\t\t}\n \n-\t\t\t\tList<TopicPartition> assignedPartitions = invocationOnMock.getArgument(0);\n-\t\t\t\tfor (TopicPartition assigned : assignedPartitions) {\n-\t\t\t\t\tmockConsumerAssignmentAndPosition.put(assigned, null);\n-\t\t\t\t}\n-\t\t\t\treturn null;\n+\t\t@Override\n+\t\tpublic void assign(List<TopicPartition> assignedPartitions) {\n+\t\t\tmockConsumerAssignmentAndPosition.clear();\n+\n+\t\t\tfor (TopicPartition assigned : assignedPartitions) {\n+\t\t\t\tmockConsumerAssignmentAndPosition.put(assigned, null);\n \t\t\t}\n-\t\t}).when(mockConsumer).assign(anyListOf(TopicPartition.class));\n+\t\t}\n \n-\t\tdoAnswer(new Answer() {\n-\t\t\t@Override\n-\t\t\tpublic Object answer(InvocationOnMock invocationOnMock) throws Throwable {\n-\t\t\t\tTopicPartition partition = invocationOnMock.getArgument(0);\n-\t\t\t\tlong position = invocationOnMock.getArgument(1);\n+\t\t@Override\n+\t\tpublic void subscribe(Pattern pattern, ConsumerRebalanceListener consumerRebalanceListener) {\n+\t\t}\n \n-\t\t\t\tif (!mockConsumerAssignmentAndPosition.containsKey(partition)) {\n-\t\t\t\t\tthrow new Exception(\"the current mock assignment does not contain partition \" + partition);\n-\t\t\t\t} else {\n-\t\t\t\t\tmockConsumerAssignmentAndPosition.put(partition, position);\n-\t\t\t\t}\n-\t\t\t\treturn null;\n-\t\t\t}\n-\t\t}).when(mockConsumer).seek(any(TopicPartition.class), anyLong());\n+\t\t@Override\n+\t\tpublic void unsubscribe() {\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic ConsumerRecords<byte[], byte[]> poll(long l) {\n+\t\t\treturn mock(ConsumerRecords.class);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void commitSync() {\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void commitSync(Map<TopicPartition, OffsetAndMetadata> map) {\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void commitAsync() {\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void commitAsync(OffsetCommitCallback offsetCommitCallback) {\n+\t\t}\n \n-\t\tdoAnswer(new Answer() {\n-\t\t\t@Override\n-\t\t\tpublic Object answer(InvocationOnMock invocationOnMock) throws Throwable {\n-\t\t\t\tTopicPartition partition = invocationOnMock.getArgument(0);\n+\t\t@Override\n+\t\tpublic void commitAsync(Map<TopicPartition, OffsetAndMetadata> map, OffsetCommitCallback offsetCommitCallback) {\n+\t\t}\n \n+\t\t@Override\n+\t\tpublic void seek(TopicPartition partition, long position) {\n+\t\t\tif (!mockConsumerAssignmentAndPosition.containsKey(partition)) {\n+\t\t\t\tthrow new RuntimeException(\"the current mock assignment does not contain partition \" + partition);\n+\t\t\t} else {\n+\t\t\t\tmockConsumerAssignmentAndPosition.put(partition, position);\n+\t\t\t}\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void seekToBeginning(TopicPartition... partitions) {\n+\t\t\tfor (TopicPartition partition : partitions) {\n \t\t\t\tif (!mockConsumerAssignmentAndPosition.containsKey(partition)) {\n-\t\t\t\t\tthrow new Exception(\"the current mock assignment does not contain partition \" + partition);\n+\t\t\t\t\tthrow new RuntimeException(\"the current mock assignment does not contain partition \" + partition);\n \t\t\t\t} else {\n \t\t\t\t\tLong mockRetrievedPosition = mockRetrievedPositions.get(partition);\n \t\t\t\t\tif (mockRetrievedPosition == null) {\n-\t\t\t\t\t\tthrow new Exception(\"mock consumer needed to retrieve a position, but no value was provided in the mock values for retrieval\");\n+\t\t\t\t\t\tthrow new RuntimeException(\"mock consumer needed to retrieve a position, but no value was provided in the mock values for retrieval\");\n \t\t\t\t\t} else {\n \t\t\t\t\t\tmockConsumerAssignmentAndPosition.put(partition, mockRetrievedPositions.get(partition));\n \t\t\t\t\t}\n \t\t\t\t}\n-\t\t\t\treturn null;\n \t\t\t}\n-\t\t}).when(mockConsumer).seekToBeginning(any(TopicPartition.class));\n-\n-\t\tdoAnswer(new Answer() {\n-\t\t\t@Override\n-\t\t\tpublic Object answer(InvocationOnMock invocationOnMock) throws Throwable {\n-\t\t\t\tTopicPartition partition = invocationOnMock.getArgument(0);\n+\t\t}\n \n+\t\t@Override\n+\t\tpublic void seekToEnd(TopicPartition... partitions) {\n+\t\t\tfor (TopicPartition partition : partitions) {\n \t\t\t\tif (!mockConsumerAssignmentAndPosition.containsKey(partition)) {\n-\t\t\t\t\tthrow new Exception(\"the current mock assignment does not contain partition \" + partition);\n+\t\t\t\t\tthrow new RuntimeException(\"the current mock assignment does not contain partition \" + partition);\n \t\t\t\t} else {\n \t\t\t\t\tLong mockRetrievedPosition = mockRetrievedPositions.get(partition);\n \t\t\t\t\tif (mockRetrievedPosition == null) {\n-\t\t\t\t\t\tthrow new Exception(\"mock consumer needed to retrieve a position, but no value was provided in the mock values for retrieval\");\n+\t\t\t\t\t\tthrow new RuntimeException(\"mock consumer needed to retrieve a position, but no value was provided in the mock values for retrieval\");\n \t\t\t\t\t} else {\n \t\t\t\t\t\tmockConsumerAssignmentAndPosition.put(partition, mockRetrievedPositions.get(partition));\n \t\t\t\t\t}\n \t\t\t\t}\n-\t\t\t\treturn null;\n \t\t\t}\n-\t\t}).when(mockConsumer).seekToEnd(any(TopicPartition.class));\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic long position(TopicPartition topicPartition) {\n+\t\t\tif (!earlyWakeup) {\n+\t\t\t\treturn mockConsumerAssignmentAndPosition.get(topicPartition);\n+\t\t\t} else {\n+\t\t\t\tthrow new WakeupException();\n+\t\t\t}\n+\t\t}\n \n-\t\treturn mockConsumer;\n+\t\t@Override\n+\t\tpublic OffsetAndMetadata committed(TopicPartition topicPartition) {\n+\t\t\treturn null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18dd7d344258743705da311508a1fc7d0873da45"}, "originalPosition": 392}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTYxMzgyMQ==", "bodyText": "Tests still passes with all methods that return something throwing an exception instead, so we'll go with that.", "url": "https://github.com/apache/flink/pull/10762#discussion_r365613821", "createdAt": "2020-01-12T21:52:37Z", "author": {"login": "zentol"}, "path": "flink-connectors/flink-connector-kafka-0.9/src/test/java/org/apache/flink/streaming/connectors/kafka/internal/KafkaConsumerThreadTest.java", "diffHunk": "@@ -875,109 +878,194 @@ void reassignPartitions(List<KafkaTopicPartitionState<TopicPartition>> newPartit\n \t}\n \n \t@SuppressWarnings(\"unchecked\")\n-\tprivate static KafkaConsumer<byte[], byte[]> createMockConsumer(\n+\tprivate static TestConsumer createMockConsumer(\n \t\t\tfinal Map<TopicPartition, Long> mockConsumerAssignmentAndPosition,\n \t\t\tfinal Map<TopicPartition, Long> mockRetrievedPositions,\n \t\t\tfinal boolean earlyWakeup,\n \t\t\tfinal OneShotLatch midAssignmentLatch,\n \t\t\tfinal OneShotLatch continueAssignmentLatch) {\n \n-\t\tfinal KafkaConsumer<byte[], byte[]> mockConsumer = mock(KafkaConsumer.class);\n+\t\treturn new TestConsumer(mockConsumerAssignmentAndPosition, mockRetrievedPositions, earlyWakeup, midAssignmentLatch, continueAssignmentLatch);\n+\t}\n \n-\t\twhen(mockConsumer.assignment()).thenAnswer(new Answer<Object>() {\n-\t\t\t@Override\n-\t\t\tpublic Object answer(InvocationOnMock invocationOnMock) throws Throwable {\n-\t\t\t\tif (midAssignmentLatch != null) {\n-\t\t\t\t\tmidAssignmentLatch.trigger();\n-\t\t\t\t}\n+\tprivate static class TestConsumer implements Consumer<byte[], byte[]> {\n+\t\tprivate final Map<TopicPartition, Long> mockConsumerAssignmentAndPosition;\n+\t\tprivate final Map<TopicPartition, Long> mockRetrievedPositions;\n+\t\tprivate final boolean earlyWakeup;\n+\t\tprivate final OneShotLatch midAssignmentLatch;\n+\t\tprivate final OneShotLatch continueAssignmentLatch;\n+\n+\t\tprivate int numWakeupCalls = 0;\n+\n+\t\tprivate TestConsumer(Map<TopicPartition, Long> mockConsumerAssignmentAndPosition, Map<TopicPartition, Long> mockRetrievedPositions, boolean earlyWakeup, OneShotLatch midAssignmentLatch, OneShotLatch continueAssignmentLatch) {\n+\t\t\tthis.mockConsumerAssignmentAndPosition = mockConsumerAssignmentAndPosition;\n+\t\t\tthis.mockRetrievedPositions = mockRetrievedPositions;\n+\t\t\tthis.earlyWakeup = earlyWakeup;\n+\t\t\tthis.midAssignmentLatch = midAssignmentLatch;\n+\t\t\tthis.continueAssignmentLatch = continueAssignmentLatch;\n+\t\t}\n \n-\t\t\t\tif (continueAssignmentLatch != null) {\n+\t\t@Override\n+\t\tpublic Set<TopicPartition> assignment() {\n+\t\t\tif (midAssignmentLatch != null) {\n+\t\t\t\tmidAssignmentLatch.trigger();\n+\t\t\t}\n+\n+\t\t\tif (continueAssignmentLatch != null) {\n+\t\t\t\ttry {\n \t\t\t\t\tcontinueAssignmentLatch.await();\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tThread.currentThread().interrupt();\n \t\t\t\t}\n-\t\t\t\treturn mockConsumerAssignmentAndPosition.keySet();\n \t\t\t}\n-\t\t});\n+\t\t\treturn mockConsumerAssignmentAndPosition.keySet();\n+\t\t}\n \n-\t\twhen(mockConsumer.poll(anyLong())).thenReturn(mock(ConsumerRecords.class));\n+\t\t@Override\n+\t\tpublic Set<String> subscription() {\n+\t\t\treturn null;\n+\t\t}\n \n-\t\tif (!earlyWakeup) {\n-\t\t\twhen(mockConsumer.position(any(TopicPartition.class))).thenAnswer(new Answer<Object>() {\n-\t\t\t\t@Override\n-\t\t\t\tpublic Object answer(InvocationOnMock invocationOnMock) throws Throwable {\n-\t\t\t\t\treturn mockConsumerAssignmentAndPosition.get(invocationOnMock.getArgument(0));\n-\t\t\t\t}\n-\t\t\t});\n-\t\t} else {\n-\t\t\twhen(mockConsumer.position(any(TopicPartition.class))).thenThrow(new WakeupException());\n+\t\t@Override\n+\t\tpublic void subscribe(List<String> list) {\n \t\t}\n \n-\t\tdoAnswer(new Answer() {\n-\t\t\t@Override\n-\t\t\tpublic Object answer(InvocationOnMock invocationOnMock) throws Throwable {\n-\t\t\t\tmockConsumerAssignmentAndPosition.clear();\n+\t\t@Override\n+\t\tpublic void subscribe(List<String> list, ConsumerRebalanceListener consumerRebalanceListener) {\n+\t\t}\n \n-\t\t\t\tList<TopicPartition> assignedPartitions = invocationOnMock.getArgument(0);\n-\t\t\t\tfor (TopicPartition assigned : assignedPartitions) {\n-\t\t\t\t\tmockConsumerAssignmentAndPosition.put(assigned, null);\n-\t\t\t\t}\n-\t\t\t\treturn null;\n+\t\t@Override\n+\t\tpublic void assign(List<TopicPartition> assignedPartitions) {\n+\t\t\tmockConsumerAssignmentAndPosition.clear();\n+\n+\t\t\tfor (TopicPartition assigned : assignedPartitions) {\n+\t\t\t\tmockConsumerAssignmentAndPosition.put(assigned, null);\n \t\t\t}\n-\t\t}).when(mockConsumer).assign(anyListOf(TopicPartition.class));\n+\t\t}\n \n-\t\tdoAnswer(new Answer() {\n-\t\t\t@Override\n-\t\t\tpublic Object answer(InvocationOnMock invocationOnMock) throws Throwable {\n-\t\t\t\tTopicPartition partition = invocationOnMock.getArgument(0);\n-\t\t\t\tlong position = invocationOnMock.getArgument(1);\n+\t\t@Override\n+\t\tpublic void subscribe(Pattern pattern, ConsumerRebalanceListener consumerRebalanceListener) {\n+\t\t}\n \n-\t\t\t\tif (!mockConsumerAssignmentAndPosition.containsKey(partition)) {\n-\t\t\t\t\tthrow new Exception(\"the current mock assignment does not contain partition \" + partition);\n-\t\t\t\t} else {\n-\t\t\t\t\tmockConsumerAssignmentAndPosition.put(partition, position);\n-\t\t\t\t}\n-\t\t\t\treturn null;\n-\t\t\t}\n-\t\t}).when(mockConsumer).seek(any(TopicPartition.class), anyLong());\n+\t\t@Override\n+\t\tpublic void unsubscribe() {\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic ConsumerRecords<byte[], byte[]> poll(long l) {\n+\t\t\treturn mock(ConsumerRecords.class);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void commitSync() {\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void commitSync(Map<TopicPartition, OffsetAndMetadata> map) {\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void commitAsync() {\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void commitAsync(OffsetCommitCallback offsetCommitCallback) {\n+\t\t}\n \n-\t\tdoAnswer(new Answer() {\n-\t\t\t@Override\n-\t\t\tpublic Object answer(InvocationOnMock invocationOnMock) throws Throwable {\n-\t\t\t\tTopicPartition partition = invocationOnMock.getArgument(0);\n+\t\t@Override\n+\t\tpublic void commitAsync(Map<TopicPartition, OffsetAndMetadata> map, OffsetCommitCallback offsetCommitCallback) {\n+\t\t}\n \n+\t\t@Override\n+\t\tpublic void seek(TopicPartition partition, long position) {\n+\t\t\tif (!mockConsumerAssignmentAndPosition.containsKey(partition)) {\n+\t\t\t\tthrow new RuntimeException(\"the current mock assignment does not contain partition \" + partition);\n+\t\t\t} else {\n+\t\t\t\tmockConsumerAssignmentAndPosition.put(partition, position);\n+\t\t\t}\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void seekToBeginning(TopicPartition... partitions) {\n+\t\t\tfor (TopicPartition partition : partitions) {\n \t\t\t\tif (!mockConsumerAssignmentAndPosition.containsKey(partition)) {\n-\t\t\t\t\tthrow new Exception(\"the current mock assignment does not contain partition \" + partition);\n+\t\t\t\t\tthrow new RuntimeException(\"the current mock assignment does not contain partition \" + partition);\n \t\t\t\t} else {\n \t\t\t\t\tLong mockRetrievedPosition = mockRetrievedPositions.get(partition);\n \t\t\t\t\tif (mockRetrievedPosition == null) {\n-\t\t\t\t\t\tthrow new Exception(\"mock consumer needed to retrieve a position, but no value was provided in the mock values for retrieval\");\n+\t\t\t\t\t\tthrow new RuntimeException(\"mock consumer needed to retrieve a position, but no value was provided in the mock values for retrieval\");\n \t\t\t\t\t} else {\n \t\t\t\t\t\tmockConsumerAssignmentAndPosition.put(partition, mockRetrievedPositions.get(partition));\n \t\t\t\t\t}\n \t\t\t\t}\n-\t\t\t\treturn null;\n \t\t\t}\n-\t\t}).when(mockConsumer).seekToBeginning(any(TopicPartition.class));\n-\n-\t\tdoAnswer(new Answer() {\n-\t\t\t@Override\n-\t\t\tpublic Object answer(InvocationOnMock invocationOnMock) throws Throwable {\n-\t\t\t\tTopicPartition partition = invocationOnMock.getArgument(0);\n+\t\t}\n \n+\t\t@Override\n+\t\tpublic void seekToEnd(TopicPartition... partitions) {\n+\t\t\tfor (TopicPartition partition : partitions) {\n \t\t\t\tif (!mockConsumerAssignmentAndPosition.containsKey(partition)) {\n-\t\t\t\t\tthrow new Exception(\"the current mock assignment does not contain partition \" + partition);\n+\t\t\t\t\tthrow new RuntimeException(\"the current mock assignment does not contain partition \" + partition);\n \t\t\t\t} else {\n \t\t\t\t\tLong mockRetrievedPosition = mockRetrievedPositions.get(partition);\n \t\t\t\t\tif (mockRetrievedPosition == null) {\n-\t\t\t\t\t\tthrow new Exception(\"mock consumer needed to retrieve a position, but no value was provided in the mock values for retrieval\");\n+\t\t\t\t\t\tthrow new RuntimeException(\"mock consumer needed to retrieve a position, but no value was provided in the mock values for retrieval\");\n \t\t\t\t\t} else {\n \t\t\t\t\t\tmockConsumerAssignmentAndPosition.put(partition, mockRetrievedPositions.get(partition));\n \t\t\t\t\t}\n \t\t\t\t}\n-\t\t\t\treturn null;\n \t\t\t}\n-\t\t}).when(mockConsumer).seekToEnd(any(TopicPartition.class));\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic long position(TopicPartition topicPartition) {\n+\t\t\tif (!earlyWakeup) {\n+\t\t\t\treturn mockConsumerAssignmentAndPosition.get(topicPartition);\n+\t\t\t} else {\n+\t\t\t\tthrow new WakeupException();\n+\t\t\t}\n+\t\t}\n \n-\t\treturn mockConsumer;\n+\t\t@Override\n+\t\tpublic OffsetAndMetadata committed(TopicPartition topicPartition) {\n+\t\t\treturn null;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTMxODk2MA=="}, "originalCommit": {"oid": "18dd7d344258743705da311508a1fc7d0873da45"}, "originalPosition": 392}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1NjU4NjU0OnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-connector-kafka-0.9/src/test/java/org/apache/flink/streaming/connectors/kafka/internal/KafkaConsumerThreadTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQxNjoyODoxM1rOFcZTOQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQxNjoyODoxM1rOFcZTOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTMxODk2OQ==", "bodyText": "Same here with the UnsupportedOperationException.", "url": "https://github.com/apache/flink/pull/10762#discussion_r365318969", "createdAt": "2020-01-10T16:28:13Z", "author": {"login": "tillrohrmann"}, "path": "flink-connectors/flink-connector-kafka-0.9/src/test/java/org/apache/flink/streaming/connectors/kafka/internal/KafkaConsumerThreadTest.java", "diffHunk": "@@ -875,109 +878,194 @@ void reassignPartitions(List<KafkaTopicPartitionState<TopicPartition>> newPartit\n \t}\n \n \t@SuppressWarnings(\"unchecked\")\n-\tprivate static KafkaConsumer<byte[], byte[]> createMockConsumer(\n+\tprivate static TestConsumer createMockConsumer(\n \t\t\tfinal Map<TopicPartition, Long> mockConsumerAssignmentAndPosition,\n \t\t\tfinal Map<TopicPartition, Long> mockRetrievedPositions,\n \t\t\tfinal boolean earlyWakeup,\n \t\t\tfinal OneShotLatch midAssignmentLatch,\n \t\t\tfinal OneShotLatch continueAssignmentLatch) {\n \n-\t\tfinal KafkaConsumer<byte[], byte[]> mockConsumer = mock(KafkaConsumer.class);\n+\t\treturn new TestConsumer(mockConsumerAssignmentAndPosition, mockRetrievedPositions, earlyWakeup, midAssignmentLatch, continueAssignmentLatch);\n+\t}\n \n-\t\twhen(mockConsumer.assignment()).thenAnswer(new Answer<Object>() {\n-\t\t\t@Override\n-\t\t\tpublic Object answer(InvocationOnMock invocationOnMock) throws Throwable {\n-\t\t\t\tif (midAssignmentLatch != null) {\n-\t\t\t\t\tmidAssignmentLatch.trigger();\n-\t\t\t\t}\n+\tprivate static class TestConsumer implements Consumer<byte[], byte[]> {\n+\t\tprivate final Map<TopicPartition, Long> mockConsumerAssignmentAndPosition;\n+\t\tprivate final Map<TopicPartition, Long> mockRetrievedPositions;\n+\t\tprivate final boolean earlyWakeup;\n+\t\tprivate final OneShotLatch midAssignmentLatch;\n+\t\tprivate final OneShotLatch continueAssignmentLatch;\n+\n+\t\tprivate int numWakeupCalls = 0;\n+\n+\t\tprivate TestConsumer(Map<TopicPartition, Long> mockConsumerAssignmentAndPosition, Map<TopicPartition, Long> mockRetrievedPositions, boolean earlyWakeup, OneShotLatch midAssignmentLatch, OneShotLatch continueAssignmentLatch) {\n+\t\t\tthis.mockConsumerAssignmentAndPosition = mockConsumerAssignmentAndPosition;\n+\t\t\tthis.mockRetrievedPositions = mockRetrievedPositions;\n+\t\t\tthis.earlyWakeup = earlyWakeup;\n+\t\t\tthis.midAssignmentLatch = midAssignmentLatch;\n+\t\t\tthis.continueAssignmentLatch = continueAssignmentLatch;\n+\t\t}\n \n-\t\t\t\tif (continueAssignmentLatch != null) {\n+\t\t@Override\n+\t\tpublic Set<TopicPartition> assignment() {\n+\t\t\tif (midAssignmentLatch != null) {\n+\t\t\t\tmidAssignmentLatch.trigger();\n+\t\t\t}\n+\n+\t\t\tif (continueAssignmentLatch != null) {\n+\t\t\t\ttry {\n \t\t\t\t\tcontinueAssignmentLatch.await();\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tThread.currentThread().interrupt();\n \t\t\t\t}\n-\t\t\t\treturn mockConsumerAssignmentAndPosition.keySet();\n \t\t\t}\n-\t\t});\n+\t\t\treturn mockConsumerAssignmentAndPosition.keySet();\n+\t\t}\n \n-\t\twhen(mockConsumer.poll(anyLong())).thenReturn(mock(ConsumerRecords.class));\n+\t\t@Override\n+\t\tpublic Set<String> subscription() {\n+\t\t\treturn null;\n+\t\t}\n \n-\t\tif (!earlyWakeup) {\n-\t\t\twhen(mockConsumer.position(any(TopicPartition.class))).thenAnswer(new Answer<Object>() {\n-\t\t\t\t@Override\n-\t\t\t\tpublic Object answer(InvocationOnMock invocationOnMock) throws Throwable {\n-\t\t\t\t\treturn mockConsumerAssignmentAndPosition.get(invocationOnMock.getArgument(0));\n-\t\t\t\t}\n-\t\t\t});\n-\t\t} else {\n-\t\t\twhen(mockConsumer.position(any(TopicPartition.class))).thenThrow(new WakeupException());\n+\t\t@Override\n+\t\tpublic void subscribe(List<String> list) {\n \t\t}\n \n-\t\tdoAnswer(new Answer() {\n-\t\t\t@Override\n-\t\t\tpublic Object answer(InvocationOnMock invocationOnMock) throws Throwable {\n-\t\t\t\tmockConsumerAssignmentAndPosition.clear();\n+\t\t@Override\n+\t\tpublic void subscribe(List<String> list, ConsumerRebalanceListener consumerRebalanceListener) {\n+\t\t}\n \n-\t\t\t\tList<TopicPartition> assignedPartitions = invocationOnMock.getArgument(0);\n-\t\t\t\tfor (TopicPartition assigned : assignedPartitions) {\n-\t\t\t\t\tmockConsumerAssignmentAndPosition.put(assigned, null);\n-\t\t\t\t}\n-\t\t\t\treturn null;\n+\t\t@Override\n+\t\tpublic void assign(List<TopicPartition> assignedPartitions) {\n+\t\t\tmockConsumerAssignmentAndPosition.clear();\n+\n+\t\t\tfor (TopicPartition assigned : assignedPartitions) {\n+\t\t\t\tmockConsumerAssignmentAndPosition.put(assigned, null);\n \t\t\t}\n-\t\t}).when(mockConsumer).assign(anyListOf(TopicPartition.class));\n+\t\t}\n \n-\t\tdoAnswer(new Answer() {\n-\t\t\t@Override\n-\t\t\tpublic Object answer(InvocationOnMock invocationOnMock) throws Throwable {\n-\t\t\t\tTopicPartition partition = invocationOnMock.getArgument(0);\n-\t\t\t\tlong position = invocationOnMock.getArgument(1);\n+\t\t@Override\n+\t\tpublic void subscribe(Pattern pattern, ConsumerRebalanceListener consumerRebalanceListener) {\n+\t\t}\n \n-\t\t\t\tif (!mockConsumerAssignmentAndPosition.containsKey(partition)) {\n-\t\t\t\t\tthrow new Exception(\"the current mock assignment does not contain partition \" + partition);\n-\t\t\t\t} else {\n-\t\t\t\t\tmockConsumerAssignmentAndPosition.put(partition, position);\n-\t\t\t\t}\n-\t\t\t\treturn null;\n-\t\t\t}\n-\t\t}).when(mockConsumer).seek(any(TopicPartition.class), anyLong());\n+\t\t@Override\n+\t\tpublic void unsubscribe() {\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic ConsumerRecords<byte[], byte[]> poll(long l) {\n+\t\t\treturn mock(ConsumerRecords.class);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void commitSync() {\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void commitSync(Map<TopicPartition, OffsetAndMetadata> map) {\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void commitAsync() {\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void commitAsync(OffsetCommitCallback offsetCommitCallback) {\n+\t\t}\n \n-\t\tdoAnswer(new Answer() {\n-\t\t\t@Override\n-\t\t\tpublic Object answer(InvocationOnMock invocationOnMock) throws Throwable {\n-\t\t\t\tTopicPartition partition = invocationOnMock.getArgument(0);\n+\t\t@Override\n+\t\tpublic void commitAsync(Map<TopicPartition, OffsetAndMetadata> map, OffsetCommitCallback offsetCommitCallback) {\n+\t\t}\n \n+\t\t@Override\n+\t\tpublic void seek(TopicPartition partition, long position) {\n+\t\t\tif (!mockConsumerAssignmentAndPosition.containsKey(partition)) {\n+\t\t\t\tthrow new RuntimeException(\"the current mock assignment does not contain partition \" + partition);\n+\t\t\t} else {\n+\t\t\t\tmockConsumerAssignmentAndPosition.put(partition, position);\n+\t\t\t}\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void seekToBeginning(TopicPartition... partitions) {\n+\t\t\tfor (TopicPartition partition : partitions) {\n \t\t\t\tif (!mockConsumerAssignmentAndPosition.containsKey(partition)) {\n-\t\t\t\t\tthrow new Exception(\"the current mock assignment does not contain partition \" + partition);\n+\t\t\t\t\tthrow new RuntimeException(\"the current mock assignment does not contain partition \" + partition);\n \t\t\t\t} else {\n \t\t\t\t\tLong mockRetrievedPosition = mockRetrievedPositions.get(partition);\n \t\t\t\t\tif (mockRetrievedPosition == null) {\n-\t\t\t\t\t\tthrow new Exception(\"mock consumer needed to retrieve a position, but no value was provided in the mock values for retrieval\");\n+\t\t\t\t\t\tthrow new RuntimeException(\"mock consumer needed to retrieve a position, but no value was provided in the mock values for retrieval\");\n \t\t\t\t\t} else {\n \t\t\t\t\t\tmockConsumerAssignmentAndPosition.put(partition, mockRetrievedPositions.get(partition));\n \t\t\t\t\t}\n \t\t\t\t}\n-\t\t\t\treturn null;\n \t\t\t}\n-\t\t}).when(mockConsumer).seekToBeginning(any(TopicPartition.class));\n-\n-\t\tdoAnswer(new Answer() {\n-\t\t\t@Override\n-\t\t\tpublic Object answer(InvocationOnMock invocationOnMock) throws Throwable {\n-\t\t\t\tTopicPartition partition = invocationOnMock.getArgument(0);\n+\t\t}\n \n+\t\t@Override\n+\t\tpublic void seekToEnd(TopicPartition... partitions) {\n+\t\t\tfor (TopicPartition partition : partitions) {\n \t\t\t\tif (!mockConsumerAssignmentAndPosition.containsKey(partition)) {\n-\t\t\t\t\tthrow new Exception(\"the current mock assignment does not contain partition \" + partition);\n+\t\t\t\t\tthrow new RuntimeException(\"the current mock assignment does not contain partition \" + partition);\n \t\t\t\t} else {\n \t\t\t\t\tLong mockRetrievedPosition = mockRetrievedPositions.get(partition);\n \t\t\t\t\tif (mockRetrievedPosition == null) {\n-\t\t\t\t\t\tthrow new Exception(\"mock consumer needed to retrieve a position, but no value was provided in the mock values for retrieval\");\n+\t\t\t\t\t\tthrow new RuntimeException(\"mock consumer needed to retrieve a position, but no value was provided in the mock values for retrieval\");\n \t\t\t\t\t} else {\n \t\t\t\t\t\tmockConsumerAssignmentAndPosition.put(partition, mockRetrievedPositions.get(partition));\n \t\t\t\t\t}\n \t\t\t\t}\n-\t\t\t\treturn null;\n \t\t\t}\n-\t\t}).when(mockConsumer).seekToEnd(any(TopicPartition.class));\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic long position(TopicPartition topicPartition) {\n+\t\t\tif (!earlyWakeup) {\n+\t\t\t\treturn mockConsumerAssignmentAndPosition.get(topicPartition);\n+\t\t\t} else {\n+\t\t\t\tthrow new WakeupException();\n+\t\t\t}\n+\t\t}\n \n-\t\treturn mockConsumer;\n+\t\t@Override\n+\t\tpublic OffsetAndMetadata committed(TopicPartition topicPartition) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic Map<MetricName, ? extends Metric> metrics() {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic List<PartitionInfo> partitionsFor(String s) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic Map<String, List<PartitionInfo>> listTopics() {\n+\t\t\treturn null;\n+\t\t}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18dd7d344258743705da311508a1fc7d0873da45"}, "originalPosition": 408}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1NjU5OTgwOnYy", "diffSide": "RIGHT", "path": "docs/dev/connectors/kafka.zh.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQxNjozMjozNVrOFcZbjA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQxNjozMjozNVrOFcZbjA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTMyMTEwMA==", "bodyText": "docs/dev/datastream_api.md and docs/dev/datastream_api.zh.md still contain a reference to FlinkKafkaConsumer08", "url": "https://github.com/apache/flink/pull/10762#discussion_r365321100", "createdAt": "2020-01-10T16:32:35Z", "author": {"login": "tillrohrmann"}, "path": "docs/dev/connectors/kafka.zh.md", "diffHunk": "@@ -161,22 +151,18 @@ Flink \u7684 Kafka consumer \u79f0\u4e3a `FlinkKafkaConsumer08`\uff08\u6216\u9002\u7528\u4e8e Kafka 0.9.\n {% highlight java %}\n Properties properties = new Properties();\n properties.setProperty(\"bootstrap.servers\", \"localhost:9092\");\n-// \u4ec5 Kafka 0.8 \u9700\u8981\n-properties.setProperty(\"zookeeper.connect\", \"localhost:2181\");\n properties.setProperty(\"group.id\", \"test\");\n DataStream<String> stream = env\n-  .addSource(new FlinkKafkaConsumer08<>(\"topic\", new SimpleStringSchema(), properties));\n+  .addSource(new FlinkKafkaConsumer09<>(\"topic\", new SimpleStringSchema(), properties));\n {% endhighlight %}\n </div>\n <div data-lang=\"scala\" markdown=\"1\">\n {% highlight scala %}\n val properties = new Properties()\n properties.setProperty(\"bootstrap.servers\", \"localhost:9092\")\n-// \u4ec5 Kafka 0.8 \u9700\u8981\n-properties.setProperty(\"zookeeper.connect\", \"localhost:2181\")\n properties.setProperty(\"group.id\", \"test\")\n stream = env\n-    .addSource(new FlinkKafkaConsumer08[String](\"topic\", new SimpleStringSchema(), properties))\n+    .addSource(new FlinkKafkaConsumer09[String](\"topic\", new SimpleStringSchema(), properties))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e0a89f84b48d5daa31fac2a2f6e916f4ae596e2"}, "originalPosition": 72}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1NjYwNTU2OnYy", "diffSide": "LEFT", "path": "tools/travis/stage.sh", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQxNjozNDoyMFrOFcZfEA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQxNjozNDoyMFrOFcZfEA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTMyMjAwMA==", "bodyText": "flink-runtime/pom.xml contains reference to Kafka 0.8 in line 562.", "url": "https://github.com/apache/flink/pull/10762#discussion_r365322000", "createdAt": "2020-01-10T16:34:20Z", "author": {"login": "tillrohrmann"}, "path": "tools/travis/stage.sh", "diffHunk": "@@ -128,11 +128,6 @@ flink-connectors/flink-sql-connector-kafka,\"\n MODULES_TESTS=\"\\\n flink-tests\"\n \n-# we can only build the Kafka 0.8 connector when building for Scala 2.11\n-if [[ $PROFILE == *\"scala-2.11\"* ]]; then\n-    MODULES_CONNECTORS=\"$MODULES_CONNECTORS,flink-connectors/flink-connector-kafka-0.8\"\n-fi\n-", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e0a89f84b48d5daa31fac2a2f6e916f4ae596e2"}, "originalPosition": 8}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1NjYwOTY1OnYy", "diffSide": "LEFT", "path": "flink-connectors/flink-connector-kafka-base/src/main/java/org/apache/flink/table/descriptors/KafkaValidator.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQxNjozNTozNlrOFcZhnA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQxNjozNjoyNFrOFcZi_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTMyMjY1Mg==", "bodyText": "ConnectorDescriptorValidator.java contains a reference to Kafka 0.8 in line 47.", "url": "https://github.com/apache/flink/pull/10762#discussion_r365322652", "createdAt": "2020-01-10T16:35:36Z", "author": {"login": "tillrohrmann"}, "path": "flink-connectors/flink-connector-kafka-base/src/main/java/org/apache/flink/table/descriptors/KafkaValidator.java", "diffHunk": "@@ -38,7 +38,6 @@\n public class KafkaValidator extends ConnectorDescriptorValidator {\n \n \tpublic static final String CONNECTOR_TYPE_VALUE_KAFKA = \"kafka\";\n-\tpublic static final String CONNECTOR_VERSION_VALUE_08 = \"0.8\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e0a89f84b48d5daa31fac2a2f6e916f4ae596e2"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTMyMzAwNQ==", "bodyText": "KafkaShortRetentionTestBase.java contains in line 253 Kafka 0.8 specific code. In line 254 the same class contains Kafka 0.9 specific code.", "url": "https://github.com/apache/flink/pull/10762#discussion_r365323005", "createdAt": "2020-01-10T16:36:24Z", "author": {"login": "tillrohrmann"}, "path": "flink-connectors/flink-connector-kafka-base/src/main/java/org/apache/flink/table/descriptors/KafkaValidator.java", "diffHunk": "@@ -38,7 +38,6 @@\n public class KafkaValidator extends ConnectorDescriptorValidator {\n \n \tpublic static final String CONNECTOR_TYPE_VALUE_KAFKA = \"kafka\";\n-\tpublic static final String CONNECTOR_VERSION_VALUE_08 = \"0.8\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTMyMjY1Mg=="}, "originalCommit": {"oid": "3e0a89f84b48d5daa31fac2a2f6e916f4ae596e2"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1NjYzMTAwOnYy", "diffSide": "LEFT", "path": "docs/dev/connectors/kafka.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQxNjo0Mjo1NFrOFcZvHA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQxNjo0Mjo1NFrOFcZvHA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTMyNjEwOA==", "bodyText": "docs/dev/event_time.md, docs/dev/event_time.zh.md, docs/dev/event_timestamps_watermarks.md and docs/dev/event_timestamps_watermarks.zh.md contains a reference to FlinkKafkaConsumer09", "url": "https://github.com/apache/flink/pull/10762#discussion_r365326108", "createdAt": "2020-01-10T16:42:54Z", "author": {"login": "tillrohrmann"}, "path": "docs/dev/connectors/kafka.md", "diffHunk": "@@ -263,7 +255,7 @@ Example:\n {% highlight java %}\n final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n \n-FlinkKafkaConsumer09<String> myConsumer = new FlinkKafkaConsumer09<>(...);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6bfb6d18af5fdfbddadf6da53adab78567d64aa9"}, "originalPosition": 64}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1NjY0MDg2OnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-connector-kafka-0.10/pom.xml", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQxNjo0NjoxNVrOFcZ1hg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQxNjo0NjoxNVrOFcZ1hg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTMyNzc1MA==", "bodyText": "In line 117, there is still a dependency to flink-connector-kafka-0.9.", "url": "https://github.com/apache/flink/pull/10762#discussion_r365327750", "createdAt": "2020-01-10T16:46:15Z", "author": {"login": "tillrohrmann"}, "path": "flink-connectors/flink-connector-kafka-0.10/pom.xml", "diffHunk": "@@ -46,7 +46,7 @@ under the License.\n \n \t\t<dependency>\n \t\t\t<groupId>org.apache.flink</groupId>\n-\t\t\t<artifactId>flink-connector-kafka-0.9_${scala.binary.version}</artifactId>\n+\t\t\t<artifactId>flink-connector-kafka-base_${scala.binary.version}</artifactId>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6bfb6d18af5fdfbddadf6da53adab78567d64aa9"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1NjY0NTQwOnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-connector-kafka-0.10/src/main/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumer010.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQxNjo0Nzo1MVrOFcZ4YQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMlQyMTozOTozNVrOFcrPSw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTMyODQ4MQ==", "bodyText": "Can we avoid null and instead pass in an empty collection? If not, then let's add @Nullable annotation.", "url": "https://github.com/apache/flink/pull/10762#discussion_r365328481", "createdAt": "2020-01-10T16:47:51Z", "author": {"login": "tillrohrmann"}, "path": "flink-connectors/flink-connector-kafka-0.10/src/main/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumer010.java", "diffHunk": "@@ -173,7 +205,38 @@ public FlinkKafkaConsumer010(Pattern subscriptionPattern, DeserializationSchema<\n \t */\n \t@PublicEvolving\n \tpublic FlinkKafkaConsumer010(Pattern subscriptionPattern, KafkaDeserializationSchema<T> deserializer, Properties props) {\n-\t\tsuper(subscriptionPattern, deserializer, props);\n+\t\tthis(null, subscriptionPattern, deserializer, props);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6bfb6d18af5fdfbddadf6da53adab78567d64aa9"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTYxMjg3NQ==", "bodyText": "The KafkTopicsDescriptor actually relies on this being null. I'll add Nullable to the private constructor for the time being.", "url": "https://github.com/apache/flink/pull/10762#discussion_r365612875", "createdAt": "2020-01-12T21:39:35Z", "author": {"login": "zentol"}, "path": "flink-connectors/flink-connector-kafka-0.10/src/main/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumer010.java", "diffHunk": "@@ -173,7 +205,38 @@ public FlinkKafkaConsumer010(Pattern subscriptionPattern, DeserializationSchema<\n \t */\n \t@PublicEvolving\n \tpublic FlinkKafkaConsumer010(Pattern subscriptionPattern, KafkaDeserializationSchema<T> deserializer, Properties props) {\n-\t\tsuper(subscriptionPattern, deserializer, props);\n+\t\tthis(null, subscriptionPattern, deserializer, props);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTMyODQ4MQ=="}, "originalCommit": {"oid": "6bfb6d18af5fdfbddadf6da53adab78567d64aa9"}, "originalPosition": 77}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1NjY0NjY4OnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-connector-kafka-0.10/src/main/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumer010.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQxNjo0ODoyMFrOFcZ5MQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMlQyMTo0MTowOFrOFcrPuw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTMyODY4OQ==", "bodyText": "Same here with the null value for Pattern. I think it would be good to avoid it if possible.", "url": "https://github.com/apache/flink/pull/10762#discussion_r365328689", "createdAt": "2020-01-10T16:48:20Z", "author": {"login": "tillrohrmann"}, "path": "flink-connectors/flink-connector-kafka-0.10/src/main/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumer010.java", "diffHunk": "@@ -130,7 +162,7 @@ public FlinkKafkaConsumer010(List<String> topics, DeserializationSchema<T> deser\n \t *           The properties that are used to configure both the fetcher and the offset handler.\n \t */\n \tpublic FlinkKafkaConsumer010(List<String> topics, KafkaDeserializationSchema<T> deserializer, Properties props) {\n-\t\tsuper(topics, deserializer, props);\n+\t\tthis(topics, null, deserializer, props);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6bfb6d18af5fdfbddadf6da53adab78567d64aa9"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTYxMjk4Nw==", "bodyText": "Will add Nullable with the same reasoning as for the list of topics.", "url": "https://github.com/apache/flink/pull/10762#discussion_r365612987", "createdAt": "2020-01-12T21:41:08Z", "author": {"login": "zentol"}, "path": "flink-connectors/flink-connector-kafka-0.10/src/main/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumer010.java", "diffHunk": "@@ -130,7 +162,7 @@ public FlinkKafkaConsumer010(List<String> topics, DeserializationSchema<T> deser\n \t *           The properties that are used to configure both the fetcher and the offset handler.\n \t */\n \tpublic FlinkKafkaConsumer010(List<String> topics, KafkaDeserializationSchema<T> deserializer, Properties props) {\n-\t\tsuper(topics, deserializer, props);\n+\t\tthis(topics, null, deserializer, props);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTMyODY4OQ=="}, "originalCommit": {"oid": "6bfb6d18af5fdfbddadf6da53adab78567d64aa9"}, "originalPosition": 68}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1NjY2MTUzOnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-connector-kafka-0.10/src/test/java/org/apache/flink/streaming/connectors/kafka/internal/KafkaConsumerThreadTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQxNjo1MzoyOFrOFcaCfw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQxNjo1MzoyOFrOFcaCfw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTMzMTA3MQ==", "bodyText": "I would suggest to either fail or to return an empty map but not null.", "url": "https://github.com/apache/flink/pull/10762#discussion_r365331071", "createdAt": "2020-01-10T16:53:28Z", "author": {"login": "tillrohrmann"}, "path": "flink-connectors/flink-connector-kafka-0.10/src/test/java/org/apache/flink/streaming/connectors/kafka/internal/KafkaConsumerThreadTest.java", "diffHunk": "@@ -1047,17 +1047,41 @@ public OffsetAndMetadata committed(TopicPartition topicPartition) {\n \t\t}\n \n \t\t@Override\n-\t\tpublic void pause(TopicPartition... topicPartitions) {\n+\t\tpublic Set<TopicPartition> paused() {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void pause(Collection<TopicPartition> collection) {\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void resume(Collection<TopicPartition> collection) {\n \t\t}\n \n \t\t@Override\n-\t\tpublic void resume(TopicPartition... topicPartitions) {\n+\t\tpublic Map<TopicPartition, OffsetAndTimestamp> offsetsForTimes(Map<TopicPartition, Long> map) {\n+\t\t\treturn null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6bfb6d18af5fdfbddadf6da53adab78567d64aa9"}, "originalPosition": 105}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1NjY2MTkyOnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-connector-kafka-0.10/src/test/java/org/apache/flink/streaming/connectors/kafka/internal/KafkaConsumerThreadTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQxNjo1MzozN1rOFcaCxw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQxNjo1MzozN1rOFcaCxw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTMzMTE0Mw==", "bodyText": "Same here with null.", "url": "https://github.com/apache/flink/pull/10762#discussion_r365331143", "createdAt": "2020-01-10T16:53:37Z", "author": {"login": "tillrohrmann"}, "path": "flink-connectors/flink-connector-kafka-0.10/src/test/java/org/apache/flink/streaming/connectors/kafka/internal/KafkaConsumerThreadTest.java", "diffHunk": "@@ -1047,17 +1047,41 @@ public OffsetAndMetadata committed(TopicPartition topicPartition) {\n \t\t}\n \n \t\t@Override\n-\t\tpublic void pause(TopicPartition... topicPartitions) {\n+\t\tpublic Set<TopicPartition> paused() {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void pause(Collection<TopicPartition> collection) {\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void resume(Collection<TopicPartition> collection) {\n \t\t}\n \n \t\t@Override\n-\t\tpublic void resume(TopicPartition... topicPartitions) {\n+\t\tpublic Map<TopicPartition, OffsetAndTimestamp> offsetsForTimes(Map<TopicPartition, Long> map) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic Map<TopicPartition, Long> beginningOffsets(Collection<TopicPartition> collection) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic Map<TopicPartition, Long> endOffsets(Collection<TopicPartition> collection) {\n+\t\t\treturn null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6bfb6d18af5fdfbddadf6da53adab78567d64aa9"}, "originalPosition": 115}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1278, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}