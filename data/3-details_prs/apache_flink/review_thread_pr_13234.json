{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDcyNjMxMzQw", "number": 13234, "reviewThreads": {"totalCount": 13, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQxNjozMToxMlrOEcp5WQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxMToxOTozMlrOEdqenw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk4NDgyMDA5OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/graph/StreamConfig.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQxNjozMToxMlrOHHUMXA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxNDozNzo1N1rOHITb_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzQzMjkyNA==", "bodyText": "Rename Input to InputConfig as there is ..api.operators.Input already? (and subclasses)\nMake it interface and not class? This will allow children to extend other classes and ease testing\nWhy is this class not parameterized? Its serializer is passed to parameterized classes", "url": "https://github.com/apache/flink/pull/13234#discussion_r477432924", "createdAt": "2020-08-26T16:31:12Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/graph/StreamConfig.java", "diffHunk": "@@ -628,4 +622,46 @@ public String toString() {\n \n \t\treturn builder.toString();\n \t}\n+\n+\t/**\n+\t * Interface representing chained inputs.\n+\t */\n+\tpublic static class Input implements Serializable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1b6142f9dad4b3893629b2ec774c93adb5875e84"}, "originalPosition": 208}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODQ2OTExNw==", "bodyText": "and 2. \ud83d\udc4d - I guess it's a class by accident.\n\n\nI don't think we can parametrise it with anything beside <?> in practise. And secondly SourceInput doesn't have any parameter, so parametrising Input wouldn't make much sense.", "url": "https://github.com/apache/flink/pull/13234#discussion_r478469117", "createdAt": "2020-08-27T14:37:57Z", "author": {"login": "pnowojski"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/graph/StreamConfig.java", "diffHunk": "@@ -628,4 +622,46 @@ public String toString() {\n \n \t\treturn builder.toString();\n \t}\n+\n+\t/**\n+\t * Interface representing chained inputs.\n+\t */\n+\tpublic static class Input implements Serializable {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzQzMjkyNA=="}, "originalCommit": {"oid": "1b6142f9dad4b3893629b2ec774c93adb5875e84"}, "originalPosition": 208}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk4NDg1MTY4OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/graph/StreamConfig.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQxNjozODo0NFrOHHUfuA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxNTowNzoxMVrOHIUxVw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzQzNzg4MA==", "bodyText": "Why can this happen?\nShould we return Optional or mark with @Nullable?", "url": "https://github.com/apache/flink/pull/13234#discussion_r477437880", "createdAt": "2020-08-26T16:38:44Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/graph/StreamConfig.java", "diffHunk": "@@ -160,81 +159,84 @@ public TimeCharacteristic getTimeCharacteristic() {\n \t\t}\n \t}\n \n-\tpublic void setTypeSerializersIn(TypeSerializer<?> ...serializers) {\n-\t\tconfig.setInteger(TYPE_SERIALIZERS_IN_COUNT, serializers.length);\n-\t\tfor (int i = 0; i < serializers.length; i++) {\n-\t\t\tsetTypeSerializer(String.format(TYPE_SERIALIZERS_IN_PATTERN, i), serializers[i]);\n-\t\t}\n-\t}\n-\n \tpublic void setTypeSerializerOut(TypeSerializer<?> serializer) {\n \t\tsetTypeSerializer(TYPE_SERIALIZER_OUT_1, serializer);\n \t}\n \n+\tpublic <T> TypeSerializer<T> getTypeSerializerOut(ClassLoader cl) {\n+\t\ttry {\n+\t\t\treturn InstantiationUtil.readObjectFromConfig(this.config, TYPE_SERIALIZER_OUT_1, cl);\n+\t\t} catch (Exception e) {\n+\t\t\tthrow new StreamTaskException(\"Could not instantiate serializer.\", e);\n+\t\t}\n+\t}\n+\n \tpublic void setTypeSerializerSideOut(OutputTag<?> outputTag, TypeSerializer<?> serializer) {\n \t\tsetTypeSerializer(TYPE_SERIALIZER_SIDEOUT_PREFIX + outputTag.getId(), serializer);\n \t}\n \n-\t@Deprecated\n-\tpublic <T> TypeSerializer<T> getTypeSerializerIn1(ClassLoader cl) {\n-\t\treturn getTypeSerializerIn(0, cl);\n+\tprivate void setTypeSerializer(String key, TypeSerializer<?> typeWrapper) {\n+\t\ttry {\n+\t\t\tInstantiationUtil.writeObjectToConfig(typeWrapper, this.config, key);\n+\t\t} catch (IOException e) {\n+\t\t\tthrow new StreamTaskException(\"Could not serialize type serializer.\", e);\n+\t\t}\n \t}\n \n-\t@Deprecated\n-\tpublic <T> TypeSerializer<T> getTypeSerializerIn2(ClassLoader cl) {\n-\t\treturn getTypeSerializerIn(1, cl);\n+\tpublic <T> TypeSerializer<T> getTypeSerializerSideOut(OutputTag<?> outputTag, ClassLoader cl) {\n+\t\tPreconditions.checkNotNull(outputTag, \"Side output id must not be null.\");\n+\t\ttry {\n+\t\t\treturn InstantiationUtil.readObjectFromConfig(this.config, TYPE_SERIALIZER_SIDEOUT_PREFIX + outputTag.getId(), cl);\n+\t\t} catch (Exception e) {\n+\t\t\tthrow new StreamTaskException(\"Could not instantiate serializer.\", e);\n+\t\t}\n \t}\n \n-\tpublic TypeSerializer<?>[] getTypeSerializersIn(ClassLoader cl) {\n-\t\tint typeSerializersCount = config.getInteger(TYPE_SERIALIZERS_IN_COUNT, -1);\n-\t\tcheckState(\n-\t\t\ttypeSerializersCount >= 0,\n-\t\t\t\"Missing value for %s in the config? [%d]\",\n-\t\t\tTYPE_SERIALIZERS_IN_COUNT,\n-\t\t\ttypeSerializersCount);\n-\t\tTypeSerializer<?>[] typeSerializers = new TypeSerializer<?>[typeSerializersCount];\n-\t\tfor (int i = 0; i < typeSerializers.length; i++) {\n-\t\t\ttypeSerializers[i] = getTypeSerializerIn(i, cl);\n+\tpublic void setTypeSerializersIn(TypeSerializer<?> ...serializers) {\n+\t\tInput[] inputs = new Input[serializers.length];\n+\t\tfor (int i = 0; i < serializers.length; i++) {\n+\t\t\tinputs[i] = new NetworkInput(serializers[i], i);\n \t\t}\n-\t\treturn typeSerializers;\n+\t\tsetInputs(inputs);\n \t}\n \n-\tpublic <T> TypeSerializer<T> getTypeSerializerIn(int index, ClassLoader cl) {\n+\tpublic void setInputs(Input ...inputs) {\n \t\ttry {\n-\t\t\treturn InstantiationUtil.readObjectFromConfig(\n-\t\t\t\tthis.config,\n-\t\t\t\tString.format(TYPE_SERIALIZERS_IN_PATTERN, index),\n-\t\t\t\tcl);\n-\t\t} catch (Exception e) {\n-\t\t\tthrow new StreamTaskException(\n-\t\t\t\tString.format(\"Could not instantiate serializer for [%d] input.\", index),\n-\t\t\t\te);\n+\t\t\tInstantiationUtil.writeObjectToConfig(inputs, this.config, INPUTS);\n+\t\t} catch (IOException e) {\n+\t\t\tthrow new StreamTaskException(\"Could not serialize inputs.\", e);\n \t\t}\n \t}\n \n-\tpublic <T> TypeSerializer<T> getTypeSerializerOut(ClassLoader cl) {\n+\tpublic Input[] getInputs(ClassLoader cl) {\n \t\ttry {\n-\t\t\treturn InstantiationUtil.readObjectFromConfig(this.config, TYPE_SERIALIZER_OUT_1, cl);\n+\t\t\tInput[] inputs = InstantiationUtil.readObjectFromConfig(this.config, INPUTS, cl);\n+\t\t\tif (inputs == null) {\n+\t\t\t\treturn new Input[0];\n+\t\t\t}\n+\t\t\treturn inputs;\n \t\t} catch (Exception e) {\n-\t\t\tthrow new StreamTaskException(\"Could not instantiate serializer.\", e);\n+\t\t\tthrow new StreamTaskException(\"Could not deserialize inputs\", e);\n \t\t}\n \t}\n \n-\tpublic <T> TypeSerializer<T> getTypeSerializerSideOut(OutputTag<?> outputTag, ClassLoader cl) {\n-\t\tPreconditions.checkNotNull(outputTag, \"Side output id must not be null.\");\n-\t\ttry {\n-\t\t\treturn InstantiationUtil.readObjectFromConfig(this.config, TYPE_SERIALIZER_SIDEOUT_PREFIX + outputTag.getId(), cl);\n-\t\t} catch (Exception e) {\n-\t\t\tthrow new StreamTaskException(\"Could not instantiate serializer.\", e);\n-\t\t}\n+\t@Deprecated\n+\tpublic <T> TypeSerializer<T> getTypeSerializerIn1(ClassLoader cl) {\n+\t\treturn getTypeSerializerIn(0, cl);\n \t}\n \n-\tprivate void setTypeSerializer(String key, TypeSerializer<?> typeWrapper) {\n-\t\ttry {\n-\t\t\tInstantiationUtil.writeObjectToConfig(typeWrapper, this.config, key);\n-\t\t} catch (IOException e) {\n-\t\t\tthrow new StreamTaskException(\"Could not serialize type serializer.\", e);\n+\t@Deprecated\n+\tpublic <T> TypeSerializer<T> getTypeSerializerIn2(ClassLoader cl) {\n+\t\treturn getTypeSerializerIn(1, cl);\n+\t}\n+\n+\tpublic <T> TypeSerializer<T> getTypeSerializerIn(int index, ClassLoader cl) {\n+\t\tInput[] inputs = getInputs(cl);\n+\t\tif (index >= inputs.length) {\n+\t\t\treturn null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1b6142f9dad4b3893629b2ec774c93adb5875e84"}, "originalPosition": 145}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODQ5MDk2Nw==", "bodyText": "It was for backwards compatibility, as this is the equivalent of the code on the master. I think at least some of the tests are failing, that are manually constructing StreamConfig, but I'm not sure - I don't know this code very well. I will try to track those failures down and if are easy to fix, will replace it with a checkState", "url": "https://github.com/apache/flink/pull/13234#discussion_r478490967", "createdAt": "2020-08-27T15:07:11Z", "author": {"login": "pnowojski"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/graph/StreamConfig.java", "diffHunk": "@@ -160,81 +159,84 @@ public TimeCharacteristic getTimeCharacteristic() {\n \t\t}\n \t}\n \n-\tpublic void setTypeSerializersIn(TypeSerializer<?> ...serializers) {\n-\t\tconfig.setInteger(TYPE_SERIALIZERS_IN_COUNT, serializers.length);\n-\t\tfor (int i = 0; i < serializers.length; i++) {\n-\t\t\tsetTypeSerializer(String.format(TYPE_SERIALIZERS_IN_PATTERN, i), serializers[i]);\n-\t\t}\n-\t}\n-\n \tpublic void setTypeSerializerOut(TypeSerializer<?> serializer) {\n \t\tsetTypeSerializer(TYPE_SERIALIZER_OUT_1, serializer);\n \t}\n \n+\tpublic <T> TypeSerializer<T> getTypeSerializerOut(ClassLoader cl) {\n+\t\ttry {\n+\t\t\treturn InstantiationUtil.readObjectFromConfig(this.config, TYPE_SERIALIZER_OUT_1, cl);\n+\t\t} catch (Exception e) {\n+\t\t\tthrow new StreamTaskException(\"Could not instantiate serializer.\", e);\n+\t\t}\n+\t}\n+\n \tpublic void setTypeSerializerSideOut(OutputTag<?> outputTag, TypeSerializer<?> serializer) {\n \t\tsetTypeSerializer(TYPE_SERIALIZER_SIDEOUT_PREFIX + outputTag.getId(), serializer);\n \t}\n \n-\t@Deprecated\n-\tpublic <T> TypeSerializer<T> getTypeSerializerIn1(ClassLoader cl) {\n-\t\treturn getTypeSerializerIn(0, cl);\n+\tprivate void setTypeSerializer(String key, TypeSerializer<?> typeWrapper) {\n+\t\ttry {\n+\t\t\tInstantiationUtil.writeObjectToConfig(typeWrapper, this.config, key);\n+\t\t} catch (IOException e) {\n+\t\t\tthrow new StreamTaskException(\"Could not serialize type serializer.\", e);\n+\t\t}\n \t}\n \n-\t@Deprecated\n-\tpublic <T> TypeSerializer<T> getTypeSerializerIn2(ClassLoader cl) {\n-\t\treturn getTypeSerializerIn(1, cl);\n+\tpublic <T> TypeSerializer<T> getTypeSerializerSideOut(OutputTag<?> outputTag, ClassLoader cl) {\n+\t\tPreconditions.checkNotNull(outputTag, \"Side output id must not be null.\");\n+\t\ttry {\n+\t\t\treturn InstantiationUtil.readObjectFromConfig(this.config, TYPE_SERIALIZER_SIDEOUT_PREFIX + outputTag.getId(), cl);\n+\t\t} catch (Exception e) {\n+\t\t\tthrow new StreamTaskException(\"Could not instantiate serializer.\", e);\n+\t\t}\n \t}\n \n-\tpublic TypeSerializer<?>[] getTypeSerializersIn(ClassLoader cl) {\n-\t\tint typeSerializersCount = config.getInteger(TYPE_SERIALIZERS_IN_COUNT, -1);\n-\t\tcheckState(\n-\t\t\ttypeSerializersCount >= 0,\n-\t\t\t\"Missing value for %s in the config? [%d]\",\n-\t\t\tTYPE_SERIALIZERS_IN_COUNT,\n-\t\t\ttypeSerializersCount);\n-\t\tTypeSerializer<?>[] typeSerializers = new TypeSerializer<?>[typeSerializersCount];\n-\t\tfor (int i = 0; i < typeSerializers.length; i++) {\n-\t\t\ttypeSerializers[i] = getTypeSerializerIn(i, cl);\n+\tpublic void setTypeSerializersIn(TypeSerializer<?> ...serializers) {\n+\t\tInput[] inputs = new Input[serializers.length];\n+\t\tfor (int i = 0; i < serializers.length; i++) {\n+\t\t\tinputs[i] = new NetworkInput(serializers[i], i);\n \t\t}\n-\t\treturn typeSerializers;\n+\t\tsetInputs(inputs);\n \t}\n \n-\tpublic <T> TypeSerializer<T> getTypeSerializerIn(int index, ClassLoader cl) {\n+\tpublic void setInputs(Input ...inputs) {\n \t\ttry {\n-\t\t\treturn InstantiationUtil.readObjectFromConfig(\n-\t\t\t\tthis.config,\n-\t\t\t\tString.format(TYPE_SERIALIZERS_IN_PATTERN, index),\n-\t\t\t\tcl);\n-\t\t} catch (Exception e) {\n-\t\t\tthrow new StreamTaskException(\n-\t\t\t\tString.format(\"Could not instantiate serializer for [%d] input.\", index),\n-\t\t\t\te);\n+\t\t\tInstantiationUtil.writeObjectToConfig(inputs, this.config, INPUTS);\n+\t\t} catch (IOException e) {\n+\t\t\tthrow new StreamTaskException(\"Could not serialize inputs.\", e);\n \t\t}\n \t}\n \n-\tpublic <T> TypeSerializer<T> getTypeSerializerOut(ClassLoader cl) {\n+\tpublic Input[] getInputs(ClassLoader cl) {\n \t\ttry {\n-\t\t\treturn InstantiationUtil.readObjectFromConfig(this.config, TYPE_SERIALIZER_OUT_1, cl);\n+\t\t\tInput[] inputs = InstantiationUtil.readObjectFromConfig(this.config, INPUTS, cl);\n+\t\t\tif (inputs == null) {\n+\t\t\t\treturn new Input[0];\n+\t\t\t}\n+\t\t\treturn inputs;\n \t\t} catch (Exception e) {\n-\t\t\tthrow new StreamTaskException(\"Could not instantiate serializer.\", e);\n+\t\t\tthrow new StreamTaskException(\"Could not deserialize inputs\", e);\n \t\t}\n \t}\n \n-\tpublic <T> TypeSerializer<T> getTypeSerializerSideOut(OutputTag<?> outputTag, ClassLoader cl) {\n-\t\tPreconditions.checkNotNull(outputTag, \"Side output id must not be null.\");\n-\t\ttry {\n-\t\t\treturn InstantiationUtil.readObjectFromConfig(this.config, TYPE_SERIALIZER_SIDEOUT_PREFIX + outputTag.getId(), cl);\n-\t\t} catch (Exception e) {\n-\t\t\tthrow new StreamTaskException(\"Could not instantiate serializer.\", e);\n-\t\t}\n+\t@Deprecated\n+\tpublic <T> TypeSerializer<T> getTypeSerializerIn1(ClassLoader cl) {\n+\t\treturn getTypeSerializerIn(0, cl);\n \t}\n \n-\tprivate void setTypeSerializer(String key, TypeSerializer<?> typeWrapper) {\n-\t\ttry {\n-\t\t\tInstantiationUtil.writeObjectToConfig(typeWrapper, this.config, key);\n-\t\t} catch (IOException e) {\n-\t\t\tthrow new StreamTaskException(\"Could not serialize type serializer.\", e);\n+\t@Deprecated\n+\tpublic <T> TypeSerializer<T> getTypeSerializerIn2(ClassLoader cl) {\n+\t\treturn getTypeSerializerIn(1, cl);\n+\t}\n+\n+\tpublic <T> TypeSerializer<T> getTypeSerializerIn(int index, ClassLoader cl) {\n+\t\tInput[] inputs = getInputs(cl);\n+\t\tif (index >= inputs.length) {\n+\t\t\treturn null;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzQzNzg4MA=="}, "originalCommit": {"oid": "1b6142f9dad4b3893629b2ec774c93adb5875e84"}, "originalPosition": 145}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk4NDg3OTI4OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/graph/StreamConfig.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQxNjo0NTo0MVrOHHUxHw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQxNjo0NTo0MVrOHHUxHw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzQ0MjMzNQ==", "bodyText": "I think checkState only recognizes %s pattern.", "url": "https://github.com/apache/flink/pull/13234#discussion_r477442335", "createdAt": "2020-08-26T16:45:41Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/graph/StreamConfig.java", "diffHunk": "@@ -160,81 +159,84 @@ public TimeCharacteristic getTimeCharacteristic() {\n \t\t}\n \t}\n \n-\tpublic void setTypeSerializersIn(TypeSerializer<?> ...serializers) {\n-\t\tconfig.setInteger(TYPE_SERIALIZERS_IN_COUNT, serializers.length);\n-\t\tfor (int i = 0; i < serializers.length; i++) {\n-\t\t\tsetTypeSerializer(String.format(TYPE_SERIALIZERS_IN_PATTERN, i), serializers[i]);\n-\t\t}\n-\t}\n-\n \tpublic void setTypeSerializerOut(TypeSerializer<?> serializer) {\n \t\tsetTypeSerializer(TYPE_SERIALIZER_OUT_1, serializer);\n \t}\n \n+\tpublic <T> TypeSerializer<T> getTypeSerializerOut(ClassLoader cl) {\n+\t\ttry {\n+\t\t\treturn InstantiationUtil.readObjectFromConfig(this.config, TYPE_SERIALIZER_OUT_1, cl);\n+\t\t} catch (Exception e) {\n+\t\t\tthrow new StreamTaskException(\"Could not instantiate serializer.\", e);\n+\t\t}\n+\t}\n+\n \tpublic void setTypeSerializerSideOut(OutputTag<?> outputTag, TypeSerializer<?> serializer) {\n \t\tsetTypeSerializer(TYPE_SERIALIZER_SIDEOUT_PREFIX + outputTag.getId(), serializer);\n \t}\n \n-\t@Deprecated\n-\tpublic <T> TypeSerializer<T> getTypeSerializerIn1(ClassLoader cl) {\n-\t\treturn getTypeSerializerIn(0, cl);\n+\tprivate void setTypeSerializer(String key, TypeSerializer<?> typeWrapper) {\n+\t\ttry {\n+\t\t\tInstantiationUtil.writeObjectToConfig(typeWrapper, this.config, key);\n+\t\t} catch (IOException e) {\n+\t\t\tthrow new StreamTaskException(\"Could not serialize type serializer.\", e);\n+\t\t}\n \t}\n \n-\t@Deprecated\n-\tpublic <T> TypeSerializer<T> getTypeSerializerIn2(ClassLoader cl) {\n-\t\treturn getTypeSerializerIn(1, cl);\n+\tpublic <T> TypeSerializer<T> getTypeSerializerSideOut(OutputTag<?> outputTag, ClassLoader cl) {\n+\t\tPreconditions.checkNotNull(outputTag, \"Side output id must not be null.\");\n+\t\ttry {\n+\t\t\treturn InstantiationUtil.readObjectFromConfig(this.config, TYPE_SERIALIZER_SIDEOUT_PREFIX + outputTag.getId(), cl);\n+\t\t} catch (Exception e) {\n+\t\t\tthrow new StreamTaskException(\"Could not instantiate serializer.\", e);\n+\t\t}\n \t}\n \n-\tpublic TypeSerializer<?>[] getTypeSerializersIn(ClassLoader cl) {\n-\t\tint typeSerializersCount = config.getInteger(TYPE_SERIALIZERS_IN_COUNT, -1);\n-\t\tcheckState(\n-\t\t\ttypeSerializersCount >= 0,\n-\t\t\t\"Missing value for %s in the config? [%d]\",\n-\t\t\tTYPE_SERIALIZERS_IN_COUNT,\n-\t\t\ttypeSerializersCount);\n-\t\tTypeSerializer<?>[] typeSerializers = new TypeSerializer<?>[typeSerializersCount];\n-\t\tfor (int i = 0; i < typeSerializers.length; i++) {\n-\t\t\ttypeSerializers[i] = getTypeSerializerIn(i, cl);\n+\tpublic void setTypeSerializersIn(TypeSerializer<?> ...serializers) {\n+\t\tInput[] inputs = new Input[serializers.length];\n+\t\tfor (int i = 0; i < serializers.length; i++) {\n+\t\t\tinputs[i] = new NetworkInput(serializers[i], i);\n \t\t}\n-\t\treturn typeSerializers;\n+\t\tsetInputs(inputs);\n \t}\n \n-\tpublic <T> TypeSerializer<T> getTypeSerializerIn(int index, ClassLoader cl) {\n+\tpublic void setInputs(Input ...inputs) {\n \t\ttry {\n-\t\t\treturn InstantiationUtil.readObjectFromConfig(\n-\t\t\t\tthis.config,\n-\t\t\t\tString.format(TYPE_SERIALIZERS_IN_PATTERN, index),\n-\t\t\t\tcl);\n-\t\t} catch (Exception e) {\n-\t\t\tthrow new StreamTaskException(\n-\t\t\t\tString.format(\"Could not instantiate serializer for [%d] input.\", index),\n-\t\t\t\te);\n+\t\t\tInstantiationUtil.writeObjectToConfig(inputs, this.config, INPUTS);\n+\t\t} catch (IOException e) {\n+\t\t\tthrow new StreamTaskException(\"Could not serialize inputs.\", e);\n \t\t}\n \t}\n \n-\tpublic <T> TypeSerializer<T> getTypeSerializerOut(ClassLoader cl) {\n+\tpublic Input[] getInputs(ClassLoader cl) {\n \t\ttry {\n-\t\t\treturn InstantiationUtil.readObjectFromConfig(this.config, TYPE_SERIALIZER_OUT_1, cl);\n+\t\t\tInput[] inputs = InstantiationUtil.readObjectFromConfig(this.config, INPUTS, cl);\n+\t\t\tif (inputs == null) {\n+\t\t\t\treturn new Input[0];\n+\t\t\t}\n+\t\t\treturn inputs;\n \t\t} catch (Exception e) {\n-\t\t\tthrow new StreamTaskException(\"Could not instantiate serializer.\", e);\n+\t\t\tthrow new StreamTaskException(\"Could not deserialize inputs\", e);\n \t\t}\n \t}\n \n-\tpublic <T> TypeSerializer<T> getTypeSerializerSideOut(OutputTag<?> outputTag, ClassLoader cl) {\n-\t\tPreconditions.checkNotNull(outputTag, \"Side output id must not be null.\");\n-\t\ttry {\n-\t\t\treturn InstantiationUtil.readObjectFromConfig(this.config, TYPE_SERIALIZER_SIDEOUT_PREFIX + outputTag.getId(), cl);\n-\t\t} catch (Exception e) {\n-\t\t\tthrow new StreamTaskException(\"Could not instantiate serializer.\", e);\n-\t\t}\n+\t@Deprecated\n+\tpublic <T> TypeSerializer<T> getTypeSerializerIn1(ClassLoader cl) {\n+\t\treturn getTypeSerializerIn(0, cl);\n \t}\n \n-\tprivate void setTypeSerializer(String key, TypeSerializer<?> typeWrapper) {\n-\t\ttry {\n-\t\t\tInstantiationUtil.writeObjectToConfig(typeWrapper, this.config, key);\n-\t\t} catch (IOException e) {\n-\t\t\tthrow new StreamTaskException(\"Could not serialize type serializer.\", e);\n+\t@Deprecated\n+\tpublic <T> TypeSerializer<T> getTypeSerializerIn2(ClassLoader cl) {\n+\t\treturn getTypeSerializerIn(1, cl);\n+\t}\n+\n+\tpublic <T> TypeSerializer<T> getTypeSerializerIn(int index, ClassLoader cl) {\n+\t\tInput[] inputs = getInputs(cl);\n+\t\tif (index >= inputs.length) {\n+\t\t\treturn null;\n \t\t}\n+\t\tcheckState(inputs[index] instanceof NetworkInput, \"Input [%d] was assumed to be network input\", index);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1b6142f9dad4b3893629b2ec774c93adb5875e84"}, "originalPosition": 147}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk4NTAwMjg3OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/OperatorChain.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQxNzoxODoxM1rOHHV-ig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQxNzoxODoxM1rOHHV-ig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzQ2MjE1NA==", "bodyText": "nit: indentation", "url": "https://github.com/apache/flink/pull/13234#discussion_r477462154", "createdAt": "2020-08-26T17:18:13Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/OperatorChain.java", "diffHunk": "@@ -208,19 +206,100 @@ public OperatorChain(\n \tOperatorChain(\n \t\t\tList<StreamOperatorWrapper<?, ?>> allOperatorWrappers,\n \t\t\tRecordWriterOutput<?>[] streamOutputs,\n-\t\t\tWatermarkGaugeExposingOutput<StreamRecord<OUT>> chainEntryPoint,\n-\t\t\tStreamOperatorWrapper<OUT, OP> headOperatorWrapper) {\n+\t\t\tWatermarkGaugeExposingOutput<StreamRecord<OUT>> mainOperatorOutput,\n+\t\t\tStreamOperatorWrapper<OUT, OP> mainOperatorWrapper) {\n \n \t\tthis.streamOutputs = checkNotNull(streamOutputs);\n-\t\tthis.chainEntryPoint = checkNotNull(chainEntryPoint);\n+\t\tthis.mainOperatorOutput = checkNotNull(mainOperatorOutput);\n \t\tthis.operatorEventDispatcher = null;\n \n \t\tcheckState(allOperatorWrappers != null && allOperatorWrappers.size() > 0);\n-\t\tthis.headOperatorWrapper = checkNotNull(headOperatorWrapper);\n+\t\tthis.mainOperatorWrapper = checkNotNull(mainOperatorWrapper);\n \t\tthis.tailOperatorWrapper = allOperatorWrappers.get(0);\n \t\tthis.numOperators = allOperatorWrappers.size();\n+\t\tthis.chainedSourceOutputs = new ChainedSourceOutputs();\n \n-\t\tlinkOperatorWrappers(allOperatorWrappers);\n+\t\tfirstOperatorWrapper = linkOperatorWrappers(allOperatorWrappers);\n+\t}\n+\n+\tprivate void createChainOutputs(\n+\t\tList<StreamEdge> outEdgesInOrder,\n+\t\tRecordWriterDelegate<SerializationDelegate<StreamRecord<OUT>>> recordWriterDelegate,\n+\t\tMap<Integer, StreamConfig> chainedConfigs,\n+\t\tStreamTask<OUT, OP> containingTask,\n+\t\tMap<StreamEdge, RecordWriterOutput<?>> streamOutputMap) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1b6142f9dad4b3893629b2ec774c93adb5875e84"}, "originalPosition": 205}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk4NTEzNzY5OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/MultipleInputChainingOutput.java", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQxNzo1NToyNFrOHHXTLw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMVQxNTo1MTowMlrOHK89vg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzQ4MzgyMw==", "bodyText": "Objects.equals?\nI guess we should also process record if both tags are null.", "url": "https://github.com/apache/flink/pull/13234#discussion_r477483823", "createdAt": "2020-08-26T17:55:24Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/MultipleInputChainingOutput.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.tasks;\n+\n+import org.apache.flink.metrics.Counter;\n+import org.apache.flink.metrics.Gauge;\n+import org.apache.flink.metrics.SimpleCounter;\n+import org.apache.flink.runtime.metrics.groups.OperatorIOMetricGroup;\n+import org.apache.flink.runtime.metrics.groups.OperatorMetricGroup;\n+import org.apache.flink.streaming.api.operators.Input;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.metrics.WatermarkGauge;\n+import org.apache.flink.streaming.runtime.streamrecord.LatencyMarker;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatusProvider;\n+import org.apache.flink.util.OutputTag;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+class MultipleInputChainingOutput<T> implements WatermarkGaugeExposingOutput<StreamRecord<T>> {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(MultipleInputChainingOutput.class);\n+\n+\tprotected final Input<T> input;\n+\tprotected final Counter numRecordsIn;\n+\tprotected final WatermarkGauge watermarkGauge = new WatermarkGauge();\n+\tprotected final StreamStatusProvider streamStatusProvider;\n+\t@Nullable protected final OutputTag<T> outputTag;\n+\n+\tpublic MultipleInputChainingOutput(\n+\t\t\tInput<T> input,\n+\t\t\tOperatorMetricGroup operatorMetricGroup,\n+\t\t\tStreamStatusProvider streamStatusProvider,\n+\t\t\t@Nullable OutputTag<T> outputTag) {\n+\t\tthis.input = input;\n+\n+\t\t{\n+\t\t\tCounter tmpNumRecordsIn;\n+\t\t\ttry {\n+\t\t\t\tOperatorIOMetricGroup ioMetricGroup = operatorMetricGroup.getIOMetricGroup();\n+\t\t\t\ttmpNumRecordsIn = ioMetricGroup.getNumRecordsInCounter();\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tLOG.warn(\"An exception occurred during the metrics setup.\", e);\n+\t\t\t\ttmpNumRecordsIn = new SimpleCounter();\n+\t\t\t}\n+\t\t\tnumRecordsIn = tmpNumRecordsIn;\n+\t\t}\n+\n+\t\tthis.streamStatusProvider = streamStatusProvider;\n+\t\tthis.outputTag = outputTag;\n+\t}\n+\n+\t@Override\n+\tpublic void collect(StreamRecord<T> record) {\n+\t\tif (this.outputTag != null) {\n+\t\t\t// we are not responsible for emitting to the main output.\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tpushToOperator(record);\n+\t}\n+\n+\t@Override\n+\tpublic <X> void collect(OutputTag<X> outputTag, StreamRecord<X> record) {\n+\t\tif (this.outputTag == null || !this.outputTag.equals(outputTag)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1b6142f9dad4b3893629b2ec774c93adb5875e84"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODQ5NjA0MQ==", "bodyText": "In that case user should be calling Output.collect(record), as outputTag is @NonNull (by default).\nI mean, we could do it but do we want to support nullable outputTag? Keep in mind that's a public api, so we would need to change the behaviour of the public api and then keep supporting incorrect calls in the future.", "url": "https://github.com/apache/flink/pull/13234#discussion_r478496041", "createdAt": "2020-08-27T15:14:15Z", "author": {"login": "pnowojski"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/MultipleInputChainingOutput.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.tasks;\n+\n+import org.apache.flink.metrics.Counter;\n+import org.apache.flink.metrics.Gauge;\n+import org.apache.flink.metrics.SimpleCounter;\n+import org.apache.flink.runtime.metrics.groups.OperatorIOMetricGroup;\n+import org.apache.flink.runtime.metrics.groups.OperatorMetricGroup;\n+import org.apache.flink.streaming.api.operators.Input;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.metrics.WatermarkGauge;\n+import org.apache.flink.streaming.runtime.streamrecord.LatencyMarker;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatusProvider;\n+import org.apache.flink.util.OutputTag;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+class MultipleInputChainingOutput<T> implements WatermarkGaugeExposingOutput<StreamRecord<T>> {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(MultipleInputChainingOutput.class);\n+\n+\tprotected final Input<T> input;\n+\tprotected final Counter numRecordsIn;\n+\tprotected final WatermarkGauge watermarkGauge = new WatermarkGauge();\n+\tprotected final StreamStatusProvider streamStatusProvider;\n+\t@Nullable protected final OutputTag<T> outputTag;\n+\n+\tpublic MultipleInputChainingOutput(\n+\t\t\tInput<T> input,\n+\t\t\tOperatorMetricGroup operatorMetricGroup,\n+\t\t\tStreamStatusProvider streamStatusProvider,\n+\t\t\t@Nullable OutputTag<T> outputTag) {\n+\t\tthis.input = input;\n+\n+\t\t{\n+\t\t\tCounter tmpNumRecordsIn;\n+\t\t\ttry {\n+\t\t\t\tOperatorIOMetricGroup ioMetricGroup = operatorMetricGroup.getIOMetricGroup();\n+\t\t\t\ttmpNumRecordsIn = ioMetricGroup.getNumRecordsInCounter();\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tLOG.warn(\"An exception occurred during the metrics setup.\", e);\n+\t\t\t\ttmpNumRecordsIn = new SimpleCounter();\n+\t\t\t}\n+\t\t\tnumRecordsIn = tmpNumRecordsIn;\n+\t\t}\n+\n+\t\tthis.streamStatusProvider = streamStatusProvider;\n+\t\tthis.outputTag = outputTag;\n+\t}\n+\n+\t@Override\n+\tpublic void collect(StreamRecord<T> record) {\n+\t\tif (this.outputTag != null) {\n+\t\t\t// we are not responsible for emitting to the main output.\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tpushToOperator(record);\n+\t}\n+\n+\t@Override\n+\tpublic <X> void collect(OutputTag<X> outputTag, StreamRecord<X> record) {\n+\t\tif (this.outputTag == null || !this.outputTag.equals(outputTag)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzQ4MzgyMw=="}, "originalCommit": {"oid": "1b6142f9dad4b3893629b2ec774c93adb5875e84"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTA2MTIyNw==", "bodyText": "It's unclear to me what is the contract and the intended behavior.\nIf\n\noutputTag is @ NonNull (by default)\n\nthen we probably should check for it.\nCurrently, we'll just drop the record.", "url": "https://github.com/apache/flink/pull/13234#discussion_r479061227", "createdAt": "2020-08-28T10:02:39Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/MultipleInputChainingOutput.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.tasks;\n+\n+import org.apache.flink.metrics.Counter;\n+import org.apache.flink.metrics.Gauge;\n+import org.apache.flink.metrics.SimpleCounter;\n+import org.apache.flink.runtime.metrics.groups.OperatorIOMetricGroup;\n+import org.apache.flink.runtime.metrics.groups.OperatorMetricGroup;\n+import org.apache.flink.streaming.api.operators.Input;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.metrics.WatermarkGauge;\n+import org.apache.flink.streaming.runtime.streamrecord.LatencyMarker;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatusProvider;\n+import org.apache.flink.util.OutputTag;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+class MultipleInputChainingOutput<T> implements WatermarkGaugeExposingOutput<StreamRecord<T>> {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(MultipleInputChainingOutput.class);\n+\n+\tprotected final Input<T> input;\n+\tprotected final Counter numRecordsIn;\n+\tprotected final WatermarkGauge watermarkGauge = new WatermarkGauge();\n+\tprotected final StreamStatusProvider streamStatusProvider;\n+\t@Nullable protected final OutputTag<T> outputTag;\n+\n+\tpublic MultipleInputChainingOutput(\n+\t\t\tInput<T> input,\n+\t\t\tOperatorMetricGroup operatorMetricGroup,\n+\t\t\tStreamStatusProvider streamStatusProvider,\n+\t\t\t@Nullable OutputTag<T> outputTag) {\n+\t\tthis.input = input;\n+\n+\t\t{\n+\t\t\tCounter tmpNumRecordsIn;\n+\t\t\ttry {\n+\t\t\t\tOperatorIOMetricGroup ioMetricGroup = operatorMetricGroup.getIOMetricGroup();\n+\t\t\t\ttmpNumRecordsIn = ioMetricGroup.getNumRecordsInCounter();\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tLOG.warn(\"An exception occurred during the metrics setup.\", e);\n+\t\t\t\ttmpNumRecordsIn = new SimpleCounter();\n+\t\t\t}\n+\t\t\tnumRecordsIn = tmpNumRecordsIn;\n+\t\t}\n+\n+\t\tthis.streamStatusProvider = streamStatusProvider;\n+\t\tthis.outputTag = outputTag;\n+\t}\n+\n+\t@Override\n+\tpublic void collect(StreamRecord<T> record) {\n+\t\tif (this.outputTag != null) {\n+\t\t\t// we are not responsible for emitting to the main output.\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tpushToOperator(record);\n+\t}\n+\n+\t@Override\n+\tpublic <X> void collect(OutputTag<X> outputTag, StreamRecord<X> record) {\n+\t\tif (this.outputTag == null || !this.outputTag.equals(outputTag)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzQ4MzgyMw=="}, "originalCommit": {"oid": "1b6142f9dad4b3893629b2ec774c93adb5875e84"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTI0MDg0MA==", "bodyText": "If someone would like to pass outputTag = null, there is the other collect(record) method for that purpose. In Flink we have convention that everything is @NonNull unless marked otherwise (or someone forgot about @Nulalble annotation).\nAlso note that's a pre-existing problem, assuming we can agree that's a problem.\nAlso, the null check is covered by org.apache.flink.util.OutputTag#equals \ud83d\ude38 .\nRegardless, I've extracted OutputTag#isResponsibleFor method, not sure how worthwhile this was.", "url": "https://github.com/apache/flink/pull/13234#discussion_r481240840", "createdAt": "2020-09-01T15:42:41Z", "author": {"login": "pnowojski"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/MultipleInputChainingOutput.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.tasks;\n+\n+import org.apache.flink.metrics.Counter;\n+import org.apache.flink.metrics.Gauge;\n+import org.apache.flink.metrics.SimpleCounter;\n+import org.apache.flink.runtime.metrics.groups.OperatorIOMetricGroup;\n+import org.apache.flink.runtime.metrics.groups.OperatorMetricGroup;\n+import org.apache.flink.streaming.api.operators.Input;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.metrics.WatermarkGauge;\n+import org.apache.flink.streaming.runtime.streamrecord.LatencyMarker;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatusProvider;\n+import org.apache.flink.util.OutputTag;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+class MultipleInputChainingOutput<T> implements WatermarkGaugeExposingOutput<StreamRecord<T>> {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(MultipleInputChainingOutput.class);\n+\n+\tprotected final Input<T> input;\n+\tprotected final Counter numRecordsIn;\n+\tprotected final WatermarkGauge watermarkGauge = new WatermarkGauge();\n+\tprotected final StreamStatusProvider streamStatusProvider;\n+\t@Nullable protected final OutputTag<T> outputTag;\n+\n+\tpublic MultipleInputChainingOutput(\n+\t\t\tInput<T> input,\n+\t\t\tOperatorMetricGroup operatorMetricGroup,\n+\t\t\tStreamStatusProvider streamStatusProvider,\n+\t\t\t@Nullable OutputTag<T> outputTag) {\n+\t\tthis.input = input;\n+\n+\t\t{\n+\t\t\tCounter tmpNumRecordsIn;\n+\t\t\ttry {\n+\t\t\t\tOperatorIOMetricGroup ioMetricGroup = operatorMetricGroup.getIOMetricGroup();\n+\t\t\t\ttmpNumRecordsIn = ioMetricGroup.getNumRecordsInCounter();\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tLOG.warn(\"An exception occurred during the metrics setup.\", e);\n+\t\t\t\ttmpNumRecordsIn = new SimpleCounter();\n+\t\t\t}\n+\t\t\tnumRecordsIn = tmpNumRecordsIn;\n+\t\t}\n+\n+\t\tthis.streamStatusProvider = streamStatusProvider;\n+\t\tthis.outputTag = outputTag;\n+\t}\n+\n+\t@Override\n+\tpublic void collect(StreamRecord<T> record) {\n+\t\tif (this.outputTag != null) {\n+\t\t\t// we are not responsible for emitting to the main output.\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tpushToOperator(record);\n+\t}\n+\n+\t@Override\n+\tpublic <X> void collect(OutputTag<X> outputTag, StreamRecord<X> record) {\n+\t\tif (this.outputTag == null || !this.outputTag.equals(outputTag)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzQ4MzgyMw=="}, "originalCommit": {"oid": "1b6142f9dad4b3893629b2ec774c93adb5875e84"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTI0NjY1NA==", "bodyText": "In Flink we have convention that everything is @nonnull\n\nWhy there are so many explicit @nonnull and null checks then :)\n\nAlso, the null check is covered by org.apache.flink.util.OutputTag#equals smile_cat .\n\nIt drops the record instead of throwing an exception.\nBut ok, let's leave it as is.", "url": "https://github.com/apache/flink/pull/13234#discussion_r481246654", "createdAt": "2020-09-01T15:51:02Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/MultipleInputChainingOutput.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.tasks;\n+\n+import org.apache.flink.metrics.Counter;\n+import org.apache.flink.metrics.Gauge;\n+import org.apache.flink.metrics.SimpleCounter;\n+import org.apache.flink.runtime.metrics.groups.OperatorIOMetricGroup;\n+import org.apache.flink.runtime.metrics.groups.OperatorMetricGroup;\n+import org.apache.flink.streaming.api.operators.Input;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.metrics.WatermarkGauge;\n+import org.apache.flink.streaming.runtime.streamrecord.LatencyMarker;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatusProvider;\n+import org.apache.flink.util.OutputTag;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+class MultipleInputChainingOutput<T> implements WatermarkGaugeExposingOutput<StreamRecord<T>> {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(MultipleInputChainingOutput.class);\n+\n+\tprotected final Input<T> input;\n+\tprotected final Counter numRecordsIn;\n+\tprotected final WatermarkGauge watermarkGauge = new WatermarkGauge();\n+\tprotected final StreamStatusProvider streamStatusProvider;\n+\t@Nullable protected final OutputTag<T> outputTag;\n+\n+\tpublic MultipleInputChainingOutput(\n+\t\t\tInput<T> input,\n+\t\t\tOperatorMetricGroup operatorMetricGroup,\n+\t\t\tStreamStatusProvider streamStatusProvider,\n+\t\t\t@Nullable OutputTag<T> outputTag) {\n+\t\tthis.input = input;\n+\n+\t\t{\n+\t\t\tCounter tmpNumRecordsIn;\n+\t\t\ttry {\n+\t\t\t\tOperatorIOMetricGroup ioMetricGroup = operatorMetricGroup.getIOMetricGroup();\n+\t\t\t\ttmpNumRecordsIn = ioMetricGroup.getNumRecordsInCounter();\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tLOG.warn(\"An exception occurred during the metrics setup.\", e);\n+\t\t\t\ttmpNumRecordsIn = new SimpleCounter();\n+\t\t\t}\n+\t\t\tnumRecordsIn = tmpNumRecordsIn;\n+\t\t}\n+\n+\t\tthis.streamStatusProvider = streamStatusProvider;\n+\t\tthis.outputTag = outputTag;\n+\t}\n+\n+\t@Override\n+\tpublic void collect(StreamRecord<T> record) {\n+\t\tif (this.outputTag != null) {\n+\t\t\t// we are not responsible for emitting to the main output.\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tpushToOperator(record);\n+\t}\n+\n+\t@Override\n+\tpublic <X> void collect(OutputTag<X> outputTag, StreamRecord<X> record) {\n+\t\tif (this.outputTag == null || !this.outputTag.equals(outputTag)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzQ4MzgyMw=="}, "originalCommit": {"oid": "1b6142f9dad4b3893629b2ec774c93adb5875e84"}, "originalPosition": 82}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk4NTE1OTkwOnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/MultipleInputChainingOutput.java", "isResolved": false, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQxODowMToxNlrOHHXhEQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQxODozMzoxMVrOHL8b8A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzQ4NzM3Nw==", "bodyText": "This class duplicates quite some parts of ChainingOutput.\nWhy not re-use it by extending/delegating?", "url": "https://github.com/apache/flink/pull/13234#discussion_r477487377", "createdAt": "2020-08-26T18:01:16Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/MultipleInputChainingOutput.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.tasks;\n+\n+import org.apache.flink.metrics.Counter;\n+import org.apache.flink.metrics.Gauge;\n+import org.apache.flink.metrics.SimpleCounter;\n+import org.apache.flink.runtime.metrics.groups.OperatorIOMetricGroup;\n+import org.apache.flink.runtime.metrics.groups.OperatorMetricGroup;\n+import org.apache.flink.streaming.api.operators.Input;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.metrics.WatermarkGauge;\n+import org.apache.flink.streaming.runtime.streamrecord.LatencyMarker;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatusProvider;\n+import org.apache.flink.util.OutputTag;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+class MultipleInputChainingOutput<T> implements WatermarkGaugeExposingOutput<StreamRecord<T>> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1b6142f9dad4b3893629b2ec774c93adb5875e84"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODUwMjYyNQ==", "bodyText": "In an easy way, it jus duplicates two trivial collect methods (3 lines of code each). For the other methods, it's only partially duplicating them, and avoiding code duplication there would introduce even more abstract methods and more mangled code.\nI think complicating the hierarchy to avoid this duplication would do more harm than good. Especially that the ChainingOutput hasn't changed since 2017.", "url": "https://github.com/apache/flink/pull/13234#discussion_r478502625", "createdAt": "2020-08-27T15:23:32Z", "author": {"login": "pnowojski"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/MultipleInputChainingOutput.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.tasks;\n+\n+import org.apache.flink.metrics.Counter;\n+import org.apache.flink.metrics.Gauge;\n+import org.apache.flink.metrics.SimpleCounter;\n+import org.apache.flink.runtime.metrics.groups.OperatorIOMetricGroup;\n+import org.apache.flink.runtime.metrics.groups.OperatorMetricGroup;\n+import org.apache.flink.streaming.api.operators.Input;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.metrics.WatermarkGauge;\n+import org.apache.flink.streaming.runtime.streamrecord.LatencyMarker;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatusProvider;\n+import org.apache.flink.util.OutputTag;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+class MultipleInputChainingOutput<T> implements WatermarkGaugeExposingOutput<StreamRecord<T>> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzQ4NzM3Nw=="}, "originalCommit": {"oid": "1b6142f9dad4b3893629b2ec774c93adb5875e84"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTEwNzU4Mg==", "bodyText": "I ran diff on them and see the difference in only setKeyContextElement1 vs setKeyContextElement and in close.\nI think the root cause is that Input duplicates OneInputStreamOperator. And the proper solution would be to refactor SourceOperator. But that's apparently out of scope.\nInstead, we could use an adapter from operator to input and use only MultipleInputChainingOutput, like this:\n// instead of new ChainingOutput()\ncurrentOperatorOutput = new MultipleInputChainingOutput<>(Input.from(operator), ((OperatorMetricGroup) operator.getMetricGroup()), this, outputTag) {};\n// where Input.from returns some Input delegating to operator\n\n(I think the delegation overhead will be eliminated by JVM, but it can be tested).\nJust a suggestion.", "url": "https://github.com/apache/flink/pull/13234#discussion_r479107582", "createdAt": "2020-08-28T10:41:44Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/MultipleInputChainingOutput.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.tasks;\n+\n+import org.apache.flink.metrics.Counter;\n+import org.apache.flink.metrics.Gauge;\n+import org.apache.flink.metrics.SimpleCounter;\n+import org.apache.flink.runtime.metrics.groups.OperatorIOMetricGroup;\n+import org.apache.flink.runtime.metrics.groups.OperatorMetricGroup;\n+import org.apache.flink.streaming.api.operators.Input;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.metrics.WatermarkGauge;\n+import org.apache.flink.streaming.runtime.streamrecord.LatencyMarker;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatusProvider;\n+import org.apache.flink.util.OutputTag;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+class MultipleInputChainingOutput<T> implements WatermarkGaugeExposingOutput<StreamRecord<T>> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzQ4NzM3Nw=="}, "originalCommit": {"oid": "1b6142f9dad4b3893629b2ec774c93adb5875e84"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTI4MjkzMg==", "bodyText": "(I think the delegation overhead will be eliminated by JVM, but it can be tested).\n\nWould it? JVM is terrible with callsite optimisations, so I think this would add another virtual call.\nBut let me try out unifying Input with OneInputStreamOperator.", "url": "https://github.com/apache/flink/pull/13234#discussion_r481282932", "createdAt": "2020-09-01T16:37:26Z", "author": {"login": "pnowojski"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/MultipleInputChainingOutput.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.tasks;\n+\n+import org.apache.flink.metrics.Counter;\n+import org.apache.flink.metrics.Gauge;\n+import org.apache.flink.metrics.SimpleCounter;\n+import org.apache.flink.runtime.metrics.groups.OperatorIOMetricGroup;\n+import org.apache.flink.runtime.metrics.groups.OperatorMetricGroup;\n+import org.apache.flink.streaming.api.operators.Input;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.metrics.WatermarkGauge;\n+import org.apache.flink.streaming.runtime.streamrecord.LatencyMarker;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatusProvider;\n+import org.apache.flink.util.OutputTag;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+class MultipleInputChainingOutput<T> implements WatermarkGaugeExposingOutput<StreamRecord<T>> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzQ4NzM3Nw=="}, "originalCommit": {"oid": "1b6142f9dad4b3893629b2ec774c93adb5875e84"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjAxNTc5NQ==", "bodyText": "Done. Please take a look at the commits:\n\n[FLINK-18905][task/datastream] Convert OneInputStreamOperator to Input\nfixup! [FLINK-18905][task] Allow SourceOperator chaining with MultipleInputStreamTask", "url": "https://github.com/apache/flink/pull/13234#discussion_r482015795", "createdAt": "2020-09-02T12:03:49Z", "author": {"login": "pnowojski"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/MultipleInputChainingOutput.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.tasks;\n+\n+import org.apache.flink.metrics.Counter;\n+import org.apache.flink.metrics.Gauge;\n+import org.apache.flink.metrics.SimpleCounter;\n+import org.apache.flink.runtime.metrics.groups.OperatorIOMetricGroup;\n+import org.apache.flink.runtime.metrics.groups.OperatorMetricGroup;\n+import org.apache.flink.streaming.api.operators.Input;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.metrics.WatermarkGauge;\n+import org.apache.flink.streaming.runtime.streamrecord.LatencyMarker;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatusProvider;\n+import org.apache.flink.util.OutputTag;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+class MultipleInputChainingOutput<T> implements WatermarkGaugeExposingOutput<StreamRecord<T>> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzQ4NzM3Nw=="}, "originalCommit": {"oid": "1b6142f9dad4b3893629b2ec774c93adb5875e84"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjI4NjU3Ng==", "bodyText": "Great, thanks!", "url": "https://github.com/apache/flink/pull/13234#discussion_r482286576", "createdAt": "2020-09-02T18:33:11Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/MultipleInputChainingOutput.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.tasks;\n+\n+import org.apache.flink.metrics.Counter;\n+import org.apache.flink.metrics.Gauge;\n+import org.apache.flink.metrics.SimpleCounter;\n+import org.apache.flink.runtime.metrics.groups.OperatorIOMetricGroup;\n+import org.apache.flink.runtime.metrics.groups.OperatorMetricGroup;\n+import org.apache.flink.streaming.api.operators.Input;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.metrics.WatermarkGauge;\n+import org.apache.flink.streaming.runtime.streamrecord.LatencyMarker;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatusProvider;\n+import org.apache.flink.util.OutputTag;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+class MultipleInputChainingOutput<T> implements WatermarkGaugeExposingOutput<StreamRecord<T>> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzQ4NzM3Nw=="}, "originalCommit": {"oid": "1b6142f9dad4b3893629b2ec774c93adb5875e84"}, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk4NTE4NDQ5OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/MultipleInputStreamTask.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQxODowODoxOVrOHHXwxQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQwODoxNTo0NFrOHX5qWg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzQ5MTM5Nw==", "bodyText": "Isn't it the same as configuration.getNumberOfNetworkInputs below?", "url": "https://github.com/apache/flink/pull/13234#discussion_r477491397", "createdAt": "2020-08-26T18:08:19Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/MultipleInputStreamTask.java", "diffHunk": "@@ -53,42 +53,48 @@ public void init() throws Exception {\n \t\tStreamConfig configuration = getConfiguration();\n \t\tClassLoader userClassLoader = getUserCodeClassLoader();\n \n-\t\tTypeSerializer<?>[] inputDeserializers = configuration.getTypeSerializersIn(userClassLoader);\n+\t\tStreamConfig.Input[] inputs = configuration.getInputs(userClassLoader);\n \n-\t\tArrayList<IndexedInputGate>[] inputLists = new ArrayList[inputDeserializers.length];\n-\t\tWatermarkGauge[] watermarkGauges = new WatermarkGauge[inputDeserializers.length];\n+\t\tArrayList<IndexedInputGate>[] inputLists = new ArrayList[\n+\t\t\t(int) Arrays.stream(inputs)\n+\t\t\t\t.filter(input -> (input instanceof StreamConfig.NetworkInput))\n+\t\t\t\t.count()];", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1b6142f9dad4b3893629b2ec774c93adb5875e84"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODUwMzYzOA==", "bodyText": "yes, it should :)", "url": "https://github.com/apache/flink/pull/13234#discussion_r478503638", "createdAt": "2020-08-27T15:24:57Z", "author": {"login": "pnowojski"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/MultipleInputStreamTask.java", "diffHunk": "@@ -53,42 +53,48 @@ public void init() throws Exception {\n \t\tStreamConfig configuration = getConfiguration();\n \t\tClassLoader userClassLoader = getUserCodeClassLoader();\n \n-\t\tTypeSerializer<?>[] inputDeserializers = configuration.getTypeSerializersIn(userClassLoader);\n+\t\tStreamConfig.Input[] inputs = configuration.getInputs(userClassLoader);\n \n-\t\tArrayList<IndexedInputGate>[] inputLists = new ArrayList[inputDeserializers.length];\n-\t\tWatermarkGauge[] watermarkGauges = new WatermarkGauge[inputDeserializers.length];\n+\t\tArrayList<IndexedInputGate>[] inputLists = new ArrayList[\n+\t\t\t(int) Arrays.stream(inputs)\n+\t\t\t\t.filter(input -> (input instanceof StreamConfig.NetworkInput))\n+\t\t\t\t.count()];", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzQ5MTM5Nw=="}, "originalCommit": {"oid": "1b6142f9dad4b3893629b2ec774c93adb5875e84"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDgyNDAyNg==", "bodyText": "Updated answer @rkhachatryan, no it's not the same :(", "url": "https://github.com/apache/flink/pull/13234#discussion_r494824026", "createdAt": "2020-09-25T08:15:44Z", "author": {"login": "pnowojski"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/MultipleInputStreamTask.java", "diffHunk": "@@ -53,42 +53,48 @@ public void init() throws Exception {\n \t\tStreamConfig configuration = getConfiguration();\n \t\tClassLoader userClassLoader = getUserCodeClassLoader();\n \n-\t\tTypeSerializer<?>[] inputDeserializers = configuration.getTypeSerializersIn(userClassLoader);\n+\t\tStreamConfig.Input[] inputs = configuration.getInputs(userClassLoader);\n \n-\t\tArrayList<IndexedInputGate>[] inputLists = new ArrayList[inputDeserializers.length];\n-\t\tWatermarkGauge[] watermarkGauges = new WatermarkGauge[inputDeserializers.length];\n+\t\tArrayList<IndexedInputGate>[] inputLists = new ArrayList[\n+\t\t\t(int) Arrays.stream(inputs)\n+\t\t\t\t.filter(input -> (input instanceof StreamConfig.NetworkInput))\n+\t\t\t\t.count()];", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzQ5MTM5Nw=="}, "originalCommit": {"oid": "1b6142f9dad4b3893629b2ec774c93adb5875e84"}, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk4NTIxMDUxOnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/OperatorChain.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQxODoxNTo1NFrOHHYBMg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxMDo0NjozMFrOHI6vlA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzQ5NTYwMg==", "bodyText": "Something is wrong with return type or name here :)", "url": "https://github.com/apache/flink/pull/13234#discussion_r477495602", "createdAt": "2020-08-26T18:15:54Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/OperatorChain.java", "diffHunk": "@@ -208,19 +206,100 @@ public OperatorChain(\n \tOperatorChain(\n \t\t\tList<StreamOperatorWrapper<?, ?>> allOperatorWrappers,\n \t\t\tRecordWriterOutput<?>[] streamOutputs,\n-\t\t\tWatermarkGaugeExposingOutput<StreamRecord<OUT>> chainEntryPoint,\n-\t\t\tStreamOperatorWrapper<OUT, OP> headOperatorWrapper) {\n+\t\t\tWatermarkGaugeExposingOutput<StreamRecord<OUT>> mainOperatorOutput,\n+\t\t\tStreamOperatorWrapper<OUT, OP> mainOperatorWrapper) {\n \n \t\tthis.streamOutputs = checkNotNull(streamOutputs);\n-\t\tthis.chainEntryPoint = checkNotNull(chainEntryPoint);\n+\t\tthis.mainOperatorOutput = checkNotNull(mainOperatorOutput);\n \t\tthis.operatorEventDispatcher = null;\n \n \t\tcheckState(allOperatorWrappers != null && allOperatorWrappers.size() > 0);\n-\t\tthis.headOperatorWrapper = checkNotNull(headOperatorWrapper);\n+\t\tthis.mainOperatorWrapper = checkNotNull(mainOperatorWrapper);\n \t\tthis.tailOperatorWrapper = allOperatorWrappers.get(0);\n \t\tthis.numOperators = allOperatorWrappers.size();\n+\t\tthis.chainedSourceOutputs = new ChainedSourceOutputs();\n \n-\t\tlinkOperatorWrappers(allOperatorWrappers);\n+\t\tfirstOperatorWrapper = linkOperatorWrappers(allOperatorWrappers);\n+\t}\n+\n+\tprivate void createChainOutputs(\n+\t\tList<StreamEdge> outEdgesInOrder,\n+\t\tRecordWriterDelegate<SerializationDelegate<StreamRecord<OUT>>> recordWriterDelegate,\n+\t\tMap<Integer, StreamConfig> chainedConfigs,\n+\t\tStreamTask<OUT, OP> containingTask,\n+\t\tMap<StreamEdge, RecordWriterOutput<?>> streamOutputMap) {\n+\t\tfor (int i = 0; i < outEdgesInOrder.size(); i++) {\n+\t\t\tStreamEdge outEdge = outEdgesInOrder.get(i);\n+\n+\t\t\tRecordWriterOutput<?> streamOutput = createStreamOutput(\n+\t\t\t\trecordWriterDelegate.getRecordWriter(i),\n+\t\t\t\toutEdge,\n+\t\t\t\tchainedConfigs.get(outEdge.getSourceId()),\n+\t\t\t\tcontainingTask.getEnvironment());\n+\n+\t\t\tthis.streamOutputs[i] = streamOutput;\n+\t\t\tstreamOutputMap.put(outEdge, streamOutput);\n+\t\t}\n+\t}\n+\n+\tprivate ChainedSourceOutputs createChainedInputs(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1b6142f9dad4b3893629b2ec774c93adb5875e84"}, "originalPosition": 220}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODUwNTQyMQ==", "bodyText": "\ud83d\ude04\nIt makes sense. It creates chained inputs, and it's purpose is to return a collection of those chained source's outputs. But I can change the ChainedSourceOutputs name to ChainedSources", "url": "https://github.com/apache/flink/pull/13234#discussion_r478505421", "createdAt": "2020-08-27T15:27:14Z", "author": {"login": "pnowojski"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/OperatorChain.java", "diffHunk": "@@ -208,19 +206,100 @@ public OperatorChain(\n \tOperatorChain(\n \t\t\tList<StreamOperatorWrapper<?, ?>> allOperatorWrappers,\n \t\t\tRecordWriterOutput<?>[] streamOutputs,\n-\t\t\tWatermarkGaugeExposingOutput<StreamRecord<OUT>> chainEntryPoint,\n-\t\t\tStreamOperatorWrapper<OUT, OP> headOperatorWrapper) {\n+\t\t\tWatermarkGaugeExposingOutput<StreamRecord<OUT>> mainOperatorOutput,\n+\t\t\tStreamOperatorWrapper<OUT, OP> mainOperatorWrapper) {\n \n \t\tthis.streamOutputs = checkNotNull(streamOutputs);\n-\t\tthis.chainEntryPoint = checkNotNull(chainEntryPoint);\n+\t\tthis.mainOperatorOutput = checkNotNull(mainOperatorOutput);\n \t\tthis.operatorEventDispatcher = null;\n \n \t\tcheckState(allOperatorWrappers != null && allOperatorWrappers.size() > 0);\n-\t\tthis.headOperatorWrapper = checkNotNull(headOperatorWrapper);\n+\t\tthis.mainOperatorWrapper = checkNotNull(mainOperatorWrapper);\n \t\tthis.tailOperatorWrapper = allOperatorWrappers.get(0);\n \t\tthis.numOperators = allOperatorWrappers.size();\n+\t\tthis.chainedSourceOutputs = new ChainedSourceOutputs();\n \n-\t\tlinkOperatorWrappers(allOperatorWrappers);\n+\t\tfirstOperatorWrapper = linkOperatorWrappers(allOperatorWrappers);\n+\t}\n+\n+\tprivate void createChainOutputs(\n+\t\tList<StreamEdge> outEdgesInOrder,\n+\t\tRecordWriterDelegate<SerializationDelegate<StreamRecord<OUT>>> recordWriterDelegate,\n+\t\tMap<Integer, StreamConfig> chainedConfigs,\n+\t\tStreamTask<OUT, OP> containingTask,\n+\t\tMap<StreamEdge, RecordWriterOutput<?>> streamOutputMap) {\n+\t\tfor (int i = 0; i < outEdgesInOrder.size(); i++) {\n+\t\t\tStreamEdge outEdge = outEdgesInOrder.get(i);\n+\n+\t\t\tRecordWriterOutput<?> streamOutput = createStreamOutput(\n+\t\t\t\trecordWriterDelegate.getRecordWriter(i),\n+\t\t\t\toutEdge,\n+\t\t\t\tchainedConfigs.get(outEdge.getSourceId()),\n+\t\t\t\tcontainingTask.getEnvironment());\n+\n+\t\t\tthis.streamOutputs[i] = streamOutput;\n+\t\t\tstreamOutputMap.put(outEdge, streamOutput);\n+\t\t}\n+\t}\n+\n+\tprivate ChainedSourceOutputs createChainedInputs(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzQ5NTYwMg=="}, "originalCommit": {"oid": "1b6142f9dad4b3893629b2ec774c93adb5875e84"}, "originalPosition": 220}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTExMzEwOA==", "bodyText": "Given the new signature: Map<SourceInputConfig, ChainedSource> createChainedInputs,\nnit: createChainedSources?", "url": "https://github.com/apache/flink/pull/13234#discussion_r479113108", "createdAt": "2020-08-28T10:46:30Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/OperatorChain.java", "diffHunk": "@@ -208,19 +206,100 @@ public OperatorChain(\n \tOperatorChain(\n \t\t\tList<StreamOperatorWrapper<?, ?>> allOperatorWrappers,\n \t\t\tRecordWriterOutput<?>[] streamOutputs,\n-\t\t\tWatermarkGaugeExposingOutput<StreamRecord<OUT>> chainEntryPoint,\n-\t\t\tStreamOperatorWrapper<OUT, OP> headOperatorWrapper) {\n+\t\t\tWatermarkGaugeExposingOutput<StreamRecord<OUT>> mainOperatorOutput,\n+\t\t\tStreamOperatorWrapper<OUT, OP> mainOperatorWrapper) {\n \n \t\tthis.streamOutputs = checkNotNull(streamOutputs);\n-\t\tthis.chainEntryPoint = checkNotNull(chainEntryPoint);\n+\t\tthis.mainOperatorOutput = checkNotNull(mainOperatorOutput);\n \t\tthis.operatorEventDispatcher = null;\n \n \t\tcheckState(allOperatorWrappers != null && allOperatorWrappers.size() > 0);\n-\t\tthis.headOperatorWrapper = checkNotNull(headOperatorWrapper);\n+\t\tthis.mainOperatorWrapper = checkNotNull(mainOperatorWrapper);\n \t\tthis.tailOperatorWrapper = allOperatorWrappers.get(0);\n \t\tthis.numOperators = allOperatorWrappers.size();\n+\t\tthis.chainedSourceOutputs = new ChainedSourceOutputs();\n \n-\t\tlinkOperatorWrappers(allOperatorWrappers);\n+\t\tfirstOperatorWrapper = linkOperatorWrappers(allOperatorWrappers);\n+\t}\n+\n+\tprivate void createChainOutputs(\n+\t\tList<StreamEdge> outEdgesInOrder,\n+\t\tRecordWriterDelegate<SerializationDelegate<StreamRecord<OUT>>> recordWriterDelegate,\n+\t\tMap<Integer, StreamConfig> chainedConfigs,\n+\t\tStreamTask<OUT, OP> containingTask,\n+\t\tMap<StreamEdge, RecordWriterOutput<?>> streamOutputMap) {\n+\t\tfor (int i = 0; i < outEdgesInOrder.size(); i++) {\n+\t\t\tStreamEdge outEdge = outEdgesInOrder.get(i);\n+\n+\t\t\tRecordWriterOutput<?> streamOutput = createStreamOutput(\n+\t\t\t\trecordWriterDelegate.getRecordWriter(i),\n+\t\t\t\toutEdge,\n+\t\t\t\tchainedConfigs.get(outEdge.getSourceId()),\n+\t\t\t\tcontainingTask.getEnvironment());\n+\n+\t\t\tthis.streamOutputs[i] = streamOutput;\n+\t\t\tstreamOutputMap.put(outEdge, streamOutput);\n+\t\t}\n+\t}\n+\n+\tprivate ChainedSourceOutputs createChainedInputs(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzQ5NTYwMg=="}, "originalCommit": {"oid": "1b6142f9dad4b3893629b2ec774c93adb5875e84"}, "originalPosition": 220}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk4NTIyNzAxOnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/OperatorChain.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQxODoyMDo0MFrOHHYLQg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxMDo0ODoyNFrOHI632A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzQ5ODE3OA==", "bodyText": "Isn't this method called for any operator?\nThe if check above will not return from function if there are NetworkInputs configured.", "url": "https://github.com/apache/flink/pull/13234#discussion_r477498178", "createdAt": "2020-08-26T18:20:40Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/OperatorChain.java", "diffHunk": "@@ -208,19 +206,100 @@ public OperatorChain(\n \tOperatorChain(\n \t\t\tList<StreamOperatorWrapper<?, ?>> allOperatorWrappers,\n \t\t\tRecordWriterOutput<?>[] streamOutputs,\n-\t\t\tWatermarkGaugeExposingOutput<StreamRecord<OUT>> chainEntryPoint,\n-\t\t\tStreamOperatorWrapper<OUT, OP> headOperatorWrapper) {\n+\t\t\tWatermarkGaugeExposingOutput<StreamRecord<OUT>> mainOperatorOutput,\n+\t\t\tStreamOperatorWrapper<OUT, OP> mainOperatorWrapper) {\n \n \t\tthis.streamOutputs = checkNotNull(streamOutputs);\n-\t\tthis.chainEntryPoint = checkNotNull(chainEntryPoint);\n+\t\tthis.mainOperatorOutput = checkNotNull(mainOperatorOutput);\n \t\tthis.operatorEventDispatcher = null;\n \n \t\tcheckState(allOperatorWrappers != null && allOperatorWrappers.size() > 0);\n-\t\tthis.headOperatorWrapper = checkNotNull(headOperatorWrapper);\n+\t\tthis.mainOperatorWrapper = checkNotNull(mainOperatorWrapper);\n \t\tthis.tailOperatorWrapper = allOperatorWrappers.get(0);\n \t\tthis.numOperators = allOperatorWrappers.size();\n+\t\tthis.chainedSourceOutputs = new ChainedSourceOutputs();\n \n-\t\tlinkOperatorWrappers(allOperatorWrappers);\n+\t\tfirstOperatorWrapper = linkOperatorWrappers(allOperatorWrappers);\n+\t}\n+\n+\tprivate void createChainOutputs(\n+\t\tList<StreamEdge> outEdgesInOrder,\n+\t\tRecordWriterDelegate<SerializationDelegate<StreamRecord<OUT>>> recordWriterDelegate,\n+\t\tMap<Integer, StreamConfig> chainedConfigs,\n+\t\tStreamTask<OUT, OP> containingTask,\n+\t\tMap<StreamEdge, RecordWriterOutput<?>> streamOutputMap) {\n+\t\tfor (int i = 0; i < outEdgesInOrder.size(); i++) {\n+\t\t\tStreamEdge outEdge = outEdgesInOrder.get(i);\n+\n+\t\t\tRecordWriterOutput<?> streamOutput = createStreamOutput(\n+\t\t\t\trecordWriterDelegate.getRecordWriter(i),\n+\t\t\t\toutEdge,\n+\t\t\t\tchainedConfigs.get(outEdge.getSourceId()),\n+\t\t\t\tcontainingTask.getEnvironment());\n+\n+\t\t\tthis.streamOutputs[i] = streamOutput;\n+\t\t\tstreamOutputMap.put(outEdge, streamOutput);\n+\t\t}\n+\t}\n+\n+\tprivate ChainedSourceOutputs createChainedInputs(\n+\t\t\tStreamTask<OUT, OP> containingTask,\n+\t\t\tStreamConfig.Input[] configuredInputs,\n+\t\t\tMap<Integer, StreamConfig> chainedConfigs,\n+\t\t\tClassLoader userCodeClassloader,\n+\t\t\tList<StreamOperatorWrapper<?, ?>> allOpWrappers) {\n+\t\tif (Arrays.stream(configuredInputs).noneMatch(input -> input instanceof SourceInput)) {\n+\t\t\treturn new ChainedSourceOutputs();\n+\t\t}\n+\t\tcheckState(\n+\t\t\tmainOperatorWrapper.getStreamOperator() instanceof MultipleInputStreamOperator,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1b6142f9dad4b3893629b2ec774c93adb5875e84"}, "originalPosition": 230}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODUwOTA3OA==", "bodyText": "It is, but it would be an unsupported configuration. If there are chained sources, it's currently only supported with MultipleInputStreamOperator - not with for example TwoInputStreamOperator.", "url": "https://github.com/apache/flink/pull/13234#discussion_r478509078", "createdAt": "2020-08-27T15:32:13Z", "author": {"login": "pnowojski"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/OperatorChain.java", "diffHunk": "@@ -208,19 +206,100 @@ public OperatorChain(\n \tOperatorChain(\n \t\t\tList<StreamOperatorWrapper<?, ?>> allOperatorWrappers,\n \t\t\tRecordWriterOutput<?>[] streamOutputs,\n-\t\t\tWatermarkGaugeExposingOutput<StreamRecord<OUT>> chainEntryPoint,\n-\t\t\tStreamOperatorWrapper<OUT, OP> headOperatorWrapper) {\n+\t\t\tWatermarkGaugeExposingOutput<StreamRecord<OUT>> mainOperatorOutput,\n+\t\t\tStreamOperatorWrapper<OUT, OP> mainOperatorWrapper) {\n \n \t\tthis.streamOutputs = checkNotNull(streamOutputs);\n-\t\tthis.chainEntryPoint = checkNotNull(chainEntryPoint);\n+\t\tthis.mainOperatorOutput = checkNotNull(mainOperatorOutput);\n \t\tthis.operatorEventDispatcher = null;\n \n \t\tcheckState(allOperatorWrappers != null && allOperatorWrappers.size() > 0);\n-\t\tthis.headOperatorWrapper = checkNotNull(headOperatorWrapper);\n+\t\tthis.mainOperatorWrapper = checkNotNull(mainOperatorWrapper);\n \t\tthis.tailOperatorWrapper = allOperatorWrappers.get(0);\n \t\tthis.numOperators = allOperatorWrappers.size();\n+\t\tthis.chainedSourceOutputs = new ChainedSourceOutputs();\n \n-\t\tlinkOperatorWrappers(allOperatorWrappers);\n+\t\tfirstOperatorWrapper = linkOperatorWrappers(allOperatorWrappers);\n+\t}\n+\n+\tprivate void createChainOutputs(\n+\t\tList<StreamEdge> outEdgesInOrder,\n+\t\tRecordWriterDelegate<SerializationDelegate<StreamRecord<OUT>>> recordWriterDelegate,\n+\t\tMap<Integer, StreamConfig> chainedConfigs,\n+\t\tStreamTask<OUT, OP> containingTask,\n+\t\tMap<StreamEdge, RecordWriterOutput<?>> streamOutputMap) {\n+\t\tfor (int i = 0; i < outEdgesInOrder.size(); i++) {\n+\t\t\tStreamEdge outEdge = outEdgesInOrder.get(i);\n+\n+\t\t\tRecordWriterOutput<?> streamOutput = createStreamOutput(\n+\t\t\t\trecordWriterDelegate.getRecordWriter(i),\n+\t\t\t\toutEdge,\n+\t\t\t\tchainedConfigs.get(outEdge.getSourceId()),\n+\t\t\t\tcontainingTask.getEnvironment());\n+\n+\t\t\tthis.streamOutputs[i] = streamOutput;\n+\t\t\tstreamOutputMap.put(outEdge, streamOutput);\n+\t\t}\n+\t}\n+\n+\tprivate ChainedSourceOutputs createChainedInputs(\n+\t\t\tStreamTask<OUT, OP> containingTask,\n+\t\t\tStreamConfig.Input[] configuredInputs,\n+\t\t\tMap<Integer, StreamConfig> chainedConfigs,\n+\t\t\tClassLoader userCodeClassloader,\n+\t\t\tList<StreamOperatorWrapper<?, ?>> allOpWrappers) {\n+\t\tif (Arrays.stream(configuredInputs).noneMatch(input -> input instanceof SourceInput)) {\n+\t\t\treturn new ChainedSourceOutputs();\n+\t\t}\n+\t\tcheckState(\n+\t\t\tmainOperatorWrapper.getStreamOperator() instanceof MultipleInputStreamOperator,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzQ5ODE3OA=="}, "originalCommit": {"oid": "1b6142f9dad4b3893629b2ec774c93adb5875e84"}, "originalPosition": 230}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTExNTIyNA==", "bodyText": "Makes sense.", "url": "https://github.com/apache/flink/pull/13234#discussion_r479115224", "createdAt": "2020-08-28T10:48:24Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/OperatorChain.java", "diffHunk": "@@ -208,19 +206,100 @@ public OperatorChain(\n \tOperatorChain(\n \t\t\tList<StreamOperatorWrapper<?, ?>> allOperatorWrappers,\n \t\t\tRecordWriterOutput<?>[] streamOutputs,\n-\t\t\tWatermarkGaugeExposingOutput<StreamRecord<OUT>> chainEntryPoint,\n-\t\t\tStreamOperatorWrapper<OUT, OP> headOperatorWrapper) {\n+\t\t\tWatermarkGaugeExposingOutput<StreamRecord<OUT>> mainOperatorOutput,\n+\t\t\tStreamOperatorWrapper<OUT, OP> mainOperatorWrapper) {\n \n \t\tthis.streamOutputs = checkNotNull(streamOutputs);\n-\t\tthis.chainEntryPoint = checkNotNull(chainEntryPoint);\n+\t\tthis.mainOperatorOutput = checkNotNull(mainOperatorOutput);\n \t\tthis.operatorEventDispatcher = null;\n \n \t\tcheckState(allOperatorWrappers != null && allOperatorWrappers.size() > 0);\n-\t\tthis.headOperatorWrapper = checkNotNull(headOperatorWrapper);\n+\t\tthis.mainOperatorWrapper = checkNotNull(mainOperatorWrapper);\n \t\tthis.tailOperatorWrapper = allOperatorWrappers.get(0);\n \t\tthis.numOperators = allOperatorWrappers.size();\n+\t\tthis.chainedSourceOutputs = new ChainedSourceOutputs();\n \n-\t\tlinkOperatorWrappers(allOperatorWrappers);\n+\t\tfirstOperatorWrapper = linkOperatorWrappers(allOperatorWrappers);\n+\t}\n+\n+\tprivate void createChainOutputs(\n+\t\tList<StreamEdge> outEdgesInOrder,\n+\t\tRecordWriterDelegate<SerializationDelegate<StreamRecord<OUT>>> recordWriterDelegate,\n+\t\tMap<Integer, StreamConfig> chainedConfigs,\n+\t\tStreamTask<OUT, OP> containingTask,\n+\t\tMap<StreamEdge, RecordWriterOutput<?>> streamOutputMap) {\n+\t\tfor (int i = 0; i < outEdgesInOrder.size(); i++) {\n+\t\t\tStreamEdge outEdge = outEdgesInOrder.get(i);\n+\n+\t\t\tRecordWriterOutput<?> streamOutput = createStreamOutput(\n+\t\t\t\trecordWriterDelegate.getRecordWriter(i),\n+\t\t\t\toutEdge,\n+\t\t\t\tchainedConfigs.get(outEdge.getSourceId()),\n+\t\t\t\tcontainingTask.getEnvironment());\n+\n+\t\t\tthis.streamOutputs[i] = streamOutput;\n+\t\t\tstreamOutputMap.put(outEdge, streamOutput);\n+\t\t}\n+\t}\n+\n+\tprivate ChainedSourceOutputs createChainedInputs(\n+\t\t\tStreamTask<OUT, OP> containingTask,\n+\t\t\tStreamConfig.Input[] configuredInputs,\n+\t\t\tMap<Integer, StreamConfig> chainedConfigs,\n+\t\t\tClassLoader userCodeClassloader,\n+\t\t\tList<StreamOperatorWrapper<?, ?>> allOpWrappers) {\n+\t\tif (Arrays.stream(configuredInputs).noneMatch(input -> input instanceof SourceInput)) {\n+\t\t\treturn new ChainedSourceOutputs();\n+\t\t}\n+\t\tcheckState(\n+\t\t\tmainOperatorWrapper.getStreamOperator() instanceof MultipleInputStreamOperator,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzQ5ODE3OA=="}, "originalCommit": {"oid": "1b6142f9dad4b3893629b2ec774c93adb5875e84"}, "originalPosition": 230}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk4NTI1ODY0OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/OperatorChain.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQxODoyOTo1NVrOHHYfDA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxNTozODoxOFrOHIWKFQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzUwMzI0NA==", "bodyText": "I think having a single map on OperatorChain level with values holding a pair of Output + Operator would be easier to read and more efficient (by pair I mean a class, named maybe ChainedSourceOutputs).", "url": "https://github.com/apache/flink/pull/13234#discussion_r477503244", "createdAt": "2020-08-26T18:29:55Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/OperatorChain.java", "diffHunk": "@@ -547,302 +675,38 @@ private void linkOperatorWrappers(List<StreamOperatorWrapper<?, ?>> allOperatorW\n \t\treturn (tailOperatorWrapper == null) ? null : tailOperatorWrapper.getStreamOperator();\n \t}\n \n-\t// ------------------------------------------------------------------------\n-\t//  Collectors for output chaining\n-\t// ------------------------------------------------------------------------\n-\n \t/**\n-\t * An {@link Output} that measures the last emitted watermark with a {@link WatermarkGauge}.\n-\t *\n-\t * @param <T> The type of the elements that can be emitted.\n+\t * Wrapper class to access the chained sources and their's outputs.\n \t */\n-\tpublic interface WatermarkGaugeExposingOutput<T> extends Output<T> {\n-\t\tGauge<Long> getWatermarkGauge();\n-\t}\n-\n-\tstatic class ChainingOutput<T> implements WatermarkGaugeExposingOutput<StreamRecord<T>> {\n-\n-\t\tprotected final OneInputStreamOperator<T, ?> operator;\n-\t\tprotected final Counter numRecordsIn;\n-\t\tprotected final WatermarkGauge watermarkGauge = new WatermarkGauge();\n-\n-\t\tprotected final StreamStatusProvider streamStatusProvider;\n-\n-\t\t@Nullable\n-\t\tprotected final OutputTag<T> outputTag;\n-\n-\t\tpublic ChainingOutput(\n-\t\t\t\tOneInputStreamOperator<T, ?> operator,\n-\t\t\t\tStreamStatusProvider streamStatusProvider,\n-\t\t\t\t@Nullable OutputTag<T> outputTag) {\n-\t\t\tthis.operator = operator;\n-\n-\t\t\t{\n-\t\t\t\tCounter tmpNumRecordsIn;\n-\t\t\t\ttry {\n-\t\t\t\t\tOperatorIOMetricGroup ioMetricGroup = ((OperatorMetricGroup) operator.getMetricGroup()).getIOMetricGroup();\n-\t\t\t\t\ttmpNumRecordsIn = ioMetricGroup.getNumRecordsInCounter();\n-\t\t\t\t} catch (Exception e) {\n-\t\t\t\t\tLOG.warn(\"An exception occurred during the metrics setup.\", e);\n-\t\t\t\t\ttmpNumRecordsIn = new SimpleCounter();\n-\t\t\t\t}\n-\t\t\t\tnumRecordsIn = tmpNumRecordsIn;\n-\t\t\t}\n+\tpublic static class ChainedSourceOutputs {\n+\t\tprivate final Map<Integer, WatermarkGaugeExposingOutput<StreamRecord<?>>> chainedSourceOutputs;\n+\t\tprivate final Map<Integer, SourceOperator<?, ?>> sourceOperators;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1b6142f9dad4b3893629b2ec774c93adb5875e84"}, "originalPosition": 524}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzUxNzM3MQ==", "bodyText": "Map key is the index of input in StreamConfig, right? This seems a bit fragile and not obvious.\nHow about keying by Input instances? I see we have them both on put and get.", "url": "https://github.com/apache/flink/pull/13234#discussion_r477517371", "createdAt": "2020-08-26T18:55:30Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/OperatorChain.java", "diffHunk": "@@ -547,302 +675,38 @@ private void linkOperatorWrappers(List<StreamOperatorWrapper<?, ?>> allOperatorW\n \t\treturn (tailOperatorWrapper == null) ? null : tailOperatorWrapper.getStreamOperator();\n \t}\n \n-\t// ------------------------------------------------------------------------\n-\t//  Collectors for output chaining\n-\t// ------------------------------------------------------------------------\n-\n \t/**\n-\t * An {@link Output} that measures the last emitted watermark with a {@link WatermarkGauge}.\n-\t *\n-\t * @param <T> The type of the elements that can be emitted.\n+\t * Wrapper class to access the chained sources and their's outputs.\n \t */\n-\tpublic interface WatermarkGaugeExposingOutput<T> extends Output<T> {\n-\t\tGauge<Long> getWatermarkGauge();\n-\t}\n-\n-\tstatic class ChainingOutput<T> implements WatermarkGaugeExposingOutput<StreamRecord<T>> {\n-\n-\t\tprotected final OneInputStreamOperator<T, ?> operator;\n-\t\tprotected final Counter numRecordsIn;\n-\t\tprotected final WatermarkGauge watermarkGauge = new WatermarkGauge();\n-\n-\t\tprotected final StreamStatusProvider streamStatusProvider;\n-\n-\t\t@Nullable\n-\t\tprotected final OutputTag<T> outputTag;\n-\n-\t\tpublic ChainingOutput(\n-\t\t\t\tOneInputStreamOperator<T, ?> operator,\n-\t\t\t\tStreamStatusProvider streamStatusProvider,\n-\t\t\t\t@Nullable OutputTag<T> outputTag) {\n-\t\t\tthis.operator = operator;\n-\n-\t\t\t{\n-\t\t\t\tCounter tmpNumRecordsIn;\n-\t\t\t\ttry {\n-\t\t\t\t\tOperatorIOMetricGroup ioMetricGroup = ((OperatorMetricGroup) operator.getMetricGroup()).getIOMetricGroup();\n-\t\t\t\t\ttmpNumRecordsIn = ioMetricGroup.getNumRecordsInCounter();\n-\t\t\t\t} catch (Exception e) {\n-\t\t\t\t\tLOG.warn(\"An exception occurred during the metrics setup.\", e);\n-\t\t\t\t\ttmpNumRecordsIn = new SimpleCounter();\n-\t\t\t\t}\n-\t\t\t\tnumRecordsIn = tmpNumRecordsIn;\n-\t\t\t}\n+\tpublic static class ChainedSourceOutputs {\n+\t\tprivate final Map<Integer, WatermarkGaugeExposingOutput<StreamRecord<?>>> chainedSourceOutputs;\n+\t\tprivate final Map<Integer, SourceOperator<?, ?>> sourceOperators;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzUwMzI0NA=="}, "originalCommit": {"oid": "1b6142f9dad4b3893629b2ec774c93adb5875e84"}, "originalPosition": 524}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODUxMzY4NQ==", "bodyText": "Good idea with Input - I also didn't like the integer. About moving Map to an upper level, I don't mind one way or another, so let it be as you prefer.", "url": "https://github.com/apache/flink/pull/13234#discussion_r478513685", "createdAt": "2020-08-27T15:38:18Z", "author": {"login": "pnowojski"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/OperatorChain.java", "diffHunk": "@@ -547,302 +675,38 @@ private void linkOperatorWrappers(List<StreamOperatorWrapper<?, ?>> allOperatorW\n \t\treturn (tailOperatorWrapper == null) ? null : tailOperatorWrapper.getStreamOperator();\n \t}\n \n-\t// ------------------------------------------------------------------------\n-\t//  Collectors for output chaining\n-\t// ------------------------------------------------------------------------\n-\n \t/**\n-\t * An {@link Output} that measures the last emitted watermark with a {@link WatermarkGauge}.\n-\t *\n-\t * @param <T> The type of the elements that can be emitted.\n+\t * Wrapper class to access the chained sources and their's outputs.\n \t */\n-\tpublic interface WatermarkGaugeExposingOutput<T> extends Output<T> {\n-\t\tGauge<Long> getWatermarkGauge();\n-\t}\n-\n-\tstatic class ChainingOutput<T> implements WatermarkGaugeExposingOutput<StreamRecord<T>> {\n-\n-\t\tprotected final OneInputStreamOperator<T, ?> operator;\n-\t\tprotected final Counter numRecordsIn;\n-\t\tprotected final WatermarkGauge watermarkGauge = new WatermarkGauge();\n-\n-\t\tprotected final StreamStatusProvider streamStatusProvider;\n-\n-\t\t@Nullable\n-\t\tprotected final OutputTag<T> outputTag;\n-\n-\t\tpublic ChainingOutput(\n-\t\t\t\tOneInputStreamOperator<T, ?> operator,\n-\t\t\t\tStreamStatusProvider streamStatusProvider,\n-\t\t\t\t@Nullable OutputTag<T> outputTag) {\n-\t\t\tthis.operator = operator;\n-\n-\t\t\t{\n-\t\t\t\tCounter tmpNumRecordsIn;\n-\t\t\t\ttry {\n-\t\t\t\t\tOperatorIOMetricGroup ioMetricGroup = ((OperatorMetricGroup) operator.getMetricGroup()).getIOMetricGroup();\n-\t\t\t\t\ttmpNumRecordsIn = ioMetricGroup.getNumRecordsInCounter();\n-\t\t\t\t} catch (Exception e) {\n-\t\t\t\t\tLOG.warn(\"An exception occurred during the metrics setup.\", e);\n-\t\t\t\t\ttmpNumRecordsIn = new SimpleCounter();\n-\t\t\t\t}\n-\t\t\t\tnumRecordsIn = tmpNumRecordsIn;\n-\t\t\t}\n+\tpublic static class ChainedSourceOutputs {\n+\t\tprivate final Map<Integer, WatermarkGaugeExposingOutput<StreamRecord<?>>> chainedSourceOutputs;\n+\t\tprivate final Map<Integer, SourceOperator<?, ?>> sourceOperators;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzUwMzI0NA=="}, "originalCommit": {"oid": "1b6142f9dad4b3893629b2ec774c93adb5875e84"}, "originalPosition": 524}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk4NTMwMjAzOnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/OperatorChain.java", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQxODo0Mjo0M1rOHHY6Jg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQxODoyODowN1rOHL8J2A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzUxMDE4Mg==", "bodyText": "Why do we need first? Isn't it the same as main?", "url": "https://github.com/apache/flink/pull/13234#discussion_r477510182", "createdAt": "2020-08-26T18:42:43Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/OperatorChain.java", "diffHunk": "@@ -90,16 +91,19 @@\n \n \tprivate final RecordWriterOutput<?>[] streamOutputs;\n \n-\tprivate final WatermarkGaugeExposingOutput<StreamRecord<OUT>> chainEntryPoint;\n+\tprivate final WatermarkGaugeExposingOutput<StreamRecord<OUT>> mainOperatorOutput;\n \n \t/**\n \t * For iteration, {@link StreamIterationHead} and {@link StreamIterationTail} used for executing\n-\t * feedback edges do not contain any operators, in which case, {@code headOperatorWrapper} and\n+\t * feedback edges do not contain any operators, in which case, {@code mainOperatorWrapper} and\n \t * {@code tailOperatorWrapper} are null.\n \t */\n-\t@Nullable private final StreamOperatorWrapper<OUT, OP> headOperatorWrapper;\n+\t@Nullable private final StreamOperatorWrapper<OUT, OP> mainOperatorWrapper;\n+\t@Nullable private final StreamOperatorWrapper<?, ?> firstOperatorWrapper;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1b6142f9dad4b3893629b2ec774c93adb5875e84"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODUxMDI1Ng==", "bodyText": "Nope. Main operator is as explained in the java doc above. First operator can be either it, or some chained source operator (if present) - added a java doc with this explanation.", "url": "https://github.com/apache/flink/pull/13234#discussion_r478510256", "createdAt": "2020-08-27T15:33:40Z", "author": {"login": "pnowojski"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/OperatorChain.java", "diffHunk": "@@ -90,16 +91,19 @@\n \n \tprivate final RecordWriterOutput<?>[] streamOutputs;\n \n-\tprivate final WatermarkGaugeExposingOutput<StreamRecord<OUT>> chainEntryPoint;\n+\tprivate final WatermarkGaugeExposingOutput<StreamRecord<OUT>> mainOperatorOutput;\n \n \t/**\n \t * For iteration, {@link StreamIterationHead} and {@link StreamIterationTail} used for executing\n-\t * feedback edges do not contain any operators, in which case, {@code headOperatorWrapper} and\n+\t * feedback edges do not contain any operators, in which case, {@code mainOperatorWrapper} and\n \t * {@code tailOperatorWrapper} are null.\n \t */\n-\t@Nullable private final StreamOperatorWrapper<OUT, OP> headOperatorWrapper;\n+\t@Nullable private final StreamOperatorWrapper<OUT, OP> mainOperatorWrapper;\n+\t@Nullable private final StreamOperatorWrapper<?, ?> firstOperatorWrapper;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzUxMDE4Mg=="}, "originalCommit": {"oid": "1b6142f9dad4b3893629b2ec774c93adb5875e84"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTEzNjQyMQ==", "bodyText": "I'm confused :)\nIs it something like this:\nfirst\n      \\ main (multi-input) -> ... -> tail\n      /\nsecond\n\n?\nIf yes, how would wrappers be linked? Will firstOperatorWrapper.close also close the second operator?\nnit: would be nice to have that kind of diagram in code too.", "url": "https://github.com/apache/flink/pull/13234#discussion_r479136421", "createdAt": "2020-08-28T11:06:42Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/OperatorChain.java", "diffHunk": "@@ -90,16 +91,19 @@\n \n \tprivate final RecordWriterOutput<?>[] streamOutputs;\n \n-\tprivate final WatermarkGaugeExposingOutput<StreamRecord<OUT>> chainEntryPoint;\n+\tprivate final WatermarkGaugeExposingOutput<StreamRecord<OUT>> mainOperatorOutput;\n \n \t/**\n \t * For iteration, {@link StreamIterationHead} and {@link StreamIterationTail} used for executing\n-\t * feedback edges do not contain any operators, in which case, {@code headOperatorWrapper} and\n+\t * feedback edges do not contain any operators, in which case, {@code mainOperatorWrapper} and\n \t * {@code tailOperatorWrapper} are null.\n \t */\n-\t@Nullable private final StreamOperatorWrapper<OUT, OP> headOperatorWrapper;\n+\t@Nullable private final StreamOperatorWrapper<OUT, OP> mainOperatorWrapper;\n+\t@Nullable private final StreamOperatorWrapper<?, ?> firstOperatorWrapper;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzUxMDE4Mg=="}, "originalCommit": {"oid": "1b6142f9dad4b3893629b2ec774c93adb5875e84"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjAxNjU5OA==", "bodyText": "Yes, yes, & added more java doc :)", "url": "https://github.com/apache/flink/pull/13234#discussion_r482016598", "createdAt": "2020-09-02T12:05:30Z", "author": {"login": "pnowojski"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/OperatorChain.java", "diffHunk": "@@ -90,16 +91,19 @@\n \n \tprivate final RecordWriterOutput<?>[] streamOutputs;\n \n-\tprivate final WatermarkGaugeExposingOutput<StreamRecord<OUT>> chainEntryPoint;\n+\tprivate final WatermarkGaugeExposingOutput<StreamRecord<OUT>> mainOperatorOutput;\n \n \t/**\n \t * For iteration, {@link StreamIterationHead} and {@link StreamIterationTail} used for executing\n-\t * feedback edges do not contain any operators, in which case, {@code headOperatorWrapper} and\n+\t * feedback edges do not contain any operators, in which case, {@code mainOperatorWrapper} and\n \t * {@code tailOperatorWrapper} are null.\n \t */\n-\t@Nullable private final StreamOperatorWrapper<OUT, OP> headOperatorWrapper;\n+\t@Nullable private final StreamOperatorWrapper<OUT, OP> mainOperatorWrapper;\n+\t@Nullable private final StreamOperatorWrapper<?, ?> firstOperatorWrapper;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzUxMDE4Mg=="}, "originalCommit": {"oid": "1b6142f9dad4b3893629b2ec774c93adb5875e84"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjI4MTk0NA==", "bodyText": "Thanks!", "url": "https://github.com/apache/flink/pull/13234#discussion_r482281944", "createdAt": "2020-09-02T18:28:07Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/OperatorChain.java", "diffHunk": "@@ -90,16 +91,19 @@\n \n \tprivate final RecordWriterOutput<?>[] streamOutputs;\n \n-\tprivate final WatermarkGaugeExposingOutput<StreamRecord<OUT>> chainEntryPoint;\n+\tprivate final WatermarkGaugeExposingOutput<StreamRecord<OUT>> mainOperatorOutput;\n \n \t/**\n \t * For iteration, {@link StreamIterationHead} and {@link StreamIterationTail} used for executing\n-\t * feedback edges do not contain any operators, in which case, {@code headOperatorWrapper} and\n+\t * feedback edges do not contain any operators, in which case, {@code mainOperatorWrapper} and\n \t * {@code tailOperatorWrapper} are null.\n \t */\n-\t@Nullable private final StreamOperatorWrapper<OUT, OP> headOperatorWrapper;\n+\t@Nullable private final StreamOperatorWrapper<OUT, OP> mainOperatorWrapper;\n+\t@Nullable private final StreamOperatorWrapper<?, ?> firstOperatorWrapper;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzUxMDE4Mg=="}, "originalCommit": {"oid": "1b6142f9dad4b3893629b2ec774c93adb5875e84"}, "originalPosition": 93}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5NTIyMDA4OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/graph/StreamConfig.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxMDo1Mjo1N1rOHI7MBQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxMDo1Mjo1N1rOHI7MBQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTEyMDM4OQ==", "bodyText": "Are we comparing InputEdge vs SourceInputConfig here?", "url": "https://github.com/apache/flink/pull/13234#discussion_r479120389", "createdAt": "2020-08-28T10:52:57Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/graph/StreamConfig.java", "diffHunk": "@@ -628,4 +621,61 @@ public String toString() {\n \n \t\treturn builder.toString();\n \t}\n+\n+\t/**\n+\t * Interface representing chained inputs.\n+\t */\n+\tpublic interface InputConfig extends Serializable {\n+\t}\n+\n+\t/**\n+\t * A representation of a Network {@link InputConfig}.\n+\t */\n+\tpublic static class NetworkInputConfig implements InputConfig {\n+\t\tprivate final TypeSerializer<?> typeSerializer;\n+\t\tprivate int inputGateIndex;\n+\n+\t\tpublic NetworkInputConfig(TypeSerializer<?> typeSerializer, int inputGateIndex) {\n+\t\t\tthis.typeSerializer = typeSerializer;\n+\t\t\tthis.inputGateIndex = inputGateIndex;\n+\t\t}\n+\n+\t\tpublic TypeSerializer<?> getTypeSerializer() {\n+\t\t\treturn typeSerializer;\n+\t\t}\n+\n+\t\tpublic int getInputGateIndex() {\n+\t\t\treturn inputGateIndex;\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * A serialized representation of an input.\n+\t */\n+\tpublic static class SourceInputConfig implements InputConfig {\n+\t\tprivate final StreamEdge inputEdge;\n+\n+\t\tpublic SourceInputConfig(StreamEdge inputEdge) {\n+\t\t\tthis.inputEdge = inputEdge;\n+\t\t}\n+\n+\t\tpublic StreamEdge getInputEdge() {\n+\t\t\treturn inputEdge;\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic String toString() {\n+\t\t\treturn inputEdge.toString();\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic boolean equals(Object obj) {\n+\t\t\treturn Objects.equals(obj, inputEdge);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2382ecb7dcb679dddbc39f44717ed1c4c7c061cf"}, "originalPosition": 260}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5NTQwMTI3OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/OperatorChain.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxMToxOTozMlrOHI9Dgw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxMToxOTozMlrOHI9Dgw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTE1MDk3OQ==", "bodyText": "This method as well as createChainedInputs is full of compiler warnings too - can you fix them please?", "url": "https://github.com/apache/flink/pull/13234#discussion_r479150979", "createdAt": "2020-08-28T11:19:32Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/OperatorChain.java", "diffHunk": "@@ -208,19 +212,97 @@ public OperatorChain(\n \tOperatorChain(\n \t\t\tList<StreamOperatorWrapper<?, ?>> allOperatorWrappers,\n \t\t\tRecordWriterOutput<?>[] streamOutputs,\n-\t\t\tWatermarkGaugeExposingOutput<StreamRecord<OUT>> chainEntryPoint,\n-\t\t\tStreamOperatorWrapper<OUT, OP> headOperatorWrapper) {\n+\t\t\tWatermarkGaugeExposingOutput<StreamRecord<OUT>> mainOperatorOutput,\n+\t\t\tStreamOperatorWrapper<OUT, OP> mainOperatorWrapper) {\n \n \t\tthis.streamOutputs = checkNotNull(streamOutputs);\n-\t\tthis.chainEntryPoint = checkNotNull(chainEntryPoint);\n+\t\tthis.mainOperatorOutput = checkNotNull(mainOperatorOutput);\n \t\tthis.operatorEventDispatcher = null;\n \n \t\tcheckState(allOperatorWrappers != null && allOperatorWrappers.size() > 0);\n-\t\tthis.headOperatorWrapper = checkNotNull(headOperatorWrapper);\n+\t\tthis.mainOperatorWrapper = checkNotNull(mainOperatorWrapper);\n \t\tthis.tailOperatorWrapper = allOperatorWrappers.get(0);\n \t\tthis.numOperators = allOperatorWrappers.size();\n+\t\tthis.chainedSources = Collections.emptyMap();\n+\n+\t\tfirstOperatorWrapper = linkOperatorWrappers(allOperatorWrappers);\n+\t}\n+\n+\tprivate void createChainOutputs(\n+\t\t\tList<StreamEdge> outEdgesInOrder,\n+\t\t\tRecordWriterDelegate<SerializationDelegate<StreamRecord<OUT>>> recordWriterDelegate,\n+\t\t\tMap<Integer, StreamConfig> chainedConfigs,\n+\t\t\tStreamTask<OUT, OP> containingTask,\n+\t\t\tMap<StreamEdge, RecordWriterOutput<?>> streamOutputMap) {\n+\t\tfor (int i = 0; i < outEdgesInOrder.size(); i++) {\n+\t\t\tStreamEdge outEdge = outEdgesInOrder.get(i);\n+\n+\t\t\tRecordWriterOutput<?> streamOutput = createStreamOutput(\n+\t\t\t\trecordWriterDelegate.getRecordWriter(i),\n+\t\t\t\toutEdge,\n+\t\t\t\tchainedConfigs.get(outEdge.getSourceId()),\n+\t\t\t\tcontainingTask.getEnvironment());\n+\n+\t\t\tthis.streamOutputs[i] = streamOutput;\n+\t\t\tstreamOutputMap.put(outEdge, streamOutput);\n+\t\t}\n+\t}\n+\n+\tprivate Map<SourceInputConfig, ChainedSource> createChainedInputs(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2382ecb7dcb679dddbc39f44717ed1c4c7c061cf"}, "originalPosition": 225}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 520, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}