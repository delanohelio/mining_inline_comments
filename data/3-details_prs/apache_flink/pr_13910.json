{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTE0ODk5MDkz", "number": 13910, "title": "[FLINK-19276][json][connector-kafka] Support reading Debezium metadata", "bodyText": "What is the purpose of the change\nThis exposes metadata for the Debezium JSON format according to FLIP-107.\nNote: A complete end-to-end test for Kafka + Debezium is missing yet.\nBrief change log\n\nUpdate the Kafka connector to expose format specific metadata.\nReconfigure the internal JsonRowDataDeserializationSchema to read additional fields.\nLet DebeziumJsonDeserializationSchema access and convert those additional fields to metadata columns.\n\nVerifying this change\nThis change added tests and can be verified as follows: DebeziumJsonSerDeSchemaTest, KafkaDynamicTableFactoryTest\nDoes this pull request potentially affect one of the following parts:\n\nDependencies (does it add or upgrade a dependency): no\nThe public API, i.e., is any changed class annotated with @Public(Evolving): yes\nThe serializers: no\nThe runtime per-record code paths (performance sensitive): no\nAnything that affects deployment or recovery: JobManager (and its components), Checkpointing, Kubernetes/Yarn/Mesos, ZooKeeper: no\nThe S3 file system connector: no\n\nDocumentation\n\nDoes this pull request introduce a new feature? yes\nIf yes, how is the feature documented? JavaDocs", "createdAt": "2020-11-03T17:49:21Z", "url": "https://github.com/apache/flink/pull/13910", "merged": true, "mergeCommit": {"oid": "64b96651579d76c718d67ebf2caca526d402a70e"}, "closed": true, "closedAt": "2020-11-07T09:39:10Z", "author": {"login": "twalthr"}, "timelineItems": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdZhBt0gFqTUyNDA5MTgyMQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdaIEvUgBqjM5Njk3NDMwNjc=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI0MDkxODIx", "url": "https://github.com/apache/flink/pull/13910#pullrequestreview-524091821", "createdAt": "2020-11-05T09:51:49Z", "commit": {"oid": "44e62800be6f0c1ed5b117997212d69f1f7aae85"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQwOTo1MTo1MFrOHt7chA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQxMTo1MzozOVrOHt_30Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzkyMTkyNA==", "bodyText": "Add VIRTUAL to the metadata (even it is not tested)?", "url": "https://github.com/apache/flink/pull/13910#discussion_r517921924", "createdAt": "2020-11-05T09:51:50Z", "author": {"login": "wuchong"}, "path": "flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/table/KafkaChangelogTableITCase.java", "diffHunk": "@@ -109,6 +109,7 @@ public void testKafkaDebeziumChangelogSource() throws Exception {\n \t\tString bootstraps = standardProps.getProperty(\"bootstrap.servers\");\n \t\tString sourceDDL = String.format(\n \t\t\t\"CREATE TABLE debezium_source (\" +\n+\t\t\t\" origin STRING METADATA FROM 'value.source.table',\" + // test some metadata", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "44e62800be6f0c1ed5b117997212d69f1f7aae85"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzk5MTI0MA==", "bodyText": "Add a comment to mention why we must put the format metadata before connector metadata? I think the order can't be switched.", "url": "https://github.com/apache/flink/pull/13910#discussion_r517991240", "createdAt": "2020-11-05T11:47:36Z", "author": {"login": "wuchong"}, "path": "flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/streaming/connectors/kafka/table/KafkaDynamicSource.java", "diffHunk": "@@ -179,13 +183,37 @@ public ScanRuntimeProvider getScanRuntimeProvider(ScanContext context) {\n \t@Override\n \tpublic Map<String, DataType> listReadableMetadata() {\n \t\tfinal Map<String, DataType> metadataMap = new LinkedHashMap<>();\n+\n+\t\t// add value format metadata with prefix", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "44e62800be6f0c1ed5b117997212d69f1f7aae85"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzk5NDQ0OQ==", "bodyText": "Could you make this case more complex? For example, declaring 2 format metadata and 2 connector metadata, but only select 1 format metadata and 1 connector metadata. This helps to verify format and connector metadata can work together and the metadata pruning also works.", "url": "https://github.com/apache/flink/pull/13910#discussion_r517994449", "createdAt": "2020-11-05T11:53:39Z", "author": {"login": "wuchong"}, "path": "flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/table/KafkaChangelogTableITCase.java", "diffHunk": "@@ -131,7 +133,8 @@ public void testKafkaDebeziumChangelogSource() throws Exception {\n \t\ttEnv.executeSql(sourceDDL);\n \t\ttEnv.executeSql(sinkDDL);\n \t\tTableResult tableResult = tEnv.executeSql(\n-\t\t\t\"INSERT INTO sink SELECT name, SUM(weight) FROM debezium_source GROUP BY name\");\n+\t\t\t\"INSERT INTO sink SELECT FIRST_VALUE(origin), name, SUM(weight) \"\n+\t\t\t\t+ \"FROM debezium_source GROUP BY name\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "44e62800be6f0c1ed5b117997212d69f1f7aae85"}, "originalPosition": 26}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "44e62800be6f0c1ed5b117997212d69f1f7aae85", "author": {"user": {"login": "twalthr", "name": "Timo Walther"}}, "url": "https://github.com/apache/flink/commit/44e62800be6f0c1ed5b117997212d69f1f7aae85", "committedDate": "2020-11-04T08:26:56Z", "message": "Extend KafkaChangelogITCase"}, "afterCommit": {"oid": "90a7f3c54a6cb48a381037ed50ba051d130f06bb", "author": {"user": {"login": "twalthr", "name": "Timo Walther"}}, "url": "https://github.com/apache/flink/commit/90a7f3c54a6cb48a381037ed50ba051d130f06bb", "committedDate": "2020-11-06T14:33:45Z", "message": "Feedback addressed"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI1MjUyMjA2", "url": "https://github.com/apache/flink/pull/13910#pullrequestreview-525252206", "createdAt": "2020-11-06T15:22:44Z", "commit": {"oid": "90a7f3c54a6cb48a381037ed50ba051d130f06bb"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fe9313e8a53267a252c3f47b300790accc814ed9", "author": {"user": {"login": "twalthr", "name": "Timo Walther"}}, "url": "https://github.com/apache/flink/commit/fe9313e8a53267a252c3f47b300790accc814ed9", "committedDate": "2020-11-07T09:19:32Z", "message": "[hotfix][table-common] Improve terminology for data types in formats"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d978a05d6c34fdf80711e4946235105d17137d5e", "author": {"user": {"login": "twalthr", "name": "Timo Walther"}}, "url": "https://github.com/apache/flink/commit/d978a05d6c34fdf80711e4946235105d17137d5e", "committedDate": "2020-11-07T09:19:32Z", "message": "[hotfix][table-common] Add hashCode/equals to DataTypes.Field"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "64b96651579d76c718d67ebf2caca526d402a70e", "author": {"user": {"login": "twalthr", "name": "Timo Walther"}}, "url": "https://github.com/apache/flink/commit/64b96651579d76c718d67ebf2caca526d402a70e", "committedDate": "2020-11-07T09:22:09Z", "message": "[FLINK-19276][json][connector-kafka] Support reading Debezium metadata\n\nThis exposes metadata for the Debezium JSON format according to FLIP-107.\n\n- Update the Kafka connector to expose format specific metadata.\n- Reconfigure the internal JsonRowDataDeserializationSchema to read additional fields.\n- Let DebeziumJsonDeserializationSchema access and convert those additional fields to metadata columns.\n\nThis closes #13910."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "90a7f3c54a6cb48a381037ed50ba051d130f06bb", "author": {"user": {"login": "twalthr", "name": "Timo Walther"}}, "url": "https://github.com/apache/flink/commit/90a7f3c54a6cb48a381037ed50ba051d130f06bb", "committedDate": "2020-11-06T14:33:45Z", "message": "Feedback addressed"}, "afterCommit": {"oid": "64b96651579d76c718d67ebf2caca526d402a70e", "author": {"user": {"login": "twalthr", "name": "Timo Walther"}}, "url": "https://github.com/apache/flink/commit/64b96651579d76c718d67ebf2caca526d402a70e", "committedDate": "2020-11-07T09:22:09Z", "message": "[FLINK-19276][json][connector-kafka] Support reading Debezium metadata\n\nThis exposes metadata for the Debezium JSON format according to FLIP-107.\n\n- Update the Kafka connector to expose format specific metadata.\n- Reconfigure the internal JsonRowDataDeserializationSchema to read additional fields.\n- Let DebeziumJsonDeserializationSchema access and convert those additional fields to metadata columns.\n\nThis closes #13910."}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4733, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}