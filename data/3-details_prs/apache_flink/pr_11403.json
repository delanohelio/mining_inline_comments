{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg3NzUxMzg4", "number": 11403, "title": "[FLINK-16316][operators] Implement new StreamOperatorBase as a replacement for AbstractStreamOperator", "bodyText": "Implement new StreamOperatorBase as a replacement for AbstractStreamOperator\nThe new base class for operators tries to address couple of limitations in the AbstractStreamOperator like:\n- lack of support for multiple inputs\n- setup(...) method\nI'm not happy about couple of things, like StreamOperatorStateHandler being a component inside the StreamOperatorBase, instead of a wrapper around. However it seems like it's important for AbstractStreamOperator to expose to people extending from it, the content of the StreamOperatorStateHandler.\nAnother issue with StreamOperatorStateHandler is that it's also handling timers, but they are kind of coupled with state... maybe there is a better name for that class?\nBrief change log\nPlease check individual commit messages.\nVerifying this change\nThis change is cover by existing tests and adds couple of new ones where necessary.\nDoes this pull request potentially affect one of the following parts:\n\nDependencies (does it add or upgrade a dependency): (yes / no)\nThe public API, i.e., is any changed class annotated with @Public(Evolving): (yes / no)\nThe serializers: (yes / no / don't know)\nThe runtime per-record code paths (performance sensitive): (yes / no / don't know)\nAnything that affects deployment or recovery: JobManager (and its components), Checkpointing, Kubernetes/Yarn/Mesos, ZooKeeper: (yes / no / don't know)\nThe S3 file system connector: (yes / no / don't know)\n\nDocumentation\n\nDoes this pull request introduce a new feature? (yes / no)\nIf yes, how is the feature documented? (not applicable / docs / JavaDocs / not documented)", "createdAt": "2020-03-13T12:28:20Z", "url": "https://github.com/apache/flink/pull/11403", "merged": true, "mergeCommit": {"oid": "73d410354d367e91ec6f68af87115cee0d86a0ac"}, "closed": true, "closedAt": "2020-03-25T14:06:36Z", "author": {"login": "pnowojski"}, "timelineItems": {"totalCount": 33, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcNPnyeAFqTM3NDI2NTU5OQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcRGosAAFqTM4MTA5ODg4Mw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc0MjY1NTk5", "url": "https://github.com/apache/flink/pull/11403#pullrequestreview-374265599", "createdAt": "2020-03-13T12:37:41Z", "commit": {"oid": "c7595ee5eb7ac60dae52bcd1368878d70d372533"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xM1QxMjozNzo0MlrOF2CFHg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xM1QxMjozODo1N1rOF2CHMA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjIwMTUwMg==", "bodyText": "@AHeise what do you think about including processingTimeService in StreamOperatorInitializer always, regardless of the ProcessingTimeServiceAware? Generally speaking what do you think about StreamOperatorInitializer?", "url": "https://github.com/apache/flink/pull/11403#discussion_r392201502", "createdAt": "2020-03-13T12:37:42Z", "author": {"login": "pnowojski"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorFactoryUtil.java", "diffHunk": "@@ -57,7 +57,13 @@\n \t\t\t((ProcessingTimeServiceAware) operatorFactory).setProcessingTimeService(processingTimeService);\n \t\t}\n \n-\t\tOP op = operatorFactory.createStreamOperator(containingTask, configuration, output);\n+\t\t// TODO: what to do with ProcessingTimeServiceAware?\n+\t\tOP op = operatorFactory.createStreamOperator(\n+\t\t\tnew StreamOperatorInitializer<>(\n+\t\t\t\tcontainingTask,\n+\t\t\t\tconfiguration,\n+\t\t\t\toutput,\n+\t\t\t\tprocessingTimeService));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c7595ee5eb7ac60dae52bcd1368878d70d372533"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjIwMjAzMg==", "bodyText": "alternative name could be AbstractStreamOperatorV2?", "url": "https://github.com/apache/flink/pull/11403#discussion_r392202032", "createdAt": "2020-03-13T12:38:57Z", "author": {"login": "pnowojski"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorBase.java", "diffHunk": "@@ -0,0 +1,484 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.Experimental;\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.KeyedStateStore;\n+import org.apache.flink.api.common.state.State;\n+import org.apache.flink.api.common.state.StateDescriptor;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.java.functions.KeySelector;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.configuration.MetricOptions;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.metrics.MetricGroup;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.execution.Environment;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.metrics.groups.OperatorMetricGroup;\n+import org.apache.flink.runtime.metrics.groups.TaskManagerJobMetricGroup;\n+import org.apache.flink.runtime.metrics.groups.UnregisteredMetricGroups;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.KeyedStateBackend;\n+import org.apache.flink.runtime.state.OperatorStateBackend;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.runtime.state.VoidNamespace;\n+import org.apache.flink.runtime.state.VoidNamespaceSerializer;\n+import org.apache.flink.streaming.api.graph.StreamConfig;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.streamrecord.LatencyMarker;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.tasks.ProcessingTimeService;\n+import org.apache.flink.streaming.runtime.tasks.StreamTask;\n+import org.apache.flink.streaming.util.LatencyStats;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Arrays;\n+import java.util.Locale;\n+import java.util.Optional;\n+\n+/**\n+ * New base class for all stream operators, replacing previous {@link AbstractStreamOperator}.\n+ * Currently intended to work with {@link MultipleInputStreamOperator}.\n+ *\n+ * <p>One note-able difference in comparison to {@link AbstractStreamOperator} is lack of\n+ * {@link AbstractStreamOperator#setup(StreamTask, StreamConfig, Output)} in favor of initialisation\n+ * in the constructor, and removed some tight coupling with classes like {@link StreamTask}.\n+ *\n+ * <p>Methods are guaranteed not to be called concurrently.\n+ *\n+ * @param <OUT> The output type of the operator\n+ */\n+@Experimental\n+public abstract class StreamOperatorBase<OUT> implements StreamOperator<OUT> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c7595ee5eb7ac60dae52bcd1368878d70d372533"}, "originalPosition": 75}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c7595ee5eb7ac60dae52bcd1368878d70d372533", "author": {"user": {"login": "pnowojski", "name": "Piotr Nowojski"}}, "url": "https://github.com/apache/flink/commit/c7595ee5eb7ac60dae52bcd1368878d70d372533", "committedDate": "2020-03-13T12:25:26Z", "message": "[FLINK-16316][operators] Make StreamOperatorFactory PublicEvolving"}, "afterCommit": {"oid": "c1facefebee52a1ac84f188f46b114deae0aad89", "author": {"user": {"login": "pnowojski", "name": "Piotr Nowojski"}}, "url": "https://github.com/apache/flink/commit/c1facefebee52a1ac84f188f46b114deae0aad89", "committedDate": "2020-03-13T15:07:10Z", "message": "[FLINK-16316][operators] Make StreamOperatorFactory PublicEvolving"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc1MDU0Mzc1", "url": "https://github.com/apache/flink/pull/11403#pullrequestreview-375054375", "createdAt": "2020-03-16T09:54:43Z", "commit": {"oid": "a5f59ce50eca4dbadba277d85f731c7bb52cb66f"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 15, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQwOTo1NDo0M1rOF2sihg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQxMDo1MjowMFrOF2uwZg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjg5NzE1OA==", "bodyText": "nit: indent", "url": "https://github.com/apache/flink/pull/11403#discussion_r392897158", "createdAt": "2020-03-16T09:54:43Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/CheckpointingOperation.java", "diffHunk": "@@ -133,4 +136,26 @@ static void execute(\n \t\t}\n \t}\n \n+\tprivate static void checkpointStreamOperator(\n+\t\tStreamOperator<?> op,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a5f59ce50eca4dbadba277d85f731c7bb52cb66f"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjg5NzUzNg==", "bodyText": "Map or better return the OperatorSnapshotFutures and put it on caller side into map.", "url": "https://github.com/apache/flink/pull/11403#discussion_r392897536", "createdAt": "2020-03-16T09:55:20Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/CheckpointingOperation.java", "diffHunk": "@@ -133,4 +136,26 @@ static void execute(\n \t\t}\n \t}\n \n+\tprivate static void checkpointStreamOperator(\n+\t\tStreamOperator<?> op,\n+\t\tCheckpointMetaData checkpointMetaData,\n+\t\tCheckpointOptions checkpointOptions,\n+\t\tCheckpointStreamFactory storageLocation,\n+\t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a5f59ce50eca4dbadba277d85f731c7bb52cb66f"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjg5ODgxMA==", "bodyText": "\ud83d\udc4d for commit. message could reflect that it's actually moved into SetupableOperator.", "url": "https://github.com/apache/flink/pull/11403#discussion_r392898810", "createdAt": "2020-03-16T09:57:32Z", "author": {"login": "AHeise"}, "path": "flink-libraries/flink-state-processing-api/src/test/java/org/apache/flink/state/api/output/SnapshotUtilsTest.java", "diffHunk": "@@ -26,7 +26,6 @@\n import org.apache.flink.runtime.state.CheckpointStorageWorkerView;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27cc48bb76227f7e53048ac1cd3dc148cefad738"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkwMzYxMA==", "bodyText": "Please check if that needs to be closed at the end of the test.", "url": "https://github.com/apache/flink/pull/11403#discussion_r392903610", "createdAt": "2020-03-16T10:06:31Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/test/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandlerTest.java", "diffHunk": "@@ -0,0 +1,207 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.ListStateDescriptor;\n+import org.apache.flink.api.common.state.ValueStateDescriptor;\n+import org.apache.flink.api.common.typeutils.base.IntSerializer;\n+import org.apache.flink.api.common.typeutils.base.LongSerializer;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.metrics.util.InterceptingOperatorMetricGroup;\n+import org.apache.flink.runtime.operators.testutils.ExpectedTestException;\n+import org.apache.flink.runtime.operators.testutils.MockEnvironmentBuilder;\n+import org.apache.flink.runtime.state.KeyGroupRange;\n+import org.apache.flink.runtime.state.KeyedStateHandle;\n+import org.apache.flink.runtime.state.OperatorStateHandle;\n+import org.apache.flink.runtime.state.SnapshotResult;\n+import org.apache.flink.runtime.state.StateSnapshotContextSynchronousImpl;\n+import org.apache.flink.runtime.state.memory.MemCheckpointStreamFactory;\n+import org.apache.flink.runtime.state.memory.MemoryStateBackend;\n+import org.apache.flink.streaming.runtime.tasks.TestProcessingTimeService;\n+import org.apache.flink.util.ExceptionUtils;\n+\n+import org.junit.Test;\n+\n+import java.util.concurrent.RunnableFuture;\n+import java.util.concurrent.TimeUnit;\n+\n+import static junit.framework.TestCase.assertTrue;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.CoreMatchers.not;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.empty;\n+import static org.junit.Assert.fail;\n+\n+/**\n+ * Tests for {@link StreamOperatorStateHandlerTest}.\n+ */\n+public class StreamOperatorStateHandlerTest {\n+\t/**\n+\t * Tests that a failing snapshot method call to the keyed state backend will trigger the closing\n+\t * of the StateSnapshotContextSynchronousImpl and the cancellation of the\n+\t * OperatorSnapshotResult. The latter is supposed to also cancel all assigned futures.\n+\t */\n+\t@Test\n+\tpublic void testFailingBackendSnapshotMethod() throws Exception {\n+\t\tfinal long checkpointId = 42L;\n+\t\tfinal long timestamp = 1L;\n+\n+\t\tfinal CloseableRegistry closeableRegistry = new CloseableRegistry();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9cce09936e14e63d8bef95bff57d0e2f2401e1f0"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkwNTU3OQ==", "bodyText": "It's quite confusing that the supplied key is never really used or tested. Also could you make key and value of a different type?", "url": "https://github.com/apache/flink/pull/11403#discussion_r392905579", "createdAt": "2020-03-16T10:10:15Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/test/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandlerTest.java", "diffHunk": "@@ -0,0 +1,207 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.ListStateDescriptor;\n+import org.apache.flink.api.common.state.ValueStateDescriptor;\n+import org.apache.flink.api.common.typeutils.base.IntSerializer;\n+import org.apache.flink.api.common.typeutils.base.LongSerializer;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.metrics.util.InterceptingOperatorMetricGroup;\n+import org.apache.flink.runtime.operators.testutils.ExpectedTestException;\n+import org.apache.flink.runtime.operators.testutils.MockEnvironmentBuilder;\n+import org.apache.flink.runtime.state.KeyGroupRange;\n+import org.apache.flink.runtime.state.KeyedStateHandle;\n+import org.apache.flink.runtime.state.OperatorStateHandle;\n+import org.apache.flink.runtime.state.SnapshotResult;\n+import org.apache.flink.runtime.state.StateSnapshotContextSynchronousImpl;\n+import org.apache.flink.runtime.state.memory.MemCheckpointStreamFactory;\n+import org.apache.flink.runtime.state.memory.MemoryStateBackend;\n+import org.apache.flink.streaming.runtime.tasks.TestProcessingTimeService;\n+import org.apache.flink.util.ExceptionUtils;\n+\n+import org.junit.Test;\n+\n+import java.util.concurrent.RunnableFuture;\n+import java.util.concurrent.TimeUnit;\n+\n+import static junit.framework.TestCase.assertTrue;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.CoreMatchers.not;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.empty;\n+import static org.junit.Assert.fail;\n+\n+/**\n+ * Tests for {@link StreamOperatorStateHandlerTest}.\n+ */\n+public class StreamOperatorStateHandlerTest {\n+\t/**\n+\t * Tests that a failing snapshot method call to the keyed state backend will trigger the closing\n+\t * of the StateSnapshotContextSynchronousImpl and the cancellation of the\n+\t * OperatorSnapshotResult. The latter is supposed to also cancel all assigned futures.\n+\t */\n+\t@Test\n+\tpublic void testFailingBackendSnapshotMethod() throws Exception {\n+\t\tfinal long checkpointId = 42L;\n+\t\tfinal long timestamp = 1L;\n+\n+\t\tfinal CloseableRegistry closeableRegistry = new CloseableRegistry();\n+\n+\t\tRunnableFuture<SnapshotResult<KeyedStateHandle>> keyedStateManagedFuture = new CancelableFuture<>();\n+\t\tRunnableFuture<SnapshotResult<KeyedStateHandle>> keyedStateRawFuture = new CancelableFuture<>();\n+\t\tRunnableFuture<SnapshotResult<OperatorStateHandle>> operatorStateManagedFuture = new CancelableFuture<>();\n+\t\tRunnableFuture<SnapshotResult<OperatorStateHandle>> operatorStateRawFuture = new CancelableFuture<>();\n+\n+\t\tOperatorSnapshotFutures operatorSnapshotResult = new OperatorSnapshotFutures(\n+\t\t\tkeyedStateManagedFuture,\n+\t\t\tkeyedStateRawFuture,\n+\t\t\toperatorStateManagedFuture,\n+\t\t\toperatorStateRawFuture);\n+\n+\t\tStateSnapshotContextSynchronousImpl context = new TestStateSnapshotContextSynchronousImpl(checkpointId, timestamp, closeableRegistry);\n+\t\tcontext.getRawKeyedOperatorStateOutput();\n+\t\tcontext.getRawOperatorStateOutput();\n+\n+\t\tStreamTaskStateInitializerImpl stateInitializer =\n+\t\t\tnew StreamTaskStateInitializerImpl(new MockEnvironmentBuilder().build(), new MemoryStateBackend());\n+\t\tStreamOperatorStateContext stateContext = stateInitializer.streamOperatorStateContext(\n+\t\t\tnew OperatorID(),\n+\t\t\t\"whatever\",\n+\t\t\tnew TestProcessingTimeService(),\n+\t\t\tnew UnUsedKeyContext(),\n+\t\t\tIntSerializer.INSTANCE,\n+\t\t\tcloseableRegistry,\n+\t\t\tnew InterceptingOperatorMetricGroup());\n+\t\tStreamOperatorStateHandler stateHandler = new StreamOperatorStateHandler(stateContext, new ExecutionConfig(), closeableRegistry);\n+\n+\t\tfinal String keyedStateField = \"keyedStateField\";\n+\t\tfinal String operatorStateField = \"operatorStateField\";\n+\n+\t\tstateHandler.setCurrentKey(44L);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9cce09936e14e63d8bef95bff57d0e2f2401e1f0"}, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkwNjA4MA==", "bodyText": "Looks like two test cases to me: in this test, I'd actually would like to see a successful snapshot. And then have second with failure.", "url": "https://github.com/apache/flink/pull/11403#discussion_r392906080", "createdAt": "2020-03-16T10:11:12Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/test/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandlerTest.java", "diffHunk": "@@ -0,0 +1,207 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.ListStateDescriptor;\n+import org.apache.flink.api.common.state.ValueStateDescriptor;\n+import org.apache.flink.api.common.typeutils.base.IntSerializer;\n+import org.apache.flink.api.common.typeutils.base.LongSerializer;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.metrics.util.InterceptingOperatorMetricGroup;\n+import org.apache.flink.runtime.operators.testutils.ExpectedTestException;\n+import org.apache.flink.runtime.operators.testutils.MockEnvironmentBuilder;\n+import org.apache.flink.runtime.state.KeyGroupRange;\n+import org.apache.flink.runtime.state.KeyedStateHandle;\n+import org.apache.flink.runtime.state.OperatorStateHandle;\n+import org.apache.flink.runtime.state.SnapshotResult;\n+import org.apache.flink.runtime.state.StateSnapshotContextSynchronousImpl;\n+import org.apache.flink.runtime.state.memory.MemCheckpointStreamFactory;\n+import org.apache.flink.runtime.state.memory.MemoryStateBackend;\n+import org.apache.flink.streaming.runtime.tasks.TestProcessingTimeService;\n+import org.apache.flink.util.ExceptionUtils;\n+\n+import org.junit.Test;\n+\n+import java.util.concurrent.RunnableFuture;\n+import java.util.concurrent.TimeUnit;\n+\n+import static junit.framework.TestCase.assertTrue;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.CoreMatchers.not;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.empty;\n+import static org.junit.Assert.fail;\n+\n+/**\n+ * Tests for {@link StreamOperatorStateHandlerTest}.\n+ */\n+public class StreamOperatorStateHandlerTest {\n+\t/**\n+\t * Tests that a failing snapshot method call to the keyed state backend will trigger the closing\n+\t * of the StateSnapshotContextSynchronousImpl and the cancellation of the\n+\t * OperatorSnapshotResult. The latter is supposed to also cancel all assigned futures.\n+\t */\n+\t@Test\n+\tpublic void testFailingBackendSnapshotMethod() throws Exception {\n+\t\tfinal long checkpointId = 42L;\n+\t\tfinal long timestamp = 1L;\n+\n+\t\tfinal CloseableRegistry closeableRegistry = new CloseableRegistry();\n+\n+\t\tRunnableFuture<SnapshotResult<KeyedStateHandle>> keyedStateManagedFuture = new CancelableFuture<>();\n+\t\tRunnableFuture<SnapshotResult<KeyedStateHandle>> keyedStateRawFuture = new CancelableFuture<>();\n+\t\tRunnableFuture<SnapshotResult<OperatorStateHandle>> operatorStateManagedFuture = new CancelableFuture<>();\n+\t\tRunnableFuture<SnapshotResult<OperatorStateHandle>> operatorStateRawFuture = new CancelableFuture<>();\n+\n+\t\tOperatorSnapshotFutures operatorSnapshotResult = new OperatorSnapshotFutures(\n+\t\t\tkeyedStateManagedFuture,\n+\t\t\tkeyedStateRawFuture,\n+\t\t\toperatorStateManagedFuture,\n+\t\t\toperatorStateRawFuture);\n+\n+\t\tStateSnapshotContextSynchronousImpl context = new TestStateSnapshotContextSynchronousImpl(checkpointId, timestamp, closeableRegistry);\n+\t\tcontext.getRawKeyedOperatorStateOutput();\n+\t\tcontext.getRawOperatorStateOutput();\n+\n+\t\tStreamTaskStateInitializerImpl stateInitializer =\n+\t\t\tnew StreamTaskStateInitializerImpl(new MockEnvironmentBuilder().build(), new MemoryStateBackend());\n+\t\tStreamOperatorStateContext stateContext = stateInitializer.streamOperatorStateContext(\n+\t\t\tnew OperatorID(),\n+\t\t\t\"whatever\",\n+\t\t\tnew TestProcessingTimeService(),\n+\t\t\tnew UnUsedKeyContext(),\n+\t\t\tIntSerializer.INSTANCE,\n+\t\t\tcloseableRegistry,\n+\t\t\tnew InterceptingOperatorMetricGroup());\n+\t\tStreamOperatorStateHandler stateHandler = new StreamOperatorStateHandler(stateContext, new ExecutionConfig(), closeableRegistry);\n+\n+\t\tfinal String keyedStateField = \"keyedStateField\";\n+\t\tfinal String operatorStateField = \"operatorStateField\";\n+\n+\t\tstateHandler.setCurrentKey(44L);\n+\t\tstateHandler.initializeOperatorState(stateSnapshotContext -> {\n+\t\t\tstateSnapshotContext.getKeyedStateStore()\n+\t\t\t\t.getState(new ValueStateDescriptor<>(keyedStateField, LongSerializer.INSTANCE))\n+\t\t\t\t.update(42L);\n+\t\t\tstateSnapshotContext.getOperatorStateStore()\n+\t\t\t\t.getListState(new ListStateDescriptor<>(operatorStateField, LongSerializer.INSTANCE))\n+\t\t\t\t.add(42L);\n+\t\t});\n+\n+\t\tassertThat(stateContext.operatorStateBackend().getRegisteredStateNames(), is(not(empty())));\n+\t\tassertThat(stateContext.keyedStateBackend().numKeyValueStatesByName(), equalTo(1));\n+\n+\t\ttry {\n+\t\t\tstateHandler.snapshotState(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9cce09936e14e63d8bef95bff57d0e2f2401e1f0"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkwNzU5NA==", "bodyText": "Could we use FutureTask instead of implementing it ourselves?", "url": "https://github.com/apache/flink/pull/11403#discussion_r392907594", "createdAt": "2020-03-16T10:13:55Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/test/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandlerTest.java", "diffHunk": "@@ -0,0 +1,207 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.ListStateDescriptor;\n+import org.apache.flink.api.common.state.ValueStateDescriptor;\n+import org.apache.flink.api.common.typeutils.base.IntSerializer;\n+import org.apache.flink.api.common.typeutils.base.LongSerializer;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.metrics.util.InterceptingOperatorMetricGroup;\n+import org.apache.flink.runtime.operators.testutils.ExpectedTestException;\n+import org.apache.flink.runtime.operators.testutils.MockEnvironmentBuilder;\n+import org.apache.flink.runtime.state.KeyGroupRange;\n+import org.apache.flink.runtime.state.KeyedStateHandle;\n+import org.apache.flink.runtime.state.OperatorStateHandle;\n+import org.apache.flink.runtime.state.SnapshotResult;\n+import org.apache.flink.runtime.state.StateSnapshotContextSynchronousImpl;\n+import org.apache.flink.runtime.state.memory.MemCheckpointStreamFactory;\n+import org.apache.flink.runtime.state.memory.MemoryStateBackend;\n+import org.apache.flink.streaming.runtime.tasks.TestProcessingTimeService;\n+import org.apache.flink.util.ExceptionUtils;\n+\n+import org.junit.Test;\n+\n+import java.util.concurrent.RunnableFuture;\n+import java.util.concurrent.TimeUnit;\n+\n+import static junit.framework.TestCase.assertTrue;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.CoreMatchers.not;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.empty;\n+import static org.junit.Assert.fail;\n+\n+/**\n+ * Tests for {@link StreamOperatorStateHandlerTest}.\n+ */\n+public class StreamOperatorStateHandlerTest {\n+\t/**\n+\t * Tests that a failing snapshot method call to the keyed state backend will trigger the closing\n+\t * of the StateSnapshotContextSynchronousImpl and the cancellation of the\n+\t * OperatorSnapshotResult. The latter is supposed to also cancel all assigned futures.\n+\t */\n+\t@Test\n+\tpublic void testFailingBackendSnapshotMethod() throws Exception {\n+\t\tfinal long checkpointId = 42L;\n+\t\tfinal long timestamp = 1L;\n+\n+\t\tfinal CloseableRegistry closeableRegistry = new CloseableRegistry();\n+\n+\t\tRunnableFuture<SnapshotResult<KeyedStateHandle>> keyedStateManagedFuture = new CancelableFuture<>();\n+\t\tRunnableFuture<SnapshotResult<KeyedStateHandle>> keyedStateRawFuture = new CancelableFuture<>();\n+\t\tRunnableFuture<SnapshotResult<OperatorStateHandle>> operatorStateManagedFuture = new CancelableFuture<>();\n+\t\tRunnableFuture<SnapshotResult<OperatorStateHandle>> operatorStateRawFuture = new CancelableFuture<>();\n+\n+\t\tOperatorSnapshotFutures operatorSnapshotResult = new OperatorSnapshotFutures(\n+\t\t\tkeyedStateManagedFuture,\n+\t\t\tkeyedStateRawFuture,\n+\t\t\toperatorStateManagedFuture,\n+\t\t\toperatorStateRawFuture);\n+\n+\t\tStateSnapshotContextSynchronousImpl context = new TestStateSnapshotContextSynchronousImpl(checkpointId, timestamp, closeableRegistry);\n+\t\tcontext.getRawKeyedOperatorStateOutput();\n+\t\tcontext.getRawOperatorStateOutput();\n+\n+\t\tStreamTaskStateInitializerImpl stateInitializer =\n+\t\t\tnew StreamTaskStateInitializerImpl(new MockEnvironmentBuilder().build(), new MemoryStateBackend());\n+\t\tStreamOperatorStateContext stateContext = stateInitializer.streamOperatorStateContext(\n+\t\t\tnew OperatorID(),\n+\t\t\t\"whatever\",\n+\t\t\tnew TestProcessingTimeService(),\n+\t\t\tnew UnUsedKeyContext(),\n+\t\t\tIntSerializer.INSTANCE,\n+\t\t\tcloseableRegistry,\n+\t\t\tnew InterceptingOperatorMetricGroup());\n+\t\tStreamOperatorStateHandler stateHandler = new StreamOperatorStateHandler(stateContext, new ExecutionConfig(), closeableRegistry);\n+\n+\t\tfinal String keyedStateField = \"keyedStateField\";\n+\t\tfinal String operatorStateField = \"operatorStateField\";\n+\n+\t\tstateHandler.setCurrentKey(44L);\n+\t\tstateHandler.initializeOperatorState(stateSnapshotContext -> {\n+\t\t\tstateSnapshotContext.getKeyedStateStore()\n+\t\t\t\t.getState(new ValueStateDescriptor<>(keyedStateField, LongSerializer.INSTANCE))\n+\t\t\t\t.update(42L);\n+\t\t\tstateSnapshotContext.getOperatorStateStore()\n+\t\t\t\t.getListState(new ListStateDescriptor<>(operatorStateField, LongSerializer.INSTANCE))\n+\t\t\t\t.add(42L);\n+\t\t});\n+\n+\t\tassertThat(stateContext.operatorStateBackend().getRegisteredStateNames(), is(not(empty())));\n+\t\tassertThat(stateContext.keyedStateBackend().numKeyValueStatesByName(), equalTo(1));\n+\n+\t\ttry {\n+\t\t\tstateHandler.snapshotState(\n+\t\t\t\tstateSnapshotContext -> {\n+\t\t\t\t\tthrow new ExpectedTestException();\n+\t\t\t\t},\n+\t\t\t\t\"42\",\n+\t\t\t\t42,\n+\t\t\t\t42,\n+\t\t\t\tCheckpointOptions.forCheckpointWithDefaultLocation(),\n+\t\t\t\tnew MemCheckpointStreamFactory(1024),\n+\t\t\t\toperatorSnapshotResult,\n+\t\t\t\tcontext);\n+\t\t\tfail(\"Exception expected.\");\n+\t\t} catch (CheckpointException e) {\n+\t\t\t// We can not check for ExpectedTestException class directly,\n+\t\t\t// as CheckpointException is wrapping the cause with SerializedThrowable\n+\t\t\tif (!ExceptionUtils.findThrowableWithMessage(e, ExpectedTestException.MESSAGE).isPresent()) {\n+\t\t\t\tthrow e;\n+\t\t\t}\n+\t\t}\n+\n+\t\tassertTrue(keyedStateManagedFuture.isCancelled());\n+\t\tassertTrue(keyedStateRawFuture.isCancelled());\n+\t\tassertTrue(context.getKeyedStateStreamFuture().isCancelled());\n+\t\tassertTrue(operatorStateManagedFuture.isCancelled());\n+\t\tassertTrue(operatorStateRawFuture.isCancelled());\n+\t\tassertTrue(context.getOperatorStateStreamFuture().isCancelled());\n+\n+\t\tstateHandler.dispose();\n+\n+\t\tassertThat(stateContext.operatorStateBackend().getRegisteredBroadcastStateNames(), is(empty()));\n+\t\tassertThat(stateContext.operatorStateBackend().getRegisteredStateNames(), is(empty()));\n+\t\tassertThat(stateContext.keyedStateBackend().numKeyValueStatesByName(), is(0));\n+\t}\n+\n+\tprivate static class TestStateSnapshotContextSynchronousImpl extends StateSnapshotContextSynchronousImpl {\n+\t\tpublic TestStateSnapshotContextSynchronousImpl(\n+\t\t\t\tlong checkpointId,\n+\t\t\t\tlong timestamp,\n+\t\t\t\tCloseableRegistry closeableRegistry) {\n+\t\t\tsuper(checkpointId, timestamp, new MemCheckpointStreamFactory(1024), new KeyGroupRange(0, 2), closeableRegistry);\n+\t\t\tthis.keyedStateCheckpointClosingFuture = new CancelableFuture<>();\n+\t\t\tthis.operatorStateCheckpointClosingFuture = new CancelableFuture<>();\n+\t\t}\n+\t}\n+\n+\tprivate static class CancelableFuture<T> implements RunnableFuture<T> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9cce09936e14e63d8bef95bff57d0e2f2401e1f0"}, "originalPosition": 161}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkxNDI2OA==", "bodyText": "\ud83d\udc4d to the idea. Long overdue. However, StreamOperatorInitializer sounds like something active, while it's just a parameter object. How about StreamOperatorSettings or StreamOperatorParameters?", "url": "https://github.com/apache/flink/pull/11403#discussion_r392914268", "createdAt": "2020-03-16T10:26:48Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/functions/source/ContinuousFileReaderOperatorFactory.java", "diffHunk": "@@ -58,11 +56,11 @@ public void setMailboxExecutor(MailboxExecutor mailboxExecutor) {\n \t}\n \n \t@Override\n-\tpublic StreamOperator createStreamOperator(StreamTask containingTask, StreamConfig config, Output output) {\n+\tpublic <T extends StreamOperator<OUT>> T createStreamOperator(StreamOperatorInitializer<OUT> initializer) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "73b6e6e569d5ccac8bd56c593ba3f8bf5caec9c7"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkyMzUwNQ==", "bodyText": "In general, as written above \ud83d\udc4d .\nAlways passing timeService comes closer to my understanding of a factory (factory being stateless except for fundamental configurations that would change the type of the returned operator for all invocations of createStreamOperator). The factory then decides if it wants to use the service or not.\nIf the service processingTimeService would only be (costly) created for a specific operator factory (e.g. MailboxExecutor being used only in AsyncWaitOperatorFactory), then I'd wrap the creation in a supplier.\nUltimately, we would get rid of all the different OperatorFactory interfaces except for the main one. Then I'd be perfectly fine to keep factories and not convert them into builders.\nNote for that goal, we would need to get rid of SimpleOperatorFactory: Once an operator has been created, it cannot go back into factory. If we need to functionality, then I only see builder pattern as a clean solution, where going back and forth between operator and operator builder is doable.\nLast remark, if StreamOperatorInitializer ends up with 10+ fields that are all passed on construction, I'd probably switch to a builder style, but that can also be done later.", "url": "https://github.com/apache/flink/pull/11403#discussion_r392923505", "createdAt": "2020-03-16T10:38:07Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorFactoryUtil.java", "diffHunk": "@@ -57,7 +57,13 @@\n \t\t\t((ProcessingTimeServiceAware) operatorFactory).setProcessingTimeService(processingTimeService);\n \t\t}\n \n-\t\tOP op = operatorFactory.createStreamOperator(containingTask, configuration, output);\n+\t\t// TODO: what to do with ProcessingTimeServiceAware?\n+\t\tOP op = operatorFactory.createStreamOperator(\n+\t\t\tnew StreamOperatorInitializer<>(\n+\t\t\t\tcontainingTask,\n+\t\t\t\tconfiguration,\n+\t\t\t\toutput,\n+\t\t\t\tprocessingTimeService));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjIwMTUwMg=="}, "originalCommit": {"oid": "c7595ee5eb7ac60dae52bcd1368878d70d372533"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkyNTA5MA==", "bodyText": "Candidate for builder pattern as described above.", "url": "https://github.com/apache/flink/pull/11403#discussion_r392925090", "createdAt": "2020-03-16T10:39:50Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorInitializer.java", "diffHunk": "@@ -0,0 +1,65 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.Experimental;\n+import org.apache.flink.streaming.api.graph.StreamConfig;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.tasks.ProcessingTimeService;\n+import org.apache.flink.streaming.runtime.tasks.StreamTask;\n+\n+/**\n+ * Helper  class to construct {@link StreamOperatorBase}. Wraps couple of internal parameters\n+ * to simplify for users construction of classes extending {@link StreamOperatorBase} and to\n+ * allow for backward compatible changes in the {@link StreamOperatorBase}'s constructor.\n+ */\n+@Experimental\n+public class StreamOperatorInitializer<OUT> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "73b6e6e569d5ccac8bd56c593ba3f8bf5caec9c7"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkyNTgxNA==", "bodyText": "OUT needs a java tag: I initially thought OUT is the type of the operator.", "url": "https://github.com/apache/flink/pull/11403#discussion_r392925814", "createdAt": "2020-03-16T10:40:38Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorInitializer.java", "diffHunk": "@@ -0,0 +1,65 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.Experimental;\n+import org.apache.flink.streaming.api.graph.StreamConfig;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.tasks.ProcessingTimeService;\n+import org.apache.flink.streaming.runtime.tasks.StreamTask;\n+\n+/**\n+ * Helper  class to construct {@link StreamOperatorBase}. Wraps couple of internal parameters\n+ * to simplify for users construction of classes extending {@link StreamOperatorBase} and to\n+ * allow for backward compatible changes in the {@link StreamOperatorBase}'s constructor.\n+ */\n+@Experimental\n+public class StreamOperatorInitializer<OUT> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "73b6e6e569d5ccac8bd56c593ba3f8bf5caec9c7"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkyNzYxMQ==", "bodyText": "@rkhachatryan wanted to get rid of this method's generic afaik. It's really a bit anti pattern. So I'm not sure going into it makes any sense.", "url": "https://github.com/apache/flink/pull/11403#discussion_r392927611", "createdAt": "2020-03-16T10:42:31Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/async/AsyncWaitOperatorFactory.java", "diffHunk": "@@ -61,16 +59,16 @@ public void setMailboxExecutor(MailboxExecutor mailboxExecutor) {\n \t}\n \n \t@Override\n-\tpublic StreamOperator createStreamOperator(StreamTask containingTask, StreamConfig config, Output output) {\n+\tpublic <T extends StreamOperator<OUT>> T createStreamOperator(StreamOperatorInitializer<OUT> initializer) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "73b6e6e569d5ccac8bd56c593ba3f8bf5caec9c7"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkzMDgxMw==", "bodyText": "\ud83d\udc4d to no setup. I'd really wish we could get rid of initializeState as well. Maybe with V3 ;).\n(meta: it's hard for me to see the changes to V1. I have seen no obvious problem with the class itself, but I haven't comapred it)", "url": "https://github.com/apache/flink/pull/11403#discussion_r392930813", "createdAt": "2020-03-16T10:47:12Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorBase.java", "diffHunk": "@@ -0,0 +1,488 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.Experimental;\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.KeyedStateStore;\n+import org.apache.flink.api.common.state.State;\n+import org.apache.flink.api.common.state.StateDescriptor;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.java.functions.KeySelector;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.configuration.MetricOptions;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.metrics.MetricGroup;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.execution.Environment;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.metrics.groups.OperatorMetricGroup;\n+import org.apache.flink.runtime.metrics.groups.TaskManagerJobMetricGroup;\n+import org.apache.flink.runtime.metrics.groups.UnregisteredMetricGroups;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.KeyedStateBackend;\n+import org.apache.flink.runtime.state.OperatorStateBackend;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.runtime.state.VoidNamespace;\n+import org.apache.flink.runtime.state.VoidNamespaceSerializer;\n+import org.apache.flink.streaming.api.graph.StreamConfig;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.streamrecord.LatencyMarker;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.tasks.ProcessingTimeService;\n+import org.apache.flink.streaming.runtime.tasks.StreamTask;\n+import org.apache.flink.streaming.util.LatencyStats;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Arrays;\n+import java.util.Locale;\n+import java.util.Optional;\n+\n+/**\n+ * New base class for all stream operators, replacing previous {@link AbstractStreamOperator}.\n+ * Currently intended to work with {@link MultipleInputStreamOperator}.\n+ *\n+ * <p>One note-able difference in comparison to {@link AbstractStreamOperator} is lack of\n+ * {@link AbstractStreamOperator#setup(StreamTask, StreamConfig, Output)} in favor of initialisation\n+ * in the constructor, and removed some tight coupling with classes like {@link StreamTask}.\n+ *\n+ * <p>Methods are guaranteed not to be called concurrently.\n+ *\n+ * @param <OUT> The output type of the operator\n+ */\n+@Experimental\n+public abstract class StreamOperatorBase<OUT> implements StreamOperator<OUT> {\n+\t/** The logger used by the operator class and its subclasses. */\n+\tprotected static final Logger LOG = LoggerFactory.getLogger(StreamOperatorBase.class);\n+\n+\tprotected final StreamConfig config;\n+\tprotected final Output<StreamRecord<OUT>> output;\n+\tprivate final StreamingRuntimeContext runtimeContext;\n+\tprivate final ExecutionConfig executionConfig;\n+\tprivate final ClassLoader userCodeClassLoader;\n+\tprivate final CloseableRegistry cancelables;\n+\tprivate final long[] inputWatermarks;\n+\n+\t/** Metric group for the operator. */\n+\tprotected final OperatorMetricGroup metrics;\n+\tprotected final LatencyStats latencyStats;\n+\tprotected final ProcessingTimeService processingTimeService;\n+\n+\tprivate StreamOperatorStateHandler stateHandler;\n+\n+\t// We keep track of watermarks from both inputs, the combined input is the minimum\n+\t// Once the minimum advances we emit a new watermark for downstream operators\n+\tprivate long combinedWatermark = Long.MIN_VALUE;\n+\n+\tpublic StreamOperatorBase(StreamOperatorInitializer<OUT> initializer, int numberOfInputs) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4c4ec9eb40a8efc96897d0c0b4c6c27755f2ed7c"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkzMjA5NQ==", "bodyText": "I'm fine with both. V2 conveys to me that this is the only Flink left in Flink 2.0. If that roughly corresponds with your deprecation plan, then I like it more.", "url": "https://github.com/apache/flink/pull/11403#discussion_r392932095", "createdAt": "2020-03-16T10:49:30Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorBase.java", "diffHunk": "@@ -0,0 +1,484 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.Experimental;\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.KeyedStateStore;\n+import org.apache.flink.api.common.state.State;\n+import org.apache.flink.api.common.state.StateDescriptor;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.java.functions.KeySelector;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.configuration.MetricOptions;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.metrics.MetricGroup;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.execution.Environment;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.metrics.groups.OperatorMetricGroup;\n+import org.apache.flink.runtime.metrics.groups.TaskManagerJobMetricGroup;\n+import org.apache.flink.runtime.metrics.groups.UnregisteredMetricGroups;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.KeyedStateBackend;\n+import org.apache.flink.runtime.state.OperatorStateBackend;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.runtime.state.VoidNamespace;\n+import org.apache.flink.runtime.state.VoidNamespaceSerializer;\n+import org.apache.flink.streaming.api.graph.StreamConfig;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.streamrecord.LatencyMarker;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.tasks.ProcessingTimeService;\n+import org.apache.flink.streaming.runtime.tasks.StreamTask;\n+import org.apache.flink.streaming.util.LatencyStats;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Arrays;\n+import java.util.Locale;\n+import java.util.Optional;\n+\n+/**\n+ * New base class for all stream operators, replacing previous {@link AbstractStreamOperator}.\n+ * Currently intended to work with {@link MultipleInputStreamOperator}.\n+ *\n+ * <p>One note-able difference in comparison to {@link AbstractStreamOperator} is lack of\n+ * {@link AbstractStreamOperator#setup(StreamTask, StreamConfig, Output)} in favor of initialisation\n+ * in the constructor, and removed some tight coupling with classes like {@link StreamTask}.\n+ *\n+ * <p>Methods are guaranteed not to be called concurrently.\n+ *\n+ * @param <OUT> The output type of the operator\n+ */\n+@Experimental\n+public abstract class StreamOperatorBase<OUT> implements StreamOperator<OUT> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjIwMjAzMg=="}, "originalCommit": {"oid": "c7595ee5eb7ac60dae52bcd1368878d70d372533"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkzMzQ3OA==", "bodyText": "This guy should be removed and merged into StreamOperatorInitializer by exposing a Supplier<MailboxExecutor> mailboxExecutorFactory.", "url": "https://github.com/apache/flink/pull/11403#discussion_r392933478", "createdAt": "2020-03-16T10:52:00Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/YieldingOperatorFactory.java", "diffHunk": "@@ -17,10 +17,13 @@\n \n package org.apache.flink.streaming.api.operators;\n \n+import org.apache.flink.annotation.PublicEvolving;\n+\n /**\n  * An operator that needs access to the {@link MailboxExecutor} to yield to downstream operators needs to be created\n  * through a factory implementing this interface.\n  */\n+@PublicEvolving\n public interface YieldingOperatorFactory<OUT> extends StreamOperatorFactory<OUT> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c1facefebee52a1ac84f188f46b114deae0aad89"}, "originalPosition": 11}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc1NDkxODI2", "url": "https://github.com/apache/flink/pull/11403#pullrequestreview-375491826", "createdAt": "2020-03-16T18:44:29Z", "commit": {"oid": "c1facefebee52a1ac84f188f46b114deae0aad89"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQxODo0NDoyOVrOF3BZ7w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQxOToyMDozNlrOF3CoIw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzIzOTAyMw==", "bodyText": "Or AbstractStreamOperatorNg :)\nI'd like to make it clear for somebody implementing new operator what's the difference and purpose of each - straight from names, without looking at annotations or javadocs.", "url": "https://github.com/apache/flink/pull/11403#discussion_r393239023", "createdAt": "2020-03-16T18:44:29Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorBase.java", "diffHunk": "@@ -0,0 +1,484 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.Experimental;\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.KeyedStateStore;\n+import org.apache.flink.api.common.state.State;\n+import org.apache.flink.api.common.state.StateDescriptor;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.java.functions.KeySelector;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.configuration.MetricOptions;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.metrics.MetricGroup;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.execution.Environment;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.metrics.groups.OperatorMetricGroup;\n+import org.apache.flink.runtime.metrics.groups.TaskManagerJobMetricGroup;\n+import org.apache.flink.runtime.metrics.groups.UnregisteredMetricGroups;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.KeyedStateBackend;\n+import org.apache.flink.runtime.state.OperatorStateBackend;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.runtime.state.VoidNamespace;\n+import org.apache.flink.runtime.state.VoidNamespaceSerializer;\n+import org.apache.flink.streaming.api.graph.StreamConfig;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.streamrecord.LatencyMarker;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.tasks.ProcessingTimeService;\n+import org.apache.flink.streaming.runtime.tasks.StreamTask;\n+import org.apache.flink.streaming.util.LatencyStats;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Arrays;\n+import java.util.Locale;\n+import java.util.Optional;\n+\n+/**\n+ * New base class for all stream operators, replacing previous {@link AbstractStreamOperator}.\n+ * Currently intended to work with {@link MultipleInputStreamOperator}.\n+ *\n+ * <p>One note-able difference in comparison to {@link AbstractStreamOperator} is lack of\n+ * {@link AbstractStreamOperator#setup(StreamTask, StreamConfig, Output)} in favor of initialisation\n+ * in the constructor, and removed some tight coupling with classes like {@link StreamTask}.\n+ *\n+ * <p>Methods are guaranteed not to be called concurrently.\n+ *\n+ * @param <OUT> The output type of the operator\n+ */\n+@Experimental\n+public abstract class StreamOperatorBase<OUT> implements StreamOperator<OUT> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjIwMjAzMg=="}, "originalCommit": {"oid": "c7595ee5eb7ac60dae52bcd1368878d70d372533"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzIzOTg3Mw==", "bodyText": "protected?\nI guess it's only for descendants.", "url": "https://github.com/apache/flink/pull/11403#discussion_r393239873", "createdAt": "2020-03-16T18:46:05Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorBase.java", "diffHunk": "@@ -0,0 +1,488 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.Experimental;\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.KeyedStateStore;\n+import org.apache.flink.api.common.state.State;\n+import org.apache.flink.api.common.state.StateDescriptor;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.java.functions.KeySelector;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.configuration.MetricOptions;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.metrics.MetricGroup;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.execution.Environment;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.metrics.groups.OperatorMetricGroup;\n+import org.apache.flink.runtime.metrics.groups.TaskManagerJobMetricGroup;\n+import org.apache.flink.runtime.metrics.groups.UnregisteredMetricGroups;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.KeyedStateBackend;\n+import org.apache.flink.runtime.state.OperatorStateBackend;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.runtime.state.VoidNamespace;\n+import org.apache.flink.runtime.state.VoidNamespaceSerializer;\n+import org.apache.flink.streaming.api.graph.StreamConfig;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.streamrecord.LatencyMarker;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.tasks.ProcessingTimeService;\n+import org.apache.flink.streaming.runtime.tasks.StreamTask;\n+import org.apache.flink.streaming.util.LatencyStats;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Arrays;\n+import java.util.Locale;\n+import java.util.Optional;\n+\n+/**\n+ * New base class for all stream operators, replacing previous {@link AbstractStreamOperator}.\n+ * Currently intended to work with {@link MultipleInputStreamOperator}.\n+ *\n+ * <p>One note-able difference in comparison to {@link AbstractStreamOperator} is lack of\n+ * {@link AbstractStreamOperator#setup(StreamTask, StreamConfig, Output)} in favor of initialisation\n+ * in the constructor, and removed some tight coupling with classes like {@link StreamTask}.\n+ *\n+ * <p>Methods are guaranteed not to be called concurrently.\n+ *\n+ * @param <OUT> The output type of the operator\n+ */\n+@Experimental\n+public abstract class StreamOperatorBase<OUT> implements StreamOperator<OUT> {\n+\t/** The logger used by the operator class and its subclasses. */\n+\tprotected static final Logger LOG = LoggerFactory.getLogger(StreamOperatorBase.class);\n+\n+\tprotected final StreamConfig config;\n+\tprotected final Output<StreamRecord<OUT>> output;\n+\tprivate final StreamingRuntimeContext runtimeContext;\n+\tprivate final ExecutionConfig executionConfig;\n+\tprivate final ClassLoader userCodeClassLoader;\n+\tprivate final CloseableRegistry cancelables;\n+\tprivate final long[] inputWatermarks;\n+\n+\t/** Metric group for the operator. */\n+\tprotected final OperatorMetricGroup metrics;\n+\tprotected final LatencyStats latencyStats;\n+\tprotected final ProcessingTimeService processingTimeService;\n+\n+\tprivate StreamOperatorStateHandler stateHandler;\n+\n+\t// We keep track of watermarks from both inputs, the combined input is the minimum\n+\t// Once the minimum advances we emit a new watermark for downstream operators\n+\tprivate long combinedWatermark = Long.MIN_VALUE;\n+\n+\tpublic StreamOperatorBase(StreamOperatorInitializer<OUT> initializer, int numberOfInputs) {\n+\t\tinputWatermarks = new long[numberOfInputs];\n+\t\tArrays.fill(inputWatermarks, Long.MIN_VALUE);\n+\t\tfinal Environment environment = initializer.getContainingTask().getEnvironment();\n+\t\tconfig = initializer.getStreamConfig();\n+\t\tCountingOutput<OUT> countingOutput;\n+\t\tOperatorMetricGroup operatorMetricGroup;\n+\t\ttry {\n+\t\t\toperatorMetricGroup = environment.getMetricGroup().getOrAddOperator(config.getOperatorID(), config.getOperatorName());\n+\t\t\tcountingOutput = new CountingOutput(initializer.getOutput(), operatorMetricGroup.getIOMetricGroup().getNumRecordsOutCounter());\n+\t\t\tif (config.isChainStart()) {\n+\t\t\t\toperatorMetricGroup.getIOMetricGroup().reuseInputMetricsForTask();\n+\t\t\t}\n+\t\t\tif (config.isChainEnd()) {\n+\t\t\t\toperatorMetricGroup.getIOMetricGroup().reuseOutputMetricsForTask();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\tLOG.warn(\"An error occurred while instantiating task metrics.\", e);\n+\t\t\tcountingOutput = null;\n+\t\t\toperatorMetricGroup = null;\n+\t\t}\n+\n+\t\tif (countingOutput == null || operatorMetricGroup == null) {\n+\t\t\tmetrics = UnregisteredMetricGroups.createUnregisteredOperatorMetricGroup();\n+\t\t\toutput = initializer.getOutput();\n+\t\t}\n+\t\telse {\n+\t\t\tmetrics = operatorMetricGroup;\n+\t\t\toutput = countingOutput;\n+\t\t}\n+\n+\t\tlatencyStats = createLatencyStats(\n+\t\t\tenvironment.getTaskManagerInfo().getConfiguration(),\n+\t\t\tinitializer.getContainingTask().getIndexInSubtaskGroup());\n+\n+\t\tprocessingTimeService = Preconditions.checkNotNull(initializer.getProcessingTimeService());\n+\t\texecutionConfig = initializer.getContainingTask().getExecutionConfig();\n+\t\tuserCodeClassLoader = initializer.getContainingTask().getUserCodeClassLoader();\n+\t\tcancelables = initializer.getContainingTask().getCancelables();\n+\n+\t\truntimeContext = new StreamingRuntimeContext(\n+\t\t\tenvironment,\n+\t\t\tinitializer.getContainingTask().getAccumulatorMap(),\n+\t\t\toperatorMetricGroup,\n+\t\t\tgetOperatorID(),\n+\t\t\tprocessingTimeService,\n+\t\t\tnull);\n+\t}\n+\n+\tprivate LatencyStats createLatencyStats(Configuration taskManagerConfig, int indexInSubtaskGroup) {\n+\t\ttry {\n+\t\t\tint historySize = taskManagerConfig.getInteger(MetricOptions.LATENCY_HISTORY_SIZE);\n+\t\t\tif (historySize <= 0) {\n+\t\t\t\tLOG.warn(\"{} has been set to a value equal or below 0: {}. Using default.\", MetricOptions.LATENCY_HISTORY_SIZE, historySize);\n+\t\t\t\thistorySize = MetricOptions.LATENCY_HISTORY_SIZE.defaultValue();\n+\t\t\t}\n+\n+\t\t\tfinal String configuredGranularity = taskManagerConfig.getString(MetricOptions.LATENCY_SOURCE_GRANULARITY);\n+\t\t\tLatencyStats.Granularity granularity;\n+\t\t\ttry {\n+\t\t\t\tgranularity = LatencyStats.Granularity.valueOf(configuredGranularity.toUpperCase(Locale.ROOT));\n+\t\t\t} catch (IllegalArgumentException iae) {\n+\t\t\t\tgranularity = LatencyStats.Granularity.OPERATOR;\n+\t\t\t\tLOG.warn(\n+\t\t\t\t\t\"Configured value {} option for {} is invalid. Defaulting to {}.\",\n+\t\t\t\t\tconfiguredGranularity,\n+\t\t\t\t\tMetricOptions.LATENCY_SOURCE_GRANULARITY.key(),\n+\t\t\t\t\tgranularity);\n+\t\t\t}\n+\t\t\tTaskManagerJobMetricGroup jobMetricGroup = this.metrics.parent().parent();\n+\t\t\treturn new LatencyStats(jobMetricGroup.addGroup(\"latency\"),\n+\t\t\t\thistorySize,\n+\t\t\t\tindexInSubtaskGroup,\n+\t\t\t\tgetOperatorID(),\n+\t\t\t\tgranularity);\n+\t\t} catch (Exception e) {\n+\t\t\tLOG.warn(\"An error occurred while instantiating latency metrics.\", e);\n+\t\t\treturn new LatencyStats(\n+\t\t\t\tUnregisteredMetricGroups.createUnregisteredTaskManagerJobMetricGroup().addGroup(\"latency\"),\n+\t\t\t\t1,\n+\t\t\t\t0,\n+\t\t\t\tnew OperatorID(),\n+\t\t\t\tLatencyStats.Granularity.SINGLE);\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic MetricGroup getMetricGroup() {\n+\t\treturn metrics;\n+\t}\n+\n+\t@Override\n+\tpublic final void initializeState(StreamTaskStateInitializer streamTaskStateManager) throws Exception {\n+\t\tfinal TypeSerializer<?> keySerializer = config.getStateKeySerializer(getUserCodeClassloader());\n+\n+\t\tfinal StreamOperatorStateContext context =\n+\t\t\tstreamTaskStateManager.streamOperatorStateContext(\n+\t\t\t\tgetOperatorID(),\n+\t\t\t\tgetClass().getSimpleName(),\n+\t\t\t\tgetProcessingTimeService(),\n+\t\t\t\tthis,\n+\t\t\t\tkeySerializer,\n+\t\t\t\tcancelables,\n+\t\t\t\tmetrics);\n+\n+\t\tstateHandler = new StreamOperatorStateHandler(context, getExecutionConfig(), cancelables);\n+\t\tstateHandler.initializeOperatorState(this::initializeState);\n+\t}\n+\n+\t/**\n+\t * This method is called immediately before any elements are processed, it should contain the\n+\t * operator's initialization logic, e.g. state initialization.\n+\t *\n+\t * <p>The default implementation does nothing.\n+\t *\n+\t * @throws Exception An exception in this method causes the operator to fail.\n+\t */\n+\t@Override\n+\tpublic void open() throws Exception {}\n+\n+\t/**\n+\t * This method is called after all records have been added to the operators via the methods\n+\t * {@link OneInputStreamOperator#processElement(StreamRecord)}, or\n+\t * {@link TwoInputStreamOperator#processElement1(StreamRecord)} and\n+\t * {@link TwoInputStreamOperator#processElement2(StreamRecord)}.\n+\t *\n+\t * <p>The method is expected to flush all remaining buffered data. Exceptions during this flushing\n+\t * of buffered should be propagated, in order to cause the operation to be recognized asa failed,\n+\t * because the last data items are not processed properly.\n+\t *\n+\t * @throws Exception An exception in this method causes the operator to fail.\n+\t */\n+\t@Override\n+\tpublic void close() throws Exception {}\n+\n+\t/**\n+\t * This method is called at the very end of the operator's life, both in the case of a successful\n+\t * completion of the operation, and in the case of a failure and canceling.\n+\t *\n+\t * <p>This method is expected to make a thorough effort to release all resources\n+\t * that the operator has acquired.\n+\t */\n+\t@Override\n+\tpublic void dispose() throws Exception {\n+\t\tif (stateHandler != null) {\n+\t\t\tstateHandler.dispose();\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void prepareSnapshotPreBarrier(long checkpointId) throws Exception {\n+\t\t// the default implementation does nothing and accepts the checkpoint\n+\t\t// this is purely for subclasses to override\n+\t}\n+\n+\t@Override\n+\tpublic final OperatorSnapshotFutures snapshotState(long checkpointId, long timestamp, CheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory) throws Exception {\n+\t\treturn stateHandler.snapshotState(\n+\t\t\tthis::snapshotState,\n+\t\t\tgetOperatorName(),\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tcheckpointOptions,\n+\t\t\tfactory);\n+\t}\n+\n+\t/**\n+\t * Stream operators with state, which want to participate in a snapshot need to override this hook method.\n+\t *\n+\t * @param context context that provides information and means required for taking a snapshot\n+\t */\n+\tpublic void snapshotState(StateSnapshotContext context) throws Exception {\n+\t}\n+\n+\t/**\n+\t * Stream operators with state which can be restored need to override this hook method.\n+\t *\n+\t * @param context context that allows to register different states.\n+\t */\n+\tpublic void initializeState(StateInitializationContext context) throws Exception {\n+\n+\t}\n+\n+\t@Override\n+\tpublic void notifyCheckpointComplete(long checkpointId) throws Exception {\n+\t\tstateHandler.notifyCheckpointComplete(checkpointId);\n+\t}\n+\n+\t// ------------------------------------------------------------------------\n+\t//  Properties and Services\n+\t// ------------------------------------------------------------------------\n+\n+\t/**\n+\t * Gets the execution config defined on the execution environment of the job to which this\n+\t * operator belongs.\n+\t *\n+\t * @return The job's execution config.\n+\t */\n+\tpublic ExecutionConfig getExecutionConfig() {\n+\t\treturn executionConfig;\n+\t}\n+\n+\tpublic StreamConfig getOperatorConfig() {\n+\t\treturn config;\n+\t}\n+\n+\tpublic ClassLoader getUserCodeClassloader() {\n+\t\treturn userCodeClassLoader;\n+\t}\n+\n+\t/**\n+\t * Return the operator name. If the runtime context has been set, then the task name with\n+\t * subtask index is returned. Otherwise, the simple class name is returned.\n+\t *\n+\t * @return If runtime context is set, then return task name with subtask index. Otherwise return\n+\t * \t\t\tsimple class name.\n+\t */\n+\tprotected String getOperatorName() {\n+\t\tif (runtimeContext != null) {\n+\t\t\treturn runtimeContext.getTaskNameWithSubtasks();\n+\t\t} else {\n+\t\t\treturn getClass().getSimpleName();\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Returns a context that allows the operator to query information about the execution and also\n+\t * to interact with systems such as broadcast variables and managed state. This also allows\n+\t * to register timers.\n+\t */\n+\tpublic StreamingRuntimeContext getRuntimeContext() {\n+\t\treturn runtimeContext;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic <K> KeyedStateBackend<K> getKeyedStateBackend() {\n+\t\treturn (KeyedStateBackend<K>) stateHandler.getKeyedStateBackend();\n+\t}\n+\n+\tpublic OperatorStateBackend getOperatorStateBackend() {\n+\t\treturn stateHandler.getOperatorStateBackend();\n+\t}\n+\n+\t/**\n+\t * Returns the {@link ProcessingTimeService} responsible for getting the current\n+\t * processing time and registering timers.\n+\t */\n+\tpublic ProcessingTimeService getProcessingTimeService() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c1facefebee52a1ac84f188f46b114deae0aad89"}, "originalPosition": 346}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI0MTM2OA==", "bodyText": "There are 4 similar try-catch blocks here; can we eliminate duplication (by iterating through Runnables for example)?", "url": "https://github.com/apache/flink/pull/11403#discussion_r393241368", "createdAt": "2020-03-16T18:49:01Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java", "diffHunk": "@@ -0,0 +1,434 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.PublicEvolving;\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.KeyedStateStore;\n+import org.apache.flink.api.common.state.State;\n+import org.apache.flink.api.common.state.StateDescriptor;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.core.memory.DataOutputViewStreamWrapper;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.CheckpointFailureReason;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.state.AbstractKeyedStateBackend;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.DefaultKeyedStateStore;\n+import org.apache.flink.runtime.state.KeyGroupRange;\n+import org.apache.flink.runtime.state.KeyGroupStatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.KeyGroupsList;\n+import org.apache.flink.runtime.state.KeyedStateBackend;\n+import org.apache.flink.runtime.state.KeyedStateCheckpointOutputStream;\n+import org.apache.flink.runtime.state.OperatorStateBackend;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateInitializationContextImpl;\n+import org.apache.flink.runtime.state.StatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.runtime.state.StateSnapshotContextSynchronousImpl;\n+import org.apache.flink.runtime.state.VoidNamespaceSerializer;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.util.CloseableIterable;\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.IOUtils;\n+import org.apache.flink.util.function.ThrowingConsumer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.Optional;\n+\n+/**\n+ * Class encapsulating various state backend handling logic for {@link StreamOperator} implementations.\n+ */\n+@PublicEvolving\n+public class StreamOperatorStateHandler {\n+\n+\tprotected static final Logger LOG = LoggerFactory.getLogger(StreamOperatorStateHandler.class);\n+\n+\t/** Backend for keyed state. This might be empty if we're not on a keyed stream. */\n+\t@Nullable\n+\tprivate final AbstractKeyedStateBackend<?> keyedStateBackend;\n+\tprivate final CloseableRegistry closeableRegistry;\n+\t@Nullable\n+\tprivate final DefaultKeyedStateStore keyedStateStore;\n+\tprivate final OperatorStateBackend operatorStateBackend;\n+\tprivate final InternalTimeServiceManager<?> timeServiceManager;\n+\tprivate final StreamOperatorStateContext context;\n+\n+\tpublic StreamOperatorStateHandler(\n+\t\t\tStreamOperatorStateContext context,\n+\t\t\tExecutionConfig executionConfig,\n+\t\t\tCloseableRegistry closeableRegistry) {\n+\t\tthis.context = context;\n+\t\toperatorStateBackend = context.operatorStateBackend();\n+\t\tkeyedStateBackend = context.keyedStateBackend();\n+\t\tthis.closeableRegistry = closeableRegistry;\n+\n+\t\tif (keyedStateBackend != null) {\n+\t\t\tkeyedStateStore = new DefaultKeyedStateStore(keyedStateBackend, executionConfig);\n+\t\t}\n+\t\telse {\n+\t\t\tkeyedStateStore = null;\n+\t\t}\n+\n+\t\ttimeServiceManager = context.internalTimerServiceManager();\n+\t}\n+\n+\tpublic void initializeOperatorState(ThrowingConsumer<StateInitializationContext, Exception> initializeOperatorAction) throws Exception {\n+\t\tCloseableIterable<KeyGroupStatePartitionStreamProvider> keyedStateInputs = context.rawKeyedStateInputs();\n+\t\tCloseableIterable<StatePartitionStreamProvider> operatorStateInputs = context.rawOperatorStateInputs();\n+\n+\t\ttry {\n+\t\t\tStateInitializationContext initializationContext = new StateInitializationContextImpl(\n+\t\t\t\tcontext.isRestored(), // information whether we restore or start for the first time\n+\t\t\t\toperatorStateBackend, // access to operator state backend\n+\t\t\t\tkeyedStateStore, // access to keyed state backend\n+\t\t\t\tkeyedStateInputs, // access to keyed state stream\n+\t\t\t\toperatorStateInputs); // access to operator state stream\n+\n+\t\t\tinitializeOperatorAction.accept(initializationContext);\n+\t\t} finally {\n+\t\t\tcloseFromRegistry(operatorStateInputs, closeableRegistry);\n+\t\t\tcloseFromRegistry(keyedStateInputs, closeableRegistry);\n+\t\t}\n+\t}\n+\n+\tprivate static void closeFromRegistry(Closeable closeable, CloseableRegistry registry) {\n+\t\tif (registry.unregisterCloseable(closeable)) {\n+\t\t\tIOUtils.closeQuietly(closeable);\n+\t\t}\n+\t}\n+\n+\tpublic void dispose() throws Exception {\n+\n+\t\tException exception = null;\n+\n+\t\ttry {\n+\t\t\tif (closeableRegistry.unregisterCloseable(operatorStateBackend)) {\n+\t\t\t\toperatorStateBackend.close();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = e;\n+\t\t}\n+\n+\t\ttry {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c1facefebee52a1ac84f188f46b114deae0aad89"}, "originalPosition": 137}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI0MjcyMA==", "bodyText": "It would be more clear to me to see void return type instead of returning passed parameter.\nIf not, it can be returned earlier.", "url": "https://github.com/apache/flink/pull/11403#discussion_r393242720", "createdAt": "2020-03-16T18:51:14Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java", "diffHunk": "@@ -0,0 +1,434 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.PublicEvolving;\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.KeyedStateStore;\n+import org.apache.flink.api.common.state.State;\n+import org.apache.flink.api.common.state.StateDescriptor;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.core.memory.DataOutputViewStreamWrapper;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.CheckpointFailureReason;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.state.AbstractKeyedStateBackend;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.DefaultKeyedStateStore;\n+import org.apache.flink.runtime.state.KeyGroupRange;\n+import org.apache.flink.runtime.state.KeyGroupStatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.KeyGroupsList;\n+import org.apache.flink.runtime.state.KeyedStateBackend;\n+import org.apache.flink.runtime.state.KeyedStateCheckpointOutputStream;\n+import org.apache.flink.runtime.state.OperatorStateBackend;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateInitializationContextImpl;\n+import org.apache.flink.runtime.state.StatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.runtime.state.StateSnapshotContextSynchronousImpl;\n+import org.apache.flink.runtime.state.VoidNamespaceSerializer;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.util.CloseableIterable;\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.IOUtils;\n+import org.apache.flink.util.function.ThrowingConsumer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.Optional;\n+\n+/**\n+ * Class encapsulating various state backend handling logic for {@link StreamOperator} implementations.\n+ */\n+@PublicEvolving\n+public class StreamOperatorStateHandler {\n+\n+\tprotected static final Logger LOG = LoggerFactory.getLogger(StreamOperatorStateHandler.class);\n+\n+\t/** Backend for keyed state. This might be empty if we're not on a keyed stream. */\n+\t@Nullable\n+\tprivate final AbstractKeyedStateBackend<?> keyedStateBackend;\n+\tprivate final CloseableRegistry closeableRegistry;\n+\t@Nullable\n+\tprivate final DefaultKeyedStateStore keyedStateStore;\n+\tprivate final OperatorStateBackend operatorStateBackend;\n+\tprivate final InternalTimeServiceManager<?> timeServiceManager;\n+\tprivate final StreamOperatorStateContext context;\n+\n+\tpublic StreamOperatorStateHandler(\n+\t\t\tStreamOperatorStateContext context,\n+\t\t\tExecutionConfig executionConfig,\n+\t\t\tCloseableRegistry closeableRegistry) {\n+\t\tthis.context = context;\n+\t\toperatorStateBackend = context.operatorStateBackend();\n+\t\tkeyedStateBackend = context.keyedStateBackend();\n+\t\tthis.closeableRegistry = closeableRegistry;\n+\n+\t\tif (keyedStateBackend != null) {\n+\t\t\tkeyedStateStore = new DefaultKeyedStateStore(keyedStateBackend, executionConfig);\n+\t\t}\n+\t\telse {\n+\t\t\tkeyedStateStore = null;\n+\t\t}\n+\n+\t\ttimeServiceManager = context.internalTimerServiceManager();\n+\t}\n+\n+\tpublic void initializeOperatorState(ThrowingConsumer<StateInitializationContext, Exception> initializeOperatorAction) throws Exception {\n+\t\tCloseableIterable<KeyGroupStatePartitionStreamProvider> keyedStateInputs = context.rawKeyedStateInputs();\n+\t\tCloseableIterable<StatePartitionStreamProvider> operatorStateInputs = context.rawOperatorStateInputs();\n+\n+\t\ttry {\n+\t\t\tStateInitializationContext initializationContext = new StateInitializationContextImpl(\n+\t\t\t\tcontext.isRestored(), // information whether we restore or start for the first time\n+\t\t\t\toperatorStateBackend, // access to operator state backend\n+\t\t\t\tkeyedStateStore, // access to keyed state backend\n+\t\t\t\tkeyedStateInputs, // access to keyed state stream\n+\t\t\t\toperatorStateInputs); // access to operator state stream\n+\n+\t\t\tinitializeOperatorAction.accept(initializationContext);\n+\t\t} finally {\n+\t\t\tcloseFromRegistry(operatorStateInputs, closeableRegistry);\n+\t\t\tcloseFromRegistry(keyedStateInputs, closeableRegistry);\n+\t\t}\n+\t}\n+\n+\tprivate static void closeFromRegistry(Closeable closeable, CloseableRegistry registry) {\n+\t\tif (registry.unregisterCloseable(closeable)) {\n+\t\t\tIOUtils.closeQuietly(closeable);\n+\t\t}\n+\t}\n+\n+\tpublic void dispose() throws Exception {\n+\n+\t\tException exception = null;\n+\n+\t\ttry {\n+\t\t\tif (closeableRegistry.unregisterCloseable(operatorStateBackend)) {\n+\t\t\t\toperatorStateBackend.close();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = e;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tif (closeableRegistry.unregisterCloseable(keyedStateBackend)) {\n+\t\t\t\tkeyedStateBackend.close();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = ExceptionUtils.firstOrSuppressed(e, exception);\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tif (operatorStateBackend != null) {\n+\t\t\t\toperatorStateBackend.dispose();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = ExceptionUtils.firstOrSuppressed(e, exception);\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tif (keyedStateBackend != null) {\n+\t\t\t\tkeyedStateBackend.dispose();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = ExceptionUtils.firstOrSuppressed(e, exception);\n+\t\t}\n+\n+\t\tif (exception != null) {\n+\t\t\tthrow exception;\n+\t\t}\n+\t}\n+\n+\tpublic OperatorSnapshotFutures snapshotState(\n+\t\t\tThrowingConsumer<StateSnapshotContext, Exception> snapshotStateAction,\n+\t\t\tString operatorName,\n+\t\t\tlong checkpointId,\n+\t\t\tlong timestamp,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory) throws CheckpointException {\n+\t\tKeyGroupRange keyGroupRange = null != keyedStateBackend ?\n+\t\t\tkeyedStateBackend.getKeyGroupRange() : KeyGroupRange.EMPTY_KEY_GROUP_RANGE;\n+\n+\t\tOperatorSnapshotFutures snapshotInProgress = new OperatorSnapshotFutures();\n+\n+\t\tStateSnapshotContextSynchronousImpl snapshotContext = new StateSnapshotContextSynchronousImpl(\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tfactory,\n+\t\t\tkeyGroupRange,\n+\t\t\tcloseableRegistry);\n+\n+\t\treturn snapshotState(\n+\t\t\tsnapshotStateAction,\n+\t\t\toperatorName,\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tcheckpointOptions,\n+\t\t\tfactory,\n+\t\t\tsnapshotInProgress,\n+\t\t\tsnapshotContext);\n+\t}\n+\n+\t@VisibleForTesting\n+\tOperatorSnapshotFutures snapshotState(\n+\t\t\tThrowingConsumer<StateSnapshotContext, Exception> snapshotStateAction,\n+\t\t\tString operatorName,\n+\t\t\tlong checkpointId,\n+\t\t\tlong timestamp,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory,\n+\t\t\tOperatorSnapshotFutures snapshotInProgress,\n+\t\t\tStateSnapshotContextSynchronousImpl snapshotContext) throws CheckpointException {\n+\t\ttry {\n+\t\t\tsnapshotState(snapshotContext, operatorName);\n+\t\t\tsnapshotStateAction.accept(snapshotContext);\n+\n+\t\t\tsnapshotInProgress.setKeyedStateRawFuture(snapshotContext.getKeyedStateStreamFuture());\n+\t\t\tsnapshotInProgress.setOperatorStateRawFuture(snapshotContext.getOperatorStateStreamFuture());\n+\n+\t\t\tif (null != operatorStateBackend) {\n+\t\t\t\tsnapshotInProgress.setOperatorStateManagedFuture(\n+\t\t\t\t\toperatorStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));\n+\t\t\t}\n+\n+\t\t\tif (null != keyedStateBackend) {\n+\t\t\t\tsnapshotInProgress.setKeyedStateManagedFuture(\n+\t\t\t\t\tkeyedStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));\n+\t\t\t}\n+\t\t} catch (Exception snapshotException) {\n+\t\t\ttry {\n+\t\t\t\tsnapshotInProgress.cancel();\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tsnapshotException.addSuppressed(e);\n+\t\t\t}\n+\n+\t\t\tString snapshotFailMessage = \"Could not complete snapshot \" + checkpointId + \" for operator \" +\n+\t\t\t\toperatorName + \".\";\n+\n+\t\t\ttry {\n+\t\t\t\tsnapshotContext.closeExceptionally();\n+\t\t\t} catch (IOException e) {\n+\t\t\t\tsnapshotException.addSuppressed(e);\n+\t\t\t}\n+\t\t\tthrow new CheckpointException(snapshotFailMessage, CheckpointFailureReason.CHECKPOINT_DECLINED, snapshotException);\n+\t\t}\n+\n+\t\treturn snapshotInProgress;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c1facefebee52a1ac84f188f46b114deae0aad89"}, "originalPosition": 240}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI0NTA3Mg==", "bodyText": "protected?\nShould we add type parameter on class level instead of casting?\nIf not, why don't return just KeyedStateBackend<?>?", "url": "https://github.com/apache/flink/pull/11403#discussion_r393245072", "createdAt": "2020-03-16T18:55:44Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java", "diffHunk": "@@ -0,0 +1,434 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.PublicEvolving;\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.KeyedStateStore;\n+import org.apache.flink.api.common.state.State;\n+import org.apache.flink.api.common.state.StateDescriptor;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.core.memory.DataOutputViewStreamWrapper;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.CheckpointFailureReason;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.state.AbstractKeyedStateBackend;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.DefaultKeyedStateStore;\n+import org.apache.flink.runtime.state.KeyGroupRange;\n+import org.apache.flink.runtime.state.KeyGroupStatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.KeyGroupsList;\n+import org.apache.flink.runtime.state.KeyedStateBackend;\n+import org.apache.flink.runtime.state.KeyedStateCheckpointOutputStream;\n+import org.apache.flink.runtime.state.OperatorStateBackend;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateInitializationContextImpl;\n+import org.apache.flink.runtime.state.StatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.runtime.state.StateSnapshotContextSynchronousImpl;\n+import org.apache.flink.runtime.state.VoidNamespaceSerializer;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.util.CloseableIterable;\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.IOUtils;\n+import org.apache.flink.util.function.ThrowingConsumer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.Optional;\n+\n+/**\n+ * Class encapsulating various state backend handling logic for {@link StreamOperator} implementations.\n+ */\n+@PublicEvolving\n+public class StreamOperatorStateHandler {\n+\n+\tprotected static final Logger LOG = LoggerFactory.getLogger(StreamOperatorStateHandler.class);\n+\n+\t/** Backend for keyed state. This might be empty if we're not on a keyed stream. */\n+\t@Nullable\n+\tprivate final AbstractKeyedStateBackend<?> keyedStateBackend;\n+\tprivate final CloseableRegistry closeableRegistry;\n+\t@Nullable\n+\tprivate final DefaultKeyedStateStore keyedStateStore;\n+\tprivate final OperatorStateBackend operatorStateBackend;\n+\tprivate final InternalTimeServiceManager<?> timeServiceManager;\n+\tprivate final StreamOperatorStateContext context;\n+\n+\tpublic StreamOperatorStateHandler(\n+\t\t\tStreamOperatorStateContext context,\n+\t\t\tExecutionConfig executionConfig,\n+\t\t\tCloseableRegistry closeableRegistry) {\n+\t\tthis.context = context;\n+\t\toperatorStateBackend = context.operatorStateBackend();\n+\t\tkeyedStateBackend = context.keyedStateBackend();\n+\t\tthis.closeableRegistry = closeableRegistry;\n+\n+\t\tif (keyedStateBackend != null) {\n+\t\t\tkeyedStateStore = new DefaultKeyedStateStore(keyedStateBackend, executionConfig);\n+\t\t}\n+\t\telse {\n+\t\t\tkeyedStateStore = null;\n+\t\t}\n+\n+\t\ttimeServiceManager = context.internalTimerServiceManager();\n+\t}\n+\n+\tpublic void initializeOperatorState(ThrowingConsumer<StateInitializationContext, Exception> initializeOperatorAction) throws Exception {\n+\t\tCloseableIterable<KeyGroupStatePartitionStreamProvider> keyedStateInputs = context.rawKeyedStateInputs();\n+\t\tCloseableIterable<StatePartitionStreamProvider> operatorStateInputs = context.rawOperatorStateInputs();\n+\n+\t\ttry {\n+\t\t\tStateInitializationContext initializationContext = new StateInitializationContextImpl(\n+\t\t\t\tcontext.isRestored(), // information whether we restore or start for the first time\n+\t\t\t\toperatorStateBackend, // access to operator state backend\n+\t\t\t\tkeyedStateStore, // access to keyed state backend\n+\t\t\t\tkeyedStateInputs, // access to keyed state stream\n+\t\t\t\toperatorStateInputs); // access to operator state stream\n+\n+\t\t\tinitializeOperatorAction.accept(initializationContext);\n+\t\t} finally {\n+\t\t\tcloseFromRegistry(operatorStateInputs, closeableRegistry);\n+\t\t\tcloseFromRegistry(keyedStateInputs, closeableRegistry);\n+\t\t}\n+\t}\n+\n+\tprivate static void closeFromRegistry(Closeable closeable, CloseableRegistry registry) {\n+\t\tif (registry.unregisterCloseable(closeable)) {\n+\t\t\tIOUtils.closeQuietly(closeable);\n+\t\t}\n+\t}\n+\n+\tpublic void dispose() throws Exception {\n+\n+\t\tException exception = null;\n+\n+\t\ttry {\n+\t\t\tif (closeableRegistry.unregisterCloseable(operatorStateBackend)) {\n+\t\t\t\toperatorStateBackend.close();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = e;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tif (closeableRegistry.unregisterCloseable(keyedStateBackend)) {\n+\t\t\t\tkeyedStateBackend.close();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = ExceptionUtils.firstOrSuppressed(e, exception);\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tif (operatorStateBackend != null) {\n+\t\t\t\toperatorStateBackend.dispose();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = ExceptionUtils.firstOrSuppressed(e, exception);\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tif (keyedStateBackend != null) {\n+\t\t\t\tkeyedStateBackend.dispose();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = ExceptionUtils.firstOrSuppressed(e, exception);\n+\t\t}\n+\n+\t\tif (exception != null) {\n+\t\t\tthrow exception;\n+\t\t}\n+\t}\n+\n+\tpublic OperatorSnapshotFutures snapshotState(\n+\t\t\tThrowingConsumer<StateSnapshotContext, Exception> snapshotStateAction,\n+\t\t\tString operatorName,\n+\t\t\tlong checkpointId,\n+\t\t\tlong timestamp,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory) throws CheckpointException {\n+\t\tKeyGroupRange keyGroupRange = null != keyedStateBackend ?\n+\t\t\tkeyedStateBackend.getKeyGroupRange() : KeyGroupRange.EMPTY_KEY_GROUP_RANGE;\n+\n+\t\tOperatorSnapshotFutures snapshotInProgress = new OperatorSnapshotFutures();\n+\n+\t\tStateSnapshotContextSynchronousImpl snapshotContext = new StateSnapshotContextSynchronousImpl(\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tfactory,\n+\t\t\tkeyGroupRange,\n+\t\t\tcloseableRegistry);\n+\n+\t\treturn snapshotState(\n+\t\t\tsnapshotStateAction,\n+\t\t\toperatorName,\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tcheckpointOptions,\n+\t\t\tfactory,\n+\t\t\tsnapshotInProgress,\n+\t\t\tsnapshotContext);\n+\t}\n+\n+\t@VisibleForTesting\n+\tOperatorSnapshotFutures snapshotState(\n+\t\t\tThrowingConsumer<StateSnapshotContext, Exception> snapshotStateAction,\n+\t\t\tString operatorName,\n+\t\t\tlong checkpointId,\n+\t\t\tlong timestamp,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory,\n+\t\t\tOperatorSnapshotFutures snapshotInProgress,\n+\t\t\tStateSnapshotContextSynchronousImpl snapshotContext) throws CheckpointException {\n+\t\ttry {\n+\t\t\tsnapshotState(snapshotContext, operatorName);\n+\t\t\tsnapshotStateAction.accept(snapshotContext);\n+\n+\t\t\tsnapshotInProgress.setKeyedStateRawFuture(snapshotContext.getKeyedStateStreamFuture());\n+\t\t\tsnapshotInProgress.setOperatorStateRawFuture(snapshotContext.getOperatorStateStreamFuture());\n+\n+\t\t\tif (null != operatorStateBackend) {\n+\t\t\t\tsnapshotInProgress.setOperatorStateManagedFuture(\n+\t\t\t\t\toperatorStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));\n+\t\t\t}\n+\n+\t\t\tif (null != keyedStateBackend) {\n+\t\t\t\tsnapshotInProgress.setKeyedStateManagedFuture(\n+\t\t\t\t\tkeyedStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));\n+\t\t\t}\n+\t\t} catch (Exception snapshotException) {\n+\t\t\ttry {\n+\t\t\t\tsnapshotInProgress.cancel();\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tsnapshotException.addSuppressed(e);\n+\t\t\t}\n+\n+\t\t\tString snapshotFailMessage = \"Could not complete snapshot \" + checkpointId + \" for operator \" +\n+\t\t\t\toperatorName + \".\";\n+\n+\t\t\ttry {\n+\t\t\t\tsnapshotContext.closeExceptionally();\n+\t\t\t} catch (IOException e) {\n+\t\t\t\tsnapshotException.addSuppressed(e);\n+\t\t\t}\n+\t\t\tthrow new CheckpointException(snapshotFailMessage, CheckpointFailureReason.CHECKPOINT_DECLINED, snapshotException);\n+\t\t}\n+\n+\t\treturn snapshotInProgress;\n+\t}\n+\n+\t/**\n+\t * Stream operators with state, which want to participate in a snapshot need to override this hook method.\n+\t *\n+\t * @param context context that provides information and means required for taking a snapshot\n+\t * @param operatorName\n+\t */\n+\tpublic void snapshotState(StateSnapshotContext context, String operatorName) throws Exception {\n+\t\tfinal KeyedStateBackend<?> keyedStateBackend = getKeyedStateBackend();\n+\t\t//TODO all of this can be removed once heap-based timers are integrated with RocksDB incremental snapshots\n+\t\tif (keyedStateBackend instanceof AbstractKeyedStateBackend &&\n+\t\t\t((AbstractKeyedStateBackend<?>) keyedStateBackend).requiresLegacySynchronousTimerSnapshots()) {\n+\n+\t\t\tKeyedStateCheckpointOutputStream out;\n+\n+\t\t\ttry {\n+\t\t\t\tout = context.getRawKeyedOperatorStateOutput();\n+\t\t\t} catch (Exception exception) {\n+\t\t\t\tthrow new Exception(\"Could not open raw keyed operator state stream for \" +\n+\t\t\t\t\toperatorName + '.', exception);\n+\t\t\t}\n+\n+\t\t\ttry {\n+\t\t\t\tKeyGroupsList allKeyGroups = out.getKeyGroupList();\n+\t\t\t\tfor (int keyGroupIdx : allKeyGroups) {\n+\t\t\t\t\tout.startNewKeyGroup(keyGroupIdx);\n+\n+\t\t\t\t\ttimeServiceManager.snapshotStateForKeyGroup(\n+\t\t\t\t\t\tnew DataOutputViewStreamWrapper(out), keyGroupIdx);\n+\t\t\t\t}\n+\t\t\t} catch (Exception exception) {\n+\t\t\t\tthrow new Exception(\"Could not write timer service of \" + operatorName +\n+\t\t\t\t\t\" to checkpoint state stream.\", exception);\n+\t\t\t} finally {\n+\t\t\t\ttry {\n+\t\t\t\t\tout.close();\n+\t\t\t\t} catch (Exception closeException) {\n+\t\t\t\t\tLOG.warn(\"Could not close raw keyed operator state stream for {}. This \" +\n+\t\t\t\t\t\t\"might have prevented deleting some state data.\", operatorName, closeException);\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void notifyCheckpointComplete(long checkpointId) throws Exception {\n+\t\tif (keyedStateBackend != null) {\n+\t\t\tkeyedStateBackend.notifyCheckpointComplete(checkpointId);\n+\t\t}\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic <K> KeyedStateBackend<K> getKeyedStateBackend() {\n+\t\treturn (KeyedStateBackend<K>) keyedStateBackend;\n+\t}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c1facefebee52a1ac84f188f46b114deae0aad89"}, "originalPosition": 295}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI0NjAxOQ==", "bodyText": "Same as getKeyedStateBackend.", "url": "https://github.com/apache/flink/pull/11403#discussion_r393246019", "createdAt": "2020-03-16T18:57:02Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java", "diffHunk": "@@ -0,0 +1,434 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.PublicEvolving;\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.KeyedStateStore;\n+import org.apache.flink.api.common.state.State;\n+import org.apache.flink.api.common.state.StateDescriptor;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.core.memory.DataOutputViewStreamWrapper;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.CheckpointFailureReason;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.state.AbstractKeyedStateBackend;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.DefaultKeyedStateStore;\n+import org.apache.flink.runtime.state.KeyGroupRange;\n+import org.apache.flink.runtime.state.KeyGroupStatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.KeyGroupsList;\n+import org.apache.flink.runtime.state.KeyedStateBackend;\n+import org.apache.flink.runtime.state.KeyedStateCheckpointOutputStream;\n+import org.apache.flink.runtime.state.OperatorStateBackend;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateInitializationContextImpl;\n+import org.apache.flink.runtime.state.StatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.runtime.state.StateSnapshotContextSynchronousImpl;\n+import org.apache.flink.runtime.state.VoidNamespaceSerializer;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.util.CloseableIterable;\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.IOUtils;\n+import org.apache.flink.util.function.ThrowingConsumer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.Optional;\n+\n+/**\n+ * Class encapsulating various state backend handling logic for {@link StreamOperator} implementations.\n+ */\n+@PublicEvolving\n+public class StreamOperatorStateHandler {\n+\n+\tprotected static final Logger LOG = LoggerFactory.getLogger(StreamOperatorStateHandler.class);\n+\n+\t/** Backend for keyed state. This might be empty if we're not on a keyed stream. */\n+\t@Nullable\n+\tprivate final AbstractKeyedStateBackend<?> keyedStateBackend;\n+\tprivate final CloseableRegistry closeableRegistry;\n+\t@Nullable\n+\tprivate final DefaultKeyedStateStore keyedStateStore;\n+\tprivate final OperatorStateBackend operatorStateBackend;\n+\tprivate final InternalTimeServiceManager<?> timeServiceManager;\n+\tprivate final StreamOperatorStateContext context;\n+\n+\tpublic StreamOperatorStateHandler(\n+\t\t\tStreamOperatorStateContext context,\n+\t\t\tExecutionConfig executionConfig,\n+\t\t\tCloseableRegistry closeableRegistry) {\n+\t\tthis.context = context;\n+\t\toperatorStateBackend = context.operatorStateBackend();\n+\t\tkeyedStateBackend = context.keyedStateBackend();\n+\t\tthis.closeableRegistry = closeableRegistry;\n+\n+\t\tif (keyedStateBackend != null) {\n+\t\t\tkeyedStateStore = new DefaultKeyedStateStore(keyedStateBackend, executionConfig);\n+\t\t}\n+\t\telse {\n+\t\t\tkeyedStateStore = null;\n+\t\t}\n+\n+\t\ttimeServiceManager = context.internalTimerServiceManager();\n+\t}\n+\n+\tpublic void initializeOperatorState(ThrowingConsumer<StateInitializationContext, Exception> initializeOperatorAction) throws Exception {\n+\t\tCloseableIterable<KeyGroupStatePartitionStreamProvider> keyedStateInputs = context.rawKeyedStateInputs();\n+\t\tCloseableIterable<StatePartitionStreamProvider> operatorStateInputs = context.rawOperatorStateInputs();\n+\n+\t\ttry {\n+\t\t\tStateInitializationContext initializationContext = new StateInitializationContextImpl(\n+\t\t\t\tcontext.isRestored(), // information whether we restore or start for the first time\n+\t\t\t\toperatorStateBackend, // access to operator state backend\n+\t\t\t\tkeyedStateStore, // access to keyed state backend\n+\t\t\t\tkeyedStateInputs, // access to keyed state stream\n+\t\t\t\toperatorStateInputs); // access to operator state stream\n+\n+\t\t\tinitializeOperatorAction.accept(initializationContext);\n+\t\t} finally {\n+\t\t\tcloseFromRegistry(operatorStateInputs, closeableRegistry);\n+\t\t\tcloseFromRegistry(keyedStateInputs, closeableRegistry);\n+\t\t}\n+\t}\n+\n+\tprivate static void closeFromRegistry(Closeable closeable, CloseableRegistry registry) {\n+\t\tif (registry.unregisterCloseable(closeable)) {\n+\t\t\tIOUtils.closeQuietly(closeable);\n+\t\t}\n+\t}\n+\n+\tpublic void dispose() throws Exception {\n+\n+\t\tException exception = null;\n+\n+\t\ttry {\n+\t\t\tif (closeableRegistry.unregisterCloseable(operatorStateBackend)) {\n+\t\t\t\toperatorStateBackend.close();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = e;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tif (closeableRegistry.unregisterCloseable(keyedStateBackend)) {\n+\t\t\t\tkeyedStateBackend.close();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = ExceptionUtils.firstOrSuppressed(e, exception);\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tif (operatorStateBackend != null) {\n+\t\t\t\toperatorStateBackend.dispose();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = ExceptionUtils.firstOrSuppressed(e, exception);\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tif (keyedStateBackend != null) {\n+\t\t\t\tkeyedStateBackend.dispose();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = ExceptionUtils.firstOrSuppressed(e, exception);\n+\t\t}\n+\n+\t\tif (exception != null) {\n+\t\t\tthrow exception;\n+\t\t}\n+\t}\n+\n+\tpublic OperatorSnapshotFutures snapshotState(\n+\t\t\tThrowingConsumer<StateSnapshotContext, Exception> snapshotStateAction,\n+\t\t\tString operatorName,\n+\t\t\tlong checkpointId,\n+\t\t\tlong timestamp,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory) throws CheckpointException {\n+\t\tKeyGroupRange keyGroupRange = null != keyedStateBackend ?\n+\t\t\tkeyedStateBackend.getKeyGroupRange() : KeyGroupRange.EMPTY_KEY_GROUP_RANGE;\n+\n+\t\tOperatorSnapshotFutures snapshotInProgress = new OperatorSnapshotFutures();\n+\n+\t\tStateSnapshotContextSynchronousImpl snapshotContext = new StateSnapshotContextSynchronousImpl(\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tfactory,\n+\t\t\tkeyGroupRange,\n+\t\t\tcloseableRegistry);\n+\n+\t\treturn snapshotState(\n+\t\t\tsnapshotStateAction,\n+\t\t\toperatorName,\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tcheckpointOptions,\n+\t\t\tfactory,\n+\t\t\tsnapshotInProgress,\n+\t\t\tsnapshotContext);\n+\t}\n+\n+\t@VisibleForTesting\n+\tOperatorSnapshotFutures snapshotState(\n+\t\t\tThrowingConsumer<StateSnapshotContext, Exception> snapshotStateAction,\n+\t\t\tString operatorName,\n+\t\t\tlong checkpointId,\n+\t\t\tlong timestamp,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory,\n+\t\t\tOperatorSnapshotFutures snapshotInProgress,\n+\t\t\tStateSnapshotContextSynchronousImpl snapshotContext) throws CheckpointException {\n+\t\ttry {\n+\t\t\tsnapshotState(snapshotContext, operatorName);\n+\t\t\tsnapshotStateAction.accept(snapshotContext);\n+\n+\t\t\tsnapshotInProgress.setKeyedStateRawFuture(snapshotContext.getKeyedStateStreamFuture());\n+\t\t\tsnapshotInProgress.setOperatorStateRawFuture(snapshotContext.getOperatorStateStreamFuture());\n+\n+\t\t\tif (null != operatorStateBackend) {\n+\t\t\t\tsnapshotInProgress.setOperatorStateManagedFuture(\n+\t\t\t\t\toperatorStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));\n+\t\t\t}\n+\n+\t\t\tif (null != keyedStateBackend) {\n+\t\t\t\tsnapshotInProgress.setKeyedStateManagedFuture(\n+\t\t\t\t\tkeyedStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));\n+\t\t\t}\n+\t\t} catch (Exception snapshotException) {\n+\t\t\ttry {\n+\t\t\t\tsnapshotInProgress.cancel();\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tsnapshotException.addSuppressed(e);\n+\t\t\t}\n+\n+\t\t\tString snapshotFailMessage = \"Could not complete snapshot \" + checkpointId + \" for operator \" +\n+\t\t\t\toperatorName + \".\";\n+\n+\t\t\ttry {\n+\t\t\t\tsnapshotContext.closeExceptionally();\n+\t\t\t} catch (IOException e) {\n+\t\t\t\tsnapshotException.addSuppressed(e);\n+\t\t\t}\n+\t\t\tthrow new CheckpointException(snapshotFailMessage, CheckpointFailureReason.CHECKPOINT_DECLINED, snapshotException);\n+\t\t}\n+\n+\t\treturn snapshotInProgress;\n+\t}\n+\n+\t/**\n+\t * Stream operators with state, which want to participate in a snapshot need to override this hook method.\n+\t *\n+\t * @param context context that provides information and means required for taking a snapshot\n+\t * @param operatorName\n+\t */\n+\tpublic void snapshotState(StateSnapshotContext context, String operatorName) throws Exception {\n+\t\tfinal KeyedStateBackend<?> keyedStateBackend = getKeyedStateBackend();\n+\t\t//TODO all of this can be removed once heap-based timers are integrated with RocksDB incremental snapshots\n+\t\tif (keyedStateBackend instanceof AbstractKeyedStateBackend &&\n+\t\t\t((AbstractKeyedStateBackend<?>) keyedStateBackend).requiresLegacySynchronousTimerSnapshots()) {\n+\n+\t\t\tKeyedStateCheckpointOutputStream out;\n+\n+\t\t\ttry {\n+\t\t\t\tout = context.getRawKeyedOperatorStateOutput();\n+\t\t\t} catch (Exception exception) {\n+\t\t\t\tthrow new Exception(\"Could not open raw keyed operator state stream for \" +\n+\t\t\t\t\toperatorName + '.', exception);\n+\t\t\t}\n+\n+\t\t\ttry {\n+\t\t\t\tKeyGroupsList allKeyGroups = out.getKeyGroupList();\n+\t\t\t\tfor (int keyGroupIdx : allKeyGroups) {\n+\t\t\t\t\tout.startNewKeyGroup(keyGroupIdx);\n+\n+\t\t\t\t\ttimeServiceManager.snapshotStateForKeyGroup(\n+\t\t\t\t\t\tnew DataOutputViewStreamWrapper(out), keyGroupIdx);\n+\t\t\t\t}\n+\t\t\t} catch (Exception exception) {\n+\t\t\t\tthrow new Exception(\"Could not write timer service of \" + operatorName +\n+\t\t\t\t\t\" to checkpoint state stream.\", exception);\n+\t\t\t} finally {\n+\t\t\t\ttry {\n+\t\t\t\t\tout.close();\n+\t\t\t\t} catch (Exception closeException) {\n+\t\t\t\t\tLOG.warn(\"Could not close raw keyed operator state stream for {}. This \" +\n+\t\t\t\t\t\t\"might have prevented deleting some state data.\", operatorName, closeException);\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void notifyCheckpointComplete(long checkpointId) throws Exception {\n+\t\tif (keyedStateBackend != null) {\n+\t\t\tkeyedStateBackend.notifyCheckpointComplete(checkpointId);\n+\t\t}\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic <K> KeyedStateBackend<K> getKeyedStateBackend() {\n+\t\treturn (KeyedStateBackend<K>) keyedStateBackend;\n+\t}\n+\n+\tpublic OperatorStateBackend getOperatorStateBackend() {\n+\t\treturn operatorStateBackend;\n+\t}\n+\n+\tpublic <N, S extends State, T> S getOrCreateKeyedState(\n+\t\t\tTypeSerializer<N> namespaceSerializer,\n+\t\t\tStateDescriptor<S, T> stateDescriptor) throws Exception {\n+\n+\t\tif (keyedStateStore != null) {\n+\t\t\treturn keyedStateBackend.getOrCreateKeyedState(namespaceSerializer, stateDescriptor);\n+\t\t}\n+\t\telse {\n+\t\t\tthrow new IllegalStateException(\"Cannot create partitioned state. \" +\n+\t\t\t\t\t\"The keyed state backend has not been set.\" +\n+\t\t\t\t\t\"This indicates that the operator is not partitioned/keyed.\");\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Creates a partitioned state handle, using the state backend configured for this task.\n+\t *\n+\t * @throws IllegalStateException Thrown, if the key/value state was already initialized.\n+\t * @throws Exception Thrown, if the state backend cannot create the key/value state.\n+\t */\n+\tprotected <S extends State, N> S getPartitionedState(\n+\t\t\tN namespace,\n+\t\t\tTypeSerializer<N> namespaceSerializer,\n+\t\t\tStateDescriptor<S, ?> stateDescriptor) throws Exception {\n+\n+\t\t/*\n+\t    TODO: NOTE: This method does a lot of work caching / retrieving states just to update the namespace.\n+\t    This method should be removed for the sake of namespaces being lazily fetched from the keyed\n+\t    state backend, or being set on the state directly.\n+\t    */\n+\n+\t\tif (keyedStateStore != null) {\n+\t\t\treturn keyedStateBackend.getPartitionedState(namespace, namespaceSerializer, stateDescriptor);\n+\t\t} else {\n+\t\t\tthrow new RuntimeException(\"Cannot create partitioned state. The keyed state \" +\n+\t\t\t\t\"backend has not been set. This indicates that the operator is not \" +\n+\t\t\t\t\"partitioned/keyed.\");\n+\t\t}\n+\t}\n+\n+\t@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+\tpublic void setCurrentKey(Object key) {\n+\t\tif (keyedStateBackend != null) {\n+\t\t\ttry {\n+\t\t\t\t// need to work around type restrictions\n+\t\t\t\t@SuppressWarnings(\"unchecked,rawtypes\")\n+\t\t\t\tAbstractKeyedStateBackend rawBackend = (AbstractKeyedStateBackend) keyedStateBackend;\n+\n+\t\t\t\trawBackend.setCurrentKey(key);\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tthrow new RuntimeException(\"Exception occurred while setting the current key context.\", e);\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\t@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+\tpublic Object getCurrentKey() {\n+\t\tif (keyedStateBackend != null) {\n+\t\t\treturn keyedStateBackend.getCurrentKey();\n+\t\t} else {\n+\t\t\tthrow new UnsupportedOperationException(\"Key can only be retrieved on KeyedStream.\");\n+\t\t}\n+\t}\n+\n+\tpublic Optional<KeyedStateStore> getKeyedStateStore() {\n+\t\treturn Optional.ofNullable(keyedStateStore);\n+\t}\n+\n+\t/**\n+\t * Returns a {@link InternalTimerService} that can be used to query current processing time\n+\t * and event time and to set timers. An operator can have several timer services, where\n+\t * each has its own namespace serializer. Timer services are differentiated by the string\n+\t * key that is given when requesting them, if you call this method with the same key\n+\t * multiple times you will get the same timer service instance in subsequent requests.\n+\t *\n+\t * <p>Timers are always scoped to a key, the currently active key of a keyed stream operation.\n+\t * When a timer fires, this key will also be set as the currently active key.\n+\t *\n+\t * <p>Each timer has attached metadata, the namespace. Different timer services\n+\t * can have a different namespace type. If you don't need namespace differentiation you\n+\t * can use {@link VoidNamespaceSerializer} as the namespace serializer.\n+\t *\n+\t * @param name The name of the requested timer service. If no service exists under the given\n+\t *             name a new one will be created and returned.\n+\t * @param namespaceSerializer {@code TypeSerializer} for the timer namespace.\n+\t * @param triggerable The {@link Triggerable} that should be invoked when timers fire\n+\t *\n+\t * @param <N> The type of the timer namespace.\n+\t */\n+\tpublic <K, N> InternalTimerService<N> getInternalTimerService(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c1facefebee52a1ac84f188f46b114deae0aad89"}, "originalPosition": 390}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI0Njc4MA==", "bodyText": "I couldn't find usages, am I missing something?", "url": "https://github.com/apache/flink/pull/11403#discussion_r393246780", "createdAt": "2020-03-16T18:57:58Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java", "diffHunk": "@@ -0,0 +1,434 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.PublicEvolving;\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.KeyedStateStore;\n+import org.apache.flink.api.common.state.State;\n+import org.apache.flink.api.common.state.StateDescriptor;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.core.memory.DataOutputViewStreamWrapper;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.CheckpointFailureReason;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.state.AbstractKeyedStateBackend;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.DefaultKeyedStateStore;\n+import org.apache.flink.runtime.state.KeyGroupRange;\n+import org.apache.flink.runtime.state.KeyGroupStatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.KeyGroupsList;\n+import org.apache.flink.runtime.state.KeyedStateBackend;\n+import org.apache.flink.runtime.state.KeyedStateCheckpointOutputStream;\n+import org.apache.flink.runtime.state.OperatorStateBackend;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateInitializationContextImpl;\n+import org.apache.flink.runtime.state.StatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.runtime.state.StateSnapshotContextSynchronousImpl;\n+import org.apache.flink.runtime.state.VoidNamespaceSerializer;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.util.CloseableIterable;\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.IOUtils;\n+import org.apache.flink.util.function.ThrowingConsumer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.Optional;\n+\n+/**\n+ * Class encapsulating various state backend handling logic for {@link StreamOperator} implementations.\n+ */\n+@PublicEvolving\n+public class StreamOperatorStateHandler {\n+\n+\tprotected static final Logger LOG = LoggerFactory.getLogger(StreamOperatorStateHandler.class);\n+\n+\t/** Backend for keyed state. This might be empty if we're not on a keyed stream. */\n+\t@Nullable\n+\tprivate final AbstractKeyedStateBackend<?> keyedStateBackend;\n+\tprivate final CloseableRegistry closeableRegistry;\n+\t@Nullable\n+\tprivate final DefaultKeyedStateStore keyedStateStore;\n+\tprivate final OperatorStateBackend operatorStateBackend;\n+\tprivate final InternalTimeServiceManager<?> timeServiceManager;\n+\tprivate final StreamOperatorStateContext context;\n+\n+\tpublic StreamOperatorStateHandler(\n+\t\t\tStreamOperatorStateContext context,\n+\t\t\tExecutionConfig executionConfig,\n+\t\t\tCloseableRegistry closeableRegistry) {\n+\t\tthis.context = context;\n+\t\toperatorStateBackend = context.operatorStateBackend();\n+\t\tkeyedStateBackend = context.keyedStateBackend();\n+\t\tthis.closeableRegistry = closeableRegistry;\n+\n+\t\tif (keyedStateBackend != null) {\n+\t\t\tkeyedStateStore = new DefaultKeyedStateStore(keyedStateBackend, executionConfig);\n+\t\t}\n+\t\telse {\n+\t\t\tkeyedStateStore = null;\n+\t\t}\n+\n+\t\ttimeServiceManager = context.internalTimerServiceManager();\n+\t}\n+\n+\tpublic void initializeOperatorState(ThrowingConsumer<StateInitializationContext, Exception> initializeOperatorAction) throws Exception {\n+\t\tCloseableIterable<KeyGroupStatePartitionStreamProvider> keyedStateInputs = context.rawKeyedStateInputs();\n+\t\tCloseableIterable<StatePartitionStreamProvider> operatorStateInputs = context.rawOperatorStateInputs();\n+\n+\t\ttry {\n+\t\t\tStateInitializationContext initializationContext = new StateInitializationContextImpl(\n+\t\t\t\tcontext.isRestored(), // information whether we restore or start for the first time\n+\t\t\t\toperatorStateBackend, // access to operator state backend\n+\t\t\t\tkeyedStateStore, // access to keyed state backend\n+\t\t\t\tkeyedStateInputs, // access to keyed state stream\n+\t\t\t\toperatorStateInputs); // access to operator state stream\n+\n+\t\t\tinitializeOperatorAction.accept(initializationContext);\n+\t\t} finally {\n+\t\t\tcloseFromRegistry(operatorStateInputs, closeableRegistry);\n+\t\t\tcloseFromRegistry(keyedStateInputs, closeableRegistry);\n+\t\t}\n+\t}\n+\n+\tprivate static void closeFromRegistry(Closeable closeable, CloseableRegistry registry) {\n+\t\tif (registry.unregisterCloseable(closeable)) {\n+\t\t\tIOUtils.closeQuietly(closeable);\n+\t\t}\n+\t}\n+\n+\tpublic void dispose() throws Exception {\n+\n+\t\tException exception = null;\n+\n+\t\ttry {\n+\t\t\tif (closeableRegistry.unregisterCloseable(operatorStateBackend)) {\n+\t\t\t\toperatorStateBackend.close();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = e;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tif (closeableRegistry.unregisterCloseable(keyedStateBackend)) {\n+\t\t\t\tkeyedStateBackend.close();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = ExceptionUtils.firstOrSuppressed(e, exception);\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tif (operatorStateBackend != null) {\n+\t\t\t\toperatorStateBackend.dispose();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = ExceptionUtils.firstOrSuppressed(e, exception);\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tif (keyedStateBackend != null) {\n+\t\t\t\tkeyedStateBackend.dispose();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = ExceptionUtils.firstOrSuppressed(e, exception);\n+\t\t}\n+\n+\t\tif (exception != null) {\n+\t\t\tthrow exception;\n+\t\t}\n+\t}\n+\n+\tpublic OperatorSnapshotFutures snapshotState(\n+\t\t\tThrowingConsumer<StateSnapshotContext, Exception> snapshotStateAction,\n+\t\t\tString operatorName,\n+\t\t\tlong checkpointId,\n+\t\t\tlong timestamp,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory) throws CheckpointException {\n+\t\tKeyGroupRange keyGroupRange = null != keyedStateBackend ?\n+\t\t\tkeyedStateBackend.getKeyGroupRange() : KeyGroupRange.EMPTY_KEY_GROUP_RANGE;\n+\n+\t\tOperatorSnapshotFutures snapshotInProgress = new OperatorSnapshotFutures();\n+\n+\t\tStateSnapshotContextSynchronousImpl snapshotContext = new StateSnapshotContextSynchronousImpl(\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tfactory,\n+\t\t\tkeyGroupRange,\n+\t\t\tcloseableRegistry);\n+\n+\t\treturn snapshotState(\n+\t\t\tsnapshotStateAction,\n+\t\t\toperatorName,\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tcheckpointOptions,\n+\t\t\tfactory,\n+\t\t\tsnapshotInProgress,\n+\t\t\tsnapshotContext);\n+\t}\n+\n+\t@VisibleForTesting\n+\tOperatorSnapshotFutures snapshotState(\n+\t\t\tThrowingConsumer<StateSnapshotContext, Exception> snapshotStateAction,\n+\t\t\tString operatorName,\n+\t\t\tlong checkpointId,\n+\t\t\tlong timestamp,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory,\n+\t\t\tOperatorSnapshotFutures snapshotInProgress,\n+\t\t\tStateSnapshotContextSynchronousImpl snapshotContext) throws CheckpointException {\n+\t\ttry {\n+\t\t\tsnapshotState(snapshotContext, operatorName);\n+\t\t\tsnapshotStateAction.accept(snapshotContext);\n+\n+\t\t\tsnapshotInProgress.setKeyedStateRawFuture(snapshotContext.getKeyedStateStreamFuture());\n+\t\t\tsnapshotInProgress.setOperatorStateRawFuture(snapshotContext.getOperatorStateStreamFuture());\n+\n+\t\t\tif (null != operatorStateBackend) {\n+\t\t\t\tsnapshotInProgress.setOperatorStateManagedFuture(\n+\t\t\t\t\toperatorStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));\n+\t\t\t}\n+\n+\t\t\tif (null != keyedStateBackend) {\n+\t\t\t\tsnapshotInProgress.setKeyedStateManagedFuture(\n+\t\t\t\t\tkeyedStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));\n+\t\t\t}\n+\t\t} catch (Exception snapshotException) {\n+\t\t\ttry {\n+\t\t\t\tsnapshotInProgress.cancel();\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tsnapshotException.addSuppressed(e);\n+\t\t\t}\n+\n+\t\t\tString snapshotFailMessage = \"Could not complete snapshot \" + checkpointId + \" for operator \" +\n+\t\t\t\toperatorName + \".\";\n+\n+\t\t\ttry {\n+\t\t\t\tsnapshotContext.closeExceptionally();\n+\t\t\t} catch (IOException e) {\n+\t\t\t\tsnapshotException.addSuppressed(e);\n+\t\t\t}\n+\t\t\tthrow new CheckpointException(snapshotFailMessage, CheckpointFailureReason.CHECKPOINT_DECLINED, snapshotException);\n+\t\t}\n+\n+\t\treturn snapshotInProgress;\n+\t}\n+\n+\t/**\n+\t * Stream operators with state, which want to participate in a snapshot need to override this hook method.\n+\t *\n+\t * @param context context that provides information and means required for taking a snapshot\n+\t * @param operatorName\n+\t */\n+\tpublic void snapshotState(StateSnapshotContext context, String operatorName) throws Exception {\n+\t\tfinal KeyedStateBackend<?> keyedStateBackend = getKeyedStateBackend();\n+\t\t//TODO all of this can be removed once heap-based timers are integrated with RocksDB incremental snapshots\n+\t\tif (keyedStateBackend instanceof AbstractKeyedStateBackend &&\n+\t\t\t((AbstractKeyedStateBackend<?>) keyedStateBackend).requiresLegacySynchronousTimerSnapshots()) {\n+\n+\t\t\tKeyedStateCheckpointOutputStream out;\n+\n+\t\t\ttry {\n+\t\t\t\tout = context.getRawKeyedOperatorStateOutput();\n+\t\t\t} catch (Exception exception) {\n+\t\t\t\tthrow new Exception(\"Could not open raw keyed operator state stream for \" +\n+\t\t\t\t\toperatorName + '.', exception);\n+\t\t\t}\n+\n+\t\t\ttry {\n+\t\t\t\tKeyGroupsList allKeyGroups = out.getKeyGroupList();\n+\t\t\t\tfor (int keyGroupIdx : allKeyGroups) {\n+\t\t\t\t\tout.startNewKeyGroup(keyGroupIdx);\n+\n+\t\t\t\t\ttimeServiceManager.snapshotStateForKeyGroup(\n+\t\t\t\t\t\tnew DataOutputViewStreamWrapper(out), keyGroupIdx);\n+\t\t\t\t}\n+\t\t\t} catch (Exception exception) {\n+\t\t\t\tthrow new Exception(\"Could not write timer service of \" + operatorName +\n+\t\t\t\t\t\" to checkpoint state stream.\", exception);\n+\t\t\t} finally {\n+\t\t\t\ttry {\n+\t\t\t\t\tout.close();\n+\t\t\t\t} catch (Exception closeException) {\n+\t\t\t\t\tLOG.warn(\"Could not close raw keyed operator state stream for {}. This \" +\n+\t\t\t\t\t\t\"might have prevented deleting some state data.\", operatorName, closeException);\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void notifyCheckpointComplete(long checkpointId) throws Exception {\n+\t\tif (keyedStateBackend != null) {\n+\t\t\tkeyedStateBackend.notifyCheckpointComplete(checkpointId);\n+\t\t}\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic <K> KeyedStateBackend<K> getKeyedStateBackend() {\n+\t\treturn (KeyedStateBackend<K>) keyedStateBackend;\n+\t}\n+\n+\tpublic OperatorStateBackend getOperatorStateBackend() {\n+\t\treturn operatorStateBackend;\n+\t}\n+\n+\tpublic <N, S extends State, T> S getOrCreateKeyedState(\n+\t\t\tTypeSerializer<N> namespaceSerializer,\n+\t\t\tStateDescriptor<S, T> stateDescriptor) throws Exception {\n+\n+\t\tif (keyedStateStore != null) {\n+\t\t\treturn keyedStateBackend.getOrCreateKeyedState(namespaceSerializer, stateDescriptor);\n+\t\t}\n+\t\telse {\n+\t\t\tthrow new IllegalStateException(\"Cannot create partitioned state. \" +\n+\t\t\t\t\t\"The keyed state backend has not been set.\" +\n+\t\t\t\t\t\"This indicates that the operator is not partitioned/keyed.\");\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Creates a partitioned state handle, using the state backend configured for this task.\n+\t *\n+\t * @throws IllegalStateException Thrown, if the key/value state was already initialized.\n+\t * @throws Exception Thrown, if the state backend cannot create the key/value state.\n+\t */\n+\tprotected <S extends State, N> S getPartitionedState(\n+\t\t\tN namespace,\n+\t\t\tTypeSerializer<N> namespaceSerializer,\n+\t\t\tStateDescriptor<S, ?> stateDescriptor) throws Exception {\n+\n+\t\t/*\n+\t    TODO: NOTE: This method does a lot of work caching / retrieving states just to update the namespace.\n+\t    This method should be removed for the sake of namespaces being lazily fetched from the keyed\n+\t    state backend, or being set on the state directly.\n+\t    */\n+\n+\t\tif (keyedStateStore != null) {\n+\t\t\treturn keyedStateBackend.getPartitionedState(namespace, namespaceSerializer, stateDescriptor);\n+\t\t} else {\n+\t\t\tthrow new RuntimeException(\"Cannot create partitioned state. The keyed state \" +\n+\t\t\t\t\"backend has not been set. This indicates that the operator is not \" +\n+\t\t\t\t\"partitioned/keyed.\");\n+\t\t}\n+\t}\n+\n+\t@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+\tpublic void setCurrentKey(Object key) {\n+\t\tif (keyedStateBackend != null) {\n+\t\t\ttry {\n+\t\t\t\t// need to work around type restrictions\n+\t\t\t\t@SuppressWarnings(\"unchecked,rawtypes\")\n+\t\t\t\tAbstractKeyedStateBackend rawBackend = (AbstractKeyedStateBackend) keyedStateBackend;\n+\n+\t\t\t\trawBackend.setCurrentKey(key);\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tthrow new RuntimeException(\"Exception occurred while setting the current key context.\", e);\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\t@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+\tpublic Object getCurrentKey() {\n+\t\tif (keyedStateBackend != null) {\n+\t\t\treturn keyedStateBackend.getCurrentKey();\n+\t\t} else {\n+\t\t\tthrow new UnsupportedOperationException(\"Key can only be retrieved on KeyedStream.\");\n+\t\t}\n+\t}\n+\n+\tpublic Optional<KeyedStateStore> getKeyedStateStore() {\n+\t\treturn Optional.ofNullable(keyedStateStore);\n+\t}\n+\n+\t/**\n+\t * Returns a {@link InternalTimerService} that can be used to query current processing time\n+\t * and event time and to set timers. An operator can have several timer services, where\n+\t * each has its own namespace serializer. Timer services are differentiated by the string\n+\t * key that is given when requesting them, if you call this method with the same key\n+\t * multiple times you will get the same timer service instance in subsequent requests.\n+\t *\n+\t * <p>Timers are always scoped to a key, the currently active key of a keyed stream operation.\n+\t * When a timer fires, this key will also be set as the currently active key.\n+\t *\n+\t * <p>Each timer has attached metadata, the namespace. Different timer services\n+\t * can have a different namespace type. If you don't need namespace differentiation you\n+\t * can use {@link VoidNamespaceSerializer} as the namespace serializer.\n+\t *\n+\t * @param name The name of the requested timer service. If no service exists under the given\n+\t *             name a new one will be created and returned.\n+\t * @param namespaceSerializer {@code TypeSerializer} for the timer namespace.\n+\t * @param triggerable The {@link Triggerable} that should be invoked when timers fire\n+\t *\n+\t * @param <N> The type of the timer namespace.\n+\t */\n+\tpublic <K, N> InternalTimerService<N> getInternalTimerService(\n+\t\t\tString name,\n+\t\t\tTypeSerializer<N> namespaceSerializer,\n+\t\t\tTriggerable<K, N> triggerable) {\n+\n+\t\tcheckTimerServiceInitialization();\n+\n+\t\t// the following casting is to overcome type restrictions.\n+\t\tKeyedStateBackend<K> keyedStateBackend = getKeyedStateBackend();\n+\t\tTypeSerializer<K> keySerializer = keyedStateBackend.getKeySerializer();\n+\t\tInternalTimeServiceManager<K> keyedTimeServiceHandler = (InternalTimeServiceManager<K>) timeServiceManager;\n+\t\tTimerSerializer<K, N> timerSerializer = new TimerSerializer<>(keySerializer, namespaceSerializer);\n+\t\treturn keyedTimeServiceHandler.getInternalTimerService(name, timerSerializer, triggerable);\n+\t}\n+\n+\tprivate void checkTimerServiceInitialization() {\n+\t\tif (getKeyedStateBackend() == null) {\n+\t\t\tthrow new UnsupportedOperationException(\"Timers can only be used on keyed operators.\");\n+\t\t} else if (timeServiceManager == null) {\n+\t\t\tthrow new RuntimeException(\"The timer service has not been initialized.\");\n+\t\t}\n+\t}\n+\n+\tpublic void advanceWatermark(Watermark mark) throws Exception {\n+\t\tif (timeServiceManager != null) {\n+\t\t\ttimeServiceManager.advanceWatermark(mark);\n+\t\t}\n+\t}\n+\n+\t@VisibleForTesting\n+\tpublic int numProcessingTimeTimers() {\n+\t\treturn timeServiceManager == null ? 0 :\n+\t\t\ttimeServiceManager.numProcessingTimeTimers();\n+\t}\n+\n+\t@VisibleForTesting\n+\tpublic int numEventTimeTimers() {\n+\t\treturn timeServiceManager == null ? 0 :\n+\t\t\ttimeServiceManager.numEventTimeTimers();\n+\t}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c1facefebee52a1ac84f188f46b114deae0aad89"}, "originalPosition": 429}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI1Mjc2Mw==", "bodyText": "+1, other candidates: StreamOperatorCreationContext, StreamOperatorFactoryContext", "url": "https://github.com/apache/flink/pull/11403#discussion_r393252763", "createdAt": "2020-03-16T19:07:34Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/functions/source/ContinuousFileReaderOperatorFactory.java", "diffHunk": "@@ -58,11 +56,11 @@ public void setMailboxExecutor(MailboxExecutor mailboxExecutor) {\n \t}\n \n \t@Override\n-\tpublic StreamOperator createStreamOperator(StreamTask containingTask, StreamConfig config, Output output) {\n+\tpublic <T extends StreamOperator<OUT>> T createStreamOperator(StreamOperatorInitializer<OUT> initializer) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkxNDI2OA=="}, "originalCommit": {"oid": "73b6e6e569d5ccac8bd56c593ba3f8bf5caec9c7"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI1ODE4MQ==", "bodyText": "Why do we allow client to specify return type (T)?\nIMO, it's a factory who knows what it creates, except for strange cases of SimpleOperatorFactory and CodeGenOperatorFactory :)\nI see two options:\n\nparameterize StreamOperatorFactory with the return type (I tried - too many changes)\nreturn StreamOperator<OUT> and move cast to the client; this is less casts and IMO confusion", "url": "https://github.com/apache/flink/pull/11403#discussion_r393258181", "createdAt": "2020-03-16T19:18:44Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorFactory.java", "diffHunk": "@@ -32,14 +30,13 @@\n  *\n  * @param <OUT> The output type of the operator\n  */\n-@Internal\n+@PublicEvolving\n public interface StreamOperatorFactory<OUT> extends Serializable {\n \n \t/**\n \t * Create the operator. Sets access to the context and the output.\n \t */\n-\t<T extends StreamOperator<OUT>> T createStreamOperator(\n-\t\t\tStreamTask<?, ?> containingTask, StreamConfig config, Output<StreamRecord<OUT>> output);\n+\t<T extends StreamOperator<OUT>> T createStreamOperator(StreamOperatorInitializer<OUT> initializer);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c1facefebee52a1ac84f188f46b114deae0aad89"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI1OTA0Mw==", "bodyText": "\ud83d\udc4d for extracting and grouping state-related operations", "url": "https://github.com/apache/flink/pull/11403#discussion_r393259043", "createdAt": "2020-03-16T19:20:36Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java", "diffHunk": "@@ -0,0 +1,434 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.PublicEvolving;\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.KeyedStateStore;\n+import org.apache.flink.api.common.state.State;\n+import org.apache.flink.api.common.state.StateDescriptor;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.core.memory.DataOutputViewStreamWrapper;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.CheckpointFailureReason;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.state.AbstractKeyedStateBackend;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.DefaultKeyedStateStore;\n+import org.apache.flink.runtime.state.KeyGroupRange;\n+import org.apache.flink.runtime.state.KeyGroupStatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.KeyGroupsList;\n+import org.apache.flink.runtime.state.KeyedStateBackend;\n+import org.apache.flink.runtime.state.KeyedStateCheckpointOutputStream;\n+import org.apache.flink.runtime.state.OperatorStateBackend;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateInitializationContextImpl;\n+import org.apache.flink.runtime.state.StatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.runtime.state.StateSnapshotContextSynchronousImpl;\n+import org.apache.flink.runtime.state.VoidNamespaceSerializer;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.util.CloseableIterable;\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.IOUtils;\n+import org.apache.flink.util.function.ThrowingConsumer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.Optional;\n+\n+/**\n+ * Class encapsulating various state backend handling logic for {@link StreamOperator} implementations.\n+ */\n+@PublicEvolving\n+public class StreamOperatorStateHandler {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c1facefebee52a1ac84f188f46b114deae0aad89"}, "originalPosition": 67}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c1facefebee52a1ac84f188f46b114deae0aad89", "author": {"user": {"login": "pnowojski", "name": "Piotr Nowojski"}}, "url": "https://github.com/apache/flink/commit/c1facefebee52a1ac84f188f46b114deae0aad89", "committedDate": "2020-03-13T15:07:10Z", "message": "[FLINK-16316][operators] Make StreamOperatorFactory PublicEvolving"}, "afterCommit": {"oid": "af0a9aaf0e21579c2de2715535d166142aa4d2fe", "author": {"user": {"login": "pnowojski", "name": "Piotr Nowojski"}}, "url": "https://github.com/apache/flink/commit/af0a9aaf0e21579c2de2715535d166142aa4d2fe", "committedDate": "2020-03-19T08:13:14Z", "message": "[FLINK-16316][operators] Make StreamOperatorFactory PublicEvolving"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc2ODkzMjQ1", "url": "https://github.com/apache/flink/pull/11403#pullrequestreview-376893245", "createdAt": "2020-03-18T14:04:07Z", "commit": {"oid": "9cce09936e14e63d8bef95bff57d0e2f2401e1f0"}, "state": "COMMENTED", "comments": {"totalCount": 15, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOFQxNDowNDowN1rOF4Gadw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQwODoxMDowMlrOF4jvNQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDM2OTY1NQ==", "bodyText": "protected I don't think it's needed, as this is looks like valid public api of this class. Note,  StreamOperatorStateHandler is a private field of abstract classes.\n KeyedStateBackend<?> wouldn't work as some PublicEvolving apis need this to be casted. I think global type parameter wouldn't work, as this field/class is being used also in non keyed context.", "url": "https://github.com/apache/flink/pull/11403#discussion_r394369655", "createdAt": "2020-03-18T14:04:07Z", "author": {"login": "pnowojski"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java", "diffHunk": "@@ -0,0 +1,434 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.PublicEvolving;\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.KeyedStateStore;\n+import org.apache.flink.api.common.state.State;\n+import org.apache.flink.api.common.state.StateDescriptor;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.core.memory.DataOutputViewStreamWrapper;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.CheckpointFailureReason;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.state.AbstractKeyedStateBackend;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.DefaultKeyedStateStore;\n+import org.apache.flink.runtime.state.KeyGroupRange;\n+import org.apache.flink.runtime.state.KeyGroupStatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.KeyGroupsList;\n+import org.apache.flink.runtime.state.KeyedStateBackend;\n+import org.apache.flink.runtime.state.KeyedStateCheckpointOutputStream;\n+import org.apache.flink.runtime.state.OperatorStateBackend;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateInitializationContextImpl;\n+import org.apache.flink.runtime.state.StatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.runtime.state.StateSnapshotContextSynchronousImpl;\n+import org.apache.flink.runtime.state.VoidNamespaceSerializer;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.util.CloseableIterable;\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.IOUtils;\n+import org.apache.flink.util.function.ThrowingConsumer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.Optional;\n+\n+/**\n+ * Class encapsulating various state backend handling logic for {@link StreamOperator} implementations.\n+ */\n+@PublicEvolving\n+public class StreamOperatorStateHandler {\n+\n+\tprotected static final Logger LOG = LoggerFactory.getLogger(StreamOperatorStateHandler.class);\n+\n+\t/** Backend for keyed state. This might be empty if we're not on a keyed stream. */\n+\t@Nullable\n+\tprivate final AbstractKeyedStateBackend<?> keyedStateBackend;\n+\tprivate final CloseableRegistry closeableRegistry;\n+\t@Nullable\n+\tprivate final DefaultKeyedStateStore keyedStateStore;\n+\tprivate final OperatorStateBackend operatorStateBackend;\n+\tprivate final InternalTimeServiceManager<?> timeServiceManager;\n+\tprivate final StreamOperatorStateContext context;\n+\n+\tpublic StreamOperatorStateHandler(\n+\t\t\tStreamOperatorStateContext context,\n+\t\t\tExecutionConfig executionConfig,\n+\t\t\tCloseableRegistry closeableRegistry) {\n+\t\tthis.context = context;\n+\t\toperatorStateBackend = context.operatorStateBackend();\n+\t\tkeyedStateBackend = context.keyedStateBackend();\n+\t\tthis.closeableRegistry = closeableRegistry;\n+\n+\t\tif (keyedStateBackend != null) {\n+\t\t\tkeyedStateStore = new DefaultKeyedStateStore(keyedStateBackend, executionConfig);\n+\t\t}\n+\t\telse {\n+\t\t\tkeyedStateStore = null;\n+\t\t}\n+\n+\t\ttimeServiceManager = context.internalTimerServiceManager();\n+\t}\n+\n+\tpublic void initializeOperatorState(ThrowingConsumer<StateInitializationContext, Exception> initializeOperatorAction) throws Exception {\n+\t\tCloseableIterable<KeyGroupStatePartitionStreamProvider> keyedStateInputs = context.rawKeyedStateInputs();\n+\t\tCloseableIterable<StatePartitionStreamProvider> operatorStateInputs = context.rawOperatorStateInputs();\n+\n+\t\ttry {\n+\t\t\tStateInitializationContext initializationContext = new StateInitializationContextImpl(\n+\t\t\t\tcontext.isRestored(), // information whether we restore or start for the first time\n+\t\t\t\toperatorStateBackend, // access to operator state backend\n+\t\t\t\tkeyedStateStore, // access to keyed state backend\n+\t\t\t\tkeyedStateInputs, // access to keyed state stream\n+\t\t\t\toperatorStateInputs); // access to operator state stream\n+\n+\t\t\tinitializeOperatorAction.accept(initializationContext);\n+\t\t} finally {\n+\t\t\tcloseFromRegistry(operatorStateInputs, closeableRegistry);\n+\t\t\tcloseFromRegistry(keyedStateInputs, closeableRegistry);\n+\t\t}\n+\t}\n+\n+\tprivate static void closeFromRegistry(Closeable closeable, CloseableRegistry registry) {\n+\t\tif (registry.unregisterCloseable(closeable)) {\n+\t\t\tIOUtils.closeQuietly(closeable);\n+\t\t}\n+\t}\n+\n+\tpublic void dispose() throws Exception {\n+\n+\t\tException exception = null;\n+\n+\t\ttry {\n+\t\t\tif (closeableRegistry.unregisterCloseable(operatorStateBackend)) {\n+\t\t\t\toperatorStateBackend.close();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = e;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tif (closeableRegistry.unregisterCloseable(keyedStateBackend)) {\n+\t\t\t\tkeyedStateBackend.close();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = ExceptionUtils.firstOrSuppressed(e, exception);\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tif (operatorStateBackend != null) {\n+\t\t\t\toperatorStateBackend.dispose();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = ExceptionUtils.firstOrSuppressed(e, exception);\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tif (keyedStateBackend != null) {\n+\t\t\t\tkeyedStateBackend.dispose();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = ExceptionUtils.firstOrSuppressed(e, exception);\n+\t\t}\n+\n+\t\tif (exception != null) {\n+\t\t\tthrow exception;\n+\t\t}\n+\t}\n+\n+\tpublic OperatorSnapshotFutures snapshotState(\n+\t\t\tThrowingConsumer<StateSnapshotContext, Exception> snapshotStateAction,\n+\t\t\tString operatorName,\n+\t\t\tlong checkpointId,\n+\t\t\tlong timestamp,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory) throws CheckpointException {\n+\t\tKeyGroupRange keyGroupRange = null != keyedStateBackend ?\n+\t\t\tkeyedStateBackend.getKeyGroupRange() : KeyGroupRange.EMPTY_KEY_GROUP_RANGE;\n+\n+\t\tOperatorSnapshotFutures snapshotInProgress = new OperatorSnapshotFutures();\n+\n+\t\tStateSnapshotContextSynchronousImpl snapshotContext = new StateSnapshotContextSynchronousImpl(\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tfactory,\n+\t\t\tkeyGroupRange,\n+\t\t\tcloseableRegistry);\n+\n+\t\treturn snapshotState(\n+\t\t\tsnapshotStateAction,\n+\t\t\toperatorName,\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tcheckpointOptions,\n+\t\t\tfactory,\n+\t\t\tsnapshotInProgress,\n+\t\t\tsnapshotContext);\n+\t}\n+\n+\t@VisibleForTesting\n+\tOperatorSnapshotFutures snapshotState(\n+\t\t\tThrowingConsumer<StateSnapshotContext, Exception> snapshotStateAction,\n+\t\t\tString operatorName,\n+\t\t\tlong checkpointId,\n+\t\t\tlong timestamp,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory,\n+\t\t\tOperatorSnapshotFutures snapshotInProgress,\n+\t\t\tStateSnapshotContextSynchronousImpl snapshotContext) throws CheckpointException {\n+\t\ttry {\n+\t\t\tsnapshotState(snapshotContext, operatorName);\n+\t\t\tsnapshotStateAction.accept(snapshotContext);\n+\n+\t\t\tsnapshotInProgress.setKeyedStateRawFuture(snapshotContext.getKeyedStateStreamFuture());\n+\t\t\tsnapshotInProgress.setOperatorStateRawFuture(snapshotContext.getOperatorStateStreamFuture());\n+\n+\t\t\tif (null != operatorStateBackend) {\n+\t\t\t\tsnapshotInProgress.setOperatorStateManagedFuture(\n+\t\t\t\t\toperatorStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));\n+\t\t\t}\n+\n+\t\t\tif (null != keyedStateBackend) {\n+\t\t\t\tsnapshotInProgress.setKeyedStateManagedFuture(\n+\t\t\t\t\tkeyedStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));\n+\t\t\t}\n+\t\t} catch (Exception snapshotException) {\n+\t\t\ttry {\n+\t\t\t\tsnapshotInProgress.cancel();\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tsnapshotException.addSuppressed(e);\n+\t\t\t}\n+\n+\t\t\tString snapshotFailMessage = \"Could not complete snapshot \" + checkpointId + \" for operator \" +\n+\t\t\t\toperatorName + \".\";\n+\n+\t\t\ttry {\n+\t\t\t\tsnapshotContext.closeExceptionally();\n+\t\t\t} catch (IOException e) {\n+\t\t\t\tsnapshotException.addSuppressed(e);\n+\t\t\t}\n+\t\t\tthrow new CheckpointException(snapshotFailMessage, CheckpointFailureReason.CHECKPOINT_DECLINED, snapshotException);\n+\t\t}\n+\n+\t\treturn snapshotInProgress;\n+\t}\n+\n+\t/**\n+\t * Stream operators with state, which want to participate in a snapshot need to override this hook method.\n+\t *\n+\t * @param context context that provides information and means required for taking a snapshot\n+\t * @param operatorName\n+\t */\n+\tpublic void snapshotState(StateSnapshotContext context, String operatorName) throws Exception {\n+\t\tfinal KeyedStateBackend<?> keyedStateBackend = getKeyedStateBackend();\n+\t\t//TODO all of this can be removed once heap-based timers are integrated with RocksDB incremental snapshots\n+\t\tif (keyedStateBackend instanceof AbstractKeyedStateBackend &&\n+\t\t\t((AbstractKeyedStateBackend<?>) keyedStateBackend).requiresLegacySynchronousTimerSnapshots()) {\n+\n+\t\t\tKeyedStateCheckpointOutputStream out;\n+\n+\t\t\ttry {\n+\t\t\t\tout = context.getRawKeyedOperatorStateOutput();\n+\t\t\t} catch (Exception exception) {\n+\t\t\t\tthrow new Exception(\"Could not open raw keyed operator state stream for \" +\n+\t\t\t\t\toperatorName + '.', exception);\n+\t\t\t}\n+\n+\t\t\ttry {\n+\t\t\t\tKeyGroupsList allKeyGroups = out.getKeyGroupList();\n+\t\t\t\tfor (int keyGroupIdx : allKeyGroups) {\n+\t\t\t\t\tout.startNewKeyGroup(keyGroupIdx);\n+\n+\t\t\t\t\ttimeServiceManager.snapshotStateForKeyGroup(\n+\t\t\t\t\t\tnew DataOutputViewStreamWrapper(out), keyGroupIdx);\n+\t\t\t\t}\n+\t\t\t} catch (Exception exception) {\n+\t\t\t\tthrow new Exception(\"Could not write timer service of \" + operatorName +\n+\t\t\t\t\t\" to checkpoint state stream.\", exception);\n+\t\t\t} finally {\n+\t\t\t\ttry {\n+\t\t\t\t\tout.close();\n+\t\t\t\t} catch (Exception closeException) {\n+\t\t\t\t\tLOG.warn(\"Could not close raw keyed operator state stream for {}. This \" +\n+\t\t\t\t\t\t\"might have prevented deleting some state data.\", operatorName, closeException);\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void notifyCheckpointComplete(long checkpointId) throws Exception {\n+\t\tif (keyedStateBackend != null) {\n+\t\t\tkeyedStateBackend.notifyCheckpointComplete(checkpointId);\n+\t\t}\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic <K> KeyedStateBackend<K> getKeyedStateBackend() {\n+\t\treturn (KeyedStateBackend<K>) keyedStateBackend;\n+\t}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI0NTA3Mg=="}, "originalCommit": {"oid": "c1facefebee52a1ac84f188f46b114deae0aad89"}, "originalPosition": 295}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDM3MDc3Mg==", "bodyText": "They are being used in PublicEvolving api, so users might be relaying on this.", "url": "https://github.com/apache/flink/pull/11403#discussion_r394370772", "createdAt": "2020-03-18T14:05:43Z", "author": {"login": "pnowojski"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java", "diffHunk": "@@ -0,0 +1,434 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.PublicEvolving;\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.KeyedStateStore;\n+import org.apache.flink.api.common.state.State;\n+import org.apache.flink.api.common.state.StateDescriptor;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.core.memory.DataOutputViewStreamWrapper;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.CheckpointFailureReason;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.state.AbstractKeyedStateBackend;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.DefaultKeyedStateStore;\n+import org.apache.flink.runtime.state.KeyGroupRange;\n+import org.apache.flink.runtime.state.KeyGroupStatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.KeyGroupsList;\n+import org.apache.flink.runtime.state.KeyedStateBackend;\n+import org.apache.flink.runtime.state.KeyedStateCheckpointOutputStream;\n+import org.apache.flink.runtime.state.OperatorStateBackend;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateInitializationContextImpl;\n+import org.apache.flink.runtime.state.StatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.runtime.state.StateSnapshotContextSynchronousImpl;\n+import org.apache.flink.runtime.state.VoidNamespaceSerializer;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.util.CloseableIterable;\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.IOUtils;\n+import org.apache.flink.util.function.ThrowingConsumer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.Optional;\n+\n+/**\n+ * Class encapsulating various state backend handling logic for {@link StreamOperator} implementations.\n+ */\n+@PublicEvolving\n+public class StreamOperatorStateHandler {\n+\n+\tprotected static final Logger LOG = LoggerFactory.getLogger(StreamOperatorStateHandler.class);\n+\n+\t/** Backend for keyed state. This might be empty if we're not on a keyed stream. */\n+\t@Nullable\n+\tprivate final AbstractKeyedStateBackend<?> keyedStateBackend;\n+\tprivate final CloseableRegistry closeableRegistry;\n+\t@Nullable\n+\tprivate final DefaultKeyedStateStore keyedStateStore;\n+\tprivate final OperatorStateBackend operatorStateBackend;\n+\tprivate final InternalTimeServiceManager<?> timeServiceManager;\n+\tprivate final StreamOperatorStateContext context;\n+\n+\tpublic StreamOperatorStateHandler(\n+\t\t\tStreamOperatorStateContext context,\n+\t\t\tExecutionConfig executionConfig,\n+\t\t\tCloseableRegistry closeableRegistry) {\n+\t\tthis.context = context;\n+\t\toperatorStateBackend = context.operatorStateBackend();\n+\t\tkeyedStateBackend = context.keyedStateBackend();\n+\t\tthis.closeableRegistry = closeableRegistry;\n+\n+\t\tif (keyedStateBackend != null) {\n+\t\t\tkeyedStateStore = new DefaultKeyedStateStore(keyedStateBackend, executionConfig);\n+\t\t}\n+\t\telse {\n+\t\t\tkeyedStateStore = null;\n+\t\t}\n+\n+\t\ttimeServiceManager = context.internalTimerServiceManager();\n+\t}\n+\n+\tpublic void initializeOperatorState(ThrowingConsumer<StateInitializationContext, Exception> initializeOperatorAction) throws Exception {\n+\t\tCloseableIterable<KeyGroupStatePartitionStreamProvider> keyedStateInputs = context.rawKeyedStateInputs();\n+\t\tCloseableIterable<StatePartitionStreamProvider> operatorStateInputs = context.rawOperatorStateInputs();\n+\n+\t\ttry {\n+\t\t\tStateInitializationContext initializationContext = new StateInitializationContextImpl(\n+\t\t\t\tcontext.isRestored(), // information whether we restore or start for the first time\n+\t\t\t\toperatorStateBackend, // access to operator state backend\n+\t\t\t\tkeyedStateStore, // access to keyed state backend\n+\t\t\t\tkeyedStateInputs, // access to keyed state stream\n+\t\t\t\toperatorStateInputs); // access to operator state stream\n+\n+\t\t\tinitializeOperatorAction.accept(initializationContext);\n+\t\t} finally {\n+\t\t\tcloseFromRegistry(operatorStateInputs, closeableRegistry);\n+\t\t\tcloseFromRegistry(keyedStateInputs, closeableRegistry);\n+\t\t}\n+\t}\n+\n+\tprivate static void closeFromRegistry(Closeable closeable, CloseableRegistry registry) {\n+\t\tif (registry.unregisterCloseable(closeable)) {\n+\t\t\tIOUtils.closeQuietly(closeable);\n+\t\t}\n+\t}\n+\n+\tpublic void dispose() throws Exception {\n+\n+\t\tException exception = null;\n+\n+\t\ttry {\n+\t\t\tif (closeableRegistry.unregisterCloseable(operatorStateBackend)) {\n+\t\t\t\toperatorStateBackend.close();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = e;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tif (closeableRegistry.unregisterCloseable(keyedStateBackend)) {\n+\t\t\t\tkeyedStateBackend.close();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = ExceptionUtils.firstOrSuppressed(e, exception);\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tif (operatorStateBackend != null) {\n+\t\t\t\toperatorStateBackend.dispose();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = ExceptionUtils.firstOrSuppressed(e, exception);\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tif (keyedStateBackend != null) {\n+\t\t\t\tkeyedStateBackend.dispose();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = ExceptionUtils.firstOrSuppressed(e, exception);\n+\t\t}\n+\n+\t\tif (exception != null) {\n+\t\t\tthrow exception;\n+\t\t}\n+\t}\n+\n+\tpublic OperatorSnapshotFutures snapshotState(\n+\t\t\tThrowingConsumer<StateSnapshotContext, Exception> snapshotStateAction,\n+\t\t\tString operatorName,\n+\t\t\tlong checkpointId,\n+\t\t\tlong timestamp,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory) throws CheckpointException {\n+\t\tKeyGroupRange keyGroupRange = null != keyedStateBackend ?\n+\t\t\tkeyedStateBackend.getKeyGroupRange() : KeyGroupRange.EMPTY_KEY_GROUP_RANGE;\n+\n+\t\tOperatorSnapshotFutures snapshotInProgress = new OperatorSnapshotFutures();\n+\n+\t\tStateSnapshotContextSynchronousImpl snapshotContext = new StateSnapshotContextSynchronousImpl(\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tfactory,\n+\t\t\tkeyGroupRange,\n+\t\t\tcloseableRegistry);\n+\n+\t\treturn snapshotState(\n+\t\t\tsnapshotStateAction,\n+\t\t\toperatorName,\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tcheckpointOptions,\n+\t\t\tfactory,\n+\t\t\tsnapshotInProgress,\n+\t\t\tsnapshotContext);\n+\t}\n+\n+\t@VisibleForTesting\n+\tOperatorSnapshotFutures snapshotState(\n+\t\t\tThrowingConsumer<StateSnapshotContext, Exception> snapshotStateAction,\n+\t\t\tString operatorName,\n+\t\t\tlong checkpointId,\n+\t\t\tlong timestamp,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory,\n+\t\t\tOperatorSnapshotFutures snapshotInProgress,\n+\t\t\tStateSnapshotContextSynchronousImpl snapshotContext) throws CheckpointException {\n+\t\ttry {\n+\t\t\tsnapshotState(snapshotContext, operatorName);\n+\t\t\tsnapshotStateAction.accept(snapshotContext);\n+\n+\t\t\tsnapshotInProgress.setKeyedStateRawFuture(snapshotContext.getKeyedStateStreamFuture());\n+\t\t\tsnapshotInProgress.setOperatorStateRawFuture(snapshotContext.getOperatorStateStreamFuture());\n+\n+\t\t\tif (null != operatorStateBackend) {\n+\t\t\t\tsnapshotInProgress.setOperatorStateManagedFuture(\n+\t\t\t\t\toperatorStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));\n+\t\t\t}\n+\n+\t\t\tif (null != keyedStateBackend) {\n+\t\t\t\tsnapshotInProgress.setKeyedStateManagedFuture(\n+\t\t\t\t\tkeyedStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));\n+\t\t\t}\n+\t\t} catch (Exception snapshotException) {\n+\t\t\ttry {\n+\t\t\t\tsnapshotInProgress.cancel();\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tsnapshotException.addSuppressed(e);\n+\t\t\t}\n+\n+\t\t\tString snapshotFailMessage = \"Could not complete snapshot \" + checkpointId + \" for operator \" +\n+\t\t\t\toperatorName + \".\";\n+\n+\t\t\ttry {\n+\t\t\t\tsnapshotContext.closeExceptionally();\n+\t\t\t} catch (IOException e) {\n+\t\t\t\tsnapshotException.addSuppressed(e);\n+\t\t\t}\n+\t\t\tthrow new CheckpointException(snapshotFailMessage, CheckpointFailureReason.CHECKPOINT_DECLINED, snapshotException);\n+\t\t}\n+\n+\t\treturn snapshotInProgress;\n+\t}\n+\n+\t/**\n+\t * Stream operators with state, which want to participate in a snapshot need to override this hook method.\n+\t *\n+\t * @param context context that provides information and means required for taking a snapshot\n+\t * @param operatorName\n+\t */\n+\tpublic void snapshotState(StateSnapshotContext context, String operatorName) throws Exception {\n+\t\tfinal KeyedStateBackend<?> keyedStateBackend = getKeyedStateBackend();\n+\t\t//TODO all of this can be removed once heap-based timers are integrated with RocksDB incremental snapshots\n+\t\tif (keyedStateBackend instanceof AbstractKeyedStateBackend &&\n+\t\t\t((AbstractKeyedStateBackend<?>) keyedStateBackend).requiresLegacySynchronousTimerSnapshots()) {\n+\n+\t\t\tKeyedStateCheckpointOutputStream out;\n+\n+\t\t\ttry {\n+\t\t\t\tout = context.getRawKeyedOperatorStateOutput();\n+\t\t\t} catch (Exception exception) {\n+\t\t\t\tthrow new Exception(\"Could not open raw keyed operator state stream for \" +\n+\t\t\t\t\toperatorName + '.', exception);\n+\t\t\t}\n+\n+\t\t\ttry {\n+\t\t\t\tKeyGroupsList allKeyGroups = out.getKeyGroupList();\n+\t\t\t\tfor (int keyGroupIdx : allKeyGroups) {\n+\t\t\t\t\tout.startNewKeyGroup(keyGroupIdx);\n+\n+\t\t\t\t\ttimeServiceManager.snapshotStateForKeyGroup(\n+\t\t\t\t\t\tnew DataOutputViewStreamWrapper(out), keyGroupIdx);\n+\t\t\t\t}\n+\t\t\t} catch (Exception exception) {\n+\t\t\t\tthrow new Exception(\"Could not write timer service of \" + operatorName +\n+\t\t\t\t\t\" to checkpoint state stream.\", exception);\n+\t\t\t} finally {\n+\t\t\t\ttry {\n+\t\t\t\t\tout.close();\n+\t\t\t\t} catch (Exception closeException) {\n+\t\t\t\t\tLOG.warn(\"Could not close raw keyed operator state stream for {}. This \" +\n+\t\t\t\t\t\t\"might have prevented deleting some state data.\", operatorName, closeException);\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void notifyCheckpointComplete(long checkpointId) throws Exception {\n+\t\tif (keyedStateBackend != null) {\n+\t\t\tkeyedStateBackend.notifyCheckpointComplete(checkpointId);\n+\t\t}\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic <K> KeyedStateBackend<K> getKeyedStateBackend() {\n+\t\treturn (KeyedStateBackend<K>) keyedStateBackend;\n+\t}\n+\n+\tpublic OperatorStateBackend getOperatorStateBackend() {\n+\t\treturn operatorStateBackend;\n+\t}\n+\n+\tpublic <N, S extends State, T> S getOrCreateKeyedState(\n+\t\t\tTypeSerializer<N> namespaceSerializer,\n+\t\t\tStateDescriptor<S, T> stateDescriptor) throws Exception {\n+\n+\t\tif (keyedStateStore != null) {\n+\t\t\treturn keyedStateBackend.getOrCreateKeyedState(namespaceSerializer, stateDescriptor);\n+\t\t}\n+\t\telse {\n+\t\t\tthrow new IllegalStateException(\"Cannot create partitioned state. \" +\n+\t\t\t\t\t\"The keyed state backend has not been set.\" +\n+\t\t\t\t\t\"This indicates that the operator is not partitioned/keyed.\");\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Creates a partitioned state handle, using the state backend configured for this task.\n+\t *\n+\t * @throws IllegalStateException Thrown, if the key/value state was already initialized.\n+\t * @throws Exception Thrown, if the state backend cannot create the key/value state.\n+\t */\n+\tprotected <S extends State, N> S getPartitionedState(\n+\t\t\tN namespace,\n+\t\t\tTypeSerializer<N> namespaceSerializer,\n+\t\t\tStateDescriptor<S, ?> stateDescriptor) throws Exception {\n+\n+\t\t/*\n+\t    TODO: NOTE: This method does a lot of work caching / retrieving states just to update the namespace.\n+\t    This method should be removed for the sake of namespaces being lazily fetched from the keyed\n+\t    state backend, or being set on the state directly.\n+\t    */\n+\n+\t\tif (keyedStateStore != null) {\n+\t\t\treturn keyedStateBackend.getPartitionedState(namespace, namespaceSerializer, stateDescriptor);\n+\t\t} else {\n+\t\t\tthrow new RuntimeException(\"Cannot create partitioned state. The keyed state \" +\n+\t\t\t\t\"backend has not been set. This indicates that the operator is not \" +\n+\t\t\t\t\"partitioned/keyed.\");\n+\t\t}\n+\t}\n+\n+\t@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+\tpublic void setCurrentKey(Object key) {\n+\t\tif (keyedStateBackend != null) {\n+\t\t\ttry {\n+\t\t\t\t// need to work around type restrictions\n+\t\t\t\t@SuppressWarnings(\"unchecked,rawtypes\")\n+\t\t\t\tAbstractKeyedStateBackend rawBackend = (AbstractKeyedStateBackend) keyedStateBackend;\n+\n+\t\t\t\trawBackend.setCurrentKey(key);\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tthrow new RuntimeException(\"Exception occurred while setting the current key context.\", e);\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\t@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+\tpublic Object getCurrentKey() {\n+\t\tif (keyedStateBackend != null) {\n+\t\t\treturn keyedStateBackend.getCurrentKey();\n+\t\t} else {\n+\t\t\tthrow new UnsupportedOperationException(\"Key can only be retrieved on KeyedStream.\");\n+\t\t}\n+\t}\n+\n+\tpublic Optional<KeyedStateStore> getKeyedStateStore() {\n+\t\treturn Optional.ofNullable(keyedStateStore);\n+\t}\n+\n+\t/**\n+\t * Returns a {@link InternalTimerService} that can be used to query current processing time\n+\t * and event time and to set timers. An operator can have several timer services, where\n+\t * each has its own namespace serializer. Timer services are differentiated by the string\n+\t * key that is given when requesting them, if you call this method with the same key\n+\t * multiple times you will get the same timer service instance in subsequent requests.\n+\t *\n+\t * <p>Timers are always scoped to a key, the currently active key of a keyed stream operation.\n+\t * When a timer fires, this key will also be set as the currently active key.\n+\t *\n+\t * <p>Each timer has attached metadata, the namespace. Different timer services\n+\t * can have a different namespace type. If you don't need namespace differentiation you\n+\t * can use {@link VoidNamespaceSerializer} as the namespace serializer.\n+\t *\n+\t * @param name The name of the requested timer service. If no service exists under the given\n+\t *             name a new one will be created and returned.\n+\t * @param namespaceSerializer {@code TypeSerializer} for the timer namespace.\n+\t * @param triggerable The {@link Triggerable} that should be invoked when timers fire\n+\t *\n+\t * @param <N> The type of the timer namespace.\n+\t */\n+\tpublic <K, N> InternalTimerService<N> getInternalTimerService(\n+\t\t\tString name,\n+\t\t\tTypeSerializer<N> namespaceSerializer,\n+\t\t\tTriggerable<K, N> triggerable) {\n+\n+\t\tcheckTimerServiceInitialization();\n+\n+\t\t// the following casting is to overcome type restrictions.\n+\t\tKeyedStateBackend<K> keyedStateBackend = getKeyedStateBackend();\n+\t\tTypeSerializer<K> keySerializer = keyedStateBackend.getKeySerializer();\n+\t\tInternalTimeServiceManager<K> keyedTimeServiceHandler = (InternalTimeServiceManager<K>) timeServiceManager;\n+\t\tTimerSerializer<K, N> timerSerializer = new TimerSerializer<>(keySerializer, namespaceSerializer);\n+\t\treturn keyedTimeServiceHandler.getInternalTimerService(name, timerSerializer, triggerable);\n+\t}\n+\n+\tprivate void checkTimerServiceInitialization() {\n+\t\tif (getKeyedStateBackend() == null) {\n+\t\t\tthrow new UnsupportedOperationException(\"Timers can only be used on keyed operators.\");\n+\t\t} else if (timeServiceManager == null) {\n+\t\t\tthrow new RuntimeException(\"The timer service has not been initialized.\");\n+\t\t}\n+\t}\n+\n+\tpublic void advanceWatermark(Watermark mark) throws Exception {\n+\t\tif (timeServiceManager != null) {\n+\t\t\ttimeServiceManager.advanceWatermark(mark);\n+\t\t}\n+\t}\n+\n+\t@VisibleForTesting\n+\tpublic int numProcessingTimeTimers() {\n+\t\treturn timeServiceManager == null ? 0 :\n+\t\t\ttimeServiceManager.numProcessingTimeTimers();\n+\t}\n+\n+\t@VisibleForTesting\n+\tpublic int numEventTimeTimers() {\n+\t\treturn timeServiceManager == null ? 0 :\n+\t\t\ttimeServiceManager.numEventTimeTimers();\n+\t}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI0Njc4MA=="}, "originalCommit": {"oid": "c1facefebee52a1ac84f188f46b114deae0aad89"}, "originalPosition": 429}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDM3MzE3MQ==", "bodyText": "I don't know, but closing doesn't hurt :)", "url": "https://github.com/apache/flink/pull/11403#discussion_r394373171", "createdAt": "2020-03-18T14:08:54Z", "author": {"login": "pnowojski"}, "path": "flink-streaming-java/src/test/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandlerTest.java", "diffHunk": "@@ -0,0 +1,207 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.ListStateDescriptor;\n+import org.apache.flink.api.common.state.ValueStateDescriptor;\n+import org.apache.flink.api.common.typeutils.base.IntSerializer;\n+import org.apache.flink.api.common.typeutils.base.LongSerializer;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.metrics.util.InterceptingOperatorMetricGroup;\n+import org.apache.flink.runtime.operators.testutils.ExpectedTestException;\n+import org.apache.flink.runtime.operators.testutils.MockEnvironmentBuilder;\n+import org.apache.flink.runtime.state.KeyGroupRange;\n+import org.apache.flink.runtime.state.KeyedStateHandle;\n+import org.apache.flink.runtime.state.OperatorStateHandle;\n+import org.apache.flink.runtime.state.SnapshotResult;\n+import org.apache.flink.runtime.state.StateSnapshotContextSynchronousImpl;\n+import org.apache.flink.runtime.state.memory.MemCheckpointStreamFactory;\n+import org.apache.flink.runtime.state.memory.MemoryStateBackend;\n+import org.apache.flink.streaming.runtime.tasks.TestProcessingTimeService;\n+import org.apache.flink.util.ExceptionUtils;\n+\n+import org.junit.Test;\n+\n+import java.util.concurrent.RunnableFuture;\n+import java.util.concurrent.TimeUnit;\n+\n+import static junit.framework.TestCase.assertTrue;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.CoreMatchers.not;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.empty;\n+import static org.junit.Assert.fail;\n+\n+/**\n+ * Tests for {@link StreamOperatorStateHandlerTest}.\n+ */\n+public class StreamOperatorStateHandlerTest {\n+\t/**\n+\t * Tests that a failing snapshot method call to the keyed state backend will trigger the closing\n+\t * of the StateSnapshotContextSynchronousImpl and the cancellation of the\n+\t * OperatorSnapshotResult. The latter is supposed to also cancel all assigned futures.\n+\t */\n+\t@Test\n+\tpublic void testFailingBackendSnapshotMethod() throws Exception {\n+\t\tfinal long checkpointId = 42L;\n+\t\tfinal long timestamp = 1L;\n+\n+\t\tfinal CloseableRegistry closeableRegistry = new CloseableRegistry();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkwMzYxMA=="}, "originalCommit": {"oid": "9cce09936e14e63d8bef95bff57d0e2f2401e1f0"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDM3NDg4Ng==", "bodyText": "I need it only to pass some checkState, but sure, I can change it to \"44\" if it makes any difference.", "url": "https://github.com/apache/flink/pull/11403#discussion_r394374886", "createdAt": "2020-03-18T14:11:18Z", "author": {"login": "pnowojski"}, "path": "flink-streaming-java/src/test/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandlerTest.java", "diffHunk": "@@ -0,0 +1,207 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.ListStateDescriptor;\n+import org.apache.flink.api.common.state.ValueStateDescriptor;\n+import org.apache.flink.api.common.typeutils.base.IntSerializer;\n+import org.apache.flink.api.common.typeutils.base.LongSerializer;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.metrics.util.InterceptingOperatorMetricGroup;\n+import org.apache.flink.runtime.operators.testutils.ExpectedTestException;\n+import org.apache.flink.runtime.operators.testutils.MockEnvironmentBuilder;\n+import org.apache.flink.runtime.state.KeyGroupRange;\n+import org.apache.flink.runtime.state.KeyedStateHandle;\n+import org.apache.flink.runtime.state.OperatorStateHandle;\n+import org.apache.flink.runtime.state.SnapshotResult;\n+import org.apache.flink.runtime.state.StateSnapshotContextSynchronousImpl;\n+import org.apache.flink.runtime.state.memory.MemCheckpointStreamFactory;\n+import org.apache.flink.runtime.state.memory.MemoryStateBackend;\n+import org.apache.flink.streaming.runtime.tasks.TestProcessingTimeService;\n+import org.apache.flink.util.ExceptionUtils;\n+\n+import org.junit.Test;\n+\n+import java.util.concurrent.RunnableFuture;\n+import java.util.concurrent.TimeUnit;\n+\n+import static junit.framework.TestCase.assertTrue;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.CoreMatchers.not;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.empty;\n+import static org.junit.Assert.fail;\n+\n+/**\n+ * Tests for {@link StreamOperatorStateHandlerTest}.\n+ */\n+public class StreamOperatorStateHandlerTest {\n+\t/**\n+\t * Tests that a failing snapshot method call to the keyed state backend will trigger the closing\n+\t * of the StateSnapshotContextSynchronousImpl and the cancellation of the\n+\t * OperatorSnapshotResult. The latter is supposed to also cancel all assigned futures.\n+\t */\n+\t@Test\n+\tpublic void testFailingBackendSnapshotMethod() throws Exception {\n+\t\tfinal long checkpointId = 42L;\n+\t\tfinal long timestamp = 1L;\n+\n+\t\tfinal CloseableRegistry closeableRegistry = new CloseableRegistry();\n+\n+\t\tRunnableFuture<SnapshotResult<KeyedStateHandle>> keyedStateManagedFuture = new CancelableFuture<>();\n+\t\tRunnableFuture<SnapshotResult<KeyedStateHandle>> keyedStateRawFuture = new CancelableFuture<>();\n+\t\tRunnableFuture<SnapshotResult<OperatorStateHandle>> operatorStateManagedFuture = new CancelableFuture<>();\n+\t\tRunnableFuture<SnapshotResult<OperatorStateHandle>> operatorStateRawFuture = new CancelableFuture<>();\n+\n+\t\tOperatorSnapshotFutures operatorSnapshotResult = new OperatorSnapshotFutures(\n+\t\t\tkeyedStateManagedFuture,\n+\t\t\tkeyedStateRawFuture,\n+\t\t\toperatorStateManagedFuture,\n+\t\t\toperatorStateRawFuture);\n+\n+\t\tStateSnapshotContextSynchronousImpl context = new TestStateSnapshotContextSynchronousImpl(checkpointId, timestamp, closeableRegistry);\n+\t\tcontext.getRawKeyedOperatorStateOutput();\n+\t\tcontext.getRawOperatorStateOutput();\n+\n+\t\tStreamTaskStateInitializerImpl stateInitializer =\n+\t\t\tnew StreamTaskStateInitializerImpl(new MockEnvironmentBuilder().build(), new MemoryStateBackend());\n+\t\tStreamOperatorStateContext stateContext = stateInitializer.streamOperatorStateContext(\n+\t\t\tnew OperatorID(),\n+\t\t\t\"whatever\",\n+\t\t\tnew TestProcessingTimeService(),\n+\t\t\tnew UnUsedKeyContext(),\n+\t\t\tIntSerializer.INSTANCE,\n+\t\t\tcloseableRegistry,\n+\t\t\tnew InterceptingOperatorMetricGroup());\n+\t\tStreamOperatorStateHandler stateHandler = new StreamOperatorStateHandler(stateContext, new ExecutionConfig(), closeableRegistry);\n+\n+\t\tfinal String keyedStateField = \"keyedStateField\";\n+\t\tfinal String operatorStateField = \"operatorStateField\";\n+\n+\t\tstateHandler.setCurrentKey(44L);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkwNTU3OQ=="}, "originalCommit": {"oid": "9cce09936e14e63d8bef95bff57d0e2f2401e1f0"}, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDM3NTY3NA==", "bodyText": "You do realize that you are punishing the messenger here?\nMost of the cases are still tested in AbstractStreamOperatorTest (FYI, I will try to provide equivalent of those tests for the new base class once watermarks and other things are also implemented).", "url": "https://github.com/apache/flink/pull/11403#discussion_r394375674", "createdAt": "2020-03-18T14:12:21Z", "author": {"login": "pnowojski"}, "path": "flink-streaming-java/src/test/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandlerTest.java", "diffHunk": "@@ -0,0 +1,207 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.ListStateDescriptor;\n+import org.apache.flink.api.common.state.ValueStateDescriptor;\n+import org.apache.flink.api.common.typeutils.base.IntSerializer;\n+import org.apache.flink.api.common.typeutils.base.LongSerializer;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.metrics.util.InterceptingOperatorMetricGroup;\n+import org.apache.flink.runtime.operators.testutils.ExpectedTestException;\n+import org.apache.flink.runtime.operators.testutils.MockEnvironmentBuilder;\n+import org.apache.flink.runtime.state.KeyGroupRange;\n+import org.apache.flink.runtime.state.KeyedStateHandle;\n+import org.apache.flink.runtime.state.OperatorStateHandle;\n+import org.apache.flink.runtime.state.SnapshotResult;\n+import org.apache.flink.runtime.state.StateSnapshotContextSynchronousImpl;\n+import org.apache.flink.runtime.state.memory.MemCheckpointStreamFactory;\n+import org.apache.flink.runtime.state.memory.MemoryStateBackend;\n+import org.apache.flink.streaming.runtime.tasks.TestProcessingTimeService;\n+import org.apache.flink.util.ExceptionUtils;\n+\n+import org.junit.Test;\n+\n+import java.util.concurrent.RunnableFuture;\n+import java.util.concurrent.TimeUnit;\n+\n+import static junit.framework.TestCase.assertTrue;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.CoreMatchers.not;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.empty;\n+import static org.junit.Assert.fail;\n+\n+/**\n+ * Tests for {@link StreamOperatorStateHandlerTest}.\n+ */\n+public class StreamOperatorStateHandlerTest {\n+\t/**\n+\t * Tests that a failing snapshot method call to the keyed state backend will trigger the closing\n+\t * of the StateSnapshotContextSynchronousImpl and the cancellation of the\n+\t * OperatorSnapshotResult. The latter is supposed to also cancel all assigned futures.\n+\t */\n+\t@Test\n+\tpublic void testFailingBackendSnapshotMethod() throws Exception {\n+\t\tfinal long checkpointId = 42L;\n+\t\tfinal long timestamp = 1L;\n+\n+\t\tfinal CloseableRegistry closeableRegistry = new CloseableRegistry();\n+\n+\t\tRunnableFuture<SnapshotResult<KeyedStateHandle>> keyedStateManagedFuture = new CancelableFuture<>();\n+\t\tRunnableFuture<SnapshotResult<KeyedStateHandle>> keyedStateRawFuture = new CancelableFuture<>();\n+\t\tRunnableFuture<SnapshotResult<OperatorStateHandle>> operatorStateManagedFuture = new CancelableFuture<>();\n+\t\tRunnableFuture<SnapshotResult<OperatorStateHandle>> operatorStateRawFuture = new CancelableFuture<>();\n+\n+\t\tOperatorSnapshotFutures operatorSnapshotResult = new OperatorSnapshotFutures(\n+\t\t\tkeyedStateManagedFuture,\n+\t\t\tkeyedStateRawFuture,\n+\t\t\toperatorStateManagedFuture,\n+\t\t\toperatorStateRawFuture);\n+\n+\t\tStateSnapshotContextSynchronousImpl context = new TestStateSnapshotContextSynchronousImpl(checkpointId, timestamp, closeableRegistry);\n+\t\tcontext.getRawKeyedOperatorStateOutput();\n+\t\tcontext.getRawOperatorStateOutput();\n+\n+\t\tStreamTaskStateInitializerImpl stateInitializer =\n+\t\t\tnew StreamTaskStateInitializerImpl(new MockEnvironmentBuilder().build(), new MemoryStateBackend());\n+\t\tStreamOperatorStateContext stateContext = stateInitializer.streamOperatorStateContext(\n+\t\t\tnew OperatorID(),\n+\t\t\t\"whatever\",\n+\t\t\tnew TestProcessingTimeService(),\n+\t\t\tnew UnUsedKeyContext(),\n+\t\t\tIntSerializer.INSTANCE,\n+\t\t\tcloseableRegistry,\n+\t\t\tnew InterceptingOperatorMetricGroup());\n+\t\tStreamOperatorStateHandler stateHandler = new StreamOperatorStateHandler(stateContext, new ExecutionConfig(), closeableRegistry);\n+\n+\t\tfinal String keyedStateField = \"keyedStateField\";\n+\t\tfinal String operatorStateField = \"operatorStateField\";\n+\n+\t\tstateHandler.setCurrentKey(44L);\n+\t\tstateHandler.initializeOperatorState(stateSnapshotContext -> {\n+\t\t\tstateSnapshotContext.getKeyedStateStore()\n+\t\t\t\t.getState(new ValueStateDescriptor<>(keyedStateField, LongSerializer.INSTANCE))\n+\t\t\t\t.update(42L);\n+\t\t\tstateSnapshotContext.getOperatorStateStore()\n+\t\t\t\t.getListState(new ListStateDescriptor<>(operatorStateField, LongSerializer.INSTANCE))\n+\t\t\t\t.add(42L);\n+\t\t});\n+\n+\t\tassertThat(stateContext.operatorStateBackend().getRegisteredStateNames(), is(not(empty())));\n+\t\tassertThat(stateContext.keyedStateBackend().numKeyValueStatesByName(), equalTo(1));\n+\n+\t\ttry {\n+\t\t\tstateHandler.snapshotState(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkwNjA4MA=="}, "originalCommit": {"oid": "9cce09936e14e63d8bef95bff57d0e2f2401e1f0"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDQwNTQ2Ng==", "bodyText": "I will go with StreamOperatorParameters", "url": "https://github.com/apache/flink/pull/11403#discussion_r394405466", "createdAt": "2020-03-18T14:51:10Z", "author": {"login": "pnowojski"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/functions/source/ContinuousFileReaderOperatorFactory.java", "diffHunk": "@@ -58,11 +56,11 @@ public void setMailboxExecutor(MailboxExecutor mailboxExecutor) {\n \t}\n \n \t@Override\n-\tpublic StreamOperator createStreamOperator(StreamTask containingTask, StreamConfig config, Output output) {\n+\tpublic <T extends StreamOperator<OUT>> T createStreamOperator(StreamOperatorInitializer<OUT> initializer) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkxNDI2OA=="}, "originalCommit": {"oid": "73b6e6e569d5ccac8bd56c593ba3f8bf5caec9c7"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDgyMzkwMA==", "bodyText": "I agree and I don't remember what was the reason behind the template argument here, maybe it was just some error that went under our radar when reviewing/merging. Definitely trying to fix it is on my to do list.\nCurrently I would lean towards option 2. But I don't want to change status quo right know, as the PR is already pretty big and I don't know if that will not explode into some larger change/fix - especially that I'm not sure that there might be some reason behind this construct?", "url": "https://github.com/apache/flink/pull/11403#discussion_r394823900", "createdAt": "2020-03-19T07:01:40Z", "author": {"login": "pnowojski"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorFactory.java", "diffHunk": "@@ -32,14 +30,13 @@\n  *\n  * @param <OUT> The output type of the operator\n  */\n-@Internal\n+@PublicEvolving\n public interface StreamOperatorFactory<OUT> extends Serializable {\n \n \t/**\n \t * Create the operator. Sets access to the context and the output.\n \t */\n-\t<T extends StreamOperator<OUT>> T createStreamOperator(\n-\t\t\tStreamTask<?, ?> containingTask, StreamConfig config, Output<StreamRecord<OUT>> output);\n+\t<T extends StreamOperator<OUT>> T createStreamOperator(StreamOperatorInitializer<OUT> initializer);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI1ODE4MQ=="}, "originalCommit": {"oid": "c1facefebee52a1ac84f188f46b114deae0aad89"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDgyODg0Ng==", "bodyText": "Note for that goal, we would need to get rid of SimpleOperatorFactory: Once an operator has been created, it cannot go back into factory. If we need to functionality, then I only see builder pattern as a clean solution, where going back and forth between operator and operator builder is doable\n\nSimpleOperatorFactory is not intended to make possible to go back and forth between operators and factories, but just to provide backward compatible class for transporting SetupableStreamOperator classes. Also as it's intended to be removed in the future (we can do it as that's PublicEvolving API), in the design let's assume SimpleOperatorFactory doesn't exist.\nBut @AHeise, what do you think we should do with ProcessingTimeServiceAware? @Deprecate and mark it for removal? Or Should I do it in this PR?", "url": "https://github.com/apache/flink/pull/11403#discussion_r394828846", "createdAt": "2020-03-19T07:16:24Z", "author": {"login": "pnowojski"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorFactoryUtil.java", "diffHunk": "@@ -57,7 +57,13 @@\n \t\t\t((ProcessingTimeServiceAware) operatorFactory).setProcessingTimeService(processingTimeService);\n \t\t}\n \n-\t\tOP op = operatorFactory.createStreamOperator(containingTask, configuration, output);\n+\t\t// TODO: what to do with ProcessingTimeServiceAware?\n+\t\tOP op = operatorFactory.createStreamOperator(\n+\t\t\tnew StreamOperatorInitializer<>(\n+\t\t\t\tcontainingTask,\n+\t\t\t\tconfiguration,\n+\t\t\t\toutput,\n+\t\t\t\tprocessingTimeService));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjIwMTUwMg=="}, "originalCommit": {"oid": "c7595ee5eb7ac60dae52bcd1368878d70d372533"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDgyODk1MQ==", "bodyText": "Let's keep it simple for now.", "url": "https://github.com/apache/flink/pull/11403#discussion_r394828951", "createdAt": "2020-03-19T07:16:46Z", "author": {"login": "pnowojski"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorInitializer.java", "diffHunk": "@@ -0,0 +1,65 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.Experimental;\n+import org.apache.flink.streaming.api.graph.StreamConfig;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.tasks.ProcessingTimeService;\n+import org.apache.flink.streaming.runtime.tasks.StreamTask;\n+\n+/**\n+ * Helper  class to construct {@link StreamOperatorBase}. Wraps couple of internal parameters\n+ * to simplify for users construction of classes extending {@link StreamOperatorBase} and to\n+ * allow for backward compatible changes in the {@link StreamOperatorBase}'s constructor.\n+ */\n+@Experimental\n+public class StreamOperatorInitializer<OUT> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkyNTA5MA=="}, "originalCommit": {"oid": "73b6e6e569d5ccac8bd56c593ba3f8bf5caec9c7"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDgyOTkzNg==", "bodyText": "Do you mean adding java doc? I've added it.", "url": "https://github.com/apache/flink/pull/11403#discussion_r394829936", "createdAt": "2020-03-19T07:19:40Z", "author": {"login": "pnowojski"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorInitializer.java", "diffHunk": "@@ -0,0 +1,65 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.Experimental;\n+import org.apache.flink.streaming.api.graph.StreamConfig;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.tasks.ProcessingTimeService;\n+import org.apache.flink.streaming.runtime.tasks.StreamTask;\n+\n+/**\n+ * Helper  class to construct {@link StreamOperatorBase}. Wraps couple of internal parameters\n+ * to simplify for users construction of classes extending {@link StreamOperatorBase} and to\n+ * allow for backward compatible changes in the {@link StreamOperatorBase}'s constructor.\n+ */\n+@Experimental\n+public class StreamOperatorInitializer<OUT> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkyNTgxNA=="}, "originalCommit": {"oid": "73b6e6e569d5ccac8bd56c593ba3f8bf5caec9c7"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDgzMTg3Mw==", "bodyText": "I know, but I had to do it for now, because of compile errors:\nError:(62, 31) java: name clash: createStreamOperator(org.apache.flink.streaming.api.operators.StreamOperatorParameters<OUT>) in org.apache.flink.streaming.api.operators.async.AsyncWaitOperatorFactory and <T>createStreamOperator(org.apache.flink.streaming.api.operators.StreamOperatorParameters<OUT>) in org.apache.flink.streaming.api.operators.StreamOperatorFactory have the same erasure, yet neither overrides the other", "url": "https://github.com/apache/flink/pull/11403#discussion_r394831873", "createdAt": "2020-03-19T07:25:22Z", "author": {"login": "pnowojski"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/async/AsyncWaitOperatorFactory.java", "diffHunk": "@@ -61,16 +59,16 @@ public void setMailboxExecutor(MailboxExecutor mailboxExecutor) {\n \t}\n \n \t@Override\n-\tpublic StreamOperator createStreamOperator(StreamTask containingTask, StreamConfig config, Output output) {\n+\tpublic <T extends StreamOperator<OUT>> T createStreamOperator(StreamOperatorInitializer<OUT> initializer) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkyNzYxMQ=="}, "originalCommit": {"oid": "73b6e6e569d5ccac8bd56c593ba3f8bf5caec9c7"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDg0MzYzOA==", "bodyText": "Renamed to AbstractStreamOperatorV2", "url": "https://github.com/apache/flink/pull/11403#discussion_r394843638", "createdAt": "2020-03-19T07:54:57Z", "author": {"login": "pnowojski"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorBase.java", "diffHunk": "@@ -0,0 +1,484 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.Experimental;\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.KeyedStateStore;\n+import org.apache.flink.api.common.state.State;\n+import org.apache.flink.api.common.state.StateDescriptor;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.java.functions.KeySelector;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.configuration.MetricOptions;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.metrics.MetricGroup;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.execution.Environment;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.metrics.groups.OperatorMetricGroup;\n+import org.apache.flink.runtime.metrics.groups.TaskManagerJobMetricGroup;\n+import org.apache.flink.runtime.metrics.groups.UnregisteredMetricGroups;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.KeyedStateBackend;\n+import org.apache.flink.runtime.state.OperatorStateBackend;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.runtime.state.VoidNamespace;\n+import org.apache.flink.runtime.state.VoidNamespaceSerializer;\n+import org.apache.flink.streaming.api.graph.StreamConfig;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.streamrecord.LatencyMarker;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.tasks.ProcessingTimeService;\n+import org.apache.flink.streaming.runtime.tasks.StreamTask;\n+import org.apache.flink.streaming.util.LatencyStats;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Arrays;\n+import java.util.Locale;\n+import java.util.Optional;\n+\n+/**\n+ * New base class for all stream operators, replacing previous {@link AbstractStreamOperator}.\n+ * Currently intended to work with {@link MultipleInputStreamOperator}.\n+ *\n+ * <p>One note-able difference in comparison to {@link AbstractStreamOperator} is lack of\n+ * {@link AbstractStreamOperator#setup(StreamTask, StreamConfig, Output)} in favor of initialisation\n+ * in the constructor, and removed some tight coupling with classes like {@link StreamTask}.\n+ *\n+ * <p>Methods are guaranteed not to be called concurrently.\n+ *\n+ * @param <OUT> The output type of the operator\n+ */\n+@Experimental\n+public abstract class StreamOperatorBase<OUT> implements StreamOperator<OUT> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjIwMjAzMg=="}, "originalCommit": {"oid": "c7595ee5eb7ac60dae52bcd1368878d70d372533"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDg0MzkzOA==", "bodyText": "Yes, initializeState annoyed me as well :/ But one step at a time.", "url": "https://github.com/apache/flink/pull/11403#discussion_r394843938", "createdAt": "2020-03-19T07:55:36Z", "author": {"login": "pnowojski"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorBase.java", "diffHunk": "@@ -0,0 +1,488 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.Experimental;\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.KeyedStateStore;\n+import org.apache.flink.api.common.state.State;\n+import org.apache.flink.api.common.state.StateDescriptor;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.java.functions.KeySelector;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.configuration.MetricOptions;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.metrics.MetricGroup;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.execution.Environment;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.metrics.groups.OperatorMetricGroup;\n+import org.apache.flink.runtime.metrics.groups.TaskManagerJobMetricGroup;\n+import org.apache.flink.runtime.metrics.groups.UnregisteredMetricGroups;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.KeyedStateBackend;\n+import org.apache.flink.runtime.state.OperatorStateBackend;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.runtime.state.VoidNamespace;\n+import org.apache.flink.runtime.state.VoidNamespaceSerializer;\n+import org.apache.flink.streaming.api.graph.StreamConfig;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.streamrecord.LatencyMarker;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.tasks.ProcessingTimeService;\n+import org.apache.flink.streaming.runtime.tasks.StreamTask;\n+import org.apache.flink.streaming.util.LatencyStats;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Arrays;\n+import java.util.Locale;\n+import java.util.Optional;\n+\n+/**\n+ * New base class for all stream operators, replacing previous {@link AbstractStreamOperator}.\n+ * Currently intended to work with {@link MultipleInputStreamOperator}.\n+ *\n+ * <p>One note-able difference in comparison to {@link AbstractStreamOperator} is lack of\n+ * {@link AbstractStreamOperator#setup(StreamTask, StreamConfig, Output)} in favor of initialisation\n+ * in the constructor, and removed some tight coupling with classes like {@link StreamTask}.\n+ *\n+ * <p>Methods are guaranteed not to be called concurrently.\n+ *\n+ * @param <OUT> The output type of the operator\n+ */\n+@Experimental\n+public abstract class StreamOperatorBase<OUT> implements StreamOperator<OUT> {\n+\t/** The logger used by the operator class and its subclasses. */\n+\tprotected static final Logger LOG = LoggerFactory.getLogger(StreamOperatorBase.class);\n+\n+\tprotected final StreamConfig config;\n+\tprotected final Output<StreamRecord<OUT>> output;\n+\tprivate final StreamingRuntimeContext runtimeContext;\n+\tprivate final ExecutionConfig executionConfig;\n+\tprivate final ClassLoader userCodeClassLoader;\n+\tprivate final CloseableRegistry cancelables;\n+\tprivate final long[] inputWatermarks;\n+\n+\t/** Metric group for the operator. */\n+\tprotected final OperatorMetricGroup metrics;\n+\tprotected final LatencyStats latencyStats;\n+\tprotected final ProcessingTimeService processingTimeService;\n+\n+\tprivate StreamOperatorStateHandler stateHandler;\n+\n+\t// We keep track of watermarks from both inputs, the combined input is the minimum\n+\t// Once the minimum advances we emit a new watermark for downstream operators\n+\tprivate long combinedWatermark = Long.MIN_VALUE;\n+\n+\tpublic StreamOperatorBase(StreamOperatorInitializer<OUT> initializer, int numberOfInputs) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkzMDgxMw=="}, "originalCommit": {"oid": "4c4ec9eb40a8efc96897d0c0b4c6c27755f2ed7c"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDg0ODg3Mg==", "bodyText": "At least for now, not really. This and other methods are being used in different places outside of an operator. Some just in tests, others not only. I would prefer to keep it as is in the first iteration using assumption, that if it was exposed before, there were some reasons behind it. Especially to make transitions from V1 to V2 as smooth as possible.", "url": "https://github.com/apache/flink/pull/11403#discussion_r394848872", "createdAt": "2020-03-19T08:07:24Z", "author": {"login": "pnowojski"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorBase.java", "diffHunk": "@@ -0,0 +1,488 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.Experimental;\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.KeyedStateStore;\n+import org.apache.flink.api.common.state.State;\n+import org.apache.flink.api.common.state.StateDescriptor;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.java.functions.KeySelector;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.configuration.MetricOptions;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.metrics.MetricGroup;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.execution.Environment;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.metrics.groups.OperatorMetricGroup;\n+import org.apache.flink.runtime.metrics.groups.TaskManagerJobMetricGroup;\n+import org.apache.flink.runtime.metrics.groups.UnregisteredMetricGroups;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.KeyedStateBackend;\n+import org.apache.flink.runtime.state.OperatorStateBackend;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.runtime.state.VoidNamespace;\n+import org.apache.flink.runtime.state.VoidNamespaceSerializer;\n+import org.apache.flink.streaming.api.graph.StreamConfig;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.streamrecord.LatencyMarker;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.tasks.ProcessingTimeService;\n+import org.apache.flink.streaming.runtime.tasks.StreamTask;\n+import org.apache.flink.streaming.util.LatencyStats;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Arrays;\n+import java.util.Locale;\n+import java.util.Optional;\n+\n+/**\n+ * New base class for all stream operators, replacing previous {@link AbstractStreamOperator}.\n+ * Currently intended to work with {@link MultipleInputStreamOperator}.\n+ *\n+ * <p>One note-able difference in comparison to {@link AbstractStreamOperator} is lack of\n+ * {@link AbstractStreamOperator#setup(StreamTask, StreamConfig, Output)} in favor of initialisation\n+ * in the constructor, and removed some tight coupling with classes like {@link StreamTask}.\n+ *\n+ * <p>Methods are guaranteed not to be called concurrently.\n+ *\n+ * @param <OUT> The output type of the operator\n+ */\n+@Experimental\n+public abstract class StreamOperatorBase<OUT> implements StreamOperator<OUT> {\n+\t/** The logger used by the operator class and its subclasses. */\n+\tprotected static final Logger LOG = LoggerFactory.getLogger(StreamOperatorBase.class);\n+\n+\tprotected final StreamConfig config;\n+\tprotected final Output<StreamRecord<OUT>> output;\n+\tprivate final StreamingRuntimeContext runtimeContext;\n+\tprivate final ExecutionConfig executionConfig;\n+\tprivate final ClassLoader userCodeClassLoader;\n+\tprivate final CloseableRegistry cancelables;\n+\tprivate final long[] inputWatermarks;\n+\n+\t/** Metric group for the operator. */\n+\tprotected final OperatorMetricGroup metrics;\n+\tprotected final LatencyStats latencyStats;\n+\tprotected final ProcessingTimeService processingTimeService;\n+\n+\tprivate StreamOperatorStateHandler stateHandler;\n+\n+\t// We keep track of watermarks from both inputs, the combined input is the minimum\n+\t// Once the minimum advances we emit a new watermark for downstream operators\n+\tprivate long combinedWatermark = Long.MIN_VALUE;\n+\n+\tpublic StreamOperatorBase(StreamOperatorInitializer<OUT> initializer, int numberOfInputs) {\n+\t\tinputWatermarks = new long[numberOfInputs];\n+\t\tArrays.fill(inputWatermarks, Long.MIN_VALUE);\n+\t\tfinal Environment environment = initializer.getContainingTask().getEnvironment();\n+\t\tconfig = initializer.getStreamConfig();\n+\t\tCountingOutput<OUT> countingOutput;\n+\t\tOperatorMetricGroup operatorMetricGroup;\n+\t\ttry {\n+\t\t\toperatorMetricGroup = environment.getMetricGroup().getOrAddOperator(config.getOperatorID(), config.getOperatorName());\n+\t\t\tcountingOutput = new CountingOutput(initializer.getOutput(), operatorMetricGroup.getIOMetricGroup().getNumRecordsOutCounter());\n+\t\t\tif (config.isChainStart()) {\n+\t\t\t\toperatorMetricGroup.getIOMetricGroup().reuseInputMetricsForTask();\n+\t\t\t}\n+\t\t\tif (config.isChainEnd()) {\n+\t\t\t\toperatorMetricGroup.getIOMetricGroup().reuseOutputMetricsForTask();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\tLOG.warn(\"An error occurred while instantiating task metrics.\", e);\n+\t\t\tcountingOutput = null;\n+\t\t\toperatorMetricGroup = null;\n+\t\t}\n+\n+\t\tif (countingOutput == null || operatorMetricGroup == null) {\n+\t\t\tmetrics = UnregisteredMetricGroups.createUnregisteredOperatorMetricGroup();\n+\t\t\toutput = initializer.getOutput();\n+\t\t}\n+\t\telse {\n+\t\t\tmetrics = operatorMetricGroup;\n+\t\t\toutput = countingOutput;\n+\t\t}\n+\n+\t\tlatencyStats = createLatencyStats(\n+\t\t\tenvironment.getTaskManagerInfo().getConfiguration(),\n+\t\t\tinitializer.getContainingTask().getIndexInSubtaskGroup());\n+\n+\t\tprocessingTimeService = Preconditions.checkNotNull(initializer.getProcessingTimeService());\n+\t\texecutionConfig = initializer.getContainingTask().getExecutionConfig();\n+\t\tuserCodeClassLoader = initializer.getContainingTask().getUserCodeClassLoader();\n+\t\tcancelables = initializer.getContainingTask().getCancelables();\n+\n+\t\truntimeContext = new StreamingRuntimeContext(\n+\t\t\tenvironment,\n+\t\t\tinitializer.getContainingTask().getAccumulatorMap(),\n+\t\t\toperatorMetricGroup,\n+\t\t\tgetOperatorID(),\n+\t\t\tprocessingTimeService,\n+\t\t\tnull);\n+\t}\n+\n+\tprivate LatencyStats createLatencyStats(Configuration taskManagerConfig, int indexInSubtaskGroup) {\n+\t\ttry {\n+\t\t\tint historySize = taskManagerConfig.getInteger(MetricOptions.LATENCY_HISTORY_SIZE);\n+\t\t\tif (historySize <= 0) {\n+\t\t\t\tLOG.warn(\"{} has been set to a value equal or below 0: {}. Using default.\", MetricOptions.LATENCY_HISTORY_SIZE, historySize);\n+\t\t\t\thistorySize = MetricOptions.LATENCY_HISTORY_SIZE.defaultValue();\n+\t\t\t}\n+\n+\t\t\tfinal String configuredGranularity = taskManagerConfig.getString(MetricOptions.LATENCY_SOURCE_GRANULARITY);\n+\t\t\tLatencyStats.Granularity granularity;\n+\t\t\ttry {\n+\t\t\t\tgranularity = LatencyStats.Granularity.valueOf(configuredGranularity.toUpperCase(Locale.ROOT));\n+\t\t\t} catch (IllegalArgumentException iae) {\n+\t\t\t\tgranularity = LatencyStats.Granularity.OPERATOR;\n+\t\t\t\tLOG.warn(\n+\t\t\t\t\t\"Configured value {} option for {} is invalid. Defaulting to {}.\",\n+\t\t\t\t\tconfiguredGranularity,\n+\t\t\t\t\tMetricOptions.LATENCY_SOURCE_GRANULARITY.key(),\n+\t\t\t\t\tgranularity);\n+\t\t\t}\n+\t\t\tTaskManagerJobMetricGroup jobMetricGroup = this.metrics.parent().parent();\n+\t\t\treturn new LatencyStats(jobMetricGroup.addGroup(\"latency\"),\n+\t\t\t\thistorySize,\n+\t\t\t\tindexInSubtaskGroup,\n+\t\t\t\tgetOperatorID(),\n+\t\t\t\tgranularity);\n+\t\t} catch (Exception e) {\n+\t\t\tLOG.warn(\"An error occurred while instantiating latency metrics.\", e);\n+\t\t\treturn new LatencyStats(\n+\t\t\t\tUnregisteredMetricGroups.createUnregisteredTaskManagerJobMetricGroup().addGroup(\"latency\"),\n+\t\t\t\t1,\n+\t\t\t\t0,\n+\t\t\t\tnew OperatorID(),\n+\t\t\t\tLatencyStats.Granularity.SINGLE);\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic MetricGroup getMetricGroup() {\n+\t\treturn metrics;\n+\t}\n+\n+\t@Override\n+\tpublic final void initializeState(StreamTaskStateInitializer streamTaskStateManager) throws Exception {\n+\t\tfinal TypeSerializer<?> keySerializer = config.getStateKeySerializer(getUserCodeClassloader());\n+\n+\t\tfinal StreamOperatorStateContext context =\n+\t\t\tstreamTaskStateManager.streamOperatorStateContext(\n+\t\t\t\tgetOperatorID(),\n+\t\t\t\tgetClass().getSimpleName(),\n+\t\t\t\tgetProcessingTimeService(),\n+\t\t\t\tthis,\n+\t\t\t\tkeySerializer,\n+\t\t\t\tcancelables,\n+\t\t\t\tmetrics);\n+\n+\t\tstateHandler = new StreamOperatorStateHandler(context, getExecutionConfig(), cancelables);\n+\t\tstateHandler.initializeOperatorState(this::initializeState);\n+\t}\n+\n+\t/**\n+\t * This method is called immediately before any elements are processed, it should contain the\n+\t * operator's initialization logic, e.g. state initialization.\n+\t *\n+\t * <p>The default implementation does nothing.\n+\t *\n+\t * @throws Exception An exception in this method causes the operator to fail.\n+\t */\n+\t@Override\n+\tpublic void open() throws Exception {}\n+\n+\t/**\n+\t * This method is called after all records have been added to the operators via the methods\n+\t * {@link OneInputStreamOperator#processElement(StreamRecord)}, or\n+\t * {@link TwoInputStreamOperator#processElement1(StreamRecord)} and\n+\t * {@link TwoInputStreamOperator#processElement2(StreamRecord)}.\n+\t *\n+\t * <p>The method is expected to flush all remaining buffered data. Exceptions during this flushing\n+\t * of buffered should be propagated, in order to cause the operation to be recognized asa failed,\n+\t * because the last data items are not processed properly.\n+\t *\n+\t * @throws Exception An exception in this method causes the operator to fail.\n+\t */\n+\t@Override\n+\tpublic void close() throws Exception {}\n+\n+\t/**\n+\t * This method is called at the very end of the operator's life, both in the case of a successful\n+\t * completion of the operation, and in the case of a failure and canceling.\n+\t *\n+\t * <p>This method is expected to make a thorough effort to release all resources\n+\t * that the operator has acquired.\n+\t */\n+\t@Override\n+\tpublic void dispose() throws Exception {\n+\t\tif (stateHandler != null) {\n+\t\t\tstateHandler.dispose();\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void prepareSnapshotPreBarrier(long checkpointId) throws Exception {\n+\t\t// the default implementation does nothing and accepts the checkpoint\n+\t\t// this is purely for subclasses to override\n+\t}\n+\n+\t@Override\n+\tpublic final OperatorSnapshotFutures snapshotState(long checkpointId, long timestamp, CheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory) throws Exception {\n+\t\treturn stateHandler.snapshotState(\n+\t\t\tthis::snapshotState,\n+\t\t\tgetOperatorName(),\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tcheckpointOptions,\n+\t\t\tfactory);\n+\t}\n+\n+\t/**\n+\t * Stream operators with state, which want to participate in a snapshot need to override this hook method.\n+\t *\n+\t * @param context context that provides information and means required for taking a snapshot\n+\t */\n+\tpublic void snapshotState(StateSnapshotContext context) throws Exception {\n+\t}\n+\n+\t/**\n+\t * Stream operators with state which can be restored need to override this hook method.\n+\t *\n+\t * @param context context that allows to register different states.\n+\t */\n+\tpublic void initializeState(StateInitializationContext context) throws Exception {\n+\n+\t}\n+\n+\t@Override\n+\tpublic void notifyCheckpointComplete(long checkpointId) throws Exception {\n+\t\tstateHandler.notifyCheckpointComplete(checkpointId);\n+\t}\n+\n+\t// ------------------------------------------------------------------------\n+\t//  Properties and Services\n+\t// ------------------------------------------------------------------------\n+\n+\t/**\n+\t * Gets the execution config defined on the execution environment of the job to which this\n+\t * operator belongs.\n+\t *\n+\t * @return The job's execution config.\n+\t */\n+\tpublic ExecutionConfig getExecutionConfig() {\n+\t\treturn executionConfig;\n+\t}\n+\n+\tpublic StreamConfig getOperatorConfig() {\n+\t\treturn config;\n+\t}\n+\n+\tpublic ClassLoader getUserCodeClassloader() {\n+\t\treturn userCodeClassLoader;\n+\t}\n+\n+\t/**\n+\t * Return the operator name. If the runtime context has been set, then the task name with\n+\t * subtask index is returned. Otherwise, the simple class name is returned.\n+\t *\n+\t * @return If runtime context is set, then return task name with subtask index. Otherwise return\n+\t * \t\t\tsimple class name.\n+\t */\n+\tprotected String getOperatorName() {\n+\t\tif (runtimeContext != null) {\n+\t\t\treturn runtimeContext.getTaskNameWithSubtasks();\n+\t\t} else {\n+\t\t\treturn getClass().getSimpleName();\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Returns a context that allows the operator to query information about the execution and also\n+\t * to interact with systems such as broadcast variables and managed state. This also allows\n+\t * to register timers.\n+\t */\n+\tpublic StreamingRuntimeContext getRuntimeContext() {\n+\t\treturn runtimeContext;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic <K> KeyedStateBackend<K> getKeyedStateBackend() {\n+\t\treturn (KeyedStateBackend<K>) stateHandler.getKeyedStateBackend();\n+\t}\n+\n+\tpublic OperatorStateBackend getOperatorStateBackend() {\n+\t\treturn stateHandler.getOperatorStateBackend();\n+\t}\n+\n+\t/**\n+\t * Returns the {@link ProcessingTimeService} responsible for getting the current\n+\t * processing time and registering timers.\n+\t */\n+\tpublic ProcessingTimeService getProcessingTimeService() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzIzOTg3Mw=="}, "originalCommit": {"oid": "c1facefebee52a1ac84f188f46b114deae0aad89"}, "originalPosition": 346}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDg1MDEwMQ==", "bodyText": "That would contradict\n\t\t// yielding operators cannot be chained to legacy sources\n\t\tif (downStreamOperator instanceof YieldingOperatorFactory) {\n\t\t\t// unfortunately the information that vertices have been chained is not preserved at this point\n\t\t\treturn !getHeadOperator(upStreamVertex, streamGraph).isStreamSource();\n\t\t}\n\nWhat do you think about having mixed pattern? Common parameters in StreamOperatorParameters, and \"special\" or rare ones as decorators?", "url": "https://github.com/apache/flink/pull/11403#discussion_r394850101", "createdAt": "2020-03-19T08:10:02Z", "author": {"login": "pnowojski"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/YieldingOperatorFactory.java", "diffHunk": "@@ -17,10 +17,13 @@\n \n package org.apache.flink.streaming.api.operators;\n \n+import org.apache.flink.annotation.PublicEvolving;\n+\n /**\n  * An operator that needs access to the {@link MailboxExecutor} to yield to downstream operators needs to be created\n  * through a factory implementing this interface.\n  */\n+@PublicEvolving\n public interface YieldingOperatorFactory<OUT> extends StreamOperatorFactory<OUT> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkzMzQ3OA=="}, "originalCommit": {"oid": "c1facefebee52a1ac84f188f46b114deae0aad89"}, "originalPosition": 11}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "af0a9aaf0e21579c2de2715535d166142aa4d2fe", "author": {"user": {"login": "pnowojski", "name": "Piotr Nowojski"}}, "url": "https://github.com/apache/flink/commit/af0a9aaf0e21579c2de2715535d166142aa4d2fe", "committedDate": "2020-03-19T08:13:14Z", "message": "[FLINK-16316][operators] Make StreamOperatorFactory PublicEvolving"}, "afterCommit": {"oid": "6e60715d78ca865c3d687699124338afb1f6d1e2", "author": {"user": {"login": "pnowojski", "name": "Piotr Nowojski"}}, "url": "https://github.com/apache/flink/commit/6e60715d78ca865c3d687699124338afb1f6d1e2", "committedDate": "2020-03-19T08:38:31Z", "message": "[FLINK-16316][operators] Make StreamOperatorFactory PublicEvolving"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc3NTc5NTA1", "url": "https://github.com/apache/flink/pull/11403#pullrequestreview-377579505", "createdAt": "2020-03-19T10:09:53Z", "commit": {"oid": "6e60715d78ca865c3d687699124338afb1f6d1e2"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxMDowOTo1M1rOF4nxeA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxMDowOTo1M1rOF4nxeA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDkxNjIxNg==", "bodyText": "This would confuse me if I'd implement a new operator. Should I extend this class or AbstractStreamOperator?\n(annotations don't tell much: this one is \"Experimental\" but the other one - \"PublicEvolving\").\nI think we should direct users to v1 until we remove @Experimental (and deprecate v1).\nMaybe something like this:\nNew base class for all stream operators, intended to eventually replace {@link AbstractStreamOperator}.\n?", "url": "https://github.com/apache/flink/pull/11403#discussion_r394916216", "createdAt": "2020-03-19T10:09:53Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/AbstractStreamOperatorV2.java", "diffHunk": "@@ -0,0 +1,488 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.Experimental;\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.KeyedStateStore;\n+import org.apache.flink.api.common.state.State;\n+import org.apache.flink.api.common.state.StateDescriptor;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.java.functions.KeySelector;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.configuration.MetricOptions;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.metrics.MetricGroup;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.execution.Environment;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.metrics.groups.OperatorMetricGroup;\n+import org.apache.flink.runtime.metrics.groups.TaskManagerJobMetricGroup;\n+import org.apache.flink.runtime.metrics.groups.UnregisteredMetricGroups;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.KeyedStateBackend;\n+import org.apache.flink.runtime.state.OperatorStateBackend;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.runtime.state.VoidNamespace;\n+import org.apache.flink.runtime.state.VoidNamespaceSerializer;\n+import org.apache.flink.streaming.api.graph.StreamConfig;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.streamrecord.LatencyMarker;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.tasks.ProcessingTimeService;\n+import org.apache.flink.streaming.runtime.tasks.StreamTask;\n+import org.apache.flink.streaming.util.LatencyStats;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Arrays;\n+import java.util.Locale;\n+import java.util.Optional;\n+\n+/**\n+ * New base class for all stream operators, replacing previous {@link AbstractStreamOperator}.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6e60715d78ca865c3d687699124338afb1f6d1e2"}, "originalPosition": 63}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc3NTgxMDA4", "url": "https://github.com/apache/flink/pull/11403#pullrequestreview-377581008", "createdAt": "2020-03-19T10:11:54Z", "commit": {"oid": "6e60715d78ca865c3d687699124338afb1f6d1e2"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "6e60715d78ca865c3d687699124338afb1f6d1e2", "author": {"user": {"login": "pnowojski", "name": "Piotr Nowojski"}}, "url": "https://github.com/apache/flink/commit/6e60715d78ca865c3d687699124338afb1f6d1e2", "committedDate": "2020-03-19T08:38:31Z", "message": "[FLINK-16316][operators] Make StreamOperatorFactory PublicEvolving"}, "afterCommit": {"oid": "b8fc7b297694ceb7786827ff642c64d84b7e822d", "author": {"user": {"login": "pnowojski", "name": "Piotr Nowojski"}}, "url": "https://github.com/apache/flink/commit/b8fc7b297694ceb7786827ff642c64d84b7e822d", "committedDate": "2020-03-19T10:45:11Z", "message": "[FLINK-16316][operators] Make StreamOperatorFactory PublicEvolving"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b8fc7b297694ceb7786827ff642c64d84b7e822d", "author": {"user": {"login": "pnowojski", "name": "Piotr Nowojski"}}, "url": "https://github.com/apache/flink/commit/b8fc7b297694ceb7786827ff642c64d84b7e822d", "committedDate": "2020-03-19T10:45:11Z", "message": "[FLINK-16316][operators] Make StreamOperatorFactory PublicEvolving"}, "afterCommit": {"oid": "46d9e932e6884f229e88d3c69d7a746ed3634124", "author": {"user": {"login": "pnowojski", "name": "Piotr Nowojski"}}, "url": "https://github.com/apache/flink/commit/46d9e932e6884f229e88d3c69d7a746ed3634124", "committedDate": "2020-03-23T10:01:31Z", "message": "[FLINK-16316][operators] Make StreamOperatorFactory PublicEvolving"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "46d9e932e6884f229e88d3c69d7a746ed3634124", "author": {"user": {"login": "pnowojski", "name": "Piotr Nowojski"}}, "url": "https://github.com/apache/flink/commit/46d9e932e6884f229e88d3c69d7a746ed3634124", "committedDate": "2020-03-23T10:01:31Z", "message": "[FLINK-16316][operators] Make StreamOperatorFactory PublicEvolving"}, "afterCommit": {"oid": "b77da7156f766d2c480943434732bed63ff1dc0a", "author": {"user": {"login": "pnowojski", "name": "Piotr Nowojski"}}, "url": "https://github.com/apache/flink/commit/b77da7156f766d2c480943434732bed63ff1dc0a", "committedDate": "2020-03-23T10:06:25Z", "message": "[FLINK-16316][operators] Make StreamOperatorFactory PublicEvolving"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc5MzAyMDg0", "url": "https://github.com/apache/flink/pull/11403#pullrequestreview-379302084", "createdAt": "2020-03-23T10:30:36Z", "commit": {"oid": "b77da7156f766d2c480943434732bed63ff1dc0a"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yM1QxMDozMDozNlrOF5_SCg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yM1QxMTo1MDozOFrOF6B-FQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjM0OTk2Mg==", "bodyText": "I don't see how this is related to the scope of the PR. Can you please explain the motivation?\nAlso, I don't think this interface is ready to become a part of public API (because of the type parameter issue discussed below; and probably other issues).\nI see fixing this interface and making it public should be separate PR or two.", "url": "https://github.com/apache/flink/pull/11403#discussion_r396349962", "createdAt": "2020-03-23T10:30:36Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorFactory.java", "diffHunk": "@@ -32,14 +30,13 @@\n  *\n  * @param <OUT> The output type of the operator\n  */\n-@Internal\n+@PublicEvolving\n public interface StreamOperatorFactory<OUT> extends Serializable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b77da7156f766d2c480943434732bed63ff1dc0a"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjM2NTc3MA==", "bodyText": "sorry, I messed it up with the base operator class. But nevertheless, we shouldn't expose class internals without a need. Here, all the usages are inside the package, so it could be package-private.\nAt least, we could split StreamOperatorStateHandler (regarding reference to overall comment, please see my reply to it).\nIn either case, why not to parameterize AbstractStreamOperatorV2, StreamOperatorStateHandler and it's keyedStateBackend; in AbstractStreamOperator we can still have a cast; and each time we migrate an operator to V2 we add a proper type parameter (or Object).", "url": "https://github.com/apache/flink/pull/11403#discussion_r396365770", "createdAt": "2020-03-23T10:57:31Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java", "diffHunk": "@@ -0,0 +1,434 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.PublicEvolving;\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.KeyedStateStore;\n+import org.apache.flink.api.common.state.State;\n+import org.apache.flink.api.common.state.StateDescriptor;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.core.memory.DataOutputViewStreamWrapper;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.CheckpointFailureReason;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.state.AbstractKeyedStateBackend;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.DefaultKeyedStateStore;\n+import org.apache.flink.runtime.state.KeyGroupRange;\n+import org.apache.flink.runtime.state.KeyGroupStatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.KeyGroupsList;\n+import org.apache.flink.runtime.state.KeyedStateBackend;\n+import org.apache.flink.runtime.state.KeyedStateCheckpointOutputStream;\n+import org.apache.flink.runtime.state.OperatorStateBackend;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateInitializationContextImpl;\n+import org.apache.flink.runtime.state.StatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.runtime.state.StateSnapshotContextSynchronousImpl;\n+import org.apache.flink.runtime.state.VoidNamespaceSerializer;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.util.CloseableIterable;\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.IOUtils;\n+import org.apache.flink.util.function.ThrowingConsumer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.Optional;\n+\n+/**\n+ * Class encapsulating various state backend handling logic for {@link StreamOperator} implementations.\n+ */\n+@PublicEvolving\n+public class StreamOperatorStateHandler {\n+\n+\tprotected static final Logger LOG = LoggerFactory.getLogger(StreamOperatorStateHandler.class);\n+\n+\t/** Backend for keyed state. This might be empty if we're not on a keyed stream. */\n+\t@Nullable\n+\tprivate final AbstractKeyedStateBackend<?> keyedStateBackend;\n+\tprivate final CloseableRegistry closeableRegistry;\n+\t@Nullable\n+\tprivate final DefaultKeyedStateStore keyedStateStore;\n+\tprivate final OperatorStateBackend operatorStateBackend;\n+\tprivate final InternalTimeServiceManager<?> timeServiceManager;\n+\tprivate final StreamOperatorStateContext context;\n+\n+\tpublic StreamOperatorStateHandler(\n+\t\t\tStreamOperatorStateContext context,\n+\t\t\tExecutionConfig executionConfig,\n+\t\t\tCloseableRegistry closeableRegistry) {\n+\t\tthis.context = context;\n+\t\toperatorStateBackend = context.operatorStateBackend();\n+\t\tkeyedStateBackend = context.keyedStateBackend();\n+\t\tthis.closeableRegistry = closeableRegistry;\n+\n+\t\tif (keyedStateBackend != null) {\n+\t\t\tkeyedStateStore = new DefaultKeyedStateStore(keyedStateBackend, executionConfig);\n+\t\t}\n+\t\telse {\n+\t\t\tkeyedStateStore = null;\n+\t\t}\n+\n+\t\ttimeServiceManager = context.internalTimerServiceManager();\n+\t}\n+\n+\tpublic void initializeOperatorState(ThrowingConsumer<StateInitializationContext, Exception> initializeOperatorAction) throws Exception {\n+\t\tCloseableIterable<KeyGroupStatePartitionStreamProvider> keyedStateInputs = context.rawKeyedStateInputs();\n+\t\tCloseableIterable<StatePartitionStreamProvider> operatorStateInputs = context.rawOperatorStateInputs();\n+\n+\t\ttry {\n+\t\t\tStateInitializationContext initializationContext = new StateInitializationContextImpl(\n+\t\t\t\tcontext.isRestored(), // information whether we restore or start for the first time\n+\t\t\t\toperatorStateBackend, // access to operator state backend\n+\t\t\t\tkeyedStateStore, // access to keyed state backend\n+\t\t\t\tkeyedStateInputs, // access to keyed state stream\n+\t\t\t\toperatorStateInputs); // access to operator state stream\n+\n+\t\t\tinitializeOperatorAction.accept(initializationContext);\n+\t\t} finally {\n+\t\t\tcloseFromRegistry(operatorStateInputs, closeableRegistry);\n+\t\t\tcloseFromRegistry(keyedStateInputs, closeableRegistry);\n+\t\t}\n+\t}\n+\n+\tprivate static void closeFromRegistry(Closeable closeable, CloseableRegistry registry) {\n+\t\tif (registry.unregisterCloseable(closeable)) {\n+\t\t\tIOUtils.closeQuietly(closeable);\n+\t\t}\n+\t}\n+\n+\tpublic void dispose() throws Exception {\n+\n+\t\tException exception = null;\n+\n+\t\ttry {\n+\t\t\tif (closeableRegistry.unregisterCloseable(operatorStateBackend)) {\n+\t\t\t\toperatorStateBackend.close();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = e;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tif (closeableRegistry.unregisterCloseable(keyedStateBackend)) {\n+\t\t\t\tkeyedStateBackend.close();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = ExceptionUtils.firstOrSuppressed(e, exception);\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tif (operatorStateBackend != null) {\n+\t\t\t\toperatorStateBackend.dispose();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = ExceptionUtils.firstOrSuppressed(e, exception);\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tif (keyedStateBackend != null) {\n+\t\t\t\tkeyedStateBackend.dispose();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = ExceptionUtils.firstOrSuppressed(e, exception);\n+\t\t}\n+\n+\t\tif (exception != null) {\n+\t\t\tthrow exception;\n+\t\t}\n+\t}\n+\n+\tpublic OperatorSnapshotFutures snapshotState(\n+\t\t\tThrowingConsumer<StateSnapshotContext, Exception> snapshotStateAction,\n+\t\t\tString operatorName,\n+\t\t\tlong checkpointId,\n+\t\t\tlong timestamp,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory) throws CheckpointException {\n+\t\tKeyGroupRange keyGroupRange = null != keyedStateBackend ?\n+\t\t\tkeyedStateBackend.getKeyGroupRange() : KeyGroupRange.EMPTY_KEY_GROUP_RANGE;\n+\n+\t\tOperatorSnapshotFutures snapshotInProgress = new OperatorSnapshotFutures();\n+\n+\t\tStateSnapshotContextSynchronousImpl snapshotContext = new StateSnapshotContextSynchronousImpl(\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tfactory,\n+\t\t\tkeyGroupRange,\n+\t\t\tcloseableRegistry);\n+\n+\t\treturn snapshotState(\n+\t\t\tsnapshotStateAction,\n+\t\t\toperatorName,\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tcheckpointOptions,\n+\t\t\tfactory,\n+\t\t\tsnapshotInProgress,\n+\t\t\tsnapshotContext);\n+\t}\n+\n+\t@VisibleForTesting\n+\tOperatorSnapshotFutures snapshotState(\n+\t\t\tThrowingConsumer<StateSnapshotContext, Exception> snapshotStateAction,\n+\t\t\tString operatorName,\n+\t\t\tlong checkpointId,\n+\t\t\tlong timestamp,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory,\n+\t\t\tOperatorSnapshotFutures snapshotInProgress,\n+\t\t\tStateSnapshotContextSynchronousImpl snapshotContext) throws CheckpointException {\n+\t\ttry {\n+\t\t\tsnapshotState(snapshotContext, operatorName);\n+\t\t\tsnapshotStateAction.accept(snapshotContext);\n+\n+\t\t\tsnapshotInProgress.setKeyedStateRawFuture(snapshotContext.getKeyedStateStreamFuture());\n+\t\t\tsnapshotInProgress.setOperatorStateRawFuture(snapshotContext.getOperatorStateStreamFuture());\n+\n+\t\t\tif (null != operatorStateBackend) {\n+\t\t\t\tsnapshotInProgress.setOperatorStateManagedFuture(\n+\t\t\t\t\toperatorStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));\n+\t\t\t}\n+\n+\t\t\tif (null != keyedStateBackend) {\n+\t\t\t\tsnapshotInProgress.setKeyedStateManagedFuture(\n+\t\t\t\t\tkeyedStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));\n+\t\t\t}\n+\t\t} catch (Exception snapshotException) {\n+\t\t\ttry {\n+\t\t\t\tsnapshotInProgress.cancel();\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tsnapshotException.addSuppressed(e);\n+\t\t\t}\n+\n+\t\t\tString snapshotFailMessage = \"Could not complete snapshot \" + checkpointId + \" for operator \" +\n+\t\t\t\toperatorName + \".\";\n+\n+\t\t\ttry {\n+\t\t\t\tsnapshotContext.closeExceptionally();\n+\t\t\t} catch (IOException e) {\n+\t\t\t\tsnapshotException.addSuppressed(e);\n+\t\t\t}\n+\t\t\tthrow new CheckpointException(snapshotFailMessage, CheckpointFailureReason.CHECKPOINT_DECLINED, snapshotException);\n+\t\t}\n+\n+\t\treturn snapshotInProgress;\n+\t}\n+\n+\t/**\n+\t * Stream operators with state, which want to participate in a snapshot need to override this hook method.\n+\t *\n+\t * @param context context that provides information and means required for taking a snapshot\n+\t * @param operatorName\n+\t */\n+\tpublic void snapshotState(StateSnapshotContext context, String operatorName) throws Exception {\n+\t\tfinal KeyedStateBackend<?> keyedStateBackend = getKeyedStateBackend();\n+\t\t//TODO all of this can be removed once heap-based timers are integrated with RocksDB incremental snapshots\n+\t\tif (keyedStateBackend instanceof AbstractKeyedStateBackend &&\n+\t\t\t((AbstractKeyedStateBackend<?>) keyedStateBackend).requiresLegacySynchronousTimerSnapshots()) {\n+\n+\t\t\tKeyedStateCheckpointOutputStream out;\n+\n+\t\t\ttry {\n+\t\t\t\tout = context.getRawKeyedOperatorStateOutput();\n+\t\t\t} catch (Exception exception) {\n+\t\t\t\tthrow new Exception(\"Could not open raw keyed operator state stream for \" +\n+\t\t\t\t\toperatorName + '.', exception);\n+\t\t\t}\n+\n+\t\t\ttry {\n+\t\t\t\tKeyGroupsList allKeyGroups = out.getKeyGroupList();\n+\t\t\t\tfor (int keyGroupIdx : allKeyGroups) {\n+\t\t\t\t\tout.startNewKeyGroup(keyGroupIdx);\n+\n+\t\t\t\t\ttimeServiceManager.snapshotStateForKeyGroup(\n+\t\t\t\t\t\tnew DataOutputViewStreamWrapper(out), keyGroupIdx);\n+\t\t\t\t}\n+\t\t\t} catch (Exception exception) {\n+\t\t\t\tthrow new Exception(\"Could not write timer service of \" + operatorName +\n+\t\t\t\t\t\" to checkpoint state stream.\", exception);\n+\t\t\t} finally {\n+\t\t\t\ttry {\n+\t\t\t\t\tout.close();\n+\t\t\t\t} catch (Exception closeException) {\n+\t\t\t\t\tLOG.warn(\"Could not close raw keyed operator state stream for {}. This \" +\n+\t\t\t\t\t\t\"might have prevented deleting some state data.\", operatorName, closeException);\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void notifyCheckpointComplete(long checkpointId) throws Exception {\n+\t\tif (keyedStateBackend != null) {\n+\t\t\tkeyedStateBackend.notifyCheckpointComplete(checkpointId);\n+\t\t}\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic <K> KeyedStateBackend<K> getKeyedStateBackend() {\n+\t\treturn (KeyedStateBackend<K>) keyedStateBackend;\n+\t}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI0NTA3Mg=="}, "originalCommit": {"oid": "c1facefebee52a1ac84f188f46b114deae0aad89"}, "originalPosition": 295}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjM4OTg5OA==", "bodyText": "Reducing visibility would fail migration of only 2 tests.\nWe don't know though when this will happen. And then we could either fix the tests, disable them temporarily, or change visibility back to public.\nSo I think it's better to have it protected until then.\nSimilar argument applies to numEventTimeTimers and numProcessingTimeTimers.", "url": "https://github.com/apache/flink/pull/11403#discussion_r396389898", "createdAt": "2020-03-23T11:42:40Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/AbstractStreamOperatorV2.java", "diffHunk": "@@ -0,0 +1,488 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.Experimental;\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.KeyedStateStore;\n+import org.apache.flink.api.common.state.State;\n+import org.apache.flink.api.common.state.StateDescriptor;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.java.functions.KeySelector;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.configuration.MetricOptions;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.metrics.MetricGroup;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.execution.Environment;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.metrics.groups.OperatorMetricGroup;\n+import org.apache.flink.runtime.metrics.groups.TaskManagerJobMetricGroup;\n+import org.apache.flink.runtime.metrics.groups.UnregisteredMetricGroups;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.KeyedStateBackend;\n+import org.apache.flink.runtime.state.OperatorStateBackend;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.runtime.state.VoidNamespace;\n+import org.apache.flink.runtime.state.VoidNamespaceSerializer;\n+import org.apache.flink.streaming.api.graph.StreamConfig;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.streamrecord.LatencyMarker;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.tasks.ProcessingTimeService;\n+import org.apache.flink.streaming.runtime.tasks.StreamTask;\n+import org.apache.flink.streaming.util.LatencyStats;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Arrays;\n+import java.util.Locale;\n+import java.util.Optional;\n+\n+/**\n+ * New base class for all stream operators, intended to eventually replace {@link AbstractStreamOperator}.\n+ * Currently intended to work smoothly just with {@link MultipleInputStreamOperator}.\n+ *\n+ * <p>One note-able difference in comparison to {@link AbstractStreamOperator} is lack of\n+ * {@link AbstractStreamOperator#setup(StreamTask, StreamConfig, Output)} in favor of initialisation\n+ * in the constructor, and removed some tight coupling with classes like {@link StreamTask}.\n+ *\n+ * <p>Methods are guaranteed not to be called concurrently.\n+ *\n+ * @param <OUT> The output type of the operator\n+ */\n+@Experimental\n+public abstract class AbstractStreamOperatorV2<OUT> implements StreamOperator<OUT> {\n+\t/** The logger used by the operator class and its subclasses. */\n+\tprotected static final Logger LOG = LoggerFactory.getLogger(AbstractStreamOperatorV2.class);\n+\n+\tprotected final StreamConfig config;\n+\tprotected final Output<StreamRecord<OUT>> output;\n+\tprivate final StreamingRuntimeContext runtimeContext;\n+\tprivate final ExecutionConfig executionConfig;\n+\tprivate final ClassLoader userCodeClassLoader;\n+\tprivate final CloseableRegistry cancelables;\n+\tprivate final long[] inputWatermarks;\n+\n+\t/** Metric group for the operator. */\n+\tprotected final OperatorMetricGroup metrics;\n+\tprotected final LatencyStats latencyStats;\n+\tprotected final ProcessingTimeService processingTimeService;\n+\n+\tprivate StreamOperatorStateHandler stateHandler;\n+\n+\t// We keep track of watermarks from both inputs, the combined input is the minimum\n+\t// Once the minimum advances we emit a new watermark for downstream operators\n+\tprivate long combinedWatermark = Long.MIN_VALUE;\n+\n+\tpublic AbstractStreamOperatorV2(StreamOperatorParameters<OUT> parameters, int numberOfInputs) {\n+\t\tinputWatermarks = new long[numberOfInputs];\n+\t\tArrays.fill(inputWatermarks, Long.MIN_VALUE);\n+\t\tfinal Environment environment = parameters.getContainingTask().getEnvironment();\n+\t\tconfig = parameters.getStreamConfig();\n+\t\tCountingOutput<OUT> countingOutput;\n+\t\tOperatorMetricGroup operatorMetricGroup;\n+\t\ttry {\n+\t\t\toperatorMetricGroup = environment.getMetricGroup().getOrAddOperator(config.getOperatorID(), config.getOperatorName());\n+\t\t\tcountingOutput = new CountingOutput(parameters.getOutput(), operatorMetricGroup.getIOMetricGroup().getNumRecordsOutCounter());\n+\t\t\tif (config.isChainStart()) {\n+\t\t\t\toperatorMetricGroup.getIOMetricGroup().reuseInputMetricsForTask();\n+\t\t\t}\n+\t\t\tif (config.isChainEnd()) {\n+\t\t\t\toperatorMetricGroup.getIOMetricGroup().reuseOutputMetricsForTask();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\tLOG.warn(\"An error occurred while instantiating task metrics.\", e);\n+\t\t\tcountingOutput = null;\n+\t\t\toperatorMetricGroup = null;\n+\t\t}\n+\n+\t\tif (countingOutput == null || operatorMetricGroup == null) {\n+\t\t\tmetrics = UnregisteredMetricGroups.createUnregisteredOperatorMetricGroup();\n+\t\t\toutput = parameters.getOutput();\n+\t\t}\n+\t\telse {\n+\t\t\tmetrics = operatorMetricGroup;\n+\t\t\toutput = countingOutput;\n+\t\t}\n+\n+\t\tlatencyStats = createLatencyStats(\n+\t\t\tenvironment.getTaskManagerInfo().getConfiguration(),\n+\t\t\tparameters.getContainingTask().getIndexInSubtaskGroup());\n+\n+\t\tprocessingTimeService = Preconditions.checkNotNull(parameters.getProcessingTimeService());\n+\t\texecutionConfig = parameters.getContainingTask().getExecutionConfig();\n+\t\tuserCodeClassLoader = parameters.getContainingTask().getUserCodeClassLoader();\n+\t\tcancelables = parameters.getContainingTask().getCancelables();\n+\n+\t\truntimeContext = new StreamingRuntimeContext(\n+\t\t\tenvironment,\n+\t\t\tenvironment.getAccumulatorRegistry().getUserMap(),\n+\t\t\toperatorMetricGroup,\n+\t\t\tgetOperatorID(),\n+\t\t\tprocessingTimeService,\n+\t\t\tnull);\n+\t}\n+\n+\tprivate LatencyStats createLatencyStats(Configuration taskManagerConfig, int indexInSubtaskGroup) {\n+\t\ttry {\n+\t\t\tint historySize = taskManagerConfig.getInteger(MetricOptions.LATENCY_HISTORY_SIZE);\n+\t\t\tif (historySize <= 0) {\n+\t\t\t\tLOG.warn(\"{} has been set to a value equal or below 0: {}. Using default.\", MetricOptions.LATENCY_HISTORY_SIZE, historySize);\n+\t\t\t\thistorySize = MetricOptions.LATENCY_HISTORY_SIZE.defaultValue();\n+\t\t\t}\n+\n+\t\t\tfinal String configuredGranularity = taskManagerConfig.getString(MetricOptions.LATENCY_SOURCE_GRANULARITY);\n+\t\t\tLatencyStats.Granularity granularity;\n+\t\t\ttry {\n+\t\t\t\tgranularity = LatencyStats.Granularity.valueOf(configuredGranularity.toUpperCase(Locale.ROOT));\n+\t\t\t} catch (IllegalArgumentException iae) {\n+\t\t\t\tgranularity = LatencyStats.Granularity.OPERATOR;\n+\t\t\t\tLOG.warn(\n+\t\t\t\t\t\"Configured value {} option for {} is invalid. Defaulting to {}.\",\n+\t\t\t\t\tconfiguredGranularity,\n+\t\t\t\t\tMetricOptions.LATENCY_SOURCE_GRANULARITY.key(),\n+\t\t\t\t\tgranularity);\n+\t\t\t}\n+\t\t\tTaskManagerJobMetricGroup jobMetricGroup = this.metrics.parent().parent();\n+\t\t\treturn new LatencyStats(jobMetricGroup.addGroup(\"latency\"),\n+\t\t\t\thistorySize,\n+\t\t\t\tindexInSubtaskGroup,\n+\t\t\t\tgetOperatorID(),\n+\t\t\t\tgranularity);\n+\t\t} catch (Exception e) {\n+\t\t\tLOG.warn(\"An error occurred while instantiating latency metrics.\", e);\n+\t\t\treturn new LatencyStats(\n+\t\t\t\tUnregisteredMetricGroups.createUnregisteredTaskManagerJobMetricGroup().addGroup(\"latency\"),\n+\t\t\t\t1,\n+\t\t\t\t0,\n+\t\t\t\tnew OperatorID(),\n+\t\t\t\tLatencyStats.Granularity.SINGLE);\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic MetricGroup getMetricGroup() {\n+\t\treturn metrics;\n+\t}\n+\n+\t@Override\n+\tpublic final void initializeState(StreamTaskStateInitializer streamTaskStateManager) throws Exception {\n+\t\tfinal TypeSerializer<?> keySerializer = config.getStateKeySerializer(getUserCodeClassloader());\n+\n+\t\tfinal StreamOperatorStateContext context =\n+\t\t\tstreamTaskStateManager.streamOperatorStateContext(\n+\t\t\t\tgetOperatorID(),\n+\t\t\t\tgetClass().getSimpleName(),\n+\t\t\t\tgetProcessingTimeService(),\n+\t\t\t\tthis,\n+\t\t\t\tkeySerializer,\n+\t\t\t\tcancelables,\n+\t\t\t\tmetrics);\n+\n+\t\tstateHandler = new StreamOperatorStateHandler(context, getExecutionConfig(), cancelables);\n+\t\tstateHandler.initializeOperatorState(this::initializeState);\n+\t}\n+\n+\t/**\n+\t * This method is called immediately before any elements are processed, it should contain the\n+\t * operator's initialization logic, e.g. state initialization.\n+\t *\n+\t * <p>The default implementation does nothing.\n+\t *\n+\t * @throws Exception An exception in this method causes the operator to fail.\n+\t */\n+\t@Override\n+\tpublic void open() throws Exception {}\n+\n+\t/**\n+\t * This method is called after all records have been added to the operators via the methods\n+\t * {@link OneInputStreamOperator#processElement(StreamRecord)}, or\n+\t * {@link TwoInputStreamOperator#processElement1(StreamRecord)} and\n+\t * {@link TwoInputStreamOperator#processElement2(StreamRecord)}.\n+\t *\n+\t * <p>The method is expected to flush all remaining buffered data. Exceptions during this flushing\n+\t * of buffered should be propagated, in order to cause the operation to be recognized asa failed,\n+\t * because the last data items are not processed properly.\n+\t *\n+\t * @throws Exception An exception in this method causes the operator to fail.\n+\t */\n+\t@Override\n+\tpublic void close() throws Exception {}\n+\n+\t/**\n+\t * This method is called at the very end of the operator's life, both in the case of a successful\n+\t * completion of the operation, and in the case of a failure and canceling.\n+\t *\n+\t * <p>This method is expected to make a thorough effort to release all resources\n+\t * that the operator has acquired.\n+\t */\n+\t@Override\n+\tpublic void dispose() throws Exception {\n+\t\tif (stateHandler != null) {\n+\t\t\tstateHandler.dispose();\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void prepareSnapshotPreBarrier(long checkpointId) throws Exception {\n+\t\t// the default implementation does nothing and accepts the checkpoint\n+\t\t// this is purely for subclasses to override\n+\t}\n+\n+\t@Override\n+\tpublic final OperatorSnapshotFutures snapshotState(long checkpointId, long timestamp, CheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory) throws Exception {\n+\t\treturn stateHandler.snapshotState(\n+\t\t\tthis::snapshotState,\n+\t\t\tgetOperatorName(),\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tcheckpointOptions,\n+\t\t\tfactory);\n+\t}\n+\n+\t/**\n+\t * Stream operators with state, which want to participate in a snapshot need to override this hook method.\n+\t *\n+\t * @param context context that provides information and means required for taking a snapshot\n+\t */\n+\tpublic void snapshotState(StateSnapshotContext context) throws Exception {\n+\t}\n+\n+\t/**\n+\t * Stream operators with state which can be restored need to override this hook method.\n+\t *\n+\t * @param context context that allows to register different states.\n+\t */\n+\tpublic void initializeState(StateInitializationContext context) throws Exception {\n+\n+\t}\n+\n+\t@Override\n+\tpublic void notifyCheckpointComplete(long checkpointId) throws Exception {\n+\t\tstateHandler.notifyCheckpointComplete(checkpointId);\n+\t}\n+\n+\t// ------------------------------------------------------------------------\n+\t//  Properties and Services\n+\t// ------------------------------------------------------------------------\n+\n+\t/**\n+\t * Gets the execution config defined on the execution environment of the job to which this\n+\t * operator belongs.\n+\t *\n+\t * @return The job's execution config.\n+\t */\n+\tpublic ExecutionConfig getExecutionConfig() {\n+\t\treturn executionConfig;\n+\t}\n+\n+\tpublic StreamConfig getOperatorConfig() {\n+\t\treturn config;\n+\t}\n+\n+\tpublic ClassLoader getUserCodeClassloader() {\n+\t\treturn userCodeClassLoader;\n+\t}\n+\n+\t/**\n+\t * Return the operator name. If the runtime context has been set, then the task name with\n+\t * subtask index is returned. Otherwise, the simple class name is returned.\n+\t *\n+\t * @return If runtime context is set, then return task name with subtask index. Otherwise return\n+\t * \t\t\tsimple class name.\n+\t */\n+\tprotected String getOperatorName() {\n+\t\tif (runtimeContext != null) {\n+\t\t\treturn runtimeContext.getTaskNameWithSubtasks();\n+\t\t} else {\n+\t\t\treturn getClass().getSimpleName();\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Returns a context that allows the operator to query information about the execution and also\n+\t * to interact with systems such as broadcast variables and managed state. This also allows\n+\t * to register timers.\n+\t */\n+\tpublic StreamingRuntimeContext getRuntimeContext() {\n+\t\treturn runtimeContext;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic <K> KeyedStateBackend<K> getKeyedStateBackend() {\n+\t\treturn (KeyedStateBackend<K>) stateHandler.getKeyedStateBackend();\n+\t}\n+\n+\tpublic OperatorStateBackend getOperatorStateBackend() {\n+\t\treturn stateHandler.getOperatorStateBackend();\n+\t}\n+\n+\t/**\n+\t * Returns the {@link ProcessingTimeService} responsible for getting the current\n+\t * processing time and registering timers.\n+\t */\n+\tpublic ProcessingTimeService getProcessingTimeService() {\n+\t\treturn processingTimeService;\n+\t}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b77da7156f766d2c480943434732bed63ff1dc0a"}, "originalPosition": 348}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjM5NDAwNQ==", "bodyText": "Regarding having timer-related responsibility in state handler:\n\nWhy not to have getInternalTimerService in the base class (or better outside) and pass stateHandler as a\nparameter? In StreamOperatorStateHandler.snapshotState we can have a parameter similar to\nsnapshotStateAction for timers state.\n\n(sorry for repeating this comment, but I couldn't find an answer)", "url": "https://github.com/apache/flink/pull/11403#discussion_r396394005", "createdAt": "2020-03-23T11:50:38Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java", "diffHunk": "@@ -0,0 +1,411 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.KeyedStateStore;\n+import org.apache.flink.api.common.state.State;\n+import org.apache.flink.api.common.state.StateDescriptor;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.core.memory.DataOutputViewStreamWrapper;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.CheckpointFailureReason;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.state.AbstractKeyedStateBackend;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.DefaultKeyedStateStore;\n+import org.apache.flink.runtime.state.KeyGroupRange;\n+import org.apache.flink.runtime.state.KeyGroupStatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.KeyGroupsList;\n+import org.apache.flink.runtime.state.KeyedStateBackend;\n+import org.apache.flink.runtime.state.KeyedStateCheckpointOutputStream;\n+import org.apache.flink.runtime.state.OperatorStateBackend;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateInitializationContextImpl;\n+import org.apache.flink.runtime.state.StatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.runtime.state.StateSnapshotContextSynchronousImpl;\n+import org.apache.flink.runtime.state.VoidNamespaceSerializer;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.util.CloseableIterable;\n+import org.apache.flink.util.IOUtils;\n+import org.apache.flink.util.function.ThrowingConsumer;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.io.Closer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.Optional;\n+\n+/**\n+ * Class encapsulating various state backend handling logic for {@link StreamOperator} implementations.\n+ */\n+@Internal\n+public class StreamOperatorStateHandler {\n+\n+\tprotected static final Logger LOG = LoggerFactory.getLogger(StreamOperatorStateHandler.class);\n+\n+\t/** Backend for keyed state. This might be empty if we're not on a keyed stream. */\n+\t@Nullable\n+\tprivate final AbstractKeyedStateBackend<?> keyedStateBackend;\n+\tprivate final CloseableRegistry closeableRegistry;\n+\t@Nullable\n+\tprivate final DefaultKeyedStateStore keyedStateStore;\n+\tprivate final OperatorStateBackend operatorStateBackend;\n+\tprivate final InternalTimeServiceManager<?> timeServiceManager;\n+\tprivate final StreamOperatorStateContext context;\n+\n+\tpublic StreamOperatorStateHandler(\n+\t\t\tStreamOperatorStateContext context,\n+\t\t\tExecutionConfig executionConfig,\n+\t\t\tCloseableRegistry closeableRegistry) {\n+\t\tthis.context = context;\n+\t\toperatorStateBackend = context.operatorStateBackend();\n+\t\tkeyedStateBackend = context.keyedStateBackend();\n+\t\tthis.closeableRegistry = closeableRegistry;\n+\n+\t\tif (keyedStateBackend != null) {\n+\t\t\tkeyedStateStore = new DefaultKeyedStateStore(keyedStateBackend, executionConfig);\n+\t\t}\n+\t\telse {\n+\t\t\tkeyedStateStore = null;\n+\t\t}\n+\n+\t\ttimeServiceManager = context.internalTimerServiceManager();\n+\t}\n+\n+\tpublic void initializeOperatorState(ThrowingConsumer<StateInitializationContext, Exception> initializeOperatorAction) throws Exception {\n+\t\tCloseableIterable<KeyGroupStatePartitionStreamProvider> keyedStateInputs = context.rawKeyedStateInputs();\n+\t\tCloseableIterable<StatePartitionStreamProvider> operatorStateInputs = context.rawOperatorStateInputs();\n+\n+\t\ttry {\n+\t\t\tStateInitializationContext initializationContext = new StateInitializationContextImpl(\n+\t\t\t\tcontext.isRestored(), // information whether we restore or start for the first time\n+\t\t\t\toperatorStateBackend, // access to operator state backend\n+\t\t\t\tkeyedStateStore, // access to keyed state backend\n+\t\t\t\tkeyedStateInputs, // access to keyed state stream\n+\t\t\t\toperatorStateInputs); // access to operator state stream\n+\n+\t\t\tinitializeOperatorAction.accept(initializationContext);\n+\t\t} finally {\n+\t\t\tcloseFromRegistry(operatorStateInputs, closeableRegistry);\n+\t\t\tcloseFromRegistry(keyedStateInputs, closeableRegistry);\n+\t\t}\n+\t}\n+\n+\tprivate static void closeFromRegistry(Closeable closeable, CloseableRegistry registry) {\n+\t\tif (registry.unregisterCloseable(closeable)) {\n+\t\t\tIOUtils.closeQuietly(closeable);\n+\t\t}\n+\t}\n+\n+\tpublic void dispose() throws Exception {\n+\t\ttry (Closer closer = Closer.create()) {\n+\t\t\tif (closeableRegistry.unregisterCloseable(operatorStateBackend)) {\n+\t\t\t\tcloser.register(operatorStateBackend);\n+\t\t\t}\n+\t\t\tif (closeableRegistry.unregisterCloseable(keyedStateBackend)) {\n+\t\t\t\tcloser.register(keyedStateBackend);\n+\t\t\t}\n+\t\t\tif (operatorStateBackend != null) {\n+\t\t\t\tcloser.register(() -> operatorStateBackend.dispose());\n+\t\t\t}\n+\t\t\tif (keyedStateBackend != null) {\n+\t\t\t\tcloser.register(() -> keyedStateBackend.dispose());\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic OperatorSnapshotFutures snapshotState(\n+\t\t\tThrowingConsumer<StateSnapshotContext, Exception> snapshotStateAction,\n+\t\t\tString operatorName,\n+\t\t\tlong checkpointId,\n+\t\t\tlong timestamp,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory) throws CheckpointException {\n+\t\tKeyGroupRange keyGroupRange = null != keyedStateBackend ?\n+\t\t\tkeyedStateBackend.getKeyGroupRange() : KeyGroupRange.EMPTY_KEY_GROUP_RANGE;\n+\n+\t\tOperatorSnapshotFutures snapshotInProgress = new OperatorSnapshotFutures();\n+\n+\t\tStateSnapshotContextSynchronousImpl snapshotContext = new StateSnapshotContextSynchronousImpl(\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tfactory,\n+\t\t\tkeyGroupRange,\n+\t\t\tcloseableRegistry);\n+\n+\t\tsnapshotState(\n+\t\t\tsnapshotStateAction,\n+\t\t\toperatorName,\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tcheckpointOptions,\n+\t\t\tfactory,\n+\t\t\tsnapshotInProgress,\n+\t\t\tsnapshotContext);\n+\n+\t\treturn snapshotInProgress;\n+\t}\n+\n+\t@VisibleForTesting\n+\tvoid snapshotState(\n+\t\t\tThrowingConsumer<StateSnapshotContext, Exception> snapshotStateAction,\n+\t\t\tString operatorName,\n+\t\t\tlong checkpointId,\n+\t\t\tlong timestamp,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory,\n+\t\t\tOperatorSnapshotFutures snapshotInProgress,\n+\t\t\tStateSnapshotContextSynchronousImpl snapshotContext) throws CheckpointException {\n+\t\ttry {\n+\t\t\tsnapshotState(snapshotContext, operatorName);\n+\t\t\tsnapshotStateAction.accept(snapshotContext);\n+\n+\t\t\tsnapshotInProgress.setKeyedStateRawFuture(snapshotContext.getKeyedStateStreamFuture());\n+\t\t\tsnapshotInProgress.setOperatorStateRawFuture(snapshotContext.getOperatorStateStreamFuture());\n+\n+\t\t\tif (null != operatorStateBackend) {\n+\t\t\t\tsnapshotInProgress.setOperatorStateManagedFuture(\n+\t\t\t\t\toperatorStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));\n+\t\t\t}\n+\n+\t\t\tif (null != keyedStateBackend) {\n+\t\t\t\tsnapshotInProgress.setKeyedStateManagedFuture(\n+\t\t\t\t\tkeyedStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));\n+\t\t\t}\n+\t\t} catch (Exception snapshotException) {\n+\t\t\ttry {\n+\t\t\t\tsnapshotInProgress.cancel();\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tsnapshotException.addSuppressed(e);\n+\t\t\t}\n+\n+\t\t\tString snapshotFailMessage = \"Could not complete snapshot \" + checkpointId + \" for operator \" +\n+\t\t\t\toperatorName + \".\";\n+\n+\t\t\ttry {\n+\t\t\t\tsnapshotContext.closeExceptionally();\n+\t\t\t} catch (IOException e) {\n+\t\t\t\tsnapshotException.addSuppressed(e);\n+\t\t\t}\n+\t\t\tthrow new CheckpointException(snapshotFailMessage, CheckpointFailureReason.CHECKPOINT_DECLINED, snapshotException);\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Stream operators with state, which want to participate in a snapshot need to override this hook method.\n+\t *\n+\t * @param context context that provides information and means required for taking a snapshot\n+\t * @param operatorName\n+\t */\n+\tpublic void snapshotState(StateSnapshotContext context, String operatorName) throws Exception {\n+\t\tfinal KeyedStateBackend<?> keyedStateBackend = getKeyedStateBackend();\n+\t\t//TODO all of this can be removed once heap-based timers are integrated with RocksDB incremental snapshots\n+\t\tif (keyedStateBackend instanceof AbstractKeyedStateBackend &&\n+\t\t\t((AbstractKeyedStateBackend<?>) keyedStateBackend).requiresLegacySynchronousTimerSnapshots()) {\n+\n+\t\t\tKeyedStateCheckpointOutputStream out;\n+\n+\t\t\ttry {\n+\t\t\t\tout = context.getRawKeyedOperatorStateOutput();\n+\t\t\t} catch (Exception exception) {\n+\t\t\t\tthrow new Exception(\"Could not open raw keyed operator state stream for \" +\n+\t\t\t\t\toperatorName + '.', exception);\n+\t\t\t}\n+\n+\t\t\ttry {\n+\t\t\t\tKeyGroupsList allKeyGroups = out.getKeyGroupList();\n+\t\t\t\tfor (int keyGroupIdx : allKeyGroups) {\n+\t\t\t\t\tout.startNewKeyGroup(keyGroupIdx);\n+\n+\t\t\t\t\ttimeServiceManager.snapshotStateForKeyGroup(\n+\t\t\t\t\t\tnew DataOutputViewStreamWrapper(out), keyGroupIdx);\n+\t\t\t\t}\n+\t\t\t} catch (Exception exception) {\n+\t\t\t\tthrow new Exception(\"Could not write timer service of \" + operatorName +\n+\t\t\t\t\t\" to checkpoint state stream.\", exception);\n+\t\t\t} finally {\n+\t\t\t\ttry {\n+\t\t\t\t\tout.close();\n+\t\t\t\t} catch (Exception closeException) {\n+\t\t\t\t\tLOG.warn(\"Could not close raw keyed operator state stream for {}. This \" +\n+\t\t\t\t\t\t\"might have prevented deleting some state data.\", operatorName, closeException);\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void notifyCheckpointComplete(long checkpointId) throws Exception {\n+\t\tif (keyedStateBackend != null) {\n+\t\t\tkeyedStateBackend.notifyCheckpointComplete(checkpointId);\n+\t\t}\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic <K> KeyedStateBackend<K> getKeyedStateBackend() {\n+\t\treturn (KeyedStateBackend<K>) keyedStateBackend;\n+\t}\n+\n+\tpublic OperatorStateBackend getOperatorStateBackend() {\n+\t\treturn operatorStateBackend;\n+\t}\n+\n+\tpublic <N, S extends State, T> S getOrCreateKeyedState(\n+\t\t\tTypeSerializer<N> namespaceSerializer,\n+\t\t\tStateDescriptor<S, T> stateDescriptor) throws Exception {\n+\n+\t\tif (keyedStateStore != null) {\n+\t\t\treturn keyedStateBackend.getOrCreateKeyedState(namespaceSerializer, stateDescriptor);\n+\t\t}\n+\t\telse {\n+\t\t\tthrow new IllegalStateException(\"Cannot create partitioned state. \" +\n+\t\t\t\t\t\"The keyed state backend has not been set.\" +\n+\t\t\t\t\t\"This indicates that the operator is not partitioned/keyed.\");\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Creates a partitioned state handle, using the state backend configured for this task.\n+\t *\n+\t * @throws IllegalStateException Thrown, if the key/value state was already initialized.\n+\t * @throws Exception Thrown, if the state backend cannot create the key/value state.\n+\t */\n+\tprotected <S extends State, N> S getPartitionedState(\n+\t\t\tN namespace,\n+\t\t\tTypeSerializer<N> namespaceSerializer,\n+\t\t\tStateDescriptor<S, ?> stateDescriptor) throws Exception {\n+\n+\t\t/*\n+\t    TODO: NOTE: This method does a lot of work caching / retrieving states just to update the namespace.\n+\t    This method should be removed for the sake of namespaces being lazily fetched from the keyed\n+\t    state backend, or being set on the state directly.\n+\t    */\n+\n+\t\tif (keyedStateStore != null) {\n+\t\t\treturn keyedStateBackend.getPartitionedState(namespace, namespaceSerializer, stateDescriptor);\n+\t\t} else {\n+\t\t\tthrow new RuntimeException(\"Cannot create partitioned state. The keyed state \" +\n+\t\t\t\t\"backend has not been set. This indicates that the operator is not \" +\n+\t\t\t\t\"partitioned/keyed.\");\n+\t\t}\n+\t}\n+\n+\t@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+\tpublic void setCurrentKey(Object key) {\n+\t\tif (keyedStateBackend != null) {\n+\t\t\ttry {\n+\t\t\t\t// need to work around type restrictions\n+\t\t\t\t@SuppressWarnings(\"unchecked,rawtypes\")\n+\t\t\t\tAbstractKeyedStateBackend rawBackend = (AbstractKeyedStateBackend) keyedStateBackend;\n+\n+\t\t\t\trawBackend.setCurrentKey(key);\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tthrow new RuntimeException(\"Exception occurred while setting the current key context.\", e);\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\t@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+\tpublic Object getCurrentKey() {\n+\t\tif (keyedStateBackend != null) {\n+\t\t\treturn keyedStateBackend.getCurrentKey();\n+\t\t} else {\n+\t\t\tthrow new UnsupportedOperationException(\"Key can only be retrieved on KeyedStream.\");\n+\t\t}\n+\t}\n+\n+\tpublic Optional<KeyedStateStore> getKeyedStateStore() {\n+\t\treturn Optional.ofNullable(keyedStateStore);\n+\t}\n+\n+\t/**\n+\t * Returns a {@link InternalTimerService} that can be used to query current processing time\n+\t * and event time and to set timers. An operator can have several timer services, where\n+\t * each has its own namespace serializer. Timer services are differentiated by the string\n+\t * key that is given when requesting them, if you call this method with the same key\n+\t * multiple times you will get the same timer service instance in subsequent requests.\n+\t *\n+\t * <p>Timers are always scoped to a key, the currently active key of a keyed stream operation.\n+\t * When a timer fires, this key will also be set as the currently active key.\n+\t *\n+\t * <p>Each timer has attached metadata, the namespace. Different timer services\n+\t * can have a different namespace type. If you don't need namespace differentiation you\n+\t * can use {@link VoidNamespaceSerializer} as the namespace serializer.\n+\t *\n+\t * @param name The name of the requested timer service. If no service exists under the given\n+\t *             name a new one will be created and returned.\n+\t * @param namespaceSerializer {@code TypeSerializer} for the timer namespace.\n+\t * @param triggerable The {@link Triggerable} that should be invoked when timers fire\n+\t *\n+\t * @param <N> The type of the timer namespace.\n+\t */\n+\tpublic <K, N> InternalTimerService<N> getInternalTimerService(\n+\t\t\tString name,\n+\t\t\tTypeSerializer<N> namespaceSerializer,\n+\t\t\tTriggerable<K, N> triggerable) {\n+\n+\t\tcheckTimerServiceInitialization();\n+\n+\t\t// the following casting is to overcome type restrictions.\n+\t\tKeyedStateBackend<K> keyedStateBackend = getKeyedStateBackend();\n+\t\tTypeSerializer<K> keySerializer = keyedStateBackend.getKeySerializer();\n+\t\tInternalTimeServiceManager<K> keyedTimeServiceHandler = (InternalTimeServiceManager<K>) timeServiceManager;\n+\t\tTimerSerializer<K, N> timerSerializer = new TimerSerializer<>(keySerializer, namespaceSerializer);\n+\t\treturn keyedTimeServiceHandler.getInternalTimerService(name, timerSerializer, triggerable);\n+\t}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b77da7156f766d2c480943434732bed63ff1dc0a"}, "originalPosition": 380}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b77da7156f766d2c480943434732bed63ff1dc0a", "author": {"user": {"login": "pnowojski", "name": "Piotr Nowojski"}}, "url": "https://github.com/apache/flink/commit/b77da7156f766d2c480943434732bed63ff1dc0a", "committedDate": "2020-03-23T10:06:25Z", "message": "[FLINK-16316][operators] Make StreamOperatorFactory PublicEvolving"}, "afterCommit": {"oid": "b771b91f3a71291eb6926c5521a3e40d55de5a6f", "author": {"user": {"login": "pnowojski", "name": "Piotr Nowojski"}}, "url": "https://github.com/apache/flink/commit/b771b91f3a71291eb6926c5521a3e40d55de5a6f", "committedDate": "2020-03-23T17:12:38Z", "message": "[FLINK-16316][operators] Make StreamOperatorFactory Experimental"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgwMDY0ODA3", "url": "https://github.com/apache/flink/pull/11403#pullrequestreview-380064807", "createdAt": "2020-03-24T07:51:22Z", "commit": {"oid": "9c930f35bd067109d8b5c04e1b5ef6324e623eef"}, "state": "APPROVED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNFQwNzo1MToyMlrOF6kS6w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNFQwODowMjo0MVrOF6koPQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njk1NjM5NQ==", "bodyText": "I agree with Roman that the proper way would be to have the Handler parameterized. However, I see that the public API of AbstractStreamOperator already exposes the same method. So I suggest to address the issue holistically in a different PR.", "url": "https://github.com/apache/flink/pull/11403#discussion_r396956395", "createdAt": "2020-03-24T07:51:22Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java", "diffHunk": "@@ -0,0 +1,434 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.PublicEvolving;\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.KeyedStateStore;\n+import org.apache.flink.api.common.state.State;\n+import org.apache.flink.api.common.state.StateDescriptor;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.core.memory.DataOutputViewStreamWrapper;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.CheckpointFailureReason;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.state.AbstractKeyedStateBackend;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.DefaultKeyedStateStore;\n+import org.apache.flink.runtime.state.KeyGroupRange;\n+import org.apache.flink.runtime.state.KeyGroupStatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.KeyGroupsList;\n+import org.apache.flink.runtime.state.KeyedStateBackend;\n+import org.apache.flink.runtime.state.KeyedStateCheckpointOutputStream;\n+import org.apache.flink.runtime.state.OperatorStateBackend;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateInitializationContextImpl;\n+import org.apache.flink.runtime.state.StatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.runtime.state.StateSnapshotContextSynchronousImpl;\n+import org.apache.flink.runtime.state.VoidNamespaceSerializer;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.util.CloseableIterable;\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.IOUtils;\n+import org.apache.flink.util.function.ThrowingConsumer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.Optional;\n+\n+/**\n+ * Class encapsulating various state backend handling logic for {@link StreamOperator} implementations.\n+ */\n+@PublicEvolving\n+public class StreamOperatorStateHandler {\n+\n+\tprotected static final Logger LOG = LoggerFactory.getLogger(StreamOperatorStateHandler.class);\n+\n+\t/** Backend for keyed state. This might be empty if we're not on a keyed stream. */\n+\t@Nullable\n+\tprivate final AbstractKeyedStateBackend<?> keyedStateBackend;\n+\tprivate final CloseableRegistry closeableRegistry;\n+\t@Nullable\n+\tprivate final DefaultKeyedStateStore keyedStateStore;\n+\tprivate final OperatorStateBackend operatorStateBackend;\n+\tprivate final InternalTimeServiceManager<?> timeServiceManager;\n+\tprivate final StreamOperatorStateContext context;\n+\n+\tpublic StreamOperatorStateHandler(\n+\t\t\tStreamOperatorStateContext context,\n+\t\t\tExecutionConfig executionConfig,\n+\t\t\tCloseableRegistry closeableRegistry) {\n+\t\tthis.context = context;\n+\t\toperatorStateBackend = context.operatorStateBackend();\n+\t\tkeyedStateBackend = context.keyedStateBackend();\n+\t\tthis.closeableRegistry = closeableRegistry;\n+\n+\t\tif (keyedStateBackend != null) {\n+\t\t\tkeyedStateStore = new DefaultKeyedStateStore(keyedStateBackend, executionConfig);\n+\t\t}\n+\t\telse {\n+\t\t\tkeyedStateStore = null;\n+\t\t}\n+\n+\t\ttimeServiceManager = context.internalTimerServiceManager();\n+\t}\n+\n+\tpublic void initializeOperatorState(ThrowingConsumer<StateInitializationContext, Exception> initializeOperatorAction) throws Exception {\n+\t\tCloseableIterable<KeyGroupStatePartitionStreamProvider> keyedStateInputs = context.rawKeyedStateInputs();\n+\t\tCloseableIterable<StatePartitionStreamProvider> operatorStateInputs = context.rawOperatorStateInputs();\n+\n+\t\ttry {\n+\t\t\tStateInitializationContext initializationContext = new StateInitializationContextImpl(\n+\t\t\t\tcontext.isRestored(), // information whether we restore or start for the first time\n+\t\t\t\toperatorStateBackend, // access to operator state backend\n+\t\t\t\tkeyedStateStore, // access to keyed state backend\n+\t\t\t\tkeyedStateInputs, // access to keyed state stream\n+\t\t\t\toperatorStateInputs); // access to operator state stream\n+\n+\t\t\tinitializeOperatorAction.accept(initializationContext);\n+\t\t} finally {\n+\t\t\tcloseFromRegistry(operatorStateInputs, closeableRegistry);\n+\t\t\tcloseFromRegistry(keyedStateInputs, closeableRegistry);\n+\t\t}\n+\t}\n+\n+\tprivate static void closeFromRegistry(Closeable closeable, CloseableRegistry registry) {\n+\t\tif (registry.unregisterCloseable(closeable)) {\n+\t\t\tIOUtils.closeQuietly(closeable);\n+\t\t}\n+\t}\n+\n+\tpublic void dispose() throws Exception {\n+\n+\t\tException exception = null;\n+\n+\t\ttry {\n+\t\t\tif (closeableRegistry.unregisterCloseable(operatorStateBackend)) {\n+\t\t\t\toperatorStateBackend.close();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = e;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tif (closeableRegistry.unregisterCloseable(keyedStateBackend)) {\n+\t\t\t\tkeyedStateBackend.close();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = ExceptionUtils.firstOrSuppressed(e, exception);\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tif (operatorStateBackend != null) {\n+\t\t\t\toperatorStateBackend.dispose();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = ExceptionUtils.firstOrSuppressed(e, exception);\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tif (keyedStateBackend != null) {\n+\t\t\t\tkeyedStateBackend.dispose();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = ExceptionUtils.firstOrSuppressed(e, exception);\n+\t\t}\n+\n+\t\tif (exception != null) {\n+\t\t\tthrow exception;\n+\t\t}\n+\t}\n+\n+\tpublic OperatorSnapshotFutures snapshotState(\n+\t\t\tThrowingConsumer<StateSnapshotContext, Exception> snapshotStateAction,\n+\t\t\tString operatorName,\n+\t\t\tlong checkpointId,\n+\t\t\tlong timestamp,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory) throws CheckpointException {\n+\t\tKeyGroupRange keyGroupRange = null != keyedStateBackend ?\n+\t\t\tkeyedStateBackend.getKeyGroupRange() : KeyGroupRange.EMPTY_KEY_GROUP_RANGE;\n+\n+\t\tOperatorSnapshotFutures snapshotInProgress = new OperatorSnapshotFutures();\n+\n+\t\tStateSnapshotContextSynchronousImpl snapshotContext = new StateSnapshotContextSynchronousImpl(\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tfactory,\n+\t\t\tkeyGroupRange,\n+\t\t\tcloseableRegistry);\n+\n+\t\treturn snapshotState(\n+\t\t\tsnapshotStateAction,\n+\t\t\toperatorName,\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tcheckpointOptions,\n+\t\t\tfactory,\n+\t\t\tsnapshotInProgress,\n+\t\t\tsnapshotContext);\n+\t}\n+\n+\t@VisibleForTesting\n+\tOperatorSnapshotFutures snapshotState(\n+\t\t\tThrowingConsumer<StateSnapshotContext, Exception> snapshotStateAction,\n+\t\t\tString operatorName,\n+\t\t\tlong checkpointId,\n+\t\t\tlong timestamp,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory,\n+\t\t\tOperatorSnapshotFutures snapshotInProgress,\n+\t\t\tStateSnapshotContextSynchronousImpl snapshotContext) throws CheckpointException {\n+\t\ttry {\n+\t\t\tsnapshotState(snapshotContext, operatorName);\n+\t\t\tsnapshotStateAction.accept(snapshotContext);\n+\n+\t\t\tsnapshotInProgress.setKeyedStateRawFuture(snapshotContext.getKeyedStateStreamFuture());\n+\t\t\tsnapshotInProgress.setOperatorStateRawFuture(snapshotContext.getOperatorStateStreamFuture());\n+\n+\t\t\tif (null != operatorStateBackend) {\n+\t\t\t\tsnapshotInProgress.setOperatorStateManagedFuture(\n+\t\t\t\t\toperatorStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));\n+\t\t\t}\n+\n+\t\t\tif (null != keyedStateBackend) {\n+\t\t\t\tsnapshotInProgress.setKeyedStateManagedFuture(\n+\t\t\t\t\tkeyedStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));\n+\t\t\t}\n+\t\t} catch (Exception snapshotException) {\n+\t\t\ttry {\n+\t\t\t\tsnapshotInProgress.cancel();\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tsnapshotException.addSuppressed(e);\n+\t\t\t}\n+\n+\t\t\tString snapshotFailMessage = \"Could not complete snapshot \" + checkpointId + \" for operator \" +\n+\t\t\t\toperatorName + \".\";\n+\n+\t\t\ttry {\n+\t\t\t\tsnapshotContext.closeExceptionally();\n+\t\t\t} catch (IOException e) {\n+\t\t\t\tsnapshotException.addSuppressed(e);\n+\t\t\t}\n+\t\t\tthrow new CheckpointException(snapshotFailMessage, CheckpointFailureReason.CHECKPOINT_DECLINED, snapshotException);\n+\t\t}\n+\n+\t\treturn snapshotInProgress;\n+\t}\n+\n+\t/**\n+\t * Stream operators with state, which want to participate in a snapshot need to override this hook method.\n+\t *\n+\t * @param context context that provides information and means required for taking a snapshot\n+\t * @param operatorName\n+\t */\n+\tpublic void snapshotState(StateSnapshotContext context, String operatorName) throws Exception {\n+\t\tfinal KeyedStateBackend<?> keyedStateBackend = getKeyedStateBackend();\n+\t\t//TODO all of this can be removed once heap-based timers are integrated with RocksDB incremental snapshots\n+\t\tif (keyedStateBackend instanceof AbstractKeyedStateBackend &&\n+\t\t\t((AbstractKeyedStateBackend<?>) keyedStateBackend).requiresLegacySynchronousTimerSnapshots()) {\n+\n+\t\t\tKeyedStateCheckpointOutputStream out;\n+\n+\t\t\ttry {\n+\t\t\t\tout = context.getRawKeyedOperatorStateOutput();\n+\t\t\t} catch (Exception exception) {\n+\t\t\t\tthrow new Exception(\"Could not open raw keyed operator state stream for \" +\n+\t\t\t\t\toperatorName + '.', exception);\n+\t\t\t}\n+\n+\t\t\ttry {\n+\t\t\t\tKeyGroupsList allKeyGroups = out.getKeyGroupList();\n+\t\t\t\tfor (int keyGroupIdx : allKeyGroups) {\n+\t\t\t\t\tout.startNewKeyGroup(keyGroupIdx);\n+\n+\t\t\t\t\ttimeServiceManager.snapshotStateForKeyGroup(\n+\t\t\t\t\t\tnew DataOutputViewStreamWrapper(out), keyGroupIdx);\n+\t\t\t\t}\n+\t\t\t} catch (Exception exception) {\n+\t\t\t\tthrow new Exception(\"Could not write timer service of \" + operatorName +\n+\t\t\t\t\t\" to checkpoint state stream.\", exception);\n+\t\t\t} finally {\n+\t\t\t\ttry {\n+\t\t\t\t\tout.close();\n+\t\t\t\t} catch (Exception closeException) {\n+\t\t\t\t\tLOG.warn(\"Could not close raw keyed operator state stream for {}. This \" +\n+\t\t\t\t\t\t\"might have prevented deleting some state data.\", operatorName, closeException);\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void notifyCheckpointComplete(long checkpointId) throws Exception {\n+\t\tif (keyedStateBackend != null) {\n+\t\t\tkeyedStateBackend.notifyCheckpointComplete(checkpointId);\n+\t\t}\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic <K> KeyedStateBackend<K> getKeyedStateBackend() {\n+\t\treturn (KeyedStateBackend<K>) keyedStateBackend;\n+\t}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI0NTA3Mg=="}, "originalCommit": {"oid": "c1facefebee52a1ac84f188f46b114deae0aad89"}, "originalPosition": 295}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njk2MTg1Mw==", "bodyText": "Haven't thought about this case . Since it's Experimental, I'm also fine with keeping it for now.\nIn general, I don't think we should mix patterns though.\nHere is some solution:  StreamOperatorFactory could have a default boolean needsMailboxExecutor() { return false; }, which triggers a nullable mailboxExecutor to be set in Parameters. The same method can be used to determine chainability.", "url": "https://github.com/apache/flink/pull/11403#discussion_r396961853", "createdAt": "2020-03-24T08:02:41Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/YieldingOperatorFactory.java", "diffHunk": "@@ -17,10 +17,13 @@\n \n package org.apache.flink.streaming.api.operators;\n \n+import org.apache.flink.annotation.PublicEvolving;\n+\n /**\n  * An operator that needs access to the {@link MailboxExecutor} to yield to downstream operators needs to be created\n  * through a factory implementing this interface.\n  */\n+@PublicEvolving\n public interface YieldingOperatorFactory<OUT> extends StreamOperatorFactory<OUT> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkzMzQ3OA=="}, "originalCommit": {"oid": "c1facefebee52a1ac84f188f46b114deae0aad89"}, "originalPosition": 11}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgwMjE5MTYw", "url": "https://github.com/apache/flink/pull/11403#pullrequestreview-380219160", "createdAt": "2020-03-24T11:27:39Z", "commit": {"oid": "b771b91f3a71291eb6926c5521a3e40d55de5a6f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNFQxMToyNzozOVrOF6r7zg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNFQxMToyNzozOVrOF6r7zg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzA4MTU1MA==", "bodyText": "Operator state snapshot is taken using Consumer snapshotStateAction,\nbut for timeServiceManager we pass it and call directly.\nShould we make it consistent?\nWe could remove opName parameter and then use BiConsumerWithException.\nopName can be turned into a field or exception can be wrapped on a higher level.", "url": "https://github.com/apache/flink/pull/11403#discussion_r397081550", "createdAt": "2020-03-24T11:27:39Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java", "diffHunk": "@@ -0,0 +1,297 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.KeyedStateStore;\n+import org.apache.flink.api.common.state.State;\n+import org.apache.flink.api.common.state.StateDescriptor;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.CheckpointFailureReason;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.state.AbstractKeyedStateBackend;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.DefaultKeyedStateStore;\n+import org.apache.flink.runtime.state.KeyGroupRange;\n+import org.apache.flink.runtime.state.KeyGroupStatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.KeyedStateBackend;\n+import org.apache.flink.runtime.state.OperatorStateBackend;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateInitializationContextImpl;\n+import org.apache.flink.runtime.state.StatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.runtime.state.StateSnapshotContextSynchronousImpl;\n+import org.apache.flink.util.CloseableIterable;\n+import org.apache.flink.util.IOUtils;\n+import org.apache.flink.util.function.ThrowingConsumer;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.io.Closer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.Optional;\n+\n+/**\n+ * Class encapsulating various state backend handling logic for {@link StreamOperator} implementations.\n+ */\n+@Internal\n+public class StreamOperatorStateHandler {\n+\n+\tprotected static final Logger LOG = LoggerFactory.getLogger(StreamOperatorStateHandler.class);\n+\n+\t/** Backend for keyed state. This might be empty if we're not on a keyed stream. */\n+\t@Nullable\n+\tprivate final AbstractKeyedStateBackend<?> keyedStateBackend;\n+\tprivate final CloseableRegistry closeableRegistry;\n+\t@Nullable\n+\tprivate final DefaultKeyedStateStore keyedStateStore;\n+\tprivate final OperatorStateBackend operatorStateBackend;\n+\tprivate final StreamOperatorStateContext context;\n+\n+\tpublic StreamOperatorStateHandler(\n+\t\t\tStreamOperatorStateContext context,\n+\t\t\tExecutionConfig executionConfig,\n+\t\t\tCloseableRegistry closeableRegistry) {\n+\t\tthis.context = context;\n+\t\toperatorStateBackend = context.operatorStateBackend();\n+\t\tkeyedStateBackend = context.keyedStateBackend();\n+\t\tthis.closeableRegistry = closeableRegistry;\n+\n+\t\tif (keyedStateBackend != null) {\n+\t\t\tkeyedStateStore = new DefaultKeyedStateStore(keyedStateBackend, executionConfig);\n+\t\t}\n+\t\telse {\n+\t\t\tkeyedStateStore = null;\n+\t\t}\n+\t}\n+\n+\tpublic void initializeOperatorState(ThrowingConsumer<StateInitializationContext, Exception> initializeOperatorAction) throws Exception {\n+\t\tCloseableIterable<KeyGroupStatePartitionStreamProvider> keyedStateInputs = context.rawKeyedStateInputs();\n+\t\tCloseableIterable<StatePartitionStreamProvider> operatorStateInputs = context.rawOperatorStateInputs();\n+\n+\t\ttry {\n+\t\t\tStateInitializationContext initializationContext = new StateInitializationContextImpl(\n+\t\t\t\tcontext.isRestored(), // information whether we restore or start for the first time\n+\t\t\t\toperatorStateBackend, // access to operator state backend\n+\t\t\t\tkeyedStateStore, // access to keyed state backend\n+\t\t\t\tkeyedStateInputs, // access to keyed state stream\n+\t\t\t\toperatorStateInputs); // access to operator state stream\n+\n+\t\t\tinitializeOperatorAction.accept(initializationContext);\n+\t\t} finally {\n+\t\t\tcloseFromRegistry(operatorStateInputs, closeableRegistry);\n+\t\t\tcloseFromRegistry(keyedStateInputs, closeableRegistry);\n+\t\t}\n+\t}\n+\n+\tprivate static void closeFromRegistry(Closeable closeable, CloseableRegistry registry) {\n+\t\tif (registry.unregisterCloseable(closeable)) {\n+\t\t\tIOUtils.closeQuietly(closeable);\n+\t\t}\n+\t}\n+\n+\tpublic void dispose() throws Exception {\n+\t\ttry (Closer closer = Closer.create()) {\n+\t\t\tif (closeableRegistry.unregisterCloseable(operatorStateBackend)) {\n+\t\t\t\tcloser.register(operatorStateBackend);\n+\t\t\t}\n+\t\t\tif (closeableRegistry.unregisterCloseable(keyedStateBackend)) {\n+\t\t\t\tcloser.register(keyedStateBackend);\n+\t\t\t}\n+\t\t\tif (operatorStateBackend != null) {\n+\t\t\t\tcloser.register(() -> operatorStateBackend.dispose());\n+\t\t\t}\n+\t\t\tif (keyedStateBackend != null) {\n+\t\t\t\tcloser.register(() -> keyedStateBackend.dispose());\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic OperatorSnapshotFutures snapshotState(\n+\t\t\tThrowingConsumer<StateSnapshotContext, Exception> snapshotStateAction,\n+\t\t\tInternalTimeServiceManager<?> timeServiceManager,\n+\t\t\tString operatorName,\n+\t\t\tlong checkpointId,\n+\t\t\tlong timestamp,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory) throws CheckpointException {\n+\t\tKeyGroupRange keyGroupRange = null != keyedStateBackend ?\n+\t\t\tkeyedStateBackend.getKeyGroupRange() : KeyGroupRange.EMPTY_KEY_GROUP_RANGE;\n+\n+\t\tOperatorSnapshotFutures snapshotInProgress = new OperatorSnapshotFutures();\n+\n+\t\tStateSnapshotContextSynchronousImpl snapshotContext = new StateSnapshotContextSynchronousImpl(\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tfactory,\n+\t\t\tkeyGroupRange,\n+\t\t\tcloseableRegistry);\n+\n+\t\tsnapshotState(\n+\t\t\tsnapshotStateAction,\n+\t\t\ttimeServiceManager,\n+\t\t\toperatorName,\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tcheckpointOptions,\n+\t\t\tfactory,\n+\t\t\tsnapshotInProgress,\n+\t\t\tsnapshotContext);\n+\n+\t\treturn snapshotInProgress;\n+\t}\n+\n+\t@VisibleForTesting\n+\tvoid snapshotState(\n+\t\t\tThrowingConsumer<StateSnapshotContext, Exception> snapshotStateAction,\n+\t\t\tInternalTimeServiceManager<?> timeServiceManager,\n+\t\t\tString operatorName,\n+\t\t\tlong checkpointId,\n+\t\t\tlong timestamp,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory,\n+\t\t\tOperatorSnapshotFutures snapshotInProgress,\n+\t\t\tStateSnapshotContextSynchronousImpl snapshotContext) throws CheckpointException {\n+\t\ttry {\n+\t\t\ttimeServiceManager.snapshotState(keyedStateBackend, snapshotContext, operatorName);\n+\t\t\tsnapshotStateAction.accept(snapshotContext);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b771b91f3a71291eb6926c5521a3e40d55de5a6f"}, "originalPosition": 182}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "17a0f2628aad246c23018195a3980e552aca36df", "author": {"user": {"login": "pnowojski", "name": "Piotr Nowojski"}}, "url": "https://github.com/apache/flink/commit/17a0f2628aad246c23018195a3980e552aca36df", "committedDate": "2020-03-24T12:20:06Z", "message": "[FLINK-16316][task] Remove StreamTask dependency from AbstractStreamOperator#snapshotState"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5d5b4fb4bf0ee156f05b465ed3630905114c7358", "author": {"user": {"login": "pnowojski", "name": "Piotr Nowojski"}}, "url": "https://github.com/apache/flink/commit/5d5b4fb4bf0ee156f05b465ed3630905114c7358", "committedDate": "2020-03-24T12:20:08Z", "message": "[FLINK-16316][operators] Remove chaining strategy methods from the StreamOperator interface\n\nThose methods do not have any reason to be on the StreamOperator level since we introduced\nStreamOperatorFactory concept, so they should be moved to SetupableStreamOperator"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d7f53e983fee8f37638fce4b42c86a8f36b8c586", "author": {"user": {"login": "pnowojski", "name": "Piotr Nowojski"}}, "url": "https://github.com/apache/flink/commit/d7f53e983fee8f37638fce4b42c86a8f36b8c586", "committedDate": "2020-03-24T12:20:09Z", "message": "[FLINK-16316][operators] Pass StreamTaskStateInitializer to operators from outside\n\nThis removes another dependency on the StreamTask from AbstractStreamOperator"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "80d7744ad7a39cb05fdc1ba6f473f85da9b09ac0", "author": {"user": {"login": "pnowojski", "name": "Piotr Nowojski"}}, "url": "https://github.com/apache/flink/commit/80d7744ad7a39cb05fdc1ba6f473f85da9b09ac0", "committedDate": "2020-03-24T12:20:10Z", "message": "[hotfix][test] Fix formatting in AbstractStreamOperatorTest"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cf3c5304a20da6a7b725f7b8983236ccc5e111f8", "author": {"user": {"login": "pnowojski", "name": "Piotr Nowojski"}}, "url": "https://github.com/apache/flink/commit/cf3c5304a20da6a7b725f7b8983236ccc5e111f8", "committedDate": "2020-03-24T12:20:12Z", "message": "[hotfix][test] Remove no-op tests for AbstractStreamOperator\n\nThose two tests were not performing any assertions since [FLINK-13326] (c75af84d44dfb9b883115bf4fd65b6a5989464e4)"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b771b91f3a71291eb6926c5521a3e40d55de5a6f", "author": {"user": {"login": "pnowojski", "name": "Piotr Nowojski"}}, "url": "https://github.com/apache/flink/commit/b771b91f3a71291eb6926c5521a3e40d55de5a6f", "committedDate": "2020-03-23T17:12:38Z", "message": "[FLINK-16316][operators] Make StreamOperatorFactory Experimental"}, "afterCommit": {"oid": "ab7f6c9a2a2ab86a0fd8fa78a1aab35aa0145533", "author": {"user": {"login": "pnowojski", "name": "Piotr Nowojski"}}, "url": "https://github.com/apache/flink/commit/ab7f6c9a2a2ab86a0fd8fa78a1aab35aa0145533", "committedDate": "2020-03-24T12:20:20Z", "message": "[FLINK-16316][operators] Make StreamOperatorFactory Experimental"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ab7f6c9a2a2ab86a0fd8fa78a1aab35aa0145533", "author": {"user": {"login": "pnowojski", "name": "Piotr Nowojski"}}, "url": "https://github.com/apache/flink/commit/ab7f6c9a2a2ab86a0fd8fa78a1aab35aa0145533", "committedDate": "2020-03-24T12:20:20Z", "message": "[FLINK-16316][operators] Make StreamOperatorFactory Experimental"}, "afterCommit": {"oid": "af33b0c91276a144e31fe788196f861da3a766f1", "author": {"user": {"login": "pnowojski", "name": "Piotr Nowojski"}}, "url": "https://github.com/apache/flink/commit/af33b0c91276a144e31fe788196f861da3a766f1", "committedDate": "2020-03-24T13:56:34Z", "message": "[FLINK-16316][operators] Make StreamOperatorFactory Experimental"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "265474afad0690193c2b195e8293c0f530037335", "author": {"user": {"login": "pnowojski", "name": "Piotr Nowojski"}}, "url": "https://github.com/apache/flink/commit/265474afad0690193c2b195e8293c0f530037335", "committedDate": "2020-03-24T16:05:29Z", "message": "[FLINK-16316][operators] Extract state handling code from AbstractStreamOperator\n\nIntroduce StreamOperatorStateHandler class for that purpose and move more logic into\nIntrenalTimeServiceManager.\n\nThis makes AbstractStreamOperator a simpler class and will allow to deduplicate code with\nnew replacement of AbstractStreamOperator that will come soon."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b9283b31291a29c829856682b92db1f76b3b59e9", "author": {"user": {"login": "pnowojski", "name": "Piotr Nowojski"}}, "url": "https://github.com/apache/flink/commit/b9283b31291a29c829856682b92db1f76b3b59e9", "committedDate": "2020-03-24T16:05:30Z", "message": "[FLINK-16316][operators] Cut dependency between StreamingRuntimeContext and AbstractStreamOperator\n\nThis simplifies dependencies between those two classes and will allow for StreamingRuntimeContext\nto be re-used in new replacement for AbstractStreamOperator."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "290c2fa43d4bd8ac8e6d21c1bacd7aea010d6332", "author": {"user": {"login": "pnowojski", "name": "Piotr Nowojski"}}, "url": "https://github.com/apache/flink/commit/290c2fa43d4bd8ac8e6d21c1bacd7aea010d6332", "committedDate": "2020-03-24T16:05:32Z", "message": "[FLINK-16316][operators] Move inner CountingClass class out from AbstractStreamOperator"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3d1a3e0164d6ab44c10bc16df582c725ceadc8e5", "author": {"user": {"login": "pnowojski", "name": "Piotr Nowojski"}}, "url": "https://github.com/apache/flink/commit/3d1a3e0164d6ab44c10bc16df582c725ceadc8e5", "committedDate": "2020-03-24T16:05:33Z", "message": "[FLINK-16316][operators] Introduce StreamOperatorParameters class\n\nNew POJO class will make Public and PublicEvolving interfaces more stable\nand easier to use. User will not have to pass n parameters, but just this\none POJO."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "464da82dd19bcbcfda733a1efb185aeff7bb18a8", "author": {"user": {"login": "pnowojski", "name": "Piotr Nowojski"}}, "url": "https://github.com/apache/flink/commit/464da82dd19bcbcfda733a1efb185aeff7bb18a8", "committedDate": "2020-03-24T16:05:34Z", "message": "[FLINK-16316][operators] Implement new AbstractStreamOperatorV2 as a replacement for AbstractStreamOperator\n\nThe new base class for operators tries to address couple of limitations in the AbstractStreamOperator like:\n- lack of support for multiple inputs\n- setup(...) method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ef4235ea44fb27303cc8355de9111fe545e8d580", "author": {"user": {"login": "pnowojski", "name": "Piotr Nowojski"}}, "url": "https://github.com/apache/flink/commit/ef4235ea44fb27303cc8355de9111fe545e8d580", "committedDate": "2020-03-24T16:05:36Z", "message": "[FLINK-16316][operators] Make StreamOperatorFactory Experimental"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "af33b0c91276a144e31fe788196f861da3a766f1", "author": {"user": {"login": "pnowojski", "name": "Piotr Nowojski"}}, "url": "https://github.com/apache/flink/commit/af33b0c91276a144e31fe788196f861da3a766f1", "committedDate": "2020-03-24T13:56:34Z", "message": "[FLINK-16316][operators] Make StreamOperatorFactory Experimental"}, "afterCommit": {"oid": "ef4235ea44fb27303cc8355de9111fe545e8d580", "author": {"user": {"login": "pnowojski", "name": "Piotr Nowojski"}}, "url": "https://github.com/apache/flink/commit/ef4235ea44fb27303cc8355de9111fe545e8d580", "committedDate": "2020-03-24T16:05:36Z", "message": "[FLINK-16316][operators] Make StreamOperatorFactory Experimental"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgxMDczMzAy", "url": "https://github.com/apache/flink/pull/11403#pullrequestreview-381073302", "createdAt": "2020-03-25T11:46:10Z", "commit": {"oid": "ef4235ea44fb27303cc8355de9111fe545e8d580"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQxMTo0NjoxMVrOF7XYZg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQxMTo0NjoxMVrOF7XYZg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzc5MzM4Mg==", "bodyText": "This interface is implemented by @PublicEvolving AbstractStreamOperator (which is de-facto API).\nShould it be a top-level @PublicEvolving class then?\nWith Javadoc moved from AbstractStreamOperator into it.", "url": "https://github.com/apache/flink/pull/11403#discussion_r397793382", "createdAt": "2020-03-25T11:46:11Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.KeyedStateStore;\n+import org.apache.flink.api.common.state.State;\n+import org.apache.flink.api.common.state.StateDescriptor;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.CheckpointFailureReason;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.state.AbstractKeyedStateBackend;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.DefaultKeyedStateStore;\n+import org.apache.flink.runtime.state.KeyGroupRange;\n+import org.apache.flink.runtime.state.KeyGroupStatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.KeyedStateBackend;\n+import org.apache.flink.runtime.state.OperatorStateBackend;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateInitializationContextImpl;\n+import org.apache.flink.runtime.state.StatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.runtime.state.StateSnapshotContextSynchronousImpl;\n+import org.apache.flink.util.CloseableIterable;\n+import org.apache.flink.util.IOUtils;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.io.Closer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.Optional;\n+\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * Class encapsulating various state backend handling logic for {@link StreamOperator} implementations.\n+ */\n+@Internal\n+public class StreamOperatorStateHandler {\n+\n+\tprotected static final Logger LOG = LoggerFactory.getLogger(StreamOperatorStateHandler.class);\n+\n+\t/** Backend for keyed state. This might be empty if we're not on a keyed stream. */\n+\t@Nullable\n+\tprivate final AbstractKeyedStateBackend<?> keyedStateBackend;\n+\tprivate final CloseableRegistry closeableRegistry;\n+\t@Nullable\n+\tprivate final DefaultKeyedStateStore keyedStateStore;\n+\tprivate final OperatorStateBackend operatorStateBackend;\n+\tprivate final StreamOperatorStateContext context;\n+\n+\tpublic StreamOperatorStateHandler(\n+\t\t\tStreamOperatorStateContext context,\n+\t\t\tExecutionConfig executionConfig,\n+\t\t\tCloseableRegistry closeableRegistry) {\n+\t\tthis.context = context;\n+\t\toperatorStateBackend = context.operatorStateBackend();\n+\t\tkeyedStateBackend = context.keyedStateBackend();\n+\t\tthis.closeableRegistry = closeableRegistry;\n+\n+\t\tif (keyedStateBackend != null) {\n+\t\t\tkeyedStateStore = new DefaultKeyedStateStore(keyedStateBackend, executionConfig);\n+\t\t}\n+\t\telse {\n+\t\t\tkeyedStateStore = null;\n+\t\t}\n+\t}\n+\n+\tpublic void initializeOperatorState(CheckpointedStreamOperator streamOperator) throws Exception {\n+\t\tCloseableIterable<KeyGroupStatePartitionStreamProvider> keyedStateInputs = context.rawKeyedStateInputs();\n+\t\tCloseableIterable<StatePartitionStreamProvider> operatorStateInputs = context.rawOperatorStateInputs();\n+\n+\t\ttry {\n+\t\t\tStateInitializationContext initializationContext = new StateInitializationContextImpl(\n+\t\t\t\tcontext.isRestored(), // information whether we restore or start for the first time\n+\t\t\t\toperatorStateBackend, // access to operator state backend\n+\t\t\t\tkeyedStateStore, // access to keyed state backend\n+\t\t\t\tkeyedStateInputs, // access to keyed state stream\n+\t\t\t\toperatorStateInputs); // access to operator state stream\n+\n+\t\t\tstreamOperator.initializeState(initializationContext);\n+\t\t} finally {\n+\t\t\tcloseFromRegistry(operatorStateInputs, closeableRegistry);\n+\t\t\tcloseFromRegistry(keyedStateInputs, closeableRegistry);\n+\t\t}\n+\t}\n+\n+\tprivate static void closeFromRegistry(Closeable closeable, CloseableRegistry registry) {\n+\t\tif (registry.unregisterCloseable(closeable)) {\n+\t\t\tIOUtils.closeQuietly(closeable);\n+\t\t}\n+\t}\n+\n+\tpublic void dispose() throws Exception {\n+\t\ttry (Closer closer = Closer.create()) {\n+\t\t\tif (closeableRegistry.unregisterCloseable(operatorStateBackend)) {\n+\t\t\t\tcloser.register(operatorStateBackend);\n+\t\t\t}\n+\t\t\tif (closeableRegistry.unregisterCloseable(keyedStateBackend)) {\n+\t\t\t\tcloser.register(keyedStateBackend);\n+\t\t\t}\n+\t\t\tif (operatorStateBackend != null) {\n+\t\t\t\tcloser.register(() -> operatorStateBackend.dispose());\n+\t\t\t}\n+\t\t\tif (keyedStateBackend != null) {\n+\t\t\t\tcloser.register(() -> keyedStateBackend.dispose());\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic OperatorSnapshotFutures snapshotState(\n+\t\t\tCheckpointedStreamOperator streamOperator,\n+\t\t\tOptional<InternalTimeServiceManager<?>> timeServiceManager,\n+\t\t\tString operatorName,\n+\t\t\tlong checkpointId,\n+\t\t\tlong timestamp,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory) throws CheckpointException {\n+\t\tKeyGroupRange keyGroupRange = null != keyedStateBackend ?\n+\t\t\tkeyedStateBackend.getKeyGroupRange() : KeyGroupRange.EMPTY_KEY_GROUP_RANGE;\n+\n+\t\tOperatorSnapshotFutures snapshotInProgress = new OperatorSnapshotFutures();\n+\n+\t\tStateSnapshotContextSynchronousImpl snapshotContext = new StateSnapshotContextSynchronousImpl(\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tfactory,\n+\t\t\tkeyGroupRange,\n+\t\t\tcloseableRegistry);\n+\n+\t\tsnapshotState(\n+\t\t\tstreamOperator,\n+\t\t\ttimeServiceManager,\n+\t\t\toperatorName,\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tcheckpointOptions,\n+\t\t\tfactory,\n+\t\t\tsnapshotInProgress,\n+\t\t\tsnapshotContext);\n+\n+\t\treturn snapshotInProgress;\n+\t}\n+\n+\t@VisibleForTesting\n+\tvoid snapshotState(\n+\t\t\tCheckpointedStreamOperator streamOperator,\n+\t\t\tOptional<InternalTimeServiceManager<?>> timeServiceManager,\n+\t\t\tString operatorName,\n+\t\t\tlong checkpointId,\n+\t\t\tlong timestamp,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory,\n+\t\t\tOperatorSnapshotFutures snapshotInProgress,\n+\t\t\tStateSnapshotContextSynchronousImpl snapshotContext) throws CheckpointException {\n+\t\ttry {\n+\t\t\tif (timeServiceManager.isPresent()) {\n+\t\t\t\tcheckState(keyedStateBackend != null, \"keyedStateBackend should be available with timeServiceManager\");\n+\t\t\t\ttimeServiceManager.get().snapshotState(keyedStateBackend, snapshotContext, operatorName);\n+\t\t\t}\n+\t\t\tstreamOperator.snapshotState(snapshotContext);\n+\n+\t\t\tsnapshotInProgress.setKeyedStateRawFuture(snapshotContext.getKeyedStateStreamFuture());\n+\t\t\tsnapshotInProgress.setOperatorStateRawFuture(snapshotContext.getOperatorStateStreamFuture());\n+\n+\t\t\tif (null != operatorStateBackend) {\n+\t\t\t\tsnapshotInProgress.setOperatorStateManagedFuture(\n+\t\t\t\t\toperatorStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));\n+\t\t\t}\n+\n+\t\t\tif (null != keyedStateBackend) {\n+\t\t\t\tsnapshotInProgress.setKeyedStateManagedFuture(\n+\t\t\t\t\tkeyedStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));\n+\t\t\t}\n+\t\t} catch (Exception snapshotException) {\n+\t\t\ttry {\n+\t\t\t\tsnapshotInProgress.cancel();\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tsnapshotException.addSuppressed(e);\n+\t\t\t}\n+\n+\t\t\tString snapshotFailMessage = \"Could not complete snapshot \" + checkpointId + \" for operator \" +\n+\t\t\t\toperatorName + \".\";\n+\n+\t\t\ttry {\n+\t\t\t\tsnapshotContext.closeExceptionally();\n+\t\t\t} catch (IOException e) {\n+\t\t\t\tsnapshotException.addSuppressed(e);\n+\t\t\t}\n+\t\t\tthrow new CheckpointException(snapshotFailMessage, CheckpointFailureReason.CHECKPOINT_DECLINED, snapshotException);\n+\t\t}\n+\t}\n+\n+\tpublic void notifyCheckpointComplete(long checkpointId) throws Exception {\n+\t\tif (keyedStateBackend != null) {\n+\t\t\tkeyedStateBackend.notifyCheckpointComplete(checkpointId);\n+\t\t}\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic <K> KeyedStateBackend<K> getKeyedStateBackend() {\n+\t\treturn (KeyedStateBackend<K>) keyedStateBackend;\n+\t}\n+\n+\tpublic OperatorStateBackend getOperatorStateBackend() {\n+\t\treturn operatorStateBackend;\n+\t}\n+\n+\tpublic <N, S extends State, T> S getOrCreateKeyedState(\n+\t\t\tTypeSerializer<N> namespaceSerializer,\n+\t\t\tStateDescriptor<S, T> stateDescriptor) throws Exception {\n+\n+\t\tif (keyedStateStore != null) {\n+\t\t\treturn keyedStateBackend.getOrCreateKeyedState(namespaceSerializer, stateDescriptor);\n+\t\t}\n+\t\telse {\n+\t\t\tthrow new IllegalStateException(\"Cannot create partitioned state. \" +\n+\t\t\t\t\t\"The keyed state backend has not been set.\" +\n+\t\t\t\t\t\"This indicates that the operator is not partitioned/keyed.\");\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Creates a partitioned state handle, using the state backend configured for this task.\n+\t *\n+\t * @throws IllegalStateException Thrown, if the key/value state was already initialized.\n+\t * @throws Exception Thrown, if the state backend cannot create the key/value state.\n+\t */\n+\tprotected <S extends State, N> S getPartitionedState(\n+\t\t\tN namespace,\n+\t\t\tTypeSerializer<N> namespaceSerializer,\n+\t\t\tStateDescriptor<S, ?> stateDescriptor) throws Exception {\n+\n+\t\t/*\n+\t    TODO: NOTE: This method does a lot of work caching / retrieving states just to update the namespace.\n+\t    This method should be removed for the sake of namespaces being lazily fetched from the keyed\n+\t    state backend, or being set on the state directly.\n+\t    */\n+\n+\t\tif (keyedStateStore != null) {\n+\t\t\treturn keyedStateBackend.getPartitionedState(namespace, namespaceSerializer, stateDescriptor);\n+\t\t} else {\n+\t\t\tthrow new RuntimeException(\"Cannot create partitioned state. The keyed state \" +\n+\t\t\t\t\"backend has not been set. This indicates that the operator is not \" +\n+\t\t\t\t\"partitioned/keyed.\");\n+\t\t}\n+\t}\n+\n+\t@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+\tpublic void setCurrentKey(Object key) {\n+\t\tif (keyedStateBackend != null) {\n+\t\t\ttry {\n+\t\t\t\t// need to work around type restrictions\n+\t\t\t\t@SuppressWarnings(\"unchecked,rawtypes\")\n+\t\t\t\tAbstractKeyedStateBackend rawBackend = (AbstractKeyedStateBackend) keyedStateBackend;\n+\n+\t\t\t\trawBackend.setCurrentKey(key);\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tthrow new RuntimeException(\"Exception occurred while setting the current key context.\", e);\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\t@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+\tpublic Object getCurrentKey() {\n+\t\tif (keyedStateBackend != null) {\n+\t\t\treturn keyedStateBackend.getCurrentKey();\n+\t\t} else {\n+\t\t\tthrow new UnsupportedOperationException(\"Key can only be retrieved on KeyedStream.\");\n+\t\t}\n+\t}\n+\n+\tpublic Optional<KeyedStateStore> getKeyedStateStore() {\n+\t\treturn Optional.ofNullable(keyedStateStore);\n+\t}\n+\n+\t/**\n+\t * Custom state handling hooks to be invoked by {@link StreamOperatorStateHandler}.\n+\t */\n+\tpublic interface CheckpointedStreamOperator {\n+\t\tvoid initializeState(StateInitializationContext context) throws Exception;\n+\n+\t\tvoid snapshotState(StateSnapshotContext context) throws Exception;\n+\t}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ef4235ea44fb27303cc8355de9111fe545e8d580"}, "originalPosition": 309}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgxMDc1MTMz", "url": "https://github.com/apache/flink/pull/11403#pullrequestreview-381075133", "createdAt": "2020-03-25T11:49:07Z", "commit": {"oid": "ef4235ea44fb27303cc8355de9111fe545e8d580"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQxMTo0OTowN1rOF7XeNg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQxMTo0OTowN1rOF7XeNg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzc5NDg3MA==", "bodyText": "nit: ifPresent could be used instead to get rid of get().\n(exception thrown by snapshotState could/should be runtime)", "url": "https://github.com/apache/flink/pull/11403#discussion_r397794870", "createdAt": "2020-03-25T11:49:07Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.KeyedStateStore;\n+import org.apache.flink.api.common.state.State;\n+import org.apache.flink.api.common.state.StateDescriptor;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.CheckpointFailureReason;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.state.AbstractKeyedStateBackend;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.DefaultKeyedStateStore;\n+import org.apache.flink.runtime.state.KeyGroupRange;\n+import org.apache.flink.runtime.state.KeyGroupStatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.KeyedStateBackend;\n+import org.apache.flink.runtime.state.OperatorStateBackend;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateInitializationContextImpl;\n+import org.apache.flink.runtime.state.StatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.runtime.state.StateSnapshotContextSynchronousImpl;\n+import org.apache.flink.util.CloseableIterable;\n+import org.apache.flink.util.IOUtils;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.io.Closer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.Optional;\n+\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * Class encapsulating various state backend handling logic for {@link StreamOperator} implementations.\n+ */\n+@Internal\n+public class StreamOperatorStateHandler {\n+\n+\tprotected static final Logger LOG = LoggerFactory.getLogger(StreamOperatorStateHandler.class);\n+\n+\t/** Backend for keyed state. This might be empty if we're not on a keyed stream. */\n+\t@Nullable\n+\tprivate final AbstractKeyedStateBackend<?> keyedStateBackend;\n+\tprivate final CloseableRegistry closeableRegistry;\n+\t@Nullable\n+\tprivate final DefaultKeyedStateStore keyedStateStore;\n+\tprivate final OperatorStateBackend operatorStateBackend;\n+\tprivate final StreamOperatorStateContext context;\n+\n+\tpublic StreamOperatorStateHandler(\n+\t\t\tStreamOperatorStateContext context,\n+\t\t\tExecutionConfig executionConfig,\n+\t\t\tCloseableRegistry closeableRegistry) {\n+\t\tthis.context = context;\n+\t\toperatorStateBackend = context.operatorStateBackend();\n+\t\tkeyedStateBackend = context.keyedStateBackend();\n+\t\tthis.closeableRegistry = closeableRegistry;\n+\n+\t\tif (keyedStateBackend != null) {\n+\t\t\tkeyedStateStore = new DefaultKeyedStateStore(keyedStateBackend, executionConfig);\n+\t\t}\n+\t\telse {\n+\t\t\tkeyedStateStore = null;\n+\t\t}\n+\t}\n+\n+\tpublic void initializeOperatorState(CheckpointedStreamOperator streamOperator) throws Exception {\n+\t\tCloseableIterable<KeyGroupStatePartitionStreamProvider> keyedStateInputs = context.rawKeyedStateInputs();\n+\t\tCloseableIterable<StatePartitionStreamProvider> operatorStateInputs = context.rawOperatorStateInputs();\n+\n+\t\ttry {\n+\t\t\tStateInitializationContext initializationContext = new StateInitializationContextImpl(\n+\t\t\t\tcontext.isRestored(), // information whether we restore or start for the first time\n+\t\t\t\toperatorStateBackend, // access to operator state backend\n+\t\t\t\tkeyedStateStore, // access to keyed state backend\n+\t\t\t\tkeyedStateInputs, // access to keyed state stream\n+\t\t\t\toperatorStateInputs); // access to operator state stream\n+\n+\t\t\tstreamOperator.initializeState(initializationContext);\n+\t\t} finally {\n+\t\t\tcloseFromRegistry(operatorStateInputs, closeableRegistry);\n+\t\t\tcloseFromRegistry(keyedStateInputs, closeableRegistry);\n+\t\t}\n+\t}\n+\n+\tprivate static void closeFromRegistry(Closeable closeable, CloseableRegistry registry) {\n+\t\tif (registry.unregisterCloseable(closeable)) {\n+\t\t\tIOUtils.closeQuietly(closeable);\n+\t\t}\n+\t}\n+\n+\tpublic void dispose() throws Exception {\n+\t\ttry (Closer closer = Closer.create()) {\n+\t\t\tif (closeableRegistry.unregisterCloseable(operatorStateBackend)) {\n+\t\t\t\tcloser.register(operatorStateBackend);\n+\t\t\t}\n+\t\t\tif (closeableRegistry.unregisterCloseable(keyedStateBackend)) {\n+\t\t\t\tcloser.register(keyedStateBackend);\n+\t\t\t}\n+\t\t\tif (operatorStateBackend != null) {\n+\t\t\t\tcloser.register(() -> operatorStateBackend.dispose());\n+\t\t\t}\n+\t\t\tif (keyedStateBackend != null) {\n+\t\t\t\tcloser.register(() -> keyedStateBackend.dispose());\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic OperatorSnapshotFutures snapshotState(\n+\t\t\tCheckpointedStreamOperator streamOperator,\n+\t\t\tOptional<InternalTimeServiceManager<?>> timeServiceManager,\n+\t\t\tString operatorName,\n+\t\t\tlong checkpointId,\n+\t\t\tlong timestamp,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory) throws CheckpointException {\n+\t\tKeyGroupRange keyGroupRange = null != keyedStateBackend ?\n+\t\t\tkeyedStateBackend.getKeyGroupRange() : KeyGroupRange.EMPTY_KEY_GROUP_RANGE;\n+\n+\t\tOperatorSnapshotFutures snapshotInProgress = new OperatorSnapshotFutures();\n+\n+\t\tStateSnapshotContextSynchronousImpl snapshotContext = new StateSnapshotContextSynchronousImpl(\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tfactory,\n+\t\t\tkeyGroupRange,\n+\t\t\tcloseableRegistry);\n+\n+\t\tsnapshotState(\n+\t\t\tstreamOperator,\n+\t\t\ttimeServiceManager,\n+\t\t\toperatorName,\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tcheckpointOptions,\n+\t\t\tfactory,\n+\t\t\tsnapshotInProgress,\n+\t\t\tsnapshotContext);\n+\n+\t\treturn snapshotInProgress;\n+\t}\n+\n+\t@VisibleForTesting\n+\tvoid snapshotState(\n+\t\t\tCheckpointedStreamOperator streamOperator,\n+\t\t\tOptional<InternalTimeServiceManager<?>> timeServiceManager,\n+\t\t\tString operatorName,\n+\t\t\tlong checkpointId,\n+\t\t\tlong timestamp,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory,\n+\t\t\tOperatorSnapshotFutures snapshotInProgress,\n+\t\t\tStateSnapshotContextSynchronousImpl snapshotContext) throws CheckpointException {\n+\t\ttry {\n+\t\t\tif (timeServiceManager.isPresent()) {\n+\t\t\t\tcheckState(keyedStateBackend != null, \"keyedStateBackend should be available with timeServiceManager\");\n+\t\t\t\ttimeServiceManager.get().snapshotState(keyedStateBackend, snapshotContext, operatorName);\n+\t\t\t}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ef4235ea44fb27303cc8355de9111fe545e8d580"}, "originalPosition": 185}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgxMDk4ODgz", "url": "https://github.com/apache/flink/pull/11403#pullrequestreview-381098883", "createdAt": "2020-03-25T12:26:40Z", "commit": {"oid": "ef4235ea44fb27303cc8355de9111fe545e8d580"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2773, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}