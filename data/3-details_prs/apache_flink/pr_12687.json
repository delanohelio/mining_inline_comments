{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDM1MzM4NDU1", "number": 12687, "title": "[FLINK-17678][hbase] Support fink-sql-connector-hbase", "bodyText": "What is the purpose of the change\n\n\nFlink doesn't contains a hbase shade jar right now, so users have to add hbase dependency manually. This pull request import a new flink-sql-connector-hbase module likes flink-sql-connector-elasticsearch7 to offer bundled jar.\n\n\nSpecially, this PR is inspired by #12369\uff0c #9898\n\n\nBrief change log\n\nAdd new modular flink-sql-connector-hbase.\nAdd new modular flink-end-to-end-test-hbase.\n\nVerifying this change\n\nEnd2end test SQLClientHbaseITCase covered\nThe new module flink-sql-connector-hbase only includes necessary dependencies that used to reading or writing data from/to hbase. And the module flink-end-to-end-test-hbase, just as name implies, is used for hbase e2e test.\n\n(1) We do not shade hadoop dependencies into the jar. Because flink-sql-connector-hive doesn't contains either, so we do this in similar way.\n(2) We shade all dependencies that hbase needed but except org.apache.hadoop.hbase.codec.* for preventing hbase region server throw timeout exception . Because the hbase region server can not find the shaded codec class to decoding data(byte[]).\n(3) We add a new module, flink-end-to-end-test-hbase, only for e2e test.\nDoes this pull request potentially affect one of the following parts:\n\nDependencies (does it add or upgrade a dependency): (no)\nThe public API, i.e., is any changed class annotated with @Public(Evolving): (no)\nThe serializers: (no)\nThe runtime per-record code paths (performance sensitive): ( no)\nAnything that affects deployment or recovery: JobManager (and its components), Checkpointing, Yarn/Mesos, ZooKeeper: (no)\nThe S3 file system connector: (no)\n\nDocumentation\n\nDoes this pull request introduce a new feature? (no)\nIf yes, how is the feature documented? (not applicable / docs / JavaDocs / not documented)", "createdAt": "2020-06-16T16:36:55Z", "url": "https://github.com/apache/flink/pull/12687", "merged": true, "mergeCommit": {"oid": "6c7416a733505ca2dc16e68208ac718953a7eb0e"}, "closed": true, "closedAt": "2020-06-23T02:44:25Z", "author": {"login": "leonardBang"}, "timelineItems": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcsEL-ZgBqjM0NTIwODM0MTE=", "endCursor": "Y3Vyc29yOnYyOpPPAAABctv1hEABqjM0NjgwNjQ0NzE=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b0a58a724af992da53061c770b18813c3bab69b5", "author": {"user": {"login": "leonardBang", "name": "Leonard Xu"}}, "url": "https://github.com/apache/flink/commit/b0a58a724af992da53061c770b18813c3bab69b5", "committedDate": "2020-06-16T16:24:01Z", "message": "update"}, "afterCommit": {"oid": "472ebc575789c2d6e5f5d6ac50bfd54c93c600ea", "author": {"user": {"login": "leonardBang", "name": "Leonard Xu"}}, "url": "https://github.com/apache/flink/commit/472ebc575789c2d6e5f5d6ac50bfd54c93c600ea", "committedDate": "2020-06-17T06:49:56Z", "message": "update e2e test with new connector format"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMyMTE0Mjcz", "url": "https://github.com/apache/flink/pull/12687#pullrequestreview-432114273", "createdAt": "2020-06-17T07:06:16Z", "commit": {"oid": "472ebc575789c2d6e5f5d6ac50bfd54c93c600ea"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QwNzowNjoxNlrOGk4YjQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QwNzoxMTozN1rOGk4i3A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTMyNTcwOQ==", "bodyText": "Add license file for protobuf", "url": "https://github.com/apache/flink/pull/12687#discussion_r441325709", "createdAt": "2020-06-17T07:06:16Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-sql-connector-hbase/src/main/resources/META-INF/NOTICE", "diffHunk": "@@ -0,0 +1,27 @@\n+flink-sql-connector-hbase\n+Copyright 2014-2020 The Apache Software Foundation\n+\n+This product includes software developed at\n+The Apache Software Foundation (http://www.apache.org/).\n+\n+This project bundles the following dependencies under the Apache Software License 2.0. (http://www.apache.org/licenses/LICENSE-2.0.txt)\n+\n+- org.apache.hbase:hbase-common:1.4.3\n+- org.apache.hbase:hbase-protocol:1.4.3\n+- org.apache.hbase:hbase-procedure:1.4.3\n+- org.apache.hbase:hbase-client:1.4.3\n+- org.apache.hbase:hbase-prefix-tree:1.4.3\n+- org.apache.htrace:htrace-core:3.1.0-incubating\n+- org.apache.zookeeper:zookeeper:3.4.14\n+- commons-codec:commons-codec:1.10\n+- commons-configuration:commons-configuration:1.7\n+- commons-lang:commons-lang:2.6\n+- commons-logging:commons-logging:1.1.3\n+- com.google.guava:guava:12.0.1\n+- com.yammer.metrics:metrics-core:2.2.0\n+- io.netty:netty-all:4.1.44.Final\n+\n+This project bundles the following dependencies under the BSD license.\n+See bundled license files for details.\n+\n+- com.google.protobuf:protobuf-java:2.5.0", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "472ebc575789c2d6e5f5d6ac50bfd54c93c600ea"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTMyODM0OA==", "bodyText": "sort them by order", "url": "https://github.com/apache/flink/pull/12687#discussion_r441328348", "createdAt": "2020-06-17T07:11:37Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-sql-connector-hbase/src/main/resources/META-INF/NOTICE", "diffHunk": "@@ -0,0 +1,27 @@\n+flink-sql-connector-hbase\n+Copyright 2014-2020 The Apache Software Foundation\n+\n+This product includes software developed at\n+The Apache Software Foundation (http://www.apache.org/).\n+\n+This project bundles the following dependencies under the Apache Software License 2.0. (http://www.apache.org/licenses/LICENSE-2.0.txt)\n+\n+- org.apache.hbase:hbase-common:1.4.3", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "472ebc575789c2d6e5f5d6ac50bfd54c93c600ea"}, "originalPosition": 9}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMyMTY3MjM3", "url": "https://github.com/apache/flink/pull/12687#pullrequestreview-432167237", "createdAt": "2020-06-17T08:19:40Z", "commit": {"oid": "8a8a8090a66006f8386f0737b08d5428fdc53394"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QwODoxOTo0MVrOGk68Wg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QwODoyNToxMVrOGk7JQA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTM2NzY0Mg==", "bodyText": "Simplify to\nAutoClosableProcess\n\t.create(hbaseDir.resolve(Paths.get(\"bin\", \"hbase\")).toString(), \"shell\")\n\t.setStdoutProcessor(stdoutProcessor)\n\t.setStdInputs(cmd)\n\t.runBlocking();", "url": "https://github.com/apache/flink/pull/12687#discussion_r441367642", "createdAt": "2020-06-17T08:19:41Z", "author": {"login": "wuchong"}, "path": "flink-end-to-end-tests/flink-end-to-end-tests-hbase/src/main/java/org/apache/flink/tests/util/hbase/LocalStandaloneHBaseResource.java", "diffHunk": "@@ -0,0 +1,203 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.tests.util.hbase;\n+\n+import org.apache.flink.tests.util.AutoClosableProcess;\n+import org.apache.flink.tests.util.CommandLineWrapper;\n+import org.apache.flink.tests.util.activation.OperatingSystemRestriction;\n+import org.apache.flink.tests.util.cache.DownloadCache;\n+import org.apache.flink.util.OperatingSystem;\n+\n+import org.junit.rules.TemporaryFolder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.io.PrintStream;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * {@link HBaseResource} that downloads hbase and set up a local hbase cluster.\n+ */\n+public class LocalStandaloneHBaseResource implements HBaseResource {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(LocalStandaloneHBaseResource.class);\n+\n+\tprivate final TemporaryFolder tmp = new TemporaryFolder();\n+\n+\tprivate final DownloadCache downloadCache = DownloadCache.get();\n+\tprivate Path hbaseDir;\n+\n+\tLocalStandaloneHBaseResource() {\n+\t\tOperatingSystemRestriction.forbid(\n+\t\t\tString.format(\"The %s relies on UNIX utils and shell scripts.\", getClass().getSimpleName()),\n+\t\t\tOperatingSystem.WINDOWS);\n+\t}\n+\n+\tprivate static String getHBaseDownloadUrl() {\n+\t\treturn \"https://archive.apache.org/dist/hbase/1.4.3/hbase-1.4.3-bin.tar.gz\";\n+\t}\n+\n+\t@Override\n+\tpublic void before() throws Exception {\n+\t\ttmp.create();\n+\t\tdownloadCache.before();\n+\n+\t\tthis.hbaseDir = tmp.newFolder(\"hbase\").toPath().toAbsolutePath();\n+\t\tsetupHBaseDist();\n+\t\tsetupHBaseCluster();\n+\t}\n+\n+\tprivate void setupHBaseDist() throws IOException {\n+\t\tfinal Path downloadDirectory = tmp.newFolder(\"getOrDownload\").toPath();\n+\t\tfinal Path hbaseArchive = downloadCache.getOrDownload(getHBaseDownloadUrl(), downloadDirectory);\n+\n+\t\tLOG.info(\"HBase localtion: {}\", hbaseDir.toAbsolutePath());\n+\t\tAutoClosableProcess.runBlocking(CommandLineWrapper\n+\t\t\t.tar(hbaseArchive)\n+\t\t\t.extract()\n+\t\t\t.zipped()\n+\t\t\t.strip(1)\n+\t\t\t.targetDir(hbaseDir)\n+\t\t\t.build());\n+\n+\t\tLOG.info(\"Configure {} as hbase.tmp.dir\", hbaseDir.toAbsolutePath());\n+\t\tfinal String tmpDirConfig = \"<configuration><property><name>hbase.tmp.dir</name><value>\" + hbaseDir + \"</value></property></configuration>\";\n+\t\tFiles.write(hbaseDir.resolve(Paths.get(\"conf\", \"hbase-site.xml\")), tmpDirConfig.getBytes());\n+\t}\n+\n+\tprivate void setupHBaseCluster() throws IOException {\n+\t\tLOG.info(\"Starting HBase cluster\");\n+\t\tAutoClosableProcess.runBlocking(\n+\t\t\thbaseDir.resolve(Paths.get(\"bin\", \"start-hbase.sh\")).toString());\n+\n+\t\twhile (!isHBaseRunning()) {\n+\t\t\ttry {\n+\t\t\t\tLOG.info(\"Waiting for HBase to start\");\n+\t\t\t\tThread.sleep(500L);\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\tbreak;\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void afterTestSuccess() {\n+\t\ttry {\n+\t\t\tLOG.info(\"Stopping HBase Cluster\");\n+\t\t\tAutoClosableProcess.runBlocking(\n+\t\t\t\thbaseDir.resolve(Paths.get(\"bin\", \"hbase-daemon.sh\")).toString(),\n+\t\t\t\t\"stop\",\n+\t\t\t\t\"master\");\n+\n+\t\t\twhile (isHBaseRunning()) {\n+\t\t\t\ttry {\n+\t\t\t\t\tLOG.info(\"Waiting for HBase to stop\");\n+\t\t\t\t\tThread.sleep(500L);\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\tbreak;\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t} catch (IOException ioe) {\n+\t\t\tLOG.warn(\"Error while shutting down hbase.\", ioe);\n+\t\t}\n+\t\tdownloadCache.afterTestSuccess();\n+\t\ttmp.delete();\n+\t}\n+\n+\tprivate static boolean isHBaseRunning() {\n+\t\ttry {\n+\t\t\tfinal AtomicBoolean atomicHMasterStarted = new AtomicBoolean(false);\n+\t\t\tqueryHMasterStatus(line -> atomicHMasterStarted.compareAndSet(false, line.contains(\"HMaster\")));\n+\t\t\treturn atomicHMasterStarted.get();\n+\t\t} catch (IOException ioe) {\n+\t\t\treturn false;\n+\t\t}\n+\t}\n+\n+\tprivate static void queryHMasterStatus(final Consumer<String> stdoutProcessor) throws IOException {\n+\t\tAutoClosableProcess\n+\t\t\t.create(\"jps\")\n+\t\t\t.setStdoutProcessor(stdoutProcessor)\n+\t\t\t.runBlocking();\n+\t}\n+\n+\t@Override\n+\tpublic void createTable(String tableName, String... columnFamilies) throws IOException {\n+\t\tfinal String createTable = String.format(\"create '%s',\", tableName) +\n+\t\t\tArrays.stream(columnFamilies)\n+\t\t\t\t.map(cf -> String.format(\"{NAME=>'%s'}\", cf))\n+\t\t\t\t.collect(Collectors.joining(\",\"));\n+\n+\t\texecuteHBaseShell(createTable);\n+\t}\n+\n+\t@Override\n+\tpublic List<String> scanTable(String tableName) throws IOException {\n+\t\tfinal List<String> result = new ArrayList<>();\n+\t\texecuteHBaseShell(String.format(\"scan '%s'\", tableName), line -> {\n+\t\t\tif (line.contains(\"value=\")) {\n+\t\t\t\tresult.add(line);\n+\t\t\t}\n+\t\t});\n+\t\treturn result;\n+\t}\n+\n+\t@Override\n+\tpublic void putData(String tableName, String rowKey, String columnFamily, String columnQualifier, String value) throws IOException {\n+\t\texecuteHBaseShell(\n+\t\t\tString.format(\"put '%s','%s','%s:%s','%s'\", tableName, rowKey, columnFamily, columnQualifier, value));\n+\t}\n+\n+\tprivate void executeHBaseShell(String cmd) throws IOException {\n+\t\texecuteHBaseShell(cmd, line -> {\n+\t\t});\n+\t}\n+\n+\tprivate void executeHBaseShell(String cmd, Consumer<String> stdoutProcessor) throws IOException {\n+\t\ttry (AutoClosableProcess autoClosableProcess = AutoClosableProcess\n+\t\t\t.create(hbaseDir.resolve(Paths.get(\"bin\", \"hbase\")).toString(), \"shell\")\n+\t\t\t.setStdoutProcessor(stdoutProcessor)\n+\t\t\t.runNonBlocking()) {\n+\n+\t\t\ttry (PrintStream printStream = new PrintStream(autoClosableProcess.getProcess().getOutputStream(), true, StandardCharsets.UTF_8.name())) {\n+\t\t\t\tLOG.info(\"Executing hbase shell: {}\", cmd);\n+\t\t\t\tprintStream.println(cmd);\n+\t\t\t}\n+\n+\t\t\ttry {\n+\t\t\t\tautoClosableProcess.getProcess().waitFor();\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t}\n+\t\t}\n+\t}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a8a8090a66006f8386f0737b08d5428fdc53394"}, "originalPosition": 202}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTM3MDk0NA==", "bodyText": "Not found yarn.classpath?", "url": "https://github.com/apache/flink/pull/12687#discussion_r441370944", "createdAt": "2020-06-17T08:25:11Z", "author": {"login": "wuchong"}, "path": "flink-end-to-end-tests/flink-end-to-end-tests-hbase/src/test/java/org/apache/flink/tests/util/hbase/SQLClientHBaseITCase.java", "diffHunk": "@@ -0,0 +1,191 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.tests.util.hbase;\n+\n+import org.apache.flink.api.common.time.Deadline;\n+import org.apache.flink.tests.util.TestUtils;\n+import org.apache.flink.tests.util.cache.DownloadCache;\n+import org.apache.flink.tests.util.categories.PreCommit;\n+import org.apache.flink.tests.util.categories.TravisGroup1;\n+import org.apache.flink.tests.util.flink.ClusterController;\n+import org.apache.flink.tests.util.flink.FlinkResource;\n+import org.apache.flink.tests.util.flink.FlinkResourceSetup;\n+import org.apache.flink.tests.util.flink.LocalStandaloneFlinkResourceFactory;\n+import org.apache.flink.tests.util.flink.SQLJobSubmission;\n+import org.apache.flink.util.FileUtils;\n+import org.apache.flink.util.TestLogger;\n+\n+import org.hamcrest.CoreMatchers;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.TemporaryFolder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.File;\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.net.URL;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Duration;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import static org.hamcrest.Matchers.arrayContainingInAnyOrder;\n+import static org.hamcrest.Matchers.containsString;\n+import static org.junit.Assert.assertThat;\n+\n+/**\n+ * End-to-end test for the HBase connectors.\n+ */\n+@Category(value = {TravisGroup1.class, PreCommit.class})\n+public class SQLClientHBaseITCase extends TestLogger {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(SQLClientHBaseITCase.class);\n+\n+\tprivate static final String HBASE_E2E_SQL = \"hbase_e2e.sql\";\n+\n+\t@Rule\n+\tpublic final HBaseResource hbase;\n+\n+\t@Rule\n+\tpublic final FlinkResource flink = new LocalStandaloneFlinkResourceFactory()\n+\t\t.create(FlinkResourceSetup.builder().build());\n+\n+\t@Rule\n+\tpublic final TemporaryFolder tmp = new TemporaryFolder();\n+\n+\t@ClassRule\n+\tpublic static final DownloadCache DOWNLOAD_CACHE = DownloadCache.get();\n+\n+\tprivate static final Path sqlToolBoxJar = TestUtils.getResourceJar(\".*SqlToolbox.jar\");\n+\tprivate static final Path sqlConnectorHBaseJar = TestUtils.getResourceJar(\".*hbase.jar\");\n+\tprivate List<Path> hadoopClasspathJars;\n+\n+\tpublic SQLClientHBaseITCase() {\n+\t\tthis.hbase = HBaseResource.get();\n+\t}\n+\n+\t@Before\n+\tpublic void before() throws Exception {\n+\t\tDOWNLOAD_CACHE.before();\n+\t\tPath tmpPath = tmp.getRoot().toPath();\n+\t\tLOG.info(\"The current temporary path: {}\", tmpPath);\n+\n+\t\t// Prepare all hadoop jars under HADOOP_CLASSPATH, use yarn.classpath which contains all hadoop jars\n+\t\tPath currentModulePath = Paths.get(\"\").toAbsolutePath();\n+\t\tPath flinkHomePath = currentModulePath.getParent().getParent().toAbsolutePath();\n+\t\tPath hadoopClasspath = Paths.get(flinkHomePath.toString(), \"/flink-yarn-tests/target/yarn.classpath\");\n+\t\tFile hadoopClasspathFile = new File(hadoopClasspath.toString());\n+\n+\t\tif (!hadoopClasspathFile.exists()) {\n+\t\t\tthrow new FileNotFoundException(HBASE_E2E_SQL);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a8a8090a66006f8386f0737b08d5428fdc53394"}, "originalPosition": 105}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMyMjQ5MTEy", "url": "https://github.com/apache/flink/pull/12687#pullrequestreview-432249112", "createdAt": "2020-06-17T10:02:14Z", "commit": {"oid": "72524f4c7ed614aa45c288e8a17229f6ada9a253"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMDowMjoxNVrOGk-1ug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxMDoxMjoxN1rOGk_MTA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTQzMTQ4Mg==", "bodyText": "htrace-core bundles several dependencies but doesn't have a proper NOTICE. Maybe we should list the dependencies:\nhtrace-core\nFrom: 'FasterXML' (http://fasterxml.com/)\n  - Jackson-annotations (http://wiki.fasterxml.com/JacksonHome) com.fasterxml.jackson.core:jackson-annotations:bundle:2.4.0\n    License: The Apache Software License, Version 2.0  (http://www.apache.org/licenses/LICENSE-2.0.txt)\n  - Jackson-core (http://wiki.fasterxml.com/JacksonHome) com.fasterxml.jackson.core:jackson-core:bundle:2.4.0\n    License: The Apache Software License, Version 2.0  (http://www.apache.org/licenses/LICENSE-2.0.txt)\n  - jackson-databind (http://wiki.fasterxml.com/JacksonHome) com.fasterxml.jackson.core:jackson-databind:bundle:2.4.0\n    License: The Apache Software License, Version 2.0  (http://www.apache.org/licenses/LICENSE-2.0.txt)\n\nFrom: 'The Apache Software Foundation' (http://www.apache.org/)\n  - Commons Logging (http://commons.apache.org/logging) commons-logging:commons-logging:jar:1.1.1\n    License: The Apache Software License, Version 2.0  (http://www.apache.org/licenses/LICENSE-2.0.txt)\n\nThe commons-logging is a different version.", "url": "https://github.com/apache/flink/pull/12687#discussion_r441431482", "createdAt": "2020-06-17T10:02:15Z", "author": {"login": "wuchong"}, "path": "flink-connectors/flink-sql-connector-hbase/src/main/resources/META-INF/NOTICE", "diffHunk": "@@ -0,0 +1,27 @@\n+flink-sql-connector-hbase\n+Copyright 2014-2020 The Apache Software Foundation\n+\n+This product includes software developed at\n+The Apache Software Foundation (http://www.apache.org/).\n+\n+This project bundles the following dependencies under the Apache Software License 2.0. (http://www.apache.org/licenses/LICENSE-2.0.txt)\n+\n+- commons-codec:commons-codec:1.10\n+- commons-configuration:commons-configuration:1.7\n+- commons-lang:commons-lang:2.6\n+- commons-logging:commons-logging:1.1.3\n+- com.google.guava:guava:12.0.1\n+- com.yammer.metrics:metrics-core:2.2.0\n+- io.netty:netty-all:4.1.44.Final\n+- org.apache.hbase:hbase-common:1.4.3\n+- org.apache.hbase:hbase-protocol:1.4.3\n+- org.apache.hbase:hbase-procedure:1.4.3\n+- org.apache.hbase:hbase-client:1.4.3\n+- org.apache.hbase:hbase-prefix-tree:1.4.3\n+- org.apache.htrace:htrace-core:3.1.0-incubating", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "72524f4c7ed614aa45c288e8a17229f6ada9a253"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTQzNzI2MA==", "bodyText": "Shall we list all the netty dependencies if netty-all is included?\nio.netty:netty-codec-smtp:4.1.44.Final\nio.netty:netty-transport-native-epoll:4.1.44.Final\nio.netty:netty-codec-redis:4.1.44.Final\nio.netty:netty-resolver-dns:4.1.44.Final\nio.netty:netty-codec-dns:4.1.44.Final\nio.netty:netty-resolver-dns-native-macos:4.1.44.Final\nio.netty:netty-codec-mqtt:4.1.44.Final\nio.netty:netty-codec-http2:4.1.44.Final\nio.netty:netty-transport-native-unix-common:4.1.44.Final\nio.netty:netty-transport-sctp:4.1.44.Final\nio.netty:netty-transport-native-epoll:4.1.44.Final\nio.netty:netty-codec-http:4.1.44.Final\nio.netty:netty-transport-udt:4.1.44.Final\nio.netty:netty-handler-proxy:4.1.44.Final\nio.netty:netty-resolver:4.1.44.Final\nio.netty:netty-common:4.1.44.Final\nio.netty:netty-codec-xml:4.1.44.Final\nio.netty:netty-transport:4.1.44.Final\nio.netty:netty-codec:4.1.44.Final\nio.netty:netty-codec-socks:4.1.44.Final\nio.netty:netty-codec-stomp:4.1.44.Final\nio.netty:netty-buffer:4.1.44.Final\nio.netty:netty-transport-rxtx:4.1.44.Final\nio.netty:netty-codec-haproxy:4.1.44.Final\nio.netty:netty-codec-haproxy:4.1.44.Final\nio.netty:netty-tcnative:2.0.28.Final\nio.netty:netty-transport-native-kqueue:4.1.44.Final\nio.netty:netty-handler:4.1.44.Final\nio.netty:netty-codec-memcache:4.1.44.Final\n\nI'm not sure about this, but as there are no other 3rd party dependencies in netty-all, maybe it's fine just include netty-all.", "url": "https://github.com/apache/flink/pull/12687#discussion_r441437260", "createdAt": "2020-06-17T10:12:17Z", "author": {"login": "wuchong"}, "path": "flink-connectors/flink-sql-connector-hbase/src/main/resources/META-INF/NOTICE", "diffHunk": "@@ -0,0 +1,27 @@\n+flink-sql-connector-hbase\n+Copyright 2014-2020 The Apache Software Foundation\n+\n+This product includes software developed at\n+The Apache Software Foundation (http://www.apache.org/).\n+\n+This project bundles the following dependencies under the Apache Software License 2.0. (http://www.apache.org/licenses/LICENSE-2.0.txt)\n+\n+- commons-codec:commons-codec:1.10\n+- commons-configuration:commons-configuration:1.7\n+- commons-lang:commons-lang:2.6\n+- commons-logging:commons-logging:1.1.3\n+- com.google.guava:guava:12.0.1\n+- com.yammer.metrics:metrics-core:2.2.0\n+- io.netty:netty-all:4.1.44.Final", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "72524f4c7ed614aa45c288e8a17229f6ada9a253"}, "originalPosition": 15}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMyNjcwNjM0", "url": "https://github.com/apache/flink/pull/12687#pullrequestreview-432670634", "createdAt": "2020-06-17T18:35:43Z", "commit": {"oid": "ea01ddac48d67d2288ae1a9f9c85cc46b0b03c70"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxODozNTo0M1rOGlSNSg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QxOTowNjozMlrOGlTmxg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTc0ODgxMA==", "bodyText": "This dependency does not seem to be included in the jar (according to my maven shade plugin output)", "url": "https://github.com/apache/flink/pull/12687#discussion_r441748810", "createdAt": "2020-06-17T18:35:43Z", "author": {"login": "rmetzger"}, "path": "flink-connectors/flink-sql-connector-hbase/src/main/resources/META-INF/NOTICE", "diffHunk": "@@ -0,0 +1,60 @@\n+flink-sql-connector-hbase\n+Copyright 2014-2020 The Apache Software Foundation\n+\n+This product includes software developed at\n+The Apache Software Foundation (http://www.apache.org/).\n+\n+This project bundles the following dependencies under the Apache Software License 2.0. (http://www.apache.org/licenses/LICENSE-2.0.txt)\n+\n+- commons-codec:commons-codec:1.10\n+- commons-configuration:commons-configuration:1.7\n+- commons-lang:commons-lang:2.6\n+- commons-logging:commons-logging:1.1.1", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ea01ddac48d67d2288ae1a9f9c85cc46b0b03c70"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTc1MjAwNw==", "bodyText": "Maybe we should separate these dependencies in the list of dependencies, otherwise, people will be confused where the dependencies are coming from", "url": "https://github.com/apache/flink/pull/12687#discussion_r441752007", "createdAt": "2020-06-17T18:41:25Z", "author": {"login": "rmetzger"}, "path": "flink-connectors/flink-sql-connector-hbase/src/main/resources/META-INF/NOTICE", "diffHunk": "@@ -0,0 +1,27 @@\n+flink-sql-connector-hbase\n+Copyright 2014-2020 The Apache Software Foundation\n+\n+This product includes software developed at\n+The Apache Software Foundation (http://www.apache.org/).\n+\n+This project bundles the following dependencies under the Apache Software License 2.0. (http://www.apache.org/licenses/LICENSE-2.0.txt)\n+\n+- commons-codec:commons-codec:1.10\n+- commons-configuration:commons-configuration:1.7\n+- commons-lang:commons-lang:2.6\n+- commons-logging:commons-logging:1.1.3\n+- com.google.guava:guava:12.0.1\n+- com.yammer.metrics:metrics-core:2.2.0\n+- io.netty:netty-all:4.1.44.Final\n+- org.apache.hbase:hbase-common:1.4.3\n+- org.apache.hbase:hbase-protocol:1.4.3\n+- org.apache.hbase:hbase-procedure:1.4.3\n+- org.apache.hbase:hbase-client:1.4.3\n+- org.apache.hbase:hbase-prefix-tree:1.4.3\n+- org.apache.htrace:htrace-core:3.1.0-incubating", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTQzMTQ4Mg=="}, "originalCommit": {"oid": "72524f4c7ed614aa45c288e8a17229f6ada9a253"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTc3MTcxOA==", "bodyText": "I believe we don't need to \"expand\" the dependencies included in \"netty-all\". Everything that is included in netty-all is licensed to the netty project (as long as there's nothing shaded etc.)", "url": "https://github.com/apache/flink/pull/12687#discussion_r441771718", "createdAt": "2020-06-17T19:06:32Z", "author": {"login": "rmetzger"}, "path": "flink-connectors/flink-sql-connector-hbase/src/main/resources/META-INF/NOTICE", "diffHunk": "@@ -0,0 +1,27 @@\n+flink-sql-connector-hbase\n+Copyright 2014-2020 The Apache Software Foundation\n+\n+This product includes software developed at\n+The Apache Software Foundation (http://www.apache.org/).\n+\n+This project bundles the following dependencies under the Apache Software License 2.0. (http://www.apache.org/licenses/LICENSE-2.0.txt)\n+\n+- commons-codec:commons-codec:1.10\n+- commons-configuration:commons-configuration:1.7\n+- commons-lang:commons-lang:2.6\n+- commons-logging:commons-logging:1.1.3\n+- com.google.guava:guava:12.0.1\n+- com.yammer.metrics:metrics-core:2.2.0\n+- io.netty:netty-all:4.1.44.Final", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTQzNzI2MA=="}, "originalCommit": {"oid": "72524f4c7ed614aa45c288e8a17229f6ada9a253"}, "originalPosition": 15}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMyOTIzOTYz", "url": "https://github.com/apache/flink/pull/12687#pullrequestreview-432923963", "createdAt": "2020-06-18T03:58:20Z", "commit": {"oid": "7aa36ae36a4ab5db1dc6fd03b0ed8b3d8ac9b044"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQwMzo1ODoyMFrOGlexrg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQwMzo1OToyNlrOGleytA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTk1NDczNA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t\t\t\t\t\t\" automatically. Please point the 'rootDir' property to the  flink project root directory;\" +\n          \n          \n            \n            \t\t\t\t\t\t\" automatically. Please point the 'rootDir' property to the flink project root directory;\" +", "url": "https://github.com/apache/flink/pull/12687#discussion_r441954734", "createdAt": "2020-06-18T03:58:20Z", "author": {"login": "wuchong"}, "path": "flink-end-to-end-tests/flink-end-to-end-tests-common/src/main/java/org/apache/flink/tests/util/flink/LocalStandaloneFlinkResourceFactory.java", "diffHunk": "@@ -80,6 +80,33 @@ public FlinkResource create(FlinkResourceSetup setup) {\n \t\treturn new LocalStandaloneFlinkResource(distributionDirectory.get(), logBackupDirectory.orElse(null), setup);\n \t}\n \n+\t/**\n+\t * Utils to find the flink project root directory.\n+\t * @param currentDirectory\n+\t * @return The flink project root directory.\n+\t */\n+\tpublic static Path getProjectRootDirectory(Path currentDirectory) {\n+\t\tPath projectRootPath;\n+\t\tOptional<Path> projectRoot = PROJECT_ROOT_DIRECTORY.get();\n+\t\tif (projectRoot.isPresent()) {\n+\t\t\t// running with maven\n+\t\t\tprojectRootPath = projectRoot.get();\n+\t\t} else {\n+\t\t\t// running in the IDE; working directory is test module\n+\t\t\tOptional<Path> projectRootDirectory = findProjectRootDirectory(currentDirectory);\n+\t\t\t// this distinction is required in case this class is used outside of Flink\n+\t\t\tif (projectRootDirectory.isPresent()) {\n+\t\t\t\tprojectRootPath = projectRootDirectory.get();\n+\t\t\t} else {\n+\t\t\t\tthrow new IllegalArgumentException(\n+\t\t\t\t\t\"The 'rootDir' property was not set and the flink project root directory could not be found\" +\n+\t\t\t\t\t\t\" automatically. Please point the 'rootDir' property to the  flink project root directory;\" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7aa36ae36a4ab5db1dc6fd03b0ed8b3d8ac9b044"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTk1NDk5Ng==", "bodyText": "We can use this method to replace the code block in LocalStandaloneFlinkResourceFactory#create().", "url": "https://github.com/apache/flink/pull/12687#discussion_r441954996", "createdAt": "2020-06-18T03:59:26Z", "author": {"login": "wuchong"}, "path": "flink-end-to-end-tests/flink-end-to-end-tests-common/src/main/java/org/apache/flink/tests/util/flink/LocalStandaloneFlinkResourceFactory.java", "diffHunk": "@@ -80,6 +80,33 @@ public FlinkResource create(FlinkResourceSetup setup) {\n \t\treturn new LocalStandaloneFlinkResource(distributionDirectory.get(), logBackupDirectory.orElse(null), setup);\n \t}\n \n+\t/**\n+\t * Utils to find the flink project root directory.\n+\t * @param currentDirectory\n+\t * @return The flink project root directory.\n+\t */\n+\tpublic static Path getProjectRootDirectory(Path currentDirectory) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7aa36ae36a4ab5db1dc6fd03b0ed8b3d8ac9b044"}, "originalPosition": 9}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMyOTkwMzg2", "url": "https://github.com/apache/flink/pull/12687#pullrequestreview-432990386", "createdAt": "2020-06-18T06:57:19Z", "commit": {"oid": "6e80f12ea70c120dc97e8bb9399151d0f4ccec14"}, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "dfbc8d9e09c77bb62087e02f8f1d6538253e767b", "author": {"user": {"login": "leonardBang", "name": "Leonard Xu"}}, "url": "https://github.com/apache/flink/commit/dfbc8d9e09c77bb62087e02f8f1d6538253e767b", "committedDate": "2020-06-18T07:16:06Z", "message": "minor"}, "afterCommit": {"oid": "769512268be9cb063af00d107cbd1382576fb6fb", "author": {"user": {"login": "leonardBang", "name": "Leonard Xu"}}, "url": "https://github.com/apache/flink/commit/769512268be9cb063af00d107cbd1382576fb6fb", "committedDate": "2020-06-18T09:30:37Z", "message": "address Chesnay's comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM0ODU4NjA5", "url": "https://github.com/apache/flink/pull/12687#pullrequestreview-434858609", "createdAt": "2020-06-22T12:05:58Z", "commit": {"oid": "85a2f479298ac5cbf249d6ecbc85209b666f46b7"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "15681586a0c9fab7bfbefe943e7b6b1cd6700864", "author": {"user": {"login": "leonardBang", "name": "Leonard Xu"}}, "url": "https://github.com/apache/flink/commit/15681586a0c9fab7bfbefe943e7b6b1cd6700864", "committedDate": "2020-06-22T12:16:20Z", "message": "[FLINK-17678][hbase] Support fink-sql-connector-hbase"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "85a2f479298ac5cbf249d6ecbc85209b666f46b7", "author": {"user": {"login": "leonardBang", "name": "Leonard Xu"}}, "url": "https://github.com/apache/flink/commit/85a2f479298ac5cbf249d6ecbc85209b666f46b7", "committedDate": "2020-06-18T13:01:13Z", "message": "skip dependency convergence for flink-end-to-end-tests-hbase module"}, "afterCommit": {"oid": "15681586a0c9fab7bfbefe943e7b6b1cd6700864", "author": {"user": {"login": "leonardBang", "name": "Leonard Xu"}}, "url": "https://github.com/apache/flink/commit/15681586a0c9fab7bfbefe943e7b6b1cd6700864", "committedDate": "2020-06-22T12:16:20Z", "message": "[FLINK-17678][hbase] Support fink-sql-connector-hbase"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3626, "cost": 1, "resetAt": "2021-10-28T16:48:13Z"}}}