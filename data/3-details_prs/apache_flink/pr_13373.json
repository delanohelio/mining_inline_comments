{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDg1MDQwNzMy", "number": 13373, "title": "[FLINK-18802] Upgrade avro to 1.10 ", "bodyText": "What is the purpose of the change\nThis PR upgrades the default version of avro that Flink will use. It makes Flink no longer in sync with the version of avro used in Hadoop. Users might need to downgrade the version of avro, if they want to use Hadoop classes that transitively use avro.\nMoreover it provides an uber-jar with all avro dependencies bundled for sql-client.\nBrief change log\n\nFix field access in Pojo comparator for cases when the record did not go through serialization and private fields where not made accessible\nFixes the interpretation of TIMESTAMP_WITHOUT_TIME_ZONE in AvroRowData(De)SerializationSchema (previously it was handled as if it was TIMESTAMP_WITH_LOCAL_TIME_ZONE.\nAdded handling of timestamp-micros and time-micros in AvroDeserializationSchema\nUpgraded avro to version 1.10\nCreated module flink-sql-avro that creates an uber jar for sql-client\n\nSome issues that might need a second opinion:\n\nthis PR changes the artifact name for avro sql jar. Before users were supposed to use flink-avro-sql-jar*. Now to align with other sql modules (parquet, orc) I introduced flink-sql-avro*\nwe do not shade avro in the uber jar. We shade avro's dependencies. Other sql-client modules such as e.g. parquet or orc do not shade anything.\n\nVerifying this change\nThis change is already covered by existing tests.\nDoes this pull request potentially affect one of the following parts:\n\nDependencies (does it add or upgrade a dependency): (yes / no)\nThe public API, i.e., is any changed class annotated with @Public(Evolving): (yes / no)\nThe serializers: (yes / no / don't know)\nThe runtime per-record code paths (performance sensitive): (yes / no / don't know)\nAnything that affects deployment or recovery: JobManager (and its components), Checkpointing, Kubernetes/Yarn/Mesos, ZooKeeper: (yes / no / don't know)\nThe S3 file system connector: (yes / no / don't know)\n\nDocumentation\n\nDoes this pull request introduce a new feature? (yes / no)\nIf yes, how is the feature documented? (not applicable / docs / JavaDocs / not documented)", "createdAt": "2020-09-11T12:52:27Z", "url": "https://github.com/apache/flink/pull/13373", "merged": true, "mergeCommit": {"oid": "a6a4d169f649d193853fddb2c589820fc0004d07"}, "closed": true, "closedAt": "2020-09-14T19:46:10Z", "author": {"login": "dawidwys"}, "timelineItems": {"totalCount": 26, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdH0-8NgFqTQ4Njc4MjA4OQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdIvl5vABqjM3NjIzMDkxNTE=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg2NzgyMDg5", "url": "https://github.com/apache/flink/pull/13373#pullrequestreview-486782089", "createdAt": "2020-09-11T12:58:31Z", "commit": {"oid": "df666257b536825e8cb4e3497349079e9a35c51e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQxMjo1ODozMVrOHQdybQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQxMjo1ODozMVrOHQdybQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzAyNzMwOQ==", "bodyText": "Had to drop the logical types, because the BatchTableEnvironment fails if we have a java.time.Instant in the input DataSet. We extract BasicTypeInfo.INSTANT_TYPE_INFO for it, which is translated to TIMESTAMP_WITH_LOCAL_TIME_ZONE which fails in legacy planner.\nAfter the upgrade to avro 1.10 one of the fields of the User class is of type java.time.Instant, previously it was joda's DateTime.", "url": "https://github.com/apache/flink/pull/13373#discussion_r487027309", "createdAt": "2020-09-11T12:58:31Z", "author": {"login": "dawidwys"}, "path": "flink-formats/flink-avro/src/test/java/org/apache/flink/table/runtime/batch/AvroTypesITCase.java", "diffHunk": "@@ -58,7 +55,7 @@\n @RunWith(Parameterized.class)\n public class AvroTypesITCase extends TableProgramsClusterTestBase {\n \n-\tprivate static final User USER_1 = User.newBuilder()\n+\tprivate static final SimpleUser USER_1 = SimpleUser.newBuilder()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "df666257b536825e8cb4e3497349079e9a35c51e"}, "originalPosition": 33}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg2Nzg0NzAz", "url": "https://github.com/apache/flink/pull/13373#pullrequestreview-486784703", "createdAt": "2020-09-11T13:01:55Z", "commit": {"oid": "ed7fa522fc930a22eee7e51e87dc778ad6ad3b71"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQxMzowMTo1NVrOHQd5qQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQxMzowMTo1NVrOHQd5qQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzAyOTE2MQ==", "bodyText": "wouldn't it be easier (and also more performant) to simply make the field accessible in the constructor of the comparator? Going through all methods for every field access is not very beautiful.", "url": "https://github.com/apache/flink/pull/13373#discussion_r487029161", "createdAt": "2020-09-11T13:01:55Z", "author": {"login": "twalthr"}, "path": "flink-core/src/main/java/org/apache/flink/api/java/typeutils/runtime/PojoComparator.java", "diffHunk": "@@ -176,14 +181,25 @@ public void getFlatComparator(List<TypeComparator> flatComparators) {\n \t */\n \tpublic final Object accessField(Field field, Object object) {\n \t\ttry {\n-\t\t\tobject = field.get(object);\n+\t\t\tif (field.isAccessible()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ed7fa522fc930a22eee7e51e87dc778ad6ad3b71"}, "originalPosition": 28}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg2Nzg4ODcy", "url": "https://github.com/apache/flink/pull/13373#pullrequestreview-486788872", "createdAt": "2020-09-11T13:07:28Z", "commit": {"oid": "20cabf7afcac656efb5b959fa8c1a33b76c44fb1"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQxMzowNzoyOFrOHQeFdA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQxMzoxMDoxMFrOHQeL5w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzAzMjE4MA==", "bodyText": "we can simply access the member field instead of passing it through the methods, no?", "url": "https://github.com/apache/flink/pull/13373#discussion_r487032180", "createdAt": "2020-09-11T13:07:28Z", "author": {"login": "twalthr"}, "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroRowDeserializationSchema.java", "diffHunk": "@@ -218,7 +231,7 @@ private Object convertAvroType(Schema schema, TypeInformation<?> info, Object ob\n \t\tswitch (schema.getType()) {\n \t\t\tcase RECORD:\n \t\t\t\tif (object instanceof IndexedRecord) {\n-\t\t\t\t\treturn convertAvroRecordToRow(schema, (RowTypeInfo) info, (IndexedRecord) object);\n+\t\t\t\t\treturn convertAvroRecordToRow(schema, (RowTypeInfo) info, (IndexedRecord) object, jodaConverter);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "20cabf7afcac656efb5b959fa8c1a33b76c44fb1"}, "originalPosition": 86}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzAzMzgzMQ==", "bodyText": "We can simply access JodaConverter where needed as a singleton? I would not pollute this methods.", "url": "https://github.com/apache/flink/pull/13373#discussion_r487033831", "createdAt": "2020-09-11T13:10:10Z", "author": {"login": "twalthr"}, "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroToRowDataConverters.java", "diffHunk": "@@ -101,7 +106,7 @@ private static AvroToRowDataConverter createNullableConverter(LogicalType type)\n \t/**\n \t * Creates a runtime converter which assuming input object is not null.\n \t */\n-\tprivate static AvroToRowDataConverter createConverter(LogicalType type) {\n+\tprivate static AvroToRowDataConverter createConverter(LogicalType type, @Nullable JodaConverter jodaConverter) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "20cabf7afcac656efb5b959fa8c1a33b76c44fb1"}, "originalPosition": 53}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "df666257b536825e8cb4e3497349079e9a35c51e", "author": {"user": {"login": "dawidwys", "name": "Dawid Wysakowicz"}}, "url": "https://github.com/apache/flink/commit/df666257b536825e8cb4e3497349079e9a35c51e", "committedDate": "2020-09-11T07:42:31Z", "message": "[FLINK-18802] Create an uber jar for avro for sql-client"}, "afterCommit": {"oid": "0f6f3bd9e8607ed77350723e5710e1705af3f710", "author": {"user": {"login": "dawidwys", "name": "Dawid Wysakowicz"}}, "url": "https://github.com/apache/flink/commit/0f6f3bd9e8607ed77350723e5710e1705af3f710", "committedDate": "2020-09-11T13:13:13Z", "message": "[FLINK-18802] Create an uber jar for avro for sql-client"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0f6f3bd9e8607ed77350723e5710e1705af3f710", "author": {"user": {"login": "dawidwys", "name": "Dawid Wysakowicz"}}, "url": "https://github.com/apache/flink/commit/0f6f3bd9e8607ed77350723e5710e1705af3f710", "committedDate": "2020-09-11T13:13:13Z", "message": "[FLINK-18802] Create an uber jar for avro for sql-client"}, "afterCommit": {"oid": "8396f34387c87703171a06563b15e0f0b2a53699", "author": {"user": {"login": "dawidwys", "name": "Dawid Wysakowicz"}}, "url": "https://github.com/apache/flink/commit/8396f34387c87703171a06563b15e0f0b2a53699", "committedDate": "2020-09-11T13:18:05Z", "message": "[FLINK-18802] Create an uber jar for avro for sql-client"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8396f34387c87703171a06563b15e0f0b2a53699", "author": {"user": {"login": "dawidwys", "name": "Dawid Wysakowicz"}}, "url": "https://github.com/apache/flink/commit/8396f34387c87703171a06563b15e0f0b2a53699", "committedDate": "2020-09-11T13:18:05Z", "message": "[FLINK-18802] Create an uber jar for avro for sql-client"}, "afterCommit": {"oid": "2cb9ec4b5e8daf8f4333acb2a8c09a8f2b1cfdb8", "author": {"user": {"login": "dawidwys", "name": "Dawid Wysakowicz"}}, "url": "https://github.com/apache/flink/commit/2cb9ec4b5e8daf8f4333acb2a8c09a8f2b1cfdb8", "committedDate": "2020-09-11T13:32:13Z", "message": "[FLINK-18802] Create an uber jar for avro for sql-client"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg2ODA4Mzk1", "url": "https://github.com/apache/flink/pull/13373#pullrequestreview-486808395", "createdAt": "2020-09-11T13:31:41Z", "commit": {"oid": "9038509a993f32233b4406cd6f6ca713258622c5"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQxMzozMTo0MVrOHQe-Iw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQxMzo0NTo1M1rOHQfgrg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzA0NjY5MQ==", "bodyText": "maybe to much optimization but should we just do the long arithmetic ourselves here and below? We are creating a lot of objects for the hot path.", "url": "https://github.com/apache/flink/pull/13373#discussion_r487046691", "createdAt": "2020-09-11T13:31:41Z", "author": {"login": "twalthr"}, "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroRowDeserializationSchema.java", "diffHunk": "@@ -340,10 +357,22 @@ private Time convertToTime(Object object, @Nullable JodaConverter jodaConverter)\n \t\treturn new Time(millis - LOCAL_TZ.getOffset(millis));\n \t}\n \n-\tprivate Timestamp convertToTimestamp(Object object) {\n+\tprivate Timestamp convertToTimestamp(Object object, @Nullable JodaConverter jodaConverter, boolean isMicros) {\n \t\tfinal long millis;\n \t\tif (object instanceof Long) {\n-\t\t\tmillis = (Long) object;\n+\t\t\tif (isMicros) {\n+\t\t\t\tlong micros = (Long) object;\n+\t\t\t\tInstant instant = Instant.ofEpochSecond(0)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9038509a993f32233b4406cd6f6ca713258622c5"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzA1MDkxMQ==", "bodyText": "Shouldn't this be a SQL type like the others? Is this method actually used?", "url": "https://github.com/apache/flink/pull/13373#discussion_r487050911", "createdAt": "2020-09-11T13:38:56Z", "author": {"login": "twalthr"}, "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java", "diffHunk": "@@ -272,11 +276,14 @@ private static DataType convertToDataType(Schema schema) {\n \t\t\t\treturn DataTypes.TIMESTAMP(3)\n \t\t\t\t\t\t.bridgedTo(java.sql.Timestamp.class)\n \t\t\t\t\t\t.notNull();\n-\t\t\t}\n-\t\t\tif (schema.getLogicalType() == LogicalTypes.timestampMicros()) {\n+\t\t\t} else if (schema.getLogicalType() == LogicalTypes.timestampMicros()) {\n \t\t\t\treturn DataTypes.TIMESTAMP(6)\n \t\t\t\t\t\t.bridgedTo(java.sql.Timestamp.class)\n \t\t\t\t\t\t.notNull();\n+\t\t\t} else if (schema.getLogicalType() == LogicalTypes.timeMicros()) {\n+\t\t\t\treturn DataTypes.TIME(6)\n+\t\t\t\t\t.bridgedTo(LocalTime.class)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9038509a993f32233b4406cd6f6ca713258622c5"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzA1MjU4MQ==", "bodyText": "same question as above why is this not sql.Time?", "url": "https://github.com/apache/flink/pull/13373#discussion_r487052581", "createdAt": "2020-09-11T13:41:31Z", "author": {"login": "twalthr"}, "path": "flink-formats/flink-avro/src/test/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverterTest.java", "diffHunk": "@@ -193,7 +193,7 @@ private void validateUserSchema(DataType actual) {\n \t\t\t\tDataTypes.FIELD(\"type_bytes\", DataTypes.ARRAY(DataTypes.TINYINT().bridgedTo(Byte.class)).notNull()),\n \t\t\t\tDataTypes.FIELD(\"type_date\", DataTypes.DATE().bridgedTo(java.sql.Date.class).notNull()),\n \t\t\t\tDataTypes.FIELD(\"type_time_millis\", DataTypes.TIME().bridgedTo(java.sql.Time.class).notNull()),\n-\t\t\t\tDataTypes.FIELD(\"type_time_micros\", DataTypes.INT().notNull()),\n+\t\t\t\tDataTypes.FIELD(\"type_time_micros\", DataTypes.TIME(6).notNull()),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9038509a993f32233b4406cd6f6ca713258622c5"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzA1NDE5OQ==", "bodyText": "Thanks for the explanation.", "url": "https://github.com/apache/flink/pull/13373#discussion_r487054199", "createdAt": "2020-09-11T13:43:56Z", "author": {"login": "twalthr"}, "path": "flink-formats/flink-avro/src/test/java/org/apache/flink/table/runtime/batch/AvroTypesITCase.java", "diffHunk": "@@ -58,7 +55,7 @@\n @RunWith(Parameterized.class)\n public class AvroTypesITCase extends TableProgramsClusterTestBase {\n \n-\tprivate static final User USER_1 = User.newBuilder()\n+\tprivate static final SimpleUser USER_1 = SimpleUser.newBuilder()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzAyNzMwOQ=="}, "originalCommit": {"oid": "df666257b536825e8cb4e3497349079e9a35c51e"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzA1NTUzNA==", "bodyText": "But it would still be nice to test all types for Avro but maybe to the new Blink planner. Could we add least have a separate commit for this class? Then we can revert the changes because after FLIP-136 this test should definitely work again, no? Or does it work already today?", "url": "https://github.com/apache/flink/pull/13373#discussion_r487055534", "createdAt": "2020-09-11T13:45:53Z", "author": {"login": "twalthr"}, "path": "flink-formats/flink-avro/src/test/java/org/apache/flink/table/runtime/batch/AvroTypesITCase.java", "diffHunk": "@@ -58,7 +55,7 @@\n @RunWith(Parameterized.class)\n public class AvroTypesITCase extends TableProgramsClusterTestBase {\n \n-\tprivate static final User USER_1 = User.newBuilder()\n+\tprivate static final SimpleUser USER_1 = SimpleUser.newBuilder()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzAyNzMwOQ=="}, "originalCommit": {"oid": "df666257b536825e8cb4e3497349079e9a35c51e"}, "originalPosition": 33}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg2ODMwMTM0", "url": "https://github.com/apache/flink/pull/13373#pullrequestreview-486830134", "createdAt": "2020-09-11T13:57:35Z", "commit": {"oid": "2cb9ec4b5e8daf8f4333acb2a8c09a8f2b1cfdb8"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQxMzo1NzozNVrOHQf-Qg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQxNDowMjowM1rOHQgJJQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzA2MzEwNg==", "bodyText": "We have a shading pattern in Flink like:\norg.apache.flink.elasticsearch6.shaded.org.apache.commons", "url": "https://github.com/apache/flink/pull/13373#discussion_r487063106", "createdAt": "2020-09-11T13:57:35Z", "author": {"login": "twalthr"}, "path": "flink-formats/flink-sql-avro/pom.xml", "diffHunk": "@@ -0,0 +1,85 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n+\t\txsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\">\n+\t\n+\t<modelVersion>4.0.0</modelVersion>\n+\n+\t<parent>\n+\t\t<groupId>org.apache.flink</groupId>\n+\t\t<artifactId>flink-formats</artifactId>\n+\t\t<version>1.12-SNAPSHOT</version>\n+\t\t<relativePath>..</relativePath>\n+\t</parent>\n+\n+\t<artifactId>flink-sql-avro</artifactId>\n+\t<name>Flink : Formats : SQL Avro</name>\n+\n+\t<packaging>jar</packaging>\n+\n+\t<dependencies>\n+\t\t<dependency>\n+\t\t\t<groupId>org.apache.flink</groupId>\n+\t\t\t<artifactId>flink-avro</artifactId>\n+\t\t\t<version>${project.version}</version>\n+\t\t</dependency>\n+\t</dependencies>\n+\n+\t<build>\n+\t\t<plugins>\n+\t\t\t<plugin>\n+\t\t\t\t<groupId>org.apache.maven.plugins</groupId>\n+\t\t\t\t<artifactId>maven-shade-plugin</artifactId>\n+\t\t\t\t<executions>\n+\t\t\t\t\t<execution>\n+\t\t\t\t\t\t<id>shade-flink</id>\n+\t\t\t\t\t\t<phase>package</phase>\n+\t\t\t\t\t\t<goals>\n+\t\t\t\t\t\t\t<goal>shade</goal>\n+\t\t\t\t\t\t</goals>\n+\t\t\t\t\t\t<configuration>\n+\t\t\t\t\t\t\t<shadeTestJar>false</shadeTestJar>\n+\t\t\t\t\t\t\t<artifactSet>\n+\t\t\t\t\t\t\t\t<includes>\n+\t\t\t\t\t\t\t\t\t<include>org.apache.flink:flink-avro</include>\n+\t\t\t\t\t\t\t\t\t<include>org.apache.avro:avro</include>\n+\t\t\t\t\t\t\t\t\t<include>com.fasterxml.jackson.core:jackson-core</include>\n+\t\t\t\t\t\t\t\t\t<include>com.fasterxml.jackson.core:jackson-databind</include>\n+\t\t\t\t\t\t\t\t\t<include>com.fasterxml.jackson.core:jackson-annotations</include>\n+\t\t\t\t\t\t\t\t\t<include>org.apache.commons:commons-compress</include>\n+\t\t\t\t\t\t\t\t</includes>\n+\t\t\t\t\t\t\t</artifactSet>\n+\t\t\t\t\t\t\t<relocations>\n+\t\t\t\t\t\t\t\t<relocation>\n+\t\t\t\t\t\t\t\t\t<pattern>com.fasterxml.jackson</pattern>\n+\t\t\t\t\t\t\t\t\t<shadedPattern>org.apache.flink.com.fasterxml.jackson</shadedPattern>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2cb9ec4b5e8daf8f4333acb2a8c09a8f2b1cfdb8"}, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzA2NTA5MA==", "bodyText": "Pleas also update https://flink.apache.org/downloads.html (Optional components)\nAnd https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/connectors/formats/avro.html (the Download link and the mentioning of Hadoop \ud83d\ude14).", "url": "https://github.com/apache/flink/pull/13373#discussion_r487065090", "createdAt": "2020-09-11T14:00:41Z", "author": {"login": "twalthr"}, "path": "flink-formats/pom.xml", "diffHunk": "@@ -81,6 +81,7 @@ under the License.\n \t\t\t<modules>\n \t\t\t\t<module>flink-sql-orc</module>\n \t\t\t\t<module>flink-sql-parquet</module>\n+\t\t\t\t<module>flink-sql-avro</module>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2cb9ec4b5e8daf8f4333acb2a8c09a8f2b1cfdb8"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzA2NTg5Mw==", "bodyText": "The org.apache.flink.tests.util.kafka.SQLClientKafkaITCase should not need to download the dependencies anymore.", "url": "https://github.com/apache/flink/pull/13373#discussion_r487065893", "createdAt": "2020-09-11T14:02:03Z", "author": {"login": "twalthr"}, "path": "flink-formats/pom.xml", "diffHunk": "@@ -81,6 +81,7 @@ under the License.\n \t\t\t<modules>\n \t\t\t\t<module>flink-sql-orc</module>\n \t\t\t\t<module>flink-sql-parquet</module>\n+\t\t\t\t<module>flink-sql-avro</module>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzA2NTA5MA=="}, "originalCommit": {"oid": "2cb9ec4b5e8daf8f4333acb2a8c09a8f2b1cfdb8"}, "originalPosition": 4}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "2cb9ec4b5e8daf8f4333acb2a8c09a8f2b1cfdb8", "author": {"user": {"login": "dawidwys", "name": "Dawid Wysakowicz"}}, "url": "https://github.com/apache/flink/commit/2cb9ec4b5e8daf8f4333acb2a8c09a8f2b1cfdb8", "committedDate": "2020-09-11T13:32:13Z", "message": "[FLINK-18802] Create an uber jar for avro for sql-client"}, "afterCommit": {"oid": "0999b2c052be034e7de38f03a13840292a4b497f", "author": {"user": {"login": "dawidwys", "name": "Dawid Wysakowicz"}}, "url": "https://github.com/apache/flink/commit/0999b2c052be034e7de38f03a13840292a4b497f", "committedDate": "2020-09-11T18:06:58Z", "message": "[FLINK-18802] Create an uber jar for avro for sql-client"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0999b2c052be034e7de38f03a13840292a4b497f", "author": {"user": {"login": "dawidwys", "name": "Dawid Wysakowicz"}}, "url": "https://github.com/apache/flink/commit/0999b2c052be034e7de38f03a13840292a4b497f", "committedDate": "2020-09-11T18:06:58Z", "message": "[FLINK-18802] Create an uber jar for avro for sql-client"}, "afterCommit": {"oid": "bab621c4f92387eef5bf0101a5b687e45c479f80", "author": {"user": {"login": "dawidwys", "name": "Dawid Wysakowicz"}}, "url": "https://github.com/apache/flink/commit/bab621c4f92387eef5bf0101a5b687e45c479f80", "committedDate": "2020-09-11T19:56:10Z", "message": "[FLINK-18802] Create an uber jar for avro for sql-client"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg3NDYzMzE0", "url": "https://github.com/apache/flink/pull/13373#pullrequestreview-487463314", "createdAt": "2020-09-14T06:58:01Z", "commit": {"oid": "bab621c4f92387eef5bf0101a5b687e45c479f80"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg3NDY2MTkw", "url": "https://github.com/apache/flink/pull/13373#pullrequestreview-487466190", "createdAt": "2020-09-14T07:03:07Z", "commit": {"oid": "bab621c4f92387eef5bf0101a5b687e45c479f80"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg3NDY5MzEy", "url": "https://github.com/apache/flink/pull/13373#pullrequestreview-487469312", "createdAt": "2020-09-14T07:08:11Z", "commit": {"oid": "cac5bf3b0420f10b9480c8e1e8e0b00884612ee7"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQwNzowODoxMVrOHRGgSA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQwNzowODoxMVrOHRGgSA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzY5NDQwOA==", "bodyText": "Actually, this should be DataTypes.BYTES() which would also match to Avro's BYTES type.", "url": "https://github.com/apache/flink/pull/13373#discussion_r487694408", "createdAt": "2020-09-14T07:08:11Z", "author": {"login": "twalthr"}, "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java", "diffHunk": "@@ -255,28 +257,24 @@ private static DataType convertToDataType(Schema schema) {\n \t\t\t\t\t\tdecimalType.getScale())\n \t\t\t\t\t\t.notNull();\n \t\t\t}\n-\t\t\treturn DataTypes.ARRAY(DataTypes.TINYINT().bridgedTo(Byte.class))\n-\t\t\t\t\t.notNull();\n+\t\t\treturn DataTypes.ARRAY(DataTypes.TINYINT()).notNull();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cac5bf3b0420f10b9480c8e1e8e0b00884612ee7"}, "originalPosition": 15}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg3NDcyNTEx", "url": "https://github.com/apache/flink/pull/13373#pullrequestreview-487472511", "createdAt": "2020-09-14T07:13:06Z", "commit": {"oid": "a639495f2bc3cef6fedf52492e546ebeb6306be5"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQwNzoxMzowNlrOHRGpaw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQwNzoxMzowNlrOHRGpaw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzY5Njc0Nw==", "bodyText": "nit: private?", "url": "https://github.com/apache/flink/pull/13373#discussion_r487696747", "createdAt": "2020-09-14T07:13:06Z", "author": {"login": "twalthr"}, "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroRowDeserializationSchema.java", "diffHunk": "@@ -75,12 +75,11 @@\n  */\n @PublicEvolving\n public class AvroRowDeserializationSchema extends AbstractDeserializationSchema<Row> {\n-\n \t/**\n \t * Used for time conversions into SQL types.\n \t */\n \tprivate static final TimeZone LOCAL_TZ = TimeZone.getDefault();\n-\n+\tpublic static final long MICROS_PER_SECOND = 1_000_000L;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a639495f2bc3cef6fedf52492e546ebeb6306be5"}, "originalPosition": 10}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg3NDgwODI0", "url": "https://github.com/apache/flink/pull/13373#pullrequestreview-487480824", "createdAt": "2020-09-14T07:25:48Z", "commit": {"oid": "a0122e0683100ca2e8e1190b940cdd3a7166a19d"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQwNzoyNTo0OVrOHRHCqw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQwNzoyODozMlrOHRHH-Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzcwMzIxMQ==", "bodyText": "can we add a TODO here, because actually the record should pass the Table API unmodified, but this will come with FLUP-136", "url": "https://github.com/apache/flink/pull/13373#discussion_r487703211", "createdAt": "2020-09-14T07:25:49Z", "author": {"login": "twalthr"}, "path": "flink-formats/flink-avro/src/test/java/org/apache/flink/table/runtime/batch/AvroTypesITCase.java", "diffHunk": "@@ -147,24 +150,26 @@ public AvroTypesITCase(\n \n \t@Test\n \tpublic void testAvroToRow() throws Exception {\n-\t\tExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n+\t\tStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n \t\tenv.getConfig().registerTypeWithKryoSerializer(LocalDate.class, AvroKryoSerializerUtils.JodaLocalDateSerializer.class);\n \t\tenv.getConfig().registerTypeWithKryoSerializer(LocalTime.class, AvroKryoSerializerUtils.JodaLocalTimeSerializer.class);\n-\t\tBatchTableEnvironment tEnv = BatchTableEnvironment.create(env, config());\n+\t\tStreamTableEnvironment tEnv = StreamTableEnvironment.create(env, EnvironmentSettings.newInstance().useBlinkPlanner().build());\n \n-\t\tTable t = tEnv.fromDataSet(testData(env));\n+\t\tTable t = tEnv.fromDataStream(testData(env));\n \t\tTable result = t.select($(\"*\"));\n \n-\t\tList<Row> results = tEnv.toDataSet(result, Row.class).collect();\n+\t\tIterable<Row> users = () -> DataStreamUtils.collect(tEnv.toAppendStream(result, Row.class));\n+\t\tList<Row> results = StreamSupport\n+\t\t\t.stream(users.spliterator(), false)\n+\t\t\t.collect(Collectors.toList());\n \t\tString expected =\n \t\t\t\"black,null,Whatever,[true],[hello],true,java.nio.HeapByteBuffer[pos=0 lim=10 cap=10],\" +\n \t\t\t\"2014-03-01,java.nio.HeapByteBuffer[pos=0 lim=2 cap=2],[7, -48],0.0,GREEN,\" +\n \t\t\t\"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],42,{},null,null,null,123456,\" +\n \t\t\t\"12:12:12.000,123456,2014-03-01T12:12:12.321Z,null\\n\" +\n \t\t\t\"blue,null,Charlie,[],[],false,java.nio.HeapByteBuffer[pos=0 lim=10 cap=10],2014-03-01,\" +\n \t\t\t\"java.nio.HeapByteBuffer[pos=0 lim=2 cap=2],[7, -48],1.337,RED,null,1337,{},\" +\n-\t\t\t\"{\\\"num\\\": 42, \\\"street\\\": \\\"Bakerstreet\\\", \\\"city\\\": \\\"Berlin\\\", \\\"state\\\": \" +\n-\t\t\t\"\\\"Berlin\\\", \\\"zip\\\": \\\"12049\\\"},null,null,123456,12:12:12.000,123456,\" +\n+\t\t\t\"Berlin,42,Berlin,Bakerstreet,12049,null,null,123456,12:12:12.000,123456,\" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a0122e0683100ca2e8e1190b940cdd3a7166a19d"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzcwMzcwOQ==", "bodyText": "These should not be necessary in our tests, right?", "url": "https://github.com/apache/flink/pull/13373#discussion_r487703709", "createdAt": "2020-09-14T07:26:48Z", "author": {"login": "twalthr"}, "path": "flink-formats/flink-avro/src/test/java/org/apache/flink/table/runtime/batch/AvroTypesITCase.java", "diffHunk": "@@ -147,24 +150,26 @@ public AvroTypesITCase(\n \n \t@Test\n \tpublic void testAvroToRow() throws Exception {\n-\t\tExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n+\t\tStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n \t\tenv.getConfig().registerTypeWithKryoSerializer(LocalDate.class, AvroKryoSerializerUtils.JodaLocalDateSerializer.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a0122e0683100ca2e8e1190b940cdd3a7166a19d"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzcwNDU2OQ==", "bodyText": "nit: We recently added a CollectionUtils.iterableToList maybe this is easier to read than the StreamSupport class.", "url": "https://github.com/apache/flink/pull/13373#discussion_r487704569", "createdAt": "2020-09-14T07:28:32Z", "author": {"login": "twalthr"}, "path": "flink-formats/flink-avro/src/test/java/org/apache/flink/table/runtime/batch/AvroTypesITCase.java", "diffHunk": "@@ -147,24 +150,26 @@ public AvroTypesITCase(\n \n \t@Test\n \tpublic void testAvroToRow() throws Exception {\n-\t\tExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n+\t\tStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n \t\tenv.getConfig().registerTypeWithKryoSerializer(LocalDate.class, AvroKryoSerializerUtils.JodaLocalDateSerializer.class);\n \t\tenv.getConfig().registerTypeWithKryoSerializer(LocalTime.class, AvroKryoSerializerUtils.JodaLocalTimeSerializer.class);\n-\t\tBatchTableEnvironment tEnv = BatchTableEnvironment.create(env, config());\n+\t\tStreamTableEnvironment tEnv = StreamTableEnvironment.create(env, EnvironmentSettings.newInstance().useBlinkPlanner().build());\n \n-\t\tTable t = tEnv.fromDataSet(testData(env));\n+\t\tTable t = tEnv.fromDataStream(testData(env));\n \t\tTable result = t.select($(\"*\"));\n \n-\t\tList<Row> results = tEnv.toDataSet(result, Row.class).collect();\n+\t\tIterable<Row> users = () -> DataStreamUtils.collect(tEnv.toAppendStream(result, Row.class));\n+\t\tList<Row> results = StreamSupport", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a0122e0683100ca2e8e1190b940cdd3a7166a19d"}, "originalPosition": 49}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg3NDg2Mzk5", "url": "https://github.com/apache/flink/pull/13373#pullrequestreview-487486399", "createdAt": "2020-09-14T07:34:05Z", "commit": {"oid": "bab621c4f92387eef5bf0101a5b687e45c479f80"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg3NDg4OTQx", "url": "https://github.com/apache/flink/pull/13373#pullrequestreview-487488941", "createdAt": "2020-09-14T07:36:45Z", "commit": {"oid": "bab621c4f92387eef5bf0101a5b687e45c479f80"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "44161ed79481cd2f7b76527124fbd6186eac5aaf", "author": {"user": {"login": "dawidwys", "name": "Dawid Wysakowicz"}}, "url": "https://github.com/apache/flink/commit/44161ed79481cd2f7b76527124fbd6186eac5aaf", "committedDate": "2020-09-14T08:28:44Z", "message": "[hotfix] Fix Pojo comparator field access\n\nThe PojoComparator assumes it can access a field of a pojo directly. It assumes the field is either public or setAccessible was called before. This is the case though only if  the record went through serialization. This is not the case e.g. in CollectionExecution mode.\n\nStarting from this commit we make all fields accessible in\nPojoComparator constructor."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a99c86b50af1d061dcb329d44c88d7419f8ddfb2", "author": {"user": {"login": "dawidwys", "name": "Dawid Wysakowicz"}}, "url": "https://github.com/apache/flink/commit/a99c86b50af1d061dcb329d44c88d7419f8ddfb2", "committedDate": "2020-09-14T08:28:44Z", "message": "[hotfix] Extract joda conversions to a separate class"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bb7e8094f0675c882471f7ca31732f954275e470", "author": {"user": {"login": "dawidwys", "name": "Dawid Wysakowicz"}}, "url": "https://github.com/apache/flink/commit/bb7e8094f0675c882471f7ca31732f954275e470", "committedDate": "2020-09-14T08:39:43Z", "message": "[hotfix] Fix schema to DataType/Type conversion"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "76e7b1f3424c7348e99ba27d6f533ac01cb0af4d", "author": {"user": {"login": "dawidwys", "name": "Dawid Wysakowicz"}}, "url": "https://github.com/apache/flink/commit/76e7b1f3424c7348e99ba27d6f533ac01cb0af4d", "committedDate": "2020-09-14T08:40:47Z", "message": "[hotfix] Fix time-micros and timestamp-micros handling"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8442f93c6b63aa92c72b890e012151dd8c58d81b", "author": {"user": {"login": "dawidwys", "name": "Dawid Wysakowicz"}}, "url": "https://github.com/apache/flink/commit/8442f93c6b63aa92c72b890e012151dd8c58d81b", "committedDate": "2020-09-14T09:06:04Z", "message": "[hotfix] Migrate AvroTypesITCase to blink planner"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "bab621c4f92387eef5bf0101a5b687e45c479f80", "author": {"user": {"login": "dawidwys", "name": "Dawid Wysakowicz"}}, "url": "https://github.com/apache/flink/commit/bab621c4f92387eef5bf0101a5b687e45c479f80", "committedDate": "2020-09-11T19:56:10Z", "message": "[FLINK-18802] Create an uber jar for avro for sql-client"}, "afterCommit": {"oid": "58d8186564b4f1e810985d59fb8764b1cabb21ff", "author": {"user": {"login": "dawidwys", "name": "Dawid Wysakowicz"}}, "url": "https://github.com/apache/flink/commit/58d8186564b4f1e810985d59fb8764b1cabb21ff", "committedDate": "2020-09-14T09:12:05Z", "message": "[FLINK-18802] Create an uber jar for avro for sql-client"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1979b49a8f98b6edfb860d3e514076407ae2a0d1", "author": {"user": {"login": "dawidwys", "name": "Dawid Wysakowicz"}}, "url": "https://github.com/apache/flink/commit/1979b49a8f98b6edfb860d3e514076407ae2a0d1", "committedDate": "2020-09-14T09:15:08Z", "message": "[FLINK-18192] Upgrade avro to 1.10\n\nThis commit upgrades the default version of avro that flink-avro will use. It should be possible to downgrade the avro version in a user job as the binary format is compatible and we do not expose any dependencies on avro in the API.\n\nAdditionally this commit fixes handling of logical types: time-micros and timestamp-micros as well as interpretation of timestamp-millis in the AvroRowDataDeserializationSchema."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "166a17e676304c9215f3b5b517cca71fdb2e927f", "author": {"user": {"login": "dawidwys", "name": "Dawid Wysakowicz"}}, "url": "https://github.com/apache/flink/commit/166a17e676304c9215f3b5b517cca71fdb2e927f", "committedDate": "2020-09-14T09:15:15Z", "message": "[FLINK-18802] Create an uber jar for avro for sql-client"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "58d8186564b4f1e810985d59fb8764b1cabb21ff", "author": {"user": {"login": "dawidwys", "name": "Dawid Wysakowicz"}}, "url": "https://github.com/apache/flink/commit/58d8186564b4f1e810985d59fb8764b1cabb21ff", "committedDate": "2020-09-14T09:12:05Z", "message": "[FLINK-18802] Create an uber jar for avro for sql-client"}, "afterCommit": {"oid": "166a17e676304c9215f3b5b517cca71fdb2e927f", "author": {"user": {"login": "dawidwys", "name": "Dawid Wysakowicz"}}, "url": "https://github.com/apache/flink/commit/166a17e676304c9215f3b5b517cca71fdb2e927f", "committedDate": "2020-09-14T09:15:15Z", "message": "[FLINK-18802] Create an uber jar for avro for sql-client"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3876, "cost": 1, "resetAt": "2021-10-28T16:48:13Z"}}}