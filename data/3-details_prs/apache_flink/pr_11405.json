{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg4MTg5NDc2", "number": 11405, "title": "[FLINK-16413]Reduce hive source parallelism when limit push down", "bodyText": "What is the purpose of the change\nReduce hive source parallelism when limit push down\nBrief change log\nwhen limit push down ,set the parallelism to min(parallelism,limit)\nVerifying this change\n(Please pick either of the following options)\nThis change is a trivial rework / code cleanup without any test coverage.\n(or)\nThis change is already covered by existing tests, such as (please describe tests).\n(or)\nThis change added tests and can be verified as follows:\n(example:)\n\nAdded integration tests for end-to-end deployment with large payloads (100MB)\nExtended integration test for recovery after master (JobManager) failure\nAdded test that validates that TaskInfo is transferred only once across recoveries\nManually verified the change by running a 4 node cluser with 2 JobManagers and 4 TaskManagers, a stateful streaming program, and killing one JobManager and two TaskManagers during the execution, verifying that recovery happens correctly.\n\nDoes this pull request potentially affect one of the following parts:\n\nDependencies (does it add or upgrade a dependency): no\nThe public API, i.e., is any changed class annotated with @Public(Evolving): no\nThe serializers: no\nThe runtime per-record code paths (performance sensitive): no\nAnything that affects deployment or recovery: JobManager (and its components), Checkpointing, Kubernetes/Yarn/Mesos, ZooKeeper: no\nThe S3 file system connector:no\n\nDocumentation\n\nDoes this pull request introduce a new feature? (yes / no)\nIf yes, how is the feature documented? (not applicable / docs / JavaDocs / not documented)", "createdAt": "2020-03-14T06:51:13Z", "url": "https://github.com/apache/flink/pull/11405", "merged": true, "mergeCommit": {"oid": "1063d56154caddc6d116605fb6590ec06ab6e5d1"}, "closed": true, "closedAt": "2020-03-17T02:47:19Z", "author": {"login": "zhangjun0x01"}, "timelineItems": {"totalCount": 13, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABb8Y8X3gH2gAyMzg4MTg5NDc2OmQwYmZkODlhYzY5MTExZGMyMDAyMzJkY2QzN2NlNWI5NTRlNTA5Nzc=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcOZhR-AFqTM3NTcwMzcyMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "d0bfd89ac69111dc200232dcd37ce5b954e50977", "author": {"user": null}, "url": "https://github.com/apache/flink/commit/d0bfd89ac69111dc200232dcd37ce5b954e50977", "committedDate": "2020-01-21T03:54:03Z", "message": "test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5661cfc7aebe7f3340c88a413fa868c8a34b6b1b", "author": {"user": null}, "url": "https://github.com/apache/flink/commit/5661cfc7aebe7f3340c88a413fa868c8a34b6b1b", "committedDate": "2020-03-13T05:46:06Z", "message": "Merge branch 'master' of https://github.com/apache/flink"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "eb82471fb734d65609504d47e3c37bd5495595eb", "author": {"user": null}, "url": "https://github.com/apache/flink/commit/eb82471fb734d65609504d47e3c37bd5495595eb", "committedDate": "2020-03-13T14:27:16Z", "message": "Merge branch 'master' of https://github.com/apache/flink"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3f7c411943106addb8d85d19a22b23e5a74bc457", "author": {"user": null}, "url": "https://github.com/apache/flink/commit/3f7c411943106addb8d85d19a22b23e5a74bc457", "committedDate": "2020-03-14T00:34:18Z", "message": "Merge branch 'master' of https://github.com/apache/flink"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3d425d3af8d4bb20259fb5c60b3b62e4e00161b8", "author": {"user": {"login": "zhangjun0x01", "name": "JunZhang"}}, "url": "https://github.com/apache/flink/commit/3d425d3af8d4bb20259fb5c60b3b62e4e00161b8", "committedDate": "2020-03-14T00:49:43Z", "message": "Delete HotelOrder2HdfsK8sTest.java"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b196447b93a3c1bdb64fce172c2aea305e16093b", "author": {"user": {"login": "HarukaMa", "name": "Haruka Ma"}}, "url": "https://github.com/apache/flink/commit/b196447b93a3c1bdb64fce172c2aea305e16093b", "committedDate": "2020-03-14T06:33:15Z", "message": "Reduce hive source parallelism when limit push down"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6bdafe404b708ddd3a50340f8cc961824b1f533f", "author": {"user": {"login": "zhangjun0x01", "name": "JunZhang"}}, "url": "https://github.com/apache/flink/commit/6bdafe404b708ddd3a50340f8cc961824b1f533f", "committedDate": "2020-03-16T01:14:55Z", "message": "Update pom.xml"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ba40c607250f084c3210b678e82159c479307dff", "author": {"user": {"login": "zhangjun0x01", "name": "JunZhang"}}, "url": "https://github.com/apache/flink/commit/ba40c607250f084c3210b678e82159c479307dff", "committedDate": "2020-03-16T01:17:06Z", "message": "Update pom.xml"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc0ODczMzY1", "url": "https://github.com/apache/flink/pull/11405#pullrequestreview-374873365", "createdAt": "2020-03-16T01:48:57Z", "commit": {"oid": "b196447b93a3c1bdb64fce172c2aea305e16093b"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQwMTo0ODo1N1rOF2je3Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQwMjowMDowNlrOF2jqmQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjc0ODc2NQ==", "bodyText": "Should also affect when not open parallelism infer, modify to:\nint parallelism = flinkConf.get(ExecutionConfigOptions.TABLE_EXEC_RESOURCE_DEFAULT_PARALLELISM);\nif (flinkConf.get(HiveOptions.TABLE_EXEC_HIVE_INFER_SOURCE_PARALLELISM)) {\n    ......\n    parallelism = Math.min(splitNum, max);\n}\nparallelism = limit > 0 ? Math.min(parallelism, (int) limit / 1000) : parallelism;\nparallelism = Math.max(1, parallelism);\nsource.setParallelism(parallelism);", "url": "https://github.com/apache/flink/pull/11405#discussion_r392748765", "createdAt": "2020-03-16T01:48:57Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/HiveTableSource.java", "diffHunk": "@@ -168,7 +168,9 @@ public boolean isBounded() {\n \t\t\t} catch (IOException e) {\n \t\t\t\tthrow new FlinkHiveException(e);\n \t\t\t}\n-\t\t\tsource.setParallelism(Math.min(Math.max(1, splitNum), max));\n+\t\t\tint parallelism = Math.min(Math.max(1, splitNum), max);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b196447b93a3c1bdb64fce172c2aea305e16093b"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjc1MTQ0Mg==", "bodyText": "Add this for real test parallelism:\ntEnv.getConfig().getConfiguration().setBoolean(\n\t\t\t\tHiveOptions.TABLE_EXEC_HIVE_FALLBACK_MAPRED_READER, false);\ntEnv.getConfig().getConfiguration().setInteger(\n\t\t\t\tExecutionConfigOptions.TABLE_EXEC_RESOURCE_DEFAULT_PARALLELISM, 2);", "url": "https://github.com/apache/flink/pull/11405#discussion_r392751442", "createdAt": "2020-03-16T01:58:02Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveTableSourceTest.java", "diffHunk": "@@ -410,6 +410,32 @@ public void testParallelismSetting() {\n \t\tAssert.assertEquals(2, transformation.getParallelism());\n \t}\n \n+\t@Test\n+\tpublic void testParallelismOnLimitPushDown() {\n+\t\tfinal String catalogName = \"hive\";\n+\t\tfinal String dbName = \"source_db\";\n+\t\tfinal String tblName = \"test_parallelism_limit_pushdown\";\n+\t\thiveShell.execute(\"CREATE TABLE source_db.test_parallelism_limit_pushdown \" +\n+\t\t                  \"(year STRING, value INT) partitioned by (pt int);\");\n+\t\tHiveTestUtils.createTextTableInserter(hiveShell, dbName, tblName)\n+\t\t             .addRow(new Object[]{\"2014\", 3})\n+\t\t             .addRow(new Object[]{\"2014\", 4})\n+\t\t             .commit(\"pt=0\");\n+\t\tHiveTestUtils.createTextTableInserter(hiveShell, dbName, tblName)\n+\t\t             .addRow(new Object[]{\"2015\", 2})\n+\t\t             .addRow(new Object[]{\"2015\", 5})\n+\t\t             .commit(\"pt=1\");\n+\t\tTableEnvironment tEnv = HiveTestUtils.createTableEnvWithBlinkPlannerBatchMode();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b196447b93a3c1bdb64fce172c2aea305e16093b"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjc1MTc2OQ==", "bodyText": "This is limit transformation, should always be 1.\nAssert.assertEquals(1, ((PartitionTransformation) ((OneInputTransformation) transformation).getInput())\n\t\t\t\t.getInput().getParallelism());", "url": "https://github.com/apache/flink/pull/11405#discussion_r392751769", "createdAt": "2020-03-16T02:00:06Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveTableSourceTest.java", "diffHunk": "@@ -410,6 +410,32 @@ public void testParallelismSetting() {\n \t\tAssert.assertEquals(2, transformation.getParallelism());\n \t}\n \n+\t@Test\n+\tpublic void testParallelismOnLimitPushDown() {\n+\t\tfinal String catalogName = \"hive\";\n+\t\tfinal String dbName = \"source_db\";\n+\t\tfinal String tblName = \"test_parallelism_limit_pushdown\";\n+\t\thiveShell.execute(\"CREATE TABLE source_db.test_parallelism_limit_pushdown \" +\n+\t\t                  \"(year STRING, value INT) partitioned by (pt int);\");\n+\t\tHiveTestUtils.createTextTableInserter(hiveShell, dbName, tblName)\n+\t\t             .addRow(new Object[]{\"2014\", 3})\n+\t\t             .addRow(new Object[]{\"2014\", 4})\n+\t\t             .commit(\"pt=0\");\n+\t\tHiveTestUtils.createTextTableInserter(hiveShell, dbName, tblName)\n+\t\t             .addRow(new Object[]{\"2015\", 2})\n+\t\t             .addRow(new Object[]{\"2015\", 5})\n+\t\t             .commit(\"pt=1\");\n+\t\tTableEnvironment tEnv = HiveTestUtils.createTableEnvWithBlinkPlannerBatchMode();\n+\t\ttEnv.registerCatalog(catalogName, hiveCatalog);\n+\t\tTable table = tEnv.sqlQuery(\"select * from hive.source_db.test_parallelism_limit_pushdown limit 1\");\n+\t\tPlannerBase planner = (PlannerBase) ((TableEnvironmentImpl) tEnv).getPlanner();\n+\t\tRelNode relNode = planner.optimize(TableTestUtil.toRelNode(table));\n+\t\tExecNode execNode = planner.translateToExecNodePlan(toScala(Collections.singletonList(relNode))).get(0);\n+\t\t@SuppressWarnings(\"unchecked\")\n+\t\tTransformation transformation = execNode.translateToPlan(planner);\n+\t\tAssert.assertEquals(1, transformation.getParallelism());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b196447b93a3c1bdb64fce172c2aea305e16093b"}, "originalPosition": 27}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7fc8bc0e4c1f9d99e4b4edfcbe7939d23596283d", "author": {"user": null}, "url": "https://github.com/apache/flink/commit/7fc8bc0e4c1f9d99e4b4edfcbe7939d23596283d", "committedDate": "2020-03-16T13:48:32Z", "message": "Reduce hive source parallelism when limit push down"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4a3d439a9e53fed320efd8220c35f092e64dbbf3", "author": {"user": null}, "url": "https://github.com/apache/flink/commit/4a3d439a9e53fed320efd8220c35f092e64dbbf3", "committedDate": "2020-03-16T13:48:32Z", "message": "Reduce hive source parallelism when limit push down"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d24333b8d10136ea7ba12a1f2da62cf18fd01d89", "author": {"user": null}, "url": "https://github.com/apache/flink/commit/d24333b8d10136ea7ba12a1f2da62cf18fd01d89", "committedDate": "2020-03-16T14:11:58Z", "message": "Reduce hive source parallelism when limit push down"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc1NzAzNzIx", "url": "https://github.com/apache/flink/pull/11405#pullrequestreview-375703721", "createdAt": "2020-03-17T02:45:00Z", "commit": {"oid": "d24333b8d10136ea7ba12a1f2da62cf18fd01d89"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2778, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}