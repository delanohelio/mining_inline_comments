{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzcxMjgzNjAx", "number": 11020, "reviewThreads": {"totalCount": 22, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQwODowOToxMlrODdl9Ug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QxMzoxMzo0NlrODeBCbA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyMzU3MjAyOnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/table/runtime/typeutils/serializers/python/TableSerializer.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQwODowOToxMlrOFmSLWw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQwODowOToxMlrOFmSLWw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY4ODAyNw==", "bodyText": "Rename this to PythonTableFunctionSerializer?", "url": "https://github.com/apache/flink/pull/11020#discussion_r375688027", "createdAt": "2020-02-06T08:09:12Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/table/runtime/typeutils/serializers/python/TableSerializer.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.typeutils.serializers.python;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.TypeSerializerSnapshot;\n+import org.apache.flink.core.memory.DataInputView;\n+import org.apache.flink.core.memory.DataOutputView;\n+\n+import java.io.DataInputStream;\n+import java.io.IOException;\n+import java.util.Arrays;\n+\n+import static org.apache.flink.api.java.typeutils.runtime.NullMaskUtils.readIntoNullMask;\n+\n+/**\n+ * Base Table Serializer for Table Function.\n+ */\n+@Internal\n+abstract class TableSerializer<T> extends TypeSerializer<T> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a2f0e14c373b5fb8aa56ec8371899e549e8859fa"}, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyNDE0ODQyOnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/table/runtime/typeutils/PythonTypeUtils.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxMToyMDo0OFrOFmXsAA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxMToyMDo0OFrOFmXsAA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTc3ODMwNA==", "bodyText": "Since this method is only used by TableFunction, I'd like not to add this method in the class. How about add it in PythonTableFunctionRunner.\nSame for toTableProtoType.", "url": "https://github.com/apache/flink/pull/11020#discussion_r375778304", "createdAt": "2020-02-06T11:20:48Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/table/runtime/typeutils/PythonTypeUtils.java", "diffHunk": "@@ -90,6 +91,39 @@ public static TypeSerializer toBlinkTypeSerializer(LogicalType logicalType) {\n \t\treturn logicalType.accept(new LogicalTypeToProtoTypeConverter());\n \t}\n \n+\tpublic static TypeSerializer toFlinkTableTypeSerializer(LogicalType logicalType) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a2f0e14c373b5fb8aa56ec8371899e549e8859fa"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyNDE1MjI3OnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/table/runtime/typeutils/PythonTypeUtils.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxMToyMjowNlrOFmXuQw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxMToyMjowNlrOFmXuQw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTc3ODg4Mw==", "bodyText": "It's not good to cast here. It's better to change the method from toFlinkTableTypeSerializer(LogicalType logicalType) to toFlinkTableTypeSerializer(RowType logicalType)\nSame for toTableProtoType.", "url": "https://github.com/apache/flink/pull/11020#discussion_r375778883", "createdAt": "2020-02-06T11:22:06Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/table/runtime/typeutils/PythonTypeUtils.java", "diffHunk": "@@ -90,6 +91,39 @@ public static TypeSerializer toBlinkTypeSerializer(LogicalType logicalType) {\n \t\treturn logicalType.accept(new LogicalTypeToProtoTypeConverter());\n \t}\n \n+\tpublic static TypeSerializer toFlinkTableTypeSerializer(LogicalType logicalType) {\n+\t\tRowType rowType = (RowType) logicalType;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a2f0e14c373b5fb8aa56ec8371899e549e8859fa"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyNDE1ODYzOnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/table/runtime/typeutils/PythonTypeUtils.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxMToyNDozOVrOFmXyOQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxMToyNDozOVrOFmXyOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTc3OTg5Nw==", "bodyText": "Rename the method name to toFlinkTableFunctionTypeSerializer", "url": "https://github.com/apache/flink/pull/11020#discussion_r375779897", "createdAt": "2020-02-06T11:24:39Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/table/runtime/typeutils/PythonTypeUtils.java", "diffHunk": "@@ -90,6 +91,39 @@ public static TypeSerializer toBlinkTypeSerializer(LogicalType logicalType) {\n \t\treturn logicalType.accept(new LogicalTypeToProtoTypeConverter());\n \t}\n \n+\tpublic static TypeSerializer toFlinkTableTypeSerializer(LogicalType logicalType) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a2f0e14c373b5fb8aa56ec8371899e549e8859fa"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyNDE1OTY3OnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/table/runtime/typeutils/PythonTypeUtils.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxMToyNTowMlrOFmXy4w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxMToyNTowMlrOFmXy4w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTc4MDA2Nw==", "bodyText": "Rename method name to toTableFunctionProtoType", "url": "https://github.com/apache/flink/pull/11020#discussion_r375780067", "createdAt": "2020-02-06T11:25:02Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/table/runtime/typeutils/PythonTypeUtils.java", "diffHunk": "@@ -90,6 +91,39 @@ public static TypeSerializer toBlinkTypeSerializer(LogicalType logicalType) {\n \t\treturn logicalType.accept(new LogicalTypeToProtoTypeConverter());\n \t}\n \n+\tpublic static TypeSerializer toFlinkTableTypeSerializer(LogicalType logicalType) {\n+\t\tRowType rowType = (RowType) logicalType;\n+\t\tLogicalTypeDefaultVisitor<TypeSerializer> converter =\n+\t\t\tnew LogicalTypeToTypeSerializerConverter();\n+\t\tfinal TypeSerializer[] fieldTypeSerializers = rowType.getFields()\n+\t\t\t.stream()\n+\t\t\t.map(f -> f.getType().accept(converter))\n+\t\t\t.toArray(TypeSerializer[]::new);\n+\t\treturn new RowTableSerializer(fieldTypeSerializers);\n+\t}\n+\n+\tpublic static FlinkFnApi.Schema.FieldType toTableProtoType(LogicalType logicalType) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a2f0e14c373b5fb8aa56ec8371899e549e8859fa"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyNDE3NTEzOnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/table/runtime/typeutils/serializers/python/RowTableSerializer.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxMTozMDoyNVrOFmX8CQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxMTozMDoyNVrOFmX8CQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTc4MjQwOQ==", "bodyText": "Rename this to RowTableFunctionSerializer?", "url": "https://github.com/apache/flink/pull/11020#discussion_r375782409", "createdAt": "2020-02-06T11:30:25Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/table/runtime/typeutils/serializers/python/RowTableSerializer.java", "diffHunk": "@@ -0,0 +1,60 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.typeutils.serializers.python;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.java.typeutils.runtime.RowSerializer;\n+import org.apache.flink.core.memory.DataOutputView;\n+import org.apache.flink.types.Row;\n+\n+import java.io.IOException;\n+\n+/**\n+ * The implementation of TableSerializer in legacy planner.\n+ */\n+@Internal\n+public final class RowTableSerializer extends TableSerializer<Row> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a2f0e14c373b5fb8aa56ec8371899e549e8859fa"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyNDE5MTcxOnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/table/runtime/typeutils/serializers/python/TableSerializer.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxMTozNjo1MFrOFmYGVA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QwNDo0ODozNFrOFmyOfg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTc4NTA0NA==", "bodyText": "Do we have any other TableFunctionSerializers beside RowTableFunctionSerializer? For example, TupleTableFunctionSerializer. If there no other serializers, I'd like not to add this abstract class. Instead, simply add RowTableFunctionSerializer extends from TypeSerializer would be ok. What do you think?", "url": "https://github.com/apache/flink/pull/11020#discussion_r375785044", "createdAt": "2020-02-06T11:36:50Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/table/runtime/typeutils/serializers/python/TableSerializer.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.typeutils.serializers.python;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.TypeSerializerSnapshot;\n+import org.apache.flink.core.memory.DataInputView;\n+import org.apache.flink.core.memory.DataOutputView;\n+\n+import java.io.DataInputStream;\n+import java.io.IOException;\n+import java.util.Arrays;\n+\n+import static org.apache.flink.api.java.typeutils.runtime.NullMaskUtils.readIntoNullMask;\n+\n+/**\n+ * Base Table Serializer for Table Function.\n+ */\n+@Internal\n+abstract class TableSerializer<T> extends TypeSerializer<T> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a2f0e14c373b5fb8aa56ec8371899e549e8859fa"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjE2NTQ5MQ==", "bodyText": "I will add BaseRowTableFunctionSerializer extends from TableFunctionSerializers in next pr.", "url": "https://github.com/apache/flink/pull/11020#discussion_r376165491", "createdAt": "2020-02-07T00:59:01Z", "author": {"login": "HuangXingBo"}, "path": "flink-python/src/main/java/org/apache/flink/table/runtime/typeutils/serializers/python/TableSerializer.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.typeutils.serializers.python;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.TypeSerializerSnapshot;\n+import org.apache.flink.core.memory.DataInputView;\n+import org.apache.flink.core.memory.DataOutputView;\n+\n+import java.io.DataInputStream;\n+import java.io.IOException;\n+import java.util.Arrays;\n+\n+import static org.apache.flink.api.java.typeutils.runtime.NullMaskUtils.readIntoNullMask;\n+\n+/**\n+ * Base Table Serializer for Table Function.\n+ */\n+@Internal\n+abstract class TableSerializer<T> extends TypeSerializer<T> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTc4NTA0NA=="}, "originalCommit": {"oid": "a2f0e14c373b5fb8aa56ec8371899e549e8859fa"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjIxMzExOA==", "bodyText": "After rebase the pr FLINK-15897, I think we can remove the TableFunctionSerializer.Because we can decide whether the message is finish message according to the length and content of  the message byte array.", "url": "https://github.com/apache/flink/pull/11020#discussion_r376213118", "createdAt": "2020-02-07T04:48:34Z", "author": {"login": "HuangXingBo"}, "path": "flink-python/src/main/java/org/apache/flink/table/runtime/typeutils/serializers/python/TableSerializer.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.typeutils.serializers.python;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.TypeSerializerSnapshot;\n+import org.apache.flink.core.memory.DataInputView;\n+import org.apache.flink.core.memory.DataOutputView;\n+\n+import java.io.DataInputStream;\n+import java.io.IOException;\n+import java.util.Arrays;\n+\n+import static org.apache.flink.api.java.typeutils.runtime.NullMaskUtils.readIntoNullMask;\n+\n+/**\n+ * Base Table Serializer for Table Function.\n+ */\n+@Internal\n+abstract class TableSerializer<T> extends TypeSerializer<T> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTc4NTA0NA=="}, "originalCommit": {"oid": "a2f0e14c373b5fb8aa56ec8371899e549e8859fa"}, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyNDIwNzY2OnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/table/runtime/typeutils/serializers/python/TableSerializer.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxMTo0MjozMlrOFmYPwQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxMTo0MjozMlrOFmYPwQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTc4NzQ1Nw==", "bodyText": "This method has not been overrided by the child class RowTableFunctionSerializer. Once we have multi child classes, the equals method would be wrong, for example, a RowTableFunctionSerializer will equal to a TupleTableFunctionSerializer if they share the same filed serializers.", "url": "https://github.com/apache/flink/pull/11020#discussion_r375787457", "createdAt": "2020-02-06T11:42:32Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/table/runtime/typeutils/serializers/python/TableSerializer.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.typeutils.serializers.python;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.TypeSerializerSnapshot;\n+import org.apache.flink.core.memory.DataInputView;\n+import org.apache.flink.core.memory.DataOutputView;\n+\n+import java.io.DataInputStream;\n+import java.io.IOException;\n+import java.util.Arrays;\n+\n+import static org.apache.flink.api.java.typeutils.runtime.NullMaskUtils.readIntoNullMask;\n+\n+/**\n+ * Base Table Serializer for Table Function.\n+ */\n+@Internal\n+abstract class TableSerializer<T> extends TypeSerializer<T> {\n+\n+\tprivate final TypeSerializer[] fieldSerializers;\n+\n+\tprivate transient boolean[] nullMask;\n+\n+\tTableSerializer(TypeSerializer[] fieldSerializers) {\n+\t\tthis.fieldSerializers = fieldSerializers;\n+\t\tthis.nullMask = new boolean[Math.max(fieldSerializers.length - 8, 0)];\n+\t}\n+\n+\t@Override\n+\tpublic boolean isImmutableType() {\n+\t\treturn false;\n+\t}\n+\n+\t@Override\n+\tpublic TypeSerializer<T> duplicate() {\n+\t\tthrow new RuntimeException(\"This method duplicate() should not be called\");\n+\t}\n+\n+\t@Override\n+\tpublic T createInstance() {\n+\t\treturn unwantedMethodCall(\"createInstance()\");\n+\t}\n+\n+\t@Override\n+\tpublic T copy(T from) {\n+\t\treturn unwantedMethodCall(\"copy(T from)\");\n+\t}\n+\n+\t@Override\n+\tpublic T copy(T from, T reuse) {\n+\t\treturn unwantedMethodCall(\"copy(T from, T reuse)\");\n+\t}\n+\n+\t@Override\n+\tpublic int getLength() {\n+\t\treturn -1;\n+\t}\n+\n+\t@Override\n+\tpublic T deserialize(T reuse, DataInputView source) throws IOException {\n+\t\treturn unwantedMethodCall(\"deserialize(T reuse, DataInputView source)\");\n+\t}\n+\n+\t@Override\n+\tpublic void copy(DataInputView source, DataOutputView target) throws IOException {\n+\t\tunwantedMethodCall(\"copy(DataInputView source, DataOutputView target)\");\n+\t}\n+\n+\tprivate T unwantedMethodCall(String methodName) {\n+\t\tthrow new RuntimeException(String.format(\"The method %s should not be called\", methodName));\n+\t}\n+\n+\tpublic abstract T createResult(int len);\n+\n+\tpublic abstract void setField(T result, int index, Object value);\n+\n+\t@Override\n+\tpublic T deserialize(DataInputView source) throws IOException {\n+\t\tint len = fieldSerializers.length;\n+\t\tint b = source.readUnsignedByte() & 0xff;\n+\t\tDataInputStream inputStream = (DataInputStream) source;\n+\t\tif (b == 0x00 && inputStream.available() == 0) {\n+\t\t\treturn createResult(0);\n+\t\t}\n+\t\tT result = createResult(len);\n+\t\tint minLen = Math.min(8, len);\n+\t\treadIntoNullMask(len - 8, source, nullMask);\n+\t\tfor (int i = 0; i < minLen; i++) {\n+\t\t\tif ((b & 0x80) > 0) {\n+\t\t\t\tsetField(result, i, null);\n+\t\t\t} else {\n+\t\t\t\tsetField(result, i, fieldSerializers[i].deserialize(source));\n+\t\t\t}\n+\t\t\tb = b << 1;\n+\t\t}\n+\t\tfor (int i = 0, j = minLen; j < len; i++, j++) {\n+\t\t\tif (nullMask[i]) {\n+\t\t\t\tsetField(result, j, null);\n+\t\t\t} else {\n+\t\t\t\tsetField(result, j, fieldSerializers[j].deserialize(source));\n+\t\t\t}\n+\t\t}\n+\n+\t\treturn result;\n+\t}\n+\n+\t@Override\n+\tpublic boolean equals(Object obj) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a2f0e14c373b5fb8aa56ec8371899e549e8859fa"}, "originalPosition": 127}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyNDIyNTgxOnYy", "diffSide": "RIGHT", "path": "flink-python/pyflink/proto/flink-fn-execution.proto", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxMTo0OTo0M1rOFmYa9Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QwNDo1Mjo0OVrOFmyRYw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTc5MDMyNQ==", "bodyText": "Can we reuse the ROW Type here? A ROW type for the TableFunction should be a TABLE type.", "url": "https://github.com/apache/flink/pull/11020#discussion_r375790325", "createdAt": "2020-02-06T11:49:43Z", "author": {"login": "hequn8128"}, "path": "flink-python/pyflink/proto/flink-fn-execution.proto", "diffHunk": "@@ -73,6 +73,7 @@ message Schema {\n     ARRAY = 16;\n     MAP = 17;\n     MULTISET = 18;\n+    TABLE = 19;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a2f0e14c373b5fb8aa56ec8371899e549e8859fa"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjIxMzg1OQ==", "bodyText": "Because the proto doesn't include any info about the function type is TableFunction, We need  extra info to know the coder type or func type in Python.Maybe there would be better solution. What's your suggestion?", "url": "https://github.com/apache/flink/pull/11020#discussion_r376213859", "createdAt": "2020-02-07T04:52:49Z", "author": {"login": "HuangXingBo"}, "path": "flink-python/pyflink/proto/flink-fn-execution.proto", "diffHunk": "@@ -73,6 +73,7 @@ message Schema {\n     ARRAY = 16;\n     MAP = 17;\n     MULTISET = 18;\n+    TABLE = 19;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTc5MDMyNQ=="}, "originalCommit": {"oid": "a2f0e14c373b5fb8aa56ec8371899e549e8859fa"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyNDI3MDgyOnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/table/runtime/typeutils/serializers/python/TableSerializer.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxMjowNjo1MVrOFmY2Pw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxMjowNjo1MVrOFmY2Pw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTc5NzMxMQ==", "bodyText": "Add some comments for this method. It would be quite helpful for other ones to understand.", "url": "https://github.com/apache/flink/pull/11020#discussion_r375797311", "createdAt": "2020-02-06T12:06:51Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/table/runtime/typeutils/serializers/python/TableSerializer.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.typeutils.serializers.python;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.TypeSerializerSnapshot;\n+import org.apache.flink.core.memory.DataInputView;\n+import org.apache.flink.core.memory.DataOutputView;\n+\n+import java.io.DataInputStream;\n+import java.io.IOException;\n+import java.util.Arrays;\n+\n+import static org.apache.flink.api.java.typeutils.runtime.NullMaskUtils.readIntoNullMask;\n+\n+/**\n+ * Base Table Serializer for Table Function.\n+ */\n+@Internal\n+abstract class TableSerializer<T> extends TypeSerializer<T> {\n+\n+\tprivate final TypeSerializer[] fieldSerializers;\n+\n+\tprivate transient boolean[] nullMask;\n+\n+\tTableSerializer(TypeSerializer[] fieldSerializers) {\n+\t\tthis.fieldSerializers = fieldSerializers;\n+\t\tthis.nullMask = new boolean[Math.max(fieldSerializers.length - 8, 0)];\n+\t}\n+\n+\t@Override\n+\tpublic boolean isImmutableType() {\n+\t\treturn false;\n+\t}\n+\n+\t@Override\n+\tpublic TypeSerializer<T> duplicate() {\n+\t\tthrow new RuntimeException(\"This method duplicate() should not be called\");\n+\t}\n+\n+\t@Override\n+\tpublic T createInstance() {\n+\t\treturn unwantedMethodCall(\"createInstance()\");\n+\t}\n+\n+\t@Override\n+\tpublic T copy(T from) {\n+\t\treturn unwantedMethodCall(\"copy(T from)\");\n+\t}\n+\n+\t@Override\n+\tpublic T copy(T from, T reuse) {\n+\t\treturn unwantedMethodCall(\"copy(T from, T reuse)\");\n+\t}\n+\n+\t@Override\n+\tpublic int getLength() {\n+\t\treturn -1;\n+\t}\n+\n+\t@Override\n+\tpublic T deserialize(T reuse, DataInputView source) throws IOException {\n+\t\treturn unwantedMethodCall(\"deserialize(T reuse, DataInputView source)\");\n+\t}\n+\n+\t@Override\n+\tpublic void copy(DataInputView source, DataOutputView target) throws IOException {\n+\t\tunwantedMethodCall(\"copy(DataInputView source, DataOutputView target)\");\n+\t}\n+\n+\tprivate T unwantedMethodCall(String methodName) {\n+\t\tthrow new RuntimeException(String.format(\"The method %s should not be called\", methodName));\n+\t}\n+\n+\tpublic abstract T createResult(int len);\n+\n+\tpublic abstract void setField(T result, int index, Object value);\n+\n+\t@Override\n+\tpublic T deserialize(DataInputView source) throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a2f0e14c373b5fb8aa56ec8371899e549e8859fa"}, "originalPosition": 97}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyNDMwMDMxOnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/table/runtime/operators/python/PythonTableFunctionOperator.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxMjoxODozMFrOFmZH_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxMjoxODozMFrOFmZH_g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTgwMTg1NA==", "bodyText": "Copy the input Row before putting into the queue if getExecutionConfig().isObjectReuseEnabled() returns true", "url": "https://github.com/apache/flink/pull/11020#discussion_r375801854", "createdAt": "2020-02-06T12:18:30Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/table/runtime/operators/python/PythonTableFunctionOperator.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.operators.python;\n+\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.python.PythonFunctionRunner;\n+import org.apache.flink.python.env.PythonEnvironmentManager;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.table.functions.TableFunction;\n+import org.apache.flink.table.functions.python.PythonFunctionInfo;\n+import org.apache.flink.table.runtime.runners.python.PythonTableFunctionRunner;\n+import org.apache.flink.table.runtime.types.CRow;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.types.Row;\n+import org.apache.flink.util.Collector;\n+\n+import org.apache.beam.sdk.fn.data.FnDataReceiver;\n+\n+/**\n+ * The Python {@link TableFunction} operator for the legacy planner.\n+ */\n+public class PythonTableFunctionOperator extends AbstractPythonTableFunctionOperator<CRow, CRow, Row, Row> {\n+\n+\tprivate static final long serialVersionUID = 1L;\n+\n+\t/**\n+\t * The collector used to collect records.\n+\t */\n+\tprivate transient StreamRecordCRowWrappingCollector cRowWrapper;\n+\n+\tpublic PythonTableFunctionOperator(\n+\t\tConfiguration config,\n+\t\tPythonFunctionInfo tableFunction,\n+\t\tRowType inputType,\n+\t\tRowType outputType,\n+\t\tint[] udtfInputOffsets) {\n+\t\tsuper(config, tableFunction, inputType, outputType, udtfInputOffsets);\n+\t}\n+\n+\t@Override\n+\tpublic void open() throws Exception {\n+\t\tsuper.open();\n+\t\tthis.cRowWrapper = new StreamRecordCRowWrappingCollector(output);\n+\t}\n+\n+\tprivate boolean isFinishResult(Row result) {\n+\t\treturn result.getArity() == 0;\n+\t}\n+\n+\t@Override\n+\tpublic void emitResults() {\n+\t\tRow udtfResult;\n+\t\tCRow input = null;\n+\t\twhile ((udtfResult = udtfResultQueue.poll()) != null) {\n+\t\t\tif (input == null) {\n+\t\t\t\tinput = forwardedInputQueue.poll();\n+\t\t\t}\n+\t\t\tif (isFinishResult(udtfResult)) {\n+\t\t\t\tinput = forwardedInputQueue.poll();\n+\t\t\t}\n+\t\t\tif (input != null && !isFinishResult(udtfResult)) {\n+\t\t\t\tcRowWrapper.setChange(input.change());\n+\t\t\t\tcRowWrapper.collect(Row.join(input.row(), udtfResult));\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void bufferInput(CRow input) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a2f0e14c373b5fb8aa56ec8371899e549e8859fa"}, "originalPosition": 85}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyNDMwMzMxOnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/table/runtime/operators/python/PythonTableFunctionOperator.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxMjoxOTo0NFrOFmZJ6Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxMjoxOTo0NFrOFmZJ6Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTgwMjM0NQ==", "bodyText": "This class is copied from PythonScalarFunctionOperator. I think we can do some code reuse.", "url": "https://github.com/apache/flink/pull/11020#discussion_r375802345", "createdAt": "2020-02-06T12:19:44Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/table/runtime/operators/python/PythonTableFunctionOperator.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.operators.python;\n+\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.python.PythonFunctionRunner;\n+import org.apache.flink.python.env.PythonEnvironmentManager;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.table.functions.TableFunction;\n+import org.apache.flink.table.functions.python.PythonFunctionInfo;\n+import org.apache.flink.table.runtime.runners.python.PythonTableFunctionRunner;\n+import org.apache.flink.table.runtime.types.CRow;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.types.Row;\n+import org.apache.flink.util.Collector;\n+\n+import org.apache.beam.sdk.fn.data.FnDataReceiver;\n+\n+/**\n+ * The Python {@link TableFunction} operator for the legacy planner.\n+ */\n+public class PythonTableFunctionOperator extends AbstractPythonTableFunctionOperator<CRow, CRow, Row, Row> {\n+\n+\tprivate static final long serialVersionUID = 1L;\n+\n+\t/**\n+\t * The collector used to collect records.\n+\t */\n+\tprivate transient StreamRecordCRowWrappingCollector cRowWrapper;\n+\n+\tpublic PythonTableFunctionOperator(\n+\t\tConfiguration config,\n+\t\tPythonFunctionInfo tableFunction,\n+\t\tRowType inputType,\n+\t\tRowType outputType,\n+\t\tint[] udtfInputOffsets) {\n+\t\tsuper(config, tableFunction, inputType, outputType, udtfInputOffsets);\n+\t}\n+\n+\t@Override\n+\tpublic void open() throws Exception {\n+\t\tsuper.open();\n+\t\tthis.cRowWrapper = new StreamRecordCRowWrappingCollector(output);\n+\t}\n+\n+\tprivate boolean isFinishResult(Row result) {\n+\t\treturn result.getArity() == 0;\n+\t}\n+\n+\t@Override\n+\tpublic void emitResults() {\n+\t\tRow udtfResult;\n+\t\tCRow input = null;\n+\t\twhile ((udtfResult = udtfResultQueue.poll()) != null) {\n+\t\t\tif (input == null) {\n+\t\t\t\tinput = forwardedInputQueue.poll();\n+\t\t\t}\n+\t\t\tif (isFinishResult(udtfResult)) {\n+\t\t\t\tinput = forwardedInputQueue.poll();\n+\t\t\t}\n+\t\t\tif (input != null && !isFinishResult(udtfResult)) {\n+\t\t\t\tcRowWrapper.setChange(input.change());\n+\t\t\t\tcRowWrapper.collect(Row.join(input.row(), udtfResult));\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void bufferInput(CRow input) {\n+\t\tforwardedInputQueue.add(input);\n+\t}\n+\n+\t@Override\n+\tpublic Row getUdtfInput(CRow element) {\n+\t\treturn Row.project(element.row(), udtfInputOffsets);\n+\t}\n+\n+\t@Override\n+\tpublic PythonFunctionRunner<Row> createPythonFunctionRunner(\n+\t\tFnDataReceiver<Row> resultReceiver,\n+\t\tPythonEnvironmentManager pythonEnvironmentManager) {\n+\t\treturn new PythonTableFunctionRunner(\n+\t\t\tgetRuntimeContext().getTaskName(),\n+\t\t\tresultReceiver,\n+\t\t\ttableFunction,\n+\t\t\tpythonEnvironmentManager,\n+\t\t\tudtfInputType,\n+\t\t\tudtfOutputType);\n+\t}\n+\n+\t/**\n+\t * The collector is used to convert a {@link Row} to a {@link CRow}.\n+\t */\n+\tprivate static class StreamRecordCRowWrappingCollector implements Collector<Row> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a2f0e14c373b5fb8aa56ec8371899e549e8859fa"}, "originalPosition": 110}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyNDMyMTk1OnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/table/runtime/operators/python/AbstractPythonTableFunctionOperator.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxMjoyNjo1N1rOFmZVXw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxMjoyNjo1N1rOFmZVXw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTgwNTI3OQ==", "bodyText": "Please try to avoid code deduplication. For example, we can add a StatelessFunctionOperator and put the same code in this class. What do you think?", "url": "https://github.com/apache/flink/pull/11020#discussion_r375805279", "createdAt": "2020-02-06T12:26:57Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/table/runtime/operators/python/AbstractPythonTableFunctionOperator.java", "diffHunk": "@@ -0,0 +1,189 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.operators.python;\n+\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.python.PythonFunctionRunner;\n+import org.apache.flink.python.env.PythonEnvironmentManager;\n+import org.apache.flink.streaming.api.operators.python.AbstractPythonFunctionOperator;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.table.functions.TableFunction;\n+import org.apache.flink.table.functions.python.PythonEnv;\n+import org.apache.flink.table.functions.python.PythonFunctionInfo;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.beam.sdk.fn.data.FnDataReceiver;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * @param <IN>      Type of the input elements.\n+ * @param <OUT>     Type of the output elements.\n+ * @param <UDTFIN>  Type of the UDF input type.\n+ * @param <UDTFOUT> Type of the UDF input type.\n+ */\n+public abstract class AbstractPythonTableFunctionOperator<IN, OUT, UDTFIN, UDTFOUT>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a2f0e14c373b5fb8aa56ec8371899e549e8859fa"}, "originalPosition": 46}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyNDMyNDk5OnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/table/runtime/operators/python/AbstractPythonTableFunctionOperator.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxMjoyODowOFrOFmZXSA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxMjoyODowOFrOFmZXSA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTgwNTc2OA==", "bodyText": "Add @Internal", "url": "https://github.com/apache/flink/pull/11020#discussion_r375805768", "createdAt": "2020-02-06T12:28:08Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/table/runtime/operators/python/AbstractPythonTableFunctionOperator.java", "diffHunk": "@@ -0,0 +1,189 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.operators.python;\n+\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.python.PythonFunctionRunner;\n+import org.apache.flink.python.env.PythonEnvironmentManager;\n+import org.apache.flink.streaming.api.operators.python.AbstractPythonFunctionOperator;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.table.functions.TableFunction;\n+import org.apache.flink.table.functions.python.PythonEnv;\n+import org.apache.flink.table.functions.python.PythonFunctionInfo;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.beam.sdk.fn.data.FnDataReceiver;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * @param <IN>      Type of the input elements.\n+ * @param <OUT>     Type of the output elements.\n+ * @param <UDTFIN>  Type of the UDF input type.\n+ * @param <UDTFOUT> Type of the UDF input type.\n+ */\n+public abstract class AbstractPythonTableFunctionOperator<IN, OUT, UDTFIN, UDTFOUT>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a2f0e14c373b5fb8aa56ec8371899e549e8859fa"}, "originalPosition": 46}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyNDMyNzI3OnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/table/runtime/operators/python/PythonTableFunctionOperator.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxMjoyODo1MVrOFmZYmw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxMjoyODo1MVrOFmZYmw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTgwNjEwNw==", "bodyText": "Add @Internal", "url": "https://github.com/apache/flink/pull/11020#discussion_r375806107", "createdAt": "2020-02-06T12:28:51Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/table/runtime/operators/python/PythonTableFunctionOperator.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.operators.python;\n+\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.python.PythonFunctionRunner;\n+import org.apache.flink.python.env.PythonEnvironmentManager;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.table.functions.TableFunction;\n+import org.apache.flink.table.functions.python.PythonFunctionInfo;\n+import org.apache.flink.table.runtime.runners.python.PythonTableFunctionRunner;\n+import org.apache.flink.table.runtime.types.CRow;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.types.Row;\n+import org.apache.flink.util.Collector;\n+\n+import org.apache.beam.sdk.fn.data.FnDataReceiver;\n+\n+/**\n+ * The Python {@link TableFunction} operator for the legacy planner.\n+ */\n+public class PythonTableFunctionOperator extends AbstractPythonTableFunctionOperator<CRow, CRow, Row, Row> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a2f0e14c373b5fb8aa56ec8371899e549e8859fa"}, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyNDMyODQ0OnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/table/runtime/runners/python/AbstractPythonTableFunctionRunner.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxMjoyOToxNlrOFmZZNw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxMjoyOToxNlrOFmZZNw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTgwNjI2Mw==", "bodyText": "Add @Internal", "url": "https://github.com/apache/flink/pull/11020#discussion_r375806263", "createdAt": "2020-02-06T12:29:16Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/table/runtime/runners/python/AbstractPythonTableFunctionRunner.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.runners.python;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.fnexecution.v1.FlinkFnApi;\n+import org.apache.flink.python.PythonFunctionRunner;\n+import org.apache.flink.python.env.PythonEnvironmentManager;\n+import org.apache.flink.table.functions.TableFunction;\n+import org.apache.flink.table.functions.python.PythonFunctionInfo;\n+import org.apache.flink.table.runtime.typeutils.PythonTypeUtils;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+import org.apache.beam.sdk.fn.data.FnDataReceiver;\n+\n+/**\n+ * Abstract {@link PythonFunctionRunner} used to execute Python {@link TableFunction}.\n+ *\n+ * @param <IN>  Type of the input elements.\n+ * @param <OUT> Type of the execution results.\n+ */\n+public abstract class AbstractPythonTableFunctionRunner<IN, OUT> extends AbstractPythonStatelessFunctionRunner<IN, OUT> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a2f0e14c373b5fb8aa56ec8371899e549e8859fa"}, "originalPosition": 40}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyNzkxNTk0OnYy", "diffSide": "RIGHT", "path": "flink-python/pyflink/proto/flink-fn-execution.proto", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QxMjozNDowM1rOFm7q5A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QxMjozNDowM1rOFm7q5A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjM2Nzg0NA==", "bodyText": "TABLE_FUNCTION_ROW ?", "url": "https://github.com/apache/flink/pull/11020#discussion_r376367844", "createdAt": "2020-02-07T12:34:03Z", "author": {"login": "hequn8128"}, "path": "flink-python/pyflink/proto/flink-fn-execution.proto", "diffHunk": "@@ -73,6 +73,7 @@ message Schema {\n     ARRAY = 16;\n     MAP = 17;\n     MULTISET = 18;\n+    TABLEFUNCTIONROW = 19;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2ea6049aa8c495dda6b78395435170fa0c56b8c"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyNzk1OTA3OnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/table/runtime/operators/python/AbstractPythonTableFunctionOperator.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QxMjo1MjoyMlrOFm8FDQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QxMjo1MjoyMlrOFm8FDQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjM3NDU0MQ==", "bodyText": "when it is a byte 0x00 => when it is a byte with value 0x00", "url": "https://github.com/apache/flink/pull/11020#discussion_r376374541", "createdAt": "2020-02-07T12:52:22Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/table/runtime/operators/python/AbstractPythonTableFunctionOperator.java", "diffHunk": "@@ -0,0 +1,77 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.operators.python;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.table.functions.TableFunction;\n+import org.apache.flink.table.functions.python.PythonEnv;\n+import org.apache.flink.table.functions.python.PythonFunctionInfo;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.util.Preconditions;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+/**\n+ * @param <IN>     Type of the input elements.\n+ * @param <OUT>    Type of the output elements.\n+ * @param <UDTFIN> Type of the UDTF input type.\n+ */\n+@Internal\n+public abstract class AbstractPythonTableFunctionOperator<IN, OUT, UDTFIN>\n+\textends AbstractStatelessFunctionOperator<IN, OUT, UDTFIN> {\n+\n+\tprivate static final long serialVersionUID = 1L;\n+\n+\t/**\n+\t * The Python {@link TableFunction} to be executed.\n+\t */\n+\tprotected final PythonFunctionInfo tableFunction;\n+\n+\tpublic AbstractPythonTableFunctionOperator(\n+\t\tConfiguration config,\n+\t\tPythonFunctionInfo tableFunction,\n+\t\tRowType inputType,\n+\t\tRowType outputType,\n+\t\tint[] udtfInputOffsets) {\n+\t\tsuper(config, inputType, outputType, udtfInputOffsets);\n+\t\tthis.tableFunction = Preconditions.checkNotNull(tableFunction);\n+\t}\n+\n+\t@Override\n+\tpublic void open() throws Exception {\n+\t\tList<RowType.RowField> udtfOutputDataFields = new ArrayList<>(\n+\t\t\toutputType.getFields().subList(inputType.getFieldCount(), outputType.getFieldCount()));\n+\t\tudfOutputType = new RowType(udtfOutputDataFields);\n+\t\tsuper.open();\n+\t}\n+\n+\t@Override\n+\tpublic PythonEnv getPythonEnv() {\n+\t\treturn tableFunction.getPythonFunction().getPythonEnv();\n+\t}\n+\n+\t/**\n+\t * The received udtf execution result is a finish message when it is a byte 0x00.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2ea6049aa8c495dda6b78395435170fa0c56b8c"}, "originalPosition": 72}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyNzk4ODYyOnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/table/runtime/operators/python/AbstractStatelessFunctionOperator.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QxMzowNDo1MVrOFm8XSg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QxMzowNDo1MVrOFm8XSg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjM3OTIxMA==", "bodyText": "user-defined table function => user-defined function", "url": "https://github.com/apache/flink/pull/11020#discussion_r376379210", "createdAt": "2020-02-07T13:04:51Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/table/runtime/operators/python/AbstractStatelessFunctionOperator.java", "diffHunk": "@@ -0,0 +1,251 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.operators.python;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.core.memory.ByteArrayInputStreamWithPos;\n+import org.apache.flink.core.memory.DataInputViewStreamWrapper;\n+import org.apache.flink.python.PythonFunctionRunner;\n+import org.apache.flink.python.env.PythonEnvironmentManager;\n+import org.apache.flink.streaming.api.operators.python.AbstractPythonFunctionOperator;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.table.dataformat.BaseRow;\n+import org.apache.flink.table.runtime.types.CRow;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.types.Row;\n+import org.apache.flink.util.Collector;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.beam.sdk.fn.data.FnDataReceiver;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Base class for all stream operators to execute Python Stateless Functions.\n+ *\n+ * @param <IN>    Type of the input elements.\n+ * @param <OUT>   Type of the output elements.\n+ * @param <UDFIN> Type of the UDF input type.\n+ */\n+@Internal\n+public abstract class AbstractStatelessFunctionOperator<IN, OUT, UDFIN>\n+\textends AbstractPythonFunctionOperator<IN, OUT> {\n+\n+\tprivate static final long serialVersionUID = 1L;\n+\n+\t/**\n+\t * The input logical type.\n+\t */\n+\tprotected final RowType inputType;\n+\n+\t/**\n+\t * The output logical type.\n+\t */\n+\tprotected final RowType outputType;\n+\n+\t/**\n+\t * The offsets of udf inputs.\n+\t */\n+\tprotected final int[] udfInputOffsets;\n+\n+\t/**\n+\t * The udf input logical type.\n+\t */\n+\tprotected transient RowType udfInputType;\n+\n+\t/**\n+\t * The udf output logical type.\n+\t */\n+\tprotected transient RowType udfOutputType;\n+\n+\t/**\n+\t * The queue holding the input elements for which the execution results have not been received.\n+\t */\n+\tprotected transient LinkedBlockingQueue<IN> forwardedInputQueue;\n+\n+\t/**\n+\t * The queue holding the user-defined table function execution results. The execution results", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2ea6049aa8c495dda6b78395435170fa0c56b8c"}, "originalPosition": 87}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyNzk5ODY1OnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/table/runtime/operators/python/AbstractStatelessFunctionOperator.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QxMzowOToyNlrOFm8diw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QxMzowOToyNlrOFm8diw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjM4MDgxMQ==", "bodyText": "How about rename udfOutputType to functionOutputType or userDefinedFunctionOutputType? It seems strange to see the udfOutputType variable in AbstractPythonTableFunctionOperator.\nSame for other variable names.", "url": "https://github.com/apache/flink/pull/11020#discussion_r376380811", "createdAt": "2020-02-07T13:09:26Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/table/runtime/operators/python/AbstractStatelessFunctionOperator.java", "diffHunk": "@@ -0,0 +1,251 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.operators.python;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.core.memory.ByteArrayInputStreamWithPos;\n+import org.apache.flink.core.memory.DataInputViewStreamWrapper;\n+import org.apache.flink.python.PythonFunctionRunner;\n+import org.apache.flink.python.env.PythonEnvironmentManager;\n+import org.apache.flink.streaming.api.operators.python.AbstractPythonFunctionOperator;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.table.dataformat.BaseRow;\n+import org.apache.flink.table.runtime.types.CRow;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.types.Row;\n+import org.apache.flink.util.Collector;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.beam.sdk.fn.data.FnDataReceiver;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Base class for all stream operators to execute Python Stateless Functions.\n+ *\n+ * @param <IN>    Type of the input elements.\n+ * @param <OUT>   Type of the output elements.\n+ * @param <UDFIN> Type of the UDF input type.\n+ */\n+@Internal\n+public abstract class AbstractStatelessFunctionOperator<IN, OUT, UDFIN>\n+\textends AbstractPythonFunctionOperator<IN, OUT> {\n+\n+\tprivate static final long serialVersionUID = 1L;\n+\n+\t/**\n+\t * The input logical type.\n+\t */\n+\tprotected final RowType inputType;\n+\n+\t/**\n+\t * The output logical type.\n+\t */\n+\tprotected final RowType outputType;\n+\n+\t/**\n+\t * The offsets of udf inputs.\n+\t */\n+\tprotected final int[] udfInputOffsets;\n+\n+\t/**\n+\t * The udf input logical type.\n+\t */\n+\tprotected transient RowType udfInputType;\n+\n+\t/**\n+\t * The udf output logical type.\n+\t */\n+\tprotected transient RowType udfOutputType;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2ea6049aa8c495dda6b78395435170fa0c56b8c"}, "originalPosition": 79}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyODAwNTg5OnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/table/runtime/operators/python/PythonTableFunctionOperator.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QxMzoxMjozOVrOFm8iKA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QxMzoxMjozOVrOFm8iKA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjM4MTk5Mg==", "bodyText": "udf => udtf", "url": "https://github.com/apache/flink/pull/11020#discussion_r376381992", "createdAt": "2020-02-07T13:12:39Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/table/runtime/operators/python/PythonTableFunctionOperator.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.operators.python;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.java.typeutils.RowTypeInfo;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.python.PythonFunctionRunner;\n+import org.apache.flink.python.env.PythonEnvironmentManager;\n+import org.apache.flink.table.functions.TableFunction;\n+import org.apache.flink.table.functions.python.PythonFunctionInfo;\n+import org.apache.flink.table.runtime.runners.python.PythonTableFunctionRunner;\n+import org.apache.flink.table.runtime.types.CRow;\n+import org.apache.flink.table.runtime.types.CRowTypeInfo;\n+import org.apache.flink.table.runtime.typeutils.PythonTypeUtils;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.table.types.utils.TypeConversions;\n+import org.apache.flink.types.Row;\n+\n+import org.apache.beam.sdk.fn.data.FnDataReceiver;\n+\n+import java.io.IOException;\n+\n+/**\n+ * The Python {@link TableFunction} operator for the legacy planner.\n+ */\n+@Internal\n+public class PythonTableFunctionOperator extends AbstractPythonTableFunctionOperator<CRow, CRow, Row> {\n+\n+\tprivate static final long serialVersionUID = 1L;\n+\n+\t/**\n+\t * The collector used to collect records.\n+\t */\n+\tprivate transient StreamRecordCRowWrappingCollector cRowWrapper;\n+\n+\t/**\n+\t * The type serializer for the forwarded fields.\n+\t */\n+\tprivate transient TypeSerializer<CRow> forwardedInputSerializer;\n+\n+\t/**\n+\t * The TypeSerializer for udf execution results.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2ea6049aa8c495dda6b78395435170fa0c56b8c"}, "originalPosition": 60}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyODAwODc2OnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/table/runtime/operators/python/PythonTableFunctionOperator.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QxMzoxMzo0NlrOFm8j6A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QxMzoxMzo0NlrOFm8j6A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjM4MjQ0MA==", "bodyText": "Remove the blank after =", "url": "https://github.com/apache/flink/pull/11020#discussion_r376382440", "createdAt": "2020-02-07T13:13:46Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/table/runtime/operators/python/PythonTableFunctionOperator.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.operators.python;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.java.typeutils.RowTypeInfo;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.python.PythonFunctionRunner;\n+import org.apache.flink.python.env.PythonEnvironmentManager;\n+import org.apache.flink.table.functions.TableFunction;\n+import org.apache.flink.table.functions.python.PythonFunctionInfo;\n+import org.apache.flink.table.runtime.runners.python.PythonTableFunctionRunner;\n+import org.apache.flink.table.runtime.types.CRow;\n+import org.apache.flink.table.runtime.types.CRowTypeInfo;\n+import org.apache.flink.table.runtime.typeutils.PythonTypeUtils;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.table.types.utils.TypeConversions;\n+import org.apache.flink.types.Row;\n+\n+import org.apache.beam.sdk.fn.data.FnDataReceiver;\n+\n+import java.io.IOException;\n+\n+/**\n+ * The Python {@link TableFunction} operator for the legacy planner.\n+ */\n+@Internal\n+public class PythonTableFunctionOperator extends AbstractPythonTableFunctionOperator<CRow, CRow, Row> {\n+\n+\tprivate static final long serialVersionUID = 1L;\n+\n+\t/**\n+\t * The collector used to collect records.\n+\t */\n+\tprivate transient StreamRecordCRowWrappingCollector cRowWrapper;\n+\n+\t/**\n+\t * The type serializer for the forwarded fields.\n+\t */\n+\tprivate transient TypeSerializer<CRow> forwardedInputSerializer;\n+\n+\t/**\n+\t * The TypeSerializer for udf execution results.\n+\t */\n+\tprivate transient TypeSerializer<Row> udtfOutputTypeSerializer;\n+\n+\tpublic PythonTableFunctionOperator(\n+\t\tConfiguration config,\n+\t\tPythonFunctionInfo tableFunction,\n+\t\tRowType inputType,\n+\t\tRowType outputType,\n+\t\tint[] udtfInputOffsets) {\n+\t\tsuper(config, tableFunction, inputType, outputType, udtfInputOffsets);\n+\t}\n+\n+\t@Override\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic void open() throws Exception {\n+\t\tsuper.open();\n+\t\tthis.cRowWrapper = new StreamRecordCRowWrappingCollector(output);\n+\t\tCRowTypeInfo forwardedInputTypeInfo = new CRowTypeInfo(\n+\t\t\tnew RowTypeInfo(TypeConversions.fromDataTypeToLegacyInfo(\n+\t\t\t\tTypeConversions.fromLogicalToDataType(inputType))));\n+\t\tforwardedInputSerializer = forwardedInputTypeInfo.createSerializer(getExecutionConfig());\n+\t\tudtfOutputTypeSerializer = PythonTypeUtils.toFlinkTypeSerializer(udfOutputType);\n+\t}\n+\n+\t@Override\n+\tpublic void emitResults() throws IOException {\n+\t\tCRow input = null;\n+\t\tbyte[] rawUdtfResult;\n+\t\twhile ((rawUdtfResult = udfResultQueue.poll()) != null) {\n+\t\t\tif (input == null) {\n+\t\t\t\tinput = forwardedInputQueue.poll();\n+\t\t\t}\n+\t\t\tboolean isFinishResult = isFinishResult(rawUdtfResult);\n+\t\t\tif (isFinishResult) {\n+\t\t\t\tinput = forwardedInputQueue.poll();\n+\t\t\t}\n+\t\t\tif (input != null && !isFinishResult) {\n+\t\t\t\tbais.setBuffer(rawUdtfResult, 0, rawUdtfResult.length);\n+\t\t\t\tRow udtfResult = udtfOutputTypeSerializer.deserialize(baisWrapper);\n+\t\t\t\tcRowWrapper.setChange(input.change());\n+\t\t\t\tcRowWrapper.collect(Row.join(input.row(), udtfResult));\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void bufferInput(CRow input) {\n+\t\tif (getExecutionConfig().isObjectReuseEnabled()) {\n+\t\t\tinput =  forwardedInputSerializer.copy(input);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2ea6049aa8c495dda6b78395435170fa0c56b8c"}, "originalPosition": 109}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1025, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}