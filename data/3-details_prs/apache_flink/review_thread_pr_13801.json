{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTEwNDQ1MjA4", "number": 13801, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQwMjoyNjo1NlrOEyn9SA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQwMjozOTo1MVrOEyoGXQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxNTE4OTIwOnYy", "diffSide": "RIGHT", "path": "docs/dev/table/connectors/formats/avro-confluent.zh.md", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQwMjoyNjo1NlrOHpXsCg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQwMjoyNjo1NlrOHpXsCg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzE0MTc3MA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            [Apache Avro Format]({% link dev/table/connectors/formats/avro.zh.md%}#data-type-mapping)\u4e2d\u63cf\u8ff0\u4e86flink\u6570\u636e\u548cAvro\u6570\u636e\u7684\u5bf9\u5e94\u5173\u7cfb\u3002 \n          \n          \n            \n            [Apache Avro Format]({% link dev/table/connectors/formats/avro.zh.md%}#data-type-mapping)\u4e2d\u63cf\u8ff0\u4e86 Flink \u6570\u636e\u7c7b\u578b\u548c Avro \u7c7b\u578b\u7684\u5bf9\u5e94\u5173\u7cfb\u3002", "url": "https://github.com/apache/flink/pull/13801#discussion_r513141770", "createdAt": "2020-10-28T02:26:56Z", "author": {"login": "wuchong"}, "path": "docs/dev/table/connectors/formats/avro-confluent.zh.md", "diffHunk": "@@ -72,50 +72,50 @@ CREATE TABLE user_behavior (\n </div>\n </div>\n \n-Format Options\n+Format \u53c2\u6570\n ----------------\n \n <table class=\"table table-bordered\">\n     <thead>\n       <tr>\n-        <th class=\"text-left\" style=\"width: 25%\">Option</th>\n-        <th class=\"text-center\" style=\"width: 8%\">Required</th>\n-        <th class=\"text-center\" style=\"width: 7%\">Default</th>\n-        <th class=\"text-center\" style=\"width: 10%\">Type</th>\n-        <th class=\"text-center\" style=\"width: 50%\">Description</th>\n+        <th class=\"text-left\" style=\"width: 25%\">\u53c2\u6570</th>\n+        <th class=\"text-center\" style=\"width: 8%\">\u662f\u5426\u5fc5\u9009</th>\n+        <th class=\"text-center\" style=\"width: 7%\">\u9ed8\u8ba4\u503c</th>\n+        <th class=\"text-center\" style=\"width: 10%\">\u7c7b\u578b</th>\n+        <th class=\"text-center\" style=\"width: 50%\">\u63cf\u8ff0</th>\n       </tr>\n     </thead>\n     <tbody>\n     <tr>\n       <td><h5>format</h5></td>\n-      <td>required</td>\n+      <td>\u5fc5\u9009</td>\n       <td style=\"word-wrap: break-word;\">(none)</td>\n       <td>String</td>\n-      <td>Specify what format to use, here should be <code>'avro-confluent'</code>.</td>\n+      <td>\u6307\u5b9a\u8981\u4f7f\u7528\u7684\u683c\u5f0f\uff0c\u8fd9\u91cc\u5e94\u8be5\u662f <code>'avro-confluent'</code>.</td>\n     </tr>\n     <tr>\n       <td><h5>avro-confluent.schema-registry.url</h5></td>\n-      <td>required</td>\n+      <td>\u5fc5\u9009</td>\n       <td style=\"word-wrap: break-word;\">(none)</td>\n       <td>String</td>\n-      <td>The URL of the Confluent Schema Registry to fetch/register schemas</td>\n+      <td>\u7528\u4e8e\u83b7\u53d6/\u6ce8\u518c schemas \u7684 Confluent Schema Registry \u7684URL </td>\n     </tr>\n     <tr>\n       <td><h5>avro-confluent.schema-registry.subject</h5></td>\n-      <td>required by sink</td>\n+      <td>sink \u5fc5\u9009</td>\n       <td style=\"word-wrap: break-word;\">(none)</td>\n       <td>String</td>\n-      <td>The Confluent Schema Registry subject under which to register the schema used by this format during serialization</td>\n+      <td>Confluent Schema Registry\u4e3b\u9898\uff0c\u7528\u4e8e\u5728\u5e8f\u5217\u5316\u671f\u95f4\u6ce8\u518c\u6b64\u683c\u5f0f\u4f7f\u7528\u7684 schema </td>\n     </tr>\n     </tbody>\n </table>\n \n-Data Type Mapping\n+\u6570\u636e\u7c7b\u578b\u6620\u5c04\n ----------------\n \n-Currently, Apache Flink always uses the table schema to derive the Avro reader schema during deserialization and Avro writer schema during serialization. Explicitly defining an Avro schema is not supported yet.\n-See the [Apache Avro Format]({% link dev/table/connectors/formats/avro.zh.md%}#data-type-mapping) for the mapping between Avro and Flink DataTypes. \n+\u76ee\u524d Apache Flink \u90fd\u662f\u4ece table schema \u53bb\u63a8\u65ad\u53cd\u5e8f\u5217\u5316\u671f\u95f4\u7684 Avro reader schema \u548c\u5e8f\u5217\u5316\u671f\u95f4\u7684 Avro writer schema\u3002\u663e\u5f0f\u5730\u5b9a\u4e49 Avro schema \u6682\u4e0d\u652f\u6301\u3002\n+[Apache Avro Format]({% link dev/table/connectors/formats/avro.zh.md%}#data-type-mapping)\u4e2d\u63cf\u8ff0\u4e86flink\u6570\u636e\u548cAvro\u6570\u636e\u7684\u5bf9\u5e94\u5173\u7cfb\u3002 ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4d511a01a26b4a0ad0ea7423887cdd37d163a0e7"}, "originalPosition": 99}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxNTE5MDMxOnYy", "diffSide": "RIGHT", "path": "docs/dev/table/connectors/formats/avro-confluent.zh.md", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQwMjoyNzozM1rOHpXsqg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQwMjoyNzozM1rOHpXsqg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzE0MTkzMA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \u9664\u4e86\u6b64\u5904\u5217\u51fa\u7684\u7c7b\u578b\u4e4b\u5916\uff0cFlink \u8fd8\u652f\u6301\u8bfb\u53d6/\u5199\u5165\u53ef\u4e3a\u7a7a\u7684\u7c7b\u578b\u3002 Flink \u5c06\u53ef\u4e3a\u7a7a\u7684\u7c7b\u578b\u6620\u5c04\u5230 Avro `union(something, null)`, \u5176\u4e2d `something` \u662f\u4ece Flink \u7c7b\u578b\u8f6c\u6362\u7684 Avro \u7c7b\u578b\u3002\n          \n          \n            \n            \u9664\u4e86\u6b64\u5904\u5217\u51fa\u7684\u7c7b\u578b\u4e4b\u5916\uff0cFlink \u8fd8\u652f\u6301\u8bfb\u53d6/\u5199\u5165\u53ef\u4e3a\u7a7a\uff08nullable\uff09\u7684\u7c7b\u578b\u3002 Flink \u5c06\u53ef\u4e3a\u7a7a\u7684\u7c7b\u578b\u6620\u5c04\u5230 Avro `union(something, null)`, \u5176\u4e2d `something` \u662f\u4ece Flink \u7c7b\u578b\u8f6c\u6362\u7684 Avro \u7c7b\u578b\u3002", "url": "https://github.com/apache/flink/pull/13801#discussion_r513141930", "createdAt": "2020-10-28T02:27:33Z", "author": {"login": "wuchong"}, "path": "docs/dev/table/connectors/formats/avro-confluent.zh.md", "diffHunk": "@@ -72,50 +72,50 @@ CREATE TABLE user_behavior (\n </div>\n </div>\n \n-Format Options\n+Format \u53c2\u6570\n ----------------\n \n <table class=\"table table-bordered\">\n     <thead>\n       <tr>\n-        <th class=\"text-left\" style=\"width: 25%\">Option</th>\n-        <th class=\"text-center\" style=\"width: 8%\">Required</th>\n-        <th class=\"text-center\" style=\"width: 7%\">Default</th>\n-        <th class=\"text-center\" style=\"width: 10%\">Type</th>\n-        <th class=\"text-center\" style=\"width: 50%\">Description</th>\n+        <th class=\"text-left\" style=\"width: 25%\">\u53c2\u6570</th>\n+        <th class=\"text-center\" style=\"width: 8%\">\u662f\u5426\u5fc5\u9009</th>\n+        <th class=\"text-center\" style=\"width: 7%\">\u9ed8\u8ba4\u503c</th>\n+        <th class=\"text-center\" style=\"width: 10%\">\u7c7b\u578b</th>\n+        <th class=\"text-center\" style=\"width: 50%\">\u63cf\u8ff0</th>\n       </tr>\n     </thead>\n     <tbody>\n     <tr>\n       <td><h5>format</h5></td>\n-      <td>required</td>\n+      <td>\u5fc5\u9009</td>\n       <td style=\"word-wrap: break-word;\">(none)</td>\n       <td>String</td>\n-      <td>Specify what format to use, here should be <code>'avro-confluent'</code>.</td>\n+      <td>\u6307\u5b9a\u8981\u4f7f\u7528\u7684\u683c\u5f0f\uff0c\u8fd9\u91cc\u5e94\u8be5\u662f <code>'avro-confluent'</code>.</td>\n     </tr>\n     <tr>\n       <td><h5>avro-confluent.schema-registry.url</h5></td>\n-      <td>required</td>\n+      <td>\u5fc5\u9009</td>\n       <td style=\"word-wrap: break-word;\">(none)</td>\n       <td>String</td>\n-      <td>The URL of the Confluent Schema Registry to fetch/register schemas</td>\n+      <td>\u7528\u4e8e\u83b7\u53d6/\u6ce8\u518c schemas \u7684 Confluent Schema Registry \u7684URL </td>\n     </tr>\n     <tr>\n       <td><h5>avro-confluent.schema-registry.subject</h5></td>\n-      <td>required by sink</td>\n+      <td>sink \u5fc5\u9009</td>\n       <td style=\"word-wrap: break-word;\">(none)</td>\n       <td>String</td>\n-      <td>The Confluent Schema Registry subject under which to register the schema used by this format during serialization</td>\n+      <td>Confluent Schema Registry\u4e3b\u9898\uff0c\u7528\u4e8e\u5728\u5e8f\u5217\u5316\u671f\u95f4\u6ce8\u518c\u6b64\u683c\u5f0f\u4f7f\u7528\u7684 schema </td>\n     </tr>\n     </tbody>\n </table>\n \n-Data Type Mapping\n+\u6570\u636e\u7c7b\u578b\u6620\u5c04\n ----------------\n \n-Currently, Apache Flink always uses the table schema to derive the Avro reader schema during deserialization and Avro writer schema during serialization. Explicitly defining an Avro schema is not supported yet.\n-See the [Apache Avro Format]({% link dev/table/connectors/formats/avro.zh.md%}#data-type-mapping) for the mapping between Avro and Flink DataTypes. \n+\u76ee\u524d Apache Flink \u90fd\u662f\u4ece table schema \u53bb\u63a8\u65ad\u53cd\u5e8f\u5217\u5316\u671f\u95f4\u7684 Avro reader schema \u548c\u5e8f\u5217\u5316\u671f\u95f4\u7684 Avro writer schema\u3002\u663e\u5f0f\u5730\u5b9a\u4e49 Avro schema \u6682\u4e0d\u652f\u6301\u3002\n+[Apache Avro Format]({% link dev/table/connectors/formats/avro.zh.md%}#data-type-mapping)\u4e2d\u63cf\u8ff0\u4e86flink\u6570\u636e\u548cAvro\u6570\u636e\u7684\u5bf9\u5e94\u5173\u7cfb\u3002 \n \n-In addition to the types listed there, Flink supports reading/writing nullable types. Flink maps nullable types to Avro `union(something, null)`, where `something` is the Avro type converted from Flink type.\n+\u9664\u4e86\u6b64\u5904\u5217\u51fa\u7684\u7c7b\u578b\u4e4b\u5916\uff0cFlink \u8fd8\u652f\u6301\u8bfb\u53d6/\u5199\u5165\u53ef\u4e3a\u7a7a\u7684\u7c7b\u578b\u3002 Flink \u5c06\u53ef\u4e3a\u7a7a\u7684\u7c7b\u578b\u6620\u5c04\u5230 Avro `union(something, null)`, \u5176\u4e2d `something` \u662f\u4ece Flink \u7c7b\u578b\u8f6c\u6362\u7684 Avro \u7c7b\u578b\u3002", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4d511a01a26b4a0ad0ea7423887cdd37d163a0e7"}, "originalPosition": 102}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxNTE5NTcyOnYy", "diffSide": "RIGHT", "path": "docs/dev/table/connectors/formats/avro-confluent.zh.md", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQwMjozMDoyNVrOHpXv4A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQwMjozMDoyNVrOHpXv4A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzE0Mjc1Mg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Avro Schema Registry (``avro-confluent``) \u683c\u5f0f\u80fd\u8ba9\u4f60\u8bfb\u53d6\u88ab ``io.confluent.kafka.serializers.KafkaAvroSerializer``\u5e8f\u5217\u5316\u7684\u8bb0\u5f55\u5e76\u53ef\u4ee5\u5199\u5165\u6210 ``io.confluent.kafka.serializers.KafkaAvroDeserializer``\u53cd\u5e8f\u5217\u5316\u7684\u8bb0\u5f55\u3002\n          \n          \n            \n            Avro Schema Registry (``avro-confluent``) \u683c\u5f0f\u80fd\u8ba9\u4f60\u8bfb\u53d6\u88ab ``io.confluent.kafka.serializers.KafkaAvroSerializer``\u5e8f\u5217\u5316\u7684\u8bb0\u5f55\uff0c\u4ee5\u53ca\u53ef\u4ee5\u5199\u5165\u6210\u80fd\u88ab ``io.confluent.kafka.serializers.KafkaAvroDeserializer``\u53cd\u5e8f\u5217\u5316\u7684\u8bb0\u5f55\u3002", "url": "https://github.com/apache/flink/pull/13801#discussion_r513142752", "createdAt": "2020-10-28T02:30:25Z", "author": {"login": "wuchong"}, "path": "docs/dev/table/connectors/formats/avro-confluent.zh.md", "diffHunk": "@@ -29,27 +29,27 @@ under the License.\n * This will be replaced by the TOC\n {:toc}\n \n-The Avro Schema Registry (``avro-confluent``) format allows you to read records that were serialized by the ``io.confluent.kafka.serializers.KafkaAvroSerializer`` and to write records that can in turn be read by the ``io.confluent.kafka.serializers.KafkaAvroDeserializer``. \n+Avro Schema Registry (``avro-confluent``) \u683c\u5f0f\u80fd\u8ba9\u4f60\u8bfb\u53d6\u88ab ``io.confluent.kafka.serializers.KafkaAvroSerializer``\u5e8f\u5217\u5316\u7684\u8bb0\u5f55\u5e76\u53ef\u4ee5\u5199\u5165\u6210 ``io.confluent.kafka.serializers.KafkaAvroDeserializer``\u53cd\u5e8f\u5217\u5316\u7684\u8bb0\u5f55\u3002", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4d511a01a26b4a0ad0ea7423887cdd37d163a0e7"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxNTIxMjQ1OnYy", "diffSide": "RIGHT", "path": "docs/dev/table/connectors/formats/avro-confluent.zh.md", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQwMjozOTo1MVrOHpX5mQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQwMzoxODozMVrOHpYiYg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzE0NTI0MQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \u5f53\u4ee5\u8fd9\u79cd\u683c\u5f0f\u5199\u5165\uff08\u5e8f\u5217\u5316\uff09\u8bb0\u5f55\u65f6\uff0cAvro schema \u662f\u4ece table schema \u4e2d\u63a8\u65ad\u51fa\u6765\u7684\uff0c\u5e76\u7528\u4e8e\u68c0\u7d22\u8981\u4e0e\u6570\u636e\u4e00\u8d77\u7f16\u7801\u7684 schema id\u3002\u68c0\u7d22\u662f\u5728 Confluent Schema Registry \u914d\u7f6e\u4e2d\u7684 `avro-confluent.schema-registry.subject` \u4e2d\u6307\u5b9a\u7684[subject](https://docs.confluent.io/current/schema-registry/index.html#schemas-subjects-and-topics)\u4e0b\u6267\u884c\u7684\u3002\n          \n          \n            \n            \u5f53\u4ee5\u8fd9\u79cd\u683c\u5f0f\u5199\u5165\uff08\u5e8f\u5217\u5316\uff09\u8bb0\u5f55\u65f6\uff0cAvro schema \u662f\u4ece table schema \u4e2d\u63a8\u65ad\u51fa\u6765\u7684\uff0c\u5e76\u4f1a\u7528\u6765\u68c0\u7d22\u8981\u4e0e\u6570\u636e\u4e00\u8d77\u7f16\u7801\u7684 schema id\u3002\u6211\u4eec\u4f1a\u5728\u914d\u7f6e\u7684 Confluent Schema Registry \u4e2d\uff0c\u914d\u7f6e\u7684 [subject](https://docs.confluent.io/current/schema-registry/index.html#schemas-subjects-and-topics) \u4e0b\uff0c\u68c0\u7d22 schema id\u3002subject \u901a\u8fc7 `avro-confluent.schema-registry.subject` \u53c2\u6570\u6765\u5236\u5b9a\u3002", "url": "https://github.com/apache/flink/pull/13801#discussion_r513145241", "createdAt": "2020-10-28T02:39:51Z", "author": {"login": "wuchong"}, "path": "docs/dev/table/connectors/formats/avro-confluent.zh.md", "diffHunk": "@@ -29,27 +29,27 @@ under the License.\n * This will be replaced by the TOC\n {:toc}\n \n-The Avro Schema Registry (``avro-confluent``) format allows you to read records that were serialized by the ``io.confluent.kafka.serializers.KafkaAvroSerializer`` and to write records that can in turn be read by the ``io.confluent.kafka.serializers.KafkaAvroDeserializer``. \n+Avro Schema Registry (``avro-confluent``) \u683c\u5f0f\u80fd\u8ba9\u4f60\u8bfb\u53d6\u88ab ``io.confluent.kafka.serializers.KafkaAvroSerializer``\u5e8f\u5217\u5316\u7684\u8bb0\u5f55\u5e76\u53ef\u4ee5\u5199\u5165\u6210 ``io.confluent.kafka.serializers.KafkaAvroDeserializer``\u53cd\u5e8f\u5217\u5316\u7684\u8bb0\u5f55\u3002\n \n-When reading (deserializing) a record with this format the Avro writer schema is fetched from the configured Confluent Schema Registry based on the schema version id encoded in the record while the reader schema is inferred from table schema. \n+\u5f53\u4ee5\u8fd9\u79cd\u683c\u5f0f\u8bfb\u53d6\uff08\u53cd\u5e8f\u5217\u5316\uff09\u8bb0\u5f55\u65f6\uff0c\u5c06\u6839\u636e\u8bb0\u5f55\u4e2d\u7f16\u7801\u7684 schema \u7248\u672c id \u4ece\u914d\u7f6e\u7684 Confluent Schema Registry \u4e2d\u83b7\u53d6 Avro writer schema \uff0c\u800c\u4ece table schema \u4e2d\u63a8\u65ad\u51fa reader schema\u3002\n \n-When writing (serializing) a record with this format the Avro schema is inferred from the table schema and used to retrieve a schema id to be encoded with the data. The lookup is performed with in the configured Confluent Schema Registry under the [subject](https://docs.confluent.io/current/schema-registry/index.html#schemas-subjects-and-topics) given in `avro-confluent.schema-registry.subject`.\n+\u5f53\u4ee5\u8fd9\u79cd\u683c\u5f0f\u5199\u5165\uff08\u5e8f\u5217\u5316\uff09\u8bb0\u5f55\u65f6\uff0cAvro schema \u662f\u4ece table schema \u4e2d\u63a8\u65ad\u51fa\u6765\u7684\uff0c\u5e76\u7528\u4e8e\u68c0\u7d22\u8981\u4e0e\u6570\u636e\u4e00\u8d77\u7f16\u7801\u7684 schema id\u3002\u68c0\u7d22\u662f\u5728 Confluent Schema Registry \u914d\u7f6e\u4e2d\u7684 `avro-confluent.schema-registry.subject` \u4e2d\u6307\u5b9a\u7684[subject](https://docs.confluent.io/current/schema-registry/index.html#schemas-subjects-and-topics)\u4e0b\u6267\u884c\u7684\u3002", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4d511a01a26b4a0ad0ea7423887cdd37d163a0e7"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzE1NTY4Mg==", "bodyText": "thanks,i will update my code with your comments", "url": "https://github.com/apache/flink/pull/13801#discussion_r513155682", "createdAt": "2020-10-28T03:18:31Z", "author": {"login": "xiaoHoly"}, "path": "docs/dev/table/connectors/formats/avro-confluent.zh.md", "diffHunk": "@@ -29,27 +29,27 @@ under the License.\n * This will be replaced by the TOC\n {:toc}\n \n-The Avro Schema Registry (``avro-confluent``) format allows you to read records that were serialized by the ``io.confluent.kafka.serializers.KafkaAvroSerializer`` and to write records that can in turn be read by the ``io.confluent.kafka.serializers.KafkaAvroDeserializer``. \n+Avro Schema Registry (``avro-confluent``) \u683c\u5f0f\u80fd\u8ba9\u4f60\u8bfb\u53d6\u88ab ``io.confluent.kafka.serializers.KafkaAvroSerializer``\u5e8f\u5217\u5316\u7684\u8bb0\u5f55\u5e76\u53ef\u4ee5\u5199\u5165\u6210 ``io.confluent.kafka.serializers.KafkaAvroDeserializer``\u53cd\u5e8f\u5217\u5316\u7684\u8bb0\u5f55\u3002\n \n-When reading (deserializing) a record with this format the Avro writer schema is fetched from the configured Confluent Schema Registry based on the schema version id encoded in the record while the reader schema is inferred from table schema. \n+\u5f53\u4ee5\u8fd9\u79cd\u683c\u5f0f\u8bfb\u53d6\uff08\u53cd\u5e8f\u5217\u5316\uff09\u8bb0\u5f55\u65f6\uff0c\u5c06\u6839\u636e\u8bb0\u5f55\u4e2d\u7f16\u7801\u7684 schema \u7248\u672c id \u4ece\u914d\u7f6e\u7684 Confluent Schema Registry \u4e2d\u83b7\u53d6 Avro writer schema \uff0c\u800c\u4ece table schema \u4e2d\u63a8\u65ad\u51fa reader schema\u3002\n \n-When writing (serializing) a record with this format the Avro schema is inferred from the table schema and used to retrieve a schema id to be encoded with the data. The lookup is performed with in the configured Confluent Schema Registry under the [subject](https://docs.confluent.io/current/schema-registry/index.html#schemas-subjects-and-topics) given in `avro-confluent.schema-registry.subject`.\n+\u5f53\u4ee5\u8fd9\u79cd\u683c\u5f0f\u5199\u5165\uff08\u5e8f\u5217\u5316\uff09\u8bb0\u5f55\u65f6\uff0cAvro schema \u662f\u4ece table schema \u4e2d\u63a8\u65ad\u51fa\u6765\u7684\uff0c\u5e76\u7528\u4e8e\u68c0\u7d22\u8981\u4e0e\u6570\u636e\u4e00\u8d77\u7f16\u7801\u7684 schema id\u3002\u68c0\u7d22\u662f\u5728 Confluent Schema Registry \u914d\u7f6e\u4e2d\u7684 `avro-confluent.schema-registry.subject` \u4e2d\u6307\u5b9a\u7684[subject](https://docs.confluent.io/current/schema-registry/index.html#schemas-subjects-and-topics)\u4e0b\u6267\u884c\u7684\u3002", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzE0NTI0MQ=="}, "originalCommit": {"oid": "4d511a01a26b4a0ad0ea7423887cdd37d163a0e7"}, "originalPosition": 11}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4971, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}