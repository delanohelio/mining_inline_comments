{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzU5MzA3NjUy", "number": 10769, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wOFQxMToyODowN1rODWg3kg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQxMzoxNDoxMVrODX16Qg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI0OTMzNzc4OnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-jdbc/src/test/java/org/apache/flink/api/java/io/jdbc/JDBCTableSourceSinkFactoryTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wOFQxMToyODowN1rOFbUHrg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wOVQwMjozOToxOVrOFbpjmA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDE4NTUxOA==", "bodyText": "I think we should add an integreation test to verify the JDBC source can work when project is pushed down.", "url": "https://github.com/apache/flink/pull/10769#discussion_r364185518", "createdAt": "2020-01-08T11:28:07Z", "author": {"login": "wuchong"}, "path": "flink-connectors/flink-jdbc/src/test/java/org/apache/flink/api/java/io/jdbc/JDBCTableSourceSinkFactoryTest.java", "diffHunk": "@@ -182,6 +184,12 @@ public void testJDBCWithFilter() {\n \t\tassertEquals(projectedFields.get(\"aaa\"), DataTypes.INT());\n \t\tassertNull(projectedFields.get(\"bbb\"));\n \t\tassertEquals(projectedFields.get(\"ccc\"), DataTypes.DOUBLE());\n+\n+\t\t// test jdbc table source description\n+\t\tList<String> fieldNames = ((RowType) actual.getProducedDataType().getLogicalType()).getFieldNames();\n+\t\tString expectedSourceDescription = actual.getClass().getSimpleName()\n+\t\t\t+ \"(\" + String.join(\", \", fieldNames.stream().toArray(String[]::new)) + \")\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9f9c59090ca6b17d95441dd5d1b4c86be6c01bbf"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDUzNjcyOA==", "bodyText": "@wuchong Good idea. I have updated.", "url": "https://github.com/apache/flink/pull/10769#discussion_r364536728", "createdAt": "2020-01-09T02:39:19Z", "author": {"login": "wangxlong"}, "path": "flink-connectors/flink-jdbc/src/test/java/org/apache/flink/api/java/io/jdbc/JDBCTableSourceSinkFactoryTest.java", "diffHunk": "@@ -182,6 +184,12 @@ public void testJDBCWithFilter() {\n \t\tassertEquals(projectedFields.get(\"aaa\"), DataTypes.INT());\n \t\tassertNull(projectedFields.get(\"bbb\"));\n \t\tassertEquals(projectedFields.get(\"ccc\"), DataTypes.DOUBLE());\n+\n+\t\t// test jdbc table source description\n+\t\tList<String> fieldNames = ((RowType) actual.getProducedDataType().getLogicalType()).getFieldNames();\n+\t\tString expectedSourceDescription = actual.getClass().getSimpleName()\n+\t\t\t+ \"(\" + String.join(\", \", fieldNames.stream().toArray(String[]::new)) + \")\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDE4NTUxOA=="}, "originalCommit": {"oid": "9f9c59090ca6b17d95441dd5d1b4c86be6c01bbf"}, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2MjAyMDM4OnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-jdbc/src/test/java/org/apache/flink/api/java/io/jdbc/JDBCTableSourceITCase.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQwMzoyMjo1MlrOFdLOjA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQwMzoyMjo1MlrOFdLOjA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjEzNjk3Mg==", "bodyText": "remove empty line.", "url": "https://github.com/apache/flink/pull/10769#discussion_r366136972", "createdAt": "2020-01-14T03:22:52Z", "author": {"login": "wuchong"}, "path": "flink-connectors/flink-jdbc/src/test/java/org/apache/flink/api/java/io/jdbc/JDBCTableSourceITCase.java", "diffHunk": "@@ -0,0 +1,111 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.api.java.io.jdbc;\n+\n+import org.apache.flink.streaming.api.datastream.DataStream;\n+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\n+import org.apache.flink.table.api.Table;\n+import org.apache.flink.table.api.java.StreamTableEnvironment;\n+import org.apache.flink.table.runtime.utils.StreamITCase;\n+import org.apache.flink.types.Row;\n+\n+import org.junit.Test;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+/**\n+ * IT case for {@link JDBCTableSource}.\n+ */\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ea00615b2fcd2ad6fe9a1c03f9ba334fc23e8ddf"}, "originalPosition": 36}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2MzI2NzYwOnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-jdbc/src/test/java/org/apache/flink/api/java/io/jdbc/JDBCTableSourceITCase.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQxMzoxMjo1M1rOFdW96g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQxNDozMzowNFrOFdZg7w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjMyOTMyMg==", "bodyText": "Please use @BeforeClass instead of static code block.", "url": "https://github.com/apache/flink/pull/10769#discussion_r366329322", "createdAt": "2020-01-14T13:12:53Z", "author": {"login": "wuchong"}, "path": "flink-connectors/flink-jdbc/src/test/java/org/apache/flink/api/java/io/jdbc/JDBCTableSourceITCase.java", "diffHunk": "@@ -0,0 +1,108 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.api.java.io.jdbc;\n+\n+import org.apache.flink.streaming.api.datastream.DataStream;\n+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\n+import org.apache.flink.table.api.EnvironmentSettings;\n+import org.apache.flink.table.api.Table;\n+import org.apache.flink.table.api.java.StreamTableEnvironment;\n+import org.apache.flink.table.runtime.utils.StreamITCase;\n+import org.apache.flink.types.Row;\n+\n+import org.junit.Test;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+/**\n+ * IT case for {@link JDBCTableSource}.\n+ */\n+public class JDBCTableSourceITCase extends JDBCTestBase {\n+\n+\tprivate static final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n+\tprivate static final EnvironmentSettings bsSettings = EnvironmentSettings.newInstance().useBlinkPlanner().inStreamingMode().build();\n+\tprivate static final StreamTableEnvironment tEnv = StreamTableEnvironment.create(env, bsSettings);\n+\n+\tstatic final String TABLE_SOURCE_SQL = \"CREATE TABLE books (\" +\n+\t\t\" id int, \" +\n+\t\t\" title varchar, \" +\n+\t\t\" author varchar, \" +\n+\t\t\" price double, \" +\n+\t\t\" qty int \" +\n+\t\t\") with (\" +\n+\t\t\" 'connector.type' = 'jdbc', \" +\n+\t\t\" 'connector.url' = 'jdbc:derby:memory:ebookshop', \" +\n+\t\t\" 'connector.table' = 'books', \" +\n+\t\t\" 'connector.driver' = 'org.apache.derby.jdbc.EmbeddedDriver' \" +\n+\t\t\")\";\n+\n+\tstatic {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e1d0a854d224d253d452ef4188ad4ff65045b39"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjM3MTA1NQ==", "bodyText": "Thanks, Done.", "url": "https://github.com/apache/flink/pull/10769#discussion_r366371055", "createdAt": "2020-01-14T14:33:04Z", "author": {"login": "wangxlong"}, "path": "flink-connectors/flink-jdbc/src/test/java/org/apache/flink/api/java/io/jdbc/JDBCTableSourceITCase.java", "diffHunk": "@@ -0,0 +1,108 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.api.java.io.jdbc;\n+\n+import org.apache.flink.streaming.api.datastream.DataStream;\n+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\n+import org.apache.flink.table.api.EnvironmentSettings;\n+import org.apache.flink.table.api.Table;\n+import org.apache.flink.table.api.java.StreamTableEnvironment;\n+import org.apache.flink.table.runtime.utils.StreamITCase;\n+import org.apache.flink.types.Row;\n+\n+import org.junit.Test;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+/**\n+ * IT case for {@link JDBCTableSource}.\n+ */\n+public class JDBCTableSourceITCase extends JDBCTestBase {\n+\n+\tprivate static final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n+\tprivate static final EnvironmentSettings bsSettings = EnvironmentSettings.newInstance().useBlinkPlanner().inStreamingMode().build();\n+\tprivate static final StreamTableEnvironment tEnv = StreamTableEnvironment.create(env, bsSettings);\n+\n+\tstatic final String TABLE_SOURCE_SQL = \"CREATE TABLE books (\" +\n+\t\t\" id int, \" +\n+\t\t\" title varchar, \" +\n+\t\t\" author varchar, \" +\n+\t\t\" price double, \" +\n+\t\t\" qty int \" +\n+\t\t\") with (\" +\n+\t\t\" 'connector.type' = 'jdbc', \" +\n+\t\t\" 'connector.url' = 'jdbc:derby:memory:ebookshop', \" +\n+\t\t\" 'connector.table' = 'books', \" +\n+\t\t\" 'connector.driver' = 'org.apache.derby.jdbc.EmbeddedDriver' \" +\n+\t\t\")\";\n+\n+\tstatic {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjMyOTMyMg=="}, "originalCommit": {"oid": "4e1d0a854d224d253d452ef4188ad4ff65045b39"}, "originalPosition": 56}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2MzI3MTA2OnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-jdbc/pom.xml", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQxMzoxNDoxMVrOFdXAOw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQxNDozMjo0NVrOFdZgPw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjMyOTkxNQ==", "bodyText": "Can we set the scope only for test?", "url": "https://github.com/apache/flink/pull/10769#discussion_r366329915", "createdAt": "2020-01-14T13:14:11Z", "author": {"login": "wuchong"}, "path": "flink-connectors/flink-jdbc/pom.xml", "diffHunk": "@@ -54,6 +54,14 @@ under the License.\n \t\t\t<optional>true</optional>\n \t\t</dependency>\n \n+\t\t<dependency>\n+\t\t\t<groupId>org.apache.flink</groupId>\n+\t\t\t<artifactId>flink-table-planner-blink_${scala.binary.version}</artifactId>\n+\t\t\t<version>${project.version}</version>\n+\t\t\t<scope>provided</scope>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e1d0a854d224d253d452ef4188ad4ff65045b39"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjM3MDg3OQ==", "bodyText": "Yes, It is ok to set scope  as test. But I don't know why set provide in old planner before.", "url": "https://github.com/apache/flink/pull/10769#discussion_r366370879", "createdAt": "2020-01-14T14:32:45Z", "author": {"login": "wangxlong"}, "path": "flink-connectors/flink-jdbc/pom.xml", "diffHunk": "@@ -54,6 +54,14 @@ under the License.\n \t\t\t<optional>true</optional>\n \t\t</dependency>\n \n+\t\t<dependency>\n+\t\t\t<groupId>org.apache.flink</groupId>\n+\t\t\t<artifactId>flink-table-planner-blink_${scala.binary.version}</artifactId>\n+\t\t\t<version>${project.version}</version>\n+\t\t\t<scope>provided</scope>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjMyOTkxNQ=="}, "originalCommit": {"oid": "4e1d0a854d224d253d452ef4188ad4ff65045b39"}, "originalPosition": 8}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1286, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}