{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg1NDk5MjEx", "number": 11353, "title": "[FLINK-16438][yarn] Make YarnResourceManager starts workers using WorkerResourceSpec requested by SlotManager", "bodyText": "What is the purpose of the change\nThis PR is one step of FLINK-14106, making YarnResourceManager starts workers using WorkerResourceSpec requested by SlotManager.\nThis also means YarnResourceManager no longer:\n\nbe aware of the default task executor resources\nassumes all workers are identical\n\nThis PR is based on #11323.\nBrief change log\n\n5ee2a8e..d7a0626: Commits from previous PR.\n2f20532..4e214f9: Refactoring YarnResourceManagerTest, getting rid of using of Mockito.\nef959ec: Introduce WorkerSpecContainerResourceAdapter for converting between Flink WorkerResourceSpec and Yarn container Resource in YarnResourceManager.\n\nThis is to address the problem that resource of containers allocated from Yarn can differs from what were requested.\n\n\n785558f: YarnResourceManager starts workers with resources requested by SlotManager.\n0c5eb8c: Remove unused TaskExecutorProcessSpec from ActiveResourceManager.\n\nVerifying this change\nAdded test cases in YarnResourceManagerTest, for:\n\nValidating behaviors of WorkerSpecContainerResourceAdapter.\nValidating YarnResourceManager dealing with workers with different resources.\n\nDoes this pull request potentially affect one of the following parts:\n\nDependencies (does it add or upgrade a dependency): (no)\nThe public API, i.e., is any changed class annotated with @Public(Evolving): (no)\nThe serializers: (no)\nThe runtime per-record code paths (performance sensitive): (no)\nAnything that affects deployment or recovery: JobManager (and its components), Checkpointing, Kubernetes/Yarn/Mesos, ZooKeeper: (yes)\nThe S3 file system connector: (no)\n\nDocumentation\n\nDoes this pull request introduce a new feature? (no)\nIf yes, how is the feature documented? (not applicable)", "createdAt": "2020-03-09T10:23:19Z", "url": "https://github.com/apache/flink/pull/11353", "merged": true, "mergeCommit": {"oid": "65e43b823a71c277e5abaa324672f39c1918b49a"}, "closed": true, "closedAt": "2020-04-25T20:29:30Z", "author": {"login": "xintongsong"}, "timelineItems": {"totalCount": 27, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcMezH9AFqTM3MjQzNjU2MQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcbGJYhgBqjMyNzE5MjMxNDE=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcyNDM2NTYx", "url": "https://github.com/apache/flink/pull/11353#pullrequestreview-372436561", "createdAt": "2020-03-11T02:17:18Z", "commit": {"oid": "80a6254bc7f7b433b9c6ab26e2fa63d5c7e0ba2a"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQwMjoxNzoxOFrOF0nIdg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQwMzo0MjozMlrOF0oTlg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDcxMTQxNA==", "bodyText": "Not sure we could add underscores in the method name.", "url": "https://github.com/apache/flink/pull/11353#discussion_r390711414", "createdAt": "2020-03-11T02:17:18Z", "author": {"login": "KarmaGYZ"}, "path": "flink-yarn/src/test/java/org/apache/flink/yarn/YarnResourceManagerTest.java", "diffHunk": "@@ -584,6 +590,85 @@ public void testGetCpuExceedMaxInt() throws Exception {\n \t\t}};\n \t}\n \n+\t@Test\n+\tpublic void testWorkerSpecContainerResourceAdapter_MatchVcores() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "80a6254bc7f7b433b9c6ab26e2fa63d5c7e0ba2a"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDcxNTExNA==", "bodyText": "These records seem never to be cleaned up. It will not cause any problem atm though.", "url": "https://github.com/apache/flink/pull/11353#discussion_r390715114", "createdAt": "2020-03-11T02:32:43Z", "author": {"login": "KarmaGYZ"}, "path": "flink-yarn/src/main/java/org/apache/flink/yarn/YarnResourceManager.java", "diffHunk": "@@ -615,4 +632,85 @@ protected double getCpuCores(final Configuration configuration) {\n \t\t//noinspection NumericCastThatLosesPrecision\n \t\treturn cpuCoresLong;\n \t}\n+\n+\t/**\n+\t * Utility class for converting between Flink {@link WorkerResourceSpec} and Yarn {@link Resource}.\n+\t */\n+\t@VisibleForTesting\n+\tstatic class WorkerSpecContainerResourceAdapter {\n+\t\tprivate final Configuration flinkConfig;\n+\t\tprivate final int minMemMB;\n+\t\tprivate final int minVcore;\n+\t\tprivate final boolean matchVcores;\n+\t\tprivate final Map<WorkerResourceSpec, Resource> workerSpecToContainerResource;\n+\t\tprivate final Map<Resource, Collection<WorkerResourceSpec>> containerResourceToWorkerSpecs;\n+\t\tprivate final Map<Integer, Collection<Resource>> containerMemoryToContainerResource;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "80a6254bc7f7b433b9c6ab26e2fa63d5c7e0ba2a"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDcyMjMwNw==", "bodyText": "Seems we don't need to add it to containerMemoryToContainerResource if matchVcores is false.", "url": "https://github.com/apache/flink/pull/11353#discussion_r390722307", "createdAt": "2020-03-11T03:03:42Z", "author": {"login": "KarmaGYZ"}, "path": "flink-yarn/src/main/java/org/apache/flink/yarn/YarnResourceManager.java", "diffHunk": "@@ -615,4 +632,85 @@ protected double getCpuCores(final Configuration configuration) {\n \t\t//noinspection NumericCastThatLosesPrecision\n \t\treturn cpuCoresLong;\n \t}\n+\n+\t/**\n+\t * Utility class for converting between Flink {@link WorkerResourceSpec} and Yarn {@link Resource}.\n+\t */\n+\t@VisibleForTesting\n+\tstatic class WorkerSpecContainerResourceAdapter {\n+\t\tprivate final Configuration flinkConfig;\n+\t\tprivate final int minMemMB;\n+\t\tprivate final int minVcore;\n+\t\tprivate final boolean matchVcores;\n+\t\tprivate final Map<WorkerResourceSpec, Resource> workerSpecToContainerResource;\n+\t\tprivate final Map<Resource, Collection<WorkerResourceSpec>> containerResourceToWorkerSpecs;\n+\t\tprivate final Map<Integer, Collection<Resource>> containerMemoryToContainerResource;\n+\n+\t\t@VisibleForTesting\n+\t\tWorkerSpecContainerResourceAdapter(\n+\t\t\t\tfinal Configuration flinkConfig,\n+\t\t\t\tfinal int minMemMB,\n+\t\t\t\tfinal int minVcore,\n+\t\t\t\tfinal boolean matchVcores) {\n+\t\t\tthis.flinkConfig = Preconditions.checkNotNull(flinkConfig);\n+\t\t\tthis.minMemMB = minMemMB;\n+\t\t\tthis.minVcore = minVcore;\n+\t\t\tthis.matchVcores = matchVcores;\n+\t\t\tworkerSpecToContainerResource = new HashMap<>();\n+\t\t\tcontainerResourceToWorkerSpecs = new HashMap<>();\n+\t\t\tcontainerMemoryToContainerResource = new HashMap<>();\n+\t\t}\n+\n+\t\t@VisibleForTesting\n+\t\tResource getContainerResource(final WorkerResourceSpec workerResourceSpec) {\n+\t\t\treturn workerSpecToContainerResource.computeIfAbsent(\n+\t\t\t\tPreconditions.checkNotNull(workerResourceSpec),\n+\t\t\t\tthis::createAndMapContainerResource);\n+\t\t}\n+\n+\t\t@VisibleForTesting\n+\t\tCollection<WorkerResourceSpec> getWorkerSpecs(final Resource containerResource) {\n+\t\t\treturn getEquivalentContainerResource(containerResource).stream()\n+\t\t\t\t.flatMap(resource -> containerResourceToWorkerSpecs.getOrDefault(resource, Collections.emptyList()).stream())\n+\t\t\t\t.collect(Collectors.toList());\n+\t\t}\n+\n+\t\t@VisibleForTesting\n+\t\tCollection<Resource> getEquivalentContainerResource(final Resource containerResource) {\n+\t\t\t// Yarn might ignore the requested vcores, depending on its configurations.\n+\t\t\t// In such cases, we should also not matching vcores.\n+\t\t\treturn matchVcores ?\n+\t\t\t\tCollections.singletonList(containerResource) :\n+\t\t\t\tcontainerMemoryToContainerResource.getOrDefault(containerResource.getMemory(), Collections.emptyList());\n+\t\t}\n+\n+\t\tprivate Resource createAndMapContainerResource(final WorkerResourceSpec workerResourceSpec) {\n+\t\t\t// TODO: need to unset process/flink memory size from configuration if dynamic worker resource is activated\n+\t\t\tfinal TaskExecutorProcessSpec taskExecutorProcessSpec =\n+\t\t\t\tTaskExecutorProcessUtils.processSpecFromWorkerResourceSpec(flinkConfig, workerResourceSpec);\n+\t\t\tfinal Resource containerResource = Resource.newInstance(\n+\t\t\t\tnormalize(taskExecutorProcessSpec.getTotalProcessMemorySize().getMebiBytes(), minMemMB),\n+\t\t\t\tnormalize(taskExecutorProcessSpec.getCpuCores().getValue().intValue(), minVcore));\n+\t\t\tcontainerResourceToWorkerSpecs.computeIfAbsent(containerResource, ignored -> new ArrayList<>())\n+\t\t\t\t.add(workerResourceSpec);\n+\t\t\tcontainerMemoryToContainerResource.computeIfAbsent(containerResource.getMemory(), ignored -> new HashSet<>())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "80a6254bc7f7b433b9c6ab26e2fa63d5c7e0ba2a"}, "originalPosition": 124}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDczMDY0Ng==", "bodyText": "Is there any benefit we could get from extending AMRMClientAsyncImpl instead of AMRMClientAsync? This class is annotated with Unstable.", "url": "https://github.com/apache/flink/pull/11353#discussion_r390730646", "createdAt": "2020-03-11T03:42:32Z", "author": {"login": "KarmaGYZ"}, "path": "flink-yarn/src/test/java/org/apache/flink/yarn/TestingYarnAMRMClientAsync.java", "diffHunk": "@@ -0,0 +1,113 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.yarn;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.api.java.tuple.Tuple4;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.yarn.api.records.ContainerId;\n+import org.apache.hadoop.yarn.api.records.Priority;\n+import org.apache.hadoop.yarn.api.records.Resource;\n+import org.apache.hadoop.yarn.client.api.AMRMClient;\n+import org.apache.hadoop.yarn.client.api.async.AMRMClientAsync;\n+import org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl;\n+\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+\n+/**\n+ * A Yarn {@link AMRMClientAsync} implementation for testing.\n+ */\n+public class TestingYarnAMRMClientAsync extends AMRMClientAsyncImpl<AMRMClient.ContainerRequest> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9fc7db6c74fbc2b870daa35bd9da1a9f3132360b"}, "originalPosition": 42}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "af8a042f0b1bb2b7492f03144eadabcbf0c9f8d7", "author": {"user": {"login": "xintongsong", "name": "Xintong Song"}}, "url": "https://github.com/apache/flink/commit/af8a042f0b1bb2b7492f03144eadabcbf0c9f8d7", "committedDate": "2020-03-09T10:11:41Z", "message": "[FLINK-16438][runtime] Remove unused TaskExecutorProcessSpec from ActiveResourceManager."}, "afterCommit": {"oid": "e3a0e97a99c05635fd1b295638044c5d7147a3c1", "author": {"user": {"login": "xintongsong", "name": "Xintong Song"}}, "url": "https://github.com/apache/flink/commit/e3a0e97a99c05635fd1b295638044c5d7147a3c1", "committedDate": "2020-03-27T09:33:40Z", "message": "[FLINK-16438][runtime] Remove unused TaskExecutorProcessSpec from ActiveResourceManager."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e3a0e97a99c05635fd1b295638044c5d7147a3c1", "author": {"user": {"login": "xintongsong", "name": "Xintong Song"}}, "url": "https://github.com/apache/flink/commit/e3a0e97a99c05635fd1b295638044c5d7147a3c1", "committedDate": "2020-03-27T09:33:40Z", "message": "[FLINK-16438][runtime] Remove unused TaskExecutorProcessSpec from ActiveResourceManager."}, "afterCommit": {"oid": "9deac788721c83899d8bc4ce14732869e8bc2330", "author": {"user": {"login": "xintongsong", "name": "Xintong Song"}}, "url": "https://github.com/apache/flink/commit/9deac788721c83899d8bc4ce14732869e8bc2330", "committedDate": "2020-03-30T02:33:25Z", "message": "[FLINK-16438][runtime] Remove unused TaskExecutorProcessSpec from ActiveResourceManager."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9deac788721c83899d8bc4ce14732869e8bc2330", "author": {"user": {"login": "xintongsong", "name": "Xintong Song"}}, "url": "https://github.com/apache/flink/commit/9deac788721c83899d8bc4ce14732869e8bc2330", "committedDate": "2020-03-30T02:33:25Z", "message": "[FLINK-16438][runtime] Remove unused TaskExecutorProcessSpec from ActiveResourceManager."}, "afterCommit": {"oid": "0c5eb8c3d46d2142f9dd64acfaba9d27102ad3f2", "author": {"user": {"login": "xintongsong", "name": "Xintong Song"}}, "url": "https://github.com/apache/flink/commit/0c5eb8c3d46d2142f9dd64acfaba9d27102ad3f2", "committedDate": "2020-03-30T05:04:14Z", "message": "[FLINK-16438][runtime] Remove unused TaskExecutorProcessSpec from ActiveResourceManager."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg3MzQ5NjU4", "url": "https://github.com/apache/flink/pull/11353#pullrequestreview-387349658", "createdAt": "2020-04-03T15:16:36Z", "commit": {"oid": "d3fc9010a987cd299f355ddc1fbeb4225b5fb418"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 30, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wM1QxNToxNjozNlrOGAZ-EA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wM1QxNjozNjoyOFrOGAdTUQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzA3ODY3Mg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            public class ActiveResourceManagerTest {\n          \n          \n            \n            public class ActiveResourceManagerTest extends TestLogger {", "url": "https://github.com/apache/flink/pull/11353#discussion_r403078672", "createdAt": "2020-04-03T15:16:36Z", "author": {"login": "tillrohrmann"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/resourcemanager/ActiveResourceManagerTest.java", "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.resourcemanager;\n+\n+import org.junit.Test;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.core.Is.is;\n+\n+/**\n+ * Tests for {@link ActiveResourceManager}.\n+ */\n+public class ActiveResourceManagerTest {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3fc9010a987cd299f355ddc1fbeb4225b5fb418"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzA4Mzc4OQ==", "bodyText": "Call me old fashioned, but I think the for-each loop for (KubernetesPod pod: pods) is superior to forEach.", "url": "https://github.com/apache/flink/pull/11353#discussion_r403083789", "createdAt": "2020-04-03T15:24:15Z", "author": {"login": "tillrohrmann"}, "path": "flink-kubernetes/src/main/java/org/apache/flink/kubernetes/KubernetesResourceManager.java", "diffHunk": "@@ -183,16 +178,18 @@ public boolean stopWorker(final KubernetesWorkerNode worker) {\n \t@Override\n \tpublic void onAdded(List<KubernetesPod> pods) {\n \t\trunAsync(() -> {\n-\t\t\tfor (KubernetesPod pod : pods) {\n-\t\t\t\tif (numPendingPodRequests > 0) {\n-\t\t\t\t\tnumPendingPodRequests--;\n+\t\t\tpods.forEach(pod -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d7a0626255f2445cfe20dcb7bab1aede3af4b0d7"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzA4NjYyNQ==", "bodyText": "I'm wondering whether this logic shouldn't go into the ActiveResourceManager. I would expect that all ActiveResourceManager implementations would need to do something similar. Maybe we could introduce notifyNewWorkerStarted(WorkerResourceSpec). This could also have the benefit that we could hide pendingWorkerCounter completely.", "url": "https://github.com/apache/flink/pull/11353#discussion_r403086625", "createdAt": "2020-04-03T15:28:23Z", "author": {"login": "tillrohrmann"}, "path": "flink-kubernetes/src/main/java/org/apache/flink/kubernetes/KubernetesResourceManager.java", "diffHunk": "@@ -183,16 +178,18 @@ public boolean stopWorker(final KubernetesWorkerNode worker) {\n \t@Override\n \tpublic void onAdded(List<KubernetesPod> pods) {\n \t\trunAsync(() -> {\n-\t\t\tfor (KubernetesPod pod : pods) {\n-\t\t\t\tif (numPendingPodRequests > 0) {\n-\t\t\t\t\tnumPendingPodRequests--;\n+\t\t\tpods.forEach(pod -> {\n+\t\t\t\tWorkerResourceSpec workerResourceSpec = podWorkerResources.get(pod.getName());\n+\t\t\t\tfinal int pendingNum = pendingWorkerCounter.getNum(workerResourceSpec);\n+\t\t\t\tif (pendingNum > 0) {\n+\t\t\t\t\tpendingWorkerCounter.decreaseAndGet(workerResourceSpec);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d7a0626255f2445cfe20dcb7bab1aede3af4b0d7"}, "originalPosition": 73}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzA4ODEzMw==", "bodyText": "Should we add a check state to ensure that we fail in case that we request a different size?", "url": "https://github.com/apache/flink/pull/11353#discussion_r403088133", "createdAt": "2020-04-03T15:30:29Z", "author": {"login": "tillrohrmann"}, "path": "flink-kubernetes/src/main/java/org/apache/flink/kubernetes/KubernetesResourceManager.java", "diffHunk": "@@ -232,57 +229,75 @@ private void recoverWorkerNodesFromPreviousAttempts() throws ResourceManagerExce\n \t\t\t++currentMaxAttemptId);\n \t}\n \n-\tprivate void requestKubernetesPod() {\n-\t\tnumPendingPodRequests++;\n+\tprivate void requestKubernetesPod(WorkerResourceSpec workerResourceSpec) {\n+\t\tfinal KubernetesTaskManagerParameters parameters =\n+\t\t\tcreateKubernetesTaskManagerParameters(workerResourceSpec);\n+\n+\t\tpodWorkerResources.put(parameters.getPodName(), workerResourceSpec);\n+\t\tfinal int pendingWorkerNum = pendingWorkerCounter.increaseAndGet(workerResourceSpec);\n \n \t\tlog.info(\"Requesting new TaskManager pod with <{},{}>. Number pending requests {}.\",\n-\t\t\tdefaultMemoryMB,\n-\t\t\tdefaultCpus,\n-\t\t\tnumPendingPodRequests);\n+\t\t\tparameters.getTaskManagerMemoryMB(),\n+\t\t\tparameters.getTaskManagerCPU(),\n+\t\t\tpendingWorkerNum);\n+\t\tlog.info(\"TaskManager {} will be started with {}.\", parameters.getPodName(), workerResourceSpec);\n+\n+\t\tfinal KubernetesPod taskManagerPod =\n+\t\t\tKubernetesTaskManagerFactory.createTaskManagerComponent(parameters);\n+\t\tkubeClient.createTaskManagerPod(taskManagerPod);\n+\t}\n+\n+\tprivate KubernetesTaskManagerParameters createKubernetesTaskManagerParameters(WorkerResourceSpec workerResourceSpec) {\n+\t\t// TODO: need to unset process/flink memory size from configuration if dynamic worker resource is activated", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d7a0626255f2445cfe20dcb7bab1aede3af4b0d7"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzA4ODQ3Mw==", "bodyText": "Btw: where do we change the Configuration?", "url": "https://github.com/apache/flink/pull/11353#discussion_r403088473", "createdAt": "2020-04-03T15:30:58Z", "author": {"login": "tillrohrmann"}, "path": "flink-kubernetes/src/main/java/org/apache/flink/kubernetes/KubernetesResourceManager.java", "diffHunk": "@@ -232,57 +229,75 @@ private void recoverWorkerNodesFromPreviousAttempts() throws ResourceManagerExce\n \t\t\t++currentMaxAttemptId);\n \t}\n \n-\tprivate void requestKubernetesPod() {\n-\t\tnumPendingPodRequests++;\n+\tprivate void requestKubernetesPod(WorkerResourceSpec workerResourceSpec) {\n+\t\tfinal KubernetesTaskManagerParameters parameters =\n+\t\t\tcreateKubernetesTaskManagerParameters(workerResourceSpec);\n+\n+\t\tpodWorkerResources.put(parameters.getPodName(), workerResourceSpec);\n+\t\tfinal int pendingWorkerNum = pendingWorkerCounter.increaseAndGet(workerResourceSpec);\n \n \t\tlog.info(\"Requesting new TaskManager pod with <{},{}>. Number pending requests {}.\",\n-\t\t\tdefaultMemoryMB,\n-\t\t\tdefaultCpus,\n-\t\t\tnumPendingPodRequests);\n+\t\t\tparameters.getTaskManagerMemoryMB(),\n+\t\t\tparameters.getTaskManagerCPU(),\n+\t\t\tpendingWorkerNum);\n+\t\tlog.info(\"TaskManager {} will be started with {}.\", parameters.getPodName(), workerResourceSpec);\n+\n+\t\tfinal KubernetesPod taskManagerPod =\n+\t\t\tKubernetesTaskManagerFactory.createTaskManagerComponent(parameters);\n+\t\tkubeClient.createTaskManagerPod(taskManagerPod);\n+\t}\n+\n+\tprivate KubernetesTaskManagerParameters createKubernetesTaskManagerParameters(WorkerResourceSpec workerResourceSpec) {\n+\t\t// TODO: need to unset process/flink memory size from configuration if dynamic worker resource is activated", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzA4ODEzMw=="}, "originalCommit": {"oid": "d7a0626255f2445cfe20dcb7bab1aede3af4b0d7"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzA4OTY2OQ==", "bodyText": "I think I would hide pendingWorkerCounter behind some methods which the base class provides.", "url": "https://github.com/apache/flink/pull/11353#discussion_r403089669", "createdAt": "2020-04-03T15:32:47Z", "author": {"login": "tillrohrmann"}, "path": "flink-kubernetes/src/main/java/org/apache/flink/kubernetes/KubernetesResourceManager.java", "diffHunk": "@@ -232,57 +229,75 @@ private void recoverWorkerNodesFromPreviousAttempts() throws ResourceManagerExce\n \t\t\t++currentMaxAttemptId);\n \t}\n \n-\tprivate void requestKubernetesPod() {\n-\t\tnumPendingPodRequests++;\n+\tprivate void requestKubernetesPod(WorkerResourceSpec workerResourceSpec) {\n+\t\tfinal KubernetesTaskManagerParameters parameters =\n+\t\t\tcreateKubernetesTaskManagerParameters(workerResourceSpec);\n+\n+\t\tpodWorkerResources.put(parameters.getPodName(), workerResourceSpec);\n+\t\tfinal int pendingWorkerNum = pendingWorkerCounter.increaseAndGet(workerResourceSpec);\n \n \t\tlog.info(\"Requesting new TaskManager pod with <{},{}>. Number pending requests {}.\",\n-\t\t\tdefaultMemoryMB,\n-\t\t\tdefaultCpus,\n-\t\t\tnumPendingPodRequests);\n+\t\t\tparameters.getTaskManagerMemoryMB(),\n+\t\t\tparameters.getTaskManagerCPU(),\n+\t\t\tpendingWorkerNum);\n+\t\tlog.info(\"TaskManager {} will be started with {}.\", parameters.getPodName(), workerResourceSpec);\n+\n+\t\tfinal KubernetesPod taskManagerPod =\n+\t\t\tKubernetesTaskManagerFactory.createTaskManagerComponent(parameters);\n+\t\tkubeClient.createTaskManagerPod(taskManagerPod);\n+\t}\n+\n+\tprivate KubernetesTaskManagerParameters createKubernetesTaskManagerParameters(WorkerResourceSpec workerResourceSpec) {\n+\t\t// TODO: need to unset process/flink memory size from configuration if dynamic worker resource is activated\n+\t\tfinal TaskExecutorProcessSpec taskExecutorProcessSpec =\n+\t\t\tTaskExecutorProcessUtils.processSpecFromWorkerResourceSpec(flinkConfig, workerResourceSpec);\n \n \t\tfinal String podName = String.format(\n \t\t\tTASK_MANAGER_POD_FORMAT,\n \t\t\tclusterId,\n \t\t\tcurrentMaxAttemptId,\n \t\t\t++currentMaxPodId);\n \n+\t\tfinal ContaineredTaskManagerParameters taskManagerParameters =\n+\t\t\tContaineredTaskManagerParameters.create(flinkConfig, taskExecutorProcessSpec);\n+\n \t\tfinal String dynamicProperties =\n \t\t\tBootstrapTools.getDynamicPropertiesAsString(flinkClientConfig, flinkConfig);\n \n-\t\tfinal KubernetesTaskManagerParameters kubernetesTaskManagerParameters = new KubernetesTaskManagerParameters(\n+\t\treturn new KubernetesTaskManagerParameters(\n \t\t\tflinkConfig,\n \t\t\tpodName,\n \t\t\tdynamicProperties,\n \t\t\ttaskManagerParameters);\n-\n-\t\tfinal KubernetesPod taskManagerPod =\n-\t\t\tKubernetesTaskManagerFactory.createTaskManagerComponent(kubernetesTaskManagerParameters);\n-\n-\t\tlog.info(\"TaskManager {} will be started with {}.\", podName, taskExecutorProcessSpec);\n-\t\tkubeClient.createTaskManagerPod(taskManagerPod);\n \t}\n \n \t/**\n \t * Request new pod if pending pods cannot satisfy pending slot requests.\n \t */\n-\tprivate void requestKubernetesPodIfRequired() {\n-\t\tfinal int requiredTaskManagers = getNumberRequiredTaskManagers();\n+\tprivate void requestKubernetesPodIfRequired(WorkerResourceSpec workerResourceSpec) {\n+\t\tfinal int requiredTaskManagers = getPendingWorkerNums().get(workerResourceSpec);\n+\t\tfinal int pendingWorkerNum = pendingWorkerCounter.getNum(workerResourceSpec);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d7a0626255f2445cfe20dcb7bab1aede3af4b0d7"}, "originalPosition": 153}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzA5MDk4OA==", "bodyText": "Nit: Changing the return type to Optional<WorkerResourceSpec> could make the contract of this method a bit more explicit.", "url": "https://github.com/apache/flink/pull/11353#discussion_r403090988", "createdAt": "2020-04-03T15:34:36Z", "author": {"login": "tillrohrmann"}, "path": "flink-kubernetes/src/main/java/org/apache/flink/kubernetes/KubernetesResourceManager.java", "diffHunk": "@@ -232,57 +229,75 @@ private void recoverWorkerNodesFromPreviousAttempts() throws ResourceManagerExce\n \t\t\t++currentMaxAttemptId);\n \t}\n \n-\tprivate void requestKubernetesPod() {\n-\t\tnumPendingPodRequests++;\n+\tprivate void requestKubernetesPod(WorkerResourceSpec workerResourceSpec) {\n+\t\tfinal KubernetesTaskManagerParameters parameters =\n+\t\t\tcreateKubernetesTaskManagerParameters(workerResourceSpec);\n+\n+\t\tpodWorkerResources.put(parameters.getPodName(), workerResourceSpec);\n+\t\tfinal int pendingWorkerNum = pendingWorkerCounter.increaseAndGet(workerResourceSpec);\n \n \t\tlog.info(\"Requesting new TaskManager pod with <{},{}>. Number pending requests {}.\",\n-\t\t\tdefaultMemoryMB,\n-\t\t\tdefaultCpus,\n-\t\t\tnumPendingPodRequests);\n+\t\t\tparameters.getTaskManagerMemoryMB(),\n+\t\t\tparameters.getTaskManagerCPU(),\n+\t\t\tpendingWorkerNum);\n+\t\tlog.info(\"TaskManager {} will be started with {}.\", parameters.getPodName(), workerResourceSpec);\n+\n+\t\tfinal KubernetesPod taskManagerPod =\n+\t\t\tKubernetesTaskManagerFactory.createTaskManagerComponent(parameters);\n+\t\tkubeClient.createTaskManagerPod(taskManagerPod);\n+\t}\n+\n+\tprivate KubernetesTaskManagerParameters createKubernetesTaskManagerParameters(WorkerResourceSpec workerResourceSpec) {\n+\t\t// TODO: need to unset process/flink memory size from configuration if dynamic worker resource is activated\n+\t\tfinal TaskExecutorProcessSpec taskExecutorProcessSpec =\n+\t\t\tTaskExecutorProcessUtils.processSpecFromWorkerResourceSpec(flinkConfig, workerResourceSpec);\n \n \t\tfinal String podName = String.format(\n \t\t\tTASK_MANAGER_POD_FORMAT,\n \t\t\tclusterId,\n \t\t\tcurrentMaxAttemptId,\n \t\t\t++currentMaxPodId);\n \n+\t\tfinal ContaineredTaskManagerParameters taskManagerParameters =\n+\t\t\tContaineredTaskManagerParameters.create(flinkConfig, taskExecutorProcessSpec);\n+\n \t\tfinal String dynamicProperties =\n \t\t\tBootstrapTools.getDynamicPropertiesAsString(flinkClientConfig, flinkConfig);\n \n-\t\tfinal KubernetesTaskManagerParameters kubernetesTaskManagerParameters = new KubernetesTaskManagerParameters(\n+\t\treturn new KubernetesTaskManagerParameters(\n \t\t\tflinkConfig,\n \t\t\tpodName,\n \t\t\tdynamicProperties,\n \t\t\ttaskManagerParameters);\n-\n-\t\tfinal KubernetesPod taskManagerPod =\n-\t\t\tKubernetesTaskManagerFactory.createTaskManagerComponent(kubernetesTaskManagerParameters);\n-\n-\t\tlog.info(\"TaskManager {} will be started with {}.\", podName, taskExecutorProcessSpec);\n-\t\tkubeClient.createTaskManagerPod(taskManagerPod);\n \t}\n \n \t/**\n \t * Request new pod if pending pods cannot satisfy pending slot requests.\n \t */\n-\tprivate void requestKubernetesPodIfRequired() {\n-\t\tfinal int requiredTaskManagers = getNumberRequiredTaskManagers();\n+\tprivate void requestKubernetesPodIfRequired(WorkerResourceSpec workerResourceSpec) {\n+\t\tfinal int requiredTaskManagers = getPendingWorkerNums().get(workerResourceSpec);\n+\t\tfinal int pendingWorkerNum = pendingWorkerCounter.getNum(workerResourceSpec);\n \n-\t\tif (requiredTaskManagers > numPendingPodRequests) {\n-\t\t\trequestKubernetesPod();\n+\t\tif (requiredTaskManagers > pendingWorkerNum) {\n+\t\t\trequestKubernetesPod(workerResourceSpec);\n \t\t}\n \t}\n \n \tprivate void removePodIfTerminated(KubernetesPod pod) {\n \t\tif (pod.isTerminated()) {\n \t\t\tkubeClient.stopPod(pod.getName());\n-\t\t\tfinal KubernetesWorkerNode kubernetesWorkerNode = workerNodes.remove(new ResourceID(pod.getName()));\n-\t\t\tif (kubernetesWorkerNode != null) {\n-\t\t\t\trequestKubernetesPodIfRequired();\n+\t\t\tfinal WorkerResourceSpec workerResourceSpec = removeWorkerNodeAndResourceSpec(new ResourceID(pod.getName()));\n+\t\t\tif (workerResourceSpec != null) {\n+\t\t\t\trequestKubernetesPodIfRequired(workerResourceSpec);\n \t\t\t}\n \t\t}\n \t}\n \n+\tprivate WorkerResourceSpec removeWorkerNodeAndResourceSpec(ResourceID resourceId) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d7a0626255f2445cfe20dcb7bab1aede3af4b0d7"}, "originalPosition": 175}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzA5Mjc3Mw==", "bodyText": "I think this is pretty much whitebox testing as it strongly relies on internal implementation details. I would recommend to go another way and to rely either on the public APIs of the component or to encapsulate the bookkeeping logic so that it can be tested separately.", "url": "https://github.com/apache/flink/pull/11353#discussion_r403092773", "createdAt": "2020-04-03T15:37:20Z", "author": {"login": "tillrohrmann"}, "path": "flink-kubernetes/src/test/java/org/apache/flink/kubernetes/KubernetesResourceManagerTest.java", "diffHunk": "@@ -176,6 +185,15 @@ MainThreadExecutor getMainThreadExecutorForTesting() {\n \t\tSlotManager getSlotManager() {\n \t\t\treturn this.slotManager;\n \t\t}\n+\n+\t\t@Override\n+\t\tpublic Map<WorkerResourceSpec, Integer> getPendingWorkerNums() {\n+\t\t\treturn customPendingWorkerNums != null ? customPendingWorkerNums : super.getPendingWorkerNums();\n+\t\t}\n+\n+\t\tpublic void setCustomPendingWorkerNums(final Map<WorkerResourceSpec, Integer> customPendingWorkerNums) {\n+\t\t\tthis.customPendingWorkerNums = customPendingWorkerNums;\n+\t\t}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d7a0626255f2445cfe20dcb7bab1aede3af4b0d7"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzA5Mzk5Nw==", "bodyText": "I would recommend to not test the component like this. It requires detailed knowledge of the component's internals and makes it harder to evolve it because this test relies on the fact that the KubernetesResourceManager has a map of WorkerResourceSpec to Integers.", "url": "https://github.com/apache/flink/pull/11353#discussion_r403093997", "createdAt": "2020-04-03T15:39:08Z", "author": {"login": "tillrohrmann"}, "path": "flink-kubernetes/src/test/java/org/apache/flink/kubernetes/KubernetesResourceManagerTest.java", "diffHunk": "@@ -321,6 +339,47 @@ public void testGetCpuCoresNumSlots() {\n \t\tassertThat(resourceManager.getCpuCores(configuration), is(3.0));\n \t}\n \n+\t@Test\n+\tpublic void testStartAndRecoverVariousResourceSpec() {\n+\t\t// Start two workers with different resources\n+\t\tfinal WorkerResourceSpec workerResourceSpec1 = new WorkerResourceSpec(1.0, 100, 0, 100, 100);\n+\t\tfinal WorkerResourceSpec workerResourceSpec2 = new WorkerResourceSpec(1.0, 99, 0, 100, 100);\n+\t\tresourceManager.startNewWorker(workerResourceSpec1);\n+\t\tresourceManager.startNewWorker(workerResourceSpec2);\n+\n+\t\t// Verify two pods with both worker resources are started\n+\t\tfinal PodList initialPodList = kubeClient.pods().list();\n+\t\tassertEquals(2, initialPodList.getItems().size());\n+\t\tfinal Pod initialPod1 = getPodContainsStrInArgs(initialPodList, TaskManagerOptions.TASK_HEAP_MEMORY.key() + \"=\" + (100L << 20));\n+\t\tfinal Pod initialPod2 = getPodContainsStrInArgs(initialPodList, TaskManagerOptions.TASK_HEAP_MEMORY.key() + \"=\" + (99L << 20));\n+\n+\t\t// Notify resource manager about pods added.\n+\t\tfinal KubernetesPod initialKubernetesPod1 = new KubernetesPod(initialPod1);\n+\t\tfinal KubernetesPod initialKubernetesPod2 = new KubernetesPod(initialPod2);\n+\t\tresourceManager.onAdded(ImmutableList.of(initialKubernetesPod1, initialKubernetesPod2));\n+\n+\t\t// Terminate pod1.\n+\t\tterminatePod(initialPod1);\n+\t\tresourceManager.setCustomPendingWorkerNums(Collections.singletonMap(workerResourceSpec1, 1));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d7a0626255f2445cfe20dcb7bab1aede3af4b0d7"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzA5NzI3NQ==", "bodyText": "I think this class is large enough to warrant its own file. This would also decrease the size of this source code file a bit.", "url": "https://github.com/apache/flink/pull/11353#discussion_r403097275", "createdAt": "2020-04-03T15:44:20Z", "author": {"login": "tillrohrmann"}, "path": "flink-yarn/src/main/java/org/apache/flink/yarn/YarnResourceManager.java", "diffHunk": "@@ -615,4 +632,85 @@ protected double getCpuCores(final Configuration configuration) {\n \t\t//noinspection NumericCastThatLosesPrecision\n \t\treturn cpuCoresLong;\n \t}\n+\n+\t/**\n+\t * Utility class for converting between Flink {@link WorkerResourceSpec} and Yarn {@link Resource}.\n+\t */\n+\t@VisibleForTesting\n+\tstatic class WorkerSpecContainerResourceAdapter {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ef959ec03f964ceb0664388b4b72c8eac5773fbd"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzA5OTU5MQ==", "bodyText": "I would suggest to add a check state to ensure that we fail once we enable dynamic worker resources.", "url": "https://github.com/apache/flink/pull/11353#discussion_r403099591", "createdAt": "2020-04-03T15:48:00Z", "author": {"login": "tillrohrmann"}, "path": "flink-yarn/src/main/java/org/apache/flink/yarn/YarnResourceManager.java", "diffHunk": "@@ -615,4 +632,85 @@ protected double getCpuCores(final Configuration configuration) {\n \t\t//noinspection NumericCastThatLosesPrecision\n \t\treturn cpuCoresLong;\n \t}\n+\n+\t/**\n+\t * Utility class for converting between Flink {@link WorkerResourceSpec} and Yarn {@link Resource}.\n+\t */\n+\t@VisibleForTesting\n+\tstatic class WorkerSpecContainerResourceAdapter {\n+\t\tprivate final Configuration flinkConfig;\n+\t\tprivate final int minMemMB;\n+\t\tprivate final int minVcore;\n+\t\tprivate final boolean matchVcores;\n+\t\tprivate final Map<WorkerResourceSpec, Resource> workerSpecToContainerResource;\n+\t\tprivate final Map<Resource, Collection<WorkerResourceSpec>> containerResourceToWorkerSpecs;\n+\t\tprivate final Map<Integer, Collection<Resource>> containerMemoryToContainerResource;\n+\n+\t\t@VisibleForTesting\n+\t\tWorkerSpecContainerResourceAdapter(\n+\t\t\t\tfinal Configuration flinkConfig,\n+\t\t\t\tfinal int minMemMB,\n+\t\t\t\tfinal int minVcore,\n+\t\t\t\tfinal boolean matchVcores) {\n+\t\t\tthis.flinkConfig = Preconditions.checkNotNull(flinkConfig);\n+\t\t\tthis.minMemMB = minMemMB;\n+\t\t\tthis.minVcore = minVcore;\n+\t\t\tthis.matchVcores = matchVcores;\n+\t\t\tworkerSpecToContainerResource = new HashMap<>();\n+\t\t\tcontainerResourceToWorkerSpecs = new HashMap<>();\n+\t\t\tcontainerMemoryToContainerResource = new HashMap<>();\n+\t\t}\n+\n+\t\t@VisibleForTesting\n+\t\tResource getContainerResource(final WorkerResourceSpec workerResourceSpec) {\n+\t\t\treturn workerSpecToContainerResource.computeIfAbsent(\n+\t\t\t\tPreconditions.checkNotNull(workerResourceSpec),\n+\t\t\t\tthis::createAndMapContainerResource);\n+\t\t}\n+\n+\t\t@VisibleForTesting\n+\t\tCollection<WorkerResourceSpec> getWorkerSpecs(final Resource containerResource) {\n+\t\t\treturn getEquivalentContainerResource(containerResource).stream()\n+\t\t\t\t.flatMap(resource -> containerResourceToWorkerSpecs.getOrDefault(resource, Collections.emptyList()).stream())\n+\t\t\t\t.collect(Collectors.toList());\n+\t\t}\n+\n+\t\t@VisibleForTesting\n+\t\tCollection<Resource> getEquivalentContainerResource(final Resource containerResource) {\n+\t\t\t// Yarn might ignore the requested vcores, depending on its configurations.\n+\t\t\t// In such cases, we should also not matching vcores.\n+\t\t\treturn matchVcores ?\n+\t\t\t\tCollections.singletonList(containerResource) :\n+\t\t\t\tcontainerMemoryToContainerResource.getOrDefault(containerResource.getMemory(), Collections.emptyList());\n+\t\t}\n+\n+\t\tprivate Resource createAndMapContainerResource(final WorkerResourceSpec workerResourceSpec) {\n+\t\t\t// TODO: need to unset process/flink memory size from configuration if dynamic worker resource is activated", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ef959ec03f964ceb0664388b4b72c8eac5773fbd"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzEwNDg3Mw==", "bodyText": "If we are only interested in the equivalence class, then I would suggest to change the type from Collection to Set.", "url": "https://github.com/apache/flink/pull/11353#discussion_r403104873", "createdAt": "2020-04-03T15:56:43Z", "author": {"login": "tillrohrmann"}, "path": "flink-yarn/src/main/java/org/apache/flink/yarn/YarnResourceManager.java", "diffHunk": "@@ -615,4 +632,85 @@ protected double getCpuCores(final Configuration configuration) {\n \t\t//noinspection NumericCastThatLosesPrecision\n \t\treturn cpuCoresLong;\n \t}\n+\n+\t/**\n+\t * Utility class for converting between Flink {@link WorkerResourceSpec} and Yarn {@link Resource}.\n+\t */\n+\t@VisibleForTesting\n+\tstatic class WorkerSpecContainerResourceAdapter {\n+\t\tprivate final Configuration flinkConfig;\n+\t\tprivate final int minMemMB;\n+\t\tprivate final int minVcore;\n+\t\tprivate final boolean matchVcores;\n+\t\tprivate final Map<WorkerResourceSpec, Resource> workerSpecToContainerResource;\n+\t\tprivate final Map<Resource, Collection<WorkerResourceSpec>> containerResourceToWorkerSpecs;\n+\t\tprivate final Map<Integer, Collection<Resource>> containerMemoryToContainerResource;\n+\n+\t\t@VisibleForTesting\n+\t\tWorkerSpecContainerResourceAdapter(\n+\t\t\t\tfinal Configuration flinkConfig,\n+\t\t\t\tfinal int minMemMB,\n+\t\t\t\tfinal int minVcore,\n+\t\t\t\tfinal boolean matchVcores) {\n+\t\t\tthis.flinkConfig = Preconditions.checkNotNull(flinkConfig);\n+\t\t\tthis.minMemMB = minMemMB;\n+\t\t\tthis.minVcore = minVcore;\n+\t\t\tthis.matchVcores = matchVcores;\n+\t\t\tworkerSpecToContainerResource = new HashMap<>();\n+\t\t\tcontainerResourceToWorkerSpecs = new HashMap<>();\n+\t\t\tcontainerMemoryToContainerResource = new HashMap<>();\n+\t\t}\n+\n+\t\t@VisibleForTesting\n+\t\tResource getContainerResource(final WorkerResourceSpec workerResourceSpec) {\n+\t\t\treturn workerSpecToContainerResource.computeIfAbsent(\n+\t\t\t\tPreconditions.checkNotNull(workerResourceSpec),\n+\t\t\t\tthis::createAndMapContainerResource);\n+\t\t}\n+\n+\t\t@VisibleForTesting\n+\t\tCollection<WorkerResourceSpec> getWorkerSpecs(final Resource containerResource) {\n+\t\t\treturn getEquivalentContainerResource(containerResource).stream()\n+\t\t\t\t.flatMap(resource -> containerResourceToWorkerSpecs.getOrDefault(resource, Collections.emptyList()).stream())\n+\t\t\t\t.collect(Collectors.toList());\n+\t\t}\n+\n+\t\t@VisibleForTesting\n+\t\tCollection<Resource> getEquivalentContainerResource(final Resource containerResource) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ef959ec03f964ceb0664388b4b72c8eac5773fbd"}, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzEwNTgzMA==", "bodyText": "If we are interested in every WorkerResourceSpec which ever resulted into a given Resource, then I would suggest to change the value type to List. Otherwise one could instantiate this field with a Set which has different semantics.", "url": "https://github.com/apache/flink/pull/11353#discussion_r403105830", "createdAt": "2020-04-03T15:58:11Z", "author": {"login": "tillrohrmann"}, "path": "flink-yarn/src/main/java/org/apache/flink/yarn/YarnResourceManager.java", "diffHunk": "@@ -615,4 +632,85 @@ protected double getCpuCores(final Configuration configuration) {\n \t\t//noinspection NumericCastThatLosesPrecision\n \t\treturn cpuCoresLong;\n \t}\n+\n+\t/**\n+\t * Utility class for converting between Flink {@link WorkerResourceSpec} and Yarn {@link Resource}.\n+\t */\n+\t@VisibleForTesting\n+\tstatic class WorkerSpecContainerResourceAdapter {\n+\t\tprivate final Configuration flinkConfig;\n+\t\tprivate final int minMemMB;\n+\t\tprivate final int minVcore;\n+\t\tprivate final boolean matchVcores;\n+\t\tprivate final Map<WorkerResourceSpec, Resource> workerSpecToContainerResource;\n+\t\tprivate final Map<Resource, Collection<WorkerResourceSpec>> containerResourceToWorkerSpecs;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ef959ec03f964ceb0664388b4b72c8eac5773fbd"}, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzEwNzA0Ng==", "bodyText": "Does this mean that one has to configure ones Flink cluster depending on the configuration of the Yarn cluster? What happens if one forgets about Flink?", "url": "https://github.com/apache/flink/pull/11353#discussion_r403107046", "createdAt": "2020-04-03T16:00:02Z", "author": {"login": "tillrohrmann"}, "path": "flink-yarn/src/main/java/org/apache/flink/yarn/configuration/YarnConfigOptionsInternal.java", "diffHunk": "@@ -34,4 +37,24 @@\n \t\t\t\t\t.stringType()\n \t\t\t\t\t.noDefaultValue()\n \t\t\t\t\t.withDescription(\"**DO NOT USE** The location of the log config file, e.g. the path to your log4j.properties for log4j.\");\n+\n+\t/**\n+\t * **DO NO USE** Whether {@link YarnResourceManager} should match the vcores of allocated containers with those requested.\n+\t *\n+\t * <p>By default, Yarn ignores vcores in the container requests, and always allocate 1 vcore for each container.\n+\t * Iff 'yarn.scheduler.capacity.resource-calculator' is set to 'DominantResourceCalculator' for Yarn, will it\n+\t * allocate container vcores as requested. Unfortunately, this configuration option is dedicated for Yarn Scheduler,\n+\t * and is only accessible to applications in Hadoop 2.6+.\n+\t *\n+\t * <p>ATM, it should be fine to not match vcores, because with the current {@link SlotManagerImpl} all the TM\n+\t * containers should have the same resources.\n+\t *\n+\t * <p>If later we add another {@link SlotManager} implementation that may have TMs with different resources, we can\n+\t * switch this option on only for the new SM, and the new SM can also be available on Hadoop 2.6+ only.\n+\t */\n+\tpublic static final ConfigOption<Boolean> MATCH_CONTAINER_VCORES =\n+\t\t\tkey(\"$internal.yarn.resourcemanager.enable-vcore-matching\")\n+\t\t\t\t\t.booleanType()\n+\t\t\t\t\t.defaultValue(false)\n+\t\t\t\t\t.withDescription(\"**DO NOT USE** Whether YarnResourceManager should match the container vcores.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ef959ec03f964ceb0664388b4b72c8eac5773fbd"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzEwODU0Mw==", "bodyText": "It is usually easier to understand if one use an enum instead of boolean because one can give the different values expressive names (e.g. MATCH_VCORES, IGNORE_VCORES).", "url": "https://github.com/apache/flink/pull/11353#discussion_r403108543", "createdAt": "2020-04-03T16:02:33Z", "author": {"login": "tillrohrmann"}, "path": "flink-yarn/src/test/java/org/apache/flink/yarn/YarnResourceManagerTest.java", "diffHunk": "@@ -584,6 +590,85 @@ public void testGetCpuExceedMaxInt() throws Exception {\n \t\t}};\n \t}\n \n+\t@Test\n+\tpublic void testWorkerSpecContainerResourceAdapter_MatchVcores() {\n+\t\tfinal int minMemMB = 100;\n+\t\tfinal int minVcore = 10;\n+\t\tfinal YarnResourceManager.WorkerSpecContainerResourceAdapter adapter =\n+\t\t\tnew YarnResourceManager.WorkerSpecContainerResourceAdapter(\n+\t\t\t\tgetConfigProcessSpecEqualsWorkerSpec(), minMemMB, minVcore, true);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ef959ec03f964ceb0664388b4b72c8eac5773fbd"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzExMzM5OA==", "bodyText": "I like the idea of getting rid of Mockito but how do we ensure that this works with all Hadoop versions? Looking at Hadoop 2.10. https://github.com/apache/hadoop/blob/release-2.10.0-RC1/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/records/Container.java it looks as if the container has gotten some more methods.", "url": "https://github.com/apache/flink/pull/11353#discussion_r403113398", "createdAt": "2020-04-03T16:10:41Z", "author": {"login": "tillrohrmann"}, "path": "flink-yarn/src/test/java/org/apache/flink/yarn/TestingContainer.java", "diffHunk": "@@ -0,0 +1,113 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.yarn;\n+\n+import org.apache.hadoop.yarn.api.records.Container;\n+import org.apache.hadoop.yarn.api.records.ContainerId;\n+import org.apache.hadoop.yarn.api.records.NodeId;\n+import org.apache.hadoop.yarn.api.records.Priority;\n+import org.apache.hadoop.yarn.api.records.Resource;\n+import org.apache.hadoop.yarn.api.records.Token;\n+\n+/**\n+ * A {@link Container} implementation for testing.\n+ */\n+class TestingContainer extends Container {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2f2053259d86240c56ad4498eadae237ab30e979"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzExNTc0MA==", "bodyText": "Shouldn't we fail in case someone calls setContainerId here? Otherwise it might go unnoticed and result in some strange behaviour/failure.", "url": "https://github.com/apache/flink/pull/11353#discussion_r403115740", "createdAt": "2020-04-03T16:13:12Z", "author": {"login": "tillrohrmann"}, "path": "flink-yarn/src/test/java/org/apache/flink/yarn/TestingContainerStatus.java", "diffHunk": "@@ -0,0 +1,86 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.yarn;\n+\n+import org.apache.hadoop.yarn.api.records.ContainerId;\n+import org.apache.hadoop.yarn.api.records.ContainerState;\n+import org.apache.hadoop.yarn.api.records.ContainerStatus;\n+\n+/**\n+ * A {@link ContainerStatus} implementation for testing.\n+ */\n+class TestingContainerStatus extends ContainerStatus {\n+\n+\tprivate final ContainerId containerId;\n+\tprivate final ContainerState containerState;\n+\tprivate final String diagnostics;\n+\tprivate final int exitStatus;\n+\n+\tTestingContainerStatus(\n+\t\tfinal ContainerId containerId,\n+\t\tfinal ContainerState containerState,\n+\t\tfinal String diagnostics,\n+\t\tfinal int exitStatus) {\n+\n+\t\tthis.containerId = containerId;\n+\t\tthis.containerState = containerState;\n+\t\tthis.diagnostics = diagnostics;\n+\t\tthis.exitStatus = exitStatus;\n+\t}\n+\n+\t@Override\n+\tpublic ContainerId getContainerId() {\n+\t\treturn containerId;\n+\t}\n+\n+\t@Override\n+\tpublic void setContainerId(ContainerId containerId) {\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dfde526f4f6cea035e7774b59c3b8987fd4ae973"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzExODIyMw==", "bodyText": "AMRMClientAsyncImpl is annotated as unstable. I'm not sure how will the testing implementation works across different Yarn versions. Have we tried this out?", "url": "https://github.com/apache/flink/pull/11353#discussion_r403118223", "createdAt": "2020-04-03T16:15:43Z", "author": {"login": "tillrohrmann"}, "path": "flink-yarn/src/test/java/org/apache/flink/yarn/TestingYarnAMRMClientAsync.java", "diffHunk": "@@ -0,0 +1,113 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.yarn;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.api.java.tuple.Tuple4;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.yarn.api.records.ContainerId;\n+import org.apache.hadoop.yarn.api.records.Priority;\n+import org.apache.hadoop.yarn.api.records.Resource;\n+import org.apache.hadoop.yarn.client.api.AMRMClient;\n+import org.apache.hadoop.yarn.client.api.async.AMRMClientAsync;\n+import org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl;\n+\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+\n+/**\n+ * A Yarn {@link AMRMClientAsync} implementation for testing.\n+ */\n+public class TestingYarnAMRMClientAsync extends AMRMClientAsyncImpl<AMRMClient.ContainerRequest> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "658172cc8265792b710830a5d2749304cd1b10ba"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzExODYwMg==", "bodyText": "I'd suggest to use the BiConsumer here.", "url": "https://github.com/apache/flink/pull/11353#discussion_r403118602", "createdAt": "2020-04-03T16:16:10Z", "author": {"login": "tillrohrmann"}, "path": "flink-yarn/src/test/java/org/apache/flink/yarn/TestingYarnAMRMClientAsync.java", "diffHunk": "@@ -0,0 +1,113 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.yarn;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.api.java.tuple.Tuple4;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.yarn.api.records.ContainerId;\n+import org.apache.hadoop.yarn.api.records.Priority;\n+import org.apache.hadoop.yarn.api.records.Resource;\n+import org.apache.hadoop.yarn.client.api.AMRMClient;\n+import org.apache.hadoop.yarn.client.api.async.AMRMClientAsync;\n+import org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl;\n+\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+\n+/**\n+ * A Yarn {@link AMRMClientAsync} implementation for testing.\n+ */\n+public class TestingYarnAMRMClientAsync extends AMRMClientAsyncImpl<AMRMClient.ContainerRequest> {\n+\n+\tprivate Function<Tuple4<Priority, String, Resource, CallbackHandler>, List<? extends Collection<AMRMClient.ContainerRequest>>>\n+\t\tgetMatchingRequestsFunction = ignored -> Collections.emptyList();\n+\tprivate Consumer<Tuple2<AMRMClient.ContainerRequest, CallbackHandler>> addContainerRequestConsumer = ignored -> {};\n+\tprivate Consumer<Tuple2<AMRMClient.ContainerRequest, CallbackHandler>> removeContainerRequestConsumer = ignored -> {};\n+\tprivate Consumer<Tuple2<ContainerId, CallbackHandler>> releaseAssignedContainerConsumer = ignored -> {};", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "658172cc8265792b710830a5d2749304cd1b10ba"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzEyMTY3MQ==", "bodyText": "Same here NMClientAsyncImpl seems to be unstable and might change depending on the used Yarn version.", "url": "https://github.com/apache/flink/pull/11353#discussion_r403121671", "createdAt": "2020-04-03T16:19:46Z", "author": {"login": "tillrohrmann"}, "path": "flink-yarn/src/test/java/org/apache/flink/yarn/TestingYarnNMClientAsync.java", "diffHunk": "@@ -0,0 +1,82 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.yarn;\n+\n+import org.apache.flink.api.java.tuple.Tuple3;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.yarn.api.records.Container;\n+import org.apache.hadoop.yarn.api.records.ContainerId;\n+import org.apache.hadoop.yarn.api.records.ContainerLaunchContext;\n+import org.apache.hadoop.yarn.api.records.NodeId;\n+import org.apache.hadoop.yarn.client.api.async.NMClientAsync;\n+import org.apache.hadoop.yarn.client.api.async.impl.NMClientAsyncImpl;\n+\n+import java.util.function.Consumer;\n+\n+/**\n+ * A Yarn {@link NMClientAsync} implementation for testing.\n+ */\n+class TestingYarnNMClientAsync extends NMClientAsyncImpl {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8144ec035355decb400352fb6606b55075d13b8b"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzEyMTk0MQ==", "bodyText": "I'd suggest to use the TriConsumer here.", "url": "https://github.com/apache/flink/pull/11353#discussion_r403121941", "createdAt": "2020-04-03T16:20:05Z", "author": {"login": "tillrohrmann"}, "path": "flink-yarn/src/test/java/org/apache/flink/yarn/TestingYarnNMClientAsync.java", "diffHunk": "@@ -0,0 +1,82 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.yarn;\n+\n+import org.apache.flink.api.java.tuple.Tuple3;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.yarn.api.records.Container;\n+import org.apache.hadoop.yarn.api.records.ContainerId;\n+import org.apache.hadoop.yarn.api.records.ContainerLaunchContext;\n+import org.apache.hadoop.yarn.api.records.NodeId;\n+import org.apache.hadoop.yarn.client.api.async.NMClientAsync;\n+import org.apache.hadoop.yarn.client.api.async.impl.NMClientAsyncImpl;\n+\n+import java.util.function.Consumer;\n+\n+/**\n+ * A Yarn {@link NMClientAsync} implementation for testing.\n+ */\n+class TestingYarnNMClientAsync extends NMClientAsyncImpl {\n+\n+\tprivate Consumer<Tuple3<Container, ContainerLaunchContext, CallbackHandler>> startContainerAsyncConsumer = ignored -> {};\n+\tprivate Consumer<Tuple3<ContainerId, NodeId, CallbackHandler>> stopContainerAsyncConsumer = ignored -> {};", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8144ec035355decb400352fb6606b55075d13b8b"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzEyMzg2Nw==", "bodyText": "I'd suggest to use the for-each loop.", "url": "https://github.com/apache/flink/pull/11353#discussion_r403123867", "createdAt": "2020-04-03T16:22:16Z", "author": {"login": "tillrohrmann"}, "path": "flink-yarn/src/main/java/org/apache/flink/yarn/YarnResourceManager.java", "diffHunk": "@@ -363,31 +356,64 @@ public void onContainersCompleted(final List<ContainerStatus> statuses) {\n \t@Override\n \tpublic void onContainersAllocated(List<Container> containers) {\n \t\trunAsync(() -> {\n-\t\t\tlog.info(\"Received {} containers with {} pending container requests.\", containers.size(), numPendingContainerRequests);\n-\t\t\tfinal Collection<AMRMClient.ContainerRequest> pendingRequests = getPendingRequests();\n-\t\t\tfinal Iterator<AMRMClient.ContainerRequest> pendingRequestsIterator = pendingRequests.iterator();\n+\t\t\tlog.info(\"Received {} containers.\", containers.size());\n \n-\t\t\t// number of allocated containers can be larger than the number of pending container requests\n-\t\t\tfinal int numAcceptedContainers = Math.min(containers.size(), numPendingContainerRequests);\n-\t\t\tfinal List<Container> requiredContainers = containers.subList(0, numAcceptedContainers);\n-\t\t\tfinal List<Container> excessContainers = containers.subList(numAcceptedContainers, containers.size());\n-\n-\t\t\tfor (int i = 0; i < requiredContainers.size(); i++) {\n-\t\t\t\tremoveContainerRequest(pendingRequestsIterator.next());\n-\t\t\t}\n-\n-\t\t\texcessContainers.forEach(this::returnExcessContainer);\n-\t\t\trequiredContainers.forEach(this::startTaskExecutorInContainer);\n+\t\t\tgroupContainerByResource(containers).forEach(this::onContainersOfResourceAllocated);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "785558f7c2944cb50e57e191a242c5e981ab42b7"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzEyNjAxNQ==", "bodyText": "Can it happen that getWorkerSpecs(resource) returns a list which contains a WorkerResourceSpec twice?", "url": "https://github.com/apache/flink/pull/11353#discussion_r403126015", "createdAt": "2020-04-03T16:24:52Z", "author": {"login": "tillrohrmann"}, "path": "flink-yarn/src/main/java/org/apache/flink/yarn/YarnResourceManager.java", "diffHunk": "@@ -363,31 +356,64 @@ public void onContainersCompleted(final List<ContainerStatus> statuses) {\n \t@Override\n \tpublic void onContainersAllocated(List<Container> containers) {\n \t\trunAsync(() -> {\n-\t\t\tlog.info(\"Received {} containers with {} pending container requests.\", containers.size(), numPendingContainerRequests);\n-\t\t\tfinal Collection<AMRMClient.ContainerRequest> pendingRequests = getPendingRequests();\n-\t\t\tfinal Iterator<AMRMClient.ContainerRequest> pendingRequestsIterator = pendingRequests.iterator();\n+\t\t\tlog.info(\"Received {} containers.\", containers.size());\n \n-\t\t\t// number of allocated containers can be larger than the number of pending container requests\n-\t\t\tfinal int numAcceptedContainers = Math.min(containers.size(), numPendingContainerRequests);\n-\t\t\tfinal List<Container> requiredContainers = containers.subList(0, numAcceptedContainers);\n-\t\t\tfinal List<Container> excessContainers = containers.subList(numAcceptedContainers, containers.size());\n-\n-\t\t\tfor (int i = 0; i < requiredContainers.size(); i++) {\n-\t\t\t\tremoveContainerRequest(pendingRequestsIterator.next());\n-\t\t\t}\n-\n-\t\t\texcessContainers.forEach(this::returnExcessContainer);\n-\t\t\trequiredContainers.forEach(this::startTaskExecutorInContainer);\n+\t\t\tgroupContainerByResource(containers).forEach(this::onContainersOfResourceAllocated);\n \n \t\t\t// if we are waiting for no further containers, we can go to the\n \t\t\t// regular heartbeat interval\n-\t\t\tif (numPendingContainerRequests <= 0) {\n+\t\t\tif (pendingWorkerCounter.getTotalNum() <= 0) {\n \t\t\t\tresourceManagerClient.setHeartbeatInterval(yarnHeartbeatIntervalMillis);\n \t\t\t}\n \t\t});\n \t}\n \n-\tprivate void startTaskExecutorInContainer(Container container) {\n+\tprivate Map<Resource, List<Container>> groupContainerByResource(List<Container> containers) {\n+\t\treturn containers.stream().collect(Collectors.groupingBy(Container::getResource));\n+\t}\n+\n+\tprivate void onContainersOfResourceAllocated(Resource resource, List<Container> containers) {\n+\t\tfinal List<WorkerResourceSpec> pendingWorkerResourceSpecs =\n+\t\t\tworkerSpecContainerResourceAdapter.getWorkerSpecs(resource).stream()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "785558f7c2944cb50e57e191a242c5e981ab42b7"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzEyNzU0Ng==", "bodyText": "What about removing it from workerSpecContainerResourceAdapter?", "url": "https://github.com/apache/flink/pull/11353#discussion_r403127546", "createdAt": "2020-04-03T16:27:03Z", "author": {"login": "tillrohrmann"}, "path": "flink-yarn/src/main/java/org/apache/flink/yarn/YarnResourceManager.java", "diffHunk": "@@ -412,30 +439,32 @@ private void releaseFailedContainerAndRequestNewContainerIfRequired(ContainerId\n \n \t\tfinal ResourceID resourceId = new ResourceID(containerId.toString());\n \t\t// release the failed container\n-\t\tworkerNodeMap.remove(resourceId);\n+\t\tYarnWorkerNode yarnWorkerNode = workerNodeMap.remove(resourceId);\n \t\tresourceManagerClient.releaseAssignedContainer(containerId);\n \t\t// and ask for a new one\n-\t\trequestYarnContainerIfRequired();\n+\t\trequestYarnContainerIfRequired(yarnWorkerNode.getContainer().getResource());\n \t}\n \n \tprivate void returnExcessContainer(Container excessContainer) {\n \t\tlog.info(\"Returning excess container {}.\", excessContainer.getId());\n \t\tresourceManagerClient.releaseAssignedContainer(excessContainer.getId());\n \t}\n \n-\tprivate void removeContainerRequest(AMRMClient.ContainerRequest pendingContainerRequest) {\n-\t\tnumPendingContainerRequests--;\n-\n-\t\tlog.info(\"Removing container request {}. Pending container requests {}.\", pendingContainerRequest, numPendingContainerRequests);\n-\n+\tprivate void removeContainerRequest(AMRMClient.ContainerRequest pendingContainerRequest, WorkerResourceSpec workerResourceSpec) {\n+\t\tlog.info(\"Removing container request {}.\", pendingContainerRequest);\n+\t\tpendingWorkerCounter.decreaseAndGet(workerResourceSpec);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "785558f7c2944cb50e57e191a242c5e981ab42b7"}, "originalPosition": 164}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzEyODgwMw==", "bodyText": "Shouldn't we do this for all instead of any?", "url": "https://github.com/apache/flink/pull/11353#discussion_r403128803", "createdAt": "2020-04-03T16:29:08Z", "author": {"login": "tillrohrmann"}, "path": "flink-yarn/src/main/java/org/apache/flink/yarn/YarnResourceManager.java", "diffHunk": "@@ -540,39 +571,41 @@ private FinalApplicationStatus getYarnStatus(ApplicationStatus status) {\n \t/**\n \t * Request new container if pending containers cannot satisfy pending slot requests.\n \t */\n-\tprivate void requestYarnContainerIfRequired() {\n-\t\tint requiredTaskManagers = getNumberRequiredTaskManagers();\n-\n-\t\tif (requiredTaskManagers > numPendingContainerRequests) {\n-\t\t\trequestYarnContainer();\n-\t\t}\n+\tprivate void requestYarnContainerIfRequired(Resource containerResource) {\n+\t\tgetPendingWorkerNums().entrySet().stream()\n+\t\t\t.filter(entry ->\n+\t\t\t\tgetContainerResource(entry.getKey()).equals(containerResource) &&\n+\t\t\t\tentry.getValue() > pendingWorkerCounter.getNum(entry.getKey()))\n+\t\t\t.findAny()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "785558f7c2944cb50e57e191a242c5e981ab42b7"}, "originalPosition": 213}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzEzMDM1Mg==", "bodyText": "I have to admit that I find getPendingWorkerNums() and pendingWorkerCounter quite confusing. The sound almost the same but the former means the requirements of the SlotManager and the latter the currently pending workers which have been requested by the RM.", "url": "https://github.com/apache/flink/pull/11353#discussion_r403130352", "createdAt": "2020-04-03T16:32:00Z", "author": {"login": "tillrohrmann"}, "path": "flink-yarn/src/main/java/org/apache/flink/yarn/YarnResourceManager.java", "diffHunk": "@@ -540,39 +571,41 @@ private FinalApplicationStatus getYarnStatus(ApplicationStatus status) {\n \t/**\n \t * Request new container if pending containers cannot satisfy pending slot requests.\n \t */\n-\tprivate void requestYarnContainerIfRequired() {\n-\t\tint requiredTaskManagers = getNumberRequiredTaskManagers();\n-\n-\t\tif (requiredTaskManagers > numPendingContainerRequests) {\n-\t\t\trequestYarnContainer();\n-\t\t}\n+\tprivate void requestYarnContainerIfRequired(Resource containerResource) {\n+\t\tgetPendingWorkerNums().entrySet().stream()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "785558f7c2944cb50e57e191a242c5e981ab42b7"}, "originalPosition": 209}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzEzMTk2OA==", "bodyText": "Differently asked, when do we clean workerSpecContainerResourceAdapter up?", "url": "https://github.com/apache/flink/pull/11353#discussion_r403131968", "createdAt": "2020-04-03T16:34:15Z", "author": {"login": "tillrohrmann"}, "path": "flink-yarn/src/main/java/org/apache/flink/yarn/YarnResourceManager.java", "diffHunk": "@@ -412,30 +439,32 @@ private void releaseFailedContainerAndRequestNewContainerIfRequired(ContainerId\n \n \t\tfinal ResourceID resourceId = new ResourceID(containerId.toString());\n \t\t// release the failed container\n-\t\tworkerNodeMap.remove(resourceId);\n+\t\tYarnWorkerNode yarnWorkerNode = workerNodeMap.remove(resourceId);\n \t\tresourceManagerClient.releaseAssignedContainer(containerId);\n \t\t// and ask for a new one\n-\t\trequestYarnContainerIfRequired();\n+\t\trequestYarnContainerIfRequired(yarnWorkerNode.getContainer().getResource());\n \t}\n \n \tprivate void returnExcessContainer(Container excessContainer) {\n \t\tlog.info(\"Returning excess container {}.\", excessContainer.getId());\n \t\tresourceManagerClient.releaseAssignedContainer(excessContainer.getId());\n \t}\n \n-\tprivate void removeContainerRequest(AMRMClient.ContainerRequest pendingContainerRequest) {\n-\t\tnumPendingContainerRequests--;\n-\n-\t\tlog.info(\"Removing container request {}. Pending container requests {}.\", pendingContainerRequest, numPendingContainerRequests);\n-\n+\tprivate void removeContainerRequest(AMRMClient.ContainerRequest pendingContainerRequest, WorkerResourceSpec workerResourceSpec) {\n+\t\tlog.info(\"Removing container request {}.\", pendingContainerRequest);\n+\t\tpendingWorkerCounter.decreaseAndGet(workerResourceSpec);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzEyNzU0Ng=="}, "originalCommit": {"oid": "785558f7c2944cb50e57e191a242c5e981ab42b7"}, "originalPosition": 164}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzEzMjQ3MQ==", "bodyText": "Shouldn't we iterate over all resources which are needed instead of restricting it to containerResource?", "url": "https://github.com/apache/flink/pull/11353#discussion_r403132471", "createdAt": "2020-04-03T16:35:06Z", "author": {"login": "tillrohrmann"}, "path": "flink-yarn/src/main/java/org/apache/flink/yarn/YarnResourceManager.java", "diffHunk": "@@ -540,39 +571,41 @@ private FinalApplicationStatus getYarnStatus(ApplicationStatus status) {\n \t/**\n \t * Request new container if pending containers cannot satisfy pending slot requests.\n \t */\n-\tprivate void requestYarnContainerIfRequired() {\n-\t\tint requiredTaskManagers = getNumberRequiredTaskManagers();\n-\n-\t\tif (requiredTaskManagers > numPendingContainerRequests) {\n-\t\t\trequestYarnContainer();\n-\t\t}\n+\tprivate void requestYarnContainerIfRequired(Resource containerResource) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "785558f7c2944cb50e57e191a242c5e981ab42b7"}, "originalPosition": 208}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzEzMjkxMQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            public class KubernetesResourceManagerFactoryTest {\n          \n          \n            \n            public class KubernetesResourceManagerFactoryTest extends TestLogger {", "url": "https://github.com/apache/flink/pull/11353#discussion_r403132911", "createdAt": "2020-04-03T16:35:51Z", "author": {"login": "tillrohrmann"}, "path": "flink-kubernetes/src/test/java/org/apache/flink/kubernetes/entrypoint/KubernetesResourceManagerFactoryTest.java", "diffHunk": "@@ -0,0 +1,65 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.kubernetes.entrypoint;\n+\n+import org.apache.flink.api.common.resources.CPUResource;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.configuration.TaskManagerOptions;\n+import org.apache.flink.kubernetes.configuration.KubernetesConfigOptions;\n+\n+import org.junit.Test;\n+\n+import static org.hamcrest.core.Is.is;\n+import static org.junit.Assert.assertThat;\n+\n+/**\n+ * Tests for {@link KubernetesResourceManagerFactory}.\n+ */\n+public class KubernetesResourceManagerFactoryTest {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0c5eb8c3d46d2142f9dd64acfaba9d27102ad3f2"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzEzMzI2NQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            public class YarnResourceManagerFactoryTest {\n          \n          \n            \n            public class YarnResourceManagerFactoryTest extends TestLogger {", "url": "https://github.com/apache/flink/pull/11353#discussion_r403133265", "createdAt": "2020-04-03T16:36:28Z", "author": {"login": "tillrohrmann"}, "path": "flink-yarn/src/test/java/org/apache/flink/yarn/entrypoint/YarnResourceManagerFactoryTest.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.yarn.entrypoint;\n+\n+import org.apache.flink.api.common.resources.CPUResource;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.configuration.IllegalConfigurationException;\n+import org.apache.flink.configuration.TaskManagerOptions;\n+import org.apache.flink.yarn.configuration.YarnConfigOptions;\n+\n+import org.junit.Test;\n+\n+import static org.hamcrest.Matchers.is;\n+import static org.junit.Assert.assertThat;\n+\n+/**\n+ * Tests for {@link YarnResourceManagerFactory}.\n+ */\n+public class YarnResourceManagerFactoryTest {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0c5eb8c3d46d2142f9dd64acfaba9d27102ad3f2"}, "originalPosition": 35}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg4NzMzNTE3", "url": "https://github.com/apache/flink/pull/11353#pullrequestreview-388733517", "createdAt": "2020-04-07T01:52:27Z", "commit": {"oid": "0c5eb8c3d46d2142f9dd64acfaba9d27102ad3f2"}, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0c5eb8c3d46d2142f9dd64acfaba9d27102ad3f2", "author": {"user": {"login": "xintongsong", "name": "Xintong Song"}}, "url": "https://github.com/apache/flink/commit/0c5eb8c3d46d2142f9dd64acfaba9d27102ad3f2", "committedDate": "2020-03-30T05:04:14Z", "message": "[FLINK-16438][runtime] Remove unused TaskExecutorProcessSpec from ActiveResourceManager."}, "afterCommit": {"oid": "82d5dd9966f887470f20377d618c78a88f25dd82", "author": {"user": {"login": "xintongsong", "name": "Xintong Song"}}, "url": "https://github.com/apache/flink/commit/82d5dd9966f887470f20377d618c78a88f25dd82", "committedDate": "2020-04-10T08:11:12Z", "message": "[FLINK-16438][yarn] Decide WorkerSpecContainerResourceAdapter.MatchingStrategy based on RegisterApplicationMasterResponse."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk0NjUyOTA0", "url": "https://github.com/apache/flink/pull/11353#pullrequestreview-394652904", "createdAt": "2020-04-16T13:51:10Z", "commit": {"oid": "7f312629f59d37249600d4e17546a4122cd07589"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 19, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQxMzo1MToxMFrOGGmTtw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQxNTowNDoyM1rOGGp2qQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTU3MjI3OQ==", "bodyText": "It's not super important but I would prefer setting these functions in the constructor of the TestingYarnAMRMClientAsync class instead of using setters.", "url": "https://github.com/apache/flink/pull/11353#discussion_r409572279", "createdAt": "2020-04-16T13:51:10Z", "author": {"login": "tillrohrmann"}, "path": "flink-yarn/src/test/java/org/apache/flink/yarn/TestingYarnAMRMClientAsync.java", "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.yarn;\n+\n+import org.apache.flink.api.java.tuple.Tuple4;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.TriConsumer;\n+import org.apache.flink.util.function.TriFunction;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse;\n+import org.apache.hadoop.yarn.api.records.ContainerId;\n+import org.apache.hadoop.yarn.api.records.FinalApplicationStatus;\n+import org.apache.hadoop.yarn.api.records.Priority;\n+import org.apache.hadoop.yarn.api.records.Resource;\n+import org.apache.hadoop.yarn.client.api.AMRMClient;\n+import org.apache.hadoop.yarn.client.api.async.AMRMClientAsync;\n+import org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl;\n+\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.function.BiConsumer;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+\n+/**\n+ * A Yarn {@link AMRMClientAsync} implementation for testing.\n+ */\n+public class TestingYarnAMRMClientAsync extends AMRMClientAsyncImpl<AMRMClient.ContainerRequest> {\n+\n+\tprivate Function<Tuple4<Priority, String, Resource, CallbackHandler>, List<? extends Collection<AMRMClient.ContainerRequest>>>\n+\t\tgetMatchingRequestsFunction = ignored -> Collections.emptyList();\n+\tprivate BiConsumer<AMRMClient.ContainerRequest, CallbackHandler> addContainerRequestConsumer = (ignored1, ignored2) -> {};\n+\tprivate BiConsumer<AMRMClient.ContainerRequest, CallbackHandler> removeContainerRequestConsumer = (ignored1, ignored2) -> {};\n+\tprivate BiConsumer<ContainerId, CallbackHandler> releaseAssignedContainerConsumer = (ignored1, ignored2) -> {};\n+\tprivate Consumer<Integer> setHeartbeatIntervalConsumer = (ignored) -> {};\n+\tprivate TriFunction<String, Integer, String, RegisterApplicationMasterResponse> registerApplicationMasterFunction =\n+\t\t(ignored1, ignored2, ignored3) -> RegisterApplicationMasterResponse.newInstance(\n+\t\t\tResource.newInstance(0, 0),\n+\t\t\tResource.newInstance(Integer.MAX_VALUE, Integer.MAX_VALUE),\n+\t\t\tCollections.emptyMap(),\n+\t\t\tnull,\n+\t\t\tCollections.emptyList(),\n+\t\t\tnull,\n+\t\t\tCollections.emptyList());\n+\tprivate TriConsumer<FinalApplicationStatus, String, String> unregisterApplicationMasterConsumer = (ignored1, ignored2, ignored3) -> {};\n+\n+\tTestingYarnAMRMClientAsync(CallbackHandler callbackHandler) {\n+\t\tsuper(0, callbackHandler);\n+\t}\n+\n+\t@Override\n+\tpublic List<? extends Collection<AMRMClient.ContainerRequest>> getMatchingRequests(Priority priority, String resourceName, Resource capability) {\n+\t\treturn getMatchingRequestsFunction.apply(Tuple4.of(priority, resourceName, capability, handler));\n+\t}\n+\n+\t@Override\n+\tpublic void addContainerRequest(AMRMClient.ContainerRequest req) {\n+\t\taddContainerRequestConsumer.accept(req, handler);\n+\t}\n+\n+\t@Override\n+\tpublic void removeContainerRequest(AMRMClient.ContainerRequest req) {\n+\t\tremoveContainerRequestConsumer.accept(req, handler);\n+\t}\n+\n+\t@Override\n+\tpublic void releaseAssignedContainer(ContainerId containerId) {\n+\t\treleaseAssignedContainerConsumer.accept(containerId, handler);\n+\t}\n+\n+\t@Override\n+\tpublic void setHeartbeatInterval(int interval) {\n+\t\tsetHeartbeatIntervalConsumer.accept(interval);\n+\t}\n+\n+\t@Override\n+\tpublic RegisterApplicationMasterResponse registerApplicationMaster(String appHostName, int appHostPort, String appTrackingUrl) {\n+\t\treturn registerApplicationMasterFunction.apply(appHostName, appHostPort, appTrackingUrl);\n+\t}\n+\n+\t@Override\n+\tpublic void unregisterApplicationMaster(FinalApplicationStatus appStatus, String appMessage, String appTrackingUrl) {\n+\t\tunregisterApplicationMasterConsumer.accept(appStatus, appMessage, appTrackingUrl);\n+\t}\n+\n+\tvoid setGetMatchingRequestsFunction(\n+\t\tFunction<Tuple4<Priority, String, Resource, CallbackHandler>, List<? extends Collection<AMRMClient.ContainerRequest>>>\n+\t\t\tgetMatchingRequestsFunction) {\n+\t\tthis.getMatchingRequestsFunction = Preconditions.checkNotNull(getMatchingRequestsFunction);\n+\t}\n+\n+\tvoid setAddContainerRequestConsumer(\n+\t\tBiConsumer<AMRMClient.ContainerRequest, CallbackHandler> addContainerRequestConsumer) {\n+\t\tthis.addContainerRequestConsumer = Preconditions.checkNotNull(addContainerRequestConsumer);\n+\t}\n+\n+\tvoid setRemoveContainerRequestConsumer(\n+\t\tBiConsumer<AMRMClient.ContainerRequest, CallbackHandler> removeContainerRequestConsumer) {\n+\t\tthis.removeContainerRequestConsumer = Preconditions.checkNotNull(removeContainerRequestConsumer);\n+\t}\n+\n+\tvoid setReleaseAssignedContainerConsumer(\n+\t\tBiConsumer<ContainerId, CallbackHandler> releaseAssignedContainerConsumer) {\n+\t\tthis.releaseAssignedContainerConsumer = Preconditions.checkNotNull(releaseAssignedContainerConsumer);\n+\t}\n+\n+\tvoid setSetHeartbeatIntervalConsumer(\n+\t\tConsumer<Integer> setHeartbeatIntervalConsumer) {\n+\t\tthis.setHeartbeatIntervalConsumer = setHeartbeatIntervalConsumer;\n+\t}\n+\n+\tvoid setRegisterApplicationMasterFunction(\n+\t\tTriFunction<String, Integer, String, RegisterApplicationMasterResponse> registerApplicationMasterFunction) {\n+\t\tthis.registerApplicationMasterFunction = registerApplicationMasterFunction;\n+\t}\n+\n+\tvoid setUnregisterApplicationMasterConsumer(\n+\t\tTriConsumer<FinalApplicationStatus, String, String> unregisterApplicationMasterConsumer) {\n+\t\tthis.unregisterApplicationMasterConsumer = unregisterApplicationMasterConsumer;\n+\t}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7f312629f59d37249600d4e17546a4122cd07589"}, "originalPosition": 138}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTU3NTk2Mw==", "bodyText": "If one uses the setters, then the corresponding fields should be volatile if they are being set from a different thread.", "url": "https://github.com/apache/flink/pull/11353#discussion_r409575963", "createdAt": "2020-04-16T13:55:51Z", "author": {"login": "tillrohrmann"}, "path": "flink-yarn/src/test/java/org/apache/flink/yarn/TestingYarnAMRMClientAsync.java", "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.yarn;\n+\n+import org.apache.flink.api.java.tuple.Tuple4;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.TriConsumer;\n+import org.apache.flink.util.function.TriFunction;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse;\n+import org.apache.hadoop.yarn.api.records.ContainerId;\n+import org.apache.hadoop.yarn.api.records.FinalApplicationStatus;\n+import org.apache.hadoop.yarn.api.records.Priority;\n+import org.apache.hadoop.yarn.api.records.Resource;\n+import org.apache.hadoop.yarn.client.api.AMRMClient;\n+import org.apache.hadoop.yarn.client.api.async.AMRMClientAsync;\n+import org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl;\n+\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.function.BiConsumer;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+\n+/**\n+ * A Yarn {@link AMRMClientAsync} implementation for testing.\n+ */\n+public class TestingYarnAMRMClientAsync extends AMRMClientAsyncImpl<AMRMClient.ContainerRequest> {\n+\n+\tprivate Function<Tuple4<Priority, String, Resource, CallbackHandler>, List<? extends Collection<AMRMClient.ContainerRequest>>>\n+\t\tgetMatchingRequestsFunction = ignored -> Collections.emptyList();\n+\tprivate BiConsumer<AMRMClient.ContainerRequest, CallbackHandler> addContainerRequestConsumer = (ignored1, ignored2) -> {};\n+\tprivate BiConsumer<AMRMClient.ContainerRequest, CallbackHandler> removeContainerRequestConsumer = (ignored1, ignored2) -> {};\n+\tprivate BiConsumer<ContainerId, CallbackHandler> releaseAssignedContainerConsumer = (ignored1, ignored2) -> {};\n+\tprivate Consumer<Integer> setHeartbeatIntervalConsumer = (ignored) -> {};\n+\tprivate TriFunction<String, Integer, String, RegisterApplicationMasterResponse> registerApplicationMasterFunction =\n+\t\t(ignored1, ignored2, ignored3) -> RegisterApplicationMasterResponse.newInstance(\n+\t\t\tResource.newInstance(0, 0),\n+\t\t\tResource.newInstance(Integer.MAX_VALUE, Integer.MAX_VALUE),\n+\t\t\tCollections.emptyMap(),\n+\t\t\tnull,\n+\t\t\tCollections.emptyList(),\n+\t\t\tnull,\n+\t\t\tCollections.emptyList());\n+\tprivate TriConsumer<FinalApplicationStatus, String, String> unregisterApplicationMasterConsumer = (ignored1, ignored2, ignored3) -> {};\n+\n+\tTestingYarnAMRMClientAsync(CallbackHandler callbackHandler) {\n+\t\tsuper(0, callbackHandler);\n+\t}\n+\n+\t@Override\n+\tpublic List<? extends Collection<AMRMClient.ContainerRequest>> getMatchingRequests(Priority priority, String resourceName, Resource capability) {\n+\t\treturn getMatchingRequestsFunction.apply(Tuple4.of(priority, resourceName, capability, handler));\n+\t}\n+\n+\t@Override\n+\tpublic void addContainerRequest(AMRMClient.ContainerRequest req) {\n+\t\taddContainerRequestConsumer.accept(req, handler);\n+\t}\n+\n+\t@Override\n+\tpublic void removeContainerRequest(AMRMClient.ContainerRequest req) {\n+\t\tremoveContainerRequestConsumer.accept(req, handler);\n+\t}\n+\n+\t@Override\n+\tpublic void releaseAssignedContainer(ContainerId containerId) {\n+\t\treleaseAssignedContainerConsumer.accept(containerId, handler);\n+\t}\n+\n+\t@Override\n+\tpublic void setHeartbeatInterval(int interval) {\n+\t\tsetHeartbeatIntervalConsumer.accept(interval);\n+\t}\n+\n+\t@Override\n+\tpublic RegisterApplicationMasterResponse registerApplicationMaster(String appHostName, int appHostPort, String appTrackingUrl) {\n+\t\treturn registerApplicationMasterFunction.apply(appHostName, appHostPort, appTrackingUrl);\n+\t}\n+\n+\t@Override\n+\tpublic void unregisterApplicationMaster(FinalApplicationStatus appStatus, String appMessage, String appTrackingUrl) {\n+\t\tunregisterApplicationMasterConsumer.accept(appStatus, appMessage, appTrackingUrl);\n+\t}\n+\n+\tvoid setGetMatchingRequestsFunction(\n+\t\tFunction<Tuple4<Priority, String, Resource, CallbackHandler>, List<? extends Collection<AMRMClient.ContainerRequest>>>\n+\t\t\tgetMatchingRequestsFunction) {\n+\t\tthis.getMatchingRequestsFunction = Preconditions.checkNotNull(getMatchingRequestsFunction);\n+\t}\n+\n+\tvoid setAddContainerRequestConsumer(\n+\t\tBiConsumer<AMRMClient.ContainerRequest, CallbackHandler> addContainerRequestConsumer) {\n+\t\tthis.addContainerRequestConsumer = Preconditions.checkNotNull(addContainerRequestConsumer);\n+\t}\n+\n+\tvoid setRemoveContainerRequestConsumer(\n+\t\tBiConsumer<AMRMClient.ContainerRequest, CallbackHandler> removeContainerRequestConsumer) {\n+\t\tthis.removeContainerRequestConsumer = Preconditions.checkNotNull(removeContainerRequestConsumer);\n+\t}\n+\n+\tvoid setReleaseAssignedContainerConsumer(\n+\t\tBiConsumer<ContainerId, CallbackHandler> releaseAssignedContainerConsumer) {\n+\t\tthis.releaseAssignedContainerConsumer = Preconditions.checkNotNull(releaseAssignedContainerConsumer);\n+\t}\n+\n+\tvoid setSetHeartbeatIntervalConsumer(\n+\t\tConsumer<Integer> setHeartbeatIntervalConsumer) {\n+\t\tthis.setHeartbeatIntervalConsumer = setHeartbeatIntervalConsumer;\n+\t}\n+\n+\tvoid setRegisterApplicationMasterFunction(\n+\t\tTriFunction<String, Integer, String, RegisterApplicationMasterResponse> registerApplicationMasterFunction) {\n+\t\tthis.registerApplicationMasterFunction = registerApplicationMasterFunction;\n+\t}\n+\n+\tvoid setUnregisterApplicationMasterConsumer(\n+\t\tTriConsumer<FinalApplicationStatus, String, String> unregisterApplicationMasterConsumer) {\n+\t\tthis.unregisterApplicationMasterConsumer = unregisterApplicationMasterConsumer;\n+\t}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTU3MjI3OQ=="}, "originalCommit": {"oid": "7f312629f59d37249600d4e17546a4122cd07589"}, "originalPosition": 138}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTU3NjY2OA==", "bodyText": "Same here with the setters and volatile fields.", "url": "https://github.com/apache/flink/pull/11353#discussion_r409576668", "createdAt": "2020-04-16T13:56:47Z", "author": {"login": "tillrohrmann"}, "path": "flink-yarn/src/test/java/org/apache/flink/yarn/TestingYarnNMClientAsync.java", "diffHunk": "@@ -0,0 +1,80 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.yarn;\n+\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.TriConsumer;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.yarn.api.records.Container;\n+import org.apache.hadoop.yarn.api.records.ContainerId;\n+import org.apache.hadoop.yarn.api.records.ContainerLaunchContext;\n+import org.apache.hadoop.yarn.api.records.NodeId;\n+import org.apache.hadoop.yarn.client.api.async.NMClientAsync;\n+import org.apache.hadoop.yarn.client.api.async.impl.NMClientAsyncImpl;\n+\n+/**\n+ * A Yarn {@link NMClientAsync} implementation for testing.\n+ */\n+class TestingYarnNMClientAsync extends NMClientAsyncImpl {\n+\n+\tprivate TriConsumer<Container, ContainerLaunchContext, CallbackHandler> startContainerAsyncConsumer = (ignored1, ignored2, ignored3) -> {};\n+\tprivate TriConsumer<ContainerId, NodeId, CallbackHandler> stopContainerAsyncConsumer = (ignored1, ignored2, ignored3) -> {};\n+\n+\tTestingYarnNMClientAsync(final CallbackHandler callbackHandler) {\n+\t\tsuper(callbackHandler);\n+\t}\n+\n+\t@Override\n+\tpublic void startContainerAsync(Container container, ContainerLaunchContext containerLaunchContext) {\n+\t\tthis.startContainerAsyncConsumer.accept(container, containerLaunchContext, callbackHandler);\n+\t}\n+\n+\t@Override\n+\tpublic void stopContainerAsync(ContainerId containerId, NodeId nodeId) {\n+\t\tthis.stopContainerAsyncConsumer.accept(containerId, nodeId, callbackHandler);\n+\t}\n+\n+\tvoid setStartContainerAsyncConsumer(TriConsumer<Container, ContainerLaunchContext, CallbackHandler> startContainerAsyncConsumer) {\n+\t\tthis.startContainerAsyncConsumer = Preconditions.checkNotNull(startContainerAsyncConsumer);\n+\t}\n+\n+\tvoid setStopContainerAsyncConsumer(TriConsumer<ContainerId, NodeId, CallbackHandler> stopContainerAsyncConsumer) {\n+\t\tthis.stopContainerAsyncConsumer = Preconditions.checkNotNull(stopContainerAsyncConsumer);\n+\t}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4b7b0c179879f994f6fd67f41eb690a58751edfa"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTU3OTc5Mg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \tprivate final Logger log = LoggerFactory.getLogger(WorkerSpecContainerResourceAdapter.class);\n          \n          \n            \n            \tprivate static final Logger LOG = LoggerFactory.getLogger(WorkerSpecContainerResourceAdapter.class);", "url": "https://github.com/apache/flink/pull/11353#discussion_r409579792", "createdAt": "2020-04-16T14:00:42Z", "author": {"login": "tillrohrmann"}, "path": "flink-yarn/src/main/java/org/apache/flink/yarn/WorkerSpecContainerResourceAdapter.java", "diffHunk": "@@ -0,0 +1,156 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.yarn;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.runtime.clusterframework.TaskExecutorProcessSpec;\n+import org.apache.flink.runtime.clusterframework.TaskExecutorProcessUtils;\n+import org.apache.flink.runtime.resourcemanager.WorkerResourceSpec;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.hadoop.yarn.api.records.Resource;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Utility class for converting between Flink {@link WorkerResourceSpec} and Yarn {@link Resource}.\n+ */\n+public class WorkerSpecContainerResourceAdapter {\n+\tprivate final Logger log = LoggerFactory.getLogger(WorkerSpecContainerResourceAdapter.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "149f0715bdc453d010789292dcfd8e6de796af55"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTU4MDIwMw==", "bodyText": "nit:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \tprivate final int minMemMB;\n          \n          \n            \n            \tprivate final int minVcore;\n          \n          \n            \n            \tprivate final int maxMemMB;\n          \n          \n            \n            \tprivate final int maxVcore;\n          \n          \n            \n            \tprivate final int minMemMB;\n          \n          \n            \n            \tprivate final int maxMemMB;\n          \n          \n            \n            \tprivate final int minVcore;\n          \n          \n            \n            \tprivate final int maxVcore;", "url": "https://github.com/apache/flink/pull/11353#discussion_r409580203", "createdAt": "2020-04-16T14:01:14Z", "author": {"login": "tillrohrmann"}, "path": "flink-yarn/src/main/java/org/apache/flink/yarn/WorkerSpecContainerResourceAdapter.java", "diffHunk": "@@ -0,0 +1,156 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.yarn;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.runtime.clusterframework.TaskExecutorProcessSpec;\n+import org.apache.flink.runtime.clusterframework.TaskExecutorProcessUtils;\n+import org.apache.flink.runtime.resourcemanager.WorkerResourceSpec;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.hadoop.yarn.api.records.Resource;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Utility class for converting between Flink {@link WorkerResourceSpec} and Yarn {@link Resource}.\n+ */\n+public class WorkerSpecContainerResourceAdapter {\n+\tprivate final Logger log = LoggerFactory.getLogger(WorkerSpecContainerResourceAdapter.class);\n+\n+\tprivate final Configuration flinkConfig;\n+\tprivate final int minMemMB;\n+\tprivate final int minVcore;\n+\tprivate final int maxMemMB;\n+\tprivate final int maxVcore;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "149f0715bdc453d010789292dcfd8e6de796af55"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTU4MTc0NA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t\tif (value < unitValue) {\n          \n          \n            \n            \t\t\treturn unitValue;\n          \n          \n            \n            \t\t}\n          \n          \n            \n            \n          \n          \n            \n            \t\tif (value % unitValue == 0) {\n          \n          \n            \n            \t\t\treturn value;\n          \n          \n            \n            \t\t}\n          \n          \n            \n            \n          \n          \n            \n            \t\treturn (value / unitValue + 1) * unitValue;\n          \n          \n            \n            \t\treturn MathUtils.divideRoundUp(value, unitValue) * unitValue;", "url": "https://github.com/apache/flink/pull/11353#discussion_r409581744", "createdAt": "2020-04-16T14:03:12Z", "author": {"login": "tillrohrmann"}, "path": "flink-yarn/src/main/java/org/apache/flink/yarn/WorkerSpecContainerResourceAdapter.java", "diffHunk": "@@ -0,0 +1,156 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.yarn;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.runtime.clusterframework.TaskExecutorProcessSpec;\n+import org.apache.flink.runtime.clusterframework.TaskExecutorProcessUtils;\n+import org.apache.flink.runtime.resourcemanager.WorkerResourceSpec;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.hadoop.yarn.api.records.Resource;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Utility class for converting between Flink {@link WorkerResourceSpec} and Yarn {@link Resource}.\n+ */\n+public class WorkerSpecContainerResourceAdapter {\n+\tprivate final Logger log = LoggerFactory.getLogger(WorkerSpecContainerResourceAdapter.class);\n+\n+\tprivate final Configuration flinkConfig;\n+\tprivate final int minMemMB;\n+\tprivate final int minVcore;\n+\tprivate final int maxMemMB;\n+\tprivate final int maxVcore;\n+\tprivate final WorkerSpecContainerResourceAdapter.MatchingStrategy matchingStrategy;\n+\tprivate final Map<WorkerResourceSpec, Resource> workerSpecToContainerResource;\n+\tprivate final Map<Resource, List<WorkerResourceSpec>> containerResourceToWorkerSpecs;\n+\tprivate final Map<Integer, Set<Resource>> containerMemoryToContainerResource;\n+\n+\t@VisibleForTesting\n+\tWorkerSpecContainerResourceAdapter(\n+\t\tfinal Configuration flinkConfig,\n+\t\tfinal int minMemMB,\n+\t\tfinal int minVcore,\n+\t\tfinal int maxMemMB,\n+\t\tfinal int maxVcore,\n+\t\tfinal WorkerSpecContainerResourceAdapter.MatchingStrategy matchingStrategy) {\n+\t\tthis.flinkConfig = Preconditions.checkNotNull(flinkConfig);\n+\t\tthis.minMemMB = minMemMB;\n+\t\tthis.minVcore = minVcore;\n+\t\tthis.maxMemMB = maxMemMB;\n+\t\tthis.maxVcore = maxVcore;\n+\t\tthis.matchingStrategy = matchingStrategy;\n+\t\tworkerSpecToContainerResource = new HashMap<>();\n+\t\tcontainerResourceToWorkerSpecs = new HashMap<>();\n+\t\tcontainerMemoryToContainerResource = new HashMap<>();\n+\t}\n+\n+\t@VisibleForTesting\n+\tOptional<Resource> getContainerResource(final WorkerResourceSpec workerResourceSpec) {\n+\t\treturn Optional.ofNullable(workerSpecToContainerResource.computeIfAbsent(\n+\t\t\tPreconditions.checkNotNull(workerResourceSpec),\n+\t\t\tthis::createAndMapContainerResource));\n+\t}\n+\n+\t@VisibleForTesting\n+\tSet<WorkerResourceSpec> getWorkerSpecs(final Resource containerResource) {\n+\t\treturn getEquivalentContainerResource(containerResource).stream()\n+\t\t\t.flatMap(resource -> containerResourceToWorkerSpecs.getOrDefault(resource, Collections.emptyList()).stream())\n+\t\t\t.collect(Collectors.toSet());\n+\t}\n+\n+\t@VisibleForTesting\n+\tSet<Resource> getEquivalentContainerResource(final Resource containerResource) {\n+\t\t// Yarn might ignore the requested vcores, depending on its configurations.\n+\t\t// In such cases, we should also not matching vcores.\n+\t\tfinal Set<Resource> equivalentContainerResources;\n+\t\tswitch (matchingStrategy) {\n+\t\t\tcase MATCH_VCORE:\n+\t\t\t\tequivalentContainerResources = Collections.singleton(containerResource);\n+\t\t\t\tbreak;\n+\t\t\tcase IGNORE_VCORE:\n+\t\t\tdefault:\n+\t\t\t\tequivalentContainerResources = containerMemoryToContainerResource\n+\t\t\t\t\t.getOrDefault(containerResource.getMemory(), Collections.emptySet());\n+\t\t\t\tbreak;\n+\t\t}\n+\t\treturn equivalentContainerResources;\n+\t}\n+\n+\t@Nullable\n+\tprivate Resource createAndMapContainerResource(final WorkerResourceSpec workerResourceSpec) {\n+\t\tfinal TaskExecutorProcessSpec taskExecutorProcessSpec =\n+\t\t\tTaskExecutorProcessUtils.processSpecFromWorkerResourceSpec(flinkConfig, workerResourceSpec);\n+\t\tfinal Resource containerResource = Resource.newInstance(\n+\t\t\tnormalize(taskExecutorProcessSpec.getTotalProcessMemorySize().getMebiBytes(), minMemMB),\n+\t\t\tnormalize(taskExecutorProcessSpec.getCpuCores().getValue().intValue(), minVcore));\n+\n+\t\tif (resourceWithinMaxAllocation(containerResource)) {\n+\t\t\tcontainerResourceToWorkerSpecs.computeIfAbsent(containerResource, ignored -> new ArrayList<>())\n+\t\t\t\t.add(workerResourceSpec);\n+\t\t\tcontainerMemoryToContainerResource.computeIfAbsent(containerResource.getMemory(), ignored -> new HashSet<>())\n+\t\t\t\t.add(containerResource);\n+\t\t\treturn containerResource;\n+\t\t} else {\n+\t\t\tlog.warn(\"Requested container resource {} exceeds yarn max allocation {}. Will not allocate resource.\",\n+\t\t\t\tcontainerResource,\n+\t\t\t\tResource.newInstance(maxMemMB, maxVcore));\n+\t\t\treturn null;\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Normalize to the minimum integer that is greater or equal to 'value' and is integer multiple of 'unitValue'.\n+\t */\n+\tprivate int normalize(final int value, final int unitValue) {\n+\t\tif (value < unitValue) {\n+\t\t\treturn unitValue;\n+\t\t}\n+\n+\t\tif (value % unitValue == 0) {\n+\t\t\treturn value;\n+\t\t}\n+\n+\t\treturn (value / unitValue + 1) * unitValue;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "149f0715bdc453d010789292dcfd8e6de796af55"}, "originalPosition": 145}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTU4MzY5MQ==", "bodyText": "I think we don't need the @VisibleForTesting annotations in this class because we did not increase the visibility of these methods for testing purposes.", "url": "https://github.com/apache/flink/pull/11353#discussion_r409583691", "createdAt": "2020-04-16T14:05:40Z", "author": {"login": "tillrohrmann"}, "path": "flink-yarn/src/main/java/org/apache/flink/yarn/WorkerSpecContainerResourceAdapter.java", "diffHunk": "@@ -0,0 +1,156 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.yarn;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.runtime.clusterframework.TaskExecutorProcessSpec;\n+import org.apache.flink.runtime.clusterframework.TaskExecutorProcessUtils;\n+import org.apache.flink.runtime.resourcemanager.WorkerResourceSpec;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.hadoop.yarn.api.records.Resource;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Utility class for converting between Flink {@link WorkerResourceSpec} and Yarn {@link Resource}.\n+ */\n+public class WorkerSpecContainerResourceAdapter {\n+\tprivate final Logger log = LoggerFactory.getLogger(WorkerSpecContainerResourceAdapter.class);\n+\n+\tprivate final Configuration flinkConfig;\n+\tprivate final int minMemMB;\n+\tprivate final int minVcore;\n+\tprivate final int maxMemMB;\n+\tprivate final int maxVcore;\n+\tprivate final WorkerSpecContainerResourceAdapter.MatchingStrategy matchingStrategy;\n+\tprivate final Map<WorkerResourceSpec, Resource> workerSpecToContainerResource;\n+\tprivate final Map<Resource, List<WorkerResourceSpec>> containerResourceToWorkerSpecs;\n+\tprivate final Map<Integer, Set<Resource>> containerMemoryToContainerResource;\n+\n+\t@VisibleForTesting", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "149f0715bdc453d010789292dcfd8e6de796af55"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTU4OTA5MA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t * **DO NO USE** Whether {@link YarnResourceManager} should match the vcores of allocated containers with those requested.\n          \n          \n            \n            \t * **DO NOT USE** Whether {@link YarnResourceManager} should match the vcores of allocated containers with those requested.", "url": "https://github.com/apache/flink/pull/11353#discussion_r409589090", "createdAt": "2020-04-16T14:12:37Z", "author": {"login": "tillrohrmann"}, "path": "flink-yarn/src/main/java/org/apache/flink/yarn/configuration/YarnConfigOptionsInternal.java", "diffHunk": "@@ -34,4 +37,27 @@\n \t\t\t\t\t.stringType()\n \t\t\t\t\t.noDefaultValue()\n \t\t\t\t\t.withDescription(\"**DO NOT USE** The location of the log config file, e.g. the path to your log4j.properties for log4j.\");\n+\n+\t/**\n+\t * **DO NO USE** Whether {@link YarnResourceManager} should match the vcores of allocated containers with those requested.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "149f0715bdc453d010789292dcfd8e6de796af55"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTU5MjE4OQ==", "bodyText": "Maybe rename into tryComputeContainerResource or so because this method is not simply a look up. It is rather a creation call with a caching mechanism.", "url": "https://github.com/apache/flink/pull/11353#discussion_r409592189", "createdAt": "2020-04-16T14:16:28Z", "author": {"login": "tillrohrmann"}, "path": "flink-yarn/src/main/java/org/apache/flink/yarn/WorkerSpecContainerResourceAdapter.java", "diffHunk": "@@ -0,0 +1,156 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.yarn;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.runtime.clusterframework.TaskExecutorProcessSpec;\n+import org.apache.flink.runtime.clusterframework.TaskExecutorProcessUtils;\n+import org.apache.flink.runtime.resourcemanager.WorkerResourceSpec;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.hadoop.yarn.api.records.Resource;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Utility class for converting between Flink {@link WorkerResourceSpec} and Yarn {@link Resource}.\n+ */\n+public class WorkerSpecContainerResourceAdapter {\n+\tprivate final Logger log = LoggerFactory.getLogger(WorkerSpecContainerResourceAdapter.class);\n+\n+\tprivate final Configuration flinkConfig;\n+\tprivate final int minMemMB;\n+\tprivate final int minVcore;\n+\tprivate final int maxMemMB;\n+\tprivate final int maxVcore;\n+\tprivate final WorkerSpecContainerResourceAdapter.MatchingStrategy matchingStrategy;\n+\tprivate final Map<WorkerResourceSpec, Resource> workerSpecToContainerResource;\n+\tprivate final Map<Resource, List<WorkerResourceSpec>> containerResourceToWorkerSpecs;\n+\tprivate final Map<Integer, Set<Resource>> containerMemoryToContainerResource;\n+\n+\t@VisibleForTesting\n+\tWorkerSpecContainerResourceAdapter(\n+\t\tfinal Configuration flinkConfig,\n+\t\tfinal int minMemMB,\n+\t\tfinal int minVcore,\n+\t\tfinal int maxMemMB,\n+\t\tfinal int maxVcore,\n+\t\tfinal WorkerSpecContainerResourceAdapter.MatchingStrategy matchingStrategy) {\n+\t\tthis.flinkConfig = Preconditions.checkNotNull(flinkConfig);\n+\t\tthis.minMemMB = minMemMB;\n+\t\tthis.minVcore = minVcore;\n+\t\tthis.maxMemMB = maxMemMB;\n+\t\tthis.maxVcore = maxVcore;\n+\t\tthis.matchingStrategy = matchingStrategy;\n+\t\tworkerSpecToContainerResource = new HashMap<>();\n+\t\tcontainerResourceToWorkerSpecs = new HashMap<>();\n+\t\tcontainerMemoryToContainerResource = new HashMap<>();\n+\t}\n+\n+\t@VisibleForTesting\n+\tOptional<Resource> getContainerResource(final WorkerResourceSpec workerResourceSpec) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "149f0715bdc453d010789292dcfd8e6de796af55"}, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTU5NTEyNg==", "bodyText": "I think contains and containsInAnyOrder already do the size check meaning the that list must contain exactly as many items as matchers are specified.", "url": "https://github.com/apache/flink/pull/11353#discussion_r409595126", "createdAt": "2020-04-16T14:20:12Z", "author": {"login": "tillrohrmann"}, "path": "flink-yarn/src/test/java/org/apache/flink/yarn/WorkerSpecContainerResourceAdapterTest.java", "diffHunk": "@@ -0,0 +1,213 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.yarn;\n+\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.configuration.MemorySize;\n+import org.apache.flink.configuration.TaskManagerOptions;\n+import org.apache.flink.runtime.resourcemanager.WorkerResourceSpec;\n+import org.apache.flink.util.TestLogger;\n+\n+import org.apache.hadoop.yarn.api.records.Resource;\n+import org.junit.Test;\n+\n+import static org.hamcrest.Matchers.contains;\n+import static org.hamcrest.Matchers.containsInAnyOrder;\n+import static org.hamcrest.Matchers.empty;\n+import static org.hamcrest.Matchers.hasSize;\n+import static org.hamcrest.Matchers.is;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertThat;\n+\n+/**\n+ * Tests for {@link WorkerSpecContainerResourceAdapter}.\n+ */\n+public class WorkerSpecContainerResourceAdapterTest extends TestLogger {\n+\n+\t@Test\n+\tpublic void testMatchVcores() {\n+\t\tfinal int minMemMB = 100;\n+\t\tfinal int minVcore = 10;\n+\t\tfinal WorkerSpecContainerResourceAdapter adapter =\n+\t\t\tnew WorkerSpecContainerResourceAdapter(\n+\t\t\t\tgetConfigProcessSpecEqualsWorkerSpec(),\n+\t\t\t\tminMemMB,\n+\t\t\t\tminVcore,\n+\t\t\t\tInteger.MAX_VALUE,\n+\t\t\t\tInteger.MAX_VALUE,\n+\t\t\t\tWorkerSpecContainerResourceAdapter.MatchingStrategy.MATCH_VCORE);\n+\n+\t\tfinal WorkerResourceSpec workerSpec1 = new WorkerResourceSpec.Builder()\n+\t\t\t.setCpuCores(1.0)\n+\t\t\t.setTaskHeapMemoryMB(10)\n+\t\t\t.setTaskOffHeapMemoryMB(10)\n+\t\t\t.setNetworkMemoryMB(10)\n+\t\t\t.setManagedMemoryMB(10)\n+\t\t\t.build();\n+\t\tfinal WorkerResourceSpec workerSpec2 = new WorkerResourceSpec.Builder()\n+\t\t\t.setCpuCores(10.0)\n+\t\t\t.setTaskHeapMemoryMB(25)\n+\t\t\t.setTaskOffHeapMemoryMB(25)\n+\t\t\t.setNetworkMemoryMB(25)\n+\t\t\t.setManagedMemoryMB(25)\n+\t\t\t.build();\n+\t\tfinal WorkerResourceSpec workerSpec3 = new WorkerResourceSpec.Builder()\n+\t\t\t.setCpuCores(5.0)\n+\t\t\t.setTaskHeapMemoryMB(30)\n+\t\t\t.setTaskOffHeapMemoryMB(30)\n+\t\t\t.setNetworkMemoryMB(30)\n+\t\t\t.setManagedMemoryMB(30)\n+\t\t\t.build();\n+\t\tfinal WorkerResourceSpec workerSpec4 = new WorkerResourceSpec.Builder()\n+\t\t\t.setCpuCores(15.0)\n+\t\t\t.setTaskHeapMemoryMB(10)\n+\t\t\t.setTaskOffHeapMemoryMB(10)\n+\t\t\t.setNetworkMemoryMB(10)\n+\t\t\t.setManagedMemoryMB(10)\n+\t\t\t.build();\n+\n+\t\tfinal Resource containerResource1 = Resource.newInstance(100, 10);\n+\t\tfinal Resource containerResource2 = Resource.newInstance(200, 10);\n+\t\tfinal Resource containerResource3 = Resource.newInstance(100, 20);\n+\n+\t\tassertThat(adapter.getWorkerSpecs(containerResource1), empty());\n+\t\tassertThat(adapter.getWorkerSpecs(containerResource2), empty());\n+\n+\t\tassertThat(adapter.getContainerResource(workerSpec1).get(), is(containerResource1));\n+\t\tassertThat(adapter.getContainerResource(workerSpec2).get(), is(containerResource1));\n+\t\tassertThat(adapter.getContainerResource(workerSpec3).get(), is(containerResource2));\n+\t\tassertThat(adapter.getContainerResource(workerSpec4).get(), is(containerResource3));\n+\n+\t\tassertThat(adapter.getWorkerSpecs(containerResource1), hasSize(2));\n+\t\tassertThat(adapter.getWorkerSpecs(containerResource2), hasSize(1));\n+\t\tassertThat(adapter.getWorkerSpecs(containerResource3), hasSize(1));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "149f0715bdc453d010789292dcfd8e6de796af55"}, "originalPosition": 99}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTU5NjYzNA==", "bodyText": "Can the value type be a set?\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \tprivate final Map<Resource, List<WorkerResourceSpec>> containerResourceToWorkerSpecs;\n          \n          \n            \n            \tprivate final Map<Resource, Set<WorkerResourceSpec>> containerResourceToWorkerSpecs;", "url": "https://github.com/apache/flink/pull/11353#discussion_r409596634", "createdAt": "2020-04-16T14:22:10Z", "author": {"login": "tillrohrmann"}, "path": "flink-yarn/src/main/java/org/apache/flink/yarn/WorkerSpecContainerResourceAdapter.java", "diffHunk": "@@ -0,0 +1,156 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.yarn;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.runtime.clusterframework.TaskExecutorProcessSpec;\n+import org.apache.flink.runtime.clusterframework.TaskExecutorProcessUtils;\n+import org.apache.flink.runtime.resourcemanager.WorkerResourceSpec;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.hadoop.yarn.api.records.Resource;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Utility class for converting between Flink {@link WorkerResourceSpec} and Yarn {@link Resource}.\n+ */\n+public class WorkerSpecContainerResourceAdapter {\n+\tprivate final Logger log = LoggerFactory.getLogger(WorkerSpecContainerResourceAdapter.class);\n+\n+\tprivate final Configuration flinkConfig;\n+\tprivate final int minMemMB;\n+\tprivate final int minVcore;\n+\tprivate final int maxMemMB;\n+\tprivate final int maxVcore;\n+\tprivate final WorkerSpecContainerResourceAdapter.MatchingStrategy matchingStrategy;\n+\tprivate final Map<WorkerResourceSpec, Resource> workerSpecToContainerResource;\n+\tprivate final Map<Resource, List<WorkerResourceSpec>> containerResourceToWorkerSpecs;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "149f0715bdc453d010789292dcfd8e6de796af55"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTYwODYxNA==", "bodyText": "forEach is always an indicator that one could do the same with a while loop. In this case I would suggest to keep it simple and stupid:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t\tgetNumberRequiredWorkersPerWorkerResourceSpec().entrySet().stream()\n          \n          \n            \n            \t\t\t.filter(entry -> entry.getValue() > getNumPendingWorkersFor(entry.getKey()))\n          \n          \n            \n            \t\t\t.forEach(entry -> requestYarnContainer(entry.getKey()));\n          \n          \n            \n            \t\tfor (Map.Entry<WorkerResourceSpec, Integer> requiredWorkersPerResourceSpec : getNumberRequiredWorkersPerWorkerResourceSpec().entrySet()) {\n          \n          \n            \n            \t\t\tfinal WorkerResourceSpec workerResourceSpec = requiredWorkersPerResourceSpec.getKey();\n          \n          \n            \n            \t\t\twhile (requiredWorkersPerResourceSpec.getValue() > getNumPendingWorkersFor(workerResourceSpec)) {\n          \n          \n            \n            \t\t\t\trequestYarnContainer(workerResourceSpec);\n          \n          \n            \n            \t\t\t}\n          \n          \n            \n            \t\t}", "url": "https://github.com/apache/flink/pull/11353#discussion_r409608614", "createdAt": "2020-04-16T14:37:22Z", "author": {"login": "tillrohrmann"}, "path": "flink-yarn/src/main/java/org/apache/flink/yarn/YarnResourceManager.java", "diffHunk": "@@ -552,38 +581,44 @@ private FinalApplicationStatus getYarnStatus(ApplicationStatus status) {\n \t * Request new container if pending containers cannot satisfy pending slot requests.\n \t */\n \tprivate void requestYarnContainerIfRequired() {\n-\t\tint requiredTaskManagers = getNumberRequiredWorkers();\n-\n-\t\twhile (requiredTaskManagers-- > numPendingContainerRequests) {\n-\t\t\trequestYarnContainer();\n-\t\t}\n+\t\tgetNumberRequiredWorkersPerWorkerResourceSpec().entrySet().stream()\n+\t\t\t.filter(entry -> entry.getValue() > getNumPendingWorkersFor(entry.getKey()))\n+\t\t\t.forEach(entry -> requestYarnContainer(entry.getKey()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "112fe6526c4e11aabe35b0a72c310536e9e6c8c0"}, "originalPosition": 220}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTYxMDY1Mg==", "bodyText": "I assume that requestYarnContainer should never return false here, right? If this is the case, then let's add a checkState to ensure this invariant.", "url": "https://github.com/apache/flink/pull/11353#discussion_r409610652", "createdAt": "2020-04-16T14:40:00Z", "author": {"login": "tillrohrmann"}, "path": "flink-yarn/src/main/java/org/apache/flink/yarn/YarnResourceManager.java", "diffHunk": "@@ -552,38 +581,44 @@ private FinalApplicationStatus getYarnStatus(ApplicationStatus status) {\n \t * Request new container if pending containers cannot satisfy pending slot requests.\n \t */\n \tprivate void requestYarnContainerIfRequired() {\n-\t\tint requiredTaskManagers = getNumberRequiredWorkers();\n-\n-\t\twhile (requiredTaskManagers-- > numPendingContainerRequests) {\n-\t\t\trequestYarnContainer();\n-\t\t}\n+\t\tgetNumberRequiredWorkersPerWorkerResourceSpec().entrySet().stream()\n+\t\t\t.filter(entry -> entry.getValue() > getNumPendingWorkersFor(entry.getKey()))\n+\t\t\t.forEach(entry -> requestYarnContainer(entry.getKey()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "112fe6526c4e11aabe35b0a72c310536e9e6c8c0"}, "originalPosition": 220}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTYxMTc5NQ==", "bodyText": "Why not moving this block into the default constructor and removing the @Nullable annotation from slotManager?", "url": "https://github.com/apache/flink/pull/11353#discussion_r409611795", "createdAt": "2020-04-16T14:41:28Z", "author": {"login": "tillrohrmann"}, "path": "flink-yarn/src/test/java/org/apache/flink/yarn/YarnResourceManagerTest.java", "diffHunk": "@@ -243,24 +248,33 @@ protected NMClientAsync createAndStartNodeManagerClient(YarnConfiguration yarnCo\n \n \t\t// domain objects for test purposes\n \t\tfinal ResourceProfile resourceProfile1 = ResourceProfile.UNKNOWN;\n+\t\tfinal WorkerResourceSpec workerResourceSpec;\n+\n+\t\tfinal Resource containerResource;\n \n \t\tpublic String taskHost = \"host1\";\n \n \t\tfinal TestingYarnNMClientAsync testingYarnNMClientAsync;\n \n \t\tfinal TestingYarnAMRMClientAsync testingYarnAMRMClientAsync;\n \n+\t\tint containerIdx = 0;\n+\n \t\t/**\n \t\t * Create mock RM dependencies.\n \t\t */\n \t\tContext() throws Exception {\n-\t\t\tthis(flinkConfig);\n+\t\t\tthis(flinkConfig, null);\n \t\t}\n \n-\t\tContext(Configuration configuration) throws  Exception {\n-\t\t\tfinal SlotManager slotManager = SlotManagerBuilder.newBuilder()\n-\t\t\t\t.setDefaultWorkerResourceSpec(YarnWorkerResourceSpecFactory.INSTANCE.createDefaultWorkerResourceSpec(configuration))\n-\t\t\t\t.build();\n+\t\tContext(Configuration configuration, @Nullable SlotManager slotManager) throws  Exception {\n+\n+\t\t\tworkerResourceSpec = YarnWorkerResourceSpecFactory.INSTANCE.createDefaultWorkerResourceSpec(configuration);\n+\t\t\tif (slotManager == null) {\n+\t\t\t\tslotManager = SlotManagerBuilder.newBuilder()\n+\t\t\t\t\t.setDefaultWorkerResourceSpec(workerResourceSpec)\n+\t\t\t\t\t.build();\n+\t\t\t}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "112fe6526c4e11aabe35b0a72c310536e9e6c8c0"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTYxOTg4OA==", "bodyText": "One could think about factoring the lookup of methods and the logging statement out into a another method to avoid code duplication.", "url": "https://github.com/apache/flink/pull/11353#discussion_r409619888", "createdAt": "2020-04-16T14:51:24Z", "author": {"login": "tillrohrmann"}, "path": "flink-yarn/src/main/java/org/apache/flink/yarn/RegisterApplicationMasterResponseReflector.java", "diffHunk": "@@ -53,12 +59,20 @@\n \t\trequireNonNull(clazz);\n \n \t\ttry {\n-\t\t\tmethod = clazz.getMethod(\"getContainersFromPreviousAttempts\");\n+\t\t\tgetContainersFromPreviousAttemptsMethod = clazz.getMethod(\"getContainersFromPreviousAttempts\");\n \t\t} catch (NoSuchMethodException e) {\n \t\t\t// that happens in earlier Hadoop versions (pre 2.2)\n \t\t\tlogger.info(\"Cannot reconnect to previously allocated containers. \" +\n \t\t\t\t\"This YARN version does not support 'getContainersFromPreviousAttempts()'\");\n \t\t}\n+\n+\t\ttry {\n+\t\t\tgetSchedulerResourceTypesMethod = clazz.getMethod(\"getSchedulerResourceTypes\");\n+\t\t} catch (NoSuchMethodException e) {\n+\t\t\t// that happens in earlier Hadoop versions (pre 2.6)\n+\t\t\tlogger.info(\"Cannot get scheduler resource types. \" +\n+\t\t\t\t\"This YARN version does not support 'getSchedulerResourceTypes()'\");\n+\t\t}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82d5dd9966f887470f20377d618c78a88f25dd82"}, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTYyMjE4MA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \tOptional<Set<String>> getSchedulerResourceTypeNamesUnsafe(final Object response) {\n          \n          \n            \n            \tprivate Optional<Set<String>> getSchedulerResourceTypeNamesUnsafe(final Object response) {\n          \n      \n    \n    \n  \n\nand remove @VisibleForTesting.", "url": "https://github.com/apache/flink/pull/11353#discussion_r409622180", "createdAt": "2020-04-16T14:54:04Z", "author": {"login": "tillrohrmann"}, "path": "flink-yarn/src/main/java/org/apache/flink/yarn/RegisterApplicationMasterResponseReflector.java", "diffHunk": "@@ -96,7 +110,40 @@\n \t}\n \n \t@VisibleForTesting\n-\tMethod getMethod() {\n-\t\treturn method;\n+\tMethod getGetContainersFromPreviousAttemptsMethod() {\n+\t\treturn getContainersFromPreviousAttemptsMethod;\n+\t}\n+\n+\t/**\n+\t * Get names of resource types that are considered by the Yarn scheduler.\n+\t * @param response The response object from the registration at the ResourceManager.\n+\t * @return A set of resource type names, or {@link Optional#empty()} if the Yarn version does not support this API.\n+\t */\n+\tOptional<Set<String>> getSchedulerResourceTypeNames(final RegisterApplicationMasterResponse response) {\n+\t\treturn getSchedulerResourceTypeNamesUnsafe(response);\n+\t}\n+\n+\t@VisibleForTesting\n+\tOptional<Set<String>> getSchedulerResourceTypeNamesUnsafe(final Object response) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82d5dd9966f887470f20377d618c78a88f25dd82"}, "originalPosition": 92}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTYyNDM5MA==", "bodyText": "Either annotate with @Nullable and add the corresponding null checks or initialize with a mock WorkerSpecContainerResourceAdapter which fails on every call with an exception saying that the RM has not been properly initialized.", "url": "https://github.com/apache/flink/pull/11353#discussion_r409624390", "createdAt": "2020-04-16T14:56:52Z", "author": {"login": "tillrohrmann"}, "path": "flink-yarn/src/main/java/org/apache/flink/yarn/YarnResourceManager.java", "diffHunk": "@@ -117,7 +118,9 @@\n \t/** Client to communicate with the Node manager and launch TaskExecutor processes. */\n \tprivate NMClientAsync nodeManagerClient;\n \n-\tprivate final WorkerSpecContainerResourceAdapter workerSpecContainerResourceAdapter;\n+\tprivate WorkerSpecContainerResourceAdapter workerSpecContainerResourceAdapter = null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82d5dd9966f887470f20377d618c78a88f25dd82"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTYyNzY0Nw==", "bodyText": "Instead of calling private methods of the RegisterApplicationMasterResponseReflector we could also add an assumeTrue statement based on the Hadoop version. Then we can have two tests for Hadoop >= 2.6 and < 2.6.", "url": "https://github.com/apache/flink/pull/11353#discussion_r409627647", "createdAt": "2020-04-16T15:00:53Z", "author": {"login": "tillrohrmann"}, "path": "flink-yarn/src/test/java/org/apache/flink/yarn/RegisterApplicationMasterResponseReflectorTest.java", "diffHunk": "@@ -88,7 +94,44 @@ public void testGetMethodReflectiveHadoop22() {\n \t\tfinal RegisterApplicationMasterResponseReflector registerApplicationMasterResponseReflector =\n \t\t\tnew RegisterApplicationMasterResponseReflector(LOG);\n \n-\t\tfinal Method method = registerApplicationMasterResponseReflector.getMethod();\n+\t\tfinal Method method = registerApplicationMasterResponseReflector.getGetContainersFromPreviousAttemptsMethod();\n+\t\tassertThat(method, notNullValue());\n+\t}\n+\n+\t@Test\n+\tpublic void testCallsGetSchedulerResourceTypesMethodIfPresent() {\n+\t\tfinal RegisterApplicationMasterResponseReflector registerApplicationMasterResponseReflector =\n+\t\t\tnew RegisterApplicationMasterResponseReflector(LOG, HasMethod.class);\n+\n+\t\tfinal Optional<Set<String>> schedulerResourceTypeNames =\n+\t\t\tregisterApplicationMasterResponseReflector.getSchedulerResourceTypeNamesUnsafe(new HasMethod());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82d5dd9966f887470f20377d618c78a88f25dd82"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTYzMDM3Nw==", "bodyText": "An idea to keep the WorkerSpecContainerResourceAdapter final is to pass in the WorkerSpecContainerResourceAdapter.MatchingStrategy to the method getWorkerSpecs. If you look at the WorkerSpecContainerResourceAdapter class then one also sees that the matching strategy is not really an essential part of it. Only the lookup method changes its behaviour based on it. Everything else stays the same.", "url": "https://github.com/apache/flink/pull/11353#discussion_r409630377", "createdAt": "2020-04-16T15:04:23Z", "author": {"login": "tillrohrmann"}, "path": "flink-yarn/src/main/java/org/apache/flink/yarn/YarnResourceManager.java", "diffHunk": "@@ -117,7 +118,9 @@\n \t/** Client to communicate with the Node manager and launch TaskExecutor processes. */\n \tprivate NMClientAsync nodeManagerClient;\n \n-\tprivate final WorkerSpecContainerResourceAdapter workerSpecContainerResourceAdapter;\n+\tprivate WorkerSpecContainerResourceAdapter workerSpecContainerResourceAdapter = null;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTYyNDM5MA=="}, "originalCommit": {"oid": "82d5dd9966f887470f20377d618c78a88f25dd82"}, "originalPosition": 13}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "220c5fac2e7eefb4776f0909ebce640186301309", "author": {"user": {"login": "xintongsong", "name": "Xintong Song"}}, "url": "https://github.com/apache/flink/commit/220c5fac2e7eefb4776f0909ebce640186301309", "committedDate": "2020-04-13T02:06:27Z", "message": "[hotfix] Fix PerJobMiniClusterFactory does not properly calculate numSlotsPerTaskManager."}, "afterCommit": {"oid": "c4edf089b07a5a95a8cc53c6a32bd98ff3f7dde0", "author": {"user": {"login": "xintongsong", "name": "Xintong Song"}}, "url": "https://github.com/apache/flink/commit/c4edf089b07a5a95a8cc53c6a32bd98ff3f7dde0", "committedDate": "2020-04-19T09:51:50Z", "message": "[FLINK-16438][yarn] Decide WorkerSpecContainerResourceAdapter.MatchingStrategy based on RegisterApplicationMasterResponse."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk2NTMwMjI4", "url": "https://github.com/apache/flink/pull/11353#pullrequestreview-396530228", "createdAt": "2020-04-20T14:52:52Z", "commit": {"oid": "c4edf089b07a5a95a8cc53c6a32bd98ff3f7dde0"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c4edf089b07a5a95a8cc53c6a32bd98ff3f7dde0", "author": {"user": {"login": "xintongsong", "name": "Xintong Song"}}, "url": "https://github.com/apache/flink/commit/c4edf089b07a5a95a8cc53c6a32bd98ff3f7dde0", "committedDate": "2020-04-19T09:51:50Z", "message": "[FLINK-16438][yarn] Decide WorkerSpecContainerResourceAdapter.MatchingStrategy based on RegisterApplicationMasterResponse."}, "afterCommit": {"oid": "d3311198b6bdb3067daaede3847e73c9d2b2496e", "author": {"user": {"login": "xintongsong", "name": "Xintong Song"}}, "url": "https://github.com/apache/flink/commit/d3311198b6bdb3067daaede3847e73c9d2b2496e", "committedDate": "2020-04-24T13:58:53Z", "message": "[FLINK-16438][yarn] Decide WorkerSpecContainerResourceAdapter.MatchingStrategy based on RegisterApplicationMasterResponse.\n\nThis closes #11353."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5d1c5ac910681356c57f129fcfaa0c37eb6eca11", "author": {"user": {"login": "xintongsong", "name": "Xintong Song"}}, "url": "https://github.com/apache/flink/commit/5d1c5ac910681356c57f129fcfaa0c37eb6eca11", "committedDate": "2020-04-25T13:31:25Z", "message": "[hotfix][k8s] Remove duplicated taskManagerMemoryMB from KubernetesTaskManagerParameters."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "83b71388187c82d29d8ba44e32a786642ec87ec5", "author": {"user": {"login": "xintongsong", "name": "Xintong Song"}}, "url": "https://github.com/apache/flink/commit/83b71388187c82d29d8ba44e32a786642ec87ec5", "committedDate": "2020-04-25T13:31:25Z", "message": "[hotfix][k8s][test] Allowing custom slot manager in KubernetesResourceManagerTest."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "78603b37601598568a26adf4e01a89f5eea3ad7d", "author": {"user": {"login": "xintongsong", "name": "Xintong Song"}}, "url": "https://github.com/apache/flink/commit/78603b37601598568a26adf4e01a89f5eea3ad7d", "committedDate": "2020-04-25T13:31:26Z", "message": "[FLINK-16439][runtime] Introduce PendingWorkerCounter for counting pending workers per WorkerResourceSpec in ActiveResourceManager."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "98e8b0e6f9bef21b4e740cf1ade18e9ec3df0b24", "author": {"user": {"login": "xintongsong", "name": "Xintong Song"}}, "url": "https://github.com/apache/flink/commit/98e8b0e6f9bef21b4e740cf1ade18e9ec3df0b24", "committedDate": "2020-04-25T13:31:26Z", "message": "[FLINK-16439][k8s] KubernetesResourceManager starts workers with resources requested by SlotManager.\n\nThis means KubernetesResourceManager no longer:\n- be aware of the default task executor resources\n- assumes all workers are identical\n\nThis closes #11323."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8882b86566c51dc0161757b951f3af711e76c6d3", "author": {"user": {"login": "xintongsong", "name": "Xintong Song"}}, "url": "https://github.com/apache/flink/commit/8882b86566c51dc0161757b951f3af711e76c6d3", "committedDate": "2020-04-25T13:31:26Z", "message": "[hotfix][runtime][k8s] Renaming methods for better code readability."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bdd39782cdf6eade8adfb7fb28dbc3824bc6e3a2", "author": {"user": {"login": "xintongsong", "name": "Xintong Song"}}, "url": "https://github.com/apache/flink/commit/bdd39782cdf6eade8adfb7fb28dbc3824bc6e3a2", "committedDate": "2020-04-25T13:31:26Z", "message": "[hotfix][yarn][test] Avoid using Mockito for Container in YarnResourceManagerTest."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8b2376ac603170bbb9bf804fce2cb97a3b73fac7", "author": {"user": {"login": "xintongsong", "name": "Xintong Song"}}, "url": "https://github.com/apache/flink/commit/8b2376ac603170bbb9bf804fce2cb97a3b73fac7", "committedDate": "2020-04-25T13:31:26Z", "message": "[hotfix][yarn][test] Avoid using Mockito for ContainerStatus in YarnResourceManagerTest."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "16a84fdcb9f2ba7216f989bcce88522830a31d51", "author": {"user": {"login": "xintongsong", "name": "Xintong Song"}}, "url": "https://github.com/apache/flink/commit/16a84fdcb9f2ba7216f989bcce88522830a31d51", "committedDate": "2020-04-25T13:31:27Z", "message": "[hotfix][yarn][test] Avoid using Mockito for AMRMClientAsync in YarnResourceManagerTest."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a864a8e89eaeb2f5363f1991c7339f7ddae7426f", "author": {"user": {"login": "xintongsong", "name": "Xintong Song"}}, "url": "https://github.com/apache/flink/commit/a864a8e89eaeb2f5363f1991c7339f7ddae7426f", "committedDate": "2020-04-25T13:31:27Z", "message": "[hotfix][yarn][test] Avoid using Mockito for NMClientAsync in YarnResourceManagerTest."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "47025f716c4b303aa707653f46420277174c9455", "author": {"user": {"login": "xintongsong", "name": "Xintong Song"}}, "url": "https://github.com/apache/flink/commit/47025f716c4b303aa707653f46420277174c9455", "committedDate": "2020-04-25T13:31:27Z", "message": "[hotfix][yarn][test] Avoid using Mockito for TaskExecutorGateway in YarnResourceManagerTest."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8380081e59939cc1b481aacb94a1299647d0cc9e", "author": {"user": {"login": "xintongsong", "name": "Xintong Song"}}, "url": "https://github.com/apache/flink/commit/8380081e59939cc1b481aacb94a1299647d0cc9e", "committedDate": "2020-04-25T13:31:27Z", "message": "[hotfix][yarn] Code clean-ups in RegisterApplicationMasterResponseReflectorTest."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a91057f02ae2acf412afa5b501a4c378e583e2a3", "author": {"user": {"login": "xintongsong", "name": "Xintong Song"}}, "url": "https://github.com/apache/flink/commit/a91057f02ae2acf412afa5b501a4c378e583e2a3", "committedDate": "2020-04-25T13:31:27Z", "message": "[FLINK-16438][yarn] Introduce WorkerSpecContainerResourceAdapter for converting between Flink WorkerResourceSpec and Yarn container Resource in YarnResourceManager."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f0193565c33dea816be14f859ca8c02b034ec617", "author": {"user": {"login": "xintongsong", "name": "Xintong Song"}}, "url": "https://github.com/apache/flink/commit/f0193565c33dea816be14f859ca8c02b034ec617", "committedDate": "2020-04-25T13:31:27Z", "message": "[FLINK-16438][yarn] YarnResourceManager starts workers with resources requested by SlotManager.\n\nThis means YarnResourceManager no longer:\n- be aware of the default task executor resources\n- assumes all workers are identical"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "03da1cf6475a969256e2adf4f2acc97ac169a227", "author": {"user": {"login": "xintongsong", "name": "Xintong Song"}}, "url": "https://github.com/apache/flink/commit/03da1cf6475a969256e2adf4f2acc97ac169a227", "committedDate": "2020-04-25T13:31:28Z", "message": "[FLINK-16438][runtime] Remove unused TaskExecutorProcessSpec from ActiveResourceManager."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "65e43b823a71c277e5abaa324672f39c1918b49a", "author": {"user": {"login": "xintongsong", "name": "Xintong Song"}}, "url": "https://github.com/apache/flink/commit/65e43b823a71c277e5abaa324672f39c1918b49a", "committedDate": "2020-04-25T13:31:28Z", "message": "[FLINK-16438][yarn] Decide WorkerSpecContainerResourceAdapter.MatchingStrategy based on RegisterApplicationMasterResponse.\n\nThis closes #11353."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d3311198b6bdb3067daaede3847e73c9d2b2496e", "author": {"user": {"login": "xintongsong", "name": "Xintong Song"}}, "url": "https://github.com/apache/flink/commit/d3311198b6bdb3067daaede3847e73c9d2b2496e", "committedDate": "2020-04-24T13:58:53Z", "message": "[FLINK-16438][yarn] Decide WorkerSpecContainerResourceAdapter.MatchingStrategy based on RegisterApplicationMasterResponse.\n\nThis closes #11353."}, "afterCommit": {"oid": "65e43b823a71c277e5abaa324672f39c1918b49a", "author": {"user": {"login": "xintongsong", "name": "Xintong Song"}}, "url": "https://github.com/apache/flink/commit/65e43b823a71c277e5abaa324672f39c1918b49a", "committedDate": "2020-04-25T13:31:28Z", "message": "[FLINK-16438][yarn] Decide WorkerSpecContainerResourceAdapter.MatchingStrategy based on RegisterApplicationMasterResponse.\n\nThis closes #11353."}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3183, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}