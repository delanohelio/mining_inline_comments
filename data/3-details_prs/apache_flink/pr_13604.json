{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTAxOTk2NTc3", "number": 13604, "title": "[FLINK-19585][tests] Waiting for job to run before savepointing in UnalignedCheckpointCompatibilityITCase.", "bodyText": "What is the purpose of the change\nFixes UnalignedCheckpointCompatibilityITCase.test:97->runAndTakeSavepoint: \"Not all required tasks are currently running.\", which may be caused when deploying takes longer than expected, such that stopWithSavepoint is called before everything is running.\nBrief change log\n\nAllow savepoints to be used in MiniCluster.\nUse JobDetailsInfo to ensure that job and all tasks are running.\n\nVerifying this change\nFixes test failure.\nDoes this pull request potentially affect one of the following parts:\n\nDependencies (does it add or upgrade a dependency): (yes / no)\nThe public API, i.e., is any changed class annotated with @Public(Evolving): (yes / no)\nThe serializers: (yes / no / don't know)\nThe runtime per-record code paths (performance sensitive): (yes / no / don't know)\nAnything that affects deployment or recovery: JobManager (and its components), Checkpointing, Kubernetes/Yarn/Mesos, ZooKeeper: (yes / no / don't know)\nThe S3 file system connector: (yes / no / don't know)\n\nDocumentation\n\nDoes this pull request introduce a new feature? (yes / no)\nIf yes, how is the feature documented? (not applicable / docs / JavaDocs / not documented)", "createdAt": "2020-10-13T05:38:50Z", "url": "https://github.com/apache/flink/pull/13604", "merged": true, "mergeCommit": {"oid": "02177a2b33a75e70925e29c8f268135adb85347c"}, "closed": true, "closedAt": "2020-10-16T14:26:08Z", "author": {"login": "AHeise"}, "timelineItems": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdSP8gMABqjM4NzM3NjQ4ODU=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdSuDy3gBqjM4ODA0MjM3MDU=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d37db71a8713a6f475e58195eaaaca6645d70dcf", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/d37db71a8713a6f475e58195eaaaca6645d70dcf", "committedDate": "2020-10-13T05:36:07Z", "message": "[FLINK-19585][tests] Waiting for job to run before savepointing in UnalignedCheckpointCompatibilityITCase."}, "afterCommit": {"oid": "a7dfc27d1536928c114b7e065865fb5e156a7f65", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/a7dfc27d1536928c114b7e065865fb5e156a7f65", "committedDate": "2020-10-13T22:02:11Z", "message": "[FLINK-19585][minicluster] Use SavepointRestoreSettings of StreamGraph while creating JobGraph."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a7dfc27d1536928c114b7e065865fb5e156a7f65", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/a7dfc27d1536928c114b7e065865fb5e156a7f65", "committedDate": "2020-10-13T22:02:11Z", "message": "[FLINK-19585][minicluster] Use SavepointRestoreSettings of StreamGraph while creating JobGraph."}, "afterCommit": {"oid": "f8b8123bdb849188383542ba20927f2118a34c70", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/f8b8123bdb849188383542ba20927f2118a34c70", "committedDate": "2020-10-14T06:39:43Z", "message": "[FLINK-19585][minicluster] Use SavepointRestoreSettings of StreamGraph while creating JobGraph."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f8b8123bdb849188383542ba20927f2118a34c70", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/f8b8123bdb849188383542ba20927f2118a34c70", "committedDate": "2020-10-14T06:39:43Z", "message": "[FLINK-19585][minicluster] Use SavepointRestoreSettings of StreamGraph while creating JobGraph."}, "afterCommit": {"oid": "755d9eb83e7fa1f497fe083850ce369d8d1d5940", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/755d9eb83e7fa1f497fe083850ce369d8d1d5940", "committedDate": "2020-10-14T06:51:47Z", "message": "[FLINK-19585][tests] Waiting for all tasks to run before savepointing in UnalignedCheckpointCompatibilityITCase."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f573014ea1efca40fbd14f2880fd7ce922559dc9", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/f573014ea1efca40fbd14f2880fd7ce922559dc9", "committedDate": "2020-10-14T06:56:04Z", "message": "[FLINK-19585][minicluster] Use SavepointRestoreSettings of StreamGraph while creating JobGraph.\n\nThere is currently no way to start from savepoints while using MiniCluster. The cluster config cannot be used (and would be a mismatch) because it's overridden by MiniClusterPipelineExecutorServiceLoader#createConfiguration.\nHowever, the jobgraph that is being generated in MiniClusterPipelineExecutorServiceLoader#MiniClusterExecutor only uses this configuration to translate the Pipeline/StreamGraph. In production code, savepoint restore settings are usually applied last and taken from the StreamGraph."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA4NDUwOTg2", "url": "https://github.com/apache/flink/pull/13604#pullrequestreview-508450986", "createdAt": "2020-10-14T15:08:55Z", "commit": {"oid": "755d9eb83e7fa1f497fe083850ce369d8d1d5940"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQxNTowODo1NlrOHhX5Pw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQxNTozNjowMFrOHhZKjg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc1NjU0Mw==", "bodyText": "It's generally an anti-pattern in tests to \"just sleep for a while\". Can't you use the backpressure monitoring to wait until there is backpressure? (or would that take longer?)", "url": "https://github.com/apache/flink/pull/13604#discussion_r504756543", "createdAt": "2020-10-14T15:08:56Z", "author": {"login": "rmetzger"}, "path": "flink-tests/src/test/java/org/apache/flink/test/checkpointing/UnalignedCheckpointCompatibilityITCase.java", "diffHunk": "@@ -107,28 +119,55 @@ public void test() throws Exception {\n \t}\n \n \tprivate Tuple2<String, Map<String, Object>> runAndTakeSavepoint() throws Exception {\n-\t\tJobClient jobClient = submitJobInitially(env(startAligned, 0, emptyMap()));\n-\t\tThread.sleep(FIRST_RUN_EL_COUNT * FIRST_RUN_BACKPRESSURE_MS); // wait for all tasks to run and some backpressure from sink\n-\t\tFuture<Map<String, Object>> accFuture = jobClient.getAccumulators();\n-\t\tFuture<String> savepointFuture = jobClient.stopWithSavepoint(false, tempFolder().toURI().toString());\n-\t\treturn new Tuple2<>(savepointFuture.get(), accFuture.get());\n+\t\treturn withCluster(new Configuration(), miniCluster -> {\n+\t\t\tJobClient jobClient = submitJobInitially(env(startAligned, 0));\n+\t\t\twaitForAllTaskRunning(miniCluster, jobClient.getJobID(), Deadline.fromNow(Duration.of(30, ChronoUnit.SECONDS)));\n+\t\t\tThread.sleep(FIRST_RUN_BACKPRESSURE_MS); // wait for some backpressure from sink", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "755d9eb83e7fa1f497fe083850ce369d8d1d5940"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc2MjQ4NA==", "bodyText": "Why are you not reusing the cluster for the different tests / jobs?", "url": "https://github.com/apache/flink/pull/13604#discussion_r504762484", "createdAt": "2020-10-14T15:16:37Z", "author": {"login": "rmetzger"}, "path": "flink-tests/src/test/java/org/apache/flink/test/checkpointing/UnalignedCheckpointCompatibilityITCase.java", "diffHunk": "@@ -107,28 +119,55 @@ public void test() throws Exception {\n \t}\n \n \tprivate Tuple2<String, Map<String, Object>> runAndTakeSavepoint() throws Exception {\n-\t\tJobClient jobClient = submitJobInitially(env(startAligned, 0, emptyMap()));\n-\t\tThread.sleep(FIRST_RUN_EL_COUNT * FIRST_RUN_BACKPRESSURE_MS); // wait for all tasks to run and some backpressure from sink\n-\t\tFuture<Map<String, Object>> accFuture = jobClient.getAccumulators();\n-\t\tFuture<String> savepointFuture = jobClient.stopWithSavepoint(false, tempFolder().toURI().toString());\n-\t\treturn new Tuple2<>(savepointFuture.get(), accFuture.get());\n+\t\treturn withCluster(new Configuration(), miniCluster -> {\n+\t\t\tJobClient jobClient = submitJobInitially(env(startAligned, 0));\n+\t\t\twaitForAllTaskRunning(miniCluster, jobClient.getJobID(), Deadline.fromNow(Duration.of(30, ChronoUnit.SECONDS)));\n+\t\t\tThread.sleep(FIRST_RUN_BACKPRESSURE_MS); // wait for some backpressure from sink\n+\n+\t\t\tFuture<Map<String, Object>> accFuture = jobClient.getAccumulators();\n+\t\t\tFuture<String> savepointFuture = jobClient.stopWithSavepoint(false, tempFolder().toURI().toString());\n+\t\t\treturn new Tuple2<>(savepointFuture.get(), accFuture.get());\n+\t\t});\n \t}\n \n \tprivate Tuple2<String, Map<String, Object>> runAndTakeExternalCheckpoint() throws Exception {\n \t\tFile folder = tempFolder();\n-\t\tJobClient jobClient = submitJobInitially(externalCheckpointEnv(startAligned, folder, 100));\n-\t\tFile metadata = waitForChild(waitForChild(waitForChild(folder))); // structure: root/attempt/checkpoint/_metadata\n-\t\tcancelJob(jobClient);\n-\t\treturn new Tuple2<>(metadata.getParentFile().toString(), emptyMap());\n+\t\tfinal Configuration conf = new Configuration();\n+\t\tconf.set(CHECKPOINTS_DIRECTORY, folder.toURI().toString());\n+\t\t// prevent deletion of checkpoint files while it's being checked and used\n+\t\tconf.set(MAX_RETAINED_CHECKPOINTS, Integer.MAX_VALUE);\n+\t\treturn withCluster(conf,\n+\t\t\tminiCluster -> {\n+\t\t\t\tJobClient jobClient = submitJobInitially(externalCheckpointEnv(startAligned, 100));\n+\t\t\t\tFile metadata = waitForChild(waitForChild(waitForChild(folder))); // structure: root/attempt/checkpoint/_metadata\n+\t\t\t\tcancelJob(jobClient);\n+\t\t\t\treturn new Tuple2<>(metadata.getParentFile().toString(), emptyMap());\n+\t\t\t});\n \t}\n \n \tprivate static JobClient submitJobInitially(StreamExecutionEnvironment env) throws Exception {\n \t\treturn env.executeAsync(dag(FIRST_RUN_EL_COUNT, true, FIRST_RUN_BACKPRESSURE_MS, env));\n \t}\n \n \tprivate Map<String, Object> runFromSavepoint(String path, boolean isAligned, int totalCount) throws Exception {\n-\t\tStreamExecutionEnvironment env = env(isAligned, 50, Collections.singletonMap(SAVEPOINT_PATH, path));\n-\t\treturn env.execute(dag(totalCount, false, 0, env)).getJobExecutionResult().getAllAccumulatorResults();\n+\t\treturn withCluster(new Configuration(), miniCluster -> {\n+\t\t\tStreamExecutionEnvironment env = env(isAligned, 50);\n+\t\t\tfinal StreamGraph streamGraph = dag(totalCount, false, 0, env);\n+\t\t\tstreamGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(path));\n+\t\t\treturn env.execute(streamGraph).getJobExecutionResult().getAllAccumulatorResults();\n+\t\t});\n+\t}\n+\n+\tprivate <T> T withCluster(Configuration configuration,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "755d9eb83e7fa1f497fe083850ce369d8d1d5940"}, "originalPosition": 111}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc3NzA2OA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \tpublic static void waitForAllTaskRunning(MiniClusterResource miniCluster, JobID jobID, Deadline deadline) throws Exception {\n          \n          \n            \n            \t\ttry (final RestClusterClient<?> clusterClient = new RestClusterClient<Object>(\n          \n          \n            \n            \t\t\t\tminiCluster.getClientConfiguration(),\n          \n          \n            \n            \t\t\t\tStandaloneClusterId.getInstance())) {\n          \n          \n            \n            \t\t\tJobMessageParameters params = new JobMessageParameters();\n          \n          \n            \n            \t\t\tparams.jobPathParameter.resolve(jobID);\n          \n          \n            \n            \t\t\torg.apache.flink.runtime.testutils.CommonTestUtils.waitUntilCondition(() -> {\n          \n          \n            \n            \t\t\t\tfinal JobDetailsInfo jobDetailsInfo = clusterClient.sendRequest(\n          \n          \n            \n            \t\t\t\t\tJobDetailsHeaders.getInstance(),\n          \n          \n            \n            \t\t\t\t\tparams,\n          \n          \n            \n            \t\t\t\t\tEmptyRequestBody.getInstance()).get();\n          \n          \n            \n            \t\t\t\treturn jobDetailsInfo.getJobStatus() == JobStatus.RUNNING &&\n          \n          \n            \n            \t\t\t\t\tjobDetailsInfo.getJobVerticesPerState().get(ExecutionState.RUNNING) ==\n          \n          \n            \n            \t\t\t\t\t\tjobDetailsInfo.getJobVertexInfos().size();\n          \n          \n            \n            \t\t\t}, deadline, 500);\n          \n          \n            \n            \t\t}\n          \n          \n            \n            \t}\n          \n          \n            \n            \tpublic static void waitForAllTaskRunning(MiniCluster miniCluster, JobID jobID, Deadline deadline) throws Exception {\n          \n          \n            \n            \t\torg.apache.flink.runtime.testutils.CommonTestUtils.waitUntilCondition(() -> {\n          \n          \n            \n            \t\t\tAccessExecutionGraph ec = miniCluster.getExecutionGraph(jobID).get();\n          \n          \n            \n            \t\t\treturn ec.getState() == JobStatus.RUNNING && ec.getAllVertices()\n          \n          \n            \n            \t\t\t\t.values()\n          \n          \n            \n            \t\t\t\t.stream()\n          \n          \n            \n            \t\t\t\t.allMatch(jobVertex ->\n          \n          \n            \n            \t\t\t\t\tArrays.stream(jobVertex.getTaskVertices()).allMatch(task -> task.getExecutionState() == ExecutionState.RUNNING)\n          \n          \n            \n            \t\t\t\t);\n          \n          \n            \n            \t\t}, deadline);\n          \n          \n            \n            \t}", "url": "https://github.com/apache/flink/pull/13604#discussion_r504777068", "createdAt": "2020-10-14T15:35:36Z", "author": {"login": "rmetzger"}, "path": "flink-test-utils-parent/flink-test-utils/src/main/java/org/apache/flink/test/util/TestBaseUtils.java", "diffHunk": "@@ -102,6 +116,24 @@ private static void verifyJvmOptions() {\n \t\t\t\t+ \"m\", heap > MINIMUM_HEAP_SIZE_MB - 50);\n \t}\n \n+\tpublic static void waitForAllTaskRunning(MiniClusterResource miniCluster, JobID jobID, Deadline deadline) throws Exception {\n+\t\ttry (final RestClusterClient<?> clusterClient = new RestClusterClient<Object>(\n+\t\t\t\tminiCluster.getClientConfiguration(),\n+\t\t\t\tStandaloneClusterId.getInstance())) {\n+\t\t\tJobMessageParameters params = new JobMessageParameters();\n+\t\t\tparams.jobPathParameter.resolve(jobID);\n+\t\t\torg.apache.flink.runtime.testutils.CommonTestUtils.waitUntilCondition(() -> {\n+\t\t\t\tfinal JobDetailsInfo jobDetailsInfo = clusterClient.sendRequest(\n+\t\t\t\t\tJobDetailsHeaders.getInstance(),\n+\t\t\t\t\tparams,\n+\t\t\t\t\tEmptyRequestBody.getInstance()).get();\n+\t\t\t\treturn jobDetailsInfo.getJobStatus() == JobStatus.RUNNING &&\n+\t\t\t\t\tjobDetailsInfo.getJobVerticesPerState().get(ExecutionState.RUNNING) ==\n+\t\t\t\t\t\tjobDetailsInfo.getJobVertexInfos().size();\n+\t\t\t}, deadline, 500);\n+\t\t}\n+\t}\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "755d9eb83e7fa1f497fe083850ce369d8d1d5940"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc3NzM1OA==", "bodyText": "Not sure about the code formatting, and I haven't tested it much. But I guess you get the idea.", "url": "https://github.com/apache/flink/pull/13604#discussion_r504777358", "createdAt": "2020-10-14T15:36:00Z", "author": {"login": "rmetzger"}, "path": "flink-test-utils-parent/flink-test-utils/src/main/java/org/apache/flink/test/util/TestBaseUtils.java", "diffHunk": "@@ -102,6 +116,24 @@ private static void verifyJvmOptions() {\n \t\t\t\t+ \"m\", heap > MINIMUM_HEAP_SIZE_MB - 50);\n \t}\n \n+\tpublic static void waitForAllTaskRunning(MiniClusterResource miniCluster, JobID jobID, Deadline deadline) throws Exception {\n+\t\ttry (final RestClusterClient<?> clusterClient = new RestClusterClient<Object>(\n+\t\t\t\tminiCluster.getClientConfiguration(),\n+\t\t\t\tStandaloneClusterId.getInstance())) {\n+\t\t\tJobMessageParameters params = new JobMessageParameters();\n+\t\t\tparams.jobPathParameter.resolve(jobID);\n+\t\t\torg.apache.flink.runtime.testutils.CommonTestUtils.waitUntilCondition(() -> {\n+\t\t\t\tfinal JobDetailsInfo jobDetailsInfo = clusterClient.sendRequest(\n+\t\t\t\t\tJobDetailsHeaders.getInstance(),\n+\t\t\t\t\tparams,\n+\t\t\t\t\tEmptyRequestBody.getInstance()).get();\n+\t\t\t\treturn jobDetailsInfo.getJobStatus() == JobStatus.RUNNING &&\n+\t\t\t\t\tjobDetailsInfo.getJobVerticesPerState().get(ExecutionState.RUNNING) ==\n+\t\t\t\t\t\tjobDetailsInfo.getJobVertexInfos().size();\n+\t\t\t}, deadline, 500);\n+\t\t}\n+\t}\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc3NzA2OA=="}, "originalCommit": {"oid": "755d9eb83e7fa1f497fe083850ce369d8d1d5940"}, "originalPosition": 54}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "755d9eb83e7fa1f497fe083850ce369d8d1d5940", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/755d9eb83e7fa1f497fe083850ce369d8d1d5940", "committedDate": "2020-10-14T06:51:47Z", "message": "[FLINK-19585][tests] Waiting for all tasks to run before savepointing in UnalignedCheckpointCompatibilityITCase."}, "afterCommit": {"oid": "2ae2677fac9f1e1fadcef3f236191950c23f82a1", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/2ae2677fac9f1e1fadcef3f236191950c23f82a1", "committedDate": "2020-10-14T19:45:48Z", "message": "[FLINK-19585][tests] Waiting for all tasks to run before savepointing in UnalignedCheckpointCompatibilityITCase."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "2ae2677fac9f1e1fadcef3f236191950c23f82a1", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/2ae2677fac9f1e1fadcef3f236191950c23f82a1", "committedDate": "2020-10-14T19:45:48Z", "message": "[FLINK-19585][tests] Waiting for all tasks to run before savepointing in UnalignedCheckpointCompatibilityITCase."}, "afterCommit": {"oid": "493263a69146fe8c801c25febbb5e972634f9379", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/493263a69146fe8c801c25febbb5e972634f9379", "committedDate": "2020-10-14T19:47:58Z", "message": "[FLINK-19585][tests] Waiting for all tasks to run before savepointing in UnalignedCheckpointCompatibilityITCase."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA4Njg3NjYz", "url": "https://github.com/apache/flink/pull/13604#pullrequestreview-508687663", "createdAt": "2020-10-14T20:05:14Z", "commit": {"oid": "493263a69146fe8c801c25febbb5e972634f9379"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2c46ee38b46372ba7e5fbe33d186b29b39a2a0e1", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/2c46ee38b46372ba7e5fbe33d186b29b39a2a0e1", "committedDate": "2020-10-15T09:03:15Z", "message": "[FLINK-19585][tests] Waiting for all tasks to run before savepointing in UnalignedCheckpointCompatibilityITCase."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "493263a69146fe8c801c25febbb5e972634f9379", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/493263a69146fe8c801c25febbb5e972634f9379", "committedDate": "2020-10-14T19:47:58Z", "message": "[FLINK-19585][tests] Waiting for all tasks to run before savepointing in UnalignedCheckpointCompatibilityITCase."}, "afterCommit": {"oid": "2c46ee38b46372ba7e5fbe33d186b29b39a2a0e1", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/2c46ee38b46372ba7e5fbe33d186b29b39a2a0e1", "committedDate": "2020-10-15T09:03:15Z", "message": "[FLINK-19585][tests] Waiting for all tasks to run before savepointing in UnalignedCheckpointCompatibilityITCase."}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3190, "cost": 1, "resetAt": "2021-10-28T16:48:13Z"}}}