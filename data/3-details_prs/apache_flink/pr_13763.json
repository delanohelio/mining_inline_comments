{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTA4Nzg5NjEy", "number": 13763, "title": "[FLINK-19779][avro] Remove the record_ field name prefix for Confluen\u2026", "bodyText": "\u2026t Avro format deserialization\nWhat is the purpose of the change\nAdd prefix for the field name only when the record and field have the same name.\nBrief change log\n\nModify AvroSchemaConverter.convertToSchema to only append field prefix when the record and field have the same name\nModify the existing test\n\nVerifying this change\nAdded UT.\nDoes this pull request potentially affect one of the following parts:\n\nDependencies (does it add or upgrade a dependency): no\nThe public API, i.e., is any changed class annotated with @Public(Evolving): no\nThe serializers: no\nThe runtime per-record code paths (performance sensitive): no\nAnything that affects deployment or recovery: JobManager (and its components), Checkpointing, Kubernetes/Yarn/Mesos, ZooKeeper: no\nThe S3 file system connector: no\n\nDocumentation\n\nDoes this pull request introduce a new feature? no", "createdAt": "2020-10-23T07:56:31Z", "url": "https://github.com/apache/flink/pull/13763", "merged": true, "mergeCommit": {"oid": "146269db821f975af65b61f7dde8720591abdda6"}, "closed": true, "closedAt": "2020-10-29T15:54:33Z", "author": {"login": "danny0405"}, "timelineItems": {"totalCount": 17, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdVTmAKgFqTUxNTUyMDA3MA==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdXTkqUAFqTUxOTc2NTMyNQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE1NTIwMDcw", "url": "https://github.com/apache/flink/pull/13763#pullrequestreview-515520070", "createdAt": "2020-10-23T09:59:21Z", "commit": {"oid": "b92a32d37a8eaa446f24f44e467e588cdabcd9f5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yM1QwOTo1OToyMVrOHnHLHA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yM1QwOTo1OToyMVrOHnHLHA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDc3NDA0NA==", "bodyText": "I think there is still existed a bug. see: https://issues.apache.org/jira/browse/FLINK-19779?focusedCommentId=17219588&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-17219588", "url": "https://github.com/apache/flink/pull/13763#discussion_r510774044", "createdAt": "2020-10-23T09:59:21Z", "author": {"login": "V1ncentzzZ"}, "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java", "diffHunk": "@@ -362,7 +369,11 @@ public static Schema convertToSchema(LogicalType logicalType, String rowName) {\n \t\t\t\t\t.record(rowName)\n \t\t\t\t\t.fields();\n \t\t\t\tfor (int i = 0; i < rowType.getFieldCount(); i++) {\n-\t\t\t\t\tString fieldName = rowName + \"_\" + fieldNames.get(i);\n+\t\t\t\t\tString fieldName = fieldNames.get(i);\n+\t\t\t\t\tif (rowName.equals(fieldName)) {\n+\t\t\t\t\t\t// Can not build schema when the record and field have the same name\n+\t\t\t\t\t\tfieldName = rowName + \"_\" + fieldName;\n+\t\t\t\t\t}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b92a32d37a8eaa446f24f44e467e588cdabcd9f5"}, "originalPosition": 23}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b92a32d37a8eaa446f24f44e467e588cdabcd9f5", "author": {"user": {"login": "danny0405", "name": "Danny Chan"}}, "url": "https://github.com/apache/flink/commit/b92a32d37a8eaa446f24f44e467e588cdabcd9f5", "committedDate": "2020-10-23T07:53:36Z", "message": "[FLINK-19779][avro] Remove the record_ field name prefix for Confluent Avro format deserialization"}, "afterCommit": {"oid": "6ef138838f1a4a0b45a42eff39b75847c9b39767", "author": {"user": {"login": "danny0405", "name": "Danny Chan"}}, "url": "https://github.com/apache/flink/commit/6ef138838f1a4a0b45a42eff39b75847c9b39767", "committedDate": "2020-10-26T07:48:00Z", "message": "[FLINK-19779][avro] Remove the record_ field name prefix for Confluent Avro format deserialization\n\n* Add prefix for the field name only when the record and field have the\n  same name\n* Fix the nullability and precision during data type and Avro schema\n  conversion"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE2NjIyNDYw", "url": "https://github.com/apache/flink/pull/13763#pullrequestreview-516622460", "createdAt": "2020-10-26T10:01:55Z", "commit": {"oid": "6ef138838f1a4a0b45a42eff39b75847c9b39767"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQxMDowMTo1NlrOHoIXnA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQxMzoyNDoxOFrOHoPRjA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTg0MjIwNA==", "bodyText": "Could we stick to a single way of declaring Schema nullable? With this PR we have two methods for the same purpose:\n\nnullableSchema\ngetNullableBuilder\n\nEither use the nullableSchema everywhere or use getNullableBuilder(...).type(...).", "url": "https://github.com/apache/flink/pull/13763#discussion_r511842204", "createdAt": "2020-10-26T10:01:56Z", "author": {"login": "dawidwys"}, "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java", "diffHunk": "@@ -417,4 +431,11 @@ public static LogicalType extractValueTypeToAvroMap(LogicalType type) {\n \t\t}\n \t\treturn builder;\n \t}\n+\n+\t/** Returns schema with nullable true. */\n+\tprivate static Schema nullableSchema(Schema schema) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6ef138838f1a4a0b45a42eff39b75847c9b39767"}, "originalPosition": 118}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTkzNTYwNw==", "bodyText": "That is not correct. The builder does support same names for fields in different nested levels.\nAvro in general does not support same record types with different schemas. And it does it rightly so. Therefore a schema like:\n{\n    \"type\": \"record\", \n    \"name\": \"top\", \n    \"fields\": [ \n\t\t  {\n             \"name\": \"top\", \n             \"type\": { \n                 \"type\": \"record\", \n                 \"name\": \"nested\", \n                 \"fields\": [ \n                     {\"type\": \"string\", \"name\": \"top\"} \n                 ]\n             }\n          }\n    ] \n}\n\nis valid and supported. However if we change the name of the nested record to top it will be invalid:\n{\n    \"type\": \"record\", \n    \"name\": \"top\", \n    \"fields\": [ \n\t\t  {\n             \"name\": \"top\", \n             \"type\": { \n                 \"type\": \"record\", \n                 \"name\": \"top\", \n                 \"fields\": [ \n                     {\"type\": \"string\", \"name\": \"top\"} \n                 ]\n             }\n          }\n    ] \n}\n\nI think the core problem lays in how the rowName is generated. I think we should never adjust the fieldName, but we should append the fieldName to the rowName.\nBTW another shortcoming that I see is that we are losing the record name when converting from Schema to DataType. I think it is not a real issue though.", "url": "https://github.com/apache/flink/pull/13763#discussion_r511935607", "createdAt": "2020-10-26T12:52:10Z", "author": {"login": "dawidwys"}, "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java", "diffHunk": "@@ -362,7 +369,11 @@ public static Schema convertToSchema(LogicalType logicalType, String rowName) {\n \t\t\t\t\t.record(rowName)\n \t\t\t\t\t.fields();\n \t\t\t\tfor (int i = 0; i < rowType.getFieldCount(); i++) {\n-\t\t\t\t\tString fieldName = rowName + \"_\" + fieldNames.get(i);\n+\t\t\t\t\tString fieldName = fieldNames.get(i);\n+\t\t\t\t\tif (rowName.equals(fieldName)) {\n+\t\t\t\t\t\t// Can not build schema when the record and field have the same name\n+\t\t\t\t\t\tfieldName = rowName + \"_\" + fieldName;\n+\t\t\t\t\t}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDc3NDA0NA=="}, "originalCommit": {"oid": "b92a32d37a8eaa446f24f44e467e588cdabcd9f5"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTk1NDM0NQ==", "bodyText": "I think the correct solution will be:\n\t\t\t\tRowType rowType = (RowType) logicalType;\n\t\t\t\tList<String> fieldNames = rowType.getFieldNames();\n\t\t\t\t// we have to make sure the record name is different in a Schema\n\t\t\t\tSchemaBuilder.FieldAssembler<Schema> builder =\n\t\t\t\t\t\tgetNullableBuilder(logicalType)\n\t\t\t\t\t\t\t\t.record(rowName)\n\t\t\t\t\t\t\t\t.fields();\n\t\t\t\tfor (int i = 0; i < rowType.getFieldCount(); i++) {\n\t\t\t\t\tString fieldName = fieldNames.get(i);\n\t\t\t\t\tbuilder = builder\n\t\t\t\t\t\t.name(fieldName)\n\t\t\t\t\t\t.type(convertToSchema(rowType.getTypeAt(i), rowName + \"_\" + fieldName))\n\t\t\t\t\t\t.noDefault();\n\t\t\t\t}\n\t\t\t\treturn builder.endRecord();", "url": "https://github.com/apache/flink/pull/13763#discussion_r511954345", "createdAt": "2020-10-26T13:22:43Z", "author": {"login": "dawidwys"}, "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java", "diffHunk": "@@ -362,7 +369,11 @@ public static Schema convertToSchema(LogicalType logicalType, String rowName) {\n \t\t\t\t\t.record(rowName)\n \t\t\t\t\t.fields();\n \t\t\t\tfor (int i = 0; i < rowType.getFieldCount(); i++) {\n-\t\t\t\t\tString fieldName = rowName + \"_\" + fieldNames.get(i);\n+\t\t\t\t\tString fieldName = fieldNames.get(i);\n+\t\t\t\t\tif (rowName.equals(fieldName)) {\n+\t\t\t\t\t\t// Can not build schema when the record and field have the same name\n+\t\t\t\t\t\tfieldName = rowName + \"_\" + fieldName;\n+\t\t\t\t\t}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDc3NDA0NA=="}, "originalCommit": {"oid": "b92a32d37a8eaa446f24f44e467e588cdabcd9f5"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTk1NTM0MA==", "bodyText": "I think it would be nice to add a test that we can convert back and forth between DataType and Schema in respect to the field names.", "url": "https://github.com/apache/flink/pull/13763#discussion_r511955340", "createdAt": "2020-10-26T13:24:18Z", "author": {"login": "dawidwys"}, "path": "flink-formats/flink-avro/src/test/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverterTest.java", "diffHunk": "@@ -104,48 +104,115 @@ public void testRowTypeAvroSchemaConversion() {\n \t\t\t\tDataTypes.FIELD(\"row3\", DataTypes.ROW(DataTypes.FIELD(\"c\", DataTypes.STRING())))))\n \t\t\t.build().toRowDataType().getLogicalType();\n \t\tSchema schema = AvroSchemaConverter.convertToSchema(rowType);\n-\t\tassertEquals(\"{\\n\" +\n+\t\tassertEquals(\"[ {\\n\" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6ef138838f1a4a0b45a42eff39b75847c9b39767"}, "originalPosition": 5}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "6ef138838f1a4a0b45a42eff39b75847c9b39767", "author": {"user": {"login": "danny0405", "name": "Danny Chan"}}, "url": "https://github.com/apache/flink/commit/6ef138838f1a4a0b45a42eff39b75847c9b39767", "committedDate": "2020-10-26T07:48:00Z", "message": "[FLINK-19779][avro] Remove the record_ field name prefix for Confluent Avro format deserialization\n\n* Add prefix for the field name only when the record and field have the\n  same name\n* Fix the nullability and precision during data type and Avro schema\n  conversion"}, "afterCommit": {"oid": "11a1af7e69935ec9bbbcc4aeea5dcb5a8b0c68ce", "author": {"user": {"login": "danny0405", "name": "Danny Chan"}}, "url": "https://github.com/apache/flink/commit/11a1af7e69935ec9bbbcc4aeea5dcb5a8b0c68ce", "committedDate": "2020-10-27T06:47:54Z", "message": "[FLINK-19779][avro] Fix the nullability and precision for Avro format deserialization\n\n* Fix the TIME schema precision as 3\n* Fix the nullability of type: TIMESTAMP_WITHOUT_TIME_ZONE, DATE, TIME_WITHOUT_TIME_ZONE,\n  DECIMAL, MAP, ARRAY"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE3NTc2NTE2", "url": "https://github.com/apache/flink/pull/13763#pullrequestreview-517576516", "createdAt": "2020-10-27T10:57:25Z", "commit": {"oid": "11a1af7e69935ec9bbbcc4aeea5dcb5a8b0c68ce"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yN1QxMDo1NzoyNVrOHo2Ocg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yN1QxMTowMDo0OFrOHo2ZAg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjU5MzUyMg==", "bodyText": "That comment is misleading. There is no limitation in the actual handling of nulls with SpecificRecord/GenericRecord.\nIt's just that the LogicalTimeRecord has those fields declared as notNull. The previous dataType was just wrong and did not describe the LogicalTimeRecord correctly.", "url": "https://github.com/apache/flink/pull/13763#discussion_r512593522", "createdAt": "2020-10-27T10:57:25Z", "author": {"login": "dawidwys"}, "path": "flink-formats/flink-avro/src/test/java/org/apache/flink/formats/avro/AvroRowDataDeSerializationSchemaTest.java", "diffHunk": "@@ -181,10 +181,11 @@ public void testSpecificType() throws Exception {\n \t\tencoder.flush();\n \t\tbyte[] input = byteArrayOutputStream.toByteArray();\n \n+\t\t// SE/DE SpecificRecord using the GenericRecord way only supports non-nullable data type.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "11a1af7e69935ec9bbbcc4aeea5dcb5a8b0c68ce"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjU5NjIyNg==", "bodyText": "Is it necessary? Shouldn't the top be handled in the planner and just passed with a correct setting in the logicalType? I think it is a bit too deep to fix it here.", "url": "https://github.com/apache/flink/pull/13763#discussion_r512596226", "createdAt": "2020-10-27T11:00:48Z", "author": {"login": "dawidwys"}, "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java", "diffHunk": "@@ -297,17 +299,22 @@ private static DataType convertToDataType(Schema schema) {\n \t * @return Avro's {@link Schema} matching this logical type.\n \t */\n \tpublic static Schema convertToSchema(LogicalType logicalType) {\n-\t\treturn convertToSchema(logicalType, \"record\");\n+\t\treturn convertToSchema(logicalType, \"record\", true);\n \t}\n \n \t/**\n \t * Converts Flink SQL {@link LogicalType} (can be nested) into an Avro schema.\n \t *\n \t * @param logicalType logical type\n \t * @param rowName     the record name\n+\t * @param top         whether it is parsing the root record,\n+\t *                    if it is, the logical type nullability would be ignored\n \t * @return Avro's {@link Schema} matching this logical type.\n \t */\n-\tpublic static Schema convertToSchema(LogicalType logicalType, String rowName) {\n+\tpublic static Schema convertToSchema(\n+\t\t\tLogicalType logicalType,\n+\t\t\tString rowName,\n+\t\t\tboolean top) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "11a1af7e69935ec9bbbcc4aeea5dcb5a8b0c68ce"}, "originalPosition": 39}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "11a1af7e69935ec9bbbcc4aeea5dcb5a8b0c68ce", "author": {"user": {"login": "danny0405", "name": "Danny Chan"}}, "url": "https://github.com/apache/flink/commit/11a1af7e69935ec9bbbcc4aeea5dcb5a8b0c68ce", "committedDate": "2020-10-27T06:47:54Z", "message": "[FLINK-19779][avro] Fix the nullability and precision for Avro format deserialization\n\n* Fix the TIME schema precision as 3\n* Fix the nullability of type: TIMESTAMP_WITHOUT_TIME_ZONE, DATE, TIME_WITHOUT_TIME_ZONE,\n  DECIMAL, MAP, ARRAY"}, "afterCommit": {"oid": "e57049c1254d265b0cf68e424a3b8d8bd53f729c", "author": {"user": {"login": "danny0405", "name": "Danny Chan"}}, "url": "https://github.com/apache/flink/commit/e57049c1254d265b0cf68e424a3b8d8bd53f729c", "committedDate": "2020-10-27T12:07:03Z", "message": "[FLINK-19786][avro] Fix the nullability and precision for Avro format deserialization\n\n* Fix the TIME schema precision as 3\n* Fix the nullability of type: TIMESTAMP_WITHOUT_TIME_ZONE, DATE, TIME_WITHOUT_TIME_ZONE,\n  DECIMAL, MAP, ARRAY"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e57049c1254d265b0cf68e424a3b8d8bd53f729c", "author": {"user": {"login": "danny0405", "name": "Danny Chan"}}, "url": "https://github.com/apache/flink/commit/e57049c1254d265b0cf68e424a3b8d8bd53f729c", "committedDate": "2020-10-27T12:07:03Z", "message": "[FLINK-19786][avro] Fix the nullability and precision for Avro format deserialization\n\n* Fix the TIME schema precision as 3\n* Fix the nullability of type: TIMESTAMP_WITHOUT_TIME_ZONE, DATE, TIME_WITHOUT_TIME_ZONE,\n  DECIMAL, MAP, ARRAY"}, "afterCommit": {"oid": "a28669bca9c36dac74f89da177825d73bea0ece0", "author": {"user": {"login": "danny0405", "name": "Danny Chan"}}, "url": "https://github.com/apache/flink/commit/a28669bca9c36dac74f89da177825d73bea0ece0", "committedDate": "2020-10-27T12:12:35Z", "message": "[FLINK-19786][avro] Fix the nullability and precision for Avro format deserialization\n\n* Fix the TIME schema precision as 3\n* Fix the nullability of type: TIMESTAMP_WITHOUT_TIME_ZONE, DATE, TIME_WITHOUT_TIME_ZONE,\n  DECIMAL, MAP, ARRAY"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a28669bca9c36dac74f89da177825d73bea0ece0", "author": {"user": {"login": "danny0405", "name": "Danny Chan"}}, "url": "https://github.com/apache/flink/commit/a28669bca9c36dac74f89da177825d73bea0ece0", "committedDate": "2020-10-27T12:12:35Z", "message": "[FLINK-19786][avro] Fix the nullability and precision for Avro format deserialization\n\n* Fix the TIME schema precision as 3\n* Fix the nullability of type: TIMESTAMP_WITHOUT_TIME_ZONE, DATE, TIME_WITHOUT_TIME_ZONE,\n  DECIMAL, MAP, ARRAY"}, "afterCommit": {"oid": "ba752274c9926115f65f5ecbef55b71b0b71cfa2", "author": {"user": {"login": "danny0405", "name": "Danny Chan"}}, "url": "https://github.com/apache/flink/commit/ba752274c9926115f65f5ecbef55b71b0b71cfa2", "committedDate": "2020-10-28T01:53:38Z", "message": "[FLINK-19786][avro] Fix the nullability and precision for Avro format deserialization\n\n* Fix the TIME schema precision as 3\n* Fix the nullability of type: TIMESTAMP_WITHOUT_TIME_ZONE, DATE, TIME_WITHOUT_TIME_ZONE,\n  DECIMAL, MAP, ARRAY"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE4Mjc4NzM4", "url": "https://github.com/apache/flink/pull/13763#pullrequestreview-518278738", "createdAt": "2020-10-28T02:21:06Z", "commit": {"oid": "ba752274c9926115f65f5ecbef55b71b0b71cfa2"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQwMjoyMTowNlrOHpXl9w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQwMjoyMTowNlrOHpXl9w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzE0MDIxNQ==", "bodyText": "I think we can make the parameter to be RowType, that would make sense to use it as the top-level row type and not generate nullable for it. Besides, would be better to add comments in the Javadoc. Currently, this method has the same Javadoc with convertToSchema(LogicalType logicalType, String rowName).", "url": "https://github.com/apache/flink/pull/13763#discussion_r513140215", "createdAt": "2020-10-28T02:21:06Z", "author": {"login": "wuchong"}, "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java", "diffHunk": "@@ -297,32 +300,53 @@ private static DataType convertToDataType(Schema schema) {\n \t * @return Avro's {@link Schema} matching this logical type.\n \t */\n \tpublic static Schema convertToSchema(LogicalType logicalType) {\n+\t\t// If it is parsing the root row type, switches from nullable true to false\n+\t\t// because a nullable row type is meaningless and would generate wrong schema.\n+\t\tif (logicalType.getTypeRoot() == LogicalTypeRoot.ROW", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ba752274c9926115f65f5ecbef55b71b0b71cfa2"}, "originalPosition": 32}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ba752274c9926115f65f5ecbef55b71b0b71cfa2", "author": {"user": {"login": "danny0405", "name": "Danny Chan"}}, "url": "https://github.com/apache/flink/commit/ba752274c9926115f65f5ecbef55b71b0b71cfa2", "committedDate": "2020-10-28T01:53:38Z", "message": "[FLINK-19786][avro] Fix the nullability and precision for Avro format deserialization\n\n* Fix the TIME schema precision as 3\n* Fix the nullability of type: TIMESTAMP_WITHOUT_TIME_ZONE, DATE, TIME_WITHOUT_TIME_ZONE,\n  DECIMAL, MAP, ARRAY"}, "afterCommit": {"oid": "f004220668e20dcd9860026b69566868d473db33", "author": {"user": {"login": "danny0405", "name": "Danny Chan"}}, "url": "https://github.com/apache/flink/commit/f004220668e20dcd9860026b69566868d473db33", "committedDate": "2020-10-28T03:32:00Z", "message": "[FLINK-19786][avro] Fix the nullability and precision for Avro format deserialization\n\n* Fix the TIME schema precision as 3\n* Fix the nullability of type: TIMESTAMP_WITHOUT_TIME_ZONE, DATE, TIME_WITHOUT_TIME_ZONE,\n  DECIMAL, MAP, ARRAY"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f004220668e20dcd9860026b69566868d473db33", "author": {"user": {"login": "danny0405", "name": "Danny Chan"}}, "url": "https://github.com/apache/flink/commit/f004220668e20dcd9860026b69566868d473db33", "committedDate": "2020-10-28T03:32:00Z", "message": "[FLINK-19786][avro] Fix the nullability and precision for Avro format deserialization\n\n* Fix the TIME schema precision as 3\n* Fix the nullability of type: TIMESTAMP_WITHOUT_TIME_ZONE, DATE, TIME_WITHOUT_TIME_ZONE,\n  DECIMAL, MAP, ARRAY"}, "afterCommit": {"oid": "4c5a06b1ca2833fe7f63c25503660ed7acf9b77d", "author": {"user": {"login": "danny0405", "name": "Danny Chan"}}, "url": "https://github.com/apache/flink/commit/4c5a06b1ca2833fe7f63c25503660ed7acf9b77d", "committedDate": "2020-10-28T11:26:19Z", "message": "[FLINK-19786][avro] Fix the nullability and precision for Avro format deserialization\n\n* Fix the TIME schema precision as 3\n* Fix the nullability of type: TIMESTAMP_WITHOUT_TIME_ZONE, DATE, TIME_WITHOUT_TIME_ZONE,\n  DECIMAL, MAP, ARRAY"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "4c5a06b1ca2833fe7f63c25503660ed7acf9b77d", "author": {"user": {"login": "danny0405", "name": "Danny Chan"}}, "url": "https://github.com/apache/flink/commit/4c5a06b1ca2833fe7f63c25503660ed7acf9b77d", "committedDate": "2020-10-28T11:26:19Z", "message": "[FLINK-19786][avro] Fix the nullability and precision for Avro format deserialization\n\n* Fix the TIME schema precision as 3\n* Fix the nullability of type: TIMESTAMP_WITHOUT_TIME_ZONE, DATE, TIME_WITHOUT_TIME_ZONE,\n  DECIMAL, MAP, ARRAY"}, "afterCommit": {"oid": "13712c13da124c38a430d4cc50ad28aec4318764", "author": {"user": {"login": "danny0405", "name": "Danny Chan"}}, "url": "https://github.com/apache/flink/commit/13712c13da124c38a430d4cc50ad28aec4318764", "committedDate": "2020-10-29T03:38:10Z", "message": "[FLINK-19786][avro] Fix the nullability and precision for Avro format deserialization\n\n* Fix the TIME schema precision as 3\n* Fix the nullability of type: TIMESTAMP_WITHOUT_TIME_ZONE, DATE, TIME_WITHOUT_TIME_ZONE,\n  DECIMAL, MAP, ARRAY\n* The table schema row type should be always non-nullable"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "13712c13da124c38a430d4cc50ad28aec4318764", "author": {"user": {"login": "danny0405", "name": "Danny Chan"}}, "url": "https://github.com/apache/flink/commit/13712c13da124c38a430d4cc50ad28aec4318764", "committedDate": "2020-10-29T03:38:10Z", "message": "[FLINK-19786][avro] Fix the nullability and precision for Avro format deserialization\n\n* Fix the TIME schema precision as 3\n* Fix the nullability of type: TIMESTAMP_WITHOUT_TIME_ZONE, DATE, TIME_WITHOUT_TIME_ZONE,\n  DECIMAL, MAP, ARRAY\n* The table schema row type should be always non-nullable"}, "afterCommit": {"oid": "170355bcb112d902e78ee4fc1644b3e6aee5eb29", "author": {"user": {"login": "danny0405", "name": "Danny Chan"}}, "url": "https://github.com/apache/flink/commit/170355bcb112d902e78ee4fc1644b3e6aee5eb29", "committedDate": "2020-10-29T08:45:08Z", "message": "[FLINK-19786][avro] Fix the nullability and precision for Avro format deserialization\n\n* Fix the TIME schema precision as 3\n* Fix the nullability of type: TIMESTAMP_WITHOUT_TIME_ZONE, DATE, TIME_WITHOUT_TIME_ZONE,\n  DECIMAL, MAP, ARRAY\n* The table schema row type should be always non-nullable"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6282778015269bf5e4a1a036540fc6f5fc441cb3", "author": {"user": {"login": "danny0405", "name": "Danny Chan"}}, "url": "https://github.com/apache/flink/commit/6282778015269bf5e4a1a036540fc6f5fc441cb3", "committedDate": "2020-10-29T10:12:05Z", "message": "[FLINK-19779][avro] Remove the \"record_\" field name prefix for Avro format deserialization\n\nNever modify and prefix the field name, instead, we now use the {rowName}_{fieldName}\nas the nested row type name because Avro schema does not allow same name row type\nwith different schema."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e0a53361318b9ee5ceae9a1d6bc50f77a2d28c8a", "author": {"user": {"login": "danny0405", "name": "Danny Chan"}}, "url": "https://github.com/apache/flink/commit/e0a53361318b9ee5ceae9a1d6bc50f77a2d28c8a", "committedDate": "2020-10-29T10:12:05Z", "message": "[FLINK-19786][avro] Fix the nullability and precision for Avro format deserialization\n\n* Fix the TIME schema precision as 3\n* Fix the nullability of type: TIMESTAMP_WITHOUT_TIME_ZONE, DATE, TIME_WITHOUT_TIME_ZONE,\n  DECIMAL, MAP, ARRAY\n* The table schema row type should be always non-nullable"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "170355bcb112d902e78ee4fc1644b3e6aee5eb29", "author": {"user": {"login": "danny0405", "name": "Danny Chan"}}, "url": "https://github.com/apache/flink/commit/170355bcb112d902e78ee4fc1644b3e6aee5eb29", "committedDate": "2020-10-29T08:45:08Z", "message": "[FLINK-19786][avro] Fix the nullability and precision for Avro format deserialization\n\n* Fix the TIME schema precision as 3\n* Fix the nullability of type: TIMESTAMP_WITHOUT_TIME_ZONE, DATE, TIME_WITHOUT_TIME_ZONE,\n  DECIMAL, MAP, ARRAY\n* The table schema row type should be always non-nullable"}, "afterCommit": {"oid": "e0a53361318b9ee5ceae9a1d6bc50f77a2d28c8a", "author": {"user": {"login": "danny0405", "name": "Danny Chan"}}, "url": "https://github.com/apache/flink/commit/e0a53361318b9ee5ceae9a1d6bc50f77a2d28c8a", "committedDate": "2020-10-29T10:12:05Z", "message": "[FLINK-19786][avro] Fix the nullability and precision for Avro format deserialization\n\n* Fix the TIME schema precision as 3\n* Fix the nullability of type: TIMESTAMP_WITHOUT_TIME_ZONE, DATE, TIME_WITHOUT_TIME_ZONE,\n  DECIMAL, MAP, ARRAY\n* The table schema row type should be always non-nullable"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE5NzY1MzI1", "url": "https://github.com/apache/flink/pull/13763#pullrequestreview-519765325", "createdAt": "2020-10-29T15:05:44Z", "commit": {"oid": "e0a53361318b9ee5ceae9a1d6bc50f77a2d28c8a"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3088, "cost": 1, "resetAt": "2021-10-28T16:48:13Z"}}}