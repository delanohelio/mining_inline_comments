{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDIyNzMyMTU2", "number": 12321, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wM1QwNzoyNDo0N1rOECCEpA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQwNTo1MzoyMFrOEDTufg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcwNTY2NTY0OnYy", "diffSide": "RIGHT", "path": "docs/dev/connectors/streamfile_sink.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wM1QwNzoyNDo0N1rOGePRnw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wM1QwNzoyNDo0N1rOGePRnw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDM2MDczNQ==", "bodyText": "maybe \"For creating customized Avro writers, e.g. enabling compression, ...\" ?", "url": "https://github.com/apache/flink/pull/12321#discussion_r434360735", "createdAt": "2020-06-03T07:24:47Z", "author": {"login": "zhuzhurk"}, "path": "docs/dev/connectors/streamfile_sink.md", "diffHunk": "@@ -204,6 +205,65 @@ input.addSink(sink)\n </div>\n </div>\n \n+#### Avro format\n+\n+Flink also provides built-in support for writing data into Avro files. A list of convenience methods to create\n+Avro writer factories and their associated documentation can be found in the \n+[AvroWriters]({{ site.javadocs_baseurl }}/api/java/org/apache/flink/formats/avro/AvroWriters.html) class.\n+\n+For creating customized Avro writers like enabling compression, users need to create the `AvroWriterFactory`", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "56bdc3a61f65cb30b48cf7f932520be02ebed734"}, "originalPosition": 18}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcwNTc5MTMwOnYy", "diffSide": "RIGHT", "path": "docs/dev/connectors/streamfile_sink.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wM1QwODowMDo1MVrOGeQgBg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wN1QwODo1MDozMVrOGgIHNA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDM4MDgwNg==", "bodyText": "Would it make sense to add an example on creating customized Avro writers?", "url": "https://github.com/apache/flink/pull/12321#discussion_r434380806", "createdAt": "2020-06-03T08:00:51Z", "author": {"login": "zhuzhurk"}, "path": "docs/dev/connectors/streamfile_sink.md", "diffHunk": "@@ -204,6 +205,65 @@ input.addSink(sink)\n </div>\n </div>\n \n+#### Avro format\n+\n+Flink also provides built-in support for writing data into Avro files. A list of convenience methods to create\n+Avro writer factories and their associated documentation can be found in the \n+[AvroWriters]({{ site.javadocs_baseurl }}/api/java/org/apache/flink/formats/avro/AvroWriters.html) class.\n+\n+For creating customized Avro writers like enabling compression, users need to create the `AvroWriterFactory`\n+with a custom implementation of the [AvroBuilder]({{ site.javadocs_baseurl }}/api/java/org/apache/flink/formats/avro/AvroBuilder.html) interface.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "56bdc3a61f65cb30b48cf7f932520be02ebed734"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjM0MDUzMg==", "bodyText": "I have added the example for the customized Avro writers.", "url": "https://github.com/apache/flink/pull/12321#discussion_r436340532", "createdAt": "2020-06-07T08:50:31Z", "author": {"login": "gaoyunhaii"}, "path": "docs/dev/connectors/streamfile_sink.md", "diffHunk": "@@ -204,6 +205,65 @@ input.addSink(sink)\n </div>\n </div>\n \n+#### Avro format\n+\n+Flink also provides built-in support for writing data into Avro files. A list of convenience methods to create\n+Avro writer factories and their associated documentation can be found in the \n+[AvroWriters]({{ site.javadocs_baseurl }}/api/java/org/apache/flink/formats/avro/AvroWriters.html) class.\n+\n+For creating customized Avro writers like enabling compression, users need to create the `AvroWriterFactory`\n+with a custom implementation of the [AvroBuilder]({{ site.javadocs_baseurl }}/api/java/org/apache/flink/formats/avro/AvroBuilder.html) interface.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDM4MDgwNg=="}, "originalCommit": {"oid": "56bdc3a61f65cb30b48cf7f932520be02ebed734"}, "originalPosition": 19}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcxOTA0MzgyOnYy", "diffSide": "RIGHT", "path": "docs/dev/connectors/streamfile_sink.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQwNTo1MzoyMFrOGgQAkQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQwNTo1MzoyMFrOGgQAkQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQ2OTkwNQ==", "bodyText": "Better to use lambda, because lambda is serializable, but inner class depends on outer class.", "url": "https://github.com/apache/flink/pull/12321#discussion_r436469905", "createdAt": "2020-06-08T05:53:20Z", "author": {"login": "JingsongLi"}, "path": "docs/dev/connectors/streamfile_sink.md", "diffHunk": "@@ -204,6 +205,109 @@ input.addSink(sink)\n </div>\n </div>\n \n+#### Avro format\n+\n+Flink also provides built-in support for writing data into Avro files. A list of convenience methods to create\n+Avro writer factories and their associated documentation can be found in the \n+[AvroWriters]({{ site.javadocs_baseurl }}/api/java/org/apache/flink/formats/avro/AvroWriters.html) class.\n+\n+To use the Avro writers in your application you need to add the following dependency:\n+\n+{% highlight xml %}\n+<dependency>\n+  <groupId>org.apache.flink</groupId>\n+  <artifactId>flink-avro</artifactId>\n+  <version>{{ site.version }}</version>\n+</dependency>\n+{% endhighlight %}\n+\n+A StreamingFileSink that writes data to Avro files can be created like this:\n+\n+<div class=\"codetabs\" markdown=\"1\">\n+<div data-lang=\"java\" markdown=\"1\">\n+{% highlight java %}\n+import org.apache.flink.streaming.api.functions.sink.filesystem.StreamingFileSink;\n+import org.apache.flink.formats.avro.AvroWriters;\n+import org.apache.avro.Schema;\n+\n+\n+Schema schema = ...;\n+DataStream<GenericRecord> stream = ...;\n+\n+final StreamingFileSink<GenericRecord> sink = StreamingFileSink\n+\t.forBulkFormat(outputBasePath, AvroWriters.forGenericRecord(schema))\n+\t.build();\n+\n+input.addSink(sink);\n+\n+{% endhighlight %}\n+</div>\n+<div data-lang=\"scala\" markdown=\"1\">\n+{% highlight scala %}\n+import org.apache.flink.streaming.api.functions.sink.filesystem.StreamingFileSink\n+import org.apache.flink.formats.avro.AvroWriters\n+import org.apache.avro.Schema\n+\n+val schema: Schema = ...\n+val input: DataStream[GenericRecord] = ...\n+\n+val sink: StreamingFileSink[GenericRecord] = StreamingFileSink\n+    .forBulkFormat(outputBasePath, AvroWriters.forGenericRecord(schema))\n+    .build()\n+\n+input.addSink(sink)\n+\n+{% endhighlight %}\n+</div>\n+</div>\n+\n+For creating customized Avro writers, e.g. enabling compression, users need to create the `AvroWriterFactory`\n+with a custom implementation of the [AvroBuilder]({{ site.javadocs_baseurl }}/api/java/org/apache/flink/formats/avro/AvroBuilder.html) interface:\n+\n+<div class=\"codetabs\" markdown=\"1\">\n+<div data-lang=\"java\" markdown=\"1\">\n+{% highlight java %}\n+AvroWriterFactory<?> factory = new AvroWriterFactory<>(new AvroBuilder<Address>() {\n+\t@Override\n+\tpublic DataFileWriter<Address> createWriter(OutputStream out) throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "23a939d18a7e3b989e521963e0399b73c775165d"}, "originalPosition": 76}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4454, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}