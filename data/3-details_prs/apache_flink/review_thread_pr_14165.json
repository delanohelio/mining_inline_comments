{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTI1NTQ2Mzkx", "number": 14165, "reviewThreads": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwNjozOTowMFrOE9FSaw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwNzozMTo1OVrOFBGE-w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyNDg1MjI3OnYy", "diffSide": "RIGHT", "path": "flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/api/StatementSet.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwNjozOTowMFrOH5lByg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQwODoxODozNlrOH6QH5g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDEzNzU0Ng==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t *                     e.g. estimated cost, changelog mode for streaming, execution plan in json format\n          \n          \n            \n            \t *                     e.g. estimated cost, changelog mode for streaming, displaying execution plan in json format", "url": "https://github.com/apache/flink/pull/14165#discussion_r530137546", "createdAt": "2020-11-25T06:39:00Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/api/StatementSet.java", "diffHunk": "@@ -51,7 +51,7 @@\n \t * all statements and Tables.\n \t *\n \t * @param extraDetails The extra explain details which the explain result should include,\n-\t *                     e.g. estimated cost, changelog mode for streaming\n+\t *                     e.g. estimated cost, changelog mode for streaming, execution plan in json format", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "452c291a21493b2ae4e722de1879b5a94fca9ca9"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDczMTUxMQ==", "bodyText": "We should also update the docs of TableEnviroment#explainSql() and Planner#explain", "url": "https://github.com/apache/flink/pull/14165#discussion_r530731511", "createdAt": "2020-11-26T02:01:39Z", "author": {"login": "godfreyhe"}, "path": "flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/api/StatementSet.java", "diffHunk": "@@ -51,7 +51,7 @@\n \t * all statements and Tables.\n \t *\n \t * @param extraDetails The extra explain details which the explain result should include,\n-\t *                     e.g. estimated cost, changelog mode for streaming\n+\t *                     e.g. estimated cost, changelog mode for streaming, execution plan in json format", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDEzNzU0Ng=="}, "originalCommit": {"oid": "452c291a21493b2ae4e722de1879b5a94fca9ca9"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDg0MzYyMg==", "bodyText": "@godfreyhe Thanks for your reminder. I will update it.", "url": "https://github.com/apache/flink/pull/14165#discussion_r530843622", "createdAt": "2020-11-26T08:18:36Z", "author": {"login": "V1ncentzzZ"}, "path": "flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/api/StatementSet.java", "diffHunk": "@@ -51,7 +51,7 @@\n \t * all statements and Tables.\n \t *\n \t * @param extraDetails The extra explain details which the explain result should include,\n-\t *                     e.g. estimated cost, changelog mode for streaming\n+\t *                     e.g. estimated cost, changelog mode for streaming, execution plan in json format", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDEzNzU0Ng=="}, "originalCommit": {"oid": "452c291a21493b2ae4e722de1879b5a94fca9ca9"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyNDg1NjUxOnYy", "diffSide": "RIGHT", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/delegation/StreamPlanner.scala", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwNjo0MDo0N1rOH5lEKQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQwODowNjoyNFrOH6PvKw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDEzODE1Mw==", "bodyText": "I have discussed with @godfreyhe . We think that we don't need to add a new entry for the \"Streaming Execution Plan\". Because it describes the same plan with \"Physical Execution Plan\", just in different format.\nThus, we suggest to replace the content of \"Physical Execution Plan\" using the json string when ExplainDetail is in JSON_EXECUTION_PLAN.", "url": "https://github.com/apache/flink/pull/14165#discussion_r530138153", "createdAt": "2020-11-25T06:40:47Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/delegation/StreamPlanner.scala", "diffHunk": "@@ -129,6 +129,13 @@ class StreamPlanner(\n     sb.append(\"== Physical Execution Plan ==\")\n     sb.append(System.lineSeparator)\n     sb.append(executionPlan)\n+\n+    if (extraDetails.contains(ExplainDetail.JSON_EXECUTION_PLAN)) {\n+      sb.append(System.lineSeparator)\n+      sb.append(\"== Streaming Execution Plan ==\")\n+      sb.append(System.lineSeparator)\n+      sb.append(streamGraph.getStreamingPlanAsJSON)\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "452c291a21493b2ae4e722de1879b5a94fca9ca9"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDgzNzI5MQ==", "bodyText": "Okay, I will update it and add some test cases.", "url": "https://github.com/apache/flink/pull/14165#discussion_r530837291", "createdAt": "2020-11-26T08:06:24Z", "author": {"login": "V1ncentzzZ"}, "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/delegation/StreamPlanner.scala", "diffHunk": "@@ -129,6 +129,13 @@ class StreamPlanner(\n     sb.append(\"== Physical Execution Plan ==\")\n     sb.append(System.lineSeparator)\n     sb.append(executionPlan)\n+\n+    if (extraDetails.contains(ExplainDetail.JSON_EXECUTION_PLAN)) {\n+      sb.append(System.lineSeparator)\n+      sb.append(\"== Streaming Execution Plan ==\")\n+      sb.append(System.lineSeparator)\n+      sb.append(streamGraph.getStreamingPlanAsJSON)\n+    }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDEzODE1Mw=="}, "originalCommit": {"oid": "452c291a21493b2ae4e722de1879b5a94fca9ca9"}, "originalPosition": 10}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM2MjI3NzgxOnYy", "diffSide": "RIGHT", "path": "flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/api/TableEnvironmentITCase.scala", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQwNjo0Nzo1NFrOH_DH3Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQwOTo0OToyNFrOH_JGrg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTg3MzUwMQ==", "bodyText": "This test case is a unit test, not an integration test, so this test case should be moved to TableEnvironmentTest\nnit: sink1Path and sink2Path are unnecessary", "url": "https://github.com/apache/flink/pull/14165#discussion_r535873501", "createdAt": "2020-12-04T06:47:54Z", "author": {"login": "godfreyhe"}, "path": "flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/api/TableEnvironmentITCase.scala", "diffHunk": "@@ -429,6 +429,26 @@ class TableEnvironmentITCase(tableEnvName: String, isStreaming: Boolean) extends\n     assertLastValues(sink2Path)\n   }\n \n+  @Test\n+  def testExecutionPlanFromStatementSet(): Unit = {\n+    val sink1Path = TestTableSourceSinks.createCsvTemporarySinkTable(\n+      tEnv, new TableSchema(Array(\"first\"), Array(STRING)), \"MySink1\")\n+\n+    val sink2Path = TestTableSourceSinks.createCsvTemporarySinkTable(\n+      tEnv, new TableSchema(Array(\"last\"), Array(STRING)), \"MySink2\")\n+\n+    val stmtSet = tEnv.createStatementSet()\n+    stmtSet.addInsert(\"MySink1\", tEnv.sqlQuery(\"select first from MyTable\"))\n+        .addInsertSql(\"insert into MySink2 select last from MyTable\")\n+\n+    val actual = stmtSet.explain(ExplainDetail.JSON_EXECUTION_PLAN)\n+    val expected =\n+      TableTestUtil.readFromResource(\"/explain/testExecutionPlanFromStatementSet.out\")\n+\n+    assertEquals(replaceStreamNodeIdAndParallelism(expected),\n+      replaceStreamNodeIdAndParallelism(actual))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c5728be97ab3b29a7dc4834b9fb2bbf63a0143dd"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTk0MDQzOQ==", "bodyText": "You means that move this tests to TableEnvironmentTest  from TableEnvironmentITCase?", "url": "https://github.com/apache/flink/pull/14165#discussion_r535940439", "createdAt": "2020-12-04T09:01:30Z", "author": {"login": "V1ncentzzZ"}, "path": "flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/api/TableEnvironmentITCase.scala", "diffHunk": "@@ -429,6 +429,26 @@ class TableEnvironmentITCase(tableEnvName: String, isStreaming: Boolean) extends\n     assertLastValues(sink2Path)\n   }\n \n+  @Test\n+  def testExecutionPlanFromStatementSet(): Unit = {\n+    val sink1Path = TestTableSourceSinks.createCsvTemporarySinkTable(\n+      tEnv, new TableSchema(Array(\"first\"), Array(STRING)), \"MySink1\")\n+\n+    val sink2Path = TestTableSourceSinks.createCsvTemporarySinkTable(\n+      tEnv, new TableSchema(Array(\"last\"), Array(STRING)), \"MySink2\")\n+\n+    val stmtSet = tEnv.createStatementSet()\n+    stmtSet.addInsert(\"MySink1\", tEnv.sqlQuery(\"select first from MyTable\"))\n+        .addInsertSql(\"insert into MySink2 select last from MyTable\")\n+\n+    val actual = stmtSet.explain(ExplainDetail.JSON_EXECUTION_PLAN)\n+    val expected =\n+      TableTestUtil.readFromResource(\"/explain/testExecutionPlanFromStatementSet.out\")\n+\n+    assertEquals(replaceStreamNodeIdAndParallelism(expected),\n+      replaceStreamNodeIdAndParallelism(actual))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTg3MzUwMQ=="}, "originalCommit": {"oid": "c5728be97ab3b29a7dc4834b9fb2bbf63a0143dd"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTk1NDIxMA==", "bodyText": "yes, sorry for the typo word \"removed\"", "url": "https://github.com/apache/flink/pull/14165#discussion_r535954210", "createdAt": "2020-12-04T09:23:24Z", "author": {"login": "godfreyhe"}, "path": "flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/api/TableEnvironmentITCase.scala", "diffHunk": "@@ -429,6 +429,26 @@ class TableEnvironmentITCase(tableEnvName: String, isStreaming: Boolean) extends\n     assertLastValues(sink2Path)\n   }\n \n+  @Test\n+  def testExecutionPlanFromStatementSet(): Unit = {\n+    val sink1Path = TestTableSourceSinks.createCsvTemporarySinkTable(\n+      tEnv, new TableSchema(Array(\"first\"), Array(STRING)), \"MySink1\")\n+\n+    val sink2Path = TestTableSourceSinks.createCsvTemporarySinkTable(\n+      tEnv, new TableSchema(Array(\"last\"), Array(STRING)), \"MySink2\")\n+\n+    val stmtSet = tEnv.createStatementSet()\n+    stmtSet.addInsert(\"MySink1\", tEnv.sqlQuery(\"select first from MyTable\"))\n+        .addInsertSql(\"insert into MySink2 select last from MyTable\")\n+\n+    val actual = stmtSet.explain(ExplainDetail.JSON_EXECUTION_PLAN)\n+    val expected =\n+      TableTestUtil.readFromResource(\"/explain/testExecutionPlanFromStatementSet.out\")\n+\n+    assertEquals(replaceStreamNodeIdAndParallelism(expected),\n+      replaceStreamNodeIdAndParallelism(actual))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTg3MzUwMQ=="}, "originalCommit": {"oid": "c5728be97ab3b29a7dc4834b9fb2bbf63a0143dd"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTk3MTUwMg==", "bodyText": "Okay", "url": "https://github.com/apache/flink/pull/14165#discussion_r535971502", "createdAt": "2020-12-04T09:49:24Z", "author": {"login": "V1ncentzzZ"}, "path": "flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/api/TableEnvironmentITCase.scala", "diffHunk": "@@ -429,6 +429,26 @@ class TableEnvironmentITCase(tableEnvName: String, isStreaming: Boolean) extends\n     assertLastValues(sink2Path)\n   }\n \n+  @Test\n+  def testExecutionPlanFromStatementSet(): Unit = {\n+    val sink1Path = TestTableSourceSinks.createCsvTemporarySinkTable(\n+      tEnv, new TableSchema(Array(\"first\"), Array(STRING)), \"MySink1\")\n+\n+    val sink2Path = TestTableSourceSinks.createCsvTemporarySinkTable(\n+      tEnv, new TableSchema(Array(\"last\"), Array(STRING)), \"MySink2\")\n+\n+    val stmtSet = tEnv.createStatementSet()\n+    stmtSet.addInsert(\"MySink1\", tEnv.sqlQuery(\"select first from MyTable\"))\n+        .addInsertSql(\"insert into MySink2 select last from MyTable\")\n+\n+    val actual = stmtSet.explain(ExplainDetail.JSON_EXECUTION_PLAN)\n+    val expected =\n+      TableTestUtil.readFromResource(\"/explain/testExecutionPlanFromStatementSet.out\")\n+\n+    assertEquals(replaceStreamNodeIdAndParallelism(expected),\n+      replaceStreamNodeIdAndParallelism(actual))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTg3MzUwMQ=="}, "originalCommit": {"oid": "c5728be97ab3b29a7dc4834b9fb2bbf63a0143dd"}, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM2MjI4NDQxOnYy", "diffSide": "RIGHT", "path": "flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/api/TableEnvironmentTest.scala", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQwNjo1MDozMFrOH_DLgw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQwOTo0OTo0N1rOH_JH3A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTg3NDQzNQ==", "bodyText": "please also add some test cases for legacy planner", "url": "https://github.com/apache/flink/pull/14165#discussion_r535874435", "createdAt": "2020-12-04T06:50:30Z", "author": {"login": "godfreyhe"}, "path": "flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/api/TableEnvironmentTest.scala", "diffHunk": "@@ -103,6 +103,26 @@ class TableEnvironmentTest {\n     assertEquals(TableTestUtil.replaceStageId(expected), TableTestUtil.replaceStageId(actual))\n   }\n \n+  @Test\n+  def testStreamTableEnvironmentExecutionExplain(): Unit = {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c5728be97ab3b29a7dc4834b9fb2bbf63a0143dd"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTk0MDQ3Ng==", "bodyText": "Hi @godfreyhe , Sry, How i get legacy planner and add tests for it? Add it to org.apache.flink.table.api.TableEnvironmentTest?", "url": "https://github.com/apache/flink/pull/14165#discussion_r535940476", "createdAt": "2020-12-04T09:01:33Z", "author": {"login": "V1ncentzzZ"}, "path": "flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/api/TableEnvironmentTest.scala", "diffHunk": "@@ -103,6 +103,26 @@ class TableEnvironmentTest {\n     assertEquals(TableTestUtil.replaceStageId(expected), TableTestUtil.replaceStageId(actual))\n   }\n \n+  @Test\n+  def testStreamTableEnvironmentExecutionExplain(): Unit = {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTg3NDQzNQ=="}, "originalCommit": {"oid": "c5728be97ab3b29a7dc4834b9fb2bbf63a0143dd"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTk1NTk0Nw==", "bodyText": "you can add tests into org.apache.flink.table.api.stream.ExplainTest and org.apache.flink.table.api.batch.ExplainTest", "url": "https://github.com/apache/flink/pull/14165#discussion_r535955947", "createdAt": "2020-12-04T09:26:07Z", "author": {"login": "godfreyhe"}, "path": "flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/api/TableEnvironmentTest.scala", "diffHunk": "@@ -103,6 +103,26 @@ class TableEnvironmentTest {\n     assertEquals(TableTestUtil.replaceStageId(expected), TableTestUtil.replaceStageId(actual))\n   }\n \n+  @Test\n+  def testStreamTableEnvironmentExecutionExplain(): Unit = {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTg3NDQzNQ=="}, "originalCommit": {"oid": "c5728be97ab3b29a7dc4834b9fb2bbf63a0143dd"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTk3MTgwNA==", "bodyText": "Okay", "url": "https://github.com/apache/flink/pull/14165#discussion_r535971804", "createdAt": "2020-12-04T09:49:47Z", "author": {"login": "V1ncentzzZ"}, "path": "flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/api/TableEnvironmentTest.scala", "diffHunk": "@@ -103,6 +103,26 @@ class TableEnvironmentTest {\n     assertEquals(TableTestUtil.replaceStageId(expected), TableTestUtil.replaceStageId(actual))\n   }\n \n+  @Test\n+  def testStreamTableEnvironmentExecutionExplain(): Unit = {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTg3NDQzNQ=="}, "originalCommit": {"oid": "c5728be97ab3b29a7dc4834b9fb2bbf63a0143dd"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM2NjkyNDc1OnYy", "diffSide": "RIGHT", "path": "flink-table/flink-table-planner/src/test/scala/resources/testStatementSetExecutionExplain1.out", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwNzozMTo1OVrOH_rjQg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wN1QwMzoxNjo0MVrOIAURXg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjUzNTg3NA==", "bodyText": "A minor concern: the estimated cost maybe unstable, so it's better the value can be normalized to zero or unknown to avoid unstable test.\nbtw, the parallelism value is a key information and the value is determinate except the default parallelism is the number of cpu cores for LocalStreamEnvironment, we can explicitly set the value var setParallelism method", "url": "https://github.com/apache/flink/pull/14165#discussion_r536535874", "createdAt": "2020-12-05T07:31:59Z", "author": {"login": "godfreyhe"}, "path": "flink-table/flink-table-planner/src/test/scala/resources/testStatementSetExecutionExplain1.out", "diffHunk": "@@ -0,0 +1,121 @@\n+== Abstract Syntax Tree ==\n+LogicalSink(name=[`default_catalog`.`default_database`.`targetTable`], fields=[d, e])\n+  LogicalProject(first=[$0], id=[$1])\n+    LogicalTableScan(table=[[default_catalog, default_database, sourceTable]])\n+\n+== Optimized Logical Plan ==\n+DataSetSink(name=[`default_catalog`.`default_database`.`targetTable`], fields=[d, e])\n+  BatchTableSourceScan(table=[[default_catalog, default_database, sourceTable]], fields=[first, id], source=[CsvTableSource(read fields: first, id)])\n+\n+== Physical Execution Plan ==\n+{\n+\t\"nodes\": [\n+\n+\t{\n+\t\t\"id\": ,\n+\t\t\"type\": \"source\",\n+\t\t\"pact\": \"Data Source\",\n+\t\t\"contents\": \"CsvTableSource(read fields: first, id)\",\n+\t\t\"parallelism\":,\n+\t\t\"global_properties\": [\n+\t\t\t{ \"name\": \"Partitioning\", \"value\": \"RANDOM_PARTITIONED\" },\n+\t\t\t{ \"name\": \"Partitioning Order\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Uniqueness\", \"value\": \"not unique\" }\n+\t\t],\n+\t\t\"local_properties\": [\n+\t\t\t{ \"name\": \"Order\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Grouping\", \"value\": \"not grouped\" },\n+\t\t\t{ \"name\": \"Uniqueness\", \"value\": \"not unique\" }\n+\t\t],\n+\t\t\"estimates\": [\n+\t\t\t{ \"name\": \"Est. Output Size\", \"value\": \"190.00\" },\n+\t\t\t{ \"name\": \"Est. Cardinality\", \"value\": \"10.00\" }\t\t],\n+\t\t\"costs\": [\n+\t\t\t{ \"name\": \"Network\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"Disk I/O\", \"value\": \"190.00\" },\n+\t\t\t{ \"name\": \"CPU\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"Cumulative Network\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"Cumulative Disk I/O\", \"value\": \"190.00\" },\n+\t\t\t{ \"name\": \"Cumulative CPU\", \"value\": \"0.0\" }\n+\t\t],\n+\t\t\"compiler_hints\": [\n+\t\t\t{ \"name\": \"Output Size (bytes)\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Output Cardinality\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Avg. Output Record Size (bytes)\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Filter Factor\", \"value\": \"(none)\" }\t\t]\n+\t},\n+\t{\n+\t\t\"id\": ,\n+\t\t\"type\": \"pact\",\n+\t\t\"pact\": \"Map\",\n+\t\t\"contents\": \"to: Row\",\n+\t\t\"parallelism\":,\n+\t\t\"predecessors\": [\n+\t\t\t{\"id\": , \"ship_strategy\": \"Forward\", \"exchange_mode\": \"PIPELINED\"}\n+\t\t],\n+\t\t\"driver_strategy\": \"Map\",\n+\t\t\"global_properties\": [\n+\t\t\t{ \"name\": \"Partitioning\", \"value\": \"RANDOM_PARTITIONED\" },\n+\t\t\t{ \"name\": \"Partitioning Order\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Uniqueness\", \"value\": \"not unique\" }\n+\t\t],\n+\t\t\"local_properties\": [\n+\t\t\t{ \"name\": \"Order\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Grouping\", \"value\": \"not grouped\" },\n+\t\t\t{ \"name\": \"Uniqueness\", \"value\": \"not unique\" }\n+\t\t],\n+\t\t\"estimates\": [\n+\t\t\t{ \"name\": \"Est. Output Size\", \"value\": \"(unknown)\" },\n+\t\t\t{ \"name\": \"Est. Cardinality\", \"value\": \"10.00\" }\t\t],\n+\t\t\"costs\": [\n+\t\t\t{ \"name\": \"Network\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"Disk I/O\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"CPU\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"Cumulative Network\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"Cumulative Disk I/O\", \"value\": \"190.00\" },\n+\t\t\t{ \"name\": \"Cumulative CPU\", \"value\": \"0.0\" }\n+\t\t],\n+\t\t\"compiler_hints\": [\n+\t\t\t{ \"name\": \"Output Size (bytes)\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Output Cardinality\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Avg. Output Record Size (bytes)\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Filter Factor\", \"value\": \"(none)\" }\t\t]\n+\t},\n+\t{\n+\t\t\"id\": ,\n+\t\t\"type\": \"sink\",\n+\t\t\"pact\": \"Data Sink\",\n+\t\t\"contents\": \"UnsafeMemoryAppendTableSink(d, e)\",\n+\t\t\"parallelism\":,\n+\t\t\"predecessors\": [\n+\t\t\t{\"id\": , \"ship_strategy\": \"Forward\", \"exchange_mode\": \"PIPELINED\"}\n+\t\t],\n+\t\t\"global_properties\": [\n+\t\t\t{ \"name\": \"Partitioning\", \"value\": \"RANDOM_PARTITIONED\" },\n+\t\t\t{ \"name\": \"Partitioning Order\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Uniqueness\", \"value\": \"not unique\" }\n+\t\t],\n+\t\t\"local_properties\": [\n+\t\t\t{ \"name\": \"Order\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Grouping\", \"value\": \"not grouped\" },\n+\t\t\t{ \"name\": \"Uniqueness\", \"value\": \"not unique\" }\n+\t\t],\n+\t\t\"estimates\": [\n+\t\t\t{ \"name\": \"Est. Output Size\", \"value\": \"(unknown)\" },\n+\t\t\t{ \"name\": \"Est. Cardinality\", \"value\": \"10.00\" }\t\t],\n+\t\t\"costs\": [\n+\t\t\t{ \"name\": \"Network\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"Disk I/O\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"CPU\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"Cumulative Network\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"Cumulative Disk I/O\", \"value\": \"190.00\" },\n+\t\t\t{ \"name\": \"Cumulative CPU\", \"value\": \"0.0\" }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "61cdd876e27d23952da5c66f6d201c7c7102ad3f"}, "originalPosition": 112}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzIwMzAzOA==", "bodyText": "Done.", "url": "https://github.com/apache/flink/pull/14165#discussion_r537203038", "createdAt": "2020-12-07T03:16:41Z", "author": {"login": "V1ncentzzZ"}, "path": "flink-table/flink-table-planner/src/test/scala/resources/testStatementSetExecutionExplain1.out", "diffHunk": "@@ -0,0 +1,121 @@\n+== Abstract Syntax Tree ==\n+LogicalSink(name=[`default_catalog`.`default_database`.`targetTable`], fields=[d, e])\n+  LogicalProject(first=[$0], id=[$1])\n+    LogicalTableScan(table=[[default_catalog, default_database, sourceTable]])\n+\n+== Optimized Logical Plan ==\n+DataSetSink(name=[`default_catalog`.`default_database`.`targetTable`], fields=[d, e])\n+  BatchTableSourceScan(table=[[default_catalog, default_database, sourceTable]], fields=[first, id], source=[CsvTableSource(read fields: first, id)])\n+\n+== Physical Execution Plan ==\n+{\n+\t\"nodes\": [\n+\n+\t{\n+\t\t\"id\": ,\n+\t\t\"type\": \"source\",\n+\t\t\"pact\": \"Data Source\",\n+\t\t\"contents\": \"CsvTableSource(read fields: first, id)\",\n+\t\t\"parallelism\":,\n+\t\t\"global_properties\": [\n+\t\t\t{ \"name\": \"Partitioning\", \"value\": \"RANDOM_PARTITIONED\" },\n+\t\t\t{ \"name\": \"Partitioning Order\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Uniqueness\", \"value\": \"not unique\" }\n+\t\t],\n+\t\t\"local_properties\": [\n+\t\t\t{ \"name\": \"Order\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Grouping\", \"value\": \"not grouped\" },\n+\t\t\t{ \"name\": \"Uniqueness\", \"value\": \"not unique\" }\n+\t\t],\n+\t\t\"estimates\": [\n+\t\t\t{ \"name\": \"Est. Output Size\", \"value\": \"190.00\" },\n+\t\t\t{ \"name\": \"Est. Cardinality\", \"value\": \"10.00\" }\t\t],\n+\t\t\"costs\": [\n+\t\t\t{ \"name\": \"Network\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"Disk I/O\", \"value\": \"190.00\" },\n+\t\t\t{ \"name\": \"CPU\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"Cumulative Network\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"Cumulative Disk I/O\", \"value\": \"190.00\" },\n+\t\t\t{ \"name\": \"Cumulative CPU\", \"value\": \"0.0\" }\n+\t\t],\n+\t\t\"compiler_hints\": [\n+\t\t\t{ \"name\": \"Output Size (bytes)\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Output Cardinality\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Avg. Output Record Size (bytes)\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Filter Factor\", \"value\": \"(none)\" }\t\t]\n+\t},\n+\t{\n+\t\t\"id\": ,\n+\t\t\"type\": \"pact\",\n+\t\t\"pact\": \"Map\",\n+\t\t\"contents\": \"to: Row\",\n+\t\t\"parallelism\":,\n+\t\t\"predecessors\": [\n+\t\t\t{\"id\": , \"ship_strategy\": \"Forward\", \"exchange_mode\": \"PIPELINED\"}\n+\t\t],\n+\t\t\"driver_strategy\": \"Map\",\n+\t\t\"global_properties\": [\n+\t\t\t{ \"name\": \"Partitioning\", \"value\": \"RANDOM_PARTITIONED\" },\n+\t\t\t{ \"name\": \"Partitioning Order\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Uniqueness\", \"value\": \"not unique\" }\n+\t\t],\n+\t\t\"local_properties\": [\n+\t\t\t{ \"name\": \"Order\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Grouping\", \"value\": \"not grouped\" },\n+\t\t\t{ \"name\": \"Uniqueness\", \"value\": \"not unique\" }\n+\t\t],\n+\t\t\"estimates\": [\n+\t\t\t{ \"name\": \"Est. Output Size\", \"value\": \"(unknown)\" },\n+\t\t\t{ \"name\": \"Est. Cardinality\", \"value\": \"10.00\" }\t\t],\n+\t\t\"costs\": [\n+\t\t\t{ \"name\": \"Network\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"Disk I/O\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"CPU\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"Cumulative Network\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"Cumulative Disk I/O\", \"value\": \"190.00\" },\n+\t\t\t{ \"name\": \"Cumulative CPU\", \"value\": \"0.0\" }\n+\t\t],\n+\t\t\"compiler_hints\": [\n+\t\t\t{ \"name\": \"Output Size (bytes)\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Output Cardinality\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Avg. Output Record Size (bytes)\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Filter Factor\", \"value\": \"(none)\" }\t\t]\n+\t},\n+\t{\n+\t\t\"id\": ,\n+\t\t\"type\": \"sink\",\n+\t\t\"pact\": \"Data Sink\",\n+\t\t\"contents\": \"UnsafeMemoryAppendTableSink(d, e)\",\n+\t\t\"parallelism\":,\n+\t\t\"predecessors\": [\n+\t\t\t{\"id\": , \"ship_strategy\": \"Forward\", \"exchange_mode\": \"PIPELINED\"}\n+\t\t],\n+\t\t\"global_properties\": [\n+\t\t\t{ \"name\": \"Partitioning\", \"value\": \"RANDOM_PARTITIONED\" },\n+\t\t\t{ \"name\": \"Partitioning Order\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Uniqueness\", \"value\": \"not unique\" }\n+\t\t],\n+\t\t\"local_properties\": [\n+\t\t\t{ \"name\": \"Order\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Grouping\", \"value\": \"not grouped\" },\n+\t\t\t{ \"name\": \"Uniqueness\", \"value\": \"not unique\" }\n+\t\t],\n+\t\t\"estimates\": [\n+\t\t\t{ \"name\": \"Est. Output Size\", \"value\": \"(unknown)\" },\n+\t\t\t{ \"name\": \"Est. Cardinality\", \"value\": \"10.00\" }\t\t],\n+\t\t\"costs\": [\n+\t\t\t{ \"name\": \"Network\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"Disk I/O\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"CPU\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"Cumulative Network\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"Cumulative Disk I/O\", \"value\": \"190.00\" },\n+\t\t\t{ \"name\": \"Cumulative CPU\", \"value\": \"0.0\" }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjUzNTg3NA=="}, "originalCommit": {"oid": "61cdd876e27d23952da5c66f6d201c7c7102ad3f"}, "originalPosition": 112}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4721, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}