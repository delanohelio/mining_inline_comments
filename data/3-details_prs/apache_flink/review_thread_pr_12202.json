{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE5MTE4MTY5", "number": 12202, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQwNzoxOToxMFrOD9RKGg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQwNzoyMzo0MFrOD9RPuA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NTcwODQyOnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/datastream/DataStreamUtils.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQwNzoxOToxMFrOGWqSxA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQwNzoxOToxMFrOGWqSxA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjQxNDc4OA==", "bodyText": "id is meaningless  here, use \"data stream collect\" ?", "url": "https://github.com/apache/flink/pull/12202#discussion_r426414788", "createdAt": "2020-05-18T07:19:10Z", "author": {"login": "godfreyhe"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/datastream/DataStreamUtils.java", "diffHunk": "@@ -47,44 +44,30 @@\n \t * Returns an iterator to iterate over the elements of the DataStream.\n \t * @return The iterator\n \t */\n-\tpublic static <OUT> Iterator<OUT> collect(DataStream<OUT> stream) throws IOException {\n-\n+\tpublic static <OUT> Iterator<OUT> collect(DataStream<OUT> stream) {\n \t\tTypeSerializer<OUT> serializer = stream.getType().createSerializer(\n-\t\t\t\tstream.getExecutionEnvironment().getConfig());\n+\t\t\tstream.getExecutionEnvironment().getConfig());\n+\t\tString id = UUID.randomUUID().toString();\n+\t\tString accumulatorName = \"dataStreamCollect_\" + id;\n \n-\t\tSocketStreamIterator<OUT> iter = new SocketStreamIterator<OUT>(serializer);\n+\t\tCollectSinkOperatorFactory<OUT> factory = new CollectSinkOperatorFactory<>(serializer, accumulatorName);\n+\t\tCollectSinkOperator<OUT> operator = (CollectSinkOperator<OUT>) factory.getOperator();\n+\t\tCollectResultIterator<OUT> iterator = new CollectResultIterator<>(\n+\t\t\toperator.getOperatorIdFuture(), serializer, accumulatorName);\n+\t\tCollectStreamSink<OUT> sink = new CollectStreamSink<>(stream, factory);\n+\t\tsink.name(\"Data stream collect sink\");\n \n-\t\t//Find out what IP of us should be given to CollectSink, that it will be able to connect to\n \t\tStreamExecutionEnvironment env = stream.getExecutionEnvironment();\n-\t\tInetAddress clientAddress;\n-\n-\t\tif (env instanceof RemoteStreamEnvironment) {\n-\t\t\tString host = ((RemoteStreamEnvironment) env).getHost();\n-\t\t\tint port = ((RemoteStreamEnvironment) env).getPort();\n-\t\t\ttry {\n-\t\t\t\tclientAddress = ConnectionUtils.findConnectingAddress(new InetSocketAddress(host, port), 2000, 400);\n-\t\t\t}\n-\t\t\tcatch (Exception e) {\n-\t\t\t\tthrow new IOException(\"Could not determine an suitable network address to \" +\n-\t\t\t\t\t\t\"receive back data from the streaming program.\", e);\n-\t\t\t}\n-\t\t} else if (env instanceof LocalStreamEnvironment) {\n-\t\t\tclientAddress = InetAddress.getLoopbackAddress();\n-\t\t} else {\n-\t\t\ttry {\n-\t\t\t\tclientAddress = InetAddress.getLocalHost();\n-\t\t\t} catch (UnknownHostException e) {\n-\t\t\t\tthrow new IOException(\"Could not determine this machines own local address to \" +\n-\t\t\t\t\t\t\"receive back data from the streaming program.\", e);\n-\t\t\t}\n-\t\t}\n-\n-\t\tDataStreamSink<OUT> sink = stream.addSink(new CollectSink<OUT>(clientAddress, iter.getPort(), serializer));\n-\t\tsink.setParallelism(1); // It would not work if multiple instances would connect to the same port\n+\t\tenv.addOperator(sink.getTransformation());\n \n-\t\t(new CallExecute(env, iter)).start();\n+\t\ttry {\n+\t\t\tJobClient jobClient = env.executeAsync(\"DataStreamCollect_\" + id);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3a44fbe9824e576068a4f172ca5738a7dd5cf9d1"}, "originalPosition": 79}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NTcxNDU1OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectStreamSink.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQwNzoyMToxMFrOGWqWlg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQwNzoyMToxMFrOGWqWlg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjQxNTc2Ng==", "bodyText": "CollectStreamSink  is not only used for select query but also for DataStream collect, so make this comment more generic.", "url": "https://github.com/apache/flink/pull/12202#discussion_r426415766", "createdAt": "2020-05-18T07:21:10Z", "author": {"login": "godfreyhe"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectStreamSink.java", "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.streaming.api.datastream.DataStream;\n+import org.apache.flink.streaming.api.datastream.DataStreamSink;\n+import org.apache.flink.streaming.api.operators.ChainingStrategy;\n+import org.apache.flink.streaming.api.transformations.SinkTransformation;\n+\n+/**\n+ * A {@link DataStreamSink} which is used to collect query results.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3a44fbe9824e576068a4f172ca5738a7dd5cf9d1"}, "originalPosition": 27}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NTcyMjgwOnYy", "diffSide": "RIGHT", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/sinks/BatchSelectTableSink.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQwNzoyMzo0MFrOGWqbfg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQwNzoyMzo0MFrOGWqbfg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjQxNzAyMg==", "bodyText": "we can extract the most code of BatchSelectTableSink and StreamSelectTableSink  into a base class (SelectTableSinkBase)", "url": "https://github.com/apache/flink/pull/12202#discussion_r426417022", "createdAt": "2020-05-18T07:23:40Z", "author": {"login": "godfreyhe"}, "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/sinks/BatchSelectTableSink.java", "diffHunk": "@@ -49,19 +44,24 @@\n  * once FLINK-14807 is finished, the implementation should be changed.\n  */\n public class BatchSelectTableSink implements StreamTableSink<Row>, SelectTableSink {\n+\n \tprivate final TableSchema tableSchema;\n-\tprivate final String accumulatorName;\n-\tprivate final TypeSerializer<Row> typeSerializer;\n-\tprivate JobClient jobClient;\n+\tprivate final CollectSinkOperatorFactory<Row> factory;\n+\tprivate final CollectResultIterator<Row> iterator;\n \n \t@SuppressWarnings(\"unchecked\")\n \tpublic BatchSelectTableSink(TableSchema tableSchema) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3a44fbe9824e576068a4f172ca5738a7dd5cf9d1"}, "originalPosition": 47}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1351, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}