{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDMyOTQ3ODQ2", "number": 12597, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQwNjo0NToxMFrOEE80bA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQwNjo0Nzo0OFrOEE82uw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczNjI2MjIwOnYy", "diffSide": "RIGHT", "path": "docs/dev/table/connectors/formats/parquet.md", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQwNjo0NToxMFrOGi45Hw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQwNjo0NToxMFrOGi45Hw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTIzNjg5NQ==", "bodyText": "Only allows stable release link ?", "url": "https://github.com/apache/flink/pull/12597#discussion_r439236895", "createdAt": "2020-06-12T06:45:10Z", "author": {"login": "danny0405"}, "path": "docs/dev/table/connectors/formats/parquet.md", "diffHunk": "@@ -0,0 +1,189 @@\n+---\n+title: \"Parquet Format\"\n+nav-title: Parquet\n+nav-parent_id: sql-formats\n+nav-pos: 5\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+<span class=\"label label-info\">Format: Serialization Schema</span>\n+<span class=\"label label-info\">Format: Deserialization Schema</span>\n+\n+* This will be replaced by the TOC\n+{:toc}\n+\n+The [Apache Parquet](https://parquet.apache.org/) format allows to read and write Parquet data.\n+\n+Dependencies\n+------------\n+\n+In order to setup the Parquet format, the following table provides dependency information for both\n+projects using a build automation tool (such as Maven or SBT) and SQL Client with SQL JAR bundles.\n+\n+| Maven dependency   | SQL Client JAR         |\n+| :----------------- | :----------------------|\n+| `flink-parquet`    | [Download](https://repo.maven.apache.org/maven2/org/apache/flink/flink-parquet{{site.scala_version_suffix}}/{{site.version}}/flink-parquet{{site.scala_version_suffix}}-{{site.version}}-jar-with-dependencies.jar) |\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "63ee22532e4ed8321a0e1c14a922b2cf1a2679e0"}, "originalPosition": 43}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczNjI2ODExOnYy", "diffSide": "RIGHT", "path": "docs/dev/table/connectors/formats/parquet.md", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQwNjo0Nzo0OFrOGi489Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQwNjo0Nzo0OFrOGi489Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTIzNzg3Nw==", "bodyText": "Composite data type: Array, Map and Row are not supported.", "url": "https://github.com/apache/flink/pull/12597#discussion_r439237877", "createdAt": "2020-06-12T06:47:48Z", "author": {"login": "danny0405"}, "path": "docs/dev/table/connectors/formats/parquet.md", "diffHunk": "@@ -0,0 +1,189 @@\n+---\n+title: \"Parquet Format\"\n+nav-title: Parquet\n+nav-parent_id: sql-formats\n+nav-pos: 5\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+<span class=\"label label-info\">Format: Serialization Schema</span>\n+<span class=\"label label-info\">Format: Deserialization Schema</span>\n+\n+* This will be replaced by the TOC\n+{:toc}\n+\n+The [Apache Parquet](https://parquet.apache.org/) format allows to read and write Parquet data.\n+\n+Dependencies\n+------------\n+\n+In order to setup the Parquet format, the following table provides dependency information for both\n+projects using a build automation tool (such as Maven or SBT) and SQL Client with SQL JAR bundles.\n+\n+| Maven dependency   | SQL Client JAR         |\n+| :----------------- | :----------------------|\n+| `flink-parquet`    | [Download](https://repo.maven.apache.org/maven2/org/apache/flink/flink-parquet{{site.scala_version_suffix}}/{{site.version}}/flink-parquet{{site.scala_version_suffix}}-{{site.version}}-jar-with-dependencies.jar) |\n+\n+How to create a table with Parquet format\n+----------------\n+\n+Here is an example to create a table using Filesystem connector and Parquet format.\n+\n+<div class=\"codetabs\" markdown=\"1\">\n+<div data-lang=\"SQL\" markdown=\"1\">\n+{% highlight sql %}\n+CREATE TABLE user_behavior (\n+  user_id BIGINT,\n+  item_id BIGINT,\n+  category_id BIGINT,\n+  behavior STRING,\n+  ts TIMESTAMP(3),\n+  dt STRING\n+) PARTITIONED BY (dt) WITH (\n+ 'connector' = 'filesystem',\n+ 'path' = '/tmp/user_behavior',\n+ 'format' = 'parquet'\n+)\n+{% endhighlight %}\n+</div>\n+</div>\n+\n+Format Options\n+----------------\n+\n+<table class=\"table table-bordered\">\n+    <thead>\n+      <tr>\n+        <th class=\"text-left\" style=\"width: 25%\">Option</th>\n+        <th class=\"text-center\" style=\"width: 8%\">Required</th>\n+        <th class=\"text-center\" style=\"width: 7%\">Default</th>\n+        <th class=\"text-center\" style=\"width: 10%\">Type</th>\n+        <th class=\"text-center\" style=\"width: 50%\">Description</th>\n+      </tr>\n+    </thead>\n+    <tbody>\n+    <tr>\n+      <td><h5>format</h5></td>\n+      <td>required</td>\n+      <td style=\"word-wrap: break-word;\">(none)</td>\n+      <td>String</td>\n+      <td>Specify what format to use, here should be 'parquet'.</td>\n+    </tr>\n+    <tr>\n+      <td><h5>parquet.utc-timezone</h5></td>\n+      <td>optional</td>\n+      <td style=\"word-wrap: break-word;\">false</td>\n+      <td>Boolean</td>\n+      <td>Use UTC timezone or local timezone to the conversion between epoch time and LocalDateTime. Hive 0.x/1.x/2.x use local timezone. But Hive 3.x use UTC timezone.</td>\n+    </tr>\n+    </tbody>\n+</table>\n+\n+Parquet format also supports configuration from [ParquetOutputFormat](https://www.javadoc.io/doc/org.apache.parquet/parquet-hadoop/1.10.0/org/apache/parquet/hadoop/ParquetOutputFormat.html).\n+For example, you can configure `parquet.compression=GZIP` to enable gzip compression.\n+\n+Data Type Mapping\n+----------------\n+\n+Currently, Parquet format type mapping is compatible with Apache Hive, but different with Apache Spark:\n+\n+- Timestamp: mapping timestamp type to int96 whatever the precision is.\n+- Decimal: mapping decimal type to fixed length byte array according to the precision.\n+\n+The following table lists the type mapping from Flink type to Parquet type.\n+\n+<table class=\"table table-bordered\">\n+    <thead>\n+      <tr>\n+        <th class=\"text-left\">Flink Data Type</th>\n+        <th class=\"text-center\">Parquet type</th>\n+        <th class=\"text-center\">Parquet logical type</th>\n+      </tr>\n+    </thead>\n+    <tbody>\n+    <tr>\n+      <td>CHAR / VARCHAR / STRING</td>\n+      <td>BINARY</td>\n+      <td>UTF8</td>\n+    </tr>\n+    <tr>\n+      <td>BOOLEAN</td>\n+      <td>BOOLEAN</td>\n+      <td></td>\n+    </tr>\n+    <tr>\n+      <td>BINARY / VARBINARY</td>\n+      <td>BINARY</td>\n+      <td></td>\n+    </tr>\n+    <tr>\n+      <td>DECIMAL</td>\n+      <td>FIXED_LEN_BYTE_ARRAY</td>\n+      <td>DECIMAL</td>\n+    </tr>\n+    <tr>\n+      <td>TINYINT</td>\n+      <td>INT32</td>\n+      <td>INT_8</td>\n+    </tr>\n+    <tr>\n+      <td>SMALLINT</td>\n+      <td>INT32</td>\n+      <td>INT_16</td>\n+    </tr>\n+    <tr>\n+      <td>INT</td>\n+      <td>INT32</td>\n+      <td></td>\n+    </tr>\n+    <tr>\n+      <td>BIGINT</td>\n+      <td>INT64</td>\n+      <td></td>\n+    </tr>\n+    <tr>\n+      <td>FLOAT</td>\n+      <td>FLOAT</td>\n+      <td></td>\n+    </tr>\n+    <tr>\n+      <td>DOUBLE</td>\n+      <td>DOUBLE</td>\n+      <td></td>\n+    </tr>\n+    <tr>\n+      <td>DATE</td>\n+      <td>INT32</td>\n+      <td>DATE</td>\n+    </tr>\n+    <tr>\n+      <td>TIME</td>\n+      <td>INT32</td>\n+      <td>TIME_MILLIS</td>\n+    </tr>\n+    <tr>\n+      <td>TIMESTAMP</td>\n+      <td>INT96</td>\n+      <td></td>\n+    </tr>\n+    </tbody>\n+</table>\n+\n+<span class=\"label label-danger\">Attention</span> Not support complex data type like: Array, Map, Row.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "63ee22532e4ed8321a0e1c14a922b2cf1a2679e0"}, "originalPosition": 189}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4380, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}