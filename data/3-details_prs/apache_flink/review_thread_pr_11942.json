{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDEwNTg2NjA2", "number": 11942, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQxMjowNzoyOVrOD3mL6Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQxMjo1MzoxOVrOD3nNDQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5NjIzOTEzOnYy", "diffSide": "RIGHT", "path": "flink-formats/flink-orc/src/main/java/org/apache/flink/orc/OrcFileSystemFormatFactory.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQxMjowNzoyOVrOGN7zMA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQxMjowNzoyOVrOGN7zMA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzI2NDQzMg==", "bodyText": "rename to ORC_PROPERTY_PREFIX?", "url": "https://github.com/apache/flink/pull/11942#discussion_r417264432", "createdAt": "2020-04-29T12:07:29Z", "author": {"login": "lirui-apache"}, "path": "flink-formats/flink-orc/src/main/java/org/apache/flink/orc/OrcFileSystemFormatFactory.java", "diffHunk": "@@ -0,0 +1,230 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.orc;\n+\n+import org.apache.flink.api.common.io.FileInputFormat;\n+import org.apache.flink.api.common.io.InputFormat;\n+import org.apache.flink.api.common.serialization.BulkWriter;\n+import org.apache.flink.api.common.serialization.Encoder;\n+import org.apache.flink.core.fs.FileInputSplit;\n+import org.apache.flink.core.fs.Path;\n+import org.apache.flink.orc.vector.RowDataVectorizer;\n+import org.apache.flink.orc.writer.OrcBulkWriterFactory;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.descriptors.DescriptorProperties;\n+import org.apache.flink.table.factories.FileSystemFormatFactory;\n+import org.apache.flink.table.filesystem.PartitionPathUtils;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.RowType;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.ql.exec.vector.VectorizedRowBatch;\n+import org.apache.orc.TypeDescription;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Properties;\n+\n+import static org.apache.flink.table.data.vector.VectorizedColumnBatch.DEFAULT_SIZE;\n+import static org.apache.flink.table.descriptors.FormatDescriptorValidator.FORMAT;\n+import static org.apache.flink.table.filesystem.RowPartitionComputer.restorePartValueFromType;\n+\n+/**\n+ * Orc {@link FileSystemFormatFactory} for file system.\n+ */\n+public class OrcFileSystemFormatFactory implements FileSystemFormatFactory {\n+\n+\t/**\n+\t * Prefix for orc-related properties, besides format, start with \"orc\".\n+\t * See more in {@link org.apache.orc.OrcConf}.\n+\t */\n+\tpublic static final String ORC_PROPERTIES = \"format.orc\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5e6e5057f05147c8eed38a148d54ad0f0022a5b9"}, "originalPosition": 65}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5NjQwNTg5OnYy", "diffSide": "RIGHT", "path": "flink-formats/flink-orc/src/main/java/org/apache/flink/orc/vector/RowDataVectorizer.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQxMjo1MzoxOVrOGN9ZUw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQxMjo1MzoxOVrOGN9ZUw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzI5MDU3OQ==", "bodyText": "rename i to columnId?", "url": "https://github.com/apache/flink/pull/11942#discussion_r417290579", "createdAt": "2020-04-29T12:53:19Z", "author": {"login": "lirui-apache"}, "path": "flink-formats/flink-orc/src/main/java/org/apache/flink/orc/vector/RowDataVectorizer.java", "diffHunk": "@@ -0,0 +1,144 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.orc.vector;\n+\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.LocalZonedTimestampType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+\n+import org.apache.hadoop.hive.common.type.HiveDecimal;\n+import org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector;\n+import org.apache.hadoop.hive.ql.exec.vector.ColumnVector;\n+import org.apache.hadoop.hive.ql.exec.vector.DecimalColumnVector;\n+import org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector;\n+import org.apache.hadoop.hive.ql.exec.vector.LongColumnVector;\n+import org.apache.hadoop.hive.ql.exec.vector.TimestampColumnVector;\n+import org.apache.hadoop.hive.ql.exec.vector.VectorizedRowBatch;\n+\n+import java.sql.Timestamp;\n+\n+/**\n+ * A {@link Vectorizer} of {@link RowData} type element.\n+ */\n+public class RowDataVectorizer extends Vectorizer<RowData> {\n+\n+\tprivate final LogicalType[] fieldTypes;\n+\n+\tpublic RowDataVectorizer(String schema, LogicalType[] fieldTypes) {\n+\t\tsuper(schema);\n+\t\tthis.fieldTypes = fieldTypes;\n+\t}\n+\n+\t@Override\n+\tpublic void vectorize(RowData row, VectorizedRowBatch batch) {\n+\t\tint rowId = batch.size++;\n+\t\tfor(int i = 0; i < row.getArity(); ++i) {\n+\t\t\tsetColumn(rowId, batch.cols[i], fieldTypes[i], row, i);\n+\t\t}\n+\t}\n+\n+\tprivate static void setColumn(\n+\t\t\tint rowId, ColumnVector column, LogicalType type, RowData row, int i) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5e6e5057f05147c8eed38a148d54ad0f0022a5b9"}, "originalPosition": 59}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1455, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}