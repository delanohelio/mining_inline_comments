{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDIwODAwNzc4", "number": 12269, "title": "[FLINK-17351] [runtime] Increase `continuousFailureCounter` in `CheckpointFailureManager` for CHECKPOINT_EXPIRED", "bodyText": "What is the purpose of the change\nBefore this PR, CHECKPOINT_EXPIRED was not counted in continuousFailureCounter. Hence,\nif the failure of checkpointing is detected after checkpoint times out, the failure gets ignored since\nthe PendingCheckpoint has already been discarded, leading the job unable to restart automatically in theory, unless something else fails.\nThis PR counts CHECKPOINT_EXPIRED in continuousFailureCounter.\nBrief change log\n\nCHECKPOINT_EXPIRED is counted in CheckpointFailureManager#continuousFailureCounter.\n\nVerifying this change\nunit tests\nCheckpointCoordinatorTest#testExpiredCheckpointExceedsTolerableFailureNumber\nDoes this pull request potentially affect one of the following parts:\n\nDependencies (does it add or upgrade a dependency): no\nThe public API, i.e., is any changed class annotated with @Public(Evolving): no\nThe serializers: no\nThe runtime per-record code paths (performance sensitive): no\nAnything that affects deployment or recovery: JobManager (and its components), Checkpointing, Kubernetes/Yarn/Mesos, ZooKeeper: Checkpointing\nThe S3 file system connector: no\n\nDocumentation\n\nDoes this pull request introduce a new feature? no\nIf yes, how is the feature documented?  not applicable", "createdAt": "2020-05-20T14:47:47Z", "url": "https://github.com/apache/flink/pull/12269", "merged": true, "mergeCommit": {"oid": "3ec768a6c8f37dbe1dbb684e84c9844ad09957d9"}, "closed": true, "closedAt": "2020-05-27T15:10:35Z", "author": {"login": "curcur"}, "timelineItems": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcjKSOFgBqjMzNTY4NjIxNjM=", "endCursor": "Y3Vyc29yOnYyOpPPAAABck_1cagFqTQxODA1MDIwNQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8da849c3217f1ff94fcf65f63c5eea7f9cd49ed5", "author": {"user": {"login": "curcur", "name": "Yuan Mei"}}, "url": "https://github.com/apache/flink/commit/8da849c3217f1ff94fcf65f63c5eea7f9cd49ed5", "committedDate": "2020-05-20T14:27:34Z", "message": "[FLINK-17351] Increase `continuousFailureCounter` in `CheckpointFailureManager` for CHECKPOINT_EXPIRED\n\nBefore this PR, `CHECKPOINT_EXPIRED` is not counted in `continuousFailureCounter`. Hence,\nif the failure of checkpointing is detected after checkpoint times out, the failure get ignored since\nthe `PendingCheckpoint` has already been discarded, leading the job unable to restart automatically in theory\nunless something else fails.\n\nThis PR counts `CHECKPOINT_EXPIRED` in `continuousFailureCounter`."}, "afterCommit": {"oid": "24c44fd00652a6b5859075b3afea1e4e9ca98445", "author": {"user": {"login": "curcur", "name": "Yuan Mei"}}, "url": "https://github.com/apache/flink/commit/24c44fd00652a6b5859075b3afea1e4e9ca98445", "committedDate": "2020-05-20T14:51:38Z", "message": "[FLINK-17351] Increase `continuousFailureCounter` in `CheckpointFailureManager` for CHECKPOINT_EXPIRED\n\nBefore this PR, `CHECKPOINT_EXPIRED` is not counted in `continuousFailureCounter`. Hence,\nif the failure of checkpointing is detected after checkpoint times out, the failure gets ignored since\nthe `PendingCheckpoint` has already been discarded, leading the job unable to restart automatically in theory\nunless something else fails.\n\nThis PR counts `CHECKPOINT_EXPIRED` in `continuousFailureCounter`."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE2MTE2MDAx", "url": "https://github.com/apache/flink/pull/12269#pullrequestreview-416116001", "createdAt": "2020-05-21T12:48:17Z", "commit": {"oid": "24c44fd00652a6b5859075b3afea1e4e9ca98445"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQxMjo0ODoxN1rOGYxg0A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQxMzowODoxMFrOGYyGPw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODYzMDIyNA==", "bodyText": "I think using org.junit.Test#expected (and a specific exception class) would be more expressive and less verbose here.", "url": "https://github.com/apache/flink/pull/12269#discussion_r428630224", "createdAt": "2020-05-21T12:48:17Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/CheckpointCoordinatorTest.java", "diffHunk": "@@ -262,6 +251,40 @@ public void failJobDueToTaskFailure(Throwable cause, ExecutionAttemptID failingT\n \t\t}\n \t}\n \n+\t@Test\n+\tpublic void testExpiredCheckpointExceedsTolerableFailureNumber() {\n+\t\t// create some mock Execution vertices that receive the checkpoint trigger messages\n+\t\tExecutionVertex vertex1 = mockExecutionVertex(new ExecutionAttemptID());\n+\t\tExecutionVertex vertex2 = mockExecutionVertex(new ExecutionAttemptID());\n+\n+\t\tfinal String errorMsg = \"Exceeded checkpoint failure tolerance number!\";\n+\t\tCheckpointFailureManager checkpointFailureManager = getCheckpointFailureManager(errorMsg);\n+\t\tCheckpointCoordinator coord = getCheckpointCoordinator(new JobID(), vertex1, vertex2, checkpointFailureManager);\n+\n+\t\ttry {\n+\t\t\t// trigger the checkpoint. this should succeed\n+\t\t\tfinal CompletableFuture<CompletedCheckpoint> checkPointFuture = coord.triggerCheckpoint(false);\n+\t\t\tmanuallyTriggeredScheduledExecutor.triggerAll();\n+\t\t\tassertFalse(checkPointFuture.isCompletedExceptionally());\n+\n+\t\t\tcoord.abortPendingCheckpoints(new CheckpointException(CHECKPOINT_EXPIRED));\n+\n+\t\t\tfail(\"Test failed.\");\n+\t\t}\n+\t\tcatch (Exception e) {\n+\t\t\t//expected\n+\t\t\tassertTrue(e instanceof RuntimeException);\n+\t\t\tassertEquals(errorMsg, e.getMessage());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "24c44fd00652a6b5859075b3afea1e4e9ca98445"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODYzMDkxMA==", "bodyText": "Why do we need to handle this error? Won't it's stacktrace be printed and test fail anyways?", "url": "https://github.com/apache/flink/pull/12269#discussion_r428630910", "createdAt": "2020-05-21T12:49:51Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/CheckpointCoordinatorTest.java", "diffHunk": "@@ -262,6 +251,40 @@ public void failJobDueToTaskFailure(Throwable cause, ExecutionAttemptID failingT\n \t\t}\n \t}\n \n+\t@Test\n+\tpublic void testExpiredCheckpointExceedsTolerableFailureNumber() {\n+\t\t// create some mock Execution vertices that receive the checkpoint trigger messages\n+\t\tExecutionVertex vertex1 = mockExecutionVertex(new ExecutionAttemptID());\n+\t\tExecutionVertex vertex2 = mockExecutionVertex(new ExecutionAttemptID());\n+\n+\t\tfinal String errorMsg = \"Exceeded checkpoint failure tolerance number!\";\n+\t\tCheckpointFailureManager checkpointFailureManager = getCheckpointFailureManager(errorMsg);\n+\t\tCheckpointCoordinator coord = getCheckpointCoordinator(new JobID(), vertex1, vertex2, checkpointFailureManager);\n+\n+\t\ttry {\n+\t\t\t// trigger the checkpoint. this should succeed\n+\t\t\tfinal CompletableFuture<CompletedCheckpoint> checkPointFuture = coord.triggerCheckpoint(false);\n+\t\t\tmanuallyTriggeredScheduledExecutor.triggerAll();\n+\t\t\tassertFalse(checkPointFuture.isCompletedExceptionally());\n+\n+\t\t\tcoord.abortPendingCheckpoints(new CheckpointException(CHECKPOINT_EXPIRED));\n+\n+\t\t\tfail(\"Test failed.\");\n+\t\t}\n+\t\tcatch (Exception e) {\n+\t\t\t//expected\n+\t\t\tassertTrue(e instanceof RuntimeException);\n+\t\t\tassertEquals(errorMsg, e.getMessage());\n+\t\t} finally {\n+\t\t\ttry {\n+\t\t\t\tcoord.shutdown(JobStatus.FINISHED);\n+\t\t\t} catch (Exception e) {\n+\t\t\t\te.printStackTrace();\n+\t\t\t\tfail(e.getMessage());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "24c44fd00652a6b5859075b3afea1e4e9ca98445"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODYzMjMyMQ==", "bodyText": "I think this check is not necessary here because triggering should be tested separately\n(and the next check should fail anyways if trigger failed)", "url": "https://github.com/apache/flink/pull/12269#discussion_r428632321", "createdAt": "2020-05-21T12:52:48Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/CheckpointCoordinatorTest.java", "diffHunk": "@@ -262,6 +251,40 @@ public void failJobDueToTaskFailure(Throwable cause, ExecutionAttemptID failingT\n \t\t}\n \t}\n \n+\t@Test\n+\tpublic void testExpiredCheckpointExceedsTolerableFailureNumber() {\n+\t\t// create some mock Execution vertices that receive the checkpoint trigger messages\n+\t\tExecutionVertex vertex1 = mockExecutionVertex(new ExecutionAttemptID());\n+\t\tExecutionVertex vertex2 = mockExecutionVertex(new ExecutionAttemptID());\n+\n+\t\tfinal String errorMsg = \"Exceeded checkpoint failure tolerance number!\";\n+\t\tCheckpointFailureManager checkpointFailureManager = getCheckpointFailureManager(errorMsg);\n+\t\tCheckpointCoordinator coord = getCheckpointCoordinator(new JobID(), vertex1, vertex2, checkpointFailureManager);\n+\n+\t\ttry {\n+\t\t\t// trigger the checkpoint. this should succeed\n+\t\t\tfinal CompletableFuture<CompletedCheckpoint> checkPointFuture = coord.triggerCheckpoint(false);\n+\t\t\tmanuallyTriggeredScheduledExecutor.triggerAll();\n+\t\t\tassertFalse(checkPointFuture.isCompletedExceptionally());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "24c44fd00652a6b5859075b3afea1e4e9ca98445"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODYzMzMzOA==", "bodyText": "nit: this comment basically repeats what the code does, I think it's unnecessary", "url": "https://github.com/apache/flink/pull/12269#discussion_r428633338", "createdAt": "2020-05-21T12:54:59Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/CheckpointCoordinatorTest.java", "diffHunk": "@@ -262,6 +251,40 @@ public void failJobDueToTaskFailure(Throwable cause, ExecutionAttemptID failingT\n \t\t}\n \t}\n \n+\t@Test\n+\tpublic void testExpiredCheckpointExceedsTolerableFailureNumber() {\n+\t\t// create some mock Execution vertices that receive the checkpoint trigger messages\n+\t\tExecutionVertex vertex1 = mockExecutionVertex(new ExecutionAttemptID());\n+\t\tExecutionVertex vertex2 = mockExecutionVertex(new ExecutionAttemptID());\n+\n+\t\tfinal String errorMsg = \"Exceeded checkpoint failure tolerance number!\";\n+\t\tCheckpointFailureManager checkpointFailureManager = getCheckpointFailureManager(errorMsg);\n+\t\tCheckpointCoordinator coord = getCheckpointCoordinator(new JobID(), vertex1, vertex2, checkpointFailureManager);\n+\n+\t\ttry {\n+\t\t\t// trigger the checkpoint. this should succeed", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "24c44fd00652a6b5859075b3afea1e4e9ca98445"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODYzOTgwNw==", "bodyText": "\ud83d\udc4d for extracting shared code", "url": "https://github.com/apache/flink/pull/12269#discussion_r428639807", "createdAt": "2020-05-21T13:08:10Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/CheckpointCoordinatorTest.java", "diffHunk": "@@ -2292,6 +2315,22 @@ private CheckpointCoordinator getCheckpointCoordinator() {\n \t\t\t.build();\n \t}\n \n+\tprivate CheckpointFailureManager getCheckpointFailureManager(String errorMsg) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "24c44fd00652a6b5859075b3afea1e4e9ca98445"}, "originalPosition": 83}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "24c44fd00652a6b5859075b3afea1e4e9ca98445", "author": {"user": {"login": "curcur", "name": "Yuan Mei"}}, "url": "https://github.com/apache/flink/commit/24c44fd00652a6b5859075b3afea1e4e9ca98445", "committedDate": "2020-05-20T14:51:38Z", "message": "[FLINK-17351] Increase `continuousFailureCounter` in `CheckpointFailureManager` for CHECKPOINT_EXPIRED\n\nBefore this PR, `CHECKPOINT_EXPIRED` is not counted in `continuousFailureCounter`. Hence,\nif the failure of checkpointing is detected after checkpoint times out, the failure gets ignored since\nthe `PendingCheckpoint` has already been discarded, leading the job unable to restart automatically in theory\nunless something else fails.\n\nThis PR counts `CHECKPOINT_EXPIRED` in `continuousFailureCounter`."}, "afterCommit": {"oid": "f415b350558bea9b17e12638e70efc701f06c14d", "author": {"user": {"login": "curcur", "name": "Yuan Mei"}}, "url": "https://github.com/apache/flink/commit/f415b350558bea9b17e12638e70efc701f06c14d", "committedDate": "2020-05-22T03:30:49Z", "message": "[FLINK-17351] Increase `continuousFailureCounter` in `CheckpointFailureManager` for CHECKPOINT_EXPIRED\n\nBefore this PR, `CHECKPOINT_EXPIRED` is not counted in `continuousFailureCounter`. Hence,\nif the failure of checkpointing is detected after checkpoint times out, the failure gets ignored since\nthe `PendingCheckpoint` has already been discarded, leading the job unable to restart automatically in theory\nunless something else fails.\n\nThis PR counts `CHECKPOINT_EXPIRED` in `continuousFailureCounter`."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dce852dcb934f4b8e301b3b242decd2704d99cc8", "author": {"user": {"login": "curcur", "name": "Yuan Mei"}}, "url": "https://github.com/apache/flink/commit/dce852dcb934f4b8e301b3b242decd2704d99cc8", "committedDate": "2020-05-26T03:25:43Z", "message": "[FLINK-17351] Increase `continuousFailureCounter` in `CheckpointFailureManager` for CHECKPOINT_EXPIRED\n\nBefore this PR, `CHECKPOINT_EXPIRED` is not counted in `continuousFailureCounter`. Hence,\nif the failure of checkpointing is detected after checkpoint times out, the failure gets ignored since\nthe `PendingCheckpoint` has already been discarded, leading the job unable to restart automatically in theory\nunless something else fails.\n\nThis PR counts `CHECKPOINT_EXPIRED` in `continuousFailureCounter`."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f415b350558bea9b17e12638e70efc701f06c14d", "author": {"user": {"login": "curcur", "name": "Yuan Mei"}}, "url": "https://github.com/apache/flink/commit/f415b350558bea9b17e12638e70efc701f06c14d", "committedDate": "2020-05-22T03:30:49Z", "message": "[FLINK-17351] Increase `continuousFailureCounter` in `CheckpointFailureManager` for CHECKPOINT_EXPIRED\n\nBefore this PR, `CHECKPOINT_EXPIRED` is not counted in `continuousFailureCounter`. Hence,\nif the failure of checkpointing is detected after checkpoint times out, the failure gets ignored since\nthe `PendingCheckpoint` has already been discarded, leading the job unable to restart automatically in theory\nunless something else fails.\n\nThis PR counts `CHECKPOINT_EXPIRED` in `continuousFailureCounter`."}, "afterCommit": {"oid": "dce852dcb934f4b8e301b3b242decd2704d99cc8", "author": {"user": {"login": "curcur", "name": "Yuan Mei"}}, "url": "https://github.com/apache/flink/commit/dce852dcb934f4b8e301b3b242decd2704d99cc8", "committedDate": "2020-05-26T03:25:43Z", "message": "[FLINK-17351] Increase `continuousFailureCounter` in `CheckpointFailureManager` for CHECKPOINT_EXPIRED\n\nBefore this PR, `CHECKPOINT_EXPIRED` is not counted in `continuousFailureCounter`. Hence,\nif the failure of checkpointing is detected after checkpoint times out, the failure gets ignored since\nthe `PendingCheckpoint` has already been discarded, leading the job unable to restart automatically in theory\nunless something else fails.\n\nThis PR counts `CHECKPOINT_EXPIRED` in `continuousFailureCounter`."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4MDUwMjA1", "url": "https://github.com/apache/flink/pull/12269#pullrequestreview-418050205", "createdAt": "2020-05-26T07:49:45Z", "commit": {"oid": "dce852dcb934f4b8e301b3b242decd2704d99cc8"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4678, "cost": 1, "resetAt": "2021-10-28T16:48:13Z"}}}