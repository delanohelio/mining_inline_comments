{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg1MTQ3NDUx", "number": 11342, "title": "[FLINK-16483][python] Add Python building blocks to make sure the basic functionality of vectorized Python UDF could work", "bodyText": "What is the purpose of the change\nThis pull request add the Python building blocks to make sure the basic functionality of vectorized Python UDF could work.\nBrief change log\n\nChanges in udf.py to make sure we can define vectorized Python UDF\nIntroduce ArrowCoder/ArrowCoderImpl for Arrow data serialization/deserialization\n\nVerifying this change\nThis change added tests and can be verified as follows:\n\nAdded tests test_pandas_udf\n\nDoes this pull request potentially affect one of the following parts:\n\nDependencies (does it add or upgrade a dependency): (yes, python dependency pyarrow and pandas)\nThe public API, i.e., is any changed class annotated with @Public(Evolving): (no)\nThe serializers: (no)\nThe runtime per-record code paths (performance sensitive): (no)\nAnything that affects deployment or recovery: JobManager (and its components), Checkpointing, Kubernetes/Yarn/Mesos, ZooKeeper: (no)\nThe S3 file system connector: (no)\n\nDocumentation\n\nDoes this pull request introduce a new feature? (no)\nIf yes, how is the feature documented? (not applicable)", "createdAt": "2020-03-07T13:59:08Z", "url": "https://github.com/apache/flink/pull/11342", "merged": true, "mergeCommit": {"oid": "6f19fd2a72e85c9954d4e1830e15637180fee8ec"}, "closed": true, "closedAt": "2020-03-10T11:36:16Z", "author": {"login": "dianfu"}, "timelineItems": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcL_vvkgFqTM3MDk3NjEwNg==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcMQ58ugFqTM3MTg3NDkwMA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcwOTc2MTA2", "url": "https://github.com/apache/flink/pull/11342#pullrequestreview-370976106", "createdAt": "2020-03-09T08:17:20Z", "commit": {"oid": "27f93cc605b980ae0ce93b1d5503031ae98f6cd9"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQwODoxNzoyMVrOFzd7sQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQxNTozMTozNVrOFztn_w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTUxMjExMw==", "bodyText": "Remove the blank between the version range? It seems it contains no blank usually.", "url": "https://github.com/apache/flink/pull/11342#discussion_r389512113", "createdAt": "2020-03-09T08:17:21Z", "author": {"login": "hequn8128"}, "path": "flink-python/setup.py", "diffHunk": "@@ -224,7 +224,8 @@ def remove_if_exists(file_path):\n         author_email='dev@flink.apache.org',\n         python_requires='>=3.5',\n         install_requires=['py4j==0.10.8.1', 'python-dateutil==2.8.0', 'apache-beam==2.19.0',\n-                          'cloudpickle==1.2.2', 'avro-python3>=1.8.1,<=1.9.1', 'jsonpickle==1.2'],\n+                          'cloudpickle==1.2.2', 'avro-python3>=1.8.1,<=1.9.1', 'jsonpickle==1.2',\n+                          'pandas>=0.23.4, <=0.25.3', 'pyarrow>=0.15.1, <=0.16.0'],", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27f93cc605b980ae0ce93b1d5503031ae98f6cd9"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTUzMjg2Mw==", "bodyText": "How about adding a PythonFunctionKind class which contains GENERAL and PANDAS? It is consistent with Java and also would be easier for users to add the parameter.", "url": "https://github.com/apache/flink/pull/11342#discussion_r389532863", "createdAt": "2020-03-09T09:06:27Z", "author": {"login": "hequn8128"}, "path": "flink-python/pyflink/table/udf.py", "diffHunk": "@@ -297,15 +308,17 @@ def _get_python_env():\n     return gateway.jvm.org.apache.flink.table.functions.python.PythonEnv(exec_type)\n \n \n-def _create_udf(f, input_types, result_type, deterministic, name):\n-    return UserDefinedScalarFunctionWrapper(f, input_types, result_type, deterministic, name)\n+def _create_udf(f, input_types, result_type, udf_type, deterministic, name):\n+    return UserDefinedScalarFunctionWrapper(\n+        f, input_types, result_type, udf_type, deterministic, name)\n \n \n def _create_udtf(f, input_types, result_types, deterministic, name):\n     return UserDefinedTableFunctionWrapper(f, input_types, result_types, deterministic, name)\n \n \n-def udf(f=None, input_types=None, result_type=None, deterministic=None, name=None):\n+def udf(f=None, input_types=None, result_type=None, deterministic=None, name=None,\n+        udf_type=\"general\"):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27f93cc605b980ae0ce93b1d5503031ae98f6cd9"}, "originalPosition": 67}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc0NDY3NA==", "bodyText": "Maybe we should not contain this commit in this PR? as it is included in FLINK-16273\uff1fotherwise there will be two commits for addressing the same problem.", "url": "https://github.com/apache/flink/pull/11342#discussion_r389744674", "createdAt": "2020-03-09T14:56:42Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/table/runtime/runners/python/scalar/arrow/AbstractArrowPythonScalarFunctionRunner.java", "diffHunk": "@@ -46,6 +46,12 @@\n \n \tprivate static final String SCHEMA_ARROW_CODER_URN = \"flink:coder:schema:scalar_function:arrow:v1\";\n \n+\tstatic {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27f93cc605b980ae0ce93b1d5503031ae98f6cd9"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc1ODU1MQ==", "bodyText": "Why we only get the first batch in the batch list?", "url": "https://github.com/apache/flink/pull/11342#discussion_r389758551", "createdAt": "2020-03-09T15:16:42Z", "author": {"login": "hequn8128"}, "path": "flink-python/pyflink/fn_execution/coder_impl.py", "diffHunk": "@@ -373,3 +376,45 @@ def internal_to_timestamp(self, milliseconds, nanoseconds):\n         second, microsecond = (milliseconds // 1000,\n                                milliseconds % 1000 * 1000 + nanoseconds // 1000)\n         return datetime.datetime.utcfromtimestamp(second).replace(microsecond=microsecond)\n+\n+\n+class ArrowCoderImpl(StreamCoderImpl):\n+\n+    def __init__(self, schema):\n+        self._schema = schema\n+        self._resettable_io = ResettableIO()\n+\n+    def encode_to_stream(self, cols, out_stream, nested):\n+        if not hasattr(self, \"_batch_writer\"):\n+            self._batch_writer = pa.RecordBatchStreamWriter(self._resettable_io, self._schema)\n+\n+        self._resettable_io.set_output_stream(out_stream)\n+        self._batch_writer.write_batch(self._create_batch(cols))\n+\n+    def decode_from_stream(self, in_stream, nested):\n+        if not hasattr(self, \"_batch_reader\"):\n+            def load_from_stream(stream):\n+                reader = pa.ipc.open_stream(stream)\n+                for batch in reader:\n+                    yield batch\n+\n+            self._batch_reader = load_from_stream(self._resettable_io)\n+\n+        self._resettable_io.set_input_bytes(in_stream.read_all())\n+        table = pa.Table.from_batches([next(self._batch_reader)])", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27f93cc605b980ae0ce93b1d5503031ae98f6cd9"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc2MzQ4NA==", "bodyText": "Why we must init the _batch_writer here instead of in __init__?", "url": "https://github.com/apache/flink/pull/11342#discussion_r389763484", "createdAt": "2020-03-09T15:23:32Z", "author": {"login": "hequn8128"}, "path": "flink-python/pyflink/fn_execution/coder_impl.py", "diffHunk": "@@ -373,3 +376,45 @@ def internal_to_timestamp(self, milliseconds, nanoseconds):\n         second, microsecond = (milliseconds // 1000,\n                                milliseconds % 1000 * 1000 + nanoseconds // 1000)\n         return datetime.datetime.utcfromtimestamp(second).replace(microsecond=microsecond)\n+\n+\n+class ArrowCoderImpl(StreamCoderImpl):\n+\n+    def __init__(self, schema):\n+        self._schema = schema\n+        self._resettable_io = ResettableIO()\n+\n+    def encode_to_stream(self, cols, out_stream, nested):\n+        if not hasattr(self, \"_batch_writer\"):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27f93cc605b980ae0ce93b1d5503031ae98f6cd9"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc2OTIxNQ==", "bodyText": "I'm wondering if we can avoid these hasattr. Can we use pa.ipc.open_stream read the stream directly and return the batch?", "url": "https://github.com/apache/flink/pull/11342#discussion_r389769215", "createdAt": "2020-03-09T15:31:35Z", "author": {"login": "hequn8128"}, "path": "flink-python/pyflink/fn_execution/coder_impl.py", "diffHunk": "@@ -373,3 +376,45 @@ def internal_to_timestamp(self, milliseconds, nanoseconds):\n         second, microsecond = (milliseconds // 1000,\n                                milliseconds % 1000 * 1000 + nanoseconds // 1000)\n         return datetime.datetime.utcfromtimestamp(second).replace(microsecond=microsecond)\n+\n+\n+class ArrowCoderImpl(StreamCoderImpl):\n+\n+    def __init__(self, schema):\n+        self._schema = schema\n+        self._resettable_io = ResettableIO()\n+\n+    def encode_to_stream(self, cols, out_stream, nested):\n+        if not hasattr(self, \"_batch_writer\"):\n+            self._batch_writer = pa.RecordBatchStreamWriter(self._resettable_io, self._schema)\n+\n+        self._resettable_io.set_output_stream(out_stream)\n+        self._batch_writer.write_batch(self._create_batch(cols))\n+\n+    def decode_from_stream(self, in_stream, nested):\n+        if not hasattr(self, \"_batch_reader\"):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27f93cc605b980ae0ce93b1d5503031ae98f6cd9"}, "originalPosition": 32}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "27f93cc605b980ae0ce93b1d5503031ae98f6cd9", "author": {"user": {"login": "dianfu", "name": "Dian Fu"}}, "url": "https://github.com/apache/flink/commit/27f93cc605b980ae0ce93b1d5503031ae98f6cd9", "committedDate": "2020-03-07T13:52:50Z", "message": "[FLINK-16483][python] Add Python building blocks to make sure the basic functionality of vectorized Python UDF could work"}, "afterCommit": {"oid": "0e82d816f679e1ff790ebeae58ec6501411831b2", "author": {"user": {"login": "dianfu", "name": "Dian Fu"}}, "url": "https://github.com/apache/flink/commit/0e82d816f679e1ff790ebeae58ec6501411831b2", "committedDate": "2020-03-10T03:14:09Z", "message": "address review"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e431a7c17f43bba9ae2dd6e471b0191942cb7287", "author": {"user": {"login": "dianfu", "name": "Dian Fu"}}, "url": "https://github.com/apache/flink/commit/e431a7c17f43bba9ae2dd6e471b0191942cb7287", "committedDate": "2020-03-10T03:18:08Z", "message": "[FLINK-16483][python] Add Python building blocks to make sure the basic functionality of vectorized Python UDF could work"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c506306f83eec4450719dfdfb2fe205a3fb69857", "author": {"user": {"login": "dianfu", "name": "Dian Fu"}}, "url": "https://github.com/apache/flink/commit/c506306f83eec4450719dfdfb2fe205a3fb69857", "committedDate": "2020-03-10T03:18:08Z", "message": "address review"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0e82d816f679e1ff790ebeae58ec6501411831b2", "author": {"user": {"login": "dianfu", "name": "Dian Fu"}}, "url": "https://github.com/apache/flink/commit/0e82d816f679e1ff790ebeae58ec6501411831b2", "committedDate": "2020-03-10T03:14:09Z", "message": "address review"}, "afterCommit": {"oid": "c506306f83eec4450719dfdfb2fe205a3fb69857", "author": {"user": {"login": "dianfu", "name": "Dian Fu"}}, "url": "https://github.com/apache/flink/commit/c506306f83eec4450719dfdfb2fe205a3fb69857", "committedDate": "2020-03-10T03:18:08Z", "message": "address review"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcxODc0OTAw", "url": "https://github.com/apache/flink/pull/11342#pullrequestreview-371874900", "createdAt": "2020-03-10T11:34:57Z", "commit": {"oid": "c506306f83eec4450719dfdfb2fe205a3fb69857"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3149, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}