{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzgyMDQxMTYy", "number": 11273, "title": "[FLINK-12814][sql-client] Support tableau result format", "bodyText": "What is the purpose of the change\nCurrently, when sql client display either batch or streaming results, it will open a new terminal and show dynamic paged results. When user quit retrieving results, the terminal will also disappear, making it impossible to copy previous finished job's results.\nWe want to add a more traditional result mode for both batch & streaming query. The format is almost the same with mysql.\nBrief change log\n\nAdd a new sql client config, execution.result-mode: tableau\nIn steaming execution, the result will be changelog, meaning there is an extra field within the result table\n\nVerifying this change\nCliTableauResultViewTest covers various cases when retrieving result data. And you can also see the example output for batch & streaming jobs.", "createdAt": "2020-03-01T13:02:12Z", "url": "https://github.com/apache/flink/pull/11273", "merged": true, "mergeCommit": {"oid": "242efcdc3170341c5f8ccef5b29f3317cead3fa3"}, "closed": true, "closedAt": "2020-03-03T08:55:05Z", "author": {"login": "KurtYoung"}, "timelineItems": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcJmblDgFqTM2Njg1ODI2OQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcJ8byDgBqjMwOTA4Mzc0ODg=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY2ODU4MjY5", "url": "https://github.com/apache/flink/pull/11273#pullrequestreview-366858269", "createdAt": "2020-03-01T13:11:37Z", "commit": {"oid": "106c923b64d7246305c1e131bd7bd8ffeb213f87"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wMVQxMzoxMTozN1rOFwOG0g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wMVQxMzoxNjo1MlrOFwOIQQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjEwNzA5MA==", "bodyText": "2? There is a decimal point.\nlike -123.567", "url": "https://github.com/apache/flink/pull/11273#discussion_r386107090", "createdAt": "2020-03-01T13:11:37Z", "author": {"login": "JingsongLi"}, "path": "flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/cli/CliTableauResultView.java", "diffHunk": "@@ -0,0 +1,378 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.client.cli;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.api.TableColumn;\n+import org.apache.flink.table.client.gateway.Executor;\n+import org.apache.flink.table.client.gateway.ResultDescriptor;\n+import org.apache.flink.table.client.gateway.SqlExecutionException;\n+import org.apache.flink.table.client.gateway.TypedResult;\n+import org.apache.flink.table.types.logical.BigIntType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.IntType;\n+import org.apache.flink.table.types.logical.LocalZonedTimestampType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.SmallIntType;\n+import org.apache.flink.table.types.logical.TimeType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+import org.apache.flink.table.types.logical.TinyIntType;\n+import org.apache.flink.types.Row;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.jline.terminal.Terminal;\n+\n+import java.io.Closeable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Stream;\n+\n+import static org.apache.flink.table.client.cli.CliUtils.rowToString;\n+\n+/**\n+ * Print result in tableau mode.\n+ */\n+public class CliTableauResultView implements Closeable {\n+\n+\tprivate static final int NULL_COLUMN_WIDTH = CliStrings.NULL_COLUMN.length();\n+\tprivate static final int MAX_COLUMN_WIDTH = 30;\n+\tprivate static final int DEFAULT_COLUMN_WIDTH = 20;\n+\tprivate static final String COLUMN_TRUNCATED_FLAG = \"...\";\n+\tprivate static final String CHANGEFLAG_COLUMN_NAME = \"+/-\";\n+\n+\tprivate final Terminal terminal;\n+\tprivate final Executor sqlExecutor;\n+\tprivate final String sessionId;\n+\tprivate final ResultDescriptor resultDescriptor;\n+\tprivate final ExecutorService displayResultExecutorService;\n+\n+\tprivate volatile boolean cleanUpQuery;\n+\n+\tpublic CliTableauResultView(\n+\t\t\tfinal Terminal terminal,\n+\t\t\tfinal Executor sqlExecutor,\n+\t\t\tfinal String sessionId,\n+\t\t\tfinal ResultDescriptor resultDescriptor) {\n+\t\tthis.terminal = terminal;\n+\t\tthis.sqlExecutor = sqlExecutor;\n+\t\tthis.sessionId = sessionId;\n+\t\tthis.resultDescriptor = resultDescriptor;\n+\t\tthis.displayResultExecutorService = Executors.newSingleThreadExecutor();\n+\t}\n+\n+\tpublic void displayStreamResults() throws SqlExecutionException {\n+\t\tfinal AtomicInteger receivedRowCount = new AtomicInteger(0);\n+\t\tFuture<?> resultFuture = displayResultExecutorService.submit(() -> {\n+\t\t\tprintStreamResults(receivedRowCount);\n+\t\t});\n+\n+\t\t// capture CTRL-C\n+\t\tterminal.handle(Terminal.Signal.INT, signal -> {\n+\t\t\tresultFuture.cancel(true);\n+\t\t});\n+\n+\t\tcleanUpQuery = true;\n+\t\ttry {\n+\t\t\tresultFuture.get();\n+\t\t\tcleanUpQuery = false; // job finished successfully\n+\t\t} catch (CancellationException e) {\n+\t\t\tterminal.writer().println(\"Query terminated, received a total of \" + receivedRowCount.get() + \" rows\");\n+\t\t\tterminal.flush();\n+\t\t} catch (ExecutionException e) {\n+\t\t\tif (e.getCause() instanceof SqlExecutionException) {\n+\t\t\t\tthrow (SqlExecutionException) e.getCause();\n+\t\t\t}\n+\t\t\tthrow new SqlExecutionException(\"unknown exception\", e.getCause());\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new SqlExecutionException(\"Query interrupted\", e);\n+\t\t} finally {\n+\t\t\tcheckAndCleanUpQuery();\n+\t\t}\n+\t}\n+\n+\tpublic void displayBatchResults() throws SqlExecutionException {\n+\t\tFuture<?> resultFuture = displayResultExecutorService.submit(() -> {\n+\t\t\tfinal List<Row> resultRows = waitBatchResults();\n+\t\t\tprintBatchResults(resultRows);\n+\t\t});\n+\n+\t\t// capture CTRL-C\n+\t\tterminal.handle(Terminal.Signal.INT, signal -> {\n+\t\t\tresultFuture.cancel(true);\n+\t\t});\n+\n+\t\tcleanUpQuery = true;\n+\t\ttry {\n+\t\t\tresultFuture.get();\n+\t\t\tcleanUpQuery = false; // job finished successfully\n+\t\t} catch (CancellationException e) {\n+\t\t\tterminal.writer().println(\"Query terminated\");\n+\t\t\tterminal.flush();\n+\t\t} catch (ExecutionException e) {\n+\t\t\tif (e.getCause() instanceof SqlExecutionException) {\n+\t\t\t\tthrow (SqlExecutionException) e.getCause();\n+\t\t\t}\n+\t\t\tthrow new SqlExecutionException(\"unknown exception\", e.getCause());\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new SqlExecutionException(\"Query interrupted\", e);\n+\t\t} finally {\n+\t\t\tcheckAndCleanUpQuery();\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tthis.displayResultExecutorService.shutdown();\n+\t}\n+\n+\tprivate void checkAndCleanUpQuery() {\n+\t\tif (cleanUpQuery) {\n+\t\t\ttry {\n+\t\t\t\tsqlExecutor.cancelQuery(sessionId, resultDescriptor.getResultId());\n+\t\t\t} catch (SqlExecutionException e) {\n+\t\t\t\t// ignore further exceptions\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate List<Row> waitBatchResults() {\n+\t\tList<Row> resultRows;\n+\t\t// take snapshot and make all results in one page\n+\t\tdo {\n+\t\t\ttry {\n+\t\t\t\tThread.sleep(50);\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t}\n+\t\t\tTypedResult<Integer> result = sqlExecutor.snapshotResult(\n+\t\t\t\t\tsessionId,\n+\t\t\t\t\tresultDescriptor.getResultId(),\n+\t\t\t\t\tInteger.MAX_VALUE);\n+\n+\t\t\tif (result.getType() == TypedResult.ResultType.EOS) {\n+\t\t\t\tresultRows = Collections.emptyList();\n+\t\t\t\tbreak;\n+\t\t\t} else if (result.getType() == TypedResult.ResultType.PAYLOAD) {\n+\t\t\t\tresultRows = sqlExecutor.retrieveResultPage(resultDescriptor.getResultId(), 1);\n+\t\t\t\tbreak;\n+\t\t\t} else {\n+\t\t\t\t// result not retrieved yet\n+\t\t\t}\n+\t\t} while (true);\n+\n+\t\treturn resultRows;\n+\t}\n+\n+\tprivate void printStreamResults(AtomicInteger receivedRowCount) {\n+\t\tList<TableColumn> columns = resultDescriptor.getResultSchema().getTableColumns();\n+\t\tString[] fieldNames =\n+\t\t\t\tStream.concat(\n+\t\t\t\t\t\tStream.of(\"+/-\"),\n+\t\t\t\t\t\tcolumns.stream().map(TableColumn::getName)\n+\t\t\t\t).toArray(String[]::new);\n+\n+\t\tint[] colWidths = columnWidthsByType(columns, true);\n+\t\tString borderline = genBorderLine(colWidths);\n+\n+\t\t// print filed names\n+\t\tterminal.writer().println(borderline);\n+\t\tprintSingleRow(colWidths, fieldNames);\n+\t\tterminal.writer().println(borderline);\n+\t\tterminal.flush();\n+\n+\t\twhile (true) {\n+\t\t\tfinal TypedResult<List<Tuple2<Boolean, Row>>> result =\n+\t\t\t\t\tsqlExecutor.retrieveResultChanges(sessionId, resultDescriptor.getResultId());\n+\n+\t\t\tswitch (result.getType()) {\n+\t\t\t\tcase EMPTY:\n+\t\t\t\t\t// do nothing\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase EOS:\n+\t\t\t\t\tif (receivedRowCount.get() > 0) {\n+\t\t\t\t\t\tterminal.writer().println(borderline);\n+\t\t\t\t\t}\n+\t\t\t\t\tterminal.writer().println(\"Received a total of \" + receivedRowCount.get() + \" rows\");\n+\t\t\t\t\tterminal.flush();\n+\t\t\t\t\treturn;\n+\t\t\t\tdefault:\n+\t\t\t\t\tList<Tuple2<Boolean, Row>> changes = result.getPayload();\n+\t\t\t\t\tfor (Tuple2<Boolean, Row> change : changes) {\n+\t\t\t\t\t\tfinal String[] cols = rowToString(change.f1);\n+\t\t\t\t\t\tString[] row = new String[cols.length + 1];\n+\t\t\t\t\t\trow[0] = change.f0 ? \"+\" : \"-\";\n+\t\t\t\t\t\tSystem.arraycopy(cols, 0, row, 1, cols.length);\n+\t\t\t\t\t\tprintSingleRow(colWidths, row);\n+\t\t\t\t\t\treceivedRowCount.addAndGet(1);\n+\t\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate void printBatchResults(List<Row> resultRows) {\n+\t\tList<String[]> rows = new ArrayList<>(resultRows.size() + 1);\n+\n+\t\t// fill field names first\n+\t\tList<TableColumn> columns = resultDescriptor.getResultSchema().getTableColumns();\n+\t\trows.add(columns.stream().map(TableColumn::getName).toArray(String[]::new));\n+\t\tresultRows.forEach(row -> rows.add(rowToString(row)));\n+\n+\t\tint[] colWidths = columnWidthsByContent(columns, rows);\n+\t\tString borderline = genBorderLine(colWidths);\n+\n+\t\t// print field names\n+\t\tterminal.writer().println(borderline);\n+\t\tprintSingleRow(colWidths, rows.get(0));\n+\t\tterminal.writer().println(borderline);\n+\n+\t\t// print content\n+\t\trows.subList(1, rows.size()).forEach(row -> printSingleRow(colWidths, row));\n+\t\tif (!resultRows.isEmpty()) {\n+\t\t\tterminal.writer().println(borderline);\n+\t\t}\n+\n+\t\t// print footer\n+\t\tterminal.writer().println(resultRows.size() + \" row in set\");\n+\t\tterminal.flush();\n+\t}\n+\n+\tprivate String genBorderLine(int[] colWidths) {\n+\t\tStringBuilder sb = new StringBuilder();\n+\t\tsb.append(\"+\");\n+\t\tfor (int width : colWidths) {\n+\t\t\tsb.append(StringUtils.repeat(\"-\", width + 1));\n+\t\t\tsb.append(\"-+\");\n+\t\t}\n+\t\treturn sb.toString();\n+\t}\n+\n+\tprivate void printSingleRow(int[] colWidths, String[] cols) {\n+\t\tStringBuilder sb = new StringBuilder();\n+\t\tsb.append(\"|\");\n+\t\tint idx = 0;\n+\t\tfor (String col : cols) {\n+\t\t\tsb.append(\" \");\n+\t\t\tif (col.length() <= colWidths[idx]) {\n+\t\t\t\tsb.append(StringUtils.repeat(\" \", colWidths[idx] - col.length()));\n+\t\t\t\tsb.append(col);\n+\t\t\t} else {\n+\t\t\t\tsb.append(col, 0, colWidths[idx] - COLUMN_TRUNCATED_FLAG.length());\n+\t\t\t\tsb.append(COLUMN_TRUNCATED_FLAG);\n+\t\t\t}\n+\t\t\tsb.append(\" |\");\n+\t\t\tidx++;\n+\t\t}\n+\t\tterminal.writer().println(sb.toString());\n+\t\tterminal.flush();\n+\t}\n+\n+\t/**\n+\t * Try to infer column width based on column types. In streaming case, we will have an\n+\t * endless result set, thus couldn't determine column widths based on column values.\n+\t */\n+\tprivate int[] columnWidthsByType(List<TableColumn> columns, boolean includeChangeflag) {\n+\t\t// fill width with field names first\n+\t\tint[] colWidths  = columns.stream()\n+\t\t\t\t.mapToInt(col -> col.getName().length())\n+\t\t\t\t.toArray();\n+\n+\t\t// determine proper column width based on types\n+\t\tfor (int i = 0; i < columns.size(); ++i) {\n+\t\t\tLogicalType type = columns.get(i).getType().getLogicalType();\n+\t\t\tint len;\n+\t\t\tswitch (type.getTypeRoot()) {\n+\t\t\t\tcase TINYINT:\n+\t\t\t\t\tlen = TinyIntType.PRECISION + 1; // extra for negative value\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase SMALLINT:\n+\t\t\t\t\tlen = SmallIntType.PRECISION + 1; // extra for negative value\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase INTEGER:\n+\t\t\t\t\tlen = IntType.PRECISION + 1; // extra for negative value\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase BIGINT:\n+\t\t\t\t\tlen = BigIntType.PRECISION + 1; // extra for negative value\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase DECIMAL:\n+\t\t\t\t\tlen = ((DecimalType) type).getPrecision() + 1; // extra for negative value", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "106c923b64d7246305c1e131bd7bd8ffeb213f87"}, "originalPosition": 320}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjEwNzQ1Nw==", "bodyText": "Actually LocalDateTime.toString is:\n     * <li>{@code uuuu-MM-dd'T'HH:mm}</li>\n     * <li>{@code uuuu-MM-dd'T'HH:mm:ss}</li>\n     * <li>{@code uuuu-MM-dd'T'HH:mm:ss.SSS}</li>\n     * <li>{@code uuuu-MM-dd'T'HH:mm:ss.SSSSSS}</li>\n     * <li>{@code uuuu-MM-dd'T'HH:mm:ss.SSSSSSSSS}</li>\n\nSo maybe we need pad zero for mills,micros,nanos too?", "url": "https://github.com/apache/flink/pull/11273#discussion_r386107457", "createdAt": "2020-03-01T13:16:52Z", "author": {"login": "JingsongLi"}, "path": "flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/cli/CliTableauResultView.java", "diffHunk": "@@ -0,0 +1,378 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.client.cli;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.api.TableColumn;\n+import org.apache.flink.table.client.gateway.Executor;\n+import org.apache.flink.table.client.gateway.ResultDescriptor;\n+import org.apache.flink.table.client.gateway.SqlExecutionException;\n+import org.apache.flink.table.client.gateway.TypedResult;\n+import org.apache.flink.table.types.logical.BigIntType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.IntType;\n+import org.apache.flink.table.types.logical.LocalZonedTimestampType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.SmallIntType;\n+import org.apache.flink.table.types.logical.TimeType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+import org.apache.flink.table.types.logical.TinyIntType;\n+import org.apache.flink.types.Row;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.jline.terminal.Terminal;\n+\n+import java.io.Closeable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Stream;\n+\n+import static org.apache.flink.table.client.cli.CliUtils.rowToString;\n+\n+/**\n+ * Print result in tableau mode.\n+ */\n+public class CliTableauResultView implements Closeable {\n+\n+\tprivate static final int NULL_COLUMN_WIDTH = CliStrings.NULL_COLUMN.length();\n+\tprivate static final int MAX_COLUMN_WIDTH = 30;\n+\tprivate static final int DEFAULT_COLUMN_WIDTH = 20;\n+\tprivate static final String COLUMN_TRUNCATED_FLAG = \"...\";\n+\tprivate static final String CHANGEFLAG_COLUMN_NAME = \"+/-\";\n+\n+\tprivate final Terminal terminal;\n+\tprivate final Executor sqlExecutor;\n+\tprivate final String sessionId;\n+\tprivate final ResultDescriptor resultDescriptor;\n+\tprivate final ExecutorService displayResultExecutorService;\n+\n+\tprivate volatile boolean cleanUpQuery;\n+\n+\tpublic CliTableauResultView(\n+\t\t\tfinal Terminal terminal,\n+\t\t\tfinal Executor sqlExecutor,\n+\t\t\tfinal String sessionId,\n+\t\t\tfinal ResultDescriptor resultDescriptor) {\n+\t\tthis.terminal = terminal;\n+\t\tthis.sqlExecutor = sqlExecutor;\n+\t\tthis.sessionId = sessionId;\n+\t\tthis.resultDescriptor = resultDescriptor;\n+\t\tthis.displayResultExecutorService = Executors.newSingleThreadExecutor();\n+\t}\n+\n+\tpublic void displayStreamResults() throws SqlExecutionException {\n+\t\tfinal AtomicInteger receivedRowCount = new AtomicInteger(0);\n+\t\tFuture<?> resultFuture = displayResultExecutorService.submit(() -> {\n+\t\t\tprintStreamResults(receivedRowCount);\n+\t\t});\n+\n+\t\t// capture CTRL-C\n+\t\tterminal.handle(Terminal.Signal.INT, signal -> {\n+\t\t\tresultFuture.cancel(true);\n+\t\t});\n+\n+\t\tcleanUpQuery = true;\n+\t\ttry {\n+\t\t\tresultFuture.get();\n+\t\t\tcleanUpQuery = false; // job finished successfully\n+\t\t} catch (CancellationException e) {\n+\t\t\tterminal.writer().println(\"Query terminated, received a total of \" + receivedRowCount.get() + \" rows\");\n+\t\t\tterminal.flush();\n+\t\t} catch (ExecutionException e) {\n+\t\t\tif (e.getCause() instanceof SqlExecutionException) {\n+\t\t\t\tthrow (SqlExecutionException) e.getCause();\n+\t\t\t}\n+\t\t\tthrow new SqlExecutionException(\"unknown exception\", e.getCause());\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new SqlExecutionException(\"Query interrupted\", e);\n+\t\t} finally {\n+\t\t\tcheckAndCleanUpQuery();\n+\t\t}\n+\t}\n+\n+\tpublic void displayBatchResults() throws SqlExecutionException {\n+\t\tFuture<?> resultFuture = displayResultExecutorService.submit(() -> {\n+\t\t\tfinal List<Row> resultRows = waitBatchResults();\n+\t\t\tprintBatchResults(resultRows);\n+\t\t});\n+\n+\t\t// capture CTRL-C\n+\t\tterminal.handle(Terminal.Signal.INT, signal -> {\n+\t\t\tresultFuture.cancel(true);\n+\t\t});\n+\n+\t\tcleanUpQuery = true;\n+\t\ttry {\n+\t\t\tresultFuture.get();\n+\t\t\tcleanUpQuery = false; // job finished successfully\n+\t\t} catch (CancellationException e) {\n+\t\t\tterminal.writer().println(\"Query terminated\");\n+\t\t\tterminal.flush();\n+\t\t} catch (ExecutionException e) {\n+\t\t\tif (e.getCause() instanceof SqlExecutionException) {\n+\t\t\t\tthrow (SqlExecutionException) e.getCause();\n+\t\t\t}\n+\t\t\tthrow new SqlExecutionException(\"unknown exception\", e.getCause());\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new SqlExecutionException(\"Query interrupted\", e);\n+\t\t} finally {\n+\t\t\tcheckAndCleanUpQuery();\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tthis.displayResultExecutorService.shutdown();\n+\t}\n+\n+\tprivate void checkAndCleanUpQuery() {\n+\t\tif (cleanUpQuery) {\n+\t\t\ttry {\n+\t\t\t\tsqlExecutor.cancelQuery(sessionId, resultDescriptor.getResultId());\n+\t\t\t} catch (SqlExecutionException e) {\n+\t\t\t\t// ignore further exceptions\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate List<Row> waitBatchResults() {\n+\t\tList<Row> resultRows;\n+\t\t// take snapshot and make all results in one page\n+\t\tdo {\n+\t\t\ttry {\n+\t\t\t\tThread.sleep(50);\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t}\n+\t\t\tTypedResult<Integer> result = sqlExecutor.snapshotResult(\n+\t\t\t\t\tsessionId,\n+\t\t\t\t\tresultDescriptor.getResultId(),\n+\t\t\t\t\tInteger.MAX_VALUE);\n+\n+\t\t\tif (result.getType() == TypedResult.ResultType.EOS) {\n+\t\t\t\tresultRows = Collections.emptyList();\n+\t\t\t\tbreak;\n+\t\t\t} else if (result.getType() == TypedResult.ResultType.PAYLOAD) {\n+\t\t\t\tresultRows = sqlExecutor.retrieveResultPage(resultDescriptor.getResultId(), 1);\n+\t\t\t\tbreak;\n+\t\t\t} else {\n+\t\t\t\t// result not retrieved yet\n+\t\t\t}\n+\t\t} while (true);\n+\n+\t\treturn resultRows;\n+\t}\n+\n+\tprivate void printStreamResults(AtomicInteger receivedRowCount) {\n+\t\tList<TableColumn> columns = resultDescriptor.getResultSchema().getTableColumns();\n+\t\tString[] fieldNames =\n+\t\t\t\tStream.concat(\n+\t\t\t\t\t\tStream.of(\"+/-\"),\n+\t\t\t\t\t\tcolumns.stream().map(TableColumn::getName)\n+\t\t\t\t).toArray(String[]::new);\n+\n+\t\tint[] colWidths = columnWidthsByType(columns, true);\n+\t\tString borderline = genBorderLine(colWidths);\n+\n+\t\t// print filed names\n+\t\tterminal.writer().println(borderline);\n+\t\tprintSingleRow(colWidths, fieldNames);\n+\t\tterminal.writer().println(borderline);\n+\t\tterminal.flush();\n+\n+\t\twhile (true) {\n+\t\t\tfinal TypedResult<List<Tuple2<Boolean, Row>>> result =\n+\t\t\t\t\tsqlExecutor.retrieveResultChanges(sessionId, resultDescriptor.getResultId());\n+\n+\t\t\tswitch (result.getType()) {\n+\t\t\t\tcase EMPTY:\n+\t\t\t\t\t// do nothing\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase EOS:\n+\t\t\t\t\tif (receivedRowCount.get() > 0) {\n+\t\t\t\t\t\tterminal.writer().println(borderline);\n+\t\t\t\t\t}\n+\t\t\t\t\tterminal.writer().println(\"Received a total of \" + receivedRowCount.get() + \" rows\");\n+\t\t\t\t\tterminal.flush();\n+\t\t\t\t\treturn;\n+\t\t\t\tdefault:\n+\t\t\t\t\tList<Tuple2<Boolean, Row>> changes = result.getPayload();\n+\t\t\t\t\tfor (Tuple2<Boolean, Row> change : changes) {\n+\t\t\t\t\t\tfinal String[] cols = rowToString(change.f1);\n+\t\t\t\t\t\tString[] row = new String[cols.length + 1];\n+\t\t\t\t\t\trow[0] = change.f0 ? \"+\" : \"-\";\n+\t\t\t\t\t\tSystem.arraycopy(cols, 0, row, 1, cols.length);\n+\t\t\t\t\t\tprintSingleRow(colWidths, row);\n+\t\t\t\t\t\treceivedRowCount.addAndGet(1);\n+\t\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate void printBatchResults(List<Row> resultRows) {\n+\t\tList<String[]> rows = new ArrayList<>(resultRows.size() + 1);\n+\n+\t\t// fill field names first\n+\t\tList<TableColumn> columns = resultDescriptor.getResultSchema().getTableColumns();\n+\t\trows.add(columns.stream().map(TableColumn::getName).toArray(String[]::new));\n+\t\tresultRows.forEach(row -> rows.add(rowToString(row)));\n+\n+\t\tint[] colWidths = columnWidthsByContent(columns, rows);\n+\t\tString borderline = genBorderLine(colWidths);\n+\n+\t\t// print field names\n+\t\tterminal.writer().println(borderline);\n+\t\tprintSingleRow(colWidths, rows.get(0));\n+\t\tterminal.writer().println(borderline);\n+\n+\t\t// print content\n+\t\trows.subList(1, rows.size()).forEach(row -> printSingleRow(colWidths, row));\n+\t\tif (!resultRows.isEmpty()) {\n+\t\t\tterminal.writer().println(borderline);\n+\t\t}\n+\n+\t\t// print footer\n+\t\tterminal.writer().println(resultRows.size() + \" row in set\");\n+\t\tterminal.flush();\n+\t}\n+\n+\tprivate String genBorderLine(int[] colWidths) {\n+\t\tStringBuilder sb = new StringBuilder();\n+\t\tsb.append(\"+\");\n+\t\tfor (int width : colWidths) {\n+\t\t\tsb.append(StringUtils.repeat(\"-\", width + 1));\n+\t\t\tsb.append(\"-+\");\n+\t\t}\n+\t\treturn sb.toString();\n+\t}\n+\n+\tprivate void printSingleRow(int[] colWidths, String[] cols) {\n+\t\tStringBuilder sb = new StringBuilder();\n+\t\tsb.append(\"|\");\n+\t\tint idx = 0;\n+\t\tfor (String col : cols) {\n+\t\t\tsb.append(\" \");\n+\t\t\tif (col.length() <= colWidths[idx]) {\n+\t\t\t\tsb.append(StringUtils.repeat(\" \", colWidths[idx] - col.length()));\n+\t\t\t\tsb.append(col);\n+\t\t\t} else {\n+\t\t\t\tsb.append(col, 0, colWidths[idx] - COLUMN_TRUNCATED_FLAG.length());\n+\t\t\t\tsb.append(COLUMN_TRUNCATED_FLAG);\n+\t\t\t}\n+\t\t\tsb.append(\" |\");\n+\t\t\tidx++;\n+\t\t}\n+\t\tterminal.writer().println(sb.toString());\n+\t\tterminal.flush();\n+\t}\n+\n+\t/**\n+\t * Try to infer column width based on column types. In streaming case, we will have an\n+\t * endless result set, thus couldn't determine column widths based on column values.\n+\t */\n+\tprivate int[] columnWidthsByType(List<TableColumn> columns, boolean includeChangeflag) {\n+\t\t// fill width with field names first\n+\t\tint[] colWidths  = columns.stream()\n+\t\t\t\t.mapToInt(col -> col.getName().length())\n+\t\t\t\t.toArray();\n+\n+\t\t// determine proper column width based on types\n+\t\tfor (int i = 0; i < columns.size(); ++i) {\n+\t\t\tLogicalType type = columns.get(i).getType().getLogicalType();\n+\t\t\tint len;\n+\t\t\tswitch (type.getTypeRoot()) {\n+\t\t\t\tcase TINYINT:\n+\t\t\t\t\tlen = TinyIntType.PRECISION + 1; // extra for negative value\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase SMALLINT:\n+\t\t\t\t\tlen = SmallIntType.PRECISION + 1; // extra for negative value\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase INTEGER:\n+\t\t\t\t\tlen = IntType.PRECISION + 1; // extra for negative value\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase BIGINT:\n+\t\t\t\t\tlen = BigIntType.PRECISION + 1; // extra for negative value\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase DECIMAL:\n+\t\t\t\t\tlen = ((DecimalType) type).getPrecision() + 1; // extra for negative value\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase BOOLEAN:\n+\t\t\t\t\tlen = 5; // \"true\" or \"false\"\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase DATE:\n+\t\t\t\t\tlen = 10; // e.g. 9999-12-31\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase TIME_WITHOUT_TIME_ZONE:\n+\t\t\t\t\tint precision = ((TimeType) type).getPrecision();\n+\t\t\t\t\tlen = precision == 0 ? 8 : precision + 9; // 23:59:59[.999999999]\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase TIMESTAMP_WITHOUT_TIME_ZONE:\n+\t\t\t\t\tprecision = ((TimestampType) type).getPrecision();\n+\t\t\t\t\tlen = precision == 0 ? 19 : precision + 20; // 2020-02-01T23:59:59[.999999999]\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase TIMESTAMP_WITH_LOCAL_TIME_ZONE:\n+\t\t\t\t\tprecision = ((LocalZonedTimestampType) type).getPrecision();\n+\t\t\t\t\tlen = precision == 0 ? 19 : precision + 20; // 2020-02-01T23:59:59[.999999999]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "106c923b64d7246305c1e131bd7bd8ffeb213f87"}, "originalPosition": 338}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY2OTk2NDc0", "url": "https://github.com/apache/flink/pull/11273#pullrequestreview-366996474", "createdAt": "2020-03-02T07:43:01Z", "commit": {"oid": "87fcf8d5a1309a85519e0a09df0191acd515c15d"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wMlQwNzo0MzowMVrOFwV61Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wMlQwODowMDowM1rOFwWP_A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjIzNTA5Mw==", "bodyText": "One more space.", "url": "https://github.com/apache/flink/pull/11273#discussion_r386235093", "createdAt": "2020-03-02T07:43:01Z", "author": {"login": "JingsongLi"}, "path": "flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/cli/CliTableauResultView.java", "diffHunk": "@@ -0,0 +1,378 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.client.cli;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.api.TableColumn;\n+import org.apache.flink.table.client.gateway.Executor;\n+import org.apache.flink.table.client.gateway.ResultDescriptor;\n+import org.apache.flink.table.client.gateway.SqlExecutionException;\n+import org.apache.flink.table.client.gateway.TypedResult;\n+import org.apache.flink.table.types.logical.BigIntType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.IntType;\n+import org.apache.flink.table.types.logical.LocalZonedTimestampType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.SmallIntType;\n+import org.apache.flink.table.types.logical.TimeType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+import org.apache.flink.table.types.logical.TinyIntType;\n+import org.apache.flink.types.Row;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.jline.terminal.Terminal;\n+\n+import java.io.Closeable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Stream;\n+\n+import static org.apache.flink.table.client.cli.CliUtils.rowToString;\n+\n+/**\n+ * Print result in tableau mode.\n+ */\n+public class CliTableauResultView implements Closeable {\n+\n+\tprivate static final int NULL_COLUMN_WIDTH = CliStrings.NULL_COLUMN.length();\n+\tprivate static final int MAX_COLUMN_WIDTH = 30;\n+\tprivate static final int DEFAULT_COLUMN_WIDTH = 20;\n+\tprivate static final String COLUMN_TRUNCATED_FLAG = \"...\";\n+\tprivate static final String CHANGEFLAG_COLUMN_NAME = \"+/-\";\n+\n+\tprivate final Terminal terminal;\n+\tprivate final Executor sqlExecutor;\n+\tprivate final String sessionId;\n+\tprivate final ResultDescriptor resultDescriptor;\n+\tprivate final ExecutorService displayResultExecutorService;\n+\n+\tprivate volatile boolean cleanUpQuery;\n+\n+\tpublic CliTableauResultView(\n+\t\t\tfinal Terminal terminal,\n+\t\t\tfinal Executor sqlExecutor,\n+\t\t\tfinal String sessionId,\n+\t\t\tfinal ResultDescriptor resultDescriptor) {\n+\t\tthis.terminal = terminal;\n+\t\tthis.sqlExecutor = sqlExecutor;\n+\t\tthis.sessionId = sessionId;\n+\t\tthis.resultDescriptor = resultDescriptor;\n+\t\tthis.displayResultExecutorService = Executors.newSingleThreadExecutor();\n+\t}\n+\n+\tpublic void displayStreamResults() throws SqlExecutionException {\n+\t\tfinal AtomicInteger receivedRowCount = new AtomicInteger(0);\n+\t\tFuture<?> resultFuture = displayResultExecutorService.submit(() -> {\n+\t\t\tprintStreamResults(receivedRowCount);\n+\t\t});\n+\n+\t\t// capture CTRL-C\n+\t\tterminal.handle(Terminal.Signal.INT, signal -> {\n+\t\t\tresultFuture.cancel(true);\n+\t\t});\n+\n+\t\tcleanUpQuery = true;\n+\t\ttry {\n+\t\t\tresultFuture.get();\n+\t\t\tcleanUpQuery = false; // job finished successfully\n+\t\t} catch (CancellationException e) {\n+\t\t\tterminal.writer().println(\"Query terminated, received a total of \" + receivedRowCount.get() + \" rows\");\n+\t\t\tterminal.flush();\n+\t\t} catch (ExecutionException e) {\n+\t\t\tif (e.getCause() instanceof SqlExecutionException) {\n+\t\t\t\tthrow (SqlExecutionException) e.getCause();\n+\t\t\t}\n+\t\t\tthrow new SqlExecutionException(\"unknown exception\", e.getCause());\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new SqlExecutionException(\"Query interrupted\", e);\n+\t\t} finally {\n+\t\t\tcheckAndCleanUpQuery();\n+\t\t}\n+\t}\n+\n+\tpublic void displayBatchResults() throws SqlExecutionException {\n+\t\tFuture<?> resultFuture = displayResultExecutorService.submit(() -> {\n+\t\t\tfinal List<Row> resultRows = waitBatchResults();\n+\t\t\tprintBatchResults(resultRows);\n+\t\t});\n+\n+\t\t// capture CTRL-C\n+\t\tterminal.handle(Terminal.Signal.INT, signal -> {\n+\t\t\tresultFuture.cancel(true);\n+\t\t});\n+\n+\t\tcleanUpQuery = true;\n+\t\ttry {\n+\t\t\tresultFuture.get();\n+\t\t\tcleanUpQuery = false; // job finished successfully\n+\t\t} catch (CancellationException e) {\n+\t\t\tterminal.writer().println(\"Query terminated\");\n+\t\t\tterminal.flush();\n+\t\t} catch (ExecutionException e) {\n+\t\t\tif (e.getCause() instanceof SqlExecutionException) {\n+\t\t\t\tthrow (SqlExecutionException) e.getCause();\n+\t\t\t}\n+\t\t\tthrow new SqlExecutionException(\"unknown exception\", e.getCause());\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new SqlExecutionException(\"Query interrupted\", e);\n+\t\t} finally {\n+\t\t\tcheckAndCleanUpQuery();\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tthis.displayResultExecutorService.shutdown();\n+\t}\n+\n+\tprivate void checkAndCleanUpQuery() {\n+\t\tif (cleanUpQuery) {\n+\t\t\ttry {\n+\t\t\t\tsqlExecutor.cancelQuery(sessionId, resultDescriptor.getResultId());\n+\t\t\t} catch (SqlExecutionException e) {\n+\t\t\t\t// ignore further exceptions\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate List<Row> waitBatchResults() {\n+\t\tList<Row> resultRows;\n+\t\t// take snapshot and make all results in one page\n+\t\tdo {\n+\t\t\ttry {\n+\t\t\t\tThread.sleep(50);\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t}\n+\t\t\tTypedResult<Integer> result = sqlExecutor.snapshotResult(\n+\t\t\t\t\tsessionId,\n+\t\t\t\t\tresultDescriptor.getResultId(),\n+\t\t\t\t\tInteger.MAX_VALUE);\n+\n+\t\t\tif (result.getType() == TypedResult.ResultType.EOS) {\n+\t\t\t\tresultRows = Collections.emptyList();\n+\t\t\t\tbreak;\n+\t\t\t} else if (result.getType() == TypedResult.ResultType.PAYLOAD) {\n+\t\t\t\tresultRows = sqlExecutor.retrieveResultPage(resultDescriptor.getResultId(), 1);\n+\t\t\t\tbreak;\n+\t\t\t} else {\n+\t\t\t\t// result not retrieved yet\n+\t\t\t}\n+\t\t} while (true);\n+\n+\t\treturn resultRows;\n+\t}\n+\n+\tprivate void printStreamResults(AtomicInteger receivedRowCount) {\n+\t\tList<TableColumn> columns = resultDescriptor.getResultSchema().getTableColumns();\n+\t\tString[] fieldNames =\n+\t\t\t\tStream.concat(\n+\t\t\t\t\t\tStream.of(\"+/-\"),\n+\t\t\t\t\t\tcolumns.stream().map(TableColumn::getName)\n+\t\t\t\t).toArray(String[]::new);\n+\n+\t\tint[] colWidths = columnWidthsByType(columns, true);\n+\t\tString borderline = genBorderLine(colWidths);\n+\n+\t\t// print filed names\n+\t\tterminal.writer().println(borderline);\n+\t\tprintSingleRow(colWidths, fieldNames);\n+\t\tterminal.writer().println(borderline);\n+\t\tterminal.flush();\n+\n+\t\twhile (true) {\n+\t\t\tfinal TypedResult<List<Tuple2<Boolean, Row>>> result =\n+\t\t\t\t\tsqlExecutor.retrieveResultChanges(sessionId, resultDescriptor.getResultId());\n+\n+\t\t\tswitch (result.getType()) {\n+\t\t\t\tcase EMPTY:\n+\t\t\t\t\t// do nothing\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase EOS:\n+\t\t\t\t\tif (receivedRowCount.get() > 0) {\n+\t\t\t\t\t\tterminal.writer().println(borderline);\n+\t\t\t\t\t}\n+\t\t\t\t\tterminal.writer().println(\"Received a total of \" + receivedRowCount.get() + \" rows\");\n+\t\t\t\t\tterminal.flush();\n+\t\t\t\t\treturn;\n+\t\t\t\tdefault:\n+\t\t\t\t\tList<Tuple2<Boolean, Row>> changes = result.getPayload();\n+\t\t\t\t\tfor (Tuple2<Boolean, Row> change : changes) {\n+\t\t\t\t\t\tfinal String[] cols = rowToString(change.f1);\n+\t\t\t\t\t\tString[] row = new String[cols.length + 1];\n+\t\t\t\t\t\trow[0] = change.f0 ? \"+\" : \"-\";\n+\t\t\t\t\t\tSystem.arraycopy(cols, 0, row, 1, cols.length);\n+\t\t\t\t\t\tprintSingleRow(colWidths, row);\n+\t\t\t\t\t\treceivedRowCount.addAndGet(1);\n+\t\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate void printBatchResults(List<Row> resultRows) {\n+\t\tList<String[]> rows = new ArrayList<>(resultRows.size() + 1);\n+\n+\t\t// fill field names first\n+\t\tList<TableColumn> columns = resultDescriptor.getResultSchema().getTableColumns();\n+\t\trows.add(columns.stream().map(TableColumn::getName).toArray(String[]::new));\n+\t\tresultRows.forEach(row -> rows.add(rowToString(row)));\n+\n+\t\tint[] colWidths = columnWidthsByContent(columns, rows);\n+\t\tString borderline = genBorderLine(colWidths);\n+\n+\t\t// print field names\n+\t\tterminal.writer().println(borderline);\n+\t\tprintSingleRow(colWidths, rows.get(0));\n+\t\tterminal.writer().println(borderline);\n+\n+\t\t// print content\n+\t\trows.subList(1, rows.size()).forEach(row -> printSingleRow(colWidths, row));\n+\t\tif (!resultRows.isEmpty()) {\n+\t\t\tterminal.writer().println(borderline);\n+\t\t}\n+\n+\t\t// print footer\n+\t\tterminal.writer().println(resultRows.size() + \" row in set\");\n+\t\tterminal.flush();\n+\t}\n+\n+\tprivate String genBorderLine(int[] colWidths) {\n+\t\tStringBuilder sb = new StringBuilder();\n+\t\tsb.append(\"+\");\n+\t\tfor (int width : colWidths) {\n+\t\t\tsb.append(StringUtils.repeat(\"-\", width + 1));\n+\t\t\tsb.append(\"-+\");\n+\t\t}\n+\t\treturn sb.toString();\n+\t}\n+\n+\tprivate void printSingleRow(int[] colWidths, String[] cols) {\n+\t\tStringBuilder sb = new StringBuilder();\n+\t\tsb.append(\"|\");\n+\t\tint idx = 0;\n+\t\tfor (String col : cols) {\n+\t\t\tsb.append(\" \");\n+\t\t\tif (col.length() <= colWidths[idx]) {\n+\t\t\t\tsb.append(StringUtils.repeat(\" \", colWidths[idx] - col.length()));\n+\t\t\t\tsb.append(col);\n+\t\t\t} else {\n+\t\t\t\tsb.append(col, 0, colWidths[idx] - COLUMN_TRUNCATED_FLAG.length());\n+\t\t\t\tsb.append(COLUMN_TRUNCATED_FLAG);\n+\t\t\t}\n+\t\t\tsb.append(\" |\");\n+\t\t\tidx++;\n+\t\t}\n+\t\tterminal.writer().println(sb.toString());\n+\t\tterminal.flush();\n+\t}\n+\n+\t/**\n+\t * Try to infer column width based on column types. In streaming case, we will have an\n+\t * endless result set, thus couldn't determine column widths based on column values.\n+\t */\n+\tprivate int[] columnWidthsByType(List<TableColumn> columns, boolean includeChangeflag) {\n+\t\t// fill width with field names first\n+\t\tint[] colWidths  = columns.stream()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "87fcf8d5a1309a85519e0a09df0191acd515c15d"}, "originalPosition": 298}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjIzNzM0MA==", "bodyText": "Use StringUtils.repeat(char) or CliUtils.repeatChar?", "url": "https://github.com/apache/flink/pull/11273#discussion_r386237340", "createdAt": "2020-03-02T07:50:20Z", "author": {"login": "JingsongLi"}, "path": "flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/cli/CliTableauResultView.java", "diffHunk": "@@ -0,0 +1,378 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.client.cli;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.api.TableColumn;\n+import org.apache.flink.table.client.gateway.Executor;\n+import org.apache.flink.table.client.gateway.ResultDescriptor;\n+import org.apache.flink.table.client.gateway.SqlExecutionException;\n+import org.apache.flink.table.client.gateway.TypedResult;\n+import org.apache.flink.table.types.logical.BigIntType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.IntType;\n+import org.apache.flink.table.types.logical.LocalZonedTimestampType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.SmallIntType;\n+import org.apache.flink.table.types.logical.TimeType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+import org.apache.flink.table.types.logical.TinyIntType;\n+import org.apache.flink.types.Row;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.jline.terminal.Terminal;\n+\n+import java.io.Closeable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Stream;\n+\n+import static org.apache.flink.table.client.cli.CliUtils.rowToString;\n+\n+/**\n+ * Print result in tableau mode.\n+ */\n+public class CliTableauResultView implements Closeable {\n+\n+\tprivate static final int NULL_COLUMN_WIDTH = CliStrings.NULL_COLUMN.length();\n+\tprivate static final int MAX_COLUMN_WIDTH = 30;\n+\tprivate static final int DEFAULT_COLUMN_WIDTH = 20;\n+\tprivate static final String COLUMN_TRUNCATED_FLAG = \"...\";\n+\tprivate static final String CHANGEFLAG_COLUMN_NAME = \"+/-\";\n+\n+\tprivate final Terminal terminal;\n+\tprivate final Executor sqlExecutor;\n+\tprivate final String sessionId;\n+\tprivate final ResultDescriptor resultDescriptor;\n+\tprivate final ExecutorService displayResultExecutorService;\n+\n+\tprivate volatile boolean cleanUpQuery;\n+\n+\tpublic CliTableauResultView(\n+\t\t\tfinal Terminal terminal,\n+\t\t\tfinal Executor sqlExecutor,\n+\t\t\tfinal String sessionId,\n+\t\t\tfinal ResultDescriptor resultDescriptor) {\n+\t\tthis.terminal = terminal;\n+\t\tthis.sqlExecutor = sqlExecutor;\n+\t\tthis.sessionId = sessionId;\n+\t\tthis.resultDescriptor = resultDescriptor;\n+\t\tthis.displayResultExecutorService = Executors.newSingleThreadExecutor();\n+\t}\n+\n+\tpublic void displayStreamResults() throws SqlExecutionException {\n+\t\tfinal AtomicInteger receivedRowCount = new AtomicInteger(0);\n+\t\tFuture<?> resultFuture = displayResultExecutorService.submit(() -> {\n+\t\t\tprintStreamResults(receivedRowCount);\n+\t\t});\n+\n+\t\t// capture CTRL-C\n+\t\tterminal.handle(Terminal.Signal.INT, signal -> {\n+\t\t\tresultFuture.cancel(true);\n+\t\t});\n+\n+\t\tcleanUpQuery = true;\n+\t\ttry {\n+\t\t\tresultFuture.get();\n+\t\t\tcleanUpQuery = false; // job finished successfully\n+\t\t} catch (CancellationException e) {\n+\t\t\tterminal.writer().println(\"Query terminated, received a total of \" + receivedRowCount.get() + \" rows\");\n+\t\t\tterminal.flush();\n+\t\t} catch (ExecutionException e) {\n+\t\t\tif (e.getCause() instanceof SqlExecutionException) {\n+\t\t\t\tthrow (SqlExecutionException) e.getCause();\n+\t\t\t}\n+\t\t\tthrow new SqlExecutionException(\"unknown exception\", e.getCause());\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new SqlExecutionException(\"Query interrupted\", e);\n+\t\t} finally {\n+\t\t\tcheckAndCleanUpQuery();\n+\t\t}\n+\t}\n+\n+\tpublic void displayBatchResults() throws SqlExecutionException {\n+\t\tFuture<?> resultFuture = displayResultExecutorService.submit(() -> {\n+\t\t\tfinal List<Row> resultRows = waitBatchResults();\n+\t\t\tprintBatchResults(resultRows);\n+\t\t});\n+\n+\t\t// capture CTRL-C\n+\t\tterminal.handle(Terminal.Signal.INT, signal -> {\n+\t\t\tresultFuture.cancel(true);\n+\t\t});\n+\n+\t\tcleanUpQuery = true;\n+\t\ttry {\n+\t\t\tresultFuture.get();\n+\t\t\tcleanUpQuery = false; // job finished successfully\n+\t\t} catch (CancellationException e) {\n+\t\t\tterminal.writer().println(\"Query terminated\");\n+\t\t\tterminal.flush();\n+\t\t} catch (ExecutionException e) {\n+\t\t\tif (e.getCause() instanceof SqlExecutionException) {\n+\t\t\t\tthrow (SqlExecutionException) e.getCause();\n+\t\t\t}\n+\t\t\tthrow new SqlExecutionException(\"unknown exception\", e.getCause());\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new SqlExecutionException(\"Query interrupted\", e);\n+\t\t} finally {\n+\t\t\tcheckAndCleanUpQuery();\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tthis.displayResultExecutorService.shutdown();\n+\t}\n+\n+\tprivate void checkAndCleanUpQuery() {\n+\t\tif (cleanUpQuery) {\n+\t\t\ttry {\n+\t\t\t\tsqlExecutor.cancelQuery(sessionId, resultDescriptor.getResultId());\n+\t\t\t} catch (SqlExecutionException e) {\n+\t\t\t\t// ignore further exceptions\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate List<Row> waitBatchResults() {\n+\t\tList<Row> resultRows;\n+\t\t// take snapshot and make all results in one page\n+\t\tdo {\n+\t\t\ttry {\n+\t\t\t\tThread.sleep(50);\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t}\n+\t\t\tTypedResult<Integer> result = sqlExecutor.snapshotResult(\n+\t\t\t\t\tsessionId,\n+\t\t\t\t\tresultDescriptor.getResultId(),\n+\t\t\t\t\tInteger.MAX_VALUE);\n+\n+\t\t\tif (result.getType() == TypedResult.ResultType.EOS) {\n+\t\t\t\tresultRows = Collections.emptyList();\n+\t\t\t\tbreak;\n+\t\t\t} else if (result.getType() == TypedResult.ResultType.PAYLOAD) {\n+\t\t\t\tresultRows = sqlExecutor.retrieveResultPage(resultDescriptor.getResultId(), 1);\n+\t\t\t\tbreak;\n+\t\t\t} else {\n+\t\t\t\t// result not retrieved yet\n+\t\t\t}\n+\t\t} while (true);\n+\n+\t\treturn resultRows;\n+\t}\n+\n+\tprivate void printStreamResults(AtomicInteger receivedRowCount) {\n+\t\tList<TableColumn> columns = resultDescriptor.getResultSchema().getTableColumns();\n+\t\tString[] fieldNames =\n+\t\t\t\tStream.concat(\n+\t\t\t\t\t\tStream.of(\"+/-\"),\n+\t\t\t\t\t\tcolumns.stream().map(TableColumn::getName)\n+\t\t\t\t).toArray(String[]::new);\n+\n+\t\tint[] colWidths = columnWidthsByType(columns, true);\n+\t\tString borderline = genBorderLine(colWidths);\n+\n+\t\t// print filed names\n+\t\tterminal.writer().println(borderline);\n+\t\tprintSingleRow(colWidths, fieldNames);\n+\t\tterminal.writer().println(borderline);\n+\t\tterminal.flush();\n+\n+\t\twhile (true) {\n+\t\t\tfinal TypedResult<List<Tuple2<Boolean, Row>>> result =\n+\t\t\t\t\tsqlExecutor.retrieveResultChanges(sessionId, resultDescriptor.getResultId());\n+\n+\t\t\tswitch (result.getType()) {\n+\t\t\t\tcase EMPTY:\n+\t\t\t\t\t// do nothing\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase EOS:\n+\t\t\t\t\tif (receivedRowCount.get() > 0) {\n+\t\t\t\t\t\tterminal.writer().println(borderline);\n+\t\t\t\t\t}\n+\t\t\t\t\tterminal.writer().println(\"Received a total of \" + receivedRowCount.get() + \" rows\");\n+\t\t\t\t\tterminal.flush();\n+\t\t\t\t\treturn;\n+\t\t\t\tdefault:\n+\t\t\t\t\tList<Tuple2<Boolean, Row>> changes = result.getPayload();\n+\t\t\t\t\tfor (Tuple2<Boolean, Row> change : changes) {\n+\t\t\t\t\t\tfinal String[] cols = rowToString(change.f1);\n+\t\t\t\t\t\tString[] row = new String[cols.length + 1];\n+\t\t\t\t\t\trow[0] = change.f0 ? \"+\" : \"-\";\n+\t\t\t\t\t\tSystem.arraycopy(cols, 0, row, 1, cols.length);\n+\t\t\t\t\t\tprintSingleRow(colWidths, row);\n+\t\t\t\t\t\treceivedRowCount.addAndGet(1);\n+\t\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate void printBatchResults(List<Row> resultRows) {\n+\t\tList<String[]> rows = new ArrayList<>(resultRows.size() + 1);\n+\n+\t\t// fill field names first\n+\t\tList<TableColumn> columns = resultDescriptor.getResultSchema().getTableColumns();\n+\t\trows.add(columns.stream().map(TableColumn::getName).toArray(String[]::new));\n+\t\tresultRows.forEach(row -> rows.add(rowToString(row)));\n+\n+\t\tint[] colWidths = columnWidthsByContent(columns, rows);\n+\t\tString borderline = genBorderLine(colWidths);\n+\n+\t\t// print field names\n+\t\tterminal.writer().println(borderline);\n+\t\tprintSingleRow(colWidths, rows.get(0));\n+\t\tterminal.writer().println(borderline);\n+\n+\t\t// print content\n+\t\trows.subList(1, rows.size()).forEach(row -> printSingleRow(colWidths, row));\n+\t\tif (!resultRows.isEmpty()) {\n+\t\t\tterminal.writer().println(borderline);\n+\t\t}\n+\n+\t\t// print footer\n+\t\tterminal.writer().println(resultRows.size() + \" row in set\");\n+\t\tterminal.flush();\n+\t}\n+\n+\tprivate String genBorderLine(int[] colWidths) {\n+\t\tStringBuilder sb = new StringBuilder();\n+\t\tsb.append(\"+\");\n+\t\tfor (int width : colWidths) {\n+\t\t\tsb.append(StringUtils.repeat(\"-\", width + 1));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "87fcf8d5a1309a85519e0a09df0191acd515c15d"}, "originalPosition": 266}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjIzNzM3MA==", "bodyText": "Use StringUtils.repeat(char) or CliUtils.repeatChar?", "url": "https://github.com/apache/flink/pull/11273#discussion_r386237370", "createdAt": "2020-03-02T07:50:25Z", "author": {"login": "JingsongLi"}, "path": "flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/cli/CliTableauResultView.java", "diffHunk": "@@ -0,0 +1,378 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.client.cli;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.api.TableColumn;\n+import org.apache.flink.table.client.gateway.Executor;\n+import org.apache.flink.table.client.gateway.ResultDescriptor;\n+import org.apache.flink.table.client.gateway.SqlExecutionException;\n+import org.apache.flink.table.client.gateway.TypedResult;\n+import org.apache.flink.table.types.logical.BigIntType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.IntType;\n+import org.apache.flink.table.types.logical.LocalZonedTimestampType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.SmallIntType;\n+import org.apache.flink.table.types.logical.TimeType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+import org.apache.flink.table.types.logical.TinyIntType;\n+import org.apache.flink.types.Row;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.jline.terminal.Terminal;\n+\n+import java.io.Closeable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Stream;\n+\n+import static org.apache.flink.table.client.cli.CliUtils.rowToString;\n+\n+/**\n+ * Print result in tableau mode.\n+ */\n+public class CliTableauResultView implements Closeable {\n+\n+\tprivate static final int NULL_COLUMN_WIDTH = CliStrings.NULL_COLUMN.length();\n+\tprivate static final int MAX_COLUMN_WIDTH = 30;\n+\tprivate static final int DEFAULT_COLUMN_WIDTH = 20;\n+\tprivate static final String COLUMN_TRUNCATED_FLAG = \"...\";\n+\tprivate static final String CHANGEFLAG_COLUMN_NAME = \"+/-\";\n+\n+\tprivate final Terminal terminal;\n+\tprivate final Executor sqlExecutor;\n+\tprivate final String sessionId;\n+\tprivate final ResultDescriptor resultDescriptor;\n+\tprivate final ExecutorService displayResultExecutorService;\n+\n+\tprivate volatile boolean cleanUpQuery;\n+\n+\tpublic CliTableauResultView(\n+\t\t\tfinal Terminal terminal,\n+\t\t\tfinal Executor sqlExecutor,\n+\t\t\tfinal String sessionId,\n+\t\t\tfinal ResultDescriptor resultDescriptor) {\n+\t\tthis.terminal = terminal;\n+\t\tthis.sqlExecutor = sqlExecutor;\n+\t\tthis.sessionId = sessionId;\n+\t\tthis.resultDescriptor = resultDescriptor;\n+\t\tthis.displayResultExecutorService = Executors.newSingleThreadExecutor();\n+\t}\n+\n+\tpublic void displayStreamResults() throws SqlExecutionException {\n+\t\tfinal AtomicInteger receivedRowCount = new AtomicInteger(0);\n+\t\tFuture<?> resultFuture = displayResultExecutorService.submit(() -> {\n+\t\t\tprintStreamResults(receivedRowCount);\n+\t\t});\n+\n+\t\t// capture CTRL-C\n+\t\tterminal.handle(Terminal.Signal.INT, signal -> {\n+\t\t\tresultFuture.cancel(true);\n+\t\t});\n+\n+\t\tcleanUpQuery = true;\n+\t\ttry {\n+\t\t\tresultFuture.get();\n+\t\t\tcleanUpQuery = false; // job finished successfully\n+\t\t} catch (CancellationException e) {\n+\t\t\tterminal.writer().println(\"Query terminated, received a total of \" + receivedRowCount.get() + \" rows\");\n+\t\t\tterminal.flush();\n+\t\t} catch (ExecutionException e) {\n+\t\t\tif (e.getCause() instanceof SqlExecutionException) {\n+\t\t\t\tthrow (SqlExecutionException) e.getCause();\n+\t\t\t}\n+\t\t\tthrow new SqlExecutionException(\"unknown exception\", e.getCause());\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new SqlExecutionException(\"Query interrupted\", e);\n+\t\t} finally {\n+\t\t\tcheckAndCleanUpQuery();\n+\t\t}\n+\t}\n+\n+\tpublic void displayBatchResults() throws SqlExecutionException {\n+\t\tFuture<?> resultFuture = displayResultExecutorService.submit(() -> {\n+\t\t\tfinal List<Row> resultRows = waitBatchResults();\n+\t\t\tprintBatchResults(resultRows);\n+\t\t});\n+\n+\t\t// capture CTRL-C\n+\t\tterminal.handle(Terminal.Signal.INT, signal -> {\n+\t\t\tresultFuture.cancel(true);\n+\t\t});\n+\n+\t\tcleanUpQuery = true;\n+\t\ttry {\n+\t\t\tresultFuture.get();\n+\t\t\tcleanUpQuery = false; // job finished successfully\n+\t\t} catch (CancellationException e) {\n+\t\t\tterminal.writer().println(\"Query terminated\");\n+\t\t\tterminal.flush();\n+\t\t} catch (ExecutionException e) {\n+\t\t\tif (e.getCause() instanceof SqlExecutionException) {\n+\t\t\t\tthrow (SqlExecutionException) e.getCause();\n+\t\t\t}\n+\t\t\tthrow new SqlExecutionException(\"unknown exception\", e.getCause());\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new SqlExecutionException(\"Query interrupted\", e);\n+\t\t} finally {\n+\t\t\tcheckAndCleanUpQuery();\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tthis.displayResultExecutorService.shutdown();\n+\t}\n+\n+\tprivate void checkAndCleanUpQuery() {\n+\t\tif (cleanUpQuery) {\n+\t\t\ttry {\n+\t\t\t\tsqlExecutor.cancelQuery(sessionId, resultDescriptor.getResultId());\n+\t\t\t} catch (SqlExecutionException e) {\n+\t\t\t\t// ignore further exceptions\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate List<Row> waitBatchResults() {\n+\t\tList<Row> resultRows;\n+\t\t// take snapshot and make all results in one page\n+\t\tdo {\n+\t\t\ttry {\n+\t\t\t\tThread.sleep(50);\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t}\n+\t\t\tTypedResult<Integer> result = sqlExecutor.snapshotResult(\n+\t\t\t\t\tsessionId,\n+\t\t\t\t\tresultDescriptor.getResultId(),\n+\t\t\t\t\tInteger.MAX_VALUE);\n+\n+\t\t\tif (result.getType() == TypedResult.ResultType.EOS) {\n+\t\t\t\tresultRows = Collections.emptyList();\n+\t\t\t\tbreak;\n+\t\t\t} else if (result.getType() == TypedResult.ResultType.PAYLOAD) {\n+\t\t\t\tresultRows = sqlExecutor.retrieveResultPage(resultDescriptor.getResultId(), 1);\n+\t\t\t\tbreak;\n+\t\t\t} else {\n+\t\t\t\t// result not retrieved yet\n+\t\t\t}\n+\t\t} while (true);\n+\n+\t\treturn resultRows;\n+\t}\n+\n+\tprivate void printStreamResults(AtomicInteger receivedRowCount) {\n+\t\tList<TableColumn> columns = resultDescriptor.getResultSchema().getTableColumns();\n+\t\tString[] fieldNames =\n+\t\t\t\tStream.concat(\n+\t\t\t\t\t\tStream.of(\"+/-\"),\n+\t\t\t\t\t\tcolumns.stream().map(TableColumn::getName)\n+\t\t\t\t).toArray(String[]::new);\n+\n+\t\tint[] colWidths = columnWidthsByType(columns, true);\n+\t\tString borderline = genBorderLine(colWidths);\n+\n+\t\t// print filed names\n+\t\tterminal.writer().println(borderline);\n+\t\tprintSingleRow(colWidths, fieldNames);\n+\t\tterminal.writer().println(borderline);\n+\t\tterminal.flush();\n+\n+\t\twhile (true) {\n+\t\t\tfinal TypedResult<List<Tuple2<Boolean, Row>>> result =\n+\t\t\t\t\tsqlExecutor.retrieveResultChanges(sessionId, resultDescriptor.getResultId());\n+\n+\t\t\tswitch (result.getType()) {\n+\t\t\t\tcase EMPTY:\n+\t\t\t\t\t// do nothing\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase EOS:\n+\t\t\t\t\tif (receivedRowCount.get() > 0) {\n+\t\t\t\t\t\tterminal.writer().println(borderline);\n+\t\t\t\t\t}\n+\t\t\t\t\tterminal.writer().println(\"Received a total of \" + receivedRowCount.get() + \" rows\");\n+\t\t\t\t\tterminal.flush();\n+\t\t\t\t\treturn;\n+\t\t\t\tdefault:\n+\t\t\t\t\tList<Tuple2<Boolean, Row>> changes = result.getPayload();\n+\t\t\t\t\tfor (Tuple2<Boolean, Row> change : changes) {\n+\t\t\t\t\t\tfinal String[] cols = rowToString(change.f1);\n+\t\t\t\t\t\tString[] row = new String[cols.length + 1];\n+\t\t\t\t\t\trow[0] = change.f0 ? \"+\" : \"-\";\n+\t\t\t\t\t\tSystem.arraycopy(cols, 0, row, 1, cols.length);\n+\t\t\t\t\t\tprintSingleRow(colWidths, row);\n+\t\t\t\t\t\treceivedRowCount.addAndGet(1);\n+\t\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate void printBatchResults(List<Row> resultRows) {\n+\t\tList<String[]> rows = new ArrayList<>(resultRows.size() + 1);\n+\n+\t\t// fill field names first\n+\t\tList<TableColumn> columns = resultDescriptor.getResultSchema().getTableColumns();\n+\t\trows.add(columns.stream().map(TableColumn::getName).toArray(String[]::new));\n+\t\tresultRows.forEach(row -> rows.add(rowToString(row)));\n+\n+\t\tint[] colWidths = columnWidthsByContent(columns, rows);\n+\t\tString borderline = genBorderLine(colWidths);\n+\n+\t\t// print field names\n+\t\tterminal.writer().println(borderline);\n+\t\tprintSingleRow(colWidths, rows.get(0));\n+\t\tterminal.writer().println(borderline);\n+\n+\t\t// print content\n+\t\trows.subList(1, rows.size()).forEach(row -> printSingleRow(colWidths, row));\n+\t\tif (!resultRows.isEmpty()) {\n+\t\t\tterminal.writer().println(borderline);\n+\t\t}\n+\n+\t\t// print footer\n+\t\tterminal.writer().println(resultRows.size() + \" row in set\");\n+\t\tterminal.flush();\n+\t}\n+\n+\tprivate String genBorderLine(int[] colWidths) {\n+\t\tStringBuilder sb = new StringBuilder();\n+\t\tsb.append(\"+\");\n+\t\tfor (int width : colWidths) {\n+\t\t\tsb.append(StringUtils.repeat(\"-\", width + 1));\n+\t\t\tsb.append(\"-+\");\n+\t\t}\n+\t\treturn sb.toString();\n+\t}\n+\n+\tprivate void printSingleRow(int[] colWidths, String[] cols) {\n+\t\tStringBuilder sb = new StringBuilder();\n+\t\tsb.append(\"|\");\n+\t\tint idx = 0;\n+\t\tfor (String col : cols) {\n+\t\t\tsb.append(\" \");\n+\t\t\tif (col.length() <= colWidths[idx]) {\n+\t\t\t\tsb.append(StringUtils.repeat(\" \", colWidths[idx] - col.length()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "87fcf8d5a1309a85519e0a09df0191acd515c15d"}, "originalPosition": 279}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjIzODA2NA==", "bodyText": "Why not put sb.append(\" \"); into if (col.length() <= colWidths[idx]) block, and not use this append.", "url": "https://github.com/apache/flink/pull/11273#discussion_r386238064", "createdAt": "2020-03-02T07:52:23Z", "author": {"login": "JingsongLi"}, "path": "flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/cli/CliTableauResultView.java", "diffHunk": "@@ -0,0 +1,378 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.client.cli;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.api.TableColumn;\n+import org.apache.flink.table.client.gateway.Executor;\n+import org.apache.flink.table.client.gateway.ResultDescriptor;\n+import org.apache.flink.table.client.gateway.SqlExecutionException;\n+import org.apache.flink.table.client.gateway.TypedResult;\n+import org.apache.flink.table.types.logical.BigIntType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.IntType;\n+import org.apache.flink.table.types.logical.LocalZonedTimestampType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.SmallIntType;\n+import org.apache.flink.table.types.logical.TimeType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+import org.apache.flink.table.types.logical.TinyIntType;\n+import org.apache.flink.types.Row;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.jline.terminal.Terminal;\n+\n+import java.io.Closeable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Stream;\n+\n+import static org.apache.flink.table.client.cli.CliUtils.rowToString;\n+\n+/**\n+ * Print result in tableau mode.\n+ */\n+public class CliTableauResultView implements Closeable {\n+\n+\tprivate static final int NULL_COLUMN_WIDTH = CliStrings.NULL_COLUMN.length();\n+\tprivate static final int MAX_COLUMN_WIDTH = 30;\n+\tprivate static final int DEFAULT_COLUMN_WIDTH = 20;\n+\tprivate static final String COLUMN_TRUNCATED_FLAG = \"...\";\n+\tprivate static final String CHANGEFLAG_COLUMN_NAME = \"+/-\";\n+\n+\tprivate final Terminal terminal;\n+\tprivate final Executor sqlExecutor;\n+\tprivate final String sessionId;\n+\tprivate final ResultDescriptor resultDescriptor;\n+\tprivate final ExecutorService displayResultExecutorService;\n+\n+\tprivate volatile boolean cleanUpQuery;\n+\n+\tpublic CliTableauResultView(\n+\t\t\tfinal Terminal terminal,\n+\t\t\tfinal Executor sqlExecutor,\n+\t\t\tfinal String sessionId,\n+\t\t\tfinal ResultDescriptor resultDescriptor) {\n+\t\tthis.terminal = terminal;\n+\t\tthis.sqlExecutor = sqlExecutor;\n+\t\tthis.sessionId = sessionId;\n+\t\tthis.resultDescriptor = resultDescriptor;\n+\t\tthis.displayResultExecutorService = Executors.newSingleThreadExecutor();\n+\t}\n+\n+\tpublic void displayStreamResults() throws SqlExecutionException {\n+\t\tfinal AtomicInteger receivedRowCount = new AtomicInteger(0);\n+\t\tFuture<?> resultFuture = displayResultExecutorService.submit(() -> {\n+\t\t\tprintStreamResults(receivedRowCount);\n+\t\t});\n+\n+\t\t// capture CTRL-C\n+\t\tterminal.handle(Terminal.Signal.INT, signal -> {\n+\t\t\tresultFuture.cancel(true);\n+\t\t});\n+\n+\t\tcleanUpQuery = true;\n+\t\ttry {\n+\t\t\tresultFuture.get();\n+\t\t\tcleanUpQuery = false; // job finished successfully\n+\t\t} catch (CancellationException e) {\n+\t\t\tterminal.writer().println(\"Query terminated, received a total of \" + receivedRowCount.get() + \" rows\");\n+\t\t\tterminal.flush();\n+\t\t} catch (ExecutionException e) {\n+\t\t\tif (e.getCause() instanceof SqlExecutionException) {\n+\t\t\t\tthrow (SqlExecutionException) e.getCause();\n+\t\t\t}\n+\t\t\tthrow new SqlExecutionException(\"unknown exception\", e.getCause());\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new SqlExecutionException(\"Query interrupted\", e);\n+\t\t} finally {\n+\t\t\tcheckAndCleanUpQuery();\n+\t\t}\n+\t}\n+\n+\tpublic void displayBatchResults() throws SqlExecutionException {\n+\t\tFuture<?> resultFuture = displayResultExecutorService.submit(() -> {\n+\t\t\tfinal List<Row> resultRows = waitBatchResults();\n+\t\t\tprintBatchResults(resultRows);\n+\t\t});\n+\n+\t\t// capture CTRL-C\n+\t\tterminal.handle(Terminal.Signal.INT, signal -> {\n+\t\t\tresultFuture.cancel(true);\n+\t\t});\n+\n+\t\tcleanUpQuery = true;\n+\t\ttry {\n+\t\t\tresultFuture.get();\n+\t\t\tcleanUpQuery = false; // job finished successfully\n+\t\t} catch (CancellationException e) {\n+\t\t\tterminal.writer().println(\"Query terminated\");\n+\t\t\tterminal.flush();\n+\t\t} catch (ExecutionException e) {\n+\t\t\tif (e.getCause() instanceof SqlExecutionException) {\n+\t\t\t\tthrow (SqlExecutionException) e.getCause();\n+\t\t\t}\n+\t\t\tthrow new SqlExecutionException(\"unknown exception\", e.getCause());\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new SqlExecutionException(\"Query interrupted\", e);\n+\t\t} finally {\n+\t\t\tcheckAndCleanUpQuery();\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tthis.displayResultExecutorService.shutdown();\n+\t}\n+\n+\tprivate void checkAndCleanUpQuery() {\n+\t\tif (cleanUpQuery) {\n+\t\t\ttry {\n+\t\t\t\tsqlExecutor.cancelQuery(sessionId, resultDescriptor.getResultId());\n+\t\t\t} catch (SqlExecutionException e) {\n+\t\t\t\t// ignore further exceptions\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate List<Row> waitBatchResults() {\n+\t\tList<Row> resultRows;\n+\t\t// take snapshot and make all results in one page\n+\t\tdo {\n+\t\t\ttry {\n+\t\t\t\tThread.sleep(50);\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t}\n+\t\t\tTypedResult<Integer> result = sqlExecutor.snapshotResult(\n+\t\t\t\t\tsessionId,\n+\t\t\t\t\tresultDescriptor.getResultId(),\n+\t\t\t\t\tInteger.MAX_VALUE);\n+\n+\t\t\tif (result.getType() == TypedResult.ResultType.EOS) {\n+\t\t\t\tresultRows = Collections.emptyList();\n+\t\t\t\tbreak;\n+\t\t\t} else if (result.getType() == TypedResult.ResultType.PAYLOAD) {\n+\t\t\t\tresultRows = sqlExecutor.retrieveResultPage(resultDescriptor.getResultId(), 1);\n+\t\t\t\tbreak;\n+\t\t\t} else {\n+\t\t\t\t// result not retrieved yet\n+\t\t\t}\n+\t\t} while (true);\n+\n+\t\treturn resultRows;\n+\t}\n+\n+\tprivate void printStreamResults(AtomicInteger receivedRowCount) {\n+\t\tList<TableColumn> columns = resultDescriptor.getResultSchema().getTableColumns();\n+\t\tString[] fieldNames =\n+\t\t\t\tStream.concat(\n+\t\t\t\t\t\tStream.of(\"+/-\"),\n+\t\t\t\t\t\tcolumns.stream().map(TableColumn::getName)\n+\t\t\t\t).toArray(String[]::new);\n+\n+\t\tint[] colWidths = columnWidthsByType(columns, true);\n+\t\tString borderline = genBorderLine(colWidths);\n+\n+\t\t// print filed names\n+\t\tterminal.writer().println(borderline);\n+\t\tprintSingleRow(colWidths, fieldNames);\n+\t\tterminal.writer().println(borderline);\n+\t\tterminal.flush();\n+\n+\t\twhile (true) {\n+\t\t\tfinal TypedResult<List<Tuple2<Boolean, Row>>> result =\n+\t\t\t\t\tsqlExecutor.retrieveResultChanges(sessionId, resultDescriptor.getResultId());\n+\n+\t\t\tswitch (result.getType()) {\n+\t\t\t\tcase EMPTY:\n+\t\t\t\t\t// do nothing\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase EOS:\n+\t\t\t\t\tif (receivedRowCount.get() > 0) {\n+\t\t\t\t\t\tterminal.writer().println(borderline);\n+\t\t\t\t\t}\n+\t\t\t\t\tterminal.writer().println(\"Received a total of \" + receivedRowCount.get() + \" rows\");\n+\t\t\t\t\tterminal.flush();\n+\t\t\t\t\treturn;\n+\t\t\t\tdefault:\n+\t\t\t\t\tList<Tuple2<Boolean, Row>> changes = result.getPayload();\n+\t\t\t\t\tfor (Tuple2<Boolean, Row> change : changes) {\n+\t\t\t\t\t\tfinal String[] cols = rowToString(change.f1);\n+\t\t\t\t\t\tString[] row = new String[cols.length + 1];\n+\t\t\t\t\t\trow[0] = change.f0 ? \"+\" : \"-\";\n+\t\t\t\t\t\tSystem.arraycopy(cols, 0, row, 1, cols.length);\n+\t\t\t\t\t\tprintSingleRow(colWidths, row);\n+\t\t\t\t\t\treceivedRowCount.addAndGet(1);\n+\t\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate void printBatchResults(List<Row> resultRows) {\n+\t\tList<String[]> rows = new ArrayList<>(resultRows.size() + 1);\n+\n+\t\t// fill field names first\n+\t\tList<TableColumn> columns = resultDescriptor.getResultSchema().getTableColumns();\n+\t\trows.add(columns.stream().map(TableColumn::getName).toArray(String[]::new));\n+\t\tresultRows.forEach(row -> rows.add(rowToString(row)));\n+\n+\t\tint[] colWidths = columnWidthsByContent(columns, rows);\n+\t\tString borderline = genBorderLine(colWidths);\n+\n+\t\t// print field names\n+\t\tterminal.writer().println(borderline);\n+\t\tprintSingleRow(colWidths, rows.get(0));\n+\t\tterminal.writer().println(borderline);\n+\n+\t\t// print content\n+\t\trows.subList(1, rows.size()).forEach(row -> printSingleRow(colWidths, row));\n+\t\tif (!resultRows.isEmpty()) {\n+\t\t\tterminal.writer().println(borderline);\n+\t\t}\n+\n+\t\t// print footer\n+\t\tterminal.writer().println(resultRows.size() + \" row in set\");\n+\t\tterminal.flush();\n+\t}\n+\n+\tprivate String genBorderLine(int[] colWidths) {\n+\t\tStringBuilder sb = new StringBuilder();\n+\t\tsb.append(\"+\");\n+\t\tfor (int width : colWidths) {\n+\t\t\tsb.append(StringUtils.repeat(\"-\", width + 1));\n+\t\t\tsb.append(\"-+\");\n+\t\t}\n+\t\treturn sb.toString();\n+\t}\n+\n+\tprivate void printSingleRow(int[] colWidths, String[] cols) {\n+\t\tStringBuilder sb = new StringBuilder();\n+\t\tsb.append(\"|\");\n+\t\tint idx = 0;\n+\t\tfor (String col : cols) {\n+\t\t\tsb.append(\" \");\n+\t\t\tif (col.length() <= colWidths[idx]) {\n+\t\t\t\tsb.append(StringUtils.repeat(\" \", colWidths[idx] - col.length()));\n+\t\t\t\tsb.append(col);\n+\t\t\t} else {\n+\t\t\t\tsb.append(col, 0, colWidths[idx] - COLUMN_TRUNCATED_FLAG.length());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "87fcf8d5a1309a85519e0a09df0191acd515c15d"}, "originalPosition": 282}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjIzODk3OA==", "bodyText": "Why flush? Flush at final when batch?", "url": "https://github.com/apache/flink/pull/11273#discussion_r386238978", "createdAt": "2020-03-02T07:55:24Z", "author": {"login": "JingsongLi"}, "path": "flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/cli/CliTableauResultView.java", "diffHunk": "@@ -0,0 +1,378 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.client.cli;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.api.TableColumn;\n+import org.apache.flink.table.client.gateway.Executor;\n+import org.apache.flink.table.client.gateway.ResultDescriptor;\n+import org.apache.flink.table.client.gateway.SqlExecutionException;\n+import org.apache.flink.table.client.gateway.TypedResult;\n+import org.apache.flink.table.types.logical.BigIntType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.IntType;\n+import org.apache.flink.table.types.logical.LocalZonedTimestampType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.SmallIntType;\n+import org.apache.flink.table.types.logical.TimeType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+import org.apache.flink.table.types.logical.TinyIntType;\n+import org.apache.flink.types.Row;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.jline.terminal.Terminal;\n+\n+import java.io.Closeable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Stream;\n+\n+import static org.apache.flink.table.client.cli.CliUtils.rowToString;\n+\n+/**\n+ * Print result in tableau mode.\n+ */\n+public class CliTableauResultView implements Closeable {\n+\n+\tprivate static final int NULL_COLUMN_WIDTH = CliStrings.NULL_COLUMN.length();\n+\tprivate static final int MAX_COLUMN_WIDTH = 30;\n+\tprivate static final int DEFAULT_COLUMN_WIDTH = 20;\n+\tprivate static final String COLUMN_TRUNCATED_FLAG = \"...\";\n+\tprivate static final String CHANGEFLAG_COLUMN_NAME = \"+/-\";\n+\n+\tprivate final Terminal terminal;\n+\tprivate final Executor sqlExecutor;\n+\tprivate final String sessionId;\n+\tprivate final ResultDescriptor resultDescriptor;\n+\tprivate final ExecutorService displayResultExecutorService;\n+\n+\tprivate volatile boolean cleanUpQuery;\n+\n+\tpublic CliTableauResultView(\n+\t\t\tfinal Terminal terminal,\n+\t\t\tfinal Executor sqlExecutor,\n+\t\t\tfinal String sessionId,\n+\t\t\tfinal ResultDescriptor resultDescriptor) {\n+\t\tthis.terminal = terminal;\n+\t\tthis.sqlExecutor = sqlExecutor;\n+\t\tthis.sessionId = sessionId;\n+\t\tthis.resultDescriptor = resultDescriptor;\n+\t\tthis.displayResultExecutorService = Executors.newSingleThreadExecutor();\n+\t}\n+\n+\tpublic void displayStreamResults() throws SqlExecutionException {\n+\t\tfinal AtomicInteger receivedRowCount = new AtomicInteger(0);\n+\t\tFuture<?> resultFuture = displayResultExecutorService.submit(() -> {\n+\t\t\tprintStreamResults(receivedRowCount);\n+\t\t});\n+\n+\t\t// capture CTRL-C\n+\t\tterminal.handle(Terminal.Signal.INT, signal -> {\n+\t\t\tresultFuture.cancel(true);\n+\t\t});\n+\n+\t\tcleanUpQuery = true;\n+\t\ttry {\n+\t\t\tresultFuture.get();\n+\t\t\tcleanUpQuery = false; // job finished successfully\n+\t\t} catch (CancellationException e) {\n+\t\t\tterminal.writer().println(\"Query terminated, received a total of \" + receivedRowCount.get() + \" rows\");\n+\t\t\tterminal.flush();\n+\t\t} catch (ExecutionException e) {\n+\t\t\tif (e.getCause() instanceof SqlExecutionException) {\n+\t\t\t\tthrow (SqlExecutionException) e.getCause();\n+\t\t\t}\n+\t\t\tthrow new SqlExecutionException(\"unknown exception\", e.getCause());\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new SqlExecutionException(\"Query interrupted\", e);\n+\t\t} finally {\n+\t\t\tcheckAndCleanUpQuery();\n+\t\t}\n+\t}\n+\n+\tpublic void displayBatchResults() throws SqlExecutionException {\n+\t\tFuture<?> resultFuture = displayResultExecutorService.submit(() -> {\n+\t\t\tfinal List<Row> resultRows = waitBatchResults();\n+\t\t\tprintBatchResults(resultRows);\n+\t\t});\n+\n+\t\t// capture CTRL-C\n+\t\tterminal.handle(Terminal.Signal.INT, signal -> {\n+\t\t\tresultFuture.cancel(true);\n+\t\t});\n+\n+\t\tcleanUpQuery = true;\n+\t\ttry {\n+\t\t\tresultFuture.get();\n+\t\t\tcleanUpQuery = false; // job finished successfully\n+\t\t} catch (CancellationException e) {\n+\t\t\tterminal.writer().println(\"Query terminated\");\n+\t\t\tterminal.flush();\n+\t\t} catch (ExecutionException e) {\n+\t\t\tif (e.getCause() instanceof SqlExecutionException) {\n+\t\t\t\tthrow (SqlExecutionException) e.getCause();\n+\t\t\t}\n+\t\t\tthrow new SqlExecutionException(\"unknown exception\", e.getCause());\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new SqlExecutionException(\"Query interrupted\", e);\n+\t\t} finally {\n+\t\t\tcheckAndCleanUpQuery();\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tthis.displayResultExecutorService.shutdown();\n+\t}\n+\n+\tprivate void checkAndCleanUpQuery() {\n+\t\tif (cleanUpQuery) {\n+\t\t\ttry {\n+\t\t\t\tsqlExecutor.cancelQuery(sessionId, resultDescriptor.getResultId());\n+\t\t\t} catch (SqlExecutionException e) {\n+\t\t\t\t// ignore further exceptions\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate List<Row> waitBatchResults() {\n+\t\tList<Row> resultRows;\n+\t\t// take snapshot and make all results in one page\n+\t\tdo {\n+\t\t\ttry {\n+\t\t\t\tThread.sleep(50);\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t}\n+\t\t\tTypedResult<Integer> result = sqlExecutor.snapshotResult(\n+\t\t\t\t\tsessionId,\n+\t\t\t\t\tresultDescriptor.getResultId(),\n+\t\t\t\t\tInteger.MAX_VALUE);\n+\n+\t\t\tif (result.getType() == TypedResult.ResultType.EOS) {\n+\t\t\t\tresultRows = Collections.emptyList();\n+\t\t\t\tbreak;\n+\t\t\t} else if (result.getType() == TypedResult.ResultType.PAYLOAD) {\n+\t\t\t\tresultRows = sqlExecutor.retrieveResultPage(resultDescriptor.getResultId(), 1);\n+\t\t\t\tbreak;\n+\t\t\t} else {\n+\t\t\t\t// result not retrieved yet\n+\t\t\t}\n+\t\t} while (true);\n+\n+\t\treturn resultRows;\n+\t}\n+\n+\tprivate void printStreamResults(AtomicInteger receivedRowCount) {\n+\t\tList<TableColumn> columns = resultDescriptor.getResultSchema().getTableColumns();\n+\t\tString[] fieldNames =\n+\t\t\t\tStream.concat(\n+\t\t\t\t\t\tStream.of(\"+/-\"),\n+\t\t\t\t\t\tcolumns.stream().map(TableColumn::getName)\n+\t\t\t\t).toArray(String[]::new);\n+\n+\t\tint[] colWidths = columnWidthsByType(columns, true);\n+\t\tString borderline = genBorderLine(colWidths);\n+\n+\t\t// print filed names\n+\t\tterminal.writer().println(borderline);\n+\t\tprintSingleRow(colWidths, fieldNames);\n+\t\tterminal.writer().println(borderline);\n+\t\tterminal.flush();\n+\n+\t\twhile (true) {\n+\t\t\tfinal TypedResult<List<Tuple2<Boolean, Row>>> result =\n+\t\t\t\t\tsqlExecutor.retrieveResultChanges(sessionId, resultDescriptor.getResultId());\n+\n+\t\t\tswitch (result.getType()) {\n+\t\t\t\tcase EMPTY:\n+\t\t\t\t\t// do nothing\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase EOS:\n+\t\t\t\t\tif (receivedRowCount.get() > 0) {\n+\t\t\t\t\t\tterminal.writer().println(borderline);\n+\t\t\t\t\t}\n+\t\t\t\t\tterminal.writer().println(\"Received a total of \" + receivedRowCount.get() + \" rows\");\n+\t\t\t\t\tterminal.flush();\n+\t\t\t\t\treturn;\n+\t\t\t\tdefault:\n+\t\t\t\t\tList<Tuple2<Boolean, Row>> changes = result.getPayload();\n+\t\t\t\t\tfor (Tuple2<Boolean, Row> change : changes) {\n+\t\t\t\t\t\tfinal String[] cols = rowToString(change.f1);\n+\t\t\t\t\t\tString[] row = new String[cols.length + 1];\n+\t\t\t\t\t\trow[0] = change.f0 ? \"+\" : \"-\";\n+\t\t\t\t\t\tSystem.arraycopy(cols, 0, row, 1, cols.length);\n+\t\t\t\t\t\tprintSingleRow(colWidths, row);\n+\t\t\t\t\t\treceivedRowCount.addAndGet(1);\n+\t\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate void printBatchResults(List<Row> resultRows) {\n+\t\tList<String[]> rows = new ArrayList<>(resultRows.size() + 1);\n+\n+\t\t// fill field names first\n+\t\tList<TableColumn> columns = resultDescriptor.getResultSchema().getTableColumns();\n+\t\trows.add(columns.stream().map(TableColumn::getName).toArray(String[]::new));\n+\t\tresultRows.forEach(row -> rows.add(rowToString(row)));\n+\n+\t\tint[] colWidths = columnWidthsByContent(columns, rows);\n+\t\tString borderline = genBorderLine(colWidths);\n+\n+\t\t// print field names\n+\t\tterminal.writer().println(borderline);\n+\t\tprintSingleRow(colWidths, rows.get(0));\n+\t\tterminal.writer().println(borderline);\n+\n+\t\t// print content\n+\t\trows.subList(1, rows.size()).forEach(row -> printSingleRow(colWidths, row));\n+\t\tif (!resultRows.isEmpty()) {\n+\t\t\tterminal.writer().println(borderline);\n+\t\t}\n+\n+\t\t// print footer\n+\t\tterminal.writer().println(resultRows.size() + \" row in set\");\n+\t\tterminal.flush();\n+\t}\n+\n+\tprivate String genBorderLine(int[] colWidths) {\n+\t\tStringBuilder sb = new StringBuilder();\n+\t\tsb.append(\"+\");\n+\t\tfor (int width : colWidths) {\n+\t\t\tsb.append(StringUtils.repeat(\"-\", width + 1));\n+\t\t\tsb.append(\"-+\");\n+\t\t}\n+\t\treturn sb.toString();\n+\t}\n+\n+\tprivate void printSingleRow(int[] colWidths, String[] cols) {\n+\t\tStringBuilder sb = new StringBuilder();\n+\t\tsb.append(\"|\");\n+\t\tint idx = 0;\n+\t\tfor (String col : cols) {\n+\t\t\tsb.append(\" \");\n+\t\t\tif (col.length() <= colWidths[idx]) {\n+\t\t\t\tsb.append(StringUtils.repeat(\" \", colWidths[idx] - col.length()));\n+\t\t\t\tsb.append(col);\n+\t\t\t} else {\n+\t\t\t\tsb.append(col, 0, colWidths[idx] - COLUMN_TRUNCATED_FLAG.length());\n+\t\t\t\tsb.append(COLUMN_TRUNCATED_FLAG);\n+\t\t\t}\n+\t\t\tsb.append(\" |\");\n+\t\t\tidx++;\n+\t\t}\n+\t\tterminal.writer().println(sb.toString());\n+\t\tterminal.flush();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "87fcf8d5a1309a85519e0a09df0191acd515c15d"}, "originalPosition": 289}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjI0MDUwOA==", "bodyText": "When includeChangeflag is false?", "url": "https://github.com/apache/flink/pull/11273#discussion_r386240508", "createdAt": "2020-03-02T08:00:03Z", "author": {"login": "JingsongLi"}, "path": "flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/cli/CliTableauResultView.java", "diffHunk": "@@ -0,0 +1,378 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.client.cli;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.api.TableColumn;\n+import org.apache.flink.table.client.gateway.Executor;\n+import org.apache.flink.table.client.gateway.ResultDescriptor;\n+import org.apache.flink.table.client.gateway.SqlExecutionException;\n+import org.apache.flink.table.client.gateway.TypedResult;\n+import org.apache.flink.table.types.logical.BigIntType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.IntType;\n+import org.apache.flink.table.types.logical.LocalZonedTimestampType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.SmallIntType;\n+import org.apache.flink.table.types.logical.TimeType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+import org.apache.flink.table.types.logical.TinyIntType;\n+import org.apache.flink.types.Row;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.jline.terminal.Terminal;\n+\n+import java.io.Closeable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Stream;\n+\n+import static org.apache.flink.table.client.cli.CliUtils.rowToString;\n+\n+/**\n+ * Print result in tableau mode.\n+ */\n+public class CliTableauResultView implements Closeable {\n+\n+\tprivate static final int NULL_COLUMN_WIDTH = CliStrings.NULL_COLUMN.length();\n+\tprivate static final int MAX_COLUMN_WIDTH = 30;\n+\tprivate static final int DEFAULT_COLUMN_WIDTH = 20;\n+\tprivate static final String COLUMN_TRUNCATED_FLAG = \"...\";\n+\tprivate static final String CHANGEFLAG_COLUMN_NAME = \"+/-\";\n+\n+\tprivate final Terminal terminal;\n+\tprivate final Executor sqlExecutor;\n+\tprivate final String sessionId;\n+\tprivate final ResultDescriptor resultDescriptor;\n+\tprivate final ExecutorService displayResultExecutorService;\n+\n+\tprivate volatile boolean cleanUpQuery;\n+\n+\tpublic CliTableauResultView(\n+\t\t\tfinal Terminal terminal,\n+\t\t\tfinal Executor sqlExecutor,\n+\t\t\tfinal String sessionId,\n+\t\t\tfinal ResultDescriptor resultDescriptor) {\n+\t\tthis.terminal = terminal;\n+\t\tthis.sqlExecutor = sqlExecutor;\n+\t\tthis.sessionId = sessionId;\n+\t\tthis.resultDescriptor = resultDescriptor;\n+\t\tthis.displayResultExecutorService = Executors.newSingleThreadExecutor();\n+\t}\n+\n+\tpublic void displayStreamResults() throws SqlExecutionException {\n+\t\tfinal AtomicInteger receivedRowCount = new AtomicInteger(0);\n+\t\tFuture<?> resultFuture = displayResultExecutorService.submit(() -> {\n+\t\t\tprintStreamResults(receivedRowCount);\n+\t\t});\n+\n+\t\t// capture CTRL-C\n+\t\tterminal.handle(Terminal.Signal.INT, signal -> {\n+\t\t\tresultFuture.cancel(true);\n+\t\t});\n+\n+\t\tcleanUpQuery = true;\n+\t\ttry {\n+\t\t\tresultFuture.get();\n+\t\t\tcleanUpQuery = false; // job finished successfully\n+\t\t} catch (CancellationException e) {\n+\t\t\tterminal.writer().println(\"Query terminated, received a total of \" + receivedRowCount.get() + \" rows\");\n+\t\t\tterminal.flush();\n+\t\t} catch (ExecutionException e) {\n+\t\t\tif (e.getCause() instanceof SqlExecutionException) {\n+\t\t\t\tthrow (SqlExecutionException) e.getCause();\n+\t\t\t}\n+\t\t\tthrow new SqlExecutionException(\"unknown exception\", e.getCause());\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new SqlExecutionException(\"Query interrupted\", e);\n+\t\t} finally {\n+\t\t\tcheckAndCleanUpQuery();\n+\t\t}\n+\t}\n+\n+\tpublic void displayBatchResults() throws SqlExecutionException {\n+\t\tFuture<?> resultFuture = displayResultExecutorService.submit(() -> {\n+\t\t\tfinal List<Row> resultRows = waitBatchResults();\n+\t\t\tprintBatchResults(resultRows);\n+\t\t});\n+\n+\t\t// capture CTRL-C\n+\t\tterminal.handle(Terminal.Signal.INT, signal -> {\n+\t\t\tresultFuture.cancel(true);\n+\t\t});\n+\n+\t\tcleanUpQuery = true;\n+\t\ttry {\n+\t\t\tresultFuture.get();\n+\t\t\tcleanUpQuery = false; // job finished successfully\n+\t\t} catch (CancellationException e) {\n+\t\t\tterminal.writer().println(\"Query terminated\");\n+\t\t\tterminal.flush();\n+\t\t} catch (ExecutionException e) {\n+\t\t\tif (e.getCause() instanceof SqlExecutionException) {\n+\t\t\t\tthrow (SqlExecutionException) e.getCause();\n+\t\t\t}\n+\t\t\tthrow new SqlExecutionException(\"unknown exception\", e.getCause());\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new SqlExecutionException(\"Query interrupted\", e);\n+\t\t} finally {\n+\t\t\tcheckAndCleanUpQuery();\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tthis.displayResultExecutorService.shutdown();\n+\t}\n+\n+\tprivate void checkAndCleanUpQuery() {\n+\t\tif (cleanUpQuery) {\n+\t\t\ttry {\n+\t\t\t\tsqlExecutor.cancelQuery(sessionId, resultDescriptor.getResultId());\n+\t\t\t} catch (SqlExecutionException e) {\n+\t\t\t\t// ignore further exceptions\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate List<Row> waitBatchResults() {\n+\t\tList<Row> resultRows;\n+\t\t// take snapshot and make all results in one page\n+\t\tdo {\n+\t\t\ttry {\n+\t\t\t\tThread.sleep(50);\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t}\n+\t\t\tTypedResult<Integer> result = sqlExecutor.snapshotResult(\n+\t\t\t\t\tsessionId,\n+\t\t\t\t\tresultDescriptor.getResultId(),\n+\t\t\t\t\tInteger.MAX_VALUE);\n+\n+\t\t\tif (result.getType() == TypedResult.ResultType.EOS) {\n+\t\t\t\tresultRows = Collections.emptyList();\n+\t\t\t\tbreak;\n+\t\t\t} else if (result.getType() == TypedResult.ResultType.PAYLOAD) {\n+\t\t\t\tresultRows = sqlExecutor.retrieveResultPage(resultDescriptor.getResultId(), 1);\n+\t\t\t\tbreak;\n+\t\t\t} else {\n+\t\t\t\t// result not retrieved yet\n+\t\t\t}\n+\t\t} while (true);\n+\n+\t\treturn resultRows;\n+\t}\n+\n+\tprivate void printStreamResults(AtomicInteger receivedRowCount) {\n+\t\tList<TableColumn> columns = resultDescriptor.getResultSchema().getTableColumns();\n+\t\tString[] fieldNames =\n+\t\t\t\tStream.concat(\n+\t\t\t\t\t\tStream.of(\"+/-\"),\n+\t\t\t\t\t\tcolumns.stream().map(TableColumn::getName)\n+\t\t\t\t).toArray(String[]::new);\n+\n+\t\tint[] colWidths = columnWidthsByType(columns, true);\n+\t\tString borderline = genBorderLine(colWidths);\n+\n+\t\t// print filed names\n+\t\tterminal.writer().println(borderline);\n+\t\tprintSingleRow(colWidths, fieldNames);\n+\t\tterminal.writer().println(borderline);\n+\t\tterminal.flush();\n+\n+\t\twhile (true) {\n+\t\t\tfinal TypedResult<List<Tuple2<Boolean, Row>>> result =\n+\t\t\t\t\tsqlExecutor.retrieveResultChanges(sessionId, resultDescriptor.getResultId());\n+\n+\t\t\tswitch (result.getType()) {\n+\t\t\t\tcase EMPTY:\n+\t\t\t\t\t// do nothing\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase EOS:\n+\t\t\t\t\tif (receivedRowCount.get() > 0) {\n+\t\t\t\t\t\tterminal.writer().println(borderline);\n+\t\t\t\t\t}\n+\t\t\t\t\tterminal.writer().println(\"Received a total of \" + receivedRowCount.get() + \" rows\");\n+\t\t\t\t\tterminal.flush();\n+\t\t\t\t\treturn;\n+\t\t\t\tdefault:\n+\t\t\t\t\tList<Tuple2<Boolean, Row>> changes = result.getPayload();\n+\t\t\t\t\tfor (Tuple2<Boolean, Row> change : changes) {\n+\t\t\t\t\t\tfinal String[] cols = rowToString(change.f1);\n+\t\t\t\t\t\tString[] row = new String[cols.length + 1];\n+\t\t\t\t\t\trow[0] = change.f0 ? \"+\" : \"-\";\n+\t\t\t\t\t\tSystem.arraycopy(cols, 0, row, 1, cols.length);\n+\t\t\t\t\t\tprintSingleRow(colWidths, row);\n+\t\t\t\t\t\treceivedRowCount.addAndGet(1);\n+\t\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate void printBatchResults(List<Row> resultRows) {\n+\t\tList<String[]> rows = new ArrayList<>(resultRows.size() + 1);\n+\n+\t\t// fill field names first\n+\t\tList<TableColumn> columns = resultDescriptor.getResultSchema().getTableColumns();\n+\t\trows.add(columns.stream().map(TableColumn::getName).toArray(String[]::new));\n+\t\tresultRows.forEach(row -> rows.add(rowToString(row)));\n+\n+\t\tint[] colWidths = columnWidthsByContent(columns, rows);\n+\t\tString borderline = genBorderLine(colWidths);\n+\n+\t\t// print field names\n+\t\tterminal.writer().println(borderline);\n+\t\tprintSingleRow(colWidths, rows.get(0));\n+\t\tterminal.writer().println(borderline);\n+\n+\t\t// print content\n+\t\trows.subList(1, rows.size()).forEach(row -> printSingleRow(colWidths, row));\n+\t\tif (!resultRows.isEmpty()) {\n+\t\t\tterminal.writer().println(borderline);\n+\t\t}\n+\n+\t\t// print footer\n+\t\tterminal.writer().println(resultRows.size() + \" row in set\");\n+\t\tterminal.flush();\n+\t}\n+\n+\tprivate String genBorderLine(int[] colWidths) {\n+\t\tStringBuilder sb = new StringBuilder();\n+\t\tsb.append(\"+\");\n+\t\tfor (int width : colWidths) {\n+\t\t\tsb.append(StringUtils.repeat(\"-\", width + 1));\n+\t\t\tsb.append(\"-+\");\n+\t\t}\n+\t\treturn sb.toString();\n+\t}\n+\n+\tprivate void printSingleRow(int[] colWidths, String[] cols) {\n+\t\tStringBuilder sb = new StringBuilder();\n+\t\tsb.append(\"|\");\n+\t\tint idx = 0;\n+\t\tfor (String col : cols) {\n+\t\t\tsb.append(\" \");\n+\t\t\tif (col.length() <= colWidths[idx]) {\n+\t\t\t\tsb.append(StringUtils.repeat(\" \", colWidths[idx] - col.length()));\n+\t\t\t\tsb.append(col);\n+\t\t\t} else {\n+\t\t\t\tsb.append(col, 0, colWidths[idx] - COLUMN_TRUNCATED_FLAG.length());\n+\t\t\t\tsb.append(COLUMN_TRUNCATED_FLAG);\n+\t\t\t}\n+\t\t\tsb.append(\" |\");\n+\t\t\tidx++;\n+\t\t}\n+\t\tterminal.writer().println(sb.toString());\n+\t\tterminal.flush();\n+\t}\n+\n+\t/**\n+\t * Try to infer column width based on column types. In streaming case, we will have an\n+\t * endless result set, thus couldn't determine column widths based on column values.\n+\t */\n+\tprivate int[] columnWidthsByType(List<TableColumn> columns, boolean includeChangeflag) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "87fcf8d5a1309a85519e0a09df0191acd515c15d"}, "originalPosition": 296}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY3MDA2MDQ4", "url": "https://github.com/apache/flink/pull/11273#pullrequestreview-367006048", "createdAt": "2020-03-02T08:06:50Z", "commit": {"oid": "87fcf8d5a1309a85519e0a09df0191acd515c15d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wMlQwODowNjo1MFrOFwWYhw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wMlQwODowNjo1MFrOFwWYhw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjI0MjY5NQ==", "bodyText": "try with resource management?", "url": "https://github.com/apache/flink/pull/11273#discussion_r386242695", "createdAt": "2020-03-02T08:06:50Z", "author": {"login": "JingsongLi"}, "path": "flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/cli/CliClient.java", "diffHunk": "@@ -512,21 +512,38 @@ private void callSelect(SqlCommandCall cmdCall) {\n \t\t\tprintExecutionException(e);\n \t\t\treturn;\n \t\t}\n-\t\tfinal CliResultView view;\n-\t\tif (resultDesc.isMaterialized()) {\n-\t\t\tview = new CliTableResultView(this, resultDesc);\n+\n+\t\tif (resultDesc.isTableauMode()) {\n+\t\t\tCliTableauResultView tableauResultView = new CliTableauResultView(\n+\t\t\t\t\tterminal, executor, sessionId, resultDesc);\n+\t\t\ttry {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "87fcf8d5a1309a85519e0a09df0191acd515c15d"}, "originalPosition": 11}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY3MDExNzc1", "url": "https://github.com/apache/flink/pull/11273#pullrequestreview-367011775", "createdAt": "2020-03-02T08:19:32Z", "commit": {"oid": "87fcf8d5a1309a85519e0a09df0191acd515c15d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wMlQwODoxOTozMlrOFwWqAg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wMlQwODoxOTozMlrOFwWqAg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjI0NzE3MA==", "bodyText": "Do we need this? Just field in method is OK?", "url": "https://github.com/apache/flink/pull/11273#discussion_r386247170", "createdAt": "2020-03-02T08:19:32Z", "author": {"login": "JingsongLi"}, "path": "flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/cli/CliTableauResultView.java", "diffHunk": "@@ -0,0 +1,378 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.client.cli;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.api.TableColumn;\n+import org.apache.flink.table.client.gateway.Executor;\n+import org.apache.flink.table.client.gateway.ResultDescriptor;\n+import org.apache.flink.table.client.gateway.SqlExecutionException;\n+import org.apache.flink.table.client.gateway.TypedResult;\n+import org.apache.flink.table.types.logical.BigIntType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.IntType;\n+import org.apache.flink.table.types.logical.LocalZonedTimestampType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.SmallIntType;\n+import org.apache.flink.table.types.logical.TimeType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+import org.apache.flink.table.types.logical.TinyIntType;\n+import org.apache.flink.types.Row;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.jline.terminal.Terminal;\n+\n+import java.io.Closeable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Stream;\n+\n+import static org.apache.flink.table.client.cli.CliUtils.rowToString;\n+\n+/**\n+ * Print result in tableau mode.\n+ */\n+public class CliTableauResultView implements Closeable {\n+\n+\tprivate static final int NULL_COLUMN_WIDTH = CliStrings.NULL_COLUMN.length();\n+\tprivate static final int MAX_COLUMN_WIDTH = 30;\n+\tprivate static final int DEFAULT_COLUMN_WIDTH = 20;\n+\tprivate static final String COLUMN_TRUNCATED_FLAG = \"...\";\n+\tprivate static final String CHANGEFLAG_COLUMN_NAME = \"+/-\";\n+\n+\tprivate final Terminal terminal;\n+\tprivate final Executor sqlExecutor;\n+\tprivate final String sessionId;\n+\tprivate final ResultDescriptor resultDescriptor;\n+\tprivate final ExecutorService displayResultExecutorService;\n+\n+\tprivate volatile boolean cleanUpQuery;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "87fcf8d5a1309a85519e0a09df0191acd515c15d"}, "originalPosition": 72}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY3MDEyOTg2", "url": "https://github.com/apache/flink/pull/11273#pullrequestreview-367012986", "createdAt": "2020-03-02T08:22:05Z", "commit": {"oid": "87fcf8d5a1309a85519e0a09df0191acd515c15d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wMlQwODoyMjowNVrOFwWtgg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wMlQwODoyMjowNVrOFwWtgg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjI0ODA2Ng==", "bodyText": "add case PAYLOAD and throw unsupport exception for default?", "url": "https://github.com/apache/flink/pull/11273#discussion_r386248066", "createdAt": "2020-03-02T08:22:05Z", "author": {"login": "JingsongLi"}, "path": "flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/cli/CliTableauResultView.java", "diffHunk": "@@ -0,0 +1,378 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.client.cli;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.api.TableColumn;\n+import org.apache.flink.table.client.gateway.Executor;\n+import org.apache.flink.table.client.gateway.ResultDescriptor;\n+import org.apache.flink.table.client.gateway.SqlExecutionException;\n+import org.apache.flink.table.client.gateway.TypedResult;\n+import org.apache.flink.table.types.logical.BigIntType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.IntType;\n+import org.apache.flink.table.types.logical.LocalZonedTimestampType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.SmallIntType;\n+import org.apache.flink.table.types.logical.TimeType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+import org.apache.flink.table.types.logical.TinyIntType;\n+import org.apache.flink.types.Row;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.jline.terminal.Terminal;\n+\n+import java.io.Closeable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Stream;\n+\n+import static org.apache.flink.table.client.cli.CliUtils.rowToString;\n+\n+/**\n+ * Print result in tableau mode.\n+ */\n+public class CliTableauResultView implements Closeable {\n+\n+\tprivate static final int NULL_COLUMN_WIDTH = CliStrings.NULL_COLUMN.length();\n+\tprivate static final int MAX_COLUMN_WIDTH = 30;\n+\tprivate static final int DEFAULT_COLUMN_WIDTH = 20;\n+\tprivate static final String COLUMN_TRUNCATED_FLAG = \"...\";\n+\tprivate static final String CHANGEFLAG_COLUMN_NAME = \"+/-\";\n+\n+\tprivate final Terminal terminal;\n+\tprivate final Executor sqlExecutor;\n+\tprivate final String sessionId;\n+\tprivate final ResultDescriptor resultDescriptor;\n+\tprivate final ExecutorService displayResultExecutorService;\n+\n+\tprivate volatile boolean cleanUpQuery;\n+\n+\tpublic CliTableauResultView(\n+\t\t\tfinal Terminal terminal,\n+\t\t\tfinal Executor sqlExecutor,\n+\t\t\tfinal String sessionId,\n+\t\t\tfinal ResultDescriptor resultDescriptor) {\n+\t\tthis.terminal = terminal;\n+\t\tthis.sqlExecutor = sqlExecutor;\n+\t\tthis.sessionId = sessionId;\n+\t\tthis.resultDescriptor = resultDescriptor;\n+\t\tthis.displayResultExecutorService = Executors.newSingleThreadExecutor();\n+\t}\n+\n+\tpublic void displayStreamResults() throws SqlExecutionException {\n+\t\tfinal AtomicInteger receivedRowCount = new AtomicInteger(0);\n+\t\tFuture<?> resultFuture = displayResultExecutorService.submit(() -> {\n+\t\t\tprintStreamResults(receivedRowCount);\n+\t\t});\n+\n+\t\t// capture CTRL-C\n+\t\tterminal.handle(Terminal.Signal.INT, signal -> {\n+\t\t\tresultFuture.cancel(true);\n+\t\t});\n+\n+\t\tcleanUpQuery = true;\n+\t\ttry {\n+\t\t\tresultFuture.get();\n+\t\t\tcleanUpQuery = false; // job finished successfully\n+\t\t} catch (CancellationException e) {\n+\t\t\tterminal.writer().println(\"Query terminated, received a total of \" + receivedRowCount.get() + \" rows\");\n+\t\t\tterminal.flush();\n+\t\t} catch (ExecutionException e) {\n+\t\t\tif (e.getCause() instanceof SqlExecutionException) {\n+\t\t\t\tthrow (SqlExecutionException) e.getCause();\n+\t\t\t}\n+\t\t\tthrow new SqlExecutionException(\"unknown exception\", e.getCause());\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new SqlExecutionException(\"Query interrupted\", e);\n+\t\t} finally {\n+\t\t\tcheckAndCleanUpQuery();\n+\t\t}\n+\t}\n+\n+\tpublic void displayBatchResults() throws SqlExecutionException {\n+\t\tFuture<?> resultFuture = displayResultExecutorService.submit(() -> {\n+\t\t\tfinal List<Row> resultRows = waitBatchResults();\n+\t\t\tprintBatchResults(resultRows);\n+\t\t});\n+\n+\t\t// capture CTRL-C\n+\t\tterminal.handle(Terminal.Signal.INT, signal -> {\n+\t\t\tresultFuture.cancel(true);\n+\t\t});\n+\n+\t\tcleanUpQuery = true;\n+\t\ttry {\n+\t\t\tresultFuture.get();\n+\t\t\tcleanUpQuery = false; // job finished successfully\n+\t\t} catch (CancellationException e) {\n+\t\t\tterminal.writer().println(\"Query terminated\");\n+\t\t\tterminal.flush();\n+\t\t} catch (ExecutionException e) {\n+\t\t\tif (e.getCause() instanceof SqlExecutionException) {\n+\t\t\t\tthrow (SqlExecutionException) e.getCause();\n+\t\t\t}\n+\t\t\tthrow new SqlExecutionException(\"unknown exception\", e.getCause());\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new SqlExecutionException(\"Query interrupted\", e);\n+\t\t} finally {\n+\t\t\tcheckAndCleanUpQuery();\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tthis.displayResultExecutorService.shutdown();\n+\t}\n+\n+\tprivate void checkAndCleanUpQuery() {\n+\t\tif (cleanUpQuery) {\n+\t\t\ttry {\n+\t\t\t\tsqlExecutor.cancelQuery(sessionId, resultDescriptor.getResultId());\n+\t\t\t} catch (SqlExecutionException e) {\n+\t\t\t\t// ignore further exceptions\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate List<Row> waitBatchResults() {\n+\t\tList<Row> resultRows;\n+\t\t// take snapshot and make all results in one page\n+\t\tdo {\n+\t\t\ttry {\n+\t\t\t\tThread.sleep(50);\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t}\n+\t\t\tTypedResult<Integer> result = sqlExecutor.snapshotResult(\n+\t\t\t\t\tsessionId,\n+\t\t\t\t\tresultDescriptor.getResultId(),\n+\t\t\t\t\tInteger.MAX_VALUE);\n+\n+\t\t\tif (result.getType() == TypedResult.ResultType.EOS) {\n+\t\t\t\tresultRows = Collections.emptyList();\n+\t\t\t\tbreak;\n+\t\t\t} else if (result.getType() == TypedResult.ResultType.PAYLOAD) {\n+\t\t\t\tresultRows = sqlExecutor.retrieveResultPage(resultDescriptor.getResultId(), 1);\n+\t\t\t\tbreak;\n+\t\t\t} else {\n+\t\t\t\t// result not retrieved yet\n+\t\t\t}\n+\t\t} while (true);\n+\n+\t\treturn resultRows;\n+\t}\n+\n+\tprivate void printStreamResults(AtomicInteger receivedRowCount) {\n+\t\tList<TableColumn> columns = resultDescriptor.getResultSchema().getTableColumns();\n+\t\tString[] fieldNames =\n+\t\t\t\tStream.concat(\n+\t\t\t\t\t\tStream.of(\"+/-\"),\n+\t\t\t\t\t\tcolumns.stream().map(TableColumn::getName)\n+\t\t\t\t).toArray(String[]::new);\n+\n+\t\tint[] colWidths = columnWidthsByType(columns, true);\n+\t\tString borderline = genBorderLine(colWidths);\n+\n+\t\t// print filed names\n+\t\tterminal.writer().println(borderline);\n+\t\tprintSingleRow(colWidths, fieldNames);\n+\t\tterminal.writer().println(borderline);\n+\t\tterminal.flush();\n+\n+\t\twhile (true) {\n+\t\t\tfinal TypedResult<List<Tuple2<Boolean, Row>>> result =\n+\t\t\t\t\tsqlExecutor.retrieveResultChanges(sessionId, resultDescriptor.getResultId());\n+\n+\t\t\tswitch (result.getType()) {\n+\t\t\t\tcase EMPTY:\n+\t\t\t\t\t// do nothing\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase EOS:\n+\t\t\t\t\tif (receivedRowCount.get() > 0) {\n+\t\t\t\t\t\tterminal.writer().println(borderline);\n+\t\t\t\t\t}\n+\t\t\t\t\tterminal.writer().println(\"Received a total of \" + receivedRowCount.get() + \" rows\");\n+\t\t\t\t\tterminal.flush();\n+\t\t\t\t\treturn;\n+\t\t\t\tdefault:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "87fcf8d5a1309a85519e0a09df0191acd515c15d"}, "originalPosition": 221}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY3MDE0MDM0", "url": "https://github.com/apache/flink/pull/11273#pullrequestreview-367014034", "createdAt": "2020-03-02T08:24:16Z", "commit": {"oid": "87fcf8d5a1309a85519e0a09df0191acd515c15d"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wMlQwODoyNDoxNlrOFwWwsg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wMlQwODoyODo1NlrOFwW4KA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjI0ODg4Mg==", "bodyText": "incrementAndGet?", "url": "https://github.com/apache/flink/pull/11273#discussion_r386248882", "createdAt": "2020-03-02T08:24:16Z", "author": {"login": "JingsongLi"}, "path": "flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/cli/CliTableauResultView.java", "diffHunk": "@@ -0,0 +1,378 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.client.cli;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.api.TableColumn;\n+import org.apache.flink.table.client.gateway.Executor;\n+import org.apache.flink.table.client.gateway.ResultDescriptor;\n+import org.apache.flink.table.client.gateway.SqlExecutionException;\n+import org.apache.flink.table.client.gateway.TypedResult;\n+import org.apache.flink.table.types.logical.BigIntType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.IntType;\n+import org.apache.flink.table.types.logical.LocalZonedTimestampType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.SmallIntType;\n+import org.apache.flink.table.types.logical.TimeType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+import org.apache.flink.table.types.logical.TinyIntType;\n+import org.apache.flink.types.Row;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.jline.terminal.Terminal;\n+\n+import java.io.Closeable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Stream;\n+\n+import static org.apache.flink.table.client.cli.CliUtils.rowToString;\n+\n+/**\n+ * Print result in tableau mode.\n+ */\n+public class CliTableauResultView implements Closeable {\n+\n+\tprivate static final int NULL_COLUMN_WIDTH = CliStrings.NULL_COLUMN.length();\n+\tprivate static final int MAX_COLUMN_WIDTH = 30;\n+\tprivate static final int DEFAULT_COLUMN_WIDTH = 20;\n+\tprivate static final String COLUMN_TRUNCATED_FLAG = \"...\";\n+\tprivate static final String CHANGEFLAG_COLUMN_NAME = \"+/-\";\n+\n+\tprivate final Terminal terminal;\n+\tprivate final Executor sqlExecutor;\n+\tprivate final String sessionId;\n+\tprivate final ResultDescriptor resultDescriptor;\n+\tprivate final ExecutorService displayResultExecutorService;\n+\n+\tprivate volatile boolean cleanUpQuery;\n+\n+\tpublic CliTableauResultView(\n+\t\t\tfinal Terminal terminal,\n+\t\t\tfinal Executor sqlExecutor,\n+\t\t\tfinal String sessionId,\n+\t\t\tfinal ResultDescriptor resultDescriptor) {\n+\t\tthis.terminal = terminal;\n+\t\tthis.sqlExecutor = sqlExecutor;\n+\t\tthis.sessionId = sessionId;\n+\t\tthis.resultDescriptor = resultDescriptor;\n+\t\tthis.displayResultExecutorService = Executors.newSingleThreadExecutor();\n+\t}\n+\n+\tpublic void displayStreamResults() throws SqlExecutionException {\n+\t\tfinal AtomicInteger receivedRowCount = new AtomicInteger(0);\n+\t\tFuture<?> resultFuture = displayResultExecutorService.submit(() -> {\n+\t\t\tprintStreamResults(receivedRowCount);\n+\t\t});\n+\n+\t\t// capture CTRL-C\n+\t\tterminal.handle(Terminal.Signal.INT, signal -> {\n+\t\t\tresultFuture.cancel(true);\n+\t\t});\n+\n+\t\tcleanUpQuery = true;\n+\t\ttry {\n+\t\t\tresultFuture.get();\n+\t\t\tcleanUpQuery = false; // job finished successfully\n+\t\t} catch (CancellationException e) {\n+\t\t\tterminal.writer().println(\"Query terminated, received a total of \" + receivedRowCount.get() + \" rows\");\n+\t\t\tterminal.flush();\n+\t\t} catch (ExecutionException e) {\n+\t\t\tif (e.getCause() instanceof SqlExecutionException) {\n+\t\t\t\tthrow (SqlExecutionException) e.getCause();\n+\t\t\t}\n+\t\t\tthrow new SqlExecutionException(\"unknown exception\", e.getCause());\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new SqlExecutionException(\"Query interrupted\", e);\n+\t\t} finally {\n+\t\t\tcheckAndCleanUpQuery();\n+\t\t}\n+\t}\n+\n+\tpublic void displayBatchResults() throws SqlExecutionException {\n+\t\tFuture<?> resultFuture = displayResultExecutorService.submit(() -> {\n+\t\t\tfinal List<Row> resultRows = waitBatchResults();\n+\t\t\tprintBatchResults(resultRows);\n+\t\t});\n+\n+\t\t// capture CTRL-C\n+\t\tterminal.handle(Terminal.Signal.INT, signal -> {\n+\t\t\tresultFuture.cancel(true);\n+\t\t});\n+\n+\t\tcleanUpQuery = true;\n+\t\ttry {\n+\t\t\tresultFuture.get();\n+\t\t\tcleanUpQuery = false; // job finished successfully\n+\t\t} catch (CancellationException e) {\n+\t\t\tterminal.writer().println(\"Query terminated\");\n+\t\t\tterminal.flush();\n+\t\t} catch (ExecutionException e) {\n+\t\t\tif (e.getCause() instanceof SqlExecutionException) {\n+\t\t\t\tthrow (SqlExecutionException) e.getCause();\n+\t\t\t}\n+\t\t\tthrow new SqlExecutionException(\"unknown exception\", e.getCause());\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new SqlExecutionException(\"Query interrupted\", e);\n+\t\t} finally {\n+\t\t\tcheckAndCleanUpQuery();\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tthis.displayResultExecutorService.shutdown();\n+\t}\n+\n+\tprivate void checkAndCleanUpQuery() {\n+\t\tif (cleanUpQuery) {\n+\t\t\ttry {\n+\t\t\t\tsqlExecutor.cancelQuery(sessionId, resultDescriptor.getResultId());\n+\t\t\t} catch (SqlExecutionException e) {\n+\t\t\t\t// ignore further exceptions\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate List<Row> waitBatchResults() {\n+\t\tList<Row> resultRows;\n+\t\t// take snapshot and make all results in one page\n+\t\tdo {\n+\t\t\ttry {\n+\t\t\t\tThread.sleep(50);\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t}\n+\t\t\tTypedResult<Integer> result = sqlExecutor.snapshotResult(\n+\t\t\t\t\tsessionId,\n+\t\t\t\t\tresultDescriptor.getResultId(),\n+\t\t\t\t\tInteger.MAX_VALUE);\n+\n+\t\t\tif (result.getType() == TypedResult.ResultType.EOS) {\n+\t\t\t\tresultRows = Collections.emptyList();\n+\t\t\t\tbreak;\n+\t\t\t} else if (result.getType() == TypedResult.ResultType.PAYLOAD) {\n+\t\t\t\tresultRows = sqlExecutor.retrieveResultPage(resultDescriptor.getResultId(), 1);\n+\t\t\t\tbreak;\n+\t\t\t} else {\n+\t\t\t\t// result not retrieved yet\n+\t\t\t}\n+\t\t} while (true);\n+\n+\t\treturn resultRows;\n+\t}\n+\n+\tprivate void printStreamResults(AtomicInteger receivedRowCount) {\n+\t\tList<TableColumn> columns = resultDescriptor.getResultSchema().getTableColumns();\n+\t\tString[] fieldNames =\n+\t\t\t\tStream.concat(\n+\t\t\t\t\t\tStream.of(\"+/-\"),\n+\t\t\t\t\t\tcolumns.stream().map(TableColumn::getName)\n+\t\t\t\t).toArray(String[]::new);\n+\n+\t\tint[] colWidths = columnWidthsByType(columns, true);\n+\t\tString borderline = genBorderLine(colWidths);\n+\n+\t\t// print filed names\n+\t\tterminal.writer().println(borderline);\n+\t\tprintSingleRow(colWidths, fieldNames);\n+\t\tterminal.writer().println(borderline);\n+\t\tterminal.flush();\n+\n+\t\twhile (true) {\n+\t\t\tfinal TypedResult<List<Tuple2<Boolean, Row>>> result =\n+\t\t\t\t\tsqlExecutor.retrieveResultChanges(sessionId, resultDescriptor.getResultId());\n+\n+\t\t\tswitch (result.getType()) {\n+\t\t\t\tcase EMPTY:\n+\t\t\t\t\t// do nothing\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase EOS:\n+\t\t\t\t\tif (receivedRowCount.get() > 0) {\n+\t\t\t\t\t\tterminal.writer().println(borderline);\n+\t\t\t\t\t}\n+\t\t\t\t\tterminal.writer().println(\"Received a total of \" + receivedRowCount.get() + \" rows\");\n+\t\t\t\t\tterminal.flush();\n+\t\t\t\t\treturn;\n+\t\t\t\tdefault:\n+\t\t\t\t\tList<Tuple2<Boolean, Row>> changes = result.getPayload();\n+\t\t\t\t\tfor (Tuple2<Boolean, Row> change : changes) {\n+\t\t\t\t\t\tfinal String[] cols = rowToString(change.f1);\n+\t\t\t\t\t\tString[] row = new String[cols.length + 1];\n+\t\t\t\t\t\trow[0] = change.f0 ? \"+\" : \"-\";\n+\t\t\t\t\t\tSystem.arraycopy(cols, 0, row, 1, cols.length);\n+\t\t\t\t\t\tprintSingleRow(colWidths, row);\n+\t\t\t\t\t\treceivedRowCount.addAndGet(1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "87fcf8d5a1309a85519e0a09df0191acd515c15d"}, "originalPosition": 229}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjI1MDc5Mg==", "bodyText": "Why we need a displayResultExecutorService?", "url": "https://github.com/apache/flink/pull/11273#discussion_r386250792", "createdAt": "2020-03-02T08:28:56Z", "author": {"login": "JingsongLi"}, "path": "flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/cli/CliTableauResultView.java", "diffHunk": "@@ -0,0 +1,378 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.client.cli;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.api.TableColumn;\n+import org.apache.flink.table.client.gateway.Executor;\n+import org.apache.flink.table.client.gateway.ResultDescriptor;\n+import org.apache.flink.table.client.gateway.SqlExecutionException;\n+import org.apache.flink.table.client.gateway.TypedResult;\n+import org.apache.flink.table.types.logical.BigIntType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.IntType;\n+import org.apache.flink.table.types.logical.LocalZonedTimestampType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.SmallIntType;\n+import org.apache.flink.table.types.logical.TimeType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+import org.apache.flink.table.types.logical.TinyIntType;\n+import org.apache.flink.types.Row;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.jline.terminal.Terminal;\n+\n+import java.io.Closeable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Stream;\n+\n+import static org.apache.flink.table.client.cli.CliUtils.rowToString;\n+\n+/**\n+ * Print result in tableau mode.\n+ */\n+public class CliTableauResultView implements Closeable {\n+\n+\tprivate static final int NULL_COLUMN_WIDTH = CliStrings.NULL_COLUMN.length();\n+\tprivate static final int MAX_COLUMN_WIDTH = 30;\n+\tprivate static final int DEFAULT_COLUMN_WIDTH = 20;\n+\tprivate static final String COLUMN_TRUNCATED_FLAG = \"...\";\n+\tprivate static final String CHANGEFLAG_COLUMN_NAME = \"+/-\";\n+\n+\tprivate final Terminal terminal;\n+\tprivate final Executor sqlExecutor;\n+\tprivate final String sessionId;\n+\tprivate final ResultDescriptor resultDescriptor;\n+\tprivate final ExecutorService displayResultExecutorService;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "87fcf8d5a1309a85519e0a09df0191acd515c15d"}, "originalPosition": 70}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY3NzEyMDU2", "url": "https://github.com/apache/flink/pull/11273#pullrequestreview-367712056", "createdAt": "2020-03-03T05:33:07Z", "commit": {"oid": "0499cecb07f7f274ad68f4988d2e424898e44bad"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "242efcdc3170341c5f8ccef5b29f3317cead3fa3", "author": {"user": {"login": "KurtYoung", "name": "Kurt Young"}}, "url": "https://github.com/apache/flink/commit/242efcdc3170341c5f8ccef5b29f3317cead3fa3", "committedDate": "2020-03-03T06:35:15Z", "message": "[FLINK-12814][sql-client] Support a traditional and scrolling view of result (tableau format)\n\nThis closes #11273"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0499cecb07f7f274ad68f4988d2e424898e44bad", "author": {"user": {"login": "KurtYoung", "name": "Kurt Young"}}, "url": "https://github.com/apache/flink/commit/0499cecb07f7f274ad68f4988d2e424898e44bad", "committedDate": "2020-03-02T13:49:19Z", "message": "fix check style"}, "afterCommit": {"oid": "242efcdc3170341c5f8ccef5b29f3317cead3fa3", "author": {"user": {"login": "KurtYoung", "name": "Kurt Young"}}, "url": "https://github.com/apache/flink/commit/242efcdc3170341c5f8ccef5b29f3317cead3fa3", "committedDate": "2020-03-03T06:35:15Z", "message": "[FLINK-12814][sql-client] Support a traditional and scrolling view of result (tableau format)\n\nThis closes #11273"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2937, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}