{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDI2NTM5MzM0", "number": 12439, "title": "[FLINK-17776][hive][doc] Add documentation for DDL&DML in hive dialect", "bodyText": "What is the purpose of the change\nAdd doc for Hive dialect.\nBrief change log\n\nAdd a new page for Hive dialect\n\nVerifying this change\nManually built the page and everything looks fine.\nDoes this pull request potentially affect one of the following parts:\nNA\nDocumentation\nNA", "createdAt": "2020-06-02T12:01:47Z", "url": "https://github.com/apache/flink/pull/12439", "merged": true, "mergeCommit": {"oid": "0b7c23eb5b2ce47fc6c10fbd022d428872a521ae"}, "closed": true, "closedAt": "2020-06-08T08:21:23Z", "author": {"login": "lirui-apache"}, "timelineItems": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcoNEtpAFqTQyNTAzNTE3OQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcpMEzWgFqTQyNjAwODEyOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1MDM1MTc5", "url": "https://github.com/apache/flink/pull/12439#pullrequestreview-425035179", "createdAt": "2020-06-05T06:47:03Z", "commit": {"oid": "723262421f8fbf9a4b86639ef8be6d6651f26bba"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQwNjo0NzowNFrOGfiTVg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQwNjo1NjoyM1rOGfiguw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTcyMTA0Ng==", "bodyText": "You have to choose to use Hive -> You need to switch to Hive dialect", "url": "https://github.com/apache/flink/pull/12439#discussion_r435721046", "createdAt": "2020-06-05T06:47:04Z", "author": {"login": "danny0405"}, "path": "docs/dev/table/hive/hive_dialect.md", "diffHunk": "@@ -0,0 +1,347 @@\n+---\n+title: \"Hive Dialect\"\n+nav-parent_id: hive_tableapi\n+nav-pos: 1\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+Starting from 1.11.0, Flink allows users to write SQL statements in Hive syntax when Hive dialect\n+is used. By providing compatibility with Hive syntax, we aim to improve the interoperability with\n+Hive and reduce the scenarios when users need to switch between Flink and Hive in order to execute\n+different statements.\n+\n+* This will be replaced by the TOC\n+{:toc}\n+\n+## Use Hive Dialect\n+\n+Flink currently supports two SQL dialects: `default` and `hive`. You have to choose to use Hive\n+dialect before you can write in Hive syntax. The following describes how to set dialect with\n+SQL Client and Table API. Please also be noted that you can dynamically switch dialect for each", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "723262421f8fbf9a4b86639ef8be6d6651f26bba"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTcyMTIyNg==", "bodyText": "Please also be noted that -> Also notice that", "url": "https://github.com/apache/flink/pull/12439#discussion_r435721226", "createdAt": "2020-06-05T06:47:35Z", "author": {"login": "danny0405"}, "path": "docs/dev/table/hive/hive_dialect.md", "diffHunk": "@@ -0,0 +1,347 @@\n+---\n+title: \"Hive Dialect\"\n+nav-parent_id: hive_tableapi\n+nav-pos: 1\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+Starting from 1.11.0, Flink allows users to write SQL statements in Hive syntax when Hive dialect\n+is used. By providing compatibility with Hive syntax, we aim to improve the interoperability with\n+Hive and reduce the scenarios when users need to switch between Flink and Hive in order to execute\n+different statements.\n+\n+* This will be replaced by the TOC\n+{:toc}\n+\n+## Use Hive Dialect\n+\n+Flink currently supports two SQL dialects: `default` and `hive`. You have to choose to use Hive\n+dialect before you can write in Hive syntax. The following describes how to set dialect with\n+SQL Client and Table API. Please also be noted that you can dynamically switch dialect for each", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTcyMTA0Ng=="}, "originalCommit": {"oid": "723262421f8fbf9a4b86639ef8be6d6651f26bba"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTcyMzA1Nw==", "bodyText": "You can set dialect for you TableEnvironment with Table API.", "url": "https://github.com/apache/flink/pull/12439#discussion_r435723057", "createdAt": "2020-06-05T06:52:39Z", "author": {"login": "danny0405"}, "path": "docs/dev/table/hive/hive_dialect.md", "diffHunk": "@@ -0,0 +1,347 @@\n+---\n+title: \"Hive Dialect\"\n+nav-parent_id: hive_tableapi\n+nav-pos: 1\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+Starting from 1.11.0, Flink allows users to write SQL statements in Hive syntax when Hive dialect\n+is used. By providing compatibility with Hive syntax, we aim to improve the interoperability with\n+Hive and reduce the scenarios when users need to switch between Flink and Hive in order to execute\n+different statements.\n+\n+* This will be replaced by the TOC\n+{:toc}\n+\n+## Use Hive Dialect\n+\n+Flink currently supports two SQL dialects: `default` and `hive`. You have to choose to use Hive\n+dialect before you can write in Hive syntax. The following describes how to set dialect with\n+SQL Client and Table API. Please also be noted that you can dynamically switch dialect for each\n+statement you execute. There's no need to restart a session to use a different dialect.\n+\n+### SQL Client\n+\n+SQL dialect can be specified via the `table.sql-dialect` property. Therefore you can set the initial dialect to use in\n+the `configuration` section of the yaml file for your SQL Client.\n+\n+{% highlight yaml %}\n+\n+execution:\n+  planner: blink\n+  type: batch\n+  result-mode: table\n+\n+configuration:\n+  table.sql-dialect: hive\n+  \n+{% endhighlight %}\n+\n+You can also set the dialect after the SQL Client has launched.\n+\n+{% highlight bash %}\n+\n+Flink SQL> set table.sql-dialect=hive; -- to use hive dialect\n+[INFO] Session property has been set.\n+\n+Flink SQL> set table.sql-dialect=default; -- to use default dialect\n+[INFO] Session property has been set.\n+\n+{% endhighlight %}\n+\n+### Table API\n+\n+With Table API, you can set dialect for you TableEnvironment.\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "723262421f8fbf9a4b86639ef8be6d6651f26bba"}, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTcyNDQ3NQ==", "bodyText": "The following are some precautions for using using the Hive dialect.", "url": "https://github.com/apache/flink/pull/12439#discussion_r435724475", "createdAt": "2020-06-05T06:56:23Z", "author": {"login": "danny0405"}, "path": "docs/dev/table/hive/hive_dialect.md", "diffHunk": "@@ -0,0 +1,347 @@\n+---\n+title: \"Hive Dialect\"\n+nav-parent_id: hive_tableapi\n+nav-pos: 1\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+Starting from 1.11.0, Flink allows users to write SQL statements in Hive syntax when Hive dialect\n+is used. By providing compatibility with Hive syntax, we aim to improve the interoperability with\n+Hive and reduce the scenarios when users need to switch between Flink and Hive in order to execute\n+different statements.\n+\n+* This will be replaced by the TOC\n+{:toc}\n+\n+## Use Hive Dialect\n+\n+Flink currently supports two SQL dialects: `default` and `hive`. You have to choose to use Hive\n+dialect before you can write in Hive syntax. The following describes how to set dialect with\n+SQL Client and Table API. Please also be noted that you can dynamically switch dialect for each\n+statement you execute. There's no need to restart a session to use a different dialect.\n+\n+### SQL Client\n+\n+SQL dialect can be specified via the `table.sql-dialect` property. Therefore you can set the initial dialect to use in\n+the `configuration` section of the yaml file for your SQL Client.\n+\n+{% highlight yaml %}\n+\n+execution:\n+  planner: blink\n+  type: batch\n+  result-mode: table\n+\n+configuration:\n+  table.sql-dialect: hive\n+  \n+{% endhighlight %}\n+\n+You can also set the dialect after the SQL Client has launched.\n+\n+{% highlight bash %}\n+\n+Flink SQL> set table.sql-dialect=hive; -- to use hive dialect\n+[INFO] Session property has been set.\n+\n+Flink SQL> set table.sql-dialect=default; -- to use default dialect\n+[INFO] Session property has been set.\n+\n+{% endhighlight %}\n+\n+### Table API\n+\n+With Table API, you can set dialect for you TableEnvironment.\n+\n+{% highlight java %}\n+\n+EnvironmentSettings settings = EnvironmentSettings.newInstance().useBlinkPlanner()...build();\n+TableEnvironment tableEnv = TableEnvironment.create(settings);\n+// to use hive dialect\n+tableEnv.getConfig().setSqlDialect(SqlDialect.HIVE);\n+// to use default dialect\n+tableEnv.getConfig().setSqlDialect(SqlDialect.DEFAULT);\n+\n+{% endhighlight %}\n+\n+## DDL\n+\n+This section lists the supported DDLs with the Hive dialect. We'll mainly focus on the syntax\n+here. You can refer to [Hive doc](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL)\n+for the semantics of each DDL statement.\n+\n+### DATABASE\n+\n+#### Show\n+\n+{% highlight sql %}\n+SHOW DATABASES;\n+{% endhighlight %}\n+\n+#### Create\n+\n+{% highlight sql %}\n+CREATE (DATABASE|SCHEMA) [IF NOT EXISTS] database_name\n+  [COMMENT database_comment]\n+  [LOCATION fs_path]\n+  [WITH DBPROPERTIES (property_name=property_value, ...)];\n+{% endhighlight %}\n+\n+#### Alter\n+\n+##### Update Properties\n+\n+{% highlight sql %}\n+ALTER (DATABASE|SCHEMA) database_name SET DBPROPERTIES (property_name=property_value, ...);\n+{% endhighlight %}\n+\n+##### Update Owner\n+\n+{% highlight sql %}\n+ALTER (DATABASE|SCHEMA) database_name SET OWNER [USER|ROLE] user_or_role;\n+{% endhighlight %}\n+\n+##### Update Location\n+\n+{% highlight sql %}\n+ALTER (DATABASE|SCHEMA) database_name SET LOCATION fs_path;\n+{% endhighlight %}\n+\n+#### Drop\n+\n+{% highlight sql %}\n+DROP (DATABASE|SCHEMA) [IF EXISTS] database_name [RESTRICT|CASCADE];\n+{% endhighlight %}\n+\n+#### Use\n+\n+{% highlight sql %}\n+USE database_name;\n+{% endhighlight %}\n+\n+### TABLE\n+\n+#### Show\n+\n+{% highlight sql %}\n+SHOW TABLES;\n+{% endhighlight %}\n+\n+#### Create\n+\n+{% highlight sql %}\n+CREATE [EXTERNAL] TABLE [IF NOT EXISTS] table_name\n+  [(col_name data_type [column_constraint] [COMMENT col_comment], ... [table_constraint])]\n+  [COMMENT table_comment]\n+  [PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)]\n+  [\n+    [ROW FORMAT row_format]\n+    [STORED AS file_format]\n+  ]\n+  [LOCATION fs_path]\n+  [TBLPROPERTIES (property_name=property_value, ...)]\n+  \n+row_format:\n+  : DELIMITED [FIELDS TERMINATED BY char [ESCAPED BY char]] [COLLECTION ITEMS TERMINATED BY char]\n+      [MAP KEYS TERMINATED BY char] [LINES TERMINATED BY char]\n+      [NULL DEFINED AS char]\n+  | SERDE serde_name [WITH SERDEPROPERTIES (property_name=property_value, ...)]\n+  \n+file_format:\n+  : SEQUENCEFILE\n+  | TEXTFILE\n+  | RCFILE\n+  | ORC\n+  | PARQUET\n+  | AVRO\n+  | INPUTFORMAT input_format_classname OUTPUTFORMAT output_format_classname\n+  \n+column_constraint:\n+  : NOT NULL [[ENABLE|DISABLE] [VALIDATE|NOVALIDATE] [RELY|NORELY]]\n+  \n+table_constraint:\n+  : [CONSTRAINT constraint_name] PRIMARY KEY (col_name, ...) [[ENABLE|DISABLE] [VALIDATE|NOVALIDATE] [RELY|NORELY]]\n+{% endhighlight %}\n+\n+#### Alter\n+\n+##### Rename\n+\n+{% highlight sql %}\n+ALTER TABLE table_name RENAME TO new_table_name;\n+{% endhighlight %}\n+\n+##### Update Properties\n+\n+{% highlight sql %}\n+ALTER TABLE table_name SET TBLPROPERTIES (property_name = property_value, property_name = property_value, ... );\n+{% endhighlight %}\n+\n+##### Update Location\n+\n+{% highlight sql %}\n+ALTER TABLE table_name [PARTITION partition_spec] SET LOCATION fs_path;\n+{% endhighlight %}\n+\n+The `partition_spec`, if present, needs to be a full spec, i.e. has values for all partition columns. And when it's\n+present, the operation will be applied to the corresponding partition instead of the table.\n+\n+##### Update File Format\n+\n+{% highlight sql %}\n+ALTER TABLE table_name [PARTITION partition_spec] SET FILEFORMAT file_format;\n+{% endhighlight %}\n+\n+The `partition_spec`, if present, needs to be a full spec, i.e. has values for all partition columns. And when it's\n+present, the operation will be applied to the corresponding partition instead of the table.\n+\n+##### Update SerDe Properties\n+\n+{% highlight sql %}\n+ALTER TABLE table_name [PARTITION partition_spec] SET SERDE serde_class_name [WITH SERDEPROPERTIES serde_properties];\n+ \n+ALTER TABLE table_name [PARTITION partition_spec] SET SERDEPROPERTIES serde_properties;\n+ \n+serde_properties:\n+  : (property_name = property_value, property_name = property_value, ... )\n+{% endhighlight %}\n+\n+The `partition_spec`, if present, needs to be a full spec, i.e. has values for all partition columns. And when it's\n+present, the operation will be applied to the corresponding partition instead of the table.\n+\n+##### Add Partitions\n+\n+{% highlight sql %}\n+ALTER TABLE table_name ADD [IF NOT EXISTS] (PARTITION partition_spec [LOCATION fs_path])+;\n+{% endhighlight %}\n+\n+##### Drop Partitions\n+\n+{% highlight sql %}\n+ALTER TABLE table_name DROP [IF EXISTS] PARTITION partition_spec[, PARTITION partition_spec, ...];\n+{% endhighlight %}\n+\n+##### Add/Replace Columns\n+\n+{% highlight sql %}\n+ALTER TABLE table_name\n+  ADD|REPLACE COLUMNS (col_name data_type [COMMENT col_comment], ...)\n+  [CASCADE|RESTRICT]\n+{% endhighlight %}\n+\n+##### Change Column\n+\n+{% highlight sql %}\n+ALTER TABLE table_name CHANGE [COLUMN] col_old_name col_new_name column_type\n+  [COMMENT col_comment] [FIRST|AFTER column_name] [CASCADE|RESTRICT];\n+{% endhighlight %}\n+\n+#### Drop\n+\n+{% highlight sql %}\n+DROP TABLE [IF EXISTS] table_name;\n+{% endhighlight %}\n+\n+### VIEW\n+\n+#### Create\n+\n+{% highlight sql %}\n+CREATE VIEW [IF NOT EXISTS] view_name [(column_name, ...) ]\n+  [COMMENT view_comment]\n+  [TBLPROPERTIES (property_name = property_value, ...)]\n+  AS SELECT ...;\n+{% endhighlight %}\n+\n+#### Alter\n+\n+##### Rename\n+\n+{% highlight sql %}\n+ALTER VIEW view_name RENAME TO new_view_name;\n+{% endhighlight %}\n+\n+##### Update Properties\n+\n+{% highlight sql %}\n+ALTER VIEW view_name SET TBLPROPERTIES (property_name = property_value, ... );\n+{% endhighlight %}\n+\n+##### Update As Select\n+\n+{% highlight sql %}\n+ALTER VIEW view_name AS select_statement;\n+{% endhighlight %}\n+\n+#### Drop\n+\n+{% highlight sql %}\n+DROP VIEW [IF EXISTS] view_name;\n+{% endhighlight %}\n+\n+### FUNCTION\n+\n+#### Show\n+\n+{% highlight sql %}\n+SHOW FUNCTIONS;\n+{% endhighlight %}\n+\n+#### Create\n+\n+{% highlight sql %}\n+CREATE FUNCTION function_name AS class_name;\n+{% endhighlight %}\n+\n+#### Drop\n+\n+{% highlight sql %}\n+DROP FUNCTION [IF EXISTS] function_name;\n+{% endhighlight %}\n+\n+## DML\n+\n+### INSERT\n+\n+{% highlight sql %}\n+INSERT (INTO|OVERWRITE) [TABLE] table_name [PARTITION partition_spec] SELECT ...;\n+{% endhighlight %}\n+\n+The `partition_spec`, if present, can be either a full spec or partial spec. If the `partition_spec` is a partial\n+spec, the dynamic partition column names can be omitted.\n+\n+## DQL\n+\n+At the moment, Hive dialect supports the same syntax as Flink SQL for DQLs. Refer to\n+[Flink SQL queries]({{ site.baseurl }}/dev/table/sql/queries.html) for more details. And it's recommended to switch to\n+`default` dialect to execute DQLs.\n+\n+## Notice\n+\n+Some things to notice when using the Hive dialect.\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "723262421f8fbf9a4b86639ef8be6d6651f26bba"}, "originalPosition": 339}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1MDgxOTM3", "url": "https://github.com/apache/flink/pull/12439#pullrequestreview-425081937", "createdAt": "2020-06-05T08:03:41Z", "commit": {"oid": "d7de89b8333fd9e073f6a329e2ba641a2d71f26e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQwODowMzo0MVrOGfkbNA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQwODowMzo0MVrOGfkbNA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTc1NTgyOA==", "bodyText": "Can we also give an example for Hive create table ? The syntax template is too complex to understand.", "url": "https://github.com/apache/flink/pull/12439#discussion_r435755828", "createdAt": "2020-06-05T08:03:41Z", "author": {"login": "danny0405"}, "path": "docs/dev/table/hive/hive_dialect.md", "diffHunk": "@@ -0,0 +1,347 @@\n+---\n+title: \"Hive Dialect\"\n+nav-parent_id: hive_tableapi\n+nav-pos: 1\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+Starting from 1.11.0, Flink allows users to write SQL statements in Hive syntax when Hive dialect\n+is used. By providing compatibility with Hive syntax, we aim to improve the interoperability with\n+Hive and reduce the scenarios when users need to switch between Flink and Hive in order to execute\n+different statements.\n+\n+* This will be replaced by the TOC\n+{:toc}\n+\n+## Use Hive Dialect\n+\n+Flink currently supports two SQL dialects: `default` and `hive`. You need to switch to Hive dialect\n+before you can write in Hive syntax. The following describes how to set dialect with\n+SQL Client and Table API. Also notice that you can dynamically switch dialect for each\n+statement you execute. There's no need to restart a session to use a different dialect.\n+\n+### SQL Client\n+\n+SQL dialect can be specified via the `table.sql-dialect` property. Therefore you can set the initial dialect to use in\n+the `configuration` section of the yaml file for your SQL Client.\n+\n+{% highlight yaml %}\n+\n+execution:\n+  planner: blink\n+  type: batch\n+  result-mode: table\n+\n+configuration:\n+  table.sql-dialect: hive\n+  \n+{% endhighlight %}\n+\n+You can also set the dialect after the SQL Client has launched.\n+\n+{% highlight bash %}\n+\n+Flink SQL> set table.sql-dialect=hive; -- to use hive dialect\n+[INFO] Session property has been set.\n+\n+Flink SQL> set table.sql-dialect=default; -- to use default dialect\n+[INFO] Session property has been set.\n+\n+{% endhighlight %}\n+\n+### Table API\n+\n+You can set dialect for your TableEnvironment with Table API.\n+\n+{% highlight java %}\n+\n+EnvironmentSettings settings = EnvironmentSettings.newInstance().useBlinkPlanner()...build();\n+TableEnvironment tableEnv = TableEnvironment.create(settings);\n+// to use hive dialect\n+tableEnv.getConfig().setSqlDialect(SqlDialect.HIVE);\n+// to use default dialect\n+tableEnv.getConfig().setSqlDialect(SqlDialect.DEFAULT);\n+\n+{% endhighlight %}\n+\n+## DDL\n+\n+This section lists the supported DDLs with the Hive dialect. We'll mainly focus on the syntax\n+here. You can refer to [Hive doc](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL)\n+for the semantics of each DDL statement.\n+\n+### DATABASE\n+\n+#### Show\n+\n+{% highlight sql %}\n+SHOW DATABASES;\n+{% endhighlight %}\n+\n+#### Create\n+\n+{% highlight sql %}\n+CREATE (DATABASE|SCHEMA) [IF NOT EXISTS] database_name\n+  [COMMENT database_comment]\n+  [LOCATION fs_path]\n+  [WITH DBPROPERTIES (property_name=property_value, ...)];\n+{% endhighlight %}\n+\n+#### Alter\n+\n+##### Update Properties\n+\n+{% highlight sql %}\n+ALTER (DATABASE|SCHEMA) database_name SET DBPROPERTIES (property_name=property_value, ...);\n+{% endhighlight %}\n+\n+##### Update Owner\n+\n+{% highlight sql %}\n+ALTER (DATABASE|SCHEMA) database_name SET OWNER [USER|ROLE] user_or_role;\n+{% endhighlight %}\n+\n+##### Update Location\n+\n+{% highlight sql %}\n+ALTER (DATABASE|SCHEMA) database_name SET LOCATION fs_path;\n+{% endhighlight %}\n+\n+#### Drop\n+\n+{% highlight sql %}\n+DROP (DATABASE|SCHEMA) [IF EXISTS] database_name [RESTRICT|CASCADE];\n+{% endhighlight %}\n+\n+#### Use\n+\n+{% highlight sql %}\n+USE database_name;\n+{% endhighlight %}\n+\n+### TABLE\n+\n+#### Show\n+\n+{% highlight sql %}\n+SHOW TABLES;\n+{% endhighlight %}\n+\n+#### Create\n+\n+{% highlight sql %}\n+CREATE [EXTERNAL] TABLE [IF NOT EXISTS] table_name\n+  [(col_name data_type [column_constraint] [COMMENT col_comment], ... [table_constraint])]\n+  [COMMENT table_comment]\n+  [PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)]\n+  [\n+    [ROW FORMAT row_format]\n+    [STORED AS file_format]\n+  ]\n+  [LOCATION fs_path]\n+  [TBLPROPERTIES (property_name=property_value, ...)]\n+  \n+row_format:\n+  : DELIMITED [FIELDS TERMINATED BY char [ESCAPED BY char]] [COLLECTION ITEMS TERMINATED BY char]\n+      [MAP KEYS TERMINATED BY char] [LINES TERMINATED BY char]\n+      [NULL DEFINED AS char]\n+  | SERDE serde_name [WITH SERDEPROPERTIES (property_name=property_value, ...)]\n+  \n+file_format:\n+  : SEQUENCEFILE\n+  | TEXTFILE\n+  | RCFILE\n+  | ORC\n+  | PARQUET\n+  | AVRO\n+  | INPUTFORMAT input_format_classname OUTPUTFORMAT output_format_classname\n+  \n+column_constraint:\n+  : NOT NULL [[ENABLE|DISABLE] [VALIDATE|NOVALIDATE] [RELY|NORELY]]\n+  \n+table_constraint:\n+  : [CONSTRAINT constraint_name] PRIMARY KEY (col_name, ...) [[ENABLE|DISABLE] [VALIDATE|NOVALIDATE] [RELY|NORELY]]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d7de89b8333fd9e073f6a329e2ba641a2d71f26e"}, "originalPosition": 180}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1NzAwNTkw", "url": "https://github.com/apache/flink/pull/12439#pullrequestreview-425700590", "createdAt": "2020-06-06T01:16:13Z", "commit": {"oid": "d7de89b8333fd9e073f6a329e2ba641a2d71f26e"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1ODg3MzU2", "url": "https://github.com/apache/flink/pull/12439#pullrequestreview-425887356", "createdAt": "2020-06-08T02:41:37Z", "commit": {"oid": "d7de89b8333fd9e073f6a329e2ba641a2d71f26e"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "efba94b30447bf94addd8fedfdfebd62a3a94bcb", "author": {"user": {"login": "lirui-apache", "name": "Rui Li"}}, "url": "https://github.com/apache/flink/commit/efba94b30447bf94addd8fedfdfebd62a3a94bcb", "committedDate": "2020-06-08T04:55:57Z", "message": "[FLINK-17776][hive][doc] Add documentation for DDL&DML in hive dialect"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5668926fd44843ac0e86920ba69618a13b726039", "author": {"user": {"login": "lirui-apache", "name": "Rui Li"}}, "url": "https://github.com/apache/flink/commit/5668926fd44843ac0e86920ba69618a13b726039", "committedDate": "2020-06-08T04:55:57Z", "message": "update overview page"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "24c9e617346fa55fd31b963d98b324271a5fd1b1", "author": {"user": {"login": "lirui-apache", "name": "Rui Li"}}, "url": "https://github.com/apache/flink/commit/24c9e617346fa55fd31b963d98b324271a5fd1b1", "committedDate": "2020-06-08T04:55:57Z", "message": "address comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0c4484444c65a12851446dcdf99d962bd02fbd53", "author": {"user": {"login": "lirui-apache", "name": "Rui Li"}}, "url": "https://github.com/apache/flink/commit/0c4484444c65a12851446dcdf99d962bd02fbd53", "committedDate": "2020-06-08T04:55:58Z", "message": "fix typo"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "31b991e463168e16cc3400c1df3e06cb28a8a917", "author": {"user": {"login": "lirui-apache", "name": "Rui Li"}}, "url": "https://github.com/apache/flink/commit/31b991e463168e16cc3400c1df3e06cb28a8a917", "committedDate": "2020-06-08T05:14:58Z", "message": "add zh page"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d7de89b8333fd9e073f6a329e2ba641a2d71f26e", "author": {"user": {"login": "lirui-apache", "name": "Rui Li"}}, "url": "https://github.com/apache/flink/commit/d7de89b8333fd9e073f6a329e2ba641a2d71f26e", "committedDate": "2020-06-05T07:22:18Z", "message": "fix typo"}, "afterCommit": {"oid": "31b991e463168e16cc3400c1df3e06cb28a8a917", "author": {"user": {"login": "lirui-apache", "name": "Rui Li"}}, "url": "https://github.com/apache/flink/commit/31b991e463168e16cc3400c1df3e06cb28a8a917", "committedDate": "2020-06-08T05:14:58Z", "message": "add zh page"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI2MDA4MTI4", "url": "https://github.com/apache/flink/pull/12439#pullrequestreview-426008128", "createdAt": "2020-06-08T08:21:06Z", "commit": {"oid": "31b991e463168e16cc3400c1df3e06cb28a8a917"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4193, "cost": 1, "resetAt": "2021-10-28T16:48:13Z"}}}