{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg5NjA2NzQw", "number": 11424, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xN1QwNTowMjozNVrODolYVQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xN1QwNTowMjozNVrODolYVQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzODgyMDY5OnYy", "diffSide": "RIGHT", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/schema/CatalogSourceTable.scala", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xN1QwNTowMjozNVrOF3ODtQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxMTozNDo0MVrOF5QSBA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzQ0NjMyNQ==", "bodyText": "I think the right place to fix is the SqlToOperationConverter#createTableSchema, before we make the computed column type inference, the time attribute should be patched up based on the watermark definitions.", "url": "https://github.com/apache/flink/pull/11424#discussion_r393446325", "createdAt": "2020-03-17T05:02:35Z", "author": {"login": "danny0405"}, "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/schema/CatalogSourceTable.scala", "diffHunk": "@@ -106,7 +111,7 @@ class CatalogSourceTable[T](\n     val toRexFactory = flinkContext.getSqlExprToRexConverterFactory\n \n     // 2. push computed column project\n-    val fieldNames = rowType.getFieldNames.asScala\n+    val fieldNames = erasedRowType.getFieldNames.asScala", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a891d89757f7432a095de20c361faeee98f31ff6"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU3OTkwOA==", "bodyText": "After an offline discussion with @danny0405 , we reached an consensus that erasing time indicators in CatalogSourceTable#toRel is the only way to fix this for now. So we will keep the current implementation in PR.", "url": "https://github.com/apache/flink/pull/11424#discussion_r395579908", "createdAt": "2020-03-20T11:34:41Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/schema/CatalogSourceTable.scala", "diffHunk": "@@ -106,7 +111,7 @@ class CatalogSourceTable[T](\n     val toRexFactory = flinkContext.getSqlExprToRexConverterFactory\n \n     // 2. push computed column project\n-    val fieldNames = rowType.getFieldNames.asScala\n+    val fieldNames = erasedRowType.getFieldNames.asScala", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzQ0NjMyNQ=="}, "originalCommit": {"oid": "a891d89757f7432a095de20c361faeee98f31ff6"}, "originalPosition": 40}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 802, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}