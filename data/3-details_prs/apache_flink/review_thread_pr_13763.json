{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTA4Nzg5NjEy", "number": 13763, "reviewThreads": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yM1QwOTo1OToyMVrOExI3fg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQwMjoyMTowNlrOEyn5BQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE5OTYwOTU4OnYy", "diffSide": "RIGHT", "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yM1QwOTo1OToyMVrOHnHLHA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQxMzoyMjo0M1rOHoPNqQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDc3NDA0NA==", "bodyText": "I think there is still existed a bug. see: https://issues.apache.org/jira/browse/FLINK-19779?focusedCommentId=17219588&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-17219588", "url": "https://github.com/apache/flink/pull/13763#discussion_r510774044", "createdAt": "2020-10-23T09:59:21Z", "author": {"login": "V1ncentzzZ"}, "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java", "diffHunk": "@@ -362,7 +369,11 @@ public static Schema convertToSchema(LogicalType logicalType, String rowName) {\n \t\t\t\t\t.record(rowName)\n \t\t\t\t\t.fields();\n \t\t\t\tfor (int i = 0; i < rowType.getFieldCount(); i++) {\n-\t\t\t\t\tString fieldName = rowName + \"_\" + fieldNames.get(i);\n+\t\t\t\t\tString fieldName = fieldNames.get(i);\n+\t\t\t\t\tif (rowName.equals(fieldName)) {\n+\t\t\t\t\t\t// Can not build schema when the record and field have the same name\n+\t\t\t\t\t\tfieldName = rowName + \"_\" + fieldName;\n+\t\t\t\t\t}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b92a32d37a8eaa446f24f44e467e588cdabcd9f5"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTc1Nzc0NQ==", "bodyText": "Yes, the avro schema builder does not allow same name field names, even if they are in different scope (different layer).", "url": "https://github.com/apache/flink/pull/13763#discussion_r511757745", "createdAt": "2020-10-26T07:23:29Z", "author": {"login": "danny0405"}, "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java", "diffHunk": "@@ -362,7 +369,11 @@ public static Schema convertToSchema(LogicalType logicalType, String rowName) {\n \t\t\t\t\t.record(rowName)\n \t\t\t\t\t.fields();\n \t\t\t\tfor (int i = 0; i < rowType.getFieldCount(); i++) {\n-\t\t\t\t\tString fieldName = rowName + \"_\" + fieldNames.get(i);\n+\t\t\t\t\tString fieldName = fieldNames.get(i);\n+\t\t\t\t\tif (rowName.equals(fieldName)) {\n+\t\t\t\t\t\t// Can not build schema when the record and field have the same name\n+\t\t\t\t\t\tfieldName = rowName + \"_\" + fieldName;\n+\t\t\t\t\t}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDc3NDA0NA=="}, "originalCommit": {"oid": "b92a32d37a8eaa446f24f44e467e588cdabcd9f5"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTkzNTYwNw==", "bodyText": "That is not correct. The builder does support same names for fields in different nested levels.\nAvro in general does not support same record types with different schemas. And it does it rightly so. Therefore a schema like:\n{\n    \"type\": \"record\", \n    \"name\": \"top\", \n    \"fields\": [ \n\t\t  {\n             \"name\": \"top\", \n             \"type\": { \n                 \"type\": \"record\", \n                 \"name\": \"nested\", \n                 \"fields\": [ \n                     {\"type\": \"string\", \"name\": \"top\"} \n                 ]\n             }\n          }\n    ] \n}\n\nis valid and supported. However if we change the name of the nested record to top it will be invalid:\n{\n    \"type\": \"record\", \n    \"name\": \"top\", \n    \"fields\": [ \n\t\t  {\n             \"name\": \"top\", \n             \"type\": { \n                 \"type\": \"record\", \n                 \"name\": \"top\", \n                 \"fields\": [ \n                     {\"type\": \"string\", \"name\": \"top\"} \n                 ]\n             }\n          }\n    ] \n}\n\nI think the core problem lays in how the rowName is generated. I think we should never adjust the fieldName, but we should append the fieldName to the rowName.\nBTW another shortcoming that I see is that we are losing the record name when converting from Schema to DataType. I think it is not a real issue though.", "url": "https://github.com/apache/flink/pull/13763#discussion_r511935607", "createdAt": "2020-10-26T12:52:10Z", "author": {"login": "dawidwys"}, "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java", "diffHunk": "@@ -362,7 +369,11 @@ public static Schema convertToSchema(LogicalType logicalType, String rowName) {\n \t\t\t\t\t.record(rowName)\n \t\t\t\t\t.fields();\n \t\t\t\tfor (int i = 0; i < rowType.getFieldCount(); i++) {\n-\t\t\t\t\tString fieldName = rowName + \"_\" + fieldNames.get(i);\n+\t\t\t\t\tString fieldName = fieldNames.get(i);\n+\t\t\t\t\tif (rowName.equals(fieldName)) {\n+\t\t\t\t\t\t// Can not build schema when the record and field have the same name\n+\t\t\t\t\t\tfieldName = rowName + \"_\" + fieldName;\n+\t\t\t\t\t}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDc3NDA0NA=="}, "originalCommit": {"oid": "b92a32d37a8eaa446f24f44e467e588cdabcd9f5"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTk1NDM0NQ==", "bodyText": "I think the correct solution will be:\n\t\t\t\tRowType rowType = (RowType) logicalType;\n\t\t\t\tList<String> fieldNames = rowType.getFieldNames();\n\t\t\t\t// we have to make sure the record name is different in a Schema\n\t\t\t\tSchemaBuilder.FieldAssembler<Schema> builder =\n\t\t\t\t\t\tgetNullableBuilder(logicalType)\n\t\t\t\t\t\t\t\t.record(rowName)\n\t\t\t\t\t\t\t\t.fields();\n\t\t\t\tfor (int i = 0; i < rowType.getFieldCount(); i++) {\n\t\t\t\t\tString fieldName = fieldNames.get(i);\n\t\t\t\t\tbuilder = builder\n\t\t\t\t\t\t.name(fieldName)\n\t\t\t\t\t\t.type(convertToSchema(rowType.getTypeAt(i), rowName + \"_\" + fieldName))\n\t\t\t\t\t\t.noDefault();\n\t\t\t\t}\n\t\t\t\treturn builder.endRecord();", "url": "https://github.com/apache/flink/pull/13763#discussion_r511954345", "createdAt": "2020-10-26T13:22:43Z", "author": {"login": "dawidwys"}, "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java", "diffHunk": "@@ -362,7 +369,11 @@ public static Schema convertToSchema(LogicalType logicalType, String rowName) {\n \t\t\t\t\t.record(rowName)\n \t\t\t\t\t.fields();\n \t\t\t\tfor (int i = 0; i < rowType.getFieldCount(); i++) {\n-\t\t\t\t\tString fieldName = rowName + \"_\" + fieldNames.get(i);\n+\t\t\t\t\tString fieldName = fieldNames.get(i);\n+\t\t\t\t\tif (rowName.equals(fieldName)) {\n+\t\t\t\t\t\t// Can not build schema when the record and field have the same name\n+\t\t\t\t\t\tfieldName = rowName + \"_\" + fieldName;\n+\t\t\t\t\t}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDc3NDA0NA=="}, "originalCommit": {"oid": "b92a32d37a8eaa446f24f44e467e588cdabcd9f5"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIwNjg0Mzk0OnYy", "diffSide": "RIGHT", "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQxMDowMTo1NlrOHoIXnA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yN1QwMTo0Njo1NVrOHoocCw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTg0MjIwNA==", "bodyText": "Could we stick to a single way of declaring Schema nullable? With this PR we have two methods for the same purpose:\n\nnullableSchema\ngetNullableBuilder\n\nEither use the nullableSchema everywhere or use getNullableBuilder(...).type(...).", "url": "https://github.com/apache/flink/pull/13763#discussion_r511842204", "createdAt": "2020-10-26T10:01:56Z", "author": {"login": "dawidwys"}, "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java", "diffHunk": "@@ -417,4 +431,11 @@ public static LogicalType extractValueTypeToAvroMap(LogicalType type) {\n \t\t}\n \t\treturn builder;\n \t}\n+\n+\t/** Returns schema with nullable true. */\n+\tprivate static Schema nullableSchema(Schema schema) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6ef138838f1a4a0b45a42eff39b75847c9b39767"}, "originalPosition": 118}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjM2NzYyNw==", "bodyText": "They are for different purpose but i think we can use nullableSchema altogether.", "url": "https://github.com/apache/flink/pull/13763#discussion_r512367627", "createdAt": "2020-10-27T01:46:55Z", "author": {"login": "danny0405"}, "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java", "diffHunk": "@@ -417,4 +431,11 @@ public static LogicalType extractValueTypeToAvroMap(LogicalType type) {\n \t\t}\n \t\treturn builder;\n \t}\n+\n+\t/** Returns schema with nullable true. */\n+\tprivate static Schema nullableSchema(Schema schema) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTg0MjIwNA=="}, "originalCommit": {"oid": "6ef138838f1a4a0b45a42eff39b75847c9b39767"}, "originalPosition": 118}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIwNzU3NTQyOnYy", "diffSide": "RIGHT", "path": "flink-formats/flink-avro/src/test/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverterTest.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQxMzoyNDoxOFrOHoPRjA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yN1QxMTozODo0MlrOHo3xJQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTk1NTM0MA==", "bodyText": "I think it would be nice to add a test that we can convert back and forth between DataType and Schema in respect to the field names.", "url": "https://github.com/apache/flink/pull/13763#discussion_r511955340", "createdAt": "2020-10-26T13:24:18Z", "author": {"login": "dawidwys"}, "path": "flink-formats/flink-avro/src/test/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverterTest.java", "diffHunk": "@@ -104,48 +104,115 @@ public void testRowTypeAvroSchemaConversion() {\n \t\t\t\tDataTypes.FIELD(\"row3\", DataTypes.ROW(DataTypes.FIELD(\"c\", DataTypes.STRING())))))\n \t\t\t.build().toRowDataType().getLogicalType();\n \t\tSchema schema = AvroSchemaConverter.convertToSchema(rowType);\n-\t\tassertEquals(\"{\\n\" +\n+\t\tassertEquals(\"[ {\\n\" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6ef138838f1a4a0b45a42eff39b75847c9b39767"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjM3NDIxMA==", "bodyText": "Already added, see AvroSchemaConverterTest.testConversionIntegralityNullable.", "url": "https://github.com/apache/flink/pull/13763#discussion_r512374210", "createdAt": "2020-10-27T02:11:05Z", "author": {"login": "danny0405"}, "path": "flink-formats/flink-avro/src/test/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverterTest.java", "diffHunk": "@@ -104,48 +104,115 @@ public void testRowTypeAvroSchemaConversion() {\n \t\t\t\tDataTypes.FIELD(\"row3\", DataTypes.ROW(DataTypes.FIELD(\"c\", DataTypes.STRING())))))\n \t\t\t.build().toRowDataType().getLogicalType();\n \t\tSchema schema = AvroSchemaConverter.convertToSchema(rowType);\n-\t\tassertEquals(\"{\\n\" +\n+\t\tassertEquals(\"[ {\\n\" +", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTk1NTM0MA=="}, "originalCommit": {"oid": "6ef138838f1a4a0b45a42eff39b75847c9b39767"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjU4NjMyNA==", "bodyText": "True, you test though only the DataType -> Schema and back. We could also add a test for Schema -> DataType (you start with a Schema), which is important in case of a schema registry.", "url": "https://github.com/apache/flink/pull/13763#discussion_r512586324", "createdAt": "2020-10-27T10:48:08Z", "author": {"login": "dawidwys"}, "path": "flink-formats/flink-avro/src/test/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverterTest.java", "diffHunk": "@@ -104,48 +104,115 @@ public void testRowTypeAvroSchemaConversion() {\n \t\t\t\tDataTypes.FIELD(\"row3\", DataTypes.ROW(DataTypes.FIELD(\"c\", DataTypes.STRING())))))\n \t\t\t.build().toRowDataType().getLogicalType();\n \t\tSchema schema = AvroSchemaConverter.convertToSchema(rowType);\n-\t\tassertEquals(\"{\\n\" +\n+\t\tassertEquals(\"[ {\\n\" +", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTk1NTM0MA=="}, "originalCommit": {"oid": "6ef138838f1a4a0b45a42eff39b75847c9b39767"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjYxODc4OQ==", "bodyText": "Thanks, i would add schema -> DataType -> schema test.", "url": "https://github.com/apache/flink/pull/13763#discussion_r512618789", "createdAt": "2020-10-27T11:38:42Z", "author": {"login": "danny0405"}, "path": "flink-formats/flink-avro/src/test/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverterTest.java", "diffHunk": "@@ -104,48 +104,115 @@ public void testRowTypeAvroSchemaConversion() {\n \t\t\t\tDataTypes.FIELD(\"row3\", DataTypes.ROW(DataTypes.FIELD(\"c\", DataTypes.STRING())))))\n \t\t\t.build().toRowDataType().getLogicalType();\n \t\tSchema schema = AvroSchemaConverter.convertToSchema(rowType);\n-\t\tassertEquals(\"{\\n\" +\n+\t\tassertEquals(\"[ {\\n\" +", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTk1NTM0MA=="}, "originalCommit": {"oid": "6ef138838f1a4a0b45a42eff39b75847c9b39767"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxMTY5OTg0OnYy", "diffSide": "RIGHT", "path": "flink-formats/flink-avro/src/test/java/org/apache/flink/formats/avro/AvroRowDataDeSerializationSchemaTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yN1QxMDo1NzoyNVrOHo2Ocg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yN1QxMTozNDo0M1rOHo3oqA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjU5MzUyMg==", "bodyText": "That comment is misleading. There is no limitation in the actual handling of nulls with SpecificRecord/GenericRecord.\nIt's just that the LogicalTimeRecord has those fields declared as notNull. The previous dataType was just wrong and did not describe the LogicalTimeRecord correctly.", "url": "https://github.com/apache/flink/pull/13763#discussion_r512593522", "createdAt": "2020-10-27T10:57:25Z", "author": {"login": "dawidwys"}, "path": "flink-formats/flink-avro/src/test/java/org/apache/flink/formats/avro/AvroRowDataDeSerializationSchemaTest.java", "diffHunk": "@@ -181,10 +181,11 @@ public void testSpecificType() throws Exception {\n \t\tencoder.flush();\n \t\tbyte[] input = byteArrayOutputStream.toByteArray();\n \n+\t\t// SE/DE SpecificRecord using the GenericRecord way only supports non-nullable data type.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "11a1af7e69935ec9bbbcc4aeea5dcb5a8b0c68ce"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjYxNjYxNg==", "bodyText": "Thanks, would remove it.", "url": "https://github.com/apache/flink/pull/13763#discussion_r512616616", "createdAt": "2020-10-27T11:34:43Z", "author": {"login": "danny0405"}, "path": "flink-formats/flink-avro/src/test/java/org/apache/flink/formats/avro/AvroRowDataDeSerializationSchemaTest.java", "diffHunk": "@@ -181,10 +181,11 @@ public void testSpecificType() throws Exception {\n \t\tencoder.flush();\n \t\tbyte[] input = byteArrayOutputStream.toByteArray();\n \n+\t\t// SE/DE SpecificRecord using the GenericRecord way only supports non-nullable data type.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjU5MzUyMg=="}, "originalCommit": {"oid": "11a1af7e69935ec9bbbcc4aeea5dcb5a8b0c68ce"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxMTcxODA5OnYy", "diffSide": "RIGHT", "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java", "isResolved": false, "comments": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yN1QxMTowMDo0OFrOHo2ZAg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOVQwMzo0MzozNFrOHqHo3w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjU5NjIyNg==", "bodyText": "Is it necessary? Shouldn't the top be handled in the planner and just passed with a correct setting in the logicalType? I think it is a bit too deep to fix it here.", "url": "https://github.com/apache/flink/pull/13763#discussion_r512596226", "createdAt": "2020-10-27T11:00:48Z", "author": {"login": "dawidwys"}, "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java", "diffHunk": "@@ -297,17 +299,22 @@ private static DataType convertToDataType(Schema schema) {\n \t * @return Avro's {@link Schema} matching this logical type.\n \t */\n \tpublic static Schema convertToSchema(LogicalType logicalType) {\n-\t\treturn convertToSchema(logicalType, \"record\");\n+\t\treturn convertToSchema(logicalType, \"record\", true);\n \t}\n \n \t/**\n \t * Converts Flink SQL {@link LogicalType} (can be nested) into an Avro schema.\n \t *\n \t * @param logicalType logical type\n \t * @param rowName     the record name\n+\t * @param top         whether it is parsing the root record,\n+\t *                    if it is, the logical type nullability would be ignored\n \t * @return Avro's {@link Schema} matching this logical type.\n \t */\n-\tpublic static Schema convertToSchema(LogicalType logicalType, String rowName) {\n+\tpublic static Schema convertToSchema(\n+\t\t\tLogicalType logicalType,\n+\t\t\tString rowName,\n+\t\t\tboolean top) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "11a1af7e69935ec9bbbcc4aeea5dcb5a8b0c68ce"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjYxODE0Mg==", "bodyText": "It is meaningless to have a nullable top row type, and in the CREATE TABLE DDL there is no way to specify that the table row is not nullable, actually it should always be not null(even if all the fields are null).", "url": "https://github.com/apache/flink/pull/13763#discussion_r512618142", "createdAt": "2020-10-27T11:37:31Z", "author": {"login": "danny0405"}, "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java", "diffHunk": "@@ -297,17 +299,22 @@ private static DataType convertToDataType(Schema schema) {\n \t * @return Avro's {@link Schema} matching this logical type.\n \t */\n \tpublic static Schema convertToSchema(LogicalType logicalType) {\n-\t\treturn convertToSchema(logicalType, \"record\");\n+\t\treturn convertToSchema(logicalType, \"record\", true);\n \t}\n \n \t/**\n \t * Converts Flink SQL {@link LogicalType} (can be nested) into an Avro schema.\n \t *\n \t * @param logicalType logical type\n \t * @param rowName     the record name\n+\t * @param top         whether it is parsing the root record,\n+\t *                    if it is, the logical type nullability would be ignored\n \t * @return Avro's {@link Schema} matching this logical type.\n \t */\n-\tpublic static Schema convertToSchema(LogicalType logicalType, String rowName) {\n+\tpublic static Schema convertToSchema(\n+\t\t\tLogicalType logicalType,\n+\t\t\tString rowName,\n+\t\t\tboolean top) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjU5NjIyNg=="}, "originalCommit": {"oid": "11a1af7e69935ec9bbbcc4aeea5dcb5a8b0c68ce"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjYyODYxMw==", "bodyText": "I agree that the top row should not be nullable. It is a property of a SQL Table though, not of the format. If I am not wrong there you can not specify a ROW nullable in CREATE TABLE because it is always NOT NULL. Therefore it is meaningless to have additional parameter in the convertToSchema.\nWhat I am saying is that the format should not be bother with this. It is purely a matter of the planner.", "url": "https://github.com/apache/flink/pull/13763#discussion_r512628613", "createdAt": "2020-10-27T11:50:52Z", "author": {"login": "dawidwys"}, "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java", "diffHunk": "@@ -297,17 +299,22 @@ private static DataType convertToDataType(Schema schema) {\n \t * @return Avro's {@link Schema} matching this logical type.\n \t */\n \tpublic static Schema convertToSchema(LogicalType logicalType) {\n-\t\treturn convertToSchema(logicalType, \"record\");\n+\t\treturn convertToSchema(logicalType, \"record\", true);\n \t}\n \n \t/**\n \t * Converts Flink SQL {@link LogicalType} (can be nested) into an Avro schema.\n \t *\n \t * @param logicalType logical type\n \t * @param rowName     the record name\n+\t * @param top         whether it is parsing the root record,\n+\t *                    if it is, the logical type nullability would be ignored\n \t * @return Avro's {@link Schema} matching this logical type.\n \t */\n-\tpublic static Schema convertToSchema(LogicalType logicalType, String rowName) {\n+\tpublic static Schema convertToSchema(\n+\t\t\tLogicalType logicalType,\n+\t\t\tString rowName,\n+\t\t\tboolean top) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjU5NjIyNg=="}, "originalCommit": {"oid": "11a1af7e69935ec9bbbcc4aeea5dcb5a8b0c68ce"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjYzMjQzNg==", "bodyText": "I have the same feeling with @dawidwys .", "url": "https://github.com/apache/flink/pull/13763#discussion_r512632436", "createdAt": "2020-10-27T11:56:43Z", "author": {"login": "wuchong"}, "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java", "diffHunk": "@@ -297,17 +299,22 @@ private static DataType convertToDataType(Schema schema) {\n \t * @return Avro's {@link Schema} matching this logical type.\n \t */\n \tpublic static Schema convertToSchema(LogicalType logicalType) {\n-\t\treturn convertToSchema(logicalType, \"record\");\n+\t\treturn convertToSchema(logicalType, \"record\", true);\n \t}\n \n \t/**\n \t * Converts Flink SQL {@link LogicalType} (can be nested) into an Avro schema.\n \t *\n \t * @param logicalType logical type\n \t * @param rowName     the record name\n+\t * @param top         whether it is parsing the root record,\n+\t *                    if it is, the logical type nullability would be ignored\n \t * @return Avro's {@link Schema} matching this logical type.\n \t */\n-\tpublic static Schema convertToSchema(LogicalType logicalType, String rowName) {\n+\tpublic static Schema convertToSchema(\n+\t\t\tLogicalType logicalType,\n+\t\t\tString rowName,\n+\t\t\tboolean top) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjU5NjIyNg=="}, "originalCommit": {"oid": "11a1af7e69935ec9bbbcc4aeea5dcb5a8b0c68ce"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjY0MDgzNQ==", "bodyText": "Currently, only avro format cares about the outer row nullability, we can switch to change the planner if we found more user cases.\nTechnically to say, it is impossible to infer the outer row nullability only from the DDL.", "url": "https://github.com/apache/flink/pull/13763#discussion_r512640835", "createdAt": "2020-10-27T12:11:05Z", "author": {"login": "danny0405"}, "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java", "diffHunk": "@@ -297,17 +299,22 @@ private static DataType convertToDataType(Schema schema) {\n \t * @return Avro's {@link Schema} matching this logical type.\n \t */\n \tpublic static Schema convertToSchema(LogicalType logicalType) {\n-\t\treturn convertToSchema(logicalType, \"record\");\n+\t\treturn convertToSchema(logicalType, \"record\", true);\n \t}\n \n \t/**\n \t * Converts Flink SQL {@link LogicalType} (can be nested) into an Avro schema.\n \t *\n \t * @param logicalType logical type\n \t * @param rowName     the record name\n+\t * @param top         whether it is parsing the root record,\n+\t *                    if it is, the logical type nullability would be ignored\n \t * @return Avro's {@link Schema} matching this logical type.\n \t */\n-\tpublic static Schema convertToSchema(LogicalType logicalType, String rowName) {\n+\tpublic static Schema convertToSchema(\n+\t\t\tLogicalType logicalType,\n+\t\t\tString rowName,\n+\t\t\tboolean top) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjU5NjIyNg=="}, "originalCommit": {"oid": "11a1af7e69935ec9bbbcc4aeea5dcb5a8b0c68ce"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjY3MzkzMQ==", "bodyText": "Sorry, but I don't understand your arguments.\nWhat do you mean by \"inferring\" the outer row nullability? There is no inference. In SQL the outer row is always NOT NULL or otherwise the row simply does not exist.\nIn the current shape you have two arguments that contradict each other. Take this example:\nDataType type = DataTypes.ROW(\n    DataTypes.FIELD(\"f0\", DataTypes.ROW(\n        DataTypes.FIELD(\"f1\", DataTypes.BIGINT()\n    ).nullable()\n).nullable();\n\nSchema schema = convertToSchema(type, \"record\", true) // <- you're overriding the property of type\n// you can achieve the same with\n// Schema schema = convertToSchema(type.notNull(), \"record\")\n\nIt's the Planners task to produce a notNull type for a Tables type.", "url": "https://github.com/apache/flink/pull/13763#discussion_r512673931", "createdAt": "2020-10-27T13:05:11Z", "author": {"login": "dawidwys"}, "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java", "diffHunk": "@@ -297,17 +299,22 @@ private static DataType convertToDataType(Schema schema) {\n \t * @return Avro's {@link Schema} matching this logical type.\n \t */\n \tpublic static Schema convertToSchema(LogicalType logicalType) {\n-\t\treturn convertToSchema(logicalType, \"record\");\n+\t\treturn convertToSchema(logicalType, \"record\", true);\n \t}\n \n \t/**\n \t * Converts Flink SQL {@link LogicalType} (can be nested) into an Avro schema.\n \t *\n \t * @param logicalType logical type\n \t * @param rowName     the record name\n+\t * @param top         whether it is parsing the root record,\n+\t *                    if it is, the logical type nullability would be ignored\n \t * @return Avro's {@link Schema} matching this logical type.\n \t */\n-\tpublic static Schema convertToSchema(LogicalType logicalType, String rowName) {\n+\tpublic static Schema convertToSchema(\n+\t\t\tLogicalType logicalType,\n+\t\t\tString rowName,\n+\t\t\tboolean top) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjU5NjIyNg=="}, "originalCommit": {"oid": "11a1af7e69935ec9bbbcc4aeea5dcb5a8b0c68ce"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzEzNTc4OQ==", "bodyText": "In SQL the outer row is always NOT NULL\n\nIt is not true, a row (null, null) is nullable true. And i don't think it makes sense to change the planner behavior in general in order to fix a specific use case.\n\n// you can achieve the same with\n// Schema schema = convertToSchema(type.notNull(), \"record\")\n\nI don't think we should let each invoker to decide whether to make the data type not null, because in current codebase, we should always do that, make the decision everyone is error-prone and hard to maintain.\nI have merge the top into a row type nullability switch, see AvroSchemaConverter.convertToSchema(LogicalType logicalType).", "url": "https://github.com/apache/flink/pull/13763#discussion_r513135789", "createdAt": "2020-10-28T02:04:19Z", "author": {"login": "danny0405"}, "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java", "diffHunk": "@@ -297,17 +299,22 @@ private static DataType convertToDataType(Schema schema) {\n \t * @return Avro's {@link Schema} matching this logical type.\n \t */\n \tpublic static Schema convertToSchema(LogicalType logicalType) {\n-\t\treturn convertToSchema(logicalType, \"record\");\n+\t\treturn convertToSchema(logicalType, \"record\", true);\n \t}\n \n \t/**\n \t * Converts Flink SQL {@link LogicalType} (can be nested) into an Avro schema.\n \t *\n \t * @param logicalType logical type\n \t * @param rowName     the record name\n+\t * @param top         whether it is parsing the root record,\n+\t *                    if it is, the logical type nullability would be ignored\n \t * @return Avro's {@link Schema} matching this logical type.\n \t */\n-\tpublic static Schema convertToSchema(LogicalType logicalType, String rowName) {\n+\tpublic static Schema convertToSchema(\n+\t\t\tLogicalType logicalType,\n+\t\t\tString rowName,\n+\t\t\tboolean top) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjU5NjIyNg=="}, "originalCommit": {"oid": "11a1af7e69935ec9bbbcc4aeea5dcb5a8b0c68ce"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzI1MjcyNA==", "bodyText": "It is not true, a row (null, null) is nullable true. And i don't think it makes sense to change the planner behavior in general in order to fix a specific use case.\n\nExcuse me, but I wholeheartedly disagree with your statement. null =/= (null, null). (null, null) is still NOT NULL. A whole row in a Table can not be null. Only particular columns can be null. Therefore the top level row of a Table is always NOT NULL.\nI am not suggesting changing planner behaviour for a particular use case. The planner should always produce NOT NULL type for a top level row of a Table. If it doesn't, it is a bug.", "url": "https://github.com/apache/flink/pull/13763#discussion_r513252724", "createdAt": "2020-10-28T08:19:18Z", "author": {"login": "dawidwys"}, "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java", "diffHunk": "@@ -297,17 +299,22 @@ private static DataType convertToDataType(Schema schema) {\n \t * @return Avro's {@link Schema} matching this logical type.\n \t */\n \tpublic static Schema convertToSchema(LogicalType logicalType) {\n-\t\treturn convertToSchema(logicalType, \"record\");\n+\t\treturn convertToSchema(logicalType, \"record\", true);\n \t}\n \n \t/**\n \t * Converts Flink SQL {@link LogicalType} (can be nested) into an Avro schema.\n \t *\n \t * @param logicalType logical type\n \t * @param rowName     the record name\n+\t * @param top         whether it is parsing the root record,\n+\t *                    if it is, the logical type nullability would be ignored\n \t * @return Avro's {@link Schema} matching this logical type.\n \t */\n-\tpublic static Schema convertToSchema(LogicalType logicalType, String rowName) {\n+\tpublic static Schema convertToSchema(\n+\t\t\tLogicalType logicalType,\n+\t\t\tString rowName,\n+\t\t\tboolean top) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjU5NjIyNg=="}, "originalCommit": {"oid": "11a1af7e69935ec9bbbcc4aeea5dcb5a8b0c68ce"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzI1MzY4Mg==", "bodyText": "I don't think we should let each invoker to decide whether to make the data type not null, because in current codebase, we should always do that, make the decision everyone is error-prone and hard to maintain.\n\nI agree making the same decision over and over again at multiple location is error prone and hard to maintain and that's what I want to avoid.", "url": "https://github.com/apache/flink/pull/13763#discussion_r513253682", "createdAt": "2020-10-28T08:20:58Z", "author": {"login": "dawidwys"}, "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java", "diffHunk": "@@ -297,17 +299,22 @@ private static DataType convertToDataType(Schema schema) {\n \t * @return Avro's {@link Schema} matching this logical type.\n \t */\n \tpublic static Schema convertToSchema(LogicalType logicalType) {\n-\t\treturn convertToSchema(logicalType, \"record\");\n+\t\treturn convertToSchema(logicalType, \"record\", true);\n \t}\n \n \t/**\n \t * Converts Flink SQL {@link LogicalType} (can be nested) into an Avro schema.\n \t *\n \t * @param logicalType logical type\n \t * @param rowName     the record name\n+\t * @param top         whether it is parsing the root record,\n+\t *                    if it is, the logical type nullability would be ignored\n \t * @return Avro's {@link Schema} matching this logical type.\n \t */\n-\tpublic static Schema convertToSchema(LogicalType logicalType, String rowName) {\n+\tpublic static Schema convertToSchema(\n+\t\t\tLogicalType logicalType,\n+\t\t\tString rowName,\n+\t\t\tboolean top) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjU5NjIyNg=="}, "originalCommit": {"oid": "11a1af7e69935ec9bbbcc4aeea5dcb5a8b0c68ce"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzI2NDk4Nw==", "bodyText": "Excuse me, but I wholeheartedly disagree with your statement. null =/= (null, null). (null, null) is still NOT NULL. A whole row in a Table can not be null. Only particular columns can be null. Therefore the top level row of a Table is always NOT NULL.\n\nYou can test it in PostgreSQL with the following SQL:\ncreate type my_type as (a int, b varchar(20));\n\ncreate table t1(\n  f0 my_type,\n  f1 varchar(20)\n);\n\ninsert into t1 values((null, null), 'def');\n\nselect f0 is null from t1; -- it returns true", "url": "https://github.com/apache/flink/pull/13763#discussion_r513264987", "createdAt": "2020-10-28T08:40:50Z", "author": {"login": "danny0405"}, "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java", "diffHunk": "@@ -297,17 +299,22 @@ private static DataType convertToDataType(Schema schema) {\n \t * @return Avro's {@link Schema} matching this logical type.\n \t */\n \tpublic static Schema convertToSchema(LogicalType logicalType) {\n-\t\treturn convertToSchema(logicalType, \"record\");\n+\t\treturn convertToSchema(logicalType, \"record\", true);\n \t}\n \n \t/**\n \t * Converts Flink SQL {@link LogicalType} (can be nested) into an Avro schema.\n \t *\n \t * @param logicalType logical type\n \t * @param rowName     the record name\n+\t * @param top         whether it is parsing the root record,\n+\t *                    if it is, the logical type nullability would be ignored\n \t * @return Avro's {@link Schema} matching this logical type.\n \t */\n-\tpublic static Schema convertToSchema(LogicalType logicalType, String rowName) {\n+\tpublic static Schema convertToSchema(\n+\t\t\tLogicalType logicalType,\n+\t\t\tString rowName,\n+\t\t\tboolean top) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjU5NjIyNg=="}, "originalCommit": {"oid": "11a1af7e69935ec9bbbcc4aeea5dcb5a8b0c68ce"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzI2OTYyNA==", "bodyText": "But the my_type is not a top level row in your example. It is a type of a column. It has nothing to do with the case we're discussing.", "url": "https://github.com/apache/flink/pull/13763#discussion_r513269624", "createdAt": "2020-10-28T08:48:31Z", "author": {"login": "dawidwys"}, "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java", "diffHunk": "@@ -297,17 +299,22 @@ private static DataType convertToDataType(Schema schema) {\n \t * @return Avro's {@link Schema} matching this logical type.\n \t */\n \tpublic static Schema convertToSchema(LogicalType logicalType) {\n-\t\treturn convertToSchema(logicalType, \"record\");\n+\t\treturn convertToSchema(logicalType, \"record\", true);\n \t}\n \n \t/**\n \t * Converts Flink SQL {@link LogicalType} (can be nested) into an Avro schema.\n \t *\n \t * @param logicalType logical type\n \t * @param rowName     the record name\n+\t * @param top         whether it is parsing the root record,\n+\t *                    if it is, the logical type nullability would be ignored\n \t * @return Avro's {@link Schema} matching this logical type.\n \t */\n-\tpublic static Schema convertToSchema(LogicalType logicalType, String rowName) {\n+\tpublic static Schema convertToSchema(\n+\t\t\tLogicalType logicalType,\n+\t\t\tString rowName,\n+\t\t\tboolean top) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjU5NjIyNg=="}, "originalCommit": {"oid": "11a1af7e69935ec9bbbcc4aeea5dcb5a8b0c68ce"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzkyNzM5MQ==", "bodyText": "@dawidwys  I have changed the schema row type to be always nullable false, please take a look again if you have time, thanks so much.", "url": "https://github.com/apache/flink/pull/13763#discussion_r513927391", "createdAt": "2020-10-29T03:43:34Z", "author": {"login": "danny0405"}, "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java", "diffHunk": "@@ -297,17 +299,22 @@ private static DataType convertToDataType(Schema schema) {\n \t * @return Avro's {@link Schema} matching this logical type.\n \t */\n \tpublic static Schema convertToSchema(LogicalType logicalType) {\n-\t\treturn convertToSchema(logicalType, \"record\");\n+\t\treturn convertToSchema(logicalType, \"record\", true);\n \t}\n \n \t/**\n \t * Converts Flink SQL {@link LogicalType} (can be nested) into an Avro schema.\n \t *\n \t * @param logicalType logical type\n \t * @param rowName     the record name\n+\t * @param top         whether it is parsing the root record,\n+\t *                    if it is, the logical type nullability would be ignored\n \t * @return Avro's {@link Schema} matching this logical type.\n \t */\n-\tpublic static Schema convertToSchema(LogicalType logicalType, String rowName) {\n+\tpublic static Schema convertToSchema(\n+\t\t\tLogicalType logicalType,\n+\t\t\tString rowName,\n+\t\t\tboolean top) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjU5NjIyNg=="}, "originalCommit": {"oid": "11a1af7e69935ec9bbbcc4aeea5dcb5a8b0c68ce"}, "originalPosition": 39}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxNTE3ODI5OnYy", "diffSide": "RIGHT", "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQwMjoyMTowNlrOHpXl9w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQwMzo0MzoxMlrOHpY79Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzE0MDIxNQ==", "bodyText": "I think we can make the parameter to be RowType, that would make sense to use it as the top-level row type and not generate nullable for it. Besides, would be better to add comments in the Javadoc. Currently, this method has the same Javadoc with convertToSchema(LogicalType logicalType, String rowName).", "url": "https://github.com/apache/flink/pull/13763#discussion_r513140215", "createdAt": "2020-10-28T02:21:06Z", "author": {"login": "wuchong"}, "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java", "diffHunk": "@@ -297,32 +300,53 @@ private static DataType convertToDataType(Schema schema) {\n \t * @return Avro's {@link Schema} matching this logical type.\n \t */\n \tpublic static Schema convertToSchema(LogicalType logicalType) {\n+\t\t// If it is parsing the root row type, switches from nullable true to false\n+\t\t// because a nullable row type is meaningless and would generate wrong schema.\n+\t\tif (logicalType.getTypeRoot() == LogicalTypeRoot.ROW", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ba752274c9926115f65f5ecbef55b71b0b71cfa2"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzE2MjIyOQ==", "bodyText": "Although the AvroSchemaConverter is a tool class, it is still used as a public API, so i'm inclined to keep the signature unchanged. Another reason is that only logical type is enough for the conversion.\nHave added more documents to the methods.", "url": "https://github.com/apache/flink/pull/13763#discussion_r513162229", "createdAt": "2020-10-28T03:43:12Z", "author": {"login": "danny0405"}, "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java", "diffHunk": "@@ -297,32 +300,53 @@ private static DataType convertToDataType(Schema schema) {\n \t * @return Avro's {@link Schema} matching this logical type.\n \t */\n \tpublic static Schema convertToSchema(LogicalType logicalType) {\n+\t\t// If it is parsing the root row type, switches from nullable true to false\n+\t\t// because a nullable row type is meaningless and would generate wrong schema.\n+\t\tif (logicalType.getTypeRoot() == LogicalTypeRoot.ROW", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzE0MDIxNQ=="}, "originalCommit": {"oid": "ba752274c9926115f65f5ecbef55b71b0b71cfa2"}, "originalPosition": 32}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 90, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}