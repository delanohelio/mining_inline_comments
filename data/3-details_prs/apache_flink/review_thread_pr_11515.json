{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzkzODYwOTIx", "number": 11515, "reviewThreads": {"totalCount": 149, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNTo0MToyMlrODuAzAA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxNjoyODo0M1rODwEf6w==", "hasNextPage": false, "hasPreviousPage": true}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5NTc0MTQ0OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNTo0MToyMlrOF_xZAw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNTo0MToyMlrOF_xZAw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQxMzgyNw==", "bodyText": "ditto: no need to throw explicitly", "url": "https://github.com/apache/flink/pull/11515#discussion_r402413827", "createdAt": "2020-04-02T15:41:22Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriter.java", "diffHunk": "@@ -46,60 +78,64 @@\n \t/**\n \t * Initiate write of channel state for the given checkpoint id.\n \t */\n-\tvoid start(long checkpointId);\n+\tvoid start(long checkpointId, CheckpointOptions checkpointOptions);\n \n \t/**\n \t * Add in-flight buffers from the {@link org.apache.flink.runtime.io.network.partition.consumer.InputChannel InputChannel}.\n-\t * Must be called after {@link #start(long)} and before {@link #finish(long)}.\n+\t * Must be called after {@link #start} (long)} and before {@link #finishInput(long)}.\n+\t * Buffers are recycled after they are written.\n \t * @param startSeqNum sequence number of the 1st passed buffer.\n \t *                    It is intended to use for incremental snapshots.\n \t *                    If no data is passed it is ignored.\n-\t * @param data zero or more buffers ordered by their sequence numbers\n+\t * @param data zero or more <b>data</b> buffers ordered by their sequence numbers\n+\t * @throws IllegalArgumentException if one or more passed buffers {@link Buffer#isBuffer()  isn't a buffer}\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_RESTORED\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_UNKNOWN\n \t */\n-\tvoid addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data);\n+\tvoid addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data) throws IllegalArgumentException;\n \n \t/**\n \t * Add in-flight buffers from the {@link org.apache.flink.runtime.io.network.partition.ResultSubpartition ResultSubpartition}.\n-\t * Must be called after {@link #start(long)} and before {@link #finish(long)}.\n+\t * Must be called after {@link #start} and before {@link #finishOutput(long)}.\n+\t * Buffers are recycled after they are written.\n \t * @param startSeqNum sequence number of the 1st passed buffer.\n \t *                    It is intended to use for incremental snapshots.\n \t *                    If no data is passed it is ignored.\n-\t * @param data zero or more buffers ordered by their sequence numbers\n+\t * @param data zero or more <b>data</b> buffers ordered by their sequence numbers\n+\t * @throws IllegalArgumentException if one or more passed buffers {@link Buffer#isBuffer()  isn't a buffer}\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_RESTORED\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_UNKNOWN\n \t */\n-\tvoid addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data);\n+\tvoid addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data) throws IllegalArgumentException;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 94}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5NTc2MDEwOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNTo0NTozMFrOF_xkgA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNTo0NTozMFrOF_xkgA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQxNjc2OA==", "bodyText": "#start missing one argument", "url": "https://github.com/apache/flink/pull/11515#discussion_r402416768", "createdAt": "2020-04-02T15:45:30Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriter.java", "diffHunk": "@@ -46,60 +78,64 @@\n \t/**\n \t * Initiate write of channel state for the given checkpoint id.\n \t */\n-\tvoid start(long checkpointId);\n+\tvoid start(long checkpointId, CheckpointOptions checkpointOptions);\n \n \t/**\n \t * Add in-flight buffers from the {@link org.apache.flink.runtime.io.network.partition.consumer.InputChannel InputChannel}.\n-\t * Must be called after {@link #start(long)} and before {@link #finish(long)}.\n+\t * Must be called after {@link #start} (long)} and before {@link #finishInput(long)}.\n+\t * Buffers are recycled after they are written.\n \t * @param startSeqNum sequence number of the 1st passed buffer.\n \t *                    It is intended to use for incremental snapshots.\n \t *                    If no data is passed it is ignored.\n-\t * @param data zero or more buffers ordered by their sequence numbers\n+\t * @param data zero or more <b>data</b> buffers ordered by their sequence numbers\n+\t * @throws IllegalArgumentException if one or more passed buffers {@link Buffer#isBuffer()  isn't a buffer}\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_RESTORED\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_UNKNOWN\n \t */\n-\tvoid addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data);\n+\tvoid addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data) throws IllegalArgumentException;\n \n \t/**\n \t * Add in-flight buffers from the {@link org.apache.flink.runtime.io.network.partition.ResultSubpartition ResultSubpartition}.\n-\t * Must be called after {@link #start(long)} and before {@link #finish(long)}.\n+\t * Must be called after {@link #start} and before {@link #finishOutput(long)}.\n+\t * Buffers are recycled after they are written.\n \t * @param startSeqNum sequence number of the 1st passed buffer.\n \t *                    It is intended to use for incremental snapshots.\n \t *                    If no data is passed it is ignored.\n-\t * @param data zero or more buffers ordered by their sequence numbers\n+\t * @param data zero or more <b>data</b> buffers ordered by their sequence numbers\n+\t * @throws IllegalArgumentException if one or more passed buffers {@link Buffer#isBuffer()  isn't a buffer}\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_RESTORED\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_UNKNOWN\n \t */\n-\tvoid addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data);\n+\tvoid addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data) throws IllegalArgumentException;\n \n \t/**\n \t * Finalize write of channel state data for the given checkpoint id.\n \t * Must be called after {@link #start(long)} and all of the input data of the given checkpoint added.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 98}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5NTc2MzMzOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNTo0NjoxNlrOF_xmow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNTo0NjoxNlrOF_xmow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQxNzMxNQ==", "bodyText": "remove this method directly?", "url": "https://github.com/apache/flink/pull/11515#discussion_r402417315", "createdAt": "2020-04-02T15:46:16Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriter.java", "diffHunk": "@@ -46,60 +78,64 @@\n \t/**\n \t * Initiate write of channel state for the given checkpoint id.\n \t */\n-\tvoid start(long checkpointId);\n+\tvoid start(long checkpointId, CheckpointOptions checkpointOptions);\n \n \t/**\n \t * Add in-flight buffers from the {@link org.apache.flink.runtime.io.network.partition.consumer.InputChannel InputChannel}.\n-\t * Must be called after {@link #start(long)} and before {@link #finish(long)}.\n+\t * Must be called after {@link #start} (long)} and before {@link #finishInput(long)}.\n+\t * Buffers are recycled after they are written.\n \t * @param startSeqNum sequence number of the 1st passed buffer.\n \t *                    It is intended to use for incremental snapshots.\n \t *                    If no data is passed it is ignored.\n-\t * @param data zero or more buffers ordered by their sequence numbers\n+\t * @param data zero or more <b>data</b> buffers ordered by their sequence numbers\n+\t * @throws IllegalArgumentException if one or more passed buffers {@link Buffer#isBuffer()  isn't a buffer}\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_RESTORED\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_UNKNOWN\n \t */\n-\tvoid addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data);\n+\tvoid addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data) throws IllegalArgumentException;\n \n \t/**\n \t * Add in-flight buffers from the {@link org.apache.flink.runtime.io.network.partition.ResultSubpartition ResultSubpartition}.\n-\t * Must be called after {@link #start(long)} and before {@link #finish(long)}.\n+\t * Must be called after {@link #start} and before {@link #finishOutput(long)}.\n+\t * Buffers are recycled after they are written.\n \t * @param startSeqNum sequence number of the 1st passed buffer.\n \t *                    It is intended to use for incremental snapshots.\n \t *                    If no data is passed it is ignored.\n-\t * @param data zero or more buffers ordered by their sequence numbers\n+\t * @param data zero or more <b>data</b> buffers ordered by their sequence numbers\n+\t * @throws IllegalArgumentException if one or more passed buffers {@link Buffer#isBuffer()  isn't a buffer}\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_RESTORED\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_UNKNOWN\n \t */\n-\tvoid addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data);\n+\tvoid addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data) throws IllegalArgumentException;\n \n \t/**\n \t * Finalize write of channel state data for the given checkpoint id.\n \t * Must be called after {@link #start(long)} and all of the input data of the given checkpoint added.\n \t * When both {@link #finishInput} and {@link #finishOutput} were called the results can be (eventually) obtained\n-\t * using {@link #getWriteCompletionFuture}\n+\t * using {@link #getWriteResult}\n \t */\n \tvoid finishInput(long checkpointId);\n \n \t/**\n \t * Finalize write of channel state data for the given checkpoint id.\n \t * Must be called after {@link #start(long)} and all of the output data of the given checkpoint added.\n \t * When both {@link #finishInput} and {@link #finishOutput} were called the results can be (eventually) obtained\n-\t * using {@link #getWriteCompletionFuture}\n+\t * using {@link #getWriteResult}\n \t */\n \tvoid finishOutput(long checkpointId);\n \n \t/**\n-\t * Must be called after {@link #start(long)}.\n+\t * Must be called after {@link #start}.\n \t */\n-\tFuture<Collection<StateObject>> getWriteCompletionFuture(long checkpointId);\n+\tChannelStateWriteResult getWriteResult(long checkpointId);\n \n \t@Override\n-\tvoid close() throws Exception;\n+\tvoid close();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 123}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5NTgxMzcwOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/buffer/BufferBuilder.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNTo1NzozMVrOF_yHQQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNTo1NzozMVrOF_yHQQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQyNTY2NQ==", "bodyText": "nit: getWritableBytes()?", "url": "https://github.com/apache/flink/pull/11515#discussion_r402425665", "createdAt": "2020-04-02T15:57:31Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/buffer/BufferBuilder.java", "diffHunk": "@@ -117,6 +117,11 @@ public boolean isFull() {\n \t\treturn positionMarker.getCached() == getMaxCapacity();\n \t}\n \n+\tpublic int writableBytes() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxMTk0ODE4OnYy", "diffSide": "RIGHT", "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/over/BufferDataOverWindowOperatorTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxMzoyMDo0N1rOGCDM_w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxMzoyNDo0NVrOGCDX-Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDgwMjgxNQ==", "bodyText": "this seems never be used.", "url": "https://github.com/apache/flink/pull/11515#discussion_r404802815", "createdAt": "2020-04-07T13:20:47Z", "author": {"login": "zhijiangW"}, "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/over/BufferDataOverWindowOperatorTest.java", "diffHunk": "@@ -237,4 +241,9 @@ public StreamingRuntimeContext getRuntimeContext() {\n \tprivate void addRow(Object... fields) throws Exception {\n \t\toperator.processElement(new StreamRecord<>(GenericRow.of(fields)));\n \t}\n+\n+\tprivate interface EnvironmentSupport {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1798f9618fd405fa87bfcac215fae4d4d30c469"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDgwNTYyNQ==", "bodyText": "Yes, leftover from the previous version. Thanks.", "url": "https://github.com/apache/flink/pull/11515#discussion_r404805625", "createdAt": "2020-04-07T13:24:45Z", "author": {"login": "rkhachatryan"}, "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/over/BufferDataOverWindowOperatorTest.java", "diffHunk": "@@ -237,4 +241,9 @@ public StreamingRuntimeContext getRuntimeContext() {\n \tprivate void addRow(Object... fields) throws Exception {\n \t\toperator.processElement(new StreamRecord<>(GenericRow.of(fields)));\n \t}\n+\n+\tprivate interface EnvironmentSupport {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDgwMjgxNQ=="}, "originalCommit": {"oid": "f1798f9618fd405fa87bfcac215fae4d4d30c469"}, "originalPosition": 49}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxMTk1Nzg5OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/operators/testutils/MockEnvironmentBuilder.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxMzoyMjo1OFrOGCDS6Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxMzoyMjo1OFrOGCDS6Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDgwNDMyOQ==", "bodyText": "nit: actually this is not used now in all places and we can add it by demands future. If we want to rich the builder now, it is better to place it in front of #build() to make related methods close with each other.", "url": "https://github.com/apache/flink/pull/11515#discussion_r404804329", "createdAt": "2020-04-07T13:22:58Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/operators/testutils/MockEnvironmentBuilder.java", "diffHunk": "@@ -154,6 +159,12 @@ public MockEnvironment build() {\n \t\t\tsubtaskIndex,\n \t\t\tuserCodeClassLoader,\n \t\t\ttaskMetricGroup,\n-\t\t\ttaskManagerRuntimeInfo);\n+\t\t\ttaskManagerRuntimeInfo,\n+\t\t\tmemoryManager);\n+\t}\n+\n+\tpublic MockEnvironmentBuilder setMemoryManager(MemoryManager memoryManager) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1798f9618fd405fa87bfcac215fae4d4d30c469"}, "originalPosition": 76}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxMjUxNTY4OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNToyMDoyNVrOGCIzdQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNToyMDoyNVrOGCIzdQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDg5NDU4MQ==", "bodyText": "nit: only missing checkNotNull for the last argument actionExecutor", "url": "https://github.com/apache/flink/pull/11515#discussion_r404894581", "createdAt": "2020-04-07T15:20:25Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -0,0 +1,124 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.tasks;\n+\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.runtime.checkpoint.CheckpointMetaData;\n+import org.apache.flink.runtime.checkpoint.CheckpointMetrics;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.execution.Environment;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.concurrent.ExecutorService;\n+import java.util.function.Supplier;\n+\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+\n+class SubtaskCheckpointCoordinatorImpl implements SubtaskCheckpointCoordinator {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(SubtaskCheckpointCoordinatorImpl.class);\n+\n+\tprivate final CheckpointStorageWorkerView checkpointStorage;\n+\tprivate final String taskName;\n+\tprivate final CloseableRegistry closeableRegistry;\n+\tprivate final ExecutorService executorService;\n+\tprivate final Environment env;\n+\tprivate final AsyncExceptionHandler asyncExceptionHandler;\n+\tprivate final StreamTaskActionExecutor actionExecutor;\n+\n+\tSubtaskCheckpointCoordinatorImpl(\n+\t\t\tCheckpointStorageWorkerView checkpointStorage,\n+\t\t\tString taskName,\n+\t\t\tStreamTaskActionExecutor actionExecutor,\n+\t\t\tCloseableRegistry closeableRegistry,\n+\t\t\tExecutorService executorService,\n+\t\t\tEnvironment env,\n+\t\t\tAsyncExceptionHandler asyncExceptionHandler) {\n+\t\tthis.checkpointStorage = checkNotNull(checkpointStorage);\n+\t\tthis.taskName = checkNotNull(taskName);\n+\t\tthis.closeableRegistry = checkNotNull(closeableRegistry);\n+\t\tthis.executorService = checkNotNull(executorService);\n+\t\tthis.env = checkNotNull(env);\n+\t\tthis.asyncExceptionHandler = checkNotNull(asyncExceptionHandler);\n+\t\tthis.actionExecutor = actionExecutor;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a233c1fb23c6c3abdb3a3dee745750b191470aa1"}, "originalPosition": 61}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxMjU2MDU5OnYy", "diffSide": "LEFT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNToyOToyMlrOGCJPcw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNToyOToyMlrOGCJPcw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDkwMTc0Nw==", "bodyText": "From the commit \"[FLINK-16744][task][refactor] inline CheckpointingOperation\", it is unnecessary changes to move the position of this method, if we want to merge this commit separately.", "url": "https://github.com/apache/flink/pull/11515#discussion_r404901747", "createdAt": "2020-04-07T15:29:22Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -61,11 +65,6 @@\n \t\tthis.actionExecutor = actionExecutor;\n \t}\n \n-\t@Override", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "725b18cbede97464a1fa77f984108e70c337789f"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxMjY3NTkwOnYy", "diffSide": "LEFT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriter.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNTo1MzoxNFrOGCKXdA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNTo1MzoxNFrOGCKXdA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDkyMDE4MA==", "bodyText": "we should also adjust the references of {@link #finish(long)} in above addInputData and addOutput descriptions for the commit \"[FLINK-16744][task] split finish() in ChanStateWrite\"", "url": "https://github.com/apache/flink/pull/11515#discussion_r404920180", "createdAt": "2020-04-07T15:53:14Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriter.java", "diffHunk": "@@ -73,10 +73,20 @@\n \tvoid addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data);\n \n \t/**\n-\t * Finalize write of channel state for the given checkpoint id.\n-\t * Must be called after {@link #start(long)} and all of the data of the given checkpoint added.\n+\t * Finalize write of channel state data for the given checkpoint id.\n+\t * Must be called after {@link #start(long)} and all of the input data of the given checkpoint added.\n+\t * When both {@link #finishInput} and {@link #finishOutput} were called the results can be (eventually) obtained\n+\t * using {@link #getWriteCompletionFuture}\n \t */\n-\tvoid finish(long checkpointId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ead3567fb7f140353779ab3a4d52e67185485e39"}, "originalPosition": 11}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxMjcxOTc4OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateCheckpointWriter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNjowMjoyMlrOGCKzmg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNjowMjoyMlrOGCKzmg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDkyNzM4Ng==", "bodyText": "Uniform the argument form as writeInput? Buffer... or Buffer[]", "url": "https://github.com/apache/flink/pull/11515#discussion_r404927386", "createdAt": "2020-04-07T16:02:22Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateCheckpointWriter.java", "diffHunk": "@@ -0,0 +1,203 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory.CheckpointStateOutputStream;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.runtime.state.ResultSubpartitionStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.BiFunction;\n+\n+import static org.apache.flink.runtime.state.CheckpointedStateScope.EXCLUSIVE;\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * Writes channel state for a specific checkpoint-subtask-attempt triple.\n+ */\n+@NotThreadSafe\n+class ChannelStateCheckpointWriter {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateCheckpointWriter.class);\n+\n+\tprivate final DataOutputStream dataStream;\n+\tprivate final CheckpointStateOutputStream checkpointStream;\n+\tprivate final ChannelStateWriteResult result;\n+\tprivate final Map<InputChannelInfo, List<Long>> inputChannelOffsets = new HashMap<>();\n+\tprivate final Map<ResultSubpartitionInfo, List<Long>> resultSubpartitionOffsets = new HashMap<>();\n+\tprivate final ChannelStateSerializer serializer;\n+\tprivate final long checkpointId;\n+\tprivate boolean allInputsReceived = false;\n+\tprivate boolean allOutputsReceived = false;\n+\tprivate final RunnableWithException onComplete;\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tCheckpointStartRequest startCheckpointItem,\n+\t\t\tCheckpointStreamFactory streamFactory,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnableWithException onComplete) throws Exception {\n+\t\tthis(\n+\t\t\tstartCheckpointItem.getCheckpointId(),\n+\t\t\tstartCheckpointItem.getTargetResult(),\n+\t\t\tstreamFactory.createCheckpointStateOutputStream(EXCLUSIVE),\n+\t\t\tserializer,\n+\t\t\tonComplete);\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tCheckpointStateOutputStream stream,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnableWithException onComplete) throws Exception {\n+\t\tthis(checkpointId, result, serializer, onComplete, stream, new DataOutputStream(stream));\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnableWithException onComplete,\n+\t\t\tCheckpointStateOutputStream checkpointStateOutputStream,\n+\t\t\tDataOutputStream dataStream) throws Exception {\n+\t\tthis.checkpointId = checkpointId;\n+\t\tthis.result = checkNotNull(result);\n+\t\tthis.checkpointStream = checkNotNull(checkpointStateOutputStream);\n+\t\tthis.serializer = checkNotNull(serializer);\n+\t\tthis.dataStream = checkNotNull(dataStream);\n+\t\tthis.onComplete = checkNotNull(onComplete);\n+\t\trunWithChecks(() -> serializer.writeHeader(dataStream));\n+\t}\n+\n+\tvoid writeInput(InputChannelInfo info, Buffer... flinkBuffers) throws Exception {\n+\t\twrite(inputChannelOffsets, info, flinkBuffers, !allInputsReceived);\n+\t}\n+\n+\tvoid writeOutput(ResultSubpartitionInfo info, Buffer[] flinkBuffers) throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 110}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxMjc0NzM4OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateCheckpointWriter.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNjowODo1NlrOGCLFvQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QyMDo1OToxOFrOGCV5pQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDkzMjAyOQ==", "bodyText": "Are there any problems if checkpointStream.close() causes exception to not execute the below dataStream.close()?", "url": "https://github.com/apache/flink/pull/11515#discussion_r404932029", "createdAt": "2020-04-07T16:08:56Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateCheckpointWriter.java", "diffHunk": "@@ -0,0 +1,203 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory.CheckpointStateOutputStream;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.runtime.state.ResultSubpartitionStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.BiFunction;\n+\n+import static org.apache.flink.runtime.state.CheckpointedStateScope.EXCLUSIVE;\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * Writes channel state for a specific checkpoint-subtask-attempt triple.\n+ */\n+@NotThreadSafe\n+class ChannelStateCheckpointWriter {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateCheckpointWriter.class);\n+\n+\tprivate final DataOutputStream dataStream;\n+\tprivate final CheckpointStateOutputStream checkpointStream;\n+\tprivate final ChannelStateWriteResult result;\n+\tprivate final Map<InputChannelInfo, List<Long>> inputChannelOffsets = new HashMap<>();\n+\tprivate final Map<ResultSubpartitionInfo, List<Long>> resultSubpartitionOffsets = new HashMap<>();\n+\tprivate final ChannelStateSerializer serializer;\n+\tprivate final long checkpointId;\n+\tprivate boolean allInputsReceived = false;\n+\tprivate boolean allOutputsReceived = false;\n+\tprivate final RunnableWithException onComplete;\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tCheckpointStartRequest startCheckpointItem,\n+\t\t\tCheckpointStreamFactory streamFactory,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnableWithException onComplete) throws Exception {\n+\t\tthis(\n+\t\t\tstartCheckpointItem.getCheckpointId(),\n+\t\t\tstartCheckpointItem.getTargetResult(),\n+\t\t\tstreamFactory.createCheckpointStateOutputStream(EXCLUSIVE),\n+\t\t\tserializer,\n+\t\t\tonComplete);\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tCheckpointStateOutputStream stream,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnableWithException onComplete) throws Exception {\n+\t\tthis(checkpointId, result, serializer, onComplete, stream, new DataOutputStream(stream));\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnableWithException onComplete,\n+\t\t\tCheckpointStateOutputStream checkpointStateOutputStream,\n+\t\t\tDataOutputStream dataStream) throws Exception {\n+\t\tthis.checkpointId = checkpointId;\n+\t\tthis.result = checkNotNull(result);\n+\t\tthis.checkpointStream = checkNotNull(checkpointStateOutputStream);\n+\t\tthis.serializer = checkNotNull(serializer);\n+\t\tthis.dataStream = checkNotNull(dataStream);\n+\t\tthis.onComplete = checkNotNull(onComplete);\n+\t\trunWithChecks(() -> serializer.writeHeader(dataStream));\n+\t}\n+\n+\tvoid writeInput(InputChannelInfo info, Buffer... flinkBuffers) throws Exception {\n+\t\twrite(inputChannelOffsets, info, flinkBuffers, !allInputsReceived);\n+\t}\n+\n+\tvoid writeOutput(ResultSubpartitionInfo info, Buffer[] flinkBuffers) throws Exception {\n+\t\twrite(resultSubpartitionOffsets, info, flinkBuffers, !allOutputsReceived);\n+\t}\n+\n+\tprivate <K> void write(Map<K, List<Long>> offsets, K key, Buffer[] flinkBuffers, boolean precondition) throws Exception {\n+\t\ttry {\n+\t\t\tif (result.isDone()) {\n+\t\t\t\treturn;\n+\t\t\t}\n+\t\t\trunWithChecks(() -> {\n+\t\t\t\tcheckState(precondition);\n+\t\t\t\toffsets\n+\t\t\t\t\t.computeIfAbsent(key, unused -> new ArrayList<>())\n+\t\t\t\t\t.add(checkpointStream.getPos());\n+\t\t\t\tserializer.writeData(dataStream, flinkBuffers);\n+\t\t\t});\n+\t\t} finally {\n+\t\t\tfor (Buffer flinkBuffer : flinkBuffers) {\n+\t\t\t\tflinkBuffer.recycleBuffer();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tvoid completeInput() throws Exception {\n+\t\tLOG.debug(\"complete input, output completed: {}\", allOutputsReceived);\n+\t\tcomplete(!allInputsReceived, () -> allInputsReceived = true);\n+\t}\n+\n+\tvoid completeOutput() throws Exception {\n+\t\tLOG.debug(\"complete output, input completed: {}\", allInputsReceived);\n+\t\tcomplete(!allOutputsReceived, () -> allOutputsReceived = true);\n+\t}\n+\n+\tprivate void complete(boolean precondition, RunnableWithException complete) throws Exception {\n+\t\tif (result.isDone()) {\n+\t\t\t// likely after abort - only need to set the flag run onComplete callback\n+\t\t\tdoComplete(precondition, complete, onComplete);\n+\t\t} else {\n+\t\t\trunWithChecks(() -> doComplete(precondition, complete, onComplete, this::finishWriteAndResult));\n+\t\t}\n+\t}\n+\n+\tprivate void finishWriteAndResult() throws IOException {\n+\t\tdataStream.flush();\n+\t\tStreamStateHandle underlying = checkpointStream.closeAndGetHandle();\n+\t\tcomplete(\n+\t\t\t\tresult.inputChannelStateHandles,\n+\t\t\t\tinputChannelOffsets,\n+\t\t\t\t(chan, offsets) -> new InputChannelStateHandle(chan, underlying, offsets));\n+\t\tcomplete(\n+\t\t\t\tresult.resultSubpartitionStateHandles,\n+\t\t\t\tresultSubpartitionOffsets,\n+\t\t\t\t(chan, offsets) -> new ResultSubpartitionStateHandle(chan, underlying, offsets));\n+\t}\n+\n+\tprivate void doComplete(boolean precondition, RunnableWithException complete, RunnableWithException... callbacks) throws Exception {\n+\t\tPreconditions.checkArgument(precondition);\n+\t\tcomplete.run();\n+\t\tif (allInputsReceived && allOutputsReceived) {\n+\t\t\tfor (RunnableWithException callback : callbacks) {\n+\t\t\t\tcallback.run();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate <I, H extends AbstractChannelStateHandle<I>> void complete(\n+\t\t\tCompletableFuture<Collection<H>> future,\n+\t\t\tMap<I, List<Long>> offsets,\n+\t\t\tBiFunction<I, List<Long>, H> buildHandle) {\n+\t\tfinal Collection<H> handles = new ArrayList<>();\n+\t\tfor (Map.Entry<I, List<Long>> e : offsets.entrySet()) {\n+\t\t\thandles.add(buildHandle.apply(e.getKey(), e.getValue()));\n+\t\t}\n+\t\tfuture.complete(handles);\n+\t\tLOG.debug(\"channel state write completed, checkpointId: {}, handles: {}\", checkpointId, handles);\n+\t}\n+\n+\tprivate void runWithChecks(RunnableWithException r) throws Exception {\n+\t\ttry {\n+\t\t\tcheckState(!result.isDone(), \"result is already completed\", result);\n+\t\t\tr.run();\n+\t\t} catch (Exception e) {\n+\t\t\tfail(e);\n+\t\t\tthrow e;\n+\t\t}\n+\t}\n+\n+\tpublic void fail(Throwable e) throws Exception {\n+\t\tresult.fail(e);\n+\t\tcheckpointStream.close();\n+\t\tdataStream.close();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 200}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTEwOTE1Nw==", "bodyText": "Yes, but in that case closing of dataStream doesn't matter.", "url": "https://github.com/apache/flink/pull/11515#discussion_r405109157", "createdAt": "2020-04-07T20:59:18Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateCheckpointWriter.java", "diffHunk": "@@ -0,0 +1,203 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory.CheckpointStateOutputStream;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.runtime.state.ResultSubpartitionStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.BiFunction;\n+\n+import static org.apache.flink.runtime.state.CheckpointedStateScope.EXCLUSIVE;\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * Writes channel state for a specific checkpoint-subtask-attempt triple.\n+ */\n+@NotThreadSafe\n+class ChannelStateCheckpointWriter {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateCheckpointWriter.class);\n+\n+\tprivate final DataOutputStream dataStream;\n+\tprivate final CheckpointStateOutputStream checkpointStream;\n+\tprivate final ChannelStateWriteResult result;\n+\tprivate final Map<InputChannelInfo, List<Long>> inputChannelOffsets = new HashMap<>();\n+\tprivate final Map<ResultSubpartitionInfo, List<Long>> resultSubpartitionOffsets = new HashMap<>();\n+\tprivate final ChannelStateSerializer serializer;\n+\tprivate final long checkpointId;\n+\tprivate boolean allInputsReceived = false;\n+\tprivate boolean allOutputsReceived = false;\n+\tprivate final RunnableWithException onComplete;\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tCheckpointStartRequest startCheckpointItem,\n+\t\t\tCheckpointStreamFactory streamFactory,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnableWithException onComplete) throws Exception {\n+\t\tthis(\n+\t\t\tstartCheckpointItem.getCheckpointId(),\n+\t\t\tstartCheckpointItem.getTargetResult(),\n+\t\t\tstreamFactory.createCheckpointStateOutputStream(EXCLUSIVE),\n+\t\t\tserializer,\n+\t\t\tonComplete);\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tCheckpointStateOutputStream stream,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnableWithException onComplete) throws Exception {\n+\t\tthis(checkpointId, result, serializer, onComplete, stream, new DataOutputStream(stream));\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnableWithException onComplete,\n+\t\t\tCheckpointStateOutputStream checkpointStateOutputStream,\n+\t\t\tDataOutputStream dataStream) throws Exception {\n+\t\tthis.checkpointId = checkpointId;\n+\t\tthis.result = checkNotNull(result);\n+\t\tthis.checkpointStream = checkNotNull(checkpointStateOutputStream);\n+\t\tthis.serializer = checkNotNull(serializer);\n+\t\tthis.dataStream = checkNotNull(dataStream);\n+\t\tthis.onComplete = checkNotNull(onComplete);\n+\t\trunWithChecks(() -> serializer.writeHeader(dataStream));\n+\t}\n+\n+\tvoid writeInput(InputChannelInfo info, Buffer... flinkBuffers) throws Exception {\n+\t\twrite(inputChannelOffsets, info, flinkBuffers, !allInputsReceived);\n+\t}\n+\n+\tvoid writeOutput(ResultSubpartitionInfo info, Buffer[] flinkBuffers) throws Exception {\n+\t\twrite(resultSubpartitionOffsets, info, flinkBuffers, !allOutputsReceived);\n+\t}\n+\n+\tprivate <K> void write(Map<K, List<Long>> offsets, K key, Buffer[] flinkBuffers, boolean precondition) throws Exception {\n+\t\ttry {\n+\t\t\tif (result.isDone()) {\n+\t\t\t\treturn;\n+\t\t\t}\n+\t\t\trunWithChecks(() -> {\n+\t\t\t\tcheckState(precondition);\n+\t\t\t\toffsets\n+\t\t\t\t\t.computeIfAbsent(key, unused -> new ArrayList<>())\n+\t\t\t\t\t.add(checkpointStream.getPos());\n+\t\t\t\tserializer.writeData(dataStream, flinkBuffers);\n+\t\t\t});\n+\t\t} finally {\n+\t\t\tfor (Buffer flinkBuffer : flinkBuffers) {\n+\t\t\t\tflinkBuffer.recycleBuffer();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tvoid completeInput() throws Exception {\n+\t\tLOG.debug(\"complete input, output completed: {}\", allOutputsReceived);\n+\t\tcomplete(!allInputsReceived, () -> allInputsReceived = true);\n+\t}\n+\n+\tvoid completeOutput() throws Exception {\n+\t\tLOG.debug(\"complete output, input completed: {}\", allInputsReceived);\n+\t\tcomplete(!allOutputsReceived, () -> allOutputsReceived = true);\n+\t}\n+\n+\tprivate void complete(boolean precondition, RunnableWithException complete) throws Exception {\n+\t\tif (result.isDone()) {\n+\t\t\t// likely after abort - only need to set the flag run onComplete callback\n+\t\t\tdoComplete(precondition, complete, onComplete);\n+\t\t} else {\n+\t\t\trunWithChecks(() -> doComplete(precondition, complete, onComplete, this::finishWriteAndResult));\n+\t\t}\n+\t}\n+\n+\tprivate void finishWriteAndResult() throws IOException {\n+\t\tdataStream.flush();\n+\t\tStreamStateHandle underlying = checkpointStream.closeAndGetHandle();\n+\t\tcomplete(\n+\t\t\t\tresult.inputChannelStateHandles,\n+\t\t\t\tinputChannelOffsets,\n+\t\t\t\t(chan, offsets) -> new InputChannelStateHandle(chan, underlying, offsets));\n+\t\tcomplete(\n+\t\t\t\tresult.resultSubpartitionStateHandles,\n+\t\t\t\tresultSubpartitionOffsets,\n+\t\t\t\t(chan, offsets) -> new ResultSubpartitionStateHandle(chan, underlying, offsets));\n+\t}\n+\n+\tprivate void doComplete(boolean precondition, RunnableWithException complete, RunnableWithException... callbacks) throws Exception {\n+\t\tPreconditions.checkArgument(precondition);\n+\t\tcomplete.run();\n+\t\tif (allInputsReceived && allOutputsReceived) {\n+\t\t\tfor (RunnableWithException callback : callbacks) {\n+\t\t\t\tcallback.run();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate <I, H extends AbstractChannelStateHandle<I>> void complete(\n+\t\t\tCompletableFuture<Collection<H>> future,\n+\t\t\tMap<I, List<Long>> offsets,\n+\t\t\tBiFunction<I, List<Long>, H> buildHandle) {\n+\t\tfinal Collection<H> handles = new ArrayList<>();\n+\t\tfor (Map.Entry<I, List<Long>> e : offsets.entrySet()) {\n+\t\t\thandles.add(buildHandle.apply(e.getKey(), e.getValue()));\n+\t\t}\n+\t\tfuture.complete(handles);\n+\t\tLOG.debug(\"channel state write completed, checkpointId: {}, handles: {}\", checkpointId, handles);\n+\t}\n+\n+\tprivate void runWithChecks(RunnableWithException r) throws Exception {\n+\t\ttry {\n+\t\t\tcheckState(!result.isDone(), \"result is already completed\", result);\n+\t\t\tr.run();\n+\t\t} catch (Exception e) {\n+\t\t\tfail(e);\n+\t\t\tthrow e;\n+\t\t}\n+\t}\n+\n+\tpublic void fail(Throwable e) throws Exception {\n+\t\tresult.fail(e);\n+\t\tcheckpointStream.close();\n+\t\tdataStream.close();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDkzMjAyOQ=="}, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 200}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxMjk2NDI1OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNjo1OToyMlrOGCNPcg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNjo1OToyMlrOGCNPcg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk2NzI4Mg==", "bodyText": "nit: adjust the description because we only return the size of state in bytes now.", "url": "https://github.com/apache/flink/pull/11515#discussion_r404967282", "createdAt": "2020-04-07T16:59:22Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,182 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\tint readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\t/**\n+\t * Read up to <code>bytesToRead</code> bytes into this buffer from the given {@link InputStream}.\n+\t * @return     the total number of bytes read into this buffer.\n+\t */\n+\tint writeBytes(InputStream input, int bytesToRead) throws IOException;\n+\n+\tstatic ChannelStateByteBuffer wrap(Buffer buffer) {\n+\t\treturn new ChannelStateByteBuffer() {\n+\n+\t\t\tprivate final ByteBuf byteBuf = buffer.asByteBuf();\n+\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn byteBuf.isWritable();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\treturn byteBuf.writeBytes(input, Math.min(bytesToRead, byteBuf.writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(BufferBuilder bufferBuilder) {\n+\t\tfinal byte[] buf = new byte[1024];\n+\t\treturn new ChannelStateByteBuffer() {\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn !bufferBuilder.isFull();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\tint left = bytesToRead;\n+\t\t\t\tfor (int toRead = getToRead(left); toRead > 0; toRead = getToRead(left)) {\n+\t\t\t\t\tint read = input.read(buf, 0, toRead);\n+\t\t\t\t\tint copied = bufferBuilder.append(java.nio.ByteBuffer.wrap(buf, 0, read));\n+\t\t\t\t\tPreconditions.checkState(copied == read);\n+\t\t\t\t\tleft -= read;\n+\t\t\t\t}\n+\t\t\t\tbufferBuilder.commit();\n+\t\t\t\treturn bytesToRead - left;\n+\t\t\t}\n+\n+\t\t\tprivate int getToRead(int bytesToRead) {\n+\t\t\t\treturn min(bytesToRead, min(buf.length, bufferBuilder.getWritableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(byte[] bytes) {\n+\t\treturn new ChannelStateByteBuffer() {\n+\t\t\tprivate int written = 0;\n+\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn written < bytes.length;\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\tfinal int bytesRead = input.read(bytes, written, bytes.length - written);\n+\t\t\t\twritten += bytesRead;\n+\t\t\t\treturn bytesRead;\n+\t\t\t}\n+\t\t};\n+\t}\n+}\n+\n+class ChannelStateSerializerImpl implements ChannelStateSerializer, ChannelStateDeserializer {\n+\tprivate static final int SERIALIZATION_VERSION = 0;\n+\n+\t@Override\n+\tpublic void writeHeader(DataOutputStream dataStream) throws IOException {\n+\t\tdataStream.writeInt(SERIALIZATION_VERSION);\n+\t}\n+\n+\t@Override\n+\tpublic void writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException {\n+\t\tstream.writeInt(getSize(flinkBuffers));\n+\t\tfor (Buffer buffer : flinkBuffers) {\n+\t\t\tByteBuf nettyByteBuf = buffer.asByteBuf();\n+\t\t\tnettyByteBuf.getBytes(nettyByteBuf.readerIndex(), stream, nettyByteBuf.readableBytes());\n+\t\t}\n+\t}\n+\n+\tprivate int getSize(Buffer[] buffers) {\n+\t\tint len = 0;\n+\t\tfor (Buffer buffer : buffers) {\n+\t\t\tlen = addExact(len, buffer.readableBytes());\n+\t\t}\n+\t\treturn len;\n+\t}\n+\n+\t@Override\n+\tpublic void readHeader(InputStream stream) throws IOException {\n+\t\tint version = readInt(stream);\n+\t\tPreconditions.checkArgument(version == SERIALIZATION_VERSION, \"unsupported version: \" + version);\n+\t}\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 165}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxMzExNzA2OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateStreamReader.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNzozNzoxN1rOGCOvYg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxMDo1NDoyN1rOGCp3XA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk5MTg0Mg==", "bodyText": "Also not sure if we should add suppression for non-standard warnings (e.g. unchecked). Everyone has different settings and the code might be very cluttered if everyone adds these suppressions. And then there is the warning for unused suppressions, which turns it into a recursive mess.", "url": "https://github.com/apache/flink/pull/11515#discussion_r404991842", "createdAt": "2020-04-07T17:37:17Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateStreamReader.java", "diffHunk": "@@ -0,0 +1,111 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateByteBuffer.wrap;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.HAS_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+\n+/**\n+ * Reads the state of a single channel pointed by {@link org.apache.flink.runtime.state.AbstractChannelStateHandle AbstractChannelStateHandle}.\n+ * Once all data is read, this class can't be used anymore.\n+ * Uses {@link RefCountingFSDataInputStream} internally.\n+ */\n+@NotThreadSafe\n+class ChannelStateStreamReader implements Closeable {\n+\n+\tprivate final RefCountingFSDataInputStream stream;\n+\tprivate final ChannelStateDeserializer serializer;\n+\tprivate final Queue<Long> offsets;\n+\tprivate int remainingBytes = -1;\n+\tprivate boolean closed = false;\n+\n+\tChannelStateStreamReader(AbstractChannelStateHandle<?> handle, RefCountingFSDataInputStreamFactory streamFactory) {\n+\t\tthis(streamFactory.getOrCreate(handle), handle.getOffsets(), streamFactory.getSerializer());\n+\t}\n+\n+\tprivate ChannelStateStreamReader(RefCountingFSDataInputStream stream, List<Long> offsets, ChannelStateDeserializer serializer) {\n+\t\tthis.stream = stream;\n+\t\tthis.stream.incRef();\n+\t\tthis.serializer = serializer;\n+\t\tthis.offsets = new LinkedList<>(offsets);\n+\t}\n+\n+\tReadResult readInto(Buffer buffer) throws IOException {\n+\t\treturn readInto(wrap(buffer));\n+\t}\n+\n+\tReadResult readInto(BufferBuilder bufferBuilder) throws IOException {\n+\t\treturn readInto(wrap(bufferBuilder));\n+\t}\n+\n+\tprivate ReadResult readInto(ChannelStateByteBuffer buffer) throws IOException {\n+\t\tPreconditions.checkState(!closed, \"reader is closed\");\n+\t\treadWhilePossible(buffer);\n+\t\tif (haveMoreData()) {\n+\t\t\treturn HAS_MORE_DATA;\n+\t\t} else {\n+\t\t\tclosed = true;\n+\t\t\tstream.decRef();\n+\t\t\treturn NO_MORE_DATA;\n+\t\t}\n+\t}\n+\n+\tprivate void readWhilePossible(ChannelStateByteBuffer buffer) throws IOException {\n+\t\twhile (haveMoreData() && buffer.isWritable()) {\n+\t\t\tif (remainingBytes <= 0) {\n+\t\t\t\tadvanceOffset();\n+\t\t\t}\n+\t\t\tint bytesRead = serializer.readData(stream, buffer, remainingBytes);\n+\t\t\tremainingBytes -= bytesRead;\n+\t\t}\n+\t}\n+\n+\tprivate boolean haveMoreData() {\n+\t\treturn remainingBytes > 0 || !offsets.isEmpty();\n+\t}\n+\n+\t@SuppressWarnings(\"ConstantConditions\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQyNzM3Mg==", "bodyText": "SuppressWarnings is a compiler annotation so it can be ignored by humans.\nCompiler warnings, on the other hand, are intended for humans and shouldn't be ignored.\nTherefore useless warnings produce clutter and unsupported SuppressWarnings not.", "url": "https://github.com/apache/flink/pull/11515#discussion_r405427372", "createdAt": "2020-04-08T10:37:42Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateStreamReader.java", "diffHunk": "@@ -0,0 +1,111 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateByteBuffer.wrap;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.HAS_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+\n+/**\n+ * Reads the state of a single channel pointed by {@link org.apache.flink.runtime.state.AbstractChannelStateHandle AbstractChannelStateHandle}.\n+ * Once all data is read, this class can't be used anymore.\n+ * Uses {@link RefCountingFSDataInputStream} internally.\n+ */\n+@NotThreadSafe\n+class ChannelStateStreamReader implements Closeable {\n+\n+\tprivate final RefCountingFSDataInputStream stream;\n+\tprivate final ChannelStateDeserializer serializer;\n+\tprivate final Queue<Long> offsets;\n+\tprivate int remainingBytes = -1;\n+\tprivate boolean closed = false;\n+\n+\tChannelStateStreamReader(AbstractChannelStateHandle<?> handle, RefCountingFSDataInputStreamFactory streamFactory) {\n+\t\tthis(streamFactory.getOrCreate(handle), handle.getOffsets(), streamFactory.getSerializer());\n+\t}\n+\n+\tprivate ChannelStateStreamReader(RefCountingFSDataInputStream stream, List<Long> offsets, ChannelStateDeserializer serializer) {\n+\t\tthis.stream = stream;\n+\t\tthis.stream.incRef();\n+\t\tthis.serializer = serializer;\n+\t\tthis.offsets = new LinkedList<>(offsets);\n+\t}\n+\n+\tReadResult readInto(Buffer buffer) throws IOException {\n+\t\treturn readInto(wrap(buffer));\n+\t}\n+\n+\tReadResult readInto(BufferBuilder bufferBuilder) throws IOException {\n+\t\treturn readInto(wrap(bufferBuilder));\n+\t}\n+\n+\tprivate ReadResult readInto(ChannelStateByteBuffer buffer) throws IOException {\n+\t\tPreconditions.checkState(!closed, \"reader is closed\");\n+\t\treadWhilePossible(buffer);\n+\t\tif (haveMoreData()) {\n+\t\t\treturn HAS_MORE_DATA;\n+\t\t} else {\n+\t\t\tclosed = true;\n+\t\t\tstream.decRef();\n+\t\t\treturn NO_MORE_DATA;\n+\t\t}\n+\t}\n+\n+\tprivate void readWhilePossible(ChannelStateByteBuffer buffer) throws IOException {\n+\t\twhile (haveMoreData() && buffer.isWritable()) {\n+\t\t\tif (remainingBytes <= 0) {\n+\t\t\t\tadvanceOffset();\n+\t\t\t}\n+\t\t\tint bytesRead = serializer.readData(stream, buffer, remainingBytes);\n+\t\t\tremainingBytes -= bytesRead;\n+\t\t}\n+\t}\n+\n+\tprivate boolean haveMoreData() {\n+\t\treturn remainingBytes > 0 || !offsets.isEmpty();\n+\t}\n+\n+\t@SuppressWarnings(\"ConstantConditions\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk5MTg0Mg=="}, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQzNjI1Mg==", "bodyText": "My main point was that the specific warning is not a standard java compiler, but coming from IntelliJ and depends on your settings (I don't see this warning).\nIf I enable warning for unused suppression, I get a compiler warning for your suppression and I don't want to argue which settings are inherently better.\nSo I suggest to not suppress \"ConstantConditions\", but only standard suppressions like \"unchecked\".", "url": "https://github.com/apache/flink/pull/11515#discussion_r405436252", "createdAt": "2020-04-08T10:54:27Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateStreamReader.java", "diffHunk": "@@ -0,0 +1,111 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateByteBuffer.wrap;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.HAS_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+\n+/**\n+ * Reads the state of a single channel pointed by {@link org.apache.flink.runtime.state.AbstractChannelStateHandle AbstractChannelStateHandle}.\n+ * Once all data is read, this class can't be used anymore.\n+ * Uses {@link RefCountingFSDataInputStream} internally.\n+ */\n+@NotThreadSafe\n+class ChannelStateStreamReader implements Closeable {\n+\n+\tprivate final RefCountingFSDataInputStream stream;\n+\tprivate final ChannelStateDeserializer serializer;\n+\tprivate final Queue<Long> offsets;\n+\tprivate int remainingBytes = -1;\n+\tprivate boolean closed = false;\n+\n+\tChannelStateStreamReader(AbstractChannelStateHandle<?> handle, RefCountingFSDataInputStreamFactory streamFactory) {\n+\t\tthis(streamFactory.getOrCreate(handle), handle.getOffsets(), streamFactory.getSerializer());\n+\t}\n+\n+\tprivate ChannelStateStreamReader(RefCountingFSDataInputStream stream, List<Long> offsets, ChannelStateDeserializer serializer) {\n+\t\tthis.stream = stream;\n+\t\tthis.stream.incRef();\n+\t\tthis.serializer = serializer;\n+\t\tthis.offsets = new LinkedList<>(offsets);\n+\t}\n+\n+\tReadResult readInto(Buffer buffer) throws IOException {\n+\t\treturn readInto(wrap(buffer));\n+\t}\n+\n+\tReadResult readInto(BufferBuilder bufferBuilder) throws IOException {\n+\t\treturn readInto(wrap(bufferBuilder));\n+\t}\n+\n+\tprivate ReadResult readInto(ChannelStateByteBuffer buffer) throws IOException {\n+\t\tPreconditions.checkState(!closed, \"reader is closed\");\n+\t\treadWhilePossible(buffer);\n+\t\tif (haveMoreData()) {\n+\t\t\treturn HAS_MORE_DATA;\n+\t\t} else {\n+\t\t\tclosed = true;\n+\t\t\tstream.decRef();\n+\t\t\treturn NO_MORE_DATA;\n+\t\t}\n+\t}\n+\n+\tprivate void readWhilePossible(ChannelStateByteBuffer buffer) throws IOException {\n+\t\twhile (haveMoreData() && buffer.isWritable()) {\n+\t\t\tif (remainingBytes <= 0) {\n+\t\t\t\tadvanceOffset();\n+\t\t\t}\n+\t\t\tint bytesRead = serializer.readData(stream, buffer, remainingBytes);\n+\t\t\tremainingBytes -= bytesRead;\n+\t\t}\n+\t}\n+\n+\tprivate boolean haveMoreData() {\n+\t\treturn remainingBytes > 0 || !offsets.isEmpty();\n+\t}\n+\n+\t@SuppressWarnings(\"ConstantConditions\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk5MTg0Mg=="}, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 98}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxMzE0NjQ2OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestDispatcherImpl.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNzo0NDo1NFrOGCPB_Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNzo0NDo1NFrOGCPB_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk5NjYwNQ==", "bodyText": "nit: initialize field directly? (not sure what the default is, just pointing out)", "url": "https://github.com/apache/flink/pull/11515#discussion_r404996605", "createdAt": "2020-04-07T17:44:54Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestDispatcherImpl.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+/**\n+ * Maintains a set of {@link ChannelStateCheckpointWriter writers} per checkpoint and translates incoming\n+ * {@link ChannelStateWriteRequest requests} to their corresponding methods.\n+ */\n+final class ChannelStateWriteRequestDispatcherImpl implements ChannelStateWriteRequestDispatcher {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriteRequestDispatcherImpl.class);\n+\n+\tprivate final Map<Long, ChannelStateCheckpointWriter> writers; // limited indirectly by results max size\n+\tprivate final CheckpointStorageWorkerView streamFactoryResolver;\n+\tprivate final ChannelStateSerializer serializer;\n+\n+\tChannelStateWriteRequestDispatcherImpl(CheckpointStorageWorkerView streamFactoryResolver, ChannelStateSerializer serializer) {\n+\t\tthis.writers = new HashMap<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxMzE0OTc1OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestDispatcherImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNzo0NTo0OFrOGCPEFA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNzo0NTo0OFrOGCPEFA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk5NzE0MA==", "bodyText": "nit: add string message (containing checkpoint id for easier debugging).", "url": "https://github.com/apache/flink/pull/11515#discussion_r404997140", "createdAt": "2020-04-07T17:45:48Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestDispatcherImpl.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+/**\n+ * Maintains a set of {@link ChannelStateCheckpointWriter writers} per checkpoint and translates incoming\n+ * {@link ChannelStateWriteRequest requests} to their corresponding methods.\n+ */\n+final class ChannelStateWriteRequestDispatcherImpl implements ChannelStateWriteRequestDispatcher {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriteRequestDispatcherImpl.class);\n+\n+\tprivate final Map<Long, ChannelStateCheckpointWriter> writers; // limited indirectly by results max size\n+\tprivate final CheckpointStorageWorkerView streamFactoryResolver;\n+\tprivate final ChannelStateSerializer serializer;\n+\n+\tChannelStateWriteRequestDispatcherImpl(CheckpointStorageWorkerView streamFactoryResolver, ChannelStateSerializer serializer) {\n+\t\tthis.writers = new HashMap<>();\n+\t\tthis.streamFactoryResolver = streamFactoryResolver;\n+\t\tthis.serializer = serializer;\n+\t}\n+\n+\t@Override\n+\tpublic void dispatch(ChannelStateWriteRequest request) throws Exception {\n+\t\tLOG.debug(\"process {}\", request);\n+\t\ttry {\n+\t\t\tdispatchInternal(request);\n+\t\t} catch (Exception e) {\n+\t\t\trequest.cancel(e);\n+\t\t\tthrow e;\n+\t\t}\n+\t}\n+\n+\tprivate void dispatchInternal(ChannelStateWriteRequest request) throws Exception {\n+\t\tif (request instanceof CheckpointStartRequest) {\n+\t\t\tPreconditions.checkState(!writers.containsKey(request.getCheckpointId()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 59}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxMzE1NTcwOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestDispatcherImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNzo0NzoyNFrOGCPH2A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNzo0NzoyNFrOGCPH2A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk5ODEwNA==", "bodyText": "nit: forEach is not saving anything on for-loop and the latter is usually easier to read for java guys.", "url": "https://github.com/apache/flink/pull/11515#discussion_r404998104", "createdAt": "2020-04-07T17:47:24Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestDispatcherImpl.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+/**\n+ * Maintains a set of {@link ChannelStateCheckpointWriter writers} per checkpoint and translates incoming\n+ * {@link ChannelStateWriteRequest requests} to their corresponding methods.\n+ */\n+final class ChannelStateWriteRequestDispatcherImpl implements ChannelStateWriteRequestDispatcher {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriteRequestDispatcherImpl.class);\n+\n+\tprivate final Map<Long, ChannelStateCheckpointWriter> writers; // limited indirectly by results max size\n+\tprivate final CheckpointStorageWorkerView streamFactoryResolver;\n+\tprivate final ChannelStateSerializer serializer;\n+\n+\tChannelStateWriteRequestDispatcherImpl(CheckpointStorageWorkerView streamFactoryResolver, ChannelStateSerializer serializer) {\n+\t\tthis.writers = new HashMap<>();\n+\t\tthis.streamFactoryResolver = streamFactoryResolver;\n+\t\tthis.serializer = serializer;\n+\t}\n+\n+\t@Override\n+\tpublic void dispatch(ChannelStateWriteRequest request) throws Exception {\n+\t\tLOG.debug(\"process {}\", request);\n+\t\ttry {\n+\t\t\tdispatchInternal(request);\n+\t\t} catch (Exception e) {\n+\t\t\trequest.cancel(e);\n+\t\t\tthrow e;\n+\t\t}\n+\t}\n+\n+\tprivate void dispatchInternal(ChannelStateWriteRequest request) throws Exception {\n+\t\tif (request instanceof CheckpointStartRequest) {\n+\t\t\tPreconditions.checkState(!writers.containsKey(request.getCheckpointId()));\n+\t\t\twriters.put(request.getCheckpointId(), buildWriter((CheckpointStartRequest) request));\n+\t\t} else if (request instanceof CheckpointInProgressRequest) {\n+\t\t\tChannelStateCheckpointWriter writer = writers.get(request.getCheckpointId());\n+\t\t\tCheckpointInProgressRequest req = (CheckpointInProgressRequest) request;\n+\t\t\tif (writer == null) {\n+\t\t\t\treq.onWriterMissing();\n+\t\t\t} else {\n+\t\t\t\treq.execute(writer);\n+\t\t\t}\n+\t\t} else {\n+\t\t\tthrow new IllegalArgumentException(\"unknown request type: \" + request);\n+\t\t}\n+\t}\n+\n+\tprivate ChannelStateCheckpointWriter buildWriter(CheckpointStartRequest request) throws Exception {\n+\t\treturn new ChannelStateCheckpointWriter(\n+\t\t\trequest,\n+\t\t\tstreamFactoryResolver.resolveCheckpointStorageLocation(request.getCheckpointId(), request.getLocationReference()),\n+\t\t\tserializer,\n+\t\t\t() -> writers.remove(request.getCheckpointId()));\n+\t}\n+\n+\t@Override\n+\tpublic void close(Throwable cause) {\n+\t\twriters.values().forEach(writer -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 84}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxMzE2MTg5OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestDispatcher.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNzo0ODo1M1rOGCPLvw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNzo0ODo1M1rOGCPLvw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk5OTEwMw==", "bodyText": "close is a strange name for something that belongs to the exception handling. Why not call it fail like in the writer?", "url": "https://github.com/apache/flink/pull/11515#discussion_r404999103", "createdAt": "2020-04-07T17:48:53Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestDispatcher.java", "diffHunk": "@@ -0,0 +1,36 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+interface ChannelStateWriteRequestDispatcher {\n+\n+\tvoid dispatch(ChannelStateWriteRequest request) throws Exception;\n+\n+\tvoid close(Throwable cause);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxMzE2NDAxOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestExecutor.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNzo0OTozMVrOGCPNEA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNzo0OTozMVrOGCPNEA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk5OTQ0MA==", "bodyText": "nit: you don't use empty lines on other classes.", "url": "https://github.com/apache/flink/pull/11515#discussion_r404999440", "createdAt": "2020-04-07T17:49:31Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestExecutor.java", "diffHunk": "@@ -0,0 +1,49 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import java.io.Closeable;\n+\n+/**\n+ * Executes {@link ChannelStateWriteRequest}s potentially asynchronously. An exception thrown during the execution\n+ * should be re-thrown on any next call.\n+ */\n+interface ChannelStateWriteRequestExecutor extends Closeable {\n+\n+\t/**\n+\t * @throws IllegalStateException if called more than once or after {@link #close()}\n+\t */\n+\tvoid start() throws IllegalStateException;\n+\n+\t/**\n+\t * Send {@link ChannelStateWriteRequest} to this worker. If this method throws an exception then client must\n+\t * {@link ChannelStateWriteRequest#cancel cancel} it.\n+\t * @throws IllegalStateException if worker is not running\n+\t * @throws Exception if any exception occurred during processing this or other items previously\n+\t */\n+\tvoid submit(ChannelStateWriteRequest r) throws Exception;\n+\n+\t/**\n+\t * Send {@link ChannelStateWriteRequest} to this worker to be processed first. If this method throws an exception then client must\n+\t * {@link ChannelStateWriteRequest#cancel cancel} it.\n+\t * @throws IllegalStateException if worker is not running\n+\t * @throws Exception if any exception occurred during processing this or other items previously\n+\t */\n+\tvoid submitPriority(ChannelStateWriteRequest r) throws Exception;\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 48}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxMzIwNDcxOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestExecutorImpl.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxODowMDoyMlrOGCPn9w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QyMToyMDowMlrOGCWjkg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAwNjMyNw==", "bodyText": "Is there a particular reason to bound the optionally-bouded LinkedBlockingDeque? In the end, we are most likely limited by the number of buffers anyways and I'd argue that the overhead of your data structures is minimal compared to them.", "url": "https://github.com/apache/flink/pull/11515#discussion_r405006327", "createdAt": "2020-04-07T18:00:22Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestExecutorImpl.java", "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.BlockingDeque;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.LinkedBlockingDeque;\n+\n+/**\n+ * Executes {@link ChannelStateWriteRequest}s in a separate thread. Any exception occurred during execution causes this\n+ * thread to stop and the exception to be re-thrown on any subsequent call.\n+ */\n+@ThreadSafe\n+class ChannelStateWriteRequestExecutorImpl implements ChannelStateWriteRequestExecutor {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriteRequestExecutorImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10_000;\n+\n+\tprivate final ChannelStateWriteRequestDispatcher dispatcher;\n+\tprivate final BlockingDeque<ChannelStateWriteRequest> deque;\n+\tprivate final Thread thread;\n+\tprivate volatile Exception thrown = null;\n+\tprivate volatile boolean wasClosed = false;\n+\n+\tChannelStateWriteRequestExecutorImpl(ChannelStateWriteRequestDispatcher dispatcher) {\n+\t\tthis(dispatcher, new LinkedBlockingDeque<>(DEFAULT_HANDOVER_CAPACITY));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTExOTg5MA==", "bodyText": "If the same buffer can be enqueued multiple times, then this overhead can be significant.\nIt can happen because of a bug or (probably) with multiple checkpoints in-flight but without incremental checkpointing.\nIn such cases we can:\n\nthrow an exception (current behavior)\nblock\nallow to proceed (possibly exhausting memory / gc)\n\n(and no limit means Integer.MAX_VALUE, so it's just a higher limit)", "url": "https://github.com/apache/flink/pull/11515#discussion_r405119890", "createdAt": "2020-04-07T21:20:02Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestExecutorImpl.java", "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.BlockingDeque;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.LinkedBlockingDeque;\n+\n+/**\n+ * Executes {@link ChannelStateWriteRequest}s in a separate thread. Any exception occurred during execution causes this\n+ * thread to stop and the exception to be re-thrown on any subsequent call.\n+ */\n+@ThreadSafe\n+class ChannelStateWriteRequestExecutorImpl implements ChannelStateWriteRequestExecutor {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriteRequestExecutorImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10_000;\n+\n+\tprivate final ChannelStateWriteRequestDispatcher dispatcher;\n+\tprivate final BlockingDeque<ChannelStateWriteRequest> deque;\n+\tprivate final Thread thread;\n+\tprivate volatile Exception thrown = null;\n+\tprivate volatile boolean wasClosed = false;\n+\n+\tChannelStateWriteRequestExecutorImpl(ChannelStateWriteRequestDispatcher dispatcher) {\n+\t\tthis(dispatcher, new LinkedBlockingDeque<>(DEFAULT_HANDOVER_CAPACITY));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAwNjMyNw=="}, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 53}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxMzIxOTA2OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxODowMzo1NFrOGCPxEw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxMDo1MToyOVrOGCpxOw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAwODY1OQ==", "bodyText": "Since we encountered a hard error in Flink, there is no way to proceed and I'd probably also switch checkArgument to checkState.", "url": "https://github.com/apache/flink/pull/11515#discussion_r405008659", "createdAt": "2020-04-07T18:03:54Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has by default\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ * Thread-safety: this class is thread-safe when used with a thread-safe {@link ChannelStateWriteRequestExecutor executor}\n+ * (e.g. default {@link ChannelStateWriteRequestExecutorImpl}.\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate final ChannelStateWriteRequestExecutor executor;\n+\tprivate final ConcurrentMap<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.\n+\t */\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryResolver) {\n+\t\tthis(streamFactoryResolver, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link ChannelStateSerializerImpl default} {@link ChannelStateSerializer},\n+\t * and a {@link ChannelStateWriteRequestExecutorImpl}.\n+\t *\n+\t * @param maxCheckpoints        maximum number of checkpoints to be written currently or finished but not taken yet.\n+\t * @param streamFactoryResolver a factory to obtain output stream factory for a given checkpoint\n+\t */\n+\tChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryResolver, int maxCheckpoints) {\n+\t\tthis(\n+\t\t\tnew ConcurrentHashMap<>(maxCheckpoints),\n+\t\t\tnew ChannelStateWriteRequestExecutorImpl(new ChannelStateWriteRequestDispatcherImpl(streamFactoryResolver, new ChannelStateSerializerImpl())),\n+\t\t\tmaxCheckpoints\n+\t\t);\n+\t}\n+\n+\tChannelStateWriterImpl(ConcurrentMap<Long, ChannelStateWriteResult> results, ChannelStateWriteRequestExecutor executor, int maxCheckpoints) {\n+\t\tthis.results = results;\n+\t\tthis.maxCheckpoints = maxCheckpoints;\n+\t\tthis.executor = executor;\n+\t}\n+\n+\t@Override\n+\tpublic void start(long checkpointId, CheckpointOptions checkpointOptions) {\n+\t\tLOG.debug(\"start checkpoint {} ({})\", checkpointId, checkpointOptions);\n+\t\tChannelStateWriteResult result = new ChannelStateWriteResult();\n+\t\tChannelStateWriteResult put = results.computeIfAbsent(checkpointId, id -> {\n+\t\t\tPreconditions.checkState(results.size() < maxCheckpoints, \"results.size() > maxCheckpoints\", results.size(), maxCheckpoints);\n+\t\t\tenqueue(new CheckpointStartRequest(checkpointId, result, checkpointOptions.getTargetLocation()), false);\n+\t\t\treturn result;\n+\t\t});\n+\t\tPreconditions.checkArgument(put == result, \"result future already present for checkpoint id: \" + checkpointId);\n+\t}\n+\n+\t@Override\n+\tpublic void addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add input data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)), false);\n+\t}\n+\n+\t@Override\n+\tpublic void addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add output data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)), false);\n+\t}\n+\n+\t@Override\n+\tpublic void finishInput(long checkpointId) {\n+\t\tLOG.debug(\"finish input data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeInput(checkpointId), false);\n+\t}\n+\n+\t@Override\n+\tpublic void finishOutput(long checkpointId) {\n+\t\tLOG.debug(\"finish output data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeOutput(checkpointId), false);\n+\t}\n+\n+\t@Override\n+\tpublic void abort(long checkpointId, Throwable cause) {\n+\t\tLOG.debug(\"abort, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(ChannelStateWriteRequest.abort(checkpointId, cause), true); // abort already started\n+\t\tenqueue(ChannelStateWriteRequest.abort(checkpointId, cause), false); // abort enqueued but not started\n+\t}\n+\n+\t@Override\n+\tpublic ChannelStateWriteResult getWriteResult(long checkpointId) {\n+\t\tLOG.debug(\"requested write result, checkpoint id: {}\", checkpointId);\n+\t\tChannelStateWriteResult result = results.remove(checkpointId);\n+\t\tPreconditions.checkArgument(result != null, \"channel state write result not found for checkpoint id \" + checkpointId);\n+\t\treturn result;\n+\t}\n+\n+\tpublic void open() {\n+\t\texecutor.start();\n+\t}\n+\n+\t@Override\n+\tpublic void close() throws IOException {\n+\t\tresults.clear();\n+\t\texecutor.close();\n+\t}\n+\n+\tprivate void enqueue(ChannelStateWriteRequest request, boolean atTheFront) {\n+\t\t// state check and previous errors check are performed inside the worker\n+\t\ttry {\n+\t\t\tif (atTheFront) {\n+\t\t\t\texecutor.submitPriority(request);\n+\t\t\t} else {\n+\t\t\t\texecutor.submit(request);\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\trequest.cancel(e);\n+\t\t\tthrow new RuntimeException(\"unable to send request to worker\", e);\n+\t\t}\n+\t}\n+\n+\tprivate static Buffer[] checkBufferType(Buffer... data) {\n+\t\tif (data == null) {\n+\t\t\treturn new Buffer[0];\n+\t\t}\n+\t\ttry {\n+\t\t\tfor (Buffer buffer : data) {\n+\t\t\t\tPreconditions.checkArgument(buffer.isBuffer());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 173}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQzNDY4Mw==", "bodyText": "The class itself (and its \"downstream\" classes) is still operable. It shouldn't know that it's clients aren't able to deal with this exception.", "url": "https://github.com/apache/flink/pull/11515#discussion_r405434683", "createdAt": "2020-04-08T10:51:29Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has by default\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ * Thread-safety: this class is thread-safe when used with a thread-safe {@link ChannelStateWriteRequestExecutor executor}\n+ * (e.g. default {@link ChannelStateWriteRequestExecutorImpl}.\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate final ChannelStateWriteRequestExecutor executor;\n+\tprivate final ConcurrentMap<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.\n+\t */\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryResolver) {\n+\t\tthis(streamFactoryResolver, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link ChannelStateSerializerImpl default} {@link ChannelStateSerializer},\n+\t * and a {@link ChannelStateWriteRequestExecutorImpl}.\n+\t *\n+\t * @param maxCheckpoints        maximum number of checkpoints to be written currently or finished but not taken yet.\n+\t * @param streamFactoryResolver a factory to obtain output stream factory for a given checkpoint\n+\t */\n+\tChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryResolver, int maxCheckpoints) {\n+\t\tthis(\n+\t\t\tnew ConcurrentHashMap<>(maxCheckpoints),\n+\t\t\tnew ChannelStateWriteRequestExecutorImpl(new ChannelStateWriteRequestDispatcherImpl(streamFactoryResolver, new ChannelStateSerializerImpl())),\n+\t\t\tmaxCheckpoints\n+\t\t);\n+\t}\n+\n+\tChannelStateWriterImpl(ConcurrentMap<Long, ChannelStateWriteResult> results, ChannelStateWriteRequestExecutor executor, int maxCheckpoints) {\n+\t\tthis.results = results;\n+\t\tthis.maxCheckpoints = maxCheckpoints;\n+\t\tthis.executor = executor;\n+\t}\n+\n+\t@Override\n+\tpublic void start(long checkpointId, CheckpointOptions checkpointOptions) {\n+\t\tLOG.debug(\"start checkpoint {} ({})\", checkpointId, checkpointOptions);\n+\t\tChannelStateWriteResult result = new ChannelStateWriteResult();\n+\t\tChannelStateWriteResult put = results.computeIfAbsent(checkpointId, id -> {\n+\t\t\tPreconditions.checkState(results.size() < maxCheckpoints, \"results.size() > maxCheckpoints\", results.size(), maxCheckpoints);\n+\t\t\tenqueue(new CheckpointStartRequest(checkpointId, result, checkpointOptions.getTargetLocation()), false);\n+\t\t\treturn result;\n+\t\t});\n+\t\tPreconditions.checkArgument(put == result, \"result future already present for checkpoint id: \" + checkpointId);\n+\t}\n+\n+\t@Override\n+\tpublic void addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add input data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)), false);\n+\t}\n+\n+\t@Override\n+\tpublic void addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add output data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)), false);\n+\t}\n+\n+\t@Override\n+\tpublic void finishInput(long checkpointId) {\n+\t\tLOG.debug(\"finish input data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeInput(checkpointId), false);\n+\t}\n+\n+\t@Override\n+\tpublic void finishOutput(long checkpointId) {\n+\t\tLOG.debug(\"finish output data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeOutput(checkpointId), false);\n+\t}\n+\n+\t@Override\n+\tpublic void abort(long checkpointId, Throwable cause) {\n+\t\tLOG.debug(\"abort, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(ChannelStateWriteRequest.abort(checkpointId, cause), true); // abort already started\n+\t\tenqueue(ChannelStateWriteRequest.abort(checkpointId, cause), false); // abort enqueued but not started\n+\t}\n+\n+\t@Override\n+\tpublic ChannelStateWriteResult getWriteResult(long checkpointId) {\n+\t\tLOG.debug(\"requested write result, checkpoint id: {}\", checkpointId);\n+\t\tChannelStateWriteResult result = results.remove(checkpointId);\n+\t\tPreconditions.checkArgument(result != null, \"channel state write result not found for checkpoint id \" + checkpointId);\n+\t\treturn result;\n+\t}\n+\n+\tpublic void open() {\n+\t\texecutor.start();\n+\t}\n+\n+\t@Override\n+\tpublic void close() throws IOException {\n+\t\tresults.clear();\n+\t\texecutor.close();\n+\t}\n+\n+\tprivate void enqueue(ChannelStateWriteRequest request, boolean atTheFront) {\n+\t\t// state check and previous errors check are performed inside the worker\n+\t\ttry {\n+\t\t\tif (atTheFront) {\n+\t\t\t\texecutor.submitPriority(request);\n+\t\t\t} else {\n+\t\t\t\texecutor.submit(request);\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\trequest.cancel(e);\n+\t\t\tthrow new RuntimeException(\"unable to send request to worker\", e);\n+\t\t}\n+\t}\n+\n+\tprivate static Buffer[] checkBufferType(Buffer... data) {\n+\t\tif (data == null) {\n+\t\t\treturn new Buffer[0];\n+\t\t}\n+\t\ttry {\n+\t\t\tfor (Buffer buffer : data) {\n+\t\t\t\tPreconditions.checkArgument(buffer.isBuffer());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAwODY1OQ=="}, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 173}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxMzIyNjgwOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestExecutorImplTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxODowNTo1OVrOGCP12w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxODowNTo1OVrOGCP12w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAwOTg4Mw==", "bodyText": "See my previous comment on suppressions.", "url": "https://github.com/apache/flink/pull/11515#discussion_r405009883", "createdAt": "2020-04-07T18:05:59Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestExecutorImplTest.java", "diffHunk": "@@ -0,0 +1,203 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.function.BiConsumerWithException;\n+\n+import org.junit.Test;\n+\n+import javax.annotation.Nonnull;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.concurrent.LinkedBlockingDeque;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequestDispatcher.NO_OP;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * {@link ChannelStateWriteRequestExecutorImpl} test.\n+ */\n+public class ChannelStateWriteRequestExecutorImplTest {\n+\n+\t@Test(expected = IllegalStateException.class)\n+\tpublic void testCloseAfterSubmit() throws Exception {\n+\t\ttestCloseAfterSubmit(ChannelStateWriteRequestExecutor::submit);\n+\t}\n+\n+\t@Test(expected = IllegalStateException.class)\n+\tpublic void testCloseAfterSubmitPriority() throws Exception {\n+\t\ttestCloseAfterSubmit(ChannelStateWriteRequestExecutor::submitPriority);\n+\t}\n+\n+\t@Test\n+\tpublic void testSubmitFailure() throws Exception {\n+\t\ttestSubmitFailure(ChannelStateWriteRequestExecutor::submit);\n+\t}\n+\n+\t@Test\n+\tpublic void testSubmitPriorityFailure() throws Exception {\n+\t\ttestSubmitFailure(ChannelStateWriteRequestExecutor::submitPriority);\n+\t}\n+\n+\tprivate void testCloseAfterSubmit(BiConsumerWithException<ChannelStateWriteRequestExecutor, ChannelStateWriteRequest, Exception> requestFun) throws Exception {\n+\t\tWorkerClosingDeque closingDeque = new WorkerClosingDeque();\n+\t\tChannelStateWriteRequestExecutorImpl worker = new ChannelStateWriteRequestExecutorImpl(NO_OP, closingDeque);\n+\t\tclosingDeque.setWorker(worker);\n+\t\tTestWriteRequest request = new TestWriteRequest();\n+\t\trequestFun.accept(worker, request);\n+\t\tassertTrue(closingDeque.isEmpty());\n+\t\tassertFalse(request.isCancelled());\n+\t}\n+\n+\tprivate void testSubmitFailure(BiConsumerWithException<ChannelStateWriteRequestExecutor, ChannelStateWriteRequest, Exception> submitAction) throws Exception {\n+\t\tTestWriteRequest request = new TestWriteRequest();\n+\t\tLinkedBlockingDeque<ChannelStateWriteRequest> deque = new LinkedBlockingDeque<>();\n+\t\ttry {\n+\t\t\tsubmitAction.accept(new ChannelStateWriteRequestExecutorImpl(NO_OP, deque), request);\n+\t\t} catch (IllegalStateException e) {\n+\t\t\t// expected: executor not started;\n+\t\t\treturn;\n+\t\t} finally {\n+\t\t\tassertTrue(request.cancelled);\n+\t\t\tassertTrue(deque.isEmpty());\n+\t\t}\n+\t\tthrow new RuntimeException(\"expected exception not thrown\");\n+\t}\n+\n+\t@Test\n+\t@SuppressWarnings(\"CallToThreadRun\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 86}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxMzIzMTM3OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/state/ChannelPersistenceITCase.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxODowNzoxNlrOGCP4xg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxODowNzoxNlrOGCP4xg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAxMDYzMA==", "bodyText": "Now this should be a real suppression ;)", "url": "https://github.com/apache/flink/pull/11515#discussion_r405010630", "createdAt": "2020-04-07T18:07:16Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/state/ChannelPersistenceITCase.java", "diffHunk": "@@ -0,0 +1,179 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.state;\n+\n+import org.apache.flink.core.memory.HeapMemorySegment;\n+import org.apache.flink.core.memory.MemorySegment;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.StateObjectCollection;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReaderImpl;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriterImpl;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.checkpoint.channel.ResultSubpartitionInfo;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.memory.NonPersistentMetadataCheckpointStorageLocation;\n+import org.apache.flink.util.function.BiFunctionWithException;\n+\n+import org.junit.Test;\n+\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.stream.Collectors;\n+\n+import static java.util.Collections.singletonMap;\n+import static org.apache.flink.runtime.checkpoint.CheckpointType.CHECKPOINT;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.SEQUENCE_NUMBER_UNKNOWN;\n+import static org.apache.flink.util.Preconditions.checkState;\n+import static org.junit.Assert.assertArrayEquals;\n+\n+/**\n+ * ChannelPersistenceITCase.\n+ */\n+public class ChannelPersistenceITCase {\n+\tprivate static final Random RANDOM = new Random(System.currentTimeMillis());\n+\n+\t@Test\n+\tpublic void testReadWritten() throws Exception {\n+\t\tlong checkpointId = 1L;\n+\n+\t\tInputChannelInfo inputChannelInfo = new InputChannelInfo(2, 3);\n+\t\tbyte[] inputChannelInfoData = randomBytes(1024);\n+\n+\t\tResultSubpartitionInfo resultSubpartitionInfo = new ResultSubpartitionInfo(4, 5);\n+\t\tbyte[] resultSubpartitionInfoData = randomBytes(1024);\n+\n+\t\tChannelStateWriteResult handles = write(\n+\t\t\tcheckpointId,\n+\t\t\tsingletonMap(inputChannelInfo, inputChannelInfoData),\n+\t\t\tsingletonMap(resultSubpartitionInfo, resultSubpartitionInfoData)\n+\t\t);\n+\n+\t\tassertArrayEquals(inputChannelInfoData, read(\n+\t\t\ttoTaskStateSnapshot(handles),\n+\t\t\tinputChannelInfoData.length,\n+\t\t\t(reader, mem) -> reader.readInputData(inputChannelInfo, new NetworkBuffer(mem, FreeingBufferRecycler.INSTANCE))\n+\t\t));\n+\n+\t\tassertArrayEquals(resultSubpartitionInfoData, read(\n+\t\t\ttoTaskStateSnapshot(handles),\n+\t\t\tresultSubpartitionInfoData.length,\n+\t\t\t(reader, mem) -> reader.readOutputData(resultSubpartitionInfo, new BufferBuilder(mem, FreeingBufferRecycler.INSTANCE))\n+\t\t));\n+\t}\n+\n+\tprivate byte[] randomBytes(int size) {\n+\t\tbyte[] bytes = new byte[size];\n+\t\tRANDOM.nextBytes(bytes);\n+\t\treturn bytes;\n+\t}\n+\n+\tprivate ChannelStateWriteResult write(long checkpointId, Map<InputChannelInfo, byte[]> icMap, Map<ResultSubpartitionInfo, byte[]> rsMap) throws Exception {\n+\t\tint maxStateSize = sizeOfBytes(icMap) + sizeOfBytes(rsMap) + Long.BYTES * 2;\n+\t\tMap<InputChannelInfo, Buffer> icBuffers = wrapWithBuffers(icMap);\n+\t\tMap<ResultSubpartitionInfo, Buffer> rsBuffers = wrapWithBuffers(rsMap);\n+\t\ttry (ChannelStateWriterImpl writer = new ChannelStateWriterImpl(getStreamFactoryFactory(maxStateSize))) {\n+\t\t\twriter.open();\n+\t\t\twriter.start(checkpointId, new CheckpointOptions(CHECKPOINT, new CheckpointStorageLocationReference(\"poly\".getBytes())));\n+\t\t\tfor (Map.Entry<InputChannelInfo, Buffer> e : icBuffers.entrySet()) {\n+\t\t\t\twriter.addInputData(checkpointId, e.getKey(), SEQUENCE_NUMBER_UNKNOWN, e.getValue());\n+\t\t\t}\n+\t\t\twriter.finishInput(checkpointId);\n+\t\t\tfor (Map.Entry<ResultSubpartitionInfo, Buffer> e : rsBuffers.entrySet()) {\n+\t\t\t\twriter.addOutputData(checkpointId, e.getKey(), SEQUENCE_NUMBER_UNKNOWN, e.getValue());\n+\t\t\t}\n+\t\t\twriter.finishOutput(checkpointId);\n+\t\t\tChannelStateWriteResult result = writer.getWriteResult(checkpointId);\n+\t\t\tresult.getResultSubpartitionStateHandles().join(); // prevent abnormal complete in close\n+\t\t\treturn result;\n+\t\t}\n+\t}\n+\n+\tpublic static CheckpointStorageWorkerView getStreamFactoryFactory() {\n+\t\treturn getStreamFactoryFactory(42);\n+\t}\n+\n+\tpublic static CheckpointStorageWorkerView getStreamFactoryFactory(int maxStateSize) {\n+\t\treturn new CheckpointStorageWorkerView() {\n+\t\t\t@Override\n+\t\t\tpublic CheckpointStreamFactory resolveCheckpointStorageLocation(long checkpointId, CheckpointStorageLocationReference reference) {\n+\t\t\t\treturn new NonPersistentMetadataCheckpointStorageLocation(maxStateSize);\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic CheckpointStreamFactory.CheckpointStateOutputStream createTaskOwnedStateStream() {\n+\t\t\t\tthrow new UnsupportedOperationException();\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tprivate byte[] read(TaskStateSnapshot taskStateSnapshot, int size, BiFunctionWithException<ChannelStateReader, MemorySegment, ReadResult, Exception> readFn) throws Exception {\n+\t\tbyte[] dst = new byte[size];\n+\t\tHeapMemorySegment mem = HeapMemorySegment.FACTORY.wrap(dst);\n+\t\ttry {\n+\t\t\tcheckState(NO_MORE_DATA == readFn.apply(new ChannelStateReaderImpl(taskStateSnapshot), mem));\n+\t\t} finally {\n+\t\t\tmem.free();\n+\t\t}\n+\t\treturn dst;\n+\t}\n+\n+\tprivate TaskStateSnapshot toTaskStateSnapshot(ChannelStateWriteResult t) throws Exception {\n+\t\treturn new TaskStateSnapshot(singletonMap(new OperatorID(),\n+\t\t\tnew OperatorSubtaskState(\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tnew StateObjectCollection<>(t.getInputChannelStateHandles().get()),\n+\t\t\t\tnew StateObjectCollection<>(t.getResultSubpartitionStateHandles().get())\n+\t\t\t)\n+\t\t));\n+\t}\n+\n+\tprivate <C> List<C> collect(Collection<StateObject> handles, Class<C> clazz) {\n+\t\t//noinspection unchecked", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 161}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxMzIzMjc4OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/state/ChannelPersistenceITCase.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxODowNzozN1rOGCP5oA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxMDo1NjozNVrOGCp7gQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAxMDg0OA==", "bodyText": "you should decide on empty line or not?", "url": "https://github.com/apache/flink/pull/11515#discussion_r405010848", "createdAt": "2020-04-07T18:07:37Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/state/ChannelPersistenceITCase.java", "diffHunk": "@@ -0,0 +1,179 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.state;\n+\n+import org.apache.flink.core.memory.HeapMemorySegment;\n+import org.apache.flink.core.memory.MemorySegment;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.StateObjectCollection;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReaderImpl;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriterImpl;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.checkpoint.channel.ResultSubpartitionInfo;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.memory.NonPersistentMetadataCheckpointStorageLocation;\n+import org.apache.flink.util.function.BiFunctionWithException;\n+\n+import org.junit.Test;\n+\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.stream.Collectors;\n+\n+import static java.util.Collections.singletonMap;\n+import static org.apache.flink.runtime.checkpoint.CheckpointType.CHECKPOINT;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.SEQUENCE_NUMBER_UNKNOWN;\n+import static org.apache.flink.util.Preconditions.checkState;\n+import static org.junit.Assert.assertArrayEquals;\n+\n+/**\n+ * ChannelPersistenceITCase.\n+ */\n+public class ChannelPersistenceITCase {\n+\tprivate static final Random RANDOM = new Random(System.currentTimeMillis());\n+\n+\t@Test\n+\tpublic void testReadWritten() throws Exception {\n+\t\tlong checkpointId = 1L;\n+\n+\t\tInputChannelInfo inputChannelInfo = new InputChannelInfo(2, 3);\n+\t\tbyte[] inputChannelInfoData = randomBytes(1024);\n+\n+\t\tResultSubpartitionInfo resultSubpartitionInfo = new ResultSubpartitionInfo(4, 5);\n+\t\tbyte[] resultSubpartitionInfoData = randomBytes(1024);\n+\n+\t\tChannelStateWriteResult handles = write(\n+\t\t\tcheckpointId,\n+\t\t\tsingletonMap(inputChannelInfo, inputChannelInfoData),\n+\t\t\tsingletonMap(resultSubpartitionInfo, resultSubpartitionInfoData)\n+\t\t);\n+\n+\t\tassertArrayEquals(inputChannelInfoData, read(\n+\t\t\ttoTaskStateSnapshot(handles),\n+\t\t\tinputChannelInfoData.length,\n+\t\t\t(reader, mem) -> reader.readInputData(inputChannelInfo, new NetworkBuffer(mem, FreeingBufferRecycler.INSTANCE))\n+\t\t));\n+\n+\t\tassertArrayEquals(resultSubpartitionInfoData, read(\n+\t\t\ttoTaskStateSnapshot(handles),\n+\t\t\tresultSubpartitionInfoData.length,\n+\t\t\t(reader, mem) -> reader.readOutputData(resultSubpartitionInfo, new BufferBuilder(mem, FreeingBufferRecycler.INSTANCE))\n+\t\t));\n+\t}\n+\n+\tprivate byte[] randomBytes(int size) {\n+\t\tbyte[] bytes = new byte[size];\n+\t\tRANDOM.nextBytes(bytes);\n+\t\treturn bytes;\n+\t}\n+\n+\tprivate ChannelStateWriteResult write(long checkpointId, Map<InputChannelInfo, byte[]> icMap, Map<ResultSubpartitionInfo, byte[]> rsMap) throws Exception {\n+\t\tint maxStateSize = sizeOfBytes(icMap) + sizeOfBytes(rsMap) + Long.BYTES * 2;\n+\t\tMap<InputChannelInfo, Buffer> icBuffers = wrapWithBuffers(icMap);\n+\t\tMap<ResultSubpartitionInfo, Buffer> rsBuffers = wrapWithBuffers(rsMap);\n+\t\ttry (ChannelStateWriterImpl writer = new ChannelStateWriterImpl(getStreamFactoryFactory(maxStateSize))) {\n+\t\t\twriter.open();\n+\t\t\twriter.start(checkpointId, new CheckpointOptions(CHECKPOINT, new CheckpointStorageLocationReference(\"poly\".getBytes())));\n+\t\t\tfor (Map.Entry<InputChannelInfo, Buffer> e : icBuffers.entrySet()) {\n+\t\t\t\twriter.addInputData(checkpointId, e.getKey(), SEQUENCE_NUMBER_UNKNOWN, e.getValue());\n+\t\t\t}\n+\t\t\twriter.finishInput(checkpointId);\n+\t\t\tfor (Map.Entry<ResultSubpartitionInfo, Buffer> e : rsBuffers.entrySet()) {\n+\t\t\t\twriter.addOutputData(checkpointId, e.getKey(), SEQUENCE_NUMBER_UNKNOWN, e.getValue());\n+\t\t\t}\n+\t\t\twriter.finishOutput(checkpointId);\n+\t\t\tChannelStateWriteResult result = writer.getWriteResult(checkpointId);\n+\t\t\tresult.getResultSubpartitionStateHandles().join(); // prevent abnormal complete in close\n+\t\t\treturn result;\n+\t\t}\n+\t}\n+\n+\tpublic static CheckpointStorageWorkerView getStreamFactoryFactory() {\n+\t\treturn getStreamFactoryFactory(42);\n+\t}\n+\n+\tpublic static CheckpointStorageWorkerView getStreamFactoryFactory(int maxStateSize) {\n+\t\treturn new CheckpointStorageWorkerView() {\n+\t\t\t@Override\n+\t\t\tpublic CheckpointStreamFactory resolveCheckpointStorageLocation(long checkpointId, CheckpointStorageLocationReference reference) {\n+\t\t\t\treturn new NonPersistentMetadataCheckpointStorageLocation(maxStateSize);\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic CheckpointStreamFactory.CheckpointStateOutputStream createTaskOwnedStateStream() {\n+\t\t\t\tthrow new UnsupportedOperationException();\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tprivate byte[] read(TaskStateSnapshot taskStateSnapshot, int size, BiFunctionWithException<ChannelStateReader, MemorySegment, ReadResult, Exception> readFn) throws Exception {\n+\t\tbyte[] dst = new byte[size];\n+\t\tHeapMemorySegment mem = HeapMemorySegment.FACTORY.wrap(dst);\n+\t\ttry {\n+\t\t\tcheckState(NO_MORE_DATA == readFn.apply(new ChannelStateReaderImpl(taskStateSnapshot), mem));\n+\t\t} finally {\n+\t\t\tmem.free();\n+\t\t}\n+\t\treturn dst;\n+\t}\n+\n+\tprivate TaskStateSnapshot toTaskStateSnapshot(ChannelStateWriteResult t) throws Exception {\n+\t\treturn new TaskStateSnapshot(singletonMap(new OperatorID(),\n+\t\t\tnew OperatorSubtaskState(\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tnew StateObjectCollection<>(t.getInputChannelStateHandles().get()),\n+\t\t\t\tnew StateObjectCollection<>(t.getResultSubpartitionStateHandles().get())\n+\t\t\t)\n+\t\t));\n+\t}\n+\n+\tprivate <C> List<C> collect(Collection<StateObject> handles, Class<C> clazz) {\n+\t\t//noinspection unchecked\n+\t\treturn handles.stream().filter(clazz::isInstance).map(h -> (C) h).collect(Collectors.toList());\n+\t}\n+\n+\tprivate static int sizeOfBytes(Map<?, byte[]> map) {\n+\t\treturn map.values().stream().mapToInt(d -> d.length).sum();\n+\t}\n+\n+\tprivate <K> Map<K, Buffer> wrapWithBuffers(Map<K, byte[]> icMap) {\n+\t\treturn icMap.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey, e -> wrapWithBuffer(e.getValue())));\n+\t}\n+\n+\tprivate static Buffer wrapWithBuffer(byte[] data) {\n+\t\tNetworkBuffer buffer = new NetworkBuffer(HeapMemorySegment.FACTORY.allocateUnpooledSegment(data.length, null), FreeingBufferRecycler.INSTANCE);\n+\t\tbuffer.writeBytes(data);\n+\t\treturn buffer;\n+\t}\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 178}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQzNzMxMw==", "bodyText": "I don't think it makes a big difference. If it would, it should be in the Flink formatting guidelines and checkstyle config.", "url": "https://github.com/apache/flink/pull/11515#discussion_r405437313", "createdAt": "2020-04-08T10:56:35Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/state/ChannelPersistenceITCase.java", "diffHunk": "@@ -0,0 +1,179 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.state;\n+\n+import org.apache.flink.core.memory.HeapMemorySegment;\n+import org.apache.flink.core.memory.MemorySegment;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.StateObjectCollection;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReaderImpl;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriterImpl;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.checkpoint.channel.ResultSubpartitionInfo;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.memory.NonPersistentMetadataCheckpointStorageLocation;\n+import org.apache.flink.util.function.BiFunctionWithException;\n+\n+import org.junit.Test;\n+\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.stream.Collectors;\n+\n+import static java.util.Collections.singletonMap;\n+import static org.apache.flink.runtime.checkpoint.CheckpointType.CHECKPOINT;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.SEQUENCE_NUMBER_UNKNOWN;\n+import static org.apache.flink.util.Preconditions.checkState;\n+import static org.junit.Assert.assertArrayEquals;\n+\n+/**\n+ * ChannelPersistenceITCase.\n+ */\n+public class ChannelPersistenceITCase {\n+\tprivate static final Random RANDOM = new Random(System.currentTimeMillis());\n+\n+\t@Test\n+\tpublic void testReadWritten() throws Exception {\n+\t\tlong checkpointId = 1L;\n+\n+\t\tInputChannelInfo inputChannelInfo = new InputChannelInfo(2, 3);\n+\t\tbyte[] inputChannelInfoData = randomBytes(1024);\n+\n+\t\tResultSubpartitionInfo resultSubpartitionInfo = new ResultSubpartitionInfo(4, 5);\n+\t\tbyte[] resultSubpartitionInfoData = randomBytes(1024);\n+\n+\t\tChannelStateWriteResult handles = write(\n+\t\t\tcheckpointId,\n+\t\t\tsingletonMap(inputChannelInfo, inputChannelInfoData),\n+\t\t\tsingletonMap(resultSubpartitionInfo, resultSubpartitionInfoData)\n+\t\t);\n+\n+\t\tassertArrayEquals(inputChannelInfoData, read(\n+\t\t\ttoTaskStateSnapshot(handles),\n+\t\t\tinputChannelInfoData.length,\n+\t\t\t(reader, mem) -> reader.readInputData(inputChannelInfo, new NetworkBuffer(mem, FreeingBufferRecycler.INSTANCE))\n+\t\t));\n+\n+\t\tassertArrayEquals(resultSubpartitionInfoData, read(\n+\t\t\ttoTaskStateSnapshot(handles),\n+\t\t\tresultSubpartitionInfoData.length,\n+\t\t\t(reader, mem) -> reader.readOutputData(resultSubpartitionInfo, new BufferBuilder(mem, FreeingBufferRecycler.INSTANCE))\n+\t\t));\n+\t}\n+\n+\tprivate byte[] randomBytes(int size) {\n+\t\tbyte[] bytes = new byte[size];\n+\t\tRANDOM.nextBytes(bytes);\n+\t\treturn bytes;\n+\t}\n+\n+\tprivate ChannelStateWriteResult write(long checkpointId, Map<InputChannelInfo, byte[]> icMap, Map<ResultSubpartitionInfo, byte[]> rsMap) throws Exception {\n+\t\tint maxStateSize = sizeOfBytes(icMap) + sizeOfBytes(rsMap) + Long.BYTES * 2;\n+\t\tMap<InputChannelInfo, Buffer> icBuffers = wrapWithBuffers(icMap);\n+\t\tMap<ResultSubpartitionInfo, Buffer> rsBuffers = wrapWithBuffers(rsMap);\n+\t\ttry (ChannelStateWriterImpl writer = new ChannelStateWriterImpl(getStreamFactoryFactory(maxStateSize))) {\n+\t\t\twriter.open();\n+\t\t\twriter.start(checkpointId, new CheckpointOptions(CHECKPOINT, new CheckpointStorageLocationReference(\"poly\".getBytes())));\n+\t\t\tfor (Map.Entry<InputChannelInfo, Buffer> e : icBuffers.entrySet()) {\n+\t\t\t\twriter.addInputData(checkpointId, e.getKey(), SEQUENCE_NUMBER_UNKNOWN, e.getValue());\n+\t\t\t}\n+\t\t\twriter.finishInput(checkpointId);\n+\t\t\tfor (Map.Entry<ResultSubpartitionInfo, Buffer> e : rsBuffers.entrySet()) {\n+\t\t\t\twriter.addOutputData(checkpointId, e.getKey(), SEQUENCE_NUMBER_UNKNOWN, e.getValue());\n+\t\t\t}\n+\t\t\twriter.finishOutput(checkpointId);\n+\t\t\tChannelStateWriteResult result = writer.getWriteResult(checkpointId);\n+\t\t\tresult.getResultSubpartitionStateHandles().join(); // prevent abnormal complete in close\n+\t\t\treturn result;\n+\t\t}\n+\t}\n+\n+\tpublic static CheckpointStorageWorkerView getStreamFactoryFactory() {\n+\t\treturn getStreamFactoryFactory(42);\n+\t}\n+\n+\tpublic static CheckpointStorageWorkerView getStreamFactoryFactory(int maxStateSize) {\n+\t\treturn new CheckpointStorageWorkerView() {\n+\t\t\t@Override\n+\t\t\tpublic CheckpointStreamFactory resolveCheckpointStorageLocation(long checkpointId, CheckpointStorageLocationReference reference) {\n+\t\t\t\treturn new NonPersistentMetadataCheckpointStorageLocation(maxStateSize);\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic CheckpointStreamFactory.CheckpointStateOutputStream createTaskOwnedStateStream() {\n+\t\t\t\tthrow new UnsupportedOperationException();\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tprivate byte[] read(TaskStateSnapshot taskStateSnapshot, int size, BiFunctionWithException<ChannelStateReader, MemorySegment, ReadResult, Exception> readFn) throws Exception {\n+\t\tbyte[] dst = new byte[size];\n+\t\tHeapMemorySegment mem = HeapMemorySegment.FACTORY.wrap(dst);\n+\t\ttry {\n+\t\t\tcheckState(NO_MORE_DATA == readFn.apply(new ChannelStateReaderImpl(taskStateSnapshot), mem));\n+\t\t} finally {\n+\t\t\tmem.free();\n+\t\t}\n+\t\treturn dst;\n+\t}\n+\n+\tprivate TaskStateSnapshot toTaskStateSnapshot(ChannelStateWriteResult t) throws Exception {\n+\t\treturn new TaskStateSnapshot(singletonMap(new OperatorID(),\n+\t\t\tnew OperatorSubtaskState(\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tnew StateObjectCollection<>(t.getInputChannelStateHandles().get()),\n+\t\t\t\tnew StateObjectCollection<>(t.getResultSubpartitionStateHandles().get())\n+\t\t\t)\n+\t\t));\n+\t}\n+\n+\tprivate <C> List<C> collect(Collection<StateObject> handles, Class<C> clazz) {\n+\t\t//noinspection unchecked\n+\t\treturn handles.stream().filter(clazz::isInstance).map(h -> (C) h).collect(Collectors.toList());\n+\t}\n+\n+\tprivate static int sizeOfBytes(Map<?, byte[]> map) {\n+\t\treturn map.values().stream().mapToInt(d -> d.length).sum();\n+\t}\n+\n+\tprivate <K> Map<K, Buffer> wrapWithBuffers(Map<K, byte[]> icMap) {\n+\t\treturn icMap.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey, e -> wrapWithBuffer(e.getValue())));\n+\t}\n+\n+\tprivate static Buffer wrapWithBuffer(byte[] data) {\n+\t\tNetworkBuffer buffer = new NetworkBuffer(HeapMemorySegment.FACTORY.allocateUnpooledSegment(data.length, null), FreeingBufferRecycler.INSTANCE);\n+\t\tbuffer.writeBytes(data);\n+\t\treturn buffer;\n+\t}\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAxMDg0OA=="}, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 178}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxMzI0MjA0OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamTask.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxODoxMDowOVrOGCP_gQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxODoxMDowOVrOGCP_gQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAxMjM1Mw==", "bodyText": "Usually, we don't want to push TODOs into master, but I can see that it has some value. On the other hand, it should be quite easy to find when actually adding unaligned checkpoints.", "url": "https://github.com/apache/flink/pull/11515#discussion_r405012353", "createdAt": "2020-04-07T18:10:09Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamTask.java", "diffHunk": "@@ -277,7 +277,8 @@ protected StreamTask(\n \t\t\tgetCancelables(),\n \t\t\tgetAsyncOperationsThreadPool(),\n \t\t\tgetEnvironment(),\n-\t\t\tthis);\n+\t\t\tthis,\n+\t\t\tfalse); // todo: pass true if unaligned checkpoints enabled", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bdb06fc00a0da1e0c3df87383de8ebb0a28b1ef3"}, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxMzI2NDAxOnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxODoxNjoxNFrOGCQNXw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QyMToyNzowMlrOGCWxuA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAxNTkwMw==", "bodyText": "This looks a bit suspicious. Do we actually need a dedicated open or could we open it in the constructor already. Maybe it would allow us to have more final fields?", "url": "https://github.com/apache/flink/pull/11515#discussion_r405015903", "createdAt": "2020-04-07T18:16:14Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -55,20 +68,33 @@\n \t\t\tCloseableRegistry closeableRegistry,\n \t\t\tExecutorService executorService,\n \t\t\tEnvironment env,\n-\t\t\tAsyncExceptionHandler asyncExceptionHandler) {\n-\t\tthis.checkpointStorage = checkNotNull(checkpointStorage);\n+\t\t\tAsyncExceptionHandler asyncExceptionHandler,\n+\t\t\tboolean sendChannelState) throws IOException {\n+\t\tthis.checkpointStorage = new CachingCheckpointStorageWorkerView(checkNotNull(checkpointStorage));\n \t\tthis.taskName = checkNotNull(taskName);\n \t\tthis.closeableRegistry = checkNotNull(closeableRegistry);\n \t\tthis.executorService = checkNotNull(executorService);\n \t\tthis.env = checkNotNull(env);\n \t\tthis.asyncExceptionHandler = checkNotNull(asyncExceptionHandler);\n \t\tthis.actionExecutor = actionExecutor;\n+\t\tthis.channelStateWriter = sendChannelState ? openChannelStateWriter() : ChannelStateWriter.NO_OP;\n+\t\tthis.closeableRegistry.registerCloseable(this);\n+\t}\n+\n+\tprivate ChannelStateWriterImpl openChannelStateWriter() {\n+\t\tChannelStateWriterImpl writer = new ChannelStateWriterImpl(this.checkpointStorage);\n+\t\twriter.open();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bdb06fc00a0da1e0c3df87383de8ebb0a28b1ef3"}, "originalPosition": 67}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTEyMzUxMg==", "bodyText": "It starts a thread and it doesn't affect fields.", "url": "https://github.com/apache/flink/pull/11515#discussion_r405123512", "createdAt": "2020-04-07T21:27:02Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -55,20 +68,33 @@\n \t\t\tCloseableRegistry closeableRegistry,\n \t\t\tExecutorService executorService,\n \t\t\tEnvironment env,\n-\t\t\tAsyncExceptionHandler asyncExceptionHandler) {\n-\t\tthis.checkpointStorage = checkNotNull(checkpointStorage);\n+\t\t\tAsyncExceptionHandler asyncExceptionHandler,\n+\t\t\tboolean sendChannelState) throws IOException {\n+\t\tthis.checkpointStorage = new CachingCheckpointStorageWorkerView(checkNotNull(checkpointStorage));\n \t\tthis.taskName = checkNotNull(taskName);\n \t\tthis.closeableRegistry = checkNotNull(closeableRegistry);\n \t\tthis.executorService = checkNotNull(executorService);\n \t\tthis.env = checkNotNull(env);\n \t\tthis.asyncExceptionHandler = checkNotNull(asyncExceptionHandler);\n \t\tthis.actionExecutor = actionExecutor;\n+\t\tthis.channelStateWriter = sendChannelState ? openChannelStateWriter() : ChannelStateWriter.NO_OP;\n+\t\tthis.closeableRegistry.registerCloseable(this);\n+\t}\n+\n+\tprivate ChannelStateWriterImpl openChannelStateWriter() {\n+\t\tChannelStateWriterImpl writer = new ChannelStateWriterImpl(this.checkpointStorage);\n+\t\twriter.open();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAxNTkwMw=="}, "originalCommit": {"oid": "bdb06fc00a0da1e0c3df87383de8ebb0a28b1ef3"}, "originalPosition": 67}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxNDc1NjM4OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNDoxNDoxMFrOGCeYDg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNDoxNDoxMFrOGCeYDg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTI0ODAxNA==", "bodyText": "nit: too long line", "url": "https://github.com/apache/flink/pull/11515#discussion_r405248014", "createdAt": "2020-04-08T04:14:10Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequest.java", "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageLocationReference;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.ThrowingConsumer;\n+\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+\n+interface ChannelStateWriteRequest {\n+\tlong getCheckpointId();\n+\n+\tvoid cancel(Throwable cause);\n+\n+\tstatic CheckpointInProgressRequest completeInput(long checkpointId) {\n+\t\treturn new CheckpointInProgressRequest(\"completeInput\", checkpointId, ChannelStateCheckpointWriter::completeInput, false);\n+\t}\n+\n+\tstatic CheckpointInProgressRequest completeOutput(long checkpointId) {\n+\t\treturn new CheckpointInProgressRequest(\"completeOutput\", checkpointId, ChannelStateCheckpointWriter::completeOutput, false);\n+\t}\n+\n+\tstatic ChannelStateWriteRequest write(long checkpointId, InputChannelInfo info, Buffer... flinkBuffers) {\n+\t\treturn new CheckpointInProgressRequest(\"writeInput\", checkpointId, writer -> writer.writeInput(info, flinkBuffers), recycle(flinkBuffers), false);\n+\t}\n+\n+\tstatic ChannelStateWriteRequest write(long checkpointId, ResultSubpartitionInfo info, Buffer... flinkBuffers) {\n+\t\treturn new CheckpointInProgressRequest(\"writeOutput\", checkpointId, writer -> writer.writeOutput(info, flinkBuffers), recycle(flinkBuffers), false);\n+\t}\n+\n+\tstatic ChannelStateWriteRequest start(long checkpointId, ChannelStateWriteResult targetResult, CheckpointStorageLocationReference locationReference) {\n+\t\treturn new CheckpointStartRequest(checkpointId, targetResult, locationReference);\n+\t}\n+\n+\tstatic ChannelStateWriteRequest abort(long checkpointId, Throwable cause) {\n+\t\treturn new CheckpointInProgressRequest(\"abort\", checkpointId, writer -> writer.fail(cause), true);\n+\t}\n+\n+\tstatic Consumer<Throwable> recycle(Buffer[] flinkBuffers) {\n+\t\treturn unused -> {\n+\t\t\tfor (Buffer b : flinkBuffers) {\n+\t\t\t\tb.recycleBuffer();\n+\t\t\t}\n+\t\t};\n+\t}\n+}\n+\n+final class CheckpointStartRequest implements ChannelStateWriteRequest {\n+\tprivate final ChannelStateWriteResult targetResult;\n+\tprivate final CheckpointStorageLocationReference locationReference;\n+\tprivate final long checkpointId;\n+\n+\tCheckpointStartRequest(long checkpointId, ChannelStateWriteResult targetResult, CheckpointStorageLocationReference locationReference) {\n+\t\tthis.checkpointId = checkpointId;\n+\t\tthis.targetResult = targetResult;\n+\t\tthis.locationReference = locationReference;\n+\t}\n+\n+\t@Override\n+\tpublic long getCheckpointId() {\n+\t\treturn checkpointId;\n+\t}\n+\n+\tChannelStateWriteResult getTargetResult() {\n+\t\treturn targetResult;\n+\t}\n+\n+\tpublic CheckpointStorageLocationReference getLocationReference() {\n+\t\treturn locationReference;\n+\t}\n+\n+\t@Override\n+\tpublic void cancel(Throwable cause) {\n+\t\ttargetResult.fail(cause);\n+\t}\n+\n+\t@Override\n+\tpublic String toString() {\n+\t\treturn \"start \" + checkpointId;\n+\t}\n+}\n+\n+final class CheckpointInProgressRequest implements ChannelStateWriteRequest {\n+\tprivate final ThrowingConsumer<ChannelStateCheckpointWriter, Exception> action;\n+\tprivate final Consumer<Throwable> discardAction;\n+\tprivate final long checkpointId;\n+\tprivate final String name;\n+\tprivate final boolean ignoreMissingWriter;\n+\tprivate final AtomicReference<CheckpointInProgressRequestState> state = new AtomicReference<>(CheckpointInProgressRequestState.NEW);\n+\n+\tCheckpointInProgressRequest(String name, long checkpointId, ThrowingConsumer<ChannelStateCheckpointWriter, Exception> action, boolean ignoreMissingWriter) {\n+\t\tthis(name, checkpointId, action, unused -> {\n+\t\t}, ignoreMissingWriter);\n+\t}\n+\n+\tCheckpointInProgressRequest(String name, long checkpointId, ThrowingConsumer<ChannelStateCheckpointWriter, Exception> action, Consumer<Throwable> discardAction, boolean ignoreMissingWriter) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 115}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxNDgxMjk4OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNDo1MDo0NFrOGCe5bA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxNToyODoyMFrOGC0nzQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTI1NjU1Ng==", "bodyText": "I have three concerns with the cancel:\n\n\nIn CheckpointStartRequest#cancel, the targetResult.fail(cause) would be executed. For the case of CheckpointInProgressRequest, do we also need to complete the future with failure?\n\n\n#cancel is only valid to perform before executing #execute method because of the limitation of state condition, although #cancel is still triggered while performing #execute to cause any exceptions. Is it considered by design?\n\n\nI guess the introduction of state was mainly for voiding cancelling multiple times, because #execute can not be called more than once in practice. If so, maybe it is not necessary to bring in so many state values, only need one isCancelled state.", "url": "https://github.com/apache/flink/pull/11515#discussion_r405256556", "createdAt": "2020-04-08T04:50:44Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequest.java", "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageLocationReference;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.ThrowingConsumer;\n+\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+\n+interface ChannelStateWriteRequest {\n+\tlong getCheckpointId();\n+\n+\tvoid cancel(Throwable cause);\n+\n+\tstatic CheckpointInProgressRequest completeInput(long checkpointId) {\n+\t\treturn new CheckpointInProgressRequest(\"completeInput\", checkpointId, ChannelStateCheckpointWriter::completeInput, false);\n+\t}\n+\n+\tstatic CheckpointInProgressRequest completeOutput(long checkpointId) {\n+\t\treturn new CheckpointInProgressRequest(\"completeOutput\", checkpointId, ChannelStateCheckpointWriter::completeOutput, false);\n+\t}\n+\n+\tstatic ChannelStateWriteRequest write(long checkpointId, InputChannelInfo info, Buffer... flinkBuffers) {\n+\t\treturn new CheckpointInProgressRequest(\"writeInput\", checkpointId, writer -> writer.writeInput(info, flinkBuffers), recycle(flinkBuffers), false);\n+\t}\n+\n+\tstatic ChannelStateWriteRequest write(long checkpointId, ResultSubpartitionInfo info, Buffer... flinkBuffers) {\n+\t\treturn new CheckpointInProgressRequest(\"writeOutput\", checkpointId, writer -> writer.writeOutput(info, flinkBuffers), recycle(flinkBuffers), false);\n+\t}\n+\n+\tstatic ChannelStateWriteRequest start(long checkpointId, ChannelStateWriteResult targetResult, CheckpointStorageLocationReference locationReference) {\n+\t\treturn new CheckpointStartRequest(checkpointId, targetResult, locationReference);\n+\t}\n+\n+\tstatic ChannelStateWriteRequest abort(long checkpointId, Throwable cause) {\n+\t\treturn new CheckpointInProgressRequest(\"abort\", checkpointId, writer -> writer.fail(cause), true);\n+\t}\n+\n+\tstatic Consumer<Throwable> recycle(Buffer[] flinkBuffers) {\n+\t\treturn unused -> {\n+\t\t\tfor (Buffer b : flinkBuffers) {\n+\t\t\t\tb.recycleBuffer();\n+\t\t\t}\n+\t\t};\n+\t}\n+}\n+\n+final class CheckpointStartRequest implements ChannelStateWriteRequest {\n+\tprivate final ChannelStateWriteResult targetResult;\n+\tprivate final CheckpointStorageLocationReference locationReference;\n+\tprivate final long checkpointId;\n+\n+\tCheckpointStartRequest(long checkpointId, ChannelStateWriteResult targetResult, CheckpointStorageLocationReference locationReference) {\n+\t\tthis.checkpointId = checkpointId;\n+\t\tthis.targetResult = targetResult;\n+\t\tthis.locationReference = locationReference;\n+\t}\n+\n+\t@Override\n+\tpublic long getCheckpointId() {\n+\t\treturn checkpointId;\n+\t}\n+\n+\tChannelStateWriteResult getTargetResult() {\n+\t\treturn targetResult;\n+\t}\n+\n+\tpublic CheckpointStorageLocationReference getLocationReference() {\n+\t\treturn locationReference;\n+\t}\n+\n+\t@Override\n+\tpublic void cancel(Throwable cause) {\n+\t\ttargetResult.fail(cause);\n+\t}\n+\n+\t@Override\n+\tpublic String toString() {\n+\t\treturn \"start \" + checkpointId;\n+\t}\n+}\n+\n+final class CheckpointInProgressRequest implements ChannelStateWriteRequest {\n+\tprivate final ThrowingConsumer<ChannelStateCheckpointWriter, Exception> action;\n+\tprivate final Consumer<Throwable> discardAction;\n+\tprivate final long checkpointId;\n+\tprivate final String name;\n+\tprivate final boolean ignoreMissingWriter;\n+\tprivate final AtomicReference<CheckpointInProgressRequestState> state = new AtomicReference<>(CheckpointInProgressRequestState.NEW);\n+\n+\tCheckpointInProgressRequest(String name, long checkpointId, ThrowingConsumer<ChannelStateCheckpointWriter, Exception> action, boolean ignoreMissingWriter) {\n+\t\tthis(name, checkpointId, action, unused -> {\n+\t\t}, ignoreMissingWriter);\n+\t}\n+\n+\tCheckpointInProgressRequest(String name, long checkpointId, ThrowingConsumer<ChannelStateCheckpointWriter, Exception> action, Consumer<Throwable> discardAction, boolean ignoreMissingWriter) {\n+\t\tthis.checkpointId = checkpointId;\n+\t\tthis.action = action;\n+\t\tthis.discardAction = discardAction;\n+\t\tthis.name = name;\n+\t\tthis.ignoreMissingWriter = ignoreMissingWriter;\n+\t}\n+\n+\t@Override\n+\tpublic long getCheckpointId() {\n+\t\treturn checkpointId;\n+\t}\n+\n+\t@Override\n+\tpublic void cancel(Throwable cause) {\n+\t\tif (state.compareAndSet(CheckpointInProgressRequestState.NEW, CheckpointInProgressRequestState.CANCELLED)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 130}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTYxMjQ5Mw==", "bodyText": "In case of CheckpointStartRequest it \"owns\" the result future (ChannelStateCheckpointWriter wasn't yet created for it). In other cases ChannelStateCheckpointWriter owns the future.\n\n\nThis is a bug. Fixed it.\n\n\nwith just volatile isCanceled it's possible for two thread to cancel it simultaneously", "url": "https://github.com/apache/flink/pull/11515#discussion_r405612493", "createdAt": "2020-04-08T15:28:20Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequest.java", "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageLocationReference;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.ThrowingConsumer;\n+\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+\n+interface ChannelStateWriteRequest {\n+\tlong getCheckpointId();\n+\n+\tvoid cancel(Throwable cause);\n+\n+\tstatic CheckpointInProgressRequest completeInput(long checkpointId) {\n+\t\treturn new CheckpointInProgressRequest(\"completeInput\", checkpointId, ChannelStateCheckpointWriter::completeInput, false);\n+\t}\n+\n+\tstatic CheckpointInProgressRequest completeOutput(long checkpointId) {\n+\t\treturn new CheckpointInProgressRequest(\"completeOutput\", checkpointId, ChannelStateCheckpointWriter::completeOutput, false);\n+\t}\n+\n+\tstatic ChannelStateWriteRequest write(long checkpointId, InputChannelInfo info, Buffer... flinkBuffers) {\n+\t\treturn new CheckpointInProgressRequest(\"writeInput\", checkpointId, writer -> writer.writeInput(info, flinkBuffers), recycle(flinkBuffers), false);\n+\t}\n+\n+\tstatic ChannelStateWriteRequest write(long checkpointId, ResultSubpartitionInfo info, Buffer... flinkBuffers) {\n+\t\treturn new CheckpointInProgressRequest(\"writeOutput\", checkpointId, writer -> writer.writeOutput(info, flinkBuffers), recycle(flinkBuffers), false);\n+\t}\n+\n+\tstatic ChannelStateWriteRequest start(long checkpointId, ChannelStateWriteResult targetResult, CheckpointStorageLocationReference locationReference) {\n+\t\treturn new CheckpointStartRequest(checkpointId, targetResult, locationReference);\n+\t}\n+\n+\tstatic ChannelStateWriteRequest abort(long checkpointId, Throwable cause) {\n+\t\treturn new CheckpointInProgressRequest(\"abort\", checkpointId, writer -> writer.fail(cause), true);\n+\t}\n+\n+\tstatic Consumer<Throwable> recycle(Buffer[] flinkBuffers) {\n+\t\treturn unused -> {\n+\t\t\tfor (Buffer b : flinkBuffers) {\n+\t\t\t\tb.recycleBuffer();\n+\t\t\t}\n+\t\t};\n+\t}\n+}\n+\n+final class CheckpointStartRequest implements ChannelStateWriteRequest {\n+\tprivate final ChannelStateWriteResult targetResult;\n+\tprivate final CheckpointStorageLocationReference locationReference;\n+\tprivate final long checkpointId;\n+\n+\tCheckpointStartRequest(long checkpointId, ChannelStateWriteResult targetResult, CheckpointStorageLocationReference locationReference) {\n+\t\tthis.checkpointId = checkpointId;\n+\t\tthis.targetResult = targetResult;\n+\t\tthis.locationReference = locationReference;\n+\t}\n+\n+\t@Override\n+\tpublic long getCheckpointId() {\n+\t\treturn checkpointId;\n+\t}\n+\n+\tChannelStateWriteResult getTargetResult() {\n+\t\treturn targetResult;\n+\t}\n+\n+\tpublic CheckpointStorageLocationReference getLocationReference() {\n+\t\treturn locationReference;\n+\t}\n+\n+\t@Override\n+\tpublic void cancel(Throwable cause) {\n+\t\ttargetResult.fail(cause);\n+\t}\n+\n+\t@Override\n+\tpublic String toString() {\n+\t\treturn \"start \" + checkpointId;\n+\t}\n+}\n+\n+final class CheckpointInProgressRequest implements ChannelStateWriteRequest {\n+\tprivate final ThrowingConsumer<ChannelStateCheckpointWriter, Exception> action;\n+\tprivate final Consumer<Throwable> discardAction;\n+\tprivate final long checkpointId;\n+\tprivate final String name;\n+\tprivate final boolean ignoreMissingWriter;\n+\tprivate final AtomicReference<CheckpointInProgressRequestState> state = new AtomicReference<>(CheckpointInProgressRequestState.NEW);\n+\n+\tCheckpointInProgressRequest(String name, long checkpointId, ThrowingConsumer<ChannelStateCheckpointWriter, Exception> action, boolean ignoreMissingWriter) {\n+\t\tthis(name, checkpointId, action, unused -> {\n+\t\t}, ignoreMissingWriter);\n+\t}\n+\n+\tCheckpointInProgressRequest(String name, long checkpointId, ThrowingConsumer<ChannelStateCheckpointWriter, Exception> action, Consumer<Throwable> discardAction, boolean ignoreMissingWriter) {\n+\t\tthis.checkpointId = checkpointId;\n+\t\tthis.action = action;\n+\t\tthis.discardAction = discardAction;\n+\t\tthis.name = name;\n+\t\tthis.ignoreMissingWriter = ignoreMissingWriter;\n+\t}\n+\n+\t@Override\n+\tpublic long getCheckpointId() {\n+\t\treturn checkpointId;\n+\t}\n+\n+\t@Override\n+\tpublic void cancel(Throwable cause) {\n+\t\tif (state.compareAndSet(CheckpointInProgressRequestState.NEW, CheckpointInProgressRequestState.CANCELLED)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTI1NjU1Ng=="}, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 130}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxNDg1NDczOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestExecutorImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNToxNTo0OFrOGCfRhQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxMToxOToxNlrOGCqn_w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTI2MjcyNQ==", "bodyText": "If the thread is still alive, do we also need to Thread.currentThread().interrupt()?", "url": "https://github.com/apache/flink/pull/11515#discussion_r405262725", "createdAt": "2020-04-08T05:15:48Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestExecutorImpl.java", "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.BlockingDeque;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.LinkedBlockingDeque;\n+\n+/**\n+ * Executes {@link ChannelStateWriteRequest}s in a separate thread. Any exception occurred during execution causes this\n+ * thread to stop and the exception to be re-thrown on any subsequent call.\n+ */\n+@ThreadSafe\n+class ChannelStateWriteRequestExecutorImpl implements ChannelStateWriteRequestExecutor {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriteRequestExecutorImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10_000;\n+\n+\tprivate final ChannelStateWriteRequestDispatcher dispatcher;\n+\tprivate final BlockingDeque<ChannelStateWriteRequest> deque;\n+\tprivate final Thread thread;\n+\tprivate volatile Exception thrown = null;\n+\tprivate volatile boolean wasClosed = false;\n+\n+\tChannelStateWriteRequestExecutorImpl(ChannelStateWriteRequestDispatcher dispatcher) {\n+\t\tthis(dispatcher, new LinkedBlockingDeque<>(DEFAULT_HANDOVER_CAPACITY));\n+\t}\n+\n+\tChannelStateWriteRequestExecutorImpl(ChannelStateWriteRequestDispatcher dispatcher, BlockingDeque<ChannelStateWriteRequest> deque) {\n+\t\tthis.dispatcher = dispatcher;\n+\t\tthis.deque = deque;\n+\t\tthis.thread = new Thread(this::run);\n+\t\tthis.thread.setDaemon(true);\n+\t}\n+\n+\t@VisibleForTesting\n+\tvoid run() {\n+\t\ttry {\n+\t\t\tloop();\n+\t\t} catch (Exception ex) {\n+\t\t\tthrown = ex;\n+\t\t} finally {\n+\t\t\tcleanupRequests();\n+\t\t\tdispatcher.close(thrown == null ? new CancellationException() : thrown);\n+\t\t}\n+\t\tLOG.debug(\"loop terminated\");\n+\t}\n+\n+\tprivate void loop() throws Exception {\n+\t\twhile (isActive()) {\n+\t\t\ttry {\n+\t\t\t\tdispatcher.dispatch(deque.take());\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tif (isActive()) {\n+\t\t\t\t\tLOG.debug(\"interrupted while waiting for a request (continue waiting)\", e);\n+\t\t\t\t} else {\n+\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate void cleanupRequests() {\n+\t\tThrowable cause = thrown == null ? new CancellationException() : thrown;\n+\t\tList<ChannelStateWriteRequest> drained = new ArrayList<>();\n+\t\tdeque.drainTo(drained);\n+\t\tLOG.info(\"discarding {} drained requests\", drained.size());\n+\t\tfor (ChannelStateWriteRequest request : drained) {\n+\t\t\trequest.cancel(cause);\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void start() throws IllegalStateException {\n+\t\tthis.thread.start();\n+\t}\n+\n+\t@Override\n+\tpublic void submit(ChannelStateWriteRequest request) throws Exception {\n+\t\tsubmitInternal(request, () -> deque.add(request));\n+\t}\n+\n+\t@Override\n+\tpublic void submitPriority(ChannelStateWriteRequest request) throws Exception {\n+\t\tsubmitInternal(request, () -> deque.addFirst(request));\n+\t}\n+\n+\tprivate void submitInternal(ChannelStateWriteRequest request, RunnableWithException action) throws Exception {\n+\t\ttry {\n+\t\t\taction.run();\n+\t\t} catch (Exception ex) {\n+\t\t\trequest.cancel(ex);\n+\t\t\tthrow ex;\n+\t\t}\n+\t\tensureRunning();\n+\t}\n+\n+\tprivate void ensureRunning() throws Exception {\n+\t\t// this check should be performed *at least after* enqueuing a request\n+\t\t// checking before is not enough because (check + enqueue) is not atomic\n+\t\tif (!isActive()) {\n+\t\t\tcleanupRequests();\n+\t\t\tthrow ExceptionUtils.firstOrSuppressed(new IllegalStateException(\"not running\"), thrown);\n+\t\t}\n+\t}\n+\n+\tprivate boolean isActive() {\n+\t\treturn !wasClosed && thread.isAlive();\n+\t}\n+\n+\t@Override\n+\tpublic void close() throws IOException {\n+\t\twasClosed = true;\n+\t\twhile (thread.isAlive()) {\n+\t\t\tthread.interrupt();\n+\t\t\ttry {\n+\t\t\t\tthread.join();\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tif (!thread.isAlive()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 146}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQ0ODcwMw==", "bodyText": "This will cause join to exit immediately (because the interrupt flag is set) and the loop will be essentially busy waiting.", "url": "https://github.com/apache/flink/pull/11515#discussion_r405448703", "createdAt": "2020-04-08T11:19:16Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestExecutorImpl.java", "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.BlockingDeque;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.LinkedBlockingDeque;\n+\n+/**\n+ * Executes {@link ChannelStateWriteRequest}s in a separate thread. Any exception occurred during execution causes this\n+ * thread to stop and the exception to be re-thrown on any subsequent call.\n+ */\n+@ThreadSafe\n+class ChannelStateWriteRequestExecutorImpl implements ChannelStateWriteRequestExecutor {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriteRequestExecutorImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10_000;\n+\n+\tprivate final ChannelStateWriteRequestDispatcher dispatcher;\n+\tprivate final BlockingDeque<ChannelStateWriteRequest> deque;\n+\tprivate final Thread thread;\n+\tprivate volatile Exception thrown = null;\n+\tprivate volatile boolean wasClosed = false;\n+\n+\tChannelStateWriteRequestExecutorImpl(ChannelStateWriteRequestDispatcher dispatcher) {\n+\t\tthis(dispatcher, new LinkedBlockingDeque<>(DEFAULT_HANDOVER_CAPACITY));\n+\t}\n+\n+\tChannelStateWriteRequestExecutorImpl(ChannelStateWriteRequestDispatcher dispatcher, BlockingDeque<ChannelStateWriteRequest> deque) {\n+\t\tthis.dispatcher = dispatcher;\n+\t\tthis.deque = deque;\n+\t\tthis.thread = new Thread(this::run);\n+\t\tthis.thread.setDaemon(true);\n+\t}\n+\n+\t@VisibleForTesting\n+\tvoid run() {\n+\t\ttry {\n+\t\t\tloop();\n+\t\t} catch (Exception ex) {\n+\t\t\tthrown = ex;\n+\t\t} finally {\n+\t\t\tcleanupRequests();\n+\t\t\tdispatcher.close(thrown == null ? new CancellationException() : thrown);\n+\t\t}\n+\t\tLOG.debug(\"loop terminated\");\n+\t}\n+\n+\tprivate void loop() throws Exception {\n+\t\twhile (isActive()) {\n+\t\t\ttry {\n+\t\t\t\tdispatcher.dispatch(deque.take());\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tif (isActive()) {\n+\t\t\t\t\tLOG.debug(\"interrupted while waiting for a request (continue waiting)\", e);\n+\t\t\t\t} else {\n+\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate void cleanupRequests() {\n+\t\tThrowable cause = thrown == null ? new CancellationException() : thrown;\n+\t\tList<ChannelStateWriteRequest> drained = new ArrayList<>();\n+\t\tdeque.drainTo(drained);\n+\t\tLOG.info(\"discarding {} drained requests\", drained.size());\n+\t\tfor (ChannelStateWriteRequest request : drained) {\n+\t\t\trequest.cancel(cause);\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void start() throws IllegalStateException {\n+\t\tthis.thread.start();\n+\t}\n+\n+\t@Override\n+\tpublic void submit(ChannelStateWriteRequest request) throws Exception {\n+\t\tsubmitInternal(request, () -> deque.add(request));\n+\t}\n+\n+\t@Override\n+\tpublic void submitPriority(ChannelStateWriteRequest request) throws Exception {\n+\t\tsubmitInternal(request, () -> deque.addFirst(request));\n+\t}\n+\n+\tprivate void submitInternal(ChannelStateWriteRequest request, RunnableWithException action) throws Exception {\n+\t\ttry {\n+\t\t\taction.run();\n+\t\t} catch (Exception ex) {\n+\t\t\trequest.cancel(ex);\n+\t\t\tthrow ex;\n+\t\t}\n+\t\tensureRunning();\n+\t}\n+\n+\tprivate void ensureRunning() throws Exception {\n+\t\t// this check should be performed *at least after* enqueuing a request\n+\t\t// checking before is not enough because (check + enqueue) is not atomic\n+\t\tif (!isActive()) {\n+\t\t\tcleanupRequests();\n+\t\t\tthrow ExceptionUtils.firstOrSuppressed(new IllegalStateException(\"not running\"), thrown);\n+\t\t}\n+\t}\n+\n+\tprivate boolean isActive() {\n+\t\treturn !wasClosed && thread.isAlive();\n+\t}\n+\n+\t@Override\n+\tpublic void close() throws IOException {\n+\t\twasClosed = true;\n+\t\twhile (thread.isAlive()) {\n+\t\t\tthread.interrupt();\n+\t\t\ttry {\n+\t\t\t\tthread.join();\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tif (!thread.isAlive()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTI2MjcyNQ=="}, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 146}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxNDkwNDM0OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestExecutorImpl.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNTo0MzowNlrOGCfvDA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxMToyMzo1NlrOGCqw2A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTI3MDI4NA==", "bodyText": "can we judge this condition only by thread.isAlive()? In some other cases if thread was ended not via #close() method by accident, it seems still make sense for the caller to make the decision.", "url": "https://github.com/apache/flink/pull/11515#discussion_r405270284", "createdAt": "2020-04-08T05:43:06Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestExecutorImpl.java", "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.BlockingDeque;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.LinkedBlockingDeque;\n+\n+/**\n+ * Executes {@link ChannelStateWriteRequest}s in a separate thread. Any exception occurred during execution causes this\n+ * thread to stop and the exception to be re-thrown on any subsequent call.\n+ */\n+@ThreadSafe\n+class ChannelStateWriteRequestExecutorImpl implements ChannelStateWriteRequestExecutor {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriteRequestExecutorImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10_000;\n+\n+\tprivate final ChannelStateWriteRequestDispatcher dispatcher;\n+\tprivate final BlockingDeque<ChannelStateWriteRequest> deque;\n+\tprivate final Thread thread;\n+\tprivate volatile Exception thrown = null;\n+\tprivate volatile boolean wasClosed = false;\n+\n+\tChannelStateWriteRequestExecutorImpl(ChannelStateWriteRequestDispatcher dispatcher) {\n+\t\tthis(dispatcher, new LinkedBlockingDeque<>(DEFAULT_HANDOVER_CAPACITY));\n+\t}\n+\n+\tChannelStateWriteRequestExecutorImpl(ChannelStateWriteRequestDispatcher dispatcher, BlockingDeque<ChannelStateWriteRequest> deque) {\n+\t\tthis.dispatcher = dispatcher;\n+\t\tthis.deque = deque;\n+\t\tthis.thread = new Thread(this::run);\n+\t\tthis.thread.setDaemon(true);\n+\t}\n+\n+\t@VisibleForTesting\n+\tvoid run() {\n+\t\ttry {\n+\t\t\tloop();\n+\t\t} catch (Exception ex) {\n+\t\t\tthrown = ex;\n+\t\t} finally {\n+\t\t\tcleanupRequests();\n+\t\t\tdispatcher.close(thrown == null ? new CancellationException() : thrown);\n+\t\t}\n+\t\tLOG.debug(\"loop terminated\");\n+\t}\n+\n+\tprivate void loop() throws Exception {\n+\t\twhile (isActive()) {\n+\t\t\ttry {\n+\t\t\t\tdispatcher.dispatch(deque.take());\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tif (isActive()) {\n+\t\t\t\t\tLOG.debug(\"interrupted while waiting for a request (continue waiting)\", e);\n+\t\t\t\t} else {\n+\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate void cleanupRequests() {\n+\t\tThrowable cause = thrown == null ? new CancellationException() : thrown;\n+\t\tList<ChannelStateWriteRequest> drained = new ArrayList<>();\n+\t\tdeque.drainTo(drained);\n+\t\tLOG.info(\"discarding {} drained requests\", drained.size());\n+\t\tfor (ChannelStateWriteRequest request : drained) {\n+\t\t\trequest.cancel(cause);\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void start() throws IllegalStateException {\n+\t\tthis.thread.start();\n+\t}\n+\n+\t@Override\n+\tpublic void submit(ChannelStateWriteRequest request) throws Exception {\n+\t\tsubmitInternal(request, () -> deque.add(request));\n+\t}\n+\n+\t@Override\n+\tpublic void submitPriority(ChannelStateWriteRequest request) throws Exception {\n+\t\tsubmitInternal(request, () -> deque.addFirst(request));\n+\t}\n+\n+\tprivate void submitInternal(ChannelStateWriteRequest request, RunnableWithException action) throws Exception {\n+\t\ttry {\n+\t\t\taction.run();\n+\t\t} catch (Exception ex) {\n+\t\t\trequest.cancel(ex);\n+\t\t\tthrow ex;\n+\t\t}\n+\t\tensureRunning();\n+\t}\n+\n+\tprivate void ensureRunning() throws Exception {\n+\t\t// this check should be performed *at least after* enqueuing a request\n+\t\t// checking before is not enough because (check + enqueue) is not atomic\n+\t\tif (!isActive()) {\n+\t\t\tcleanupRequests();\n+\t\t\tthrow ExceptionUtils.firstOrSuppressed(new IllegalStateException(\"not running\"), thrown);\n+\t\t}\n+\t}\n+\n+\tprivate boolean isActive() {\n+\t\treturn !wasClosed && thread.isAlive();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 135}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQ1MDk2OA==", "bodyText": "This method is used inside loop and ensureRunning.\nIn loop it actually wasClosed that matters (so it's possible to exit loop).\nIn ensureRunning we could use only thread.isAlive; but there is no guarantee when it will return false after wasClosed was set.", "url": "https://github.com/apache/flink/pull/11515#discussion_r405450968", "createdAt": "2020-04-08T11:23:56Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestExecutorImpl.java", "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.BlockingDeque;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.LinkedBlockingDeque;\n+\n+/**\n+ * Executes {@link ChannelStateWriteRequest}s in a separate thread. Any exception occurred during execution causes this\n+ * thread to stop and the exception to be re-thrown on any subsequent call.\n+ */\n+@ThreadSafe\n+class ChannelStateWriteRequestExecutorImpl implements ChannelStateWriteRequestExecutor {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriteRequestExecutorImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10_000;\n+\n+\tprivate final ChannelStateWriteRequestDispatcher dispatcher;\n+\tprivate final BlockingDeque<ChannelStateWriteRequest> deque;\n+\tprivate final Thread thread;\n+\tprivate volatile Exception thrown = null;\n+\tprivate volatile boolean wasClosed = false;\n+\n+\tChannelStateWriteRequestExecutorImpl(ChannelStateWriteRequestDispatcher dispatcher) {\n+\t\tthis(dispatcher, new LinkedBlockingDeque<>(DEFAULT_HANDOVER_CAPACITY));\n+\t}\n+\n+\tChannelStateWriteRequestExecutorImpl(ChannelStateWriteRequestDispatcher dispatcher, BlockingDeque<ChannelStateWriteRequest> deque) {\n+\t\tthis.dispatcher = dispatcher;\n+\t\tthis.deque = deque;\n+\t\tthis.thread = new Thread(this::run);\n+\t\tthis.thread.setDaemon(true);\n+\t}\n+\n+\t@VisibleForTesting\n+\tvoid run() {\n+\t\ttry {\n+\t\t\tloop();\n+\t\t} catch (Exception ex) {\n+\t\t\tthrown = ex;\n+\t\t} finally {\n+\t\t\tcleanupRequests();\n+\t\t\tdispatcher.close(thrown == null ? new CancellationException() : thrown);\n+\t\t}\n+\t\tLOG.debug(\"loop terminated\");\n+\t}\n+\n+\tprivate void loop() throws Exception {\n+\t\twhile (isActive()) {\n+\t\t\ttry {\n+\t\t\t\tdispatcher.dispatch(deque.take());\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tif (isActive()) {\n+\t\t\t\t\tLOG.debug(\"interrupted while waiting for a request (continue waiting)\", e);\n+\t\t\t\t} else {\n+\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate void cleanupRequests() {\n+\t\tThrowable cause = thrown == null ? new CancellationException() : thrown;\n+\t\tList<ChannelStateWriteRequest> drained = new ArrayList<>();\n+\t\tdeque.drainTo(drained);\n+\t\tLOG.info(\"discarding {} drained requests\", drained.size());\n+\t\tfor (ChannelStateWriteRequest request : drained) {\n+\t\t\trequest.cancel(cause);\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void start() throws IllegalStateException {\n+\t\tthis.thread.start();\n+\t}\n+\n+\t@Override\n+\tpublic void submit(ChannelStateWriteRequest request) throws Exception {\n+\t\tsubmitInternal(request, () -> deque.add(request));\n+\t}\n+\n+\t@Override\n+\tpublic void submitPriority(ChannelStateWriteRequest request) throws Exception {\n+\t\tsubmitInternal(request, () -> deque.addFirst(request));\n+\t}\n+\n+\tprivate void submitInternal(ChannelStateWriteRequest request, RunnableWithException action) throws Exception {\n+\t\ttry {\n+\t\t\taction.run();\n+\t\t} catch (Exception ex) {\n+\t\t\trequest.cancel(ex);\n+\t\t\tthrow ex;\n+\t\t}\n+\t\tensureRunning();\n+\t}\n+\n+\tprivate void ensureRunning() throws Exception {\n+\t\t// this check should be performed *at least after* enqueuing a request\n+\t\t// checking before is not enough because (check + enqueue) is not atomic\n+\t\tif (!isActive()) {\n+\t\t\tcleanupRequests();\n+\t\t\tthrow ExceptionUtils.firstOrSuppressed(new IllegalStateException(\"not running\"), thrown);\n+\t\t}\n+\t}\n+\n+\tprivate boolean isActive() {\n+\t\treturn !wasClosed && thread.isAlive();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTI3MDI4NA=="}, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 135}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxNTAwMzE2OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNjoyNDoyOVrOGCgoFw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxMTozNDowMlrOGCrEjQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTI4NDg4Nw==", "bodyText": "This can be done only via SubtaskCheckpointCoordinatorImpl#close, but i do not see StreamTask or other places will call SubtaskCheckpointCoordinatorImpl#close from the current codes. What is the consideration for this?", "url": "https://github.com/apache/flink/pull/11515#discussion_r405284887", "createdAt": "2020-04-08T06:24:29Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has by default\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ * Thread-safety: this class is thread-safe when used with a thread-safe {@link ChannelStateWriteRequestExecutor executor}\n+ * (e.g. default {@link ChannelStateWriteRequestExecutorImpl}.\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate final ChannelStateWriteRequestExecutor executor;\n+\tprivate final ConcurrentMap<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.\n+\t */\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryResolver) {\n+\t\tthis(streamFactoryResolver, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link ChannelStateSerializerImpl default} {@link ChannelStateSerializer},\n+\t * and a {@link ChannelStateWriteRequestExecutorImpl}.\n+\t *\n+\t * @param maxCheckpoints        maximum number of checkpoints to be written currently or finished but not taken yet.\n+\t * @param streamFactoryResolver a factory to obtain output stream factory for a given checkpoint\n+\t */\n+\tChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryResolver, int maxCheckpoints) {\n+\t\tthis(\n+\t\t\tnew ConcurrentHashMap<>(maxCheckpoints),\n+\t\t\tnew ChannelStateWriteRequestExecutorImpl(new ChannelStateWriteRequestDispatcherImpl(streamFactoryResolver, new ChannelStateSerializerImpl())),\n+\t\t\tmaxCheckpoints\n+\t\t);\n+\t}\n+\n+\tChannelStateWriterImpl(ConcurrentMap<Long, ChannelStateWriteResult> results, ChannelStateWriteRequestExecutor executor, int maxCheckpoints) {\n+\t\tthis.results = results;\n+\t\tthis.maxCheckpoints = maxCheckpoints;\n+\t\tthis.executor = executor;\n+\t}\n+\n+\t@Override\n+\tpublic void start(long checkpointId, CheckpointOptions checkpointOptions) {\n+\t\tLOG.debug(\"start checkpoint {} ({})\", checkpointId, checkpointOptions);\n+\t\tChannelStateWriteResult result = new ChannelStateWriteResult();\n+\t\tChannelStateWriteResult put = results.computeIfAbsent(checkpointId, id -> {\n+\t\t\tPreconditions.checkState(results.size() < maxCheckpoints, \"results.size() > maxCheckpoints\", results.size(), maxCheckpoints);\n+\t\t\tenqueue(new CheckpointStartRequest(checkpointId, result, checkpointOptions.getTargetLocation()), false);\n+\t\t\treturn result;\n+\t\t});\n+\t\tPreconditions.checkArgument(put == result, \"result future already present for checkpoint id: \" + checkpointId);\n+\t}\n+\n+\t@Override\n+\tpublic void addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add input data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)), false);\n+\t}\n+\n+\t@Override\n+\tpublic void addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add output data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)), false);\n+\t}\n+\n+\t@Override\n+\tpublic void finishInput(long checkpointId) {\n+\t\tLOG.debug(\"finish input data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeInput(checkpointId), false);\n+\t}\n+\n+\t@Override\n+\tpublic void finishOutput(long checkpointId) {\n+\t\tLOG.debug(\"finish output data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeOutput(checkpointId), false);\n+\t}\n+\n+\t@Override\n+\tpublic void abort(long checkpointId, Throwable cause) {\n+\t\tLOG.debug(\"abort, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(ChannelStateWriteRequest.abort(checkpointId, cause), true); // abort already started\n+\t\tenqueue(ChannelStateWriteRequest.abort(checkpointId, cause), false); // abort enqueued but not started\n+\t}\n+\n+\t@Override\n+\tpublic ChannelStateWriteResult getWriteResult(long checkpointId) {\n+\t\tLOG.debug(\"requested write result, checkpoint id: {}\", checkpointId);\n+\t\tChannelStateWriteResult result = results.remove(checkpointId);\n+\t\tPreconditions.checkArgument(result != null, \"channel state write result not found for checkpoint id \" + checkpointId);\n+\t\treturn result;\n+\t}\n+\n+\tpublic void open() {\n+\t\texecutor.start();\n+\t}\n+\n+\t@Override\n+\tpublic void close() throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 148}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQ1NjAxMw==", "bodyText": "SubtaskCheckpointCoordinatorImpl is registered with CloseableRegistry in its constructor (which in turn is closed by StreamTask).", "url": "https://github.com/apache/flink/pull/11515#discussion_r405456013", "createdAt": "2020-04-08T11:34:02Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has by default\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ * Thread-safety: this class is thread-safe when used with a thread-safe {@link ChannelStateWriteRequestExecutor executor}\n+ * (e.g. default {@link ChannelStateWriteRequestExecutorImpl}.\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate final ChannelStateWriteRequestExecutor executor;\n+\tprivate final ConcurrentMap<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.\n+\t */\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryResolver) {\n+\t\tthis(streamFactoryResolver, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link ChannelStateSerializerImpl default} {@link ChannelStateSerializer},\n+\t * and a {@link ChannelStateWriteRequestExecutorImpl}.\n+\t *\n+\t * @param maxCheckpoints        maximum number of checkpoints to be written currently or finished but not taken yet.\n+\t * @param streamFactoryResolver a factory to obtain output stream factory for a given checkpoint\n+\t */\n+\tChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryResolver, int maxCheckpoints) {\n+\t\tthis(\n+\t\t\tnew ConcurrentHashMap<>(maxCheckpoints),\n+\t\t\tnew ChannelStateWriteRequestExecutorImpl(new ChannelStateWriteRequestDispatcherImpl(streamFactoryResolver, new ChannelStateSerializerImpl())),\n+\t\t\tmaxCheckpoints\n+\t\t);\n+\t}\n+\n+\tChannelStateWriterImpl(ConcurrentMap<Long, ChannelStateWriteResult> results, ChannelStateWriteRequestExecutor executor, int maxCheckpoints) {\n+\t\tthis.results = results;\n+\t\tthis.maxCheckpoints = maxCheckpoints;\n+\t\tthis.executor = executor;\n+\t}\n+\n+\t@Override\n+\tpublic void start(long checkpointId, CheckpointOptions checkpointOptions) {\n+\t\tLOG.debug(\"start checkpoint {} ({})\", checkpointId, checkpointOptions);\n+\t\tChannelStateWriteResult result = new ChannelStateWriteResult();\n+\t\tChannelStateWriteResult put = results.computeIfAbsent(checkpointId, id -> {\n+\t\t\tPreconditions.checkState(results.size() < maxCheckpoints, \"results.size() > maxCheckpoints\", results.size(), maxCheckpoints);\n+\t\t\tenqueue(new CheckpointStartRequest(checkpointId, result, checkpointOptions.getTargetLocation()), false);\n+\t\t\treturn result;\n+\t\t});\n+\t\tPreconditions.checkArgument(put == result, \"result future already present for checkpoint id: \" + checkpointId);\n+\t}\n+\n+\t@Override\n+\tpublic void addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add input data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)), false);\n+\t}\n+\n+\t@Override\n+\tpublic void addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add output data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)), false);\n+\t}\n+\n+\t@Override\n+\tpublic void finishInput(long checkpointId) {\n+\t\tLOG.debug(\"finish input data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeInput(checkpointId), false);\n+\t}\n+\n+\t@Override\n+\tpublic void finishOutput(long checkpointId) {\n+\t\tLOG.debug(\"finish output data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeOutput(checkpointId), false);\n+\t}\n+\n+\t@Override\n+\tpublic void abort(long checkpointId, Throwable cause) {\n+\t\tLOG.debug(\"abort, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(ChannelStateWriteRequest.abort(checkpointId, cause), true); // abort already started\n+\t\tenqueue(ChannelStateWriteRequest.abort(checkpointId, cause), false); // abort enqueued but not started\n+\t}\n+\n+\t@Override\n+\tpublic ChannelStateWriteResult getWriteResult(long checkpointId) {\n+\t\tLOG.debug(\"requested write result, checkpoint id: {}\", checkpointId);\n+\t\tChannelStateWriteResult result = results.remove(checkpointId);\n+\t\tPreconditions.checkArgument(result != null, \"channel state write result not found for checkpoint id \" + checkpointId);\n+\t\treturn result;\n+\t}\n+\n+\tpublic void open() {\n+\t\texecutor.start();\n+\t}\n+\n+\t@Override\n+\tpublic void close() throws IOException {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTI4NDg4Nw=="}, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 148}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxNTA2MzUzOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/taskmanager/Task.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNjo0ODoxOVrOGChMZg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNjo0ODoxOVrOGChMZg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTI5NDE4Mg==", "bodyText": "nit: irrelevant change, better to have spaces", "url": "https://github.com/apache/flink/pull/11515#discussion_r405294182", "createdAt": "2020-04-08T06:48:19Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/taskmanager/Task.java", "diffHunk": "@@ -1057,7 +1062,7 @@ else if (current == ExecutionState.RUNNING) {\n \t\t\t\t\t\t// case the canceling could not continue\n \n \t\t\t\t\t\t// The canceller calls cancel and interrupts the executing thread once\n-\t\t\t\t\t\tRunnable canceler = new TaskCanceler(LOG, this :: closeNetworkResources, invokable, executingThread, taskNameWithSubtask);\n+\t\t\t\t\t\tRunnable canceler = new TaskCanceler(LOG, this::closeNetworkResources, invokable, executingThread, taskNameWithSubtask);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bdb06fc00a0da1e0c3df87383de8ebb0a28b1ef3"}, "originalPosition": 39}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxNTA5Mjk5OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNjo1ODo0NFrOGChedA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNjo1ODo0NFrOGChedA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTI5ODgwNA==", "bodyText": "Do we have the tests coverage for this new introduced caching function in the commit [FLINK-16744][task] send channel state handles to JM?", "url": "https://github.com/apache/flink/pull/11515#discussion_r405298804", "createdAt": "2020-04-08T06:58:44Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -188,6 +221,77 @@ public void checkpointState(\n \t\t}\n \t}\n \n+\tprivate OperatorSnapshotFutures buildOperatorSnapshotFutures(\n+\t\t\tCheckpointMetaData checkpointMetaData,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tOperatorChain<?, ?> operatorChain,\n+\t\t\tStreamOperator<?> op,\n+\t\t\tSupplier<Boolean> isCanceled,\n+\t\t\tChannelStateWriteResult channelStateWriteResult) throws Exception {\n+\t\tCheckpointStreamFactory storage = checkpointStorage.resolveCheckpointStorageLocation(\n+\t\t\tcheckpointMetaData.getCheckpointId(),\n+\t\t\tcheckpointOptions.getTargetLocation());\n+\t\tOperatorSnapshotFutures snapshotInProgress = checkpointStreamOperator(\n+\t\t\top,\n+\t\t\tcheckpointMetaData,\n+\t\t\tcheckpointOptions,\n+\t\t\tstorage,\n+\t\t\tisCanceled);\n+\t\tif (op == operatorChain.getHeadOperator()) {\n+\t\t\tsnapshotInProgress.setInputChannelStateFuture(\n+\t\t\t\tchannelStateWriteResult\n+\t\t\t\t\t.getInputChannelStateHandles()\n+\t\t\t\t\t.thenApply(StateObjectCollection::new)\n+\t\t\t\t\t.thenApply(SnapshotResult::of));\n+\t\t}\n+\t\tif (op == operatorChain.getTailOperator()) {\n+\t\t\tsnapshotInProgress.setResultSubpartitionStateFuture(\n+\t\t\t\tchannelStateWriteResult\n+\t\t\t\t\t.getResultSubpartitionStateHandles()\n+\t\t\t\t\t.thenApply(StateObjectCollection::new)\n+\t\t\t\t\t.thenApply(SnapshotResult::of));\n+\t\t}\n+\t\treturn snapshotInProgress;\n+\t}\n+\n+\t@Override\n+\tpublic void close() throws IOException {\n+\t\tchannelStateWriter.close();\n+\t}\n+\n+\t// Caches checkpoint output stream factories to prevent multiple output stream per checkpoint.\n+\t// This could result from requesting output stream by different entities (this and channelStateWriter)\n+\t// We can't just pass a stream to the channelStateWriter because it can receive checkpoint call earlier than this class\n+\t// in some unaligned checkpoints scenarios\n+\tprivate static class CachingCheckpointStorageWorkerView implements CheckpointStorageWorkerView {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bdb06fc00a0da1e0c3df87383de8ebb0a28b1ef3"}, "originalPosition": 179}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxNTEyMzkxOnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNzowOToyMlrOGChxlw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNzowOToyMlrOGChxlw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTMwMzcwMw==", "bodyText": "it is not suggested putting multiple arguments in one line. split line for every argument", "url": "https://github.com/apache/flink/pull/11515#discussion_r405303703", "createdAt": "2020-04-08T07:09:22Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -130,95 +130,108 @@ public void checkpointState(\n \n \t\t// Step (1): Prepare the checkpoint, allow operators to do some pre-barrier work.\n \t\t//           The pre-barrier work should be nothing or minimal in the common case.\n-\t\toperatorChain.prepareSnapshotPreBarrier(checkpointId);\n+\t\toperatorChain.prepareSnapshotPreBarrier(metadata.getCheckpointId());\n \n \t\t// Step (2): Send the checkpoint barrier downstream\n-\t\toperatorChain.broadcastCheckpointBarrier(\n-\t\t\tcheckpointId,\n-\t\t\tcheckpointMetaData.getTimestamp(),\n-\t\t\tcheckpointOptions);\n+\t\toperatorChain.broadcastCheckpointBarrier(metadata.getCheckpointId(), metadata.getTimestamp(), options);\n \n-\t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not\n-\t\t//           impact progress of the streaming topology\n+\t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not impact progress of the streaming topology\n \n-\t\tlong startSyncPartNano = System.nanoTime();\n-\n-\t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress = new HashMap<>(operatorChain.getNumberOfOperators());\n-\t\tChannelStateWriteResult channelStateWriteResult =\n-\t\t\tcheckpointOptions.getCheckpointType() == CHECKPOINT ? channelStateWriter.getWriteResult(checkpointMetaData.getCheckpointId()) :\n-\t\t\t\tChannelStateWriteResult.EMPTY;\n+\t\tMap<OperatorID, OperatorSnapshotFutures> snapshotFutures = new HashMap<>(operatorChain.getNumberOfOperators());\n \t\ttry {\n-\t\t\tfor (StreamOperatorWrapper<?, ?> operatorWrapper : operatorChain.getAllOperators(true)) {\n-\t\t\t\toperatorSnapshotsInProgress.put(\n-\t\t\t\t\toperatorWrapper.getStreamOperator().getOperatorID(),\n-\t\t\t\t\tbuildOperatorSnapshotFutures(\n-\t\t\t\t\t\tcheckpointMetaData,\n-\t\t\t\t\t\tcheckpointOptions,\n-\t\t\t\t\t\toperatorChain,\n-\t\t\t\t\t\toperatorWrapper.getStreamOperator(),\n-\t\t\t\t\t\tisCanceled,\n-\t\t\t\t\t\tchannelStateWriteResult)\n-\t\t\t\t);\n-\t\t\t}\n-\t\t\tcheckpointStorage.clearCacheFor(checkpointMetaData.getCheckpointId());\n+\t\t\ttakeSnapshotSync(snapshotFutures, metadata, metrics, options, operatorChain, isCanceled);\n+\t\t\tfinishAndReportAsync(snapshotFutures, metadata, metrics);\n+\t\t} catch (Exception ex) {\n+\t\t\tcleanup(snapshotFutures, metadata, metrics, options, ex);\n+\t\t}\n+\t}\n \n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\"Finished synchronous checkpoints for checkpoint {} on task {}\",\n-\t\t\t\t\tcheckpointMetaData.getCheckpointId(), taskName);\n-\t\t\t}\n+\tprivate void cleanup(\n+\t\t\tMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress,\n+\t\t\tCheckpointMetaData metadata,\n+\t\t\tCheckpointMetrics metrics, CheckpointOptions options,\n+\t\t\tException ex) throws Exception {\n \n-\t\t\tlong startAsyncPartNano = System.nanoTime();\n-\n-\t\t\tcheckpointMetrics.setSyncDurationMillis((startAsyncPartNano - startSyncPartNano) / 1_000_000);\n-\n-\t\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n-\t\t\texecutorService.execute(new AsyncCheckpointRunnable(\n-\t\t\t\toperatorSnapshotsInProgress,\n-\t\t\t\tcheckpointMetaData,\n-\t\t\t\tcheckpointMetrics,\n-\t\t\t\tstartAsyncPartNano,\n-\t\t\t\ttaskName,\n-\t\t\t\tcloseableRegistry,\n-\t\t\t\tenv,\n-\t\t\t\tasyncExceptionHandler));\n-\n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\n-\t\t\t\t\t\"{} - finished synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n-\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n-\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n-\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n-\t\t\t}\n-\t\t} catch (Exception ex) {\n-\t\t\t// Cleanup to release resources\n-\t\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n-\t\t\t\tif (null != operatorSnapshotResult) {\n-\t\t\t\t\ttry {\n-\t\t\t\t\t\toperatorSnapshotResult.cancel();\n-\t\t\t\t\t} catch (Exception e) {\n-\t\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n-\t\t\t\t\t}\n+\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n+\t\t\tif (operatorSnapshotResult != null) {\n+\t\t\t\ttry {\n+\t\t\t\t\toperatorSnapshotResult.cancel();\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n \t\t\t\t}\n \t\t\t}\n+\t\t}\n \n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\n-\t\t\t\t\t\"{} - did NOT finish synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n-\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n-\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n-\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n-\t\t\t}\n+\t\tif (LOG.isDebugEnabled()) {\n+\t\t\tLOG.debug(\n+\t\t\t\t\"{} - did NOT finish synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n+\t\t\t\ttaskName, metadata.getCheckpointId(),\n+\t\t\t\tmetrics.getAlignmentDurationNanos() / 1_000_000,\n+\t\t\t\tmetrics.getSyncDurationMillis());\n+\t\t}\n \n-\t\t\tif (checkpointOptions.getCheckpointType().isSynchronous()) {\n-\t\t\t\t// in the case of a synchronous checkpoint, we always rethrow the exception,\n-\t\t\t\t// so that the task fails.\n-\t\t\t\t// this is because the intention is always to stop the job after this checkpointing\n-\t\t\t\t// operation, and without the failure, the task would go back to normal execution.\n-\t\t\t\tthrow ex;\n-\t\t\t} else {\n-\t\t\t\tenv.declineCheckpoint(checkpointMetaData.getCheckpointId(), ex);\n-\t\t\t}\n+\t\tif (options.getCheckpointType().isSynchronous()) {\n+\t\t\t// in the case of a synchronous checkpoint, we always rethrow the exception,\n+\t\t\t// so that the task fails.\n+\t\t\t// this is because the intention is always to stop the job after this checkpointing\n+\t\t\t// operation, and without the failure, the task would go back to normal execution.\n+\t\t\tthrow ex;\n+\t\t} else {\n+\t\t\tenv.declineCheckpoint(metadata.getCheckpointId(), ex);\n+\t\t}\n+\t}\n+\n+\tprivate void finishAndReportAsync(Map<OperatorID, OperatorSnapshotFutures> snapshotFutures, CheckpointMetaData metadata, CheckpointMetrics metrics) {\n+\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n+\t\texecutorService.execute(new AsyncCheckpointRunnable(\n+\t\t\tsnapshotFutures,\n+\t\t\tmetadata,\n+\t\t\tmetrics,\n+\t\t\tSystem.nanoTime(),\n+\t\t\ttaskName,\n+\t\t\tcloseableRegistry,\n+\t\t\tenv,\n+\t\t\tasyncExceptionHandler));\n+\t}\n+\n+\tprivate void takeSnapshotSync(\n+\t\tMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress, CheckpointMetaData checkpointMetaData,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "102a8f1f7c4926781fba187273cd6d324f8d0bd2"}, "originalPosition": 167}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxNTEyODg5OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNzoxMTowM1rOGCh0lg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxNzowMTozMVrOGC4hLA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTMwNDQ3MA==", "bodyText": "I guess the condition checkpointOptions.getCheckpointType() == CHECKPOINT should be consistent with sendChannelState in constructor?", "url": "https://github.com/apache/flink/pull/11515#discussion_r405304470", "createdAt": "2020-04-08T07:11:03Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -130,95 +130,108 @@ public void checkpointState(\n \n \t\t// Step (1): Prepare the checkpoint, allow operators to do some pre-barrier work.\n \t\t//           The pre-barrier work should be nothing or minimal in the common case.\n-\t\toperatorChain.prepareSnapshotPreBarrier(checkpointId);\n+\t\toperatorChain.prepareSnapshotPreBarrier(metadata.getCheckpointId());\n \n \t\t// Step (2): Send the checkpoint barrier downstream\n-\t\toperatorChain.broadcastCheckpointBarrier(\n-\t\t\tcheckpointId,\n-\t\t\tcheckpointMetaData.getTimestamp(),\n-\t\t\tcheckpointOptions);\n+\t\toperatorChain.broadcastCheckpointBarrier(metadata.getCheckpointId(), metadata.getTimestamp(), options);\n \n-\t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not\n-\t\t//           impact progress of the streaming topology\n+\t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not impact progress of the streaming topology\n \n-\t\tlong startSyncPartNano = System.nanoTime();\n-\n-\t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress = new HashMap<>(operatorChain.getNumberOfOperators());\n-\t\tChannelStateWriteResult channelStateWriteResult =\n-\t\t\tcheckpointOptions.getCheckpointType() == CHECKPOINT ? channelStateWriter.getWriteResult(checkpointMetaData.getCheckpointId()) :\n-\t\t\t\tChannelStateWriteResult.EMPTY;\n+\t\tMap<OperatorID, OperatorSnapshotFutures> snapshotFutures = new HashMap<>(operatorChain.getNumberOfOperators());\n \t\ttry {\n-\t\t\tfor (StreamOperatorWrapper<?, ?> operatorWrapper : operatorChain.getAllOperators(true)) {\n-\t\t\t\toperatorSnapshotsInProgress.put(\n-\t\t\t\t\toperatorWrapper.getStreamOperator().getOperatorID(),\n-\t\t\t\t\tbuildOperatorSnapshotFutures(\n-\t\t\t\t\t\tcheckpointMetaData,\n-\t\t\t\t\t\tcheckpointOptions,\n-\t\t\t\t\t\toperatorChain,\n-\t\t\t\t\t\toperatorWrapper.getStreamOperator(),\n-\t\t\t\t\t\tisCanceled,\n-\t\t\t\t\t\tchannelStateWriteResult)\n-\t\t\t\t);\n-\t\t\t}\n-\t\t\tcheckpointStorage.clearCacheFor(checkpointMetaData.getCheckpointId());\n+\t\t\ttakeSnapshotSync(snapshotFutures, metadata, metrics, options, operatorChain, isCanceled);\n+\t\t\tfinishAndReportAsync(snapshotFutures, metadata, metrics);\n+\t\t} catch (Exception ex) {\n+\t\t\tcleanup(snapshotFutures, metadata, metrics, options, ex);\n+\t\t}\n+\t}\n \n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\"Finished synchronous checkpoints for checkpoint {} on task {}\",\n-\t\t\t\t\tcheckpointMetaData.getCheckpointId(), taskName);\n-\t\t\t}\n+\tprivate void cleanup(\n+\t\t\tMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress,\n+\t\t\tCheckpointMetaData metadata,\n+\t\t\tCheckpointMetrics metrics, CheckpointOptions options,\n+\t\t\tException ex) throws Exception {\n \n-\t\t\tlong startAsyncPartNano = System.nanoTime();\n-\n-\t\t\tcheckpointMetrics.setSyncDurationMillis((startAsyncPartNano - startSyncPartNano) / 1_000_000);\n-\n-\t\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n-\t\t\texecutorService.execute(new AsyncCheckpointRunnable(\n-\t\t\t\toperatorSnapshotsInProgress,\n-\t\t\t\tcheckpointMetaData,\n-\t\t\t\tcheckpointMetrics,\n-\t\t\t\tstartAsyncPartNano,\n-\t\t\t\ttaskName,\n-\t\t\t\tcloseableRegistry,\n-\t\t\t\tenv,\n-\t\t\t\tasyncExceptionHandler));\n-\n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\n-\t\t\t\t\t\"{} - finished synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n-\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n-\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n-\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n-\t\t\t}\n-\t\t} catch (Exception ex) {\n-\t\t\t// Cleanup to release resources\n-\t\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n-\t\t\t\tif (null != operatorSnapshotResult) {\n-\t\t\t\t\ttry {\n-\t\t\t\t\t\toperatorSnapshotResult.cancel();\n-\t\t\t\t\t} catch (Exception e) {\n-\t\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n-\t\t\t\t\t}\n+\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n+\t\t\tif (operatorSnapshotResult != null) {\n+\t\t\t\ttry {\n+\t\t\t\t\toperatorSnapshotResult.cancel();\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n \t\t\t\t}\n \t\t\t}\n+\t\t}\n \n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\n-\t\t\t\t\t\"{} - did NOT finish synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n-\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n-\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n-\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n-\t\t\t}\n+\t\tif (LOG.isDebugEnabled()) {\n+\t\t\tLOG.debug(\n+\t\t\t\t\"{} - did NOT finish synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n+\t\t\t\ttaskName, metadata.getCheckpointId(),\n+\t\t\t\tmetrics.getAlignmentDurationNanos() / 1_000_000,\n+\t\t\t\tmetrics.getSyncDurationMillis());\n+\t\t}\n \n-\t\t\tif (checkpointOptions.getCheckpointType().isSynchronous()) {\n-\t\t\t\t// in the case of a synchronous checkpoint, we always rethrow the exception,\n-\t\t\t\t// so that the task fails.\n-\t\t\t\t// this is because the intention is always to stop the job after this checkpointing\n-\t\t\t\t// operation, and without the failure, the task would go back to normal execution.\n-\t\t\t\tthrow ex;\n-\t\t\t} else {\n-\t\t\t\tenv.declineCheckpoint(checkpointMetaData.getCheckpointId(), ex);\n-\t\t\t}\n+\t\tif (options.getCheckpointType().isSynchronous()) {\n+\t\t\t// in the case of a synchronous checkpoint, we always rethrow the exception,\n+\t\t\t// so that the task fails.\n+\t\t\t// this is because the intention is always to stop the job after this checkpointing\n+\t\t\t// operation, and without the failure, the task would go back to normal execution.\n+\t\t\tthrow ex;\n+\t\t} else {\n+\t\t\tenv.declineCheckpoint(metadata.getCheckpointId(), ex);\n+\t\t}\n+\t}\n+\n+\tprivate void finishAndReportAsync(Map<OperatorID, OperatorSnapshotFutures> snapshotFutures, CheckpointMetaData metadata, CheckpointMetrics metrics) {\n+\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n+\t\texecutorService.execute(new AsyncCheckpointRunnable(\n+\t\t\tsnapshotFutures,\n+\t\t\tmetadata,\n+\t\t\tmetrics,\n+\t\t\tSystem.nanoTime(),\n+\t\t\ttaskName,\n+\t\t\tcloseableRegistry,\n+\t\t\tenv,\n+\t\t\tasyncExceptionHandler));\n+\t}\n+\n+\tprivate void takeSnapshotSync(\n+\t\tMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress, CheckpointMetaData checkpointMetaData,\n+\t\tCheckpointMetrics checkpointMetrics, CheckpointOptions checkpointOptions,\n+\t\tOperatorChain<?, ?> operatorChain,\n+\t\tSupplier<Boolean> isCanceled) throws Exception {\n+\n+\t\tlong checkpointId = checkpointMetaData.getCheckpointId();\n+\t\tlong started = System.nanoTime();\n+\n+\t\tChannelStateWriteResult channelStateWriteResult = checkpointOptions.getCheckpointType() == CHECKPOINT ?", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "102a8f1f7c4926781fba187273cd6d324f8d0bd2"}, "originalPosition": 175}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQ2MjczMw==", "bodyText": "No,\n\nsendChannelState is set on startup and never changes and means \"unaligned checkpoints enabled\".\ncheckpointOptions.getCheckpointType() varies from call to call", "url": "https://github.com/apache/flink/pull/11515#discussion_r405462733", "createdAt": "2020-04-08T11:47:11Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -130,95 +130,108 @@ public void checkpointState(\n \n \t\t// Step (1): Prepare the checkpoint, allow operators to do some pre-barrier work.\n \t\t//           The pre-barrier work should be nothing or minimal in the common case.\n-\t\toperatorChain.prepareSnapshotPreBarrier(checkpointId);\n+\t\toperatorChain.prepareSnapshotPreBarrier(metadata.getCheckpointId());\n \n \t\t// Step (2): Send the checkpoint barrier downstream\n-\t\toperatorChain.broadcastCheckpointBarrier(\n-\t\t\tcheckpointId,\n-\t\t\tcheckpointMetaData.getTimestamp(),\n-\t\t\tcheckpointOptions);\n+\t\toperatorChain.broadcastCheckpointBarrier(metadata.getCheckpointId(), metadata.getTimestamp(), options);\n \n-\t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not\n-\t\t//           impact progress of the streaming topology\n+\t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not impact progress of the streaming topology\n \n-\t\tlong startSyncPartNano = System.nanoTime();\n-\n-\t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress = new HashMap<>(operatorChain.getNumberOfOperators());\n-\t\tChannelStateWriteResult channelStateWriteResult =\n-\t\t\tcheckpointOptions.getCheckpointType() == CHECKPOINT ? channelStateWriter.getWriteResult(checkpointMetaData.getCheckpointId()) :\n-\t\t\t\tChannelStateWriteResult.EMPTY;\n+\t\tMap<OperatorID, OperatorSnapshotFutures> snapshotFutures = new HashMap<>(operatorChain.getNumberOfOperators());\n \t\ttry {\n-\t\t\tfor (StreamOperatorWrapper<?, ?> operatorWrapper : operatorChain.getAllOperators(true)) {\n-\t\t\t\toperatorSnapshotsInProgress.put(\n-\t\t\t\t\toperatorWrapper.getStreamOperator().getOperatorID(),\n-\t\t\t\t\tbuildOperatorSnapshotFutures(\n-\t\t\t\t\t\tcheckpointMetaData,\n-\t\t\t\t\t\tcheckpointOptions,\n-\t\t\t\t\t\toperatorChain,\n-\t\t\t\t\t\toperatorWrapper.getStreamOperator(),\n-\t\t\t\t\t\tisCanceled,\n-\t\t\t\t\t\tchannelStateWriteResult)\n-\t\t\t\t);\n-\t\t\t}\n-\t\t\tcheckpointStorage.clearCacheFor(checkpointMetaData.getCheckpointId());\n+\t\t\ttakeSnapshotSync(snapshotFutures, metadata, metrics, options, operatorChain, isCanceled);\n+\t\t\tfinishAndReportAsync(snapshotFutures, metadata, metrics);\n+\t\t} catch (Exception ex) {\n+\t\t\tcleanup(snapshotFutures, metadata, metrics, options, ex);\n+\t\t}\n+\t}\n \n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\"Finished synchronous checkpoints for checkpoint {} on task {}\",\n-\t\t\t\t\tcheckpointMetaData.getCheckpointId(), taskName);\n-\t\t\t}\n+\tprivate void cleanup(\n+\t\t\tMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress,\n+\t\t\tCheckpointMetaData metadata,\n+\t\t\tCheckpointMetrics metrics, CheckpointOptions options,\n+\t\t\tException ex) throws Exception {\n \n-\t\t\tlong startAsyncPartNano = System.nanoTime();\n-\n-\t\t\tcheckpointMetrics.setSyncDurationMillis((startAsyncPartNano - startSyncPartNano) / 1_000_000);\n-\n-\t\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n-\t\t\texecutorService.execute(new AsyncCheckpointRunnable(\n-\t\t\t\toperatorSnapshotsInProgress,\n-\t\t\t\tcheckpointMetaData,\n-\t\t\t\tcheckpointMetrics,\n-\t\t\t\tstartAsyncPartNano,\n-\t\t\t\ttaskName,\n-\t\t\t\tcloseableRegistry,\n-\t\t\t\tenv,\n-\t\t\t\tasyncExceptionHandler));\n-\n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\n-\t\t\t\t\t\"{} - finished synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n-\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n-\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n-\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n-\t\t\t}\n-\t\t} catch (Exception ex) {\n-\t\t\t// Cleanup to release resources\n-\t\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n-\t\t\t\tif (null != operatorSnapshotResult) {\n-\t\t\t\t\ttry {\n-\t\t\t\t\t\toperatorSnapshotResult.cancel();\n-\t\t\t\t\t} catch (Exception e) {\n-\t\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n-\t\t\t\t\t}\n+\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n+\t\t\tif (operatorSnapshotResult != null) {\n+\t\t\t\ttry {\n+\t\t\t\t\toperatorSnapshotResult.cancel();\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n \t\t\t\t}\n \t\t\t}\n+\t\t}\n \n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\n-\t\t\t\t\t\"{} - did NOT finish synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n-\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n-\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n-\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n-\t\t\t}\n+\t\tif (LOG.isDebugEnabled()) {\n+\t\t\tLOG.debug(\n+\t\t\t\t\"{} - did NOT finish synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n+\t\t\t\ttaskName, metadata.getCheckpointId(),\n+\t\t\t\tmetrics.getAlignmentDurationNanos() / 1_000_000,\n+\t\t\t\tmetrics.getSyncDurationMillis());\n+\t\t}\n \n-\t\t\tif (checkpointOptions.getCheckpointType().isSynchronous()) {\n-\t\t\t\t// in the case of a synchronous checkpoint, we always rethrow the exception,\n-\t\t\t\t// so that the task fails.\n-\t\t\t\t// this is because the intention is always to stop the job after this checkpointing\n-\t\t\t\t// operation, and without the failure, the task would go back to normal execution.\n-\t\t\t\tthrow ex;\n-\t\t\t} else {\n-\t\t\t\tenv.declineCheckpoint(checkpointMetaData.getCheckpointId(), ex);\n-\t\t\t}\n+\t\tif (options.getCheckpointType().isSynchronous()) {\n+\t\t\t// in the case of a synchronous checkpoint, we always rethrow the exception,\n+\t\t\t// so that the task fails.\n+\t\t\t// this is because the intention is always to stop the job after this checkpointing\n+\t\t\t// operation, and without the failure, the task would go back to normal execution.\n+\t\t\tthrow ex;\n+\t\t} else {\n+\t\t\tenv.declineCheckpoint(metadata.getCheckpointId(), ex);\n+\t\t}\n+\t}\n+\n+\tprivate void finishAndReportAsync(Map<OperatorID, OperatorSnapshotFutures> snapshotFutures, CheckpointMetaData metadata, CheckpointMetrics metrics) {\n+\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n+\t\texecutorService.execute(new AsyncCheckpointRunnable(\n+\t\t\tsnapshotFutures,\n+\t\t\tmetadata,\n+\t\t\tmetrics,\n+\t\t\tSystem.nanoTime(),\n+\t\t\ttaskName,\n+\t\t\tcloseableRegistry,\n+\t\t\tenv,\n+\t\t\tasyncExceptionHandler));\n+\t}\n+\n+\tprivate void takeSnapshotSync(\n+\t\tMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress, CheckpointMetaData checkpointMetaData,\n+\t\tCheckpointMetrics checkpointMetrics, CheckpointOptions checkpointOptions,\n+\t\tOperatorChain<?, ?> operatorChain,\n+\t\tSupplier<Boolean> isCanceled) throws Exception {\n+\n+\t\tlong checkpointId = checkpointMetaData.getCheckpointId();\n+\t\tlong started = System.nanoTime();\n+\n+\t\tChannelStateWriteResult channelStateWriteResult = checkpointOptions.getCheckpointType() == CHECKPOINT ?", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTMwNDQ3MA=="}, "originalCommit": {"oid": "102a8f1f7c4926781fba187273cd6d324f8d0bd2"}, "originalPosition": 175}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTY3NjMzMg==", "bodyText": "that is right", "url": "https://github.com/apache/flink/pull/11515#discussion_r405676332", "createdAt": "2020-04-08T17:01:31Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -130,95 +130,108 @@ public void checkpointState(\n \n \t\t// Step (1): Prepare the checkpoint, allow operators to do some pre-barrier work.\n \t\t//           The pre-barrier work should be nothing or minimal in the common case.\n-\t\toperatorChain.prepareSnapshotPreBarrier(checkpointId);\n+\t\toperatorChain.prepareSnapshotPreBarrier(metadata.getCheckpointId());\n \n \t\t// Step (2): Send the checkpoint barrier downstream\n-\t\toperatorChain.broadcastCheckpointBarrier(\n-\t\t\tcheckpointId,\n-\t\t\tcheckpointMetaData.getTimestamp(),\n-\t\t\tcheckpointOptions);\n+\t\toperatorChain.broadcastCheckpointBarrier(metadata.getCheckpointId(), metadata.getTimestamp(), options);\n \n-\t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not\n-\t\t//           impact progress of the streaming topology\n+\t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not impact progress of the streaming topology\n \n-\t\tlong startSyncPartNano = System.nanoTime();\n-\n-\t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress = new HashMap<>(operatorChain.getNumberOfOperators());\n-\t\tChannelStateWriteResult channelStateWriteResult =\n-\t\t\tcheckpointOptions.getCheckpointType() == CHECKPOINT ? channelStateWriter.getWriteResult(checkpointMetaData.getCheckpointId()) :\n-\t\t\t\tChannelStateWriteResult.EMPTY;\n+\t\tMap<OperatorID, OperatorSnapshotFutures> snapshotFutures = new HashMap<>(operatorChain.getNumberOfOperators());\n \t\ttry {\n-\t\t\tfor (StreamOperatorWrapper<?, ?> operatorWrapper : operatorChain.getAllOperators(true)) {\n-\t\t\t\toperatorSnapshotsInProgress.put(\n-\t\t\t\t\toperatorWrapper.getStreamOperator().getOperatorID(),\n-\t\t\t\t\tbuildOperatorSnapshotFutures(\n-\t\t\t\t\t\tcheckpointMetaData,\n-\t\t\t\t\t\tcheckpointOptions,\n-\t\t\t\t\t\toperatorChain,\n-\t\t\t\t\t\toperatorWrapper.getStreamOperator(),\n-\t\t\t\t\t\tisCanceled,\n-\t\t\t\t\t\tchannelStateWriteResult)\n-\t\t\t\t);\n-\t\t\t}\n-\t\t\tcheckpointStorage.clearCacheFor(checkpointMetaData.getCheckpointId());\n+\t\t\ttakeSnapshotSync(snapshotFutures, metadata, metrics, options, operatorChain, isCanceled);\n+\t\t\tfinishAndReportAsync(snapshotFutures, metadata, metrics);\n+\t\t} catch (Exception ex) {\n+\t\t\tcleanup(snapshotFutures, metadata, metrics, options, ex);\n+\t\t}\n+\t}\n \n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\"Finished synchronous checkpoints for checkpoint {} on task {}\",\n-\t\t\t\t\tcheckpointMetaData.getCheckpointId(), taskName);\n-\t\t\t}\n+\tprivate void cleanup(\n+\t\t\tMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress,\n+\t\t\tCheckpointMetaData metadata,\n+\t\t\tCheckpointMetrics metrics, CheckpointOptions options,\n+\t\t\tException ex) throws Exception {\n \n-\t\t\tlong startAsyncPartNano = System.nanoTime();\n-\n-\t\t\tcheckpointMetrics.setSyncDurationMillis((startAsyncPartNano - startSyncPartNano) / 1_000_000);\n-\n-\t\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n-\t\t\texecutorService.execute(new AsyncCheckpointRunnable(\n-\t\t\t\toperatorSnapshotsInProgress,\n-\t\t\t\tcheckpointMetaData,\n-\t\t\t\tcheckpointMetrics,\n-\t\t\t\tstartAsyncPartNano,\n-\t\t\t\ttaskName,\n-\t\t\t\tcloseableRegistry,\n-\t\t\t\tenv,\n-\t\t\t\tasyncExceptionHandler));\n-\n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\n-\t\t\t\t\t\"{} - finished synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n-\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n-\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n-\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n-\t\t\t}\n-\t\t} catch (Exception ex) {\n-\t\t\t// Cleanup to release resources\n-\t\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n-\t\t\t\tif (null != operatorSnapshotResult) {\n-\t\t\t\t\ttry {\n-\t\t\t\t\t\toperatorSnapshotResult.cancel();\n-\t\t\t\t\t} catch (Exception e) {\n-\t\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n-\t\t\t\t\t}\n+\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n+\t\t\tif (operatorSnapshotResult != null) {\n+\t\t\t\ttry {\n+\t\t\t\t\toperatorSnapshotResult.cancel();\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n \t\t\t\t}\n \t\t\t}\n+\t\t}\n \n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\n-\t\t\t\t\t\"{} - did NOT finish synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n-\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n-\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n-\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n-\t\t\t}\n+\t\tif (LOG.isDebugEnabled()) {\n+\t\t\tLOG.debug(\n+\t\t\t\t\"{} - did NOT finish synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n+\t\t\t\ttaskName, metadata.getCheckpointId(),\n+\t\t\t\tmetrics.getAlignmentDurationNanos() / 1_000_000,\n+\t\t\t\tmetrics.getSyncDurationMillis());\n+\t\t}\n \n-\t\t\tif (checkpointOptions.getCheckpointType().isSynchronous()) {\n-\t\t\t\t// in the case of a synchronous checkpoint, we always rethrow the exception,\n-\t\t\t\t// so that the task fails.\n-\t\t\t\t// this is because the intention is always to stop the job after this checkpointing\n-\t\t\t\t// operation, and without the failure, the task would go back to normal execution.\n-\t\t\t\tthrow ex;\n-\t\t\t} else {\n-\t\t\t\tenv.declineCheckpoint(checkpointMetaData.getCheckpointId(), ex);\n-\t\t\t}\n+\t\tif (options.getCheckpointType().isSynchronous()) {\n+\t\t\t// in the case of a synchronous checkpoint, we always rethrow the exception,\n+\t\t\t// so that the task fails.\n+\t\t\t// this is because the intention is always to stop the job after this checkpointing\n+\t\t\t// operation, and without the failure, the task would go back to normal execution.\n+\t\t\tthrow ex;\n+\t\t} else {\n+\t\t\tenv.declineCheckpoint(metadata.getCheckpointId(), ex);\n+\t\t}\n+\t}\n+\n+\tprivate void finishAndReportAsync(Map<OperatorID, OperatorSnapshotFutures> snapshotFutures, CheckpointMetaData metadata, CheckpointMetrics metrics) {\n+\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n+\t\texecutorService.execute(new AsyncCheckpointRunnable(\n+\t\t\tsnapshotFutures,\n+\t\t\tmetadata,\n+\t\t\tmetrics,\n+\t\t\tSystem.nanoTime(),\n+\t\t\ttaskName,\n+\t\t\tcloseableRegistry,\n+\t\t\tenv,\n+\t\t\tasyncExceptionHandler));\n+\t}\n+\n+\tprivate void takeSnapshotSync(\n+\t\tMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress, CheckpointMetaData checkpointMetaData,\n+\t\tCheckpointMetrics checkpointMetrics, CheckpointOptions checkpointOptions,\n+\t\tOperatorChain<?, ?> operatorChain,\n+\t\tSupplier<Boolean> isCanceled) throws Exception {\n+\n+\t\tlong checkpointId = checkpointMetaData.getCheckpointId();\n+\t\tlong started = System.nanoTime();\n+\n+\t\tChannelStateWriteResult channelStateWriteResult = checkpointOptions.getCheckpointType() == CHECKPOINT ?", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTMwNDQ3MA=="}, "originalCommit": {"oid": "102a8f1f7c4926781fba187273cd6d324f8d0bd2"}, "originalPosition": 175}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxNTEzNTE2OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNzoxMzowNFrOGCh4bA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNzoxMzowNFrOGCh4bA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTMwNTQ1Mg==", "bodyText": "nit: reduce indentation?", "url": "https://github.com/apache/flink/pull/11515#discussion_r405305452", "createdAt": "2020-04-08T07:13:04Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -130,95 +130,108 @@ public void checkpointState(\n \n \t\t// Step (1): Prepare the checkpoint, allow operators to do some pre-barrier work.\n \t\t//           The pre-barrier work should be nothing or minimal in the common case.\n-\t\toperatorChain.prepareSnapshotPreBarrier(checkpointId);\n+\t\toperatorChain.prepareSnapshotPreBarrier(metadata.getCheckpointId());\n \n \t\t// Step (2): Send the checkpoint barrier downstream\n-\t\toperatorChain.broadcastCheckpointBarrier(\n-\t\t\tcheckpointId,\n-\t\t\tcheckpointMetaData.getTimestamp(),\n-\t\t\tcheckpointOptions);\n+\t\toperatorChain.broadcastCheckpointBarrier(metadata.getCheckpointId(), metadata.getTimestamp(), options);\n \n-\t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not\n-\t\t//           impact progress of the streaming topology\n+\t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not impact progress of the streaming topology\n \n-\t\tlong startSyncPartNano = System.nanoTime();\n-\n-\t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress = new HashMap<>(operatorChain.getNumberOfOperators());\n-\t\tChannelStateWriteResult channelStateWriteResult =\n-\t\t\tcheckpointOptions.getCheckpointType() == CHECKPOINT ? channelStateWriter.getWriteResult(checkpointMetaData.getCheckpointId()) :\n-\t\t\t\tChannelStateWriteResult.EMPTY;\n+\t\tMap<OperatorID, OperatorSnapshotFutures> snapshotFutures = new HashMap<>(operatorChain.getNumberOfOperators());\n \t\ttry {\n-\t\t\tfor (StreamOperatorWrapper<?, ?> operatorWrapper : operatorChain.getAllOperators(true)) {\n-\t\t\t\toperatorSnapshotsInProgress.put(\n-\t\t\t\t\toperatorWrapper.getStreamOperator().getOperatorID(),\n-\t\t\t\t\tbuildOperatorSnapshotFutures(\n-\t\t\t\t\t\tcheckpointMetaData,\n-\t\t\t\t\t\tcheckpointOptions,\n-\t\t\t\t\t\toperatorChain,\n-\t\t\t\t\t\toperatorWrapper.getStreamOperator(),\n-\t\t\t\t\t\tisCanceled,\n-\t\t\t\t\t\tchannelStateWriteResult)\n-\t\t\t\t);\n-\t\t\t}\n-\t\t\tcheckpointStorage.clearCacheFor(checkpointMetaData.getCheckpointId());\n+\t\t\ttakeSnapshotSync(snapshotFutures, metadata, metrics, options, operatorChain, isCanceled);\n+\t\t\tfinishAndReportAsync(snapshotFutures, metadata, metrics);\n+\t\t} catch (Exception ex) {\n+\t\t\tcleanup(snapshotFutures, metadata, metrics, options, ex);\n+\t\t}\n+\t}\n \n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\"Finished synchronous checkpoints for checkpoint {} on task {}\",\n-\t\t\t\t\tcheckpointMetaData.getCheckpointId(), taskName);\n-\t\t\t}\n+\tprivate void cleanup(\n+\t\t\tMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress,\n+\t\t\tCheckpointMetaData metadata,\n+\t\t\tCheckpointMetrics metrics, CheckpointOptions options,\n+\t\t\tException ex) throws Exception {\n \n-\t\t\tlong startAsyncPartNano = System.nanoTime();\n-\n-\t\t\tcheckpointMetrics.setSyncDurationMillis((startAsyncPartNano - startSyncPartNano) / 1_000_000);\n-\n-\t\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n-\t\t\texecutorService.execute(new AsyncCheckpointRunnable(\n-\t\t\t\toperatorSnapshotsInProgress,\n-\t\t\t\tcheckpointMetaData,\n-\t\t\t\tcheckpointMetrics,\n-\t\t\t\tstartAsyncPartNano,\n-\t\t\t\ttaskName,\n-\t\t\t\tcloseableRegistry,\n-\t\t\t\tenv,\n-\t\t\t\tasyncExceptionHandler));\n-\n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\n-\t\t\t\t\t\"{} - finished synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n-\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n-\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n-\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n-\t\t\t}\n-\t\t} catch (Exception ex) {\n-\t\t\t// Cleanup to release resources\n-\t\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n-\t\t\t\tif (null != operatorSnapshotResult) {\n-\t\t\t\t\ttry {\n-\t\t\t\t\t\toperatorSnapshotResult.cancel();\n-\t\t\t\t\t} catch (Exception e) {\n-\t\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n-\t\t\t\t\t}\n+\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n+\t\t\tif (operatorSnapshotResult != null) {\n+\t\t\t\ttry {\n+\t\t\t\t\toperatorSnapshotResult.cancel();\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n \t\t\t\t}\n \t\t\t}\n+\t\t}\n \n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\n-\t\t\t\t\t\"{} - did NOT finish synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n-\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n-\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n-\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n-\t\t\t}\n+\t\tif (LOG.isDebugEnabled()) {\n+\t\t\tLOG.debug(\n+\t\t\t\t\"{} - did NOT finish synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n+\t\t\t\ttaskName, metadata.getCheckpointId(),\n+\t\t\t\tmetrics.getAlignmentDurationNanos() / 1_000_000,\n+\t\t\t\tmetrics.getSyncDurationMillis());\n+\t\t}\n \n-\t\t\tif (checkpointOptions.getCheckpointType().isSynchronous()) {\n-\t\t\t\t// in the case of a synchronous checkpoint, we always rethrow the exception,\n-\t\t\t\t// so that the task fails.\n-\t\t\t\t// this is because the intention is always to stop the job after this checkpointing\n-\t\t\t\t// operation, and without the failure, the task would go back to normal execution.\n-\t\t\t\tthrow ex;\n-\t\t\t} else {\n-\t\t\t\tenv.declineCheckpoint(checkpointMetaData.getCheckpointId(), ex);\n-\t\t\t}\n+\t\tif (options.getCheckpointType().isSynchronous()) {\n+\t\t\t// in the case of a synchronous checkpoint, we always rethrow the exception,\n+\t\t\t// so that the task fails.\n+\t\t\t// this is because the intention is always to stop the job after this checkpointing\n+\t\t\t// operation, and without the failure, the task would go back to normal execution.\n+\t\t\tthrow ex;\n+\t\t} else {\n+\t\t\tenv.declineCheckpoint(metadata.getCheckpointId(), ex);\n+\t\t}\n+\t}\n+\n+\tprivate void finishAndReportAsync(Map<OperatorID, OperatorSnapshotFutures> snapshotFutures, CheckpointMetaData metadata, CheckpointMetrics metrics) {\n+\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n+\t\texecutorService.execute(new AsyncCheckpointRunnable(\n+\t\t\tsnapshotFutures,\n+\t\t\tmetadata,\n+\t\t\tmetrics,\n+\t\t\tSystem.nanoTime(),\n+\t\t\ttaskName,\n+\t\t\tcloseableRegistry,\n+\t\t\tenv,\n+\t\t\tasyncExceptionHandler));\n+\t}\n+\n+\tprivate void takeSnapshotSync(\n+\t\tMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress, CheckpointMetaData checkpointMetaData,\n+\t\tCheckpointMetrics checkpointMetrics, CheckpointOptions checkpointOptions,\n+\t\tOperatorChain<?, ?> operatorChain,\n+\t\tSupplier<Boolean> isCanceled) throws Exception {\n+\n+\t\tlong checkpointId = checkpointMetaData.getCheckpointId();\n+\t\tlong started = System.nanoTime();\n+\n+\t\tChannelStateWriteResult channelStateWriteResult = checkpointOptions.getCheckpointType() == CHECKPOINT ?\n+\t\t\t\t\t\t\t\tchannelStateWriter.getWriteResult(checkpointId) :", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "102a8f1f7c4926781fba187273cd6d324f8d0bd2"}, "originalPosition": 176}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxNTE0MTYxOnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNzoxNTowOVrOGCh8Ug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxMTo0ODo0NlrOGCriZA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTMwNjQ1MA==", "bodyText": "If buildOperatorSnapshotFutures encounters exception, the clear will not be executed, should place within finally?", "url": "https://github.com/apache/flink/pull/11515#discussion_r405306450", "createdAt": "2020-04-08T07:15:09Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -130,95 +130,108 @@ public void checkpointState(\n \n \t\t// Step (1): Prepare the checkpoint, allow operators to do some pre-barrier work.\n \t\t//           The pre-barrier work should be nothing or minimal in the common case.\n-\t\toperatorChain.prepareSnapshotPreBarrier(checkpointId);\n+\t\toperatorChain.prepareSnapshotPreBarrier(metadata.getCheckpointId());\n \n \t\t// Step (2): Send the checkpoint barrier downstream\n-\t\toperatorChain.broadcastCheckpointBarrier(\n-\t\t\tcheckpointId,\n-\t\t\tcheckpointMetaData.getTimestamp(),\n-\t\t\tcheckpointOptions);\n+\t\toperatorChain.broadcastCheckpointBarrier(metadata.getCheckpointId(), metadata.getTimestamp(), options);\n \n-\t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not\n-\t\t//           impact progress of the streaming topology\n+\t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not impact progress of the streaming topology\n \n-\t\tlong startSyncPartNano = System.nanoTime();\n-\n-\t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress = new HashMap<>(operatorChain.getNumberOfOperators());\n-\t\tChannelStateWriteResult channelStateWriteResult =\n-\t\t\tcheckpointOptions.getCheckpointType() == CHECKPOINT ? channelStateWriter.getWriteResult(checkpointMetaData.getCheckpointId()) :\n-\t\t\t\tChannelStateWriteResult.EMPTY;\n+\t\tMap<OperatorID, OperatorSnapshotFutures> snapshotFutures = new HashMap<>(operatorChain.getNumberOfOperators());\n \t\ttry {\n-\t\t\tfor (StreamOperatorWrapper<?, ?> operatorWrapper : operatorChain.getAllOperators(true)) {\n-\t\t\t\toperatorSnapshotsInProgress.put(\n-\t\t\t\t\toperatorWrapper.getStreamOperator().getOperatorID(),\n-\t\t\t\t\tbuildOperatorSnapshotFutures(\n-\t\t\t\t\t\tcheckpointMetaData,\n-\t\t\t\t\t\tcheckpointOptions,\n-\t\t\t\t\t\toperatorChain,\n-\t\t\t\t\t\toperatorWrapper.getStreamOperator(),\n-\t\t\t\t\t\tisCanceled,\n-\t\t\t\t\t\tchannelStateWriteResult)\n-\t\t\t\t);\n-\t\t\t}\n-\t\t\tcheckpointStorage.clearCacheFor(checkpointMetaData.getCheckpointId());\n+\t\t\ttakeSnapshotSync(snapshotFutures, metadata, metrics, options, operatorChain, isCanceled);\n+\t\t\tfinishAndReportAsync(snapshotFutures, metadata, metrics);\n+\t\t} catch (Exception ex) {\n+\t\t\tcleanup(snapshotFutures, metadata, metrics, options, ex);\n+\t\t}\n+\t}\n \n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\"Finished synchronous checkpoints for checkpoint {} on task {}\",\n-\t\t\t\t\tcheckpointMetaData.getCheckpointId(), taskName);\n-\t\t\t}\n+\tprivate void cleanup(\n+\t\t\tMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress,\n+\t\t\tCheckpointMetaData metadata,\n+\t\t\tCheckpointMetrics metrics, CheckpointOptions options,\n+\t\t\tException ex) throws Exception {\n \n-\t\t\tlong startAsyncPartNano = System.nanoTime();\n-\n-\t\t\tcheckpointMetrics.setSyncDurationMillis((startAsyncPartNano - startSyncPartNano) / 1_000_000);\n-\n-\t\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n-\t\t\texecutorService.execute(new AsyncCheckpointRunnable(\n-\t\t\t\toperatorSnapshotsInProgress,\n-\t\t\t\tcheckpointMetaData,\n-\t\t\t\tcheckpointMetrics,\n-\t\t\t\tstartAsyncPartNano,\n-\t\t\t\ttaskName,\n-\t\t\t\tcloseableRegistry,\n-\t\t\t\tenv,\n-\t\t\t\tasyncExceptionHandler));\n-\n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\n-\t\t\t\t\t\"{} - finished synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n-\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n-\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n-\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n-\t\t\t}\n-\t\t} catch (Exception ex) {\n-\t\t\t// Cleanup to release resources\n-\t\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n-\t\t\t\tif (null != operatorSnapshotResult) {\n-\t\t\t\t\ttry {\n-\t\t\t\t\t\toperatorSnapshotResult.cancel();\n-\t\t\t\t\t} catch (Exception e) {\n-\t\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n-\t\t\t\t\t}\n+\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n+\t\t\tif (operatorSnapshotResult != null) {\n+\t\t\t\ttry {\n+\t\t\t\t\toperatorSnapshotResult.cancel();\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n \t\t\t\t}\n \t\t\t}\n+\t\t}\n \n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\n-\t\t\t\t\t\"{} - did NOT finish synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n-\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n-\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n-\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n-\t\t\t}\n+\t\tif (LOG.isDebugEnabled()) {\n+\t\t\tLOG.debug(\n+\t\t\t\t\"{} - did NOT finish synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n+\t\t\t\ttaskName, metadata.getCheckpointId(),\n+\t\t\t\tmetrics.getAlignmentDurationNanos() / 1_000_000,\n+\t\t\t\tmetrics.getSyncDurationMillis());\n+\t\t}\n \n-\t\t\tif (checkpointOptions.getCheckpointType().isSynchronous()) {\n-\t\t\t\t// in the case of a synchronous checkpoint, we always rethrow the exception,\n-\t\t\t\t// so that the task fails.\n-\t\t\t\t// this is because the intention is always to stop the job after this checkpointing\n-\t\t\t\t// operation, and without the failure, the task would go back to normal execution.\n-\t\t\t\tthrow ex;\n-\t\t\t} else {\n-\t\t\t\tenv.declineCheckpoint(checkpointMetaData.getCheckpointId(), ex);\n-\t\t\t}\n+\t\tif (options.getCheckpointType().isSynchronous()) {\n+\t\t\t// in the case of a synchronous checkpoint, we always rethrow the exception,\n+\t\t\t// so that the task fails.\n+\t\t\t// this is because the intention is always to stop the job after this checkpointing\n+\t\t\t// operation, and without the failure, the task would go back to normal execution.\n+\t\t\tthrow ex;\n+\t\t} else {\n+\t\t\tenv.declineCheckpoint(metadata.getCheckpointId(), ex);\n+\t\t}\n+\t}\n+\n+\tprivate void finishAndReportAsync(Map<OperatorID, OperatorSnapshotFutures> snapshotFutures, CheckpointMetaData metadata, CheckpointMetrics metrics) {\n+\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n+\t\texecutorService.execute(new AsyncCheckpointRunnable(\n+\t\t\tsnapshotFutures,\n+\t\t\tmetadata,\n+\t\t\tmetrics,\n+\t\t\tSystem.nanoTime(),\n+\t\t\ttaskName,\n+\t\t\tcloseableRegistry,\n+\t\t\tenv,\n+\t\t\tasyncExceptionHandler));\n+\t}\n+\n+\tprivate void takeSnapshotSync(\n+\t\tMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress, CheckpointMetaData checkpointMetaData,\n+\t\tCheckpointMetrics checkpointMetrics, CheckpointOptions checkpointOptions,\n+\t\tOperatorChain<?, ?> operatorChain,\n+\t\tSupplier<Boolean> isCanceled) throws Exception {\n+\n+\t\tlong checkpointId = checkpointMetaData.getCheckpointId();\n+\t\tlong started = System.nanoTime();\n+\n+\t\tChannelStateWriteResult channelStateWriteResult = checkpointOptions.getCheckpointType() == CHECKPOINT ?\n+\t\t\t\t\t\t\t\tchannelStateWriter.getWriteResult(checkpointId) :\n+\t\t\t\t\t\t\t\tChannelStateWriteResult.EMPTY;\n+\n+\t\tCheckpointStreamFactory storage = checkpointStorage.resolveCheckpointStorageLocation(checkpointId, checkpointOptions.getTargetLocation());\n+\n+\t\tfor (StreamOperatorWrapper<?, ?> operatorWrapper : operatorChain.getAllOperators(true)) {\n+\t\t\toperatorSnapshotsInProgress.put(\n+\t\t\t\toperatorWrapper.getStreamOperator().getOperatorID(),\n+\t\t\t\tbuildOperatorSnapshotFutures(\n+\t\t\t\t\tcheckpointMetaData,\n+\t\t\t\t\tcheckpointOptions,\n+\t\t\t\t\toperatorChain,\n+\t\t\t\t\toperatorWrapper.getStreamOperator(),\n+\t\t\t\t\tisCanceled,\n+\t\t\t\t\tchannelStateWriteResult,\n+\t\t\t\t\tstorage));\n \t\t}\n+\n+\t\tcheckpointStorage.clearCacheFor(checkpointId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "102a8f1f7c4926781fba187273cd6d324f8d0bd2"}, "originalPosition": 194}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQ2MzY1Mg==", "bodyText": "Yes, will fix this.", "url": "https://github.com/apache/flink/pull/11515#discussion_r405463652", "createdAt": "2020-04-08T11:48:46Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -130,95 +130,108 @@ public void checkpointState(\n \n \t\t// Step (1): Prepare the checkpoint, allow operators to do some pre-barrier work.\n \t\t//           The pre-barrier work should be nothing or minimal in the common case.\n-\t\toperatorChain.prepareSnapshotPreBarrier(checkpointId);\n+\t\toperatorChain.prepareSnapshotPreBarrier(metadata.getCheckpointId());\n \n \t\t// Step (2): Send the checkpoint barrier downstream\n-\t\toperatorChain.broadcastCheckpointBarrier(\n-\t\t\tcheckpointId,\n-\t\t\tcheckpointMetaData.getTimestamp(),\n-\t\t\tcheckpointOptions);\n+\t\toperatorChain.broadcastCheckpointBarrier(metadata.getCheckpointId(), metadata.getTimestamp(), options);\n \n-\t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not\n-\t\t//           impact progress of the streaming topology\n+\t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not impact progress of the streaming topology\n \n-\t\tlong startSyncPartNano = System.nanoTime();\n-\n-\t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress = new HashMap<>(operatorChain.getNumberOfOperators());\n-\t\tChannelStateWriteResult channelStateWriteResult =\n-\t\t\tcheckpointOptions.getCheckpointType() == CHECKPOINT ? channelStateWriter.getWriteResult(checkpointMetaData.getCheckpointId()) :\n-\t\t\t\tChannelStateWriteResult.EMPTY;\n+\t\tMap<OperatorID, OperatorSnapshotFutures> snapshotFutures = new HashMap<>(operatorChain.getNumberOfOperators());\n \t\ttry {\n-\t\t\tfor (StreamOperatorWrapper<?, ?> operatorWrapper : operatorChain.getAllOperators(true)) {\n-\t\t\t\toperatorSnapshotsInProgress.put(\n-\t\t\t\t\toperatorWrapper.getStreamOperator().getOperatorID(),\n-\t\t\t\t\tbuildOperatorSnapshotFutures(\n-\t\t\t\t\t\tcheckpointMetaData,\n-\t\t\t\t\t\tcheckpointOptions,\n-\t\t\t\t\t\toperatorChain,\n-\t\t\t\t\t\toperatorWrapper.getStreamOperator(),\n-\t\t\t\t\t\tisCanceled,\n-\t\t\t\t\t\tchannelStateWriteResult)\n-\t\t\t\t);\n-\t\t\t}\n-\t\t\tcheckpointStorage.clearCacheFor(checkpointMetaData.getCheckpointId());\n+\t\t\ttakeSnapshotSync(snapshotFutures, metadata, metrics, options, operatorChain, isCanceled);\n+\t\t\tfinishAndReportAsync(snapshotFutures, metadata, metrics);\n+\t\t} catch (Exception ex) {\n+\t\t\tcleanup(snapshotFutures, metadata, metrics, options, ex);\n+\t\t}\n+\t}\n \n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\"Finished synchronous checkpoints for checkpoint {} on task {}\",\n-\t\t\t\t\tcheckpointMetaData.getCheckpointId(), taskName);\n-\t\t\t}\n+\tprivate void cleanup(\n+\t\t\tMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress,\n+\t\t\tCheckpointMetaData metadata,\n+\t\t\tCheckpointMetrics metrics, CheckpointOptions options,\n+\t\t\tException ex) throws Exception {\n \n-\t\t\tlong startAsyncPartNano = System.nanoTime();\n-\n-\t\t\tcheckpointMetrics.setSyncDurationMillis((startAsyncPartNano - startSyncPartNano) / 1_000_000);\n-\n-\t\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n-\t\t\texecutorService.execute(new AsyncCheckpointRunnable(\n-\t\t\t\toperatorSnapshotsInProgress,\n-\t\t\t\tcheckpointMetaData,\n-\t\t\t\tcheckpointMetrics,\n-\t\t\t\tstartAsyncPartNano,\n-\t\t\t\ttaskName,\n-\t\t\t\tcloseableRegistry,\n-\t\t\t\tenv,\n-\t\t\t\tasyncExceptionHandler));\n-\n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\n-\t\t\t\t\t\"{} - finished synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n-\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n-\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n-\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n-\t\t\t}\n-\t\t} catch (Exception ex) {\n-\t\t\t// Cleanup to release resources\n-\t\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n-\t\t\t\tif (null != operatorSnapshotResult) {\n-\t\t\t\t\ttry {\n-\t\t\t\t\t\toperatorSnapshotResult.cancel();\n-\t\t\t\t\t} catch (Exception e) {\n-\t\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n-\t\t\t\t\t}\n+\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n+\t\t\tif (operatorSnapshotResult != null) {\n+\t\t\t\ttry {\n+\t\t\t\t\toperatorSnapshotResult.cancel();\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n \t\t\t\t}\n \t\t\t}\n+\t\t}\n \n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\n-\t\t\t\t\t\"{} - did NOT finish synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n-\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n-\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n-\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n-\t\t\t}\n+\t\tif (LOG.isDebugEnabled()) {\n+\t\t\tLOG.debug(\n+\t\t\t\t\"{} - did NOT finish synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n+\t\t\t\ttaskName, metadata.getCheckpointId(),\n+\t\t\t\tmetrics.getAlignmentDurationNanos() / 1_000_000,\n+\t\t\t\tmetrics.getSyncDurationMillis());\n+\t\t}\n \n-\t\t\tif (checkpointOptions.getCheckpointType().isSynchronous()) {\n-\t\t\t\t// in the case of a synchronous checkpoint, we always rethrow the exception,\n-\t\t\t\t// so that the task fails.\n-\t\t\t\t// this is because the intention is always to stop the job after this checkpointing\n-\t\t\t\t// operation, and without the failure, the task would go back to normal execution.\n-\t\t\t\tthrow ex;\n-\t\t\t} else {\n-\t\t\t\tenv.declineCheckpoint(checkpointMetaData.getCheckpointId(), ex);\n-\t\t\t}\n+\t\tif (options.getCheckpointType().isSynchronous()) {\n+\t\t\t// in the case of a synchronous checkpoint, we always rethrow the exception,\n+\t\t\t// so that the task fails.\n+\t\t\t// this is because the intention is always to stop the job after this checkpointing\n+\t\t\t// operation, and without the failure, the task would go back to normal execution.\n+\t\t\tthrow ex;\n+\t\t} else {\n+\t\t\tenv.declineCheckpoint(metadata.getCheckpointId(), ex);\n+\t\t}\n+\t}\n+\n+\tprivate void finishAndReportAsync(Map<OperatorID, OperatorSnapshotFutures> snapshotFutures, CheckpointMetaData metadata, CheckpointMetrics metrics) {\n+\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n+\t\texecutorService.execute(new AsyncCheckpointRunnable(\n+\t\t\tsnapshotFutures,\n+\t\t\tmetadata,\n+\t\t\tmetrics,\n+\t\t\tSystem.nanoTime(),\n+\t\t\ttaskName,\n+\t\t\tcloseableRegistry,\n+\t\t\tenv,\n+\t\t\tasyncExceptionHandler));\n+\t}\n+\n+\tprivate void takeSnapshotSync(\n+\t\tMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress, CheckpointMetaData checkpointMetaData,\n+\t\tCheckpointMetrics checkpointMetrics, CheckpointOptions checkpointOptions,\n+\t\tOperatorChain<?, ?> operatorChain,\n+\t\tSupplier<Boolean> isCanceled) throws Exception {\n+\n+\t\tlong checkpointId = checkpointMetaData.getCheckpointId();\n+\t\tlong started = System.nanoTime();\n+\n+\t\tChannelStateWriteResult channelStateWriteResult = checkpointOptions.getCheckpointType() == CHECKPOINT ?\n+\t\t\t\t\t\t\t\tchannelStateWriter.getWriteResult(checkpointId) :\n+\t\t\t\t\t\t\t\tChannelStateWriteResult.EMPTY;\n+\n+\t\tCheckpointStreamFactory storage = checkpointStorage.resolveCheckpointStorageLocation(checkpointId, checkpointOptions.getTargetLocation());\n+\n+\t\tfor (StreamOperatorWrapper<?, ?> operatorWrapper : operatorChain.getAllOperators(true)) {\n+\t\t\toperatorSnapshotsInProgress.put(\n+\t\t\t\toperatorWrapper.getStreamOperator().getOperatorID(),\n+\t\t\t\tbuildOperatorSnapshotFutures(\n+\t\t\t\t\tcheckpointMetaData,\n+\t\t\t\t\tcheckpointOptions,\n+\t\t\t\t\toperatorChain,\n+\t\t\t\t\toperatorWrapper.getStreamOperator(),\n+\t\t\t\t\tisCanceled,\n+\t\t\t\t\tchannelStateWriteResult,\n+\t\t\t\t\tstorage));\n \t\t}\n+\n+\t\tcheckpointStorage.clearCacheFor(checkpointId);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTMwNjQ1MA=="}, "originalCommit": {"oid": "102a8f1f7c4926781fba187273cd6d324f8d0bd2"}, "originalPosition": 194}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxNTIxMzg5OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateCheckpointWriterTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNzozNzoxNlrOGCipFQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxMTo1NzowNFrOGCrz4A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTMxNzkwOQ==", "bodyText": "it is better to also verify the ChannelStateWriteResult#isDone when complete both input and output.", "url": "https://github.com/apache/flink/pull/11515#discussion_r405317909", "createdAt": "2020-04-08T07:37:16Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateCheckpointWriterTest.java", "diffHunk": "@@ -0,0 +1,133 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.memory.HeapMemorySegment;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.runtime.state.memory.MemCheckpointStreamFactory.MemoryCheckpointOutputStream;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.junit.Test;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Random;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * {@link ChannelStateCheckpointWriter} test.\n+ */\n+public class ChannelStateCheckpointWriterTest {\n+\tprivate static final RunnableWithException NO_OP_RUNNABLE = () -> {\n+\t};\n+\tprivate final Random random = new Random();\n+\n+\t@Test\n+\tpublic void testRecyclingBuffers() throws Exception {\n+\t\tChannelStateCheckpointWriter writer = createWriter(new ChannelStateWriteResult());\n+\t\tNetworkBuffer buffer = new NetworkBuffer(HeapMemorySegment.FACTORY.allocateUnpooledSegment(10, null), FreeingBufferRecycler.INSTANCE);\n+\t\twriter.writeInput(new InputChannelInfo(1, 2), buffer);\n+\t\tassertTrue(buffer.isRecycled());\n+\t}\n+\n+\t@Test\n+\tpublic void testFlush() throws Exception {\n+\t\tclass FlushRecorder extends DataOutputStream {\n+\t\t\tprivate boolean flushed = false;\n+\n+\t\t\tprivate FlushRecorder() {\n+\t\t\t\tsuper(new ByteArrayOutputStream());\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic void flush() throws IOException {\n+\t\t\t\tflushed = true;\n+\t\t\t\tsuper.flush();\n+\t\t\t}\n+\t\t}\n+\n+\t\tFlushRecorder dataStream = new FlushRecorder();\n+\t\tfinal ChannelStateCheckpointWriter writer = new ChannelStateCheckpointWriter(\n+\t\t\t1L,\n+\t\t\tnew ChannelStateWriteResult(),\n+\t\t\tnew ChannelStateSerializerImpl(),\n+\t\t\tNO_OP_RUNNABLE,\n+\t\t\tnew MemoryCheckpointOutputStream(42),\n+\t\t\tdataStream\n+\t\t);\n+\n+\t\twriter.completeInput();\n+\t\twriter.completeOutput();\n+\n+\t\tassertTrue(dataStream.flushed);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQ2ODEyOA==", "bodyText": "There are already tests that check that result is completed.\nHowever, they are on a higher level, so I added a separate test here too.", "url": "https://github.com/apache/flink/pull/11515#discussion_r405468128", "createdAt": "2020-04-08T11:57:04Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateCheckpointWriterTest.java", "diffHunk": "@@ -0,0 +1,133 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.memory.HeapMemorySegment;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.runtime.state.memory.MemCheckpointStreamFactory.MemoryCheckpointOutputStream;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.junit.Test;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Random;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * {@link ChannelStateCheckpointWriter} test.\n+ */\n+public class ChannelStateCheckpointWriterTest {\n+\tprivate static final RunnableWithException NO_OP_RUNNABLE = () -> {\n+\t};\n+\tprivate final Random random = new Random();\n+\n+\t@Test\n+\tpublic void testRecyclingBuffers() throws Exception {\n+\t\tChannelStateCheckpointWriter writer = createWriter(new ChannelStateWriteResult());\n+\t\tNetworkBuffer buffer = new NetworkBuffer(HeapMemorySegment.FACTORY.allocateUnpooledSegment(10, null), FreeingBufferRecycler.INSTANCE);\n+\t\twriter.writeInput(new InputChannelInfo(1, 2), buffer);\n+\t\tassertTrue(buffer.isRecycled());\n+\t}\n+\n+\t@Test\n+\tpublic void testFlush() throws Exception {\n+\t\tclass FlushRecorder extends DataOutputStream {\n+\t\t\tprivate boolean flushed = false;\n+\n+\t\t\tprivate FlushRecorder() {\n+\t\t\t\tsuper(new ByteArrayOutputStream());\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic void flush() throws IOException {\n+\t\t\t\tflushed = true;\n+\t\t\t\tsuper.flush();\n+\t\t\t}\n+\t\t}\n+\n+\t\tFlushRecorder dataStream = new FlushRecorder();\n+\t\tfinal ChannelStateCheckpointWriter writer = new ChannelStateCheckpointWriter(\n+\t\t\t1L,\n+\t\t\tnew ChannelStateWriteResult(),\n+\t\t\tnew ChannelStateSerializerImpl(),\n+\t\t\tNO_OP_RUNNABLE,\n+\t\t\tnew MemoryCheckpointOutputStream(42),\n+\t\t\tdataStream\n+\t\t);\n+\n+\t\twriter.completeInput();\n+\t\twriter.completeOutput();\n+\n+\t\tassertTrue(dataStream.flushed);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTMxNzkwOQ=="}, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 85}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxNTI4MDM3OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImplTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNzo1NTo0NFrOGCjSAw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxMjoxMjoyMVrOGCsVKQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTMyODM4Nw==", "bodyText": "All the below tests are for the  ChannelStateReader#readInput, not sure whether we also need to cover the code path for ChannelStateReader#readOutput.", "url": "https://github.com/apache/flink/pull/11515#discussion_r405328387", "createdAt": "2020-04-08T07:55:44Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImplTest.java", "diffHunk": "@@ -0,0 +1,205 @@\n+package org.apache.flink.runtime.checkpoint.channel;\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+import org.apache.flink.core.memory.HeapMemorySegment;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.StateObjectCollection;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.runtime.state.memory.ByteStreamStateHandle;\n+\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Random;\n+\n+import static java.util.Collections.singletonList;\n+import static java.util.stream.Collectors.toMap;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.HAS_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+import static org.junit.Assert.assertArrayEquals;\n+import static org.junit.Assert.assertEquals;\n+\n+/**\n+ * {@link ChannelStateReaderImpl} test.\n+ */\n+public class ChannelStateReaderImplTest {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQ3NjY0OQ==", "bodyText": "I don't think it's necessary because they mostly use the same code paths.\nReading into a BufferBuilder is tested separately.", "url": "https://github.com/apache/flink/pull/11515#discussion_r405476649", "createdAt": "2020-04-08T12:12:21Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImplTest.java", "diffHunk": "@@ -0,0 +1,205 @@\n+package org.apache.flink.runtime.checkpoint.channel;\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+import org.apache.flink.core.memory.HeapMemorySegment;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.StateObjectCollection;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.runtime.state.memory.ByteStreamStateHandle;\n+\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Random;\n+\n+import static java.util.Collections.singletonList;\n+import static java.util.stream.Collectors.toMap;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.HAS_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+import static org.junit.Assert.assertArrayEquals;\n+import static org.junit.Assert.assertEquals;\n+\n+/**\n+ * {@link ChannelStateReaderImpl} test.\n+ */\n+public class ChannelStateReaderImplTest {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTMyODM4Nw=="}, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 54}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxNTc3ODkyOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImplTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxMDowMzo1OVrOGCoKtQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxMDowMzo1OVrOGCoKtQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQwODQzNw==", "bodyText": "I have not seen any tests covering the resource release for the reader. If possible, it is better to further verify the internal RefCountingFSDataInputStream is dereferenced and closed when no more data.  Then we can confirm no resource leak.", "url": "https://github.com/apache/flink/pull/11515#discussion_r405408437", "createdAt": "2020-04-08T10:03:59Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImplTest.java", "diffHunk": "@@ -0,0 +1,205 @@\n+package org.apache.flink.runtime.checkpoint.channel;\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+import org.apache.flink.core.memory.HeapMemorySegment;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.StateObjectCollection;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.runtime.state.memory.ByteStreamStateHandle;\n+\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Random;\n+\n+import static java.util.Collections.singletonList;\n+import static java.util.stream.Collectors.toMap;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.HAS_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+import static org.junit.Assert.assertArrayEquals;\n+import static org.junit.Assert.assertEquals;\n+\n+/**\n+ * {@link ChannelStateReaderImpl} test.\n+ */\n+public class ChannelStateReaderImplTest {\n+\n+\tprivate static final InputChannelInfo CHANNEL = new InputChannelInfo(1, 2);\n+\tprivate static final byte[] DATA = generateData(10);\n+\tprivate ChannelStateReaderImpl reader;\n+\n+\t@Before\n+\tpublic void init() {\n+\t\treader = getReader(CHANNEL, DATA);\n+\t}\n+\n+\t@After\n+\tpublic void tearDown() throws Exception {\n+\t\treader.close();\n+\t}\n+\n+\t@Test\n+\tpublic void testDifferentBufferSizes() throws Exception {\n+\t\tfor (int bufferSize = 1; bufferSize < 2 * DATA.length; bufferSize++) {\n+\t\t\ttry (ChannelStateReaderImpl reader = getReader(CHANNEL, DATA)) { // re-create reader to re-read the same channel\n+\t\t\t\treadAndVerify(bufferSize, CHANNEL, DATA, reader);\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\t@Test\n+\tpublic void testWithOffsets() throws IOException {\n+\t\tMap<InputChannelStateHandle, byte[]> handlesAndBytes = generateHandlesWithBytes(10, 20);\n+\t\tChannelStateReader reader = new ChannelStateReaderImpl(taskStateSnapshot(handlesAndBytes.keySet()), new ChannelStateSerializerImpl());\n+\t\tfor (Map.Entry<InputChannelStateHandle, byte[]> e : handlesAndBytes.entrySet()) {\n+\t\t\treadAndVerify(42, e.getKey().getInfo(), e.getValue(), reader);\n+\t\t}\n+\t}\n+\n+\t@Test(expected = Exception.class)\n+\tpublic void testReadOnlyOnce() throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 89}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxNTg1MzU2OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializerImplTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxMDoyNTowNVrOGCo6IA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxMDoyNTowNVrOGCo6IA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQyMDU3Ng==", "bodyText": "close the stream at the end?", "url": "https://github.com/apache/flink/pull/11515#discussion_r405420576", "createdAt": "2020-04-08T10:25:05Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializerImplTest.java", "diffHunk": "@@ -0,0 +1,108 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.memory.HeapMemorySegment;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.io.network.buffer.BufferConsumer;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+\n+import org.junit.Test;\n+\n+import java.io.ByteArrayInputStream;\n+import java.io.ByteArrayOutputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Random;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateByteBuffer.wrap;\n+import static org.junit.Assert.assertArrayEquals;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+\n+/**\n+ * {@link ChannelStateSerializerImpl} test.\n+ */\n+public class ChannelStateSerializerImplTest {\n+\n+\tprivate final Random random = new Random();\n+\n+\t@Test\n+\tpublic void testWriteRead() throws IOException {\n+\t\tint bufSize = 10;\n+\t\tint[] numBuffersToWriteAtOnce = {0, 1, 2, 3};\n+\t\tbyte[] data = getData(bufSize);\n+\t\tChannelStateSerializer s = new ChannelStateSerializerImpl();\n+\t\tByteArrayOutputStream baos = new ByteArrayOutputStream();\n+\t\tDataOutputStream out = new DataOutputStream(baos);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 55}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxNTg4MjU3OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImplTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxMDozMzoxOVrOGCpLzA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxMDozMzoxOVrOGCpLzA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQyNTEwMA==", "bodyText": "nit: this can be reused in other places, like ChannelStateSerializerImplTest#getData(int len), ChannelStateSerializerTest#randomBytes", "url": "https://github.com/apache/flink/pull/11515#discussion_r405425100", "createdAt": "2020-04-08T10:33:19Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImplTest.java", "diffHunk": "@@ -0,0 +1,205 @@\n+package org.apache.flink.runtime.checkpoint.channel;\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+import org.apache.flink.core.memory.HeapMemorySegment;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.StateObjectCollection;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.runtime.state.memory.ByteStreamStateHandle;\n+\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Random;\n+\n+import static java.util.Collections.singletonList;\n+import static java.util.stream.Collectors.toMap;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.HAS_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+import static org.junit.Assert.assertArrayEquals;\n+import static org.junit.Assert.assertEquals;\n+\n+/**\n+ * {@link ChannelStateReaderImpl} test.\n+ */\n+public class ChannelStateReaderImplTest {\n+\n+\tprivate static final InputChannelInfo CHANNEL = new InputChannelInfo(1, 2);\n+\tprivate static final byte[] DATA = generateData(10);\n+\tprivate ChannelStateReaderImpl reader;\n+\n+\t@Before\n+\tpublic void init() {\n+\t\treader = getReader(CHANNEL, DATA);\n+\t}\n+\n+\t@After\n+\tpublic void tearDown() throws Exception {\n+\t\treader.close();\n+\t}\n+\n+\t@Test\n+\tpublic void testDifferentBufferSizes() throws Exception {\n+\t\tfor (int bufferSize = 1; bufferSize < 2 * DATA.length; bufferSize++) {\n+\t\t\ttry (ChannelStateReaderImpl reader = getReader(CHANNEL, DATA)) { // re-create reader to re-read the same channel\n+\t\t\t\treadAndVerify(bufferSize, CHANNEL, DATA, reader);\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\t@Test\n+\tpublic void testWithOffsets() throws IOException {\n+\t\tMap<InputChannelStateHandle, byte[]> handlesAndBytes = generateHandlesWithBytes(10, 20);\n+\t\tChannelStateReader reader = new ChannelStateReaderImpl(taskStateSnapshot(handlesAndBytes.keySet()), new ChannelStateSerializerImpl());\n+\t\tfor (Map.Entry<InputChannelStateHandle, byte[]> e : handlesAndBytes.entrySet()) {\n+\t\t\treadAndVerify(42, e.getKey().getInfo(), e.getValue(), reader);\n+\t\t}\n+\t}\n+\n+\t@Test(expected = Exception.class)\n+\tpublic void testReadOnlyOnce() throws IOException {\n+\t\treader.readInputData(CHANNEL, getBuffer(DATA.length));\n+\t\treader.readInputData(CHANNEL, getBuffer(DATA.length));\n+\t}\n+\n+\t@Test(expected = Exception.class)\n+\tpublic void testReadClosed() throws Exception {\n+\t\treader.close();\n+\t\treader.readInputData(CHANNEL, getBuffer(DATA.length));\n+\t}\n+\n+\t@Test(expected = IllegalArgumentException.class)\n+\tpublic void testReadWrongChannelState() throws IOException {\n+\t\tInputChannelInfo wrongChannel = new InputChannelInfo(CHANNEL.getGateIdx() + 1, CHANNEL.getInputChannelIdx() + 1);\n+\t\treader.readInputData(wrongChannel, getBuffer(DATA.length));\n+\t}\n+\n+\tprivate TaskStateSnapshot taskStateSnapshot(Collection<InputChannelStateHandle> inputChannelStateHandles) {\n+\t\treturn new TaskStateSnapshot(Collections.singletonMap(\n+\t\t\tnew OperatorID(),\n+\t\t\tnew OperatorSubtaskState(\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tnew StateObjectCollection<>(inputChannelStateHandles),\n+\t\t\t\tStateObjectCollection.empty()\n+\t\t\t)));\n+\t}\n+\n+\tprivate static byte[] generateData(int len) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 119}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxNTkwMzAyOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializerTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxMDozOTozMlrOGCpYTQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxMDozOTozMlrOGCpYTQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQyODMwMQ==", "bodyText": "This class can be merged with ChannelStateSerializerImplTest, because they are all aiming for testing the ChannelStateSerializerImpl actually, for wrapping BufferBuilder, Buffer, and bytes[] separately in different tests.", "url": "https://github.com/apache/flink/pull/11515#discussion_r405428301", "createdAt": "2020-04-08T10:39:32Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializerTest.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.memory.MemorySegmentFactory;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+\n+import org.junit.Test;\n+\n+import java.io.ByteArrayInputStream;\n+import java.io.ByteArrayOutputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.util.Random;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateByteBuffer.wrap;\n+import static org.junit.Assert.assertArrayEquals;\n+import static org.junit.Assert.assertEquals;\n+\n+/**\n+ * ChannelStateSerializerTest.\n+ */\n+public class ChannelStateSerializerTest {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 40}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxNjMwNDg3OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImplTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxMjozOToxOFrOGCtRZg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxNDo1NToxOVrOGCzHiA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQ5MjA3MA==", "bodyText": "eventBuf.recycleBuffer()", "url": "https://github.com/apache/flink/pull/11515#discussion_r405492070", "createdAt": "2020-04-08T12:39:18Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImplTest.java", "diffHunk": "@@ -0,0 +1,320 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.memory.HeapMemorySegment;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.util.function.BiConsumerWithException;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.ArrayDeque;\n+import java.util.Deque;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.function.Consumer;\n+\n+import static org.apache.flink.runtime.state.ChannelPersistenceITCase.getStreamFactoryFactory;\n+import static org.apache.flink.util.ExceptionUtils.findThrowable;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * {@link ChannelStateWriterImpl} lifecycle tests.\n+ */\n+public class ChannelStateWriterImplTest {\n+\tprivate static final long CHECKPOINT_ID = 42L;\n+\n+\t@Test(expected = IllegalArgumentException.class)\n+\tpublic void testAddEventBuffer() {\n+\t\tNetworkBuffer dataBuf = getBuffer();\n+\t\tNetworkBuffer eventBuf = getBuffer();\n+\t\teventBuf.tagAsEvent();\n+\t\tChannelStateWriterImpl writer = openWriter();\n+\t\tcallStart(writer);\n+\t\ttry {\n+\t\t\twriter.addInputData(CHECKPOINT_ID, new InputChannelInfo(1, 1), 1, eventBuf, dataBuf);\n+\t\t} finally {\n+\t\t\tassertTrue(dataBuf.isRecycled());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTU4Nzg0OA==", "bodyText": "I used HeapMemorySegment in tests so buffers are freed when the method finishes at the latest.\nrecycleBuffer() would just make them eligible for GC a couple of instructions earlier.", "url": "https://github.com/apache/flink/pull/11515#discussion_r405587848", "createdAt": "2020-04-08T14:55:19Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImplTest.java", "diffHunk": "@@ -0,0 +1,320 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.memory.HeapMemorySegment;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.util.function.BiConsumerWithException;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.ArrayDeque;\n+import java.util.Deque;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.function.Consumer;\n+\n+import static org.apache.flink.runtime.state.ChannelPersistenceITCase.getStreamFactoryFactory;\n+import static org.apache.flink.util.ExceptionUtils.findThrowable;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * {@link ChannelStateWriterImpl} lifecycle tests.\n+ */\n+public class ChannelStateWriterImplTest {\n+\tprivate static final long CHECKPOINT_ID = 42L;\n+\n+\t@Test(expected = IllegalArgumentException.class)\n+\tpublic void testAddEventBuffer() {\n+\t\tNetworkBuffer dataBuf = getBuffer();\n+\t\tNetworkBuffer eventBuf = getBuffer();\n+\t\teventBuf.tagAsEvent();\n+\t\tChannelStateWriterImpl writer = openWriter();\n+\t\tcallStart(writer);\n+\t\ttry {\n+\t\t\twriter.addInputData(CHECKPOINT_ID, new InputChannelInfo(1, 1), 1, eventBuf, dataBuf);\n+\t\t} finally {\n+\t\t\tassertTrue(dataBuf.isRecycled());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQ5MjA3MA=="}, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 57}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxNjQ2NzEwOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestExecutorImplTest.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxMzoxODo1NlrOGCu1ug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxNjo1OTozM1rOGC4cHw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTUxNzc1NA==", "bodyText": "The worker should start after created, otherwise even though we do not call close via WorkerClosingDeque, it can still encounter exception as did in testSubmitFailure.", "url": "https://github.com/apache/flink/pull/11515#discussion_r405517754", "createdAt": "2020-04-08T13:18:56Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestExecutorImplTest.java", "diffHunk": "@@ -0,0 +1,203 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.function.BiConsumerWithException;\n+\n+import org.junit.Test;\n+\n+import javax.annotation.Nonnull;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.concurrent.LinkedBlockingDeque;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequestDispatcher.NO_OP;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * {@link ChannelStateWriteRequestExecutorImpl} test.\n+ */\n+public class ChannelStateWriteRequestExecutorImplTest {\n+\n+\t@Test(expected = IllegalStateException.class)\n+\tpublic void testCloseAfterSubmit() throws Exception {\n+\t\ttestCloseAfterSubmit(ChannelStateWriteRequestExecutor::submit);\n+\t}\n+\n+\t@Test(expected = IllegalStateException.class)\n+\tpublic void testCloseAfterSubmitPriority() throws Exception {\n+\t\ttestCloseAfterSubmit(ChannelStateWriteRequestExecutor::submitPriority);\n+\t}\n+\n+\t@Test\n+\tpublic void testSubmitFailure() throws Exception {\n+\t\ttestSubmitFailure(ChannelStateWriteRequestExecutor::submit);\n+\t}\n+\n+\t@Test\n+\tpublic void testSubmitPriorityFailure() throws Exception {\n+\t\ttestSubmitFailure(ChannelStateWriteRequestExecutor::submitPriority);\n+\t}\n+\n+\tprivate void testCloseAfterSubmit(BiConsumerWithException<ChannelStateWriteRequestExecutor, ChannelStateWriteRequest, Exception> requestFun) throws Exception {\n+\t\tWorkerClosingDeque closingDeque = new WorkerClosingDeque();\n+\t\tChannelStateWriteRequestExecutorImpl worker = new ChannelStateWriteRequestExecutorImpl(NO_OP, closingDeque);\n+\t\tclosingDeque.setWorker(worker);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTYwMDg1Mg==", "bodyText": "I didn't get your point here, can you please explain what do you mean?", "url": "https://github.com/apache/flink/pull/11515#discussion_r405600852", "createdAt": "2020-04-08T15:12:53Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestExecutorImplTest.java", "diffHunk": "@@ -0,0 +1,203 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.function.BiConsumerWithException;\n+\n+import org.junit.Test;\n+\n+import javax.annotation.Nonnull;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.concurrent.LinkedBlockingDeque;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequestDispatcher.NO_OP;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * {@link ChannelStateWriteRequestExecutorImpl} test.\n+ */\n+public class ChannelStateWriteRequestExecutorImplTest {\n+\n+\t@Test(expected = IllegalStateException.class)\n+\tpublic void testCloseAfterSubmit() throws Exception {\n+\t\ttestCloseAfterSubmit(ChannelStateWriteRequestExecutor::submit);\n+\t}\n+\n+\t@Test(expected = IllegalStateException.class)\n+\tpublic void testCloseAfterSubmitPriority() throws Exception {\n+\t\ttestCloseAfterSubmit(ChannelStateWriteRequestExecutor::submitPriority);\n+\t}\n+\n+\t@Test\n+\tpublic void testSubmitFailure() throws Exception {\n+\t\ttestSubmitFailure(ChannelStateWriteRequestExecutor::submit);\n+\t}\n+\n+\t@Test\n+\tpublic void testSubmitPriorityFailure() throws Exception {\n+\t\ttestSubmitFailure(ChannelStateWriteRequestExecutor::submitPriority);\n+\t}\n+\n+\tprivate void testCloseAfterSubmit(BiConsumerWithException<ChannelStateWriteRequestExecutor, ChannelStateWriteRequest, Exception> requestFun) throws Exception {\n+\t\tWorkerClosingDeque closingDeque = new WorkerClosingDeque();\n+\t\tChannelStateWriteRequestExecutorImpl worker = new ChannelStateWriteRequestExecutorImpl(NO_OP, closingDeque);\n+\t\tclosingDeque.setWorker(worker);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTUxNzc1NA=="}, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTY3NTAzOQ==", "bodyText": "I mean it is better to add worker.start(), then it is easy to distinguish the conditions with below testSubmitFailure. testSubmitFailure is to test the impact without starting, and testCloseAfterSubmit is to test the impact withe explicit close after starting.", "url": "https://github.com/apache/flink/pull/11515#discussion_r405675039", "createdAt": "2020-04-08T16:59:33Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestExecutorImplTest.java", "diffHunk": "@@ -0,0 +1,203 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.function.BiConsumerWithException;\n+\n+import org.junit.Test;\n+\n+import javax.annotation.Nonnull;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.concurrent.LinkedBlockingDeque;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequestDispatcher.NO_OP;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * {@link ChannelStateWriteRequestExecutorImpl} test.\n+ */\n+public class ChannelStateWriteRequestExecutorImplTest {\n+\n+\t@Test(expected = IllegalStateException.class)\n+\tpublic void testCloseAfterSubmit() throws Exception {\n+\t\ttestCloseAfterSubmit(ChannelStateWriteRequestExecutor::submit);\n+\t}\n+\n+\t@Test(expected = IllegalStateException.class)\n+\tpublic void testCloseAfterSubmitPriority() throws Exception {\n+\t\ttestCloseAfterSubmit(ChannelStateWriteRequestExecutor::submitPriority);\n+\t}\n+\n+\t@Test\n+\tpublic void testSubmitFailure() throws Exception {\n+\t\ttestSubmitFailure(ChannelStateWriteRequestExecutor::submit);\n+\t}\n+\n+\t@Test\n+\tpublic void testSubmitPriorityFailure() throws Exception {\n+\t\ttestSubmitFailure(ChannelStateWriteRequestExecutor::submitPriority);\n+\t}\n+\n+\tprivate void testCloseAfterSubmit(BiConsumerWithException<ChannelStateWriteRequestExecutor, ChannelStateWriteRequest, Exception> requestFun) throws Exception {\n+\t\tWorkerClosingDeque closingDeque = new WorkerClosingDeque();\n+\t\tChannelStateWriteRequestExecutorImpl worker = new ChannelStateWriteRequestExecutorImpl(NO_OP, closingDeque);\n+\t\tclosingDeque.setWorker(worker);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTUxNzc1NA=="}, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 63}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxNzAwNzY4OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestExecutorImplTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxNToxODowMlrOGC0JLQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxNTo1OToyMFrOGC2AKQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTYwNDY1Mw==", "bodyText": "I am not quite clear what is this test motivation for. When the dispatcher throws exception, it would terminate the internal thread inside ChannelStateWriteRequestExecutorImpl. And when the worker#close, it should throw exception actually, i think we should verify the exception is same with testException", "url": "https://github.com/apache/flink/pull/11515#discussion_r405604653", "createdAt": "2020-04-08T15:18:02Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestExecutorImplTest.java", "diffHunk": "@@ -0,0 +1,203 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.function.BiConsumerWithException;\n+\n+import org.junit.Test;\n+\n+import javax.annotation.Nonnull;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.concurrent.LinkedBlockingDeque;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequestDispatcher.NO_OP;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * {@link ChannelStateWriteRequestExecutorImpl} test.\n+ */\n+public class ChannelStateWriteRequestExecutorImplTest {\n+\n+\t@Test(expected = IllegalStateException.class)\n+\tpublic void testCloseAfterSubmit() throws Exception {\n+\t\ttestCloseAfterSubmit(ChannelStateWriteRequestExecutor::submit);\n+\t}\n+\n+\t@Test(expected = IllegalStateException.class)\n+\tpublic void testCloseAfterSubmitPriority() throws Exception {\n+\t\ttestCloseAfterSubmit(ChannelStateWriteRequestExecutor::submitPriority);\n+\t}\n+\n+\t@Test\n+\tpublic void testSubmitFailure() throws Exception {\n+\t\ttestSubmitFailure(ChannelStateWriteRequestExecutor::submit);\n+\t}\n+\n+\t@Test\n+\tpublic void testSubmitPriorityFailure() throws Exception {\n+\t\ttestSubmitFailure(ChannelStateWriteRequestExecutor::submitPriority);\n+\t}\n+\n+\tprivate void testCloseAfterSubmit(BiConsumerWithException<ChannelStateWriteRequestExecutor, ChannelStateWriteRequest, Exception> requestFun) throws Exception {\n+\t\tWorkerClosingDeque closingDeque = new WorkerClosingDeque();\n+\t\tChannelStateWriteRequestExecutorImpl worker = new ChannelStateWriteRequestExecutorImpl(NO_OP, closingDeque);\n+\t\tclosingDeque.setWorker(worker);\n+\t\tTestWriteRequest request = new TestWriteRequest();\n+\t\trequestFun.accept(worker, request);\n+\t\tassertTrue(closingDeque.isEmpty());\n+\t\tassertFalse(request.isCancelled());\n+\t}\n+\n+\tprivate void testSubmitFailure(BiConsumerWithException<ChannelStateWriteRequestExecutor, ChannelStateWriteRequest, Exception> submitAction) throws Exception {\n+\t\tTestWriteRequest request = new TestWriteRequest();\n+\t\tLinkedBlockingDeque<ChannelStateWriteRequest> deque = new LinkedBlockingDeque<>();\n+\t\ttry {\n+\t\t\tsubmitAction.accept(new ChannelStateWriteRequestExecutorImpl(NO_OP, deque), request);\n+\t\t} catch (IllegalStateException e) {\n+\t\t\t// expected: executor not started;\n+\t\t\treturn;\n+\t\t} finally {\n+\t\t\tassertTrue(request.cancelled);\n+\t\t\tassertTrue(deque.isEmpty());\n+\t\t}\n+\t\tthrow new RuntimeException(\"expected exception not thrown\");\n+\t}\n+\n+\t@Test\n+\t@SuppressWarnings(\"CallToThreadRun\")\n+\tpublic void testCleanup() throws IOException {\n+\t\tTestWriteRequest request = new TestWriteRequest();\n+\t\tLinkedBlockingDeque<ChannelStateWriteRequest> deque = new LinkedBlockingDeque<>();\n+\t\tdeque.add(request);\n+\t\tTestRequestDispatcher requestProcessor = new TestRequestDispatcher();\n+\t\tChannelStateWriteRequestExecutorImpl worker = new ChannelStateWriteRequestExecutorImpl(requestProcessor, deque);\n+\n+\t\tworker.close();\n+\t\tworker.run();\n+\n+\t\tassertTrue(requestProcessor.isStopped());\n+\t\tassertTrue(deque.isEmpty());\n+\t\tassertTrue(request.isCancelled());\n+\t}\n+\n+\t@Test\n+\tpublic void testIgnoresInterruptsWhileRunning() throws Exception {\n+\t\tTestRequestDispatcher requestProcessor = new TestRequestDispatcher();\n+\t\tLinkedBlockingDeque<ChannelStateWriteRequest> deque = new LinkedBlockingDeque<>();\n+\t\ttry (ChannelStateWriteRequestExecutorImpl worker = new ChannelStateWriteRequestExecutorImpl(requestProcessor, deque)) {\n+\t\t\tworker.start();\n+\t\t\tworker.getThread().interrupt();\n+\t\t\tworker.submit(new TestWriteRequest());\n+\t\t\tworker.getThread().interrupt();\n+\t\t\twhile (!deque.isEmpty()) {\n+\t\t\t\tThread.sleep(100);\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\t@Test\n+\tpublic void testCanBeClosed() throws IOException {\n+\t\tTestRequestDispatcher requestProcessor = new TestRequestDispatcher();\n+\t\ttry (ChannelStateWriteRequestExecutorImpl worker = new ChannelStateWriteRequestExecutorImpl(requestProcessor)) {\n+\t\t\tworker.start();\n+\t\t}\n+\t}\n+\n+\t@Test\n+\tpublic void testRecordsException() throws Exception {\n+\t\tTestException testException = new TestException();\n+\t\tTestRequestDispatcher requestProcessor = new TestRequestDispatcher() {\n+\t\t\t@Override\n+\t\t\tpublic void dispatch(ChannelStateWriteRequest request) {\n+\t\t\t\tthrow testException;\n+\t\t\t}\n+\t\t};\n+\t\tLinkedBlockingDeque<ChannelStateWriteRequest> deque = new LinkedBlockingDeque<>(Arrays.asList(new TestWriteRequest()));\n+\t\ttry (ChannelStateWriteRequestExecutorImpl worker = new ChannelStateWriteRequestExecutorImpl(requestProcessor, deque)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 135}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTYzNTExMw==", "bodyText": "Right.\nFixed, thanks for pointing this out", "url": "https://github.com/apache/flink/pull/11515#discussion_r405635113", "createdAt": "2020-04-08T15:59:20Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestExecutorImplTest.java", "diffHunk": "@@ -0,0 +1,203 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.function.BiConsumerWithException;\n+\n+import org.junit.Test;\n+\n+import javax.annotation.Nonnull;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.concurrent.LinkedBlockingDeque;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequestDispatcher.NO_OP;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * {@link ChannelStateWriteRequestExecutorImpl} test.\n+ */\n+public class ChannelStateWriteRequestExecutorImplTest {\n+\n+\t@Test(expected = IllegalStateException.class)\n+\tpublic void testCloseAfterSubmit() throws Exception {\n+\t\ttestCloseAfterSubmit(ChannelStateWriteRequestExecutor::submit);\n+\t}\n+\n+\t@Test(expected = IllegalStateException.class)\n+\tpublic void testCloseAfterSubmitPriority() throws Exception {\n+\t\ttestCloseAfterSubmit(ChannelStateWriteRequestExecutor::submitPriority);\n+\t}\n+\n+\t@Test\n+\tpublic void testSubmitFailure() throws Exception {\n+\t\ttestSubmitFailure(ChannelStateWriteRequestExecutor::submit);\n+\t}\n+\n+\t@Test\n+\tpublic void testSubmitPriorityFailure() throws Exception {\n+\t\ttestSubmitFailure(ChannelStateWriteRequestExecutor::submitPriority);\n+\t}\n+\n+\tprivate void testCloseAfterSubmit(BiConsumerWithException<ChannelStateWriteRequestExecutor, ChannelStateWriteRequest, Exception> requestFun) throws Exception {\n+\t\tWorkerClosingDeque closingDeque = new WorkerClosingDeque();\n+\t\tChannelStateWriteRequestExecutorImpl worker = new ChannelStateWriteRequestExecutorImpl(NO_OP, closingDeque);\n+\t\tclosingDeque.setWorker(worker);\n+\t\tTestWriteRequest request = new TestWriteRequest();\n+\t\trequestFun.accept(worker, request);\n+\t\tassertTrue(closingDeque.isEmpty());\n+\t\tassertFalse(request.isCancelled());\n+\t}\n+\n+\tprivate void testSubmitFailure(BiConsumerWithException<ChannelStateWriteRequestExecutor, ChannelStateWriteRequest, Exception> submitAction) throws Exception {\n+\t\tTestWriteRequest request = new TestWriteRequest();\n+\t\tLinkedBlockingDeque<ChannelStateWriteRequest> deque = new LinkedBlockingDeque<>();\n+\t\ttry {\n+\t\t\tsubmitAction.accept(new ChannelStateWriteRequestExecutorImpl(NO_OP, deque), request);\n+\t\t} catch (IllegalStateException e) {\n+\t\t\t// expected: executor not started;\n+\t\t\treturn;\n+\t\t} finally {\n+\t\t\tassertTrue(request.cancelled);\n+\t\t\tassertTrue(deque.isEmpty());\n+\t\t}\n+\t\tthrow new RuntimeException(\"expected exception not thrown\");\n+\t}\n+\n+\t@Test\n+\t@SuppressWarnings(\"CallToThreadRun\")\n+\tpublic void testCleanup() throws IOException {\n+\t\tTestWriteRequest request = new TestWriteRequest();\n+\t\tLinkedBlockingDeque<ChannelStateWriteRequest> deque = new LinkedBlockingDeque<>();\n+\t\tdeque.add(request);\n+\t\tTestRequestDispatcher requestProcessor = new TestRequestDispatcher();\n+\t\tChannelStateWriteRequestExecutorImpl worker = new ChannelStateWriteRequestExecutorImpl(requestProcessor, deque);\n+\n+\t\tworker.close();\n+\t\tworker.run();\n+\n+\t\tassertTrue(requestProcessor.isStopped());\n+\t\tassertTrue(deque.isEmpty());\n+\t\tassertTrue(request.isCancelled());\n+\t}\n+\n+\t@Test\n+\tpublic void testIgnoresInterruptsWhileRunning() throws Exception {\n+\t\tTestRequestDispatcher requestProcessor = new TestRequestDispatcher();\n+\t\tLinkedBlockingDeque<ChannelStateWriteRequest> deque = new LinkedBlockingDeque<>();\n+\t\ttry (ChannelStateWriteRequestExecutorImpl worker = new ChannelStateWriteRequestExecutorImpl(requestProcessor, deque)) {\n+\t\t\tworker.start();\n+\t\t\tworker.getThread().interrupt();\n+\t\t\tworker.submit(new TestWriteRequest());\n+\t\t\tworker.getThread().interrupt();\n+\t\t\twhile (!deque.isEmpty()) {\n+\t\t\t\tThread.sleep(100);\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\t@Test\n+\tpublic void testCanBeClosed() throws IOException {\n+\t\tTestRequestDispatcher requestProcessor = new TestRequestDispatcher();\n+\t\ttry (ChannelStateWriteRequestExecutorImpl worker = new ChannelStateWriteRequestExecutorImpl(requestProcessor)) {\n+\t\t\tworker.start();\n+\t\t}\n+\t}\n+\n+\t@Test\n+\tpublic void testRecordsException() throws Exception {\n+\t\tTestException testException = new TestException();\n+\t\tTestRequestDispatcher requestProcessor = new TestRequestDispatcher() {\n+\t\t\t@Override\n+\t\t\tpublic void dispatch(ChannelStateWriteRequest request) {\n+\t\t\t\tthrow testException;\n+\t\t\t}\n+\t\t};\n+\t\tLinkedBlockingDeque<ChannelStateWriteRequest> deque = new LinkedBlockingDeque<>(Arrays.asList(new TestWriteRequest()));\n+\t\ttry (ChannelStateWriteRequestExecutorImpl worker = new ChannelStateWriteRequestExecutorImpl(requestProcessor, deque)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTYwNDY1Mw=="}, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 135}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxNzEwNDEyOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImplTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxNTozODoxMVrOGC1EmA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOVQwNzoyODowNVrOGDMwZg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTYxOTg2NA==", "bodyText": "I guess it is not determined results? When the writer#close, then it relies on ChannelStateWriteRequestExecutorImpl#cleanupRequests to cancel the start request to complete the result. But if the start request was already taken away from the queue by internal thread before, then we can not take it from queue to cancel. Or I missed something else?", "url": "https://github.com/apache/flink/pull/11515#discussion_r405619864", "createdAt": "2020-04-08T15:38:11Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImplTest.java", "diffHunk": "@@ -0,0 +1,320 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.memory.HeapMemorySegment;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.util.function.BiConsumerWithException;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.ArrayDeque;\n+import java.util.Deque;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.function.Consumer;\n+\n+import static org.apache.flink.runtime.state.ChannelPersistenceITCase.getStreamFactoryFactory;\n+import static org.apache.flink.util.ExceptionUtils.findThrowable;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * {@link ChannelStateWriterImpl} lifecycle tests.\n+ */\n+public class ChannelStateWriterImplTest {\n+\tprivate static final long CHECKPOINT_ID = 42L;\n+\n+\t@Test(expected = IllegalArgumentException.class)\n+\tpublic void testAddEventBuffer() {\n+\t\tNetworkBuffer dataBuf = getBuffer();\n+\t\tNetworkBuffer eventBuf = getBuffer();\n+\t\teventBuf.tagAsEvent();\n+\t\tChannelStateWriterImpl writer = openWriter();\n+\t\tcallStart(writer);\n+\t\ttry {\n+\t\t\twriter.addInputData(CHECKPOINT_ID, new InputChannelInfo(1, 1), 1, eventBuf, dataBuf);\n+\t\t} finally {\n+\t\t\tassertTrue(dataBuf.isRecycled());\n+\t\t}\n+\t}\n+\n+\t@Test\n+\tpublic void testResultCompletion() throws IOException {\n+\t\tChannelStateWriteResult result;\n+\t\ttry (ChannelStateWriterImpl writer = openWriter()) {\n+\t\t\tcallStart(writer);\n+\t\t\tresult = writer.getWriteResult(CHECKPOINT_ID);\n+\t\t\tassertFalse(result.resultSubpartitionStateHandles.isDone());\n+\t\t\tassertFalse(result.inputChannelStateHandles.isDone());\n+\t\t}\n+\t\tassertTrue(result.inputChannelStateHandles.isDone());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjAwNzkxMA==", "bodyText": "The result shoud be competed by ChannelStateWriterImpl.close() which is not affected by any other threads.", "url": "https://github.com/apache/flink/pull/11515#discussion_r406007910", "createdAt": "2020-04-09T07:28:05Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImplTest.java", "diffHunk": "@@ -0,0 +1,320 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.memory.HeapMemorySegment;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.util.function.BiConsumerWithException;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.ArrayDeque;\n+import java.util.Deque;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.function.Consumer;\n+\n+import static org.apache.flink.runtime.state.ChannelPersistenceITCase.getStreamFactoryFactory;\n+import static org.apache.flink.util.ExceptionUtils.findThrowable;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * {@link ChannelStateWriterImpl} lifecycle tests.\n+ */\n+public class ChannelStateWriterImplTest {\n+\tprivate static final long CHECKPOINT_ID = 42L;\n+\n+\t@Test(expected = IllegalArgumentException.class)\n+\tpublic void testAddEventBuffer() {\n+\t\tNetworkBuffer dataBuf = getBuffer();\n+\t\tNetworkBuffer eventBuf = getBuffer();\n+\t\teventBuf.tagAsEvent();\n+\t\tChannelStateWriterImpl writer = openWriter();\n+\t\tcallStart(writer);\n+\t\ttry {\n+\t\t\twriter.addInputData(CHECKPOINT_ID, new InputChannelInfo(1, 1), 1, eventBuf, dataBuf);\n+\t\t} finally {\n+\t\t\tassertTrue(dataBuf.isRecycled());\n+\t\t}\n+\t}\n+\n+\t@Test\n+\tpublic void testResultCompletion() throws IOException {\n+\t\tChannelStateWriteResult result;\n+\t\ttry (ChannelStateWriterImpl writer = openWriter()) {\n+\t\t\tcallStart(writer);\n+\t\t\tresult = writer.getWriteResult(CHECKPOINT_ID);\n+\t\t\tassertFalse(result.resultSubpartitionStateHandles.isDone());\n+\t\t\tassertFalse(result.inputChannelStateHandles.isDone());\n+\t\t}\n+\t\tassertTrue(result.inputChannelStateHandles.isDone());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTYxOTg2NA=="}, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 70}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxNzExMDM5OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImplTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxNTozOTozNlrOGC1Ijg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxNTozOTozNlrOGC1Ijg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTYyMDg3OA==", "bodyText": "indentation formatting", "url": "https://github.com/apache/flink/pull/11515#discussion_r405620878", "createdAt": "2020-04-08T15:39:36Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImplTest.java", "diffHunk": "@@ -0,0 +1,320 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.memory.HeapMemorySegment;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.util.function.BiConsumerWithException;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.ArrayDeque;\n+import java.util.Deque;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.function.Consumer;\n+\n+import static org.apache.flink.runtime.state.ChannelPersistenceITCase.getStreamFactoryFactory;\n+import static org.apache.flink.util.ExceptionUtils.findThrowable;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * {@link ChannelStateWriterImpl} lifecycle tests.\n+ */\n+public class ChannelStateWriterImplTest {\n+\tprivate static final long CHECKPOINT_ID = 42L;\n+\n+\t@Test(expected = IllegalArgumentException.class)\n+\tpublic void testAddEventBuffer() {\n+\t\tNetworkBuffer dataBuf = getBuffer();\n+\t\tNetworkBuffer eventBuf = getBuffer();\n+\t\teventBuf.tagAsEvent();\n+\t\tChannelStateWriterImpl writer = openWriter();\n+\t\tcallStart(writer);\n+\t\ttry {\n+\t\t\twriter.addInputData(CHECKPOINT_ID, new InputChannelInfo(1, 1), 1, eventBuf, dataBuf);\n+\t\t} finally {\n+\t\t\tassertTrue(dataBuf.isRecycled());\n+\t\t}\n+\t}\n+\n+\t@Test\n+\tpublic void testResultCompletion() throws IOException {\n+\t\tChannelStateWriteResult result;\n+\t\ttry (ChannelStateWriterImpl writer = openWriter()) {\n+\t\t\tcallStart(writer);\n+\t\t\tresult = writer.getWriteResult(CHECKPOINT_ID);\n+\t\t\tassertFalse(result.resultSubpartitionStateHandles.isDone());\n+\t\t\tassertFalse(result.inputChannelStateHandles.isDone());\n+\t\t}\n+\t\tassertTrue(result.inputChannelStateHandles.isDone());\n+\t\tassertTrue(result.resultSubpartitionStateHandles.isDone());\n+\t}\n+\n+\t@Test\n+\tpublic void testAbort() throws Exception {\n+\t\tNetworkBuffer buffer = getBuffer();\n+\t\trunWithSyncWorker((writer, worker) -> {\n+\t\t\tcallStart(writer);\n+\t\t\tcallAddInputData(writer, buffer);\n+\t\t\tcallAbort(writer);\n+\t\t\tworker.processAllRequests();\n+\t\t\tassertTrue(writer.getWriteResult(CHECKPOINT_ID).isDone());\n+\t\t\tassertTrue(buffer.isRecycled());\n+\t\t});\n+\t}\n+\n+\t@Test\n+\tpublic void testAbortIgnoresMissing() throws Exception {\n+\t\trunWithSyncWorker(this::callAbort);\n+\t}\n+\n+\t@Test(expected = TestException.class)\n+\tpublic void testBuffersRecycledOnError() throws Exception {\n+\t\tunwrappingError(TestException.class, () -> {\n+\t\t\tNetworkBuffer buffer = getBuffer();\n+\t\t\ttry (ChannelStateWriterImpl writer = new ChannelStateWriterImpl(new ConcurrentHashMap<>(), failingWorker(), 5)) {\n+\t\t\t\twriter.open();\n+\t\t\t\tcallAddInputData(writer, buffer);\n+\t\t\t} finally {\n+\t\t\t\tassertTrue(buffer.isRecycled());\n+\t\t\t}\n+\t\t});\n+\t}\n+\n+\t@Test\n+\tpublic void testBuffersRecycledOnClose() throws IOException {\n+\t\tNetworkBuffer buffer = getBuffer();\n+\t\ttry (ChannelStateWriterImpl writer = openWriter()) {\n+\t\t\tcallStart(writer);\n+\t\t\tcallAddInputData(writer, buffer);\n+\t\t\tassertFalse(buffer.isRecycled());\n+\t\t}\n+\t\tassertTrue(buffer.isRecycled());\n+\t}\n+\n+\t@Test(expected = IllegalArgumentException.class)\n+\tpublic void testNoAddDataAfterFinished() throws Exception {\n+\t\tunwrappingError(IllegalArgumentException.class, () -> runWithSyncWorker(\n+\t\t\twriter -> {\n+\t\t\t\tcallStart(writer);\n+\t\t\t\tcallFinish(writer);\n+\t\t\t\tcallAddInputData(writer);\n+\t\t\t}\n+\t\t));\n+\t}\n+\n+\t@Test(expected = IllegalArgumentException.class)\n+\tpublic void testAddDataNotStarted() throws Exception {\n+\t\tunwrappingError(IllegalArgumentException.class, () -> runWithSyncWorker(writer -> callAddInputData(writer)));\n+\t}\n+\n+\t@Test(expected = IllegalArgumentException.class)\n+\tpublic void testFinishNotStarted() throws Exception {\n+\t\tunwrappingError(IllegalArgumentException.class, () -> runWithSyncWorker(this::callFinish));\n+\t}\n+\n+\t@Test(expected = IllegalArgumentException.class)\n+\tpublic void testRethrowOnClose() throws Exception {\n+\t\tunwrappingError(IllegalArgumentException.class, () -> runWithSyncWorker(\n+\t\t\twriter -> {\n+\t\t\t\ttry {\n+\t\t\t\t\tcallFinish(writer);\n+\t\t\t\t} catch (IllegalArgumentException e) {\n+\t\t\t\t\t// ignore here - should rethrow in close\n+\t\t\t\t}\n+\t\t\t}\n+\t\t));\n+\t}\n+\n+\t@Test(expected = TestException.class)\n+\tpublic void testRethrowOnNextCall() throws Exception {\n+\t\tSyncChannelStateWriteRequestExecutor worker = new SyncChannelStateWriteRequestExecutor();\n+\t\tChannelStateWriterImpl writer = new ChannelStateWriterImpl(new ConcurrentHashMap<>(), worker, 5);\n+\t\twriter.open();\n+\t\tworker.setThrown(new TestException());\n+\t\tunwrappingError(TestException.class, () -> callStart(writer));\n+\t}\n+\n+\t@Test(expected = IllegalStateException.class)\n+\tpublic void testLimit() throws IOException {\n+\t\tint maxCheckpoints = 3;\n+\t\ttry (ChannelStateWriterImpl writer = new ChannelStateWriterImpl(getStreamFactoryFactory(), maxCheckpoints)) {\n+\t\t\twriter.open();\n+\t\t\tfor (int i = 0; i < maxCheckpoints; i++) {\n+\t\t\t\twriter.start(i, CheckpointOptions.forCheckpointWithDefaultLocation());\n+\t\t\t}\n+\t\t\twriter.start(maxCheckpoints, CheckpointOptions.forCheckpointWithDefaultLocation());\n+\t\t}\n+\t}\n+\n+\t@Test(expected = IllegalStateException.class)\n+\tpublic void testStartNotOpened() throws Exception {\n+\t\tunwrappingError(IllegalStateException.class, () -> {\n+\t\t\ttry (ChannelStateWriterImpl writer = new ChannelStateWriterImpl(getStreamFactoryFactory())) {\n+\t\t\t\tcallStart(writer);\n+\t\t\t}\n+\t\t});\n+\t}\n+\n+\t@Test(expected = IllegalStateException.class)\n+\tpublic void testNoStartAfterClose() throws Exception {\n+\t\tunwrappingError(IllegalStateException.class, () -> {\n+\t\t\tChannelStateWriterImpl writer = openWriter();\n+\t\t\twriter.close();\n+\t\t\twriter.start(42, CheckpointOptions.forCheckpointWithDefaultLocation());\n+\t\t});\n+\t}\n+\n+\t@Test(expected = IllegalStateException.class)\n+\tpublic void testNoAddDataAfterClose() throws Exception {\n+\t\tunwrappingError(IllegalStateException.class, () -> {\n+\t\t\tChannelStateWriterImpl writer = openWriter();\n+\t\t\tcallStart(writer);\n+\t\t\twriter.close();\n+\t\t\tcallAddInputData(writer);\n+\t\t});\n+\t}\n+\n+\tprivate static <T extends Throwable> void unwrappingError(Class<T> clazz, RunnableWithException r) throws Exception {\n+\t\ttry {\n+\t\t\tr.run();\n+\t\t} catch (Exception e) {\n+\t\t\tthrow findThrowable(e, clazz).map(te -> (Exception) te).orElse(e);\n+\t\t}\n+\t}\n+\n+\tprivate NetworkBuffer getBuffer() {\n+\t\treturn new NetworkBuffer(HeapMemorySegment.FACTORY.allocateUnpooledSegment(123, null), FreeingBufferRecycler.INSTANCE);\n+\t}\n+\n+\tprivate ChannelStateWriteRequestExecutor failingWorker() {\n+\t\treturn new ChannelStateWriteRequestExecutor() {\n+\t\t\t@Override\n+\t\t\tpublic void close() {\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic void submit(ChannelStateWriteRequest e) {\n+\t\t\t\tthrow new TestException();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic void submitPriority(ChannelStateWriteRequest e) {\n+\t\t\t\tthrow new TestException();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic void start() throws IllegalStateException {\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tprivate void runWithSyncWorker(Consumer<ChannelStateWriter> writerConsumer) throws Exception {\n+\t\trunWithSyncWorker((channelStateWriter, syncChannelStateWriterWorker) -> writerConsumer.accept(channelStateWriter));\n+\t}\n+\n+\tprivate void runWithSyncWorker(BiConsumerWithException<ChannelStateWriter, SyncChannelStateWriteRequestExecutor, Exception> testFn) throws Exception {\n+\t\ttry (\n+\t\t\t\tSyncChannelStateWriteRequestExecutor worker = new SyncChannelStateWriteRequestExecutor();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 239}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxNzE5NTU0OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImplTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxNTo1ODo0M1rOGC1-Ug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOVQwNzozMzo1OVrOGDM7pw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTYzNDY0Mg==", "bodyText": "seems unstable results? After callAddInputData, if the enqueued buffer is already dispatched to be executed by internal thread, then the buffer should be recycled when this assert calls. Although this probability is very small, but in theory it is not stable and easily fragile.", "url": "https://github.com/apache/flink/pull/11515#discussion_r405634642", "createdAt": "2020-04-08T15:58:43Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImplTest.java", "diffHunk": "@@ -0,0 +1,320 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.memory.HeapMemorySegment;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.util.function.BiConsumerWithException;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.ArrayDeque;\n+import java.util.Deque;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.function.Consumer;\n+\n+import static org.apache.flink.runtime.state.ChannelPersistenceITCase.getStreamFactoryFactory;\n+import static org.apache.flink.util.ExceptionUtils.findThrowable;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * {@link ChannelStateWriterImpl} lifecycle tests.\n+ */\n+public class ChannelStateWriterImplTest {\n+\tprivate static final long CHECKPOINT_ID = 42L;\n+\n+\t@Test(expected = IllegalArgumentException.class)\n+\tpublic void testAddEventBuffer() {\n+\t\tNetworkBuffer dataBuf = getBuffer();\n+\t\tNetworkBuffer eventBuf = getBuffer();\n+\t\teventBuf.tagAsEvent();\n+\t\tChannelStateWriterImpl writer = openWriter();\n+\t\tcallStart(writer);\n+\t\ttry {\n+\t\t\twriter.addInputData(CHECKPOINT_ID, new InputChannelInfo(1, 1), 1, eventBuf, dataBuf);\n+\t\t} finally {\n+\t\t\tassertTrue(dataBuf.isRecycled());\n+\t\t}\n+\t}\n+\n+\t@Test\n+\tpublic void testResultCompletion() throws IOException {\n+\t\tChannelStateWriteResult result;\n+\t\ttry (ChannelStateWriterImpl writer = openWriter()) {\n+\t\t\tcallStart(writer);\n+\t\t\tresult = writer.getWriteResult(CHECKPOINT_ID);\n+\t\t\tassertFalse(result.resultSubpartitionStateHandles.isDone());\n+\t\t\tassertFalse(result.inputChannelStateHandles.isDone());\n+\t\t}\n+\t\tassertTrue(result.inputChannelStateHandles.isDone());\n+\t\tassertTrue(result.resultSubpartitionStateHandles.isDone());\n+\t}\n+\n+\t@Test\n+\tpublic void testAbort() throws Exception {\n+\t\tNetworkBuffer buffer = getBuffer();\n+\t\trunWithSyncWorker((writer, worker) -> {\n+\t\t\tcallStart(writer);\n+\t\t\tcallAddInputData(writer, buffer);\n+\t\t\tcallAbort(writer);\n+\t\t\tworker.processAllRequests();\n+\t\t\tassertTrue(writer.getWriteResult(CHECKPOINT_ID).isDone());\n+\t\t\tassertTrue(buffer.isRecycled());\n+\t\t});\n+\t}\n+\n+\t@Test\n+\tpublic void testAbortIgnoresMissing() throws Exception {\n+\t\trunWithSyncWorker(this::callAbort);\n+\t}\n+\n+\t@Test(expected = TestException.class)\n+\tpublic void testBuffersRecycledOnError() throws Exception {\n+\t\tunwrappingError(TestException.class, () -> {\n+\t\t\tNetworkBuffer buffer = getBuffer();\n+\t\t\ttry (ChannelStateWriterImpl writer = new ChannelStateWriterImpl(new ConcurrentHashMap<>(), failingWorker(), 5)) {\n+\t\t\t\twriter.open();\n+\t\t\t\tcallAddInputData(writer, buffer);\n+\t\t\t} finally {\n+\t\t\t\tassertTrue(buffer.isRecycled());\n+\t\t\t}\n+\t\t});\n+\t}\n+\n+\t@Test\n+\tpublic void testBuffersRecycledOnClose() throws IOException {\n+\t\tNetworkBuffer buffer = getBuffer();\n+\t\ttry (ChannelStateWriterImpl writer = openWriter()) {\n+\t\t\tcallStart(writer);\n+\t\t\tcallAddInputData(writer, buffer);\n+\t\t\tassertFalse(buffer.isRecycled());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 111}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjAxMDc5MQ==", "bodyText": "You're right, fixed it.", "url": "https://github.com/apache/flink/pull/11515#discussion_r406010791", "createdAt": "2020-04-09T07:33:59Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImplTest.java", "diffHunk": "@@ -0,0 +1,320 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.memory.HeapMemorySegment;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.util.function.BiConsumerWithException;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.ArrayDeque;\n+import java.util.Deque;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.function.Consumer;\n+\n+import static org.apache.flink.runtime.state.ChannelPersistenceITCase.getStreamFactoryFactory;\n+import static org.apache.flink.util.ExceptionUtils.findThrowable;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * {@link ChannelStateWriterImpl} lifecycle tests.\n+ */\n+public class ChannelStateWriterImplTest {\n+\tprivate static final long CHECKPOINT_ID = 42L;\n+\n+\t@Test(expected = IllegalArgumentException.class)\n+\tpublic void testAddEventBuffer() {\n+\t\tNetworkBuffer dataBuf = getBuffer();\n+\t\tNetworkBuffer eventBuf = getBuffer();\n+\t\teventBuf.tagAsEvent();\n+\t\tChannelStateWriterImpl writer = openWriter();\n+\t\tcallStart(writer);\n+\t\ttry {\n+\t\t\twriter.addInputData(CHECKPOINT_ID, new InputChannelInfo(1, 1), 1, eventBuf, dataBuf);\n+\t\t} finally {\n+\t\t\tassertTrue(dataBuf.isRecycled());\n+\t\t}\n+\t}\n+\n+\t@Test\n+\tpublic void testResultCompletion() throws IOException {\n+\t\tChannelStateWriteResult result;\n+\t\ttry (ChannelStateWriterImpl writer = openWriter()) {\n+\t\t\tcallStart(writer);\n+\t\t\tresult = writer.getWriteResult(CHECKPOINT_ID);\n+\t\t\tassertFalse(result.resultSubpartitionStateHandles.isDone());\n+\t\t\tassertFalse(result.inputChannelStateHandles.isDone());\n+\t\t}\n+\t\tassertTrue(result.inputChannelStateHandles.isDone());\n+\t\tassertTrue(result.resultSubpartitionStateHandles.isDone());\n+\t}\n+\n+\t@Test\n+\tpublic void testAbort() throws Exception {\n+\t\tNetworkBuffer buffer = getBuffer();\n+\t\trunWithSyncWorker((writer, worker) -> {\n+\t\t\tcallStart(writer);\n+\t\t\tcallAddInputData(writer, buffer);\n+\t\t\tcallAbort(writer);\n+\t\t\tworker.processAllRequests();\n+\t\t\tassertTrue(writer.getWriteResult(CHECKPOINT_ID).isDone());\n+\t\t\tassertTrue(buffer.isRecycled());\n+\t\t});\n+\t}\n+\n+\t@Test\n+\tpublic void testAbortIgnoresMissing() throws Exception {\n+\t\trunWithSyncWorker(this::callAbort);\n+\t}\n+\n+\t@Test(expected = TestException.class)\n+\tpublic void testBuffersRecycledOnError() throws Exception {\n+\t\tunwrappingError(TestException.class, () -> {\n+\t\t\tNetworkBuffer buffer = getBuffer();\n+\t\t\ttry (ChannelStateWriterImpl writer = new ChannelStateWriterImpl(new ConcurrentHashMap<>(), failingWorker(), 5)) {\n+\t\t\t\twriter.open();\n+\t\t\t\tcallAddInputData(writer, buffer);\n+\t\t\t} finally {\n+\t\t\t\tassertTrue(buffer.isRecycled());\n+\t\t\t}\n+\t\t});\n+\t}\n+\n+\t@Test\n+\tpublic void testBuffersRecycledOnClose() throws IOException {\n+\t\tNetworkBuffer buffer = getBuffer();\n+\t\ttry (ChannelStateWriterImpl writer = openWriter()) {\n+\t\t\tcallStart(writer);\n+\t\t\tcallAddInputData(writer, buffer);\n+\t\t\tassertFalse(buffer.isRecycled());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTYzNDY0Mg=="}, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 111}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxNzMxOTQ3OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/state/ChannelPersistenceITCase.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxNjoyODo0M1rOGC3NJQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxNjoyODo0M1rOGC3NJQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTY1NDgyMQ==", "bodyText": "unused method", "url": "https://github.com/apache/flink/pull/11515#discussion_r405654821", "createdAt": "2020-04-08T16:28:43Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/state/ChannelPersistenceITCase.java", "diffHunk": "@@ -0,0 +1,179 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.state;\n+\n+import org.apache.flink.core.memory.HeapMemorySegment;\n+import org.apache.flink.core.memory.MemorySegment;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.StateObjectCollection;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReaderImpl;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriterImpl;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.checkpoint.channel.ResultSubpartitionInfo;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.memory.NonPersistentMetadataCheckpointStorageLocation;\n+import org.apache.flink.util.function.BiFunctionWithException;\n+\n+import org.junit.Test;\n+\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.stream.Collectors;\n+\n+import static java.util.Collections.singletonMap;\n+import static org.apache.flink.runtime.checkpoint.CheckpointType.CHECKPOINT;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.SEQUENCE_NUMBER_UNKNOWN;\n+import static org.apache.flink.util.Preconditions.checkState;\n+import static org.junit.Assert.assertArrayEquals;\n+\n+/**\n+ * ChannelPersistenceITCase.\n+ */\n+public class ChannelPersistenceITCase {\n+\tprivate static final Random RANDOM = new Random(System.currentTimeMillis());\n+\n+\t@Test\n+\tpublic void testReadWritten() throws Exception {\n+\t\tlong checkpointId = 1L;\n+\n+\t\tInputChannelInfo inputChannelInfo = new InputChannelInfo(2, 3);\n+\t\tbyte[] inputChannelInfoData = randomBytes(1024);\n+\n+\t\tResultSubpartitionInfo resultSubpartitionInfo = new ResultSubpartitionInfo(4, 5);\n+\t\tbyte[] resultSubpartitionInfoData = randomBytes(1024);\n+\n+\t\tChannelStateWriteResult handles = write(\n+\t\t\tcheckpointId,\n+\t\t\tsingletonMap(inputChannelInfo, inputChannelInfoData),\n+\t\t\tsingletonMap(resultSubpartitionInfo, resultSubpartitionInfoData)\n+\t\t);\n+\n+\t\tassertArrayEquals(inputChannelInfoData, read(\n+\t\t\ttoTaskStateSnapshot(handles),\n+\t\t\tinputChannelInfoData.length,\n+\t\t\t(reader, mem) -> reader.readInputData(inputChannelInfo, new NetworkBuffer(mem, FreeingBufferRecycler.INSTANCE))\n+\t\t));\n+\n+\t\tassertArrayEquals(resultSubpartitionInfoData, read(\n+\t\t\ttoTaskStateSnapshot(handles),\n+\t\t\tresultSubpartitionInfoData.length,\n+\t\t\t(reader, mem) -> reader.readOutputData(resultSubpartitionInfo, new BufferBuilder(mem, FreeingBufferRecycler.INSTANCE))\n+\t\t));\n+\t}\n+\n+\tprivate byte[] randomBytes(int size) {\n+\t\tbyte[] bytes = new byte[size];\n+\t\tRANDOM.nextBytes(bytes);\n+\t\treturn bytes;\n+\t}\n+\n+\tprivate ChannelStateWriteResult write(long checkpointId, Map<InputChannelInfo, byte[]> icMap, Map<ResultSubpartitionInfo, byte[]> rsMap) throws Exception {\n+\t\tint maxStateSize = sizeOfBytes(icMap) + sizeOfBytes(rsMap) + Long.BYTES * 2;\n+\t\tMap<InputChannelInfo, Buffer> icBuffers = wrapWithBuffers(icMap);\n+\t\tMap<ResultSubpartitionInfo, Buffer> rsBuffers = wrapWithBuffers(rsMap);\n+\t\ttry (ChannelStateWriterImpl writer = new ChannelStateWriterImpl(getStreamFactoryFactory(maxStateSize))) {\n+\t\t\twriter.open();\n+\t\t\twriter.start(checkpointId, new CheckpointOptions(CHECKPOINT, new CheckpointStorageLocationReference(\"poly\".getBytes())));\n+\t\t\tfor (Map.Entry<InputChannelInfo, Buffer> e : icBuffers.entrySet()) {\n+\t\t\t\twriter.addInputData(checkpointId, e.getKey(), SEQUENCE_NUMBER_UNKNOWN, e.getValue());\n+\t\t\t}\n+\t\t\twriter.finishInput(checkpointId);\n+\t\t\tfor (Map.Entry<ResultSubpartitionInfo, Buffer> e : rsBuffers.entrySet()) {\n+\t\t\t\twriter.addOutputData(checkpointId, e.getKey(), SEQUENCE_NUMBER_UNKNOWN, e.getValue());\n+\t\t\t}\n+\t\t\twriter.finishOutput(checkpointId);\n+\t\t\tChannelStateWriteResult result = writer.getWriteResult(checkpointId);\n+\t\t\tresult.getResultSubpartitionStateHandles().join(); // prevent abnormal complete in close\n+\t\t\treturn result;\n+\t\t}\n+\t}\n+\n+\tpublic static CheckpointStorageWorkerView getStreamFactoryFactory() {\n+\t\treturn getStreamFactoryFactory(42);\n+\t}\n+\n+\tpublic static CheckpointStorageWorkerView getStreamFactoryFactory(int maxStateSize) {\n+\t\treturn new CheckpointStorageWorkerView() {\n+\t\t\t@Override\n+\t\t\tpublic CheckpointStreamFactory resolveCheckpointStorageLocation(long checkpointId, CheckpointStorageLocationReference reference) {\n+\t\t\t\treturn new NonPersistentMetadataCheckpointStorageLocation(maxStateSize);\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic CheckpointStreamFactory.CheckpointStateOutputStream createTaskOwnedStateStream() {\n+\t\t\t\tthrow new UnsupportedOperationException();\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tprivate byte[] read(TaskStateSnapshot taskStateSnapshot, int size, BiFunctionWithException<ChannelStateReader, MemorySegment, ReadResult, Exception> readFn) throws Exception {\n+\t\tbyte[] dst = new byte[size];\n+\t\tHeapMemorySegment mem = HeapMemorySegment.FACTORY.wrap(dst);\n+\t\ttry {\n+\t\t\tcheckState(NO_MORE_DATA == readFn.apply(new ChannelStateReaderImpl(taskStateSnapshot), mem));\n+\t\t} finally {\n+\t\t\tmem.free();\n+\t\t}\n+\t\treturn dst;\n+\t}\n+\n+\tprivate TaskStateSnapshot toTaskStateSnapshot(ChannelStateWriteResult t) throws Exception {\n+\t\treturn new TaskStateSnapshot(singletonMap(new OperatorID(),\n+\t\t\tnew OperatorSubtaskState(\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tnew StateObjectCollection<>(t.getInputChannelStateHandles().get()),\n+\t\t\t\tnew StateObjectCollection<>(t.getResultSubpartitionStateHandles().get())\n+\t\t\t)\n+\t\t));\n+\t}\n+\n+\tprivate <C> List<C> collect(Collection<StateObject> handles, Class<C> clazz) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 160}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ2OTg0OTM5OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RefCountingFSDataInputStream.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNlQwODo0NToyOFrOF78dyw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxNDoxOTowNlrOF-YH9A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODQwMDk3MQ==", "bodyText": "Could we avoid this class by binding the life-cycle of a FSDataInputStream to ChannelStateReaderImpl instead of ChannelStateStreamReader. Then only ChannelStateReader#close would close the input stream and we don't need to keep track.", "url": "https://github.com/apache/flink/pull/11515#discussion_r398400971", "createdAt": "2020-03-26T08:45:28Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RefCountingFSDataInputStream.java", "diffHunk": "@@ -0,0 +1,125 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.fs.FSDataInputStream;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.function.SupplierWithException;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+@NotThreadSafe\n+class RefCountingFSDataInputStream extends FSDataInputStream {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5f5ca2f608caeb6d87a0697aca5da75880a1b844"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTE0MTc3NA==", "bodyText": "Having FSDataInputStreams managed by ChannelStateReaderImpl is simpler but have these drawbacks:\n\nclients should coordinate their calls to close() (these are for or in and out channels); even if possible, I don't think it worth to couple them together\n(slight) increase of ChannelStateReaderImpl complexity", "url": "https://github.com/apache/flink/pull/11515#discussion_r399141774", "createdAt": "2020-03-27T09:40:51Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RefCountingFSDataInputStream.java", "diffHunk": "@@ -0,0 +1,125 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.fs.FSDataInputStream;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.function.SupplierWithException;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+@NotThreadSafe\n+class RefCountingFSDataInputStream extends FSDataInputStream {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODQwMDk3MQ=="}, "originalCommit": {"oid": "5f5ca2f608caeb6d87a0697aca5da75880a1b844"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk1MTI4NA==", "bodyText": "I'm also fine with either way. Just wanted to point out how we could avoid some code.", "url": "https://github.com/apache/flink/pull/11515#discussion_r400951284", "createdAt": "2020-03-31T14:19:06Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RefCountingFSDataInputStream.java", "diffHunk": "@@ -0,0 +1,125 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.fs.FSDataInputStream;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.function.SupplierWithException;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+@NotThreadSafe\n+class RefCountingFSDataInputStream extends FSDataInputStream {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODQwMDk3MQ=="}, "originalCommit": {"oid": "5f5ca2f608caeb6d87a0697aca5da75880a1b844"}, "originalPosition": 34}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ2OTg2MDkzOnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinator.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNlQwODo0ODo1M1rOF78lOw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQxMTozNTo0M1rOF9lhwQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODQwMjg3NQ==", "bodyText": "\ud83d\udc4d for pulling that out. Should it actually be TaskCheckpointCoordinator since it's bound to a StreamTask? Or do you consider StreamTask to be a misnomer that should be StreamSubtask (not proposing to change that, just want to understand the rational)?", "url": "https://github.com/apache/flink/pull/11515#discussion_r398402875", "createdAt": "2020-03-26T08:48:53Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinator.java", "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.tasks;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointMetaData;\n+import org.apache.flink.runtime.checkpoint.CheckpointMetrics;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+\n+import java.util.function.Supplier;\n+\n+/**\n+ * Coordinates checkpointing-related work for a task. Responsibilities:\n+ * <ol>\n+ * <li>build a snapshot (invokable)</li>\n+ * <li>report snapshot to the JobManager</li>\n+ * <li>maintain storage locations</li>\n+ * </ol>\n+ */\n+@Internal\n+interface SubtaskCheckpointCoordinator {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8f0c3d0c6c3fd55bf7b417c11de319b863fbe6c9"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTE0NzI2OQ==", "bodyText": "Yes, I think both Task and StreamTask are named inconsistently with higher-level terminology, where we have Tasks with their Subtasks.\nI'm not sure which should be changed though or which one should be used here :)\nThanks.", "url": "https://github.com/apache/flink/pull/11515#discussion_r399147269", "createdAt": "2020-03-27T09:50:25Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinator.java", "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.tasks;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointMetaData;\n+import org.apache.flink.runtime.checkpoint.CheckpointMetrics;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+\n+import java.util.function.Supplier;\n+\n+/**\n+ * Coordinates checkpointing-related work for a task. Responsibilities:\n+ * <ol>\n+ * <li>build a snapshot (invokable)</li>\n+ * <li>report snapshot to the JobManager</li>\n+ * <li>maintain storage locations</li>\n+ * </ol>\n+ */\n+@Internal\n+interface SubtaskCheckpointCoordinator {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODQwMjg3NQ=="}, "originalCommit": {"oid": "8f0c3d0c6c3fd55bf7b417c11de319b863fbe6c9"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDEyMjMwNQ==", "bodyText": "Okay makes sense. Maybe add comment/documentation that this corresponds to StreamTask?", "url": "https://github.com/apache/flink/pull/11515#discussion_r400122305", "createdAt": "2020-03-30T11:35:43Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinator.java", "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.tasks;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointMetaData;\n+import org.apache.flink.runtime.checkpoint.CheckpointMetrics;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+\n+import java.util.function.Supplier;\n+\n+/**\n+ * Coordinates checkpointing-related work for a task. Responsibilities:\n+ * <ol>\n+ * <li>build a snapshot (invokable)</li>\n+ * <li>report snapshot to the JobManager</li>\n+ * <li>maintain storage locations</li>\n+ * </ol>\n+ */\n+@Internal\n+interface SubtaskCheckpointCoordinator {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODQwMjg3NQ=="}, "originalCommit": {"oid": "8f0c3d0c6c3fd55bf7b417c11de319b863fbe6c9"}, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ2OTg5OTE2OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNlQwODo1OTowOFrOF789hA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQxMTozNzowOVrOF9lkvA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODQwOTA5Mg==", "bodyText": "Probably needs some reference counting here after splitting finish into finishInput and finishOutput.", "url": "https://github.com/apache/flink/pull/11515#discussion_r398409092", "createdAt": "2020-03-26T08:59:08Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,226 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.Future;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessHandoverLoop implements Runnable {\n+\t\tprivate final Map<Long, ChannelStateWriteTask> tasks = new HashMap<>(maxCheckpoints);\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\tcleanup(thrown);\n+\t\t\t}\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\tprocessItem(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\n+\t\tprivate void processItem(ChannelStateWriteItem item) throws Exception {\n+\t\t\tif (item instanceof StartCheckpointItem) {\n+\t\t\t\ttasks.put(item.checkpointId, new ChannelStateWriteTask((StartCheckpointItem) item, streamFactory, serializer)); // tasks is limited indirectly by results max size\n+\t\t\t} else if (item instanceof InputDataItem) {\n+\t\t\t\ttasks.get(item.checkpointId).write((InputDataItem) item);\n+\t\t\t} else if (item instanceof OutputDataItem) {\n+\t\t\t\ttasks.get(item.checkpointId).write((OutputDataItem) item);\n+\t\t\t} else if (item instanceof FinishInputCheckpointItem) {\n+\t\t\t\ttasks.get(item.checkpointId).completeInput(() -> tasks.remove(item.checkpointId));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5f5ca2f608caeb6d87a0697aca5da75880a1b844"}, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTE1MDI4MA==", "bodyText": "finishIn/Out split is handled by having inputCompleted and outputCompleted fields inside ChannelStateWriteTask.\nDo you think it's not enough and we need to add ref counters?", "url": "https://github.com/apache/flink/pull/11515#discussion_r399150280", "createdAt": "2020-03-27T09:55:44Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,226 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.Future;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessHandoverLoop implements Runnable {\n+\t\tprivate final Map<Long, ChannelStateWriteTask> tasks = new HashMap<>(maxCheckpoints);\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\tcleanup(thrown);\n+\t\t\t}\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\tprocessItem(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\n+\t\tprivate void processItem(ChannelStateWriteItem item) throws Exception {\n+\t\t\tif (item instanceof StartCheckpointItem) {\n+\t\t\t\ttasks.put(item.checkpointId, new ChannelStateWriteTask((StartCheckpointItem) item, streamFactory, serializer)); // tasks is limited indirectly by results max size\n+\t\t\t} else if (item instanceof InputDataItem) {\n+\t\t\t\ttasks.get(item.checkpointId).write((InputDataItem) item);\n+\t\t\t} else if (item instanceof OutputDataItem) {\n+\t\t\t\ttasks.get(item.checkpointId).write((OutputDataItem) item);\n+\t\t\t} else if (item instanceof FinishInputCheckpointItem) {\n+\t\t\t\ttasks.get(item.checkpointId).completeInput(() -> tasks.remove(item.checkpointId));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODQwOTA5Mg=="}, "originalCommit": {"oid": "5f5ca2f608caeb6d87a0697aca5da75880a1b844"}, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTMyMTUxOA==", "bodyText": "I meant that you are removing the task from tasks on the first of FinishInput/OutputItem and you probably will miss it if the other half is not finished.", "url": "https://github.com/apache/flink/pull/11515#discussion_r399321518", "createdAt": "2020-03-27T14:51:40Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,226 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.Future;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessHandoverLoop implements Runnable {\n+\t\tprivate final Map<Long, ChannelStateWriteTask> tasks = new HashMap<>(maxCheckpoints);\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\tcleanup(thrown);\n+\t\t\t}\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\tprocessItem(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\n+\t\tprivate void processItem(ChannelStateWriteItem item) throws Exception {\n+\t\t\tif (item instanceof StartCheckpointItem) {\n+\t\t\t\ttasks.put(item.checkpointId, new ChannelStateWriteTask((StartCheckpointItem) item, streamFactory, serializer)); // tasks is limited indirectly by results max size\n+\t\t\t} else if (item instanceof InputDataItem) {\n+\t\t\t\ttasks.get(item.checkpointId).write((InputDataItem) item);\n+\t\t\t} else if (item instanceof OutputDataItem) {\n+\t\t\t\ttasks.get(item.checkpointId).write((OutputDataItem) item);\n+\t\t\t} else if (item instanceof FinishInputCheckpointItem) {\n+\t\t\t\ttasks.get(item.checkpointId).completeInput(() -> tasks.remove(item.checkpointId));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODQwOTA5Mg=="}, "originalCommit": {"oid": "5f5ca2f608caeb6d87a0697aca5da75880a1b844"}, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTUzNTM1OQ==", "bodyText": "Got it. No, this is a runnable which is executed only when both input and output are finished.\nAs it confuses not only me :) I'll change it a bit:\n\nmake Runnable onComplete field in WriteTask (pass it to constructor)\ncompleteInput / Output won't have any arguments\n\nWDYT?", "url": "https://github.com/apache/flink/pull/11515#discussion_r399535359", "createdAt": "2020-03-27T21:00:28Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,226 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.Future;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessHandoverLoop implements Runnable {\n+\t\tprivate final Map<Long, ChannelStateWriteTask> tasks = new HashMap<>(maxCheckpoints);\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\tcleanup(thrown);\n+\t\t\t}\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\tprocessItem(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\n+\t\tprivate void processItem(ChannelStateWriteItem item) throws Exception {\n+\t\t\tif (item instanceof StartCheckpointItem) {\n+\t\t\t\ttasks.put(item.checkpointId, new ChannelStateWriteTask((StartCheckpointItem) item, streamFactory, serializer)); // tasks is limited indirectly by results max size\n+\t\t\t} else if (item instanceof InputDataItem) {\n+\t\t\t\ttasks.get(item.checkpointId).write((InputDataItem) item);\n+\t\t\t} else if (item instanceof OutputDataItem) {\n+\t\t\t\ttasks.get(item.checkpointId).write((OutputDataItem) item);\n+\t\t\t} else if (item instanceof FinishInputCheckpointItem) {\n+\t\t\t\ttasks.get(item.checkpointId).completeInput(() -> tasks.remove(item.checkpointId));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODQwOTA5Mg=="}, "originalCommit": {"oid": "5f5ca2f608caeb6d87a0697aca5da75880a1b844"}, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDEyMzA2OA==", "bodyText": "Sounds good to me.", "url": "https://github.com/apache/flink/pull/11515#discussion_r400123068", "createdAt": "2020-03-30T11:37:09Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,226 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.Future;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessHandoverLoop implements Runnable {\n+\t\tprivate final Map<Long, ChannelStateWriteTask> tasks = new HashMap<>(maxCheckpoints);\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\tcleanup(thrown);\n+\t\t\t}\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\tprocessItem(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\n+\t\tprivate void processItem(ChannelStateWriteItem item) throws Exception {\n+\t\t\tif (item instanceof StartCheckpointItem) {\n+\t\t\t\ttasks.put(item.checkpointId, new ChannelStateWriteTask((StartCheckpointItem) item, streamFactory, serializer)); // tasks is limited indirectly by results max size\n+\t\t\t} else if (item instanceof InputDataItem) {\n+\t\t\t\ttasks.get(item.checkpointId).write((InputDataItem) item);\n+\t\t\t} else if (item instanceof OutputDataItem) {\n+\t\t\t\ttasks.get(item.checkpointId).write((OutputDataItem) item);\n+\t\t\t} else if (item instanceof FinishInputCheckpointItem) {\n+\t\t\t\ttasks.get(item.checkpointId).completeInput(() -> tasks.remove(item.checkpointId));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODQwOTA5Mg=="}, "originalCommit": {"oid": "5f5ca2f608caeb6d87a0697aca5da75880a1b844"}, "originalPosition": 95}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4NjM3Njc2OnYy", "diffSide": "RIGHT", "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/over/BufferDataOverWindowOperatorTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxMzo1MjowOFrOF-W2Mw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxNjozOTowNFrOF_JKXQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDkzMDM1NQ==", "bodyText": "why is this line still necessary?", "url": "https://github.com/apache/flink/pull/11515#discussion_r400930355", "createdAt": "2020-03-31T13:52:08Z", "author": {"login": "AHeise"}, "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/over/BufferDataOverWindowOperatorTest.java", "diffHunk": "@@ -205,9 +206,19 @@ public StreamConfig getOperatorConfig() {\n \n \t\t\t@Override\n \t\t\tpublic StreamTask<?, ?> getContainingTask() {\n-\t\t\t\tStreamTask task = mock(StreamTask.class);\n+\t\t\t\tclass MockableStreamTask extends StreamTask<Object, StreamOperator<Object>> implements EnvironmentSupport {\n+\t\t\t\t\tMockableStreamTask() throws Exception {\n+\t\t\t\t\t\tsuper(new MockEnvironmentBuilder().build());\n+\t\t\t\t\t}\n+\n+\t\t\t\t\t@Override\n+\t\t\t\t\tprotected void init() {\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\n+\t\t\t\tStreamTask<?, ?> task = mock(MockableStreamTask.class);\n \t\t\t\tEnvironment env = mock(Environment.class);\n-\t\t\t\twhen(task.getEnvironment()).thenReturn(env);\n+\t\t\t\twhen(task.getEnvironment()).thenReturn(new MockEnvironmentBuilder().build());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "05c60654476141e8c0cb224d725cea99c85e7b15"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTc1NDcxNw==", "bodyText": "Removing mockito here (addressed the comment below).", "url": "https://github.com/apache/flink/pull/11515#discussion_r401754717", "createdAt": "2020-04-01T16:39:04Z", "author": {"login": "rkhachatryan"}, "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/over/BufferDataOverWindowOperatorTest.java", "diffHunk": "@@ -205,9 +206,19 @@ public StreamConfig getOperatorConfig() {\n \n \t\t\t@Override\n \t\t\tpublic StreamTask<?, ?> getContainingTask() {\n-\t\t\t\tStreamTask task = mock(StreamTask.class);\n+\t\t\t\tclass MockableStreamTask extends StreamTask<Object, StreamOperator<Object>> implements EnvironmentSupport {\n+\t\t\t\t\tMockableStreamTask() throws Exception {\n+\t\t\t\t\t\tsuper(new MockEnvironmentBuilder().build());\n+\t\t\t\t\t}\n+\n+\t\t\t\t\t@Override\n+\t\t\t\t\tprotected void init() {\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\n+\t\t\t\tStreamTask<?, ?> task = mock(MockableStreamTask.class);\n \t\t\t\tEnvironment env = mock(Environment.class);\n-\t\t\t\twhen(task.getEnvironment()).thenReturn(env);\n+\t\t\t\twhen(task.getEnvironment()).thenReturn(new MockEnvironmentBuilder().build());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDkzMDM1NQ=="}, "originalCommit": {"oid": "05c60654476141e8c0cb224d725cea99c85e7b15"}, "originalPosition": 36}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4NjM4MjYwOnYy", "diffSide": "RIGHT", "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/over/BufferDataOverWindowOperatorTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxMzo1MzoyMFrOF-W57Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxMzo1MzoyMFrOF-W57Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDkzMTMwOQ==", "bodyText": "Couldn't you just override the method on the MockableStreamTask to get rid of mockito?", "url": "https://github.com/apache/flink/pull/11515#discussion_r400931309", "createdAt": "2020-03-31T13:53:20Z", "author": {"login": "AHeise"}, "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/over/BufferDataOverWindowOperatorTest.java", "diffHunk": "@@ -205,9 +206,19 @@ public StreamConfig getOperatorConfig() {\n \n \t\t\t@Override\n \t\t\tpublic StreamTask<?, ?> getContainingTask() {\n-\t\t\t\tStreamTask task = mock(StreamTask.class);\n+\t\t\t\tclass MockableStreamTask extends StreamTask<Object, StreamOperator<Object>> implements EnvironmentSupport {\n+\t\t\t\t\tMockableStreamTask() throws Exception {\n+\t\t\t\t\t\tsuper(new MockEnvironmentBuilder().build());\n+\t\t\t\t\t}\n+\n+\t\t\t\t\t@Override\n+\t\t\t\t\tprotected void init() {\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\n+\t\t\t\tStreamTask<?, ?> task = mock(MockableStreamTask.class);\n \t\t\t\tEnvironment env = mock(Environment.class);\n-\t\t\t\twhen(task.getEnvironment()).thenReturn(env);\n+\t\t\t\twhen(task.getEnvironment()).thenReturn(new MockEnvironmentBuilder().build());\n \t\t\t\twhen(env.getMemoryManager()).thenReturn(memoryManager);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "05c60654476141e8c0cb224d725cea99c85e7b15"}, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4NjQwMDY1OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxMzo1Njo0N1rOF-XFDA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxMzo1Njo0N1rOF-XFDA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDkzNDE1Ng==", "bodyText": "nit: indent", "url": "https://github.com/apache/flink/pull/11515#discussion_r400934156", "createdAt": "2020-03-31T13:56:47Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.tasks;\n+\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.runtime.checkpoint.CheckpointMetaData;\n+import org.apache.flink.runtime.checkpoint.CheckpointMetrics;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.execution.Environment;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+\n+import java.util.concurrent.ExecutorService;\n+import java.util.function.Supplier;\n+\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+\n+class SubtaskCheckpointCoordinatorImpl implements SubtaskCheckpointCoordinator {\n+\tprivate final CheckpointStorageWorkerView checkpointStorage;\n+\tprivate final String taskName;\n+\tprivate final CloseableRegistry closeableRegistry;\n+\tprivate final ExecutorService executorService;\n+\tprivate final Environment env;\n+\tprivate final AsyncExceptionHandler asyncExceptionHandler;\n+\n+\tSubtaskCheckpointCoordinatorImpl(\n+\t\tCheckpointStorageWorkerView checkpointStorage,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3387596c1f3e4ed6e6cbeb586cefb59bc9f2e67"}, "originalPosition": 42}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4NjQwMzQ0OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxMzo1NzoyNFrOF-XG7w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxMzo1NzoyNFrOF-XG7w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDkzNDYzOQ==", "bodyText": "nit: indent", "url": "https://github.com/apache/flink/pull/11515#discussion_r400934639", "createdAt": "2020-03-31T13:57:24Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -89,17 +101,98 @@ public void checkpointState(\n \t\t\tcheckpointMetaData.getCheckpointId(),\n \t\t\tcheckpointOptions.getTargetLocation());\n \n-\t\tCheckpointingOperation.execute(\n-\t\t\tcheckpointMetaData,\n-\t\t\tcheckpointOptions,\n-\t\t\tcheckpointMetrics,\n-\t\t\tstorage,\n-\t\t\toperatorChain,\n-\t\t\ttaskName,\n-\t\t\tcloseableRegistry,\n-\t\t\texecutorService,\n-\t\t\tenv,\n-\t\t\tasyncExceptionHandler,\n-\t\t\tisCanceled);\n+\t\tlong startSyncPartNano = System.nanoTime();\n+\n+\t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress = new HashMap<>(operatorChain.getNumberOfOperators());\n+\t\ttry {\n+\t\t\tfor (StreamOperatorWrapper<?, ?> operatorWrapper : operatorChain.getAllOperators(true)) {\n+\t\t\t\tStreamOperator<?> op = operatorWrapper.getStreamOperator();\n+\t\t\t\tOperatorSnapshotFutures snapshotInProgress = checkpointStreamOperator(\n+\t\t\t\t\top,\n+\t\t\t\t\tcheckpointMetaData,\n+\t\t\t\t\tcheckpointOptions,\n+\t\t\t\t\tstorage,\n+\t\t\t\t\tisCanceled);\n+\t\t\t\toperatorSnapshotsInProgress.put(op.getOperatorID(), snapshotInProgress);\n+\t\t\t}\n+\n+\t\t\tif (LOG.isDebugEnabled()) {\n+\t\t\t\tLOG.debug(\"Finished synchronous checkpoints for checkpoint {} on task {}\",\n+\t\t\t\t\tcheckpointMetaData.getCheckpointId(), taskName);\n+\t\t\t}\n+\n+\t\t\tlong startAsyncPartNano = System.nanoTime();\n+\n+\t\t\tcheckpointMetrics.setSyncDurationMillis((startAsyncPartNano - startSyncPartNano) / 1_000_000);\n+\n+\t\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n+\t\t\texecutorService.execute(new AsyncCheckpointRunnable(\n+\t\t\t\toperatorSnapshotsInProgress,\n+\t\t\t\tcheckpointMetaData,\n+\t\t\t\tcheckpointMetrics,\n+\t\t\t\tstartAsyncPartNano,\n+\t\t\t\ttaskName,\n+\t\t\t\tcloseableRegistry,\n+\t\t\t\tenv,\n+\t\t\t\tasyncExceptionHandler));\n+\n+\t\t\tif (LOG.isDebugEnabled()) {\n+\t\t\t\tLOG.debug(\n+\t\t\t\t\t\"{} - finished synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n+\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n+\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n+\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n+\t\t\t}\n+\t\t} catch (Exception ex) {\n+\t\t\t// Cleanup to release resources\n+\t\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n+\t\t\t\tif (null != operatorSnapshotResult) {\n+\t\t\t\t\ttry {\n+\t\t\t\t\t\toperatorSnapshotResult.cancel();\n+\t\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\tif (LOG.isDebugEnabled()) {\n+\t\t\t\tLOG.debug(\n+\t\t\t\t\t\"{} - did NOT finish synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n+\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n+\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n+\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n+\t\t\t}\n+\n+\t\t\tif (checkpointOptions.getCheckpointType().isSynchronous()) {\n+\t\t\t\t// in the case of a synchronous checkpoint, we always rethrow the exception,\n+\t\t\t\t// so that the task fails.\n+\t\t\t\t// this is because the intention is always to stop the job after this checkpointing\n+\t\t\t\t// operation, and without the failure, the task would go back to normal execution.\n+\t\t\t\tthrow ex;\n+\t\t\t} else {\n+\t\t\t\tenv.declineCheckpoint(checkpointMetaData.getCheckpointId(), ex);\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate static OperatorSnapshotFutures checkpointStreamOperator(\n+\t\tStreamOperator<?> op,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ae7bd9f04b94f8c4810b3321df7729b11affeee4"}, "originalPosition": 126}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4NjQwNzU3OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateCheckpointWriter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxMzo1ODoxOVrOF-XJvQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxMzo1ODoxOVrOF-XJvQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDkzNTM1Nw==", "bodyText": "nit: indent", "url": "https://github.com/apache/flink/pull/11515#discussion_r400935357", "createdAt": "2020-03-31T13:58:19Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateCheckpointWriter.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory.CheckpointStateOutputStream;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.runtime.state.ResultSubpartitionStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.BiFunction;\n+\n+import static org.apache.flink.runtime.state.CheckpointedStateScope.EXCLUSIVE;\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+\n+/**\n+ * Writes channel state for a specific checkpoint-subtask-attempt triple.\n+ */\n+@NotThreadSafe\n+class ChannelStateCheckpointWriter {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateCheckpointWriter.class);\n+\n+\tprivate final DataOutputStream dataStream;\n+\tprivate final CheckpointStateOutputStream checkpointStream;\n+\tprivate final ChannelStateWriteResult result;\n+\tprivate final Map<InputChannelInfo, List<Long>> inputChannelOffsets = new HashMap<>();\n+\tprivate final Map<ResultSubpartitionInfo, List<Long>> resultSubpartitionOffsets = new HashMap<>();\n+\tprivate final ChannelStateSerializer serializer;\n+\tprivate final long checkpointId;\n+\tprivate boolean inputCompleted = false;\n+\tprivate boolean outputCompleted = false;\n+\tprivate final Runnable onComplete;\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tCheckpointStartRequest startCheckpointItem,\n+\t\t\tCheckpointStreamFactory streamFactory,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete) throws Exception {\n+\t\tthis(startCheckpointItem.checkpointId, startCheckpointItem.targetResult, streamFactory.createCheckpointStateOutputStream(EXCLUSIVE), serializer, onComplete);\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tCheckpointStateOutputStream stream,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete) throws Exception {\n+\t\tthis(checkpointId, result, serializer, onComplete, stream, new DataOutputStream(stream));\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete,\n+\t\t\tCheckpointStateOutputStream checkpointStateOutputStream,\n+\t\t\tDataOutputStream dataStream) throws Exception {\n+\t\tthis.checkpointId = checkpointId;\n+\t\tthis.result = checkNotNull(result);\n+\t\tthis.checkpointStream = checkNotNull(checkpointStateOutputStream);\n+\t\tthis.serializer = checkNotNull(serializer);\n+\t\tthis.dataStream = checkNotNull(dataStream);\n+\t\tthis.onComplete = checkNotNull(onComplete);\n+\t\trunWithChecks(() -> serializer.writeHeader(dataStream));\n+\t}\n+\n+\tvoid writeInput(InputChannelInfo info, Buffer... flinkBuffers) throws Exception {\n+\t\tPreconditions.checkState(!inputCompleted);\n+\t\twrite(inputChannelOffsets, info, flinkBuffers);\n+\t}\n+\n+\tvoid writeOutput(ResultSubpartitionInfo info, Buffer[] flinkBuffers) throws Exception {\n+\t\tPreconditions.checkState(!outputCompleted);\n+\t\twrite(resultSubpartitionOffsets, info, flinkBuffers);\n+\t}\n+\n+\tprivate <K> void write(Map<K, List<Long>> offsets, K key, Buffer[] flinkBuffers) throws Exception {\n+\t\trunWithChecks(() -> {\n+\t\t\ttry {\n+\t\t\t\toffsets\n+\t\t\t\t\t.computeIfAbsent(key, unused -> new ArrayList<>())\n+\t\t\t\t\t.add(checkpointStream.getPos());\n+\t\t\t\tserializer.writeData(dataStream, flinkBuffers);\n+\t\t\t} finally {\n+\t\t\t\tfor (Buffer flinkBuffer : flinkBuffers) {\n+\t\t\t\t\tflinkBuffer.recycleBuffer();\n+\t\t\t\t}\n+\t\t\t}\n+\t\t});\n+\t}\n+\n+\tvoid completeInput() throws Exception {\n+\t\tLOG.debug(\"complete input, output completed: {}\", outputCompleted);\n+\t\trunWithChecks(() -> {\n+\t\t\tPreconditions.checkState(!inputCompleted);\n+\t\t\tinputCompleted = true;\n+\t\t\tcomplete();\n+\t\t});\n+\t}\n+\n+\tvoid completeOutput() throws Exception {\n+\t\tLOG.debug(\"complete output, input completed: {}\", inputCompleted);\n+\t\trunWithChecks(() -> {\n+\t\t\tPreconditions.checkState(!outputCompleted);\n+\t\t\toutputCompleted = true;\n+\t\t\tcomplete();\n+\t\t});\n+\t}\n+\n+\tprivate void complete() throws IOException {\n+\t\tif (inputCompleted && outputCompleted) {\n+\t\t\tonComplete.run();\n+\t\t\tdataStream.flush();\n+\t\t\tStreamStateHandle underlying = checkpointStream.closeAndGetHandle();\n+\t\t\tcomplete(\n+\t\t\t\tresult.inputChannelStateHandles,\n+\t\t\t\tinputChannelOffsets,\n+\t\t\t\t(chan, offsets) -> new InputChannelStateHandle(chan, underlying, offsets));\n+\t\t\tcomplete(\n+\t\t\t\tresult.resultSubpartitionStateHandles,\n+\t\t\t\tresultSubpartitionOffsets,\n+\t\t\t\t(chan, offsets) -> new ResultSubpartitionStateHandle(chan, underlying, offsets));\n+\t\t}\n+\t}\n+\n+\tprivate <I, H extends AbstractChannelStateHandle<I>> void complete(\n+\t\tCompletableFuture<Collection<H>> future,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 160}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4NjQzMTkxOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxNDowMzozN1rOF-XZSg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wM1QwODo0NTo1M1rOGALvEQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDkzOTMzOA==", "bodyText": "Is that method used in later commits? Seems unused except in the implementor.", "url": "https://github.com/apache/flink/pull/11515#discussion_r400939338", "createdAt": "2020-03-31T14:03:37Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\tTuple2<Integer, Integer> readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\tint writableBytes();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTc2MTMwNw==", "bodyText": "Yes, it is used, in the same commit (probably, I've reordered changes in the last update).", "url": "https://github.com/apache/flink/pull/11515#discussion_r401761307", "createdAt": "2020-04-01T16:49:33Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\tTuple2<Integer, Integer> readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\tint writableBytes();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDkzOTMzOA=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQwMDgyNA==", "bodyText": "I guess we can remove this explicit method actually, because it is only used inside `#wrap() method and would not be called by outsides.  See dad865f#r402400614", "url": "https://github.com/apache/flink/pull/11515#discussion_r402400824", "createdAt": "2020-04-02T15:23:51Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\tTuple2<Integer, Integer> readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\tint writableBytes();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDkzOTMzOA=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjg0NTQ1Nw==", "bodyText": "Removed it, thanks.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402845457", "createdAt": "2020-04-03T08:45:53Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\tTuple2<Integer, Integer> readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\tint writableBytes();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDkzOTMzOA=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 68}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4NjQ2MzE1OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxNDoxMDoxMFrOF-Xs8A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxNjo1NDo0OVrOF_JyMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk0NDM2OA==", "bodyText": "looks okay. anything particular to check?", "url": "https://github.com/apache/flink/pull/11515#discussion_r400944368", "createdAt": "2020-03-31T14:10:10Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\tTuple2<Integer, Integer> readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\tint writableBytes();\n+\n+\tint writeBytes(InputStream input, int bytesToRead) throws IOException;\n+\n+\tstatic ChannelStateByteBuffer wrap(Buffer buffer) {\n+\t\treturn new ChannelStateByteBuffer() {\n+\n+\t\t\tprivate ByteBuf byteBuf = buffer.asByteBuf();\n+\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn byteBuf.isWritable();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn byteBuf.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\treturn byteBuf.writeBytes(input, Math.min(bytesToRead, byteBuf.writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(BufferBuilder bufferBuilder) {\n+\t\tfinal byte[] buf = new byte[1024];\n+\t\treturn new ChannelStateByteBuffer() {\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn !bufferBuilder.isFull();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn bufferBuilder.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int upToBytes) throws IOException {\n+\t\t\t\tint left = upToBytes;\n+\t\t\t\tfor (int toRead = getToRead(left); toRead > 0; toRead = getToRead(left)) {\n+\t\t\t\t\tint read = input.read(buf, 0, toRead);\n+\t\t\t\t\tint copied = bufferBuilder.append(java.nio.ByteBuffer.wrap(buf, 0, read));\n+\t\t\t\t\tPreconditions.checkState(copied == read);\n+\t\t\t\t\tleft -= read;\n+\t\t\t\t}\n+\t\t\t\tbufferBuilder.commit();\n+\t\t\t\treturn upToBytes - left;\n+\t\t\t}\n+\n+\t\t\tprivate int getToRead(int bytesToRead) {\n+\t\t\t\treturn min(bytesToRead, min(buf.length, writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(byte[] bytes) {\n+\t\tint written = 0;\n+\t\treturn new ChannelStateByteBuffer() {\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn written < bytes.length;\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn bytes.length - written;\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\treturn input.read(bytes, written, writableBytes());\n+\t\t\t}\n+\t\t};\n+\t}\n+}\n+\n+class ChannelStateSerializerImpl implements ChannelStateSerializer, ChannelStateDeserializer {\n+\tprivate static final int LEN_SIZE = Integer.BYTES;\n+\tprivate static final int SERIALIZATION_VERSION = 0;\n+\n+\t@Override\n+\tpublic void writeHeader(DataOutputStream dataStream) throws IOException {\n+\t\tdataStream.writeInt(SERIALIZATION_VERSION);\n+\t}\n+\n+\t@Override\n+\tpublic void writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException {\n+\t\tstream.writeInt(getSize(flinkBuffers));\n+\t\tfor (Buffer buffer : flinkBuffers) {\n+\t\t\tByteBuf nettyByteBuf = buffer.asByteBuf();\n+\t\t\tnettyByteBuf.getBytes(nettyByteBuf.readerIndex(), stream, nettyByteBuf.readableBytes()); // todo: review me", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 161}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTc2NDkxMw==", "bodyText": "I wanted to make sure that it's not required to update reader index here.", "url": "https://github.com/apache/flink/pull/11515#discussion_r401764913", "createdAt": "2020-04-01T16:54:49Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\tTuple2<Integer, Integer> readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\tint writableBytes();\n+\n+\tint writeBytes(InputStream input, int bytesToRead) throws IOException;\n+\n+\tstatic ChannelStateByteBuffer wrap(Buffer buffer) {\n+\t\treturn new ChannelStateByteBuffer() {\n+\n+\t\t\tprivate ByteBuf byteBuf = buffer.asByteBuf();\n+\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn byteBuf.isWritable();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn byteBuf.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\treturn byteBuf.writeBytes(input, Math.min(bytesToRead, byteBuf.writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(BufferBuilder bufferBuilder) {\n+\t\tfinal byte[] buf = new byte[1024];\n+\t\treturn new ChannelStateByteBuffer() {\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn !bufferBuilder.isFull();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn bufferBuilder.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int upToBytes) throws IOException {\n+\t\t\t\tint left = upToBytes;\n+\t\t\t\tfor (int toRead = getToRead(left); toRead > 0; toRead = getToRead(left)) {\n+\t\t\t\t\tint read = input.read(buf, 0, toRead);\n+\t\t\t\t\tint copied = bufferBuilder.append(java.nio.ByteBuffer.wrap(buf, 0, read));\n+\t\t\t\t\tPreconditions.checkState(copied == read);\n+\t\t\t\t\tleft -= read;\n+\t\t\t\t}\n+\t\t\t\tbufferBuilder.commit();\n+\t\t\t\treturn upToBytes - left;\n+\t\t\t}\n+\n+\t\t\tprivate int getToRead(int bytesToRead) {\n+\t\t\t\treturn min(bytesToRead, min(buf.length, writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(byte[] bytes) {\n+\t\tint written = 0;\n+\t\treturn new ChannelStateByteBuffer() {\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn written < bytes.length;\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn bytes.length - written;\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\treturn input.read(bytes, written, writableBytes());\n+\t\t\t}\n+\t\t};\n+\t}\n+}\n+\n+class ChannelStateSerializerImpl implements ChannelStateSerializer, ChannelStateDeserializer {\n+\tprivate static final int LEN_SIZE = Integer.BYTES;\n+\tprivate static final int SERIALIZATION_VERSION = 0;\n+\n+\t@Override\n+\tpublic void writeHeader(DataOutputStream dataStream) throws IOException {\n+\t\tdataStream.writeInt(SERIALIZATION_VERSION);\n+\t}\n+\n+\t@Override\n+\tpublic void writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException {\n+\t\tstream.writeInt(getSize(flinkBuffers));\n+\t\tfor (Buffer buffer : flinkBuffers) {\n+\t\t\tByteBuf nettyByteBuf = buffer.asByteBuf();\n+\t\t\tnettyByteBuf.getBytes(nettyByteBuf.readerIndex(), stream, nettyByteBuf.readableBytes()); // todo: review me", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk0NDM2OA=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 161}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4NjQ3MTk2OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxNDoxMjoxMFrOF-XylA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wM1QxMDoxNzoxNFrOGAPVsg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk0NTgxMg==", "bodyText": "Could we avoid creating the DIS adhoc? You need to read header anyways, so why not always create a DIS and pass it everywhere?", "url": "https://github.com/apache/flink/pull/11515#discussion_r400945812", "createdAt": "2020-03-31T14:12:10Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\tTuple2<Integer, Integer> readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\tint writableBytes();\n+\n+\tint writeBytes(InputStream input, int bytesToRead) throws IOException;\n+\n+\tstatic ChannelStateByteBuffer wrap(Buffer buffer) {\n+\t\treturn new ChannelStateByteBuffer() {\n+\n+\t\t\tprivate ByteBuf byteBuf = buffer.asByteBuf();\n+\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn byteBuf.isWritable();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn byteBuf.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\treturn byteBuf.writeBytes(input, Math.min(bytesToRead, byteBuf.writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(BufferBuilder bufferBuilder) {\n+\t\tfinal byte[] buf = new byte[1024];\n+\t\treturn new ChannelStateByteBuffer() {\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn !bufferBuilder.isFull();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn bufferBuilder.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int upToBytes) throws IOException {\n+\t\t\t\tint left = upToBytes;\n+\t\t\t\tfor (int toRead = getToRead(left); toRead > 0; toRead = getToRead(left)) {\n+\t\t\t\t\tint read = input.read(buf, 0, toRead);\n+\t\t\t\t\tint copied = bufferBuilder.append(java.nio.ByteBuffer.wrap(buf, 0, read));\n+\t\t\t\t\tPreconditions.checkState(copied == read);\n+\t\t\t\t\tleft -= read;\n+\t\t\t\t}\n+\t\t\t\tbufferBuilder.commit();\n+\t\t\t\treturn upToBytes - left;\n+\t\t\t}\n+\n+\t\t\tprivate int getToRead(int bytesToRead) {\n+\t\t\t\treturn min(bytesToRead, min(buf.length, writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(byte[] bytes) {\n+\t\tint written = 0;\n+\t\treturn new ChannelStateByteBuffer() {\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn written < bytes.length;\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn bytes.length - written;\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\treturn input.read(bytes, written, writableBytes());\n+\t\t\t}\n+\t\t};\n+\t}\n+}\n+\n+class ChannelStateSerializerImpl implements ChannelStateSerializer, ChannelStateDeserializer {\n+\tprivate static final int LEN_SIZE = Integer.BYTES;\n+\tprivate static final int SERIALIZATION_VERSION = 0;\n+\n+\t@Override\n+\tpublic void writeHeader(DataOutputStream dataStream) throws IOException {\n+\t\tdataStream.writeInt(SERIALIZATION_VERSION);\n+\t}\n+\n+\t@Override\n+\tpublic void writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException {\n+\t\tstream.writeInt(getSize(flinkBuffers));\n+\t\tfor (Buffer buffer : flinkBuffers) {\n+\t\t\tByteBuf nettyByteBuf = buffer.asByteBuf();\n+\t\t\tnettyByteBuf.getBytes(nettyByteBuf.readerIndex(), stream, nettyByteBuf.readableBytes()); // todo: review me\n+\t\t}\n+\t}\n+\n+\tprivate int getSize(Buffer[] buffers) {\n+\t\tint len = 0;\n+\t\tfor (Buffer buffer : buffers) {\n+\t\t\tlen = addExact(len, buffer.readableBytes());\n+\t\t}\n+\t\treturn len;\n+\t}\n+\n+\t@Override\n+\tpublic void readHeader(InputStream stream) throws IOException {\n+\t\tint version = readInt(stream);\n+\t\tPreconditions.checkArgument(version == SERIALIZATION_VERSION, \"unsupported version: \" + version);\n+\t}\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\t@Override\n+\tpublic Tuple2<Integer, Integer> readLength(InputStream stream) throws IOException {\n+\t\tint len = readInt(stream);\n+\t\tPreconditions.checkArgument(len >= 0, \"negative state size\");\n+\t\treturn Tuple2.of(len, LEN_SIZE);\n+\t}\n+\n+\t@Override\n+\tpublic int readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException {\n+\t\treturn buffer.writeBytes(stream, bytes);\n+\t}\n+\n+\tprivate static int readInt(InputStream stream) throws IOException {\n+\t\treturn new DataInputStream(stream).readInt();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 197}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTc3Mjg1NQ==", "bodyText": "It's doesn't do anything except creating this object and this object doesn't escape the method. So I don't think there is any performance issue here (given this is IO on recovery).\nAlternatively, I'd just replicate DataInputStream.readInt logic.\nI'd like to avoid an extra field just to get readInt method.\nWDYT?", "url": "https://github.com/apache/flink/pull/11515#discussion_r401772855", "createdAt": "2020-04-01T17:06:47Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\tTuple2<Integer, Integer> readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\tint writableBytes();\n+\n+\tint writeBytes(InputStream input, int bytesToRead) throws IOException;\n+\n+\tstatic ChannelStateByteBuffer wrap(Buffer buffer) {\n+\t\treturn new ChannelStateByteBuffer() {\n+\n+\t\t\tprivate ByteBuf byteBuf = buffer.asByteBuf();\n+\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn byteBuf.isWritable();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn byteBuf.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\treturn byteBuf.writeBytes(input, Math.min(bytesToRead, byteBuf.writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(BufferBuilder bufferBuilder) {\n+\t\tfinal byte[] buf = new byte[1024];\n+\t\treturn new ChannelStateByteBuffer() {\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn !bufferBuilder.isFull();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn bufferBuilder.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int upToBytes) throws IOException {\n+\t\t\t\tint left = upToBytes;\n+\t\t\t\tfor (int toRead = getToRead(left); toRead > 0; toRead = getToRead(left)) {\n+\t\t\t\t\tint read = input.read(buf, 0, toRead);\n+\t\t\t\t\tint copied = bufferBuilder.append(java.nio.ByteBuffer.wrap(buf, 0, read));\n+\t\t\t\t\tPreconditions.checkState(copied == read);\n+\t\t\t\t\tleft -= read;\n+\t\t\t\t}\n+\t\t\t\tbufferBuilder.commit();\n+\t\t\t\treturn upToBytes - left;\n+\t\t\t}\n+\n+\t\t\tprivate int getToRead(int bytesToRead) {\n+\t\t\t\treturn min(bytesToRead, min(buf.length, writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(byte[] bytes) {\n+\t\tint written = 0;\n+\t\treturn new ChannelStateByteBuffer() {\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn written < bytes.length;\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn bytes.length - written;\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\treturn input.read(bytes, written, writableBytes());\n+\t\t\t}\n+\t\t};\n+\t}\n+}\n+\n+class ChannelStateSerializerImpl implements ChannelStateSerializer, ChannelStateDeserializer {\n+\tprivate static final int LEN_SIZE = Integer.BYTES;\n+\tprivate static final int SERIALIZATION_VERSION = 0;\n+\n+\t@Override\n+\tpublic void writeHeader(DataOutputStream dataStream) throws IOException {\n+\t\tdataStream.writeInt(SERIALIZATION_VERSION);\n+\t}\n+\n+\t@Override\n+\tpublic void writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException {\n+\t\tstream.writeInt(getSize(flinkBuffers));\n+\t\tfor (Buffer buffer : flinkBuffers) {\n+\t\t\tByteBuf nettyByteBuf = buffer.asByteBuf();\n+\t\t\tnettyByteBuf.getBytes(nettyByteBuf.readerIndex(), stream, nettyByteBuf.readableBytes()); // todo: review me\n+\t\t}\n+\t}\n+\n+\tprivate int getSize(Buffer[] buffers) {\n+\t\tint len = 0;\n+\t\tfor (Buffer buffer : buffers) {\n+\t\t\tlen = addExact(len, buffer.readableBytes());\n+\t\t}\n+\t\treturn len;\n+\t}\n+\n+\t@Override\n+\tpublic void readHeader(InputStream stream) throws IOException {\n+\t\tint version = readInt(stream);\n+\t\tPreconditions.checkArgument(version == SERIALIZATION_VERSION, \"unsupported version: \" + version);\n+\t}\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\t@Override\n+\tpublic Tuple2<Integer, Integer> readLength(InputStream stream) throws IOException {\n+\t\tint len = readInt(stream);\n+\t\tPreconditions.checkArgument(len >= 0, \"negative state size\");\n+\t\treturn Tuple2.of(len, LEN_SIZE);\n+\t}\n+\n+\t@Override\n+\tpublic int readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException {\n+\t\treturn buffer.writeBytes(stream, bytes);\n+\t}\n+\n+\tprivate static int readInt(InputStream stream) throws IOException {\n+\t\treturn new DataInputStream(stream).readInt();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk0NTgxMg=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 197}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjkwNDQ5OA==", "bodyText": "I was more thinking to always wrap InputStream in DIS and change the signatures accordingly. Then it would be the same number of fields.\nIf that is not doable, then please leave as is, don't have a custom readInt.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402904498", "createdAt": "2020-04-03T10:17:14Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\tTuple2<Integer, Integer> readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\tint writableBytes();\n+\n+\tint writeBytes(InputStream input, int bytesToRead) throws IOException;\n+\n+\tstatic ChannelStateByteBuffer wrap(Buffer buffer) {\n+\t\treturn new ChannelStateByteBuffer() {\n+\n+\t\t\tprivate ByteBuf byteBuf = buffer.asByteBuf();\n+\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn byteBuf.isWritable();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn byteBuf.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\treturn byteBuf.writeBytes(input, Math.min(bytesToRead, byteBuf.writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(BufferBuilder bufferBuilder) {\n+\t\tfinal byte[] buf = new byte[1024];\n+\t\treturn new ChannelStateByteBuffer() {\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn !bufferBuilder.isFull();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn bufferBuilder.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int upToBytes) throws IOException {\n+\t\t\t\tint left = upToBytes;\n+\t\t\t\tfor (int toRead = getToRead(left); toRead > 0; toRead = getToRead(left)) {\n+\t\t\t\t\tint read = input.read(buf, 0, toRead);\n+\t\t\t\t\tint copied = bufferBuilder.append(java.nio.ByteBuffer.wrap(buf, 0, read));\n+\t\t\t\t\tPreconditions.checkState(copied == read);\n+\t\t\t\t\tleft -= read;\n+\t\t\t\t}\n+\t\t\t\tbufferBuilder.commit();\n+\t\t\t\treturn upToBytes - left;\n+\t\t\t}\n+\n+\t\t\tprivate int getToRead(int bytesToRead) {\n+\t\t\t\treturn min(bytesToRead, min(buf.length, writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(byte[] bytes) {\n+\t\tint written = 0;\n+\t\treturn new ChannelStateByteBuffer() {\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn written < bytes.length;\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn bytes.length - written;\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\treturn input.read(bytes, written, writableBytes());\n+\t\t\t}\n+\t\t};\n+\t}\n+}\n+\n+class ChannelStateSerializerImpl implements ChannelStateSerializer, ChannelStateDeserializer {\n+\tprivate static final int LEN_SIZE = Integer.BYTES;\n+\tprivate static final int SERIALIZATION_VERSION = 0;\n+\n+\t@Override\n+\tpublic void writeHeader(DataOutputStream dataStream) throws IOException {\n+\t\tdataStream.writeInt(SERIALIZATION_VERSION);\n+\t}\n+\n+\t@Override\n+\tpublic void writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException {\n+\t\tstream.writeInt(getSize(flinkBuffers));\n+\t\tfor (Buffer buffer : flinkBuffers) {\n+\t\t\tByteBuf nettyByteBuf = buffer.asByteBuf();\n+\t\t\tnettyByteBuf.getBytes(nettyByteBuf.readerIndex(), stream, nettyByteBuf.readableBytes()); // todo: review me\n+\t\t}\n+\t}\n+\n+\tprivate int getSize(Buffer[] buffers) {\n+\t\tint len = 0;\n+\t\tfor (Buffer buffer : buffers) {\n+\t\t\tlen = addExact(len, buffer.readableBytes());\n+\t\t}\n+\t\treturn len;\n+\t}\n+\n+\t@Override\n+\tpublic void readHeader(InputStream stream) throws IOException {\n+\t\tint version = readInt(stream);\n+\t\tPreconditions.checkArgument(version == SERIALIZATION_VERSION, \"unsupported version: \" + version);\n+\t}\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\t@Override\n+\tpublic Tuple2<Integer, Integer> readLength(InputStream stream) throws IOException {\n+\t\tint len = readInt(stream);\n+\t\tPreconditions.checkArgument(len >= 0, \"negative state size\");\n+\t\treturn Tuple2.of(len, LEN_SIZE);\n+\t}\n+\n+\t@Override\n+\tpublic int readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException {\n+\t\treturn buffer.writeBytes(stream, bytes);\n+\t}\n+\n+\tprivate static int readInt(InputStream stream) throws IOException {\n+\t\treturn new DataInputStream(stream).readInt();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk0NTgxMg=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 197}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4NjQ3ODgxOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateStreamReader.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxNDoxMzozNFrOF-X24w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxNDoxMzozNFrOF-X24w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk0NjkxNQ==", "bodyText": "Not a big fan of leaving inspection settings in code. If everyone does it with different IDEs/settings, it will become quickly a mess.", "url": "https://github.com/apache/flink/pull/11515#discussion_r400946915", "createdAt": "2020-03-31T14:13:34Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateStreamReader.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+\n+import static java.lang.Math.addExact;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateByteBuffer.wrap;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.HAS_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+\n+/**\n+ * Reads the state of a single channel pointed by {@link org.apache.flink.runtime.state.AbstractChannelStateHandle AbstractChannelStateHandle}.\n+ * Single-use.\n+ * Uses {@link RefCountingFSDataInputStream} internally.\n+ */\n+@NotThreadSafe\n+class ChannelStateStreamReader implements Closeable {\n+\n+\tprivate final RefCountingFSDataInputStream stream; // todo: buffer?\n+\tprivate final Queue<Long> offsets;\n+\tprivate final ChannelStateDeserializer serializer;\n+\tprivate long pos = -1;\n+\tprivate int rem;\n+\tprivate boolean closed = false;\n+\n+\tChannelStateStreamReader(AbstractChannelStateHandle<?> handle, RefCountingFSDataInputStreamFactory streamFactory) {\n+\t\tthis(streamFactory.forHandle(handle), handle.getOffsets(), streamFactory.getSerializer());\n+\t}\n+\n+\tprivate ChannelStateStreamReader(RefCountingFSDataInputStream stream, List<Long> offsets, ChannelStateDeserializer serializer) {\n+\t\tthis.stream = stream;\n+\t\tthis.stream.incNumReaders();\n+\t\tthis.serializer = serializer;\n+\t\tthis.offsets = new LinkedList<>(offsets);\n+\t}\n+\n+\tReadResult readInto(Buffer buffer) throws IOException {\n+\t\treturn readInto(wrap(buffer));\n+\t}\n+\n+\tReadResult readInto(BufferBuilder bufferBuilder) throws IOException {\n+\t\treturn readInto(wrap(bufferBuilder));\n+\t}\n+\n+\tprivate ReadResult readInto(ChannelStateByteBuffer buffer) throws IOException {\n+\t\tPreconditions.checkState(!closed, \"reader is closed\");\n+\t\treadWhilePossible(buffer);\n+\t\tif (haveMoreData()) {\n+\t\t\treturn HAS_MORE_DATA;\n+\t\t} else {\n+\t\t\tclose();\n+\t\t\treturn NO_MORE_DATA;\n+\t\t}\n+\t}\n+\n+\tprivate void readWhilePossible(ChannelStateByteBuffer buffer) throws IOException {\n+\t\twhile (haveMoreData() && buffer.isWritable()) {\n+\t\t\tif (pos < 0 || rem <= 0) {\n+\t\t\t\tadvanceOffset();\n+\t\t\t}\n+\t\t\tint bytesRead = serializer.readData(stream, buffer, rem);\n+\t\t\trem -= bytesRead;\n+\t\t\tpos = addExact(pos, bytesRead);\n+\t\t}\n+\t}\n+\n+\tprivate boolean haveMoreData() {\n+\t\treturn rem > 0 || !offsets.isEmpty();\n+\t}\n+\n+\tprivate void advanceOffset() throws IOException {\n+\t\t//noinspection ConstantConditions", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 102}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4NjQ4NzM0OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxNDoxNToyNVrOF-X8bw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxNDoxNToyNVrOF-X8bw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk0ODMzNQ==", "bodyText": "Add a factory for start for symmetry? Or move the factories to InProgress?", "url": "https://github.com/apache/flink/pull/11515#discussion_r400948335", "createdAt": "2020-03-31T14:15:25Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequest.java", "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageLocationReference;\n+import org.apache.flink.util.function.ThrowingConsumer;\n+\n+abstract class ChannelStateWriteRequest {\n+\tfinal long checkpointId;\n+\n+\tChannelStateWriteRequest(long checkpointId) {\n+\t\tthis.checkpointId = checkpointId;\n+\t}\n+\n+\t@Override\n+\tpublic String toString() {\n+\t\treturn getClass().getSimpleName() + \", checkpointId=\" + checkpointId;\n+\t}\n+\n+\tstatic CheckpointInProgressRequest completeInput(long checkpointId) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4NjQ5Njg1OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestProcessor.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxNDoxNzoyNVrOF-YCfA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxNDoxNzoyNVrOF-YCfA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk0OTg4NA==", "bodyText": "Rename to fail?", "url": "https://github.com/apache/flink/pull/11515#discussion_r400949884", "createdAt": "2020-03-31T14:17:25Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestProcessor.java", "diffHunk": "@@ -0,0 +1,77 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+/**\n+ * Maintains a set of {@link ChannelStateCheckpointWriter writers} per checkpoint and translates incoming\n+ * {@link ChannelStateWriteRequest requests} to their corresponding methods.\n+ */\n+final class ChannelStateWriteRequestProcessor {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriteRequestProcessor.class);\n+\n+\tprivate final Map<Long, ChannelStateCheckpointWriter> writers; // limited indirectly by results max size\n+\tprivate final CheckpointStorageWorkerView streamFactoryFactory;\n+\tprivate final ChannelStateSerializer serializer;\n+\n+\tChannelStateWriteRequestProcessor(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\tthis.writers = new HashMap<>(maxCheckpoints);\n+\t\tthis.streamFactoryFactory = streamFactoryFactory;\n+\t\tthis.serializer = serializer;\n+\t}\n+\n+\tvoid processRequest(ChannelStateWriteRequest request) throws Exception {\n+\t\tLOG.debug(\"process {}\", request);\n+\t\tif (request instanceof CheckpointStartRequest) {\n+\t\t\tPreconditions.checkState(!writers.containsKey(request.checkpointId));\n+\t\t\twriters.put(request.checkpointId, buildWriter((CheckpointStartRequest) request));\n+\t\t} else if (request instanceof CheckpointInProgressRequest) {\n+\t\t\tPreconditions.checkState(writers.containsKey(request.checkpointId), \"writer not found for checkpoint id \" + request.checkpointId);\n+\t\t\twriters.get(request.checkpointId).process((CheckpointInProgressRequest) request);\n+\t\t} else {\n+\t\t\tthrow new IllegalArgumentException(\"unknown request type: \" + request);\n+\t\t}\n+\t}\n+\n+\tprivate ChannelStateCheckpointWriter buildWriter(CheckpointStartRequest request) throws Exception {\n+\t\treturn new ChannelStateCheckpointWriter(\n+\t\t\trequest,\n+\t\t\tstreamFactoryFactory.resolveCheckpointStorageLocation(request.checkpointId, request.locationReference),\n+\t\t\tserializer,\n+\t\t\t() -> writers.remove(request.checkpointId));\n+\t}\n+\n+\tvoid cleanup(Throwable e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 67}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4NjYwOTI5OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/taskmanager/Task.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxNDo0MDoyNVrOF-ZJZw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxNDo0MDoyNVrOF-ZJZw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk2ODAzOQ==", "bodyText": "nit: space", "url": "https://github.com/apache/flink/pull/11515#discussion_r400968039", "createdAt": "2020-03-31T14:40:25Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/taskmanager/Task.java", "diffHunk": "@@ -1057,7 +1062,7 @@ else if (current == ExecutionState.RUNNING) {\n \t\t\t\t\t\t// case the canceling could not continue\n \n \t\t\t\t\t\t// The canceller calls cancel and interrupts the executing thread once\n-\t\t\t\t\t\tRunnable canceler = new TaskCanceler(LOG, this :: closeNetworkResources, invokable, executingThread, taskNameWithSubtask);\n+\t\t\t\t\t\tRunnable canceler = new TaskCanceler(LOG, this ::closeResources, invokable, executingThread, taskNameWithSubtask);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4NjYxMjMxOnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxNDo0MDo1OVrOF-ZLPQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxODoxODowMlrOF_3xtA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk2ODUwOQ==", "bodyText": "move to subtask commit", "url": "https://github.com/apache/flink/pull/11515#discussion_r400968509", "createdAt": "2020-03-31T14:40:59Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -21,53 +21,79 @@\n import org.apache.flink.runtime.checkpoint.CheckpointMetaData;\n import org.apache.flink.runtime.checkpoint.CheckpointMetrics;\n import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.StateObjectCollection;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriterImpl;\n import org.apache.flink.runtime.execution.Environment;\n import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.CheckpointStorageLocationReference;\n import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.SnapshotResult;\n import org.apache.flink.streaming.api.operators.OperatorSnapshotFutures;\n import org.apache.flink.streaming.api.operators.StreamOperator;\n+import org.apache.flink.util.WrappingRuntimeException;\n \n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import java.io.IOException;\n import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n import java.util.concurrent.ExecutorService;\n import java.util.function.Supplier;\n \n+import static org.apache.flink.runtime.checkpoint.CheckpointType.CHECKPOINT;\n import static org.apache.flink.util.Preconditions.checkNotNull;\n \n class SubtaskCheckpointCoordinatorImpl implements SubtaskCheckpointCoordinator {\n \n \tprivate static final Logger LOG = LoggerFactory.getLogger(SubtaskCheckpointCoordinatorImpl.class);\n \n-\tprivate final CheckpointStorageWorkerView checkpointStorage;\n+\tprivate final CachingCheckpointStorageWorkerView checkpointStorage;\n \tprivate final String taskName;\n \tprivate final CloseableRegistry closeableRegistry;\n \tprivate final ExecutorService executorService;\n \tprivate final Environment env;\n \tprivate final AsyncExceptionHandler asyncExceptionHandler;\n+\tprivate final ChannelStateWriter channelStateWriter;\n \n \tSubtaskCheckpointCoordinatorImpl(\n-\t\tCheckpointStorageWorkerView checkpointStorage,\n-\t\tString taskName,\n-\t\tCloseableRegistry closeableRegistry,\n-\t\tExecutorService executorService,\n-\t\tEnvironment env,\n-\t\tAsyncExceptionHandler asyncExceptionHandler) {\n-\t\tthis.checkpointStorage = checkNotNull(checkpointStorage);\n+\t\t\tCheckpointStorageWorkerView checkpointStorage,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTc3OTIwNw==", "bodyText": "Can you please explain what do you mean?", "url": "https://github.com/apache/flink/pull/11515#discussion_r401779207", "createdAt": "2020-04-01T17:16:33Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -21,53 +21,79 @@\n import org.apache.flink.runtime.checkpoint.CheckpointMetaData;\n import org.apache.flink.runtime.checkpoint.CheckpointMetrics;\n import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.StateObjectCollection;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriterImpl;\n import org.apache.flink.runtime.execution.Environment;\n import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.CheckpointStorageLocationReference;\n import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.SnapshotResult;\n import org.apache.flink.streaming.api.operators.OperatorSnapshotFutures;\n import org.apache.flink.streaming.api.operators.StreamOperator;\n+import org.apache.flink.util.WrappingRuntimeException;\n \n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import java.io.IOException;\n import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n import java.util.concurrent.ExecutorService;\n import java.util.function.Supplier;\n \n+import static org.apache.flink.runtime.checkpoint.CheckpointType.CHECKPOINT;\n import static org.apache.flink.util.Preconditions.checkNotNull;\n \n class SubtaskCheckpointCoordinatorImpl implements SubtaskCheckpointCoordinator {\n \n \tprivate static final Logger LOG = LoggerFactory.getLogger(SubtaskCheckpointCoordinatorImpl.class);\n \n-\tprivate final CheckpointStorageWorkerView checkpointStorage;\n+\tprivate final CachingCheckpointStorageWorkerView checkpointStorage;\n \tprivate final String taskName;\n \tprivate final CloseableRegistry closeableRegistry;\n \tprivate final ExecutorService executorService;\n \tprivate final Environment env;\n \tprivate final AsyncExceptionHandler asyncExceptionHandler;\n+\tprivate final ChannelStateWriter channelStateWriter;\n \n \tSubtaskCheckpointCoordinatorImpl(\n-\t\tCheckpointStorageWorkerView checkpointStorage,\n-\t\tString taskName,\n-\t\tCloseableRegistry closeableRegistry,\n-\t\tExecutorService executorService,\n-\t\tEnvironment env,\n-\t\tAsyncExceptionHandler asyncExceptionHandler) {\n-\t\tthis.checkpointStorage = checkNotNull(checkpointStorage);\n+\t\t\tCheckpointStorageWorkerView checkpointStorage,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk2ODUwOQ=="}, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjUxODQ1Mg==", "bodyText": "These lines fix what has been added to a previous commit, where you added subtask. So squash the hunk into that commit.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402518452", "createdAt": "2020-04-02T18:18:02Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -21,53 +21,79 @@\n import org.apache.flink.runtime.checkpoint.CheckpointMetaData;\n import org.apache.flink.runtime.checkpoint.CheckpointMetrics;\n import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.StateObjectCollection;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriterImpl;\n import org.apache.flink.runtime.execution.Environment;\n import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.CheckpointStorageLocationReference;\n import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.SnapshotResult;\n import org.apache.flink.streaming.api.operators.OperatorSnapshotFutures;\n import org.apache.flink.streaming.api.operators.StreamOperator;\n+import org.apache.flink.util.WrappingRuntimeException;\n \n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import java.io.IOException;\n import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n import java.util.concurrent.ExecutorService;\n import java.util.function.Supplier;\n \n+import static org.apache.flink.runtime.checkpoint.CheckpointType.CHECKPOINT;\n import static org.apache.flink.util.Preconditions.checkNotNull;\n \n class SubtaskCheckpointCoordinatorImpl implements SubtaskCheckpointCoordinator {\n \n \tprivate static final Logger LOG = LoggerFactory.getLogger(SubtaskCheckpointCoordinatorImpl.class);\n \n-\tprivate final CheckpointStorageWorkerView checkpointStorage;\n+\tprivate final CachingCheckpointStorageWorkerView checkpointStorage;\n \tprivate final String taskName;\n \tprivate final CloseableRegistry closeableRegistry;\n \tprivate final ExecutorService executorService;\n \tprivate final Environment env;\n \tprivate final AsyncExceptionHandler asyncExceptionHandler;\n+\tprivate final ChannelStateWriter channelStateWriter;\n \n \tSubtaskCheckpointCoordinatorImpl(\n-\t\tCheckpointStorageWorkerView checkpointStorage,\n-\t\tString taskName,\n-\t\tCloseableRegistry closeableRegistry,\n-\t\tExecutorService executorService,\n-\t\tEnvironment env,\n-\t\tAsyncExceptionHandler asyncExceptionHandler) {\n-\t\tthis.checkpointStorage = checkNotNull(checkpointStorage);\n+\t\t\tCheckpointStorageWorkerView checkpointStorage,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk2ODUwOQ=="}, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4NjYyMDcxOnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxNDo0Mjo0NFrOF-ZQpw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxNzoyMDoyM1rOF_KzUA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk2OTg5NQ==", "bodyText": "Also cleared on abort?", "url": "https://github.com/apache/flink/pull/11515#discussion_r400969895", "createdAt": "2020-03-31T14:42:44Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -175,6 +203,77 @@ public void checkpointState(\n \t\t}\n \t}\n \n+\tprivate OperatorSnapshotFutures buildOperatorSnapshotFutures(\n+\t\t\tCheckpointMetaData checkpointMetaData,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tOperatorChain<?, ?> operatorChain,\n+\t\t\tStreamOperator<?> op,\n+\t\t\tSupplier<Boolean> isCanceled,\n+\t\t\tChannelStateWriteResult channelStateWriteResult) throws Exception {\n+\t\tCheckpointStreamFactory storage = checkpointStorage.resolveCheckpointStorageLocation(\n+\t\t\tcheckpointMetaData.getCheckpointId(),\n+\t\t\tcheckpointOptions.getTargetLocation());\n+\t\tOperatorSnapshotFutures snapshotInProgress = checkpointStreamOperator(\n+\t\t\top,\n+\t\t\tcheckpointMetaData,\n+\t\t\tcheckpointOptions,\n+\t\t\tstorage,\n+\t\t\tisCanceled);\n+\t\tif (op == operatorChain.getHeadOperator()) {\n+\t\t\tsnapshotInProgress.setInputChannelStateFuture(channelStateWriteResult\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.getInputChannelStateHandles()\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(StateObjectCollection::new)\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(SnapshotResult::of)\n+\t\t\t);\n+\t\t}\n+\t\tif (op == operatorChain.getTailOperator()) {\n+\t\t\tsnapshotInProgress.setResultSubpartitionStateFuture(channelStateWriteResult\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.getResultSubpartitionStateHandles()\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(StateObjectCollection::new)\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(SnapshotResult::of)\n+\t\t\t);\n+\t\t}\n+\t\treturn snapshotInProgress;\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tchannelStateWriter.close();\n+\t}\n+\n+\t// Caches checkpoint output stream factories to prevent multiple output stream per checkpoint.\n+\t// This could result from requesting output stream by different entities (this and channelStateWriter)\n+\t// We can't just pass a stream to the channelStateWriter because it can receive checkpoint call earlier than this class\n+\t// in some unaligned checkpoints scenarios\n+\tprivate static class CachingCheckpointStorageWorkerView implements CheckpointStorageWorkerView {\n+\t\tprivate final Map<Long, CheckpointStreamFactory> cache = new ConcurrentHashMap<>();\n+\t\tprivate final CheckpointStorageWorkerView delegate;\n+\n+\t\tprivate CachingCheckpointStorageWorkerView(CheckpointStorageWorkerView delegate) {\n+\t\t\tthis.delegate = delegate;\n+\t\t}\n+\n+\t\tvoid clearCacheFor(long checkpointId) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 181}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTc4MTU4NA==", "bodyText": "Good point!", "url": "https://github.com/apache/flink/pull/11515#discussion_r401781584", "createdAt": "2020-04-01T17:20:23Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -175,6 +203,77 @@ public void checkpointState(\n \t\t}\n \t}\n \n+\tprivate OperatorSnapshotFutures buildOperatorSnapshotFutures(\n+\t\t\tCheckpointMetaData checkpointMetaData,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tOperatorChain<?, ?> operatorChain,\n+\t\t\tStreamOperator<?> op,\n+\t\t\tSupplier<Boolean> isCanceled,\n+\t\t\tChannelStateWriteResult channelStateWriteResult) throws Exception {\n+\t\tCheckpointStreamFactory storage = checkpointStorage.resolveCheckpointStorageLocation(\n+\t\t\tcheckpointMetaData.getCheckpointId(),\n+\t\t\tcheckpointOptions.getTargetLocation());\n+\t\tOperatorSnapshotFutures snapshotInProgress = checkpointStreamOperator(\n+\t\t\top,\n+\t\t\tcheckpointMetaData,\n+\t\t\tcheckpointOptions,\n+\t\t\tstorage,\n+\t\t\tisCanceled);\n+\t\tif (op == operatorChain.getHeadOperator()) {\n+\t\t\tsnapshotInProgress.setInputChannelStateFuture(channelStateWriteResult\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.getInputChannelStateHandles()\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(StateObjectCollection::new)\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(SnapshotResult::of)\n+\t\t\t);\n+\t\t}\n+\t\tif (op == operatorChain.getTailOperator()) {\n+\t\t\tsnapshotInProgress.setResultSubpartitionStateFuture(channelStateWriteResult\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.getResultSubpartitionStateHandles()\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(StateObjectCollection::new)\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(SnapshotResult::of)\n+\t\t\t);\n+\t\t}\n+\t\treturn snapshotInProgress;\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tchannelStateWriter.close();\n+\t}\n+\n+\t// Caches checkpoint output stream factories to prevent multiple output stream per checkpoint.\n+\t// This could result from requesting output stream by different entities (this and channelStateWriter)\n+\t// We can't just pass a stream to the channelStateWriter because it can receive checkpoint call earlier than this class\n+\t// in some unaligned checkpoints scenarios\n+\tprivate static class CachingCheckpointStorageWorkerView implements CheckpointStorageWorkerView {\n+\t\tprivate final Map<Long, CheckpointStreamFactory> cache = new ConcurrentHashMap<>();\n+\t\tprivate final CheckpointStorageWorkerView delegate;\n+\n+\t\tprivate CachingCheckpointStorageWorkerView(CheckpointStorageWorkerView delegate) {\n+\t\t\tthis.delegate = delegate;\n+\t\t}\n+\n+\t\tvoid clearCacheFor(long checkpointId) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk2OTg5NQ=="}, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 181}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4NjYzNzUzOnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxNDo0NjowNVrOF-ZbKg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxNDo0NjowNVrOF-ZbKg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk3MjU4Ng==", "bodyText": "weird format.", "url": "https://github.com/apache/flink/pull/11515#discussion_r400972586", "createdAt": "2020-03-31T14:46:05Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -175,6 +203,77 @@ public void checkpointState(\n \t\t}\n \t}\n \n+\tprivate OperatorSnapshotFutures buildOperatorSnapshotFutures(\n+\t\t\tCheckpointMetaData checkpointMetaData,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tOperatorChain<?, ?> operatorChain,\n+\t\t\tStreamOperator<?> op,\n+\t\t\tSupplier<Boolean> isCanceled,\n+\t\t\tChannelStateWriteResult channelStateWriteResult) throws Exception {\n+\t\tCheckpointStreamFactory storage = checkpointStorage.resolveCheckpointStorageLocation(\n+\t\t\tcheckpointMetaData.getCheckpointId(),\n+\t\t\tcheckpointOptions.getTargetLocation());\n+\t\tOperatorSnapshotFutures snapshotInProgress = checkpointStreamOperator(\n+\t\t\top,\n+\t\t\tcheckpointMetaData,\n+\t\t\tcheckpointOptions,\n+\t\t\tstorage,\n+\t\t\tisCanceled);\n+\t\tif (op == operatorChain.getHeadOperator()) {\n+\t\t\tsnapshotInProgress.setInputChannelStateFuture(channelStateWriteResult\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.getInputChannelStateHandles()\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(StateObjectCollection::new)\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(SnapshotResult::of)\n+\t\t\t);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 152}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4ODk1NjQ5OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/tasks/SourceTaskTerminationTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwMzo0NTo0NFrOF-v0xw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxNzo0MzoyMVrOF_Lp5A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMzOTU5MQ==", "bodyText": "I did not get the point why we need this change and it seems unrelated to this PR. If the motivation is for avoiding stuck long time during await(), but it already has timeoutPerTest for ending the test after timeout.\nIf we want to refactor some previous tests, it should be a hotfix commit if minor and give some descriptions in commit message for better understanding the motivation.", "url": "https://github.com/apache/flink/pull/11515#discussion_r401339591", "createdAt": "2020-04-01T03:45:44Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/tasks/SourceTaskTerminationTest.java", "diffHunk": "@@ -82,7 +84,7 @@ private void stopWithSavepointStreamTaskTestHelper(final boolean withMaxWatermar\n \t\tfinal Thread executionThread = srcTaskTestHarness.invoke();\n \t\tfinal StreamTask<Long, ?> srcTask = srcTaskTestHarness.getTask();\n \n-\t\tready.await();\n+\t\twaitForLatchSetByTask(ready, srcTaskTestHarness);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "86d660018a3166d1cbab1e70619004d352b2bffc"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTc5NTU1Ng==", "bodyText": "At some point, this test was failing with a timeout\nbut It was unclear why do I get this timeout.\nI'll update the commit message to includehotfix and motivation.\nRemoving the commit as it seems not necessary now.", "url": "https://github.com/apache/flink/pull/11515#discussion_r401795556", "createdAt": "2020-04-01T17:43:21Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/tasks/SourceTaskTerminationTest.java", "diffHunk": "@@ -82,7 +84,7 @@ private void stopWithSavepointStreamTaskTestHelper(final boolean withMaxWatermar\n \t\tfinal Thread executionThread = srcTaskTestHarness.invoke();\n \t\tfinal StreamTask<Long, ?> srcTask = srcTaskTestHarness.getTask();\n \n-\t\tready.await();\n+\t\twaitForLatchSetByTask(ready, srcTaskTestHarness);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMzOTU5MQ=="}, "originalCommit": {"oid": "86d660018a3166d1cbab1e70619004d352b2bffc"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4ODk3MzY4OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/tasks/SourceTaskTerminationTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwMzo1NjoxNlrOF-v-QQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwMzo1NjoxNlrOF-v-QQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM0MjAxNw==", "bodyText": "I guess we can merge the following while and if logics into this while to avoid judging srcTask.isRunning() three times separately, and make the logics more close with each other.", "url": "https://github.com/apache/flink/pull/11515#discussion_r401342017", "createdAt": "2020-04-01T03:56:16Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/tasks/SourceTaskTerminationTest.java", "diffHunk": "@@ -122,6 +124,26 @@ private void stopWithSavepointStreamTaskTestHelper(final boolean withMaxWatermar\n \t\texecutionThread.join();\n \t}\n \n+\tprivate void waitForLatchSetByTask(OneShotLatch latch, StreamTaskTestHarness<?> srcTaskTestHarness) throws Exception {\n+\t\tfinal StreamTask<?, ?> srcTask = srcTaskTestHarness.getTask();\n+\t\tfinal Thread executionThread = srcTaskTestHarness.taskThread;\n+\t\twhile (executionThread.isAlive() && srcTask.isRunning()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "86d660018a3166d1cbab1e70619004d352b2bffc"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4ODk4Mzc1OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/operators/testutils/MockEnvironment.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNDowMzowM1rOF-wELg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNjowNToxMFrOF_ycFA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM0MzUzNA==", "bodyText": "nit: unrelated change for this commit motivation", "url": "https://github.com/apache/flink/pull/11515#discussion_r401343534", "createdAt": "2020-04-01T04:03:03Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/operators/testutils/MockEnvironment.java", "diffHunk": "@@ -335,7 +335,7 @@ public void acknowledgeCheckpoint(long checkpointId, CheckpointMetrics checkpoin\n \n \t@Override\n \tpublic void declineCheckpoint(long checkpointId, Throwable cause) {\n-\t\tthrow new UnsupportedOperationException();\n+\t\tthrow new UnsupportedOperationException(cause);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "05c60654476141e8c0cb224d725cea99c85e7b15"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTgzMTc4Mw==", "bodyText": "Agree, but I don't think this change deserves its own commit.", "url": "https://github.com/apache/flink/pull/11515#discussion_r401831783", "createdAt": "2020-04-01T18:44:24Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/operators/testutils/MockEnvironment.java", "diffHunk": "@@ -335,7 +335,7 @@ public void acknowledgeCheckpoint(long checkpointId, CheckpointMetrics checkpoin\n \n \t@Override\n \tpublic void declineCheckpoint(long checkpointId, Throwable cause) {\n-\t\tthrow new UnsupportedOperationException();\n+\t\tthrow new UnsupportedOperationException(cause);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM0MzUzNA=="}, "originalCommit": {"oid": "05c60654476141e8c0cb224d725cea99c85e7b15"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQzMDk5Ng==", "bodyText": "Based on my experience, any unrelated tiny changes should be submitted as hotfix commit instead, such as typo, indentation formatting, etc.\nBut I guess there are no explicit guidelines for it, so feel free to do it or not.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402430996", "createdAt": "2020-04-02T16:05:10Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/operators/testutils/MockEnvironment.java", "diffHunk": "@@ -335,7 +335,7 @@ public void acknowledgeCheckpoint(long checkpointId, CheckpointMetrics checkpoin\n \n \t@Override\n \tpublic void declineCheckpoint(long checkpointId, Throwable cause) {\n-\t\tthrow new UnsupportedOperationException();\n+\t\tthrow new UnsupportedOperationException(cause);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM0MzUzNA=="}, "originalCommit": {"oid": "05c60654476141e8c0cb224d725cea99c85e7b15"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4ODk4NjU3OnYy", "diffSide": "LEFT", "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/over/BufferDataOverWindowOperatorTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNDowNDozMFrOF-wFsg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNDowNDozMFrOF-wFsg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM0MzkyMg==", "bodyText": "nit: unrelated change", "url": "https://github.com/apache/flink/pull/11515#discussion_r401343922", "createdAt": "2020-04-01T04:04:30Z", "author": {"login": "zhijiangW"}, "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/over/BufferDataOverWindowOperatorTest.java", "diffHunk": "@@ -64,7 +66,6 @@\n  * Test for {@link BufferDataOverWindowOperator}.\n  */\n public class BufferDataOverWindowOperatorTest {\n-", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "05c60654476141e8c0cb224d725cea99c85e7b15"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4ODk5ODI3OnYy", "diffSide": "RIGHT", "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/over/BufferDataOverWindowOperatorTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNDoxMToyNFrOF-wMBg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxODo1NDo1MlrOF_OPLQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM0NTU0Mg==", "bodyText": "TBH i did not get the point why this class change is related to the commit motivation.\nIf it is necessary, can we use MockStreamTaskBuilder to build MockStreamTask instead, to avoid construct MockableStreamTask. Besides that, it is not suggested to use mock in unit tests.", "url": "https://github.com/apache/flink/pull/11515#discussion_r401345542", "createdAt": "2020-04-01T04:11:24Z", "author": {"login": "zhijiangW"}, "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/over/BufferDataOverWindowOperatorTest.java", "diffHunk": "@@ -205,9 +206,19 @@ public StreamConfig getOperatorConfig() {\n \n \t\t\t@Override\n \t\t\tpublic StreamTask<?, ?> getContainingTask() {\n-\t\t\t\tStreamTask task = mock(StreamTask.class);\n+\t\t\t\tclass MockableStreamTask extends StreamTask<Object, StreamOperator<Object>> implements EnvironmentSupport {\n+\t\t\t\t\tMockableStreamTask() throws Exception {\n+\t\t\t\t\t\tsuper(new MockEnvironmentBuilder().build());\n+\t\t\t\t\t}\n+\n+\t\t\t\t\t@Override\n+\t\t\t\t\tprotected void init() {\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\n+\t\t\t\tStreamTask<?, ?> task = mock(MockableStreamTask.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "05c60654476141e8c0cb224d725cea99c85e7b15"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTgzNzg2OQ==", "bodyText": "After making final some methods of StreamTask this test broke because mockito wasn't able now to override them.\nEventually, I removed mockito from here.", "url": "https://github.com/apache/flink/pull/11515#discussion_r401837869", "createdAt": "2020-04-01T18:54:52Z", "author": {"login": "rkhachatryan"}, "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/over/BufferDataOverWindowOperatorTest.java", "diffHunk": "@@ -205,9 +206,19 @@ public StreamConfig getOperatorConfig() {\n \n \t\t\t@Override\n \t\t\tpublic StreamTask<?, ?> getContainingTask() {\n-\t\t\t\tStreamTask task = mock(StreamTask.class);\n+\t\t\t\tclass MockableStreamTask extends StreamTask<Object, StreamOperator<Object>> implements EnvironmentSupport {\n+\t\t\t\t\tMockableStreamTask() throws Exception {\n+\t\t\t\t\t\tsuper(new MockEnvironmentBuilder().build());\n+\t\t\t\t\t}\n+\n+\t\t\t\t\t@Override\n+\t\t\t\t\tprotected void init() {\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\n+\t\t\t\tStreamTask<?, ?> task = mock(MockableStreamTask.class);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM0NTU0Mg=="}, "originalCommit": {"oid": "05c60654476141e8c0cb224d725cea99c85e7b15"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4OTAyNzc1OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamTask.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNDozMDoxMFrOF-wcuQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNFQxNToyNjo0NlrOGAymhw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM0OTgxNw==", "bodyText": "I guess the motivation for defining final for related parent methods is from constructing SubtaskCheckpointCoordinatorImpl in StreamTask constructor. If so, we need also define final for AbstractInvokable#getEnvironment because it is also accessed while constructing SubtaskCheckpointCoordinatorImpl.\nActually we can avoid using getter while constructing SubtaskCheckpointCoordinatorImpl to use specific arguments instead. Anyway i think it is meaningful to define final for some methods if we confirm they should not be override by subclasses. But the requirement should not be from constructing SubtaskCheckpointCoordinatorImpl, and we should review all the methods in AbstractInvokable and StreamTask to make this thing completely.", "url": "https://github.com/apache/flink/pull/11515#discussion_r401349817", "createdAt": "2020-04-01T04:30:10Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamTask.java", "diffHunk": "@@ -651,7 +651,7 @@ boolean isSerializingTimestamps() {\n \t * Gets the name of the task, in the form \"taskname (2/5)\".\n \t * @return The name of the task.\n \t */\n-\tpublic String getName() {\n+\tpublic final String getName() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "05c60654476141e8c0cb224d725cea99c85e7b15"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTg0Njg0MQ==", "bodyText": "Right, the motivation is the use of this method in constructor.\nThanks for pointing out about getEnvironment (it was modified made final too but then reverted accidentally while fixing tests).\nI did consider the alternative of using specific values in constructor, but then we can get inconsistency between values used in constructor with ones in getters. So using getters here and declaring them final I think is a lesser evil.\nRegarding the contract of AbstractInvokable and StreamTask, I don't think these methods are extension points (as opposed to processInput for example), and therefore shouldn't be overridden.", "url": "https://github.com/apache/flink/pull/11515#discussion_r401846841", "createdAt": "2020-04-01T19:10:25Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamTask.java", "diffHunk": "@@ -651,7 +651,7 @@ boolean isSerializingTimestamps() {\n \t * Gets the name of the task, in the form \"taskname (2/5)\".\n \t * @return The name of the task.\n \t */\n-\tpublic String getName() {\n+\tpublic final String getName() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM0OTgxNw=="}, "originalCommit": {"oid": "05c60654476141e8c0cb224d725cea99c85e7b15"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzQ4MjI0Nw==", "bodyText": "Yes, i agree with your consideration for inconsistency between values used in constructor with ones in getters.\nRegarding the AbstractInvokable and StreamTask, you misunderstood my previous comment. I mean that there might still have other methods inside parent AbstractInvokable and StreamTask,  which should not be overridden by subclasses, so it should also be defined as final as you already did in this PR. Now we only consider the requirements from SubtaskCheckpointCoordinatorImpl to handle the related methods. But from a more general motivation, we might need to go through all the necessary methods to limit them as final to make this story complete. But it is up to you whether to touch more things in this PR.", "url": "https://github.com/apache/flink/pull/11515#discussion_r403482247", "createdAt": "2020-04-04T15:26:46Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamTask.java", "diffHunk": "@@ -651,7 +651,7 @@ boolean isSerializingTimestamps() {\n \t * Gets the name of the task, in the form \"taskname (2/5)\".\n \t * @return The name of the task.\n \t */\n-\tpublic String getName() {\n+\tpublic final String getName() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM0OTgxNw=="}, "originalCommit": {"oid": "05c60654476141e8c0cb224d725cea99c85e7b15"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4OTA0MzIzOnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamTask.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNDo0MDoxMFrOF-wlng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxOToxMToyOVrOF_O0Vg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM1MjA5NA==", "bodyText": "nit: we can get environment directly from argument instead of getEnvironment(), also for getAsyncOperationsThreadPool()", "url": "https://github.com/apache/flink/pull/11515#discussion_r401352094", "createdAt": "2020-04-01T04:40:10Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamTask.java", "diffHunk": "@@ -271,7 +269,14 @@ protected StreamTask(\n \t\t\tnew ExecutorThreadFactory(\"AsyncOperations\", uncaughtExceptionHandler));\n \n \t\tthis.stateBackend = createStateBackend();\n-\t\tthis.checkpointStorage = stateBackend.createCheckpointStorage(getEnvironment().getJobID());\n+\n+\t\tthis.subtaskCheckpointCoordinator = new SubtaskCheckpointCoordinatorImpl(\n+\t\t\tstateBackend.createCheckpointStorage(getEnvironment().getJobID()),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3387596c1f3e4ed6e6cbeb586cefb59bc9f2e67"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTg0NzM4Mg==", "bodyText": "replied in the comment above\n(this would bring inconsistency with values from getters)", "url": "https://github.com/apache/flink/pull/11515#discussion_r401847382", "createdAt": "2020-04-01T19:11:29Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamTask.java", "diffHunk": "@@ -271,7 +269,14 @@ protected StreamTask(\n \t\t\tnew ExecutorThreadFactory(\"AsyncOperations\", uncaughtExceptionHandler));\n \n \t\tthis.stateBackend = createStateBackend();\n-\t\tthis.checkpointStorage = stateBackend.createCheckpointStorage(getEnvironment().getJobID());\n+\n+\t\tthis.subtaskCheckpointCoordinator = new SubtaskCheckpointCoordinatorImpl(\n+\t\t\tstateBackend.createCheckpointStorage(getEnvironment().getJobID()),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM1MjA5NA=="}, "originalCommit": {"oid": "c3387596c1f3e4ed6e6cbeb586cefb59bc9f2e67"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4OTA0OTc4OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamTask.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNDo0NDoyOFrOF-wpWw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNDo0NDoyOFrOF-wpWw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM1MzA1MQ==", "bodyText": "nit: split the arguments into every line, seem too long.", "url": "https://github.com/apache/flink/pull/11515#discussion_r401353051", "createdAt": "2020-04-01T04:44:28Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamTask.java", "diffHunk": "@@ -772,38 +777,18 @@ private boolean performCheckpoint(\n \t\tLOG.debug(\"Starting checkpoint ({}) {} on task {}\",\n \t\t\tcheckpointMetaData.getCheckpointId(), checkpointOptions.getCheckpointType(), getName());\n \n-\t\tfinal long checkpointId = checkpointMetaData.getCheckpointId();\n-\n \t\tif (isRunning) {\n \t\t\tactionExecutor.runThrowing(() -> {\n \n \t\t\t\tif (checkpointOptions.getCheckpointType().isSynchronous()) {\n-\t\t\t\t\tsetSynchronousSavepointId(checkpointId);\n+\t\t\t\t\tsetSynchronousSavepointId(checkpointMetaData.getCheckpointId());\n \n \t\t\t\t\tif (advanceToEndOfTime) {\n \t\t\t\t\t\tadvanceToEndOfEventTime();\n \t\t\t\t\t}\n \t\t\t\t}\n \n-\t\t\t\t// All of the following steps happen as an atomic step from the perspective of barriers and\n-\t\t\t\t// records/watermarks/timers/callbacks.\n-\t\t\t\t// We generally try to emit the checkpoint barrier as soon as possible to not affect downstream\n-\t\t\t\t// checkpoint alignments\n-\n-\t\t\t\t// Step (1): Prepare the checkpoint, allow operators to do some pre-barrier work.\n-\t\t\t\t//           The pre-barrier work should be nothing or minimal in the common case.\n-\t\t\t\toperatorChain.prepareSnapshotPreBarrier(checkpointId);\n-\n-\t\t\t\t// Step (2): Send the checkpoint barrier downstream\n-\t\t\t\toperatorChain.broadcastCheckpointBarrier(\n-\t\t\t\t\t\tcheckpointId,\n-\t\t\t\t\t\tcheckpointMetaData.getTimestamp(),\n-\t\t\t\t\t\tcheckpointOptions);\n-\n-\t\t\t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not\n-\t\t\t\t//           impact progress of the streaming topology\n-\t\t\t\tcheckpointState(checkpointMetaData, checkpointOptions, checkpointMetrics);\n-\n+\t\t\t\tsubtaskCheckpointCoordinator.checkpointState(checkpointMetaData, checkpointOptions, checkpointMetrics, operatorChain, this::isCanceled);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3387596c1f3e4ed6e6cbeb586cefb59bc9f2e67"}, "originalPosition": 80}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4OTA5MDkxOnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinator.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNToxMToyM1rOF-xBxQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxOToxNTo0MFrOF_O9mQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM1OTMwMQ==", "bodyText": "I do not find any usages in this PR. Do you expect which component might use this getter future?", "url": "https://github.com/apache/flink/pull/11515#discussion_r401359301", "createdAt": "2020-04-01T05:11:23Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinator.java", "diffHunk": "@@ -0,0 +1,51 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.tasks;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointMetaData;\n+import org.apache.flink.runtime.checkpoint.CheckpointMetrics;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+\n+import java.util.function.Supplier;\n+\n+/**\n+ * Coordinates checkpointing-related work for a subtask (i.e. {@link org.apache.flink.runtime.taskmanager.Task Task} and\n+ * {@link StreamTask}). Responsibilities:\n+ * <ol>\n+ * <li>build a snapshot (invokable)</li>\n+ * <li>report snapshot to the JobManager</li>\n+ * <li>maintain storage locations</li>\n+ * </ol>\n+ */\n+@Internal\n+interface SubtaskCheckpointCoordinator {\n+\n+\tChannelStateWriter getChannelStateWriter();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3387596c1f3e4ed6e6cbeb586cefb59bc9f2e67"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTg0OTc1Mw==", "bodyText": "Yes, this is supposed to be used to \"spill\" buffers while checkpointing in Unaligned mode (#11507).", "url": "https://github.com/apache/flink/pull/11515#discussion_r401849753", "createdAt": "2020-04-01T19:15:40Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinator.java", "diffHunk": "@@ -0,0 +1,51 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.tasks;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointMetaData;\n+import org.apache.flink.runtime.checkpoint.CheckpointMetrics;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+\n+import java.util.function.Supplier;\n+\n+/**\n+ * Coordinates checkpointing-related work for a subtask (i.e. {@link org.apache.flink.runtime.taskmanager.Task Task} and\n+ * {@link StreamTask}). Responsibilities:\n+ * <ol>\n+ * <li>build a snapshot (invokable)</li>\n+ * <li>report snapshot to the JobManager</li>\n+ * <li>maintain storage locations</li>\n+ * </ol>\n+ */\n+@Internal\n+interface SubtaskCheckpointCoordinator {\n+\n+\tChannelStateWriter getChannelStateWriter();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM1OTMwMQ=="}, "originalCommit": {"oid": "c3387596c1f3e4ed6e6cbeb586cefb59bc9f2e67"}, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4OTA5NTQ3OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNToxNDoxMFrOF-xEeA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNToxNDoxMFrOF-xEeA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM1OTk5Mg==", "bodyText": "nit: better to extract a separate method for the following operation, otherwise this method seems too long for not easy tracing the steps.", "url": "https://github.com/apache/flink/pull/11515#discussion_r401359992", "createdAt": "2020-04-01T05:14:10Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -89,17 +101,98 @@ public void checkpointState(\n \t\t\tcheckpointMetaData.getCheckpointId(),\n \t\t\tcheckpointOptions.getTargetLocation());\n \n-\t\tCheckpointingOperation.execute(\n-\t\t\tcheckpointMetaData,\n-\t\t\tcheckpointOptions,\n-\t\t\tcheckpointMetrics,\n-\t\t\tstorage,\n-\t\t\toperatorChain,\n-\t\t\ttaskName,\n-\t\t\tcloseableRegistry,\n-\t\t\texecutorService,\n-\t\t\tenv,\n-\t\t\tasyncExceptionHandler,\n-\t\t\tisCanceled);\n+\t\tlong startSyncPartNano = System.nanoTime();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ae7bd9f04b94f8c4810b3321df7729b11affeee4"}, "originalPosition": 51}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4OTEwMDIwOnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNToxNzowNVrOF-xHWg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNTozNzo1NlrOGCJpuA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM2MDczMA==", "bodyText": "nit: also checkNotNull for checkpointMetaData and operatorChain, and i think they can be done with the commit [FLINK-16744][task][refactor] extract SubtaskCheckpointCoordinator", "url": "https://github.com/apache/flink/pull/11515#discussion_r401360730", "createdAt": "2020-04-01T05:17:05Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -65,6 +75,8 @@ public void checkpointState(\n \t\t\tCheckpointMetrics checkpointMetrics,\n \t\t\tOperatorChain<?, ?> operatorChain,\n \t\t\tSupplier<Boolean> isCanceled) throws Exception {\n+\t\tcheckNotNull(checkpointOptions);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ae7bd9f04b94f8c4810b3321df7729b11affeee4"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTg3OTEzNw==", "bodyText": "Both of these fields are unreferenced a few lines below. Do you think it makes sense to add this check at the beginning too?", "url": "https://github.com/apache/flink/pull/11515#discussion_r401879137", "createdAt": "2020-04-01T20:09:06Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -65,6 +75,8 @@ public void checkpointState(\n \t\t\tCheckpointMetrics checkpointMetrics,\n \t\t\tOperatorChain<?, ?> operatorChain,\n \t\t\tSupplier<Boolean> isCanceled) throws Exception {\n+\t\tcheckNotNull(checkpointOptions);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM2MDczMA=="}, "originalCommit": {"oid": "ae7bd9f04b94f8c4810b3321df7729b11affeee4"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcxNzU0NA==", "bodyText": "When I checked the commit \"[FLINK-16744][task][refactor] extract SubtaskCheckpointCoordinator\",  the arguments of CheckpointMetaData, CheckpointOptions and operatorChain are already referenced in below lines, so i suggested checkNotNull for them in that commit.", "url": "https://github.com/apache/flink/pull/11515#discussion_r403717544", "createdAt": "2020-04-05T15:30:59Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -65,6 +75,8 @@ public void checkpointState(\n \t\t\tCheckpointMetrics checkpointMetrics,\n \t\t\tOperatorChain<?, ?> operatorChain,\n \t\t\tSupplier<Boolean> isCanceled) throws Exception {\n+\t\tcheckNotNull(checkpointOptions);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM2MDczMA=="}, "originalCommit": {"oid": "ae7bd9f04b94f8c4810b3321df7729b11affeee4"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDkwODQ3Mg==", "bodyText": "When checking the commit \"[FLINK-16744][task][refactor] inline CheckpointingOperation\", we only checkNotNull for checkpointOptions and checkpointMetrics.  But from the commit \"[FLINK-16744][task][refactor] extract SubtaskCheckpointCoordinator\" when this method is firstly introduced,  we did not checkNotNull for other arguments which are actually referenced in that commit, so the criteria seems inconsistent.", "url": "https://github.com/apache/flink/pull/11515#discussion_r404908472", "createdAt": "2020-04-07T15:37:56Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -65,6 +75,8 @@ public void checkpointState(\n \t\t\tCheckpointMetrics checkpointMetrics,\n \t\t\tOperatorChain<?, ?> operatorChain,\n \t\t\tSupplier<Boolean> isCanceled) throws Exception {\n+\t\tcheckNotNull(checkpointOptions);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM2MDczMA=="}, "originalCommit": {"oid": "ae7bd9f04b94f8c4810b3321df7729b11affeee4"}, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4OTExNDkxOnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNToyNTo1MVrOF-xQFQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNToyNTo1MVrOF-xQFQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM2Mjk2NQ==", "bodyText": "nit: better to split line for every argument", "url": "https://github.com/apache/flink/pull/11515#discussion_r401362965", "createdAt": "2020-04-01T05:25:51Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -89,17 +101,98 @@ public void checkpointState(\n \t\t\tcheckpointMetaData.getCheckpointId(),\n \t\t\tcheckpointOptions.getTargetLocation());\n \n-\t\tCheckpointingOperation.execute(\n-\t\t\tcheckpointMetaData,\n-\t\t\tcheckpointOptions,\n-\t\t\tcheckpointMetrics,\n-\t\t\tstorage,\n-\t\t\toperatorChain,\n-\t\t\ttaskName,\n-\t\t\tcloseableRegistry,\n-\t\t\texecutorService,\n-\t\t\tenv,\n-\t\t\tasyncExceptionHandler,\n-\t\t\tisCanceled);\n+\t\tlong startSyncPartNano = System.nanoTime();\n+\n+\t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress = new HashMap<>(operatorChain.getNumberOfOperators());\n+\t\ttry {\n+\t\t\tfor (StreamOperatorWrapper<?, ?> operatorWrapper : operatorChain.getAllOperators(true)) {\n+\t\t\t\tStreamOperator<?> op = operatorWrapper.getStreamOperator();\n+\t\t\t\tOperatorSnapshotFutures snapshotInProgress = checkpointStreamOperator(\n+\t\t\t\t\top,\n+\t\t\t\t\tcheckpointMetaData,\n+\t\t\t\t\tcheckpointOptions,\n+\t\t\t\t\tstorage,\n+\t\t\t\t\tisCanceled);\n+\t\t\t\toperatorSnapshotsInProgress.put(op.getOperatorID(), snapshotInProgress);\n+\t\t\t}\n+\n+\t\t\tif (LOG.isDebugEnabled()) {\n+\t\t\t\tLOG.debug(\"Finished synchronous checkpoints for checkpoint {} on task {}\",\n+\t\t\t\t\tcheckpointMetaData.getCheckpointId(), taskName);\n+\t\t\t}\n+\n+\t\t\tlong startAsyncPartNano = System.nanoTime();\n+\n+\t\t\tcheckpointMetrics.setSyncDurationMillis((startAsyncPartNano - startSyncPartNano) / 1_000_000);\n+\n+\t\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n+\t\t\texecutorService.execute(new AsyncCheckpointRunnable(\n+\t\t\t\toperatorSnapshotsInProgress,\n+\t\t\t\tcheckpointMetaData,\n+\t\t\t\tcheckpointMetrics,\n+\t\t\t\tstartAsyncPartNano,\n+\t\t\t\ttaskName,\n+\t\t\t\tcloseableRegistry,\n+\t\t\t\tenv,\n+\t\t\t\tasyncExceptionHandler));\n+\n+\t\t\tif (LOG.isDebugEnabled()) {\n+\t\t\t\tLOG.debug(\n+\t\t\t\t\t\"{} - finished synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n+\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n+\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n+\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n+\t\t\t}\n+\t\t} catch (Exception ex) {\n+\t\t\t// Cleanup to release resources\n+\t\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n+\t\t\t\tif (null != operatorSnapshotResult) {\n+\t\t\t\t\ttry {\n+\t\t\t\t\t\toperatorSnapshotResult.cancel();\n+\t\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\tif (LOG.isDebugEnabled()) {\n+\t\t\t\tLOG.debug(\n+\t\t\t\t\t\"{} - did NOT finish synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n+\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ae7bd9f04b94f8c4810b3321df7729b11affeee4"}, "originalPosition": 108}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4OTEyMTcwOnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNTozMDowNFrOF-xUKQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQyMjo1MDoyM1rOF_VaCw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM2NDAwOQ==", "bodyText": "I see this log occur twice with the same arguments only different message, and this log actually seems a bit long to impact the normal logics review. I am not sure whether it is worth extracting a separate method for only passing different message in two usages.", "url": "https://github.com/apache/flink/pull/11515#discussion_r401364009", "createdAt": "2020-04-01T05:30:04Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -89,17 +101,98 @@ public void checkpointState(\n \t\t\tcheckpointMetaData.getCheckpointId(),\n \t\t\tcheckpointOptions.getTargetLocation());\n \n-\t\tCheckpointingOperation.execute(\n-\t\t\tcheckpointMetaData,\n-\t\t\tcheckpointOptions,\n-\t\t\tcheckpointMetrics,\n-\t\t\tstorage,\n-\t\t\toperatorChain,\n-\t\t\ttaskName,\n-\t\t\tcloseableRegistry,\n-\t\t\texecutorService,\n-\t\t\tenv,\n-\t\t\tasyncExceptionHandler,\n-\t\t\tisCanceled);\n+\t\tlong startSyncPartNano = System.nanoTime();\n+\n+\t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress = new HashMap<>(operatorChain.getNumberOfOperators());\n+\t\ttry {\n+\t\t\tfor (StreamOperatorWrapper<?, ?> operatorWrapper : operatorChain.getAllOperators(true)) {\n+\t\t\t\tStreamOperator<?> op = operatorWrapper.getStreamOperator();\n+\t\t\t\tOperatorSnapshotFutures snapshotInProgress = checkpointStreamOperator(\n+\t\t\t\t\top,\n+\t\t\t\t\tcheckpointMetaData,\n+\t\t\t\t\tcheckpointOptions,\n+\t\t\t\t\tstorage,\n+\t\t\t\t\tisCanceled);\n+\t\t\t\toperatorSnapshotsInProgress.put(op.getOperatorID(), snapshotInProgress);\n+\t\t\t}\n+\n+\t\t\tif (LOG.isDebugEnabled()) {\n+\t\t\t\tLOG.debug(\"Finished synchronous checkpoints for checkpoint {} on task {}\",\n+\t\t\t\t\tcheckpointMetaData.getCheckpointId(), taskName);\n+\t\t\t}\n+\n+\t\t\tlong startAsyncPartNano = System.nanoTime();\n+\n+\t\t\tcheckpointMetrics.setSyncDurationMillis((startAsyncPartNano - startSyncPartNano) / 1_000_000);\n+\n+\t\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n+\t\t\texecutorService.execute(new AsyncCheckpointRunnable(\n+\t\t\t\toperatorSnapshotsInProgress,\n+\t\t\t\tcheckpointMetaData,\n+\t\t\t\tcheckpointMetrics,\n+\t\t\t\tstartAsyncPartNano,\n+\t\t\t\ttaskName,\n+\t\t\t\tcloseableRegistry,\n+\t\t\t\tenv,\n+\t\t\t\tasyncExceptionHandler));\n+\n+\t\t\tif (LOG.isDebugEnabled()) {\n+\t\t\t\tLOG.debug(\n+\t\t\t\t\t\"{} - finished synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n+\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n+\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n+\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n+\t\t\t}\n+\t\t} catch (Exception ex) {\n+\t\t\t// Cleanup to release resources\n+\t\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n+\t\t\t\tif (null != operatorSnapshotResult) {\n+\t\t\t\t\ttry {\n+\t\t\t\t\t\toperatorSnapshotResult.cancel();\n+\t\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\tif (LOG.isDebugEnabled()) {\n+\t\t\t\tLOG.debug(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ae7bd9f04b94f8c4810b3321df7729b11affeee4"}, "originalPosition": 106}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTk1NTMzOQ==", "bodyText": "I refactored a bit SubtaskCheckpointCoordinatorImpl while addressing one of the issues below and these messages ended up one after another; so removed one.", "url": "https://github.com/apache/flink/pull/11515#discussion_r401955339", "createdAt": "2020-04-01T22:50:23Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -89,17 +101,98 @@ public void checkpointState(\n \t\t\tcheckpointMetaData.getCheckpointId(),\n \t\t\tcheckpointOptions.getTargetLocation());\n \n-\t\tCheckpointingOperation.execute(\n-\t\t\tcheckpointMetaData,\n-\t\t\tcheckpointOptions,\n-\t\t\tcheckpointMetrics,\n-\t\t\tstorage,\n-\t\t\toperatorChain,\n-\t\t\ttaskName,\n-\t\t\tcloseableRegistry,\n-\t\t\texecutorService,\n-\t\t\tenv,\n-\t\t\tasyncExceptionHandler,\n-\t\t\tisCanceled);\n+\t\tlong startSyncPartNano = System.nanoTime();\n+\n+\t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress = new HashMap<>(operatorChain.getNumberOfOperators());\n+\t\ttry {\n+\t\t\tfor (StreamOperatorWrapper<?, ?> operatorWrapper : operatorChain.getAllOperators(true)) {\n+\t\t\t\tStreamOperator<?> op = operatorWrapper.getStreamOperator();\n+\t\t\t\tOperatorSnapshotFutures snapshotInProgress = checkpointStreamOperator(\n+\t\t\t\t\top,\n+\t\t\t\t\tcheckpointMetaData,\n+\t\t\t\t\tcheckpointOptions,\n+\t\t\t\t\tstorage,\n+\t\t\t\t\tisCanceled);\n+\t\t\t\toperatorSnapshotsInProgress.put(op.getOperatorID(), snapshotInProgress);\n+\t\t\t}\n+\n+\t\t\tif (LOG.isDebugEnabled()) {\n+\t\t\t\tLOG.debug(\"Finished synchronous checkpoints for checkpoint {} on task {}\",\n+\t\t\t\t\tcheckpointMetaData.getCheckpointId(), taskName);\n+\t\t\t}\n+\n+\t\t\tlong startAsyncPartNano = System.nanoTime();\n+\n+\t\t\tcheckpointMetrics.setSyncDurationMillis((startAsyncPartNano - startSyncPartNano) / 1_000_000);\n+\n+\t\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n+\t\t\texecutorService.execute(new AsyncCheckpointRunnable(\n+\t\t\t\toperatorSnapshotsInProgress,\n+\t\t\t\tcheckpointMetaData,\n+\t\t\t\tcheckpointMetrics,\n+\t\t\t\tstartAsyncPartNano,\n+\t\t\t\ttaskName,\n+\t\t\t\tcloseableRegistry,\n+\t\t\t\tenv,\n+\t\t\t\tasyncExceptionHandler));\n+\n+\t\t\tif (LOG.isDebugEnabled()) {\n+\t\t\t\tLOG.debug(\n+\t\t\t\t\t\"{} - finished synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n+\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n+\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n+\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n+\t\t\t}\n+\t\t} catch (Exception ex) {\n+\t\t\t// Cleanup to release resources\n+\t\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n+\t\t\t\tif (null != operatorSnapshotResult) {\n+\t\t\t\t\ttry {\n+\t\t\t\t\t\toperatorSnapshotResult.cancel();\n+\t\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\tif (LOG.isDebugEnabled()) {\n+\t\t\t\tLOG.debug(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM2NDAwOQ=="}, "originalCommit": {"oid": "ae7bd9f04b94f8c4810b3321df7729b11affeee4"}, "originalPosition": 106}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4OTE1MTUyOnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNTo0NToyOVrOF-xllg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQyMDoyMDoyNFrOF_RIMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM2ODQ3MA==", "bodyText": "nit: maybe warn instead of info and give some custom message to indicate which process causes the exception.", "url": "https://github.com/apache/flink/pull/11515#discussion_r401368470", "createdAt": "2020-04-01T05:45:29Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -89,17 +101,98 @@ public void checkpointState(\n \t\t\tcheckpointMetaData.getCheckpointId(),\n \t\t\tcheckpointOptions.getTargetLocation());\n \n-\t\tCheckpointingOperation.execute(\n-\t\t\tcheckpointMetaData,\n-\t\t\tcheckpointOptions,\n-\t\t\tcheckpointMetrics,\n-\t\t\tstorage,\n-\t\t\toperatorChain,\n-\t\t\ttaskName,\n-\t\t\tcloseableRegistry,\n-\t\t\texecutorService,\n-\t\t\tenv,\n-\t\t\tasyncExceptionHandler,\n-\t\t\tisCanceled);\n+\t\tlong startSyncPartNano = System.nanoTime();\n+\n+\t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress = new HashMap<>(operatorChain.getNumberOfOperators());\n+\t\ttry {\n+\t\t\tfor (StreamOperatorWrapper<?, ?> operatorWrapper : operatorChain.getAllOperators(true)) {\n+\t\t\t\tStreamOperator<?> op = operatorWrapper.getStreamOperator();\n+\t\t\t\tOperatorSnapshotFutures snapshotInProgress = checkpointStreamOperator(\n+\t\t\t\t\top,\n+\t\t\t\t\tcheckpointMetaData,\n+\t\t\t\t\tcheckpointOptions,\n+\t\t\t\t\tstorage,\n+\t\t\t\t\tisCanceled);\n+\t\t\t\toperatorSnapshotsInProgress.put(op.getOperatorID(), snapshotInProgress);\n+\t\t\t}\n+\n+\t\t\tif (LOG.isDebugEnabled()) {\n+\t\t\t\tLOG.debug(\"Finished synchronous checkpoints for checkpoint {} on task {}\",\n+\t\t\t\t\tcheckpointMetaData.getCheckpointId(), taskName);\n+\t\t\t}\n+\n+\t\t\tlong startAsyncPartNano = System.nanoTime();\n+\n+\t\t\tcheckpointMetrics.setSyncDurationMillis((startAsyncPartNano - startSyncPartNano) / 1_000_000);\n+\n+\t\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n+\t\t\texecutorService.execute(new AsyncCheckpointRunnable(\n+\t\t\t\toperatorSnapshotsInProgress,\n+\t\t\t\tcheckpointMetaData,\n+\t\t\t\tcheckpointMetrics,\n+\t\t\t\tstartAsyncPartNano,\n+\t\t\t\ttaskName,\n+\t\t\t\tcloseableRegistry,\n+\t\t\t\tenv,\n+\t\t\t\tasyncExceptionHandler));\n+\n+\t\t\tif (LOG.isDebugEnabled()) {\n+\t\t\t\tLOG.debug(\n+\t\t\t\t\t\"{} - finished synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n+\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n+\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n+\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n+\t\t\t}\n+\t\t} catch (Exception ex) {\n+\t\t\t// Cleanup to release resources\n+\t\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n+\t\t\t\tif (null != operatorSnapshotResult) {\n+\t\t\t\t\ttry {\n+\t\t\t\t\t\toperatorSnapshotResult.cancel();\n+\t\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\tif (LOG.isDebugEnabled()) {\n+\t\t\t\tLOG.debug(\n+\t\t\t\t\t\"{} - did NOT finish synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n+\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n+\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n+\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n+\t\t\t}\n+\n+\t\t\tif (checkpointOptions.getCheckpointType().isSynchronous()) {\n+\t\t\t\t// in the case of a synchronous checkpoint, we always rethrow the exception,\n+\t\t\t\t// so that the task fails.\n+\t\t\t\t// this is because the intention is always to stop the job after this checkpointing\n+\t\t\t\t// operation, and without the failure, the task would go back to normal execution.\n+\t\t\t\tthrow ex;\n+\t\t\t} else {\n+\t\t\t\tenv.declineCheckpoint(checkpointMetaData.getCheckpointId(), ex);\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate static OperatorSnapshotFutures checkpointStreamOperator(\n+\t\tStreamOperator<?> op,\n+\t\tCheckpointMetaData checkpointMetaData,\n+\t\tCheckpointOptions checkpointOptions,\n+\t\tCheckpointStreamFactory storageLocation,\n+\t\tSupplier<Boolean> isCanceled) throws Exception {\n+\t\ttry {\n+\t\t\treturn op.snapshotState(\n+\t\t\t\tcheckpointMetaData.getCheckpointId(),\n+\t\t\t\tcheckpointMetaData.getTimestamp(),\n+\t\t\t\tcheckpointOptions,\n+\t\t\t\tstorageLocation);\n+\t\t}\n+\t\tcatch (Exception ex) {\n+\t\t\tif (!isCanceled.get()) {\n+\t\t\t\tLOG.info(ex.getMessage(), ex);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ae7bd9f04b94f8c4810b3321df7729b11affeee4"}, "originalPosition": 140}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTg4NTIzMw==", "bodyText": "This change was introduced by another commit into CheckpointingOperation which I merged with SubtaskCheckpointCoordinatorImpl.\nAs I see from StreamOperatorStateHandler.snapshotState, the message is built like this:\nString snapshotFailMessage = \"Could not complete snapshot \" + checkpointId + \" for operator \" + operatorName + \".\";\n\nWhich I think provides enough details.\nNot sure, why do we log (info) and re-throw it, but I'd like not to address it in this PR.", "url": "https://github.com/apache/flink/pull/11515#discussion_r401885233", "createdAt": "2020-04-01T20:20:24Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -89,17 +101,98 @@ public void checkpointState(\n \t\t\tcheckpointMetaData.getCheckpointId(),\n \t\t\tcheckpointOptions.getTargetLocation());\n \n-\t\tCheckpointingOperation.execute(\n-\t\t\tcheckpointMetaData,\n-\t\t\tcheckpointOptions,\n-\t\t\tcheckpointMetrics,\n-\t\t\tstorage,\n-\t\t\toperatorChain,\n-\t\t\ttaskName,\n-\t\t\tcloseableRegistry,\n-\t\t\texecutorService,\n-\t\t\tenv,\n-\t\t\tasyncExceptionHandler,\n-\t\t\tisCanceled);\n+\t\tlong startSyncPartNano = System.nanoTime();\n+\n+\t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress = new HashMap<>(operatorChain.getNumberOfOperators());\n+\t\ttry {\n+\t\t\tfor (StreamOperatorWrapper<?, ?> operatorWrapper : operatorChain.getAllOperators(true)) {\n+\t\t\t\tStreamOperator<?> op = operatorWrapper.getStreamOperator();\n+\t\t\t\tOperatorSnapshotFutures snapshotInProgress = checkpointStreamOperator(\n+\t\t\t\t\top,\n+\t\t\t\t\tcheckpointMetaData,\n+\t\t\t\t\tcheckpointOptions,\n+\t\t\t\t\tstorage,\n+\t\t\t\t\tisCanceled);\n+\t\t\t\toperatorSnapshotsInProgress.put(op.getOperatorID(), snapshotInProgress);\n+\t\t\t}\n+\n+\t\t\tif (LOG.isDebugEnabled()) {\n+\t\t\t\tLOG.debug(\"Finished synchronous checkpoints for checkpoint {} on task {}\",\n+\t\t\t\t\tcheckpointMetaData.getCheckpointId(), taskName);\n+\t\t\t}\n+\n+\t\t\tlong startAsyncPartNano = System.nanoTime();\n+\n+\t\t\tcheckpointMetrics.setSyncDurationMillis((startAsyncPartNano - startSyncPartNano) / 1_000_000);\n+\n+\t\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n+\t\t\texecutorService.execute(new AsyncCheckpointRunnable(\n+\t\t\t\toperatorSnapshotsInProgress,\n+\t\t\t\tcheckpointMetaData,\n+\t\t\t\tcheckpointMetrics,\n+\t\t\t\tstartAsyncPartNano,\n+\t\t\t\ttaskName,\n+\t\t\t\tcloseableRegistry,\n+\t\t\t\tenv,\n+\t\t\t\tasyncExceptionHandler));\n+\n+\t\t\tif (LOG.isDebugEnabled()) {\n+\t\t\t\tLOG.debug(\n+\t\t\t\t\t\"{} - finished synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n+\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n+\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n+\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n+\t\t\t}\n+\t\t} catch (Exception ex) {\n+\t\t\t// Cleanup to release resources\n+\t\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n+\t\t\t\tif (null != operatorSnapshotResult) {\n+\t\t\t\t\ttry {\n+\t\t\t\t\t\toperatorSnapshotResult.cancel();\n+\t\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\tif (LOG.isDebugEnabled()) {\n+\t\t\t\tLOG.debug(\n+\t\t\t\t\t\"{} - did NOT finish synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n+\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n+\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n+\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n+\t\t\t}\n+\n+\t\t\tif (checkpointOptions.getCheckpointType().isSynchronous()) {\n+\t\t\t\t// in the case of a synchronous checkpoint, we always rethrow the exception,\n+\t\t\t\t// so that the task fails.\n+\t\t\t\t// this is because the intention is always to stop the job after this checkpointing\n+\t\t\t\t// operation, and without the failure, the task would go back to normal execution.\n+\t\t\t\tthrow ex;\n+\t\t\t} else {\n+\t\t\t\tenv.declineCheckpoint(checkpointMetaData.getCheckpointId(), ex);\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate static OperatorSnapshotFutures checkpointStreamOperator(\n+\t\tStreamOperator<?> op,\n+\t\tCheckpointMetaData checkpointMetaData,\n+\t\tCheckpointOptions checkpointOptions,\n+\t\tCheckpointStreamFactory storageLocation,\n+\t\tSupplier<Boolean> isCanceled) throws Exception {\n+\t\ttry {\n+\t\t\treturn op.snapshotState(\n+\t\t\t\tcheckpointMetaData.getCheckpointId(),\n+\t\t\t\tcheckpointMetaData.getTimestamp(),\n+\t\t\t\tcheckpointOptions,\n+\t\t\t\tstorageLocation);\n+\t\t}\n+\t\tcatch (Exception ex) {\n+\t\t\tif (!isCanceled.get()) {\n+\t\t\t\tLOG.info(ex.getMessage(), ex);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM2ODQ3MA=="}, "originalCommit": {"oid": "ae7bd9f04b94f8c4810b3321df7729b11affeee4"}, "originalPosition": 140}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4OTQzMjE3OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/state/TaskStateManagerImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNzozNToxN1rOF-0OBg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNzozNToxN1rOF-0OBg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQxMTU5MA==", "bodyText": "nit: indentation alignment", "url": "https://github.com/apache/flink/pull/11515#discussion_r401411590", "createdAt": "2020-04-01T07:35:17Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/state/TaskStateManagerImpl.java", "diffHunk": "@@ -68,18 +70,36 @@\n \t/** The checkpoint responder through which this manager can report to the job manager. */\n \tprivate final CheckpointResponder checkpointResponder;\n \n+\tprivate final ChannelStateReader channelStateReader;\n+\n \tpublic TaskStateManagerImpl(\n-\t\t@Nonnull JobID jobId,\n-\t\t@Nonnull ExecutionAttemptID executionAttemptID,\n-\t\t@Nonnull TaskLocalStateStore localStateStore,\n-\t\t@Nullable JobManagerTaskRestore jobManagerTaskRestore,\n-\t\t@Nonnull CheckpointResponder checkpointResponder) {\n+\t\t\t@Nonnull JobID jobId,\n+\t\t\t@Nonnull ExecutionAttemptID executionAttemptID,\n+\t\t\t@Nonnull TaskLocalStateStore localStateStore,\n+\t\t\t@Nullable JobManagerTaskRestore jobManagerTaskRestore,\n+\t\t\t@Nonnull CheckpointResponder checkpointResponder) {\n+\t\tthis(jobId,\n+\t\t\texecutionAttemptID,\n+\t\t\tlocalStateStore,\n+\t\t\tjobManagerTaskRestore,\n+\t\t\tcheckpointResponder,\n+\t\t\tnew ChannelStateReaderImpl(jobManagerTaskRestore == null ? new TaskStateSnapshot() : jobManagerTaskRestore.getTaskStateSnapshot())\n+\t\t);\n+\t}\n \n-\t\tthis.jobId = jobId;\n+\tTaskStateManagerImpl(\n+\t\t\t@Nonnull JobID jobId,\n+\t\t\t@Nonnull ExecutionAttemptID executionAttemptID,\n+\t\t\t@Nonnull TaskLocalStateStore localStateStore,\n+\t\t\t@Nullable JobManagerTaskRestore jobManagerTaskRestore,\n+\t\t\t@Nonnull CheckpointResponder checkpointResponder,\n+\t\t\t@Nonnull ChannelStateReader channelStateReader) {\n+\t\t\tthis.jobId = jobId;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 43}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4OTQ2NTYwOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/state/TaskStateManagerImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNzo0NDozM1rOF-0iLQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNzo0NDozM1rOF-0iLQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQxNjc0OQ==", "bodyText": "nit: also make this argument separate line", "url": "https://github.com/apache/flink/pull/11515#discussion_r401416749", "createdAt": "2020-04-01T07:44:33Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/state/TaskStateManagerImpl.java", "diffHunk": "@@ -68,18 +70,36 @@\n \t/** The checkpoint responder through which this manager can report to the job manager. */\n \tprivate final CheckpointResponder checkpointResponder;\n \n+\tprivate final ChannelStateReader channelStateReader;\n+\n \tpublic TaskStateManagerImpl(\n-\t\t@Nonnull JobID jobId,\n-\t\t@Nonnull ExecutionAttemptID executionAttemptID,\n-\t\t@Nonnull TaskLocalStateStore localStateStore,\n-\t\t@Nullable JobManagerTaskRestore jobManagerTaskRestore,\n-\t\t@Nonnull CheckpointResponder checkpointResponder) {\n+\t\t\t@Nonnull JobID jobId,\n+\t\t\t@Nonnull ExecutionAttemptID executionAttemptID,\n+\t\t\t@Nonnull TaskLocalStateStore localStateStore,\n+\t\t\t@Nullable JobManagerTaskRestore jobManagerTaskRestore,\n+\t\t\t@Nonnull CheckpointResponder checkpointResponder) {\n+\t\tthis(jobId,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4OTQ2ODU3OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/state/TaskStateManagerImpl.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNzo0NToyNVrOF-0kEQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNFQxNTo0NDo0NVrOGAyuOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQxNzIzMw==", "bodyText": "only need private atm", "url": "https://github.com/apache/flink/pull/11515#discussion_r401417233", "createdAt": "2020-04-01T07:45:25Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/state/TaskStateManagerImpl.java", "diffHunk": "@@ -68,18 +70,36 @@\n \t/** The checkpoint responder through which this manager can report to the job manager. */\n \tprivate final CheckpointResponder checkpointResponder;\n \n+\tprivate final ChannelStateReader channelStateReader;\n+\n \tpublic TaskStateManagerImpl(\n-\t\t@Nonnull JobID jobId,\n-\t\t@Nonnull ExecutionAttemptID executionAttemptID,\n-\t\t@Nonnull TaskLocalStateStore localStateStore,\n-\t\t@Nullable JobManagerTaskRestore jobManagerTaskRestore,\n-\t\t@Nonnull CheckpointResponder checkpointResponder) {\n+\t\t\t@Nonnull JobID jobId,\n+\t\t\t@Nonnull ExecutionAttemptID executionAttemptID,\n+\t\t\t@Nonnull TaskLocalStateStore localStateStore,\n+\t\t\t@Nullable JobManagerTaskRestore jobManagerTaskRestore,\n+\t\t\t@Nonnull CheckpointResponder checkpointResponder) {\n+\t\tthis(jobId,\n+\t\t\texecutionAttemptID,\n+\t\t\tlocalStateStore,\n+\t\t\tjobManagerTaskRestore,\n+\t\t\tcheckpointResponder,\n+\t\t\tnew ChannelStateReaderImpl(jobManagerTaskRestore == null ? new TaskStateSnapshot() : jobManagerTaskRestore.getTaskStateSnapshot())\n+\t\t);\n+\t}\n \n-\t\tthis.jobId = jobId;\n+\tTaskStateManagerImpl(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTg4Njg3Nw==", "bodyText": "It could be used in tests.", "url": "https://github.com/apache/flink/pull/11515#discussion_r401886877", "createdAt": "2020-04-01T20:23:24Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/state/TaskStateManagerImpl.java", "diffHunk": "@@ -68,18 +70,36 @@\n \t/** The checkpoint responder through which this manager can report to the job manager. */\n \tprivate final CheckpointResponder checkpointResponder;\n \n+\tprivate final ChannelStateReader channelStateReader;\n+\n \tpublic TaskStateManagerImpl(\n-\t\t@Nonnull JobID jobId,\n-\t\t@Nonnull ExecutionAttemptID executionAttemptID,\n-\t\t@Nonnull TaskLocalStateStore localStateStore,\n-\t\t@Nullable JobManagerTaskRestore jobManagerTaskRestore,\n-\t\t@Nonnull CheckpointResponder checkpointResponder) {\n+\t\t\t@Nonnull JobID jobId,\n+\t\t\t@Nonnull ExecutionAttemptID executionAttemptID,\n+\t\t\t@Nonnull TaskLocalStateStore localStateStore,\n+\t\t\t@Nullable JobManagerTaskRestore jobManagerTaskRestore,\n+\t\t\t@Nonnull CheckpointResponder checkpointResponder) {\n+\t\tthis(jobId,\n+\t\t\texecutionAttemptID,\n+\t\t\tlocalStateStore,\n+\t\t\tjobManagerTaskRestore,\n+\t\t\tcheckpointResponder,\n+\t\t\tnew ChannelStateReaderImpl(jobManagerTaskRestore == null ? new TaskStateSnapshot() : jobManagerTaskRestore.getTaskStateSnapshot())\n+\t\t);\n+\t}\n \n-\t\tthis.jobId = jobId;\n+\tTaskStateManagerImpl(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQxNzIzMw=="}, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQzNDE4NA==", "bodyText": "@VisibleForTesting", "url": "https://github.com/apache/flink/pull/11515#discussion_r402434184", "createdAt": "2020-04-02T16:09:40Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/state/TaskStateManagerImpl.java", "diffHunk": "@@ -68,18 +70,36 @@\n \t/** The checkpoint responder through which this manager can report to the job manager. */\n \tprivate final CheckpointResponder checkpointResponder;\n \n+\tprivate final ChannelStateReader channelStateReader;\n+\n \tpublic TaskStateManagerImpl(\n-\t\t@Nonnull JobID jobId,\n-\t\t@Nonnull ExecutionAttemptID executionAttemptID,\n-\t\t@Nonnull TaskLocalStateStore localStateStore,\n-\t\t@Nullable JobManagerTaskRestore jobManagerTaskRestore,\n-\t\t@Nonnull CheckpointResponder checkpointResponder) {\n+\t\t\t@Nonnull JobID jobId,\n+\t\t\t@Nonnull ExecutionAttemptID executionAttemptID,\n+\t\t\t@Nonnull TaskLocalStateStore localStateStore,\n+\t\t\t@Nullable JobManagerTaskRestore jobManagerTaskRestore,\n+\t\t\t@Nonnull CheckpointResponder checkpointResponder) {\n+\t\tthis(jobId,\n+\t\t\texecutionAttemptID,\n+\t\t\tlocalStateStore,\n+\t\t\tjobManagerTaskRestore,\n+\t\t\tcheckpointResponder,\n+\t\t\tnew ChannelStateReaderImpl(jobManagerTaskRestore == null ? new TaskStateSnapshot() : jobManagerTaskRestore.getTaskStateSnapshot())\n+\t\t);\n+\t}\n \n-\t\tthis.jobId = jobId;\n+\tTaskStateManagerImpl(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQxNzIzMw=="}, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjg1NzkyMQ==", "bodyText": "There is nothing wrong with using this constructor in production code too.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402857921", "createdAt": "2020-04-03T08:59:49Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/state/TaskStateManagerImpl.java", "diffHunk": "@@ -68,18 +70,36 @@\n \t/** The checkpoint responder through which this manager can report to the job manager. */\n \tprivate final CheckpointResponder checkpointResponder;\n \n+\tprivate final ChannelStateReader channelStateReader;\n+\n \tpublic TaskStateManagerImpl(\n-\t\t@Nonnull JobID jobId,\n-\t\t@Nonnull ExecutionAttemptID executionAttemptID,\n-\t\t@Nonnull TaskLocalStateStore localStateStore,\n-\t\t@Nullable JobManagerTaskRestore jobManagerTaskRestore,\n-\t\t@Nonnull CheckpointResponder checkpointResponder) {\n+\t\t\t@Nonnull JobID jobId,\n+\t\t\t@Nonnull ExecutionAttemptID executionAttemptID,\n+\t\t\t@Nonnull TaskLocalStateStore localStateStore,\n+\t\t\t@Nullable JobManagerTaskRestore jobManagerTaskRestore,\n+\t\t\t@Nonnull CheckpointResponder checkpointResponder) {\n+\t\tthis(jobId,\n+\t\t\texecutionAttemptID,\n+\t\t\tlocalStateStore,\n+\t\t\tjobManagerTaskRestore,\n+\t\t\tcheckpointResponder,\n+\t\t\tnew ChannelStateReaderImpl(jobManagerTaskRestore == null ? new TaskStateSnapshot() : jobManagerTaskRestore.getTaskStateSnapshot())\n+\t\t);\n+\t}\n \n-\t\tthis.jobId = jobId;\n+\tTaskStateManagerImpl(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQxNzIzMw=="}, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzQ4NDIxNg==", "bodyText": "Yes, I agree with your point to some extent. I think the key concern is how we define the access modifier based on two considerations.\n\n\nBased on current demands: if so, it should be private ATM, and then further extend it  by demands if necessary future.\n\n\nBased on future considerations: if so, it can be defined as package public now, even public.  But it is hard to say whether it is alway fitting the expectation, then it might seem unnecessary for long time. If taking this option, we might even remove @VisibleForTesting annotation for previous usages, because any constructors might have the possibility to be used in core codes future.\n\n\nAnyway, I can accept both options and do not think it is a big issue. Just share some thoughts, feel free to take for your favor. :)", "url": "https://github.com/apache/flink/pull/11515#discussion_r403484216", "createdAt": "2020-04-04T15:44:45Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/state/TaskStateManagerImpl.java", "diffHunk": "@@ -68,18 +70,36 @@\n \t/** The checkpoint responder through which this manager can report to the job manager. */\n \tprivate final CheckpointResponder checkpointResponder;\n \n+\tprivate final ChannelStateReader channelStateReader;\n+\n \tpublic TaskStateManagerImpl(\n-\t\t@Nonnull JobID jobId,\n-\t\t@Nonnull ExecutionAttemptID executionAttemptID,\n-\t\t@Nonnull TaskLocalStateStore localStateStore,\n-\t\t@Nullable JobManagerTaskRestore jobManagerTaskRestore,\n-\t\t@Nonnull CheckpointResponder checkpointResponder) {\n+\t\t\t@Nonnull JobID jobId,\n+\t\t\t@Nonnull ExecutionAttemptID executionAttemptID,\n+\t\t\t@Nonnull TaskLocalStateStore localStateStore,\n+\t\t\t@Nullable JobManagerTaskRestore jobManagerTaskRestore,\n+\t\t\t@Nonnull CheckpointResponder checkpointResponder) {\n+\t\tthis(jobId,\n+\t\t\texecutionAttemptID,\n+\t\t\tlocalStateStore,\n+\t\t\tjobManagerTaskRestore,\n+\t\t\tcheckpointResponder,\n+\t\t\tnew ChannelStateReaderImpl(jobManagerTaskRestore == null ? new TaskStateSnapshot() : jobManagerTaskRestore.getTaskStateSnapshot())\n+\t\t);\n+\t}\n \n-\t\tthis.jobId = jobId;\n+\tTaskStateManagerImpl(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQxNzIzMw=="}, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 36}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4OTUwNTMxOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/taskmanager/Task.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNzo1NjowNlrOF-06mA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wM1QxNDo0MDoyNFrOGAYcdg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQyMzAwMA==", "bodyText": "The precious consideration of closing network resources early is done by canceler thread, which would throw exception while task thread interacts with buffer operation to make task exit ASAP. If we add the state manager close here, does it have the same effect to throw any exceptions while interacting with task thread?", "url": "https://github.com/apache/flink/pull/11515#discussion_r401423000", "createdAt": "2020-04-01T07:56:06Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/taskmanager/Task.java", "diffHunk": "@@ -914,6 +914,11 @@ private void closeNetworkResources() {\n \t\t\t\tLOG.error(\"Failed to release input gate for task {}.\", taskNameWithSubtask, t);\n \t\t\t}\n \t\t}\n+\t\ttry {\n+\t\t\ttaskStateManager.close();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTg5MjA4Mw==", "bodyText": "I don't fully understand your concerns, could you explain what are they?\nOn close, taskStateManager will close all opened input streams (without waiting for the task thread).", "url": "https://github.com/apache/flink/pull/11515#discussion_r401892083", "createdAt": "2020-04-01T20:33:22Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/taskmanager/Task.java", "diffHunk": "@@ -914,6 +914,11 @@ private void closeNetworkResources() {\n \t\t\t\tLOG.error(\"Failed to release input gate for task {}.\", taskNameWithSubtask, t);\n \t\t\t}\n \t\t}\n+\t\ttry {\n+\t\t\ttaskStateManager.close();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQyMzAwMA=="}, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQzNzQ3NQ==", "bodyText": "The previous closeNetworkResources can be used in two scenarios, one is for task exit in finally region, another is used by canceler thread before task exiting. The motivation to close network resource by canceler thread is to release the buffers ASAP, then the task thread can cause exception while interacting with buffer to make it exit early.\nIf the close of taskStateManager does not have the effect to make task thread exit early, then it should not be called by canceler thread, and it only needs to be called in task thread finally region.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402437475", "createdAt": "2020-04-02T16:14:20Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/taskmanager/Task.java", "diffHunk": "@@ -914,6 +914,11 @@ private void closeNetworkResources() {\n \t\t\t\tLOG.error(\"Failed to release input gate for task {}.\", taskNameWithSubtask, t);\n \t\t\t}\n \t\t}\n+\t\ttry {\n+\t\t\ttaskStateManager.close();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQyMzAwMA=="}, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzA1MzY4Ng==", "bodyText": "Thanks for the explanation.\nI will move taskStateManager.close() to releaseResources() which is called from doRun and not task canceller.", "url": "https://github.com/apache/flink/pull/11515#discussion_r403053686", "createdAt": "2020-04-03T14:40:24Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/taskmanager/Task.java", "diffHunk": "@@ -914,6 +914,11 @@ private void closeNetworkResources() {\n \t\t\t\tLOG.error(\"Failed to release input gate for task {}.\", taskNameWithSubtask, t);\n \t\t\t}\n \t\t}\n+\t\ttry {\n+\t\t\ttaskStateManager.close();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQyMzAwMA=="}, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 40}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4OTUwNjI3OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/taskmanager/Task.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNzo1NjoyMlrOF-07Lw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNzo1NjoyMlrOF-07Lw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQyMzE1MQ==", "bodyText": "also adjust the respective javadoc", "url": "https://github.com/apache/flink/pull/11515#discussion_r401423151", "createdAt": "2020-04-01T07:56:22Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/taskmanager/Task.java", "diffHunk": "@@ -889,14 +889,14 @@ private void releaseNetworkResources() {\n \t\t\t}\n \t\t}\n \n-\t\tcloseNetworkResources();\n+\t\tcloseResources();\n \t}\n \n \t/**\n \t * There are two scenarios to close the network resources. One is from {@link TaskCanceler} to early", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 27}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4OTUxOTA4OnYy", "diffSide": "LEFT", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/state/TestTaskStateManager.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNzo1OTo0OVrOF-1DKA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wM1QxNDo1NTo0NVrOGAZHOw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQyNTE5Mg==", "bodyText": "unrelated change", "url": "https://github.com/apache/flink/pull/11515#discussion_r401425192", "createdAt": "2020-04-01T07:59:49Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/state/TestTaskStateManager.java", "diffHunk": "@@ -94,7 +95,6 @@ public void reportTaskStateSnapshots(\n \t\t@Nullable TaskStateSnapshot acknowledgedState,\n \t\t@Nullable TaskStateSnapshot localState) {\n \n-", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTg5NTU0MQ==", "bodyText": "Do you mean it should go to a separate commit or PR?\nI'd rather choose a cleaner git/PR history.", "url": "https://github.com/apache/flink/pull/11515#discussion_r401895541", "createdAt": "2020-04-01T20:39:59Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/state/TestTaskStateManager.java", "diffHunk": "@@ -94,7 +95,6 @@ public void reportTaskStateSnapshots(\n \t\t@Nullable TaskStateSnapshot acknowledgedState,\n \t\t@Nullable TaskStateSnapshot localState) {\n \n-", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQyNTE5Mg=="}, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQ0MjAwMw==", "bodyText": "To be strict, any unrelated formatting change should be a separate hotfix commit, not need a separate PR, can commit separately in this PR.\nBecause I was also told the same issue multiple times by other committers when submitting PR in the early period. So I just mention it, it is not mandatory from my side. :)", "url": "https://github.com/apache/flink/pull/11515#discussion_r402442003", "createdAt": "2020-04-02T16:21:14Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/state/TestTaskStateManager.java", "diffHunk": "@@ -94,7 +95,6 @@ public void reportTaskStateSnapshots(\n \t\t@Nullable TaskStateSnapshot acknowledgedState,\n \t\t@Nullable TaskStateSnapshot localState) {\n \n-", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQyNTE5Mg=="}, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzA2NDYzNQ==", "bodyText": "I understand. Extracted into a separate commit.", "url": "https://github.com/apache/flink/pull/11515#discussion_r403064635", "createdAt": "2020-04-03T14:55:45Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/state/TestTaskStateManager.java", "diffHunk": "@@ -94,7 +95,6 @@ public void reportTaskStateSnapshots(\n \t\t@Nullable TaskStateSnapshot acknowledgedState,\n \t\t@Nullable TaskStateSnapshot localState) {\n \n-", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQyNTE5Mg=="}, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4OTUyNzA1OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/OperatorChain.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwODowMjoyNVrOF-1IRQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwODowMjoyNVrOF-1IRQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQyNjUwMQ==", "bodyText": "nit: @nullable", "url": "https://github.com/apache/flink/pull/11515#discussion_r401426501", "createdAt": "2020-04-01T08:02:25Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/OperatorChain.java", "diffHunk": "@@ -544,6 +544,10 @@ private void linkOperatorWrappers(List<StreamOperatorWrapper<?, ?>> allOperatorW\n \t\t\tcontainingTask.getMailboxExecutorFactory().createExecutor(operatorConfig.getChainIndex()));\n \t}\n \n+\tStreamOperator<?> getTailOperator() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4OTU3OTM0OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwODoxNjo0MFrOF-1oKA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQyMDo0MjowOFrOF_R0zw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQzNDY2NA==", "bodyText": "should register this after it is constructed completely?", "url": "https://github.com/apache/flink/pull/11515#discussion_r401434664", "createdAt": "2020-04-01T08:16:40Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -21,53 +21,79 @@\n import org.apache.flink.runtime.checkpoint.CheckpointMetaData;\n import org.apache.flink.runtime.checkpoint.CheckpointMetrics;\n import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.StateObjectCollection;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriterImpl;\n import org.apache.flink.runtime.execution.Environment;\n import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.CheckpointStorageLocationReference;\n import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.SnapshotResult;\n import org.apache.flink.streaming.api.operators.OperatorSnapshotFutures;\n import org.apache.flink.streaming.api.operators.StreamOperator;\n+import org.apache.flink.util.WrappingRuntimeException;\n \n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import java.io.IOException;\n import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n import java.util.concurrent.ExecutorService;\n import java.util.function.Supplier;\n \n+import static org.apache.flink.runtime.checkpoint.CheckpointType.CHECKPOINT;\n import static org.apache.flink.util.Preconditions.checkNotNull;\n \n class SubtaskCheckpointCoordinatorImpl implements SubtaskCheckpointCoordinator {\n \n \tprivate static final Logger LOG = LoggerFactory.getLogger(SubtaskCheckpointCoordinatorImpl.class);\n \n-\tprivate final CheckpointStorageWorkerView checkpointStorage;\n+\tprivate final CachingCheckpointStorageWorkerView checkpointStorage;\n \tprivate final String taskName;\n \tprivate final CloseableRegistry closeableRegistry;\n \tprivate final ExecutorService executorService;\n \tprivate final Environment env;\n \tprivate final AsyncExceptionHandler asyncExceptionHandler;\n+\tprivate final ChannelStateWriter channelStateWriter;\n \n \tSubtaskCheckpointCoordinatorImpl(\n-\t\tCheckpointStorageWorkerView checkpointStorage,\n-\t\tString taskName,\n-\t\tCloseableRegistry closeableRegistry,\n-\t\tExecutorService executorService,\n-\t\tEnvironment env,\n-\t\tAsyncExceptionHandler asyncExceptionHandler) {\n-\t\tthis.checkpointStorage = checkNotNull(checkpointStorage);\n+\t\t\tCheckpointStorageWorkerView checkpointStorage,\n+\t\t\tString taskName,\n+\t\t\tCloseableRegistry closeableRegistry,\n+\t\t\tExecutorService executorService,\n+\t\t\tEnvironment env,\n+\t\t\tAsyncExceptionHandler asyncExceptionHandler,\n+\t\t\tboolean sendChannelState) throws IOException {\n+\t\tthis.checkpointStorage = new CachingCheckpointStorageWorkerView(checkNotNull(checkpointStorage));\n \t\tthis.taskName = checkNotNull(taskName);\n \t\tthis.closeableRegistry = checkNotNull(closeableRegistry);\n \t\tthis.executorService = checkNotNull(executorService);\n \t\tthis.env = checkNotNull(env);\n \t\tthis.asyncExceptionHandler = checkNotNull(asyncExceptionHandler);\n+\t\tthis.closeableRegistry.registerCloseable(this);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTg5NjY1NQ==", "bodyText": "Agree, will move to the end of the constructor.", "url": "https://github.com/apache/flink/pull/11515#discussion_r401896655", "createdAt": "2020-04-01T20:42:08Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -21,53 +21,79 @@\n import org.apache.flink.runtime.checkpoint.CheckpointMetaData;\n import org.apache.flink.runtime.checkpoint.CheckpointMetrics;\n import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.StateObjectCollection;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriterImpl;\n import org.apache.flink.runtime.execution.Environment;\n import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.CheckpointStorageLocationReference;\n import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.SnapshotResult;\n import org.apache.flink.streaming.api.operators.OperatorSnapshotFutures;\n import org.apache.flink.streaming.api.operators.StreamOperator;\n+import org.apache.flink.util.WrappingRuntimeException;\n \n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import java.io.IOException;\n import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n import java.util.concurrent.ExecutorService;\n import java.util.function.Supplier;\n \n+import static org.apache.flink.runtime.checkpoint.CheckpointType.CHECKPOINT;\n import static org.apache.flink.util.Preconditions.checkNotNull;\n \n class SubtaskCheckpointCoordinatorImpl implements SubtaskCheckpointCoordinator {\n \n \tprivate static final Logger LOG = LoggerFactory.getLogger(SubtaskCheckpointCoordinatorImpl.class);\n \n-\tprivate final CheckpointStorageWorkerView checkpointStorage;\n+\tprivate final CachingCheckpointStorageWorkerView checkpointStorage;\n \tprivate final String taskName;\n \tprivate final CloseableRegistry closeableRegistry;\n \tprivate final ExecutorService executorService;\n \tprivate final Environment env;\n \tprivate final AsyncExceptionHandler asyncExceptionHandler;\n+\tprivate final ChannelStateWriter channelStateWriter;\n \n \tSubtaskCheckpointCoordinatorImpl(\n-\t\tCheckpointStorageWorkerView checkpointStorage,\n-\t\tString taskName,\n-\t\tCloseableRegistry closeableRegistry,\n-\t\tExecutorService executorService,\n-\t\tEnvironment env,\n-\t\tAsyncExceptionHandler asyncExceptionHandler) {\n-\t\tthis.checkpointStorage = checkNotNull(checkpointStorage);\n+\t\t\tCheckpointStorageWorkerView checkpointStorage,\n+\t\t\tString taskName,\n+\t\t\tCloseableRegistry closeableRegistry,\n+\t\t\tExecutorService executorService,\n+\t\t\tEnvironment env,\n+\t\t\tAsyncExceptionHandler asyncExceptionHandler,\n+\t\t\tboolean sendChannelState) throws IOException {\n+\t\tthis.checkpointStorage = new CachingCheckpointStorageWorkerView(checkNotNull(checkpointStorage));\n \t\tthis.taskName = checkNotNull(taskName);\n \t\tthis.closeableRegistry = checkNotNull(closeableRegistry);\n \t\tthis.executorService = checkNotNull(executorService);\n \t\tthis.env = checkNotNull(env);\n \t\tthis.asyncExceptionHandler = checkNotNull(asyncExceptionHandler);\n+\t\tthis.closeableRegistry.registerCloseable(this);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQzNDY2NA=="}, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 65}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5MDAyMTAwOnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxMDoxMzoyMlrOF-584w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNFQxNTo0ODoxNVrOGAyvcg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTUwNTUwNw==", "bodyText": "The proper javadoc format for class should be\n/**\n*\n**/", "url": "https://github.com/apache/flink/pull/11515#discussion_r401505507", "createdAt": "2020-04-01T10:13:22Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -175,6 +203,77 @@ public void checkpointState(\n \t\t}\n \t}\n \n+\tprivate OperatorSnapshotFutures buildOperatorSnapshotFutures(\n+\t\t\tCheckpointMetaData checkpointMetaData,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tOperatorChain<?, ?> operatorChain,\n+\t\t\tStreamOperator<?> op,\n+\t\t\tSupplier<Boolean> isCanceled,\n+\t\t\tChannelStateWriteResult channelStateWriteResult) throws Exception {\n+\t\tCheckpointStreamFactory storage = checkpointStorage.resolveCheckpointStorageLocation(\n+\t\t\tcheckpointMetaData.getCheckpointId(),\n+\t\t\tcheckpointOptions.getTargetLocation());\n+\t\tOperatorSnapshotFutures snapshotInProgress = checkpointStreamOperator(\n+\t\t\top,\n+\t\t\tcheckpointMetaData,\n+\t\t\tcheckpointOptions,\n+\t\t\tstorage,\n+\t\t\tisCanceled);\n+\t\tif (op == operatorChain.getHeadOperator()) {\n+\t\t\tsnapshotInProgress.setInputChannelStateFuture(channelStateWriteResult\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.getInputChannelStateHandles()\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(StateObjectCollection::new)\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(SnapshotResult::of)\n+\t\t\t);\n+\t\t}\n+\t\tif (op == operatorChain.getTailOperator()) {\n+\t\t\tsnapshotInProgress.setResultSubpartitionStateFuture(channelStateWriteResult\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.getResultSubpartitionStateHandles()\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(StateObjectCollection::new)\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(SnapshotResult::of)\n+\t\t\t);\n+\t\t}\n+\t\treturn snapshotInProgress;\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tchannelStateWriter.close();\n+\t}\n+\n+\t// Caches checkpoint output stream factories to prevent multiple output stream per checkpoint.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 169}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTg5OTEzNg==", "bodyText": "This is not a javadoc but rather description of SubtaskCheckpointCoordinatorImpl inner workings. I can make it javadoc if you prefer though.", "url": "https://github.com/apache/flink/pull/11515#discussion_r401899136", "createdAt": "2020-04-01T20:46:50Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -175,6 +203,77 @@ public void checkpointState(\n \t\t}\n \t}\n \n+\tprivate OperatorSnapshotFutures buildOperatorSnapshotFutures(\n+\t\t\tCheckpointMetaData checkpointMetaData,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tOperatorChain<?, ?> operatorChain,\n+\t\t\tStreamOperator<?> op,\n+\t\t\tSupplier<Boolean> isCanceled,\n+\t\t\tChannelStateWriteResult channelStateWriteResult) throws Exception {\n+\t\tCheckpointStreamFactory storage = checkpointStorage.resolveCheckpointStorageLocation(\n+\t\t\tcheckpointMetaData.getCheckpointId(),\n+\t\t\tcheckpointOptions.getTargetLocation());\n+\t\tOperatorSnapshotFutures snapshotInProgress = checkpointStreamOperator(\n+\t\t\top,\n+\t\t\tcheckpointMetaData,\n+\t\t\tcheckpointOptions,\n+\t\t\tstorage,\n+\t\t\tisCanceled);\n+\t\tif (op == operatorChain.getHeadOperator()) {\n+\t\t\tsnapshotInProgress.setInputChannelStateFuture(channelStateWriteResult\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.getInputChannelStateHandles()\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(StateObjectCollection::new)\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(SnapshotResult::of)\n+\t\t\t);\n+\t\t}\n+\t\tif (op == operatorChain.getTailOperator()) {\n+\t\t\tsnapshotInProgress.setResultSubpartitionStateFuture(channelStateWriteResult\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.getResultSubpartitionStateHandles()\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(StateObjectCollection::new)\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(SnapshotResult::of)\n+\t\t\t);\n+\t\t}\n+\t\treturn snapshotInProgress;\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tchannelStateWriter.close();\n+\t}\n+\n+\t// Caches checkpoint output stream factories to prevent multiple output stream per checkpoint.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTUwNTUwNw=="}, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 169}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzQ4NDUzMA==", "bodyText": "I am not forcing that, it is up to you. Only saw that most of descriptions for class scope prefers to using above, and // is almost used in inline codes, /** */ is for class fields.", "url": "https://github.com/apache/flink/pull/11515#discussion_r403484530", "createdAt": "2020-04-04T15:48:15Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -175,6 +203,77 @@ public void checkpointState(\n \t\t}\n \t}\n \n+\tprivate OperatorSnapshotFutures buildOperatorSnapshotFutures(\n+\t\t\tCheckpointMetaData checkpointMetaData,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tOperatorChain<?, ?> operatorChain,\n+\t\t\tStreamOperator<?> op,\n+\t\t\tSupplier<Boolean> isCanceled,\n+\t\t\tChannelStateWriteResult channelStateWriteResult) throws Exception {\n+\t\tCheckpointStreamFactory storage = checkpointStorage.resolveCheckpointStorageLocation(\n+\t\t\tcheckpointMetaData.getCheckpointId(),\n+\t\t\tcheckpointOptions.getTargetLocation());\n+\t\tOperatorSnapshotFutures snapshotInProgress = checkpointStreamOperator(\n+\t\t\top,\n+\t\t\tcheckpointMetaData,\n+\t\t\tcheckpointOptions,\n+\t\t\tstorage,\n+\t\t\tisCanceled);\n+\t\tif (op == operatorChain.getHeadOperator()) {\n+\t\t\tsnapshotInProgress.setInputChannelStateFuture(channelStateWriteResult\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.getInputChannelStateHandles()\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(StateObjectCollection::new)\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(SnapshotResult::of)\n+\t\t\t);\n+\t\t}\n+\t\tif (op == operatorChain.getTailOperator()) {\n+\t\t\tsnapshotInProgress.setResultSubpartitionStateFuture(channelStateWriteResult\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.getResultSubpartitionStateHandles()\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(StateObjectCollection::new)\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(SnapshotResult::of)\n+\t\t\t);\n+\t\t}\n+\t\treturn snapshotInProgress;\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tchannelStateWriter.close();\n+\t}\n+\n+\t// Caches checkpoint output stream factories to prevent multiple output stream per checkpoint.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTUwNTUwNw=="}, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 169}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5MDA0MTIyOnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxMDoxOTowMlrOF-6Jkg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxMDoxOTowMlrOF-6Jkg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTUwODc1NA==", "bodyText": "maybe better formatting as follow\nChannelStateWriteResult channelStateWriteResult = checkpointOptions.getCheckpointType() == CHECKPOINT ?\n\t\t\tchannelStateWriter.getWriteResult(checkpointMetaData.getCheckpointId()) :\n\t\t\tChannelStateWriteResult.EMPTY;", "url": "https://github.com/apache/flink/pull/11515#discussion_r401508754", "createdAt": "2020-04-01T10:19:02Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -97,24 +123,26 @@ public void checkpointState(\n \t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not\n \t\t//           impact progress of the streaming topology\n \n-\t\tCheckpointStreamFactory storage = checkpointStorage.resolveCheckpointStorageLocation(\n-\t\t\tcheckpointMetaData.getCheckpointId(),\n-\t\t\tcheckpointOptions.getTargetLocation());\n-\n \t\tlong startSyncPartNano = System.nanoTime();\n \n \t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress = new HashMap<>(operatorChain.getNumberOfOperators());\n+\t\tChannelStateWriteResult channelStateWriteResult =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 99}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5MDEwNjUwOnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxMDozNzozOFrOF-6xww==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQyMDo1MTozMlrOF_SH0Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTUxOTA0Mw==", "bodyText": "should we add some TODO before getWriteResult, otherwise it seems hard to understand from this commit that we actually have not written anything before get the result.", "url": "https://github.com/apache/flink/pull/11515#discussion_r401519043", "createdAt": "2020-04-01T10:37:38Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -97,24 +123,26 @@ public void checkpointState(\n \t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not\n \t\t//           impact progress of the streaming topology\n \n-\t\tCheckpointStreamFactory storage = checkpointStorage.resolveCheckpointStorageLocation(\n-\t\t\tcheckpointMetaData.getCheckpointId(),\n-\t\t\tcheckpointOptions.getTargetLocation());\n-\n \t\tlong startSyncPartNano = System.nanoTime();\n \n \t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress = new HashMap<>(operatorChain.getNumberOfOperators());\n+\t\tChannelStateWriteResult channelStateWriteResult =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 99}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTkwMTUyMQ==", "bodyText": "There is todo in StreamTask near SubtaskCheckpointCoordinatorImpl constructor:\nfalse); // todo: pass true if unaligned checkpoints enabled\n\n(I expect the exact type of this option could change)", "url": "https://github.com/apache/flink/pull/11515#discussion_r401901521", "createdAt": "2020-04-01T20:51:32Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -97,24 +123,26 @@ public void checkpointState(\n \t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not\n \t\t//           impact progress of the streaming topology\n \n-\t\tCheckpointStreamFactory storage = checkpointStorage.resolveCheckpointStorageLocation(\n-\t\t\tcheckpointMetaData.getCheckpointId(),\n-\t\t\tcheckpointOptions.getTargetLocation());\n-\n \t\tlong startSyncPartNano = System.nanoTime();\n \n \t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress = new HashMap<>(operatorChain.getNumberOfOperators());\n+\t\tChannelStateWriteResult channelStateWriteResult =", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTUxOTA0Mw=="}, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 99}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5MDE1NDEzOnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxMDo1MjoyOFrOF-7P8w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxMTo1MjowNFrOGB_5eQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTUyNjc3MQ==", "bodyText": "WrappingRuntimeException is used for wrapping non-runtime exceptions? I guess this should belong to runtime exception. Another option without wrapping exception is not using lambda way to throw IOException explicitly in the method resolveCheckpointStorageLocation", "url": "https://github.com/apache/flink/pull/11515#discussion_r401526771", "createdAt": "2020-04-01T10:52:28Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -175,6 +203,77 @@ public void checkpointState(\n \t\t}\n \t}\n \n+\tprivate OperatorSnapshotFutures buildOperatorSnapshotFutures(\n+\t\t\tCheckpointMetaData checkpointMetaData,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tOperatorChain<?, ?> operatorChain,\n+\t\t\tStreamOperator<?> op,\n+\t\t\tSupplier<Boolean> isCanceled,\n+\t\t\tChannelStateWriteResult channelStateWriteResult) throws Exception {\n+\t\tCheckpointStreamFactory storage = checkpointStorage.resolveCheckpointStorageLocation(\n+\t\t\tcheckpointMetaData.getCheckpointId(),\n+\t\t\tcheckpointOptions.getTargetLocation());\n+\t\tOperatorSnapshotFutures snapshotInProgress = checkpointStreamOperator(\n+\t\t\top,\n+\t\t\tcheckpointMetaData,\n+\t\t\tcheckpointOptions,\n+\t\t\tstorage,\n+\t\t\tisCanceled);\n+\t\tif (op == operatorChain.getHeadOperator()) {\n+\t\t\tsnapshotInProgress.setInputChannelStateFuture(channelStateWriteResult\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.getInputChannelStateHandles()\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(StateObjectCollection::new)\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(SnapshotResult::of)\n+\t\t\t);\n+\t\t}\n+\t\tif (op == operatorChain.getTailOperator()) {\n+\t\t\tsnapshotInProgress.setResultSubpartitionStateFuture(channelStateWriteResult\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.getResultSubpartitionStateHandles()\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(StateObjectCollection::new)\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(SnapshotResult::of)\n+\t\t\t);\n+\t\t}\n+\t\treturn snapshotInProgress;\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tchannelStateWriter.close();\n+\t}\n+\n+\t// Caches checkpoint output stream factories to prevent multiple output stream per checkpoint.\n+\t// This could result from requesting output stream by different entities (this and channelStateWriter)\n+\t// We can't just pass a stream to the channelStateWriter because it can receive checkpoint call earlier than this class\n+\t// in some unaligned checkpoints scenarios\n+\tprivate static class CachingCheckpointStorageWorkerView implements CheckpointStorageWorkerView {\n+\t\tprivate final Map<Long, CheckpointStreamFactory> cache = new ConcurrentHashMap<>();\n+\t\tprivate final CheckpointStorageWorkerView delegate;\n+\n+\t\tprivate CachingCheckpointStorageWorkerView(CheckpointStorageWorkerView delegate) {\n+\t\t\tthis.delegate = delegate;\n+\t\t}\n+\n+\t\tvoid clearCacheFor(long checkpointId) {\n+\t\t\tcache.remove(checkpointId);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic CheckpointStreamFactory resolveCheckpointStorageLocation(long checkpointId, CheckpointStorageLocationReference reference) {\n+\t\t\treturn cache.computeIfAbsent(checkpointId, id -> {\n+\t\t\t\ttry {\n+\t\t\t\t\treturn delegate.resolveCheckpointStorageLocation(checkpointId, reference);\n+\t\t\t\t} catch (IOException e) {\n+\t\t\t\t\tthrow new WrappingRuntimeException(e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 191}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTkwMjk1MQ==", "bodyText": "Yes, I think this is the very purpose of WrappingRuntimeException:\n/**\n * A runtime exception that is explicitly used to wrap non-runtime exceptions.\n\nOr did I misunderstand something?", "url": "https://github.com/apache/flink/pull/11515#discussion_r401902951", "createdAt": "2020-04-01T20:54:13Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -175,6 +203,77 @@ public void checkpointState(\n \t\t}\n \t}\n \n+\tprivate OperatorSnapshotFutures buildOperatorSnapshotFutures(\n+\t\t\tCheckpointMetaData checkpointMetaData,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tOperatorChain<?, ?> operatorChain,\n+\t\t\tStreamOperator<?> op,\n+\t\t\tSupplier<Boolean> isCanceled,\n+\t\t\tChannelStateWriteResult channelStateWriteResult) throws Exception {\n+\t\tCheckpointStreamFactory storage = checkpointStorage.resolveCheckpointStorageLocation(\n+\t\t\tcheckpointMetaData.getCheckpointId(),\n+\t\t\tcheckpointOptions.getTargetLocation());\n+\t\tOperatorSnapshotFutures snapshotInProgress = checkpointStreamOperator(\n+\t\t\top,\n+\t\t\tcheckpointMetaData,\n+\t\t\tcheckpointOptions,\n+\t\t\tstorage,\n+\t\t\tisCanceled);\n+\t\tif (op == operatorChain.getHeadOperator()) {\n+\t\t\tsnapshotInProgress.setInputChannelStateFuture(channelStateWriteResult\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.getInputChannelStateHandles()\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(StateObjectCollection::new)\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(SnapshotResult::of)\n+\t\t\t);\n+\t\t}\n+\t\tif (op == operatorChain.getTailOperator()) {\n+\t\t\tsnapshotInProgress.setResultSubpartitionStateFuture(channelStateWriteResult\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.getResultSubpartitionStateHandles()\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(StateObjectCollection::new)\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(SnapshotResult::of)\n+\t\t\t);\n+\t\t}\n+\t\treturn snapshotInProgress;\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tchannelStateWriter.close();\n+\t}\n+\n+\t// Caches checkpoint output stream factories to prevent multiple output stream per checkpoint.\n+\t// This could result from requesting output stream by different entities (this and channelStateWriter)\n+\t// We can't just pass a stream to the channelStateWriter because it can receive checkpoint call earlier than this class\n+\t// in some unaligned checkpoints scenarios\n+\tprivate static class CachingCheckpointStorageWorkerView implements CheckpointStorageWorkerView {\n+\t\tprivate final Map<Long, CheckpointStreamFactory> cache = new ConcurrentHashMap<>();\n+\t\tprivate final CheckpointStorageWorkerView delegate;\n+\n+\t\tprivate CachingCheckpointStorageWorkerView(CheckpointStorageWorkerView delegate) {\n+\t\t\tthis.delegate = delegate;\n+\t\t}\n+\n+\t\tvoid clearCacheFor(long checkpointId) {\n+\t\t\tcache.remove(checkpointId);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic CheckpointStreamFactory resolveCheckpointStorageLocation(long checkpointId, CheckpointStorageLocationReference reference) {\n+\t\t\treturn cache.computeIfAbsent(checkpointId, id -> {\n+\t\t\t\ttry {\n+\t\t\t\t\treturn delegate.resolveCheckpointStorageLocation(checkpointId, reference);\n+\t\t\t\t} catch (IOException e) {\n+\t\t\t\t\tthrow new WrappingRuntimeException(e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTUyNjc3MQ=="}, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 191}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcyMTU0NA==", "bodyText": "Sorry for misleading. Some concerns are the same as #11515 (comment), and another tiny concern is why not use FlinkRuntimeException directly? I have not found any special purpose for WrappingRuntimeException.", "url": "https://github.com/apache/flink/pull/11515#discussion_r403721544", "createdAt": "2020-04-05T16:05:04Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -175,6 +203,77 @@ public void checkpointState(\n \t\t}\n \t}\n \n+\tprivate OperatorSnapshotFutures buildOperatorSnapshotFutures(\n+\t\t\tCheckpointMetaData checkpointMetaData,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tOperatorChain<?, ?> operatorChain,\n+\t\t\tStreamOperator<?> op,\n+\t\t\tSupplier<Boolean> isCanceled,\n+\t\t\tChannelStateWriteResult channelStateWriteResult) throws Exception {\n+\t\tCheckpointStreamFactory storage = checkpointStorage.resolveCheckpointStorageLocation(\n+\t\t\tcheckpointMetaData.getCheckpointId(),\n+\t\t\tcheckpointOptions.getTargetLocation());\n+\t\tOperatorSnapshotFutures snapshotInProgress = checkpointStreamOperator(\n+\t\t\top,\n+\t\t\tcheckpointMetaData,\n+\t\t\tcheckpointOptions,\n+\t\t\tstorage,\n+\t\t\tisCanceled);\n+\t\tif (op == operatorChain.getHeadOperator()) {\n+\t\t\tsnapshotInProgress.setInputChannelStateFuture(channelStateWriteResult\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.getInputChannelStateHandles()\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(StateObjectCollection::new)\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(SnapshotResult::of)\n+\t\t\t);\n+\t\t}\n+\t\tif (op == operatorChain.getTailOperator()) {\n+\t\t\tsnapshotInProgress.setResultSubpartitionStateFuture(channelStateWriteResult\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.getResultSubpartitionStateHandles()\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(StateObjectCollection::new)\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(SnapshotResult::of)\n+\t\t\t);\n+\t\t}\n+\t\treturn snapshotInProgress;\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tchannelStateWriter.close();\n+\t}\n+\n+\t// Caches checkpoint output stream factories to prevent multiple output stream per checkpoint.\n+\t// This could result from requesting output stream by different entities (this and channelStateWriter)\n+\t// We can't just pass a stream to the channelStateWriter because it can receive checkpoint call earlier than this class\n+\t// in some unaligned checkpoints scenarios\n+\tprivate static class CachingCheckpointStorageWorkerView implements CheckpointStorageWorkerView {\n+\t\tprivate final Map<Long, CheckpointStreamFactory> cache = new ConcurrentHashMap<>();\n+\t\tprivate final CheckpointStorageWorkerView delegate;\n+\n+\t\tprivate CachingCheckpointStorageWorkerView(CheckpointStorageWorkerView delegate) {\n+\t\t\tthis.delegate = delegate;\n+\t\t}\n+\n+\t\tvoid clearCacheFor(long checkpointId) {\n+\t\t\tcache.remove(checkpointId);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic CheckpointStreamFactory resolveCheckpointStorageLocation(long checkpointId, CheckpointStorageLocationReference reference) {\n+\t\t\treturn cache.computeIfAbsent(checkpointId, id -> {\n+\t\t\t\ttry {\n+\t\t\t\t\treturn delegate.resolveCheckpointStorageLocation(checkpointId, reference);\n+\t\t\t\t} catch (IOException e) {\n+\t\t\t\t\tthrow new WrappingRuntimeException(e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTUyNjc3MQ=="}, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 191}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc0ODY2NQ==", "bodyText": "Replaced with FlinkRuntimeException.", "url": "https://github.com/apache/flink/pull/11515#discussion_r404748665", "createdAt": "2020-04-07T11:52:04Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -175,6 +203,77 @@ public void checkpointState(\n \t\t}\n \t}\n \n+\tprivate OperatorSnapshotFutures buildOperatorSnapshotFutures(\n+\t\t\tCheckpointMetaData checkpointMetaData,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tOperatorChain<?, ?> operatorChain,\n+\t\t\tStreamOperator<?> op,\n+\t\t\tSupplier<Boolean> isCanceled,\n+\t\t\tChannelStateWriteResult channelStateWriteResult) throws Exception {\n+\t\tCheckpointStreamFactory storage = checkpointStorage.resolveCheckpointStorageLocation(\n+\t\t\tcheckpointMetaData.getCheckpointId(),\n+\t\t\tcheckpointOptions.getTargetLocation());\n+\t\tOperatorSnapshotFutures snapshotInProgress = checkpointStreamOperator(\n+\t\t\top,\n+\t\t\tcheckpointMetaData,\n+\t\t\tcheckpointOptions,\n+\t\t\tstorage,\n+\t\t\tisCanceled);\n+\t\tif (op == operatorChain.getHeadOperator()) {\n+\t\t\tsnapshotInProgress.setInputChannelStateFuture(channelStateWriteResult\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.getInputChannelStateHandles()\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(StateObjectCollection::new)\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(SnapshotResult::of)\n+\t\t\t);\n+\t\t}\n+\t\tif (op == operatorChain.getTailOperator()) {\n+\t\t\tsnapshotInProgress.setResultSubpartitionStateFuture(channelStateWriteResult\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.getResultSubpartitionStateHandles()\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(StateObjectCollection::new)\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(SnapshotResult::of)\n+\t\t\t);\n+\t\t}\n+\t\treturn snapshotInProgress;\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tchannelStateWriter.close();\n+\t}\n+\n+\t// Caches checkpoint output stream factories to prevent multiple output stream per checkpoint.\n+\t// This could result from requesting output stream by different entities (this and channelStateWriter)\n+\t// We can't just pass a stream to the channelStateWriter because it can receive checkpoint call earlier than this class\n+\t// in some unaligned checkpoints scenarios\n+\tprivate static class CachingCheckpointStorageWorkerView implements CheckpointStorageWorkerView {\n+\t\tprivate final Map<Long, CheckpointStreamFactory> cache = new ConcurrentHashMap<>();\n+\t\tprivate final CheckpointStorageWorkerView delegate;\n+\n+\t\tprivate CachingCheckpointStorageWorkerView(CheckpointStorageWorkerView delegate) {\n+\t\t\tthis.delegate = delegate;\n+\t\t}\n+\n+\t\tvoid clearCacheFor(long checkpointId) {\n+\t\t\tcache.remove(checkpointId);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic CheckpointStreamFactory resolveCheckpointStorageLocation(long checkpointId, CheckpointStorageLocationReference reference) {\n+\t\t\treturn cache.computeIfAbsent(checkpointId, id -> {\n+\t\t\t\ttry {\n+\t\t\t\t\treturn delegate.resolveCheckpointStorageLocation(checkpointId, reference);\n+\t\t\t\t} catch (IOException e) {\n+\t\t\t\t\tthrow new WrappingRuntimeException(e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTUyNjc3MQ=="}, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 191}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5MDE3Njk3OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxMDo1OTo1MlrOF-7eww==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxMDo1OTo1MlrOF-7eww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTUzMDU2Mw==", "bodyText": "nit: I prefer to extracting checkpointStorage.resolveCheckpointStorageLocation from buildOperatorSnapshotFutures and put it before for loop, then it is easy to trace both the creation and clear actions in the same page.", "url": "https://github.com/apache/flink/pull/11515#discussion_r401530563", "createdAt": "2020-04-01T10:59:52Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -97,24 +123,26 @@ public void checkpointState(\n \t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not\n \t\t//           impact progress of the streaming topology\n \n-\t\tCheckpointStreamFactory storage = checkpointStorage.resolveCheckpointStorageLocation(\n-\t\t\tcheckpointMetaData.getCheckpointId(),\n-\t\t\tcheckpointOptions.getTargetLocation());\n-\n \t\tlong startSyncPartNano = System.nanoTime();\n \n \t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress = new HashMap<>(operatorChain.getNumberOfOperators());\n+\t\tChannelStateWriteResult channelStateWriteResult =\n+\t\t\tcheckpointOptions.getCheckpointType() == CHECKPOINT ? channelStateWriter.getWriteResult(checkpointMetaData.getCheckpointId()) :\n+\t\t\t\tChannelStateWriteResult.EMPTY;\n \t\ttry {\n \t\t\tfor (StreamOperatorWrapper<?, ?> operatorWrapper : operatorChain.getAllOperators(true)) {\n-\t\t\t\tStreamOperator<?> op = operatorWrapper.getStreamOperator();\n-\t\t\t\tOperatorSnapshotFutures snapshotInProgress = checkpointStreamOperator(\n-\t\t\t\t\top,\n-\t\t\t\t\tcheckpointMetaData,\n-\t\t\t\t\tcheckpointOptions,\n-\t\t\t\t\tstorage,\n-\t\t\t\t\tisCanceled);\n-\t\t\t\toperatorSnapshotsInProgress.put(op.getOperatorID(), snapshotInProgress);\n+\t\t\t\toperatorSnapshotsInProgress.put(\n+\t\t\t\t\toperatorWrapper.getStreamOperator().getOperatorID(),\n+\t\t\t\t\tbuildOperatorSnapshotFutures(\n+\t\t\t\t\t\tcheckpointMetaData,\n+\t\t\t\t\t\tcheckpointOptions,\n+\t\t\t\t\t\toperatorChain,\n+\t\t\t\t\t\toperatorWrapper.getStreamOperator(),\n+\t\t\t\t\t\tisCanceled,\n+\t\t\t\t\t\tchannelStateWriteResult)\n+\t\t\t\t);\n \t\t\t}\n+\t\t\tcheckpointStorage.clearCacheFor(checkpointMetaData.getCheckpointId());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 123}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5MzMwNjgxOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMzoxNToxOVrOF_Z4Rw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wM1QxNDo1OToxNVrOGAZRSg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAyODYxNQ==", "bodyText": "weird naming streamFactoryFactory", "url": "https://github.com/apache/flink/pull/11515#discussion_r402028615", "createdAt": "2020-04-02T03:15:19Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\tprivate volatile boolean isRunning;\n+\tprivate volatile Exception thrown;\n+\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 101}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIzMjI0NA==", "bodyText": "Agree, but it serves its purpose: make it clear what it is (at least clear to me); while checkpointStorageWorkerView wouldn't tell me much.\nDo you have any better names?", "url": "https://github.com/apache/flink/pull/11515#discussion_r402232244", "createdAt": "2020-04-02T11:09:20Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\tprivate volatile boolean isRunning;\n+\tprivate volatile Exception thrown;\n+\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAyODYxNQ=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 101}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQ1MDcyOQ==", "bodyText": "Yes, I can guess your previous motivation to name this. But I guess it might easy bring confusing for others at first glance.\nIn general the variable naming should be consistent with class naming. But I also do not like the naming of CheckpointStorageWorkerView because it is hard to get the real semantic. So the root cause might be refactoring the class name in a hotfix commit, but i am not forcing it.\nActually  CheckpointStorageWorkerView has two purposes, if only considering the builder for factory, might be streamFactoryBuilder/Resolver.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402450729", "createdAt": "2020-04-02T16:34:34Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\tprivate volatile boolean isRunning;\n+\tprivate volatile Exception thrown;\n+\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAyODYxNQ=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 101}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzA2NzIxMA==", "bodyText": "Renamed to streamFactoryResolver.", "url": "https://github.com/apache/flink/pull/11515#discussion_r403067210", "createdAt": "2020-04-03T14:59:15Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\tprivate volatile boolean isRunning;\n+\tprivate volatile Exception thrown;\n+\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAyODYxNQ=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 101}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5MzMxMjA5OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMzoxODoxN1rOF_Z7Pg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMToyMjoxNVrOF_msKg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAyOTM3NA==", "bodyText": "I guess it is not always using  DEFAULT_MAX_CHECKPOINTS, the maxCheckpoints can still be set explicitly, e.g. in tests.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402029374", "createdAt": "2020-04-02T03:18:17Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\tprivate volatile boolean isRunning;\n+\tprivate volatile Exception thrown;\n+\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory) {\n+\t\tthis(streamFactoryFactory, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 106}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIzODUwNg==", "bodyText": "Right, thanks. Updating the javadoc.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402238506", "createdAt": "2020-04-02T11:22:15Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\tprivate volatile boolean isRunning;\n+\tprivate volatile Exception thrown;\n+\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory) {\n+\t\tthis(streamFactoryFactory, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAyOTM3NA=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 106}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5MzMxNTQ5OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMzoyMDowOFrOF_Z9GQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNTo1MTo0N1rOF_x2Iw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAyOTg0OQ==", "bodyText": "it can be private ATM", "url": "https://github.com/apache/flink/pull/11515#discussion_r402029849", "createdAt": "2020-04-02T03:20:08Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\tprivate volatile boolean isRunning;\n+\tprivate volatile Exception thrown;\n+\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory) {\n+\t\tthis(streamFactoryFactory, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.\n+\t */\n+\tChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory, int maxCheckpoints) {\n+\t\tthis(streamFactoryFactory, DEFAULT_HANDOVER_CAPACITY, new ChannelStateSerializerImpl(), maxCheckpoints);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl}.\n+\t *\n+\t * @param maxCheckpoints maximum number of checkpoints to be written currently or finished but not taken yet.\n+\t */\n+\tChannelStateWriterImpl(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 117}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI0MDEzNQ==", "bodyText": "It could be used in tests.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402240135", "createdAt": "2020-04-02T11:25:17Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\tprivate volatile boolean isRunning;\n+\tprivate volatile Exception thrown;\n+\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory) {\n+\t\tthis(streamFactoryFactory, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.\n+\t */\n+\tChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory, int maxCheckpoints) {\n+\t\tthis(streamFactoryFactory, DEFAULT_HANDOVER_CAPACITY, new ChannelStateSerializerImpl(), maxCheckpoints);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl}.\n+\t *\n+\t * @param maxCheckpoints maximum number of checkpoints to be written currently or finished but not taken yet.\n+\t */\n+\tChannelStateWriterImpl(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAyOTg0OQ=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 117}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQyMTI4Mw==", "bodyText": "If so, maybe add @VisibleForTesting", "url": "https://github.com/apache/flink/pull/11515#discussion_r402421283", "createdAt": "2020-04-02T15:51:47Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\tprivate volatile boolean isRunning;\n+\tprivate volatile Exception thrown;\n+\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory) {\n+\t\tthis(streamFactoryFactory, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.\n+\t */\n+\tChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory, int maxCheckpoints) {\n+\t\tthis(streamFactoryFactory, DEFAULT_HANDOVER_CAPACITY, new ChannelStateSerializerImpl(), maxCheckpoints);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl}.\n+\t *\n+\t * @param maxCheckpoints maximum number of checkpoints to be written currently or finished but not taken yet.\n+\t */\n+\tChannelStateWriterImpl(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAyOTg0OQ=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 117}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5MzMxNzg3OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMzoyMTo0NFrOF_Z-aw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMToyODoxMVrOF_m4KQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAzMDE4Nw==", "bodyText": "Is it probably to pass different implementations of ChannelStateSerializer future?", "url": "https://github.com/apache/flink/pull/11515#discussion_r402030187", "createdAt": "2020-04-02T03:21:44Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\tprivate volatile boolean isRunning;\n+\tprivate volatile Exception thrown;\n+\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory) {\n+\t\tthis(streamFactoryFactory, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.\n+\t */\n+\tChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory, int maxCheckpoints) {\n+\t\tthis(streamFactoryFactory, DEFAULT_HANDOVER_CAPACITY, new ChannelStateSerializerImpl(), maxCheckpoints);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl}.\n+\t *\n+\t * @param maxCheckpoints maximum number of checkpoints to be written currently or finished but not taken yet.\n+\t */\n+\tChannelStateWriterImpl(\n+\t\t\tCheckpointStorageWorkerView streamFactory,\n+\t\t\tint handoverCapacity,\n+\t\t\tChannelStateSerializer serializer,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 120}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI0MTU3Nw==", "bodyText": "Yes, I considered to pass a no-op implementation for tests.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402241577", "createdAt": "2020-04-02T11:28:11Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\tprivate volatile boolean isRunning;\n+\tprivate volatile Exception thrown;\n+\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory) {\n+\t\tthis(streamFactoryFactory, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.\n+\t */\n+\tChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory, int maxCheckpoints) {\n+\t\tthis(streamFactoryFactory, DEFAULT_HANDOVER_CAPACITY, new ChannelStateSerializerImpl(), maxCheckpoints);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl}.\n+\t *\n+\t * @param maxCheckpoints maximum number of checkpoints to be written currently or finished but not taken yet.\n+\t */\n+\tChannelStateWriterImpl(\n+\t\t\tCheckpointStorageWorkerView streamFactory,\n+\t\t\tint handoverCapacity,\n+\t\t\tChannelStateSerializer serializer,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAzMDE4Nw=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 120}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5MzMyMjgwOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMzoyNDo1MVrOF_aBMQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMzoyNDo1MVrOF_aBMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAzMDg5Nw==", "bodyText": "nit: better to also describe other arguments for consistent.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402030897", "createdAt": "2020-04-02T03:24:51Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\tprivate volatile boolean isRunning;\n+\tprivate volatile Exception thrown;\n+\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory) {\n+\t\tthis(streamFactoryFactory, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.\n+\t */\n+\tChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory, int maxCheckpoints) {\n+\t\tthis(streamFactoryFactory, DEFAULT_HANDOVER_CAPACITY, new ChannelStateSerializerImpl(), maxCheckpoints);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl}.\n+\t *\n+\t * @param maxCheckpoints maximum number of checkpoints to be written currently or finished but not taken yet.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 115}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5MzM0MzYyOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMzozNzo1M1rOF_aNFQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMzozNzo1M1rOF_aNFQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAzMzk0MQ==", "bodyText": "nit: maxCheckpoints is not necessary to pass.\nweird naming streamFactoryFactory.\nAnother option is to construct ChannelStateWriteRequestProcessor inside constructor of ChannelStateWriterImpl and pass it directly into ProcessRequestsLoop", "url": "https://github.com/apache/flink/pull/11515#discussion_r402033941", "createdAt": "2020-04-02T03:37:53Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 61}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5MzM3NjMzOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMzo1OTowMFrOF_afwA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNTo1MDoxOVrOF_xyXQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAzODcyMA==", "bodyText": "nit: IMO better to place this class after constructor, not mixed among the class fields.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402038720", "createdAt": "2020-04-02T03:59:00Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI1MDg2OQ==", "bodyText": "Placing it after constructor confuses me.\nWDYT about bottom of the file?", "url": "https://github.com/apache/flink/pull/11515#discussion_r402250869", "createdAt": "2020-04-02T11:47:12Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAzODcyMA=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQyMDMxNw==", "bodyText": "Not mandatory. In general I found many internal class were placed at the bottom. For me, this class is placed among the class fields to break them down, then it is not convenient to directly overview all the class fields.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402420317", "createdAt": "2020-04-02T15:50:19Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAzODcyMA=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 58}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5MzM4Mjk1OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNDowMzozMFrOF_ajwA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QwNzo0NTozMFrOGB3C6A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAzOTc0NA==", "bodyText": "I am wondering  it might bring potential problems to use BlockingQueue with bounded size. The IO operations might be stuck sometimes in bad scenarios, then the request in the queue can not be consumed in time. Therefore it would block all the operations of #addInputData, especially the #addInputData might be triggered by multiple netty threads, to impact the network throughput. How about using unbounded queue if the memory overhead is not obvious?", "url": "https://github.com/apache/flink/pull/11515#discussion_r402039744", "createdAt": "2020-04-02T04:03:30Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI2NjYzNg==", "bodyText": "Interesting question. The usual arguments for bounded queues like protecting against memory exhaustion don't work that well here. The reasons are that the queue essentially holds references to larger memory regions and atm we can only have a single in-flight checkpoint.\nHowever,\n\nwe may have multiple references to the same region (when we remove the single-checkpoint limit and don't have incremental checkpointing yet or it doesn't help here)\nthese are different memory regions (heap and likely non-heap)\n\nWith an unbounded queue, the task could run out of memory and it would be much harder to figure it out.\nSo I'd stick with bounded queue but lift its default size.\nWDYT?", "url": "https://github.com/apache/flink/pull/11515#discussion_r402266636", "createdAt": "2020-04-02T12:16:22Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAzOTc0NA=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzQ4NzI5OQ==", "bodyText": "Thanks for sharing your thoughts. Actually I only thought of the benefits of resource limitation for bounded queue before.\nDo you concerning that the network buffer to be exhausted or run out of memory by unbounded queue I f I understand correctly? If so, I guess this hurt might be less worse than blocking the netty thread for two reasons:\n\n\nIf one netty thread is blocked, it might block multiple input channels receiving following data, then it might even delay the barrier alignment, based on the truth that one netty thread wouold serve for multiple input channels data transport.\n\n\nIf one netty thread is blocked, it does not alway mean that the left buffer memory can be better used by other channels. For exclusive buffers per-channel, it can only be used by current blocked netty thread for receiving data. For floating buffers among all the channels, if they were already requested away by the current blocked netty thread, they can not returned back to be used by other active netty threads. It can only avoid requesting more floating buffers by current blocked netty thread, but it is not determined behavior.\n\n\nSo if there are no concerns for additional memory overhead caused by unbounded queue and it is also easy to adjust, then i prefer to unblocking option. Otherwise we can lift the default size for bounded size and further convert to unbounded queue if finding serious problems in production future. But I am not quite sure whether the blocking impact can be easily found in practice.", "url": "https://github.com/apache/flink/pull/11515#discussion_r403487299", "createdAt": "2020-04-04T16:15:56Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAzOTc0NA=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM1OTg2Mg==", "bodyText": "I agree, blocking the netty thread is a bad idea for a bug-free and maybe backpressured scenarios.\nBut even with unbounded queue I think we need to check the size of the queue (and throw exception when exceeded); so that in case of a bug it can be  detected easier.\nIn that case, bounded vs unbounded becomes just an implementation detail (and I found it easier to use bounded currently).", "url": "https://github.com/apache/flink/pull/11515#discussion_r404359862", "createdAt": "2020-04-06T20:14:23Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAzOTc0NA=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDYwMzYyNA==", "bodyText": "If it is easier for using bounded atm, i am also fine with setting enough capacity for the queue, then we can assume that it would never block netty thread with this large capacity.", "url": "https://github.com/apache/flink/pull/11515#discussion_r404603624", "createdAt": "2020-04-07T07:45:30Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAzOTc0NA=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 95}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5MzQyMDQ3OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNDoyOTozOVrOF_a5ZQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNTo1NTozMlrOF_yBbA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA0NTI4NQ==", "bodyText": "Give some javadoc to explain why we do not support event data?", "url": "https://github.com/apache/flink/pull/11515#discussion_r402045285", "createdAt": "2020-04-02T04:29:39Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\tprivate volatile boolean isRunning;\n+\tprivate volatile Exception thrown;\n+\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory) {\n+\t\tthis(streamFactoryFactory, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.\n+\t */\n+\tChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory, int maxCheckpoints) {\n+\t\tthis(streamFactoryFactory, DEFAULT_HANDOVER_CAPACITY, new ChannelStateSerializerImpl(), maxCheckpoints);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl}.\n+\t *\n+\t * @param maxCheckpoints maximum number of checkpoints to be written currently or finished but not taken yet.\n+\t */\n+\tChannelStateWriterImpl(\n+\t\t\tCheckpointStorageWorkerView streamFactory,\n+\t\t\tint handoverCapacity,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tint maxCheckpoints) {\n+\t\tthis.handover = new ArrayBlockingQueue<>(handoverCapacity);\n+\t\tthis.results = new ConcurrentHashMap<>(maxCheckpoints);\n+\t\tthis.maxCheckpoints = maxCheckpoints;\n+\t\tthis.asyncWriter = new Thread(new ProcessRequestsLoop(maxCheckpoints, streamFactory, serializer));\n+\t\tthis.isRunning = true;\n+\t}\n+\n+\t@Override\n+\tpublic void start(long checkpointId, CheckpointOptions checkpointOptions) {\n+\t\tLOG.debug(\"start checkpoint {} ({})\", checkpointId, checkpointOptions);\n+\t\trethrow();\n+\t\tPreconditions.checkState(isRunning && asyncWriter.isAlive(), \"not running\");\n+\t\tChannelStateWriteResult result = new ChannelStateWriteResult();\n+\t\tChannelStateWriteResult put = results.computeIfAbsent(checkpointId, id -> {\n+\t\t\tPreconditions.checkArgument(results.size() < maxCheckpoints, \"results.size() > maxCheckpoints\", results.size(), maxCheckpoints);\n+\t\t\tenqueue(new CheckpointStartRequest(checkpointId, result, checkpointOptions.getTargetLocation()));\n+\t\t\treturn result;\n+\t\t});\n+\t\tPreconditions.checkArgument(put == result, \"result future already present for checkpoint id: \" + checkpointId);\n+\t}\n+\n+\t@Override\n+\tpublic void addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add input data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)));\n+\t}\n+\n+\t@Override\n+\tpublic void addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add output data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)));\n+\t}\n+\n+\t@Override\n+\tpublic void finishInput(long checkpointId) {\n+\t\tLOG.debug(\"finish input data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeInput(checkpointId));\n+\t}\n+\n+\t@Override\n+\tpublic void finishOutput(long checkpointId) {\n+\t\tLOG.debug(\"finish output data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeOutput(checkpointId));\n+\t}\n+\n+\t@Override\n+\tpublic ChannelStateWriteResult getWriteResult(long checkpointId) {\n+\t\tLOG.debug(\"requested write result, checkpoint id: {}\", checkpointId);\n+\t\tChannelStateWriteResult result = results.remove(checkpointId);\n+\t\tPreconditions.checkArgument(result != null, \"channel state write result not found for checkpoint id \" + checkpointId);\n+\t\treturn result;\n+\t}\n+\n+\tpublic void open() {\n+\t\tPreconditions.checkState(isRunning);\n+\t\tasyncWriter.start();\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tisRunning = false;\n+\t\tresults.clear();\n+\t\tasyncWriter.interrupt();\n+\t\twhile (asyncWriter.isAlive()) {\n+\t\t\ttry {\n+\t\t\t\tasyncWriter.join();\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tif (!asyncWriter.isAlive()) {\n+\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t}\n+\t\t\t\tLOG.debug(\"interrupted while waiting for the writer thread to die\", e);\n+\t\t\t}\n+\t\t}\n+\t\trethrow();\n+\t}\n+\n+\tprivate void enqueue(ChannelStateWriteRequest request) {\n+\t\trethrow();\n+\t\tPreconditions.checkState(isRunning);\n+\t\ttry {\n+\t\t\thandover.put(request);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new RuntimeException(\"Interrupted while trying to add new handover request\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void rethrow() {\n+\t\tif (thrown != null) {\n+\t\t\tthrow new RuntimeException(thrown); // wrap to record current stack-trace\n+\t\t}\n+\t}\n+\n+\tprivate static Buffer[] checkBufferType(Buffer... data) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 216}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI2OTQ0Nw==", "bodyText": "The limitation itself is documented on the interface level.\nThe reasons behind it are too high-level for this class IMO.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402269447", "createdAt": "2020-04-02T12:21:17Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\tprivate volatile boolean isRunning;\n+\tprivate volatile Exception thrown;\n+\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory) {\n+\t\tthis(streamFactoryFactory, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.\n+\t */\n+\tChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory, int maxCheckpoints) {\n+\t\tthis(streamFactoryFactory, DEFAULT_HANDOVER_CAPACITY, new ChannelStateSerializerImpl(), maxCheckpoints);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl}.\n+\t *\n+\t * @param maxCheckpoints maximum number of checkpoints to be written currently or finished but not taken yet.\n+\t */\n+\tChannelStateWriterImpl(\n+\t\t\tCheckpointStorageWorkerView streamFactory,\n+\t\t\tint handoverCapacity,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tint maxCheckpoints) {\n+\t\tthis.handover = new ArrayBlockingQueue<>(handoverCapacity);\n+\t\tthis.results = new ConcurrentHashMap<>(maxCheckpoints);\n+\t\tthis.maxCheckpoints = maxCheckpoints;\n+\t\tthis.asyncWriter = new Thread(new ProcessRequestsLoop(maxCheckpoints, streamFactory, serializer));\n+\t\tthis.isRunning = true;\n+\t}\n+\n+\t@Override\n+\tpublic void start(long checkpointId, CheckpointOptions checkpointOptions) {\n+\t\tLOG.debug(\"start checkpoint {} ({})\", checkpointId, checkpointOptions);\n+\t\trethrow();\n+\t\tPreconditions.checkState(isRunning && asyncWriter.isAlive(), \"not running\");\n+\t\tChannelStateWriteResult result = new ChannelStateWriteResult();\n+\t\tChannelStateWriteResult put = results.computeIfAbsent(checkpointId, id -> {\n+\t\t\tPreconditions.checkArgument(results.size() < maxCheckpoints, \"results.size() > maxCheckpoints\", results.size(), maxCheckpoints);\n+\t\t\tenqueue(new CheckpointStartRequest(checkpointId, result, checkpointOptions.getTargetLocation()));\n+\t\t\treturn result;\n+\t\t});\n+\t\tPreconditions.checkArgument(put == result, \"result future already present for checkpoint id: \" + checkpointId);\n+\t}\n+\n+\t@Override\n+\tpublic void addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add input data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)));\n+\t}\n+\n+\t@Override\n+\tpublic void addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add output data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)));\n+\t}\n+\n+\t@Override\n+\tpublic void finishInput(long checkpointId) {\n+\t\tLOG.debug(\"finish input data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeInput(checkpointId));\n+\t}\n+\n+\t@Override\n+\tpublic void finishOutput(long checkpointId) {\n+\t\tLOG.debug(\"finish output data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeOutput(checkpointId));\n+\t}\n+\n+\t@Override\n+\tpublic ChannelStateWriteResult getWriteResult(long checkpointId) {\n+\t\tLOG.debug(\"requested write result, checkpoint id: {}\", checkpointId);\n+\t\tChannelStateWriteResult result = results.remove(checkpointId);\n+\t\tPreconditions.checkArgument(result != null, \"channel state write result not found for checkpoint id \" + checkpointId);\n+\t\treturn result;\n+\t}\n+\n+\tpublic void open() {\n+\t\tPreconditions.checkState(isRunning);\n+\t\tasyncWriter.start();\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tisRunning = false;\n+\t\tresults.clear();\n+\t\tasyncWriter.interrupt();\n+\t\twhile (asyncWriter.isAlive()) {\n+\t\t\ttry {\n+\t\t\t\tasyncWriter.join();\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tif (!asyncWriter.isAlive()) {\n+\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t}\n+\t\t\t\tLOG.debug(\"interrupted while waiting for the writer thread to die\", e);\n+\t\t\t}\n+\t\t}\n+\t\trethrow();\n+\t}\n+\n+\tprivate void enqueue(ChannelStateWriteRequest request) {\n+\t\trethrow();\n+\t\tPreconditions.checkState(isRunning);\n+\t\ttry {\n+\t\t\thandover.put(request);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new RuntimeException(\"Interrupted while trying to add new handover request\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void rethrow() {\n+\t\tif (thrown != null) {\n+\t\t\tthrow new RuntimeException(thrown); // wrap to record current stack-trace\n+\t\t}\n+\t}\n+\n+\tprivate static Buffer[] checkBufferType(Buffer... data) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA0NTI4NQ=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 216}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQyNDE3Mg==", "bodyText": "That is fine for me if it is documented in some places", "url": "https://github.com/apache/flink/pull/11515#discussion_r402424172", "createdAt": "2020-04-02T15:55:32Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\tprivate volatile boolean isRunning;\n+\tprivate volatile Exception thrown;\n+\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory) {\n+\t\tthis(streamFactoryFactory, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.\n+\t */\n+\tChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory, int maxCheckpoints) {\n+\t\tthis(streamFactoryFactory, DEFAULT_HANDOVER_CAPACITY, new ChannelStateSerializerImpl(), maxCheckpoints);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl}.\n+\t *\n+\t * @param maxCheckpoints maximum number of checkpoints to be written currently or finished but not taken yet.\n+\t */\n+\tChannelStateWriterImpl(\n+\t\t\tCheckpointStorageWorkerView streamFactory,\n+\t\t\tint handoverCapacity,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tint maxCheckpoints) {\n+\t\tthis.handover = new ArrayBlockingQueue<>(handoverCapacity);\n+\t\tthis.results = new ConcurrentHashMap<>(maxCheckpoints);\n+\t\tthis.maxCheckpoints = maxCheckpoints;\n+\t\tthis.asyncWriter = new Thread(new ProcessRequestsLoop(maxCheckpoints, streamFactory, serializer));\n+\t\tthis.isRunning = true;\n+\t}\n+\n+\t@Override\n+\tpublic void start(long checkpointId, CheckpointOptions checkpointOptions) {\n+\t\tLOG.debug(\"start checkpoint {} ({})\", checkpointId, checkpointOptions);\n+\t\trethrow();\n+\t\tPreconditions.checkState(isRunning && asyncWriter.isAlive(), \"not running\");\n+\t\tChannelStateWriteResult result = new ChannelStateWriteResult();\n+\t\tChannelStateWriteResult put = results.computeIfAbsent(checkpointId, id -> {\n+\t\t\tPreconditions.checkArgument(results.size() < maxCheckpoints, \"results.size() > maxCheckpoints\", results.size(), maxCheckpoints);\n+\t\t\tenqueue(new CheckpointStartRequest(checkpointId, result, checkpointOptions.getTargetLocation()));\n+\t\t\treturn result;\n+\t\t});\n+\t\tPreconditions.checkArgument(put == result, \"result future already present for checkpoint id: \" + checkpointId);\n+\t}\n+\n+\t@Override\n+\tpublic void addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add input data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)));\n+\t}\n+\n+\t@Override\n+\tpublic void addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add output data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)));\n+\t}\n+\n+\t@Override\n+\tpublic void finishInput(long checkpointId) {\n+\t\tLOG.debug(\"finish input data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeInput(checkpointId));\n+\t}\n+\n+\t@Override\n+\tpublic void finishOutput(long checkpointId) {\n+\t\tLOG.debug(\"finish output data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeOutput(checkpointId));\n+\t}\n+\n+\t@Override\n+\tpublic ChannelStateWriteResult getWriteResult(long checkpointId) {\n+\t\tLOG.debug(\"requested write result, checkpoint id: {}\", checkpointId);\n+\t\tChannelStateWriteResult result = results.remove(checkpointId);\n+\t\tPreconditions.checkArgument(result != null, \"channel state write result not found for checkpoint id \" + checkpointId);\n+\t\treturn result;\n+\t}\n+\n+\tpublic void open() {\n+\t\tPreconditions.checkState(isRunning);\n+\t\tasyncWriter.start();\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tisRunning = false;\n+\t\tresults.clear();\n+\t\tasyncWriter.interrupt();\n+\t\twhile (asyncWriter.isAlive()) {\n+\t\t\ttry {\n+\t\t\t\tasyncWriter.join();\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tif (!asyncWriter.isAlive()) {\n+\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t}\n+\t\t\t\tLOG.debug(\"interrupted while waiting for the writer thread to die\", e);\n+\t\t\t}\n+\t\t}\n+\t\trethrow();\n+\t}\n+\n+\tprivate void enqueue(ChannelStateWriteRequest request) {\n+\t\trethrow();\n+\t\tPreconditions.checkState(isRunning);\n+\t\ttry {\n+\t\t\thandover.put(request);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new RuntimeException(\"Interrupted while trying to add new handover request\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void rethrow() {\n+\t\tif (thrown != null) {\n+\t\t\tthrow new RuntimeException(thrown); // wrap to record current stack-trace\n+\t\t}\n+\t}\n+\n+\tprivate static Buffer[] checkBufferType(Buffer... data) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA0NTI4NQ=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 216}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5MzQyNTEwOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNDozMjo1NFrOF_a8CQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNDozMjo1NFrOF_a8CQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA0NTk2MQ==", "bodyText": "should check both isRunning && asyncWriter.isAlive() as did in #start()", "url": "https://github.com/apache/flink/pull/11515#discussion_r402045961", "createdAt": "2020-04-02T04:32:54Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\tprivate volatile boolean isRunning;\n+\tprivate volatile Exception thrown;\n+\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory) {\n+\t\tthis(streamFactoryFactory, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.\n+\t */\n+\tChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory, int maxCheckpoints) {\n+\t\tthis(streamFactoryFactory, DEFAULT_HANDOVER_CAPACITY, new ChannelStateSerializerImpl(), maxCheckpoints);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl}.\n+\t *\n+\t * @param maxCheckpoints maximum number of checkpoints to be written currently or finished but not taken yet.\n+\t */\n+\tChannelStateWriterImpl(\n+\t\t\tCheckpointStorageWorkerView streamFactory,\n+\t\t\tint handoverCapacity,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tint maxCheckpoints) {\n+\t\tthis.handover = new ArrayBlockingQueue<>(handoverCapacity);\n+\t\tthis.results = new ConcurrentHashMap<>(maxCheckpoints);\n+\t\tthis.maxCheckpoints = maxCheckpoints;\n+\t\tthis.asyncWriter = new Thread(new ProcessRequestsLoop(maxCheckpoints, streamFactory, serializer));\n+\t\tthis.isRunning = true;\n+\t}\n+\n+\t@Override\n+\tpublic void start(long checkpointId, CheckpointOptions checkpointOptions) {\n+\t\tLOG.debug(\"start checkpoint {} ({})\", checkpointId, checkpointOptions);\n+\t\trethrow();\n+\t\tPreconditions.checkState(isRunning && asyncWriter.isAlive(), \"not running\");\n+\t\tChannelStateWriteResult result = new ChannelStateWriteResult();\n+\t\tChannelStateWriteResult put = results.computeIfAbsent(checkpointId, id -> {\n+\t\t\tPreconditions.checkArgument(results.size() < maxCheckpoints, \"results.size() > maxCheckpoints\", results.size(), maxCheckpoints);\n+\t\t\tenqueue(new CheckpointStartRequest(checkpointId, result, checkpointOptions.getTargetLocation()));\n+\t\t\treturn result;\n+\t\t});\n+\t\tPreconditions.checkArgument(put == result, \"result future already present for checkpoint id: \" + checkpointId);\n+\t}\n+\n+\t@Override\n+\tpublic void addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add input data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)));\n+\t}\n+\n+\t@Override\n+\tpublic void addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add output data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)));\n+\t}\n+\n+\t@Override\n+\tpublic void finishInput(long checkpointId) {\n+\t\tLOG.debug(\"finish input data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeInput(checkpointId));\n+\t}\n+\n+\t@Override\n+\tpublic void finishOutput(long checkpointId) {\n+\t\tLOG.debug(\"finish output data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeOutput(checkpointId));\n+\t}\n+\n+\t@Override\n+\tpublic ChannelStateWriteResult getWriteResult(long checkpointId) {\n+\t\tLOG.debug(\"requested write result, checkpoint id: {}\", checkpointId);\n+\t\tChannelStateWriteResult result = results.remove(checkpointId);\n+\t\tPreconditions.checkArgument(result != null, \"channel state write result not found for checkpoint id \" + checkpointId);\n+\t\treturn result;\n+\t}\n+\n+\tpublic void open() {\n+\t\tPreconditions.checkState(isRunning);\n+\t\tasyncWriter.start();\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tisRunning = false;\n+\t\tresults.clear();\n+\t\tasyncWriter.interrupt();\n+\t\twhile (asyncWriter.isAlive()) {\n+\t\t\ttry {\n+\t\t\t\tasyncWriter.join();\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tif (!asyncWriter.isAlive()) {\n+\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t}\n+\t\t\t\tLOG.debug(\"interrupted while waiting for the writer thread to die\", e);\n+\t\t\t}\n+\t\t}\n+\t\trethrow();\n+\t}\n+\n+\tprivate void enqueue(ChannelStateWriteRequest request) {\n+\t\trethrow();\n+\t\tPreconditions.checkState(isRunning);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 202}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5MzQ1NjczOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNDo1MzoxNFrOF_bOAg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxMToxNzoxN1rOGB-yIA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA1MDU2Mg==", "bodyText": "I do not think RuntimeException is a good way unless necessary. Although it seems simple to not announce exceptions explicitly in related methods, it might mislead the upper caller to think all the interactions with ChannelStateWriter would not cause any exceptions. Then the caller might lose the chance to handle exceptions in elegant way.\nAlso the RuntimeException seems have a more widely concept, I guess it probably should be IOException for writer to give more sense.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402050562", "createdAt": "2020-04-02T04:53:14Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\tprivate volatile boolean isRunning;\n+\tprivate volatile Exception thrown;\n+\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory) {\n+\t\tthis(streamFactoryFactory, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.\n+\t */\n+\tChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory, int maxCheckpoints) {\n+\t\tthis(streamFactoryFactory, DEFAULT_HANDOVER_CAPACITY, new ChannelStateSerializerImpl(), maxCheckpoints);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl}.\n+\t *\n+\t * @param maxCheckpoints maximum number of checkpoints to be written currently or finished but not taken yet.\n+\t */\n+\tChannelStateWriterImpl(\n+\t\t\tCheckpointStorageWorkerView streamFactory,\n+\t\t\tint handoverCapacity,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tint maxCheckpoints) {\n+\t\tthis.handover = new ArrayBlockingQueue<>(handoverCapacity);\n+\t\tthis.results = new ConcurrentHashMap<>(maxCheckpoints);\n+\t\tthis.maxCheckpoints = maxCheckpoints;\n+\t\tthis.asyncWriter = new Thread(new ProcessRequestsLoop(maxCheckpoints, streamFactory, serializer));\n+\t\tthis.isRunning = true;\n+\t}\n+\n+\t@Override\n+\tpublic void start(long checkpointId, CheckpointOptions checkpointOptions) {\n+\t\tLOG.debug(\"start checkpoint {} ({})\", checkpointId, checkpointOptions);\n+\t\trethrow();\n+\t\tPreconditions.checkState(isRunning && asyncWriter.isAlive(), \"not running\");\n+\t\tChannelStateWriteResult result = new ChannelStateWriteResult();\n+\t\tChannelStateWriteResult put = results.computeIfAbsent(checkpointId, id -> {\n+\t\t\tPreconditions.checkArgument(results.size() < maxCheckpoints, \"results.size() > maxCheckpoints\", results.size(), maxCheckpoints);\n+\t\t\tenqueue(new CheckpointStartRequest(checkpointId, result, checkpointOptions.getTargetLocation()));\n+\t\t\treturn result;\n+\t\t});\n+\t\tPreconditions.checkArgument(put == result, \"result future already present for checkpoint id: \" + checkpointId);\n+\t}\n+\n+\t@Override\n+\tpublic void addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add input data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)));\n+\t}\n+\n+\t@Override\n+\tpublic void addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add output data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)));\n+\t}\n+\n+\t@Override\n+\tpublic void finishInput(long checkpointId) {\n+\t\tLOG.debug(\"finish input data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeInput(checkpointId));\n+\t}\n+\n+\t@Override\n+\tpublic void finishOutput(long checkpointId) {\n+\t\tLOG.debug(\"finish output data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeOutput(checkpointId));\n+\t}\n+\n+\t@Override\n+\tpublic ChannelStateWriteResult getWriteResult(long checkpointId) {\n+\t\tLOG.debug(\"requested write result, checkpoint id: {}\", checkpointId);\n+\t\tChannelStateWriteResult result = results.remove(checkpointId);\n+\t\tPreconditions.checkArgument(result != null, \"channel state write result not found for checkpoint id \" + checkpointId);\n+\t\treturn result;\n+\t}\n+\n+\tpublic void open() {\n+\t\tPreconditions.checkState(isRunning);\n+\t\tasyncWriter.start();\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tisRunning = false;\n+\t\tresults.clear();\n+\t\tasyncWriter.interrupt();\n+\t\twhile (asyncWriter.isAlive()) {\n+\t\t\ttry {\n+\t\t\t\tasyncWriter.join();\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tif (!asyncWriter.isAlive()) {\n+\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t}\n+\t\t\t\tLOG.debug(\"interrupted while waiting for the writer thread to die\", e);\n+\t\t\t}\n+\t\t}\n+\t\trethrow();\n+\t}\n+\n+\tprivate void enqueue(ChannelStateWriteRequest request) {\n+\t\trethrow();\n+\t\tPreconditions.checkState(isRunning);\n+\t\ttry {\n+\t\t\thandover.put(request);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new RuntimeException(\"Interrupted while trying to add new handover request\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void rethrow() {\n+\t\tif (thrown != null) {\n+\t\t\tthrow new RuntimeException(thrown); // wrap to record current stack-trace", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 212}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI3OTk4MA==", "bodyText": "I don't see how the client could recover from any exception thrown by this class. Especially given that:\n\nthese exceptions can come from previous calls\nthe idiomatic way to handle errors in Flink (as I see it) is to fail and recover the whole job\n\nAlso, it can be any exception, not only IOException.\nSo there is no point to declare (likely forcing the client to wrap it or declare too).", "url": "https://github.com/apache/flink/pull/11515#discussion_r402279980", "createdAt": "2020-04-02T12:38:30Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\tprivate volatile boolean isRunning;\n+\tprivate volatile Exception thrown;\n+\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory) {\n+\t\tthis(streamFactoryFactory, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.\n+\t */\n+\tChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory, int maxCheckpoints) {\n+\t\tthis(streamFactoryFactory, DEFAULT_HANDOVER_CAPACITY, new ChannelStateSerializerImpl(), maxCheckpoints);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl}.\n+\t *\n+\t * @param maxCheckpoints maximum number of checkpoints to be written currently or finished but not taken yet.\n+\t */\n+\tChannelStateWriterImpl(\n+\t\t\tCheckpointStorageWorkerView streamFactory,\n+\t\t\tint handoverCapacity,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tint maxCheckpoints) {\n+\t\tthis.handover = new ArrayBlockingQueue<>(handoverCapacity);\n+\t\tthis.results = new ConcurrentHashMap<>(maxCheckpoints);\n+\t\tthis.maxCheckpoints = maxCheckpoints;\n+\t\tthis.asyncWriter = new Thread(new ProcessRequestsLoop(maxCheckpoints, streamFactory, serializer));\n+\t\tthis.isRunning = true;\n+\t}\n+\n+\t@Override\n+\tpublic void start(long checkpointId, CheckpointOptions checkpointOptions) {\n+\t\tLOG.debug(\"start checkpoint {} ({})\", checkpointId, checkpointOptions);\n+\t\trethrow();\n+\t\tPreconditions.checkState(isRunning && asyncWriter.isAlive(), \"not running\");\n+\t\tChannelStateWriteResult result = new ChannelStateWriteResult();\n+\t\tChannelStateWriteResult put = results.computeIfAbsent(checkpointId, id -> {\n+\t\t\tPreconditions.checkArgument(results.size() < maxCheckpoints, \"results.size() > maxCheckpoints\", results.size(), maxCheckpoints);\n+\t\t\tenqueue(new CheckpointStartRequest(checkpointId, result, checkpointOptions.getTargetLocation()));\n+\t\t\treturn result;\n+\t\t});\n+\t\tPreconditions.checkArgument(put == result, \"result future already present for checkpoint id: \" + checkpointId);\n+\t}\n+\n+\t@Override\n+\tpublic void addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add input data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)));\n+\t}\n+\n+\t@Override\n+\tpublic void addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add output data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)));\n+\t}\n+\n+\t@Override\n+\tpublic void finishInput(long checkpointId) {\n+\t\tLOG.debug(\"finish input data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeInput(checkpointId));\n+\t}\n+\n+\t@Override\n+\tpublic void finishOutput(long checkpointId) {\n+\t\tLOG.debug(\"finish output data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeOutput(checkpointId));\n+\t}\n+\n+\t@Override\n+\tpublic ChannelStateWriteResult getWriteResult(long checkpointId) {\n+\t\tLOG.debug(\"requested write result, checkpoint id: {}\", checkpointId);\n+\t\tChannelStateWriteResult result = results.remove(checkpointId);\n+\t\tPreconditions.checkArgument(result != null, \"channel state write result not found for checkpoint id \" + checkpointId);\n+\t\treturn result;\n+\t}\n+\n+\tpublic void open() {\n+\t\tPreconditions.checkState(isRunning);\n+\t\tasyncWriter.start();\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tisRunning = false;\n+\t\tresults.clear();\n+\t\tasyncWriter.interrupt();\n+\t\twhile (asyncWriter.isAlive()) {\n+\t\t\ttry {\n+\t\t\t\tasyncWriter.join();\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tif (!asyncWriter.isAlive()) {\n+\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t}\n+\t\t\t\tLOG.debug(\"interrupted while waiting for the writer thread to die\", e);\n+\t\t\t}\n+\t\t}\n+\t\trethrow();\n+\t}\n+\n+\tprivate void enqueue(ChannelStateWriteRequest request) {\n+\t\trethrow();\n+\t\tPreconditions.checkState(isRunning);\n+\t\ttry {\n+\t\t\thandover.put(request);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new RuntimeException(\"Interrupted while trying to add new handover request\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void rethrow() {\n+\t\tif (thrown != null) {\n+\t\t\tthrow new RuntimeException(thrown); // wrap to record current stack-trace", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA1MDU2Mg=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 212}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcyMDk4NA==", "bodyText": "Yes, I agree that any exceptions should fail the task and result in restarting the whole job.\nMy previous concern was that it may be better to announce the specific exceptions explicitly for the called methods, to make the caller have the possibility to handle the exception in elegant way.\nE.g. If the internal called methods without explicit exception:\n#method1() {\naction 1: request some resources\naction 2: call some methods without exception\naction 3: release resources\n}\nE.g. If the internal called methods with explicit exception\n#method1() {\naction 1: request some resources\ntry{\naction 2: call some methods without exception\n} finally {\naction 3: release resources\n}\n}\nFor the first example, it might cause resource leak for the caller if is not ware of the exception.\nI guess all the related exceptions for these methods should be IOException and InterruptedException.", "url": "https://github.com/apache/flink/pull/11515#discussion_r403720984", "createdAt": "2020-04-05T16:00:54Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\tprivate volatile boolean isRunning;\n+\tprivate volatile Exception thrown;\n+\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory) {\n+\t\tthis(streamFactoryFactory, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.\n+\t */\n+\tChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory, int maxCheckpoints) {\n+\t\tthis(streamFactoryFactory, DEFAULT_HANDOVER_CAPACITY, new ChannelStateSerializerImpl(), maxCheckpoints);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl}.\n+\t *\n+\t * @param maxCheckpoints maximum number of checkpoints to be written currently or finished but not taken yet.\n+\t */\n+\tChannelStateWriterImpl(\n+\t\t\tCheckpointStorageWorkerView streamFactory,\n+\t\t\tint handoverCapacity,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tint maxCheckpoints) {\n+\t\tthis.handover = new ArrayBlockingQueue<>(handoverCapacity);\n+\t\tthis.results = new ConcurrentHashMap<>(maxCheckpoints);\n+\t\tthis.maxCheckpoints = maxCheckpoints;\n+\t\tthis.asyncWriter = new Thread(new ProcessRequestsLoop(maxCheckpoints, streamFactory, serializer));\n+\t\tthis.isRunning = true;\n+\t}\n+\n+\t@Override\n+\tpublic void start(long checkpointId, CheckpointOptions checkpointOptions) {\n+\t\tLOG.debug(\"start checkpoint {} ({})\", checkpointId, checkpointOptions);\n+\t\trethrow();\n+\t\tPreconditions.checkState(isRunning && asyncWriter.isAlive(), \"not running\");\n+\t\tChannelStateWriteResult result = new ChannelStateWriteResult();\n+\t\tChannelStateWriteResult put = results.computeIfAbsent(checkpointId, id -> {\n+\t\t\tPreconditions.checkArgument(results.size() < maxCheckpoints, \"results.size() > maxCheckpoints\", results.size(), maxCheckpoints);\n+\t\t\tenqueue(new CheckpointStartRequest(checkpointId, result, checkpointOptions.getTargetLocation()));\n+\t\t\treturn result;\n+\t\t});\n+\t\tPreconditions.checkArgument(put == result, \"result future already present for checkpoint id: \" + checkpointId);\n+\t}\n+\n+\t@Override\n+\tpublic void addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add input data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)));\n+\t}\n+\n+\t@Override\n+\tpublic void addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add output data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)));\n+\t}\n+\n+\t@Override\n+\tpublic void finishInput(long checkpointId) {\n+\t\tLOG.debug(\"finish input data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeInput(checkpointId));\n+\t}\n+\n+\t@Override\n+\tpublic void finishOutput(long checkpointId) {\n+\t\tLOG.debug(\"finish output data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeOutput(checkpointId));\n+\t}\n+\n+\t@Override\n+\tpublic ChannelStateWriteResult getWriteResult(long checkpointId) {\n+\t\tLOG.debug(\"requested write result, checkpoint id: {}\", checkpointId);\n+\t\tChannelStateWriteResult result = results.remove(checkpointId);\n+\t\tPreconditions.checkArgument(result != null, \"channel state write result not found for checkpoint id \" + checkpointId);\n+\t\treturn result;\n+\t}\n+\n+\tpublic void open() {\n+\t\tPreconditions.checkState(isRunning);\n+\t\tasyncWriter.start();\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tisRunning = false;\n+\t\tresults.clear();\n+\t\tasyncWriter.interrupt();\n+\t\twhile (asyncWriter.isAlive()) {\n+\t\t\ttry {\n+\t\t\t\tasyncWriter.join();\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tif (!asyncWriter.isAlive()) {\n+\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t}\n+\t\t\t\tLOG.debug(\"interrupted while waiting for the writer thread to die\", e);\n+\t\t\t}\n+\t\t}\n+\t\trethrow();\n+\t}\n+\n+\tprivate void enqueue(ChannelStateWriteRequest request) {\n+\t\trethrow();\n+\t\tPreconditions.checkState(isRunning);\n+\t\ttry {\n+\t\t\thandover.put(request);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new RuntimeException(\"Interrupted while trying to add new handover request\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void rethrow() {\n+\t\tif (thrown != null) {\n+\t\t\tthrow new RuntimeException(thrown); // wrap to record current stack-trace", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA1MDU2Mg=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 212}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzc1NDgzNg==", "bodyText": "IMO, resources should be freed in finally regardless of exceptions declared in method signature.\nCurrently (#11507 PR), any exceptions are propagated, caught somewhere (as Exception) just to be wrapped and rethrown again.\nIn one case there is finally block freeing resources; but it must free them regardless of this call.\nSo, there will be no changes in the caller code if we use checked exceptions (except for some problems with lambdas).\nBut I see checked exceptions are used in many places in Flink so I'm also fine with this option.", "url": "https://github.com/apache/flink/pull/11515#discussion_r403754836", "createdAt": "2020-04-05T20:46:40Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\tprivate volatile boolean isRunning;\n+\tprivate volatile Exception thrown;\n+\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory) {\n+\t\tthis(streamFactoryFactory, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.\n+\t */\n+\tChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory, int maxCheckpoints) {\n+\t\tthis(streamFactoryFactory, DEFAULT_HANDOVER_CAPACITY, new ChannelStateSerializerImpl(), maxCheckpoints);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl}.\n+\t *\n+\t * @param maxCheckpoints maximum number of checkpoints to be written currently or finished but not taken yet.\n+\t */\n+\tChannelStateWriterImpl(\n+\t\t\tCheckpointStorageWorkerView streamFactory,\n+\t\t\tint handoverCapacity,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tint maxCheckpoints) {\n+\t\tthis.handover = new ArrayBlockingQueue<>(handoverCapacity);\n+\t\tthis.results = new ConcurrentHashMap<>(maxCheckpoints);\n+\t\tthis.maxCheckpoints = maxCheckpoints;\n+\t\tthis.asyncWriter = new Thread(new ProcessRequestsLoop(maxCheckpoints, streamFactory, serializer));\n+\t\tthis.isRunning = true;\n+\t}\n+\n+\t@Override\n+\tpublic void start(long checkpointId, CheckpointOptions checkpointOptions) {\n+\t\tLOG.debug(\"start checkpoint {} ({})\", checkpointId, checkpointOptions);\n+\t\trethrow();\n+\t\tPreconditions.checkState(isRunning && asyncWriter.isAlive(), \"not running\");\n+\t\tChannelStateWriteResult result = new ChannelStateWriteResult();\n+\t\tChannelStateWriteResult put = results.computeIfAbsent(checkpointId, id -> {\n+\t\t\tPreconditions.checkArgument(results.size() < maxCheckpoints, \"results.size() > maxCheckpoints\", results.size(), maxCheckpoints);\n+\t\t\tenqueue(new CheckpointStartRequest(checkpointId, result, checkpointOptions.getTargetLocation()));\n+\t\t\treturn result;\n+\t\t});\n+\t\tPreconditions.checkArgument(put == result, \"result future already present for checkpoint id: \" + checkpointId);\n+\t}\n+\n+\t@Override\n+\tpublic void addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add input data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)));\n+\t}\n+\n+\t@Override\n+\tpublic void addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add output data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)));\n+\t}\n+\n+\t@Override\n+\tpublic void finishInput(long checkpointId) {\n+\t\tLOG.debug(\"finish input data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeInput(checkpointId));\n+\t}\n+\n+\t@Override\n+\tpublic void finishOutput(long checkpointId) {\n+\t\tLOG.debug(\"finish output data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeOutput(checkpointId));\n+\t}\n+\n+\t@Override\n+\tpublic ChannelStateWriteResult getWriteResult(long checkpointId) {\n+\t\tLOG.debug(\"requested write result, checkpoint id: {}\", checkpointId);\n+\t\tChannelStateWriteResult result = results.remove(checkpointId);\n+\t\tPreconditions.checkArgument(result != null, \"channel state write result not found for checkpoint id \" + checkpointId);\n+\t\treturn result;\n+\t}\n+\n+\tpublic void open() {\n+\t\tPreconditions.checkState(isRunning);\n+\t\tasyncWriter.start();\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tisRunning = false;\n+\t\tresults.clear();\n+\t\tasyncWriter.interrupt();\n+\t\twhile (asyncWriter.isAlive()) {\n+\t\t\ttry {\n+\t\t\t\tasyncWriter.join();\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tif (!asyncWriter.isAlive()) {\n+\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t}\n+\t\t\t\tLOG.debug(\"interrupted while waiting for the writer thread to die\", e);\n+\t\t\t}\n+\t\t}\n+\t\trethrow();\n+\t}\n+\n+\tprivate void enqueue(ChannelStateWriteRequest request) {\n+\t\trethrow();\n+\t\tPreconditions.checkState(isRunning);\n+\t\ttry {\n+\t\t\thandover.put(request);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new RuntimeException(\"Interrupted while trying to add new handover request\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void rethrow() {\n+\t\tif (thrown != null) {\n+\t\t\tthrow new RuntimeException(thrown); // wrap to record current stack-trace", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA1MDU2Mg=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 212}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDczMDQwMA==", "bodyText": "Yes, I understand and agree with you points to some extent. It is indeed a bit trouble to carry the specific exception in many different components, and also for the case to wrapper it in most lambda cases.\nMy previous example was for forcing the caller to release resources within try...finally to pass compiling if we announce the exception explicitly in interface method. Otherwise some callers might not have the good habit to always release resources within finally region, especially in tests.\nAnother minor concern was that we only announce the IllegalArgumentException for interface methods, and actually hide the other IOException , InteruphttedException to wrapper implicitly. My guessing is that we think the IllegalArgumentException is more important to bring alerts for callers. :)", "url": "https://github.com/apache/flink/pull/11515#discussion_r404730400", "createdAt": "2020-04-07T11:17:17Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\tprivate volatile boolean isRunning;\n+\tprivate volatile Exception thrown;\n+\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory) {\n+\t\tthis(streamFactoryFactory, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.\n+\t */\n+\tChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory, int maxCheckpoints) {\n+\t\tthis(streamFactoryFactory, DEFAULT_HANDOVER_CAPACITY, new ChannelStateSerializerImpl(), maxCheckpoints);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl}.\n+\t *\n+\t * @param maxCheckpoints maximum number of checkpoints to be written currently or finished but not taken yet.\n+\t */\n+\tChannelStateWriterImpl(\n+\t\t\tCheckpointStorageWorkerView streamFactory,\n+\t\t\tint handoverCapacity,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tint maxCheckpoints) {\n+\t\tthis.handover = new ArrayBlockingQueue<>(handoverCapacity);\n+\t\tthis.results = new ConcurrentHashMap<>(maxCheckpoints);\n+\t\tthis.maxCheckpoints = maxCheckpoints;\n+\t\tthis.asyncWriter = new Thread(new ProcessRequestsLoop(maxCheckpoints, streamFactory, serializer));\n+\t\tthis.isRunning = true;\n+\t}\n+\n+\t@Override\n+\tpublic void start(long checkpointId, CheckpointOptions checkpointOptions) {\n+\t\tLOG.debug(\"start checkpoint {} ({})\", checkpointId, checkpointOptions);\n+\t\trethrow();\n+\t\tPreconditions.checkState(isRunning && asyncWriter.isAlive(), \"not running\");\n+\t\tChannelStateWriteResult result = new ChannelStateWriteResult();\n+\t\tChannelStateWriteResult put = results.computeIfAbsent(checkpointId, id -> {\n+\t\t\tPreconditions.checkArgument(results.size() < maxCheckpoints, \"results.size() > maxCheckpoints\", results.size(), maxCheckpoints);\n+\t\t\tenqueue(new CheckpointStartRequest(checkpointId, result, checkpointOptions.getTargetLocation()));\n+\t\t\treturn result;\n+\t\t});\n+\t\tPreconditions.checkArgument(put == result, \"result future already present for checkpoint id: \" + checkpointId);\n+\t}\n+\n+\t@Override\n+\tpublic void addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add input data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)));\n+\t}\n+\n+\t@Override\n+\tpublic void addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add output data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)));\n+\t}\n+\n+\t@Override\n+\tpublic void finishInput(long checkpointId) {\n+\t\tLOG.debug(\"finish input data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeInput(checkpointId));\n+\t}\n+\n+\t@Override\n+\tpublic void finishOutput(long checkpointId) {\n+\t\tLOG.debug(\"finish output data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeOutput(checkpointId));\n+\t}\n+\n+\t@Override\n+\tpublic ChannelStateWriteResult getWriteResult(long checkpointId) {\n+\t\tLOG.debug(\"requested write result, checkpoint id: {}\", checkpointId);\n+\t\tChannelStateWriteResult result = results.remove(checkpointId);\n+\t\tPreconditions.checkArgument(result != null, \"channel state write result not found for checkpoint id \" + checkpointId);\n+\t\treturn result;\n+\t}\n+\n+\tpublic void open() {\n+\t\tPreconditions.checkState(isRunning);\n+\t\tasyncWriter.start();\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tisRunning = false;\n+\t\tresults.clear();\n+\t\tasyncWriter.interrupt();\n+\t\twhile (asyncWriter.isAlive()) {\n+\t\t\ttry {\n+\t\t\t\tasyncWriter.join();\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tif (!asyncWriter.isAlive()) {\n+\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t}\n+\t\t\t\tLOG.debug(\"interrupted while waiting for the writer thread to die\", e);\n+\t\t\t}\n+\t\t}\n+\t\trethrow();\n+\t}\n+\n+\tprivate void enqueue(ChannelStateWriteRequest request) {\n+\t\trethrow();\n+\t\tPreconditions.checkState(isRunning);\n+\t\ttry {\n+\t\t\thandover.put(request);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new RuntimeException(\"Interrupted while trying to add new handover request\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void rethrow() {\n+\t\tif (thrown != null) {\n+\t\t\tthrow new RuntimeException(thrown); // wrap to record current stack-trace", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA1MDU2Mg=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 212}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5MzQ2MTc4OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNDo1NjoyMlrOF_bQ7A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNTo1MzoyMFrOF_x6ww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA1MTMwOA==", "bodyText": "rethrow() -> checkError(), because it is not determined to throw exception.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402051308", "createdAt": "2020-04-02T04:56:22Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\tprivate volatile boolean isRunning;\n+\tprivate volatile Exception thrown;\n+\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory) {\n+\t\tthis(streamFactoryFactory, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.\n+\t */\n+\tChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory, int maxCheckpoints) {\n+\t\tthis(streamFactoryFactory, DEFAULT_HANDOVER_CAPACITY, new ChannelStateSerializerImpl(), maxCheckpoints);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl}.\n+\t *\n+\t * @param maxCheckpoints maximum number of checkpoints to be written currently or finished but not taken yet.\n+\t */\n+\tChannelStateWriterImpl(\n+\t\t\tCheckpointStorageWorkerView streamFactory,\n+\t\t\tint handoverCapacity,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tint maxCheckpoints) {\n+\t\tthis.handover = new ArrayBlockingQueue<>(handoverCapacity);\n+\t\tthis.results = new ConcurrentHashMap<>(maxCheckpoints);\n+\t\tthis.maxCheckpoints = maxCheckpoints;\n+\t\tthis.asyncWriter = new Thread(new ProcessRequestsLoop(maxCheckpoints, streamFactory, serializer));\n+\t\tthis.isRunning = true;\n+\t}\n+\n+\t@Override\n+\tpublic void start(long checkpointId, CheckpointOptions checkpointOptions) {\n+\t\tLOG.debug(\"start checkpoint {} ({})\", checkpointId, checkpointOptions);\n+\t\trethrow();\n+\t\tPreconditions.checkState(isRunning && asyncWriter.isAlive(), \"not running\");\n+\t\tChannelStateWriteResult result = new ChannelStateWriteResult();\n+\t\tChannelStateWriteResult put = results.computeIfAbsent(checkpointId, id -> {\n+\t\t\tPreconditions.checkArgument(results.size() < maxCheckpoints, \"results.size() > maxCheckpoints\", results.size(), maxCheckpoints);\n+\t\t\tenqueue(new CheckpointStartRequest(checkpointId, result, checkpointOptions.getTargetLocation()));\n+\t\t\treturn result;\n+\t\t});\n+\t\tPreconditions.checkArgument(put == result, \"result future already present for checkpoint id: \" + checkpointId);\n+\t}\n+\n+\t@Override\n+\tpublic void addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add input data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)));\n+\t}\n+\n+\t@Override\n+\tpublic void addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add output data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)));\n+\t}\n+\n+\t@Override\n+\tpublic void finishInput(long checkpointId) {\n+\t\tLOG.debug(\"finish input data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeInput(checkpointId));\n+\t}\n+\n+\t@Override\n+\tpublic void finishOutput(long checkpointId) {\n+\t\tLOG.debug(\"finish output data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeOutput(checkpointId));\n+\t}\n+\n+\t@Override\n+\tpublic ChannelStateWriteResult getWriteResult(long checkpointId) {\n+\t\tLOG.debug(\"requested write result, checkpoint id: {}\", checkpointId);\n+\t\tChannelStateWriteResult result = results.remove(checkpointId);\n+\t\tPreconditions.checkArgument(result != null, \"channel state write result not found for checkpoint id \" + checkpointId);\n+\t\treturn result;\n+\t}\n+\n+\tpublic void open() {\n+\t\tPreconditions.checkState(isRunning);\n+\t\tasyncWriter.start();\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tisRunning = false;\n+\t\tresults.clear();\n+\t\tasyncWriter.interrupt();\n+\t\twhile (asyncWriter.isAlive()) {\n+\t\t\ttry {\n+\t\t\t\tasyncWriter.join();\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tif (!asyncWriter.isAlive()) {\n+\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t}\n+\t\t\t\tLOG.debug(\"interrupted while waiting for the writer thread to die\", e);\n+\t\t\t}\n+\t\t}\n+\t\trethrow();\n+\t}\n+\n+\tprivate void enqueue(ChannelStateWriteRequest request) {\n+\t\trethrow();\n+\t\tPreconditions.checkState(isRunning);\n+\t\ttry {\n+\t\t\thandover.put(request);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new RuntimeException(\"Interrupted while trying to add new handover request\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void rethrow() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 210}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI4MjA1MA==", "bodyText": "checkError() sounds ambiguously to me.\nHow about rethrowIfAny()?", "url": "https://github.com/apache/flink/pull/11515#discussion_r402282050", "createdAt": "2020-04-02T12:42:08Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\tprivate volatile boolean isRunning;\n+\tprivate volatile Exception thrown;\n+\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory) {\n+\t\tthis(streamFactoryFactory, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.\n+\t */\n+\tChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory, int maxCheckpoints) {\n+\t\tthis(streamFactoryFactory, DEFAULT_HANDOVER_CAPACITY, new ChannelStateSerializerImpl(), maxCheckpoints);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl}.\n+\t *\n+\t * @param maxCheckpoints maximum number of checkpoints to be written currently or finished but not taken yet.\n+\t */\n+\tChannelStateWriterImpl(\n+\t\t\tCheckpointStorageWorkerView streamFactory,\n+\t\t\tint handoverCapacity,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tint maxCheckpoints) {\n+\t\tthis.handover = new ArrayBlockingQueue<>(handoverCapacity);\n+\t\tthis.results = new ConcurrentHashMap<>(maxCheckpoints);\n+\t\tthis.maxCheckpoints = maxCheckpoints;\n+\t\tthis.asyncWriter = new Thread(new ProcessRequestsLoop(maxCheckpoints, streamFactory, serializer));\n+\t\tthis.isRunning = true;\n+\t}\n+\n+\t@Override\n+\tpublic void start(long checkpointId, CheckpointOptions checkpointOptions) {\n+\t\tLOG.debug(\"start checkpoint {} ({})\", checkpointId, checkpointOptions);\n+\t\trethrow();\n+\t\tPreconditions.checkState(isRunning && asyncWriter.isAlive(), \"not running\");\n+\t\tChannelStateWriteResult result = new ChannelStateWriteResult();\n+\t\tChannelStateWriteResult put = results.computeIfAbsent(checkpointId, id -> {\n+\t\t\tPreconditions.checkArgument(results.size() < maxCheckpoints, \"results.size() > maxCheckpoints\", results.size(), maxCheckpoints);\n+\t\t\tenqueue(new CheckpointStartRequest(checkpointId, result, checkpointOptions.getTargetLocation()));\n+\t\t\treturn result;\n+\t\t});\n+\t\tPreconditions.checkArgument(put == result, \"result future already present for checkpoint id: \" + checkpointId);\n+\t}\n+\n+\t@Override\n+\tpublic void addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add input data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)));\n+\t}\n+\n+\t@Override\n+\tpublic void addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add output data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)));\n+\t}\n+\n+\t@Override\n+\tpublic void finishInput(long checkpointId) {\n+\t\tLOG.debug(\"finish input data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeInput(checkpointId));\n+\t}\n+\n+\t@Override\n+\tpublic void finishOutput(long checkpointId) {\n+\t\tLOG.debug(\"finish output data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeOutput(checkpointId));\n+\t}\n+\n+\t@Override\n+\tpublic ChannelStateWriteResult getWriteResult(long checkpointId) {\n+\t\tLOG.debug(\"requested write result, checkpoint id: {}\", checkpointId);\n+\t\tChannelStateWriteResult result = results.remove(checkpointId);\n+\t\tPreconditions.checkArgument(result != null, \"channel state write result not found for checkpoint id \" + checkpointId);\n+\t\treturn result;\n+\t}\n+\n+\tpublic void open() {\n+\t\tPreconditions.checkState(isRunning);\n+\t\tasyncWriter.start();\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tisRunning = false;\n+\t\tresults.clear();\n+\t\tasyncWriter.interrupt();\n+\t\twhile (asyncWriter.isAlive()) {\n+\t\t\ttry {\n+\t\t\t\tasyncWriter.join();\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tif (!asyncWriter.isAlive()) {\n+\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t}\n+\t\t\t\tLOG.debug(\"interrupted while waiting for the writer thread to die\", e);\n+\t\t\t}\n+\t\t}\n+\t\trethrow();\n+\t}\n+\n+\tprivate void enqueue(ChannelStateWriteRequest request) {\n+\t\trethrow();\n+\t\tPreconditions.checkState(isRunning);\n+\t\ttry {\n+\t\t\thandover.put(request);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new RuntimeException(\"Interrupted while trying to add new handover request\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void rethrow() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA1MTMwOA=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 210}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQyMjQ2Nw==", "bodyText": "That is fine for me. I only referred to the way in InputChannel#checkError. :)", "url": "https://github.com/apache/flink/pull/11515#discussion_r402422467", "createdAt": "2020-04-02T15:53:20Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\tprivate volatile boolean isRunning;\n+\tprivate volatile Exception thrown;\n+\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory) {\n+\t\tthis(streamFactoryFactory, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.\n+\t */\n+\tChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory, int maxCheckpoints) {\n+\t\tthis(streamFactoryFactory, DEFAULT_HANDOVER_CAPACITY, new ChannelStateSerializerImpl(), maxCheckpoints);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl}.\n+\t *\n+\t * @param maxCheckpoints maximum number of checkpoints to be written currently or finished but not taken yet.\n+\t */\n+\tChannelStateWriterImpl(\n+\t\t\tCheckpointStorageWorkerView streamFactory,\n+\t\t\tint handoverCapacity,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tint maxCheckpoints) {\n+\t\tthis.handover = new ArrayBlockingQueue<>(handoverCapacity);\n+\t\tthis.results = new ConcurrentHashMap<>(maxCheckpoints);\n+\t\tthis.maxCheckpoints = maxCheckpoints;\n+\t\tthis.asyncWriter = new Thread(new ProcessRequestsLoop(maxCheckpoints, streamFactory, serializer));\n+\t\tthis.isRunning = true;\n+\t}\n+\n+\t@Override\n+\tpublic void start(long checkpointId, CheckpointOptions checkpointOptions) {\n+\t\tLOG.debug(\"start checkpoint {} ({})\", checkpointId, checkpointOptions);\n+\t\trethrow();\n+\t\tPreconditions.checkState(isRunning && asyncWriter.isAlive(), \"not running\");\n+\t\tChannelStateWriteResult result = new ChannelStateWriteResult();\n+\t\tChannelStateWriteResult put = results.computeIfAbsent(checkpointId, id -> {\n+\t\t\tPreconditions.checkArgument(results.size() < maxCheckpoints, \"results.size() > maxCheckpoints\", results.size(), maxCheckpoints);\n+\t\t\tenqueue(new CheckpointStartRequest(checkpointId, result, checkpointOptions.getTargetLocation()));\n+\t\t\treturn result;\n+\t\t});\n+\t\tPreconditions.checkArgument(put == result, \"result future already present for checkpoint id: \" + checkpointId);\n+\t}\n+\n+\t@Override\n+\tpublic void addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add input data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)));\n+\t}\n+\n+\t@Override\n+\tpublic void addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add output data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)));\n+\t}\n+\n+\t@Override\n+\tpublic void finishInput(long checkpointId) {\n+\t\tLOG.debug(\"finish input data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeInput(checkpointId));\n+\t}\n+\n+\t@Override\n+\tpublic void finishOutput(long checkpointId) {\n+\t\tLOG.debug(\"finish output data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeOutput(checkpointId));\n+\t}\n+\n+\t@Override\n+\tpublic ChannelStateWriteResult getWriteResult(long checkpointId) {\n+\t\tLOG.debug(\"requested write result, checkpoint id: {}\", checkpointId);\n+\t\tChannelStateWriteResult result = results.remove(checkpointId);\n+\t\tPreconditions.checkArgument(result != null, \"channel state write result not found for checkpoint id \" + checkpointId);\n+\t\treturn result;\n+\t}\n+\n+\tpublic void open() {\n+\t\tPreconditions.checkState(isRunning);\n+\t\tasyncWriter.start();\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tisRunning = false;\n+\t\tresults.clear();\n+\t\tasyncWriter.interrupt();\n+\t\twhile (asyncWriter.isAlive()) {\n+\t\t\ttry {\n+\t\t\t\tasyncWriter.join();\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tif (!asyncWriter.isAlive()) {\n+\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t}\n+\t\t\t\tLOG.debug(\"interrupted while waiting for the writer thread to die\", e);\n+\t\t\t}\n+\t\t}\n+\t\trethrow();\n+\t}\n+\n+\tprivate void enqueue(ChannelStateWriteRequest request) {\n+\t\trethrow();\n+\t\tPreconditions.checkState(isRunning);\n+\t\ttry {\n+\t\t\thandover.put(request);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new RuntimeException(\"Interrupted while trying to add new handover request\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void rethrow() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA1MTMwOA=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 210}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5MzU0MDIwOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNTo0MDo1OFrOF_b-0Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQyMDozNDowM1rOGBo1ew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA2MzA1Nw==", "bodyText": "I am wondering it might have the possibility to add a request after clearing it, to make the new added one never removed.\nE.g.\nthread 1: #enqueue to execute rethrow and thrown is null atm\nthread 2: set thrown = ex and clear the handover as above\nthread 1: #enqueue to execute handover#put", "url": "https://github.com/apache/flink/pull/11515#discussion_r402063057", "createdAt": "2020-04-02T05:40:58Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM3MDgxMQ==", "bodyText": "You're right, it's a race condition, thanks for pointing out.\nI've added a cleanup call after adding to the queue.", "url": "https://github.com/apache/flink/pull/11515#discussion_r404370811", "createdAt": "2020-04-06T20:34:03Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA2MzA1Nw=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 72}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5MzU0MzQ2OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNTo0Mjo1NVrOF_cA0A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNTo0Mjo1NVrOF_cA0A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA2MzU2OA==", "bodyText": "It is weird to give a RuntimeException for the normal end. The requestProcessor.cleanup should allow a nullable exception.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402063568", "createdAt": "2020-04-02T05:42:55Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 73}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5MzU1MTk2OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNTo0NzoyOVrOF_cF3Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQyMDoyMjo1NlrOGBoc1g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA2NDg2MQ==", "bodyText": "what is the consideration to swallow the InterruptedException in this case. Do we want to exit this thread early when encountering InterruptedException? Also LOG.warn instead?", "url": "https://github.com/apache/flink/pull/11515#discussion_r402064861", "createdAt": "2020-04-02T05:47:29Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM2NDUwMg==", "bodyText": "AFAIK, one possible reason for InterruptedException is \"spurious wakeups\".\nHere, the \"right\" way to interrupt worker thread is to first set isRunning to false and then interrupt.\nSo if after the interrupt isRunning is true then it's a spurious wakeup and thread continues.", "url": "https://github.com/apache/flink/pull/11515#discussion_r404364502", "createdAt": "2020-04-06T20:22:56Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA2NDg2MQ=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 84}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5Mzc0ODI2OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNzowNToyMFrOF_d4Ng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQwNzo1MTo1M1rOGBLr7Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA5NDEzNA==", "bodyText": "If we confirm this map has concurrent issues, then it should be defined as ConcurrentHashMap explicitly.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402094134", "createdAt": "2020-04-02T07:05:20Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 96}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzg5MzIyOQ==", "bodyText": "Yes, I'll change it, thanks (I believe you meant ConcurrentMap not ConcurrentHashMap).", "url": "https://github.com/apache/flink/pull/11515#discussion_r403893229", "createdAt": "2020-04-06T07:51:53Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA5NDEzNA=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 96}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5Mzc2MTI5OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestProcessor.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNzowOTo0MVrOF_eADw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNzowOTo0MVrOF_eADw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA5NjE0Mw==", "bodyText": "nit: checkNotNull for two arguments", "url": "https://github.com/apache/flink/pull/11515#discussion_r402096143", "createdAt": "2020-04-02T07:09:41Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestProcessor.java", "diffHunk": "@@ -0,0 +1,77 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+/**\n+ * Maintains a set of {@link ChannelStateCheckpointWriter writers} per checkpoint and translates incoming\n+ * {@link ChannelStateWriteRequest requests} to their corresponding methods.\n+ */\n+final class ChannelStateWriteRequestProcessor {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriteRequestProcessor.class);\n+\n+\tprivate final Map<Long, ChannelStateCheckpointWriter> writers; // limited indirectly by results max size\n+\tprivate final CheckpointStorageWorkerView streamFactoryFactory;\n+\tprivate final ChannelStateSerializer serializer;\n+\n+\tChannelStateWriteRequestProcessor(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\tthis.writers = new HashMap<>(maxCheckpoints);\n+\t\tthis.streamFactoryFactory = streamFactoryFactory;\n+\t\tthis.serializer = serializer;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 43}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5Mzc2Njc1OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestProcessor.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNzoxMTozN1rOF_eDbQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNzoxMTozN1rOF_eDbQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA5NzAwNQ==", "bodyText": "ditto: weird naming for me", "url": "https://github.com/apache/flink/pull/11515#discussion_r402097005", "createdAt": "2020-04-02T07:11:37Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestProcessor.java", "diffHunk": "@@ -0,0 +1,77 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+/**\n+ * Maintains a set of {@link ChannelStateCheckpointWriter writers} per checkpoint and translates incoming\n+ * {@link ChannelStateWriteRequest requests} to their corresponding methods.\n+ */\n+final class ChannelStateWriteRequestProcessor {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriteRequestProcessor.class);\n+\n+\tprivate final Map<Long, ChannelStateCheckpointWriter> writers; // limited indirectly by results max size\n+\tprivate final CheckpointStorageWorkerView streamFactoryFactory;\n+\tprivate final ChannelStateSerializer serializer;\n+\n+\tChannelStateWriteRequestProcessor(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\tthis.writers = new HashMap<>(maxCheckpoints);\n+\t\tthis.streamFactoryFactory = streamFactoryFactory;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 42}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5Mzc5OTM2OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateCheckpointWriter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNzoyMjoyM1rOF_eXYA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNzoyMjoyM1rOF_eXYA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjEwMjExMg==", "bodyText": "I suggest removing this constructor to avoid introducing multiple constructors to maintain, except for easing tests purpose. But here is not that case.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402102112", "createdAt": "2020-04-02T07:22:23Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateCheckpointWriter.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory.CheckpointStateOutputStream;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.runtime.state.ResultSubpartitionStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.BiFunction;\n+\n+import static org.apache.flink.runtime.state.CheckpointedStateScope.EXCLUSIVE;\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+\n+/**\n+ * Writes channel state for a specific checkpoint-subtask-attempt triple.\n+ */\n+@NotThreadSafe\n+class ChannelStateCheckpointWriter {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateCheckpointWriter.class);\n+\n+\tprivate final DataOutputStream dataStream;\n+\tprivate final CheckpointStateOutputStream checkpointStream;\n+\tprivate final ChannelStateWriteResult result;\n+\tprivate final Map<InputChannelInfo, List<Long>> inputChannelOffsets = new HashMap<>();\n+\tprivate final Map<ResultSubpartitionInfo, List<Long>> resultSubpartitionOffsets = new HashMap<>();\n+\tprivate final ChannelStateSerializer serializer;\n+\tprivate final long checkpointId;\n+\tprivate boolean inputCompleted = false;\n+\tprivate boolean outputCompleted = false;\n+\tprivate final Runnable onComplete;\n+\n+\tChannelStateCheckpointWriter(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 67}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5MzgxMTA5OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateCheckpointWriter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNzoyNTo1NlrOF_eedQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNzoyNTo1NlrOF_eedQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjEwMzkyNQ==", "bodyText": "nit: better to keep the sequence as above arguments", "url": "https://github.com/apache/flink/pull/11515#discussion_r402103925", "createdAt": "2020-04-02T07:25:56Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateCheckpointWriter.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory.CheckpointStateOutputStream;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.runtime.state.ResultSubpartitionStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.BiFunction;\n+\n+import static org.apache.flink.runtime.state.CheckpointedStateScope.EXCLUSIVE;\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+\n+/**\n+ * Writes channel state for a specific checkpoint-subtask-attempt triple.\n+ */\n+@NotThreadSafe\n+class ChannelStateCheckpointWriter {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateCheckpointWriter.class);\n+\n+\tprivate final DataOutputStream dataStream;\n+\tprivate final CheckpointStateOutputStream checkpointStream;\n+\tprivate final ChannelStateWriteResult result;\n+\tprivate final Map<InputChannelInfo, List<Long>> inputChannelOffsets = new HashMap<>();\n+\tprivate final Map<ResultSubpartitionInfo, List<Long>> resultSubpartitionOffsets = new HashMap<>();\n+\tprivate final ChannelStateSerializer serializer;\n+\tprivate final long checkpointId;\n+\tprivate boolean inputCompleted = false;\n+\tprivate boolean outputCompleted = false;\n+\tprivate final Runnable onComplete;\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tCheckpointStartRequest startCheckpointItem,\n+\t\t\tCheckpointStreamFactory streamFactory,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete) throws Exception {\n+\t\tthis(startCheckpointItem.checkpointId, startCheckpointItem.targetResult, streamFactory.createCheckpointStateOutputStream(EXCLUSIVE), serializer, onComplete);\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tCheckpointStateOutputStream stream,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete) throws Exception {\n+\t\tthis(checkpointId, result, serializer, onComplete, stream, new DataOutputStream(stream));\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete,\n+\t\t\tCheckpointStateOutputStream checkpointStateOutputStream,\n+\t\t\tDataOutputStream dataStream) throws Exception {\n+\t\tthis.checkpointId = checkpointId;\n+\t\tthis.result = checkNotNull(result);\n+\t\tthis.checkpointStream = checkNotNull(checkpointStateOutputStream);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 93}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5MzgzNTc0OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNzozMzo1NFrOF_et-A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNzozMzo1NFrOF_et-A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjEwNzg5Ng==", "bodyText": "nit: it is weird for me to emphasis flinkBuffers, buffers should be ok.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402107896", "createdAt": "2020-04-02T07:33:54Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequest.java", "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageLocationReference;\n+import org.apache.flink.util.function.ThrowingConsumer;\n+\n+abstract class ChannelStateWriteRequest {\n+\tfinal long checkpointId;\n+\n+\tChannelStateWriteRequest(long checkpointId) {\n+\t\tthis.checkpointId = checkpointId;\n+\t}\n+\n+\t@Override\n+\tpublic String toString() {\n+\t\treturn getClass().getSimpleName() + \", checkpointId=\" + checkpointId;\n+\t}\n+\n+\tstatic CheckpointInProgressRequest completeInput(long checkpointId) {\n+\t\treturn new CheckpointInProgressRequest(checkpointId, ChannelStateCheckpointWriter::completeInput);\n+\t}\n+\n+\tstatic CheckpointInProgressRequest completeOutput(long checkpointId) {\n+\t\treturn new CheckpointInProgressRequest(checkpointId, ChannelStateCheckpointWriter::completeOutput);\n+\t}\n+\n+\tstatic ChannelStateWriteRequest write(long checkpointId, InputChannelInfo info, Buffer... flinkBuffers) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 45}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5MzgzNzIzOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNzozNDoxM1rOF_euxw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNzozNDoxM1rOF_euxw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjEwODEwMw==", "bodyText": "nit: checkNotNull", "url": "https://github.com/apache/flink/pull/11515#discussion_r402108103", "createdAt": "2020-04-02T07:34:13Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequest.java", "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageLocationReference;\n+import org.apache.flink.util.function.ThrowingConsumer;\n+\n+abstract class ChannelStateWriteRequest {\n+\tfinal long checkpointId;\n+\n+\tChannelStateWriteRequest(long checkpointId) {\n+\t\tthis.checkpointId = checkpointId;\n+\t}\n+\n+\t@Override\n+\tpublic String toString() {\n+\t\treturn getClass().getSimpleName() + \", checkpointId=\" + checkpointId;\n+\t}\n+\n+\tstatic CheckpointInProgressRequest completeInput(long checkpointId) {\n+\t\treturn new CheckpointInProgressRequest(checkpointId, ChannelStateCheckpointWriter::completeInput);\n+\t}\n+\n+\tstatic CheckpointInProgressRequest completeOutput(long checkpointId) {\n+\t\treturn new CheckpointInProgressRequest(checkpointId, ChannelStateCheckpointWriter::completeOutput);\n+\t}\n+\n+\tstatic ChannelStateWriteRequest write(long checkpointId, InputChannelInfo info, Buffer... flinkBuffers) {\n+\t\treturn new CheckpointInProgressRequest(checkpointId, writer -> writer.writeInput(info, flinkBuffers));\n+\t}\n+\n+\tstatic ChannelStateWriteRequest write(long checkpointId, ResultSubpartitionInfo info, Buffer... flinkBuffers) {\n+\t\treturn new CheckpointInProgressRequest(checkpointId, writer -> writer.writeOutput(info, flinkBuffers));\n+\t}\n+}\n+\n+final class CheckpointStartRequest extends ChannelStateWriteRequest {\n+\tfinal ChannelStateWriteResult targetResult;\n+\tfinal CheckpointStorageLocationReference locationReference;\n+\n+\tCheckpointStartRequest(long checkpointId, ChannelStateWriteResult targetResult, CheckpointStorageLocationReference locationReference) {\n+\t\tsuper(checkpointId);\n+\t\tthis.targetResult = targetResult;\n+\t\tthis.locationReference = locationReference;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 61}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5MzgzNzk2OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNzozNDozMFrOF_evQQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNzozNDozMFrOF_evQQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjEwODIyNQ==", "bodyText": "ditto: checkNotNull", "url": "https://github.com/apache/flink/pull/11515#discussion_r402108225", "createdAt": "2020-04-02T07:34:30Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequest.java", "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageLocationReference;\n+import org.apache.flink.util.function.ThrowingConsumer;\n+\n+abstract class ChannelStateWriteRequest {\n+\tfinal long checkpointId;\n+\n+\tChannelStateWriteRequest(long checkpointId) {\n+\t\tthis.checkpointId = checkpointId;\n+\t}\n+\n+\t@Override\n+\tpublic String toString() {\n+\t\treturn getClass().getSimpleName() + \", checkpointId=\" + checkpointId;\n+\t}\n+\n+\tstatic CheckpointInProgressRequest completeInput(long checkpointId) {\n+\t\treturn new CheckpointInProgressRequest(checkpointId, ChannelStateCheckpointWriter::completeInput);\n+\t}\n+\n+\tstatic CheckpointInProgressRequest completeOutput(long checkpointId) {\n+\t\treturn new CheckpointInProgressRequest(checkpointId, ChannelStateCheckpointWriter::completeOutput);\n+\t}\n+\n+\tstatic ChannelStateWriteRequest write(long checkpointId, InputChannelInfo info, Buffer... flinkBuffers) {\n+\t\treturn new CheckpointInProgressRequest(checkpointId, writer -> writer.writeInput(info, flinkBuffers));\n+\t}\n+\n+\tstatic ChannelStateWriteRequest write(long checkpointId, ResultSubpartitionInfo info, Buffer... flinkBuffers) {\n+\t\treturn new CheckpointInProgressRequest(checkpointId, writer -> writer.writeOutput(info, flinkBuffers));\n+\t}\n+}\n+\n+final class CheckpointStartRequest extends ChannelStateWriteRequest {\n+\tfinal ChannelStateWriteResult targetResult;\n+\tfinal CheckpointStorageLocationReference locationReference;\n+\n+\tCheckpointStartRequest(long checkpointId, ChannelStateWriteResult targetResult, CheckpointStorageLocationReference locationReference) {\n+\t\tsuper(checkpointId);\n+\t\tthis.targetResult = targetResult;\n+\t\tthis.locationReference = locationReference;\n+\t}\n+}\n+\n+final class CheckpointInProgressRequest extends ChannelStateWriteRequest {\n+\tfinal ThrowingConsumer<ChannelStateCheckpointWriter, Exception> action;\n+\n+\tCheckpointInProgressRequest(long checkpointId, ThrowingConsumer<ChannelStateCheckpointWriter, Exception> action) {\n+\t\tsuper(checkpointId);\n+\t\tthis.action = action;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 70}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5Mzg4MDcyOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateCheckpointWriter.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNzo0NzozOVrOF_fJ9Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNzo0NzozOVrOF_fJ9Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjExNTA2MQ==", "bodyText": "nit: r -> runnable", "url": "https://github.com/apache/flink/pull/11515#discussion_r402115061", "createdAt": "2020-04-02T07:47:39Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateCheckpointWriter.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory.CheckpointStateOutputStream;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.runtime.state.ResultSubpartitionStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.BiFunction;\n+\n+import static org.apache.flink.runtime.state.CheckpointedStateScope.EXCLUSIVE;\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+\n+/**\n+ * Writes channel state for a specific checkpoint-subtask-attempt triple.\n+ */\n+@NotThreadSafe\n+class ChannelStateCheckpointWriter {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateCheckpointWriter.class);\n+\n+\tprivate final DataOutputStream dataStream;\n+\tprivate final CheckpointStateOutputStream checkpointStream;\n+\tprivate final ChannelStateWriteResult result;\n+\tprivate final Map<InputChannelInfo, List<Long>> inputChannelOffsets = new HashMap<>();\n+\tprivate final Map<ResultSubpartitionInfo, List<Long>> resultSubpartitionOffsets = new HashMap<>();\n+\tprivate final ChannelStateSerializer serializer;\n+\tprivate final long checkpointId;\n+\tprivate boolean inputCompleted = false;\n+\tprivate boolean outputCompleted = false;\n+\tprivate final Runnable onComplete;\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tCheckpointStartRequest startCheckpointItem,\n+\t\t\tCheckpointStreamFactory streamFactory,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete) throws Exception {\n+\t\tthis(startCheckpointItem.checkpointId, startCheckpointItem.targetResult, streamFactory.createCheckpointStateOutputStream(EXCLUSIVE), serializer, onComplete);\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tCheckpointStateOutputStream stream,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete) throws Exception {\n+\t\tthis(checkpointId, result, serializer, onComplete, stream, new DataOutputStream(stream));\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete,\n+\t\t\tCheckpointStateOutputStream checkpointStateOutputStream,\n+\t\t\tDataOutputStream dataStream) throws Exception {\n+\t\tthis.checkpointId = checkpointId;\n+\t\tthis.result = checkNotNull(result);\n+\t\tthis.checkpointStream = checkNotNull(checkpointStateOutputStream);\n+\t\tthis.serializer = checkNotNull(serializer);\n+\t\tthis.dataStream = checkNotNull(dataStream);\n+\t\tthis.onComplete = checkNotNull(onComplete);\n+\t\trunWithChecks(() -> serializer.writeHeader(dataStream));\n+\t}\n+\n+\tvoid writeInput(InputChannelInfo info, Buffer... flinkBuffers) throws Exception {\n+\t\tPreconditions.checkState(!inputCompleted);\n+\t\twrite(inputChannelOffsets, info, flinkBuffers);\n+\t}\n+\n+\tvoid writeOutput(ResultSubpartitionInfo info, Buffer[] flinkBuffers) throws Exception {\n+\t\tPreconditions.checkState(!outputCompleted);\n+\t\twrite(resultSubpartitionOffsets, info, flinkBuffers);\n+\t}\n+\n+\tprivate <K> void write(Map<K, List<Long>> offsets, K key, Buffer[] flinkBuffers) throws Exception {\n+\t\trunWithChecks(() -> {\n+\t\t\ttry {\n+\t\t\t\toffsets\n+\t\t\t\t\t.computeIfAbsent(key, unused -> new ArrayList<>())\n+\t\t\t\t\t.add(checkpointStream.getPos());\n+\t\t\t\tserializer.writeData(dataStream, flinkBuffers);\n+\t\t\t} finally {\n+\t\t\t\tfor (Buffer flinkBuffer : flinkBuffers) {\n+\t\t\t\t\tflinkBuffer.recycleBuffer();\n+\t\t\t\t}\n+\t\t\t}\n+\t\t});\n+\t}\n+\n+\tvoid completeInput() throws Exception {\n+\t\tLOG.debug(\"complete input, output completed: {}\", outputCompleted);\n+\t\trunWithChecks(() -> {\n+\t\t\tPreconditions.checkState(!inputCompleted);\n+\t\t\tinputCompleted = true;\n+\t\t\tcomplete();\n+\t\t});\n+\t}\n+\n+\tvoid completeOutput() throws Exception {\n+\t\tLOG.debug(\"complete output, input completed: {}\", inputCompleted);\n+\t\trunWithChecks(() -> {\n+\t\t\tPreconditions.checkState(!outputCompleted);\n+\t\t\toutputCompleted = true;\n+\t\t\tcomplete();\n+\t\t});\n+\t}\n+\n+\tprivate void complete() throws IOException {\n+\t\tif (inputCompleted && outputCompleted) {\n+\t\t\tonComplete.run();\n+\t\t\tdataStream.flush();\n+\t\t\tStreamStateHandle underlying = checkpointStream.closeAndGetHandle();\n+\t\t\tcomplete(\n+\t\t\t\tresult.inputChannelStateHandles,\n+\t\t\t\tinputChannelOffsets,\n+\t\t\t\t(chan, offsets) -> new InputChannelStateHandle(chan, underlying, offsets));\n+\t\t\tcomplete(\n+\t\t\t\tresult.resultSubpartitionStateHandles,\n+\t\t\t\tresultSubpartitionOffsets,\n+\t\t\t\t(chan, offsets) -> new ResultSubpartitionStateHandle(chan, underlying, offsets));\n+\t\t}\n+\t}\n+\n+\tprivate <I, H extends AbstractChannelStateHandle<I>> void complete(\n+\t\tCompletableFuture<Collection<H>> future,\n+\t\tMap<I, List<Long>> offsets,\n+\t\tBiFunction<I, List<Long>, H> buildHandle) {\n+\t\tfinal Collection<H> handles = new ArrayList<>();\n+\t\tfor (Map.Entry<I, List<Long>> e : offsets.entrySet()) {\n+\t\t\thandles.add(buildHandle.apply(e.getKey(), e.getValue()));\n+\t\t}\n+\t\tfuture.complete(handles);\n+\t\tLOG.debug(\"channel state write completed, checkpointId: {}, handles: {}\", checkpointId, handles);\n+\t}\n+\n+\tprivate void runWithChecks(RunnableWithException r) throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 171}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5MzkxMzAzOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateCheckpointWriter.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNzo1NTo1NlrOF_fd5w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNzo1NTo1NlrOF_fd5w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjEyMDE2Nw==", "bodyText": "chan -> info?", "url": "https://github.com/apache/flink/pull/11515#discussion_r402120167", "createdAt": "2020-04-02T07:55:56Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateCheckpointWriter.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory.CheckpointStateOutputStream;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.runtime.state.ResultSubpartitionStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.BiFunction;\n+\n+import static org.apache.flink.runtime.state.CheckpointedStateScope.EXCLUSIVE;\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+\n+/**\n+ * Writes channel state for a specific checkpoint-subtask-attempt triple.\n+ */\n+@NotThreadSafe\n+class ChannelStateCheckpointWriter {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateCheckpointWriter.class);\n+\n+\tprivate final DataOutputStream dataStream;\n+\tprivate final CheckpointStateOutputStream checkpointStream;\n+\tprivate final ChannelStateWriteResult result;\n+\tprivate final Map<InputChannelInfo, List<Long>> inputChannelOffsets = new HashMap<>();\n+\tprivate final Map<ResultSubpartitionInfo, List<Long>> resultSubpartitionOffsets = new HashMap<>();\n+\tprivate final ChannelStateSerializer serializer;\n+\tprivate final long checkpointId;\n+\tprivate boolean inputCompleted = false;\n+\tprivate boolean outputCompleted = false;\n+\tprivate final Runnable onComplete;\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tCheckpointStartRequest startCheckpointItem,\n+\t\t\tCheckpointStreamFactory streamFactory,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete) throws Exception {\n+\t\tthis(startCheckpointItem.checkpointId, startCheckpointItem.targetResult, streamFactory.createCheckpointStateOutputStream(EXCLUSIVE), serializer, onComplete);\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tCheckpointStateOutputStream stream,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete) throws Exception {\n+\t\tthis(checkpointId, result, serializer, onComplete, stream, new DataOutputStream(stream));\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete,\n+\t\t\tCheckpointStateOutputStream checkpointStateOutputStream,\n+\t\t\tDataOutputStream dataStream) throws Exception {\n+\t\tthis.checkpointId = checkpointId;\n+\t\tthis.result = checkNotNull(result);\n+\t\tthis.checkpointStream = checkNotNull(checkpointStateOutputStream);\n+\t\tthis.serializer = checkNotNull(serializer);\n+\t\tthis.dataStream = checkNotNull(dataStream);\n+\t\tthis.onComplete = checkNotNull(onComplete);\n+\t\trunWithChecks(() -> serializer.writeHeader(dataStream));\n+\t}\n+\n+\tvoid writeInput(InputChannelInfo info, Buffer... flinkBuffers) throws Exception {\n+\t\tPreconditions.checkState(!inputCompleted);\n+\t\twrite(inputChannelOffsets, info, flinkBuffers);\n+\t}\n+\n+\tvoid writeOutput(ResultSubpartitionInfo info, Buffer[] flinkBuffers) throws Exception {\n+\t\tPreconditions.checkState(!outputCompleted);\n+\t\twrite(resultSubpartitionOffsets, info, flinkBuffers);\n+\t}\n+\n+\tprivate <K> void write(Map<K, List<Long>> offsets, K key, Buffer[] flinkBuffers) throws Exception {\n+\t\trunWithChecks(() -> {\n+\t\t\ttry {\n+\t\t\t\toffsets\n+\t\t\t\t\t.computeIfAbsent(key, unused -> new ArrayList<>())\n+\t\t\t\t\t.add(checkpointStream.getPos());\n+\t\t\t\tserializer.writeData(dataStream, flinkBuffers);\n+\t\t\t} finally {\n+\t\t\t\tfor (Buffer flinkBuffer : flinkBuffers) {\n+\t\t\t\t\tflinkBuffer.recycleBuffer();\n+\t\t\t\t}\n+\t\t\t}\n+\t\t});\n+\t}\n+\n+\tvoid completeInput() throws Exception {\n+\t\tLOG.debug(\"complete input, output completed: {}\", outputCompleted);\n+\t\trunWithChecks(() -> {\n+\t\t\tPreconditions.checkState(!inputCompleted);\n+\t\t\tinputCompleted = true;\n+\t\t\tcomplete();\n+\t\t});\n+\t}\n+\n+\tvoid completeOutput() throws Exception {\n+\t\tLOG.debug(\"complete output, input completed: {}\", inputCompleted);\n+\t\trunWithChecks(() -> {\n+\t\t\tPreconditions.checkState(!outputCompleted);\n+\t\t\toutputCompleted = true;\n+\t\t\tcomplete();\n+\t\t});\n+\t}\n+\n+\tprivate void complete() throws IOException {\n+\t\tif (inputCompleted && outputCompleted) {\n+\t\t\tonComplete.run();\n+\t\t\tdataStream.flush();\n+\t\t\tStreamStateHandle underlying = checkpointStream.closeAndGetHandle();\n+\t\t\tcomplete(\n+\t\t\t\tresult.inputChannelStateHandles,\n+\t\t\t\tinputChannelOffsets,\n+\t\t\t\t(chan, offsets) -> new InputChannelStateHandle(chan, underlying, offsets));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 151}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5Mzk4NjYzOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateCheckpointWriter.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwODoxNzowMlrOF_gLhw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwODoxNzowMlrOF_gLhw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjEzMTg0Nw==", "bodyText": "chan -> info?", "url": "https://github.com/apache/flink/pull/11515#discussion_r402131847", "createdAt": "2020-04-02T08:17:02Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateCheckpointWriter.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory.CheckpointStateOutputStream;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.runtime.state.ResultSubpartitionStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.BiFunction;\n+\n+import static org.apache.flink.runtime.state.CheckpointedStateScope.EXCLUSIVE;\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+\n+/**\n+ * Writes channel state for a specific checkpoint-subtask-attempt triple.\n+ */\n+@NotThreadSafe\n+class ChannelStateCheckpointWriter {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateCheckpointWriter.class);\n+\n+\tprivate final DataOutputStream dataStream;\n+\tprivate final CheckpointStateOutputStream checkpointStream;\n+\tprivate final ChannelStateWriteResult result;\n+\tprivate final Map<InputChannelInfo, List<Long>> inputChannelOffsets = new HashMap<>();\n+\tprivate final Map<ResultSubpartitionInfo, List<Long>> resultSubpartitionOffsets = new HashMap<>();\n+\tprivate final ChannelStateSerializer serializer;\n+\tprivate final long checkpointId;\n+\tprivate boolean inputCompleted = false;\n+\tprivate boolean outputCompleted = false;\n+\tprivate final Runnable onComplete;\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tCheckpointStartRequest startCheckpointItem,\n+\t\t\tCheckpointStreamFactory streamFactory,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete) throws Exception {\n+\t\tthis(startCheckpointItem.checkpointId, startCheckpointItem.targetResult, streamFactory.createCheckpointStateOutputStream(EXCLUSIVE), serializer, onComplete);\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tCheckpointStateOutputStream stream,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete) throws Exception {\n+\t\tthis(checkpointId, result, serializer, onComplete, stream, new DataOutputStream(stream));\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete,\n+\t\t\tCheckpointStateOutputStream checkpointStateOutputStream,\n+\t\t\tDataOutputStream dataStream) throws Exception {\n+\t\tthis.checkpointId = checkpointId;\n+\t\tthis.result = checkNotNull(result);\n+\t\tthis.checkpointStream = checkNotNull(checkpointStateOutputStream);\n+\t\tthis.serializer = checkNotNull(serializer);\n+\t\tthis.dataStream = checkNotNull(dataStream);\n+\t\tthis.onComplete = checkNotNull(onComplete);\n+\t\trunWithChecks(() -> serializer.writeHeader(dataStream));\n+\t}\n+\n+\tvoid writeInput(InputChannelInfo info, Buffer... flinkBuffers) throws Exception {\n+\t\tPreconditions.checkState(!inputCompleted);\n+\t\twrite(inputChannelOffsets, info, flinkBuffers);\n+\t}\n+\n+\tvoid writeOutput(ResultSubpartitionInfo info, Buffer[] flinkBuffers) throws Exception {\n+\t\tPreconditions.checkState(!outputCompleted);\n+\t\twrite(resultSubpartitionOffsets, info, flinkBuffers);\n+\t}\n+\n+\tprivate <K> void write(Map<K, List<Long>> offsets, K key, Buffer[] flinkBuffers) throws Exception {\n+\t\trunWithChecks(() -> {\n+\t\t\ttry {\n+\t\t\t\toffsets\n+\t\t\t\t\t.computeIfAbsent(key, unused -> new ArrayList<>())\n+\t\t\t\t\t.add(checkpointStream.getPos());\n+\t\t\t\tserializer.writeData(dataStream, flinkBuffers);\n+\t\t\t} finally {\n+\t\t\t\tfor (Buffer flinkBuffer : flinkBuffers) {\n+\t\t\t\t\tflinkBuffer.recycleBuffer();\n+\t\t\t\t}\n+\t\t\t}\n+\t\t});\n+\t}\n+\n+\tvoid completeInput() throws Exception {\n+\t\tLOG.debug(\"complete input, output completed: {}\", outputCompleted);\n+\t\trunWithChecks(() -> {\n+\t\t\tPreconditions.checkState(!inputCompleted);\n+\t\t\tinputCompleted = true;\n+\t\t\tcomplete();\n+\t\t});\n+\t}\n+\n+\tvoid completeOutput() throws Exception {\n+\t\tLOG.debug(\"complete output, input completed: {}\", inputCompleted);\n+\t\trunWithChecks(() -> {\n+\t\t\tPreconditions.checkState(!outputCompleted);\n+\t\t\toutputCompleted = true;\n+\t\t\tcomplete();\n+\t\t});\n+\t}\n+\n+\tprivate void complete() throws IOException {\n+\t\tif (inputCompleted && outputCompleted) {\n+\t\t\tonComplete.run();\n+\t\t\tdataStream.flush();\n+\t\t\tStreamStateHandle underlying = checkpointStream.closeAndGetHandle();\n+\t\t\tcomplete(\n+\t\t\t\tresult.inputChannelStateHandles,\n+\t\t\t\tinputChannelOffsets,\n+\t\t\t\t(chan, offsets) -> new InputChannelStateHandle(chan, underlying, offsets));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 151}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5Mzk5NjY4OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwODoyMDowNVrOF_gSDA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwODoyMDowNVrOF_gSDA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjEzMzUxNg==", "bodyText": "nit: i, r give some meaningful names and split the arguments in separate line.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402133516", "createdAt": "2020-04-02T08:20:05Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriter.java", "diffHunk": "@@ -18,19 +18,51 @@\n package org.apache.flink.runtime.checkpoint.channel;\n \n import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n import org.apache.flink.runtime.io.network.buffer.Buffer;\n-import org.apache.flink.runtime.state.StateObject;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.runtime.state.ResultSubpartitionStateHandle;\n \n+import java.io.Closeable;\n import java.util.Collection;\n import java.util.Collections;\n import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.Future;\n \n /**\n  * Writes channel state during checkpoint/savepoint.\n  */\n @Internal\n-public interface ChannelStateWriter extends AutoCloseable {\n+public interface ChannelStateWriter extends Closeable {\n+\n+\t/**\n+\t * Channel state write result.\n+\t */\n+\tclass ChannelStateWriteResult {\n+\t\tfinal CompletableFuture<Collection<InputChannelStateHandle>> inputChannelStateHandles;\n+\t\tfinal CompletableFuture<Collection<ResultSubpartitionStateHandle>> resultSubpartitionStateHandles;\n+\n+\t\tChannelStateWriteResult() {\n+\t\t\tthis(new CompletableFuture<>(), new CompletableFuture<>());\n+\t\t}\n+\n+\t\tChannelStateWriteResult(CompletableFuture<Collection<InputChannelStateHandle>> i, CompletableFuture<Collection<ResultSubpartitionStateHandle>> r) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 34}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5NDQyMTI5OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMDoxMjo0MVrOF_kegg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMDoxMjo0MVrOF_kegg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIwMjI0Mg==", "bodyText": "@VisibleForTesting", "url": "https://github.com/apache/flink/pull/11515#discussion_r402202242", "createdAt": "2020-04-02T10:12:41Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImpl.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.io.Closer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * {@link ChannelStateReader} implementation. Usage considerations:\n+ * <ol>\n+ *     <li>state of a channel can be read once per instance of this class; once done it returns\n+ *     {@link org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult#NO_MORE_DATA NO_MORE_DATA}</li>\n+ *     <li>reader/writer indices of the passed buffer are respected and updated</li>\n+ *     <li>buffers must be prepared (cleared) before passing to reader</li>\n+ *     <li>buffers must be released after use</li>\n+ * </ol>\n+ */\n+@NotThreadSafe\n+@Internal\n+public class ChannelStateReaderImpl implements ChannelStateReader {\n+\tprivate static final Logger log = LoggerFactory.getLogger(ChannelStateReaderImpl.class);\n+\n+\tprivate final Map<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReaders;\n+\tprivate final Map<ResultSubpartitionInfo, ChannelStateStreamReader> resultSubpartitionHandleReaders;\n+\n+\tpublic ChannelStateReaderImpl(TaskStateSnapshot snapshot) {\n+\t\tthis(snapshot, new ChannelStateSerializerImpl());\n+\t}\n+\n+\t@SuppressWarnings(\"WeakerAccess\")\n+\tChannelStateReaderImpl(TaskStateSnapshot snapshot, ChannelStateDeserializer serializer) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 68}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5NDQzNzk2OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImpl.java", "isResolved": false, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMDoxNzo1NVrOF_kpdA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QyMDo0Mjo0MFrOGCVUvA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIwNTA0NA==", "bodyText": "we can pass class field inputChannelHandleReaders directly  in below addReaders to avoid temporary variables.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402205044", "createdAt": "2020-04-02T10:17:55Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImpl.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.io.Closer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * {@link ChannelStateReader} implementation. Usage considerations:\n+ * <ol>\n+ *     <li>state of a channel can be read once per instance of this class; once done it returns\n+ *     {@link org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult#NO_MORE_DATA NO_MORE_DATA}</li>\n+ *     <li>reader/writer indices of the passed buffer are respected and updated</li>\n+ *     <li>buffers must be prepared (cleared) before passing to reader</li>\n+ *     <li>buffers must be released after use</li>\n+ * </ol>\n+ */\n+@NotThreadSafe\n+@Internal\n+public class ChannelStateReaderImpl implements ChannelStateReader {\n+\tprivate static final Logger log = LoggerFactory.getLogger(ChannelStateReaderImpl.class);\n+\n+\tprivate final Map<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReaders;\n+\tprivate final Map<ResultSubpartitionInfo, ChannelStateStreamReader> resultSubpartitionHandleReaders;\n+\n+\tpublic ChannelStateReaderImpl(TaskStateSnapshot snapshot) {\n+\t\tthis(snapshot, new ChannelStateSerializerImpl());\n+\t}\n+\n+\t@SuppressWarnings(\"WeakerAccess\")\n+\tChannelStateReaderImpl(TaskStateSnapshot snapshot, ChannelStateDeserializer serializer) {\n+\t\tRefCountingFSDataInputStreamFactory streamFactory = new RefCountingFSDataInputStreamFactory(serializer);\n+\t\tfinal HashMap<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReadersTmp = new HashMap<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDE4NDE2Mg==", "bodyText": "The consideration here is concurrency: the maps constructed here are read and cleared in close() potentially by another thread.\nSo we need a memory barrier after construction to make the change visible to this thread.\nThis barrier is a write to final variables here.\nI'll add a comment about it.", "url": "https://github.com/apache/flink/pull/11515#discussion_r404184162", "createdAt": "2020-04-06T15:31:04Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImpl.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.io.Closer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * {@link ChannelStateReader} implementation. Usage considerations:\n+ * <ol>\n+ *     <li>state of a channel can be read once per instance of this class; once done it returns\n+ *     {@link org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult#NO_MORE_DATA NO_MORE_DATA}</li>\n+ *     <li>reader/writer indices of the passed buffer are respected and updated</li>\n+ *     <li>buffers must be prepared (cleared) before passing to reader</li>\n+ *     <li>buffers must be released after use</li>\n+ * </ol>\n+ */\n+@NotThreadSafe\n+@Internal\n+public class ChannelStateReaderImpl implements ChannelStateReader {\n+\tprivate static final Logger log = LoggerFactory.getLogger(ChannelStateReaderImpl.class);\n+\n+\tprivate final Map<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReaders;\n+\tprivate final Map<ResultSubpartitionInfo, ChannelStateStreamReader> resultSubpartitionHandleReaders;\n+\n+\tpublic ChannelStateReaderImpl(TaskStateSnapshot snapshot) {\n+\t\tthis(snapshot, new ChannelStateSerializerImpl());\n+\t}\n+\n+\t@SuppressWarnings(\"WeakerAccess\")\n+\tChannelStateReaderImpl(TaskStateSnapshot snapshot, ChannelStateDeserializer serializer) {\n+\t\tRefCountingFSDataInputStreamFactory streamFactory = new RefCountingFSDataInputStreamFactory(serializer);\n+\t\tfinal HashMap<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReadersTmp = new HashMap<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIwNTA0NA=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDcyMDk4MQ==", "bodyText": "I guess you are indicating the concurrent issue. Before the constructor is finished, some other threads might access intermediate inputChannelHandleReaders and resultSubpartitionHandleReaders.\nIf so, it seems not valid because no one can get and reference ChannelStateReaderImpl before the constructor finishes. In real codes, the constructing is done before creating Task by RPC thread, then no one would reference it to read or close until it is created to pass into task class.\nAnyway it is not big issue on my side, just to clarify the consideration.", "url": "https://github.com/apache/flink/pull/11515#discussion_r404720981", "createdAt": "2020-04-07T10:59:44Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImpl.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.io.Closer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * {@link ChannelStateReader} implementation. Usage considerations:\n+ * <ol>\n+ *     <li>state of a channel can be read once per instance of this class; once done it returns\n+ *     {@link org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult#NO_MORE_DATA NO_MORE_DATA}</li>\n+ *     <li>reader/writer indices of the passed buffer are respected and updated</li>\n+ *     <li>buffers must be prepared (cleared) before passing to reader</li>\n+ *     <li>buffers must be released after use</li>\n+ * </ol>\n+ */\n+@NotThreadSafe\n+@Internal\n+public class ChannelStateReaderImpl implements ChannelStateReader {\n+\tprivate static final Logger log = LoggerFactory.getLogger(ChannelStateReaderImpl.class);\n+\n+\tprivate final Map<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReaders;\n+\tprivate final Map<ResultSubpartitionInfo, ChannelStateStreamReader> resultSubpartitionHandleReaders;\n+\n+\tpublic ChannelStateReaderImpl(TaskStateSnapshot snapshot) {\n+\t\tthis(snapshot, new ChannelStateSerializerImpl());\n+\t}\n+\n+\t@SuppressWarnings(\"WeakerAccess\")\n+\tChannelStateReaderImpl(TaskStateSnapshot snapshot, ChannelStateDeserializer serializer) {\n+\t\tRefCountingFSDataInputStreamFactory streamFactory = new RefCountingFSDataInputStreamFactory(serializer);\n+\t\tfinal HashMap<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReadersTmp = new HashMap<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIwNTA0NA=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc2MzA5Nw==", "bodyText": "No, I meant that  after construction, the instance can be accessed by other threads.\nAnd AFAIK there is no memory barrier after constructor by default.\nSo without temporary variables, the only guarantee is that inputChannelHandleReaders points to a map, but not about contents of that map.", "url": "https://github.com/apache/flink/pull/11515#discussion_r404763097", "createdAt": "2020-04-07T12:18:52Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImpl.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.io.Closer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * {@link ChannelStateReader} implementation. Usage considerations:\n+ * <ol>\n+ *     <li>state of a channel can be read once per instance of this class; once done it returns\n+ *     {@link org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult#NO_MORE_DATA NO_MORE_DATA}</li>\n+ *     <li>reader/writer indices of the passed buffer are respected and updated</li>\n+ *     <li>buffers must be prepared (cleared) before passing to reader</li>\n+ *     <li>buffers must be released after use</li>\n+ * </ol>\n+ */\n+@NotThreadSafe\n+@Internal\n+public class ChannelStateReaderImpl implements ChannelStateReader {\n+\tprivate static final Logger log = LoggerFactory.getLogger(ChannelStateReaderImpl.class);\n+\n+\tprivate final Map<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReaders;\n+\tprivate final Map<ResultSubpartitionInfo, ChannelStateStreamReader> resultSubpartitionHandleReaders;\n+\n+\tpublic ChannelStateReaderImpl(TaskStateSnapshot snapshot) {\n+\t\tthis(snapshot, new ChannelStateSerializerImpl());\n+\t}\n+\n+\t@SuppressWarnings(\"WeakerAccess\")\n+\tChannelStateReaderImpl(TaskStateSnapshot snapshot, ChannelStateDeserializer serializer) {\n+\t\tRefCountingFSDataInputStreamFactory streamFactory = new RefCountingFSDataInputStreamFactory(serializer);\n+\t\tfinal HashMap<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReadersTmp = new HashMap<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIwNTA0NA=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk4NDYyOA==", "bodyText": "As long as you are not handing out this directly or indirectly, constructor should be atomic in terms of memory synchronization. No other thread can see this instance of ChannelStateReaderImpl and find any inconsistent state.\nChannelStateReaderImpl reader = new ChannelStateReaderImpl(...);\nreader.... // <- at this point all maps are good", "url": "https://github.com/apache/flink/pull/11515#discussion_r404984628", "createdAt": "2020-04-07T17:26:18Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImpl.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.io.Closer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * {@link ChannelStateReader} implementation. Usage considerations:\n+ * <ol>\n+ *     <li>state of a channel can be read once per instance of this class; once done it returns\n+ *     {@link org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult#NO_MORE_DATA NO_MORE_DATA}</li>\n+ *     <li>reader/writer indices of the passed buffer are respected and updated</li>\n+ *     <li>buffers must be prepared (cleared) before passing to reader</li>\n+ *     <li>buffers must be released after use</li>\n+ * </ol>\n+ */\n+@NotThreadSafe\n+@Internal\n+public class ChannelStateReaderImpl implements ChannelStateReader {\n+\tprivate static final Logger log = LoggerFactory.getLogger(ChannelStateReaderImpl.class);\n+\n+\tprivate final Map<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReaders;\n+\tprivate final Map<ResultSubpartitionInfo, ChannelStateStreamReader> resultSubpartitionHandleReaders;\n+\n+\tpublic ChannelStateReaderImpl(TaskStateSnapshot snapshot) {\n+\t\tthis(snapshot, new ChannelStateSerializerImpl());\n+\t}\n+\n+\t@SuppressWarnings(\"WeakerAccess\")\n+\tChannelStateReaderImpl(TaskStateSnapshot snapshot, ChannelStateDeserializer serializer) {\n+\t\tRefCountingFSDataInputStreamFactory streamFactory = new RefCountingFSDataInputStreamFactory(serializer);\n+\t\tfinal HashMap<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReadersTmp = new HashMap<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIwNTA0NA=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTA5OTcwOA==", "bodyText": "From JLS:\n\nAn object is considered to be completely initialized when its constructor finishes. A thread\nthat can only see a reference to an object after that object has been completely initialized is\nguaranteed to see the correctly initialized values for that object's final fields.\n\nI read it as \"you have no guarantee about non-final fields\". Which means there is no barrier in the end of the constructor.", "url": "https://github.com/apache/flink/pull/11515#discussion_r405099708", "createdAt": "2020-04-07T20:42:40Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImpl.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.io.Closer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * {@link ChannelStateReader} implementation. Usage considerations:\n+ * <ol>\n+ *     <li>state of a channel can be read once per instance of this class; once done it returns\n+ *     {@link org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult#NO_MORE_DATA NO_MORE_DATA}</li>\n+ *     <li>reader/writer indices of the passed buffer are respected and updated</li>\n+ *     <li>buffers must be prepared (cleared) before passing to reader</li>\n+ *     <li>buffers must be released after use</li>\n+ * </ol>\n+ */\n+@NotThreadSafe\n+@Internal\n+public class ChannelStateReaderImpl implements ChannelStateReader {\n+\tprivate static final Logger log = LoggerFactory.getLogger(ChannelStateReaderImpl.class);\n+\n+\tprivate final Map<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReaders;\n+\tprivate final Map<ResultSubpartitionInfo, ChannelStateStreamReader> resultSubpartitionHandleReaders;\n+\n+\tpublic ChannelStateReaderImpl(TaskStateSnapshot snapshot) {\n+\t\tthis(snapshot, new ChannelStateSerializerImpl());\n+\t}\n+\n+\t@SuppressWarnings(\"WeakerAccess\")\n+\tChannelStateReaderImpl(TaskStateSnapshot snapshot, ChannelStateDeserializer serializer) {\n+\t\tRefCountingFSDataInputStreamFactory streamFactory = new RefCountingFSDataInputStreamFactory(serializer);\n+\t\tfinal HashMap<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReadersTmp = new HashMap<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIwNTA0NA=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 70}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5NDQzOTIxOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMDoxODoxNlrOF_kqRw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMDoxODoxNlrOF_kqRw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIwNTI1NQ==", "bodyText": "too long line, should split line for arguments", "url": "https://github.com/apache/flink/pull/11515#discussion_r402205255", "createdAt": "2020-04-02T10:18:16Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImpl.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.io.Closer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * {@link ChannelStateReader} implementation. Usage considerations:\n+ * <ol>\n+ *     <li>state of a channel can be read once per instance of this class; once done it returns\n+ *     {@link org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult#NO_MORE_DATA NO_MORE_DATA}</li>\n+ *     <li>reader/writer indices of the passed buffer are respected and updated</li>\n+ *     <li>buffers must be prepared (cleared) before passing to reader</li>\n+ *     <li>buffers must be released after use</li>\n+ * </ol>\n+ */\n+@NotThreadSafe\n+@Internal\n+public class ChannelStateReaderImpl implements ChannelStateReader {\n+\tprivate static final Logger log = LoggerFactory.getLogger(ChannelStateReaderImpl.class);\n+\n+\tprivate final Map<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReaders;\n+\tprivate final Map<ResultSubpartitionInfo, ChannelStateStreamReader> resultSubpartitionHandleReaders;\n+\n+\tpublic ChannelStateReaderImpl(TaskStateSnapshot snapshot) {\n+\t\tthis(snapshot, new ChannelStateSerializerImpl());\n+\t}\n+\n+\t@SuppressWarnings(\"WeakerAccess\")\n+\tChannelStateReaderImpl(TaskStateSnapshot snapshot, ChannelStateDeserializer serializer) {\n+\t\tRefCountingFSDataInputStreamFactory streamFactory = new RefCountingFSDataInputStreamFactory(serializer);\n+\t\tfinal HashMap<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReadersTmp = new HashMap<>();\n+\t\tfinal HashMap<ResultSubpartitionInfo, ChannelStateStreamReader> resultSubpartitionHandleReadersTmp = new HashMap<>();\n+\t\tfor (Map.Entry<OperatorID, OperatorSubtaskState> e : snapshot.getSubtaskStateMappings()) {\n+\t\t\taddReaders(inputChannelHandleReadersTmp, e.getValue().getInputChannelState(), streamFactory);\n+\t\t\taddReaders(resultSubpartitionHandleReadersTmp, e.getValue().getResultSubpartitionState(), streamFactory);\n+\t\t}\n+\t\tinputChannelHandleReaders = inputChannelHandleReadersTmp;\n+\t\tresultSubpartitionHandleReaders = resultSubpartitionHandleReadersTmp;\n+\t}\n+\n+\tprivate <T> void addReaders(Map<T, ChannelStateStreamReader> readerMap, Collection<? extends AbstractChannelStateHandle<T>> handles, RefCountingFSDataInputStreamFactory streamFactory) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 80}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5NDQ1MDQ5OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMDoyMTo0MVrOF_kxXA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMDoyMTo0MVrOF_kxXA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIwNzA2OA==", "bodyText": "nit: bufferBuilder -> buffer:", "url": "https://github.com/apache/flink/pull/11515#discussion_r402207068", "createdAt": "2020-04-02T10:21:41Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImpl.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.io.Closer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * {@link ChannelStateReader} implementation. Usage considerations:\n+ * <ol>\n+ *     <li>state of a channel can be read once per instance of this class; once done it returns\n+ *     {@link org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult#NO_MORE_DATA NO_MORE_DATA}</li>\n+ *     <li>reader/writer indices of the passed buffer are respected and updated</li>\n+ *     <li>buffers must be prepared (cleared) before passing to reader</li>\n+ *     <li>buffers must be released after use</li>\n+ * </ol>\n+ */\n+@NotThreadSafe\n+@Internal\n+public class ChannelStateReaderImpl implements ChannelStateReader {\n+\tprivate static final Logger log = LoggerFactory.getLogger(ChannelStateReaderImpl.class);\n+\n+\tprivate final Map<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReaders;\n+\tprivate final Map<ResultSubpartitionInfo, ChannelStateStreamReader> resultSubpartitionHandleReaders;\n+\n+\tpublic ChannelStateReaderImpl(TaskStateSnapshot snapshot) {\n+\t\tthis(snapshot, new ChannelStateSerializerImpl());\n+\t}\n+\n+\t@SuppressWarnings(\"WeakerAccess\")\n+\tChannelStateReaderImpl(TaskStateSnapshot snapshot, ChannelStateDeserializer serializer) {\n+\t\tRefCountingFSDataInputStreamFactory streamFactory = new RefCountingFSDataInputStreamFactory(serializer);\n+\t\tfinal HashMap<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReadersTmp = new HashMap<>();\n+\t\tfinal HashMap<ResultSubpartitionInfo, ChannelStateStreamReader> resultSubpartitionHandleReadersTmp = new HashMap<>();\n+\t\tfor (Map.Entry<OperatorID, OperatorSubtaskState> e : snapshot.getSubtaskStateMappings()) {\n+\t\t\taddReaders(inputChannelHandleReadersTmp, e.getValue().getInputChannelState(), streamFactory);\n+\t\t\taddReaders(resultSubpartitionHandleReadersTmp, e.getValue().getResultSubpartitionState(), streamFactory);\n+\t\t}\n+\t\tinputChannelHandleReaders = inputChannelHandleReadersTmp;\n+\t\tresultSubpartitionHandleReaders = resultSubpartitionHandleReadersTmp;\n+\t}\n+\n+\tprivate <T> void addReaders(Map<T, ChannelStateStreamReader> readerMap, Collection<? extends AbstractChannelStateHandle<T>> handles, RefCountingFSDataInputStreamFactory streamFactory) {\n+\t\tfor (AbstractChannelStateHandle<T> handle : handles) {\n+\t\t\tcheckState(!readerMap.containsKey(handle.getInfo()), \"multiple states exist for channel: \" + handle.getInfo());\n+\t\t\treaderMap.put(handle.getInfo(), new ChannelStateStreamReader(handle, streamFactory));\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic ReadResult readInputData(InputChannelInfo info, Buffer buffer) throws IOException {\n+\t\tlog.debug(\"readInputData, resultSubpartitionInfo: {} , bufferBuilder {}\", info, buffer);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 89}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5NDUwNDAzOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateStreamReader.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMDozNjozOFrOF_lSkg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMDozNjozOFrOF_lSkg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIxNTU3MA==", "bodyText": "nit: checkNotNull", "url": "https://github.com/apache/flink/pull/11515#discussion_r402215570", "createdAt": "2020-04-02T10:36:38Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateStreamReader.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+\n+import static java.lang.Math.addExact;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateByteBuffer.wrap;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.HAS_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+\n+/**\n+ * Reads the state of a single channel pointed by {@link org.apache.flink.runtime.state.AbstractChannelStateHandle AbstractChannelStateHandle}.\n+ * Single-use.\n+ * Uses {@link RefCountingFSDataInputStream} internally.\n+ */\n+@NotThreadSafe\n+class ChannelStateStreamReader implements Closeable {\n+\n+\tprivate final RefCountingFSDataInputStream stream; // todo: buffer?\n+\tprivate final Queue<Long> offsets;\n+\tprivate final ChannelStateDeserializer serializer;\n+\tprivate long pos = -1;\n+\tprivate int rem;\n+\tprivate boolean closed = false;\n+\n+\tChannelStateStreamReader(AbstractChannelStateHandle<?> handle, RefCountingFSDataInputStreamFactory streamFactory) {\n+\t\tthis(streamFactory.forHandle(handle), handle.getOffsets(), streamFactory.getSerializer());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 57}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5NDUxMjg2OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateStreamReader.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMDozOToxNlrOF_lYCw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMDozOToxNlrOF_lYCw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIxNjk3MQ==", "bodyText": "Better to give some descriptions for these fields for better understanding, especially for rem.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402216971", "createdAt": "2020-04-02T10:39:16Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateStreamReader.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+\n+import static java.lang.Math.addExact;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateByteBuffer.wrap;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.HAS_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+\n+/**\n+ * Reads the state of a single channel pointed by {@link org.apache.flink.runtime.state.AbstractChannelStateHandle AbstractChannelStateHandle}.\n+ * Single-use.\n+ * Uses {@link RefCountingFSDataInputStream} internally.\n+ */\n+@NotThreadSafe\n+class ChannelStateStreamReader implements Closeable {\n+\n+\tprivate final RefCountingFSDataInputStream stream; // todo: buffer?\n+\tprivate final Queue<Long> offsets;\n+\tprivate final ChannelStateDeserializer serializer;\n+\tprivate long pos = -1;\n+\tprivate int rem;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 53}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5NDUyMTA3OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateStreamReader.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMDo0MjowM1rOF_ldOQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNTozNzo0OVrOGBdwfw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIxODI5Nw==", "bodyText": "nit: What is it indicating for : Single-use.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402218297", "createdAt": "2020-04-02T10:42:03Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateStreamReader.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+\n+import static java.lang.Math.addExact;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateByteBuffer.wrap;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.HAS_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+\n+/**\n+ * Reads the state of a single channel pointed by {@link org.apache.flink.runtime.state.AbstractChannelStateHandle AbstractChannelStateHandle}.\n+ * Single-use.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDE4OTMxMQ==", "bodyText": "I meant that once all data was read, the reader can't be used anymore (updated Javadoc).", "url": "https://github.com/apache/flink/pull/11515#discussion_r404189311", "createdAt": "2020-04-06T15:37:49Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateStreamReader.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+\n+import static java.lang.Math.addExact;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateByteBuffer.wrap;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.HAS_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+\n+/**\n+ * Reads the state of a single channel pointed by {@link org.apache.flink.runtime.state.AbstractChannelStateHandle AbstractChannelStateHandle}.\n+ * Single-use.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIxODI5Nw=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 43}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5NDUyMzQ3OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateStreamReader.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMDo0Mjo0NlrOF_letQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNTozNTo1OVrOGBdrOg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIxODY3Nw==", "bodyText": "should be clear for TODO", "url": "https://github.com/apache/flink/pull/11515#discussion_r402218677", "createdAt": "2020-04-02T10:42:46Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateStreamReader.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+\n+import static java.lang.Math.addExact;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateByteBuffer.wrap;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.HAS_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+\n+/**\n+ * Reads the state of a single channel pointed by {@link org.apache.flink.runtime.state.AbstractChannelStateHandle AbstractChannelStateHandle}.\n+ * Single-use.\n+ * Uses {@link RefCountingFSDataInputStream} internally.\n+ */\n+@NotThreadSafe\n+class ChannelStateStreamReader implements Closeable {\n+\n+\tprivate final RefCountingFSDataInputStream stream; // todo: buffer?", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDE4Nzk2Mg==", "bodyText": "Removed todo", "url": "https://github.com/apache/flink/pull/11515#discussion_r404187962", "createdAt": "2020-04-06T15:35:59Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateStreamReader.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+\n+import static java.lang.Math.addExact;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateByteBuffer.wrap;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.HAS_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+\n+/**\n+ * Reads the state of a single channel pointed by {@link org.apache.flink.runtime.state.AbstractChannelStateHandle AbstractChannelStateHandle}.\n+ * Single-use.\n+ * Uses {@link RefCountingFSDataInputStream} internally.\n+ */\n+@NotThreadSafe\n+class ChannelStateStreamReader implements Closeable {\n+\n+\tprivate final RefCountingFSDataInputStream stream; // todo: buffer?", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIxODY3Nw=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 49}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5NDc0NzE2OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateStreamReader.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMTo1MzowMFrOF_noWw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNjozMzo0OVrOGBgNGg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI1MzkxNQ==", "bodyText": "I guess we can get ride of pos field to only judge rem <= 0 to advance offset. If so we can also avoid return tuple2 in serializer.readLength(stream)", "url": "https://github.com/apache/flink/pull/11515#discussion_r402253915", "createdAt": "2020-04-02T11:53:00Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateStreamReader.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+\n+import static java.lang.Math.addExact;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateByteBuffer.wrap;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.HAS_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+\n+/**\n+ * Reads the state of a single channel pointed by {@link org.apache.flink.runtime.state.AbstractChannelStateHandle AbstractChannelStateHandle}.\n+ * Single-use.\n+ * Uses {@link RefCountingFSDataInputStream} internally.\n+ */\n+@NotThreadSafe\n+class ChannelStateStreamReader implements Closeable {\n+\n+\tprivate final RefCountingFSDataInputStream stream; // todo: buffer?\n+\tprivate final Queue<Long> offsets;\n+\tprivate final ChannelStateDeserializer serializer;\n+\tprivate long pos = -1;\n+\tprivate int rem;\n+\tprivate boolean closed = false;\n+\n+\tChannelStateStreamReader(AbstractChannelStateHandle<?> handle, RefCountingFSDataInputStreamFactory streamFactory) {\n+\t\tthis(streamFactory.forHandle(handle), handle.getOffsets(), streamFactory.getSerializer());\n+\t}\n+\n+\tprivate ChannelStateStreamReader(RefCountingFSDataInputStream stream, List<Long> offsets, ChannelStateDeserializer serializer) {\n+\t\tthis.stream = stream;\n+\t\tthis.stream.incNumReaders();\n+\t\tthis.serializer = serializer;\n+\t\tthis.offsets = new LinkedList<>(offsets);\n+\t}\n+\n+\tReadResult readInto(Buffer buffer) throws IOException {\n+\t\treturn readInto(wrap(buffer));\n+\t}\n+\n+\tReadResult readInto(BufferBuilder bufferBuilder) throws IOException {\n+\t\treturn readInto(wrap(bufferBuilder));\n+\t}\n+\n+\tprivate ReadResult readInto(ChannelStateByteBuffer buffer) throws IOException {\n+\t\tPreconditions.checkState(!closed, \"reader is closed\");\n+\t\treadWhilePossible(buffer);\n+\t\tif (haveMoreData()) {\n+\t\t\treturn HAS_MORE_DATA;\n+\t\t} else {\n+\t\t\tclose();\n+\t\t\treturn NO_MORE_DATA;\n+\t\t}\n+\t}\n+\n+\tprivate void readWhilePossible(ChannelStateByteBuffer buffer) throws IOException {\n+\t\twhile (haveMoreData() && buffer.isWritable()) {\n+\t\t\tif (pos < 0 || rem <= 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDIyOTQwMg==", "bodyText": "That's a good simplification, thanks!", "url": "https://github.com/apache/flink/pull/11515#discussion_r404229402", "createdAt": "2020-04-06T16:33:49Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateStreamReader.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+\n+import static java.lang.Math.addExact;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateByteBuffer.wrap;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.HAS_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+\n+/**\n+ * Reads the state of a single channel pointed by {@link org.apache.flink.runtime.state.AbstractChannelStateHandle AbstractChannelStateHandle}.\n+ * Single-use.\n+ * Uses {@link RefCountingFSDataInputStream} internally.\n+ */\n+@NotThreadSafe\n+class ChannelStateStreamReader implements Closeable {\n+\n+\tprivate final RefCountingFSDataInputStream stream; // todo: buffer?\n+\tprivate final Queue<Long> offsets;\n+\tprivate final ChannelStateDeserializer serializer;\n+\tprivate long pos = -1;\n+\tprivate int rem;\n+\tprivate boolean closed = false;\n+\n+\tChannelStateStreamReader(AbstractChannelStateHandle<?> handle, RefCountingFSDataInputStreamFactory streamFactory) {\n+\t\tthis(streamFactory.forHandle(handle), handle.getOffsets(), streamFactory.getSerializer());\n+\t}\n+\n+\tprivate ChannelStateStreamReader(RefCountingFSDataInputStream stream, List<Long> offsets, ChannelStateDeserializer serializer) {\n+\t\tthis.stream = stream;\n+\t\tthis.stream.incNumReaders();\n+\t\tthis.serializer = serializer;\n+\t\tthis.offsets = new LinkedList<>(offsets);\n+\t}\n+\n+\tReadResult readInto(Buffer buffer) throws IOException {\n+\t\treturn readInto(wrap(buffer));\n+\t}\n+\n+\tReadResult readInto(BufferBuilder bufferBuilder) throws IOException {\n+\t\treturn readInto(wrap(bufferBuilder));\n+\t}\n+\n+\tprivate ReadResult readInto(ChannelStateByteBuffer buffer) throws IOException {\n+\t\tPreconditions.checkState(!closed, \"reader is closed\");\n+\t\treadWhilePossible(buffer);\n+\t\tif (haveMoreData()) {\n+\t\t\treturn HAS_MORE_DATA;\n+\t\t} else {\n+\t\t\tclose();\n+\t\t\treturn NO_MORE_DATA;\n+\t\t}\n+\t}\n+\n+\tprivate void readWhilePossible(ChannelStateByteBuffer buffer) throws IOException {\n+\t\twhile (haveMoreData() && buffer.isWritable()) {\n+\t\t\tif (pos < 0 || rem <= 0) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI1MzkxNQ=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 88}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5NDc3Mjc4OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RefCountingFSDataInputStream.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjowMDoxN1rOF_n38g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjowMDoxN1rOF_n38g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI1NzkwNg==", "bodyText": "nit: i think it is better to place the factory class at the bottom of this class", "url": "https://github.com/apache/flink/pull/11515#discussion_r402257906", "createdAt": "2020-04-02T12:00:17Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RefCountingFSDataInputStream.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.fs.FSDataInputStream;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.SupplierWithException;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+@NotThreadSafe\n+class RefCountingFSDataInputStream extends FSDataInputStream {\n+\n+\t@NotThreadSafe\n+\tstatic class RefCountingFSDataInputStreamFactory {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5NDc3NDY3OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RefCountingFSDataInputStream.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjowMDo0OVrOF_n5EQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjowMDo0OVrOF_n5EQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI1ODE5Mw==", "bodyText": "too long line for splitting the arguments", "url": "https://github.com/apache/flink/pull/11515#discussion_r402258193", "createdAt": "2020-04-02T12:00:49Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RefCountingFSDataInputStream.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.fs.FSDataInputStream;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.SupplierWithException;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+@NotThreadSafe\n+class RefCountingFSDataInputStream extends FSDataInputStream {\n+\n+\t@NotThreadSafe\n+\tstatic class RefCountingFSDataInputStreamFactory {\n+\t\tprivate final Map<StreamStateHandle, RefCountingFSDataInputStream> map = new HashMap<>(); // not clearing: expecting short life\n+\t\tprivate final ChannelStateDeserializer serializer;\n+\n+\t\tRefCountingFSDataInputStreamFactory(ChannelStateDeserializer serializer) {\n+\t\t\tthis.serializer = serializer;\n+\t\t}\n+\n+\t\t<T> RefCountingFSDataInputStream forHandle(AbstractChannelStateHandle<T> handle) {\n+\t\t\tStreamStateHandle streamStateHandle = handle.getDelegate();\n+\t\t\tRefCountingFSDataInputStream stream = map.get(streamStateHandle);\n+\t\t\tif (stream == null) {\n+\t\t\t\tstream = new RefCountingFSDataInputStream(streamStateHandle::openInputStream, serializer);\n+\t\t\t\tmap.put(streamStateHandle, stream);\n+\t\t\t}\n+\t\t\treturn stream;\n+\t\t}\n+\n+\t\tChannelStateDeserializer getSerializer() {\n+\t\t\treturn serializer;\n+\t\t}\n+\t}\n+\n+\tprivate enum State {NEW, OPENED, CLOSED}\n+\n+\tprivate final SupplierWithException<FSDataInputStream, IOException> streamSupplier;\n+\tprivate FSDataInputStream stream;\n+\tprivate final ChannelStateDeserializer serializer;\n+\tprivate int numReaders = 0;\n+\tprivate State state = State.NEW;\n+\n+\tprivate RefCountingFSDataInputStream(SupplierWithException<FSDataInputStream, IOException> streamSupplier, ChannelStateDeserializer serializer) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 69}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5NDgyMzgwOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RefCountingFSDataInputStream.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjoxNTozMFrOF_oYKA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjoxNTozMFrOF_oYKA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI2NjE1Mg==", "bodyText": "nit: incRef seems more fit into the class name. also numReaders -> refCounter", "url": "https://github.com/apache/flink/pull/11515#discussion_r402266152", "createdAt": "2020-04-02T12:15:30Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RefCountingFSDataInputStream.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.fs.FSDataInputStream;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.SupplierWithException;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+@NotThreadSafe\n+class RefCountingFSDataInputStream extends FSDataInputStream {\n+\n+\t@NotThreadSafe\n+\tstatic class RefCountingFSDataInputStreamFactory {\n+\t\tprivate final Map<StreamStateHandle, RefCountingFSDataInputStream> map = new HashMap<>(); // not clearing: expecting short life\n+\t\tprivate final ChannelStateDeserializer serializer;\n+\n+\t\tRefCountingFSDataInputStreamFactory(ChannelStateDeserializer serializer) {\n+\t\t\tthis.serializer = serializer;\n+\t\t}\n+\n+\t\t<T> RefCountingFSDataInputStream forHandle(AbstractChannelStateHandle<T> handle) {\n+\t\t\tStreamStateHandle streamStateHandle = handle.getDelegate();\n+\t\t\tRefCountingFSDataInputStream stream = map.get(streamStateHandle);\n+\t\t\tif (stream == null) {\n+\t\t\t\tstream = new RefCountingFSDataInputStream(streamStateHandle::openInputStream, serializer);\n+\t\t\t\tmap.put(streamStateHandle, stream);\n+\t\t\t}\n+\t\t\treturn stream;\n+\t\t}\n+\n+\t\tChannelStateDeserializer getSerializer() {\n+\t\t\treturn serializer;\n+\t\t}\n+\t}\n+\n+\tprivate enum State {NEW, OPENED, CLOSED}\n+\n+\tprivate final SupplierWithException<FSDataInputStream, IOException> streamSupplier;\n+\tprivate FSDataInputStream stream;\n+\tprivate final ChannelStateDeserializer serializer;\n+\tprivate int numReaders = 0;\n+\tprivate State state = State.NEW;\n+\n+\tprivate RefCountingFSDataInputStream(SupplierWithException<FSDataInputStream, IOException> streamSupplier, ChannelStateDeserializer serializer) {\n+\t\tthis.streamSupplier = streamSupplier;\n+\t\tthis.serializer = serializer;\n+\t}\n+\n+\tvoid incNumReaders() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 74}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5NDgyOTE0OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RefCountingFSDataInputStream.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjoxNzoxOFrOF_ob1w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjoxNzoxOFrOF_ob1w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI2NzA5NQ==", "bodyText": "nit: desired -> pos", "url": "https://github.com/apache/flink/pull/11515#discussion_r402267095", "createdAt": "2020-04-02T12:17:18Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RefCountingFSDataInputStream.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.fs.FSDataInputStream;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.SupplierWithException;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+@NotThreadSafe\n+class RefCountingFSDataInputStream extends FSDataInputStream {\n+\n+\t@NotThreadSafe\n+\tstatic class RefCountingFSDataInputStreamFactory {\n+\t\tprivate final Map<StreamStateHandle, RefCountingFSDataInputStream> map = new HashMap<>(); // not clearing: expecting short life\n+\t\tprivate final ChannelStateDeserializer serializer;\n+\n+\t\tRefCountingFSDataInputStreamFactory(ChannelStateDeserializer serializer) {\n+\t\t\tthis.serializer = serializer;\n+\t\t}\n+\n+\t\t<T> RefCountingFSDataInputStream forHandle(AbstractChannelStateHandle<T> handle) {\n+\t\t\tStreamStateHandle streamStateHandle = handle.getDelegate();\n+\t\t\tRefCountingFSDataInputStream stream = map.get(streamStateHandle);\n+\t\t\tif (stream == null) {\n+\t\t\t\tstream = new RefCountingFSDataInputStream(streamStateHandle::openInputStream, serializer);\n+\t\t\t\tmap.put(streamStateHandle, stream);\n+\t\t\t}\n+\t\t\treturn stream;\n+\t\t}\n+\n+\t\tChannelStateDeserializer getSerializer() {\n+\t\t\treturn serializer;\n+\t\t}\n+\t}\n+\n+\tprivate enum State {NEW, OPENED, CLOSED}\n+\n+\tprivate final SupplierWithException<FSDataInputStream, IOException> streamSupplier;\n+\tprivate FSDataInputStream stream;\n+\tprivate final ChannelStateDeserializer serializer;\n+\tprivate int numReaders = 0;\n+\tprivate State state = State.NEW;\n+\n+\tprivate RefCountingFSDataInputStream(SupplierWithException<FSDataInputStream, IOException> streamSupplier, ChannelStateDeserializer serializer) {\n+\t\tthis.streamSupplier = streamSupplier;\n+\t\tthis.serializer = serializer;\n+\t}\n+\n+\tvoid incNumReaders() {\n+\t\tcheckNotClosed();\n+\t\tnumReaders++;\n+\t}\n+\n+\tvoid decNumReaders() throws IOException {\n+\t\tcheckNotClosed();\n+\t\tnumReaders--;\n+\t\tif (numReaders == 0) {\n+\t\t\tclose();\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic int read() throws IOException {\n+\t\tensureOpen();\n+\t\treturn stream.read();\n+\t}\n+\n+\t@Override\n+\tpublic void seek(long desired) throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 94}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5NDg0NjE2OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RefCountingFSDataInputStream.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjoyMTo1MFrOF_omYQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjoyMTo1MFrOF_omYQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI2OTc5Mw==", "bodyText": "map -> streams", "url": "https://github.com/apache/flink/pull/11515#discussion_r402269793", "createdAt": "2020-04-02T12:21:50Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RefCountingFSDataInputStream.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.fs.FSDataInputStream;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.SupplierWithException;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+@NotThreadSafe\n+class RefCountingFSDataInputStream extends FSDataInputStream {\n+\n+\t@NotThreadSafe\n+\tstatic class RefCountingFSDataInputStreamFactory {\n+\t\tprivate final Map<StreamStateHandle, RefCountingFSDataInputStream> map = new HashMap<>(); // not clearing: expecting short life", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 39}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5NDg0OTAxOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RefCountingFSDataInputStream.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjoyMjozMFrOF_ooEQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjoyMjozMFrOF_ooEQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI3MDIyNQ==", "bodyText": "nit: checkNotNull", "url": "https://github.com/apache/flink/pull/11515#discussion_r402270225", "createdAt": "2020-04-02T12:22:30Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RefCountingFSDataInputStream.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.fs.FSDataInputStream;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.SupplierWithException;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+@NotThreadSafe\n+class RefCountingFSDataInputStream extends FSDataInputStream {\n+\n+\t@NotThreadSafe\n+\tstatic class RefCountingFSDataInputStreamFactory {\n+\t\tprivate final Map<StreamStateHandle, RefCountingFSDataInputStream> map = new HashMap<>(); // not clearing: expecting short life\n+\t\tprivate final ChannelStateDeserializer serializer;\n+\n+\t\tRefCountingFSDataInputStreamFactory(ChannelStateDeserializer serializer) {\n+\t\t\tthis.serializer = serializer;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 43}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5NDg2NTE3OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RefCountingFSDataInputStream.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjoyNTo1M1rOF_oxPg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjoyNTo1M1rOF_oxPg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI3MjU3NA==", "bodyText": "forHandle->create/buildInputStream", "url": "https://github.com/apache/flink/pull/11515#discussion_r402272574", "createdAt": "2020-04-02T12:25:53Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RefCountingFSDataInputStream.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.fs.FSDataInputStream;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.SupplierWithException;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+@NotThreadSafe\n+class RefCountingFSDataInputStream extends FSDataInputStream {\n+\n+\t@NotThreadSafe\n+\tstatic class RefCountingFSDataInputStreamFactory {\n+\t\tprivate final Map<StreamStateHandle, RefCountingFSDataInputStream> map = new HashMap<>(); // not clearing: expecting short life\n+\t\tprivate final ChannelStateDeserializer serializer;\n+\n+\t\tRefCountingFSDataInputStreamFactory(ChannelStateDeserializer serializer) {\n+\t\t\tthis.serializer = serializer;\n+\t\t}\n+\n+\t\t<T> RefCountingFSDataInputStream forHandle(AbstractChannelStateHandle<T> handle) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 46}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5NDg4NDA5OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RefCountingFSDataInputStream.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjozMDo1NlrOF_o88Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNjo0MzoxMVrOGBglng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI3NTU2OQ==", "bodyText": "Will one state handle be read multiple times, so we need a map to avoid opening it multiple times?", "url": "https://github.com/apache/flink/pull/11515#discussion_r402275569", "createdAt": "2020-04-02T12:30:56Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RefCountingFSDataInputStream.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.fs.FSDataInputStream;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.SupplierWithException;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+@NotThreadSafe\n+class RefCountingFSDataInputStream extends FSDataInputStream {\n+\n+\t@NotThreadSafe\n+\tstatic class RefCountingFSDataInputStreamFactory {\n+\t\tprivate final Map<StreamStateHandle, RefCountingFSDataInputStream> map = new HashMap<>(); // not clearing: expecting short life\n+\t\tprivate final ChannelStateDeserializer serializer;\n+\n+\t\tRefCountingFSDataInputStreamFactory(ChannelStateDeserializer serializer) {\n+\t\t\tthis.serializer = serializer;\n+\t\t}\n+\n+\t\t<T> RefCountingFSDataInputStream forHandle(AbstractChannelStateHandle<T> handle) {\n+\t\t\tStreamStateHandle streamStateHandle = handle.getDelegate();\n+\t\t\tRefCountingFSDataInputStream stream = map.get(streamStateHandle);\n+\t\t\tif (stream == null) {\n+\t\t\t\tstream = new RefCountingFSDataInputStream(streamStateHandle::openInputStream, serializer);\n+\t\t\t\tmap.put(streamStateHandle, stream);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDIzNTY3OA==", "bodyText": "Yes, this is what map for.", "url": "https://github.com/apache/flink/pull/11515#discussion_r404235678", "createdAt": "2020-04-06T16:43:11Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RefCountingFSDataInputStream.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.fs.FSDataInputStream;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.SupplierWithException;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+@NotThreadSafe\n+class RefCountingFSDataInputStream extends FSDataInputStream {\n+\n+\t@NotThreadSafe\n+\tstatic class RefCountingFSDataInputStreamFactory {\n+\t\tprivate final Map<StreamStateHandle, RefCountingFSDataInputStream> map = new HashMap<>(); // not clearing: expecting short life\n+\t\tprivate final ChannelStateDeserializer serializer;\n+\n+\t\tRefCountingFSDataInputStreamFactory(ChannelStateDeserializer serializer) {\n+\t\t\tthis.serializer = serializer;\n+\t\t}\n+\n+\t\t<T> RefCountingFSDataInputStream forHandle(AbstractChannelStateHandle<T> handle) {\n+\t\t\tStreamStateHandle streamStateHandle = handle.getDelegate();\n+\t\t\tRefCountingFSDataInputStream stream = map.get(streamStateHandle);\n+\t\t\tif (stream == null) {\n+\t\t\t\tstream = new RefCountingFSDataInputStream(streamStateHandle::openInputStream, serializer);\n+\t\t\t\tmap.put(streamStateHandle, stream);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI3NTU2OQ=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 51}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5NDg5MDI2OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjozMjo1MVrOF_pA9g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjozMjo1MVrOF_pA9g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI3NjU5OA==", "bodyText": "#start misses one argument", "url": "https://github.com/apache/flink/pull/11515#discussion_r402276598", "createdAt": "2020-04-02T12:32:51Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriter.java", "diffHunk": "@@ -46,60 +78,64 @@\n \t/**\n \t * Initiate write of channel state for the given checkpoint id.\n \t */\n-\tvoid start(long checkpointId);\n+\tvoid start(long checkpointId, CheckpointOptions checkpointOptions);\n \n \t/**\n \t * Add in-flight buffers from the {@link org.apache.flink.runtime.io.network.partition.consumer.InputChannel InputChannel}.\n-\t * Must be called after {@link #start(long)} and before {@link #finish(long)}.\n+\t * Must be called after {@link #start} (long)} and before {@link #finishInput(long)}.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 65}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5NDkyMjc3OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImpl.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjo0MTozOVrOF_pVJg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNzoyNzoxNlrOGCOVog==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI4MTc2Ng==", "bodyText": "we can use the following for simple:\nIOUtils.closeAll(inputChannelHandleReaders.values());\nIOUtils.closeAll(resultSubpartitionHandleReaders.values());", "url": "https://github.com/apache/flink/pull/11515#discussion_r402281766", "createdAt": "2020-04-02T12:41:39Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImpl.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.io.Closer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * {@link ChannelStateReader} implementation. Usage considerations:\n+ * <ol>\n+ *     <li>state of a channel can be read once per instance of this class; once done it returns\n+ *     {@link org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult#NO_MORE_DATA NO_MORE_DATA}</li>\n+ *     <li>reader/writer indices of the passed buffer are respected and updated</li>\n+ *     <li>buffers must be prepared (cleared) before passing to reader</li>\n+ *     <li>buffers must be released after use</li>\n+ * </ol>\n+ */\n+@NotThreadSafe\n+@Internal\n+public class ChannelStateReaderImpl implements ChannelStateReader {\n+\tprivate static final Logger log = LoggerFactory.getLogger(ChannelStateReaderImpl.class);\n+\n+\tprivate final Map<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReaders;\n+\tprivate final Map<ResultSubpartitionInfo, ChannelStateStreamReader> resultSubpartitionHandleReaders;\n+\n+\tpublic ChannelStateReaderImpl(TaskStateSnapshot snapshot) {\n+\t\tthis(snapshot, new ChannelStateSerializerImpl());\n+\t}\n+\n+\t@SuppressWarnings(\"WeakerAccess\")\n+\tChannelStateReaderImpl(TaskStateSnapshot snapshot, ChannelStateDeserializer serializer) {\n+\t\tRefCountingFSDataInputStreamFactory streamFactory = new RefCountingFSDataInputStreamFactory(serializer);\n+\t\tfinal HashMap<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReadersTmp = new HashMap<>();\n+\t\tfinal HashMap<ResultSubpartitionInfo, ChannelStateStreamReader> resultSubpartitionHandleReadersTmp = new HashMap<>();\n+\t\tfor (Map.Entry<OperatorID, OperatorSubtaskState> e : snapshot.getSubtaskStateMappings()) {\n+\t\t\taddReaders(inputChannelHandleReadersTmp, e.getValue().getInputChannelState(), streamFactory);\n+\t\t\taddReaders(resultSubpartitionHandleReadersTmp, e.getValue().getResultSubpartitionState(), streamFactory);\n+\t\t}\n+\t\tinputChannelHandleReaders = inputChannelHandleReadersTmp;\n+\t\tresultSubpartitionHandleReaders = resultSubpartitionHandleReadersTmp;\n+\t}\n+\n+\tprivate <T> void addReaders(Map<T, ChannelStateStreamReader> readerMap, Collection<? extends AbstractChannelStateHandle<T>> handles, RefCountingFSDataInputStreamFactory streamFactory) {\n+\t\tfor (AbstractChannelStateHandle<T> handle : handles) {\n+\t\t\tcheckState(!readerMap.containsKey(handle.getInfo()), \"multiple states exist for channel: \" + handle.getInfo());\n+\t\t\treaderMap.put(handle.getInfo(), new ChannelStateStreamReader(handle, streamFactory));\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic ReadResult readInputData(InputChannelInfo info, Buffer buffer) throws IOException {\n+\t\tlog.debug(\"readInputData, resultSubpartitionInfo: {} , bufferBuilder {}\", info, buffer);\n+\t\treturn getReader(info, inputChannelHandleReaders).readInto(buffer);\n+\t}\n+\n+\t@Override\n+\tpublic ReadResult readOutputData(ResultSubpartitionInfo info, BufferBuilder bufferBuilder) throws IOException {\n+\t\tlog.debug(\"readOutputData, resultSubpartitionInfo: {} , bufferBuilder {}\", info, bufferBuilder);\n+\t\treturn getReader(info, resultSubpartitionHandleReaders).readInto(bufferBuilder);\n+\t}\n+\n+\tprivate <K> ChannelStateStreamReader getReader(K info, Map<K, ChannelStateStreamReader> readerMap) {\n+\t\tPreconditions.checkArgument(readerMap.containsKey(info), String.format(\"unknown channel %s. Known channels: %s\", info, readerMap.keySet()));\n+\t\treturn readerMap.get(info);\n+\t}\n+\n+\t@Override\n+\tpublic void close() throws Exception {\n+\t\ttry (Closer closer = Closer.create()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 106}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDI0NTY0Ng==", "bodyText": "Each of these two actions can still throw an exception; if both throw then one should be suppressed. This logic to handle that seems more complex to me than nested loops in try.", "url": "https://github.com/apache/flink/pull/11515#discussion_r404245646", "createdAt": "2020-04-06T16:58:23Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImpl.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.io.Closer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * {@link ChannelStateReader} implementation. Usage considerations:\n+ * <ol>\n+ *     <li>state of a channel can be read once per instance of this class; once done it returns\n+ *     {@link org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult#NO_MORE_DATA NO_MORE_DATA}</li>\n+ *     <li>reader/writer indices of the passed buffer are respected and updated</li>\n+ *     <li>buffers must be prepared (cleared) before passing to reader</li>\n+ *     <li>buffers must be released after use</li>\n+ * </ol>\n+ */\n+@NotThreadSafe\n+@Internal\n+public class ChannelStateReaderImpl implements ChannelStateReader {\n+\tprivate static final Logger log = LoggerFactory.getLogger(ChannelStateReaderImpl.class);\n+\n+\tprivate final Map<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReaders;\n+\tprivate final Map<ResultSubpartitionInfo, ChannelStateStreamReader> resultSubpartitionHandleReaders;\n+\n+\tpublic ChannelStateReaderImpl(TaskStateSnapshot snapshot) {\n+\t\tthis(snapshot, new ChannelStateSerializerImpl());\n+\t}\n+\n+\t@SuppressWarnings(\"WeakerAccess\")\n+\tChannelStateReaderImpl(TaskStateSnapshot snapshot, ChannelStateDeserializer serializer) {\n+\t\tRefCountingFSDataInputStreamFactory streamFactory = new RefCountingFSDataInputStreamFactory(serializer);\n+\t\tfinal HashMap<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReadersTmp = new HashMap<>();\n+\t\tfinal HashMap<ResultSubpartitionInfo, ChannelStateStreamReader> resultSubpartitionHandleReadersTmp = new HashMap<>();\n+\t\tfor (Map.Entry<OperatorID, OperatorSubtaskState> e : snapshot.getSubtaskStateMappings()) {\n+\t\t\taddReaders(inputChannelHandleReadersTmp, e.getValue().getInputChannelState(), streamFactory);\n+\t\t\taddReaders(resultSubpartitionHandleReadersTmp, e.getValue().getResultSubpartitionState(), streamFactory);\n+\t\t}\n+\t\tinputChannelHandleReaders = inputChannelHandleReadersTmp;\n+\t\tresultSubpartitionHandleReaders = resultSubpartitionHandleReadersTmp;\n+\t}\n+\n+\tprivate <T> void addReaders(Map<T, ChannelStateStreamReader> readerMap, Collection<? extends AbstractChannelStateHandle<T>> handles, RefCountingFSDataInputStreamFactory streamFactory) {\n+\t\tfor (AbstractChannelStateHandle<T> handle : handles) {\n+\t\t\tcheckState(!readerMap.containsKey(handle.getInfo()), \"multiple states exist for channel: \" + handle.getInfo());\n+\t\t\treaderMap.put(handle.getInfo(), new ChannelStateStreamReader(handle, streamFactory));\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic ReadResult readInputData(InputChannelInfo info, Buffer buffer) throws IOException {\n+\t\tlog.debug(\"readInputData, resultSubpartitionInfo: {} , bufferBuilder {}\", info, buffer);\n+\t\treturn getReader(info, inputChannelHandleReaders).readInto(buffer);\n+\t}\n+\n+\t@Override\n+\tpublic ReadResult readOutputData(ResultSubpartitionInfo info, BufferBuilder bufferBuilder) throws IOException {\n+\t\tlog.debug(\"readOutputData, resultSubpartitionInfo: {} , bufferBuilder {}\", info, bufferBuilder);\n+\t\treturn getReader(info, resultSubpartitionHandleReaders).readInto(bufferBuilder);\n+\t}\n+\n+\tprivate <K> ChannelStateStreamReader getReader(K info, Map<K, ChannelStateStreamReader> readerMap) {\n+\t\tPreconditions.checkArgument(readerMap.containsKey(info), String.format(\"unknown channel %s. Known channels: %s\", info, readerMap.keySet()));\n+\t\treturn readerMap.get(info);\n+\t}\n+\n+\t@Override\n+\tpublic void close() throws Exception {\n+\t\ttry (Closer closer = Closer.create()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI4MTc2Ng=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 106}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDU5NzcxOA==", "bodyText": "Yes, you are right.\nMy previous concern was whether it is proper way to rely on shaded.guava18 for this purpose (I am not quite sure). And we already introduced many basic functions in IOUtils for the similar usages. If the current option might also be widely used in other places, maybe it is worth the efforts to also be covered by IOUtils.", "url": "https://github.com/apache/flink/pull/11515#discussion_r404597718", "createdAt": "2020-04-07T07:35:23Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImpl.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.io.Closer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * {@link ChannelStateReader} implementation. Usage considerations:\n+ * <ol>\n+ *     <li>state of a channel can be read once per instance of this class; once done it returns\n+ *     {@link org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult#NO_MORE_DATA NO_MORE_DATA}</li>\n+ *     <li>reader/writer indices of the passed buffer are respected and updated</li>\n+ *     <li>buffers must be prepared (cleared) before passing to reader</li>\n+ *     <li>buffers must be released after use</li>\n+ * </ol>\n+ */\n+@NotThreadSafe\n+@Internal\n+public class ChannelStateReaderImpl implements ChannelStateReader {\n+\tprivate static final Logger log = LoggerFactory.getLogger(ChannelStateReaderImpl.class);\n+\n+\tprivate final Map<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReaders;\n+\tprivate final Map<ResultSubpartitionInfo, ChannelStateStreamReader> resultSubpartitionHandleReaders;\n+\n+\tpublic ChannelStateReaderImpl(TaskStateSnapshot snapshot) {\n+\t\tthis(snapshot, new ChannelStateSerializerImpl());\n+\t}\n+\n+\t@SuppressWarnings(\"WeakerAccess\")\n+\tChannelStateReaderImpl(TaskStateSnapshot snapshot, ChannelStateDeserializer serializer) {\n+\t\tRefCountingFSDataInputStreamFactory streamFactory = new RefCountingFSDataInputStreamFactory(serializer);\n+\t\tfinal HashMap<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReadersTmp = new HashMap<>();\n+\t\tfinal HashMap<ResultSubpartitionInfo, ChannelStateStreamReader> resultSubpartitionHandleReadersTmp = new HashMap<>();\n+\t\tfor (Map.Entry<OperatorID, OperatorSubtaskState> e : snapshot.getSubtaskStateMappings()) {\n+\t\t\taddReaders(inputChannelHandleReadersTmp, e.getValue().getInputChannelState(), streamFactory);\n+\t\t\taddReaders(resultSubpartitionHandleReadersTmp, e.getValue().getResultSubpartitionState(), streamFactory);\n+\t\t}\n+\t\tinputChannelHandleReaders = inputChannelHandleReadersTmp;\n+\t\tresultSubpartitionHandleReaders = resultSubpartitionHandleReadersTmp;\n+\t}\n+\n+\tprivate <T> void addReaders(Map<T, ChannelStateStreamReader> readerMap, Collection<? extends AbstractChannelStateHandle<T>> handles, RefCountingFSDataInputStreamFactory streamFactory) {\n+\t\tfor (AbstractChannelStateHandle<T> handle : handles) {\n+\t\t\tcheckState(!readerMap.containsKey(handle.getInfo()), \"multiple states exist for channel: \" + handle.getInfo());\n+\t\t\treaderMap.put(handle.getInfo(), new ChannelStateStreamReader(handle, streamFactory));\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic ReadResult readInputData(InputChannelInfo info, Buffer buffer) throws IOException {\n+\t\tlog.debug(\"readInputData, resultSubpartitionInfo: {} , bufferBuilder {}\", info, buffer);\n+\t\treturn getReader(info, inputChannelHandleReaders).readInto(buffer);\n+\t}\n+\n+\t@Override\n+\tpublic ReadResult readOutputData(ResultSubpartitionInfo info, BufferBuilder bufferBuilder) throws IOException {\n+\t\tlog.debug(\"readOutputData, resultSubpartitionInfo: {} , bufferBuilder {}\", info, bufferBuilder);\n+\t\treturn getReader(info, resultSubpartitionHandleReaders).readInto(bufferBuilder);\n+\t}\n+\n+\tprivate <K> ChannelStateStreamReader getReader(K info, Map<K, ChannelStateStreamReader> readerMap) {\n+\t\tPreconditions.checkArgument(readerMap.containsKey(info), String.format(\"unknown channel %s. Known channels: %s\", info, readerMap.keySet()));\n+\t\treturn readerMap.get(info);\n+\t}\n+\n+\t@Override\n+\tpublic void close() throws Exception {\n+\t\ttry (Closer closer = Closer.create()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI4MTc2Ng=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 106}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk4NTI1MA==", "bodyText": "Afaik it's fine to use guava now and I recommend to use Closer for all close-related, non-trivial operations.", "url": "https://github.com/apache/flink/pull/11515#discussion_r404985250", "createdAt": "2020-04-07T17:27:16Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImpl.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.io.Closer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * {@link ChannelStateReader} implementation. Usage considerations:\n+ * <ol>\n+ *     <li>state of a channel can be read once per instance of this class; once done it returns\n+ *     {@link org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult#NO_MORE_DATA NO_MORE_DATA}</li>\n+ *     <li>reader/writer indices of the passed buffer are respected and updated</li>\n+ *     <li>buffers must be prepared (cleared) before passing to reader</li>\n+ *     <li>buffers must be released after use</li>\n+ * </ol>\n+ */\n+@NotThreadSafe\n+@Internal\n+public class ChannelStateReaderImpl implements ChannelStateReader {\n+\tprivate static final Logger log = LoggerFactory.getLogger(ChannelStateReaderImpl.class);\n+\n+\tprivate final Map<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReaders;\n+\tprivate final Map<ResultSubpartitionInfo, ChannelStateStreamReader> resultSubpartitionHandleReaders;\n+\n+\tpublic ChannelStateReaderImpl(TaskStateSnapshot snapshot) {\n+\t\tthis(snapshot, new ChannelStateSerializerImpl());\n+\t}\n+\n+\t@SuppressWarnings(\"WeakerAccess\")\n+\tChannelStateReaderImpl(TaskStateSnapshot snapshot, ChannelStateDeserializer serializer) {\n+\t\tRefCountingFSDataInputStreamFactory streamFactory = new RefCountingFSDataInputStreamFactory(serializer);\n+\t\tfinal HashMap<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReadersTmp = new HashMap<>();\n+\t\tfinal HashMap<ResultSubpartitionInfo, ChannelStateStreamReader> resultSubpartitionHandleReadersTmp = new HashMap<>();\n+\t\tfor (Map.Entry<OperatorID, OperatorSubtaskState> e : snapshot.getSubtaskStateMappings()) {\n+\t\t\taddReaders(inputChannelHandleReadersTmp, e.getValue().getInputChannelState(), streamFactory);\n+\t\t\taddReaders(resultSubpartitionHandleReadersTmp, e.getValue().getResultSubpartitionState(), streamFactory);\n+\t\t}\n+\t\tinputChannelHandleReaders = inputChannelHandleReadersTmp;\n+\t\tresultSubpartitionHandleReaders = resultSubpartitionHandleReadersTmp;\n+\t}\n+\n+\tprivate <T> void addReaders(Map<T, ChannelStateStreamReader> readerMap, Collection<? extends AbstractChannelStateHandle<T>> handles, RefCountingFSDataInputStreamFactory streamFactory) {\n+\t\tfor (AbstractChannelStateHandle<T> handle : handles) {\n+\t\t\tcheckState(!readerMap.containsKey(handle.getInfo()), \"multiple states exist for channel: \" + handle.getInfo());\n+\t\t\treaderMap.put(handle.getInfo(), new ChannelStateStreamReader(handle, streamFactory));\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic ReadResult readInputData(InputChannelInfo info, Buffer buffer) throws IOException {\n+\t\tlog.debug(\"readInputData, resultSubpartitionInfo: {} , bufferBuilder {}\", info, buffer);\n+\t\treturn getReader(info, inputChannelHandleReaders).readInto(buffer);\n+\t}\n+\n+\t@Override\n+\tpublic ReadResult readOutputData(ResultSubpartitionInfo info, BufferBuilder bufferBuilder) throws IOException {\n+\t\tlog.debug(\"readOutputData, resultSubpartitionInfo: {} , bufferBuilder {}\", info, bufferBuilder);\n+\t\treturn getReader(info, resultSubpartitionHandleReaders).readInto(bufferBuilder);\n+\t}\n+\n+\tprivate <K> ChannelStateStreamReader getReader(K info, Map<K, ChannelStateStreamReader> readerMap) {\n+\t\tPreconditions.checkArgument(readerMap.containsKey(info), String.format(\"unknown channel %s. Known channels: %s\", info, readerMap.keySet()));\n+\t\treturn readerMap.get(info);\n+\t}\n+\n+\t@Override\n+\tpublic void close() throws Exception {\n+\t\ttry (Closer closer = Closer.create()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI4MTc2Ng=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 106}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5NDkyODMyOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjo0MzowNVrOF_pYgQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjo0MzowNVrOF_pYgQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI4MjYyNQ==", "bodyText": "ditto: flinkBuffers", "url": "https://github.com/apache/flink/pull/11515#discussion_r402282625", "createdAt": "2020-04-02T12:43:05Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 42}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5NDk0ODE4OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjo0ODoyN1rOF_plCg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjo0ODoyN1rOF_plCg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI4NTgzNA==", "bodyText": "nit: final", "url": "https://github.com/apache/flink/pull/11515#discussion_r402285834", "createdAt": "2020-04-02T12:48:27Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\tTuple2<Integer, Integer> readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\tint writableBytes();\n+\n+\tint writeBytes(InputStream input, int bytesToRead) throws IOException;\n+\n+\tstatic ChannelStateByteBuffer wrap(Buffer buffer) {\n+\t\treturn new ChannelStateByteBuffer() {\n+\n+\t\t\tprivate ByteBuf byteBuf = buffer.asByteBuf();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 75}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5NTU5NDM3OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNTowOToxN1rOF_v7GQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNTowOToxN1rOF_v7GQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjM4OTc4NQ==", "bodyText": "upToBytes -> bytesToRead to be consistent with above ChannelStateByteBuffer wrap(Buffer buffer)", "url": "https://github.com/apache/flink/pull/11515#discussion_r402389785", "createdAt": "2020-04-02T15:09:17Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\tTuple2<Integer, Integer> readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\tint writableBytes();\n+\n+\tint writeBytes(InputStream input, int bytesToRead) throws IOException;\n+\n+\tstatic ChannelStateByteBuffer wrap(Buffer buffer) {\n+\t\treturn new ChannelStateByteBuffer() {\n+\n+\t\t\tprivate ByteBuf byteBuf = buffer.asByteBuf();\n+\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn byteBuf.isWritable();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn byteBuf.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\treturn byteBuf.writeBytes(input, Math.min(bytesToRead, byteBuf.writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(BufferBuilder bufferBuilder) {\n+\t\tfinal byte[] buf = new byte[1024];\n+\t\treturn new ChannelStateByteBuffer() {\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn !bufferBuilder.isFull();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn bufferBuilder.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int upToBytes) throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 108}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5NTY2MTAyOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNToyMzozNlrOF_wlZg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNToyMzozNlrOF_wlZg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQwMDYxNA==", "bodyText": "Use bufferBuilder.writableBytes() to replace writableBytes() then we can remove this explicit interface method.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402400614", "createdAt": "2020-04-02T15:23:36Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\tTuple2<Integer, Integer> readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\tint writableBytes();\n+\n+\tint writeBytes(InputStream input, int bytesToRead) throws IOException;\n+\n+\tstatic ChannelStateByteBuffer wrap(Buffer buffer) {\n+\t\treturn new ChannelStateByteBuffer() {\n+\n+\t\t\tprivate ByteBuf byteBuf = buffer.asByteBuf();\n+\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn byteBuf.isWritable();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn byteBuf.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\treturn byteBuf.writeBytes(input, Math.min(bytesToRead, byteBuf.writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(BufferBuilder bufferBuilder) {\n+\t\tfinal byte[] buf = new byte[1024];\n+\t\treturn new ChannelStateByteBuffer() {\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn !bufferBuilder.isFull();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn bufferBuilder.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int upToBytes) throws IOException {\n+\t\t\t\tint left = upToBytes;\n+\t\t\t\tfor (int toRead = getToRead(left); toRead > 0; toRead = getToRead(left)) {\n+\t\t\t\t\tint read = input.read(buf, 0, toRead);\n+\t\t\t\t\tint copied = bufferBuilder.append(java.nio.ByteBuffer.wrap(buf, 0, read));\n+\t\t\t\t\tPreconditions.checkState(copied == read);\n+\t\t\t\t\tleft -= read;\n+\t\t\t\t}\n+\t\t\t\tbufferBuilder.commit();\n+\t\t\t\treturn upToBytes - left;\n+\t\t\t}\n+\n+\t\t\tprivate int getToRead(int bytesToRead) {\n+\t\t\t\treturn min(bytesToRead, min(buf.length, writableBytes()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 121}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5NTY2NDA3OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNToyNDoxMlrOF_wnVw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNzozMzowMFrOGCOktA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQwMTExMQ==", "bodyText": "I guess this wrap is never used atm", "url": "https://github.com/apache/flink/pull/11515#discussion_r402401111", "createdAt": "2020-04-02T15:24:12Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\tTuple2<Integer, Integer> readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\tint writableBytes();\n+\n+\tint writeBytes(InputStream input, int bytesToRead) throws IOException;\n+\n+\tstatic ChannelStateByteBuffer wrap(Buffer buffer) {\n+\t\treturn new ChannelStateByteBuffer() {\n+\n+\t\t\tprivate ByteBuf byteBuf = buffer.asByteBuf();\n+\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn byteBuf.isWritable();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn byteBuf.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\treturn byteBuf.writeBytes(input, Math.min(bytesToRead, byteBuf.writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(BufferBuilder bufferBuilder) {\n+\t\tfinal byte[] buf = new byte[1024];\n+\t\treturn new ChannelStateByteBuffer() {\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn !bufferBuilder.isFull();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn bufferBuilder.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int upToBytes) throws IOException {\n+\t\t\t\tint left = upToBytes;\n+\t\t\t\tfor (int toRead = getToRead(left); toRead > 0; toRead = getToRead(left)) {\n+\t\t\t\t\tint read = input.read(buf, 0, toRead);\n+\t\t\t\t\tint copied = bufferBuilder.append(java.nio.ByteBuffer.wrap(buf, 0, read));\n+\t\t\t\t\tPreconditions.checkState(copied == read);\n+\t\t\t\t\tleft -= read;\n+\t\t\t\t}\n+\t\t\t\tbufferBuilder.commit();\n+\t\t\t\treturn upToBytes - left;\n+\t\t\t}\n+\n+\t\t\tprivate int getToRead(int bytesToRead) {\n+\t\t\t\treturn min(bytesToRead, min(buf.length, writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(byte[] bytes) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 126}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDI0NzE3Ng==", "bodyText": "It is used in ChannelStateSerializerImplTest.", "url": "https://github.com/apache/flink/pull/11515#discussion_r404247176", "createdAt": "2020-04-06T17:00:37Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\tTuple2<Integer, Integer> readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\tint writableBytes();\n+\n+\tint writeBytes(InputStream input, int bytesToRead) throws IOException;\n+\n+\tstatic ChannelStateByteBuffer wrap(Buffer buffer) {\n+\t\treturn new ChannelStateByteBuffer() {\n+\n+\t\t\tprivate ByteBuf byteBuf = buffer.asByteBuf();\n+\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn byteBuf.isWritable();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn byteBuf.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\treturn byteBuf.writeBytes(input, Math.min(bytesToRead, byteBuf.writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(BufferBuilder bufferBuilder) {\n+\t\tfinal byte[] buf = new byte[1024];\n+\t\treturn new ChannelStateByteBuffer() {\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn !bufferBuilder.isFull();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn bufferBuilder.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int upToBytes) throws IOException {\n+\t\t\t\tint left = upToBytes;\n+\t\t\t\tfor (int toRead = getToRead(left); toRead > 0; toRead = getToRead(left)) {\n+\t\t\t\t\tint read = input.read(buf, 0, toRead);\n+\t\t\t\t\tint copied = bufferBuilder.append(java.nio.ByteBuffer.wrap(buf, 0, read));\n+\t\t\t\t\tPreconditions.checkState(copied == read);\n+\t\t\t\t\tleft -= read;\n+\t\t\t\t}\n+\t\t\t\tbufferBuilder.commit();\n+\t\t\t\treturn upToBytes - left;\n+\t\t\t}\n+\n+\t\t\tprivate int getToRead(int bytesToRead) {\n+\t\t\t\treturn min(bytesToRead, min(buf.length, writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(byte[] bytes) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQwMTExMQ=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 126}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk4OTEwOA==", "bodyText": "I'm not sure what the general agreement is, but I'm not a huge fan of adding code just to make testing easier. The only sensible exception is to add accessors to private fields. My main concern is that we blow up the production code without adding any functionality. This additional would then need additional tests, so we are testing code that is only relevant for tests...\nIf this subclass is useful only for testing, why not add it in the ChannelStateSerializerTest or in some *Util? For example, TestBufferFactory adds a convenient way to create small test buffers. If that was part of the actual Buffer interface, it would be very confusing to me.", "url": "https://github.com/apache/flink/pull/11515#discussion_r404989108", "createdAt": "2020-04-07T17:33:00Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\tTuple2<Integer, Integer> readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\tint writableBytes();\n+\n+\tint writeBytes(InputStream input, int bytesToRead) throws IOException;\n+\n+\tstatic ChannelStateByteBuffer wrap(Buffer buffer) {\n+\t\treturn new ChannelStateByteBuffer() {\n+\n+\t\t\tprivate ByteBuf byteBuf = buffer.asByteBuf();\n+\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn byteBuf.isWritable();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn byteBuf.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\treturn byteBuf.writeBytes(input, Math.min(bytesToRead, byteBuf.writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(BufferBuilder bufferBuilder) {\n+\t\tfinal byte[] buf = new byte[1024];\n+\t\treturn new ChannelStateByteBuffer() {\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn !bufferBuilder.isFull();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn bufferBuilder.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int upToBytes) throws IOException {\n+\t\t\t\tint left = upToBytes;\n+\t\t\t\tfor (int toRead = getToRead(left); toRead > 0; toRead = getToRead(left)) {\n+\t\t\t\t\tint read = input.read(buf, 0, toRead);\n+\t\t\t\t\tint copied = bufferBuilder.append(java.nio.ByteBuffer.wrap(buf, 0, read));\n+\t\t\t\t\tPreconditions.checkState(copied == read);\n+\t\t\t\t\tleft -= read;\n+\t\t\t\t}\n+\t\t\t\tbufferBuilder.commit();\n+\t\t\t\treturn upToBytes - left;\n+\t\t\t}\n+\n+\t\t\tprivate int getToRead(int bytesToRead) {\n+\t\t\t\treturn min(bytesToRead, min(buf.length, writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(byte[] bytes) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQwMTExMQ=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 126}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5NTY3MTk4OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNToyNTo0NVrOF_wsUA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNToyNTo0NVrOF_wsUA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQwMjM4NA==", "bodyText": "better to give javadoc for this method, then it is easy to understand the arguments especially for the meaning of the return value.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402402384", "createdAt": "2020-04-02T15:25:45Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\tTuple2<Integer, Integer> readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\tint writableBytes();\n+\n+\tint writeBytes(InputStream input, int bytesToRead) throws IOException;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 70}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5NTcwMTYyOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNTozMjowNVrOF_w_Mw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNzowNDo0OFrOGBhdRA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQwNzIxOQ==", "bodyText": "it seems redundant for defining this variable", "url": "https://github.com/apache/flink/pull/11515#discussion_r402407219", "createdAt": "2020-04-02T15:32:05Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\tTuple2<Integer, Integer> readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\tint writableBytes();\n+\n+\tint writeBytes(InputStream input, int bytesToRead) throws IOException;\n+\n+\tstatic ChannelStateByteBuffer wrap(Buffer buffer) {\n+\t\treturn new ChannelStateByteBuffer() {\n+\n+\t\t\tprivate ByteBuf byteBuf = buffer.asByteBuf();\n+\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn byteBuf.isWritable();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn byteBuf.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\treturn byteBuf.writeBytes(input, Math.min(bytesToRead, byteBuf.writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(BufferBuilder bufferBuilder) {\n+\t\tfinal byte[] buf = new byte[1024];\n+\t\treturn new ChannelStateByteBuffer() {\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn !bufferBuilder.isFull();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn bufferBuilder.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int upToBytes) throws IOException {\n+\t\t\t\tint left = upToBytes;\n+\t\t\t\tfor (int toRead = getToRead(left); toRead > 0; toRead = getToRead(left)) {\n+\t\t\t\t\tint read = input.read(buf, 0, toRead);\n+\t\t\t\t\tint copied = bufferBuilder.append(java.nio.ByteBuffer.wrap(buf, 0, read));\n+\t\t\t\t\tPreconditions.checkState(copied == read);\n+\t\t\t\t\tleft -= read;\n+\t\t\t\t}\n+\t\t\t\tbufferBuilder.commit();\n+\t\t\t\treturn upToBytes - left;\n+\t\t\t}\n+\n+\t\t\tprivate int getToRead(int bytesToRead) {\n+\t\t\t\treturn min(bytesToRead, min(buf.length, writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(byte[] bytes) {\n+\t\tint written = 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 127}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDI0OTkyNA==", "bodyText": "Should be member variable.", "url": "https://github.com/apache/flink/pull/11515#discussion_r404249924", "createdAt": "2020-04-06T17:04:48Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\tTuple2<Integer, Integer> readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\tint writableBytes();\n+\n+\tint writeBytes(InputStream input, int bytesToRead) throws IOException;\n+\n+\tstatic ChannelStateByteBuffer wrap(Buffer buffer) {\n+\t\treturn new ChannelStateByteBuffer() {\n+\n+\t\t\tprivate ByteBuf byteBuf = buffer.asByteBuf();\n+\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn byteBuf.isWritable();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn byteBuf.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\treturn byteBuf.writeBytes(input, Math.min(bytesToRead, byteBuf.writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(BufferBuilder bufferBuilder) {\n+\t\tfinal byte[] buf = new byte[1024];\n+\t\treturn new ChannelStateByteBuffer() {\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn !bufferBuilder.isFull();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn bufferBuilder.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int upToBytes) throws IOException {\n+\t\t\t\tint left = upToBytes;\n+\t\t\t\tfor (int toRead = getToRead(left); toRead > 0; toRead = getToRead(left)) {\n+\t\t\t\t\tint read = input.read(buf, 0, toRead);\n+\t\t\t\t\tint copied = bufferBuilder.append(java.nio.ByteBuffer.wrap(buf, 0, read));\n+\t\t\t\t\tPreconditions.checkState(copied == read);\n+\t\t\t\t\tleft -= read;\n+\t\t\t\t}\n+\t\t\t\tbufferBuilder.commit();\n+\t\t\t\treturn upToBytes - left;\n+\t\t\t}\n+\n+\t\t\tprivate int getToRead(int bytesToRead) {\n+\t\t\t\treturn min(bytesToRead, min(buf.length, writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(byte[] bytes) {\n+\t\tint written = 0;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQwNzIxOQ=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 127}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5NTcyMjAyOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNTozNjo1MVrOF_xMYw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxMToyOTozMFrOGB_Lxw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQxMDU5NQ==", "bodyText": "TBH I am concerning of creating the temporary byte array for every buffer level, it might be not friendly for GC. And it also brings additional copy while reading. But i have not thought of a better option now. Maybe at-least to reuse the same buf for every wrap?", "url": "https://github.com/apache/flink/pull/11515#discussion_r402410595", "createdAt": "2020-04-02T15:36:51Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\tTuple2<Integer, Integer> readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\tint writableBytes();\n+\n+\tint writeBytes(InputStream input, int bytesToRead) throws IOException;\n+\n+\tstatic ChannelStateByteBuffer wrap(Buffer buffer) {\n+\t\treturn new ChannelStateByteBuffer() {\n+\n+\t\t\tprivate ByteBuf byteBuf = buffer.asByteBuf();\n+\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn byteBuf.isWritable();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn byteBuf.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\treturn byteBuf.writeBytes(input, Math.min(bytesToRead, byteBuf.writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(BufferBuilder bufferBuilder) {\n+\t\tfinal byte[] buf = new byte[1024];", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDI2NTMwMA==", "bodyText": "I think we discussed it offline and agreed to some non-optimized approach.\nWith current BufferBuilder we can't avoid extra copying without resorting to accessing its underlying memorySegment.\nAs for GC, I don't know what's better here:\n\nallocate for each ChannelStateByteBuffer.writeBytes: won't escape method => no GC, but allocation cost\nallocate for each ChannelStateStreamReader.readInto (as it is now): short-lived - likely low GC pressure, but some allocation cost\nreuse between  ChannelStateStreamReader.readInto (what you proposed): memory overhead (we don't know when to clear); concurrency overhead / GC pressure with thread-locals (other issues?)\n\nAll in all, I think it's not a performance-critical part so we can optimize it later if needed.", "url": "https://github.com/apache/flink/pull/11515#discussion_r404265300", "createdAt": "2020-04-06T17:29:31Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\tTuple2<Integer, Integer> readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\tint writableBytes();\n+\n+\tint writeBytes(InputStream input, int bytesToRead) throws IOException;\n+\n+\tstatic ChannelStateByteBuffer wrap(Buffer buffer) {\n+\t\treturn new ChannelStateByteBuffer() {\n+\n+\t\t\tprivate ByteBuf byteBuf = buffer.asByteBuf();\n+\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn byteBuf.isWritable();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn byteBuf.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\treturn byteBuf.writeBytes(input, Math.min(bytesToRead, byteBuf.writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(BufferBuilder bufferBuilder) {\n+\t\tfinal byte[] buf = new byte[1024];", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQxMDU5NQ=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDczNjk2Nw==", "bodyText": "Yes, I remembered this discussion before and I agree this extra copy can not be avoided based on current codes. My previous assumption was that it would reuse the same bytes always like we did in SpillingAdaptiveSpanningRecordDeserializer#SpanningWrapper#buffer, to reduce GC pressure for many short-live objects.\nIf it is not easy to clear it, I am also fine with current way since it is not in critical path, only for recovery process. Then we can optimize it if necessary future.", "url": "https://github.com/apache/flink/pull/11515#discussion_r404736967", "createdAt": "2020-04-07T11:29:30Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\tTuple2<Integer, Integer> readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\tint writableBytes();\n+\n+\tint writeBytes(InputStream input, int bytesToRead) throws IOException;\n+\n+\tstatic ChannelStateByteBuffer wrap(Buffer buffer) {\n+\t\treturn new ChannelStateByteBuffer() {\n+\n+\t\t\tprivate ByteBuf byteBuf = buffer.asByteBuf();\n+\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn byteBuf.isWritable();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn byteBuf.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\treturn byteBuf.writeBytes(input, Math.min(bytesToRead, byteBuf.writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(BufferBuilder bufferBuilder) {\n+\t\tfinal byte[] buf = new byte[1024];", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQxMDU5NQ=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 95}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5NTczOTQ5OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriter.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNTo0MDo1NFrOF_xXyQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNzozMjo1OVrOGBiiAA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQxMzUxMw==", "bodyText": "nit: seems no need to throw this exception explicitly, because the subclass implementation actually does not throw such exception.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402413513", "createdAt": "2020-04-02T15:40:54Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriter.java", "diffHunk": "@@ -46,60 +78,64 @@\n \t/**\n \t * Initiate write of channel state for the given checkpoint id.\n \t */\n-\tvoid start(long checkpointId);\n+\tvoid start(long checkpointId, CheckpointOptions checkpointOptions);\n \n \t/**\n \t * Add in-flight buffers from the {@link org.apache.flink.runtime.io.network.partition.consumer.InputChannel InputChannel}.\n-\t * Must be called after {@link #start(long)} and before {@link #finish(long)}.\n+\t * Must be called after {@link #start} (long)} and before {@link #finishInput(long)}.\n+\t * Buffers are recycled after they are written.\n \t * @param startSeqNum sequence number of the 1st passed buffer.\n \t *                    It is intended to use for incremental snapshots.\n \t *                    If no data is passed it is ignored.\n-\t * @param data zero or more buffers ordered by their sequence numbers\n+\t * @param data zero or more <b>data</b> buffers ordered by their sequence numbers\n+\t * @throws IllegalArgumentException if one or more passed buffers {@link Buffer#isBuffer()  isn't a buffer}\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_RESTORED\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_UNKNOWN\n \t */\n-\tvoid addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data);\n+\tvoid addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data) throws IllegalArgumentException;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDI2NzUyMA==", "bodyText": "It does when it calls ChannelStateWriterImpl#checkBufferType (it is in signature here only to give more information to the caller (developer)).", "url": "https://github.com/apache/flink/pull/11515#discussion_r404267520", "createdAt": "2020-04-06T17:32:59Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriter.java", "diffHunk": "@@ -46,60 +78,64 @@\n \t/**\n \t * Initiate write of channel state for the given checkpoint id.\n \t */\n-\tvoid start(long checkpointId);\n+\tvoid start(long checkpointId, CheckpointOptions checkpointOptions);\n \n \t/**\n \t * Add in-flight buffers from the {@link org.apache.flink.runtime.io.network.partition.consumer.InputChannel InputChannel}.\n-\t * Must be called after {@link #start(long)} and before {@link #finish(long)}.\n+\t * Must be called after {@link #start} (long)} and before {@link #finishInput(long)}.\n+\t * Buffers are recycled after they are written.\n \t * @param startSeqNum sequence number of the 1st passed buffer.\n \t *                    It is intended to use for incremental snapshots.\n \t *                    If no data is passed it is ignored.\n-\t * @param data zero or more buffers ordered by their sequence numbers\n+\t * @param data zero or more <b>data</b> buffers ordered by their sequence numbers\n+\t * @throws IllegalArgumentException if one or more passed buffers {@link Buffer#isBuffer()  isn't a buffer}\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_RESTORED\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_UNKNOWN\n \t */\n-\tvoid addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data);\n+\tvoid addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data) throws IllegalArgumentException;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQxMzUxMw=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 77}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 712, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}