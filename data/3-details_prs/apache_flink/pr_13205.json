{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDcwNzUzNDMw", "number": 13205, "title": "[FLINK-17330[runtime] Merge cyclic dependent pipelined regions into one region", "bodyText": "What is the purpose of the change\nThis PR changes regions building to merge cyclic dependent pipelined regions into one region.\nThis is to avoid scheduling deadlocks due to cyclic dependencies.\nMore details see FLINK-17330.\nBrief change log\n\nAdded StronglyConnectedComponentsComputeUtils to find out cyclic dependent regions\nChanged PipelinedRegionComputeUtil to merge cyclic dependent pipelined regions into one region\n\nVerifying this change\n\nAdded UT StronglyConnectedComponentsComputeUtilsTest\nAdded test case in PipelinedRegionComputeUtilTest to verify regions on the same cycles are merged\n\nDoes this pull request potentially affect one of the following parts:\n\nDependencies (does it add or upgrade a dependency): (yes / no)\nThe public API, i.e., is any changed class annotated with @Public(Evolving): (yes / no)\nThe serializers: (yes / no / don't know)\nThe runtime per-record code paths (performance sensitive): (yes / no / don't know)\nAnything that affects deployment or recovery: JobManager (and its components), Checkpointing, Kubernetes/Yarn/Mesos, ZooKeeper: (yes / no / don't know)\nThe S3 file system connector: (yes / no / don't know)\n\nDocumentation\n\nDoes this pull request introduce a new feature? (yes / no)\nIf yes, how is the feature documented? (not applicable / docs / JavaDocs / not documented)", "createdAt": "2020-08-20T08:30:41Z", "url": "https://github.com/apache/flink/pull/13205", "merged": true, "mergeCommit": {"oid": "c0f382f5f0072441ef8933f6993f1c34168004d6"}, "closed": true, "closedAt": "2020-08-25T02:16:23Z", "author": {"login": "zhuzhurk"}, "timelineItems": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdA1eUNgFqTQ3MTkwNDUxMg==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdCFMJygBqjM2ODYyNTQ5ODE=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcxOTA0NTEy", "url": "https://github.com/apache/flink/pull/13205#pullrequestreview-471904512", "createdAt": "2020-08-20T19:09:12Z", "commit": {"oid": "e11ffec55b9151857069d64c806b47cc98d9679d"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQxOTowOToxMlrOHEPceQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQxOTozNDo1MlrOHEQVww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDIwOTQwMQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t\t\tfinal int vertexLoopCount = tuple.f1;\n          \n          \n            \n            \t\t\tfinal int vertexOutEdgeIndex = tuple.f1;", "url": "https://github.com/apache/flink/pull/13205#discussion_r474209401", "createdAt": "2020-08-20T19:09:12Z", "author": {"login": "azagrebin"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/failover/flip1/StronglyConnectedComponentsComputeUtils.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.flink.runtime.executiongraph.failover.flip1;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+\n+import java.util.ArrayDeque;\n+import java.util.Arrays;\n+import java.util.Deque;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+/**\n+ * Utility for computing strongly connected components.\n+ *\n+ * <p>The computation is an implementation of Tarjan's algorithm.\n+ *\n+ * <p>Ref: https://en.wikipedia.org/wiki/Tarjan%27s_strongly_connected_components_algorithm.\n+ */\n+public final class StronglyConnectedComponentsComputeUtils {\n+\n+\tstatic Set<Set<Integer>> computeStronglyConnectedComponents(final int numVertex, final List<List<Integer>> outEdges) {\n+\t\tfinal Set<Set<Integer>> stronglyConnectedComponents = new HashSet<>();\n+\n+\t\tfinal int[] vertexIndices = new int[numVertex];\n+\t\tArrays.fill(vertexIndices, -1);\n+\n+\t\tfinal int[] vertexLowLinks = new int[numVertex];\n+\t\tfinal Deque<Integer> stack = new ArrayDeque<>(numVertex);\n+\t\tfinal boolean[] onStack = new boolean[numVertex];\n+\t\tfinal AtomicInteger indexCounter = new AtomicInteger(0);\n+\n+\t\tfor (int vertex = 0; vertex < numVertex; vertex++) {\n+\t\t\tif (vertexIndices[vertex] == -1) {\n+\t\t\t\tdfs(vertex, outEdges, vertexIndices, vertexLowLinks, stack, onStack, indexCounter, stronglyConnectedComponents);\n+\t\t\t}\n+\t\t}\n+\n+\t\treturn stronglyConnectedComponents;\n+\t}\n+\n+\tprivate static void dfs(\n+\t\t\tfinal int rootVertex,\n+\t\t\tfinal List<List<Integer>> outEdges,\n+\t\t\tfinal int[] vertexIndices,\n+\t\t\tfinal int[] vertexLowLinks,\n+\t\t\tfinal Deque<Integer> stack,\n+\t\t\tfinal boolean[] onStack,\n+\t\t\tfinal AtomicInteger indexCounter,\n+\t\t\tfinal Set<Set<Integer>> stronglyConnectedComponents) {\n+\n+\t\tfinal Deque<Tuple2<Integer, Integer>> loopStack = new ArrayDeque<>();\n+\t\tloopStack.add(new Tuple2<>(rootVertex, 0));\n+\n+\t\twhile (!loopStack.isEmpty()) {\n+\t\t\tTuple2<Integer, Integer> tuple = loopStack.pollLast();\n+\t\t\tfinal int currentVertex = tuple.f0;\n+\t\t\tfinal int vertexLoopCount = tuple.f1;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e11ffec55b9151857069d64c806b47cc98d9679d"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDIxMTk0NA==", "bodyText": "I would add more comments for respective code blocks or maybe even additionally break the loop body into three methods/steps:\nstartTraversingVertex\nfinishTaversingOutEdge\ntraverseOutEdges\ncreateConnectedComponent", "url": "https://github.com/apache/flink/pull/13205#discussion_r474211944", "createdAt": "2020-08-20T19:14:01Z", "author": {"login": "azagrebin"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/failover/flip1/StronglyConnectedComponentsComputeUtils.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.flink.runtime.executiongraph.failover.flip1;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+\n+import java.util.ArrayDeque;\n+import java.util.Arrays;\n+import java.util.Deque;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+/**\n+ * Utility for computing strongly connected components.\n+ *\n+ * <p>The computation is an implementation of Tarjan's algorithm.\n+ *\n+ * <p>Ref: https://en.wikipedia.org/wiki/Tarjan%27s_strongly_connected_components_algorithm.\n+ */\n+public final class StronglyConnectedComponentsComputeUtils {\n+\n+\tstatic Set<Set<Integer>> computeStronglyConnectedComponents(final int numVertex, final List<List<Integer>> outEdges) {\n+\t\tfinal Set<Set<Integer>> stronglyConnectedComponents = new HashSet<>();\n+\n+\t\tfinal int[] vertexIndices = new int[numVertex];\n+\t\tArrays.fill(vertexIndices, -1);\n+\n+\t\tfinal int[] vertexLowLinks = new int[numVertex];\n+\t\tfinal Deque<Integer> stack = new ArrayDeque<>(numVertex);\n+\t\tfinal boolean[] onStack = new boolean[numVertex];\n+\t\tfinal AtomicInteger indexCounter = new AtomicInteger(0);\n+\n+\t\tfor (int vertex = 0; vertex < numVertex; vertex++) {\n+\t\t\tif (vertexIndices[vertex] == -1) {\n+\t\t\t\tdfs(vertex, outEdges, vertexIndices, vertexLowLinks, stack, onStack, indexCounter, stronglyConnectedComponents);\n+\t\t\t}\n+\t\t}\n+\n+\t\treturn stronglyConnectedComponents;\n+\t}\n+\n+\tprivate static void dfs(\n+\t\t\tfinal int rootVertex,\n+\t\t\tfinal List<List<Integer>> outEdges,\n+\t\t\tfinal int[] vertexIndices,\n+\t\t\tfinal int[] vertexLowLinks,\n+\t\t\tfinal Deque<Integer> stack,\n+\t\t\tfinal boolean[] onStack,\n+\t\t\tfinal AtomicInteger indexCounter,\n+\t\t\tfinal Set<Set<Integer>> stronglyConnectedComponents) {\n+\n+\t\tfinal Deque<Tuple2<Integer, Integer>> loopStack = new ArrayDeque<>();\n+\t\tloopStack.add(new Tuple2<>(rootVertex, 0));\n+\n+\t\twhile (!loopStack.isEmpty()) {\n+\t\t\tTuple2<Integer, Integer> tuple = loopStack.pollLast();\n+\t\t\tfinal int currentVertex = tuple.f0;\n+\t\t\tfinal int vertexLoopCount = tuple.f1;\n+\n+\t\t\tif (vertexLoopCount == 0) {\n+\t\t\t\tvertexIndices[currentVertex] = indexCounter.get();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e11ffec55b9151857069d64c806b47cc98d9679d"}, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDIxMjE4Ng==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t\tfinal Deque<Tuple2<Integer, Integer>> loopStack = new ArrayDeque<>();\n          \n          \n            \n            \t\tfinal Deque<Tuple2<Integer, Integer>> dfsLoopStack = new ArrayDeque<>();", "url": "https://github.com/apache/flink/pull/13205#discussion_r474212186", "createdAt": "2020-08-20T19:14:28Z", "author": {"login": "azagrebin"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/failover/flip1/StronglyConnectedComponentsComputeUtils.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.flink.runtime.executiongraph.failover.flip1;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+\n+import java.util.ArrayDeque;\n+import java.util.Arrays;\n+import java.util.Deque;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+/**\n+ * Utility for computing strongly connected components.\n+ *\n+ * <p>The computation is an implementation of Tarjan's algorithm.\n+ *\n+ * <p>Ref: https://en.wikipedia.org/wiki/Tarjan%27s_strongly_connected_components_algorithm.\n+ */\n+public final class StronglyConnectedComponentsComputeUtils {\n+\n+\tstatic Set<Set<Integer>> computeStronglyConnectedComponents(final int numVertex, final List<List<Integer>> outEdges) {\n+\t\tfinal Set<Set<Integer>> stronglyConnectedComponents = new HashSet<>();\n+\n+\t\tfinal int[] vertexIndices = new int[numVertex];\n+\t\tArrays.fill(vertexIndices, -1);\n+\n+\t\tfinal int[] vertexLowLinks = new int[numVertex];\n+\t\tfinal Deque<Integer> stack = new ArrayDeque<>(numVertex);\n+\t\tfinal boolean[] onStack = new boolean[numVertex];\n+\t\tfinal AtomicInteger indexCounter = new AtomicInteger(0);\n+\n+\t\tfor (int vertex = 0; vertex < numVertex; vertex++) {\n+\t\t\tif (vertexIndices[vertex] == -1) {\n+\t\t\t\tdfs(vertex, outEdges, vertexIndices, vertexLowLinks, stack, onStack, indexCounter, stronglyConnectedComponents);\n+\t\t\t}\n+\t\t}\n+\n+\t\treturn stronglyConnectedComponents;\n+\t}\n+\n+\tprivate static void dfs(\n+\t\t\tfinal int rootVertex,\n+\t\t\tfinal List<List<Integer>> outEdges,\n+\t\t\tfinal int[] vertexIndices,\n+\t\t\tfinal int[] vertexLowLinks,\n+\t\t\tfinal Deque<Integer> stack,\n+\t\t\tfinal boolean[] onStack,\n+\t\t\tfinal AtomicInteger indexCounter,\n+\t\t\tfinal Set<Set<Integer>> stronglyConnectedComponents) {\n+\n+\t\tfinal Deque<Tuple2<Integer, Integer>> loopStack = new ArrayDeque<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e11ffec55b9151857069d64c806b47cc98d9679d"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDIxMjQyMA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t\tfinal Deque<Integer> stack = new ArrayDeque<>(numVertex);\n          \n          \n            \n            \t\tfinal Deque<Integer> ccStack = new ArrayDeque<>(numVertex);", "url": "https://github.com/apache/flink/pull/13205#discussion_r474212420", "createdAt": "2020-08-20T19:14:54Z", "author": {"login": "azagrebin"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/failover/flip1/StronglyConnectedComponentsComputeUtils.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.flink.runtime.executiongraph.failover.flip1;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+\n+import java.util.ArrayDeque;\n+import java.util.Arrays;\n+import java.util.Deque;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+/**\n+ * Utility for computing strongly connected components.\n+ *\n+ * <p>The computation is an implementation of Tarjan's algorithm.\n+ *\n+ * <p>Ref: https://en.wikipedia.org/wiki/Tarjan%27s_strongly_connected_components_algorithm.\n+ */\n+public final class StronglyConnectedComponentsComputeUtils {\n+\n+\tstatic Set<Set<Integer>> computeStronglyConnectedComponents(final int numVertex, final List<List<Integer>> outEdges) {\n+\t\tfinal Set<Set<Integer>> stronglyConnectedComponents = new HashSet<>();\n+\n+\t\tfinal int[] vertexIndices = new int[numVertex];\n+\t\tArrays.fill(vertexIndices, -1);\n+\n+\t\tfinal int[] vertexLowLinks = new int[numVertex];\n+\t\tfinal Deque<Integer> stack = new ArrayDeque<>(numVertex);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e11ffec55b9151857069d64c806b47cc98d9679d"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDIxMzE5OQ==", "bodyText": "From what I saw before and discussed as code style, we usually put instance methods before static methods.", "url": "https://github.com/apache/flink/pull/13205#discussion_r474213199", "createdAt": "2020-08-20T19:16:21Z", "author": {"login": "azagrebin"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/failover/flip1/StronglyConnectedComponentsComputeUtils.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.flink.runtime.executiongraph.failover.flip1;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+\n+import java.util.ArrayDeque;\n+import java.util.Arrays;\n+import java.util.Deque;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+/**\n+ * Utility for computing strongly connected components.\n+ *\n+ * <p>The computation is an implementation of Tarjan's algorithm.\n+ *\n+ * <p>Ref: https://en.wikipedia.org/wiki/Tarjan%27s_strongly_connected_components_algorithm.\n+ */\n+public final class StronglyConnectedComponentsComputeUtils {\n+\n+\tstatic Set<Set<Integer>> computeStronglyConnectedComponents(final int numVertex, final List<List<Integer>> outEdges) {\n+\t\tfinal Set<Set<Integer>> stronglyConnectedComponents = new HashSet<>();\n+\n+\t\tfinal int[] vertexIndices = new int[numVertex];\n+\t\tArrays.fill(vertexIndices, -1);\n+\n+\t\tfinal int[] vertexLowLinks = new int[numVertex];\n+\t\tfinal Deque<Integer> stack = new ArrayDeque<>(numVertex);\n+\t\tfinal boolean[] onStack = new boolean[numVertex];\n+\t\tfinal AtomicInteger indexCounter = new AtomicInteger(0);\n+\n+\t\tfor (int vertex = 0; vertex < numVertex; vertex++) {\n+\t\t\tif (vertexIndices[vertex] == -1) {\n+\t\t\t\tdfs(vertex, outEdges, vertexIndices, vertexLowLinks, stack, onStack, indexCounter, stronglyConnectedComponents);\n+\t\t\t}\n+\t\t}\n+\n+\t\treturn stronglyConnectedComponents;\n+\t}\n+\n+\tprivate static void dfs(\n+\t\t\tfinal int rootVertex,\n+\t\t\tfinal List<List<Integer>> outEdges,\n+\t\t\tfinal int[] vertexIndices,\n+\t\t\tfinal int[] vertexLowLinks,\n+\t\t\tfinal Deque<Integer> stack,\n+\t\t\tfinal boolean[] onStack,\n+\t\t\tfinal AtomicInteger indexCounter,\n+\t\t\tfinal Set<Set<Integer>> stronglyConnectedComponents) {\n+\n+\t\tfinal Deque<Tuple2<Integer, Integer>> loopStack = new ArrayDeque<>();\n+\t\tloopStack.add(new Tuple2<>(rootVertex, 0));\n+\n+\t\twhile (!loopStack.isEmpty()) {\n+\t\t\tTuple2<Integer, Integer> tuple = loopStack.pollLast();\n+\t\t\tfinal int currentVertex = tuple.f0;\n+\t\t\tfinal int vertexLoopCount = tuple.f1;\n+\n+\t\t\tif (vertexLoopCount == 0) {\n+\t\t\t\tvertexIndices[currentVertex] = indexCounter.get();\n+\t\t\t\tvertexLowLinks[currentVertex] = indexCounter.getAndIncrement();\n+\t\t\t\tstack.add(currentVertex);\n+\t\t\t\tonStack[currentVertex] = true;\n+\t\t\t} else if (vertexLoopCount > 0) {\n+\t\t\t\tfinal int successorVertex = outEdges.get(currentVertex).get(vertexLoopCount - 1);\n+\t\t\t\tvertexLowLinks[currentVertex] = Math.min(vertexLowLinks[currentVertex], vertexLowLinks[successorVertex]);\n+\t\t\t}\n+\n+\t\t\tboolean visitSuccessorVertex = false;\n+\t\t\tfor (int i = vertexLoopCount; i < outEdges.get(currentVertex).size(); i++) {\n+\t\t\t\tfinal int successorVertex = outEdges.get(currentVertex).get(i);\n+\t\t\t\tif (vertexIndices[successorVertex] == -1) {\n+\t\t\t\t\tloopStack.add(new Tuple2<>(currentVertex, i + 1));\n+\t\t\t\t\tloopStack.add(new Tuple2<>(successorVertex, 0));\n+\t\t\t\t\tvisitSuccessorVertex = true;\n+\t\t\t\t\tbreak;\n+\t\t\t\t} else if (onStack[successorVertex]) {\n+\t\t\t\t\tvertexLowLinks[currentVertex] = Math.min(vertexLowLinks[currentVertex], vertexIndices[successorVertex]);\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\tif (visitSuccessorVertex) {\n+\t\t\t\tcontinue;\n+\t\t\t}\n+\n+\t\t\tif (vertexLowLinks[currentVertex] == vertexIndices[currentVertex]) {\n+\t\t\t\tfinal Set<Integer> scc = new HashSet<>();\n+\t\t\t\twhile (onStack[currentVertex]) {\n+\t\t\t\t\tfinal int v = stack.pollLast();\n+\t\t\t\t\tonStack[v] = false;\n+\t\t\t\t\tscc.add(v);\n+\n+\t\t\t\t}\n+\t\t\t\tstronglyConnectedComponents.add(scc);\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate StronglyConnectedComponentsComputeUtils() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e11ffec55b9151857069d64c806b47cc98d9679d"}, "originalPosition": 119}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDIyNDA2Nw==", "bodyText": "Do we need this random test? Is it not covered by separate deterministic cases in other tests?", "url": "https://github.com/apache/flink/pull/13205#discussion_r474224067", "createdAt": "2020-08-20T19:34:52Z", "author": {"login": "azagrebin"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/executiongraph/failover/flip1/StronglyConnectedComponentsComputeUtilsTest.java", "diffHunk": "@@ -0,0 +1,216 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.executiongraph.failover.flip1;\n+\n+import org.apache.flink.util.TestLogger;\n+\n+import org.junit.Test;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import java.util.stream.IntStream;\n+\n+import static org.apache.flink.runtime.executiongraph.failover.flip1.StronglyConnectedComponentsComputeUtils.computeStronglyConnectedComponents;\n+import static org.hamcrest.Matchers.is;\n+import static org.junit.Assert.assertThat;\n+\n+/**\n+ * Unit tests for {@link StronglyConnectedComponentsComputeUtils}.\n+ */\n+public class StronglyConnectedComponentsComputeUtilsTest extends TestLogger {\n+\n+\t@Test\n+\tpublic void testWithCycles() {\n+\t\tfinal List<List<Integer>> edges = Arrays.asList(\n+\t\t\tArrays.asList(2, 3),\n+\t\t\tArrays.asList(0),\n+\t\t\tArrays.asList(1),\n+\t\t\tArrays.asList(4),\n+\t\t\tCollections.emptyList());\n+\n+\t\tfinal Set<Set<Integer>> result = computeStronglyConnectedComponents(5, edges);\n+\n+\t\tfinal Set<Set<Integer>> expected = new HashSet<>();\n+\t\texpected.add(new HashSet<>(Arrays.asList(0, 1, 2)));\n+\t\texpected.add(Collections.singleton(3));\n+\t\texpected.add(Collections.singleton(4));\n+\n+\t\tassertThat(result, is(expected));\n+\t}\n+\n+\t@Test\n+\tpublic void testWithMultipleCycles() {\n+\t\tfinal List<List<Integer>> edges = Arrays.asList(\n+\t\t\tArrays.asList(1),\n+\t\t\tArrays.asList(2),\n+\t\t\tArrays.asList(0),\n+\t\t\tArrays.asList(1, 2, 4),\n+\t\t\tArrays.asList(3, 5),\n+\t\t\tArrays.asList(2, 6),\n+\t\t\tArrays.asList(5),\n+\t\t\tArrays.asList(4, 6, 7));\n+\n+\t\tfinal Set<Set<Integer>> result = computeStronglyConnectedComponents(8, edges);\n+\n+\t\tfinal Set<Set<Integer>> expected = new HashSet<>();\n+\t\texpected.add(new HashSet<>(Arrays.asList(0, 1, 2)));\n+\t\texpected.add(new HashSet<>(Arrays.asList(3, 4)));\n+\t\texpected.add(new HashSet<>(Arrays.asList(5, 6)));\n+\t\texpected.add(Collections.singleton(7));\n+\n+\t\tassertThat(result, is(expected));\n+\t}\n+\n+\t@Test\n+\tpublic void testWithConnectedCycles() {\n+\t\tfinal List<List<Integer>> edges = Arrays.asList(\n+\t\t\tArrays.asList(1),\n+\t\t\tArrays.asList(2, 4, 5),\n+\t\t\tArrays.asList(3, 6),\n+\t\t\tArrays.asList(2, 7),\n+\t\t\tArrays.asList(0, 5),\n+\t\t\tArrays.asList(6),\n+\t\t\tArrays.asList(5),\n+\t\t\tArrays.asList(3, 6));\n+\n+\t\tfinal Set<Set<Integer>> result = computeStronglyConnectedComponents(8, edges);\n+\n+\t\tfinal Set<Set<Integer>> expected = new HashSet<>();\n+\t\texpected.add(new HashSet<>(Arrays.asList(0, 1, 4)));\n+\t\texpected.add(new HashSet<>(Arrays.asList(2, 3, 7)));\n+\t\texpected.add(new HashSet<>(Arrays.asList(5, 6)));\n+\n+\t\tassertThat(result, is(expected));\n+\t}\n+\n+\t@Test\n+\tpublic void testWithNoEdge() {\n+\t\tfinal List<List<Integer>> edges = Arrays.asList(\n+\t\t\tCollections.emptyList(),\n+\t\t\tCollections.emptyList(),\n+\t\t\tCollections.emptyList(),\n+\t\t\tCollections.emptyList(),\n+\t\t\tCollections.emptyList());\n+\n+\t\tfinal Set<Set<Integer>> result = computeStronglyConnectedComponents(5, edges);\n+\n+\t\tfinal Set<Set<Integer>> expected = new HashSet<>();\n+\t\texpected.add(Collections.singleton(0));\n+\t\texpected.add(Collections.singleton(1));\n+\t\texpected.add(Collections.singleton(2));\n+\t\texpected.add(Collections.singleton(3));\n+\t\texpected.add(Collections.singleton(4));\n+\n+\t\tassertThat(result, is(expected));\n+\t}\n+\n+\t@Test\n+\tpublic void testWithNoCycle() {\n+\t\tfinal List<List<Integer>> edges = Arrays.asList(\n+\t\t\tArrays.asList(1),\n+\t\t\tArrays.asList(2),\n+\t\t\tArrays.asList(3),\n+\t\t\tArrays.asList(4),\n+\t\t\tCollections.emptyList());\n+\n+\t\tfinal Set<Set<Integer>> result = computeStronglyConnectedComponents(5, edges);\n+\n+\t\tfinal Set<Set<Integer>> expected = new HashSet<>();\n+\t\texpected.add(Collections.singleton(0));\n+\t\texpected.add(Collections.singleton(1));\n+\t\texpected.add(Collections.singleton(2));\n+\t\texpected.add(Collections.singleton(3));\n+\t\texpected.add(Collections.singleton(4));\n+\n+\t\tassertThat(result, is(expected));\n+\t}\n+\n+\t@Test\n+\tpublic void testLargeGraph() {\n+\t\tfinal int n = 100000;\n+\t\tfinal List<List<Integer>> edges = new ArrayList<>();\n+\t\tfor (int i = 0; i < n; i++) {\n+\t\t\tedges.add(Collections.singletonList((i + 1) % n));\n+\t\t}\n+\n+\t\tfinal Set<Set<Integer>> result = computeStronglyConnectedComponents(n, edges);\n+\n+\t\tfinal Set<Integer> singleComponent = IntStream.range(0, n).boxed().collect(Collectors.toSet());\n+\n+\t\tassertThat(result, is(Collections.singleton(singleComponent)));\n+\t}\n+\n+\t@Test\n+\tpublic void testArbitraryGraph() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e11ffec55b9151857069d64c806b47cc98d9679d"}, "originalPosition": 166}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e11ffec55b9151857069d64c806b47cc98d9679d", "author": {"user": {"login": "zhuzhurk", "name": "Zhu Zhu"}}, "url": "https://github.com/apache/flink/commit/e11ffec55b9151857069d64c806b47cc98d9679d", "committedDate": "2020-08-20T08:24:37Z", "message": "[FLINK-17330[runtime] Merge cyclic dependent pipelined regions into one region"}, "afterCommit": {"oid": "b6ec9981ff3880e61df71fc37459026dcaafb950", "author": {"user": {"login": "zhuzhurk", "name": "Zhu Zhu"}}, "url": "https://github.com/apache/flink/commit/b6ec9981ff3880e61df71fc37459026dcaafb950", "committedDate": "2020-08-24T07:16:56Z", "message": "Fixup! [FLINK-17330[runtime] Merge cyclic dependent pipelined regions into one region"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDczNTk0NTMz", "url": "https://github.com/apache/flink/pull/13205#pullrequestreview-473594533", "createdAt": "2020-08-24T15:07:58Z", "commit": {"oid": "b6ec9981ff3880e61df71fc37459026dcaafb950"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "58d0d7f9198d7c336135a3078f9c6cc993a0d358", "author": {"user": {"login": "zhuzhurk", "name": "Zhu Zhu"}}, "url": "https://github.com/apache/flink/commit/58d0d7f9198d7c336135a3078f9c6cc993a0d358", "committedDate": "2020-08-24T16:24:38Z", "message": "[hotfix][runtime] Avoid unnecessary map building in PipelinedRegionComputeUtil#buildOneRegionForAllVertices()"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e1b7f9c42197706ca699b57ed587562b05e84dc0", "author": {"user": {"login": "zhuzhurk", "name": "Zhu Zhu"}}, "url": "https://github.com/apache/flink/commit/e1b7f9c42197706ca699b57ed587562b05e84dc0", "committedDate": "2020-08-24T16:24:38Z", "message": "[FLINK-17330[runtime] Extract common methods out from PipelinedRegionComputeUtil#computePipelinedRegions()"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8617ce6c0c5e0b4e8ba01aae58b1ef5cff2f02e6", "author": {"user": {"login": "zhuzhurk", "name": "Zhu Zhu"}}, "url": "https://github.com/apache/flink/commit/8617ce6c0c5e0b4e8ba01aae58b1ef5cff2f02e6", "committedDate": "2020-08-24T16:27:31Z", "message": "[FLINK-17330[runtime] Merge cyclic dependent pipelined regions into one region"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b6ec9981ff3880e61df71fc37459026dcaafb950", "author": {"user": {"login": "zhuzhurk", "name": "Zhu Zhu"}}, "url": "https://github.com/apache/flink/commit/b6ec9981ff3880e61df71fc37459026dcaafb950", "committedDate": "2020-08-24T07:16:56Z", "message": "Fixup! [FLINK-17330[runtime] Merge cyclic dependent pipelined regions into one region"}, "afterCommit": {"oid": "8617ce6c0c5e0b4e8ba01aae58b1ef5cff2f02e6", "author": {"user": {"login": "zhuzhurk", "name": "Zhu Zhu"}}, "url": "https://github.com/apache/flink/commit/8617ce6c0c5e0b4e8ba01aae58b1ef5cff2f02e6", "committedDate": "2020-08-24T16:27:31Z", "message": "[FLINK-17330[runtime] Merge cyclic dependent pipelined regions into one region"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4658, "cost": 1, "resetAt": "2021-10-28T16:48:13Z"}}}