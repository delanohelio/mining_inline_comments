{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDAxMzIyNjU5", "number": 11687, "reviewThreads": {"totalCount": 42, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOVQxNDowODoxOFrODwa9AQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQwNzowNjo1MVrOD7hIjg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyMDk5ODQxOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/LocalInputChannel.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOVQxNDowODoxOFrOGDaYSA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQxODowNToyMlrOGFatzw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjIzMTExMg==", "bodyText": "Could those changes about dropping int subpartitionIndex be a separate commit?", "url": "https://github.com/apache/flink/pull/11687#discussion_r406231112", "createdAt": "2020-04-09T14:08:18Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/LocalInputChannel.java", "diffHunk": "@@ -95,7 +95,7 @@ public LocalInputChannel(\n \t// ------------------------------------------------------------------------\n \n \t@Override\n-\tprotected void requestSubpartition(int subpartitionIndex) throws IOException, InterruptedException {\n+\tprotected void requestSubpartition() throws IOException, InterruptedException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c8c0da9e2badf68c11e8466943c7a8e14156c858"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIyNDUzNQ==", "bodyText": "I actually considered whether to extract it as a separate commit or not when implementation. I think both ways can be interpreted from different motivations.\n\n\nIf making it as a separate hotfix or refactor commit, we only save one argument from this interface method and fetch it from SingleInputGate instead. Then the benefit seems not very obvious if without the following input recovery change.\n\n\nIf making it along with the input recovery changes, the motivation seems a must-work to do. Since we migrate the actual usage of this argument outside of this method, then this argument should also be cleaned up as a result.\n\n\nTherefore I preferred a bit not to make it a separate commit before. It is fine for my either ways actually. If you are in favor of separate commit, i am willing to change it.", "url": "https://github.com/apache/flink/pull/11687#discussion_r407224535", "createdAt": "2020-04-12T16:55:00Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/LocalInputChannel.java", "diffHunk": "@@ -95,7 +95,7 @@ public LocalInputChannel(\n \t// ------------------------------------------------------------------------\n \n \t@Override\n-\tprotected void requestSubpartition(int subpartitionIndex) throws IOException, InterruptedException {\n+\tprotected void requestSubpartition() throws IOException, InterruptedException {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjIzMTExMg=="}, "originalCommit": {"oid": "c8c0da9e2badf68c11e8466943c7a8e14156c858"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODMzMzc3NQ==", "bodyText": "It made the final commit a bit smaller, so I think it was worth it (to speed up reviewing). As hotfix on it's own it's also a nice simplification I think.", "url": "https://github.com/apache/flink/pull/11687#discussion_r408333775", "createdAt": "2020-04-14T18:05:22Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/LocalInputChannel.java", "diffHunk": "@@ -95,7 +95,7 @@ public LocalInputChannel(\n \t// ------------------------------------------------------------------------\n \n \t@Override\n-\tprotected void requestSubpartition(int subpartitionIndex) throws IOException, InterruptedException {\n+\tprotected void requestSubpartition() throws IOException, InterruptedException {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjIzMTExMg=="}, "originalCommit": {"oid": "c8c0da9e2badf68c11e8466943c7a8e14156c858"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyMTM3NjIwOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOVQxNTozNDozMlrOGDeItQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMlQxNjo0MjoyMVrOGEW6ww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjI5MjY2MQ==", "bodyText": "notifyStateBuffersAvailable()? notifyBuffersForReadChannelStateAvailable?", "url": "https://github.com/apache/flink/pull/11687#discussion_r406292661", "createdAt": "2020-04-09T15:34:32Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "diffHunk": "@@ -311,10 +367,16 @@ public void recycle(MemorySegment segment) {\n \t\t\t\t\tExceptionUtils.rethrow(t);\n \t\t\t\t}\n \t\t\t}\n+\n+\t\t\tshouldNotifyChannelState = isWaitingForStateBuffers;\n+\t\t\tisWaitingForStateBuffers = false;\n+\n \t\t\tnumAddedBuffers = bufferQueue.addExclusiveBuffer(new NetworkBuffer(segment, this), numRequiredBuffers);\n \t\t}\n \n-\t\tif (numAddedBuffers > 0 && unannouncedCredit.getAndAdd(numAddedBuffers) == 0) {\n+\t\tif (shouldNotifyChannelState) {\n+\t\t\tnotifyReadChannelState();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c8c0da9e2badf68c11e8466943c7a8e14156c858"}, "originalPosition": 139}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIyMjk3OQ==", "bodyText": "I like notifyStateBuffersAvailable", "url": "https://github.com/apache/flink/pull/11687#discussion_r407222979", "createdAt": "2020-04-12T16:42:21Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "diffHunk": "@@ -311,10 +367,16 @@ public void recycle(MemorySegment segment) {\n \t\t\t\t\tExceptionUtils.rethrow(t);\n \t\t\t\t}\n \t\t\t}\n+\n+\t\t\tshouldNotifyChannelState = isWaitingForStateBuffers;\n+\t\t\tisWaitingForStateBuffers = false;\n+\n \t\t\tnumAddedBuffers = bufferQueue.addExclusiveBuffer(new NetworkBuffer(segment, this), numRequiredBuffers);\n \t\t}\n \n-\t\tif (numAddedBuffers > 0 && unannouncedCredit.getAndAdd(numAddedBuffers) == 0) {\n+\t\tif (shouldNotifyChannelState) {\n+\t\t\tnotifyReadChannelState();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjI5MjY2MQ=="}, "originalCommit": {"oid": "c8c0da9e2badf68c11e8466943c7a8e14156c858"}, "originalPosition": 139}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDg1MDk1OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNjowNTo0N1rOGD-oTw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMlQxNjo0MTozOVrOGEW6cA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgyNTAzOQ==", "bodyText": "stateReader.readInputData is not thread safe as it is currently and this readInputChannelState method can be executed by netty threads concurrently for different channels, right?", "url": "https://github.com/apache/flink/pull/11687#discussion_r406825039", "createdAt": "2020-04-10T16:05:47Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "diffHunk": "@@ -149,16 +154,58 @@ void assignExclusiveSegments() throws IOException {\n \t\t}\n \t}\n \n+\t/**\n+\t * Reads the channel state data executed by netty thread, so it can make use of almost all the\n+\t * existing processes to avoid bringing additional race conditions with task thread. Also it can\n+\t * avoid introducing another thread pool to handle this work to make things more complex.\n+\t */\n+\tprivate void readInputChannelState() throws IOException {\n+\t\twhile (true) {\n+\t\t\tBuffer buffer;\n+\t\t\tsynchronized (bufferQueue) {\n+\t\t\t\tbuffer = bufferQueue.takeBuffer();\n+\t\t\t\tif (buffer == null) {\n+\t\t\t\t\tif (isReleased()) {\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\n+\t\t\t\t\tbuffer = inputGate.getBufferPool().requestBuffer();\n+\t\t\t\t\tif (buffer != null) {\n+\t\t\t\t\t\tbufferQueue.addFloatingBuffer(buffer);\n+\t\t\t\t\t\tcontinue;\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tinputGate.getBufferProvider().addBufferListener(this);\n+\t\t\t\t\t\tisWaitingForStateBuffers = true;\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\tChannelStateReader.ReadResult result = inputGate.stateReader.readInputData(channelInfo, buffer);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c8c0da9e2badf68c11e8466943c7a8e14156c858"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIyMjg5Ng==", "bodyText": "Yes, readInputChannelState can be executed concurrently by multiple netty threads for different channels by design. I think in general task processing should be more faster than reading states, so one thread might not be enough for filling buffer to feed task thread well. And every channel actually has exclusive buffers which can be used in parallel to speed up recovery process.\nI overlooked the NotThreadSafe annotation in ChanelStateReaderImpl.  Since every input channel handle will actually generate a separate ChannelStateStreamReader and respective stream, I was supposed one input channel state should not be read by multiple threads, but different channel states can be read by different threads concurrent. I would further confirm with Roman whether there are other limitations.", "url": "https://github.com/apache/flink/pull/11687#discussion_r407222896", "createdAt": "2020-04-12T16:41:39Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "diffHunk": "@@ -149,16 +154,58 @@ void assignExclusiveSegments() throws IOException {\n \t\t}\n \t}\n \n+\t/**\n+\t * Reads the channel state data executed by netty thread, so it can make use of almost all the\n+\t * existing processes to avoid bringing additional race conditions with task thread. Also it can\n+\t * avoid introducing another thread pool to handle this work to make things more complex.\n+\t */\n+\tprivate void readInputChannelState() throws IOException {\n+\t\twhile (true) {\n+\t\t\tBuffer buffer;\n+\t\t\tsynchronized (bufferQueue) {\n+\t\t\t\tbuffer = bufferQueue.takeBuffer();\n+\t\t\t\tif (buffer == null) {\n+\t\t\t\t\tif (isReleased()) {\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\n+\t\t\t\t\tbuffer = inputGate.getBufferPool().requestBuffer();\n+\t\t\t\t\tif (buffer != null) {\n+\t\t\t\t\t\tbufferQueue.addFloatingBuffer(buffer);\n+\t\t\t\t\t\tcontinue;\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tinputGate.getBufferProvider().addBufferListener(this);\n+\t\t\t\t\t\tisWaitingForStateBuffers = true;\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\tChannelStateReader.ReadResult result = inputGate.stateReader.readInputData(channelInfo, buffer);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgyNTAzOQ=="}, "originalCommit": {"oid": "c8c0da9e2badf68c11e8466943c7a8e14156c858"}, "originalPosition": 50}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNTA3ODg5OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/SingleInputGate.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQxODoxMDozOVrOGFa6Fg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xN1QxNzo1NTowMFrOGHXqTA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODMzNjkxOA==", "bodyText": "Could it be that we start reading from a channel before we actually request subpartition? For example:\nOptional<BufferAndAvailability> RemoteInputChannel#getNextBuffer() throws IOException {\n\t(...)\n\tcheckState(partitionRequestClient != null, \"Queried for a buffer before requesting a queue.\"); // ??\n\nor what if partitionRequestClient is already not null, but\npartitionRequestClient.requestSubpartition(partitionId, subpartitionIndex, this, 0);\n\nhasn't completed?", "url": "https://github.com/apache/flink/pull/11687#discussion_r408336918", "createdAt": "2020-04-14T18:10:39Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/SingleInputGate.java", "diffHunk": "@@ -243,7 +249,23 @@ void requestPartitions() throws IOException, InterruptedException {\n \t\t\t\t}\n \n \t\t\t\tfor (InputChannel inputChannel : inputChannels.values()) {\n-\t\t\t\t\tinputChannel.requestSubpartition();\n+\t\t\t\t\texecutor.submit(() -> {\n+\t\t\t\t\t\ttry {\n+\t\t\t\t\t\t\tinputChannel.initializeState(reader);\n+\t\t\t\t\t\t} catch (Throwable t) {\n+\t\t\t\t\t\t\tinputChannel.setError(t);\n+\t\t\t\t\t\t}\n+\t\t\t\t\t});\n+\t\t\t\t}\n+\n+\t\t\t\tfor (InputChannel inputChannel : inputChannels.values()) {\n+\t\t\t\t\texecutor.submit(() -> {\n+\t\t\t\t\t\ttry {\n+\t\t\t\t\t\t\tinputChannel.requestSubpartition();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7b32c0f208a47925d94e290a91132ec15590236e"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODU2OTI3Mg==", "bodyText": "Yes, it has another issue here.  In order to compatible with previous process, we can divide the previous requestSubpartition into two steps. The first step is to create client which can be done during InputGate#setup as before. The second step is to actual request partition which is triggered after reading channel state as done in this PR change.\nTo do so, this check is still valid, but I guess it is still breaking the previous assumption which actually wants to guarantee the partition is really requested before calling getNextBuffer. But now the existing client does not mean the partition was requested already. So another option might remove this checkState.", "url": "https://github.com/apache/flink/pull/11687#discussion_r408569272", "createdAt": "2020-04-15T04:09:56Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/SingleInputGate.java", "diffHunk": "@@ -243,7 +249,23 @@ void requestPartitions() throws IOException, InterruptedException {\n \t\t\t\t}\n \n \t\t\t\tfor (InputChannel inputChannel : inputChannels.values()) {\n-\t\t\t\t\tinputChannel.requestSubpartition();\n+\t\t\t\t\texecutor.submit(() -> {\n+\t\t\t\t\t\ttry {\n+\t\t\t\t\t\t\tinputChannel.initializeState(reader);\n+\t\t\t\t\t\t} catch (Throwable t) {\n+\t\t\t\t\t\t\tinputChannel.setError(t);\n+\t\t\t\t\t\t}\n+\t\t\t\t\t});\n+\t\t\t\t}\n+\n+\t\t\t\tfor (InputChannel inputChannel : inputChannels.values()) {\n+\t\t\t\t\texecutor.submit(() -> {\n+\t\t\t\t\t\ttry {\n+\t\t\t\t\t\t\tinputChannel.requestSubpartition();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODMzNjkxOA=="}, "originalCommit": {"oid": "7b32c0f208a47925d94e290a91132ec15590236e"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDM4MDg3Ng==", "bodyText": "I currently remove this checkState in PR for simple. If you have other thoughts, then we can further sync afterwards.", "url": "https://github.com/apache/flink/pull/11687#discussion_r410380876", "createdAt": "2020-04-17T17:55:00Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/SingleInputGate.java", "diffHunk": "@@ -243,7 +249,23 @@ void requestPartitions() throws IOException, InterruptedException {\n \t\t\t\t}\n \n \t\t\t\tfor (InputChannel inputChannel : inputChannels.values()) {\n-\t\t\t\t\tinputChannel.requestSubpartition();\n+\t\t\t\t\texecutor.submit(() -> {\n+\t\t\t\t\t\ttry {\n+\t\t\t\t\t\t\tinputChannel.initializeState(reader);\n+\t\t\t\t\t\t} catch (Throwable t) {\n+\t\t\t\t\t\t\tinputChannel.setError(t);\n+\t\t\t\t\t\t}\n+\t\t\t\t\t});\n+\t\t\t\t}\n+\n+\t\t\t\tfor (InputChannel inputChannel : inputChannels.values()) {\n+\t\t\t\t\texecutor.submit(() -> {\n+\t\t\t\t\t\ttry {\n+\t\t\t\t\t\t\tinputChannel.requestSubpartition();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODMzNjkxOA=="}, "originalCommit": {"oid": "7b32c0f208a47925d94e290a91132ec15590236e"}, "originalPosition": 60}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNTA4OTg4OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/SingleInputGate.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQxODoxMzo0N1rOGFbBUQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNDoxMDo0M1rOGFpGZg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODMzODc2OQ==", "bodyText": "I would move the for loop inside the executor, to avoid race conditions and not depend on executor being single threaded.", "url": "https://github.com/apache/flink/pull/11687#discussion_r408338769", "createdAt": "2020-04-14T18:13:47Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/SingleInputGate.java", "diffHunk": "@@ -243,7 +249,23 @@ void requestPartitions() throws IOException, InterruptedException {\n \t\t\t\t}\n \n \t\t\t\tfor (InputChannel inputChannel : inputChannels.values()) {\n-\t\t\t\t\tinputChannel.requestSubpartition();\n+\t\t\t\t\texecutor.submit(() -> {\n+\t\t\t\t\t\ttry {\n+\t\t\t\t\t\t\tinputChannel.initializeState(reader);\n+\t\t\t\t\t\t} catch (Throwable t) {\n+\t\t\t\t\t\t\tinputChannel.setError(t);\n+\t\t\t\t\t\t}\n+\t\t\t\t\t});", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7b32c0f208a47925d94e290a91132ec15590236e"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODU2OTQ0Ng==", "bodyText": "good point", "url": "https://github.com/apache/flink/pull/11687#discussion_r408569446", "createdAt": "2020-04-15T04:10:43Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/SingleInputGate.java", "diffHunk": "@@ -243,7 +249,23 @@ void requestPartitions() throws IOException, InterruptedException {\n \t\t\t\t}\n \n \t\t\t\tfor (InputChannel inputChannel : inputChannels.values()) {\n-\t\t\t\t\tinputChannel.requestSubpartition();\n+\t\t\t\t\texecutor.submit(() -> {\n+\t\t\t\t\t\ttry {\n+\t\t\t\t\t\t\tinputChannel.initializeState(reader);\n+\t\t\t\t\t\t} catch (Throwable t) {\n+\t\t\t\t\t\t\tinputChannel.setError(t);\n+\t\t\t\t\t\t}\n+\t\t\t\t\t});", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODMzODc2OQ=="}, "originalCommit": {"oid": "7b32c0f208a47925d94e290a91132ec15590236e"}, "originalPosition": 54}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNTA5OTEzOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQxODoxNjozMlrOGFbHMA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwOToyOTo0MlrOGGctbQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODM0MDI3Mg==", "bodyText": "Is someone notifing this thread to wake up? Can not we wait on the buffer in another way?", "url": "https://github.com/apache/flink/pull/11687#discussion_r408340272", "createdAt": "2020-04-14T18:16:32Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "diffHunk": "@@ -149,6 +149,47 @@ void assignExclusiveSegments() throws IOException {\n \t\t}\n \t}\n \n+\t@Override\n+\tpublic void initializeState(ChannelStateReader reader) throws IOException, InterruptedException {\n+\t\tnumRequiredBuffers = initialCredit + inputGate.getBufferPool().getMaxNumberOfMemorySegments();\n+\t\tunannouncedCredit.set(initialCredit);\n+\n+\t\twhile (true) {\n+\t\t\tBuffer buffer;\n+\t\t\tsynchronized (bufferQueue) {\n+\t\t\t\tbuffer = bufferQueue.takeBuffer();\n+\t\t\t\tif (buffer == null) {\n+\t\t\t\t\tif (isReleased()) {\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\n+\t\t\t\t\tif (!isWaitingForFloatingBuffers) {\n+\t\t\t\t\t\tbuffer = inputGate.getBufferPool().requestBuffer();\n+\t\t\t\t\t\tif (buffer == null) {\n+\t\t\t\t\t\t\tinputGate.getBufferProvider().addBufferListener(this);\n+\t\t\t\t\t\t\tisWaitingForFloatingBuffers = true;\n+\t\t\t\t\t\t}\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\tif (buffer == null) {\n+\t\t\t\twait(10);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7b32c0f208a47925d94e290a91132ec15590236e"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODU3NDI5Mg==", "bodyText": "TBH the current wait way is also not in my favor as I mentioned as unsatisfied points, because how long time to wait might be an issue.\nI also considered other ways, but the key problem is that we can not exit this runnable to let the thread execute other runables in advance, so it seems somehow as blocking way here. In contrast, the previous floating request from netty thread was non-blocking way, so we do not need the mechanism of notifyAll  inside RemoteInputChannel#recycle and RemoteInputChannel#notifyBufferAvailable.\nMaybe it is possible to add notifyAll in above two methods for compatible with the new process. WDYT?", "url": "https://github.com/apache/flink/pull/11687#discussion_r408574292", "createdAt": "2020-04-15T04:30:26Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "diffHunk": "@@ -149,6 +149,47 @@ void assignExclusiveSegments() throws IOException {\n \t\t}\n \t}\n \n+\t@Override\n+\tpublic void initializeState(ChannelStateReader reader) throws IOException, InterruptedException {\n+\t\tnumRequiredBuffers = initialCredit + inputGate.getBufferPool().getMaxNumberOfMemorySegments();\n+\t\tunannouncedCredit.set(initialCredit);\n+\n+\t\twhile (true) {\n+\t\t\tBuffer buffer;\n+\t\t\tsynchronized (bufferQueue) {\n+\t\t\t\tbuffer = bufferQueue.takeBuffer();\n+\t\t\t\tif (buffer == null) {\n+\t\t\t\t\tif (isReleased()) {\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\n+\t\t\t\t\tif (!isWaitingForFloatingBuffers) {\n+\t\t\t\t\t\tbuffer = inputGate.getBufferPool().requestBuffer();\n+\t\t\t\t\t\tif (buffer == null) {\n+\t\t\t\t\t\t\tinputGate.getBufferProvider().addBufferListener(this);\n+\t\t\t\t\t\t\tisWaitingForFloatingBuffers = true;\n+\t\t\t\t\t\t}\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\tif (buffer == null) {\n+\t\t\t\twait(10);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODM0MDI3Mg=="}, "originalCommit": {"oid": "7b32c0f208a47925d94e290a91132ec15590236e"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODcyODkzMQ==", "bodyText": "Ok I see. We can not block the shared executor for unspecified long time. This method would have to be rewritten in a such way, that once buffers are not available, it exits, and re-enqueuing action is done once more buffers are ready.\nIf we spawned our custom thread for unspilling, we could block it however we want, but in that case we would also need a mechanism to wake it up once more buffers are ready, instead of sleeping for fixed amount of time.\nedit: I guess we would have exactly the same issues with a separate unspilling component like SpilledInputChannel or SpilledInputGate?", "url": "https://github.com/apache/flink/pull/11687#discussion_r408728931", "createdAt": "2020-04-15T10:07:13Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "diffHunk": "@@ -149,6 +149,47 @@ void assignExclusiveSegments() throws IOException {\n \t\t}\n \t}\n \n+\t@Override\n+\tpublic void initializeState(ChannelStateReader reader) throws IOException, InterruptedException {\n+\t\tnumRequiredBuffers = initialCredit + inputGate.getBufferPool().getMaxNumberOfMemorySegments();\n+\t\tunannouncedCredit.set(initialCredit);\n+\n+\t\twhile (true) {\n+\t\t\tBuffer buffer;\n+\t\t\tsynchronized (bufferQueue) {\n+\t\t\t\tbuffer = bufferQueue.takeBuffer();\n+\t\t\t\tif (buffer == null) {\n+\t\t\t\t\tif (isReleased()) {\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\n+\t\t\t\t\tif (!isWaitingForFloatingBuffers) {\n+\t\t\t\t\t\tbuffer = inputGate.getBufferPool().requestBuffer();\n+\t\t\t\t\t\tif (buffer == null) {\n+\t\t\t\t\t\t\tinputGate.getBufferProvider().addBufferListener(this);\n+\t\t\t\t\t\t\tisWaitingForFloatingBuffers = true;\n+\t\t\t\t\t\t}\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\tif (buffer == null) {\n+\t\t\t\twait(10);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODM0MDI3Mg=="}, "originalCommit": {"oid": "7b32c0f208a47925d94e290a91132ec15590236e"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI4MzUyMA==", "bodyText": "Yes, we have the same issue in another option of SpilledInputChannel/SpilledInputGate.\nIn conclusion, there may be several solutions:\n\n\nwait() if unavailable buffers: block the unspilling thread always and it fits our current requirements. We should not exit current channel to switch another channel temporarily, which might bring random IO. And it requires the wakeup mechanism when buffer available again.\n\n\nwait(timeout) if unavailable buffers: more or less the same with above wait(), but wakeup mechanism is not a mandatory, can be regarded as  somehow improvement to wakeup eerily.\n\n\nunblocking way: terminate the current channel and unspill another channel with available buffers. It would bring random IO as mentioned above and not the current suggestion.\n\n\nBased on the current situation with custom thread for unspilling, and allow only one thread to unspill channel one by one to avoid random IO, so I choose the unblocking option 1 or 2.\nRegarding the option 2, wakeup is not necessary, then we do not need to touch the previous processes RemoteInputChannel#recycle and RemoteInputChannel#notifyBufferAvailable. If we want to add the wakeup mechanism, option 1 also makes sense.", "url": "https://github.com/apache/flink/pull/11687#discussion_r409283520", "createdAt": "2020-04-16T05:03:58Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "diffHunk": "@@ -149,6 +149,47 @@ void assignExclusiveSegments() throws IOException {\n \t\t}\n \t}\n \n+\t@Override\n+\tpublic void initializeState(ChannelStateReader reader) throws IOException, InterruptedException {\n+\t\tnumRequiredBuffers = initialCredit + inputGate.getBufferPool().getMaxNumberOfMemorySegments();\n+\t\tunannouncedCredit.set(initialCredit);\n+\n+\t\twhile (true) {\n+\t\t\tBuffer buffer;\n+\t\t\tsynchronized (bufferQueue) {\n+\t\t\t\tbuffer = bufferQueue.takeBuffer();\n+\t\t\t\tif (buffer == null) {\n+\t\t\t\t\tif (isReleased()) {\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\n+\t\t\t\t\tif (!isWaitingForFloatingBuffers) {\n+\t\t\t\t\t\tbuffer = inputGate.getBufferPool().requestBuffer();\n+\t\t\t\t\t\tif (buffer == null) {\n+\t\t\t\t\t\t\tinputGate.getBufferProvider().addBufferListener(this);\n+\t\t\t\t\t\t\tisWaitingForFloatingBuffers = true;\n+\t\t\t\t\t\t}\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\tif (buffer == null) {\n+\t\t\t\twait(10);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODM0MDI3Mg=="}, "originalCommit": {"oid": "7b32c0f208a47925d94e290a91132ec15590236e"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTQxNTAyMQ==", "bodyText": "Oh, I missed that we are already using a separate thread pool. In that case we don't need the not blocking option now.\nIt would be still good to get rid of timed wait in favour of some notifications though.", "url": "https://github.com/apache/flink/pull/11687#discussion_r409415021", "createdAt": "2020-04-16T09:29:42Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "diffHunk": "@@ -149,6 +149,47 @@ void assignExclusiveSegments() throws IOException {\n \t\t}\n \t}\n \n+\t@Override\n+\tpublic void initializeState(ChannelStateReader reader) throws IOException, InterruptedException {\n+\t\tnumRequiredBuffers = initialCredit + inputGate.getBufferPool().getMaxNumberOfMemorySegments();\n+\t\tunannouncedCredit.set(initialCredit);\n+\n+\t\twhile (true) {\n+\t\t\tBuffer buffer;\n+\t\t\tsynchronized (bufferQueue) {\n+\t\t\t\tbuffer = bufferQueue.takeBuffer();\n+\t\t\t\tif (buffer == null) {\n+\t\t\t\t\tif (isReleased()) {\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\n+\t\t\t\t\tif (!isWaitingForFloatingBuffers) {\n+\t\t\t\t\t\tbuffer = inputGate.getBufferPool().requestBuffer();\n+\t\t\t\t\t\tif (buffer == null) {\n+\t\t\t\t\t\t\tinputGate.getBufferProvider().addBufferListener(this);\n+\t\t\t\t\t\t\tisWaitingForFloatingBuffers = true;\n+\t\t\t\t\t\t}\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\tif (buffer == null) {\n+\t\t\t\twait(10);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODM0MDI3Mg=="}, "originalCommit": {"oid": "7b32c0f208a47925d94e290a91132ec15590236e"}, "originalPosition": 45}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNTExMDc2OnYy", "diffSide": "LEFT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/SingleInputGate.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQxODoxOTo0M1rOGFbOiA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNDozNTo1NVrOGFpeUw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODM0MjE1Mg==", "bodyText": "who is now calling this method in batch tasks?", "url": "https://github.com/apache/flink/pull/11687#discussion_r408342152", "createdAt": "2020-04-14T18:19:43Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/SingleInputGate.java", "diffHunk": "@@ -213,19 +215,23 @@ public SingleInputGate(\n \t}\n \n \t@Override\n-\tpublic void setup() throws IOException, InterruptedException {\n+\tpublic void setup() throws IOException {\n \t\tcheckState(this.bufferPool == null, \"Bug in input gate setup logic: Already registered buffer pool.\");\n \t\t// assign exclusive buffers to input channels directly and use the rest for floating buffers\n \t\tassignExclusiveSegments();\n \n \t\tBufferPool bufferPool = bufferPoolFactory.get();\n \t\tsetBufferPool(bufferPool);\n+\t}\n+\n \n-\t\trequestPartitions();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7b32c0f208a47925d94e290a91132ec15590236e"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODU3NTU3MQ==", "bodyText": "No matter streaming or batch, this method is always called by task thread when the SingleInputGate is created to setup. The only difference between streaming and batch is for RPC call updateInputChannel which is only valid in batch. But for batch we do not support unaligned cp, so the new transformed remote channel from unknown can request partition directly.", "url": "https://github.com/apache/flink/pull/11687#discussion_r408575571", "createdAt": "2020-04-15T04:35:55Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/SingleInputGate.java", "diffHunk": "@@ -213,19 +215,23 @@ public SingleInputGate(\n \t}\n \n \t@Override\n-\tpublic void setup() throws IOException, InterruptedException {\n+\tpublic void setup() throws IOException {\n \t\tcheckState(this.bufferPool == null, \"Bug in input gate setup logic: Already registered buffer pool.\");\n \t\t// assign exclusive buffers to input channels directly and use the rest for floating buffers\n \t\tassignExclusiveSegments();\n \n \t\tBufferPool bufferPool = bufferPoolFactory.get();\n \t\tsetBufferPool(bufferPool);\n+\t}\n+\n \n-\t\trequestPartitions();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODM0MjE1Mg=="}, "originalCommit": {"oid": "7b32c0f208a47925d94e290a91132ec15590236e"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0MTg2MDM1OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamTask.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwOTowOTo1OVrOGGb7Uw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwOTowOTo1OVrOGGb7Uw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTQwMjE5NQ==", "bodyText": "rename channelStateUnspillingExecutor?", "url": "https://github.com/apache/flink/pull/11687#discussion_r409402195", "createdAt": "2020-04-16T09:09:59Z", "author": {"login": "pnowojski"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamTask.java", "diffHunk": "@@ -289,6 +292,8 @@ protected StreamTask(\n \t\t} else {\n \t\t\tthis.timerService = timerService;\n \t\t}\n+\n+\t\tthis.ioExecutor = Executors.newSingleThreadExecutor(new ExecutorThreadFactory(\"state-io\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7b32c0f208a47925d94e290a91132ec15590236e"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0MTkwNDM5OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/SingleInputGate.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwOToyMTowOFrOGGcXXg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xN1QxNzo1Mzo0NlrOGHXn-w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTQwOTM3NA==", "bodyText": "could we pass the state recovery parameters here? And have a single step setup method instead of introducing 2nd initialisation step (setup and initializeState).", "url": "https://github.com/apache/flink/pull/11687#discussion_r409409374", "createdAt": "2020-04-16T09:21:08Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/SingleInputGate.java", "diffHunk": "@@ -213,19 +215,23 @@ public SingleInputGate(\n \t}\n \n \t@Override\n-\tpublic void setup() throws IOException, InterruptedException {\n+\tpublic void setup() throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7b32c0f208a47925d94e290a91132ec15590236e"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTk5NTEyNQ==", "bodyText": "I agree that it has benefits to reduce steps for managing the lifecycle of input gate. But I thought of another potential concern if integrating it within setup.\nThe previous assumption was that the output recovery should execute earlier than the input recovery in order to occupy more floating buffers from global, to get the benefit to speedup recovery process. Now the output recovery is executed by task thread during StreamTask#beforeInvoke. If we integrate the input recovery within setup process, then it would perform before output recovery to occupy more floating buffers in limited buffers environment.\nI also considered integrating the output recovery within ResultPartition#setup, but the output recovery is executed by task thread then it would block the following operations, so I wonder it might also bring potential risks to do so.", "url": "https://github.com/apache/flink/pull/11687#discussion_r409995125", "createdAt": "2020-04-17T05:07:37Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/SingleInputGate.java", "diffHunk": "@@ -213,19 +215,23 @@ public SingleInputGate(\n \t}\n \n \t@Override\n-\tpublic void setup() throws IOException, InterruptedException {\n+\tpublic void setup() throws IOException {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTQwOTM3NA=="}, "originalCommit": {"oid": "7b32c0f208a47925d94e290a91132ec15590236e"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDIyNjI1MQ==", "bodyText": "The previous assumption was that the output recovery should execute earlier than the input recovery in order to occupy more floating buffers from global, to get the benefit to speedup recovery process. Now the output recovery is executed by task thread during StreamTask#beforeInvoke. If we integrate the input recovery within setup process, then it would perform before output recovery to occupy more floating buffers in limited buffers environment.\n\nOk, I haven't considered that. I guess it's best to keep it as it is?", "url": "https://github.com/apache/flink/pull/11687#discussion_r410226251", "createdAt": "2020-04-17T13:35:20Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/SingleInputGate.java", "diffHunk": "@@ -213,19 +215,23 @@ public SingleInputGate(\n \t}\n \n \t@Override\n-\tpublic void setup() throws IOException, InterruptedException {\n+\tpublic void setup() throws IOException {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTQwOTM3NA=="}, "originalCommit": {"oid": "7b32c0f208a47925d94e290a91132ec15590236e"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDM4MDI4Mw==", "bodyText": "Yes, I guess so.\nI found another benefit to execute the input state recovery inside StreamTask instead of Task stack(setup integration). The new dedicated executor for unspilling channel state is only meaningful for the unaligned checkpoint mode. So I tried not to create this executor for normal checkpoints, also for batch jobs to reduce total threads in TaskManager. This improvement can only be done inside StreamTask because it can judge the checkpoint mode via StreamConfig. And task class can not get this option because of runtime module can not depend on streaming module.", "url": "https://github.com/apache/flink/pull/11687#discussion_r410380283", "createdAt": "2020-04-17T17:53:46Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/SingleInputGate.java", "diffHunk": "@@ -213,19 +215,23 @@ public SingleInputGate(\n \t}\n \n \t@Override\n-\tpublic void setup() throws IOException, InterruptedException {\n+\tpublic void setup() throws IOException {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTQwOTM3NA=="}, "originalCommit": {"oid": "7b32c0f208a47925d94e290a91132ec15590236e"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0MTkzMzc5OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwOToyODoyMlrOGGcp4Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwOToyODoyMlrOGGcp4Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTQxNDExMw==", "bodyText": "Does it make sense to rename initializeState to readRecoveredState? or processRecoveredState?", "url": "https://github.com/apache/flink/pull/11687#discussion_r409414113", "createdAt": "2020-04-16T09:28:22Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "diffHunk": "@@ -149,6 +149,47 @@ void assignExclusiveSegments() throws IOException {\n \t\t}\n \t}\n \n+\t@Override\n+\tpublic void initializeState(ChannelStateReader reader) throws IOException, InterruptedException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7b32c0f208a47925d94e290a91132ec15590236e"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU1NTI1NzQ3OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/tasks/StreamTaskTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQxMTo1MjozOVrOGIQuYg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQxNTowMzoyNlrOGIZCUA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTMxNTgxMA==", "bodyText": "Do we want this change here? I would like to avoid introducing many different places that are manually disabling/enabling unaligned checkpoints. Maybe this should be handled generically as part of this ticket https://issues.apache.org/jira/browse/FLINK-17258 ?", "url": "https://github.com/apache/flink/pull/11687#discussion_r411315810", "createdAt": "2020-04-20T11:52:39Z", "author": {"login": "pnowojski"}, "path": "flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/tasks/StreamTaskTest.java", "diffHunk": "@@ -914,7 +914,9 @@ public void testInitializeResultPartitionState() throws Exception {\n \n \t\tMockEnvironment mockEnvironment = new MockEnvironmentBuilder().build();\n \t\tmockEnvironment.addOutputs(Arrays.asList(partitions));\n-\t\tStreamTask task = new MockStreamTaskBuilder(mockEnvironment).build();\n+\t\tStreamConfig config = new StreamConfig(new Configuration());\n+\t\tconfig.setUnalignedCheckpointsEnabled(true);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "34a60cefb9c81c3220030ddba2ea99722ed6a622"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTQ1MTk4NA==", "bodyText": "The current default value for ExecutionCheckpointingOptions#ENABLE_UNALIGNED is still false. But in StreamTask#beforeInvoke the channel state recovery is only called when enabling unaligned mode. So ATM we still need this explicit setting for making the test through.", "url": "https://github.com/apache/flink/pull/11687#discussion_r411451984", "createdAt": "2020-04-20T15:03:26Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/tasks/StreamTaskTest.java", "diffHunk": "@@ -914,7 +914,9 @@ public void testInitializeResultPartitionState() throws Exception {\n \n \t\tMockEnvironment mockEnvironment = new MockEnvironmentBuilder().build();\n \t\tmockEnvironment.addOutputs(Arrays.asList(partitions));\n-\t\tStreamTask task = new MockStreamTaskBuilder(mockEnvironment).build();\n+\t\tStreamConfig config = new StreamConfig(new Configuration());\n+\t\tconfig.setUnalignedCheckpointsEnabled(true);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTMxNTgxMA=="}, "originalCommit": {"oid": "34a60cefb9c81c3220030ddba2ea99722ed6a622"}, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU1NTI2MjQwOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/InputGate.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQxMTo1Mzo1MlrOGIQxOQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQxNTo1MDoyN1rOGIbUeA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTMxNjUzNw==", "bodyText": "readRecoveredStateAndRequestPartitions?", "url": "https://github.com/apache/flink/pull/11687#discussion_r411316537", "createdAt": "2020-04-20T11:53:52Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/InputGate.java", "diffHunk": "@@ -131,7 +135,12 @@\n \t/**\n \t * Setup gate, potentially heavy-weight, blocking operation comparing to just creation.\n \t */\n-\tpublic abstract void setup() throws IOException, InterruptedException;\n+\tpublic abstract void setup() throws IOException;\n+\n+\tpublic abstract void initializeStateAndRequestPartitions(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "054de880d6814fd93c782d199a87490d1440a573"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTQ2NzA5OA==", "bodyText": "initializeState is for alignment with the other side ResultPartition#initializeState introduced before. I am both fine with either naming.", "url": "https://github.com/apache/flink/pull/11687#discussion_r411467098", "createdAt": "2020-04-20T15:22:22Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/InputGate.java", "diffHunk": "@@ -131,7 +135,12 @@\n \t/**\n \t * Setup gate, potentially heavy-weight, blocking operation comparing to just creation.\n \t */\n-\tpublic abstract void setup() throws IOException, InterruptedException;\n+\tpublic abstract void setup() throws IOException;\n+\n+\tpublic abstract void initializeStateAndRequestPartitions(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTMxNjUzNw=="}, "originalCommit": {"oid": "054de880d6814fd93c782d199a87490d1440a573"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTQ4MTQzNw==", "bodyText": "ok, we can keep it consistent (we could also rename it in the partitions ;) ). initializeState sounds to me more  like we are trying to initialize a state and keep using it later on (like in operators). readState better carries out the intention that the state is only used once.", "url": "https://github.com/apache/flink/pull/11687#discussion_r411481437", "createdAt": "2020-04-20T15:40:12Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/InputGate.java", "diffHunk": "@@ -131,7 +135,12 @@\n \t/**\n \t * Setup gate, potentially heavy-weight, blocking operation comparing to just creation.\n \t */\n-\tpublic abstract void setup() throws IOException, InterruptedException;\n+\tpublic abstract void setup() throws IOException;\n+\n+\tpublic abstract void initializeStateAndRequestPartitions(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTMxNjUzNw=="}, "originalCommit": {"oid": "054de880d6814fd93c782d199a87490d1440a573"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTQ4OTQwMA==", "bodyText": "Agree, I already renamed it on input side, and I can also refactor the partition side in a separate hotfix commit.", "url": "https://github.com/apache/flink/pull/11687#discussion_r411489400", "createdAt": "2020-04-20T15:50:27Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/InputGate.java", "diffHunk": "@@ -131,7 +135,12 @@\n \t/**\n \t * Setup gate, potentially heavy-weight, blocking operation comparing to just creation.\n \t */\n-\tpublic abstract void setup() throws IOException, InterruptedException;\n+\tpublic abstract void setup() throws IOException;\n+\n+\tpublic abstract void initializeStateAndRequestPartitions(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTMxNjUzNw=="}, "originalCommit": {"oid": "054de880d6814fd93c782d199a87490d1440a573"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU1NTQ1MzQ1OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQxMjo0MjoxN1rOGIShig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQxMjo0MjoxN1rOGIShig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTM0NTI5MA==", "bodyText": "initializeCreditsForRecoveringState?", "url": "https://github.com/apache/flink/pull/11687#discussion_r411345290", "createdAt": "2020-04-20T12:42:17Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "diffHunk": "@@ -162,6 +163,95 @@ void assignExclusiveSegments() throws IOException {\n \t// Consume\n \t// ------------------------------------------------------------------------\n \n+\tvoid readRecoveredState(ChannelStateReader reader) throws IOException, InterruptedException {\n+\t\tbeforeReadRecoveredState();\n+\n+\t\twhile (true) {\n+\t\t\tBuffer buffer;\n+\t\t\tsynchronized (bufferQueue) {\n+\t\t\t\tbuffer = bufferQueue.takeBuffer();\n+\t\t\t\tif (buffer == null) {\n+\t\t\t\t\tif (isReleased()) {\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t\tif (!isWaitingForFloatingBuffers) {\n+\t\t\t\t\t\tbuffer = inputGate.getBufferPool().requestBuffer();\n+\t\t\t\t\t\tif (buffer == null) {\n+\t\t\t\t\t\t\tinputGate.getBufferProvider().addBufferListener(this);\n+\t\t\t\t\t\t\tisWaitingForFloatingBuffers = true;\n+\t\t\t\t\t\t}\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t\tif (buffer == null) {\n+\t\t\t\t\tbufferQueue.wait();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\tChannelStateReader.ReadResult result = internalReaderRecoveredState(reader, buffer);\n+\t\t\tif (result == ChannelStateReader.ReadResult.NO_MORE_DATA) {\n+\t\t\t\treturn;\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate void beforeReadRecoveredState() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "054de880d6814fd93c782d199a87490d1440a573"}, "originalPosition": 44}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU1NTQ4NDU5OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/SingleInputGate.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQxMjo0OTo0M1rOGISz5A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQxNjozODoxM1rOGIdijA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTM0OTk4OA==", "bodyText": "This doesn't look right - boolean hasStates and @Nullable executor - it looks like this check should be on a different layer. As this method looks like it's called only in one place, shouldn't it be just inlined?", "url": "https://github.com/apache/flink/pull/11687#discussion_r411349988", "createdAt": "2020-04-20T12:49:43Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/SingleInputGate.java", "diffHunk": "@@ -222,19 +225,65 @@ public SingleInputGate(\n \t}\n \n \t@Override\n-\tpublic void setup() throws IOException, InterruptedException {\n+\tpublic void setup() throws IOException {\n \t\tcheckState(this.bufferPool == null, \"Bug in input gate setup logic: Already registered buffer pool.\");\n \t\t// assign exclusive buffers to input channels directly and use the rest for floating buffers\n \t\tassignExclusiveSegments();\n \n \t\tBufferPool bufferPool = bufferPoolFactory.get();\n \t\tsetBufferPool(bufferPool);\n+\t}\n \n-\t\trequestPartitions();\n+\t@Override\n+\tpublic void initializeStateAndRequestPartitions(\n+\t\t\tboolean hasStates,\n+\t\t\t@Nullable ExecutorService executor,\n+\t\t\tChannelStateReader reader) throws Exception {\n+\n+\t\tif (hasStates) {\n+\t\t\tcheckNotNull(executor);\n+\t\t\treadRecoveredStateBeforeRequestPartition(executor, reader);\n+\t\t} else {\n+\t\t\trequestPartitions();\n+\t\t}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "054de880d6814fd93c782d199a87490d1440a573"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTQ2NTU4OA==", "bodyText": "It actually inlines two requirements on purpose. TBH I was also a bit torn to do so before.\nMy previous thought was trying not to affect the normal process if not enabling unaligned mode, that means requesting partitions directly, otherwise short lifecycle jobs might be sensitive for the potential performance regression with unnecessary state recovery process. And passing nullable executor can also simplify the unit tests without unaligned mode not to maintain the useless executor.\nAnother solution is to separate it into two methods. One is for #requestPartitions and the other is for #readRecoveredState. But that means we also need to define another explicit interface method InputGate#requestPartitions, which would bring more tiny steps in the lifecycle of InputGate, like setup -> readRecoveredState -> requestPartitions. So I chose the inlined way to reduce this overhead.", "url": "https://github.com/apache/flink/pull/11687#discussion_r411465588", "createdAt": "2020-04-20T15:20:25Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/SingleInputGate.java", "diffHunk": "@@ -222,19 +225,65 @@ public SingleInputGate(\n \t}\n \n \t@Override\n-\tpublic void setup() throws IOException, InterruptedException {\n+\tpublic void setup() throws IOException {\n \t\tcheckState(this.bufferPool == null, \"Bug in input gate setup logic: Already registered buffer pool.\");\n \t\t// assign exclusive buffers to input channels directly and use the rest for floating buffers\n \t\tassignExclusiveSegments();\n \n \t\tBufferPool bufferPool = bufferPoolFactory.get();\n \t\tsetBufferPool(bufferPool);\n+\t}\n \n-\t\trequestPartitions();\n+\t@Override\n+\tpublic void initializeStateAndRequestPartitions(\n+\t\t\tboolean hasStates,\n+\t\t\t@Nullable ExecutorService executor,\n+\t\t\tChannelStateReader reader) throws Exception {\n+\n+\t\tif (hasStates) {\n+\t\t\tcheckNotNull(executor);\n+\t\t\treadRecoveredStateBeforeRequestPartition(executor, reader);\n+\t\t} else {\n+\t\t\trequestPartitions();\n+\t\t}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTM0OTk4OA=="}, "originalCommit": {"oid": "054de880d6814fd93c782d199a87490d1440a573"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTQ4ODY3Ng==", "bodyText": "Ok, I see. This is messy :/ It comes down to this issue that input gates are initialised in the Task and state is handled in StreamTask :/ It should have been handled together upon the construction of SingleInputGate class.\nI think I would be +0.1 for dropping initializeStateAndRequestPartitions and both readRecoveredStateBeforeRequestPartition and requestPartitions to the interfaces, but if you think it's better to have a single method, I'm fine with that.", "url": "https://github.com/apache/flink/pull/11687#discussion_r411488676", "createdAt": "2020-04-20T15:49:33Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/SingleInputGate.java", "diffHunk": "@@ -222,19 +225,65 @@ public SingleInputGate(\n \t}\n \n \t@Override\n-\tpublic void setup() throws IOException, InterruptedException {\n+\tpublic void setup() throws IOException {\n \t\tcheckState(this.bufferPool == null, \"Bug in input gate setup logic: Already registered buffer pool.\");\n \t\t// assign exclusive buffers to input channels directly and use the rest for floating buffers\n \t\tassignExclusiveSegments();\n \n \t\tBufferPool bufferPool = bufferPoolFactory.get();\n \t\tsetBufferPool(bufferPool);\n+\t}\n \n-\t\trequestPartitions();\n+\t@Override\n+\tpublic void initializeStateAndRequestPartitions(\n+\t\t\tboolean hasStates,\n+\t\t\t@Nullable ExecutorService executor,\n+\t\t\tChannelStateReader reader) throws Exception {\n+\n+\t\tif (hasStates) {\n+\t\t\tcheckNotNull(executor);\n+\t\t\treadRecoveredStateBeforeRequestPartition(executor, reader);\n+\t\t} else {\n+\t\t\trequestPartitions();\n+\t\t}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTM0OTk4OA=="}, "originalCommit": {"oid": "054de880d6814fd93c782d199a87490d1440a573"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTUyNTc3Mg==", "bodyText": "I am planning to separate this inlined method for your 0.1 favor. :)", "url": "https://github.com/apache/flink/pull/11687#discussion_r411525772", "createdAt": "2020-04-20T16:38:13Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/SingleInputGate.java", "diffHunk": "@@ -222,19 +225,65 @@ public SingleInputGate(\n \t}\n \n \t@Override\n-\tpublic void setup() throws IOException, InterruptedException {\n+\tpublic void setup() throws IOException {\n \t\tcheckState(this.bufferPool == null, \"Bug in input gate setup logic: Already registered buffer pool.\");\n \t\t// assign exclusive buffers to input channels directly and use the rest for floating buffers\n \t\tassignExclusiveSegments();\n \n \t\tBufferPool bufferPool = bufferPoolFactory.get();\n \t\tsetBufferPool(bufferPool);\n+\t}\n \n-\t\trequestPartitions();\n+\t@Override\n+\tpublic void initializeStateAndRequestPartitions(\n+\t\t\tboolean hasStates,\n+\t\t\t@Nullable ExecutorService executor,\n+\t\t\tChannelStateReader reader) throws Exception {\n+\n+\t\tif (hasStates) {\n+\t\t\tcheckNotNull(executor);\n+\t\t\treadRecoveredStateBeforeRequestPartition(executor, reader);\n+\t\t} else {\n+\t\t\trequestPartitions();\n+\t\t}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTM0OTk4OA=="}, "originalCommit": {"oid": "054de880d6814fd93c782d199a87490d1440a573"}, "originalPosition": 50}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU1NTQ5ODE1OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamTask.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQxMjo1Mjo1NFrOGIS79w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQxNTowODoyOFrOGIZSJg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTM1MjA1NQ==", "bodyText": "Add a TODO that it should be replaced by a global TaskManager ioExecutor?", "url": "https://github.com/apache/flink/pull/11687#discussion_r411352055", "createdAt": "2020-04-20T12:52:54Z", "author": {"login": "pnowojski"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamTask.java", "diffHunk": "@@ -204,6 +205,9 @@\n \n \tprotected final MailboxProcessor mailboxProcessor;\n \n+\t@Nullable\n+\tprivate final ExecutorService channelStateUnspillingExecutor;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "054de880d6814fd93c782d199a87490d1440a573"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTQ1NjAzOA==", "bodyText": "Maybe, not quite sure whether the existing ioExecutor in TaskManagerService can be used for unspill  state purpose. Anyway, we can always introduce a dedicated executor on TaskManager level future.", "url": "https://github.com/apache/flink/pull/11687#discussion_r411456038", "createdAt": "2020-04-20T15:08:28Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamTask.java", "diffHunk": "@@ -204,6 +205,9 @@\n \n \tprotected final MailboxProcessor mailboxProcessor;\n \n+\t@Nullable\n+\tprivate final ExecutorService channelStateUnspillingExecutor;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTM1MjA1NQ=="}, "originalCommit": {"oid": "054de880d6814fd93c782d199a87490d1440a573"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU2NzAwMjg3OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/SingleInputGate.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQxNTowNjo1NVrOGJ7hMw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQxNTowNjo1NVrOGJ7hMw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzA2NTUyMw==", "bodyText": "I think this block of code is forgetting about getUnconsumedBuffer() from the LocalInputChannel that was spilled as part of the input data.", "url": "https://github.com/apache/flink/pull/11687#discussion_r413065523", "createdAt": "2020-04-22T15:06:55Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/SingleInputGate.java", "diffHunk": "@@ -222,19 +226,54 @@ public SingleInputGate(\n \t}\n \n \t@Override\n-\tpublic void setup() throws IOException, InterruptedException {\n+\tpublic void setup() throws IOException {\n \t\tcheckState(this.bufferPool == null, \"Bug in input gate setup logic: Already registered buffer pool.\");\n \t\t// assign exclusive buffers to input channels directly and use the rest for floating buffers\n \t\tassignExclusiveSegments();\n \n \t\tBufferPool bufferPool = bufferPoolFactory.get();\n \t\tsetBufferPool(bufferPool);\n+\t}\n+\n+\t@Override\n+\tpublic void readRecoveredState(ExecutorService executor, ChannelStateReader reader) throws IOException {\n+\t\tinternalRequestPartitions(() -> executor.submit(() -> {\n+\n+\t\t\tfor (InputChannel inputChannel : inputChannels.values()) {\n+\t\t\t\tif (inputChannel instanceof RemoteInputChannel) {\n+\t\t\t\t\ttry {\n+\t\t\t\t\t\t((RemoteInputChannel) inputChannel).readRecoveredState(reader);\n+\t\t\t\t\t} catch (Throwable t) {\n+\t\t\t\t\t\tinputChannel.setError(t);\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f7399680818f5d29e917e17720e00900822a43d"}, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU3Nzg3OTM4OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/reader/AbstractRecordReader.java", "isResolved": true, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQxNjowMjo0NlrOGLenqA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wOFQwODo0Nzo1NlrOGSeYUQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDY4OTE5Mg==", "bodyText": "Why do we have to requestPartitions() once per every record?", "url": "https://github.com/apache/flink/pull/11687#discussion_r414689192", "createdAt": "2020-04-24T16:02:46Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/reader/AbstractRecordReader.java", "diffHunk": "@@ -63,6 +63,8 @@ protected AbstractRecordReader(InputGate inputGate, String[] tmpDirectories) {\n \t}\n \n \tprotected boolean getNextRecord(T target) throws IOException, InterruptedException {\n+\t\tinputGate.requestPartitions();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6ca8ec305a96d208919ab49244448de89bc7b679"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTIwNzY0Mw==", "bodyText": "This is the only concentrated place work for all the batch cases. Otherwise we have to add this call for all the specific invokable instances derived from BatchTask class, even we also need to consider many other cases which bypassed the invokable class and use the wrapped AbstractRecordReader directly in unit tests, etc.\nI remembered in the early version, the requestPartitions was also placed inside SingleInputGate#getNext  method. Because of the mailbox requirement, it was migrated into #setup afterwards.\nConsidering the batch case unrelated to mailbox path, so i think it might be accepted to redo it still in the original place only work for batch cases.", "url": "https://github.com/apache/flink/pull/11687#discussion_r415207643", "createdAt": "2020-04-26T04:00:10Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/reader/AbstractRecordReader.java", "diffHunk": "@@ -63,6 +63,8 @@ protected AbstractRecordReader(InputGate inputGate, String[] tmpDirectories) {\n \t}\n \n \tprotected boolean getNextRecord(T target) throws IOException, InterruptedException {\n+\t\tinputGate.requestPartitions();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDY4OTE5Mg=="}, "originalCommit": {"oid": "6ca8ec305a96d208919ab49244448de89bc7b679"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTM0NzczNQ==", "bodyText": "I remembered in the early version, the requestPartitions was also placed inside SingleInputGate#getNext method. Because of the mailbox requirement, it was migrated into #setup afterwards.\n\nBut that wasn't a good design, and it's still not now :(", "url": "https://github.com/apache/flink/pull/11687#discussion_r419347735", "createdAt": "2020-05-04T10:38:46Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/reader/AbstractRecordReader.java", "diffHunk": "@@ -63,6 +63,8 @@ protected AbstractRecordReader(InputGate inputGate, String[] tmpDirectories) {\n \t}\n \n \tprotected boolean getNextRecord(T target) throws IOException, InterruptedException {\n+\t\tinputGate.requestPartitions();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDY4OTE5Mg=="}, "originalCommit": {"oid": "6ca8ec305a96d208919ab49244448de89bc7b679"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTQ4NDQzMQ==", "bodyText": "Can not we keep the previous setup logic if unaligned checkpoints are disabled/not configured (that would include batch?)? And add a checkState somewhere, that unaligned checkpoints can not be used without StreamTask/in streaming or something like that?", "url": "https://github.com/apache/flink/pull/11687#discussion_r419484431", "createdAt": "2020-05-04T14:36:01Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/reader/AbstractRecordReader.java", "diffHunk": "@@ -63,6 +63,8 @@ protected AbstractRecordReader(InputGate inputGate, String[] tmpDirectories) {\n \t}\n \n \tprotected boolean getNextRecord(T target) throws IOException, InterruptedException {\n+\t\tinputGate.requestPartitions();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDY4OTE5Mg=="}, "originalCommit": {"oid": "6ca8ec305a96d208919ab49244448de89bc7b679"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTUyMjk3NQ==", "bodyText": "agree, it is not a perfect way, but the feasible simple way ATM to not maintain many different code paths, also not sensitive for batch code path.", "url": "https://github.com/apache/flink/pull/11687#discussion_r419522975", "createdAt": "2020-05-04T15:29:13Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/reader/AbstractRecordReader.java", "diffHunk": "@@ -63,6 +63,8 @@ protected AbstractRecordReader(InputGate inputGate, String[] tmpDirectories) {\n \t}\n \n \tprotected boolean getNextRecord(T target) throws IOException, InterruptedException {\n+\t\tinputGate.requestPartitions();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDY4OTE5Mg=="}, "originalCommit": {"oid": "6ca8ec305a96d208919ab49244448de89bc7b679"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjAyNTI5Nw==", "bodyText": "Could you explain why do you think:\n\nalso not sensitive for batch code path.\n\n?", "url": "https://github.com/apache/flink/pull/11687#discussion_r422025297", "createdAt": "2020-05-08T08:47:56Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/reader/AbstractRecordReader.java", "diffHunk": "@@ -63,6 +63,8 @@ protected AbstractRecordReader(InputGate inputGate, String[] tmpDirectories) {\n \t}\n \n \tprotected boolean getNextRecord(T target) throws IOException, InterruptedException {\n+\t\tinputGate.requestPartitions();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDY4OTE5Mg=="}, "originalCommit": {"oid": "6ca8ec305a96d208919ab49244448de89bc7b679"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU3NzkzMjY2OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/InputGate.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQxNjoxNTozMVrOGLfH2A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQxNjoxNTozMVrOGLfH2A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDY5NzQzMg==", "bodyText": "requestPartitions() requires similar java doc as readRecoveredState() explaining when it should be called.", "url": "https://github.com/apache/flink/pull/11687#discussion_r414697432", "createdAt": "2020-04-24T16:15:31Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/InputGate.java", "diffHunk": "@@ -131,7 +133,18 @@\n \t/**\n \t * Setup gate, potentially heavy-weight, blocking operation comparing to just creation.\n \t */\n-\tpublic abstract void setup() throws IOException, InterruptedException;\n+\tpublic abstract void setup() throws IOException;\n+\n+\t/**\n+\t * It is only performed for unaligned checkpoint mode together with internal requesting partitions afterwards.\n+\t * Otherwise only {@link #requestPartitions()} is performed for other checkpoint modes.\n+\t *\n+\t * @param executor the dedicated executor for performing the recovery state for all the internal channels.\n+\t * @param reader the dedicated reader for unspilling the respective channel state from stored snapshots.\n+\t */\n+\tpublic abstract void readRecoveredState(ExecutorService executor, ChannelStateReader reader) throws IOException;\n+\n+\tpublic abstract void requestPartitions() throws IOException;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "95dc7d6ada34179b51849d905f15c740ca585a8d"}, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU3ODAyMjY3OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/LocalInputChannel.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQxNjozNzowM1rOGLf9Cg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQwODoyNDo1MVrOGQfOgQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDcxMTA1MA==", "bodyText": "?", "url": "https://github.com/apache/flink/pull/11687#discussion_r414711050", "createdAt": "2020-04-24T16:37:03Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/LocalInputChannel.java", "diffHunk": "@@ -97,6 +100,18 @@ public LocalInputChannel(\n \t// Consume\n \t// ------------------------------------------------------------------------\n \n+\t@Override\n+\tpublic void readRecoveredState(ChannelStateReader reader) throws IOException, InterruptedException {\n+\t\tsynchronized (bufferQueue) {\n+\t\t\t// In most of cases we only need one buffer for reading recovered state except in very large record case.\n+\t\t\t// Then only one floating buffer is required to avoid receive more floating buffers after recovery. Even\n+\t\t\t// though we need more buffers for recovery in large record case, it only increases some interactions with pool.\n+\t\t\tnumRequiredBuffers = 1;\n+\t\t}\n+\n+\t\tsuper.readRecoveredState(reader);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "95dc7d6ada34179b51849d905f15c740ca585a8d"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTUyMTgxNQ==", "bodyText": "what is the issue here?", "url": "https://github.com/apache/flink/pull/11687#discussion_r419521815", "createdAt": "2020-05-04T15:27:39Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/LocalInputChannel.java", "diffHunk": "@@ -97,6 +100,18 @@ public LocalInputChannel(\n \t// Consume\n \t// ------------------------------------------------------------------------\n \n+\t@Override\n+\tpublic void readRecoveredState(ChannelStateReader reader) throws IOException, InterruptedException {\n+\t\tsynchronized (bufferQueue) {\n+\t\t\t// In most of cases we only need one buffer for reading recovered state except in very large record case.\n+\t\t\t// Then only one floating buffer is required to avoid receive more floating buffers after recovery. Even\n+\t\t\t// though we need more buffers for recovery in large record case, it only increases some interactions with pool.\n+\t\t\tnumRequiredBuffers = 1;\n+\t\t}\n+\n+\t\tsuper.readRecoveredState(reader);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDcxMTA1MA=="}, "originalCommit": {"oid": "95dc7d6ada34179b51849d905f15c740ca585a8d"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTk0MjAxNw==", "bodyText": "Ops, sorry, that was some older comment that I forgot to remove before publishing the review :)", "url": "https://github.com/apache/flink/pull/11687#discussion_r419942017", "createdAt": "2020-05-05T08:24:51Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/LocalInputChannel.java", "diffHunk": "@@ -97,6 +100,18 @@ public LocalInputChannel(\n \t// Consume\n \t// ------------------------------------------------------------------------\n \n+\t@Override\n+\tpublic void readRecoveredState(ChannelStateReader reader) throws IOException, InterruptedException {\n+\t\tsynchronized (bufferQueue) {\n+\t\t\t// In most of cases we only need one buffer for reading recovered state except in very large record case.\n+\t\t\t// Then only one floating buffer is required to avoid receive more floating buffers after recovery. Even\n+\t\t\t// though we need more buffers for recovery in large record case, it only increases some interactions with pool.\n+\t\t\tnumRequiredBuffers = 1;\n+\t\t}\n+\n+\t\tsuper.readRecoveredState(reader);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDcxMTA1MA=="}, "originalCommit": {"oid": "95dc7d6ada34179b51849d905f15c740ca585a8d"}, "originalPosition": 48}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5MTE1NDU5OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOFQwOTo0MTo1NVrOGNLruA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQwODoyNToyOVrOGQfPtQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjQ3NjA4OA==", "bodyText": "Why add synchornized section?", "url": "https://github.com/apache/flink/pull/11687#discussion_r416476088", "createdAt": "2020-04-28T09:41:55Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "diffHunk": "@@ -371,7 +373,14 @@ boolean isWaitingForFloatingBuffers() {\n \n \t@VisibleForTesting\n \tpublic Buffer getNextReceivedBuffer() {\n-\t\treturn receivedBuffers.poll();\n+\t\tsynchronized (receivedBuffers) {\n+\t\t\treturn receivedBuffers.poll();\n+\t\t}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "95dc7d6ada34179b51849d905f15c740ca585a8d"}, "originalPosition": 158}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTUyMTYwNQ==", "bodyText": "it is out of date and i can not find this code path now?", "url": "https://github.com/apache/flink/pull/11687#discussion_r419521605", "createdAt": "2020-05-04T15:27:23Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "diffHunk": "@@ -371,7 +373,14 @@ boolean isWaitingForFloatingBuffers() {\n \n \t@VisibleForTesting\n \tpublic Buffer getNextReceivedBuffer() {\n-\t\treturn receivedBuffers.poll();\n+\t\tsynchronized (receivedBuffers) {\n+\t\t\treturn receivedBuffers.poll();\n+\t\t}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjQ3NjA4OA=="}, "originalCommit": {"oid": "95dc7d6ada34179b51849d905f15c740ca585a8d"}, "originalPosition": 158}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTk0MjMyNQ==", "bodyText": "I think it's in a separate commit now org.apache.flink.runtime.io.network.partition.consumer.RemoteInputChannel#getNumberOfQueuedBuffers", "url": "https://github.com/apache/flink/pull/11687#discussion_r419942325", "createdAt": "2020-05-05T08:25:29Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "diffHunk": "@@ -371,7 +373,14 @@ boolean isWaitingForFloatingBuffers() {\n \n \t@VisibleForTesting\n \tpublic Buffer getNextReceivedBuffer() {\n-\t\treturn receivedBuffers.poll();\n+\t\tsynchronized (receivedBuffers) {\n+\t\t\treturn receivedBuffers.poll();\n+\t\t}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjQ3NjA4OA=="}, "originalCommit": {"oid": "95dc7d6ada34179b51849d905f15c740ca585a8d"}, "originalPosition": 158}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYxMDExMDM3OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQwOTo0Njo1MFrOGP5bFg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQwOTo0Njo1MFrOGP5bFg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTMyMjY0Ng==", "bodyText": "I would keep the unsynchronized prefix for this method and getNumberOfAvailableFloatingBuffers as well.", "url": "https://github.com/apache/flink/pull/11687#discussion_r419322646", "createdAt": "2020-05-04T09:46:50Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "diffHunk": "@@ -477,11 +362,11 @@ public int unsynchronizedGetNumberOfQueuedBuffers() {\n \t}\n \n \tpublic int unsynchronizedGetExclusiveBuffersUsed() {\n-\t\treturn Math.max(0, initialCredit - bufferQueue.exclusiveBuffers.size());\n+\t\treturn Math.max(0, initialCredit - bufferManager.getNumberOfAvailableExclusiveBuffers());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "52f011acf79e07ccefa2eb6db22f2835a100e9b4"}, "originalPosition": 272}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYxMDE0Njc4OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQwOTo1NzozN1rOGP5xGA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxNDoxMzozNVrOGQCSNQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTMyODI4MA==", "bodyText": "This method is not synchronized. However it could be marked as @VisibleForTesting, so we could ignore this issue for now + adding unsynchronized prefix?", "url": "https://github.com/apache/flink/pull/11687#discussion_r419328280", "createdAt": "2020-05-04T09:57:37Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "diffHunk": "@@ -321,111 +274,43 @@ private void notifyCreditAvailable() {\n \t\tpartitionRequestClient.notifyCreditAvailable(this);\n \t}\n \n-\t/**\n-\t * Exclusive buffer is recycled to this input channel directly and it may trigger return extra\n-\t * floating buffer and notify increased credit to the producer.\n-\t *\n-\t * @param segment The exclusive segment of this channel.\n-\t */\n-\t@Override\n-\tpublic void recycle(MemorySegment segment) {\n-\t\tint numAddedBuffers;\n-\n-\t\tsynchronized (bufferQueue) {\n-\t\t\t// Similar to notifyBufferAvailable(), make sure that we never add a buffer\n-\t\t\t// after releaseAllResources() released all buffers (see below for details).\n-\t\t\tif (isReleased.get()) {\n-\t\t\t\ttry {\n-\t\t\t\t\tmemorySegmentProvider.recycleMemorySegments(Collections.singletonList(segment));\n-\t\t\t\t\treturn;\n-\t\t\t\t} catch (Throwable t) {\n-\t\t\t\t\tExceptionUtils.rethrow(t);\n-\t\t\t\t}\n-\t\t\t}\n-\t\t\tnumAddedBuffers = bufferQueue.addExclusiveBuffer(new NetworkBuffer(segment, this), numRequiredBuffers);\n-\t\t}\n-\n-\t\tif (numAddedBuffers > 0 && unannouncedCredit.getAndAdd(numAddedBuffers) == 0) {\n-\t\t\tnotifyCreditAvailable();\n-\t\t}\n-\t}\n-\n \tpublic int getNumberOfAvailableBuffers() {\n-\t\tsynchronized (bufferQueue) {\n-\t\t\treturn bufferQueue.getAvailableBufferSize();\n-\t\t}\n+\t\treturn bufferManager.getNumberOfAvailableBuffers();\n \t}\n \n \tpublic int getNumberOfRequiredBuffers() {\n-\t\treturn numRequiredBuffers;\n+\t\treturn bufferManager.getNumberOfRequiredBuffers();\n \t}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "52f011acf79e07ccefa2eb6db22f2835a100e9b4"}, "originalPosition": 183}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTQ2NzgyOQ==", "bodyText": "Yes, it could be as you said. Actually it should be a separate hotfix if we want to fix it in this PR.", "url": "https://github.com/apache/flink/pull/11687#discussion_r419467829", "createdAt": "2020-05-04T14:13:35Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "diffHunk": "@@ -321,111 +274,43 @@ private void notifyCreditAvailable() {\n \t\tpartitionRequestClient.notifyCreditAvailable(this);\n \t}\n \n-\t/**\n-\t * Exclusive buffer is recycled to this input channel directly and it may trigger return extra\n-\t * floating buffer and notify increased credit to the producer.\n-\t *\n-\t * @param segment The exclusive segment of this channel.\n-\t */\n-\t@Override\n-\tpublic void recycle(MemorySegment segment) {\n-\t\tint numAddedBuffers;\n-\n-\t\tsynchronized (bufferQueue) {\n-\t\t\t// Similar to notifyBufferAvailable(), make sure that we never add a buffer\n-\t\t\t// after releaseAllResources() released all buffers (see below for details).\n-\t\t\tif (isReleased.get()) {\n-\t\t\t\ttry {\n-\t\t\t\t\tmemorySegmentProvider.recycleMemorySegments(Collections.singletonList(segment));\n-\t\t\t\t\treturn;\n-\t\t\t\t} catch (Throwable t) {\n-\t\t\t\t\tExceptionUtils.rethrow(t);\n-\t\t\t\t}\n-\t\t\t}\n-\t\t\tnumAddedBuffers = bufferQueue.addExclusiveBuffer(new NetworkBuffer(segment, this), numRequiredBuffers);\n-\t\t}\n-\n-\t\tif (numAddedBuffers > 0 && unannouncedCredit.getAndAdd(numAddedBuffers) == 0) {\n-\t\t\tnotifyCreditAvailable();\n-\t\t}\n-\t}\n-\n \tpublic int getNumberOfAvailableBuffers() {\n-\t\tsynchronized (bufferQueue) {\n-\t\t\treturn bufferQueue.getAvailableBufferSize();\n-\t\t}\n+\t\treturn bufferManager.getNumberOfAvailableBuffers();\n \t}\n \n \tpublic int getNumberOfRequiredBuffers() {\n-\t\treturn numRequiredBuffers;\n+\t\treturn bufferManager.getNumberOfRequiredBuffers();\n \t}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTMyODI4MA=="}, "originalCommit": {"oid": "52f011acf79e07ccefa2eb6db22f2835a100e9b4"}, "originalPosition": 183}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYxMDE1MDEyOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQwOTo1ODo0N1rOGP5zTg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxNDoxNjoyN1rOGQCaOw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTMyODg0Ng==", "bodyText": "unsychronized prefix + @VisibleForTesting?", "url": "https://github.com/apache/flink/pull/11687#discussion_r419328846", "createdAt": "2020-05-04T09:58:47Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.io.network.partition.consumer;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.core.memory.MemorySegment;\n+import org.apache.flink.core.memory.MemorySegmentProvider;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferListener;\n+import org.apache.flink.runtime.io.network.buffer.BufferPool;\n+import org.apache.flink.runtime.io.network.buffer.BufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.util.ExceptionUtils;\n+\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.io.IOException;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+\n+import static org.apache.flink.util.Preconditions.checkArgument;\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * The general buffer manager used by {@link InputChannel} to request/recycle\n+ * exclusive or floating buffers.\n+ */\n+public class BufferManager implements BufferListener, BufferRecycler {\n+\n+\t/** The available buffer queue wraps both exclusive and requested floating buffers. */\n+\tprivate final AvailableBufferQueue bufferQueue = new AvailableBufferQueue();\n+\n+\t/** The buffer provider for requesting exclusive buffers. */\n+\tprivate final MemorySegmentProvider globalPool;\n+\n+\t/** The input channel to own this buffer manager. */\n+\tprivate final InputChannel inputChannel;\n+\n+\t/** The tag indicates whether it is waiting for additional floating buffers from the buffer pool. */\n+\t@GuardedBy(\"bufferQueue\")\n+\tprivate boolean isWaitingForFloatingBuffers;\n+\n+\t/** The total number of required buffers for the respective input channel. */\n+\t@GuardedBy(\"bufferQueue\")\n+\tprivate int numRequiredBuffers;\n+\n+\tpublic BufferManager(\n+\t\tMemorySegmentProvider globalPool,\n+\t\tInputChannel inputChannel,\n+\t\tint numRequiredBuffers) {\n+\n+\t\tthis.globalPool = checkNotNull(globalPool);\n+\t\tthis.inputChannel = checkNotNull(inputChannel);\n+\t\tcheckArgument(numRequiredBuffers >= 0);\n+\t\tthis.numRequiredBuffers = numRequiredBuffers;\n+\t}\n+\n+\t// ------------------------------------------------------------------------\n+\t// Buffer request\n+\t// ------------------------------------------------------------------------\n+\n+\t@Nullable\n+\tBuffer requestBuffer() {\n+\t\tsynchronized (bufferQueue) {\n+\t\t\treturn bufferQueue.takeBuffer();\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Requests exclusive buffers from the provider and returns the number of requested amount.\n+\t */\n+\tint requestExclusiveBuffers() throws IOException {\n+\t\tCollection<MemorySegment> segments = globalPool.requestMemorySegments();\n+\t\tcheckArgument(!segments.isEmpty(), \"The number of exclusive buffers per channel should be larger than 0.\");\n+\n+\t\tsynchronized (bufferQueue) {\n+\t\t\tfor (MemorySegment segment : segments) {\n+\t\t\t\tbufferQueue.addExclusiveBuffer(new NetworkBuffer(segment, this), numRequiredBuffers);\n+\t\t\t}\n+\t\t}\n+\t\treturn segments.size();\n+\t}\n+\n+\t/**\n+\t * Requests floating buffers from the buffer pool based on the given required amount, and returns the actual\n+\t * requested amount. If the required amount is not fully satisfied, it will register as a listener.\n+\t */\n+\tint requestFloatingBuffers(int numRequired) throws IOException {\n+\t\tint numRequestedBuffers = 0;\n+\t\tsynchronized (bufferQueue) {\n+\t\t\t// Similar to notifyBufferAvailable(), make sure that we never add a buffer after channel\n+\t\t\t// released all buffers via releaseAllResources().\n+\t\t\tif (inputChannel.isReleased()) {\n+\t\t\t\treturn numRequestedBuffers;\n+\t\t\t}\n+\n+\t\t\tnumRequiredBuffers = numRequired;\n+\n+\t\t\twhile (bufferQueue.getAvailableBufferSize() < numRequiredBuffers && !isWaitingForFloatingBuffers) {\n+\t\t\t\tBufferPool bufferPool = inputChannel.inputGate.getBufferPool();\n+\t\t\t\tBuffer buffer = bufferPool.requestBuffer();\n+\t\t\t\tif (buffer != null) {\n+\t\t\t\t\tbufferQueue.addFloatingBuffer(buffer);\n+\t\t\t\t\tnumRequestedBuffers++;\n+\t\t\t\t} else if (bufferPool.addBufferListener(this)) {\n+\t\t\t\t\tisWaitingForFloatingBuffers = true;\n+\t\t\t\t\tbreak;\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t\treturn numRequestedBuffers;\n+\t}\n+\n+\t// ------------------------------------------------------------------------\n+\t// Buffer recycle\n+\t// ------------------------------------------------------------------------\n+\n+\t/**\n+\t * Exclusive buffer is recycled to this channel manager directly and it may trigger return extra\n+\t * floating buffer based on <tt>numRequiredBuffers</tt>.\n+\t *\n+\t * @param segment The exclusive segment of this channel.\n+\t */\n+\t@Override\n+\tpublic void recycle(MemorySegment segment) {\n+\t\tint numAddedBuffers = 0;\n+\t\tsynchronized (bufferQueue) {\n+\t\t\ttry {\n+\t\t\t\t// Similar to notifyBufferAvailable(), make sure that we never add a buffer\n+\t\t\t\t// after channel released all buffers via releaseAllResources().\n+\t\t\t\tif (inputChannel.isReleased()) {\n+\t\t\t\t\tglobalPool.recycleMemorySegments(Collections.singletonList(segment));\n+\t\t\t\t} else {\n+\t\t\t\t\tnumAddedBuffers = bufferQueue.addExclusiveBuffer(new NetworkBuffer(segment, this), numRequiredBuffers);\n+\t\t\t\t}\n+\t\t\t} catch (Throwable t) {\n+\t\t\t\tExceptionUtils.rethrow(t);\n+\t\t\t}\n+\t\t}\n+\t\tinputChannel.notifyBufferAvailable(numAddedBuffers);\n+\t}\n+\n+\t/**\n+\t * Recycles all the exclusive and floating buffers from the given buffer queue.\n+\t */\n+\tvoid releaseAllBuffers(ArrayDeque<Buffer> buffers) throws IOException {\n+\t\t// Gather all exclusive buffers and recycle them to global pool in batch, because\n+\t\t// we do not want to trigger redistribution of buffers after each recycle.\n+\t\tfinal List<MemorySegment> exclusiveRecyclingSegments = new ArrayList<>();\n+\n+\t\tBuffer buffer;\n+\t\twhile ((buffer = buffers.poll()) != null) {\n+\t\t\tif (buffer.getRecycler() == this) {\n+\t\t\t\texclusiveRecyclingSegments.add(buffer.getMemorySegment());\n+\t\t\t} else {\n+\t\t\t\tbuffer.recycleBuffer();\n+\t\t\t}\n+\t\t}\n+\t\tsynchronized (bufferQueue) {\n+\t\t\tbufferQueue.releaseAll(exclusiveRecyclingSegments);\n+\t\t}\n+\n+\t\tif (exclusiveRecyclingSegments.size() > 0) {\n+\t\t\tglobalPool.recycleMemorySegments(exclusiveRecyclingSegments);\n+\t\t}\n+\t}\n+\n+\t// ------------------------------------------------------------------------\n+\t// Buffer listener notification\n+\t// ------------------------------------------------------------------------\n+\n+\t/**\n+\t * The buffer pool notifies this listener of an available floating buffer. If the listener is released or\n+\t * currently does not need extra buffers, the buffer should be returned to the buffer pool. Otherwise,\n+\t * the buffer will be added into the <tt>bufferQueue</tt>.\n+\t *\n+\t * @param buffer Buffer that becomes available in buffer pool.\n+\t * @return NotificationResult indicates whether this channel accepts the buffer and is waiting for\n+\t * more floating buffers.\n+\t */\n+\t@Override\n+\tpublic BufferListener.NotificationResult notifyBufferAvailable(Buffer buffer) {\n+\t\tBufferListener.NotificationResult notificationResult = BufferListener.NotificationResult.BUFFER_NOT_USED;\n+\t\tThrowable throwable = null;\n+\t\tsynchronized (bufferQueue) {\n+\t\t\ttry {\n+\t\t\t\tcheckState(isWaitingForFloatingBuffers, \"This channel should be waiting for floating buffers.\");\n+\n+\t\t\t\t// Important: make sure that we never add a buffer after releaseAllResources()\n+\t\t\t\t// released all buffers. Following scenarios exist:\n+\t\t\t\t// 1) releaseAllBuffers() already released buffers inside bufferQueue\n+\t\t\t\t// -> while isReleased is set correctly in InputChannel\n+\t\t\t\t// 2) releaseAllBuffers() did not yet release buffers from bufferQueue\n+\t\t\t\t// -> we may or may not have set isReleased yet but will always wait for the\n+\t\t\t\t// lock on bufferQueue to release buffers\n+\t\t\t\tif (inputChannel.isReleased() || bufferQueue.getAvailableBufferSize() >= numRequiredBuffers) {\n+\t\t\t\t\tisWaitingForFloatingBuffers = false;\n+\t\t\t\t\treturn notificationResult;\n+\t\t\t\t}\n+\n+\t\t\t\tbufferQueue.addFloatingBuffer(buffer);\n+\n+\t\t\t\tif (bufferQueue.getAvailableBufferSize() == numRequiredBuffers) {\n+\t\t\t\t\tisWaitingForFloatingBuffers = false;\n+\t\t\t\t\tnotificationResult = BufferListener.NotificationResult.BUFFER_USED_NO_NEED_MORE;\n+\t\t\t\t} else {\n+\t\t\t\t\tnotificationResult = BufferListener.NotificationResult.BUFFER_USED_NEED_MORE;\n+\t\t\t\t}\n+\t\t\t} catch (Throwable t) {\n+\t\t\t\tthrowable = t;\n+\t\t\t}\n+\t\t}\n+\n+\t\tif (throwable != null) {\n+\t\t\tinputChannel.setError(throwable);\n+\t\t} else if (notificationResult != NotificationResult.BUFFER_NOT_USED) {\n+\t\t\tinputChannel.notifyBufferAvailable(1);\n+\t\t}\n+\t\treturn notificationResult;\n+\t}\n+\n+\t@Override\n+\tpublic void notifyBufferDestroyed() {\n+\t\t// Nothing to do actually.\n+\t}\n+\n+\t// ------------------------------------------------------------------------\n+\t// Getter properties\n+\t// ------------------------------------------------------------------------\n+\n+\tint getNumberOfRequiredBuffers() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "52f011acf79e07ccefa2eb6db22f2835a100e9b4"}, "originalPosition": 252}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTQ2OTg4Mw==", "bodyText": "unsychronized makes sense, but not for @VisibleForTesting because now it is also used in formal codes of RemoteInputChannel#getSenderBacklog", "url": "https://github.com/apache/flink/pull/11687#discussion_r419469883", "createdAt": "2020-05-04T14:16:27Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.io.network.partition.consumer;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.core.memory.MemorySegment;\n+import org.apache.flink.core.memory.MemorySegmentProvider;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferListener;\n+import org.apache.flink.runtime.io.network.buffer.BufferPool;\n+import org.apache.flink.runtime.io.network.buffer.BufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.util.ExceptionUtils;\n+\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.io.IOException;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+\n+import static org.apache.flink.util.Preconditions.checkArgument;\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * The general buffer manager used by {@link InputChannel} to request/recycle\n+ * exclusive or floating buffers.\n+ */\n+public class BufferManager implements BufferListener, BufferRecycler {\n+\n+\t/** The available buffer queue wraps both exclusive and requested floating buffers. */\n+\tprivate final AvailableBufferQueue bufferQueue = new AvailableBufferQueue();\n+\n+\t/** The buffer provider for requesting exclusive buffers. */\n+\tprivate final MemorySegmentProvider globalPool;\n+\n+\t/** The input channel to own this buffer manager. */\n+\tprivate final InputChannel inputChannel;\n+\n+\t/** The tag indicates whether it is waiting for additional floating buffers from the buffer pool. */\n+\t@GuardedBy(\"bufferQueue\")\n+\tprivate boolean isWaitingForFloatingBuffers;\n+\n+\t/** The total number of required buffers for the respective input channel. */\n+\t@GuardedBy(\"bufferQueue\")\n+\tprivate int numRequiredBuffers;\n+\n+\tpublic BufferManager(\n+\t\tMemorySegmentProvider globalPool,\n+\t\tInputChannel inputChannel,\n+\t\tint numRequiredBuffers) {\n+\n+\t\tthis.globalPool = checkNotNull(globalPool);\n+\t\tthis.inputChannel = checkNotNull(inputChannel);\n+\t\tcheckArgument(numRequiredBuffers >= 0);\n+\t\tthis.numRequiredBuffers = numRequiredBuffers;\n+\t}\n+\n+\t// ------------------------------------------------------------------------\n+\t// Buffer request\n+\t// ------------------------------------------------------------------------\n+\n+\t@Nullable\n+\tBuffer requestBuffer() {\n+\t\tsynchronized (bufferQueue) {\n+\t\t\treturn bufferQueue.takeBuffer();\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Requests exclusive buffers from the provider and returns the number of requested amount.\n+\t */\n+\tint requestExclusiveBuffers() throws IOException {\n+\t\tCollection<MemorySegment> segments = globalPool.requestMemorySegments();\n+\t\tcheckArgument(!segments.isEmpty(), \"The number of exclusive buffers per channel should be larger than 0.\");\n+\n+\t\tsynchronized (bufferQueue) {\n+\t\t\tfor (MemorySegment segment : segments) {\n+\t\t\t\tbufferQueue.addExclusiveBuffer(new NetworkBuffer(segment, this), numRequiredBuffers);\n+\t\t\t}\n+\t\t}\n+\t\treturn segments.size();\n+\t}\n+\n+\t/**\n+\t * Requests floating buffers from the buffer pool based on the given required amount, and returns the actual\n+\t * requested amount. If the required amount is not fully satisfied, it will register as a listener.\n+\t */\n+\tint requestFloatingBuffers(int numRequired) throws IOException {\n+\t\tint numRequestedBuffers = 0;\n+\t\tsynchronized (bufferQueue) {\n+\t\t\t// Similar to notifyBufferAvailable(), make sure that we never add a buffer after channel\n+\t\t\t// released all buffers via releaseAllResources().\n+\t\t\tif (inputChannel.isReleased()) {\n+\t\t\t\treturn numRequestedBuffers;\n+\t\t\t}\n+\n+\t\t\tnumRequiredBuffers = numRequired;\n+\n+\t\t\twhile (bufferQueue.getAvailableBufferSize() < numRequiredBuffers && !isWaitingForFloatingBuffers) {\n+\t\t\t\tBufferPool bufferPool = inputChannel.inputGate.getBufferPool();\n+\t\t\t\tBuffer buffer = bufferPool.requestBuffer();\n+\t\t\t\tif (buffer != null) {\n+\t\t\t\t\tbufferQueue.addFloatingBuffer(buffer);\n+\t\t\t\t\tnumRequestedBuffers++;\n+\t\t\t\t} else if (bufferPool.addBufferListener(this)) {\n+\t\t\t\t\tisWaitingForFloatingBuffers = true;\n+\t\t\t\t\tbreak;\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t\treturn numRequestedBuffers;\n+\t}\n+\n+\t// ------------------------------------------------------------------------\n+\t// Buffer recycle\n+\t// ------------------------------------------------------------------------\n+\n+\t/**\n+\t * Exclusive buffer is recycled to this channel manager directly and it may trigger return extra\n+\t * floating buffer based on <tt>numRequiredBuffers</tt>.\n+\t *\n+\t * @param segment The exclusive segment of this channel.\n+\t */\n+\t@Override\n+\tpublic void recycle(MemorySegment segment) {\n+\t\tint numAddedBuffers = 0;\n+\t\tsynchronized (bufferQueue) {\n+\t\t\ttry {\n+\t\t\t\t// Similar to notifyBufferAvailable(), make sure that we never add a buffer\n+\t\t\t\t// after channel released all buffers via releaseAllResources().\n+\t\t\t\tif (inputChannel.isReleased()) {\n+\t\t\t\t\tglobalPool.recycleMemorySegments(Collections.singletonList(segment));\n+\t\t\t\t} else {\n+\t\t\t\t\tnumAddedBuffers = bufferQueue.addExclusiveBuffer(new NetworkBuffer(segment, this), numRequiredBuffers);\n+\t\t\t\t}\n+\t\t\t} catch (Throwable t) {\n+\t\t\t\tExceptionUtils.rethrow(t);\n+\t\t\t}\n+\t\t}\n+\t\tinputChannel.notifyBufferAvailable(numAddedBuffers);\n+\t}\n+\n+\t/**\n+\t * Recycles all the exclusive and floating buffers from the given buffer queue.\n+\t */\n+\tvoid releaseAllBuffers(ArrayDeque<Buffer> buffers) throws IOException {\n+\t\t// Gather all exclusive buffers and recycle them to global pool in batch, because\n+\t\t// we do not want to trigger redistribution of buffers after each recycle.\n+\t\tfinal List<MemorySegment> exclusiveRecyclingSegments = new ArrayList<>();\n+\n+\t\tBuffer buffer;\n+\t\twhile ((buffer = buffers.poll()) != null) {\n+\t\t\tif (buffer.getRecycler() == this) {\n+\t\t\t\texclusiveRecyclingSegments.add(buffer.getMemorySegment());\n+\t\t\t} else {\n+\t\t\t\tbuffer.recycleBuffer();\n+\t\t\t}\n+\t\t}\n+\t\tsynchronized (bufferQueue) {\n+\t\t\tbufferQueue.releaseAll(exclusiveRecyclingSegments);\n+\t\t}\n+\n+\t\tif (exclusiveRecyclingSegments.size() > 0) {\n+\t\t\tglobalPool.recycleMemorySegments(exclusiveRecyclingSegments);\n+\t\t}\n+\t}\n+\n+\t// ------------------------------------------------------------------------\n+\t// Buffer listener notification\n+\t// ------------------------------------------------------------------------\n+\n+\t/**\n+\t * The buffer pool notifies this listener of an available floating buffer. If the listener is released or\n+\t * currently does not need extra buffers, the buffer should be returned to the buffer pool. Otherwise,\n+\t * the buffer will be added into the <tt>bufferQueue</tt>.\n+\t *\n+\t * @param buffer Buffer that becomes available in buffer pool.\n+\t * @return NotificationResult indicates whether this channel accepts the buffer and is waiting for\n+\t * more floating buffers.\n+\t */\n+\t@Override\n+\tpublic BufferListener.NotificationResult notifyBufferAvailable(Buffer buffer) {\n+\t\tBufferListener.NotificationResult notificationResult = BufferListener.NotificationResult.BUFFER_NOT_USED;\n+\t\tThrowable throwable = null;\n+\t\tsynchronized (bufferQueue) {\n+\t\t\ttry {\n+\t\t\t\tcheckState(isWaitingForFloatingBuffers, \"This channel should be waiting for floating buffers.\");\n+\n+\t\t\t\t// Important: make sure that we never add a buffer after releaseAllResources()\n+\t\t\t\t// released all buffers. Following scenarios exist:\n+\t\t\t\t// 1) releaseAllBuffers() already released buffers inside bufferQueue\n+\t\t\t\t// -> while isReleased is set correctly in InputChannel\n+\t\t\t\t// 2) releaseAllBuffers() did not yet release buffers from bufferQueue\n+\t\t\t\t// -> we may or may not have set isReleased yet but will always wait for the\n+\t\t\t\t// lock on bufferQueue to release buffers\n+\t\t\t\tif (inputChannel.isReleased() || bufferQueue.getAvailableBufferSize() >= numRequiredBuffers) {\n+\t\t\t\t\tisWaitingForFloatingBuffers = false;\n+\t\t\t\t\treturn notificationResult;\n+\t\t\t\t}\n+\n+\t\t\t\tbufferQueue.addFloatingBuffer(buffer);\n+\n+\t\t\t\tif (bufferQueue.getAvailableBufferSize() == numRequiredBuffers) {\n+\t\t\t\t\tisWaitingForFloatingBuffers = false;\n+\t\t\t\t\tnotificationResult = BufferListener.NotificationResult.BUFFER_USED_NO_NEED_MORE;\n+\t\t\t\t} else {\n+\t\t\t\t\tnotificationResult = BufferListener.NotificationResult.BUFFER_USED_NEED_MORE;\n+\t\t\t\t}\n+\t\t\t} catch (Throwable t) {\n+\t\t\t\tthrowable = t;\n+\t\t\t}\n+\t\t}\n+\n+\t\tif (throwable != null) {\n+\t\t\tinputChannel.setError(throwable);\n+\t\t} else if (notificationResult != NotificationResult.BUFFER_NOT_USED) {\n+\t\t\tinputChannel.notifyBufferAvailable(1);\n+\t\t}\n+\t\treturn notificationResult;\n+\t}\n+\n+\t@Override\n+\tpublic void notifyBufferDestroyed() {\n+\t\t// Nothing to do actually.\n+\t}\n+\n+\t// ------------------------------------------------------------------------\n+\t// Getter properties\n+\t// ------------------------------------------------------------------------\n+\n+\tint getNumberOfRequiredBuffers() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTMyODg0Ng=="}, "originalCommit": {"oid": "52f011acf79e07ccefa2eb6db22f2835a100e9b4"}, "originalPosition": 252}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYxMDE1Mzc2OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQwOTo1OTo1MlrOGP51kw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQwOTo1OTo1MlrOGP51kw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTMyOTQyNw==", "bodyText": "unsychronized prefix?", "url": "https://github.com/apache/flink/pull/11687#discussion_r419329427", "createdAt": "2020-05-04T09:59:52Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.io.network.partition.consumer;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.core.memory.MemorySegment;\n+import org.apache.flink.core.memory.MemorySegmentProvider;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferListener;\n+import org.apache.flink.runtime.io.network.buffer.BufferPool;\n+import org.apache.flink.runtime.io.network.buffer.BufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.util.ExceptionUtils;\n+\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.io.IOException;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+\n+import static org.apache.flink.util.Preconditions.checkArgument;\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * The general buffer manager used by {@link InputChannel} to request/recycle\n+ * exclusive or floating buffers.\n+ */\n+public class BufferManager implements BufferListener, BufferRecycler {\n+\n+\t/** The available buffer queue wraps both exclusive and requested floating buffers. */\n+\tprivate final AvailableBufferQueue bufferQueue = new AvailableBufferQueue();\n+\n+\t/** The buffer provider for requesting exclusive buffers. */\n+\tprivate final MemorySegmentProvider globalPool;\n+\n+\t/** The input channel to own this buffer manager. */\n+\tprivate final InputChannel inputChannel;\n+\n+\t/** The tag indicates whether it is waiting for additional floating buffers from the buffer pool. */\n+\t@GuardedBy(\"bufferQueue\")\n+\tprivate boolean isWaitingForFloatingBuffers;\n+\n+\t/** The total number of required buffers for the respective input channel. */\n+\t@GuardedBy(\"bufferQueue\")\n+\tprivate int numRequiredBuffers;\n+\n+\tpublic BufferManager(\n+\t\tMemorySegmentProvider globalPool,\n+\t\tInputChannel inputChannel,\n+\t\tint numRequiredBuffers) {\n+\n+\t\tthis.globalPool = checkNotNull(globalPool);\n+\t\tthis.inputChannel = checkNotNull(inputChannel);\n+\t\tcheckArgument(numRequiredBuffers >= 0);\n+\t\tthis.numRequiredBuffers = numRequiredBuffers;\n+\t}\n+\n+\t// ------------------------------------------------------------------------\n+\t// Buffer request\n+\t// ------------------------------------------------------------------------\n+\n+\t@Nullable\n+\tBuffer requestBuffer() {\n+\t\tsynchronized (bufferQueue) {\n+\t\t\treturn bufferQueue.takeBuffer();\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Requests exclusive buffers from the provider and returns the number of requested amount.\n+\t */\n+\tint requestExclusiveBuffers() throws IOException {\n+\t\tCollection<MemorySegment> segments = globalPool.requestMemorySegments();\n+\t\tcheckArgument(!segments.isEmpty(), \"The number of exclusive buffers per channel should be larger than 0.\");\n+\n+\t\tsynchronized (bufferQueue) {\n+\t\t\tfor (MemorySegment segment : segments) {\n+\t\t\t\tbufferQueue.addExclusiveBuffer(new NetworkBuffer(segment, this), numRequiredBuffers);\n+\t\t\t}\n+\t\t}\n+\t\treturn segments.size();\n+\t}\n+\n+\t/**\n+\t * Requests floating buffers from the buffer pool based on the given required amount, and returns the actual\n+\t * requested amount. If the required amount is not fully satisfied, it will register as a listener.\n+\t */\n+\tint requestFloatingBuffers(int numRequired) throws IOException {\n+\t\tint numRequestedBuffers = 0;\n+\t\tsynchronized (bufferQueue) {\n+\t\t\t// Similar to notifyBufferAvailable(), make sure that we never add a buffer after channel\n+\t\t\t// released all buffers via releaseAllResources().\n+\t\t\tif (inputChannel.isReleased()) {\n+\t\t\t\treturn numRequestedBuffers;\n+\t\t\t}\n+\n+\t\t\tnumRequiredBuffers = numRequired;\n+\n+\t\t\twhile (bufferQueue.getAvailableBufferSize() < numRequiredBuffers && !isWaitingForFloatingBuffers) {\n+\t\t\t\tBufferPool bufferPool = inputChannel.inputGate.getBufferPool();\n+\t\t\t\tBuffer buffer = bufferPool.requestBuffer();\n+\t\t\t\tif (buffer != null) {\n+\t\t\t\t\tbufferQueue.addFloatingBuffer(buffer);\n+\t\t\t\t\tnumRequestedBuffers++;\n+\t\t\t\t} else if (bufferPool.addBufferListener(this)) {\n+\t\t\t\t\tisWaitingForFloatingBuffers = true;\n+\t\t\t\t\tbreak;\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t\treturn numRequestedBuffers;\n+\t}\n+\n+\t// ------------------------------------------------------------------------\n+\t// Buffer recycle\n+\t// ------------------------------------------------------------------------\n+\n+\t/**\n+\t * Exclusive buffer is recycled to this channel manager directly and it may trigger return extra\n+\t * floating buffer based on <tt>numRequiredBuffers</tt>.\n+\t *\n+\t * @param segment The exclusive segment of this channel.\n+\t */\n+\t@Override\n+\tpublic void recycle(MemorySegment segment) {\n+\t\tint numAddedBuffers = 0;\n+\t\tsynchronized (bufferQueue) {\n+\t\t\ttry {\n+\t\t\t\t// Similar to notifyBufferAvailable(), make sure that we never add a buffer\n+\t\t\t\t// after channel released all buffers via releaseAllResources().\n+\t\t\t\tif (inputChannel.isReleased()) {\n+\t\t\t\t\tglobalPool.recycleMemorySegments(Collections.singletonList(segment));\n+\t\t\t\t} else {\n+\t\t\t\t\tnumAddedBuffers = bufferQueue.addExclusiveBuffer(new NetworkBuffer(segment, this), numRequiredBuffers);\n+\t\t\t\t}\n+\t\t\t} catch (Throwable t) {\n+\t\t\t\tExceptionUtils.rethrow(t);\n+\t\t\t}\n+\t\t}\n+\t\tinputChannel.notifyBufferAvailable(numAddedBuffers);\n+\t}\n+\n+\t/**\n+\t * Recycles all the exclusive and floating buffers from the given buffer queue.\n+\t */\n+\tvoid releaseAllBuffers(ArrayDeque<Buffer> buffers) throws IOException {\n+\t\t// Gather all exclusive buffers and recycle them to global pool in batch, because\n+\t\t// we do not want to trigger redistribution of buffers after each recycle.\n+\t\tfinal List<MemorySegment> exclusiveRecyclingSegments = new ArrayList<>();\n+\n+\t\tBuffer buffer;\n+\t\twhile ((buffer = buffers.poll()) != null) {\n+\t\t\tif (buffer.getRecycler() == this) {\n+\t\t\t\texclusiveRecyclingSegments.add(buffer.getMemorySegment());\n+\t\t\t} else {\n+\t\t\t\tbuffer.recycleBuffer();\n+\t\t\t}\n+\t\t}\n+\t\tsynchronized (bufferQueue) {\n+\t\t\tbufferQueue.releaseAll(exclusiveRecyclingSegments);\n+\t\t}\n+\n+\t\tif (exclusiveRecyclingSegments.size() > 0) {\n+\t\t\tglobalPool.recycleMemorySegments(exclusiveRecyclingSegments);\n+\t\t}\n+\t}\n+\n+\t// ------------------------------------------------------------------------\n+\t// Buffer listener notification\n+\t// ------------------------------------------------------------------------\n+\n+\t/**\n+\t * The buffer pool notifies this listener of an available floating buffer. If the listener is released or\n+\t * currently does not need extra buffers, the buffer should be returned to the buffer pool. Otherwise,\n+\t * the buffer will be added into the <tt>bufferQueue</tt>.\n+\t *\n+\t * @param buffer Buffer that becomes available in buffer pool.\n+\t * @return NotificationResult indicates whether this channel accepts the buffer and is waiting for\n+\t * more floating buffers.\n+\t */\n+\t@Override\n+\tpublic BufferListener.NotificationResult notifyBufferAvailable(Buffer buffer) {\n+\t\tBufferListener.NotificationResult notificationResult = BufferListener.NotificationResult.BUFFER_NOT_USED;\n+\t\tThrowable throwable = null;\n+\t\tsynchronized (bufferQueue) {\n+\t\t\ttry {\n+\t\t\t\tcheckState(isWaitingForFloatingBuffers, \"This channel should be waiting for floating buffers.\");\n+\n+\t\t\t\t// Important: make sure that we never add a buffer after releaseAllResources()\n+\t\t\t\t// released all buffers. Following scenarios exist:\n+\t\t\t\t// 1) releaseAllBuffers() already released buffers inside bufferQueue\n+\t\t\t\t// -> while isReleased is set correctly in InputChannel\n+\t\t\t\t// 2) releaseAllBuffers() did not yet release buffers from bufferQueue\n+\t\t\t\t// -> we may or may not have set isReleased yet but will always wait for the\n+\t\t\t\t// lock on bufferQueue to release buffers\n+\t\t\t\tif (inputChannel.isReleased() || bufferQueue.getAvailableBufferSize() >= numRequiredBuffers) {\n+\t\t\t\t\tisWaitingForFloatingBuffers = false;\n+\t\t\t\t\treturn notificationResult;\n+\t\t\t\t}\n+\n+\t\t\t\tbufferQueue.addFloatingBuffer(buffer);\n+\n+\t\t\t\tif (bufferQueue.getAvailableBufferSize() == numRequiredBuffers) {\n+\t\t\t\t\tisWaitingForFloatingBuffers = false;\n+\t\t\t\t\tnotificationResult = BufferListener.NotificationResult.BUFFER_USED_NO_NEED_MORE;\n+\t\t\t\t} else {\n+\t\t\t\t\tnotificationResult = BufferListener.NotificationResult.BUFFER_USED_NEED_MORE;\n+\t\t\t\t}\n+\t\t\t} catch (Throwable t) {\n+\t\t\t\tthrowable = t;\n+\t\t\t}\n+\t\t}\n+\n+\t\tif (throwable != null) {\n+\t\t\tinputChannel.setError(throwable);\n+\t\t} else if (notificationResult != NotificationResult.BUFFER_NOT_USED) {\n+\t\t\tinputChannel.notifyBufferAvailable(1);\n+\t\t}\n+\t\treturn notificationResult;\n+\t}\n+\n+\t@Override\n+\tpublic void notifyBufferDestroyed() {\n+\t\t// Nothing to do actually.\n+\t}\n+\n+\t// ------------------------------------------------------------------------\n+\t// Getter properties\n+\t// ------------------------------------------------------------------------\n+\n+\tint getNumberOfRequiredBuffers() {\n+\t\treturn numRequiredBuffers;\n+\t}\n+\n+\t@VisibleForTesting\n+\tboolean isWaitingForFloatingBuffers() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "52f011acf79e07ccefa2eb6db22f2835a100e9b4"}, "originalPosition": 257}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYxMDE2NzE1OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxMDowNDoyM1rOGP5-KQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxMDowNDoyM1rOGP5-KQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTMzMTYyNQ==", "bodyText": "unsychronized prefix?", "url": "https://github.com/apache/flink/pull/11687#discussion_r419331625", "createdAt": "2020-05-04T10:04:23Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.io.network.partition.consumer;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.core.memory.MemorySegment;\n+import org.apache.flink.core.memory.MemorySegmentProvider;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferListener;\n+import org.apache.flink.runtime.io.network.buffer.BufferPool;\n+import org.apache.flink.runtime.io.network.buffer.BufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.util.ExceptionUtils;\n+\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.io.IOException;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+\n+import static org.apache.flink.util.Preconditions.checkArgument;\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * The general buffer manager used by {@link InputChannel} to request/recycle\n+ * exclusive or floating buffers.\n+ */\n+public class BufferManager implements BufferListener, BufferRecycler {\n+\n+\t/** The available buffer queue wraps both exclusive and requested floating buffers. */\n+\tprivate final AvailableBufferQueue bufferQueue = new AvailableBufferQueue();\n+\n+\t/** The buffer provider for requesting exclusive buffers. */\n+\tprivate final MemorySegmentProvider globalPool;\n+\n+\t/** The input channel to own this buffer manager. */\n+\tprivate final InputChannel inputChannel;\n+\n+\t/** The tag indicates whether it is waiting for additional floating buffers from the buffer pool. */\n+\t@GuardedBy(\"bufferQueue\")\n+\tprivate boolean isWaitingForFloatingBuffers;\n+\n+\t/** The total number of required buffers for the respective input channel. */\n+\t@GuardedBy(\"bufferQueue\")\n+\tprivate int numRequiredBuffers;\n+\n+\tpublic BufferManager(\n+\t\tMemorySegmentProvider globalPool,\n+\t\tInputChannel inputChannel,\n+\t\tint numRequiredBuffers) {\n+\n+\t\tthis.globalPool = checkNotNull(globalPool);\n+\t\tthis.inputChannel = checkNotNull(inputChannel);\n+\t\tcheckArgument(numRequiredBuffers >= 0);\n+\t\tthis.numRequiredBuffers = numRequiredBuffers;\n+\t}\n+\n+\t// ------------------------------------------------------------------------\n+\t// Buffer request\n+\t// ------------------------------------------------------------------------\n+\n+\t@Nullable\n+\tBuffer requestBuffer() {\n+\t\tsynchronized (bufferQueue) {\n+\t\t\treturn bufferQueue.takeBuffer();\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Requests exclusive buffers from the provider and returns the number of requested amount.\n+\t */\n+\tint requestExclusiveBuffers() throws IOException {\n+\t\tCollection<MemorySegment> segments = globalPool.requestMemorySegments();\n+\t\tcheckArgument(!segments.isEmpty(), \"The number of exclusive buffers per channel should be larger than 0.\");\n+\n+\t\tsynchronized (bufferQueue) {\n+\t\t\tfor (MemorySegment segment : segments) {\n+\t\t\t\tbufferQueue.addExclusiveBuffer(new NetworkBuffer(segment, this), numRequiredBuffers);\n+\t\t\t}\n+\t\t}\n+\t\treturn segments.size();\n+\t}\n+\n+\t/**\n+\t * Requests floating buffers from the buffer pool based on the given required amount, and returns the actual\n+\t * requested amount. If the required amount is not fully satisfied, it will register as a listener.\n+\t */\n+\tint requestFloatingBuffers(int numRequired) throws IOException {\n+\t\tint numRequestedBuffers = 0;\n+\t\tsynchronized (bufferQueue) {\n+\t\t\t// Similar to notifyBufferAvailable(), make sure that we never add a buffer after channel\n+\t\t\t// released all buffers via releaseAllResources().\n+\t\t\tif (inputChannel.isReleased()) {\n+\t\t\t\treturn numRequestedBuffers;\n+\t\t\t}\n+\n+\t\t\tnumRequiredBuffers = numRequired;\n+\n+\t\t\twhile (bufferQueue.getAvailableBufferSize() < numRequiredBuffers && !isWaitingForFloatingBuffers) {\n+\t\t\t\tBufferPool bufferPool = inputChannel.inputGate.getBufferPool();\n+\t\t\t\tBuffer buffer = bufferPool.requestBuffer();\n+\t\t\t\tif (buffer != null) {\n+\t\t\t\t\tbufferQueue.addFloatingBuffer(buffer);\n+\t\t\t\t\tnumRequestedBuffers++;\n+\t\t\t\t} else if (bufferPool.addBufferListener(this)) {\n+\t\t\t\t\tisWaitingForFloatingBuffers = true;\n+\t\t\t\t\tbreak;\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t\treturn numRequestedBuffers;\n+\t}\n+\n+\t// ------------------------------------------------------------------------\n+\t// Buffer recycle\n+\t// ------------------------------------------------------------------------\n+\n+\t/**\n+\t * Exclusive buffer is recycled to this channel manager directly and it may trigger return extra\n+\t * floating buffer based on <tt>numRequiredBuffers</tt>.\n+\t *\n+\t * @param segment The exclusive segment of this channel.\n+\t */\n+\t@Override\n+\tpublic void recycle(MemorySegment segment) {\n+\t\tint numAddedBuffers = 0;\n+\t\tsynchronized (bufferQueue) {\n+\t\t\ttry {\n+\t\t\t\t// Similar to notifyBufferAvailable(), make sure that we never add a buffer\n+\t\t\t\t// after channel released all buffers via releaseAllResources().\n+\t\t\t\tif (inputChannel.isReleased()) {\n+\t\t\t\t\tglobalPool.recycleMemorySegments(Collections.singletonList(segment));\n+\t\t\t\t} else {\n+\t\t\t\t\tnumAddedBuffers = bufferQueue.addExclusiveBuffer(new NetworkBuffer(segment, this), numRequiredBuffers);\n+\t\t\t\t}\n+\t\t\t} catch (Throwable t) {\n+\t\t\t\tExceptionUtils.rethrow(t);\n+\t\t\t}\n+\t\t}\n+\t\tinputChannel.notifyBufferAvailable(numAddedBuffers);\n+\t}\n+\n+\t/**\n+\t * Recycles all the exclusive and floating buffers from the given buffer queue.\n+\t */\n+\tvoid releaseAllBuffers(ArrayDeque<Buffer> buffers) throws IOException {\n+\t\t// Gather all exclusive buffers and recycle them to global pool in batch, because\n+\t\t// we do not want to trigger redistribution of buffers after each recycle.\n+\t\tfinal List<MemorySegment> exclusiveRecyclingSegments = new ArrayList<>();\n+\n+\t\tBuffer buffer;\n+\t\twhile ((buffer = buffers.poll()) != null) {\n+\t\t\tif (buffer.getRecycler() == this) {\n+\t\t\t\texclusiveRecyclingSegments.add(buffer.getMemorySegment());\n+\t\t\t} else {\n+\t\t\t\tbuffer.recycleBuffer();\n+\t\t\t}\n+\t\t}\n+\t\tsynchronized (bufferQueue) {\n+\t\t\tbufferQueue.releaseAll(exclusiveRecyclingSegments);\n+\t\t}\n+\n+\t\tif (exclusiveRecyclingSegments.size() > 0) {\n+\t\t\tglobalPool.recycleMemorySegments(exclusiveRecyclingSegments);\n+\t\t}\n+\t}\n+\n+\t// ------------------------------------------------------------------------\n+\t// Buffer listener notification\n+\t// ------------------------------------------------------------------------\n+\n+\t/**\n+\t * The buffer pool notifies this listener of an available floating buffer. If the listener is released or\n+\t * currently does not need extra buffers, the buffer should be returned to the buffer pool. Otherwise,\n+\t * the buffer will be added into the <tt>bufferQueue</tt>.\n+\t *\n+\t * @param buffer Buffer that becomes available in buffer pool.\n+\t * @return NotificationResult indicates whether this channel accepts the buffer and is waiting for\n+\t * more floating buffers.\n+\t */\n+\t@Override\n+\tpublic BufferListener.NotificationResult notifyBufferAvailable(Buffer buffer) {\n+\t\tBufferListener.NotificationResult notificationResult = BufferListener.NotificationResult.BUFFER_NOT_USED;\n+\t\tThrowable throwable = null;\n+\t\tsynchronized (bufferQueue) {\n+\t\t\ttry {\n+\t\t\t\tcheckState(isWaitingForFloatingBuffers, \"This channel should be waiting for floating buffers.\");\n+\n+\t\t\t\t// Important: make sure that we never add a buffer after releaseAllResources()\n+\t\t\t\t// released all buffers. Following scenarios exist:\n+\t\t\t\t// 1) releaseAllBuffers() already released buffers inside bufferQueue\n+\t\t\t\t// -> while isReleased is set correctly in InputChannel\n+\t\t\t\t// 2) releaseAllBuffers() did not yet release buffers from bufferQueue\n+\t\t\t\t// -> we may or may not have set isReleased yet but will always wait for the\n+\t\t\t\t// lock on bufferQueue to release buffers\n+\t\t\t\tif (inputChannel.isReleased() || bufferQueue.getAvailableBufferSize() >= numRequiredBuffers) {\n+\t\t\t\t\tisWaitingForFloatingBuffers = false;\n+\t\t\t\t\treturn notificationResult;\n+\t\t\t\t}\n+\n+\t\t\t\tbufferQueue.addFloatingBuffer(buffer);\n+\n+\t\t\t\tif (bufferQueue.getAvailableBufferSize() == numRequiredBuffers) {\n+\t\t\t\t\tisWaitingForFloatingBuffers = false;\n+\t\t\t\t\tnotificationResult = BufferListener.NotificationResult.BUFFER_USED_NO_NEED_MORE;\n+\t\t\t\t} else {\n+\t\t\t\t\tnotificationResult = BufferListener.NotificationResult.BUFFER_USED_NEED_MORE;\n+\t\t\t\t}\n+\t\t\t} catch (Throwable t) {\n+\t\t\t\tthrowable = t;\n+\t\t\t}\n+\t\t}\n+\n+\t\tif (throwable != null) {\n+\t\t\tinputChannel.setError(throwable);\n+\t\t} else if (notificationResult != NotificationResult.BUFFER_NOT_USED) {\n+\t\t\tinputChannel.notifyBufferAvailable(1);\n+\t\t}\n+\t\treturn notificationResult;\n+\t}\n+\n+\t@Override\n+\tpublic void notifyBufferDestroyed() {\n+\t\t// Nothing to do actually.\n+\t}\n+\n+\t// ------------------------------------------------------------------------\n+\t// Getter properties\n+\t// ------------------------------------------------------------------------\n+\n+\tint getNumberOfRequiredBuffers() {\n+\t\treturn numRequiredBuffers;\n+\t}\n+\n+\t@VisibleForTesting\n+\tboolean isWaitingForFloatingBuffers() {\n+\t\treturn isWaitingForFloatingBuffers;\n+\t}\n+\n+\tint getNumberOfAvailableBuffers() {\n+\t\tsynchronized (bufferQueue) {\n+\t\t\treturn bufferQueue.getAvailableBufferSize();\n+\t\t}\n+\t}\n+\n+\tint getNumberOfAvailableExclusiveBuffers() {\n+\t\treturn bufferQueue.exclusiveBuffers.size();\n+\t}\n+\n+\tint getNumberOfAvailableFloatingBuffers() {\n+\t\treturn bufferQueue.floatingBuffers.size();\n+\t}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "52f011acf79e07ccefa2eb6db22f2835a100e9b4"}, "originalPosition": 273}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYxMDE4MzA4OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxMDoxMDoxMFrOGP6IbQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxNDoyMDowM1rOGQCkGw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTMzNDI1Mw==", "bodyText": "I think this method is bugged (unsychronized and used in the multi threaded context), however it seems like it's result is never used in the production code - InputChannel#getNextBuffer doesn't need to return buffersInBacklog, am I right? So we could drop it? If so, we could do it as a follow up ticket, as this is already a pre-existing issue.", "url": "https://github.com/apache/flink/pull/11687#discussion_r419334253", "createdAt": "2020-05-04T10:10:10Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "diffHunk": "@@ -321,111 +274,43 @@ private void notifyCreditAvailable() {\n \t\tpartitionRequestClient.notifyCreditAvailable(this);\n \t}\n \n-\t/**\n-\t * Exclusive buffer is recycled to this input channel directly and it may trigger return extra\n-\t * floating buffer and notify increased credit to the producer.\n-\t *\n-\t * @param segment The exclusive segment of this channel.\n-\t */\n-\t@Override\n-\tpublic void recycle(MemorySegment segment) {\n-\t\tint numAddedBuffers;\n-\n-\t\tsynchronized (bufferQueue) {\n-\t\t\t// Similar to notifyBufferAvailable(), make sure that we never add a buffer\n-\t\t\t// after releaseAllResources() released all buffers (see below for details).\n-\t\t\tif (isReleased.get()) {\n-\t\t\t\ttry {\n-\t\t\t\t\tmemorySegmentProvider.recycleMemorySegments(Collections.singletonList(segment));\n-\t\t\t\t\treturn;\n-\t\t\t\t} catch (Throwable t) {\n-\t\t\t\t\tExceptionUtils.rethrow(t);\n-\t\t\t\t}\n-\t\t\t}\n-\t\t\tnumAddedBuffers = bufferQueue.addExclusiveBuffer(new NetworkBuffer(segment, this), numRequiredBuffers);\n-\t\t}\n-\n-\t\tif (numAddedBuffers > 0 && unannouncedCredit.getAndAdd(numAddedBuffers) == 0) {\n-\t\t\tnotifyCreditAvailable();\n-\t\t}\n-\t}\n-\n \tpublic int getNumberOfAvailableBuffers() {\n-\t\tsynchronized (bufferQueue) {\n-\t\t\treturn bufferQueue.getAvailableBufferSize();\n-\t\t}\n+\t\treturn bufferManager.getNumberOfAvailableBuffers();\n \t}\n \n \tpublic int getNumberOfRequiredBuffers() {\n-\t\treturn numRequiredBuffers;\n+\t\treturn bufferManager.getNumberOfRequiredBuffers();\n \t}\n \n \tpublic int getSenderBacklog() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "52f011acf79e07ccefa2eb6db22f2835a100e9b4"}, "originalPosition": 185}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTQ3MjQxMQ==", "bodyText": "Exactly as you said, we can remove it as a separate ticket or even hotfix commit in this PR if you think so.", "url": "https://github.com/apache/flink/pull/11687#discussion_r419472411", "createdAt": "2020-05-04T14:20:03Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "diffHunk": "@@ -321,111 +274,43 @@ private void notifyCreditAvailable() {\n \t\tpartitionRequestClient.notifyCreditAvailable(this);\n \t}\n \n-\t/**\n-\t * Exclusive buffer is recycled to this input channel directly and it may trigger return extra\n-\t * floating buffer and notify increased credit to the producer.\n-\t *\n-\t * @param segment The exclusive segment of this channel.\n-\t */\n-\t@Override\n-\tpublic void recycle(MemorySegment segment) {\n-\t\tint numAddedBuffers;\n-\n-\t\tsynchronized (bufferQueue) {\n-\t\t\t// Similar to notifyBufferAvailable(), make sure that we never add a buffer\n-\t\t\t// after releaseAllResources() released all buffers (see below for details).\n-\t\t\tif (isReleased.get()) {\n-\t\t\t\ttry {\n-\t\t\t\t\tmemorySegmentProvider.recycleMemorySegments(Collections.singletonList(segment));\n-\t\t\t\t\treturn;\n-\t\t\t\t} catch (Throwable t) {\n-\t\t\t\t\tExceptionUtils.rethrow(t);\n-\t\t\t\t}\n-\t\t\t}\n-\t\t\tnumAddedBuffers = bufferQueue.addExclusiveBuffer(new NetworkBuffer(segment, this), numRequiredBuffers);\n-\t\t}\n-\n-\t\tif (numAddedBuffers > 0 && unannouncedCredit.getAndAdd(numAddedBuffers) == 0) {\n-\t\t\tnotifyCreditAvailable();\n-\t\t}\n-\t}\n-\n \tpublic int getNumberOfAvailableBuffers() {\n-\t\tsynchronized (bufferQueue) {\n-\t\t\treturn bufferQueue.getAvailableBufferSize();\n-\t\t}\n+\t\treturn bufferManager.getNumberOfAvailableBuffers();\n \t}\n \n \tpublic int getNumberOfRequiredBuffers() {\n-\t\treturn numRequiredBuffers;\n+\t\treturn bufferManager.getNumberOfRequiredBuffers();\n \t}\n \n \tpublic int getSenderBacklog() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTMzNDI1Mw=="}, "originalCommit": {"oid": "52f011acf79e07ccefa2eb6db22f2835a100e9b4"}, "originalPosition": 185}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYxMDIwNTA0OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxMDoxNzoyNlrOGP6V5w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQwODoyNzo0NlrOGQfU4w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTMzNzcwMw==", "bodyText": "This cyclic dependency can be an issue for refactoring/reusing the code. Can not we cut it? As it is, you are trying to decouple buffer manager from input channel, but after all they are still very strongly coupled and both have a shared state.", "url": "https://github.com/apache/flink/pull/11687#discussion_r419337703", "createdAt": "2020-05-04T10:17:26Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.io.network.partition.consumer;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.core.memory.MemorySegment;\n+import org.apache.flink.core.memory.MemorySegmentProvider;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferListener;\n+import org.apache.flink.runtime.io.network.buffer.BufferPool;\n+import org.apache.flink.runtime.io.network.buffer.BufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.util.ExceptionUtils;\n+\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.io.IOException;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+\n+import static org.apache.flink.util.Preconditions.checkArgument;\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * The general buffer manager used by {@link InputChannel} to request/recycle\n+ * exclusive or floating buffers.\n+ */\n+public class BufferManager implements BufferListener, BufferRecycler {\n+\n+\t/** The available buffer queue wraps both exclusive and requested floating buffers. */\n+\tprivate final AvailableBufferQueue bufferQueue = new AvailableBufferQueue();\n+\n+\t/** The buffer provider for requesting exclusive buffers. */\n+\tprivate final MemorySegmentProvider globalPool;\n+\n+\t/** The input channel to own this buffer manager. */\n+\tprivate final InputChannel inputChannel;\n+\n+\t/** The tag indicates whether it is waiting for additional floating buffers from the buffer pool. */\n+\t@GuardedBy(\"bufferQueue\")\n+\tprivate boolean isWaitingForFloatingBuffers;\n+\n+\t/** The total number of required buffers for the respective input channel. */\n+\t@GuardedBy(\"bufferQueue\")\n+\tprivate int numRequiredBuffers;\n+\n+\tpublic BufferManager(\n+\t\tMemorySegmentProvider globalPool,\n+\t\tInputChannel inputChannel,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "52f011acf79e07ccefa2eb6db22f2835a100e9b4"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTQ4NzAzNQ==", "bodyText": "yeah, I also noticed this cycle dependency issue while implementation. And I also tried to cut it if easy to go. But actually I found it needs pay more efforts, because there are many interactions among InputChannel and BufferManager.\n\n\nBufferManager relies on BufferPool, then while SingleInputGate#setup, it needs to register the respective BufferPool for every InputChannel#BufferManager. This is the main concern to bypass this issue at current implementation.\n\n\nWe also need to maintain the  separate isReleased variable inside BufferManager to not rely on InputChannel#isReleased.\n\n\nWe might need another separate interface which would be implemented by InputChannel, then we can decouple another two depending methods InputChannel#onError and InputChannel#notifyBufferAvailable.", "url": "https://github.com/apache/flink/pull/11687#discussion_r419487035", "createdAt": "2020-05-04T14:39:27Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.io.network.partition.consumer;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.core.memory.MemorySegment;\n+import org.apache.flink.core.memory.MemorySegmentProvider;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferListener;\n+import org.apache.flink.runtime.io.network.buffer.BufferPool;\n+import org.apache.flink.runtime.io.network.buffer.BufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.util.ExceptionUtils;\n+\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.io.IOException;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+\n+import static org.apache.flink.util.Preconditions.checkArgument;\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * The general buffer manager used by {@link InputChannel} to request/recycle\n+ * exclusive or floating buffers.\n+ */\n+public class BufferManager implements BufferListener, BufferRecycler {\n+\n+\t/** The available buffer queue wraps both exclusive and requested floating buffers. */\n+\tprivate final AvailableBufferQueue bufferQueue = new AvailableBufferQueue();\n+\n+\t/** The buffer provider for requesting exclusive buffers. */\n+\tprivate final MemorySegmentProvider globalPool;\n+\n+\t/** The input channel to own this buffer manager. */\n+\tprivate final InputChannel inputChannel;\n+\n+\t/** The tag indicates whether it is waiting for additional floating buffers from the buffer pool. */\n+\t@GuardedBy(\"bufferQueue\")\n+\tprivate boolean isWaitingForFloatingBuffers;\n+\n+\t/** The total number of required buffers for the respective input channel. */\n+\t@GuardedBy(\"bufferQueue\")\n+\tprivate int numRequiredBuffers;\n+\n+\tpublic BufferManager(\n+\t\tMemorySegmentProvider globalPool,\n+\t\tInputChannel inputChannel,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTMzNzcwMw=="}, "originalCommit": {"oid": "52f011acf79e07ccefa2eb6db22f2835a100e9b4"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTk0MzY1MQ==", "bodyText": "I played a bit with this code and maybe it's not perfect, but it's at least a bit better (after separating BufferManager from RemoteInputChannel), so we can keep it as it is. I don't know how to fix it properly though.", "url": "https://github.com/apache/flink/pull/11687#discussion_r419943651", "createdAt": "2020-05-05T08:27:46Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.io.network.partition.consumer;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.core.memory.MemorySegment;\n+import org.apache.flink.core.memory.MemorySegmentProvider;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferListener;\n+import org.apache.flink.runtime.io.network.buffer.BufferPool;\n+import org.apache.flink.runtime.io.network.buffer.BufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.util.ExceptionUtils;\n+\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.io.IOException;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+\n+import static org.apache.flink.util.Preconditions.checkArgument;\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * The general buffer manager used by {@link InputChannel} to request/recycle\n+ * exclusive or floating buffers.\n+ */\n+public class BufferManager implements BufferListener, BufferRecycler {\n+\n+\t/** The available buffer queue wraps both exclusive and requested floating buffers. */\n+\tprivate final AvailableBufferQueue bufferQueue = new AvailableBufferQueue();\n+\n+\t/** The buffer provider for requesting exclusive buffers. */\n+\tprivate final MemorySegmentProvider globalPool;\n+\n+\t/** The input channel to own this buffer manager. */\n+\tprivate final InputChannel inputChannel;\n+\n+\t/** The tag indicates whether it is waiting for additional floating buffers from the buffer pool. */\n+\t@GuardedBy(\"bufferQueue\")\n+\tprivate boolean isWaitingForFloatingBuffers;\n+\n+\t/** The total number of required buffers for the respective input channel. */\n+\t@GuardedBy(\"bufferQueue\")\n+\tprivate int numRequiredBuffers;\n+\n+\tpublic BufferManager(\n+\t\tMemorySegmentProvider globalPool,\n+\t\tInputChannel inputChannel,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTMzNzcwMw=="}, "originalCommit": {"oid": "52f011acf79e07ccefa2eb6db22f2835a100e9b4"}, "originalPosition": 70}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYxMDIyNjc5OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxMDoyNDo1N1rOGP6j5g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxNDo0MjoyOFrOGQDllw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTM0MTI4Ng==", "bodyText": "This should probably be injected in the constructor", "url": "https://github.com/apache/flink/pull/11687#discussion_r419341286", "createdAt": "2020-05-04T10:24:57Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.io.network.partition.consumer;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.core.memory.MemorySegment;\n+import org.apache.flink.core.memory.MemorySegmentProvider;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferListener;\n+import org.apache.flink.runtime.io.network.buffer.BufferPool;\n+import org.apache.flink.runtime.io.network.buffer.BufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.util.ExceptionUtils;\n+\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.io.IOException;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+\n+import static org.apache.flink.util.Preconditions.checkArgument;\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * The general buffer manager used by {@link InputChannel} to request/recycle\n+ * exclusive or floating buffers.\n+ */\n+public class BufferManager implements BufferListener, BufferRecycler {\n+\n+\t/** The available buffer queue wraps both exclusive and requested floating buffers. */\n+\tprivate final AvailableBufferQueue bufferQueue = new AvailableBufferQueue();\n+\n+\t/** The buffer provider for requesting exclusive buffers. */\n+\tprivate final MemorySegmentProvider globalPool;\n+\n+\t/** The input channel to own this buffer manager. */\n+\tprivate final InputChannel inputChannel;\n+\n+\t/** The tag indicates whether it is waiting for additional floating buffers from the buffer pool. */\n+\t@GuardedBy(\"bufferQueue\")\n+\tprivate boolean isWaitingForFloatingBuffers;\n+\n+\t/** The total number of required buffers for the respective input channel. */\n+\t@GuardedBy(\"bufferQueue\")\n+\tprivate int numRequiredBuffers;\n+\n+\tpublic BufferManager(\n+\t\tMemorySegmentProvider globalPool,\n+\t\tInputChannel inputChannel,\n+\t\tint numRequiredBuffers) {\n+\n+\t\tthis.globalPool = checkNotNull(globalPool);\n+\t\tthis.inputChannel = checkNotNull(inputChannel);\n+\t\tcheckArgument(numRequiredBuffers >= 0);\n+\t\tthis.numRequiredBuffers = numRequiredBuffers;\n+\t}\n+\n+\t// ------------------------------------------------------------------------\n+\t// Buffer request\n+\t// ------------------------------------------------------------------------\n+\n+\t@Nullable\n+\tBuffer requestBuffer() {\n+\t\tsynchronized (bufferQueue) {\n+\t\t\treturn bufferQueue.takeBuffer();\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Requests exclusive buffers from the provider and returns the number of requested amount.\n+\t */\n+\tint requestExclusiveBuffers() throws IOException {\n+\t\tCollection<MemorySegment> segments = globalPool.requestMemorySegments();\n+\t\tcheckArgument(!segments.isEmpty(), \"The number of exclusive buffers per channel should be larger than 0.\");\n+\n+\t\tsynchronized (bufferQueue) {\n+\t\t\tfor (MemorySegment segment : segments) {\n+\t\t\t\tbufferQueue.addExclusiveBuffer(new NetworkBuffer(segment, this), numRequiredBuffers);\n+\t\t\t}\n+\t\t}\n+\t\treturn segments.size();\n+\t}\n+\n+\t/**\n+\t * Requests floating buffers from the buffer pool based on the given required amount, and returns the actual\n+\t * requested amount. If the required amount is not fully satisfied, it will register as a listener.\n+\t */\n+\tint requestFloatingBuffers(int numRequired) throws IOException {\n+\t\tint numRequestedBuffers = 0;\n+\t\tsynchronized (bufferQueue) {\n+\t\t\t// Similar to notifyBufferAvailable(), make sure that we never add a buffer after channel\n+\t\t\t// released all buffers via releaseAllResources().\n+\t\t\tif (inputChannel.isReleased()) {\n+\t\t\t\treturn numRequestedBuffers;\n+\t\t\t}\n+\n+\t\t\tnumRequiredBuffers = numRequired;\n+\n+\t\t\twhile (bufferQueue.getAvailableBufferSize() < numRequiredBuffers && !isWaitingForFloatingBuffers) {\n+\t\t\t\tBufferPool bufferPool = inputChannel.inputGate.getBufferPool();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "52f011acf79e07ccefa2eb6db22f2835a100e9b4"}, "originalPosition": 121}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTQ4OTE3NQ==", "bodyText": "I also hope so, but the truth is not, because we can not get the proper BufferPool while constructing the BufferManager.\nThe BufferPool is created in SingleInputGate#setup, and it is also the main reason of relying on InputChannel component in BufferManager to bypass this issue.", "url": "https://github.com/apache/flink/pull/11687#discussion_r419489175", "createdAt": "2020-05-04T14:42:28Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.io.network.partition.consumer;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.core.memory.MemorySegment;\n+import org.apache.flink.core.memory.MemorySegmentProvider;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferListener;\n+import org.apache.flink.runtime.io.network.buffer.BufferPool;\n+import org.apache.flink.runtime.io.network.buffer.BufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.util.ExceptionUtils;\n+\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.io.IOException;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+\n+import static org.apache.flink.util.Preconditions.checkArgument;\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * The general buffer manager used by {@link InputChannel} to request/recycle\n+ * exclusive or floating buffers.\n+ */\n+public class BufferManager implements BufferListener, BufferRecycler {\n+\n+\t/** The available buffer queue wraps both exclusive and requested floating buffers. */\n+\tprivate final AvailableBufferQueue bufferQueue = new AvailableBufferQueue();\n+\n+\t/** The buffer provider for requesting exclusive buffers. */\n+\tprivate final MemorySegmentProvider globalPool;\n+\n+\t/** The input channel to own this buffer manager. */\n+\tprivate final InputChannel inputChannel;\n+\n+\t/** The tag indicates whether it is waiting for additional floating buffers from the buffer pool. */\n+\t@GuardedBy(\"bufferQueue\")\n+\tprivate boolean isWaitingForFloatingBuffers;\n+\n+\t/** The total number of required buffers for the respective input channel. */\n+\t@GuardedBy(\"bufferQueue\")\n+\tprivate int numRequiredBuffers;\n+\n+\tpublic BufferManager(\n+\t\tMemorySegmentProvider globalPool,\n+\t\tInputChannel inputChannel,\n+\t\tint numRequiredBuffers) {\n+\n+\t\tthis.globalPool = checkNotNull(globalPool);\n+\t\tthis.inputChannel = checkNotNull(inputChannel);\n+\t\tcheckArgument(numRequiredBuffers >= 0);\n+\t\tthis.numRequiredBuffers = numRequiredBuffers;\n+\t}\n+\n+\t// ------------------------------------------------------------------------\n+\t// Buffer request\n+\t// ------------------------------------------------------------------------\n+\n+\t@Nullable\n+\tBuffer requestBuffer() {\n+\t\tsynchronized (bufferQueue) {\n+\t\t\treturn bufferQueue.takeBuffer();\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Requests exclusive buffers from the provider and returns the number of requested amount.\n+\t */\n+\tint requestExclusiveBuffers() throws IOException {\n+\t\tCollection<MemorySegment> segments = globalPool.requestMemorySegments();\n+\t\tcheckArgument(!segments.isEmpty(), \"The number of exclusive buffers per channel should be larger than 0.\");\n+\n+\t\tsynchronized (bufferQueue) {\n+\t\t\tfor (MemorySegment segment : segments) {\n+\t\t\t\tbufferQueue.addExclusiveBuffer(new NetworkBuffer(segment, this), numRequiredBuffers);\n+\t\t\t}\n+\t\t}\n+\t\treturn segments.size();\n+\t}\n+\n+\t/**\n+\t * Requests floating buffers from the buffer pool based on the given required amount, and returns the actual\n+\t * requested amount. If the required amount is not fully satisfied, it will register as a listener.\n+\t */\n+\tint requestFloatingBuffers(int numRequired) throws IOException {\n+\t\tint numRequestedBuffers = 0;\n+\t\tsynchronized (bufferQueue) {\n+\t\t\t// Similar to notifyBufferAvailable(), make sure that we never add a buffer after channel\n+\t\t\t// released all buffers via releaseAllResources().\n+\t\t\tif (inputChannel.isReleased()) {\n+\t\t\t\treturn numRequestedBuffers;\n+\t\t\t}\n+\n+\t\t\tnumRequiredBuffers = numRequired;\n+\n+\t\t\twhile (bufferQueue.getAvailableBufferSize() < numRequiredBuffers && !isWaitingForFloatingBuffers) {\n+\t\t\t\tBufferPool bufferPool = inputChannel.inputGate.getBufferPool();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTM0MTI4Ng=="}, "originalCommit": {"oid": "52f011acf79e07ccefa2eb6db22f2835a100e9b4"}, "originalPosition": 121}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYxMDI2MjI5OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxMDozNjo1N1rOGP66GQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQxNDoyMDo0NFrOGQrwRw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTM0Njk2OQ==", "bodyText": "It would be better to inject this field instead of relaying on even tighter coupling with inputChannel.", "url": "https://github.com/apache/flink/pull/11687#discussion_r419346969", "createdAt": "2020-05-04T10:36:57Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "diffHunk": "@@ -65,14 +65,10 @@\n \t@GuardedBy(\"bufferQueue\")\n \tprivate int numRequiredBuffers;\n \n-\tpublic BufferManager(\n-\t\tMemorySegmentProvider globalPool,\n-\t\tInputChannel inputChannel,\n-\t\tint numRequiredBuffers) {\n-\n-\t\tthis.globalPool = checkNotNull(globalPool);\n-\t\tthis.inputChannel = checkNotNull(inputChannel);\n+\tpublic BufferManager(InputChannel inputChannel, int numRequiredBuffers) {\n \t\tcheckArgument(numRequiredBuffers >= 0);\n+\t\tthis.inputChannel = checkNotNull(inputChannel);\n+\t\tthis.globalPool = inputChannel.inputGate.getMemorySegmentProvider();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d1da882e9fd7249eb5b78752bc6e8e104e6633cf"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTQ5MDY0Mw==", "bodyText": "Actually I injected it in the constructor in previous version, but since we can not get ride of InputChannel completed in BufferManager as above said, then I reduce this unnecessary argument in constructor.", "url": "https://github.com/apache/flink/pull/11687#discussion_r419490643", "createdAt": "2020-05-04T14:44:30Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "diffHunk": "@@ -65,14 +65,10 @@\n \t@GuardedBy(\"bufferQueue\")\n \tprivate int numRequiredBuffers;\n \n-\tpublic BufferManager(\n-\t\tMemorySegmentProvider globalPool,\n-\t\tInputChannel inputChannel,\n-\t\tint numRequiredBuffers) {\n-\n-\t\tthis.globalPool = checkNotNull(globalPool);\n-\t\tthis.inputChannel = checkNotNull(inputChannel);\n+\tpublic BufferManager(InputChannel inputChannel, int numRequiredBuffers) {\n \t\tcheckArgument(numRequiredBuffers >= 0);\n+\t\tthis.inputChannel = checkNotNull(inputChannel);\n+\t\tthis.globalPool = inputChannel.inputGate.getMemorySegmentProvider();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTM0Njk2OQ=="}, "originalCommit": {"oid": "d1da882e9fd7249eb5b78752bc6e8e104e6633cf"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTk0NTE4OQ==", "bodyText": "I think it would be better to limit the reliance on this faulty cyclic dependency. That way it will be easier to get rid of it in the future.", "url": "https://github.com/apache/flink/pull/11687#discussion_r419945189", "createdAt": "2020-05-05T08:30:43Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "diffHunk": "@@ -65,14 +65,10 @@\n \t@GuardedBy(\"bufferQueue\")\n \tprivate int numRequiredBuffers;\n \n-\tpublic BufferManager(\n-\t\tMemorySegmentProvider globalPool,\n-\t\tInputChannel inputChannel,\n-\t\tint numRequiredBuffers) {\n-\n-\t\tthis.globalPool = checkNotNull(globalPool);\n-\t\tthis.inputChannel = checkNotNull(inputChannel);\n+\tpublic BufferManager(InputChannel inputChannel, int numRequiredBuffers) {\n \t\tcheckArgument(numRequiredBuffers >= 0);\n+\t\tthis.inputChannel = checkNotNull(inputChannel);\n+\t\tthis.globalPool = inputChannel.inputGate.getMemorySegmentProvider();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTM0Njk2OQ=="}, "originalCommit": {"oid": "d1da882e9fd7249eb5b78752bc6e8e104e6633cf"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDE0NzI3MQ==", "bodyText": "Makes sense", "url": "https://github.com/apache/flink/pull/11687#discussion_r420147271", "createdAt": "2020-05-05T14:20:44Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/BufferManager.java", "diffHunk": "@@ -65,14 +65,10 @@\n \t@GuardedBy(\"bufferQueue\")\n \tprivate int numRequiredBuffers;\n \n-\tpublic BufferManager(\n-\t\tMemorySegmentProvider globalPool,\n-\t\tInputChannel inputChannel,\n-\t\tint numRequiredBuffers) {\n-\n-\t\tthis.globalPool = checkNotNull(globalPool);\n-\t\tthis.inputChannel = checkNotNull(inputChannel);\n+\tpublic BufferManager(InputChannel inputChannel, int numRequiredBuffers) {\n \t\tcheckArgument(numRequiredBuffers >= 0);\n+\t\tthis.inputChannel = checkNotNull(inputChannel);\n+\t\tthis.globalPool = inputChannel.inputGate.getMemorySegmentProvider();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTM0Njk2OQ=="}, "originalCommit": {"oid": "d1da882e9fd7249eb5b78752bc6e8e104e6633cf"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYxMDI3Nzk5OnYy", "diffSide": "RIGHT", "path": "flink-tests/src/test/java/org/apache/flink/test/streaming/runtime/BackPressureITCase.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxMDo0Mjo1N1rOGP7EJg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxNDo1MDoyN1rOGQD8Rg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTM0OTU0Mg==", "bodyText": "Why 6 instead of (NUM_TASKS + 3)? And also why has it increased?", "url": "https://github.com/apache/flink/pull/11687#discussion_r419349542", "createdAt": "2020-05-04T10:42:57Z", "author": {"login": "pnowojski"}, "path": "flink-tests/src/test/java/org/apache/flink/test/streaming/runtime/BackPressureITCase.java", "diffHunk": "@@ -94,7 +94,7 @@ private static Configuration createNetworkBufferConfiguration() {\n \t\tfinal Configuration configuration = new Configuration();\n \n \t\tfinal int memorySegmentSizeKb = 32;\n-\t\tfinal MemorySize networkBuffersMemory = MemorySize.parse(memorySegmentSizeKb * (NUM_TASKS + 2) + \"kb\");\n+\t\tfinal MemorySize networkBuffersMemory = MemorySize.parse(memorySegmentSizeKb * 6 + \"kb\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd26e4d1aae1bfb87dee603ddd51afda409a46df"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTQ5NDk4Mg==", "bodyText": "In previous way the LocalBufferPool for SingleInputGate has 0 required buffers, but now we adjust it to guarantee at-least one required buffer for local channel state recovery.\nIn this ITCase,  the exclusive buffers for map and sink vertex should be 2 * 2 , and the floating buffers in LocalBufferPool should be 2 * 1, then the total minimum buffer amount should be 6.", "url": "https://github.com/apache/flink/pull/11687#discussion_r419494982", "createdAt": "2020-05-04T14:50:27Z", "author": {"login": "zhijiangW"}, "path": "flink-tests/src/test/java/org/apache/flink/test/streaming/runtime/BackPressureITCase.java", "diffHunk": "@@ -94,7 +94,7 @@ private static Configuration createNetworkBufferConfiguration() {\n \t\tfinal Configuration configuration = new Configuration();\n \n \t\tfinal int memorySegmentSizeKb = 32;\n-\t\tfinal MemorySize networkBuffersMemory = MemorySize.parse(memorySegmentSizeKb * (NUM_TASKS + 2) + \"kb\");\n+\t\tfinal MemorySize networkBuffersMemory = MemorySize.parse(memorySegmentSizeKb * 6 + \"kb\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTM0OTU0Mg=="}, "originalCommit": {"oid": "bd26e4d1aae1bfb87dee603ddd51afda409a46df"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYxMDI4NDY5OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/LocalInputChannel.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxMDo0NToyNFrOGP7IaQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQxNDozODozOVrOGQslrQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTM1MDYzMw==", "bodyText": "Does it mean that for every LocalInputChannel after recovery we are wasting a single buffer?\nedit: Ok, I see, that it's being released after end of reading from recovered state, but this is very mangled and hard to understand :(", "url": "https://github.com/apache/flink/pull/11687#discussion_r419350633", "createdAt": "2020-05-04T10:45:24Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/LocalInputChannel.java", "diffHunk": "@@ -87,10 +90,14 @@ public LocalInputChannel(\n \t\tint maxBackoff,\n \t\tInputChannelMetrics metrics) {\n \n-\t\tsuper(inputGate, channelIndex, partitionId, initialBackoff, maxBackoff, metrics.getNumBytesInLocalCounter(), metrics.getNumBuffersInLocalCounter());\n+\t\tsuper(inputGate, channelIndex, partitionId, initialBackoff, maxBackoff, metrics);\n \n \t\tthis.partitionManager = checkNotNull(partitionManager);\n \t\tthis.taskEventPublisher = checkNotNull(taskEventPublisher);\n+\t\t// In most cases we only need one buffer for reading recovered state except for very large record.\n+\t\t// Then only one floating buffer is required. Even though we need more buffers for recovery for\n+\t\t// large record, it only increases some interactions with pool.\n+\t\tthis.bufferManager = new BufferManager(this, 1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd26e4d1aae1bfb87dee603ddd51afda409a46df"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTUwMjMwMQ==", "bodyText": "Yes, I agree it is a bit hard to understand.\nThe numRequiredBuffers factor is only the complex point of this buffer manager model for getting a bit optimization. Actually we can give any initial value for numRequiredBuffers (e.g. 0) for unifying the local and remote channels.  And ideally we should adjust this value based on how many total channel states are under unspilling exactly like the concept of backlog in credit-based mode.\nActually any value for numRequiredBuffers can work correctly now and the only cost is increasing some unnecessary interactions between BufferManager and LocalBufferPool.\nI am really a bit torn here when implementation whether to retain this optimization.", "url": "https://github.com/apache/flink/pull/11687#discussion_r419502301", "createdAt": "2020-05-04T15:00:11Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/LocalInputChannel.java", "diffHunk": "@@ -87,10 +90,14 @@ public LocalInputChannel(\n \t\tint maxBackoff,\n \t\tInputChannelMetrics metrics) {\n \n-\t\tsuper(inputGate, channelIndex, partitionId, initialBackoff, maxBackoff, metrics.getNumBytesInLocalCounter(), metrics.getNumBuffersInLocalCounter());\n+\t\tsuper(inputGate, channelIndex, partitionId, initialBackoff, maxBackoff, metrics);\n \n \t\tthis.partitionManager = checkNotNull(partitionManager);\n \t\tthis.taskEventPublisher = checkNotNull(taskEventPublisher);\n+\t\t// In most cases we only need one buffer for reading recovered state except for very large record.\n+\t\t// Then only one floating buffer is required. Even though we need more buffers for recovery for\n+\t\t// large record, it only increases some interactions with pool.\n+\t\tthis.bufferManager = new BufferManager(this, 1);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTM1MDYzMw=="}, "originalCommit": {"oid": "bd26e4d1aae1bfb87dee603ddd51afda409a46df"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTk0MTQ1Nw==", "bodyText": "What do you mean by:\n\nActually any value for numRequiredBuffers can work correctly now and the only cost is increasing some unnecessary interactions between BufferManager and LocalBufferPool.\n\n? That with numRequiredBuffers = 0, the only difference would be that there are not floating buffers initially assigned and they need to be ramped up as the backlog increases?", "url": "https://github.com/apache/flink/pull/11687#discussion_r419941457", "createdAt": "2020-05-05T08:23:57Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/LocalInputChannel.java", "diffHunk": "@@ -87,10 +90,14 @@ public LocalInputChannel(\n \t\tint maxBackoff,\n \t\tInputChannelMetrics metrics) {\n \n-\t\tsuper(inputGate, channelIndex, partitionId, initialBackoff, maxBackoff, metrics.getNumBytesInLocalCounter(), metrics.getNumBuffersInLocalCounter());\n+\t\tsuper(inputGate, channelIndex, partitionId, initialBackoff, maxBackoff, metrics);\n \n \t\tthis.partitionManager = checkNotNull(partitionManager);\n \t\tthis.taskEventPublisher = checkNotNull(taskEventPublisher);\n+\t\t// In most cases we only need one buffer for reading recovered state except for very large record.\n+\t\t// Then only one floating buffer is required. Even though we need more buffers for recovery for\n+\t\t// large record, it only increases some interactions with pool.\n+\t\tthis.bufferManager = new BufferManager(this, 1);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTM1MDYzMw=="}, "originalCommit": {"oid": "bd26e4d1aae1bfb87dee603ddd51afda409a46df"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDE2MDk0MQ==", "bodyText": "I mean we can give any initial numRequiredBuffers actually, e.g. 0. Then while requesting floating buffers from buffer pool in practice, it might have two different paths:\n\n\nGet the available buffer right now from buffer pool.\n\n\nNo available buffer from buffer pool now, then it will register listener to buffer pool for later notification. For this process we should give a proper value of numRequiredBuffers. As long as this value is more than 0, it can work correctly.\n\n\nIt is better to give some detail examples to explain how numRequiredBuffers works differently in practice.\nE.g. numRequiredBuffers is set to 1 for RemoteInputChannel. When the exclusive buffers are processed and recycled back to RemoteInputChannel, then the current available amount might be 2 which is more than the numRequiredBuffers (1). So when the floating buffers are processed and recycled to LocalBufferPool, then it will notify the listener (RemoteInputChannel) of available buffers. But the RemoteInputChannel already has enough buffers now, so it will not accept this floating buffer to cause waste efforts of register & notify.\nBut if we give a larger numRequiredBuffers,  then we only need to register listener once. After that as long as the floating buffers are processed and recycled, they will be notified to RemoteInputChannel and be accepted to reuse future. So it might reduce more interactions between RemoteInputChannel and LocalBufferPool in practice. Especially for the channel state recovery case, it makes sense to try to occupy all the floating buffers from LocalBufferPool because only one channel is unspilling at the same time.", "url": "https://github.com/apache/flink/pull/11687#discussion_r420160941", "createdAt": "2020-05-05T14:38:39Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/LocalInputChannel.java", "diffHunk": "@@ -87,10 +90,14 @@ public LocalInputChannel(\n \t\tint maxBackoff,\n \t\tInputChannelMetrics metrics) {\n \n-\t\tsuper(inputGate, channelIndex, partitionId, initialBackoff, maxBackoff, metrics.getNumBytesInLocalCounter(), metrics.getNumBuffersInLocalCounter());\n+\t\tsuper(inputGate, channelIndex, partitionId, initialBackoff, maxBackoff, metrics);\n \n \t\tthis.partitionManager = checkNotNull(partitionManager);\n \t\tthis.taskEventPublisher = checkNotNull(taskEventPublisher);\n+\t\t// In most cases we only need one buffer for reading recovered state except for very large record.\n+\t\t// Then only one floating buffer is required. Even though we need more buffers for recovery for\n+\t\t// large record, it only increases some interactions with pool.\n+\t\tthis.bufferManager = new BufferManager(this, 1);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTM1MDYzMw=="}, "originalCommit": {"oid": "bd26e4d1aae1bfb87dee603ddd51afda409a46df"}, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYxMDQ4ODE5OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/LocalInputChannel.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxMTo1Njo0OFrOGP9Fuw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxNTowOToxM1rOGQEyVA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTM4MjcxNQ==", "bodyText": "Having to go everything through getRecoveredStateBuffer() every time is not very clean.", "url": "https://github.com/apache/flink/pull/11687#discussion_r419382715", "createdAt": "2020-05-04T11:56:48Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/LocalInputChannel.java", "diffHunk": "@@ -168,6 +175,12 @@ public void run() {\n \tOptional<BufferAndAvailability> getNextBuffer() throws IOException, InterruptedException {\n \t\tcheckError();\n \n+\t\tBufferAndAvailability bufferAndAvailability = getNextRecoveredStateBuffer();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd26e4d1aae1bfb87dee603ddd51afda409a46df"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTUwODgyMA==", "bodyText": "I am neutral for this option, because the similar way really existed in many other places before. E.g. we have BufferStorage in CheckpointedInputGate for caching the blocked channels' buffers, then while getNextBuffer we also need to check whether there are  any pending buffers to be read from BufferStorage firstly.\nI absolutely agree that it would be better to not have different paths, but I also think it is not so bad if no other easy options.", "url": "https://github.com/apache/flink/pull/11687#discussion_r419508820", "createdAt": "2020-05-04T15:09:13Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/LocalInputChannel.java", "diffHunk": "@@ -168,6 +175,12 @@ public void run() {\n \tOptional<BufferAndAvailability> getNextBuffer() throws IOException, InterruptedException {\n \t\tcheckError();\n \n+\t\tBufferAndAvailability bufferAndAvailability = getNextRecoveredStateBuffer();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTM4MjcxNQ=="}, "originalCommit": {"oid": "bd26e4d1aae1bfb87dee603ddd51afda409a46df"}, "originalPosition": 46}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYxMDQ5NDY5OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/LocalInputChannel.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxMTo1ODo1MlrOGP9Jng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQxNDo0Njo1MVrOGQs-Fg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTM4MzcxMA==", "bodyText": "If this is null, but we are still recovering, we will actually go through the the subpartitionView.getNextBuffer()?", "url": "https://github.com/apache/flink/pull/11687#discussion_r419383710", "createdAt": "2020-05-04T11:58:52Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/LocalInputChannel.java", "diffHunk": "@@ -168,6 +175,12 @@ public void run() {\n \tOptional<BufferAndAvailability> getNextBuffer() throws IOException, InterruptedException {\n \t\tcheckError();\n \n+\t\tBufferAndAvailability bufferAndAvailability = getNextRecoveredStateBuffer();\n+\t\tif (bufferAndAvailability != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd26e4d1aae1bfb87dee603ddd51afda409a46df"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTUxMzc5MQ==", "bodyText": "My previous assumption was that the local channel will not be chosen by SingleInputGate to read if there were no buffers to insert into RecoveredInputChannel#receivedBuffers to notify SingleInputGate.notifyChannelNonEmpty before.\nOr I missed some other corner case?", "url": "https://github.com/apache/flink/pull/11687#discussion_r419513791", "createdAt": "2020-05-04T15:16:23Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/LocalInputChannel.java", "diffHunk": "@@ -168,6 +175,12 @@ public void run() {\n \tOptional<BufferAndAvailability> getNextBuffer() throws IOException, InterruptedException {\n \t\tcheckError();\n \n+\t\tBufferAndAvailability bufferAndAvailability = getNextRecoveredStateBuffer();\n+\t\tif (bufferAndAvailability != null) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTM4MzcxMA=="}, "originalCommit": {"oid": "bd26e4d1aae1bfb87dee603ddd51afda409a46df"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTkzNjY1NA==", "bodyText": "Generally speaking there are no guarantees that data notifications will be accurate or not (I'm not sure if that's the case here). But the code looks a bit strange here and it relays on some extra assumptions.", "url": "https://github.com/apache/flink/pull/11687#discussion_r419936654", "createdAt": "2020-05-05T08:14:47Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/LocalInputChannel.java", "diffHunk": "@@ -168,6 +175,12 @@ public void run() {\n \tOptional<BufferAndAvailability> getNextBuffer() throws IOException, InterruptedException {\n \t\tcheckError();\n \n+\t\tBufferAndAvailability bufferAndAvailability = getNextRecoveredStateBuffer();\n+\t\tif (bufferAndAvailability != null) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTM4MzcxMA=="}, "originalCommit": {"oid": "bd26e4d1aae1bfb87dee603ddd51afda409a46df"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDE2NzE5MA==", "bodyText": "I know that the current data notification from downstream side is not very accurate which might cause return null buffer sometimes, but we can make the channel state notification accurate (actually it is the ground truth now). Then another truth is that the channel state consumption should always happen before downstream consumption, so it should be no problem here.\nAs long as getNextBuffer is triggered by channel state buffer, it can always get accurate buffer. Otherwise if it is triggered by downstream side notification, then it also confirms that the channel state recovery should already finish before.", "url": "https://github.com/apache/flink/pull/11687#discussion_r420167190", "createdAt": "2020-05-05T14:46:51Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/LocalInputChannel.java", "diffHunk": "@@ -168,6 +175,12 @@ public void run() {\n \tOptional<BufferAndAvailability> getNextBuffer() throws IOException, InterruptedException {\n \t\tcheckError();\n \n+\t\tBufferAndAvailability bufferAndAvailability = getNextRecoveredStateBuffer();\n+\t\tif (bufferAndAvailability != null) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTM4MzcxMA=="}, "originalCommit": {"oid": "bd26e4d1aae1bfb87dee603ddd51afda409a46df"}, "originalPosition": 47}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYxMDUwODI1OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxMjowMzoyMFrOGP9R9g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxNToyNTo0OVrOGQFgIw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTM4NTg0Ng==", "bodyText": "Integer.MAX_VALUE? Doesn't it mean that all floating buffers will be stuck permanently in on RemoteInputChannel (that happened to ask for them first?)", "url": "https://github.com/apache/flink/pull/11687#discussion_r419385846", "createdAt": "2020-05-04T12:03:20Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "diffHunk": "@@ -105,12 +98,15 @@ public RemoteInputChannel(\n \t\tint maxBackoff,\n \t\tInputChannelMetrics metrics) {\n \n-\t\tsuper(inputGate, channelIndex, partitionId, initialBackOff, maxBackoff,\n-\t\t\tmetrics.getNumBytesInRemoteCounter(), metrics.getNumBuffersInRemoteCounter());\n+\t\tsuper(inputGate, channelIndex, partitionId, initialBackOff, maxBackoff, metrics);\n \n \t\tthis.connectionId = checkNotNull(connectionId);\n \t\tthis.connectionManager = checkNotNull(connectionManager);\n-\t\tthis.bufferManager = new BufferManager(this, 0);\n+\t\t// In theory it should get the total number of states to indicate the numRequiredBuffers.\n+\t\t// Since we can not get this information in advance, and considering only one input channel\n+\t\t// will read state at the same time by design, then we give a maximum value here to reduce\n+\t\t// unnecessary interactions with buffer pool during recovery.\n+\t\tthis.bufferManager = new BufferManager(this, Integer.MAX_VALUE);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd26e4d1aae1bfb87dee603ddd51afda409a46df"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTUyMDU0Nw==", "bodyText": "As I explained for LocalInputChannel case, this numRequiredBuffers setting is only for a bit optimization, actually we can unify them as 0 and adjust it while really requesting floating buffers in process.\nATM we only have one input channel under unspill, so it makes sense to grab all the available floating buffers for this channel now. After this channel finishes unspilling,  then it would release all the floating buffers back to LocalBufferPool to be reused by other unspill channel.\nThere was a bit tricky to design the factor of numRequiredBuffers before. If one exclusive buffer is recycled or a floating buffer is recycled to notify available for the listener, it would double check whether the current listener still needs more floating buffers ATM based on numRequiredBuffers. If not needed, then the floating buffer would be return back to local pool to assign other listeners.\nFor input channel unspill case, we can assume that the current channel is always needing more floating buffers until finish, to avoid the floating buffer back to local pool and request from pool again when need it next time.", "url": "https://github.com/apache/flink/pull/11687#discussion_r419520547", "createdAt": "2020-05-04T15:25:49Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannel.java", "diffHunk": "@@ -105,12 +98,15 @@ public RemoteInputChannel(\n \t\tint maxBackoff,\n \t\tInputChannelMetrics metrics) {\n \n-\t\tsuper(inputGate, channelIndex, partitionId, initialBackOff, maxBackoff,\n-\t\t\tmetrics.getNumBytesInRemoteCounter(), metrics.getNumBuffersInRemoteCounter());\n+\t\tsuper(inputGate, channelIndex, partitionId, initialBackOff, maxBackoff, metrics);\n \n \t\tthis.connectionId = checkNotNull(connectionId);\n \t\tthis.connectionManager = checkNotNull(connectionManager);\n-\t\tthis.bufferManager = new BufferManager(this, 0);\n+\t\t// In theory it should get the total number of states to indicate the numRequiredBuffers.\n+\t\t// Since we can not get this information in advance, and considering only one input channel\n+\t\t// will read state at the same time by design, then we give a maximum value here to reduce\n+\t\t// unnecessary interactions with buffer pool during recovery.\n+\t\tthis.bufferManager = new BufferManager(this, Integer.MAX_VALUE);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTM4NTg0Ng=="}, "originalCommit": {"oid": "bd26e4d1aae1bfb87dee603ddd51afda409a46df"}, "originalPosition": 45}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYxMTY0OTkyOnYy", "diffSide": "LEFT", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannelTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxNjoyOToyMVrOGQINOQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQxNToxMTozMFrOGQuJMw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTU2NDg1Nw==", "bodyText": "This seems like we are loosing a test coverage here? However this test was quite fragile in the first place and I'm not entirely sure what is it suppose to test.", "url": "https://github.com/apache/flink/pull/11687#discussion_r419564857", "createdAt": "2020-05-04T16:29:21Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannelTest.java", "diffHunk": "@@ -731,33 +726,29 @@ public void testFailureInNotifyBufferAvailable() throws Exception {\n \t\t\tbuffer = checkNotNull(bufferPool.requestBuffer());\n \n \t\t\t// trigger subscription to buffer pool\n-\t\t\tfailingRemoteIC.onSenderBacklog(1);\n-\t\t\tsuccessfulRemoteIC.onSenderBacklog(numExclusiveBuffers + 1);\n-\t\t\t// recycling will call RemoteInputChannel#notifyBufferAvailable() which will fail and\n-\t\t\t// this exception will be swallowed and set as an error in failingRemoteIC\n+\t\t\tchannelWithoutPartition.onSenderBacklog(1);\n+\t\t\tchannelWithPartition.onSenderBacklog(numExclusiveBuffers + 1);\n+\n+\t\t\t// recycling will call RemoteInputChannel#notifyBufferAvailable() which will not increase\n+\t\t\t// the unannounced credit if the channel has not requested partition\n \t\t\tbuffer.recycleBuffer();\n-\t\t\tbuffer = null;\n-\t\t\ttry {\n-\t\t\t\tfailingRemoteIC.checkError();\n-\t\t\t\tfail(\"The input channel should have an error based on the failure in RemoteInputChannel#notifyBufferAvailable()\");\n-\t\t\t} catch (IOException e) {\n-\t\t\t\tassertThat(e, hasProperty(\"cause\", isA(IllegalStateException.class)));\n-\t\t\t}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd26e4d1aae1bfb87dee603ddd51afda409a46df"}, "originalPosition": 464}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDE4NjQxOQ==", "bodyText": "The previous purpose was to verify that if one remote channel has not requested partition, then the notify credit available will fail with IllegalStateException because of non-initialized PartitionRequestClient in RemoteInputChannel.  I think this test is not meaningful in practice, because if the partition request have not happened yet, then the onSenderBacklog should also not happen as well. It seems not valid to explicitly call onSenderBacklog to verify this logic without partition request.\nMy changes for this test is to verify that if the partition request have not happened yet, then the announced credit would not be increased as a result because this is only for the state recovery process to notify available buffers, but this available buffer is not regarded as credit concept without partition request. So I think it makes more sense than the previous test purpose.", "url": "https://github.com/apache/flink/pull/11687#discussion_r420186419", "createdAt": "2020-05-05T15:11:30Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannelTest.java", "diffHunk": "@@ -731,33 +726,29 @@ public void testFailureInNotifyBufferAvailable() throws Exception {\n \t\t\tbuffer = checkNotNull(bufferPool.requestBuffer());\n \n \t\t\t// trigger subscription to buffer pool\n-\t\t\tfailingRemoteIC.onSenderBacklog(1);\n-\t\t\tsuccessfulRemoteIC.onSenderBacklog(numExclusiveBuffers + 1);\n-\t\t\t// recycling will call RemoteInputChannel#notifyBufferAvailable() which will fail and\n-\t\t\t// this exception will be swallowed and set as an error in failingRemoteIC\n+\t\t\tchannelWithoutPartition.onSenderBacklog(1);\n+\t\t\tchannelWithPartition.onSenderBacklog(numExclusiveBuffers + 1);\n+\n+\t\t\t// recycling will call RemoteInputChannel#notifyBufferAvailable() which will not increase\n+\t\t\t// the unannounced credit if the channel has not requested partition\n \t\t\tbuffer.recycleBuffer();\n-\t\t\tbuffer = null;\n-\t\t\ttry {\n-\t\t\t\tfailingRemoteIC.checkError();\n-\t\t\t\tfail(\"The input channel should have an error based on the failure in RemoteInputChannel#notifyBufferAvailable()\");\n-\t\t\t} catch (IOException e) {\n-\t\t\t\tassertThat(e, hasProperty(\"cause\", isA(IllegalStateException.class)));\n-\t\t\t}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTU2NDg1Nw=="}, "originalCommit": {"oid": "bd26e4d1aae1bfb87dee603ddd51afda409a46df"}, "originalPosition": 464}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYxNTEzMDUwOnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamTask.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQxMzoxODowNFrOGQo7LA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQxNTowMToyNVrOGQtrqg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDEwMDkwOA==", "bodyText": "It would simplify a threading model, if this was executed from the main thread, via mailbox (in your PR there is already a race condition between processing data (receiving EndOfPartitionEvent/InputChannel#releaseAllResources from the main thread, vs channelIOExecutor requesting partitions). Example failure (this happened on a modified version of this code, but I think it's a valid failure on your version as well)\nWe could enqueue in the channelIOExecutor a simple job, that would enqueue a mail into the mailbox OR inputGate.readRecoveredState could return Future, and we could enqueue a mail into the mailbox once all futures are completed.", "url": "https://github.com/apache/flink/pull/11687#discussion_r420100908", "createdAt": "2020-05-05T13:18:04Z", "author": {"login": "pnowojski"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamTask.java", "diffHunk": "@@ -464,6 +472,20 @@ protected void beforeInvoke() throws Exception {\n \t\t\t\t\twriter.readRecoveredState(getEnvironment().getTaskStateManager().getChannelStateReader());\n \t\t\t\t}\n \t\t\t}\n+\n+\t\t\t// It would get possible benefits to recovery input side after output side, which guarantees the\n+\t\t\t// output can request more floating buffers from global firstly.\n+\t\t\tInputGate[] inputGates = getEnvironment().getAllInputGates();\n+\t\t\tif (inputGates != null) {\n+\t\t\t\tfor (InputGate inputGate : inputGates) {\n+\t\t\t\t\tinputGate.readRecoveredState(channelIOExecutor, getEnvironment().getTaskStateManager().getChannelStateReader());\n+\t\t\t\t}\n+\n+\t\t\t\t// Note that we must request partition after all the single gate finishes recovery.\n+\t\t\t\tfor (InputGate inputGate : inputGates) {\n+\t\t\t\t\tinputGate.requestPartitions(channelIOExecutor);\n+\t\t\t\t}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd26e4d1aae1bfb87dee603ddd51afda409a46df"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDE3ODg1OA==", "bodyText": "Yeah, actually I also considered the way of requesting partition by mailbox thread after all futures completed returned by inputGate.readRecoveredState.\nBut I also thought of another existing case to execute partition request by non-task main thread. During SingleInputGate#updateInputChannel, when the unknown channel transform into local or remote channel, then it would request partition directly by rpc thread.  If this case makes sense, then my assumption was that partition request actually can be executed by any other threads without race condition issues. So I take the current way instead to save some efforts.", "url": "https://github.com/apache/flink/pull/11687#discussion_r420178858", "createdAt": "2020-05-05T15:01:25Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamTask.java", "diffHunk": "@@ -464,6 +472,20 @@ protected void beforeInvoke() throws Exception {\n \t\t\t\t\twriter.readRecoveredState(getEnvironment().getTaskStateManager().getChannelStateReader());\n \t\t\t\t}\n \t\t\t}\n+\n+\t\t\t// It would get possible benefits to recovery input side after output side, which guarantees the\n+\t\t\t// output can request more floating buffers from global firstly.\n+\t\t\tInputGate[] inputGates = getEnvironment().getAllInputGates();\n+\t\t\tif (inputGates != null) {\n+\t\t\t\tfor (InputGate inputGate : inputGates) {\n+\t\t\t\t\tinputGate.readRecoveredState(channelIOExecutor, getEnvironment().getTaskStateManager().getChannelStateReader());\n+\t\t\t\t}\n+\n+\t\t\t\t// Note that we must request partition after all the single gate finishes recovery.\n+\t\t\t\tfor (InputGate inputGate : inputGates) {\n+\t\t\t\t\tinputGate.requestPartitions(channelIOExecutor);\n+\t\t\t\t}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDEwMDkwOA=="}, "originalCommit": {"oid": "bd26e4d1aae1bfb87dee603ddd51afda409a46df"}, "originalPosition": 45}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYyNzMyNjU5OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RecoveredInputChannel.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wOFQwODoyNjoxOVrOGSdyUg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wOFQwODoyNjoxOVrOGSdyUg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjAxNTU3MA==", "bodyText": "Maybe add\nLOG.debug(\"{}/{} Finished recovering input.\", inputGate.getOwningTaskName(), channelInfo);\n\n?", "url": "https://github.com/apache/flink/pull/11687#discussion_r422015570", "createdAt": "2020-05-08T08:26:19Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RecoveredInputChannel.java", "diffHunk": "@@ -46,15 +49,19 @@\n \t\t\tint maxBackoff,\n \t\t\tInputChannelMetrics metrics) {\n \t\tsuper(inputGate, channelIndex, partitionId, initialBackoff, maxBackoff, metrics.getNumBytesInRemoteCounter(), metrics.getNumBuffersInRemoteCounter());\n+\n+\t\tbufferManager = new BufferManager(inputGate.getMemorySegmentProvider(), this, 0);\n \t}\n \n+\tpublic abstract InputChannel toInputChannel() throws IOException;\n+\n \tprotected void readRecoveredState(ChannelStateReader reader) throws IOException, InterruptedException {\n \t\tReadResult result = ReadResult.HAS_MORE_DATA;\n \t\twhile (result == ReadResult.HAS_MORE_DATA) {\n-\t\t\tBuffer buffer = getBufferManager().requestBufferBlocking();\n+\t\t\tBuffer buffer = bufferManager.requestBufferBlocking();\n \t\t\tresult = internalReaderRecoveredState(reader, buffer);\n \t\t}\n-\t\tgetBufferManager().releaseFloatingBuffers();\n+\t\tbufferManager.releaseFloatingBuffers();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "63b78b0d9260f094d0e5b54b1527802f85b89102"}, "originalPosition": 42}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYyNzM2NjExOnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamTask.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wOFQwODozOTo1NlrOGSeKGA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wOFQwODo1NDowMlrOGSejIg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjAyMTY1Ng==", "bodyText": "Hmmm, this is a bit fragile, as it implicitly assumes futures are completed from the task thread? Maybe add a checkState(...) asserting a thread to document this assumption?", "url": "https://github.com/apache/flink/pull/11687#discussion_r422021656", "createdAt": "2020-05-08T08:39:56Z", "author": {"login": "pnowojski"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamTask.java", "diffHunk": "@@ -477,14 +477,18 @@ protected void beforeInvoke() throws Exception {\n \t\t\t// output can request more floating buffers from global firstly.\n \t\t\tInputGate[] inputGates = getEnvironment().getAllInputGates();\n \t\t\tif (inputGates != null) {\n-\t\t\t\tfor (InputGate inputGate : inputGates) {\n-\t\t\t\t\tinputGate.readRecoveredState(channelIOExecutor, getEnvironment().getTaskStateManager().getChannelStateReader());\n+\t\t\t\tCompletableFuture[] futures = new CompletableFuture[inputGates.length];\n+\t\t\t\tfor (int i = 0; i < inputGates.length; i++) {\n+\t\t\t\t\tfutures[i] = inputGates[i].readRecoveredState(\n+\t\t\t\t\t\tchannelIOExecutor, getEnvironment().getTaskStateManager().getChannelStateReader());\n \t\t\t\t}\n \n-\t\t\t\t// Note that we must request partition after all the single gate finishes recovery.\n-\t\t\t\tfor (InputGate inputGate : inputGates) {\n-\t\t\t\t\tinputGate.requestPartitions(channelIOExecutor);\n-\t\t\t\t}\n+\t\t\t\t// Note that we must request partition after all the single gates finished recovery.\n+\t\t\t\tCompletableFuture.allOf(futures).thenRun(ThrowingRunnable.unchecked(() -> {\n+\t\t\t\t\tfor (InputGate inputGate : inputGates) {\n+\t\t\t\t\t\tinputGate.requestPartitions();\n+\t\t\t\t\t}\n+\t\t\t\t}));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ed7f2261646bd55b43d94f9373b02f45bfc7d58d"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjAyODA2Ng==", "bodyText": "Yeah I assume it should be completed by task thread, actually my initial version was mailboxProcessor.getMainMailboxExecutor().execute().\nI can add a checkState here to guarantee that the current thread is mailbox thread and then give some note comments.", "url": "https://github.com/apache/flink/pull/11687#discussion_r422028066", "createdAt": "2020-05-08T08:54:02Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamTask.java", "diffHunk": "@@ -477,14 +477,18 @@ protected void beforeInvoke() throws Exception {\n \t\t\t// output can request more floating buffers from global firstly.\n \t\t\tInputGate[] inputGates = getEnvironment().getAllInputGates();\n \t\t\tif (inputGates != null) {\n-\t\t\t\tfor (InputGate inputGate : inputGates) {\n-\t\t\t\t\tinputGate.readRecoveredState(channelIOExecutor, getEnvironment().getTaskStateManager().getChannelStateReader());\n+\t\t\t\tCompletableFuture[] futures = new CompletableFuture[inputGates.length];\n+\t\t\t\tfor (int i = 0; i < inputGates.length; i++) {\n+\t\t\t\t\tfutures[i] = inputGates[i].readRecoveredState(\n+\t\t\t\t\t\tchannelIOExecutor, getEnvironment().getTaskStateManager().getChannelStateReader());\n \t\t\t\t}\n \n-\t\t\t\t// Note that we must request partition after all the single gate finishes recovery.\n-\t\t\t\tfor (InputGate inputGate : inputGates) {\n-\t\t\t\t\tinputGate.requestPartitions(channelIOExecutor);\n-\t\t\t\t}\n+\t\t\t\t// Note that we must request partition after all the single gates finished recovery.\n+\t\t\t\tCompletableFuture.allOf(futures).thenRun(ThrowingRunnable.unchecked(() -> {\n+\t\t\t\t\tfor (InputGate inputGate : inputGates) {\n+\t\t\t\t\t\tinputGate.requestPartitions();\n+\t\t\t\t\t}\n+\t\t\t\t}));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjAyMTY1Ng=="}, "originalCommit": {"oid": "ed7f2261646bd55b43d94f9373b02f45bfc7d58d"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYyNzM3NTE2OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RecoveredInputChannel.java", "isResolved": true, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wOFQwODo0MzowM1rOGSePkw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wOFQxMDowNDoxMFrOGSgbgg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjAyMzA1OQ==", "bodyText": "Why atomic? It could easily be checked and set under synchronized (receivedBuffers) lock, simplifying threading model a bit and it would also avoid extra AtomicBoolean check on the hot path.", "url": "https://github.com/apache/flink/pull/11687#discussion_r422023059", "createdAt": "2020-05-08T08:43:03Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RecoveredInputChannel.java", "diffHunk": "@@ -177,17 +178,18 @@ void sendTaskEvent(TaskEvent event) {\n \n \t@Override\n \tboolean isReleased() {\n-\t\treturn isReleased;\n+\t\treturn isReleased.get();\n \t}\n \n \tvoid releaseAllResources() throws IOException {\n-\t\tArrayDeque<Buffer> releasedBuffers = new ArrayDeque<>();\n-\t\tsynchronized (receivedBuffers) {\n-\t\t\treleasedBuffers.addAll(receivedBuffers);\n-\t\t\treceivedBuffers.clear();\n-\t\t\tisReleased = true;\n+\t\tif (isReleased.compareAndSet(false, true)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ad2be9470ed6e122bc0990e05ef0648fe4e0ce33"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjAyOTkzOQ==", "bodyText": "In RemoteInputChannel we also had the atomic released variable and I guess here is the similar case. The release operation might be called not only by task thread, but also by canceler thread. If the latter, it might has visibility issue for task thread while interacting with RecoveredInputChannel#isReleased in BufferManager related operations.", "url": "https://github.com/apache/flink/pull/11687#discussion_r422029939", "createdAt": "2020-05-08T08:58:17Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RecoveredInputChannel.java", "diffHunk": "@@ -177,17 +178,18 @@ void sendTaskEvent(TaskEvent event) {\n \n \t@Override\n \tboolean isReleased() {\n-\t\treturn isReleased;\n+\t\treturn isReleased.get();\n \t}\n \n \tvoid releaseAllResources() throws IOException {\n-\t\tArrayDeque<Buffer> releasedBuffers = new ArrayDeque<>();\n-\t\tsynchronized (receivedBuffers) {\n-\t\t\treleasedBuffers.addAll(receivedBuffers);\n-\t\t\treceivedBuffers.clear();\n-\t\t\tisReleased = true;\n+\t\tif (isReleased.compareAndSet(false, true)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjAyMzA1OQ=="}, "originalCommit": {"oid": "ad2be9470ed6e122bc0990e05ef0648fe4e0ce33"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjAzNjI1OQ==", "bodyText": "also by canceler thread. If the latter, it might has visibility issue\n\nit wouldn't:\n\nIt could easily be checked and set under synchronized (receivedBuffers) lock\n\n?", "url": "https://github.com/apache/flink/pull/11687#discussion_r422036259", "createdAt": "2020-05-08T09:12:19Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RecoveredInputChannel.java", "diffHunk": "@@ -177,17 +178,18 @@ void sendTaskEvent(TaskEvent event) {\n \n \t@Override\n \tboolean isReleased() {\n-\t\treturn isReleased;\n+\t\treturn isReleased.get();\n \t}\n \n \tvoid releaseAllResources() throws IOException {\n-\t\tArrayDeque<Buffer> releasedBuffers = new ArrayDeque<>();\n-\t\tsynchronized (receivedBuffers) {\n-\t\t\treleasedBuffers.addAll(receivedBuffers);\n-\t\t\treceivedBuffers.clear();\n-\t\t\tisReleased = true;\n+\t\tif (isReleased.compareAndSet(false, true)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjAyMzA1OQ=="}, "originalCommit": {"oid": "ad2be9470ed6e122bc0990e05ef0648fe4e0ce33"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjA1NDAwNg==", "bodyText": "yeah, we can also take the way of adding the synchronized (receivedBuffers) for the  method of RecoveredInputGate#isReleased()", "url": "https://github.com/apache/flink/pull/11687#discussion_r422054006", "createdAt": "2020-05-08T09:53:01Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RecoveredInputChannel.java", "diffHunk": "@@ -177,17 +178,18 @@ void sendTaskEvent(TaskEvent event) {\n \n \t@Override\n \tboolean isReleased() {\n-\t\treturn isReleased;\n+\t\treturn isReleased.get();\n \t}\n \n \tvoid releaseAllResources() throws IOException {\n-\t\tArrayDeque<Buffer> releasedBuffers = new ArrayDeque<>();\n-\t\tsynchronized (receivedBuffers) {\n-\t\t\treleasedBuffers.addAll(receivedBuffers);\n-\t\t\treceivedBuffers.clear();\n-\t\t\tisReleased = true;\n+\t\tif (isReleased.compareAndSet(false, true)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjAyMzA1OQ=="}, "originalCommit": {"oid": "ad2be9470ed6e122bc0990e05ef0648fe4e0ce33"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjA1NTIxOA==", "bodyText": "It seems we have different ways for this issue in different classes. LocalInputChannel introduces volatile for this variable, and RemoteInputChannel introduces atomic variable, but RecoveredInputChannel takes the normal boolean variable.\nWe might need to unify them in separate commits future.", "url": "https://github.com/apache/flink/pull/11687#discussion_r422055218", "createdAt": "2020-05-08T09:55:52Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RecoveredInputChannel.java", "diffHunk": "@@ -177,17 +178,18 @@ void sendTaskEvent(TaskEvent event) {\n \n \t@Override\n \tboolean isReleased() {\n-\t\treturn isReleased;\n+\t\treturn isReleased.get();\n \t}\n \n \tvoid releaseAllResources() throws IOException {\n-\t\tArrayDeque<Buffer> releasedBuffers = new ArrayDeque<>();\n-\t\tsynchronized (receivedBuffers) {\n-\t\t\treleasedBuffers.addAll(receivedBuffers);\n-\t\t\treceivedBuffers.clear();\n-\t\t\tisReleased = true;\n+\t\tif (isReleased.compareAndSet(false, true)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjAyMzA1OQ=="}, "originalCommit": {"oid": "ad2be9470ed6e122bc0990e05ef0648fe4e0ce33"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjA1ODg4Mg==", "bodyText": "Agreed. But generally speaking closing/releasing logic is on my list for a larger refactor/clean up for a long time, especially because of those various nasty concurrency issues - I would see closing/releasing eventually moved to task thread/mailbox.\nFor now, I would avoid introducing extra synchronisation point in form of Atomic to make reasoning about the concurrent invocations here as simple as possible.", "url": "https://github.com/apache/flink/pull/11687#discussion_r422058882", "createdAt": "2020-05-08T10:04:10Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/RecoveredInputChannel.java", "diffHunk": "@@ -177,17 +178,18 @@ void sendTaskEvent(TaskEvent event) {\n \n \t@Override\n \tboolean isReleased() {\n-\t\treturn isReleased;\n+\t\treturn isReleased.get();\n \t}\n \n \tvoid releaseAllResources() throws IOException {\n-\t\tArrayDeque<Buffer> releasedBuffers = new ArrayDeque<>();\n-\t\tsynchronized (receivedBuffers) {\n-\t\t\treleasedBuffers.addAll(receivedBuffers);\n-\t\t\treceivedBuffers.clear();\n-\t\t\tisReleased = true;\n+\t\tif (isReleased.compareAndSet(false, true)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjAyMzA1OQ=="}, "originalCommit": {"oid": "ad2be9470ed6e122bc0990e05ef0648fe4e0ce33"}, "originalPosition": 40}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYyNzc4OTQ0OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/reader/AbstractRecordReader.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wOFQxMToxNjoyNVrOGSiJGw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wOFQxMToxNjoyNVrOGSiJGw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjA4NjkzOQ==", "bodyText": "nit: maybe add a small comment why is done like so here?", "url": "https://github.com/apache/flink/pull/11687#discussion_r422086939", "createdAt": "2020-05-08T11:16:25Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/reader/AbstractRecordReader.java", "diffHunk": "@@ -63,6 +63,8 @@ protected AbstractRecordReader(InputGate inputGate, String[] tmpDirectories) {\n \t}\n \n \tprotected boolean getNextRecord(T target) throws IOException, InterruptedException {\n+\t\tinputGate.requestPartitions();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e6bf1161b89f0908b6161f13c4ed14d8585decd"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYyNzc5MjE2OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/SingleInputGateFactory.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wOFQxMToxNzozOFrOGSiK1Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wOFQxMToxNzozOFrOGSiK1Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjA4NzM4MQ==", "bodyText": "nit: remove comment", "url": "https://github.com/apache/flink/pull/11687#discussion_r422087381", "createdAt": "2020-05-08T11:17:38Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/SingleInputGateFactory.java", "diffHunk": "@@ -190,6 +190,7 @@ private InputChannel createInputChannel(\n \t\t\t\t\tpartitionRequestMaxBackoff,\n \t\t\t\t\tmetrics);\n \t\t\t},\n+\t\t\t// TODO: can we sometimes call createKnownInputChannel?", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e6bf1161b89f0908b6161f13c4ed14d8585decd"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYzNzM1NDM4OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamTask.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQwNzowNjo1MVrOGT43HA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQwOToyNDo0NlrOGT9_Ow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzUwNzc0MA==", "bodyText": "In the offline discussion about this deadlock, I meant to have !configuration.isCheckpointingEnabled() check here for now. That would solve the deadlock with input selection, while preserving functionality to disable/enable unaligned checkpoints.", "url": "https://github.com/apache/flink/pull/11687#discussion_r423507740", "createdAt": "2020-05-12T07:06:51Z", "author": {"login": "pnowojski"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamTask.java", "diffHunk": "@@ -458,17 +466,50 @@ protected void beforeInvoke() throws Exception {\n \t\t\t// registers a timer, that fires before the open() is called.\n \t\t\toperatorChain.initializeStateAndOpenOperators(createStreamTaskStateInitializer());\n \n-\t\t\tResultPartitionWriter[] writers = getEnvironment().getAllWriters();\n-\t\t\tif (writers != null) {\n-\t\t\t\tfor (ResultPartitionWriter writer : writers) {\n-\t\t\t\t\twriter.readRecoveredState(getEnvironment().getTaskStateManager().getChannelStateReader());\n-\t\t\t\t}\n-\t\t\t}\n+\t\t\treadRecoveredChannelState();\n \t\t});\n \n \t\tisRunning = true;\n \t}\n \n+\tprivate void readRecoveredChannelState() throws IOException, InterruptedException {\n+\t\t//TODO we will support channel state recovery even if the current setting is not unaligned checkpoint.\n+\t\tif (!configuration.isUnalignedCheckpointsEnabled()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4302180858352cd4fce0668615483a33d2f8e98e"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU5MTczOQ==", "bodyText": "It will be addressed in FLINK-17476", "url": "https://github.com/apache/flink/pull/11687#discussion_r423591739", "createdAt": "2020-05-12T09:24:46Z", "author": {"login": "pnowojski"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamTask.java", "diffHunk": "@@ -458,17 +466,50 @@ protected void beforeInvoke() throws Exception {\n \t\t\t// registers a timer, that fires before the open() is called.\n \t\t\toperatorChain.initializeStateAndOpenOperators(createStreamTaskStateInitializer());\n \n-\t\t\tResultPartitionWriter[] writers = getEnvironment().getAllWriters();\n-\t\t\tif (writers != null) {\n-\t\t\t\tfor (ResultPartitionWriter writer : writers) {\n-\t\t\t\t\twriter.readRecoveredState(getEnvironment().getTaskStateManager().getChannelStateReader());\n-\t\t\t\t}\n-\t\t\t}\n+\t\t\treadRecoveredChannelState();\n \t\t});\n \n \t\tisRunning = true;\n \t}\n \n+\tprivate void readRecoveredChannelState() throws IOException, InterruptedException {\n+\t\t//TODO we will support channel state recovery even if the current setting is not unaligned checkpoint.\n+\t\tif (!configuration.isUnalignedCheckpointsEnabled()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzUwNzc0MA=="}, "originalCommit": {"oid": "4302180858352cd4fce0668615483a33d2f8e98e"}, "originalPosition": 47}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1704, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}