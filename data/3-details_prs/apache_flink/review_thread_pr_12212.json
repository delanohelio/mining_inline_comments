{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE5MzEyNDUx", "number": 12212, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQwODoyOTowOFrOD9Srmg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQwOTowNDozOFrOD9Ti2Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NTk1ODAyOnYy", "diffSide": "RIGHT", "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/filesystem/FileSystemOptions.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQwODoyOTowOFrOGWssCQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQwOTozNDo1M1rOGWvL3w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjQ1NDAyNQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \tpublic static final ConfigOption<Long> SINK_ROLLING_POLICY_TIME_INTERVAL = key(\"sink.rolling-policy.time.interval\")\n          \n          \n            \n            \tpublic static final ConfigOption<Long> SINK_ROLLING_POLICY_TIME_INTERVAL = key(\"sink.rolling-policy.time-interval\")\n          \n      \n    \n    \n  \n\nhow about rename to sink.rolling-policy.time-interval which is closer to  FLIP-122's style ?", "url": "https://github.com/apache/flink/pull/12212#discussion_r426454025", "createdAt": "2020-05-18T08:29:08Z", "author": {"login": "leonardBang"}, "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/filesystem/FileSystemOptions.java", "diffHunk": "@@ -29,6 +29,35 @@\n  */\n public class FileSystemOptions {\n \n+\tpublic static final ConfigOption<String> PATH = key(\"path\")\n+\t\t\t.stringType()\n+\t\t\t.noDefaultValue()\n+\t\t\t.withDescription(\"The path of a directory\");\n+\n+\tpublic static final ConfigOption<String> PARTITION_DEFAULT_NAME = key(\"partition.default-name\")\n+\t\t\t.stringType()\n+\t\t\t.defaultValue(\"__DEFAULT_PARTITION__\")\n+\t\t\t.withDescription(\"The default partition name in case the dynamic partition\" +\n+\t\t\t\t\t\" column value is null/empty string\");\n+\n+\tpublic static final ConfigOption<Long> SINK_ROLLING_POLICY_FILE_SIZE = key(\"sink.rolling-policy.file-size\")\n+\t\t\t.longType()\n+\t\t\t.defaultValue(1024L * 1024L * 128L)\n+\t\t\t.withDescription(\"The maximum part file size before rolling (by default 128MB).\");\n+\n+\tpublic static final ConfigOption<Long> SINK_ROLLING_POLICY_TIME_INTERVAL = key(\"sink.rolling-policy.time.interval\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0ec02542ed4721376e60ea71090cbb335885e6b0"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjQ5NDk0Mw==", "bodyText": "Good catch, I think yes.", "url": "https://github.com/apache/flink/pull/12212#discussion_r426494943", "createdAt": "2020-05-18T09:34:53Z", "author": {"login": "JingsongLi"}, "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/filesystem/FileSystemOptions.java", "diffHunk": "@@ -29,6 +29,35 @@\n  */\n public class FileSystemOptions {\n \n+\tpublic static final ConfigOption<String> PATH = key(\"path\")\n+\t\t\t.stringType()\n+\t\t\t.noDefaultValue()\n+\t\t\t.withDescription(\"The path of a directory\");\n+\n+\tpublic static final ConfigOption<String> PARTITION_DEFAULT_NAME = key(\"partition.default-name\")\n+\t\t\t.stringType()\n+\t\t\t.defaultValue(\"__DEFAULT_PARTITION__\")\n+\t\t\t.withDescription(\"The default partition name in case the dynamic partition\" +\n+\t\t\t\t\t\" column value is null/empty string\");\n+\n+\tpublic static final ConfigOption<Long> SINK_ROLLING_POLICY_FILE_SIZE = key(\"sink.rolling-policy.file-size\")\n+\t\t\t.longType()\n+\t\t\t.defaultValue(1024L * 1024L * 128L)\n+\t\t\t.withDescription(\"The maximum part file size before rolling (by default 128MB).\");\n+\n+\tpublic static final ConfigOption<Long> SINK_ROLLING_POLICY_TIME_INTERVAL = key(\"sink.rolling-policy.time.interval\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjQ1NDAyNQ=="}, "originalCommit": {"oid": "0ec02542ed4721376e60ea71090cbb335885e6b0"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NjA5OTQ1OnYy", "diffSide": "RIGHT", "path": "flink-formats/flink-parquet/src/main/java/org/apache/flink/formats/parquet/ParquetFileSystemFormatFactory.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQwOTowNDozOFrOGWuDAQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQxMDowNzozMVrOGWwaDQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjQ3NjI4OQ==", "bodyText": "could we list all supported Options here? if yes please add for orc too.", "url": "https://github.com/apache/flink/pull/12212#discussion_r426476289", "createdAt": "2020-05-18T09:04:38Z", "author": {"login": "leonardBang"}, "path": "flink-formats/flink-parquet/src/main/java/org/apache/flink/formats/parquet/ParquetFileSystemFormatFactory.java", "diffHunk": "@@ -23,137 +23,104 @@\n import org.apache.flink.api.common.serialization.BulkWriter;\n import org.apache.flink.api.common.serialization.Encoder;\n import org.apache.flink.configuration.ConfigOption;\n+import org.apache.flink.configuration.ReadableConfig;\n import org.apache.flink.core.fs.FileInputSplit;\n import org.apache.flink.core.fs.Path;\n import org.apache.flink.formats.parquet.row.ParquetRowDataBuilder;\n import org.apache.flink.formats.parquet.utils.SerializableConfiguration;\n import org.apache.flink.formats.parquet.vector.ParquetColumnarRowSplitReader;\n import org.apache.flink.formats.parquet.vector.ParquetSplitReaderUtil;\n import org.apache.flink.table.data.RowData;\n-import org.apache.flink.table.descriptors.DescriptorProperties;\n import org.apache.flink.table.factories.FileSystemFormatFactory;\n import org.apache.flink.table.types.DataType;\n import org.apache.flink.table.types.logical.LogicalType;\n import org.apache.flink.table.types.logical.RowType;\n import org.apache.flink.table.utils.PartitionPathUtils;\n \n import org.apache.hadoop.conf.Configuration;\n-import org.apache.parquet.hadoop.ParquetOutputFormat;\n \n import java.io.IOException;\n import java.util.Arrays;\n-import java.util.HashMap;\n+import java.util.HashSet;\n import java.util.LinkedHashMap;\n import java.util.List;\n-import java.util.Map;\n import java.util.Optional;\n+import java.util.Properties;\n+import java.util.Set;\n \n import static org.apache.flink.configuration.ConfigOptions.key;\n import static org.apache.flink.table.data.vector.VectorizedColumnBatch.DEFAULT_SIZE;\n-import static org.apache.flink.table.descriptors.FormatDescriptorValidator.FORMAT;\n import static org.apache.flink.table.filesystem.RowPartitionComputer.restorePartValueFromType;\n \n /**\n  * Parquet {@link FileSystemFormatFactory} for file system.\n  */\n public class ParquetFileSystemFormatFactory implements FileSystemFormatFactory {\n \n-\tpublic static final ConfigOption<Boolean> UTC_TIMEZONE = key(\"format.utc-timezone\")\n+\tpublic static final String IDENTIFIER = \"parquet\";\n+\n+\tpublic static final ConfigOption<Boolean> UTC_TIMEZONE = key(\"utc-timezone\")\n \t\t\t.booleanType()\n \t\t\t.defaultValue(false)\n \t\t\t.withDescription(\"Use UTC timezone or local timezone to the conversion between epoch\" +\n \t\t\t\t\t\" time and LocalDateTime. Hive 0.x/1.x/2.x use local timezone. But Hive 3.x\" +\n \t\t\t\t\t\" use UTC timezone\");\n \n-\t/**\n-\t * Prefix for parquet-related properties, besides format, start with \"parquet\".\n-\t * See more in {@link ParquetOutputFormat}.\n-\t * - parquet.compression\n-\t * - parquet.block.size\n-\t * - parquet.page.size\n-\t * - parquet.dictionary.page.size\n-\t * - parquet.writer.max-padding\n-\t * - parquet.enable.dictionary\n-\t * - parquet.validation\n-\t * - parquet.writer.version\n-\t * ...\n-\t */\n-\tpublic static final String PARQUET_PROPERTIES = \"format.parquet\";\n-\n \t@Override\n-\tpublic Map<String, String> requiredContext() {\n-\t\tMap<String, String> context = new HashMap<>();\n-\t\tcontext.put(FORMAT, \"parquet\");\n-\t\treturn context;\n+\tpublic String factoryIdentifier() {\n+\t\treturn IDENTIFIER;\n \t}\n \n \t@Override\n-\tpublic List<String> supportedProperties() {\n-\t\treturn Arrays.asList(\n-\t\t\t\tUTC_TIMEZONE.key(),\n-\t\t\t\tPARQUET_PROPERTIES + \".*\"\n-\t\t);\n+\tpublic Set<ConfigOption<?>> requiredOptions() {\n+\t\treturn new HashSet<>();\n \t}\n \n-\tprivate static boolean isUtcTimestamp(DescriptorProperties properties) {\n-\t\treturn properties.getOptionalBoolean(UTC_TIMEZONE.key())\n-\t\t\t\t.orElse(UTC_TIMEZONE.defaultValue());\n+\t@Override\n+\tpublic Set<ConfigOption<?>> optionalOptions() {\n+\t\tSet<ConfigOption<?>> options = new HashSet<>();\n+\t\toptions.add(UTC_TIMEZONE);\n+\t\t// support \"parquet.*\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0ec02542ed4721376e60ea71090cbb335885e6b0"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjQ5OTQ2Ng==", "bodyText": "As far as I know, it is hard... Because we don't know how many options are supported by parquet and orc.", "url": "https://github.com/apache/flink/pull/12212#discussion_r426499466", "createdAt": "2020-05-18T09:42:15Z", "author": {"login": "JingsongLi"}, "path": "flink-formats/flink-parquet/src/main/java/org/apache/flink/formats/parquet/ParquetFileSystemFormatFactory.java", "diffHunk": "@@ -23,137 +23,104 @@\n import org.apache.flink.api.common.serialization.BulkWriter;\n import org.apache.flink.api.common.serialization.Encoder;\n import org.apache.flink.configuration.ConfigOption;\n+import org.apache.flink.configuration.ReadableConfig;\n import org.apache.flink.core.fs.FileInputSplit;\n import org.apache.flink.core.fs.Path;\n import org.apache.flink.formats.parquet.row.ParquetRowDataBuilder;\n import org.apache.flink.formats.parquet.utils.SerializableConfiguration;\n import org.apache.flink.formats.parquet.vector.ParquetColumnarRowSplitReader;\n import org.apache.flink.formats.parquet.vector.ParquetSplitReaderUtil;\n import org.apache.flink.table.data.RowData;\n-import org.apache.flink.table.descriptors.DescriptorProperties;\n import org.apache.flink.table.factories.FileSystemFormatFactory;\n import org.apache.flink.table.types.DataType;\n import org.apache.flink.table.types.logical.LogicalType;\n import org.apache.flink.table.types.logical.RowType;\n import org.apache.flink.table.utils.PartitionPathUtils;\n \n import org.apache.hadoop.conf.Configuration;\n-import org.apache.parquet.hadoop.ParquetOutputFormat;\n \n import java.io.IOException;\n import java.util.Arrays;\n-import java.util.HashMap;\n+import java.util.HashSet;\n import java.util.LinkedHashMap;\n import java.util.List;\n-import java.util.Map;\n import java.util.Optional;\n+import java.util.Properties;\n+import java.util.Set;\n \n import static org.apache.flink.configuration.ConfigOptions.key;\n import static org.apache.flink.table.data.vector.VectorizedColumnBatch.DEFAULT_SIZE;\n-import static org.apache.flink.table.descriptors.FormatDescriptorValidator.FORMAT;\n import static org.apache.flink.table.filesystem.RowPartitionComputer.restorePartValueFromType;\n \n /**\n  * Parquet {@link FileSystemFormatFactory} for file system.\n  */\n public class ParquetFileSystemFormatFactory implements FileSystemFormatFactory {\n \n-\tpublic static final ConfigOption<Boolean> UTC_TIMEZONE = key(\"format.utc-timezone\")\n+\tpublic static final String IDENTIFIER = \"parquet\";\n+\n+\tpublic static final ConfigOption<Boolean> UTC_TIMEZONE = key(\"utc-timezone\")\n \t\t\t.booleanType()\n \t\t\t.defaultValue(false)\n \t\t\t.withDescription(\"Use UTC timezone or local timezone to the conversion between epoch\" +\n \t\t\t\t\t\" time and LocalDateTime. Hive 0.x/1.x/2.x use local timezone. But Hive 3.x\" +\n \t\t\t\t\t\" use UTC timezone\");\n \n-\t/**\n-\t * Prefix for parquet-related properties, besides format, start with \"parquet\".\n-\t * See more in {@link ParquetOutputFormat}.\n-\t * - parquet.compression\n-\t * - parquet.block.size\n-\t * - parquet.page.size\n-\t * - parquet.dictionary.page.size\n-\t * - parquet.writer.max-padding\n-\t * - parquet.enable.dictionary\n-\t * - parquet.validation\n-\t * - parquet.writer.version\n-\t * ...\n-\t */\n-\tpublic static final String PARQUET_PROPERTIES = \"format.parquet\";\n-\n \t@Override\n-\tpublic Map<String, String> requiredContext() {\n-\t\tMap<String, String> context = new HashMap<>();\n-\t\tcontext.put(FORMAT, \"parquet\");\n-\t\treturn context;\n+\tpublic String factoryIdentifier() {\n+\t\treturn IDENTIFIER;\n \t}\n \n \t@Override\n-\tpublic List<String> supportedProperties() {\n-\t\treturn Arrays.asList(\n-\t\t\t\tUTC_TIMEZONE.key(),\n-\t\t\t\tPARQUET_PROPERTIES + \".*\"\n-\t\t);\n+\tpublic Set<ConfigOption<?>> requiredOptions() {\n+\t\treturn new HashSet<>();\n \t}\n \n-\tprivate static boolean isUtcTimestamp(DescriptorProperties properties) {\n-\t\treturn properties.getOptionalBoolean(UTC_TIMEZONE.key())\n-\t\t\t\t.orElse(UTC_TIMEZONE.defaultValue());\n+\t@Override\n+\tpublic Set<ConfigOption<?>> optionalOptions() {\n+\t\tSet<ConfigOption<?>> options = new HashSet<>();\n+\t\toptions.add(UTC_TIMEZONE);\n+\t\t// support \"parquet.*\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjQ3NjI4OQ=="}, "originalCommit": {"oid": "0ec02542ed4721376e60ea71090cbb335885e6b0"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjUxNDk1Nw==", "bodyText": "okay, it's fine to me", "url": "https://github.com/apache/flink/pull/12212#discussion_r426514957", "createdAt": "2020-05-18T10:07:31Z", "author": {"login": "leonardBang"}, "path": "flink-formats/flink-parquet/src/main/java/org/apache/flink/formats/parquet/ParquetFileSystemFormatFactory.java", "diffHunk": "@@ -23,137 +23,104 @@\n import org.apache.flink.api.common.serialization.BulkWriter;\n import org.apache.flink.api.common.serialization.Encoder;\n import org.apache.flink.configuration.ConfigOption;\n+import org.apache.flink.configuration.ReadableConfig;\n import org.apache.flink.core.fs.FileInputSplit;\n import org.apache.flink.core.fs.Path;\n import org.apache.flink.formats.parquet.row.ParquetRowDataBuilder;\n import org.apache.flink.formats.parquet.utils.SerializableConfiguration;\n import org.apache.flink.formats.parquet.vector.ParquetColumnarRowSplitReader;\n import org.apache.flink.formats.parquet.vector.ParquetSplitReaderUtil;\n import org.apache.flink.table.data.RowData;\n-import org.apache.flink.table.descriptors.DescriptorProperties;\n import org.apache.flink.table.factories.FileSystemFormatFactory;\n import org.apache.flink.table.types.DataType;\n import org.apache.flink.table.types.logical.LogicalType;\n import org.apache.flink.table.types.logical.RowType;\n import org.apache.flink.table.utils.PartitionPathUtils;\n \n import org.apache.hadoop.conf.Configuration;\n-import org.apache.parquet.hadoop.ParquetOutputFormat;\n \n import java.io.IOException;\n import java.util.Arrays;\n-import java.util.HashMap;\n+import java.util.HashSet;\n import java.util.LinkedHashMap;\n import java.util.List;\n-import java.util.Map;\n import java.util.Optional;\n+import java.util.Properties;\n+import java.util.Set;\n \n import static org.apache.flink.configuration.ConfigOptions.key;\n import static org.apache.flink.table.data.vector.VectorizedColumnBatch.DEFAULT_SIZE;\n-import static org.apache.flink.table.descriptors.FormatDescriptorValidator.FORMAT;\n import static org.apache.flink.table.filesystem.RowPartitionComputer.restorePartValueFromType;\n \n /**\n  * Parquet {@link FileSystemFormatFactory} for file system.\n  */\n public class ParquetFileSystemFormatFactory implements FileSystemFormatFactory {\n \n-\tpublic static final ConfigOption<Boolean> UTC_TIMEZONE = key(\"format.utc-timezone\")\n+\tpublic static final String IDENTIFIER = \"parquet\";\n+\n+\tpublic static final ConfigOption<Boolean> UTC_TIMEZONE = key(\"utc-timezone\")\n \t\t\t.booleanType()\n \t\t\t.defaultValue(false)\n \t\t\t.withDescription(\"Use UTC timezone or local timezone to the conversion between epoch\" +\n \t\t\t\t\t\" time and LocalDateTime. Hive 0.x/1.x/2.x use local timezone. But Hive 3.x\" +\n \t\t\t\t\t\" use UTC timezone\");\n \n-\t/**\n-\t * Prefix for parquet-related properties, besides format, start with \"parquet\".\n-\t * See more in {@link ParquetOutputFormat}.\n-\t * - parquet.compression\n-\t * - parquet.block.size\n-\t * - parquet.page.size\n-\t * - parquet.dictionary.page.size\n-\t * - parquet.writer.max-padding\n-\t * - parquet.enable.dictionary\n-\t * - parquet.validation\n-\t * - parquet.writer.version\n-\t * ...\n-\t */\n-\tpublic static final String PARQUET_PROPERTIES = \"format.parquet\";\n-\n \t@Override\n-\tpublic Map<String, String> requiredContext() {\n-\t\tMap<String, String> context = new HashMap<>();\n-\t\tcontext.put(FORMAT, \"parquet\");\n-\t\treturn context;\n+\tpublic String factoryIdentifier() {\n+\t\treturn IDENTIFIER;\n \t}\n \n \t@Override\n-\tpublic List<String> supportedProperties() {\n-\t\treturn Arrays.asList(\n-\t\t\t\tUTC_TIMEZONE.key(),\n-\t\t\t\tPARQUET_PROPERTIES + \".*\"\n-\t\t);\n+\tpublic Set<ConfigOption<?>> requiredOptions() {\n+\t\treturn new HashSet<>();\n \t}\n \n-\tprivate static boolean isUtcTimestamp(DescriptorProperties properties) {\n-\t\treturn properties.getOptionalBoolean(UTC_TIMEZONE.key())\n-\t\t\t\t.orElse(UTC_TIMEZONE.defaultValue());\n+\t@Override\n+\tpublic Set<ConfigOption<?>> optionalOptions() {\n+\t\tSet<ConfigOption<?>> options = new HashSet<>();\n+\t\toptions.add(UTC_TIMEZONE);\n+\t\t// support \"parquet.*\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjQ3NjI4OQ=="}, "originalCommit": {"oid": "0ec02542ed4721376e60ea71090cbb335885e6b0"}, "originalPosition": 94}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1359, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}