{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTEyMzYwMTg2", "number": 13845, "title": "[FLINK-19801] Adding virtual channels for rescaling unaligned checkpoints.", "bodyText": "What is the purpose of the change\nThis PR concludes rescaling for unaligned checkpoints.\nBrief change log\n\nUses the InflightDataRescalingDescriptor introduced by FLINK-19533.\nAdds VirtualChannelSelector event and adds demultiplexing on input side.\nEmits VirtualChannelSelector on recovery on input and output side and replicates data according to channel mapping in rescaling descriptor.\nAdds check for custom partitioner and allow UC rescaling for supported cases.\n\nVerifying this change\nAdds rescaling tests in UnalignedCheckpointITCase. Enables unaligned checkpoint in all e2e tests.\nDoes this pull request potentially affect one of the following parts:\n\nDependencies (does it add or upgrade a dependency): (yes / no)\nThe public API, i.e., is any changed class annotated with @Public(Evolving): (yes / no)\nThe serializers: (yes / no / don't know)\nThe runtime per-record code paths (performance sensitive): (yes / no / don't know)\nAnything that affects deployment or recovery: JobManager (and its components), Checkpointing, Kubernetes/Yarn/Mesos, ZooKeeper: (yes / no / don't know)\nThe S3 file system connector: (yes / no / don't know)\n\nDocumentation\n\nDoes this pull request introduce a new feature? (yes / no)\nIf yes, how is the feature documented? (not applicable / docs / JavaDocs / not documented) (separate PR)", "createdAt": "2020-10-29T15:28:43Z", "url": "https://github.com/apache/flink/pull/13845", "merged": true, "mergeCommit": {"oid": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa"}, "closed": true, "closedAt": "2021-03-11T18:16:01Z", "author": {"login": "AHeise"}, "timelineItems": {"totalCount": 119, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABd_yzd6ABqjQ0MDcxMjE5OTU=", "endCursor": "Y3Vyc29yOnYyOpPPAAABeCATRMgBqjQ0NDIyNDU0MTg=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "89ef91e99f9946f5defb5ecf0d165ae19a52f292", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/89ef91e99f9946f5defb5ecf0d165ae19a52f292", "committedDate": "2021-03-04T09:53:59Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}, "afterCommit": {"oid": "4d7c215cec360609246594177c3115eb760eda29", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/4d7c215cec360609246594177c3115eb760eda29", "committedDate": "2021-03-04T10:05:40Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "4d7c215cec360609246594177c3115eb760eda29", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/4d7c215cec360609246594177c3115eb760eda29", "committedDate": "2021-03-04T10:05:40Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}, "afterCommit": {"oid": "9f757b1b1e7b9bf0cf2e165c583abf7ce9f2e570", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/9f757b1b1e7b9bf0cf2e165c583abf7ce9f2e570", "committedDate": "2021-03-04T19:30:40Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9f757b1b1e7b9bf0cf2e165c583abf7ce9f2e570", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/9f757b1b1e7b9bf0cf2e165c583abf7ce9f2e570", "committedDate": "2021-03-04T19:30:40Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}, "afterCommit": {"oid": "a7552590f5ffb2802d7a577cad0d5a662ae623f2", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/a7552590f5ffb2802d7a577cad0d5a662ae623f2", "committedDate": "2021-03-05T09:23:03Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a7552590f5ffb2802d7a577cad0d5a662ae623f2", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/a7552590f5ffb2802d7a577cad0d5a662ae623f2", "committedDate": "2021-03-05T09:23:03Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}, "afterCommit": {"oid": "ca0fe3493e748c40cdc7dbb787c28716b483a91c", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/ca0fe3493e748c40cdc7dbb787c28716b483a91c", "committedDate": "2021-03-05T09:24:15Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c9a9c58c6731f711c468c9114bb113d321dfdf5e", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/c9a9c58c6731f711c468c9114bb113d321dfdf5e", "committedDate": "2021-03-10T09:55:38Z", "message": "[hotfix][checkpoint] Ensure buffers are recycled on released RecoveredInputChannel."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "12f0d0a3450a3569de598b2fdf85fd7b848874e8", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/12f0d0a3450a3569de598b2fdf85fd7b848874e8", "committedDate": "2021-03-10T09:55:38Z", "message": "[hotfix][network] Incomplete cleanup of buffer pools does no longer leak other resources."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d179e7c37f82a69676598f28e3215fc0f7fa1534", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/d179e7c37f82a69676598f28e3215fc0f7fa1534", "committedDate": "2021-03-10T09:55:38Z", "message": "[FLINK-19801][checkpoint] Using lazy initialization of aux structure while creating InflightDataRescalingDescriptor.\n\nFor rescaling unaligned checkpoints, rescaling descriptors need to be calculated. However, for larger setups, it can take a while to calculate mappings and thus it should be avoided for all aligned checkpoints, interchanges without data, and for trivial setup (simple upscaling of shuffles).\n\nThere were some optimizations already in the code but it relied on determining the simple cases in advance, which is quite complicated and fell short in two regards. In certain cases, such as channels that or filled only on either upstream or downstream, it was too aggressive and lead to wrong results. Further, some optimization opportunities were left out.\n\nThis commit also generalizes RescaledChannelMapping to RescaleMappings to be additionally used for subtask mappings.\n\nIn this refactoring, the calculation of most aux structure is lazy to simplify the detection of the cases. Accordingly, most calculations are moved inside TaskStateAssignment and properly encapsulated."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4c151a52db75a274dff347ece2ac3f0d40930527", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/4c151a52db75a274dff347ece2ac3f0d40930527", "committedDate": "2021-03-10T09:55:39Z", "message": "[FLINK-19801][checkpoint] Expose rescale descriptors in TaskStateManager and add ambiguity of subtasks + max parallelism.\n\nThe descriptors will be used during unspilling and in the StreamTaskNetworkInput to create virtual channels."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5e7f35553bc89148575902086d43a1bc26b2a0d2", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/5e7f35553bc89148575902086d43a1bc26b2a0d2", "committedDate": "2021-03-10T09:55:39Z", "message": "[FLINK-19801][streaming] Adding Watermark#UNINITIALIZED.\n\nThis special watermark can be used to reflect the state of an subtask/gate/channel that hasn't received a watermark yet. It will be used in later rescaling recovery commits."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1f91e195d306f134a7d5d07c77ff1e28a0fc29e2", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/1f91e195d306f134a7d5d07c77ff1e28a0fc29e2", "committedDate": "2021-03-10T09:55:39Z", "message": "[FLINK-19801][network] Simplify RecordDeserializer interface.\n\nRecordDeserializer is now fully responsible for the buffer that it has been given."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "56f73d129685256228406bd9036dfb34fb9589d0", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/56f73d129685256228406bd9036dfb34fb9589d0", "committedDate": "2021-03-10T09:55:39Z", "message": "[FLINK-19801][task] Extract AbstractStreamTaskNetworkInput from StreamTaskNetworkInput.\n\nAbstractStreamTaskNetworkInput will become the base of RescalingStreamTaskNetworkInput in the next commit."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f417d58448fb9236db4e3be9f36c5f40011a2c9a", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/f417d58448fb9236db4e3be9f36c5f40011a2c9a", "committedDate": "2021-03-10T09:55:40Z", "message": "[FLINK-19801][checkpoint] StreamTaskInput#prepareSnapshot throws CheckpointException to allow declining checkpoints."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9232f328fcb33993f49e2a182b700111a890784a", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/9232f328fcb33993f49e2a182b700111a890784a", "committedDate": "2021-03-10T09:55:40Z", "message": "[FLINK-19801][task] Implement virtual channel demultiplexing in RecoveringStreamTaskNetworkInput.\n\nThe demultiplexing works in two dimensions for the following cases.\n* Subtasks of the current operator have been collapsed in a round-robin fashion.\n* The connected output operator has been rescaled (up and down!) and there is an overlap of channels (mostly relevant to keyed exchanges).\nIn both cases, records from multiple old channels are received over one new physical channel, which need to demultiplex the record to correctly restore spanning records (similar to how StreamTaskNetworkInput works).\n\nFor performance reasons, the virtual demultiplexing logic is implemented separately from StreamTaskNetworkInput, such that on after recovery, the network input is replaced with the non-recovery counter-part in all StreamInputProcessors."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6771250a1599f99d21a0f00f45cf43e478e81f4b", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/6771250a1599f99d21a0f00f45cf43e478e81f4b", "committedDate": "2021-03-10T09:55:41Z", "message": "[FLINK-19801][checkpoint] Recover data with virtual channels.\n\nThis commit adds virtual channel support to SequentialChannelStateReader. The reader now replicates data on input and output side according to the InflightDataRescalingDescriptor and adds VirtualChannelSelector events before buffers."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "32d65ea98d6fee63a6042ad3525de645f6ea4385", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/32d65ea98d6fee63a6042ad3525de645f6ea4385", "committedDate": "2021-03-10T09:55:41Z", "message": "[FLINK-19801][checkpoint/tests] Enable rescaling of unaligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "6654957adfe27d492226f2fe6f0256faae2ff23e", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/6654957adfe27d492226f2fe6f0256faae2ff23e", "committedDate": "2021-03-10T09:54:55Z", "message": "fixup! [FLINK-19801][task] Implement virtual channel demultiplexing in RecoveringStreamTaskNetworkInput."}, "afterCommit": {"oid": "19744c5dc5543e001372393fb879c59ed7d3e931", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/19744c5dc5543e001372393fb879c59ed7d3e931", "committedDate": "2021-03-10T09:55:41Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjA4NjI1NjM4", "url": "https://github.com/apache/flink/pull/13845#pullrequestreview-608625638", "createdAt": "2021-03-10T11:51:51Z", "commit": {"oid": "19744c5dc5543e001372393fb879c59ed7d3e931"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "328e51b44db76cdd71dfa533c96967cb742b8d53", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/328e51b44db76cdd71dfa533c96967cb742b8d53", "committedDate": "2021-03-11T06:57:10Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "19744c5dc5543e001372393fb879c59ed7d3e931", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/19744c5dc5543e001372393fb879c59ed7d3e931", "committedDate": "2021-03-10T09:55:41Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}, "afterCommit": {"oid": "328e51b44db76cdd71dfa533c96967cb742b8d53", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/328e51b44db76cdd71dfa533c96967cb742b8d53", "committedDate": "2021-03-11T06:57:10Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "5d0a36d518a335316bcf2506c30612a6ec90a7cc", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/5d0a36d518a335316bcf2506c30612a6ec90a7cc", "committedDate": "2020-10-29T15:27:01Z", "message": "WIP"}, "afterCommit": {"oid": "6aaac7b1af37c5c6978163a0af512662b6b1340b", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/6aaac7b1af37c5c6978163a0af512662b6b1340b", "committedDate": "2020-10-29T15:30:24Z", "message": "WIP"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "6aaac7b1af37c5c6978163a0af512662b6b1340b", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/6aaac7b1af37c5c6978163a0af512662b6b1340b", "committedDate": "2020-10-29T15:30:24Z", "message": "WIP"}, "afterCommit": {"oid": "10eb7afa8a8582c5e26fba2e11f56af6861c5f4c", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/10eb7afa8a8582c5e26fba2e11f56af6861c5f4c", "committedDate": "2020-10-29T19:49:59Z", "message": "WIP"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "10eb7afa8a8582c5e26fba2e11f56af6861c5f4c", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/10eb7afa8a8582c5e26fba2e11f56af6861c5f4c", "committedDate": "2020-10-29T19:49:59Z", "message": "WIP"}, "afterCommit": {"oid": "f204fe9d94b6971ce07c7ee3c70a60209d879f32", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/f204fe9d94b6971ce07c7ee3c70a60209d879f32", "committedDate": "2020-10-29T19:55:03Z", "message": "[tmp][tests] Add rescale UCITCase."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a5a23ba0b79b33bf605a798f191693036ce4e9b7", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/a5a23ba0b79b33bf605a798f191693036ce4e9b7", "committedDate": "2020-10-29T20:15:38Z", "message": "fix reassign"}, "afterCommit": {"oid": "e591a8d179f8f0ecc7cb96007a62ca30c1ef5ae6", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/e591a8d179f8f0ecc7cb96007a62ca30c1ef5ae6", "committedDate": "2020-10-29T20:16:25Z", "message": "[FLINK-19801][checkpoint] All in-flight data rescaling."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "bbf42d9fa526eb4b4dba5afdcfdf702fb9df2276", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/bbf42d9fa526eb4b4dba5afdcfdf702fb9df2276", "committedDate": "2020-10-30T20:04:27Z", "message": "WIP"}, "afterCommit": {"oid": "a7e0a530333661cf35bf33f6ff03ca4c3ee299c9", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/a7e0a530333661cf35bf33f6ff03ca4c3ee299c9", "committedDate": "2020-11-01T18:48:07Z", "message": "WIP"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a7e0a530333661cf35bf33f6ff03ca4c3ee299c9", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/a7e0a530333661cf35bf33f6ff03ca4c3ee299c9", "committedDate": "2020-11-01T18:48:07Z", "message": "WIP"}, "afterCommit": {"oid": "27f7b010986e6e9cdc6ad96e108f4305c44f78cf", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/27f7b010986e6e9cdc6ad96e108f4305c44f78cf", "committedDate": "2020-11-02T12:59:26Z", "message": "WIP"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "27f7b010986e6e9cdc6ad96e108f4305c44f78cf", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/27f7b010986e6e9cdc6ad96e108f4305c44f78cf", "committedDate": "2020-11-02T12:59:26Z", "message": "WIP"}, "afterCommit": {"oid": "dee8e2bd0aaf272a383cfcb4a0182c72d4409559", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/dee8e2bd0aaf272a383cfcb4a0182c72d4409559", "committedDate": "2020-11-02T16:22:04Z", "message": "WIP"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "dee8e2bd0aaf272a383cfcb4a0182c72d4409559", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/dee8e2bd0aaf272a383cfcb4a0182c72d4409559", "committedDate": "2020-11-02T16:22:04Z", "message": "WIP"}, "afterCommit": {"oid": "65c29602f43c56aa89bc32dde084daaec41bb916", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/65c29602f43c56aa89bc32dde084daaec41bb916", "committedDate": "2020-11-02T21:30:31Z", "message": "WIP"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "65c29602f43c56aa89bc32dde084daaec41bb916", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/65c29602f43c56aa89bc32dde084daaec41bb916", "committedDate": "2020-11-02T21:30:31Z", "message": "WIP"}, "afterCommit": {"oid": "9197fbe10d7c8ad357f2bce478eb6aa8085a4a0d", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/9197fbe10d7c8ad357f2bce478eb6aa8085a4a0d", "committedDate": "2020-11-03T11:41:30Z", "message": "WIP"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9197fbe10d7c8ad357f2bce478eb6aa8085a4a0d", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/9197fbe10d7c8ad357f2bce478eb6aa8085a4a0d", "committedDate": "2020-11-03T11:41:30Z", "message": "WIP"}, "afterCommit": {"oid": "703be5e8c893d41d2cd516195f285328ffc6b9a5", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/703be5e8c893d41d2cd516195f285328ffc6b9a5", "committedDate": "2020-11-03T11:47:03Z", "message": "fixup! [FLINK-19533][checkpoint] Pass user classloader to StateAssignmentOperation."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "703be5e8c893d41d2cd516195f285328ffc6b9a5", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/703be5e8c893d41d2cd516195f285328ffc6b9a5", "committedDate": "2020-11-03T11:47:03Z", "message": "fixup! [FLINK-19533][checkpoint] Pass user classloader to StateAssignmentOperation."}, "afterCommit": {"oid": "3c29a27bd293d78f92f5b4628c3cb9c8acd79e00", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/3c29a27bd293d78f92f5b4628c3cb9c8acd79e00", "committedDate": "2020-11-03T11:50:45Z", "message": "test"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "3c29a27bd293d78f92f5b4628c3cb9c8acd79e00", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/3c29a27bd293d78f92f5b4628c3cb9c8acd79e00", "committedDate": "2020-11-03T11:50:45Z", "message": "test"}, "afterCommit": {"oid": "a3cee456e58935b371762f11a834dfea7deb5ac2", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/a3cee456e58935b371762f11a834dfea7deb5ac2", "committedDate": "2020-11-03T11:52:01Z", "message": "WIP"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a3cee456e58935b371762f11a834dfea7deb5ac2", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/a3cee456e58935b371762f11a834dfea7deb5ac2", "committedDate": "2020-11-03T11:52:01Z", "message": "WIP"}, "afterCommit": {"oid": "1ae89499674aa8622736d58b3a930aeb3ec1049d", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/1ae89499674aa8622736d58b3a930aeb3ec1049d", "committedDate": "2020-11-03T11:53:50Z", "message": "fixup! [FLINK-19533][runtime/streaming] Add ChannelRescaler to the JobEdge to determine mapping between old and new partitions."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "3d418c42a5ffe60a99d17a22a6aaba9955e347f9", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/3d418c42a5ffe60a99d17a22a6aaba9955e347f9", "committedDate": "2020-11-03T11:57:38Z", "message": "fixup! [FLINK-19801][checkpoint] Implement v demux"}, "afterCommit": {"oid": "fea4d76297d984d4e4f9eb9ed24e354ef80b9808", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/fea4d76297d984d4e4f9eb9ed24e354ef80b9808", "committedDate": "2020-11-03T12:01:01Z", "message": "fixup! [FLINK-19533][checkpoint] Add channel state reassignment during rescaling."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "fea4d76297d984d4e4f9eb9ed24e354ef80b9808", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/fea4d76297d984d4e4f9eb9ed24e354ef80b9808", "committedDate": "2020-11-03T12:01:01Z", "message": "fixup! [FLINK-19533][checkpoint] Add channel state reassignment during rescaling."}, "afterCommit": {"oid": "e25bd8241f170ce7c3c66491347db9e138b8da83", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/e25bd8241f170ce7c3c66491347db9e138b8da83", "committedDate": "2020-11-03T12:01:32Z", "message": "[FLINK-19801][streaming] Adding Watermark#UNINITIALIZED."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e25bd8241f170ce7c3c66491347db9e138b8da83", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/e25bd8241f170ce7c3c66491347db9e138b8da83", "committedDate": "2020-11-03T12:01:32Z", "message": "[FLINK-19801][streaming] Adding Watermark#UNINITIALIZED."}, "afterCommit": {"oid": "ded5b82c8fbda8b18a619e5d5a92c67c6181bc4c", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/ded5b82c8fbda8b18a619e5d5a92c67c6181bc4c", "committedDate": "2020-11-04T07:37:45Z", "message": "WIP"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ded5b82c8fbda8b18a619e5d5a92c67c6181bc4c", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/ded5b82c8fbda8b18a619e5d5a92c67c6181bc4c", "committedDate": "2020-11-04T07:37:45Z", "message": "WIP"}, "afterCommit": {"oid": "382a24f902e3ebe1dce08b7af37827bdd576a81b", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/382a24f902e3ebe1dce08b7af37827bdd576a81b", "committedDate": "2020-11-04T22:45:34Z", "message": "WIP"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "6cc4a796b26b66b761f50730f7534c36afad5afa", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/6cc4a796b26b66b761f50730f7534c36afad5afa", "committedDate": "2020-11-04T23:44:19Z", "message": "WIP2"}, "afterCommit": {"oid": "4cdace4e6e9082149cb09570e3f13c461a74d26d", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/4cdace4e6e9082149cb09570e3f13c461a74d26d", "committedDate": "2020-11-04T23:54:46Z", "message": "fixup! [FLINK-19801][checkpoint] Add virtual channel support to SequentialChannelStateReader."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "4cdace4e6e9082149cb09570e3f13c461a74d26d", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/4cdace4e6e9082149cb09570e3f13c461a74d26d", "committedDate": "2020-11-04T23:54:46Z", "message": "fixup! [FLINK-19801][checkpoint] Add virtual channel support to SequentialChannelStateReader."}, "afterCommit": {"oid": "7501e27a866f87f4880c1c665b88d32911cc1def", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/7501e27a866f87f4880c1c665b88d32911cc1def", "committedDate": "2020-11-04T23:59:53Z", "message": "[FLINK-19533][runtime/streaming] Add ChannelStateRescaler to determine mapping between old and new partitions."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "17cd836ad01d2b9518e64c8f485d33731b1173d8", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/17cd836ad01d2b9518e64c8f485d33731b1173d8", "committedDate": "2020-11-05T00:04:36Z", "message": "Expose"}, "afterCommit": {"oid": "6c4f08dbc3a20d24d75ff6a41d0bf5fb393445ff", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/6c4f08dbc3a20d24d75ff6a41d0bf5fb393445ff", "committedDate": "2020-11-05T00:09:01Z", "message": "expose"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "6c4f08dbc3a20d24d75ff6a41d0bf5fb393445ff", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/6c4f08dbc3a20d24d75ff6a41d0bf5fb393445ff", "committedDate": "2020-11-05T00:09:01Z", "message": "expose"}, "afterCommit": {"oid": "dff9f25ac4086acf4b2dbe650a0ed80dd0385ddb", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/dff9f25ac4086acf4b2dbe650a0ed80dd0385ddb", "committedDate": "2020-11-05T00:12:12Z", "message": "[FLINK-19801][streaming] Adding Watermark#UNINITIALIZED."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "dff9f25ac4086acf4b2dbe650a0ed80dd0385ddb", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/dff9f25ac4086acf4b2dbe650a0ed80dd0385ddb", "committedDate": "2020-11-05T00:12:12Z", "message": "[FLINK-19801][streaming] Adding Watermark#UNINITIALIZED."}, "afterCommit": {"oid": "c7d7eece1e8ee281f1f18b1a8623b7c01d325a94", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/c7d7eece1e8ee281f1f18b1a8623b7c01d325a94", "committedDate": "2020-11-05T00:50:15Z", "message": "[FLINK-19801][streaming] Adding Watermark#UNINITIALIZED."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "fd99abf6aaeeb337a27c798c2572815b56c2333d", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/fd99abf6aaeeb337a27c798c2572815b56c2333d", "committedDate": "2020-11-05T08:22:43Z", "message": "fixup! [FLINK-19801][checkpoint] All in-flight data rescaling."}, "afterCommit": {"oid": "5c9683737bf7149b519bf3177fd374d6ab1b4428", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/5c9683737bf7149b519bf3177fd374d6ab1b4428", "committedDate": "2020-11-05T08:23:35Z", "message": "WIP"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "5c9683737bf7149b519bf3177fd374d6ab1b4428", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/5c9683737bf7149b519bf3177fd374d6ab1b4428", "committedDate": "2020-11-05T08:23:35Z", "message": "WIP"}, "afterCommit": {"oid": "8680caedaa6a8b1559723623341293f5caa4f392", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/8680caedaa6a8b1559723623341293f5caa4f392", "committedDate": "2020-11-05T16:32:07Z", "message": "[FLINK-19533][runtime/streaming] Add ChannelStateRescaler to determine mapping between old and new partitions"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c3a7d20ee87c6c345349afa76fca278efa594344", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/c3a7d20ee87c6c345349afa76fca278efa594344", "committedDate": "2020-11-05T16:34:25Z", "message": "WIP"}, "afterCommit": {"oid": "e5a578c540c77e83d0fc619ed6d92f66c3bff1c4", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/e5a578c540c77e83d0fc619ed6d92f66c3bff1c4", "committedDate": "2020-11-05T16:38:28Z", "message": "WIP"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e5a578c540c77e83d0fc619ed6d92f66c3bff1c4", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/e5a578c540c77e83d0fc619ed6d92f66c3bff1c4", "committedDate": "2020-11-05T16:38:28Z", "message": "WIP"}, "afterCommit": {"oid": "6ff570d417423ac84ad5d906900758fbce2b8f43", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/6ff570d417423ac84ad5d906900758fbce2b8f43", "committedDate": "2020-11-05T22:08:55Z", "message": "WIP"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "6ff570d417423ac84ad5d906900758fbce2b8f43", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/6ff570d417423ac84ad5d906900758fbce2b8f43", "committedDate": "2020-11-05T22:08:55Z", "message": "WIP"}, "afterCommit": {"oid": "894e952378dd3ae2c7e92f65b90689ec6c989c8b", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/894e952378dd3ae2c7e92f65b90689ec6c989c8b", "committedDate": "2020-11-05T22:56:03Z", "message": "WIP"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "894e952378dd3ae2c7e92f65b90689ec6c989c8b", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/894e952378dd3ae2c7e92f65b90689ec6c989c8b", "committedDate": "2020-11-05T22:56:03Z", "message": "WIP"}, "afterCommit": {"oid": "dc4c8e30bf2167af1e06108ca1d097e74042a966", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/dc4c8e30bf2167af1e06108ca1d097e74042a966", "committedDate": "2020-11-05T23:03:16Z", "message": "WIP"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "dc4c8e30bf2167af1e06108ca1d097e74042a966", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/dc4c8e30bf2167af1e06108ca1d097e74042a966", "committedDate": "2020-11-05T23:03:16Z", "message": "WIP"}, "afterCommit": {"oid": "87b0f6802843d2e620c3f4769d4b59d512d7b36c", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/87b0f6802843d2e620c3f4769d4b59d512d7b36c", "committedDate": "2020-11-06T09:07:26Z", "message": "WIP"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "87b0f6802843d2e620c3f4769d4b59d512d7b36c", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/87b0f6802843d2e620c3f4769d4b59d512d7b36c", "committedDate": "2020-11-06T09:07:26Z", "message": "WIP"}, "afterCommit": {"oid": "f3aff0c1259abd05d4c18d404874e687431a157c", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/f3aff0c1259abd05d4c18d404874e687431a157c", "committedDate": "2020-11-06T09:09:07Z", "message": "test"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "fc92406febe134120730fcba97ce1e54d8568912", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/fc92406febe134120730fcba97ce1e54d8568912", "committedDate": "2020-11-06T09:13:39Z", "message": "[FLINK-19801][checkpoint] Expose channel mappings in TaskStateManager."}, "afterCommit": {"oid": "e1751b2ca21fcfd0666265dbbe3a35fb7ec2a9a0", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/e1751b2ca21fcfd0666265dbbe3a35fb7ec2a9a0", "committedDate": "2020-11-06T09:21:34Z", "message": "[FLINK-19801][checkpoint] Decline checkpoints while recovery is still in progress."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ed9d2fae0910bb09e1230aa4efeaee134744c99b", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/ed9d2fae0910bb09e1230aa4efeaee134744c99b", "committedDate": "2020-11-06T09:22:50Z", "message": "fixup! [FLINK-19801][checkpoint] Add virtual channel support to SequentialChannelStateReader."}, "afterCommit": {"oid": "d6ee2c9b6b262cb10d0334ce8f13867c22b9f97d", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/d6ee2c9b6b262cb10d0334ce8f13867c22b9f97d", "committedDate": "2020-11-06T10:09:48Z", "message": "test"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d6ee2c9b6b262cb10d0334ce8f13867c22b9f97d", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/d6ee2c9b6b262cb10d0334ce8f13867c22b9f97d", "committedDate": "2020-11-06T10:09:48Z", "message": "test"}, "afterCommit": {"oid": "8ab2d364ec6267e0fb4f48071ae92556b3531bf8", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/8ab2d364ec6267e0fb4f48071ae92556b3531bf8", "committedDate": "2020-11-06T10:11:10Z", "message": "[tmp] debug"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e07c51a3c4cf17ad447312889227e33e4b13d4f3", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/e07c51a3c4cf17ad447312889227e33e4b13d4f3", "committedDate": "2020-11-06T10:13:20Z", "message": "test"}, "afterCommit": {"oid": "2e8062a043bc786823a894dcc411c0988ceaa8fe", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/2e8062a043bc786823a894dcc411c0988ceaa8fe", "committedDate": "2020-11-06T10:16:15Z", "message": "test"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "2e8062a043bc786823a894dcc411c0988ceaa8fe", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/2e8062a043bc786823a894dcc411c0988ceaa8fe", "committedDate": "2020-11-06T10:16:15Z", "message": "test"}, "afterCommit": {"oid": "e031ee06ab93a0f6ffaa878bc30727e0f9b3f38f", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/e031ee06ab93a0f6ffaa878bc30727e0f9b3f38f", "committedDate": "2020-11-06T10:16:26Z", "message": "[tmp] debug"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f7f31917f83efe071aa472d566636bc2342ea0f1", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/f7f31917f83efe071aa472d566636bc2342ea0f1", "committedDate": "2020-11-06T10:23:30Z", "message": "test"}, "afterCommit": {"oid": "5f966f8f914848023f4f583c1f05200720476ec5", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/5f966f8f914848023f4f583c1f05200720476ec5", "committedDate": "2020-11-06T10:30:16Z", "message": "fixup! [FLINK-19801][task] Implement virtual channel demultiplexing in RecoveringStreamTaskNetworkInput."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "5f966f8f914848023f4f583c1f05200720476ec5", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/5f966f8f914848023f4f583c1f05200720476ec5", "committedDate": "2020-11-06T10:30:16Z", "message": "fixup! [FLINK-19801][task] Implement virtual channel demultiplexing in RecoveringStreamTaskNetworkInput."}, "afterCommit": {"oid": "a3e8d3216bbfc9885d8b4e77ee6f3f67b1db82ad", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/a3e8d3216bbfc9885d8b4e77ee6f3f67b1db82ad", "committedDate": "2020-11-06T10:30:34Z", "message": "[tmp] debug"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c53ef997d786df64a5f116dca789d08fd8bc0b17", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/c53ef997d786df64a5f116dca789d08fd8bc0b17", "committedDate": "2020-11-06T13:52:13Z", "message": "test"}, "afterCommit": {"oid": "9c76ed06d4ba5a5e793a9572cdba2a2e777444fd", "author": {"user": {"login": "pnowojski", "name": "Piotr Nowojski"}}, "url": "https://github.com/apache/flink/commit/9c76ed06d4ba5a5e793a9572cdba2a2e777444fd", "committedDate": "2020-11-06T13:52:33Z", "message": "[FLINK-19681][network] Rewrite RemoteInputChannel#getInflightBuffersUnsafe to use sequence numbers\n\nThis will make this method more stable for changes of the internal state of the RemoteInputChannel\nwhen timeouting aligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9175bb29c6e3f10d32886977d9f0fb9c8f977ebb", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/9175bb29c6e3f10d32886977d9f0fb9c8f977ebb", "committedDate": "2020-11-06T16:57:50Z", "message": "debug"}, "afterCommit": {"oid": "26235d721042cb97934e6d230b0ef15ba6ac491f", "author": {"user": {"login": "pnowojski", "name": "Piotr Nowojski"}}, "url": "https://github.com/apache/flink/commit/26235d721042cb97934e6d230b0ef15ba6ac491f", "committedDate": "2020-11-06T17:04:51Z", "message": "[FLINK-19681][network] Rewrite RemoteInputChannel#getInflightBuffersUnsafe to use sequence numbers\n\nThis will make this method more stable for changes of the internal state of the RemoteInputChannel\nwhen timeouting aligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e6e8006f53d10f5f2446161543da099f9c7ffc30", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/e6e8006f53d10f5f2446161543da099f9c7ffc30", "committedDate": "2020-11-06T17:07:27Z", "message": "fixup! [FLINK-19801][checkpoint] Decline checkpoints while recovery is still in progress."}, "afterCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/215a25d83260a048877bdf8462a06473676efb8a", "committedDate": "2020-11-06T20:56:05Z", "message": "[FLINK-19801][tests] Adding unaligned checkpoint rescaling tests."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI1NjQ0MTcw", "url": "https://github.com/apache/flink/pull/13845#pullrequestreview-525644170", "createdAt": "2020-11-07T10:38:08Z", "commit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 16, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QxMDozODowOVrOHvHNkg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QxMTo1MjoxN1rOHvHmXA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2MzI4Mg==", "bodyText": "Here, selector.getSubtaskIndex() is expected to be this subtask old index, right? This is correct for the input channel state recovered on this subtask.\nBut, when the upstream sends its subpartition recovered data, it uses its own oldSubtaskIndex.", "url": "https://github.com/apache/flink/pull/13845#discussion_r519163282", "createdAt": "2020-11-07T10:38:09Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "diffHunk": "@@ -0,0 +1,402 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+/**\n+ * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n+ * non-recovery hotpath, this interface is not extending RecordDeserializer.\n+ */\n+interface Demultiplexer extends AutoCloseable {\n+\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n+\n+\tvoid setNextBuffer(Buffer buffer) throws IOException;\n+\n+\tvoid select(VirtualChannelSelector event);\n+\n+\t@Override\n+\tvoid close();\n+}\n+\n+class NoDataDemultiplexer implements Demultiplexer {\n+\tprivate final InputChannelInfo channelInfo;\n+\n+\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n+\t\tthis.channelInfo = channelInfo;\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void select(VirtualChannelSelector event) {\n+\t\tthrow getException();\n+\t}\n+\n+\tprivate IllegalStateException getException() {\n+\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t}\n+}\n+\n+/**\n+ * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n+ */\n+class DemultiplexParameters {\n+\tfinal IOManager ioManager;\n+\tfinal InflightDataRescalingDescriptor channelMapping;\n+\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n+\tfinal SerializationDelegate<StreamRecord> delegate;\n+\tfinal int numberOfChannels;\n+\tfinal int subtaskIndex;\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tDemultiplexParameters(\n+\t\t\tTypeSerializer<?> inputSerializer,\n+\t\t\tIOManager ioManager,\n+\t\t\tInflightDataRescalingDescriptor channelMapping,\n+\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n+\t\t\tint numberOfChannels,\n+\t\t\tint subtaskIndex) {\n+\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n+\t\tthis.ioManager = ioManager;\n+\t\tthis.channelMapping = channelMapping;\n+\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n+\t\tthis.numberOfChannels = numberOfChannels;\n+\t\tthis.subtaskIndex = subtaskIndex;\n+\t}\n+}\n+\n+/**\n+ * Demultiplexes buffers on subtask-level.\n+ *\n+ * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n+ * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n+ * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n+ *\n+ * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n+ * statuses of the (nested) virtual channels.\n+ */\n+class SubtaskDemultiplexer implements Demultiplexer {\n+\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n+\n+\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n+\n+\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n+\n+\tprivate VirtualChannelSelector currentSelector;\n+\n+\tprivate ChannelDemultiplexer selectedSubtask;\n+\n+\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n+\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n+\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n+\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n+\t\tselectedSubtask = defaultSelection.getValue();\n+\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n+\t\t\tselectedSubtask.selectedChannelIndex);\n+\n+\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n+\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tgetChannelSelectors().forEach(selector -> {\n+\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n+\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n+\t\t});\n+\t}\n+\n+\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n+\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);\n+\t}\n+\n+\tpublic void select(VirtualChannelSelector selector) {\n+\t\tcurrentSelector = selector;\n+\t\tselectedSubtask = demultiplexersForSubtasks.get(selector.getSubtaskIndex());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 173}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2MzQ1Mg==", "bodyText": "nit: rename to subtaskToDemultiplexer to make the meaning of Integer clear?", "url": "https://github.com/apache/flink/pull/13845#discussion_r519163452", "createdAt": "2020-11-07T10:39:59Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "diffHunk": "@@ -0,0 +1,402 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+/**\n+ * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n+ * non-recovery hotpath, this interface is not extending RecordDeserializer.\n+ */\n+interface Demultiplexer extends AutoCloseable {\n+\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n+\n+\tvoid setNextBuffer(Buffer buffer) throws IOException;\n+\n+\tvoid select(VirtualChannelSelector event);\n+\n+\t@Override\n+\tvoid close();\n+}\n+\n+class NoDataDemultiplexer implements Demultiplexer {\n+\tprivate final InputChannelInfo channelInfo;\n+\n+\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n+\t\tthis.channelInfo = channelInfo;\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void select(VirtualChannelSelector event) {\n+\t\tthrow getException();\n+\t}\n+\n+\tprivate IllegalStateException getException() {\n+\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t}\n+}\n+\n+/**\n+ * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n+ */\n+class DemultiplexParameters {\n+\tfinal IOManager ioManager;\n+\tfinal InflightDataRescalingDescriptor channelMapping;\n+\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n+\tfinal SerializationDelegate<StreamRecord> delegate;\n+\tfinal int numberOfChannels;\n+\tfinal int subtaskIndex;\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tDemultiplexParameters(\n+\t\t\tTypeSerializer<?> inputSerializer,\n+\t\t\tIOManager ioManager,\n+\t\t\tInflightDataRescalingDescriptor channelMapping,\n+\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n+\t\t\tint numberOfChannels,\n+\t\t\tint subtaskIndex) {\n+\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n+\t\tthis.ioManager = ioManager;\n+\t\tthis.channelMapping = channelMapping;\n+\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n+\t\tthis.numberOfChannels = numberOfChannels;\n+\t\tthis.subtaskIndex = subtaskIndex;\n+\t}\n+}\n+\n+/**\n+ * Demultiplexes buffers on subtask-level.\n+ *\n+ * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n+ * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n+ * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n+ *\n+ * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n+ * statuses of the (nested) virtual channels.\n+ */\n+class SubtaskDemultiplexer implements Demultiplexer {\n+\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 138}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2MzcxNg==", "bodyText": "Make it static?\nThis method is called from the constructor and refers to a field. This makes it error-prone because the field may not be initialized.", "url": "https://github.com/apache/flink/pull/13845#discussion_r519163716", "createdAt": "2020-11-07T10:43:36Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "diffHunk": "@@ -0,0 +1,402 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+/**\n+ * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n+ * non-recovery hotpath, this interface is not extending RecordDeserializer.\n+ */\n+interface Demultiplexer extends AutoCloseable {\n+\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n+\n+\tvoid setNextBuffer(Buffer buffer) throws IOException;\n+\n+\tvoid select(VirtualChannelSelector event);\n+\n+\t@Override\n+\tvoid close();\n+}\n+\n+class NoDataDemultiplexer implements Demultiplexer {\n+\tprivate final InputChannelInfo channelInfo;\n+\n+\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n+\t\tthis.channelInfo = channelInfo;\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void select(VirtualChannelSelector event) {\n+\t\tthrow getException();\n+\t}\n+\n+\tprivate IllegalStateException getException() {\n+\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t}\n+}\n+\n+/**\n+ * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n+ */\n+class DemultiplexParameters {\n+\tfinal IOManager ioManager;\n+\tfinal InflightDataRescalingDescriptor channelMapping;\n+\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n+\tfinal SerializationDelegate<StreamRecord> delegate;\n+\tfinal int numberOfChannels;\n+\tfinal int subtaskIndex;\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tDemultiplexParameters(\n+\t\t\tTypeSerializer<?> inputSerializer,\n+\t\t\tIOManager ioManager,\n+\t\t\tInflightDataRescalingDescriptor channelMapping,\n+\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n+\t\t\tint numberOfChannels,\n+\t\t\tint subtaskIndex) {\n+\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n+\t\tthis.ioManager = ioManager;\n+\t\tthis.channelMapping = channelMapping;\n+\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n+\t\tthis.numberOfChannels = numberOfChannels;\n+\t\tthis.subtaskIndex = subtaskIndex;\n+\t}\n+}\n+\n+/**\n+ * Demultiplexes buffers on subtask-level.\n+ *\n+ * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n+ * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n+ * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n+ *\n+ * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n+ * statuses of the (nested) virtual channels.\n+ */\n+class SubtaskDemultiplexer implements Demultiplexer {\n+\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n+\n+\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n+\n+\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n+\n+\tprivate VirtualChannelSelector currentSelector;\n+\n+\tprivate ChannelDemultiplexer selectedSubtask;\n+\n+\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n+\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n+\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n+\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n+\t\tselectedSubtask = defaultSelection.getValue();\n+\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n+\t\t\tselectedSubtask.selectedChannelIndex);\n+\n+\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n+\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tgetChannelSelectors().forEach(selector -> {\n+\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n+\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n+\t\t});\n+\t}\n+\n+\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n+\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 168}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2MzgxMA==", "bodyText": "Shouldn't we check here that the new watermark is higher than the old one?", "url": "https://github.com/apache/flink/pull/13845#discussion_r519163810", "createdAt": "2020-11-07T10:44:28Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "diffHunk": "@@ -0,0 +1,402 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+/**\n+ * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n+ * non-recovery hotpath, this interface is not extending RecordDeserializer.\n+ */\n+interface Demultiplexer extends AutoCloseable {\n+\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n+\n+\tvoid setNextBuffer(Buffer buffer) throws IOException;\n+\n+\tvoid select(VirtualChannelSelector event);\n+\n+\t@Override\n+\tvoid close();\n+}\n+\n+class NoDataDemultiplexer implements Demultiplexer {\n+\tprivate final InputChannelInfo channelInfo;\n+\n+\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n+\t\tthis.channelInfo = channelInfo;\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void select(VirtualChannelSelector event) {\n+\t\tthrow getException();\n+\t}\n+\n+\tprivate IllegalStateException getException() {\n+\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t}\n+}\n+\n+/**\n+ * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n+ */\n+class DemultiplexParameters {\n+\tfinal IOManager ioManager;\n+\tfinal InflightDataRescalingDescriptor channelMapping;\n+\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n+\tfinal SerializationDelegate<StreamRecord> delegate;\n+\tfinal int numberOfChannels;\n+\tfinal int subtaskIndex;\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tDemultiplexParameters(\n+\t\t\tTypeSerializer<?> inputSerializer,\n+\t\t\tIOManager ioManager,\n+\t\t\tInflightDataRescalingDescriptor channelMapping,\n+\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n+\t\t\tint numberOfChannels,\n+\t\t\tint subtaskIndex) {\n+\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n+\t\tthis.ioManager = ioManager;\n+\t\tthis.channelMapping = channelMapping;\n+\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n+\t\tthis.numberOfChannels = numberOfChannels;\n+\t\tthis.subtaskIndex = subtaskIndex;\n+\t}\n+}\n+\n+/**\n+ * Demultiplexes buffers on subtask-level.\n+ *\n+ * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n+ * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n+ * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n+ *\n+ * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n+ * statuses of the (nested) virtual channels.\n+ */\n+class SubtaskDemultiplexer implements Demultiplexer {\n+\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n+\n+\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n+\n+\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n+\n+\tprivate VirtualChannelSelector currentSelector;\n+\n+\tprivate ChannelDemultiplexer selectedSubtask;\n+\n+\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n+\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n+\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n+\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n+\t\tselectedSubtask = defaultSelection.getValue();\n+\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n+\t\t\tselectedSubtask.selectedChannelIndex);\n+\n+\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n+\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tgetChannelSelectors().forEach(selector -> {\n+\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n+\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n+\t\t});\n+\t}\n+\n+\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n+\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);\n+\t}\n+\n+\tpublic void select(VirtualChannelSelector selector) {\n+\t\tcurrentSelector = selector;\n+\t\tselectedSubtask = demultiplexersForSubtasks.get(selector.getSubtaskIndex());\n+\t\tif (selectedSubtask == null) {\n+\t\t\tthrow new IllegalStateException(\n+\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n+\t\t}\n+\t\tselectedSubtask.select(selector);\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n+\t\tselectedSubtask.setNextBuffer(buffer);\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n+\t\tdo {\n+\t\t\tRecordDeserializer.DeserializationResult result = selectedSubtask.getNextRecord(deserializationDelegate);\n+\n+\t\t\t// special handling of watermarks and stream status\n+\t\t\tif (result.isFullRecord()) {\n+\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n+\t\t\t\tif (element.isWatermark()) {\n+\t\t\t\t\t// basically, do not emit a watermark if not all virtual channel are past it\n+\t\t\t\t\tlastWatermarks.put(currentSelector, element.asWatermark());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 196}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2Mzg4MA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t\t\t\t\tif (streamStatuses.values().stream().anyMatch(s -> s.equals(StreamStatus.ACTIVE))) {\n          \n          \n            \n            \t\t\t\t\tif (streamStatuses.values().stream().anyMatch(StreamStatus::isActive)) {", "url": "https://github.com/apache/flink/pull/13845#discussion_r519163880", "createdAt": "2020-11-07T10:45:01Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "diffHunk": "@@ -0,0 +1,402 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+/**\n+ * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n+ * non-recovery hotpath, this interface is not extending RecordDeserializer.\n+ */\n+interface Demultiplexer extends AutoCloseable {\n+\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n+\n+\tvoid setNextBuffer(Buffer buffer) throws IOException;\n+\n+\tvoid select(VirtualChannelSelector event);\n+\n+\t@Override\n+\tvoid close();\n+}\n+\n+class NoDataDemultiplexer implements Demultiplexer {\n+\tprivate final InputChannelInfo channelInfo;\n+\n+\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n+\t\tthis.channelInfo = channelInfo;\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void select(VirtualChannelSelector event) {\n+\t\tthrow getException();\n+\t}\n+\n+\tprivate IllegalStateException getException() {\n+\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t}\n+}\n+\n+/**\n+ * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n+ */\n+class DemultiplexParameters {\n+\tfinal IOManager ioManager;\n+\tfinal InflightDataRescalingDescriptor channelMapping;\n+\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n+\tfinal SerializationDelegate<StreamRecord> delegate;\n+\tfinal int numberOfChannels;\n+\tfinal int subtaskIndex;\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tDemultiplexParameters(\n+\t\t\tTypeSerializer<?> inputSerializer,\n+\t\t\tIOManager ioManager,\n+\t\t\tInflightDataRescalingDescriptor channelMapping,\n+\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n+\t\t\tint numberOfChannels,\n+\t\t\tint subtaskIndex) {\n+\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n+\t\tthis.ioManager = ioManager;\n+\t\tthis.channelMapping = channelMapping;\n+\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n+\t\tthis.numberOfChannels = numberOfChannels;\n+\t\tthis.subtaskIndex = subtaskIndex;\n+\t}\n+}\n+\n+/**\n+ * Demultiplexes buffers on subtask-level.\n+ *\n+ * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n+ * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n+ * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n+ *\n+ * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n+ * statuses of the (nested) virtual channels.\n+ */\n+class SubtaskDemultiplexer implements Demultiplexer {\n+\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n+\n+\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n+\n+\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n+\n+\tprivate VirtualChannelSelector currentSelector;\n+\n+\tprivate ChannelDemultiplexer selectedSubtask;\n+\n+\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n+\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n+\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n+\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n+\t\tselectedSubtask = defaultSelection.getValue();\n+\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n+\t\t\tselectedSubtask.selectedChannelIndex);\n+\n+\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n+\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tgetChannelSelectors().forEach(selector -> {\n+\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n+\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n+\t\t});\n+\t}\n+\n+\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n+\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);\n+\t}\n+\n+\tpublic void select(VirtualChannelSelector selector) {\n+\t\tcurrentSelector = selector;\n+\t\tselectedSubtask = demultiplexersForSubtasks.get(selector.getSubtaskIndex());\n+\t\tif (selectedSubtask == null) {\n+\t\t\tthrow new IllegalStateException(\n+\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n+\t\t}\n+\t\tselectedSubtask.select(selector);\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n+\t\tselectedSubtask.setNextBuffer(buffer);\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n+\t\tdo {\n+\t\t\tRecordDeserializer.DeserializationResult result = selectedSubtask.getNextRecord(deserializationDelegate);\n+\n+\t\t\t// special handling of watermarks and stream status\n+\t\t\tif (result.isFullRecord()) {\n+\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n+\t\t\t\tif (element.isWatermark()) {\n+\t\t\t\t\t// basically, do not emit a watermark if not all virtual channel are past it\n+\t\t\t\t\tlastWatermarks.put(currentSelector, element.asWatermark());\n+\t\t\t\t\tfinal Watermark minWatermark = lastWatermarks.values().stream()\n+\t\t\t\t\t\t.min(Comparator.comparing(Watermark::getTimestamp))\n+\t\t\t\t\t\t.orElseThrow(() -> new IllegalStateException(\"Should always have a min watermark\"));\n+\t\t\t\t\t// at least one virtual channel has no watermark, so don't emit any watermark yet\n+\t\t\t\t\tif (minWatermark.equals(Watermark.UNINITIALIZED)) {\n+\t\t\t\t\t\tcontinue;\n+\t\t\t\t\t}\n+\t\t\t\t\tdeserializationDelegate.setInstance(minWatermark);\n+\t\t\t\t} else if (element.isStreamStatus()) {\n+\t\t\t\t\tstreamStatuses.put(currentSelector, element.asStreamStatus());\n+\t\t\t\t\t// summarize statuses across all virtual channels\n+\t\t\t\t\t// duplicate statuses are filtered in StatusWatermarkValve\n+\t\t\t\t\tif (streamStatuses.values().stream().anyMatch(s -> s.equals(StreamStatus.ACTIVE))) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 209}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2Mzk4Nw==", "bodyText": "Is it intentional that filter is only applied to records?\nCan't watermarks be misinterpreted then?", "url": "https://github.com/apache/flink/pull/13845#discussion_r519163987", "createdAt": "2020-11-07T10:46:32Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "diffHunk": "@@ -0,0 +1,402 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+/**\n+ * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n+ * non-recovery hotpath, this interface is not extending RecordDeserializer.\n+ */\n+interface Demultiplexer extends AutoCloseable {\n+\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n+\n+\tvoid setNextBuffer(Buffer buffer) throws IOException;\n+\n+\tvoid select(VirtualChannelSelector event);\n+\n+\t@Override\n+\tvoid close();\n+}\n+\n+class NoDataDemultiplexer implements Demultiplexer {\n+\tprivate final InputChannelInfo channelInfo;\n+\n+\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n+\t\tthis.channelInfo = channelInfo;\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void select(VirtualChannelSelector event) {\n+\t\tthrow getException();\n+\t}\n+\n+\tprivate IllegalStateException getException() {\n+\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t}\n+}\n+\n+/**\n+ * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n+ */\n+class DemultiplexParameters {\n+\tfinal IOManager ioManager;\n+\tfinal InflightDataRescalingDescriptor channelMapping;\n+\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n+\tfinal SerializationDelegate<StreamRecord> delegate;\n+\tfinal int numberOfChannels;\n+\tfinal int subtaskIndex;\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tDemultiplexParameters(\n+\t\t\tTypeSerializer<?> inputSerializer,\n+\t\t\tIOManager ioManager,\n+\t\t\tInflightDataRescalingDescriptor channelMapping,\n+\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n+\t\t\tint numberOfChannels,\n+\t\t\tint subtaskIndex) {\n+\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n+\t\tthis.ioManager = ioManager;\n+\t\tthis.channelMapping = channelMapping;\n+\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n+\t\tthis.numberOfChannels = numberOfChannels;\n+\t\tthis.subtaskIndex = subtaskIndex;\n+\t}\n+}\n+\n+/**\n+ * Demultiplexes buffers on subtask-level.\n+ *\n+ * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n+ * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n+ * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n+ *\n+ * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n+ * statuses of the (nested) virtual channels.\n+ */\n+class SubtaskDemultiplexer implements Demultiplexer {\n+\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n+\n+\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n+\n+\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n+\n+\tprivate VirtualChannelSelector currentSelector;\n+\n+\tprivate ChannelDemultiplexer selectedSubtask;\n+\n+\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n+\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n+\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n+\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n+\t\tselectedSubtask = defaultSelection.getValue();\n+\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n+\t\t\tselectedSubtask.selectedChannelIndex);\n+\n+\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n+\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tgetChannelSelectors().forEach(selector -> {\n+\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n+\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n+\t\t});\n+\t}\n+\n+\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n+\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);\n+\t}\n+\n+\tpublic void select(VirtualChannelSelector selector) {\n+\t\tcurrentSelector = selector;\n+\t\tselectedSubtask = demultiplexersForSubtasks.get(selector.getSubtaskIndex());\n+\t\tif (selectedSubtask == null) {\n+\t\t\tthrow new IllegalStateException(\n+\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n+\t\t}\n+\t\tselectedSubtask.select(selector);\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n+\t\tselectedSubtask.setNextBuffer(buffer);\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n+\t\tdo {\n+\t\t\tRecordDeserializer.DeserializationResult result = selectedSubtask.getNextRecord(deserializationDelegate);\n+\n+\t\t\t// special handling of watermarks and stream status\n+\t\t\tif (result.isFullRecord()) {\n+\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n+\t\t\t\tif (element.isWatermark()) {\n+\t\t\t\t\t// basically, do not emit a watermark if not all virtual channel are past it\n+\t\t\t\t\tlastWatermarks.put(currentSelector, element.asWatermark());\n+\t\t\t\t\tfinal Watermark minWatermark = lastWatermarks.values().stream()\n+\t\t\t\t\t\t.min(Comparator.comparing(Watermark::getTimestamp))\n+\t\t\t\t\t\t.orElseThrow(() -> new IllegalStateException(\"Should always have a min watermark\"));\n+\t\t\t\t\t// at least one virtual channel has no watermark, so don't emit any watermark yet\n+\t\t\t\t\tif (minWatermark.equals(Watermark.UNINITIALIZED)) {\n+\t\t\t\t\t\tcontinue;\n+\t\t\t\t\t}\n+\t\t\t\t\tdeserializationDelegate.setInstance(minWatermark);\n+\t\t\t\t} else if (element.isStreamStatus()) {\n+\t\t\t\t\tstreamStatuses.put(currentSelector, element.asStreamStatus());\n+\t\t\t\t\t// summarize statuses across all virtual channels\n+\t\t\t\t\t// duplicate statuses are filtered in StatusWatermarkValve\n+\t\t\t\t\tif (streamStatuses.values().stream().anyMatch(s -> s.equals(StreamStatus.ACTIVE))) {\n+\t\t\t\t\t\tdeserializationDelegate.setInstance(StreamStatus.ACTIVE);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\treturn result;\n+\t\t\t// loop is only re-executed for suppressed watermark\n+\t\t} while (true);\n+\t}\n+\n+\tpublic void close() {\n+\t\tdemultiplexersForSubtasks.values().forEach(Demultiplexer::close);\n+\t}\n+\n+\tstatic Demultiplexer forChannel(InputChannelInfo info, DemultiplexParameters parameters) {\n+\t\tfinal int[] oldSubtaskIndexes = parameters.channelMapping.getOldSubtaskIndexes(parameters.subtaskIndex);\n+\t\tif (oldSubtaskIndexes.length == 0) {\n+\t\t\treturn new NoDataDemultiplexer(info);\n+\t\t}\n+\t\tfinal int[] oldChannelIndexes = parameters.channelMapping.getChannelMapping(info.getGateIdx())\n+\t\t\t.getOldChannelIndexes(info.getInputChannelIdx());\n+\t\tif (oldChannelIndexes.length == 0) {\n+\t\t\treturn new NoDataDemultiplexer(info);\n+\t\t}\n+\t\tint totalChannels = oldSubtaskIndexes.length * oldChannelIndexes.length;\n+\t\tMap<Integer, ChannelDemultiplexer> demultiplexersForSubtasks = Arrays.stream(oldSubtaskIndexes).boxed()\n+\t\t\t.collect(Collectors.toMap(\n+\t\t\t\tFunction.identity(),\n+\t\t\t\toldSubtaskIndex -> ChannelDemultiplexer.forChannel(oldSubtaskIndex, info, parameters, totalChannels)\n+\t\t\t));\n+\t\treturn new SubtaskDemultiplexer(demultiplexersForSubtasks, totalChannels);\n+\t}\n+\n+\t@Override\n+\tpublic String toString() {\n+\t\treturn \"SubtaskDemultiplexer{\" +\n+\t\t\t\"demultiplexersForSubtasks=\" + demultiplexersForSubtasks +\n+\t\t\t'}';\n+\t}\n+}\n+\n+/**\n+ * Demultiplexes buffers on channel-level.\n+ *\n+ * <p>Example: If the upstream task has been downscaled from 2 to 1. Then, old channels 0 and 1 are both\n+ * processed over new channel 0. So this channel demultiplexer has two {@link #recordDeserializersForChannels} associated\n+ * with the respective old channels.\n+ *\n+ * <p>For all non-unique mappings of new channels to old channels (see\n+ * {@link org.apache.flink.runtime.io.network.api.writer.SubtaskStateMapper} for more details), a filter\n+ * verifies if the restored record should be indeed processed by this subtask or if it should be filtered out and\n+ * be processed at a different subtask.\n+ */\n+class ChannelDemultiplexer implements Demultiplexer {\n+\tprivate final Map<Integer, RecordDeserializer<DeserializationDelegate<StreamElement>>> recordDeserializersForChannels;\n+\n+\tprivate static final Predicate<StreamRecord> NO_FILTER = record -> true;\n+\n+\tprivate final Map<Integer, Predicate<StreamRecord>> filters;\n+\n+\tprivate final int subtaskIndex;\n+\n+\t@Nullable\n+\tprivate RecordDeserializer<DeserializationDelegate<StreamElement>> selectedChannel;\n+\n+\tint selectedChannelIndex;\n+\n+\tChannelDemultiplexer(\n+\t\t\tint subtaskIndex,\n+\t\t\tMap<Integer, Predicate<StreamRecord>> oldChannelsWithFilters,\n+\t\t\tDemultiplexParameters parameters,\n+\t\t\tint totalChannels) {\n+\t\tthis.subtaskIndex = subtaskIndex;\n+\t\tthis.filters = oldChannelsWithFilters;\n+\t\trecordDeserializersForChannels = Maps.newHashMapWithExpectedSize(oldChannelsWithFilters.size());\n+\t\tfor (final Integer oldChannel : oldChannelsWithFilters.keySet()) {\n+\t\t\trecordDeserializersForChannels.put(oldChannel,\n+\t\t\t\tnew SpillingAdaptiveSpanningRecordDeserializer<>(parameters.ioManager.getSpillingDirectoriesPaths(),\n+\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_THRESHOLD_FOR_SPILLING / totalChannels,\n+\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_FILE_BUFFER_SIZE / totalChannels));\n+\t\t}\n+\n+\t\trecordDeserializersForChannels.entrySet().stream().findFirst().ifPresent(firstEntry -> {\n+\t\t\tselectedChannel = firstEntry.getValue();\n+\t\t\tselectedChannelIndex = firstEntry.getKey();\n+\t\t});\n+\t}\n+\n+\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n+\t\treturn recordDeserializersForChannels.keySet().stream()\n+\t\t\t.map(channelIndex -> new VirtualChannelSelector(subtaskIndex, channelIndex));\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n+\t\tdo {\n+\t\t\tfinal RecordDeserializer.DeserializationResult result = selectedChannel.getNextRecord(deserializationDelegate);\n+\n+\t\t\tif (result.isBufferConsumed()) {\n+\t\t\t\tselectedChannel.getCurrentBuffer().recycleBuffer();\n+\t\t\t}\n+\t\t\tif (result.isFullRecord()) {\n+\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n+\t\t\t\tif (element.isRecord() && !filters.get(selectedChannelIndex).test(element.asRecord())) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 313}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2NDYxMQ==", "bodyText": "This delegate is shared across all the channels, but this is the only place where it's used.\nI think it's a bit risky. Why not create it in this method (createFilter)?", "url": "https://github.com/apache/flink/pull/13845#discussion_r519164611", "createdAt": "2020-11-07T10:54:17Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "diffHunk": "@@ -0,0 +1,402 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+/**\n+ * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n+ * non-recovery hotpath, this interface is not extending RecordDeserializer.\n+ */\n+interface Demultiplexer extends AutoCloseable {\n+\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n+\n+\tvoid setNextBuffer(Buffer buffer) throws IOException;\n+\n+\tvoid select(VirtualChannelSelector event);\n+\n+\t@Override\n+\tvoid close();\n+}\n+\n+class NoDataDemultiplexer implements Demultiplexer {\n+\tprivate final InputChannelInfo channelInfo;\n+\n+\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n+\t\tthis.channelInfo = channelInfo;\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void select(VirtualChannelSelector event) {\n+\t\tthrow getException();\n+\t}\n+\n+\tprivate IllegalStateException getException() {\n+\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t}\n+}\n+\n+/**\n+ * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n+ */\n+class DemultiplexParameters {\n+\tfinal IOManager ioManager;\n+\tfinal InflightDataRescalingDescriptor channelMapping;\n+\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n+\tfinal SerializationDelegate<StreamRecord> delegate;\n+\tfinal int numberOfChannels;\n+\tfinal int subtaskIndex;\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tDemultiplexParameters(\n+\t\t\tTypeSerializer<?> inputSerializer,\n+\t\t\tIOManager ioManager,\n+\t\t\tInflightDataRescalingDescriptor channelMapping,\n+\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n+\t\t\tint numberOfChannels,\n+\t\t\tint subtaskIndex) {\n+\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n+\t\tthis.ioManager = ioManager;\n+\t\tthis.channelMapping = channelMapping;\n+\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n+\t\tthis.numberOfChannels = numberOfChannels;\n+\t\tthis.subtaskIndex = subtaskIndex;\n+\t}\n+}\n+\n+/**\n+ * Demultiplexes buffers on subtask-level.\n+ *\n+ * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n+ * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n+ * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n+ *\n+ * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n+ * statuses of the (nested) virtual channels.\n+ */\n+class SubtaskDemultiplexer implements Demultiplexer {\n+\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n+\n+\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n+\n+\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n+\n+\tprivate VirtualChannelSelector currentSelector;\n+\n+\tprivate ChannelDemultiplexer selectedSubtask;\n+\n+\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n+\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n+\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n+\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n+\t\tselectedSubtask = defaultSelection.getValue();\n+\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n+\t\t\tselectedSubtask.selectedChannelIndex);\n+\n+\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n+\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tgetChannelSelectors().forEach(selector -> {\n+\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n+\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n+\t\t});\n+\t}\n+\n+\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n+\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);\n+\t}\n+\n+\tpublic void select(VirtualChannelSelector selector) {\n+\t\tcurrentSelector = selector;\n+\t\tselectedSubtask = demultiplexersForSubtasks.get(selector.getSubtaskIndex());\n+\t\tif (selectedSubtask == null) {\n+\t\t\tthrow new IllegalStateException(\n+\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n+\t\t}\n+\t\tselectedSubtask.select(selector);\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n+\t\tselectedSubtask.setNextBuffer(buffer);\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n+\t\tdo {\n+\t\t\tRecordDeserializer.DeserializationResult result = selectedSubtask.getNextRecord(deserializationDelegate);\n+\n+\t\t\t// special handling of watermarks and stream status\n+\t\t\tif (result.isFullRecord()) {\n+\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n+\t\t\t\tif (element.isWatermark()) {\n+\t\t\t\t\t// basically, do not emit a watermark if not all virtual channel are past it\n+\t\t\t\t\tlastWatermarks.put(currentSelector, element.asWatermark());\n+\t\t\t\t\tfinal Watermark minWatermark = lastWatermarks.values().stream()\n+\t\t\t\t\t\t.min(Comparator.comparing(Watermark::getTimestamp))\n+\t\t\t\t\t\t.orElseThrow(() -> new IllegalStateException(\"Should always have a min watermark\"));\n+\t\t\t\t\t// at least one virtual channel has no watermark, so don't emit any watermark yet\n+\t\t\t\t\tif (minWatermark.equals(Watermark.UNINITIALIZED)) {\n+\t\t\t\t\t\tcontinue;\n+\t\t\t\t\t}\n+\t\t\t\t\tdeserializationDelegate.setInstance(minWatermark);\n+\t\t\t\t} else if (element.isStreamStatus()) {\n+\t\t\t\t\tstreamStatuses.put(currentSelector, element.asStreamStatus());\n+\t\t\t\t\t// summarize statuses across all virtual channels\n+\t\t\t\t\t// duplicate statuses are filtered in StatusWatermarkValve\n+\t\t\t\t\tif (streamStatuses.values().stream().anyMatch(s -> s.equals(StreamStatus.ACTIVE))) {\n+\t\t\t\t\t\tdeserializationDelegate.setInstance(StreamStatus.ACTIVE);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\treturn result;\n+\t\t\t// loop is only re-executed for suppressed watermark\n+\t\t} while (true);\n+\t}\n+\n+\tpublic void close() {\n+\t\tdemultiplexersForSubtasks.values().forEach(Demultiplexer::close);\n+\t}\n+\n+\tstatic Demultiplexer forChannel(InputChannelInfo info, DemultiplexParameters parameters) {\n+\t\tfinal int[] oldSubtaskIndexes = parameters.channelMapping.getOldSubtaskIndexes(parameters.subtaskIndex);\n+\t\tif (oldSubtaskIndexes.length == 0) {\n+\t\t\treturn new NoDataDemultiplexer(info);\n+\t\t}\n+\t\tfinal int[] oldChannelIndexes = parameters.channelMapping.getChannelMapping(info.getGateIdx())\n+\t\t\t.getOldChannelIndexes(info.getInputChannelIdx());\n+\t\tif (oldChannelIndexes.length == 0) {\n+\t\t\treturn new NoDataDemultiplexer(info);\n+\t\t}\n+\t\tint totalChannels = oldSubtaskIndexes.length * oldChannelIndexes.length;\n+\t\tMap<Integer, ChannelDemultiplexer> demultiplexersForSubtasks = Arrays.stream(oldSubtaskIndexes).boxed()\n+\t\t\t.collect(Collectors.toMap(\n+\t\t\t\tFunction.identity(),\n+\t\t\t\toldSubtaskIndex -> ChannelDemultiplexer.forChannel(oldSubtaskIndex, info, parameters, totalChannels)\n+\t\t\t));\n+\t\treturn new SubtaskDemultiplexer(demultiplexersForSubtasks, totalChannels);\n+\t}\n+\n+\t@Override\n+\tpublic String toString() {\n+\t\treturn \"SubtaskDemultiplexer{\" +\n+\t\t\t\"demultiplexersForSubtasks=\" + demultiplexersForSubtasks +\n+\t\t\t'}';\n+\t}\n+}\n+\n+/**\n+ * Demultiplexes buffers on channel-level.\n+ *\n+ * <p>Example: If the upstream task has been downscaled from 2 to 1. Then, old channels 0 and 1 are both\n+ * processed over new channel 0. So this channel demultiplexer has two {@link #recordDeserializersForChannels} associated\n+ * with the respective old channels.\n+ *\n+ * <p>For all non-unique mappings of new channels to old channels (see\n+ * {@link org.apache.flink.runtime.io.network.api.writer.SubtaskStateMapper} for more details), a filter\n+ * verifies if the restored record should be indeed processed by this subtask or if it should be filtered out and\n+ * be processed at a different subtask.\n+ */\n+class ChannelDemultiplexer implements Demultiplexer {\n+\tprivate final Map<Integer, RecordDeserializer<DeserializationDelegate<StreamElement>>> recordDeserializersForChannels;\n+\n+\tprivate static final Predicate<StreamRecord> NO_FILTER = record -> true;\n+\n+\tprivate final Map<Integer, Predicate<StreamRecord>> filters;\n+\n+\tprivate final int subtaskIndex;\n+\n+\t@Nullable\n+\tprivate RecordDeserializer<DeserializationDelegate<StreamElement>> selectedChannel;\n+\n+\tint selectedChannelIndex;\n+\n+\tChannelDemultiplexer(\n+\t\t\tint subtaskIndex,\n+\t\t\tMap<Integer, Predicate<StreamRecord>> oldChannelsWithFilters,\n+\t\t\tDemultiplexParameters parameters,\n+\t\t\tint totalChannels) {\n+\t\tthis.subtaskIndex = subtaskIndex;\n+\t\tthis.filters = oldChannelsWithFilters;\n+\t\trecordDeserializersForChannels = Maps.newHashMapWithExpectedSize(oldChannelsWithFilters.size());\n+\t\tfor (final Integer oldChannel : oldChannelsWithFilters.keySet()) {\n+\t\t\trecordDeserializersForChannels.put(oldChannel,\n+\t\t\t\tnew SpillingAdaptiveSpanningRecordDeserializer<>(parameters.ioManager.getSpillingDirectoriesPaths(),\n+\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_THRESHOLD_FOR_SPILLING / totalChannels,\n+\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_FILE_BUFFER_SIZE / totalChannels));\n+\t\t}\n+\n+\t\trecordDeserializersForChannels.entrySet().stream().findFirst().ifPresent(firstEntry -> {\n+\t\t\tselectedChannel = firstEntry.getValue();\n+\t\t\tselectedChannelIndex = firstEntry.getKey();\n+\t\t});\n+\t}\n+\n+\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n+\t\treturn recordDeserializersForChannels.keySet().stream()\n+\t\t\t.map(channelIndex -> new VirtualChannelSelector(subtaskIndex, channelIndex));\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n+\t\tdo {\n+\t\t\tfinal RecordDeserializer.DeserializationResult result = selectedChannel.getNextRecord(deserializationDelegate);\n+\n+\t\t\tif (result.isBufferConsumed()) {\n+\t\t\t\tselectedChannel.getCurrentBuffer().recycleBuffer();\n+\t\t\t}\n+\t\t\tif (result.isFullRecord()) {\n+\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n+\t\t\t\tif (element.isRecord() && !filters.get(selectedChannelIndex).test(element.asRecord())) {\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\treturn result;\n+\t\t\t// loop is re-executed for filtered full records.\n+\t\t} while (true);\n+\t}\n+\n+\tpublic void select(VirtualChannelSelector selector) {\n+\t\tselectedChannelIndex = selector.getChannelIndex();\n+\t\tselectedChannel = recordDeserializersForChannels.get(selectedChannelIndex);\n+\t\tif (selectedChannel == null) {\n+\t\t\tthrow new IllegalStateException(\n+\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n+\t\tselectedChannel.setNextBuffer(buffer);\n+\t}\n+\n+\tpublic void close() {\n+\t\tfor (RecordDeserializer<DeserializationDelegate<StreamElement>> deserializer :\n+\t\t\trecordDeserializersForChannels.values()) {\n+\t\t\t// recycle buffers and clear the deserializer.\n+\t\t\tBuffer buffer = deserializer.getCurrentBuffer();\n+\t\t\tif (buffer != null && !buffer.isRecycled()) {\n+\t\t\t\tbuffer.recycleBuffer();\n+\t\t\t}\n+\t\t\tdeserializer.clear();\n+\t\t}\n+\t}\n+\n+\tstatic ChannelDemultiplexer forChannel(\n+\t\t\tint subtaskIndex,\n+\t\t\tInputChannelInfo channelInfo,\n+\t\t\tDemultiplexParameters parameters,\n+\t\t\tint totalChannels) {\n+\t\tfinal InflightDataRescalingDescriptor mapping = parameters.channelMapping;\n+\t\tfinal RescaledChannelsMapping rescaledChannelsMapping =\n+\t\t\tmapping.getChannelMapping(channelInfo.getGateIdx());\n+\t\tfinal int[] oldChannels = rescaledChannelsMapping.getOldChannelIndexes(channelInfo.getInputChannelIdx());\n+\n+\t\tfinal Map<Integer, Predicate<StreamRecord>> oldChannelsWithFilters =\n+\t\t\tArrays.stream(oldChannels).boxed()\n+\t\t\t\t.collect(Collectors.toMap(\n+\t\t\t\t\tFunction.identity(),\n+\t\t\t\t\toldChannel -> getFilterForChannel(channelInfo, parameters, rescaledChannelsMapping, oldChannel)));\n+\n+\t\treturn new ChannelDemultiplexer(\n+\t\t\tsubtaskIndex,\n+\t\t\toldChannelsWithFilters,\n+\t\t\tparameters,\n+\t\t\ttotalChannels);\n+\t}\n+\n+\tprivate static Predicate<StreamRecord> getFilterForChannel(\n+\t\t\tInputChannelInfo channelInfo,\n+\t\t\tDemultiplexParameters parameters,\n+\t\t\tRescaledChannelsMapping rescaledChannelsMapping,\n+\t\t\tInteger oldChannel) {\n+\t\treturn rescaledChannelsMapping.getNewChannelIndexes(oldChannel).length <= 1 ?\n+\t\t\tNO_FILTER :\n+\t\t\tcreateFilter(channelInfo, parameters);\n+\t}\n+\n+\tprivate static Predicate<StreamRecord> createFilter(InputChannelInfo channelInfo, DemultiplexParameters parameters) {\n+\t\tfinal StreamPartitioner partitioner = parameters.gatePartitionerRetriever.apply(channelInfo.getGateIdx());\n+\t\tfinal int inputChannelIdx = channelInfo.getInputChannelIdx();\n+\t\tfinal SerializationDelegate<StreamRecord> delegate = parameters.delegate;\n+\t\tpartitioner.setup(parameters.numberOfChannels);\n+\t\tif (partitioner instanceof ConfigurableStreamPartitioner) {\n+\t\t\t((ConfigurableStreamPartitioner) partitioner).configure(KeyGroupRangeAssignment.UPPER_BOUND_MAX_PARALLELISM);\n+\t\t}\n+\t\treturn streamRecord -> {\n+\t\t\tdelegate.setInstance(streamRecord);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 391}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2NDk0OQ==", "bodyText": "Shouldn't it be old DOP (not UPPER_BOUND_MAX_PARALLELISM)?", "url": "https://github.com/apache/flink/pull/13845#discussion_r519164949", "createdAt": "2020-11-07T10:57:18Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "diffHunk": "@@ -0,0 +1,402 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+/**\n+ * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n+ * non-recovery hotpath, this interface is not extending RecordDeserializer.\n+ */\n+interface Demultiplexer extends AutoCloseable {\n+\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n+\n+\tvoid setNextBuffer(Buffer buffer) throws IOException;\n+\n+\tvoid select(VirtualChannelSelector event);\n+\n+\t@Override\n+\tvoid close();\n+}\n+\n+class NoDataDemultiplexer implements Demultiplexer {\n+\tprivate final InputChannelInfo channelInfo;\n+\n+\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n+\t\tthis.channelInfo = channelInfo;\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void select(VirtualChannelSelector event) {\n+\t\tthrow getException();\n+\t}\n+\n+\tprivate IllegalStateException getException() {\n+\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t}\n+}\n+\n+/**\n+ * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n+ */\n+class DemultiplexParameters {\n+\tfinal IOManager ioManager;\n+\tfinal InflightDataRescalingDescriptor channelMapping;\n+\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n+\tfinal SerializationDelegate<StreamRecord> delegate;\n+\tfinal int numberOfChannels;\n+\tfinal int subtaskIndex;\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tDemultiplexParameters(\n+\t\t\tTypeSerializer<?> inputSerializer,\n+\t\t\tIOManager ioManager,\n+\t\t\tInflightDataRescalingDescriptor channelMapping,\n+\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n+\t\t\tint numberOfChannels,\n+\t\t\tint subtaskIndex) {\n+\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n+\t\tthis.ioManager = ioManager;\n+\t\tthis.channelMapping = channelMapping;\n+\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n+\t\tthis.numberOfChannels = numberOfChannels;\n+\t\tthis.subtaskIndex = subtaskIndex;\n+\t}\n+}\n+\n+/**\n+ * Demultiplexes buffers on subtask-level.\n+ *\n+ * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n+ * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n+ * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n+ *\n+ * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n+ * statuses of the (nested) virtual channels.\n+ */\n+class SubtaskDemultiplexer implements Demultiplexer {\n+\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n+\n+\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n+\n+\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n+\n+\tprivate VirtualChannelSelector currentSelector;\n+\n+\tprivate ChannelDemultiplexer selectedSubtask;\n+\n+\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n+\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n+\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n+\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n+\t\tselectedSubtask = defaultSelection.getValue();\n+\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n+\t\t\tselectedSubtask.selectedChannelIndex);\n+\n+\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n+\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tgetChannelSelectors().forEach(selector -> {\n+\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n+\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n+\t\t});\n+\t}\n+\n+\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n+\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);\n+\t}\n+\n+\tpublic void select(VirtualChannelSelector selector) {\n+\t\tcurrentSelector = selector;\n+\t\tselectedSubtask = demultiplexersForSubtasks.get(selector.getSubtaskIndex());\n+\t\tif (selectedSubtask == null) {\n+\t\t\tthrow new IllegalStateException(\n+\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n+\t\t}\n+\t\tselectedSubtask.select(selector);\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n+\t\tselectedSubtask.setNextBuffer(buffer);\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n+\t\tdo {\n+\t\t\tRecordDeserializer.DeserializationResult result = selectedSubtask.getNextRecord(deserializationDelegate);\n+\n+\t\t\t// special handling of watermarks and stream status\n+\t\t\tif (result.isFullRecord()) {\n+\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n+\t\t\t\tif (element.isWatermark()) {\n+\t\t\t\t\t// basically, do not emit a watermark if not all virtual channel are past it\n+\t\t\t\t\tlastWatermarks.put(currentSelector, element.asWatermark());\n+\t\t\t\t\tfinal Watermark minWatermark = lastWatermarks.values().stream()\n+\t\t\t\t\t\t.min(Comparator.comparing(Watermark::getTimestamp))\n+\t\t\t\t\t\t.orElseThrow(() -> new IllegalStateException(\"Should always have a min watermark\"));\n+\t\t\t\t\t// at least one virtual channel has no watermark, so don't emit any watermark yet\n+\t\t\t\t\tif (minWatermark.equals(Watermark.UNINITIALIZED)) {\n+\t\t\t\t\t\tcontinue;\n+\t\t\t\t\t}\n+\t\t\t\t\tdeserializationDelegate.setInstance(minWatermark);\n+\t\t\t\t} else if (element.isStreamStatus()) {\n+\t\t\t\t\tstreamStatuses.put(currentSelector, element.asStreamStatus());\n+\t\t\t\t\t// summarize statuses across all virtual channels\n+\t\t\t\t\t// duplicate statuses are filtered in StatusWatermarkValve\n+\t\t\t\t\tif (streamStatuses.values().stream().anyMatch(s -> s.equals(StreamStatus.ACTIVE))) {\n+\t\t\t\t\t\tdeserializationDelegate.setInstance(StreamStatus.ACTIVE);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\treturn result;\n+\t\t\t// loop is only re-executed for suppressed watermark\n+\t\t} while (true);\n+\t}\n+\n+\tpublic void close() {\n+\t\tdemultiplexersForSubtasks.values().forEach(Demultiplexer::close);\n+\t}\n+\n+\tstatic Demultiplexer forChannel(InputChannelInfo info, DemultiplexParameters parameters) {\n+\t\tfinal int[] oldSubtaskIndexes = parameters.channelMapping.getOldSubtaskIndexes(parameters.subtaskIndex);\n+\t\tif (oldSubtaskIndexes.length == 0) {\n+\t\t\treturn new NoDataDemultiplexer(info);\n+\t\t}\n+\t\tfinal int[] oldChannelIndexes = parameters.channelMapping.getChannelMapping(info.getGateIdx())\n+\t\t\t.getOldChannelIndexes(info.getInputChannelIdx());\n+\t\tif (oldChannelIndexes.length == 0) {\n+\t\t\treturn new NoDataDemultiplexer(info);\n+\t\t}\n+\t\tint totalChannels = oldSubtaskIndexes.length * oldChannelIndexes.length;\n+\t\tMap<Integer, ChannelDemultiplexer> demultiplexersForSubtasks = Arrays.stream(oldSubtaskIndexes).boxed()\n+\t\t\t.collect(Collectors.toMap(\n+\t\t\t\tFunction.identity(),\n+\t\t\t\toldSubtaskIndex -> ChannelDemultiplexer.forChannel(oldSubtaskIndex, info, parameters, totalChannels)\n+\t\t\t));\n+\t\treturn new SubtaskDemultiplexer(demultiplexersForSubtasks, totalChannels);\n+\t}\n+\n+\t@Override\n+\tpublic String toString() {\n+\t\treturn \"SubtaskDemultiplexer{\" +\n+\t\t\t\"demultiplexersForSubtasks=\" + demultiplexersForSubtasks +\n+\t\t\t'}';\n+\t}\n+}\n+\n+/**\n+ * Demultiplexes buffers on channel-level.\n+ *\n+ * <p>Example: If the upstream task has been downscaled from 2 to 1. Then, old channels 0 and 1 are both\n+ * processed over new channel 0. So this channel demultiplexer has two {@link #recordDeserializersForChannels} associated\n+ * with the respective old channels.\n+ *\n+ * <p>For all non-unique mappings of new channels to old channels (see\n+ * {@link org.apache.flink.runtime.io.network.api.writer.SubtaskStateMapper} for more details), a filter\n+ * verifies if the restored record should be indeed processed by this subtask or if it should be filtered out and\n+ * be processed at a different subtask.\n+ */\n+class ChannelDemultiplexer implements Demultiplexer {\n+\tprivate final Map<Integer, RecordDeserializer<DeserializationDelegate<StreamElement>>> recordDeserializersForChannels;\n+\n+\tprivate static final Predicate<StreamRecord> NO_FILTER = record -> true;\n+\n+\tprivate final Map<Integer, Predicate<StreamRecord>> filters;\n+\n+\tprivate final int subtaskIndex;\n+\n+\t@Nullable\n+\tprivate RecordDeserializer<DeserializationDelegate<StreamElement>> selectedChannel;\n+\n+\tint selectedChannelIndex;\n+\n+\tChannelDemultiplexer(\n+\t\t\tint subtaskIndex,\n+\t\t\tMap<Integer, Predicate<StreamRecord>> oldChannelsWithFilters,\n+\t\t\tDemultiplexParameters parameters,\n+\t\t\tint totalChannels) {\n+\t\tthis.subtaskIndex = subtaskIndex;\n+\t\tthis.filters = oldChannelsWithFilters;\n+\t\trecordDeserializersForChannels = Maps.newHashMapWithExpectedSize(oldChannelsWithFilters.size());\n+\t\tfor (final Integer oldChannel : oldChannelsWithFilters.keySet()) {\n+\t\t\trecordDeserializersForChannels.put(oldChannel,\n+\t\t\t\tnew SpillingAdaptiveSpanningRecordDeserializer<>(parameters.ioManager.getSpillingDirectoriesPaths(),\n+\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_THRESHOLD_FOR_SPILLING / totalChannels,\n+\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_FILE_BUFFER_SIZE / totalChannels));\n+\t\t}\n+\n+\t\trecordDeserializersForChannels.entrySet().stream().findFirst().ifPresent(firstEntry -> {\n+\t\t\tselectedChannel = firstEntry.getValue();\n+\t\t\tselectedChannelIndex = firstEntry.getKey();\n+\t\t});\n+\t}\n+\n+\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n+\t\treturn recordDeserializersForChannels.keySet().stream()\n+\t\t\t.map(channelIndex -> new VirtualChannelSelector(subtaskIndex, channelIndex));\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n+\t\tdo {\n+\t\t\tfinal RecordDeserializer.DeserializationResult result = selectedChannel.getNextRecord(deserializationDelegate);\n+\n+\t\t\tif (result.isBufferConsumed()) {\n+\t\t\t\tselectedChannel.getCurrentBuffer().recycleBuffer();\n+\t\t\t}\n+\t\t\tif (result.isFullRecord()) {\n+\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n+\t\t\t\tif (element.isRecord() && !filters.get(selectedChannelIndex).test(element.asRecord())) {\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\treturn result;\n+\t\t\t// loop is re-executed for filtered full records.\n+\t\t} while (true);\n+\t}\n+\n+\tpublic void select(VirtualChannelSelector selector) {\n+\t\tselectedChannelIndex = selector.getChannelIndex();\n+\t\tselectedChannel = recordDeserializersForChannels.get(selectedChannelIndex);\n+\t\tif (selectedChannel == null) {\n+\t\t\tthrow new IllegalStateException(\n+\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n+\t\tselectedChannel.setNextBuffer(buffer);\n+\t}\n+\n+\tpublic void close() {\n+\t\tfor (RecordDeserializer<DeserializationDelegate<StreamElement>> deserializer :\n+\t\t\trecordDeserializersForChannels.values()) {\n+\t\t\t// recycle buffers and clear the deserializer.\n+\t\t\tBuffer buffer = deserializer.getCurrentBuffer();\n+\t\t\tif (buffer != null && !buffer.isRecycled()) {\n+\t\t\t\tbuffer.recycleBuffer();\n+\t\t\t}\n+\t\t\tdeserializer.clear();\n+\t\t}\n+\t}\n+\n+\tstatic ChannelDemultiplexer forChannel(\n+\t\t\tint subtaskIndex,\n+\t\t\tInputChannelInfo channelInfo,\n+\t\t\tDemultiplexParameters parameters,\n+\t\t\tint totalChannels) {\n+\t\tfinal InflightDataRescalingDescriptor mapping = parameters.channelMapping;\n+\t\tfinal RescaledChannelsMapping rescaledChannelsMapping =\n+\t\t\tmapping.getChannelMapping(channelInfo.getGateIdx());\n+\t\tfinal int[] oldChannels = rescaledChannelsMapping.getOldChannelIndexes(channelInfo.getInputChannelIdx());\n+\n+\t\tfinal Map<Integer, Predicate<StreamRecord>> oldChannelsWithFilters =\n+\t\t\tArrays.stream(oldChannels).boxed()\n+\t\t\t\t.collect(Collectors.toMap(\n+\t\t\t\t\tFunction.identity(),\n+\t\t\t\t\toldChannel -> getFilterForChannel(channelInfo, parameters, rescaledChannelsMapping, oldChannel)));\n+\n+\t\treturn new ChannelDemultiplexer(\n+\t\t\tsubtaskIndex,\n+\t\t\toldChannelsWithFilters,\n+\t\t\tparameters,\n+\t\t\ttotalChannels);\n+\t}\n+\n+\tprivate static Predicate<StreamRecord> getFilterForChannel(\n+\t\t\tInputChannelInfo channelInfo,\n+\t\t\tDemultiplexParameters parameters,\n+\t\t\tRescaledChannelsMapping rescaledChannelsMapping,\n+\t\t\tInteger oldChannel) {\n+\t\treturn rescaledChannelsMapping.getNewChannelIndexes(oldChannel).length <= 1 ?\n+\t\t\tNO_FILTER :\n+\t\t\tcreateFilter(channelInfo, parameters);\n+\t}\n+\n+\tprivate static Predicate<StreamRecord> createFilter(InputChannelInfo channelInfo, DemultiplexParameters parameters) {\n+\t\tfinal StreamPartitioner partitioner = parameters.gatePartitionerRetriever.apply(channelInfo.getGateIdx());\n+\t\tfinal int inputChannelIdx = channelInfo.getInputChannelIdx();\n+\t\tfinal SerializationDelegate<StreamRecord> delegate = parameters.delegate;\n+\t\tpartitioner.setup(parameters.numberOfChannels);\n+\t\tif (partitioner instanceof ConfigurableStreamPartitioner) {\n+\t\t\t((ConfigurableStreamPartitioner) partitioner).configure(KeyGroupRangeAssignment.UPPER_BOUND_MAX_PARALLELISM);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 388}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2NTMyOQ==", "bodyText": "Can't we use just Map<InputChannelInfo, Demultiplexer> instead of this map and channelDemultiplexers array?", "url": "https://github.com/apache/flink/pull/13845#discussion_r519165329", "createdAt": "2020-11-07T11:02:00Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/RescalingStreamTaskNetworkInput.java", "diffHunk": "@@ -0,0 +1,283 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.io.InputStatus;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.event.AbstractEvent;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.EndOfPartitionEvent;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer.DeserializationResult;\n+import org.apache.flink.runtime.io.network.partition.consumer.BufferOrEvent;\n+import org.apache.flink.runtime.io.network.partition.consumer.EndOfChannelStateEvent;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.runtime.plugable.NonReusingDeserializationDelegate;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElementSerializer;\n+import org.apache.flink.streaming.runtime.streamstatus.StatusWatermarkValve;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.Function;\n+\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * A {@link StreamTaskNetworkInput} implementation that demultiplexes virtual channels.\n+ *\n+ * <p>The demultiplexing works in two dimensions for the following cases.\n+ * <ul>\n+ *     <li> Subtasks of the current operator have been collapsed in a round-robin fashion.\n+ *     <li> The connected output operator has been rescaled (up and down!) and there is an overlap of channels (mostly\n+ * relevant to keyed exchanges).\n+ * </ul>\n+ * In both cases, records from multiple old channels are received over one new physical channel, which need to\n+ * demultiplex the record to correctly restore spanning records (similar to how StreamTaskNetworkInput works).\n+ *\n+ * <p>Note that when both cases occur at the same time (downscaling of several operators), there is the cross product of\n+ * channels. So if two subtasks are collapsed and two channels overlap from the output side, there is a total of 4\n+ * virtual channels.\n+ */\n+@Internal\n+public final class RescalingStreamTaskNetworkInput<T> implements RecoverableStreamTaskInput<T> {\n+\n+\tprivate final CheckpointedInputGate checkpointedInputGate;\n+\n+\tprivate final DeserializationDelegate<StreamElement> deserializationDelegate;\n+\n+\tprivate final Demultiplexer[] channelDemultiplexers;\n+\n+\t/** Valve that controls how watermarks and stream statuses are forwarded. */\n+\tprivate final StatusWatermarkValve statusWatermarkValve;\n+\n+\tprivate final int inputIndex;\n+\n+\tprivate final Map<InputChannelInfo, Integer> channelIndexes;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2NTQ2NA==", "bodyText": "According to javadoc above, it's a type of RecordDeserializer, just not explicitly implementing it.\nSo the name DemultiplexingRecordDeserializer would make more sense to me.", "url": "https://github.com/apache/flink/pull/13845#discussion_r519165464", "createdAt": "2020-11-07T11:03:51Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "diffHunk": "@@ -0,0 +1,402 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+/**\n+ * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n+ * non-recovery hotpath, this interface is not extending RecordDeserializer.\n+ */\n+interface Demultiplexer extends AutoCloseable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2ODY0NA==", "bodyText": "This class duplicates StreamTaskNetworkInput by most part (the same with much less extent goes to Demultiplexer).\nI guess the motivation not to reuse was performance, right?\nHow big was the impact?", "url": "https://github.com/apache/flink/pull/13845#discussion_r519168644", "createdAt": "2020-11-07T11:40:52Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/RescalingStreamTaskNetworkInput.java", "diffHunk": "@@ -0,0 +1,283 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.io.InputStatus;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.event.AbstractEvent;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.EndOfPartitionEvent;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer.DeserializationResult;\n+import org.apache.flink.runtime.io.network.partition.consumer.BufferOrEvent;\n+import org.apache.flink.runtime.io.network.partition.consumer.EndOfChannelStateEvent;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.runtime.plugable.NonReusingDeserializationDelegate;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElementSerializer;\n+import org.apache.flink.streaming.runtime.streamstatus.StatusWatermarkValve;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.Function;\n+\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * A {@link StreamTaskNetworkInput} implementation that demultiplexes virtual channels.\n+ *\n+ * <p>The demultiplexing works in two dimensions for the following cases.\n+ * <ul>\n+ *     <li> Subtasks of the current operator have been collapsed in a round-robin fashion.\n+ *     <li> The connected output operator has been rescaled (up and down!) and there is an overlap of channels (mostly\n+ * relevant to keyed exchanges).\n+ * </ul>\n+ * In both cases, records from multiple old channels are received over one new physical channel, which need to\n+ * demultiplex the record to correctly restore spanning records (similar to how StreamTaskNetworkInput works).\n+ *\n+ * <p>Note that when both cases occur at the same time (downscaling of several operators), there is the cross product of\n+ * channels. So if two subtasks are collapsed and two channels overlap from the output side, there is a total of 4\n+ * virtual channels.\n+ */\n+@Internal\n+public final class RescalingStreamTaskNetworkInput<T> implements RecoverableStreamTaskInput<T> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2ODk4OA==", "bodyText": "nit: if channels is empty then a more informative error message would be helpful", "url": "https://github.com/apache/flink/pull/13845#discussion_r519168988", "createdAt": "2020-11-07T11:44:44Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java", "diffHunk": "@@ -88,38 +127,66 @@ private RecoveredInputChannel getChannel(InputChannelInfo info) {\n \tprivate final ResultPartitionWriter[] writers;\n \tprivate final boolean notifyAndBlockOnCompletion;\n \n-\tResultSubpartitionRecoveredStateHandler(ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion) {\n+\tprivate final InflightDataRescalingDescriptor channelMapping;\n+\n+\tprivate final Map<ResultSubpartitionInfo, List<CheckpointedResultSubpartition>> rescaledChannels = new HashMap<>();\n+\n+\tResultSubpartitionRecoveredStateHandler(ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion, InflightDataRescalingDescriptor channelMapping) {\n \t\tthis.writers = writers;\n+\t\tthis.channelMapping = channelMapping;\n \t\tthis.notifyAndBlockOnCompletion = notifyAndBlockOnCompletion;\n \t}\n \n \t@Override\n \tpublic BufferWithContext<Tuple2<BufferBuilder, BufferConsumer>> getBuffer(ResultSubpartitionInfo subpartitionInfo) throws IOException, InterruptedException {\n-\t\tBufferBuilder bufferBuilder = getSubpartition(subpartitionInfo).requestBufferBuilderBlocking();\n+\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n+\t\tBufferBuilder bufferBuilder = channels.get(0).requestBufferBuilderBlocking();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 124}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2OTA3Mg==", "bodyText": "nit: move to top?", "url": "https://github.com/apache/flink/pull/13845#discussion_r519169072", "createdAt": "2020-11-07T11:45:43Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java", "diffHunk": "@@ -88,38 +127,66 @@ private RecoveredInputChannel getChannel(InputChannelInfo info) {\n \tprivate final ResultPartitionWriter[] writers;\n \tprivate final boolean notifyAndBlockOnCompletion;\n \n-\tResultSubpartitionRecoveredStateHandler(ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion) {\n+\tprivate final InflightDataRescalingDescriptor channelMapping;\n+\n+\tprivate final Map<ResultSubpartitionInfo, List<CheckpointedResultSubpartition>> rescaledChannels = new HashMap<>();\n+\n+\tResultSubpartitionRecoveredStateHandler(ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion, InflightDataRescalingDescriptor channelMapping) {\n \t\tthis.writers = writers;\n+\t\tthis.channelMapping = channelMapping;\n \t\tthis.notifyAndBlockOnCompletion = notifyAndBlockOnCompletion;\n \t}\n \n \t@Override\n \tpublic BufferWithContext<Tuple2<BufferBuilder, BufferConsumer>> getBuffer(ResultSubpartitionInfo subpartitionInfo) throws IOException, InterruptedException {\n-\t\tBufferBuilder bufferBuilder = getSubpartition(subpartitionInfo).requestBufferBuilderBlocking();\n+\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n+\t\tBufferBuilder bufferBuilder = channels.get(0).requestBufferBuilderBlocking();\n \t\treturn new BufferWithContext<>(wrap(bufferBuilder), Tuple2.of(bufferBuilder, bufferBuilder.createBufferConsumer()));\n \t}\n \n \t@Override\n-\tpublic void recover(ResultSubpartitionInfo subpartitionInfo, Tuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer) throws IOException {\n+\tpublic void recover(\n+\t\t\tResultSubpartitionInfo subpartitionInfo,\n+\t\t\tint oldSubtaskIndex,\n+\t\t\tTuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer) throws IOException {\n \t\tbufferBuilderAndConsumer.f0.finish();\n \t\tif (bufferBuilderAndConsumer.f1.isDataAvailable()) {\n-\t\t\tboolean added = getSubpartition(subpartitionInfo).add(bufferBuilderAndConsumer.f1, Integer.MIN_VALUE);\n-\t\t\tif (!added) {\n-\t\t\t\tthrow new IOException(\"Buffer consumer couldn't be added to ResultSubpartition\");\n+\t\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n+\t\t\tfor (final CheckpointedResultSubpartition channel : channels) {\n+\t\t\t\t// channel selector is created from the downstream's point of view: the subtask of downstream = subpartition index of recovered buffer\n+\t\t\t\tfinal VirtualChannelSelector channelSelector = new VirtualChannelSelector(subpartitionInfo.getSubPartitionIdx(), oldSubtaskIndex);\n+\t\t\t\tchannel.add(EventSerializer.toBufferConsumer(channelSelector, false), Integer.MIN_VALUE);\n+\t\t\t\tboolean added = channel.add(bufferBuilderAndConsumer.f1.copy(), Integer.MIN_VALUE);\n+\t\t\t\tif (!added) {\n+\t\t\t\t\tthrow new IOException(\"Buffer consumer couldn't be added to ResultSubpartition\");\n+\t\t\t\t}\n \t\t\t}\n-\t\t} else {\n-\t\t\tbufferBuilderAndConsumer.f1.close();\n \t\t}\n+\t\tbufferBuilderAndConsumer.f1.close();\n \t}\n \n-\tprivate CheckpointedResultSubpartition getSubpartition(ResultSubpartitionInfo subpartitionInfo) {\n-\t\tResultPartitionWriter writer = writers[subpartitionInfo.getPartitionIdx()];\n-\t\tif (writer instanceof CheckpointedResultPartition) {\n-\t\t\treturn ((CheckpointedResultPartition) writer).getCheckpointedSubpartition(subpartitionInfo.getSubPartitionIdx());\n-\t\t} else {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot restore state to a non-checkpointable partition type: \" + writer);\n+\tprivate CheckpointedResultSubpartition getSubpartition(int partitionIndex, int subPartitionIdx) {\n+\t\tResultPartitionWriter writer = writers[partitionIndex];\n+\t\tif (!(writer instanceof CheckpointedResultPartition)) {\n+\t\t\tthrow new IllegalStateException(\"Cannot restore state to a non-checkpointable partition type: \" + writer);\n \t\t}\n+\t\treturn ((CheckpointedResultPartition) writer).getCheckpointedSubpartition(subPartitionIdx);\n+\t}\n+\n+\tprivate List<CheckpointedResultSubpartition> getMappedChannels(ResultSubpartitionInfo subpartitionInfo) {\n+\t\treturn rescaledChannels.computeIfAbsent(subpartitionInfo, this::calculateMapping);\n+\t}\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ResultSubpartitionRecoveredStateHandler.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 174}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2OTEyMg==", "bodyText": "I think the log level should be debug here.", "url": "https://github.com/apache/flink/pull/13845#discussion_r519169122", "createdAt": "2020-11-07T11:46:19Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java", "diffHunk": "@@ -88,38 +127,66 @@ private RecoveredInputChannel getChannel(InputChannelInfo info) {\n \tprivate final ResultPartitionWriter[] writers;\n \tprivate final boolean notifyAndBlockOnCompletion;\n \n-\tResultSubpartitionRecoveredStateHandler(ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion) {\n+\tprivate final InflightDataRescalingDescriptor channelMapping;\n+\n+\tprivate final Map<ResultSubpartitionInfo, List<CheckpointedResultSubpartition>> rescaledChannels = new HashMap<>();\n+\n+\tResultSubpartitionRecoveredStateHandler(ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion, InflightDataRescalingDescriptor channelMapping) {\n \t\tthis.writers = writers;\n+\t\tthis.channelMapping = channelMapping;\n \t\tthis.notifyAndBlockOnCompletion = notifyAndBlockOnCompletion;\n \t}\n \n \t@Override\n \tpublic BufferWithContext<Tuple2<BufferBuilder, BufferConsumer>> getBuffer(ResultSubpartitionInfo subpartitionInfo) throws IOException, InterruptedException {\n-\t\tBufferBuilder bufferBuilder = getSubpartition(subpartitionInfo).requestBufferBuilderBlocking();\n+\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n+\t\tBufferBuilder bufferBuilder = channels.get(0).requestBufferBuilderBlocking();\n \t\treturn new BufferWithContext<>(wrap(bufferBuilder), Tuple2.of(bufferBuilder, bufferBuilder.createBufferConsumer()));\n \t}\n \n \t@Override\n-\tpublic void recover(ResultSubpartitionInfo subpartitionInfo, Tuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer) throws IOException {\n+\tpublic void recover(\n+\t\t\tResultSubpartitionInfo subpartitionInfo,\n+\t\t\tint oldSubtaskIndex,\n+\t\t\tTuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer) throws IOException {\n \t\tbufferBuilderAndConsumer.f0.finish();\n \t\tif (bufferBuilderAndConsumer.f1.isDataAvailable()) {\n-\t\t\tboolean added = getSubpartition(subpartitionInfo).add(bufferBuilderAndConsumer.f1, Integer.MIN_VALUE);\n-\t\t\tif (!added) {\n-\t\t\t\tthrow new IOException(\"Buffer consumer couldn't be added to ResultSubpartition\");\n+\t\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n+\t\t\tfor (final CheckpointedResultSubpartition channel : channels) {\n+\t\t\t\t// channel selector is created from the downstream's point of view: the subtask of downstream = subpartition index of recovered buffer\n+\t\t\t\tfinal VirtualChannelSelector channelSelector = new VirtualChannelSelector(subpartitionInfo.getSubPartitionIdx(), oldSubtaskIndex);\n+\t\t\t\tchannel.add(EventSerializer.toBufferConsumer(channelSelector, false), Integer.MIN_VALUE);\n+\t\t\t\tboolean added = channel.add(bufferBuilderAndConsumer.f1.copy(), Integer.MIN_VALUE);\n+\t\t\t\tif (!added) {\n+\t\t\t\t\tthrow new IOException(\"Buffer consumer couldn't be added to ResultSubpartition\");\n+\t\t\t\t}\n \t\t\t}\n-\t\t} else {\n-\t\t\tbufferBuilderAndConsumer.f1.close();\n \t\t}\n+\t\tbufferBuilderAndConsumer.f1.close();\n \t}\n \n-\tprivate CheckpointedResultSubpartition getSubpartition(ResultSubpartitionInfo subpartitionInfo) {\n-\t\tResultPartitionWriter writer = writers[subpartitionInfo.getPartitionIdx()];\n-\t\tif (writer instanceof CheckpointedResultPartition) {\n-\t\t\treturn ((CheckpointedResultPartition) writer).getCheckpointedSubpartition(subpartitionInfo.getSubPartitionIdx());\n-\t\t} else {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot restore state to a non-checkpointable partition type: \" + writer);\n+\tprivate CheckpointedResultSubpartition getSubpartition(int partitionIndex, int subPartitionIdx) {\n+\t\tResultPartitionWriter writer = writers[partitionIndex];\n+\t\tif (!(writer instanceof CheckpointedResultPartition)) {\n+\t\t\tthrow new IllegalStateException(\"Cannot restore state to a non-checkpointable partition type: \" + writer);\n \t\t}\n+\t\treturn ((CheckpointedResultPartition) writer).getCheckpointedSubpartition(subPartitionIdx);\n+\t}\n+\n+\tprivate List<CheckpointedResultSubpartition> getMappedChannels(ResultSubpartitionInfo subpartitionInfo) {\n+\t\treturn rescaledChannels.computeIfAbsent(subpartitionInfo, this::calculateMapping);\n+\t}\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ResultSubpartitionRecoveredStateHandler.class);\n+\tprivate List<CheckpointedResultSubpartition> calculateMapping(ResultSubpartitionInfo info) {\n+\t\tfinal RescaledChannelsMapping rescaledChannelsMapping = channelMapping.getChannelMapping(info.getPartitionIdx());\n+\t\tfinal List<CheckpointedResultSubpartition> subpartitions = Arrays.stream(rescaledChannelsMapping.getNewChannelIndexes(info.getSubPartitionIdx()))\n+\t\t\t.mapToObj(newIndexes -> getSubpartition(info.getPartitionIdx(), newIndexes))\n+\t\t\t.collect(Collectors.toList());\n+\n+\t\tLOG.info(\"output#calculateMapping for {} using {}: {}\", info, rescaledChannelsMapping,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 181}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2OTMwMA==", "bodyText": "Is it guaranteed that new subpartitions include all needed old subpartitions?\nI think in case of downscaling of the downstream, the new upstream will less subpartitions than the old one.\nWDYT?", "url": "https://github.com/apache/flink/pull/13845#discussion_r519169300", "createdAt": "2020-11-07T11:49:09Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java", "diffHunk": "@@ -88,38 +127,66 @@ private RecoveredInputChannel getChannel(InputChannelInfo info) {\n \tprivate final ResultPartitionWriter[] writers;\n \tprivate final boolean notifyAndBlockOnCompletion;\n \n-\tResultSubpartitionRecoveredStateHandler(ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion) {\n+\tprivate final InflightDataRescalingDescriptor channelMapping;\n+\n+\tprivate final Map<ResultSubpartitionInfo, List<CheckpointedResultSubpartition>> rescaledChannels = new HashMap<>();\n+\n+\tResultSubpartitionRecoveredStateHandler(ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion, InflightDataRescalingDescriptor channelMapping) {\n \t\tthis.writers = writers;\n+\t\tthis.channelMapping = channelMapping;\n \t\tthis.notifyAndBlockOnCompletion = notifyAndBlockOnCompletion;\n \t}\n \n \t@Override\n \tpublic BufferWithContext<Tuple2<BufferBuilder, BufferConsumer>> getBuffer(ResultSubpartitionInfo subpartitionInfo) throws IOException, InterruptedException {\n-\t\tBufferBuilder bufferBuilder = getSubpartition(subpartitionInfo).requestBufferBuilderBlocking();\n+\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n+\t\tBufferBuilder bufferBuilder = channels.get(0).requestBufferBuilderBlocking();\n \t\treturn new BufferWithContext<>(wrap(bufferBuilder), Tuple2.of(bufferBuilder, bufferBuilder.createBufferConsumer()));\n \t}\n \n \t@Override\n-\tpublic void recover(ResultSubpartitionInfo subpartitionInfo, Tuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer) throws IOException {\n+\tpublic void recover(\n+\t\t\tResultSubpartitionInfo subpartitionInfo,\n+\t\t\tint oldSubtaskIndex,\n+\t\t\tTuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer) throws IOException {\n \t\tbufferBuilderAndConsumer.f0.finish();\n \t\tif (bufferBuilderAndConsumer.f1.isDataAvailable()) {\n-\t\t\tboolean added = getSubpartition(subpartitionInfo).add(bufferBuilderAndConsumer.f1, Integer.MIN_VALUE);\n-\t\t\tif (!added) {\n-\t\t\t\tthrow new IOException(\"Buffer consumer couldn't be added to ResultSubpartition\");\n+\t\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n+\t\t\tfor (final CheckpointedResultSubpartition channel : channels) {\n+\t\t\t\t// channel selector is created from the downstream's point of view: the subtask of downstream = subpartition index of recovered buffer\n+\t\t\t\tfinal VirtualChannelSelector channelSelector = new VirtualChannelSelector(subpartitionInfo.getSubPartitionIdx(), oldSubtaskIndex);\n+\t\t\t\tchannel.add(EventSerializer.toBufferConsumer(channelSelector, false), Integer.MIN_VALUE);\n+\t\t\t\tboolean added = channel.add(bufferBuilderAndConsumer.f1.copy(), Integer.MIN_VALUE);\n+\t\t\t\tif (!added) {\n+\t\t\t\t\tthrow new IOException(\"Buffer consumer couldn't be added to ResultSubpartition\");\n+\t\t\t\t}\n \t\t\t}\n-\t\t} else {\n-\t\t\tbufferBuilderAndConsumer.f1.close();\n \t\t}\n+\t\tbufferBuilderAndConsumer.f1.close();\n \t}\n \n-\tprivate CheckpointedResultSubpartition getSubpartition(ResultSubpartitionInfo subpartitionInfo) {\n-\t\tResultPartitionWriter writer = writers[subpartitionInfo.getPartitionIdx()];\n-\t\tif (writer instanceof CheckpointedResultPartition) {\n-\t\t\treturn ((CheckpointedResultPartition) writer).getCheckpointedSubpartition(subpartitionInfo.getSubPartitionIdx());\n-\t\t} else {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot restore state to a non-checkpointable partition type: \" + writer);\n+\tprivate CheckpointedResultSubpartition getSubpartition(int partitionIndex, int subPartitionIdx) {\n+\t\tResultPartitionWriter writer = writers[partitionIndex];\n+\t\tif (!(writer instanceof CheckpointedResultPartition)) {\n+\t\t\tthrow new IllegalStateException(\"Cannot restore state to a non-checkpointable partition type: \" + writer);\n \t\t}\n+\t\treturn ((CheckpointedResultPartition) writer).getCheckpointedSubpartition(subPartitionIdx);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 167}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2OTYyOA==", "bodyText": "The meaning of these fields is a bit ambiguous to me\n\nboth: is it upstream or downstream?\nchannelIndex: is it subPartition or inputChannel?\n\nSome javadoc would be helpful.", "url": "https://github.com/apache/flink/pull/13845#discussion_r519169628", "createdAt": "2020-11-07T11:52:17Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/VirtualChannelSelector.java", "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.io.network.api;\n+\n+import org.apache.flink.core.memory.DataInputView;\n+import org.apache.flink.core.memory.DataOutputView;\n+import org.apache.flink.runtime.event.RuntimeEvent;\n+\n+import java.util.Objects;\n+\n+/**\n+ * An event that is used to demultiplex virtual channels over the same physical channel.\n+ */\n+public final class VirtualChannelSelector extends RuntimeEvent {\n+\n+\tprivate final int subtaskIndex;\n+\tprivate final int channelIndex;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 32}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/215a25d83260a048877bdf8462a06473676efb8a", "committedDate": "2020-11-06T20:56:05Z", "message": "[FLINK-19801][tests] Adding unaligned checkpoint rescaling tests."}, "afterCommit": {"oid": "fe94615bb4be9771757f98e93ff11e8d765231f2", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/fe94615bb4be9771757f98e93ff11e8d765231f2", "committedDate": "2020-11-07T21:55:15Z", "message": "[FLINK-19801][tests] Adding unaligned checkpoint rescaling tests."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b9b727e26314e52b3af4f05a162a3284656d5a9e", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/b9b727e26314e52b3af4f05a162a3284656d5a9e", "committedDate": "2020-11-07T22:57:57Z", "message": "debug"}, "afterCommit": {"oid": "d4c46ab021f7d464004ca5f58589b25a5334f147", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/d4c46ab021f7d464004ca5f58589b25a5334f147", "committedDate": "2020-11-07T23:01:05Z", "message": "[FLINK-19801][checkpoint] Workaround for RescalePartitioner rescaling.\n\nPointwise connection require special treatment as channel state assignment needs to be aware of which channels are actually connected. The current SubtaskStateMapper assumes a full connection. This workaround simply uses the same guaranteed channel for all data."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e4bdf60dbf7a9939a9a6ad36f99feb7b4408952a", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/e4bdf60dbf7a9939a9a6ad36f99feb7b4408952a", "committedDate": "2020-11-08T08:47:18Z", "message": "fixup! [FLINK-19801][checkpoint/tests] Enable rescaling of unaligned checkpoints."}, "afterCommit": {"oid": "065111ae993c76425f60cfae89ff3ad7e2fa9b0b", "author": {"user": {"login": "pnowojski", "name": "Piotr Nowojski"}}, "url": "https://github.com/apache/flink/commit/065111ae993c76425f60cfae89ff3ad7e2fa9b0b", "committedDate": "2020-11-08T08:50:39Z", "message": "[FLINK-19681][network] Rewrite RemoteInputChannel#getInflightBuffersUnsafe to use sequence numbers\n\nThis will make this method more stable for changes of the internal state of the RemoteInputChannel\nwhen timeouting aligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8948e5212d42d5fe5a799182b9739c5ef27cbc39", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/8948e5212d42d5fe5a799182b9739c5ef27cbc39", "committedDate": "2020-11-08T08:53:13Z", "message": "recover"}, "afterCommit": {"oid": "d42e17ff93fab9f5e276fe257e687ac254bcd032", "author": {"user": {"login": "pnowojski", "name": "Piotr Nowojski"}}, "url": "https://github.com/apache/flink/commit/d42e17ff93fab9f5e276fe257e687ac254bcd032", "committedDate": "2020-11-08T08:53:32Z", "message": "[FLINK-19681][network] Rewrite RemoteInputChannel#getInflightBuffersUnsafe to use sequence numbers\n\nThis will make this method more stable for changes of the internal state of the RemoteInputChannel\nwhen timeouting aligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ac0e740ac6ee3d041009472c7609484d2cc4016d", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/ac0e740ac6ee3d041009472c7609484d2cc4016d", "committedDate": "2020-11-08T09:14:07Z", "message": "barrier"}, "afterCommit": {"oid": "618de0adf81af944db70b96b9cdd4e744083901d", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/618de0adf81af944db70b96b9cdd4e744083901d", "committedDate": "2020-11-08T09:15:06Z", "message": "fixup! [FLINK-19801][tests] Adding unaligned checkpoint rescaling tests."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "618de0adf81af944db70b96b9cdd4e744083901d", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/618de0adf81af944db70b96b9cdd4e744083901d", "committedDate": "2020-11-08T09:15:06Z", "message": "fixup! [FLINK-19801][tests] Adding unaligned checkpoint rescaling tests."}, "afterCommit": {"oid": "4833cee3e9468e7f3e2db03548c7392ac1d213ea", "author": {"user": {"login": "pnowojski", "name": "Piotr Nowojski"}}, "url": "https://github.com/apache/flink/commit/4833cee3e9468e7f3e2db03548c7392ac1d213ea", "committedDate": "2020-11-08T09:15:39Z", "message": "[FLINK-19681][network] Rewrite RemoteInputChannel#getInflightBuffersUnsafe to use sequence numbers\n\nThis will make this method more stable for changes of the internal state of the RemoteInputChannel\nwhen timeouting aligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "7991853561dd95a523d38cc5dc566cdea4b1f43d", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/7991853561dd95a523d38cc5dc566cdea4b1f43d", "committedDate": "2020-11-09T10:32:37Z", "message": "WIP"}, "afterCommit": {"oid": "b213a408455370ffbf5b7f8d822476090fa00768", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/b213a408455370ffbf5b7f8d822476090fa00768", "committedDate": "2021-02-09T13:59:13Z", "message": "WIP"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b213a408455370ffbf5b7f8d822476090fa00768", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/b213a408455370ffbf5b7f8d822476090fa00768", "committedDate": "2021-02-09T13:59:13Z", "message": "WIP"}, "afterCommit": {"oid": "a9be96267d6c3a7e520baae06515fddf93494c87", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/a9be96267d6c3a7e520baae06515fddf93494c87", "committedDate": "2021-02-09T18:51:52Z", "message": "[FLINK-19801][tests] Adding unaligned checkpoint rescaling tests."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a9be96267d6c3a7e520baae06515fddf93494c87", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/a9be96267d6c3a7e520baae06515fddf93494c87", "committedDate": "2021-02-09T18:51:52Z", "message": "[FLINK-19801][tests] Adding unaligned checkpoint rescaling tests."}, "afterCommit": {"oid": "21cd123825409239bbd12fc87b39fe2b14c7efca", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/21cd123825409239bbd12fc87b39fe2b14c7efca", "committedDate": "2021-02-09T19:50:30Z", "message": "[FLINK-19801][tests] Adding unaligned checkpoint rescaling tests."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "21cd123825409239bbd12fc87b39fe2b14c7efca", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/21cd123825409239bbd12fc87b39fe2b14c7efca", "committedDate": "2021-02-09T19:50:30Z", "message": "[FLINK-19801][tests] Adding unaligned checkpoint rescaling tests."}, "afterCommit": {"oid": "a9ca4b55551e6a9785a6b156c76134a8e9dba6b2", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/a9ca4b55551e6a9785a6b156c76134a8e9dba6b2", "committedDate": "2021-02-09T20:15:04Z", "message": "[FLINK-19801][checkpoint/tests] Enable rescaling of unaligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a9ca4b55551e6a9785a6b156c76134a8e9dba6b2", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/a9ca4b55551e6a9785a6b156c76134a8e9dba6b2", "committedDate": "2021-02-09T20:15:04Z", "message": "[FLINK-19801][checkpoint/tests] Enable rescaling of unaligned checkpoints."}, "afterCommit": {"oid": "68f5ccd7d4103f9bc573ac6eb564442af8a93093", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/68f5ccd7d4103f9bc573ac6eb564442af8a93093", "committedDate": "2021-02-11T08:07:03Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "68f5ccd7d4103f9bc573ac6eb564442af8a93093", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/68f5ccd7d4103f9bc573ac6eb564442af8a93093", "committedDate": "2021-02-11T08:07:03Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}, "afterCommit": {"oid": "1fbb6064b8a707410a2bfb1a2a08e6c3d91a1d3a", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/1fbb6064b8a707410a2bfb1a2a08e6c3d91a1d3a", "committedDate": "2021-02-11T09:26:09Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e096f801ad56d5f635e49410533ae040429e9e87", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/e096f801ad56d5f635e49410533ae040429e9e87", "committedDate": "2021-02-11T12:49:40Z", "message": "fixup! [FLINK-19801][checkpoint/tests] Enable rescaling of unaligned checkpoints."}, "afterCommit": {"oid": "0883646d13efbbe7ecee1167dded6aceaecb9276", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/0883646d13efbbe7ecee1167dded6aceaecb9276", "committedDate": "2021-02-11T12:49:49Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0883646d13efbbe7ecee1167dded6aceaecb9276", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/0883646d13efbbe7ecee1167dded6aceaecb9276", "committedDate": "2021-02-11T12:49:49Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}, "afterCommit": {"oid": "0d7b88564d939fbc7480f3654cac8fdb7a36cf11", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/0d7b88564d939fbc7480f3654cac8fdb7a36cf11", "committedDate": "2021-02-11T12:59:00Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0d7b88564d939fbc7480f3654cac8fdb7a36cf11", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/0d7b88564d939fbc7480f3654cac8fdb7a36cf11", "committedDate": "2021-02-11T12:59:00Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}, "afterCommit": {"oid": "f032d1e223ce3a5348c303678a777427155cc9bd", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/f032d1e223ce3a5348c303678a777427155cc9bd", "committedDate": "2021-02-12T10:36:37Z", "message": "[FLINK-19801][task] Add RecoverableStreamTaskInput."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f032d1e223ce3a5348c303678a777427155cc9bd", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/f032d1e223ce3a5348c303678a777427155cc9bd", "committedDate": "2021-02-12T10:36:37Z", "message": "[FLINK-19801][task] Add RecoverableStreamTaskInput."}, "afterCommit": {"oid": "e2451014f2e6b880534f58217a4fd546105ccb0d", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/e2451014f2e6b880534f58217a4fd546105ccb0d", "committedDate": "2021-02-12T11:43:36Z", "message": "[FLINK-19801][task] Refactor out AbstractStreamTaskNetworkInput from StreamTaskNetworkInput.\n\nAbstractStreamTaskNetworkInput will become the base of RescalingStreamTaskNetworkInput in the next commit."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0dcc860fa599af780ed5bc8878460e4c02def214", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/0dcc860fa599af780ed5bc8878460e4c02def214", "committedDate": "2021-02-12T11:43:49Z", "message": "fixup! [FLINK-19801][task] Implement virtual channel demultiplexing in RecoveringStreamTaskNetworkInput."}, "afterCommit": {"oid": "82c63754e045bbf35991bcd54ce1b01a6cf48f9d", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/82c63754e045bbf35991bcd54ce1b01a6cf48f9d", "committedDate": "2021-02-12T14:28:00Z", "message": "[FLINK-19801][checkpoint] StreamTaskInput#prepareSnapshot throws CheckpointException to allow declining checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "bd19c1de8ab58c30e0ecc87f260cb1d71091564e", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/bd19c1de8ab58c30e0ecc87f260cb1d71091564e", "committedDate": "2021-02-12T14:28:30Z", "message": "fixup! [FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}, "afterCommit": {"oid": "8750e7df6a86754a5471aab506328113c62a6b7f", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/8750e7df6a86754a5471aab506328113c62a6b7f", "committedDate": "2021-02-12T14:29:06Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "7c4340de595fb48fc713ca46b192a8b125fa3443", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/7c4340de595fb48fc713ca46b192a8b125fa3443", "committedDate": "2021-02-13T12:37:40Z", "message": "fixup! [FLINK-19801][task] Implement virtual channel demultiplexing in RecoveringStreamTaskNetworkInput."}, "afterCommit": {"oid": "774734ce04b6b8e25eb3292e4783dfbff0524694", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/774734ce04b6b8e25eb3292e4783dfbff0524694", "committedDate": "2021-02-13T21:04:34Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c2c57f1b2c9b3e216d7ad2917954de9825852894", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/c2c57f1b2c9b3e216d7ad2917954de9825852894", "committedDate": "2021-02-13T21:07:23Z", "message": "Fix enable"}, "afterCommit": {"oid": "ab33d2fd14138a0652673af3a406c2bbf10ecf03", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/ab33d2fd14138a0652673af3a406c2bbf10ecf03", "committedDate": "2021-02-13T21:08:17Z", "message": "Fix enable"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e4e9faa2deb1791c9ad632b897f5294e9dea402e", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/e4e9faa2deb1791c9ad632b897f5294e9dea402e", "committedDate": "2021-02-13T22:04:09Z", "message": "fixup! [FLINK-19801][checkpoint/tests] Enable rescaling of unaligned checkpoints."}, "afterCommit": {"oid": "b459f4bd20940e7c2da1b10400b5c6970165fc69", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/b459f4bd20940e7c2da1b10400b5c6970165fc69", "committedDate": "2021-02-13T22:04:31Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b459f4bd20940e7c2da1b10400b5c6970165fc69", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/b459f4bd20940e7c2da1b10400b5c6970165fc69", "committedDate": "2021-02-13T22:04:31Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}, "afterCommit": {"oid": "4fcb702603dee9266b4e116aa42ea6a9aa87dccd", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/4fcb702603dee9266b4e116aa42ea6a9aa87dccd", "committedDate": "2021-02-14T16:21:44Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9462a10cf044c5e31295c28af780a164303926c3", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/9462a10cf044c5e31295c28af780a164303926c3", "committedDate": "2021-02-14T16:22:08Z", "message": "fix enable"}, "afterCommit": {"oid": "43292615b3902997d18077f4864ef6fe67623361", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/43292615b3902997d18077f4864ef6fe67623361", "committedDate": "2021-02-14T16:22:28Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ce08200f4839675ac5fabb29ddd3db4a7714b3ad", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/ce08200f4839675ac5fabb29ddd3db4a7714b3ad", "committedDate": "2021-02-14T16:25:27Z", "message": "fixup! [FLINK-19801][task] Extract AbstractStreamTaskNetworkInput from StreamTaskNetworkInput."}, "afterCommit": {"oid": "f649ade692dbeca84b697eb9a0d1fccceee40a08", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/f649ade692dbeca84b697eb9a0d1fccceee40a08", "committedDate": "2021-02-14T16:25:47Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f649ade692dbeca84b697eb9a0d1fccceee40a08", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/f649ade692dbeca84b697eb9a0d1fccceee40a08", "committedDate": "2021-02-14T16:25:47Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}, "afterCommit": {"oid": "aff3dbce3c1350c46bdb15d03e721d543fa2ce1c", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/aff3dbce3c1350c46bdb15d03e721d543fa2ce1c", "committedDate": "2021-02-14T20:54:45Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0b81cee00a166935ef7bb301502f81fe39b57c6e", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/0b81cee00a166935ef7bb301502f81fe39b57c6e", "committedDate": "2021-02-14T20:55:45Z", "message": "Ex"}, "afterCommit": {"oid": "a2e14823f1f9d7a983d89685982675fb322d6cc6", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/a2e14823f1f9d7a983d89685982675fb322d6cc6", "committedDate": "2021-02-14T20:56:04Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a2e14823f1f9d7a983d89685982675fb322d6cc6", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/a2e14823f1f9d7a983d89685982675fb322d6cc6", "committedDate": "2021-02-14T20:56:04Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}, "afterCommit": {"oid": "40df152c0e68b41b9ef4402afe092127ffb2e301", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/40df152c0e68b41b9ef4402afe092127ffb2e301", "committedDate": "2021-02-14T21:32:19Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "40df152c0e68b41b9ef4402afe092127ffb2e301", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/40df152c0e68b41b9ef4402afe092127ffb2e301", "committedDate": "2021-02-14T21:32:19Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}, "afterCommit": {"oid": "d4c5d3c5f64ac6fd5e56e8d03f7cacde0c4f47ae", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/d4c5d3c5f64ac6fd5e56e8d03f7cacde0c4f47ae", "committedDate": "2021-02-14T22:56:11Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d4c5d3c5f64ac6fd5e56e8d03f7cacde0c4f47ae", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/d4c5d3c5f64ac6fd5e56e8d03f7cacde0c4f47ae", "committedDate": "2021-02-14T22:56:11Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}, "afterCommit": {"oid": "8d923b13196a20f9f570e75ae002e95483bb3cac", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/8d923b13196a20f9f570e75ae002e95483bb3cac", "committedDate": "2021-02-15T06:50:21Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8d923b13196a20f9f570e75ae002e95483bb3cac", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/8d923b13196a20f9f570e75ae002e95483bb3cac", "committedDate": "2021-02-15T06:50:21Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}, "afterCommit": {"oid": "35e7438b7a0e6f338deed136a9c13ff4e3a00ed3", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/35e7438b7a0e6f338deed136a9c13ff4e3a00ed3", "committedDate": "2021-02-15T08:57:55Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "35e7438b7a0e6f338deed136a9c13ff4e3a00ed3", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/35e7438b7a0e6f338deed136a9c13ff4e3a00ed3", "committedDate": "2021-02-15T08:57:55Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}, "afterCommit": {"oid": "518b126d21bf2fbc00dfcbcc5ef9bb24bbf43879", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/518b126d21bf2fbc00dfcbcc5ef9bb24bbf43879", "committedDate": "2021-02-15T09:01:50Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "518b126d21bf2fbc00dfcbcc5ef9bb24bbf43879", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/518b126d21bf2fbc00dfcbcc5ef9bb24bbf43879", "committedDate": "2021-02-15T09:01:50Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}, "afterCommit": {"oid": "277ff2e661f73b8468068378b7e33e90484068cc", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/277ff2e661f73b8468068378b7e33e90484068cc", "committedDate": "2021-02-15T23:22:23Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "277ff2e661f73b8468068378b7e33e90484068cc", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/277ff2e661f73b8468068378b7e33e90484068cc", "committedDate": "2021-02-15T23:22:23Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}, "afterCommit": {"oid": "c202f5134a17dd652eb072d00d5fca894936cdaf", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/c202f5134a17dd652eb072d00d5fca894936cdaf", "committedDate": "2021-02-16T06:58:31Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c202f5134a17dd652eb072d00d5fca894936cdaf", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/c202f5134a17dd652eb072d00d5fca894936cdaf", "committedDate": "2021-02-16T06:58:31Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}, "afterCommit": {"oid": "8338e7e04da927499aad2934bb35d6ebf6484216", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/8338e7e04da927499aad2934bb35d6ebf6484216", "committedDate": "2021-02-16T21:28:41Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9fa9f241fdd9d89b6fb7fd1c206e16259cd0e8bb", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/9fa9f241fdd9d89b6fb7fd1c206e16259cd0e8bb", "committedDate": "2021-02-16T21:30:16Z", "message": "fix impl"}, "afterCommit": {"oid": "ac9c455d8ec0ebbebb4877bfd3a01e6ba4935f85", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/ac9c455d8ec0ebbebb4877bfd3a01e6ba4935f85", "committedDate": "2021-02-16T21:32:27Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ac9c455d8ec0ebbebb4877bfd3a01e6ba4935f85", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/ac9c455d8ec0ebbebb4877bfd3a01e6ba4935f85", "committedDate": "2021-02-16T21:32:27Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}, "afterCommit": {"oid": "58ad351699ca35b844d22c415d5ebe075d941839", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/58ad351699ca35b844d22c415d5ebe075d941839", "committedDate": "2021-02-17T08:14:39Z", "message": "fixup! [FLINK-19801][checkpoint/tests] Enable rescaling of unaligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "58ad351699ca35b844d22c415d5ebe075d941839", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/58ad351699ca35b844d22c415d5ebe075d941839", "committedDate": "2021-02-17T08:14:39Z", "message": "fixup! [FLINK-19801][checkpoint/tests] Enable rescaling of unaligned checkpoints."}, "afterCommit": {"oid": "6ce8c2c259ecc7e62a94a9723eb48816b1e997bb", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/6ce8c2c259ecc7e62a94a9723eb48816b1e997bb", "committedDate": "2021-02-17T10:20:41Z", "message": "fixup! [FLINK-19801][checkpoint] Expose rescale descriptors in TaskStateManager and add ambiguity of subtasks + max parallelism."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "6ce8c2c259ecc7e62a94a9723eb48816b1e997bb", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/6ce8c2c259ecc7e62a94a9723eb48816b1e997bb", "committedDate": "2021-02-17T10:20:41Z", "message": "fixup! [FLINK-19801][checkpoint] Expose rescale descriptors in TaskStateManager and add ambiguity of subtasks + max parallelism."}, "afterCommit": {"oid": "85ed74ff5e1f0bcf04b89d0eb27260fdf6741d38", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/85ed74ff5e1f0bcf04b89d0eb27260fdf6741d38", "committedDate": "2021-02-17T10:48:46Z", "message": "fixup! [FLINK-19801][checkpoint] Expose rescale descriptors in TaskStateManager and add ambiguity of subtasks + max parallelism."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e44f8ca0b2d93a28b5d6269287fc5bc0fb70039f", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/e44f8ca0b2d93a28b5d6269287fc5bc0fb70039f", "committedDate": "2021-02-17T10:48:54Z", "message": "fixup! [FLINK-19801][network] Simplify RecordDeserializer interface."}, "afterCommit": {"oid": "da33f0698acce47a96bfea1f03bbc98089e03aaa", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/da33f0698acce47a96bfea1f03bbc98089e03aaa", "committedDate": "2021-02-17T13:03:54Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0826b90e93ad11d1c51b2804066ff8c22376bd75", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/0826b90e93ad11d1c51b2804066ff8c22376bd75", "committedDate": "2021-02-17T15:05:01Z", "message": "expose"}, "afterCommit": {"oid": "9fa10d5fbd744c8d6a3a9107635ec4a385db1a3a", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/9fa10d5fbd744c8d6a3a9107635ec4a385db1a3a", "committedDate": "2021-02-17T15:05:16Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8cc2e0b15c68e22dff3805266d15eac38bfea9f0", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/8cc2e0b15c68e22dff3805266d15eac38bfea9f0", "committedDate": "2021-02-22T08:34:59Z", "message": "[FLINK-19801][task] Implement virtual channel demultiplexing in RecoveringStreamTaskNetworkInput."}, "afterCommit": {"oid": "e32883659f2d6b2b6204ca0d1dd515b79273ced9", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/e32883659f2d6b2b6204ca0d1dd515b79273ced9", "committedDate": "2021-02-22T08:35:27Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "2b88fd4c7e5009c68c19dba44f3dcef7216e4142", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/2b88fd4c7e5009c68c19dba44f3dcef7216e4142", "committedDate": "2021-02-22T08:54:01Z", "message": "expose"}, "afterCommit": {"oid": "8fba8702832690f8486239f36aa9317d73d506bd", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/8fba8702832690f8486239f36aa9317d73d506bd", "committedDate": "2021-02-22T08:54:25Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8fba8702832690f8486239f36aa9317d73d506bd", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/8fba8702832690f8486239f36aa9317d73d506bd", "committedDate": "2021-02-22T08:54:25Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}, "afterCommit": {"oid": "e4d94737381e114c248b771cd6eae4f9ac7aa32a", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/e4d94737381e114c248b771cd6eae4f9ac7aa32a", "committedDate": "2021-02-22T18:05:49Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e4d94737381e114c248b771cd6eae4f9ac7aa32a", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/e4d94737381e114c248b771cd6eae4f9ac7aa32a", "committedDate": "2021-02-22T18:05:49Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}, "afterCommit": {"oid": "c9d1296c3deac93ad1d9c2c60df53fb104e44c2f", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/c9d1296c3deac93ad1d9c2c60df53fb104e44c2f", "committedDate": "2021-02-22T19:52:01Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c9d1296c3deac93ad1d9c2c60df53fb104e44c2f", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/c9d1296c3deac93ad1d9c2c60df53fb104e44c2f", "committedDate": "2021-02-22T19:52:01Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}, "afterCommit": {"oid": "97d05dfe907b8d72e6cb6c941946acb215a6d867", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/97d05dfe907b8d72e6cb6c941946acb215a6d867", "committedDate": "2021-02-23T20:32:02Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "97d05dfe907b8d72e6cb6c941946acb215a6d867", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/97d05dfe907b8d72e6cb6c941946acb215a6d867", "committedDate": "2021-02-23T20:32:02Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}, "afterCommit": {"oid": "4350b9b923b9d349698e94c8d8c030003e760546", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/4350b9b923b9d349698e94c8d8c030003e760546", "committedDate": "2021-02-23T20:32:38Z", "message": "[FLINK-19801][checkpoint/tests] Enable rescaling of unaligned checkpoints."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTk5MzgxMDMw", "url": "https://github.com/apache/flink/pull/13845#pullrequestreview-599381030", "createdAt": "2021-02-26T09:10:46Z", "commit": {"oid": "bd18dbb4154a033a55320c2740e2499ac7d63ff9"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yNlQwOToxMDo0N1rOIsdYeg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yNlQxMDoxNTo0MFrOIsf2Dg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzQ4OTY1OA==", "bodyText": "I'm wondering whether it's possible that the record will be discarded because the partitioner always chooses the \"other\" subtask?\nFor example, in an up-scaling from 1 to 2 scenario with RoundRobin partitioner:\n\nlet subtask0.rrPartitioner.nextChannelToSendTo = 0\nselectChannel returns 1 - filtered out\nlet subtask1.rrPartitioner.nextChannelToSendTo = 1 (some record was already processed)\nselectChannel returns 0 - filtered out", "url": "https://github.com/apache/flink/pull/13845#discussion_r583489658", "createdAt": "2021-02-26T09:10:47Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RecordFilter.java", "diffHunk": "@@ -0,0 +1,64 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io.recovery;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.io.network.api.writer.ChannelSelector;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElementSerializer;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+\n+import java.util.function.Predicate;\n+\n+/**\n+ * Filters records for ambiguous channel mappings.\n+ *\n+ * <p>For example, when the downstream node of a keyed exchange is scaled from 1 to 2, the state of\n+ * the output side on te upstream node needs to be replicated to both channels. This filter then\n+ * checks the deserialized records on both downstream subtasks and filters out the irrelevant\n+ * records.\n+ *\n+ * @param <T>\n+ */\n+class RecordFilter<T> implements Predicate<StreamRecord<T>> {\n+    private final ChannelSelector<SerializationDelegate<StreamRecord<T>>> partitioner;\n+\n+    private final SerializationDelegate<StreamRecord<T>> delegate;\n+\n+    private final int subtaskIndex;\n+\n+    public RecordFilter(\n+            ChannelSelector<SerializationDelegate<StreamRecord<T>>> partitioner,\n+            TypeSerializer<T> inputSerializer,\n+            int subtaskIndex) {\n+        this.partitioner = partitioner;\n+        delegate = new SerializationDelegate<>(new StreamElementSerializer(inputSerializer));\n+        this.subtaskIndex = subtaskIndex;\n+    }\n+\n+    public static <T> Predicate<StreamRecord<T>> all() {\n+        return record -> true;\n+    }\n+\n+    @Override\n+    public boolean test(StreamRecord<T> streamRecord) {\n+        delegate.setInstance(streamRecord);\n+        // check if record would have arrived at this subtask if it had been partitioned upstream\n+        return partitioner.selectChannel(delegate) == subtaskIndex;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd18dbb4154a033a55320c2740e2499ac7d63ff9"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzQ5MDQyMA==", "bodyText": "Should it be in finally?", "url": "https://github.com/apache/flink/pull/13845#discussion_r583490420", "createdAt": "2021-02-26T09:11:55Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java", "diffHunk": "@@ -45,32 +55,46 @@\n \n     BufferWithContext<Context> getBuffer(Info info) throws IOException, InterruptedException;\n \n-    void recover(Info info, Context context) throws IOException;\n+    void recover(Info info, int oldSubtaskIndex, Context context) throws IOException;\n }\n \n class InputChannelRecoveredStateHandler\n         implements RecoveredChannelStateHandler<InputChannelInfo, Buffer> {\n     private final InputGate[] inputGates;\n \n-    InputChannelRecoveredStateHandler(InputGate[] inputGates) {\n+    private final InflightDataRescalingDescriptor channelMapping;\n+\n+    private final Map<InputChannelInfo, List<RecoveredInputChannel>> rescaledChannels =\n+            new HashMap<>();\n+\n+    InputChannelRecoveredStateHandler(\n+            InputGate[] inputGates, InflightDataRescalingDescriptor channelMapping) {\n         this.inputGates = inputGates;\n+        this.channelMapping = channelMapping;\n     }\n \n     @Override\n     public BufferWithContext<Buffer> getBuffer(InputChannelInfo channelInfo)\n             throws IOException, InterruptedException {\n-        RecoveredInputChannel channel = getChannel(channelInfo);\n+        RecoveredInputChannel channel = getMappedChannels(channelInfo).get(0);\n         Buffer buffer = channel.requestBufferBlocking();\n         return new BufferWithContext<>(wrap(buffer), buffer);\n     }\n \n     @Override\n-    public void recover(InputChannelInfo channelInfo, Buffer buffer) {\n+    public void recover(InputChannelInfo channelInfo, int oldSubtaskIndex, Buffer buffer)\n+            throws IOException {\n         if (buffer.readableBytes() > 0) {\n-            getChannel(channelInfo).onRecoveredStateBuffer(buffer);\n-        } else {\n-            buffer.recycleBuffer();\n+            for (final RecoveredInputChannel channel : getMappedChannels(channelInfo)) {\n+                channel.onRecoveredStateBuffer(\n+                        EventSerializer.toBuffer(\n+                                new VirtualChannelSelector(\n+                                        oldSubtaskIndex, channelInfo.getInputChannelIdx()),\n+                                false));\n+                channel.onRecoveredStateBuffer(buffer.retainBuffer());\n+            }\n         }\n+        buffer.recycleBuffer();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd18dbb4154a033a55320c2740e2499ac7d63ff9"}, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzQ5MDc2MQ==", "bodyText": "Should it be in finally?", "url": "https://github.com/apache/flink/pull/13845#discussion_r583490761", "createdAt": "2021-02-26T09:12:29Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java", "diffHunk": "@@ -121,27 +181,59 @@ public void recover(\n                     \"ResultSubpartitionRecoveredStateHandler#recover\",\n                     bufferBuilderAndConsumer.f1,\n                     subpartitionInfo);\n-            boolean added =\n-                    getSubpartition(subpartitionInfo)\n-                            .add(bufferBuilderAndConsumer.f1, Integer.MIN_VALUE);\n-            if (!added) {\n-                throw new IOException(\"Buffer consumer couldn't be added to ResultSubpartition\");\n+            final List<CheckpointedResultSubpartition> channels =\n+                    getMappedChannels(subpartitionInfo);\n+            for (final CheckpointedResultSubpartition channel : channels) {\n+                // channel selector is created from the downstream's point of view: the subtask of\n+                // downstream = subpartition index of recovered buffer\n+                final VirtualChannelSelector channelSelector =\n+                        new VirtualChannelSelector(\n+                                subpartitionInfo.getSubPartitionIdx(), oldSubtaskIndex);\n+                channel.add(\n+                        EventSerializer.toBufferConsumer(channelSelector, false),\n+                        Integer.MIN_VALUE);\n+                boolean added = channel.add(bufferBuilderAndConsumer.f1.copy(), Integer.MIN_VALUE);\n+                if (!added) {\n+                    throw new IOException(\n+                            \"Buffer consumer couldn't be added to ResultSubpartition\");\n+                }\n             }\n-        } else {\n-            bufferBuilderAndConsumer.f1.close();\n         }\n+        bufferBuilderAndConsumer.f1.close();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd18dbb4154a033a55320c2740e2499ac7d63ff9"}, "originalPosition": 188}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzQ5MTgyMA==", "bodyText": "I guess get(0) is used here because the actual subpartition that we use to request a buffer from doesn't matter.\nIf so, could you please add a comment in the code?", "url": "https://github.com/apache/flink/pull/13845#discussion_r583491820", "createdAt": "2021-02-26T09:14:09Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java", "diffHunk": "@@ -94,17 +145,25 @@ private RecoveredInputChannel getChannel(InputChannelInfo info) {\n     private final ResultPartitionWriter[] writers;\n     private final boolean notifyAndBlockOnCompletion;\n \n+    private final InflightDataRescalingDescriptor channelMapping;\n+\n+    private final Map<ResultSubpartitionInfo, List<CheckpointedResultSubpartition>>\n+            rescaledChannels = new HashMap<>();\n+\n     ResultSubpartitionRecoveredStateHandler(\n-            ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion) {\n+            ResultPartitionWriter[] writers,\n+            boolean notifyAndBlockOnCompletion,\n+            InflightDataRescalingDescriptor channelMapping) {\n         this.writers = writers;\n+        this.channelMapping = channelMapping;\n         this.notifyAndBlockOnCompletion = notifyAndBlockOnCompletion;\n     }\n \n     @Override\n     public BufferWithContext<Tuple2<BufferBuilder, BufferConsumer>> getBuffer(\n             ResultSubpartitionInfo subpartitionInfo) throws IOException, InterruptedException {\n-        BufferBuilder bufferBuilder =\n-                getSubpartition(subpartitionInfo).requestBufferBuilderBlocking();\n+        final List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n+        BufferBuilder bufferBuilder = channels.get(0).requestBufferBuilderBlocking();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd18dbb4154a033a55320c2740e2499ac7d63ff9"}, "originalPosition": 147}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzQ5ODExMw==", "bodyText": "nit: To me SubtaskConnectionDescriptor would be more informative. But that's a matter of taste so please ignore if you prefer VirtualChannelSelector.\nnit: virtual/physical channels in javadoc are confusing to me. How about channels before/after re-scaling? For example:\nAn event sent over a channel after re-scaling to signal what channel was used before re-scaling for the data being sent.", "url": "https://github.com/apache/flink/pull/13845#discussion_r583498113", "createdAt": "2021-02-26T09:23:56Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/VirtualChannelSelector.java", "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.io.network.api;\n+\n+import org.apache.flink.core.memory.DataInputView;\n+import org.apache.flink.core.memory.DataOutputView;\n+import org.apache.flink.runtime.event.RuntimeEvent;\n+\n+import java.util.Objects;\n+\n+/** An event that is used to demultiplex virtual channels over the same physical channel. */\n+public final class VirtualChannelSelector extends RuntimeEvent {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd18dbb4154a033a55320c2740e2499ac7d63ff9"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzQ5OTU2Ng==", "bodyText": "How about moving this (and other) static methods to a dedicated factory class?\nTo me the responsibility of this class would be more clear.", "url": "https://github.com/apache/flink/pull/13845#discussion_r583499566", "createdAt": "2021-02-26T09:26:09Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java", "diffHunk": "@@ -0,0 +1,280 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io.recovery;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.TaskInfo;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.io.InputStatus;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.event.AbstractEvent;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.partition.consumer.BufferOrEvent;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput;\n+import org.apache.flink.streaming.runtime.io.RecoverableStreamTaskInput;\n+import org.apache.flink.streaming.runtime.io.StreamTaskInput;\n+import org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput;\n+import org.apache.flink.streaming.runtime.io.checkpointing.CheckpointedInputGate;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StatusWatermarkValve;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+\n+import static org.apache.flink.runtime.checkpoint.CheckpointFailureReason.CHECKPOINT_DECLINED_TASK_NOT_READY;\n+\n+/**\n+ * A {@link StreamTaskNetworkInput} implementation that demultiplexes virtual channels.\n+ *\n+ * <p>The demultiplexing works in two dimensions for the following cases. *\n+ *\n+ * <ul>\n+ *   <li>Subtasks of the current operator have been collapsed in a round-robin fashion.\n+ *   <li>The connected output operator has been rescaled (up and down!) and there is an overlap of\n+ *       channels (mostly relevant to keyed exchanges).\n+ * </ul>\n+ *\n+ * <p>In both cases, records from multiple old channels are received over one new physical channel,\n+ * which need to demultiplex the record to correctly restore spanning records (similar to how\n+ * StreamTaskNetworkInput works).\n+ *\n+ * <p>Note that when both cases occur at the same time (downscaling of several operators), there is\n+ * the cross product of channels. So if two subtasks are collapsed and two channels overlap from the\n+ * output side, there is a total of 4 virtual channels.\n+ */\n+@Internal\n+public final class RescalingStreamTaskNetworkInput<T>\n+        extends AbstractStreamTaskNetworkInput<T, DemultiplexingRecordDeserializer<T>>\n+        implements RecoverableStreamTaskInput<T> {\n+\n+    private static final Logger LOG =\n+            LoggerFactory.getLogger(RescalingStreamTaskNetworkInput.class);\n+    private final IOManager ioManager;\n+\n+    private RescalingStreamTaskNetworkInput(\n+            CheckpointedInputGate checkpointedInputGate,\n+            TypeSerializer<T> inputSerializer,\n+            IOManager ioManager,\n+            StatusWatermarkValve statusWatermarkValve,\n+            int inputIndex,\n+            InflightDataRescalingDescriptor inflightDataRescalingDescriptor,\n+            Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+            TaskInfo taskInfo) {\n+        super(\n+                checkpointedInputGate,\n+                inputSerializer,\n+                statusWatermarkValve,\n+                inputIndex,\n+                getRecordDeserializers(\n+                        checkpointedInputGate,\n+                        inputSerializer,\n+                        ioManager,\n+                        inflightDataRescalingDescriptor,\n+                        gatePartitioners,\n+                        taskInfo));\n+        this.ioManager = ioManager;\n+\n+        LOG.info(\n+                \"Created demultiplexer for input {} from {}\",\n+                inputIndex,\n+                inflightDataRescalingDescriptor);\n+    }\n+\n+    private static <T>\n+            Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> getRecordDeserializers(\n+                    CheckpointedInputGate checkpointedInputGate,\n+                    TypeSerializer<T> inputSerializer,\n+                    IOManager ioManager,\n+                    InflightDataRescalingDescriptor rescalingDescriptor,\n+                    Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+                    TaskInfo taskInfo) {\n+\n+        RecordFilterFactory<T> recordFilterFactory =\n+                new RecordFilterFactory<>(\n+                        taskInfo.getIndexOfThisSubtask(),\n+                        inputSerializer,\n+                        taskInfo.getNumberOfParallelSubtasks(),\n+                        gatePartitioners,\n+                        taskInfo.getMaxNumberOfParallelSubtasks());\n+        final DeserializerFactory deserializerFactory = new DeserializerFactory(ioManager);\n+        Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> deserializers =\n+                Maps.newHashMapWithExpectedSize(checkpointedInputGate.getChannelInfos().size());\n+        for (InputChannelInfo channelInfo : checkpointedInputGate.getChannelInfos()) {\n+            deserializers.put(\n+                    channelInfo,\n+                    DemultiplexingRecordDeserializer.create(\n+                            channelInfo,\n+                            rescalingDescriptor,\n+                            deserializerFactory,\n+                            recordFilterFactory));\n+        }\n+        return deserializers;\n+    }\n+\n+    @Override\n+    public StreamTaskInput<T> finishRecovery() throws IOException {\n+        close();\n+        return new StreamTaskNetworkInput<>(\n+                checkpointedInputGate,\n+                inputSerializer,\n+                ioManager,\n+                statusWatermarkValve,\n+                inputIndex);\n+    }\n+\n+    /**\n+     * Factory method for {@link StreamTaskNetworkInput} or {@link RescalingStreamTaskNetworkInput}\n+     * depending on {@link InflightDataRescalingDescriptor}.\n+     */\n+    public static <T> StreamTaskInput<T> create(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd18dbb4154a033a55320c2740e2499ac7d63ff9"}, "originalPosition": 163}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzUwMDI1OA==", "bodyText": "nit: super.getActiveSerializer(channelInfo);", "url": "https://github.com/apache/flink/pull/13845#discussion_r583500258", "createdAt": "2021-02-26T09:27:15Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java", "diffHunk": "@@ -0,0 +1,280 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io.recovery;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.TaskInfo;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.io.InputStatus;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.event.AbstractEvent;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.partition.consumer.BufferOrEvent;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput;\n+import org.apache.flink.streaming.runtime.io.RecoverableStreamTaskInput;\n+import org.apache.flink.streaming.runtime.io.StreamTaskInput;\n+import org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput;\n+import org.apache.flink.streaming.runtime.io.checkpointing.CheckpointedInputGate;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StatusWatermarkValve;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+\n+import static org.apache.flink.runtime.checkpoint.CheckpointFailureReason.CHECKPOINT_DECLINED_TASK_NOT_READY;\n+\n+/**\n+ * A {@link StreamTaskNetworkInput} implementation that demultiplexes virtual channels.\n+ *\n+ * <p>The demultiplexing works in two dimensions for the following cases. *\n+ *\n+ * <ul>\n+ *   <li>Subtasks of the current operator have been collapsed in a round-robin fashion.\n+ *   <li>The connected output operator has been rescaled (up and down!) and there is an overlap of\n+ *       channels (mostly relevant to keyed exchanges).\n+ * </ul>\n+ *\n+ * <p>In both cases, records from multiple old channels are received over one new physical channel,\n+ * which need to demultiplex the record to correctly restore spanning records (similar to how\n+ * StreamTaskNetworkInput works).\n+ *\n+ * <p>Note that when both cases occur at the same time (downscaling of several operators), there is\n+ * the cross product of channels. So if two subtasks are collapsed and two channels overlap from the\n+ * output side, there is a total of 4 virtual channels.\n+ */\n+@Internal\n+public final class RescalingStreamTaskNetworkInput<T>\n+        extends AbstractStreamTaskNetworkInput<T, DemultiplexingRecordDeserializer<T>>\n+        implements RecoverableStreamTaskInput<T> {\n+\n+    private static final Logger LOG =\n+            LoggerFactory.getLogger(RescalingStreamTaskNetworkInput.class);\n+    private final IOManager ioManager;\n+\n+    private RescalingStreamTaskNetworkInput(\n+            CheckpointedInputGate checkpointedInputGate,\n+            TypeSerializer<T> inputSerializer,\n+            IOManager ioManager,\n+            StatusWatermarkValve statusWatermarkValve,\n+            int inputIndex,\n+            InflightDataRescalingDescriptor inflightDataRescalingDescriptor,\n+            Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+            TaskInfo taskInfo) {\n+        super(\n+                checkpointedInputGate,\n+                inputSerializer,\n+                statusWatermarkValve,\n+                inputIndex,\n+                getRecordDeserializers(\n+                        checkpointedInputGate,\n+                        inputSerializer,\n+                        ioManager,\n+                        inflightDataRescalingDescriptor,\n+                        gatePartitioners,\n+                        taskInfo));\n+        this.ioManager = ioManager;\n+\n+        LOG.info(\n+                \"Created demultiplexer for input {} from {}\",\n+                inputIndex,\n+                inflightDataRescalingDescriptor);\n+    }\n+\n+    private static <T>\n+            Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> getRecordDeserializers(\n+                    CheckpointedInputGate checkpointedInputGate,\n+                    TypeSerializer<T> inputSerializer,\n+                    IOManager ioManager,\n+                    InflightDataRescalingDescriptor rescalingDescriptor,\n+                    Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+                    TaskInfo taskInfo) {\n+\n+        RecordFilterFactory<T> recordFilterFactory =\n+                new RecordFilterFactory<>(\n+                        taskInfo.getIndexOfThisSubtask(),\n+                        inputSerializer,\n+                        taskInfo.getNumberOfParallelSubtasks(),\n+                        gatePartitioners,\n+                        taskInfo.getMaxNumberOfParallelSubtasks());\n+        final DeserializerFactory deserializerFactory = new DeserializerFactory(ioManager);\n+        Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> deserializers =\n+                Maps.newHashMapWithExpectedSize(checkpointedInputGate.getChannelInfos().size());\n+        for (InputChannelInfo channelInfo : checkpointedInputGate.getChannelInfos()) {\n+            deserializers.put(\n+                    channelInfo,\n+                    DemultiplexingRecordDeserializer.create(\n+                            channelInfo,\n+                            rescalingDescriptor,\n+                            deserializerFactory,\n+                            recordFilterFactory));\n+        }\n+        return deserializers;\n+    }\n+\n+    @Override\n+    public StreamTaskInput<T> finishRecovery() throws IOException {\n+        close();\n+        return new StreamTaskNetworkInput<>(\n+                checkpointedInputGate,\n+                inputSerializer,\n+                ioManager,\n+                statusWatermarkValve,\n+                inputIndex);\n+    }\n+\n+    /**\n+     * Factory method for {@link StreamTaskNetworkInput} or {@link RescalingStreamTaskNetworkInput}\n+     * depending on {@link InflightDataRescalingDescriptor}.\n+     */\n+    public static <T> StreamTaskInput<T> create(\n+            CheckpointedInputGate checkpointedInputGate,\n+            TypeSerializer<T> inputSerializer,\n+            IOManager ioManager,\n+            StatusWatermarkValve statusWatermarkValve,\n+            int inputIndex,\n+            InflightDataRescalingDescriptor rescalingDescriptorinflightDataRescalingDescriptor,\n+            Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+            TaskInfo taskInfo) {\n+        return rescalingDescriptorinflightDataRescalingDescriptor.equals(\n+                        InflightDataRescalingDescriptor.NO_RESCALE)\n+                ? new StreamTaskNetworkInput<>(\n+                        checkpointedInputGate,\n+                        inputSerializer,\n+                        ioManager,\n+                        statusWatermarkValve,\n+                        inputIndex)\n+                : new RescalingStreamTaskNetworkInput<>(\n+                        checkpointedInputGate,\n+                        inputSerializer,\n+                        ioManager,\n+                        statusWatermarkValve,\n+                        inputIndex,\n+                        rescalingDescriptorinflightDataRescalingDescriptor,\n+                        gatePartitioners,\n+                        taskInfo);\n+    }\n+\n+    protected DemultiplexingRecordDeserializer<T> getActiveSerializer(\n+            InputChannelInfo channelInfo) {\n+        final DemultiplexingRecordDeserializer<T> deserialier =\n+                recordDeserializers.get(channelInfo);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd18dbb4154a033a55320c2740e2499ac7d63ff9"}, "originalPosition": 194}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzUwMjEzNA==", "bodyText": "If the defaults in SpillingAdaptiveSpanningRecordDeserializer are decreased then we can get 0 here with high enough DoP.\nShould we add Math.max(some_minimum, ....) ?", "url": "https://github.com/apache/flink/pull/13845#discussion_r583502134", "createdAt": "2021-02-26T09:30:06Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java", "diffHunk": "@@ -0,0 +1,280 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io.recovery;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.TaskInfo;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.io.InputStatus;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.event.AbstractEvent;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.partition.consumer.BufferOrEvent;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput;\n+import org.apache.flink.streaming.runtime.io.RecoverableStreamTaskInput;\n+import org.apache.flink.streaming.runtime.io.StreamTaskInput;\n+import org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput;\n+import org.apache.flink.streaming.runtime.io.checkpointing.CheckpointedInputGate;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StatusWatermarkValve;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+\n+import static org.apache.flink.runtime.checkpoint.CheckpointFailureReason.CHECKPOINT_DECLINED_TASK_NOT_READY;\n+\n+/**\n+ * A {@link StreamTaskNetworkInput} implementation that demultiplexes virtual channels.\n+ *\n+ * <p>The demultiplexing works in two dimensions for the following cases. *\n+ *\n+ * <ul>\n+ *   <li>Subtasks of the current operator have been collapsed in a round-robin fashion.\n+ *   <li>The connected output operator has been rescaled (up and down!) and there is an overlap of\n+ *       channels (mostly relevant to keyed exchanges).\n+ * </ul>\n+ *\n+ * <p>In both cases, records from multiple old channels are received over one new physical channel,\n+ * which need to demultiplex the record to correctly restore spanning records (similar to how\n+ * StreamTaskNetworkInput works).\n+ *\n+ * <p>Note that when both cases occur at the same time (downscaling of several operators), there is\n+ * the cross product of channels. So if two subtasks are collapsed and two channels overlap from the\n+ * output side, there is a total of 4 virtual channels.\n+ */\n+@Internal\n+public final class RescalingStreamTaskNetworkInput<T>\n+        extends AbstractStreamTaskNetworkInput<T, DemultiplexingRecordDeserializer<T>>\n+        implements RecoverableStreamTaskInput<T> {\n+\n+    private static final Logger LOG =\n+            LoggerFactory.getLogger(RescalingStreamTaskNetworkInput.class);\n+    private final IOManager ioManager;\n+\n+    private RescalingStreamTaskNetworkInput(\n+            CheckpointedInputGate checkpointedInputGate,\n+            TypeSerializer<T> inputSerializer,\n+            IOManager ioManager,\n+            StatusWatermarkValve statusWatermarkValve,\n+            int inputIndex,\n+            InflightDataRescalingDescriptor inflightDataRescalingDescriptor,\n+            Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+            TaskInfo taskInfo) {\n+        super(\n+                checkpointedInputGate,\n+                inputSerializer,\n+                statusWatermarkValve,\n+                inputIndex,\n+                getRecordDeserializers(\n+                        checkpointedInputGate,\n+                        inputSerializer,\n+                        ioManager,\n+                        inflightDataRescalingDescriptor,\n+                        gatePartitioners,\n+                        taskInfo));\n+        this.ioManager = ioManager;\n+\n+        LOG.info(\n+                \"Created demultiplexer for input {} from {}\",\n+                inputIndex,\n+                inflightDataRescalingDescriptor);\n+    }\n+\n+    private static <T>\n+            Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> getRecordDeserializers(\n+                    CheckpointedInputGate checkpointedInputGate,\n+                    TypeSerializer<T> inputSerializer,\n+                    IOManager ioManager,\n+                    InflightDataRescalingDescriptor rescalingDescriptor,\n+                    Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+                    TaskInfo taskInfo) {\n+\n+        RecordFilterFactory<T> recordFilterFactory =\n+                new RecordFilterFactory<>(\n+                        taskInfo.getIndexOfThisSubtask(),\n+                        inputSerializer,\n+                        taskInfo.getNumberOfParallelSubtasks(),\n+                        gatePartitioners,\n+                        taskInfo.getMaxNumberOfParallelSubtasks());\n+        final DeserializerFactory deserializerFactory = new DeserializerFactory(ioManager);\n+        Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> deserializers =\n+                Maps.newHashMapWithExpectedSize(checkpointedInputGate.getChannelInfos().size());\n+        for (InputChannelInfo channelInfo : checkpointedInputGate.getChannelInfos()) {\n+            deserializers.put(\n+                    channelInfo,\n+                    DemultiplexingRecordDeserializer.create(\n+                            channelInfo,\n+                            rescalingDescriptor,\n+                            deserializerFactory,\n+                            recordFilterFactory));\n+        }\n+        return deserializers;\n+    }\n+\n+    @Override\n+    public StreamTaskInput<T> finishRecovery() throws IOException {\n+        close();\n+        return new StreamTaskNetworkInput<>(\n+                checkpointedInputGate,\n+                inputSerializer,\n+                ioManager,\n+                statusWatermarkValve,\n+                inputIndex);\n+    }\n+\n+    /**\n+     * Factory method for {@link StreamTaskNetworkInput} or {@link RescalingStreamTaskNetworkInput}\n+     * depending on {@link InflightDataRescalingDescriptor}.\n+     */\n+    public static <T> StreamTaskInput<T> create(\n+            CheckpointedInputGate checkpointedInputGate,\n+            TypeSerializer<T> inputSerializer,\n+            IOManager ioManager,\n+            StatusWatermarkValve statusWatermarkValve,\n+            int inputIndex,\n+            InflightDataRescalingDescriptor rescalingDescriptorinflightDataRescalingDescriptor,\n+            Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+            TaskInfo taskInfo) {\n+        return rescalingDescriptorinflightDataRescalingDescriptor.equals(\n+                        InflightDataRescalingDescriptor.NO_RESCALE)\n+                ? new StreamTaskNetworkInput<>(\n+                        checkpointedInputGate,\n+                        inputSerializer,\n+                        ioManager,\n+                        statusWatermarkValve,\n+                        inputIndex)\n+                : new RescalingStreamTaskNetworkInput<>(\n+                        checkpointedInputGate,\n+                        inputSerializer,\n+                        ioManager,\n+                        statusWatermarkValve,\n+                        inputIndex,\n+                        rescalingDescriptorinflightDataRescalingDescriptor,\n+                        gatePartitioners,\n+                        taskInfo);\n+    }\n+\n+    protected DemultiplexingRecordDeserializer<T> getActiveSerializer(\n+            InputChannelInfo channelInfo) {\n+        final DemultiplexingRecordDeserializer<T> deserialier =\n+                recordDeserializers.get(channelInfo);\n+        if (!deserialier.hasMappings()) {\n+            throw new IllegalStateException(\n+                    \"Channel \" + channelInfo + \" should not receive data during recovery.\");\n+        }\n+        return deserialier;\n+    }\n+\n+    protected InputStatus processEvent(BufferOrEvent bufferOrEvent) {\n+        // Event received\n+        final AbstractEvent event = bufferOrEvent.getEvent();\n+        if (event instanceof VirtualChannelSelector) {\n+            getActiveSerializer(bufferOrEvent.getChannelInfo())\n+                    .select((VirtualChannelSelector) event);\n+            return InputStatus.MORE_AVAILABLE;\n+        }\n+        return super.processEvent(bufferOrEvent);\n+    }\n+\n+    @Override\n+    public CompletableFuture<Void> prepareSnapshot(\n+            ChannelStateWriter channelStateWriter, long checkpointId) throws CheckpointException {\n+        throw new CheckpointException(CHECKPOINT_DECLINED_TASK_NOT_READY);\n+    }\n+\n+    static class RecordFilterFactory<T>\n+            implements Function<InputChannelInfo, Predicate<StreamRecord<T>>> {\n+        private final Map<Integer, StreamPartitioner<T>> partitionerCache = new HashMap<>(1);\n+        private final Function<Integer, StreamPartitioner<?>> gatePartitioners;\n+        private final TypeSerializer<T> inputSerializer;\n+        private final int numberOfChannels;\n+        private int subtaskIndex;\n+        private int maxParallelism;\n+\n+        public RecordFilterFactory(\n+                int subtaskIndex,\n+                TypeSerializer<T> inputSerializer,\n+                int numberOfChannels,\n+                Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+                int maxParallelism) {\n+            this.gatePartitioners = gatePartitioners;\n+            this.inputSerializer = inputSerializer;\n+            this.numberOfChannels = numberOfChannels;\n+            this.subtaskIndex = subtaskIndex;\n+            this.maxParallelism = maxParallelism;\n+        }\n+\n+        @Override\n+        public Predicate<StreamRecord<T>> apply(InputChannelInfo channelInfo) {\n+            return new RecordFilter<>(\n+                    partitionerCache.computeIfAbsent(\n+                            channelInfo.getGateIdx(), this::createPartitioner),\n+                    inputSerializer,\n+                    subtaskIndex);\n+        }\n+\n+        private StreamPartitioner<T> createPartitioner(Integer index) {\n+            StreamPartitioner<T> partitioner = (StreamPartitioner<T>) gatePartitioners.apply(index);\n+            partitioner.setup(numberOfChannels);\n+            if (partitioner instanceof ConfigurableStreamPartitioner) {\n+                ((ConfigurableStreamPartitioner) partitioner).configure(maxParallelism);\n+            }\n+            return partitioner;\n+        }\n+    }\n+\n+    static class DeserializerFactory\n+            implements Function<\n+                    Integer, RecordDeserializer<DeserializationDelegate<StreamElement>>> {\n+        private final IOManager ioManager;\n+\n+        public DeserializerFactory(IOManager ioManager) {\n+            this.ioManager = ioManager;\n+        }\n+\n+        @Override\n+        public RecordDeserializer<DeserializationDelegate<StreamElement>> apply(\n+                Integer totalChannels) {\n+            return new SpillingAdaptiveSpanningRecordDeserializer<>(\n+                    ioManager.getSpillingDirectoriesPaths(),\n+                    SpillingAdaptiveSpanningRecordDeserializer.DEFAULT_THRESHOLD_FOR_SPILLING\n+                            / totalChannels,\n+                    SpillingAdaptiveSpanningRecordDeserializer.DEFAULT_FILE_BUFFER_SIZE\n+                            / totalChannels);\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd18dbb4154a033a55320c2740e2499ac7d63ff9"}, "originalPosition": 278}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzUyOTk5OA==", "bodyText": "Do we need to make sure that all the buffers in deserializers are consumed?", "url": "https://github.com/apache/flink/pull/13845#discussion_r583529998", "createdAt": "2021-02-26T10:15:40Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java", "diffHunk": "@@ -0,0 +1,280 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io.recovery;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.TaskInfo;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.io.InputStatus;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.event.AbstractEvent;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.partition.consumer.BufferOrEvent;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput;\n+import org.apache.flink.streaming.runtime.io.RecoverableStreamTaskInput;\n+import org.apache.flink.streaming.runtime.io.StreamTaskInput;\n+import org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput;\n+import org.apache.flink.streaming.runtime.io.checkpointing.CheckpointedInputGate;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StatusWatermarkValve;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+\n+import static org.apache.flink.runtime.checkpoint.CheckpointFailureReason.CHECKPOINT_DECLINED_TASK_NOT_READY;\n+\n+/**\n+ * A {@link StreamTaskNetworkInput} implementation that demultiplexes virtual channels.\n+ *\n+ * <p>The demultiplexing works in two dimensions for the following cases. *\n+ *\n+ * <ul>\n+ *   <li>Subtasks of the current operator have been collapsed in a round-robin fashion.\n+ *   <li>The connected output operator has been rescaled (up and down!) and there is an overlap of\n+ *       channels (mostly relevant to keyed exchanges).\n+ * </ul>\n+ *\n+ * <p>In both cases, records from multiple old channels are received over one new physical channel,\n+ * which need to demultiplex the record to correctly restore spanning records (similar to how\n+ * StreamTaskNetworkInput works).\n+ *\n+ * <p>Note that when both cases occur at the same time (downscaling of several operators), there is\n+ * the cross product of channels. So if two subtasks are collapsed and two channels overlap from the\n+ * output side, there is a total of 4 virtual channels.\n+ */\n+@Internal\n+public final class RescalingStreamTaskNetworkInput<T>\n+        extends AbstractStreamTaskNetworkInput<T, DemultiplexingRecordDeserializer<T>>\n+        implements RecoverableStreamTaskInput<T> {\n+\n+    private static final Logger LOG =\n+            LoggerFactory.getLogger(RescalingStreamTaskNetworkInput.class);\n+    private final IOManager ioManager;\n+\n+    private RescalingStreamTaskNetworkInput(\n+            CheckpointedInputGate checkpointedInputGate,\n+            TypeSerializer<T> inputSerializer,\n+            IOManager ioManager,\n+            StatusWatermarkValve statusWatermarkValve,\n+            int inputIndex,\n+            InflightDataRescalingDescriptor inflightDataRescalingDescriptor,\n+            Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+            TaskInfo taskInfo) {\n+        super(\n+                checkpointedInputGate,\n+                inputSerializer,\n+                statusWatermarkValve,\n+                inputIndex,\n+                getRecordDeserializers(\n+                        checkpointedInputGate,\n+                        inputSerializer,\n+                        ioManager,\n+                        inflightDataRescalingDescriptor,\n+                        gatePartitioners,\n+                        taskInfo));\n+        this.ioManager = ioManager;\n+\n+        LOG.info(\n+                \"Created demultiplexer for input {} from {}\",\n+                inputIndex,\n+                inflightDataRescalingDescriptor);\n+    }\n+\n+    private static <T>\n+            Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> getRecordDeserializers(\n+                    CheckpointedInputGate checkpointedInputGate,\n+                    TypeSerializer<T> inputSerializer,\n+                    IOManager ioManager,\n+                    InflightDataRescalingDescriptor rescalingDescriptor,\n+                    Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+                    TaskInfo taskInfo) {\n+\n+        RecordFilterFactory<T> recordFilterFactory =\n+                new RecordFilterFactory<>(\n+                        taskInfo.getIndexOfThisSubtask(),\n+                        inputSerializer,\n+                        taskInfo.getNumberOfParallelSubtasks(),\n+                        gatePartitioners,\n+                        taskInfo.getMaxNumberOfParallelSubtasks());\n+        final DeserializerFactory deserializerFactory = new DeserializerFactory(ioManager);\n+        Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> deserializers =\n+                Maps.newHashMapWithExpectedSize(checkpointedInputGate.getChannelInfos().size());\n+        for (InputChannelInfo channelInfo : checkpointedInputGate.getChannelInfos()) {\n+            deserializers.put(\n+                    channelInfo,\n+                    DemultiplexingRecordDeserializer.create(\n+                            channelInfo,\n+                            rescalingDescriptor,\n+                            deserializerFactory,\n+                            recordFilterFactory));\n+        }\n+        return deserializers;\n+    }\n+\n+    @Override\n+    public StreamTaskInput<T> finishRecovery() throws IOException {\n+        close();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd18dbb4154a033a55320c2740e2499ac7d63ff9"}, "originalPosition": 150}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "bd18dbb4154a033a55320c2740e2499ac7d63ff9", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/bd18dbb4154a033a55320c2740e2499ac7d63ff9", "committedDate": "2021-02-24T22:00:16Z", "message": "fixup [FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}, "afterCommit": {"oid": "fd88882565595a6ca1d8a19678aee6d3050b8ccd", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/fd88882565595a6ca1d8a19678aee6d3050b8ccd", "committedDate": "2021-03-02T22:34:31Z", "message": "Larger refactoring WIP"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "fd88882565595a6ca1d8a19678aee6d3050b8ccd", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/fd88882565595a6ca1d8a19678aee6d3050b8ccd", "committedDate": "2021-03-02T22:34:31Z", "message": "Larger refactoring WIP"}, "afterCommit": {"oid": "9c359d1141fdaa0603bdbd1fd0f5e3cb5e8ec968", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/9c359d1141fdaa0603bdbd1fd0f5e3cb5e8ec968", "committedDate": "2021-03-02T22:57:59Z", "message": "Larger refactoring WIP"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9c359d1141fdaa0603bdbd1fd0f5e3cb5e8ec968", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/9c359d1141fdaa0603bdbd1fd0f5e3cb5e8ec968", "committedDate": "2021-03-02T22:57:59Z", "message": "Larger refactoring WIP"}, "afterCommit": {"oid": "0b61d75ff34ffe2ed0c53631c08eac2e8bed5703", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/0b61d75ff34ffe2ed0c53631c08eac2e8bed5703", "committedDate": "2021-03-03T13:36:15Z", "message": "Larger refactoring WIP"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0b61d75ff34ffe2ed0c53631c08eac2e8bed5703", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/0b61d75ff34ffe2ed0c53631c08eac2e8bed5703", "committedDate": "2021-03-03T13:36:15Z", "message": "Larger refactoring WIP"}, "afterCommit": {"oid": "799bfbfcb5f40839223764b72e79f7b828104f90", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/799bfbfcb5f40839223764b72e79f7b828104f90", "committedDate": "2021-03-03T21:48:13Z", "message": "Larger refactoring WIP"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "799bfbfcb5f40839223764b72e79f7b828104f90", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/799bfbfcb5f40839223764b72e79f7b828104f90", "committedDate": "2021-03-03T21:48:13Z", "message": "Larger refactoring WIP"}, "afterCommit": {"oid": "bffe7da70d1c0e55ae5e82a50beb77342193ff0d", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/bffe7da70d1c0e55ae5e82a50beb77342193ff0d", "committedDate": "2021-03-03T21:57:18Z", "message": "[FLINK-19801][checkpoint] Using lazy initialization of aux structure while creating InflightDataRescalingDescriptor.\n\nFor rescaling unaligned checkpoints, rescaling descriptors need to be calculated. However, for larger setups, it can take a while to calculate mappings and thus it should be avoided for all aligned checkpoints, interchanges without data, and for trivial setup (simple upscaling of shuffles).\n\nThere were some optimizations already in the code but it relied on determining the simple cases in advance, which is quite complicated and fell short in two regards. In certain cases, such as channels that or filled only on either upstream or downstream, it was too aggressive and lead to wrong results. Further, some optimization opportunities were left out.\n\nIn this refactoring, the calculation of most aux structure is lazy to simplify the detection of the cases. Accordingly, most calculations are moved inside TaskStateAssignment and properly encapsulated."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8adff526ff72d0a6a08c826293c96fe13e17945d", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/8adff526ff72d0a6a08c826293c96fe13e17945d", "committedDate": "2021-03-03T22:01:09Z", "message": "fixup! [FLINK-19801][checkpoint] Recover data with virtual channels."}, "afterCommit": {"oid": "90873ee40bb726e584a2711e076ca26ad171d83f", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/90873ee40bb726e584a2711e076ca26ad171d83f", "committedDate": "2021-03-03T22:22:19Z", "message": "WIP Trying to debug native memory leaks"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "90873ee40bb726e584a2711e076ca26ad171d83f", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/90873ee40bb726e584a2711e076ca26ad171d83f", "committedDate": "2021-03-03T22:22:19Z", "message": "WIP Trying to debug native memory leaks"}, "afterCommit": {"oid": "29683f9cd2f62707d5f67f0afac5c7d83776fa00", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/29683f9cd2f62707d5f67f0afac5c7d83776fa00", "committedDate": "2021-03-04T06:39:28Z", "message": "WIP Trying to debug native memory leaks"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "29683f9cd2f62707d5f67f0afac5c7d83776fa00", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/29683f9cd2f62707d5f67f0afac5c7d83776fa00", "committedDate": "2021-03-04T06:39:28Z", "message": "WIP Trying to debug native memory leaks"}, "afterCommit": {"oid": "3248e7c8f3c01e1ac5ba69a463d4272b733b10d2", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/3248e7c8f3c01e1ac5ba69a463d4272b733b10d2", "committedDate": "2021-03-04T07:10:12Z", "message": "WIP Trying to debug native memory leaks"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "3248e7c8f3c01e1ac5ba69a463d4272b733b10d2", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/3248e7c8f3c01e1ac5ba69a463d4272b733b10d2", "committedDate": "2021-03-04T07:10:12Z", "message": "WIP Trying to debug native memory leaks"}, "afterCommit": {"oid": "507697ab09ec0f4380d1e29133cdb8b0416a0c77", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/507697ab09ec0f4380d1e29133cdb8b0416a0c77", "committedDate": "2021-03-04T09:11:50Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "507697ab09ec0f4380d1e29133cdb8b0416a0c77", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/507697ab09ec0f4380d1e29133cdb8b0416a0c77", "committedDate": "2021-03-04T09:11:50Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}, "afterCommit": {"oid": "96661504184c87f29d6a5f4c673e65e8a96a2775", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/96661504184c87f29d6a5f4c673e65e8a96a2775", "committedDate": "2021-03-04T09:18:40Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "96661504184c87f29d6a5f4c673e65e8a96a2775", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/96661504184c87f29d6a5f4c673e65e8a96a2775", "committedDate": "2021-03-04T09:18:40Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}, "afterCommit": {"oid": "e11f29896312c9a3f744cecc6aeb489f6d00c9a2", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/e11f29896312c9a3f744cecc6aeb489f6d00c9a2", "committedDate": "2021-03-04T09:53:22Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e11f29896312c9a3f744cecc6aeb489f6d00c9a2", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/e11f29896312c9a3f744cecc6aeb489f6d00c9a2", "committedDate": "2021-03-04T09:53:22Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}, "afterCommit": {"oid": "89ef91e99f9946f5defb5ecf0d165ae19a52f292", "author": {"user": {"login": "AHeise", "name": "Arvid Heise"}}, "url": "https://github.com/apache/flink/commit/89ef91e99f9946f5defb5ecf0d165ae19a52f292", "committedDate": "2021-03-04T09:53:59Z", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints."}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4964, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}