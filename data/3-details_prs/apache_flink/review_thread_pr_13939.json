{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTE1OTA1NTA1", "number": 13939, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNlQwNzo0NTowNFrOE1-ipw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNlQwNzo0OToxMVrOE1-m7Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI1MDM0NjYzOnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/read/HiveBulkFormatAdapter.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNlQwNzo0NTowNFrOHujMaw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNlQwNzo0NTowNFrOHujMaw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODU3MzE2Mw==", "bodyText": "We already have a computeSelectedFields method, can it be reused?", "url": "https://github.com/apache/flink/pull/13939#discussion_r518573163", "createdAt": "2020-11-06T07:45:04Z", "author": {"login": "lirui-apache"}, "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/read/HiveBulkFormatAdapter.java", "diffHunk": "@@ -107,24 +114,78 @@ public boolean isSplittable() {\n \t\treturn InternalTypeInfo.of(producedRowType);\n \t}\n \n+\tprivate RowType tableRowType() {\n+\t\tLogicalType[] types = Arrays.stream(fieldTypes).map(DataType::getLogicalType).toArray(LogicalType[]::new);\n+\t\treturn RowType.of(types, fieldNames);\n+\t}\n+\n+\tprivate int[] projectedFields() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a7bfb90cbeffd83a836343f55f0535c7e3c487de"}, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI1MDM1NzU3OnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/read/HiveBulkFormatAdapter.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNlQwNzo0OToxMVrOHujTEg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNlQwNzo0OToxMVrOHujTEg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODU3NDg2Ng==", "bodyText": "Collections.emptyList()?", "url": "https://github.com/apache/flink/pull/13939#discussion_r518574866", "createdAt": "2020-11-06T07:49:11Z", "author": {"login": "lirui-apache"}, "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/read/HiveBulkFormatAdapter.java", "diffHunk": "@@ -107,24 +114,78 @@ public boolean isSplittable() {\n \t\treturn InternalTypeInfo.of(producedRowType);\n \t}\n \n+\tprivate RowType tableRowType() {\n+\t\tLogicalType[] types = Arrays.stream(fieldTypes).map(DataType::getLogicalType).toArray(LogicalType[]::new);\n+\t\treturn RowType.of(types, fieldNames);\n+\t}\n+\n+\tprivate int[] projectedFields() {\n+\t\tList<String> nameList = Arrays.asList(fieldNames);\n+\t\tint[] projectedFields = new int[producedRowType.getFieldCount()];\n+\t\tList<String> projectedNames = producedRowType.getFieldNames();\n+\t\tfor (int i = 0; i < projectedFields.length; i++) {\n+\t\t\tprojectedFields[i] = nameList.indexOf(projectedNames.get(i));\n+\t\t}\n+\t\treturn projectedFields;\n+\t}\n+\n \tprivate BulkFormat<RowData, ? super HiveSourceSplit> createBulkFormatForSplit(HiveSourceSplit split) {\n \t\tif (!useMapRedReader && useParquetVectorizedRead(split.getHiveTablePartition())) {\n-\t\t\tPartitionFieldExtractor<HiveSourceSplit> extractor = (PartitionFieldExtractor<HiveSourceSplit>)\n-\t\t\t\t\t(split1, fieldName, fieldType) -> split1.getHiveTablePartition().getPartitionSpec().get(fieldName);\n \t\t\treturn ParquetColumnarRowInputFormat.createPartitionedFormat(\n \t\t\t\t\tjobConfWrapper.conf(),\n \t\t\t\t\tproducedRowType,\n \t\t\t\t\tpartitionKeys,\n-\t\t\t\t\textractor,\n+\t\t\t\t\tPARTITION_FIELD_EXTRACTOR,\n \t\t\t\t\tDEFAULT_SIZE,\n \t\t\t\t\thiveVersion.startsWith(\"3\"),\n \t\t\t\t\tfalse\n \t\t\t);\n+\t\t} else if (!useMapRedReader && useOrcVectorizedRead(split.getHiveTablePartition())) {\n+\t\t\treturn createOrcFormat();\n \t\t} else {\n \t\t\treturn new HiveMapRedBulkFormat();\n \t\t}\n \t}\n \n+\tprivate OrcColumnarRowFileInputFormat<?, HiveSourceSplit> createOrcFormat() {\n+\t\treturn hiveVersion.startsWith(\"1.\") ?\n+\t\t\t\tOrcColumnarRowFileInputFormat.createPartitionedFormat(\n+\t\t\t\t\tOrcShim.createShim(hiveVersion),\n+\t\t\t\t\tjobConfWrapper.conf(),\n+\t\t\t\t\ttableRowType(),\n+\t\t\t\t\tpartitionKeys,\n+\t\t\t\t\tPARTITION_FIELD_EXTRACTOR,\n+\t\t\t\t\tprojectedFields(),\n+\t\t\t\t\tnew ArrayList<>(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a7bfb90cbeffd83a836343f55f0535c7e3c487de"}, "originalPosition": 77}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4944, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}