{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTA3OTMxMzg2", "number": 13735, "reviewThreads": {"totalCount": 23, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQxNzo0NzowMlrOEyBJFQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQxMzo0Njo0M1rOE1qedg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIwODgyOTY1OnYy", "diffSide": "LEFT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/OperatorSubtaskState.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQxNzo0NzowMlrOHobZow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QyMDo0MzowOFrOHs_wTg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjE1NDAxOQ==", "bodyText": "Removal of @Nonnull is controversial by some. Some people prefer it as cheap, debug mode only assertion. This is because as far as I know, @Nonnull in debug mode, is adding checkNonNull(...) equivalents.\nI personally would be fine by not using them, and I personally I'm not adding them in a new code, but because of the above reason, I would be actually against removing them from a code that someone added (otherwise, we can end up in a ping pong situation when you are removing them and someone else re-adding).", "url": "https://github.com/apache/flink/pull/13735#discussion_r512154019", "createdAt": "2020-10-26T17:47:02Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/OperatorSubtaskState.java", "diffHunk": "@@ -63,31 +61,25 @@\n \t/**\n \t * Snapshot from the {@link org.apache.flink.runtime.state.OperatorStateBackend}.\n \t */\n-\t@Nonnull", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4915d3dded86843b8cfd204433e71c0b6f82c138"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjk0Mzk1MA==", "bodyText": "I like the change. Especially given that there are already checkNotNull in the constructor.\n(we don't have to remove again it if someone re-adds it)\nP.S.: is checkNotNull missing for the new fields?", "url": "https://github.com/apache/flink/pull/13735#discussion_r516943950", "createdAt": "2020-11-03T20:43:08Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/OperatorSubtaskState.java", "diffHunk": "@@ -63,31 +61,25 @@\n \t/**\n \t * Snapshot from the {@link org.apache.flink.runtime.state.OperatorStateBackend}.\n \t */\n-\t@Nonnull", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjE1NDAxOQ=="}, "originalCommit": {"oid": "4915d3dded86843b8cfd204433e71c0b6f82c138"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIwODg1NTMwOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/writer/ChannelRescaler.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQxNzo1MzoyNlrOHobpvw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQxNToxNTozMVrOHuICEA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjE1ODE0Mw==", "bodyText": "What is the relation between this method/interface and #rescaleIntersections from the Partitioner? Why one returns  int[] and the other BitSet?", "url": "https://github.com/apache/flink/pull/13735#discussion_r512158143", "createdAt": "2020-10-26T17:53:26Z", "author": {"login": "pnowojski"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/writer/ChannelRescaler.java", "diffHunk": "@@ -0,0 +1,59 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.io.network.api.writer;\n+\n+import org.apache.flink.annotation.Internal;\n+\n+import java.io.Serializable;\n+import java.util.BitSet;\n+\n+/**\n+ * The {@link ChannelRescaler} narrows down the channels that need to be read during rescaling to recover from a\n+ * particular channel when in-flight data has been stored in the checkpoint.\n+ */\n+@Internal\n+public interface ChannelRescaler extends Serializable {\n+\t/**\n+\t * Returns all old channel indexes that need to be read to restore all buffers for the given new channel index on\n+\t * rescale.\n+\t */\n+\tBitSet rescaleIntersections(int newChannelIndex, int oldNumberOfChannels, int newNumberOfChannels);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "51ced4ccaf306b05185f5332983c378cecf73330"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODEyODE0NA==", "bodyText": "Removed from Partitioner", "url": "https://github.com/apache/flink/pull/13735#discussion_r518128144", "createdAt": "2020-11-05T15:15:31Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/writer/ChannelRescaler.java", "diffHunk": "@@ -0,0 +1,59 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.io.network.api.writer;\n+\n+import org.apache.flink.annotation.Internal;\n+\n+import java.io.Serializable;\n+import java.util.BitSet;\n+\n+/**\n+ * The {@link ChannelRescaler} narrows down the channels that need to be read during rescaling to recover from a\n+ * particular channel when in-flight data has been stored in the checkpoint.\n+ */\n+@Internal\n+public interface ChannelRescaler extends Serializable {\n+\t/**\n+\t * Returns all old channel indexes that need to be read to restore all buffers for the given new channel index on\n+\t * rescale.\n+\t */\n+\tBitSet rescaleIntersections(int newChannelIndex, int oldNumberOfChannels, int newNumberOfChannels);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjE1ODE0Mw=="}, "originalCommit": {"oid": "51ced4ccaf306b05185f5332983c378cecf73330"}, "originalPosition": 36}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIwODg4ODA4OnYy", "diffSide": "RIGHT", "path": "flink-core/src/main/java/org/apache/flink/api/common/functions/Partitioner.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQxODowMToyNlrOHob91g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQxNToxNjoyMFrOHuIEkA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjE2MzI4Ng==", "bodyText": "We need this to support CustomPartitionerWrapper, right? This is @Public interface :( I think we need to think twice before we commit ourselves to such change. Let's sync offline again whether this is really the best/the only way of solving our problem.", "url": "https://github.com/apache/flink/pull/13735#discussion_r512163286", "createdAt": "2020-10-26T18:01:26Z", "author": {"login": "pnowojski"}, "path": "flink-core/src/main/java/org/apache/flink/api/common/functions/Partitioner.java", "diffHunk": "@@ -37,4 +40,20 @@\n \t * @return The partition index.\n \t */\n \tint partition(K key, int numPartitions);\n+\n+\t/**\n+\t * Returns all partitions that need to be read to restore the given new partition. The partitioner is then\n+\t * applied on the key of the restored record to filter all irrelevant records.\n+\t *\n+\t * <p>In particular, to create a partition X after rescaling, all partitions returned by this method are fully read\n+\t * and the key of each record is then fed into {@link #partition(Object, int)} to check if it belongs to X.\n+\t *\n+\t * <p>The default implementation states that all partitions need to be scanned and should be overwritten to improve\n+\t * performance.\n+\t */\n+\t@PublicEvolving\n+\tdefault int[] rescaleIntersections(int newPartition, int oldNumPartitions, int newNumPartitions) {\n+\t\t// any old partition may contain a record that should be in the new partition after rescaling\n+\t\treturn IntStream.range(0, oldNumPartitions).toArray();\n+\t}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "51ced4ccaf306b05185f5332983c378cecf73330"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODEyODc4NA==", "bodyText": "Removed from CustomerPartitioner. We officially do not support it (and inofficially just use full replication and downstream filtering).", "url": "https://github.com/apache/flink/pull/13735#discussion_r518128784", "createdAt": "2020-11-05T15:16:20Z", "author": {"login": "AHeise"}, "path": "flink-core/src/main/java/org/apache/flink/api/common/functions/Partitioner.java", "diffHunk": "@@ -37,4 +40,20 @@\n \t * @return The partition index.\n \t */\n \tint partition(K key, int numPartitions);\n+\n+\t/**\n+\t * Returns all partitions that need to be read to restore the given new partition. The partitioner is then\n+\t * applied on the key of the restored record to filter all irrelevant records.\n+\t *\n+\t * <p>In particular, to create a partition X after rescaling, all partitions returned by this method are fully read\n+\t * and the key of each record is then fed into {@link #partition(Object, int)} to check if it belongs to X.\n+\t *\n+\t * <p>The default implementation states that all partitions need to be scanned and should be overwritten to improve\n+\t * performance.\n+\t */\n+\t@PublicEvolving\n+\tdefault int[] rescaleIntersections(int newPartition, int oldNumPartitions, int newNumPartitions) {\n+\t\t// any old partition may contain a record that should be in the new partition after rescaling\n+\t\treturn IntStream.range(0, oldNumPartitions).toArray();\n+\t}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjE2MzI4Ng=="}, "originalCommit": {"oid": "51ced4ccaf306b05185f5332983c378cecf73330"}, "originalPosition": 29}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIzOTU1OTAwOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/OperatorSubtaskState.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QxOToyMzo1M1rOHs9QJw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQyMjoxNjoxM1rOHtrpyg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkwMjk1MQ==", "bodyText": "Is it actually channel mapping? I think it actually remaps operator state, doesn't it?\nserialVersionUID?\nI'd rather move this class to a separate file", "url": "https://github.com/apache/flink/pull/13735#discussion_r516902951", "createdAt": "2020-11-03T19:23:53Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/OperatorSubtaskState.java", "diffHunk": "@@ -327,4 +289,252 @@ public boolean hasState() {\n \t\t\t|| inputChannelState.hasState()\n \t\t\t|| resultSubpartitionState.hasState();\n \t}\n+\n+\tpublic static Builder builder() {\n+\t\treturn new Builder();\n+\t}\n+\n+\t/**\n+\t * The builder for a new {@link OperatorSubtaskState} which can be obtained by {@link #builder()}.\n+\t */\n+\tpublic static class Builder {\n+\t\tprivate StateObjectCollection<OperatorStateHandle> managedOperatorState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<OperatorStateHandle> rawOperatorState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<KeyedStateHandle> managedKeyedState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<KeyedStateHandle> rawKeyedState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<InputChannelStateHandle> inputChannelState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<ResultSubpartitionStateHandle> resultSubpartitionState = StateObjectCollection.empty();\n+\t\tprivate VirtualChannelMapping inputChannelMappings = VirtualChannelMapping.NO_MAPPING;\n+\t\tprivate VirtualChannelMapping outputChannelMappings = VirtualChannelMapping.NO_MAPPING;\n+\n+\t\tprivate Builder() {\n+\t\t}\n+\n+\t\tpublic Builder setManagedOperatorState(StateObjectCollection<OperatorStateHandle> managedOperatorState) {\n+\t\t\tthis.managedOperatorState = checkNotNull(managedOperatorState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setManagedOperatorState(OperatorStateHandle managedOperatorState) {\n+\t\t\treturn setManagedOperatorState(StateObjectCollection.singleton(checkNotNull(managedOperatorState)));\n+\t\t}\n+\n+\t\tpublic Builder setRawOperatorState(StateObjectCollection<OperatorStateHandle> rawOperatorState) {\n+\t\t\tthis.rawOperatorState = checkNotNull(rawOperatorState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setRawOperatorState(OperatorStateHandle rawOperatorState) {\n+\t\t\treturn setRawOperatorState(StateObjectCollection.singleton(checkNotNull(rawOperatorState)));\n+\t\t}\n+\n+\t\tpublic Builder setManagedKeyedState(StateObjectCollection<KeyedStateHandle> managedKeyedState) {\n+\t\t\tthis.managedKeyedState = checkNotNull(managedKeyedState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setManagedKeyedState(KeyedStateHandle managedKeyedState) {\n+\t\t\treturn setManagedKeyedState(StateObjectCollection.singleton(checkNotNull(managedKeyedState)));\n+\t\t}\n+\n+\t\tpublic Builder setRawKeyedState(StateObjectCollection<KeyedStateHandle> rawKeyedState) {\n+\t\t\tthis.rawKeyedState = checkNotNull(rawKeyedState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setRawKeyedState(KeyedStateHandle rawKeyedState) {\n+\t\t\treturn setRawKeyedState(StateObjectCollection.singleton(checkNotNull(rawKeyedState)));\n+\t\t}\n+\n+\t\tpublic Builder setInputChannelState(StateObjectCollection<InputChannelStateHandle> inputChannelState) {\n+\t\t\tthis.inputChannelState = checkNotNull(inputChannelState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setResultSubpartitionState(StateObjectCollection<ResultSubpartitionStateHandle> resultSubpartitionState) {\n+\t\t\tthis.resultSubpartitionState = checkNotNull(resultSubpartitionState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setInputChannelMappings(VirtualChannelMapping inputChannelMappings) {\n+\t\t\tthis.inputChannelMappings = checkNotNull(inputChannelMappings);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setOutputChannelMappings(VirtualChannelMapping outputChannelMappings) {\n+\t\t\tthis.outputChannelMappings = checkNotNull(outputChannelMappings);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic OperatorSubtaskState build() {\n+\t\t\treturn new OperatorSubtaskState(\n+\t\t\t\tmanagedOperatorState,\n+\t\t\t\trawOperatorState,\n+\t\t\t\tmanagedKeyedState,\n+\t\t\t\trawKeyedState,\n+\t\t\t\tinputChannelState,\n+\t\t\t\tresultSubpartitionState,\n+\t\t\t\tinputChannelMappings,\n+\t\t\t\toutputChannelMappings);\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Captures ambiguous mappings of old channels to new channels.\n+\t *\n+\t * <p>For inputs, this mapping implies the following:\n+\t * <li>\n+\t *     <ul>{@link #oldTaskInstances} is set when there is a rescale on this task potentially leading to different\n+\t *     key groups. Upstream task has a corresponding {@link #partitionMappings} where it sends data over\n+\t *     virtual channel while specifying the channel index in the VirtualChannelSelector. This subtask then\n+\t *     demultiplexes over the virtual subtask index.</ul>\n+\t *     <ul>{@link #partitionMappings} is set when there is a downscale of the upstream task. Upstream task has\n+\t *     a corresponding {@link #oldTaskInstances} where it sends data over virtual channel while specifying the\n+\t *     subtask index in the VirtualChannelSelector. This subtask then demultiplexes over channel indexes.</ul>\n+\t * </li>\n+\t *\n+\t * <p>For outputs, it's vice-versa. The information must be kept in sync but they are used in opposite ways for\n+\t * multiplexing/demultiplexing.\n+\t *\n+\t * <p>Note that in the common rescaling case both information is set and need to be simultaneously used. If the\n+\t * input subtask subsumes the state of 3 old subtasks and a channel corresponds to 2 old channels, then there are\n+\t * 6 virtual channels to be demultiplexed.\n+\t */\n+\tpublic static class VirtualChannelMapping implements Serializable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9cbbcb24751268c0b5289b86606eb28baa1287eb"}, "originalPosition": 360}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzE1MjY0NA==", "bodyText": "hm, it's all about channel state as part of the operator state. How about ChannelStateMapping?", "url": "https://github.com/apache/flink/pull/13735#discussion_r517152644", "createdAt": "2020-11-04T07:54:31Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/OperatorSubtaskState.java", "diffHunk": "@@ -327,4 +289,252 @@ public boolean hasState() {\n \t\t\t|| inputChannelState.hasState()\n \t\t\t|| resultSubpartitionState.hasState();\n \t}\n+\n+\tpublic static Builder builder() {\n+\t\treturn new Builder();\n+\t}\n+\n+\t/**\n+\t * The builder for a new {@link OperatorSubtaskState} which can be obtained by {@link #builder()}.\n+\t */\n+\tpublic static class Builder {\n+\t\tprivate StateObjectCollection<OperatorStateHandle> managedOperatorState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<OperatorStateHandle> rawOperatorState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<KeyedStateHandle> managedKeyedState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<KeyedStateHandle> rawKeyedState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<InputChannelStateHandle> inputChannelState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<ResultSubpartitionStateHandle> resultSubpartitionState = StateObjectCollection.empty();\n+\t\tprivate VirtualChannelMapping inputChannelMappings = VirtualChannelMapping.NO_MAPPING;\n+\t\tprivate VirtualChannelMapping outputChannelMappings = VirtualChannelMapping.NO_MAPPING;\n+\n+\t\tprivate Builder() {\n+\t\t}\n+\n+\t\tpublic Builder setManagedOperatorState(StateObjectCollection<OperatorStateHandle> managedOperatorState) {\n+\t\t\tthis.managedOperatorState = checkNotNull(managedOperatorState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setManagedOperatorState(OperatorStateHandle managedOperatorState) {\n+\t\t\treturn setManagedOperatorState(StateObjectCollection.singleton(checkNotNull(managedOperatorState)));\n+\t\t}\n+\n+\t\tpublic Builder setRawOperatorState(StateObjectCollection<OperatorStateHandle> rawOperatorState) {\n+\t\t\tthis.rawOperatorState = checkNotNull(rawOperatorState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setRawOperatorState(OperatorStateHandle rawOperatorState) {\n+\t\t\treturn setRawOperatorState(StateObjectCollection.singleton(checkNotNull(rawOperatorState)));\n+\t\t}\n+\n+\t\tpublic Builder setManagedKeyedState(StateObjectCollection<KeyedStateHandle> managedKeyedState) {\n+\t\t\tthis.managedKeyedState = checkNotNull(managedKeyedState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setManagedKeyedState(KeyedStateHandle managedKeyedState) {\n+\t\t\treturn setManagedKeyedState(StateObjectCollection.singleton(checkNotNull(managedKeyedState)));\n+\t\t}\n+\n+\t\tpublic Builder setRawKeyedState(StateObjectCollection<KeyedStateHandle> rawKeyedState) {\n+\t\t\tthis.rawKeyedState = checkNotNull(rawKeyedState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setRawKeyedState(KeyedStateHandle rawKeyedState) {\n+\t\t\treturn setRawKeyedState(StateObjectCollection.singleton(checkNotNull(rawKeyedState)));\n+\t\t}\n+\n+\t\tpublic Builder setInputChannelState(StateObjectCollection<InputChannelStateHandle> inputChannelState) {\n+\t\t\tthis.inputChannelState = checkNotNull(inputChannelState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setResultSubpartitionState(StateObjectCollection<ResultSubpartitionStateHandle> resultSubpartitionState) {\n+\t\t\tthis.resultSubpartitionState = checkNotNull(resultSubpartitionState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setInputChannelMappings(VirtualChannelMapping inputChannelMappings) {\n+\t\t\tthis.inputChannelMappings = checkNotNull(inputChannelMappings);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setOutputChannelMappings(VirtualChannelMapping outputChannelMappings) {\n+\t\t\tthis.outputChannelMappings = checkNotNull(outputChannelMappings);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic OperatorSubtaskState build() {\n+\t\t\treturn new OperatorSubtaskState(\n+\t\t\t\tmanagedOperatorState,\n+\t\t\t\trawOperatorState,\n+\t\t\t\tmanagedKeyedState,\n+\t\t\t\trawKeyedState,\n+\t\t\t\tinputChannelState,\n+\t\t\t\tresultSubpartitionState,\n+\t\t\t\tinputChannelMappings,\n+\t\t\t\toutputChannelMappings);\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Captures ambiguous mappings of old channels to new channels.\n+\t *\n+\t * <p>For inputs, this mapping implies the following:\n+\t * <li>\n+\t *     <ul>{@link #oldTaskInstances} is set when there is a rescale on this task potentially leading to different\n+\t *     key groups. Upstream task has a corresponding {@link #partitionMappings} where it sends data over\n+\t *     virtual channel while specifying the channel index in the VirtualChannelSelector. This subtask then\n+\t *     demultiplexes over the virtual subtask index.</ul>\n+\t *     <ul>{@link #partitionMappings} is set when there is a downscale of the upstream task. Upstream task has\n+\t *     a corresponding {@link #oldTaskInstances} where it sends data over virtual channel while specifying the\n+\t *     subtask index in the VirtualChannelSelector. This subtask then demultiplexes over channel indexes.</ul>\n+\t * </li>\n+\t *\n+\t * <p>For outputs, it's vice-versa. The information must be kept in sync but they are used in opposite ways for\n+\t * multiplexing/demultiplexing.\n+\t *\n+\t * <p>Note that in the common rescaling case both information is set and need to be simultaneously used. If the\n+\t * input subtask subsumes the state of 3 old subtasks and a channel corresponds to 2 old channels, then there are\n+\t * 6 virtual channels to be demultiplexed.\n+\t */\n+\tpublic static class VirtualChannelMapping implements Serializable {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkwMjk1MQ=="}, "originalCommit": {"oid": "9cbbcb24751268c0b5289b86606eb28baa1287eb"}, "originalPosition": 360}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzM4OTY3OA==", "bodyText": "I think ChannelStateMapping wouldn't be consistent with a field:\n/**\n * Set when several operator instances are merged into one.\n */\nprivate final BitSet oldTaskInstances;\n\nMaybe something like EdgeRescalingDescriptor?", "url": "https://github.com/apache/flink/pull/13735#discussion_r517389678", "createdAt": "2020-11-04T14:37:22Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/OperatorSubtaskState.java", "diffHunk": "@@ -327,4 +289,252 @@ public boolean hasState() {\n \t\t\t|| inputChannelState.hasState()\n \t\t\t|| resultSubpartitionState.hasState();\n \t}\n+\n+\tpublic static Builder builder() {\n+\t\treturn new Builder();\n+\t}\n+\n+\t/**\n+\t * The builder for a new {@link OperatorSubtaskState} which can be obtained by {@link #builder()}.\n+\t */\n+\tpublic static class Builder {\n+\t\tprivate StateObjectCollection<OperatorStateHandle> managedOperatorState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<OperatorStateHandle> rawOperatorState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<KeyedStateHandle> managedKeyedState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<KeyedStateHandle> rawKeyedState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<InputChannelStateHandle> inputChannelState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<ResultSubpartitionStateHandle> resultSubpartitionState = StateObjectCollection.empty();\n+\t\tprivate VirtualChannelMapping inputChannelMappings = VirtualChannelMapping.NO_MAPPING;\n+\t\tprivate VirtualChannelMapping outputChannelMappings = VirtualChannelMapping.NO_MAPPING;\n+\n+\t\tprivate Builder() {\n+\t\t}\n+\n+\t\tpublic Builder setManagedOperatorState(StateObjectCollection<OperatorStateHandle> managedOperatorState) {\n+\t\t\tthis.managedOperatorState = checkNotNull(managedOperatorState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setManagedOperatorState(OperatorStateHandle managedOperatorState) {\n+\t\t\treturn setManagedOperatorState(StateObjectCollection.singleton(checkNotNull(managedOperatorState)));\n+\t\t}\n+\n+\t\tpublic Builder setRawOperatorState(StateObjectCollection<OperatorStateHandle> rawOperatorState) {\n+\t\t\tthis.rawOperatorState = checkNotNull(rawOperatorState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setRawOperatorState(OperatorStateHandle rawOperatorState) {\n+\t\t\treturn setRawOperatorState(StateObjectCollection.singleton(checkNotNull(rawOperatorState)));\n+\t\t}\n+\n+\t\tpublic Builder setManagedKeyedState(StateObjectCollection<KeyedStateHandle> managedKeyedState) {\n+\t\t\tthis.managedKeyedState = checkNotNull(managedKeyedState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setManagedKeyedState(KeyedStateHandle managedKeyedState) {\n+\t\t\treturn setManagedKeyedState(StateObjectCollection.singleton(checkNotNull(managedKeyedState)));\n+\t\t}\n+\n+\t\tpublic Builder setRawKeyedState(StateObjectCollection<KeyedStateHandle> rawKeyedState) {\n+\t\t\tthis.rawKeyedState = checkNotNull(rawKeyedState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setRawKeyedState(KeyedStateHandle rawKeyedState) {\n+\t\t\treturn setRawKeyedState(StateObjectCollection.singleton(checkNotNull(rawKeyedState)));\n+\t\t}\n+\n+\t\tpublic Builder setInputChannelState(StateObjectCollection<InputChannelStateHandle> inputChannelState) {\n+\t\t\tthis.inputChannelState = checkNotNull(inputChannelState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setResultSubpartitionState(StateObjectCollection<ResultSubpartitionStateHandle> resultSubpartitionState) {\n+\t\t\tthis.resultSubpartitionState = checkNotNull(resultSubpartitionState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setInputChannelMappings(VirtualChannelMapping inputChannelMappings) {\n+\t\t\tthis.inputChannelMappings = checkNotNull(inputChannelMappings);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setOutputChannelMappings(VirtualChannelMapping outputChannelMappings) {\n+\t\t\tthis.outputChannelMappings = checkNotNull(outputChannelMappings);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic OperatorSubtaskState build() {\n+\t\t\treturn new OperatorSubtaskState(\n+\t\t\t\tmanagedOperatorState,\n+\t\t\t\trawOperatorState,\n+\t\t\t\tmanagedKeyedState,\n+\t\t\t\trawKeyedState,\n+\t\t\t\tinputChannelState,\n+\t\t\t\tresultSubpartitionState,\n+\t\t\t\tinputChannelMappings,\n+\t\t\t\toutputChannelMappings);\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Captures ambiguous mappings of old channels to new channels.\n+\t *\n+\t * <p>For inputs, this mapping implies the following:\n+\t * <li>\n+\t *     <ul>{@link #oldTaskInstances} is set when there is a rescale on this task potentially leading to different\n+\t *     key groups. Upstream task has a corresponding {@link #partitionMappings} where it sends data over\n+\t *     virtual channel while specifying the channel index in the VirtualChannelSelector. This subtask then\n+\t *     demultiplexes over the virtual subtask index.</ul>\n+\t *     <ul>{@link #partitionMappings} is set when there is a downscale of the upstream task. Upstream task has\n+\t *     a corresponding {@link #oldTaskInstances} where it sends data over virtual channel while specifying the\n+\t *     subtask index in the VirtualChannelSelector. This subtask then demultiplexes over channel indexes.</ul>\n+\t * </li>\n+\t *\n+\t * <p>For outputs, it's vice-versa. The information must be kept in sync but they are used in opposite ways for\n+\t * multiplexing/demultiplexing.\n+\t *\n+\t * <p>Note that in the common rescaling case both information is set and need to be simultaneously used. If the\n+\t * input subtask subsumes the state of 3 old subtasks and a channel corresponds to 2 old channels, then there are\n+\t * 6 virtual channels to be demultiplexed.\n+\t */\n+\tpublic static class VirtualChannelMapping implements Serializable {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkwMjk1MQ=="}, "originalCommit": {"oid": "9cbbcb24751268c0b5289b86606eb28baa1287eb"}, "originalPosition": 360}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzY2MzE3OA==", "bodyText": "I went with InflightDataRescalingDescriptor for now.", "url": "https://github.com/apache/flink/pull/13735#discussion_r517663178", "createdAt": "2020-11-04T22:16:13Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/OperatorSubtaskState.java", "diffHunk": "@@ -327,4 +289,252 @@ public boolean hasState() {\n \t\t\t|| inputChannelState.hasState()\n \t\t\t|| resultSubpartitionState.hasState();\n \t}\n+\n+\tpublic static Builder builder() {\n+\t\treturn new Builder();\n+\t}\n+\n+\t/**\n+\t * The builder for a new {@link OperatorSubtaskState} which can be obtained by {@link #builder()}.\n+\t */\n+\tpublic static class Builder {\n+\t\tprivate StateObjectCollection<OperatorStateHandle> managedOperatorState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<OperatorStateHandle> rawOperatorState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<KeyedStateHandle> managedKeyedState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<KeyedStateHandle> rawKeyedState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<InputChannelStateHandle> inputChannelState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<ResultSubpartitionStateHandle> resultSubpartitionState = StateObjectCollection.empty();\n+\t\tprivate VirtualChannelMapping inputChannelMappings = VirtualChannelMapping.NO_MAPPING;\n+\t\tprivate VirtualChannelMapping outputChannelMappings = VirtualChannelMapping.NO_MAPPING;\n+\n+\t\tprivate Builder() {\n+\t\t}\n+\n+\t\tpublic Builder setManagedOperatorState(StateObjectCollection<OperatorStateHandle> managedOperatorState) {\n+\t\t\tthis.managedOperatorState = checkNotNull(managedOperatorState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setManagedOperatorState(OperatorStateHandle managedOperatorState) {\n+\t\t\treturn setManagedOperatorState(StateObjectCollection.singleton(checkNotNull(managedOperatorState)));\n+\t\t}\n+\n+\t\tpublic Builder setRawOperatorState(StateObjectCollection<OperatorStateHandle> rawOperatorState) {\n+\t\t\tthis.rawOperatorState = checkNotNull(rawOperatorState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setRawOperatorState(OperatorStateHandle rawOperatorState) {\n+\t\t\treturn setRawOperatorState(StateObjectCollection.singleton(checkNotNull(rawOperatorState)));\n+\t\t}\n+\n+\t\tpublic Builder setManagedKeyedState(StateObjectCollection<KeyedStateHandle> managedKeyedState) {\n+\t\t\tthis.managedKeyedState = checkNotNull(managedKeyedState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setManagedKeyedState(KeyedStateHandle managedKeyedState) {\n+\t\t\treturn setManagedKeyedState(StateObjectCollection.singleton(checkNotNull(managedKeyedState)));\n+\t\t}\n+\n+\t\tpublic Builder setRawKeyedState(StateObjectCollection<KeyedStateHandle> rawKeyedState) {\n+\t\t\tthis.rawKeyedState = checkNotNull(rawKeyedState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setRawKeyedState(KeyedStateHandle rawKeyedState) {\n+\t\t\treturn setRawKeyedState(StateObjectCollection.singleton(checkNotNull(rawKeyedState)));\n+\t\t}\n+\n+\t\tpublic Builder setInputChannelState(StateObjectCollection<InputChannelStateHandle> inputChannelState) {\n+\t\t\tthis.inputChannelState = checkNotNull(inputChannelState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setResultSubpartitionState(StateObjectCollection<ResultSubpartitionStateHandle> resultSubpartitionState) {\n+\t\t\tthis.resultSubpartitionState = checkNotNull(resultSubpartitionState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setInputChannelMappings(VirtualChannelMapping inputChannelMappings) {\n+\t\t\tthis.inputChannelMappings = checkNotNull(inputChannelMappings);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setOutputChannelMappings(VirtualChannelMapping outputChannelMappings) {\n+\t\t\tthis.outputChannelMappings = checkNotNull(outputChannelMappings);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic OperatorSubtaskState build() {\n+\t\t\treturn new OperatorSubtaskState(\n+\t\t\t\tmanagedOperatorState,\n+\t\t\t\trawOperatorState,\n+\t\t\t\tmanagedKeyedState,\n+\t\t\t\trawKeyedState,\n+\t\t\t\tinputChannelState,\n+\t\t\t\tresultSubpartitionState,\n+\t\t\t\tinputChannelMappings,\n+\t\t\t\toutputChannelMappings);\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Captures ambiguous mappings of old channels to new channels.\n+\t *\n+\t * <p>For inputs, this mapping implies the following:\n+\t * <li>\n+\t *     <ul>{@link #oldTaskInstances} is set when there is a rescale on this task potentially leading to different\n+\t *     key groups. Upstream task has a corresponding {@link #partitionMappings} where it sends data over\n+\t *     virtual channel while specifying the channel index in the VirtualChannelSelector. This subtask then\n+\t *     demultiplexes over the virtual subtask index.</ul>\n+\t *     <ul>{@link #partitionMappings} is set when there is a downscale of the upstream task. Upstream task has\n+\t *     a corresponding {@link #oldTaskInstances} where it sends data over virtual channel while specifying the\n+\t *     subtask index in the VirtualChannelSelector. This subtask then demultiplexes over channel indexes.</ul>\n+\t * </li>\n+\t *\n+\t * <p>For outputs, it's vice-versa. The information must be kept in sync but they are used in opposite ways for\n+\t * multiplexing/demultiplexing.\n+\t *\n+\t * <p>Note that in the common rescaling case both information is set and need to be simultaneously used. If the\n+\t * input subtask subsumes the state of 3 old subtasks and a channel corresponds to 2 old channels, then there are\n+\t * 6 virtual channels to be demultiplexed.\n+\t */\n+\tpublic static class VirtualChannelMapping implements Serializable {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkwMjk1MQ=="}, "originalCommit": {"oid": "9cbbcb24751268c0b5289b86606eb28baa1287eb"}, "originalPosition": 360}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIzOTU3MDUzOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/OperatorSubtaskState.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QxOToyNzoxMVrOHs9XQA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQwNzo1NzowOVrOHtMkOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkwNDc2OA==", "bodyText": "Why bitsets are used here and throughout the PR?\nI think just Set<Integer> would be\na) more readable\nb) more efficient (no need for extra words if only high bits are sets)", "url": "https://github.com/apache/flink/pull/13735#discussion_r516904768", "createdAt": "2020-11-03T19:27:11Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/OperatorSubtaskState.java", "diffHunk": "@@ -327,4 +289,252 @@ public boolean hasState() {\n \t\t\t|| inputChannelState.hasState()\n \t\t\t|| resultSubpartitionState.hasState();\n \t}\n+\n+\tpublic static Builder builder() {\n+\t\treturn new Builder();\n+\t}\n+\n+\t/**\n+\t * The builder for a new {@link OperatorSubtaskState} which can be obtained by {@link #builder()}.\n+\t */\n+\tpublic static class Builder {\n+\t\tprivate StateObjectCollection<OperatorStateHandle> managedOperatorState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<OperatorStateHandle> rawOperatorState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<KeyedStateHandle> managedKeyedState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<KeyedStateHandle> rawKeyedState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<InputChannelStateHandle> inputChannelState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<ResultSubpartitionStateHandle> resultSubpartitionState = StateObjectCollection.empty();\n+\t\tprivate VirtualChannelMapping inputChannelMappings = VirtualChannelMapping.NO_MAPPING;\n+\t\tprivate VirtualChannelMapping outputChannelMappings = VirtualChannelMapping.NO_MAPPING;\n+\n+\t\tprivate Builder() {\n+\t\t}\n+\n+\t\tpublic Builder setManagedOperatorState(StateObjectCollection<OperatorStateHandle> managedOperatorState) {\n+\t\t\tthis.managedOperatorState = checkNotNull(managedOperatorState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setManagedOperatorState(OperatorStateHandle managedOperatorState) {\n+\t\t\treturn setManagedOperatorState(StateObjectCollection.singleton(checkNotNull(managedOperatorState)));\n+\t\t}\n+\n+\t\tpublic Builder setRawOperatorState(StateObjectCollection<OperatorStateHandle> rawOperatorState) {\n+\t\t\tthis.rawOperatorState = checkNotNull(rawOperatorState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setRawOperatorState(OperatorStateHandle rawOperatorState) {\n+\t\t\treturn setRawOperatorState(StateObjectCollection.singleton(checkNotNull(rawOperatorState)));\n+\t\t}\n+\n+\t\tpublic Builder setManagedKeyedState(StateObjectCollection<KeyedStateHandle> managedKeyedState) {\n+\t\t\tthis.managedKeyedState = checkNotNull(managedKeyedState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setManagedKeyedState(KeyedStateHandle managedKeyedState) {\n+\t\t\treturn setManagedKeyedState(StateObjectCollection.singleton(checkNotNull(managedKeyedState)));\n+\t\t}\n+\n+\t\tpublic Builder setRawKeyedState(StateObjectCollection<KeyedStateHandle> rawKeyedState) {\n+\t\t\tthis.rawKeyedState = checkNotNull(rawKeyedState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setRawKeyedState(KeyedStateHandle rawKeyedState) {\n+\t\t\treturn setRawKeyedState(StateObjectCollection.singleton(checkNotNull(rawKeyedState)));\n+\t\t}\n+\n+\t\tpublic Builder setInputChannelState(StateObjectCollection<InputChannelStateHandle> inputChannelState) {\n+\t\t\tthis.inputChannelState = checkNotNull(inputChannelState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setResultSubpartitionState(StateObjectCollection<ResultSubpartitionStateHandle> resultSubpartitionState) {\n+\t\t\tthis.resultSubpartitionState = checkNotNull(resultSubpartitionState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setInputChannelMappings(VirtualChannelMapping inputChannelMappings) {\n+\t\t\tthis.inputChannelMappings = checkNotNull(inputChannelMappings);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setOutputChannelMappings(VirtualChannelMapping outputChannelMappings) {\n+\t\t\tthis.outputChannelMappings = checkNotNull(outputChannelMappings);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic OperatorSubtaskState build() {\n+\t\t\treturn new OperatorSubtaskState(\n+\t\t\t\tmanagedOperatorState,\n+\t\t\t\trawOperatorState,\n+\t\t\t\tmanagedKeyedState,\n+\t\t\t\trawKeyedState,\n+\t\t\t\tinputChannelState,\n+\t\t\t\tresultSubpartitionState,\n+\t\t\t\tinputChannelMappings,\n+\t\t\t\toutputChannelMappings);\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Captures ambiguous mappings of old channels to new channels.\n+\t *\n+\t * <p>For inputs, this mapping implies the following:\n+\t * <li>\n+\t *     <ul>{@link #oldTaskInstances} is set when there is a rescale on this task potentially leading to different\n+\t *     key groups. Upstream task has a corresponding {@link #partitionMappings} where it sends data over\n+\t *     virtual channel while specifying the channel index in the VirtualChannelSelector. This subtask then\n+\t *     demultiplexes over the virtual subtask index.</ul>\n+\t *     <ul>{@link #partitionMappings} is set when there is a downscale of the upstream task. Upstream task has\n+\t *     a corresponding {@link #oldTaskInstances} where it sends data over virtual channel while specifying the\n+\t *     subtask index in the VirtualChannelSelector. This subtask then demultiplexes over channel indexes.</ul>\n+\t * </li>\n+\t *\n+\t * <p>For outputs, it's vice-versa. The information must be kept in sync but they are used in opposite ways for\n+\t * multiplexing/demultiplexing.\n+\t *\n+\t * <p>Note that in the common rescaling case both information is set and need to be simultaneously used. If the\n+\t * input subtask subsumes the state of 3 old subtasks and a channel corresponds to 2 old channels, then there are\n+\t * 6 virtual channels to be demultiplexed.\n+\t */\n+\tpublic static class VirtualChannelMapping implements Serializable {\n+\t\tpublic static final PartitionMapping NO_CHANNEL_MAPPING = new PartitionMapping(emptyList());\n+\t\tpublic static final List<PartitionMapping> NO_PARTITIONS = emptyList();\n+\t\tpublic static final BitSet NO_SUBTASKS = new BitSet();\n+\t\tpublic static final VirtualChannelMapping NO_MAPPING = new VirtualChannelMapping(NO_SUBTASKS, NO_PARTITIONS);\n+\n+\t\t/**\n+\t\t * Set when several operator instances are merged into one.\n+\t\t */\n+\t\tprivate final BitSet oldTaskInstances;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9cbbcb24751268c0b5289b86606eb28baa1287eb"}, "originalPosition": 369}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzE1Mzg0OQ==", "bodyText": "I used it for memory optimization but it might have been prematurely:\nSet<Integer> uses 16 bytes per entry + 4 bytes for boxing + hash table overhead\nBitSet would be more efficient at least for all entries up to 24 bytes (so 24 channels).\nBut I see that it's not scaling well, especially since Set<Integer> should be mostly 1 or 2 entries (so ~50 bytes).", "url": "https://github.com/apache/flink/pull/13735#discussion_r517153849", "createdAt": "2020-11-04T07:57:09Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/OperatorSubtaskState.java", "diffHunk": "@@ -327,4 +289,252 @@ public boolean hasState() {\n \t\t\t|| inputChannelState.hasState()\n \t\t\t|| resultSubpartitionState.hasState();\n \t}\n+\n+\tpublic static Builder builder() {\n+\t\treturn new Builder();\n+\t}\n+\n+\t/**\n+\t * The builder for a new {@link OperatorSubtaskState} which can be obtained by {@link #builder()}.\n+\t */\n+\tpublic static class Builder {\n+\t\tprivate StateObjectCollection<OperatorStateHandle> managedOperatorState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<OperatorStateHandle> rawOperatorState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<KeyedStateHandle> managedKeyedState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<KeyedStateHandle> rawKeyedState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<InputChannelStateHandle> inputChannelState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<ResultSubpartitionStateHandle> resultSubpartitionState = StateObjectCollection.empty();\n+\t\tprivate VirtualChannelMapping inputChannelMappings = VirtualChannelMapping.NO_MAPPING;\n+\t\tprivate VirtualChannelMapping outputChannelMappings = VirtualChannelMapping.NO_MAPPING;\n+\n+\t\tprivate Builder() {\n+\t\t}\n+\n+\t\tpublic Builder setManagedOperatorState(StateObjectCollection<OperatorStateHandle> managedOperatorState) {\n+\t\t\tthis.managedOperatorState = checkNotNull(managedOperatorState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setManagedOperatorState(OperatorStateHandle managedOperatorState) {\n+\t\t\treturn setManagedOperatorState(StateObjectCollection.singleton(checkNotNull(managedOperatorState)));\n+\t\t}\n+\n+\t\tpublic Builder setRawOperatorState(StateObjectCollection<OperatorStateHandle> rawOperatorState) {\n+\t\t\tthis.rawOperatorState = checkNotNull(rawOperatorState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setRawOperatorState(OperatorStateHandle rawOperatorState) {\n+\t\t\treturn setRawOperatorState(StateObjectCollection.singleton(checkNotNull(rawOperatorState)));\n+\t\t}\n+\n+\t\tpublic Builder setManagedKeyedState(StateObjectCollection<KeyedStateHandle> managedKeyedState) {\n+\t\t\tthis.managedKeyedState = checkNotNull(managedKeyedState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setManagedKeyedState(KeyedStateHandle managedKeyedState) {\n+\t\t\treturn setManagedKeyedState(StateObjectCollection.singleton(checkNotNull(managedKeyedState)));\n+\t\t}\n+\n+\t\tpublic Builder setRawKeyedState(StateObjectCollection<KeyedStateHandle> rawKeyedState) {\n+\t\t\tthis.rawKeyedState = checkNotNull(rawKeyedState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setRawKeyedState(KeyedStateHandle rawKeyedState) {\n+\t\t\treturn setRawKeyedState(StateObjectCollection.singleton(checkNotNull(rawKeyedState)));\n+\t\t}\n+\n+\t\tpublic Builder setInputChannelState(StateObjectCollection<InputChannelStateHandle> inputChannelState) {\n+\t\t\tthis.inputChannelState = checkNotNull(inputChannelState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setResultSubpartitionState(StateObjectCollection<ResultSubpartitionStateHandle> resultSubpartitionState) {\n+\t\t\tthis.resultSubpartitionState = checkNotNull(resultSubpartitionState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setInputChannelMappings(VirtualChannelMapping inputChannelMappings) {\n+\t\t\tthis.inputChannelMappings = checkNotNull(inputChannelMappings);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setOutputChannelMappings(VirtualChannelMapping outputChannelMappings) {\n+\t\t\tthis.outputChannelMappings = checkNotNull(outputChannelMappings);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic OperatorSubtaskState build() {\n+\t\t\treturn new OperatorSubtaskState(\n+\t\t\t\tmanagedOperatorState,\n+\t\t\t\trawOperatorState,\n+\t\t\t\tmanagedKeyedState,\n+\t\t\t\trawKeyedState,\n+\t\t\t\tinputChannelState,\n+\t\t\t\tresultSubpartitionState,\n+\t\t\t\tinputChannelMappings,\n+\t\t\t\toutputChannelMappings);\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Captures ambiguous mappings of old channels to new channels.\n+\t *\n+\t * <p>For inputs, this mapping implies the following:\n+\t * <li>\n+\t *     <ul>{@link #oldTaskInstances} is set when there is a rescale on this task potentially leading to different\n+\t *     key groups. Upstream task has a corresponding {@link #partitionMappings} where it sends data over\n+\t *     virtual channel while specifying the channel index in the VirtualChannelSelector. This subtask then\n+\t *     demultiplexes over the virtual subtask index.</ul>\n+\t *     <ul>{@link #partitionMappings} is set when there is a downscale of the upstream task. Upstream task has\n+\t *     a corresponding {@link #oldTaskInstances} where it sends data over virtual channel while specifying the\n+\t *     subtask index in the VirtualChannelSelector. This subtask then demultiplexes over channel indexes.</ul>\n+\t * </li>\n+\t *\n+\t * <p>For outputs, it's vice-versa. The information must be kept in sync but they are used in opposite ways for\n+\t * multiplexing/demultiplexing.\n+\t *\n+\t * <p>Note that in the common rescaling case both information is set and need to be simultaneously used. If the\n+\t * input subtask subsumes the state of 3 old subtasks and a channel corresponds to 2 old channels, then there are\n+\t * 6 virtual channels to be demultiplexed.\n+\t */\n+\tpublic static class VirtualChannelMapping implements Serializable {\n+\t\tpublic static final PartitionMapping NO_CHANNEL_MAPPING = new PartitionMapping(emptyList());\n+\t\tpublic static final List<PartitionMapping> NO_PARTITIONS = emptyList();\n+\t\tpublic static final BitSet NO_SUBTASKS = new BitSet();\n+\t\tpublic static final VirtualChannelMapping NO_MAPPING = new VirtualChannelMapping(NO_SUBTASKS, NO_PARTITIONS);\n+\n+\t\t/**\n+\t\t * Set when several operator instances are merged into one.\n+\t\t */\n+\t\tprivate final BitSet oldTaskInstances;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkwNDc2OA=="}, "originalCommit": {"oid": "9cbbcb24751268c0b5289b86606eb28baa1287eb"}, "originalPosition": 369}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIzOTU4MjAwOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/OperatorSubtaskState.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QxOTozMDoxNlrOHs9eNw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQxNDozMTowMFrOHtarUA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkwNjU1MQ==", "bodyText": "To me, list isn't an obvious choice to provide index-based access.\nArray or hashtable would be more readable to me and guarantee O(1) time.", "url": "https://github.com/apache/flink/pull/13735#discussion_r516906551", "createdAt": "2020-11-03T19:30:16Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/OperatorSubtaskState.java", "diffHunk": "@@ -327,4 +289,252 @@ public boolean hasState() {\n \t\t\t|| inputChannelState.hasState()\n \t\t\t|| resultSubpartitionState.hasState();\n \t}\n+\n+\tpublic static Builder builder() {\n+\t\treturn new Builder();\n+\t}\n+\n+\t/**\n+\t * The builder for a new {@link OperatorSubtaskState} which can be obtained by {@link #builder()}.\n+\t */\n+\tpublic static class Builder {\n+\t\tprivate StateObjectCollection<OperatorStateHandle> managedOperatorState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<OperatorStateHandle> rawOperatorState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<KeyedStateHandle> managedKeyedState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<KeyedStateHandle> rawKeyedState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<InputChannelStateHandle> inputChannelState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<ResultSubpartitionStateHandle> resultSubpartitionState = StateObjectCollection.empty();\n+\t\tprivate VirtualChannelMapping inputChannelMappings = VirtualChannelMapping.NO_MAPPING;\n+\t\tprivate VirtualChannelMapping outputChannelMappings = VirtualChannelMapping.NO_MAPPING;\n+\n+\t\tprivate Builder() {\n+\t\t}\n+\n+\t\tpublic Builder setManagedOperatorState(StateObjectCollection<OperatorStateHandle> managedOperatorState) {\n+\t\t\tthis.managedOperatorState = checkNotNull(managedOperatorState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setManagedOperatorState(OperatorStateHandle managedOperatorState) {\n+\t\t\treturn setManagedOperatorState(StateObjectCollection.singleton(checkNotNull(managedOperatorState)));\n+\t\t}\n+\n+\t\tpublic Builder setRawOperatorState(StateObjectCollection<OperatorStateHandle> rawOperatorState) {\n+\t\t\tthis.rawOperatorState = checkNotNull(rawOperatorState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setRawOperatorState(OperatorStateHandle rawOperatorState) {\n+\t\t\treturn setRawOperatorState(StateObjectCollection.singleton(checkNotNull(rawOperatorState)));\n+\t\t}\n+\n+\t\tpublic Builder setManagedKeyedState(StateObjectCollection<KeyedStateHandle> managedKeyedState) {\n+\t\t\tthis.managedKeyedState = checkNotNull(managedKeyedState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setManagedKeyedState(KeyedStateHandle managedKeyedState) {\n+\t\t\treturn setManagedKeyedState(StateObjectCollection.singleton(checkNotNull(managedKeyedState)));\n+\t\t}\n+\n+\t\tpublic Builder setRawKeyedState(StateObjectCollection<KeyedStateHandle> rawKeyedState) {\n+\t\t\tthis.rawKeyedState = checkNotNull(rawKeyedState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setRawKeyedState(KeyedStateHandle rawKeyedState) {\n+\t\t\treturn setRawKeyedState(StateObjectCollection.singleton(checkNotNull(rawKeyedState)));\n+\t\t}\n+\n+\t\tpublic Builder setInputChannelState(StateObjectCollection<InputChannelStateHandle> inputChannelState) {\n+\t\t\tthis.inputChannelState = checkNotNull(inputChannelState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setResultSubpartitionState(StateObjectCollection<ResultSubpartitionStateHandle> resultSubpartitionState) {\n+\t\t\tthis.resultSubpartitionState = checkNotNull(resultSubpartitionState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setInputChannelMappings(VirtualChannelMapping inputChannelMappings) {\n+\t\t\tthis.inputChannelMappings = checkNotNull(inputChannelMappings);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setOutputChannelMappings(VirtualChannelMapping outputChannelMappings) {\n+\t\t\tthis.outputChannelMappings = checkNotNull(outputChannelMappings);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic OperatorSubtaskState build() {\n+\t\t\treturn new OperatorSubtaskState(\n+\t\t\t\tmanagedOperatorState,\n+\t\t\t\trawOperatorState,\n+\t\t\t\tmanagedKeyedState,\n+\t\t\t\trawKeyedState,\n+\t\t\t\tinputChannelState,\n+\t\t\t\tresultSubpartitionState,\n+\t\t\t\tinputChannelMappings,\n+\t\t\t\toutputChannelMappings);\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Captures ambiguous mappings of old channels to new channels.\n+\t *\n+\t * <p>For inputs, this mapping implies the following:\n+\t * <li>\n+\t *     <ul>{@link #oldTaskInstances} is set when there is a rescale on this task potentially leading to different\n+\t *     key groups. Upstream task has a corresponding {@link #partitionMappings} where it sends data over\n+\t *     virtual channel while specifying the channel index in the VirtualChannelSelector. This subtask then\n+\t *     demultiplexes over the virtual subtask index.</ul>\n+\t *     <ul>{@link #partitionMappings} is set when there is a downscale of the upstream task. Upstream task has\n+\t *     a corresponding {@link #oldTaskInstances} where it sends data over virtual channel while specifying the\n+\t *     subtask index in the VirtualChannelSelector. This subtask then demultiplexes over channel indexes.</ul>\n+\t * </li>\n+\t *\n+\t * <p>For outputs, it's vice-versa. The information must be kept in sync but they are used in opposite ways for\n+\t * multiplexing/demultiplexing.\n+\t *\n+\t * <p>Note that in the common rescaling case both information is set and need to be simultaneously used. If the\n+\t * input subtask subsumes the state of 3 old subtasks and a channel corresponds to 2 old channels, then there are\n+\t * 6 virtual channels to be demultiplexed.\n+\t */\n+\tpublic static class VirtualChannelMapping implements Serializable {\n+\t\tpublic static final PartitionMapping NO_CHANNEL_MAPPING = new PartitionMapping(emptyList());\n+\t\tpublic static final List<PartitionMapping> NO_PARTITIONS = emptyList();\n+\t\tpublic static final BitSet NO_SUBTASKS = new BitSet();\n+\t\tpublic static final VirtualChannelMapping NO_MAPPING = new VirtualChannelMapping(NO_SUBTASKS, NO_PARTITIONS);\n+\n+\t\t/**\n+\t\t * Set when several operator instances are merged into one.\n+\t\t */\n+\t\tprivate final BitSet oldTaskInstances;\n+\n+\t\t/**\n+\t\t * Set when channels are merged because the connected operator has been rescaled.\n+\t\t */\n+\t\tprivate final List<PartitionMapping> partitionMappings;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9cbbcb24751268c0b5289b86606eb28baa1287eb"}, "originalPosition": 374}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzMzNDE3NQ==", "bodyText": "Isn't array and array-list the same in complexity? I usually use a map for sparse data and list when it's dense (ideally consecutive), since it's much better on the memory consumption.\nBut I could go for array. At some point, I didn't have PartitionMapping and used generics which don't mix well with arrays.", "url": "https://github.com/apache/flink/pull/13735#discussion_r517334175", "createdAt": "2020-11-04T13:15:56Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/OperatorSubtaskState.java", "diffHunk": "@@ -327,4 +289,252 @@ public boolean hasState() {\n \t\t\t|| inputChannelState.hasState()\n \t\t\t|| resultSubpartitionState.hasState();\n \t}\n+\n+\tpublic static Builder builder() {\n+\t\treturn new Builder();\n+\t}\n+\n+\t/**\n+\t * The builder for a new {@link OperatorSubtaskState} which can be obtained by {@link #builder()}.\n+\t */\n+\tpublic static class Builder {\n+\t\tprivate StateObjectCollection<OperatorStateHandle> managedOperatorState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<OperatorStateHandle> rawOperatorState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<KeyedStateHandle> managedKeyedState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<KeyedStateHandle> rawKeyedState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<InputChannelStateHandle> inputChannelState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<ResultSubpartitionStateHandle> resultSubpartitionState = StateObjectCollection.empty();\n+\t\tprivate VirtualChannelMapping inputChannelMappings = VirtualChannelMapping.NO_MAPPING;\n+\t\tprivate VirtualChannelMapping outputChannelMappings = VirtualChannelMapping.NO_MAPPING;\n+\n+\t\tprivate Builder() {\n+\t\t}\n+\n+\t\tpublic Builder setManagedOperatorState(StateObjectCollection<OperatorStateHandle> managedOperatorState) {\n+\t\t\tthis.managedOperatorState = checkNotNull(managedOperatorState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setManagedOperatorState(OperatorStateHandle managedOperatorState) {\n+\t\t\treturn setManagedOperatorState(StateObjectCollection.singleton(checkNotNull(managedOperatorState)));\n+\t\t}\n+\n+\t\tpublic Builder setRawOperatorState(StateObjectCollection<OperatorStateHandle> rawOperatorState) {\n+\t\t\tthis.rawOperatorState = checkNotNull(rawOperatorState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setRawOperatorState(OperatorStateHandle rawOperatorState) {\n+\t\t\treturn setRawOperatorState(StateObjectCollection.singleton(checkNotNull(rawOperatorState)));\n+\t\t}\n+\n+\t\tpublic Builder setManagedKeyedState(StateObjectCollection<KeyedStateHandle> managedKeyedState) {\n+\t\t\tthis.managedKeyedState = checkNotNull(managedKeyedState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setManagedKeyedState(KeyedStateHandle managedKeyedState) {\n+\t\t\treturn setManagedKeyedState(StateObjectCollection.singleton(checkNotNull(managedKeyedState)));\n+\t\t}\n+\n+\t\tpublic Builder setRawKeyedState(StateObjectCollection<KeyedStateHandle> rawKeyedState) {\n+\t\t\tthis.rawKeyedState = checkNotNull(rawKeyedState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setRawKeyedState(KeyedStateHandle rawKeyedState) {\n+\t\t\treturn setRawKeyedState(StateObjectCollection.singleton(checkNotNull(rawKeyedState)));\n+\t\t}\n+\n+\t\tpublic Builder setInputChannelState(StateObjectCollection<InputChannelStateHandle> inputChannelState) {\n+\t\t\tthis.inputChannelState = checkNotNull(inputChannelState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setResultSubpartitionState(StateObjectCollection<ResultSubpartitionStateHandle> resultSubpartitionState) {\n+\t\t\tthis.resultSubpartitionState = checkNotNull(resultSubpartitionState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setInputChannelMappings(VirtualChannelMapping inputChannelMappings) {\n+\t\t\tthis.inputChannelMappings = checkNotNull(inputChannelMappings);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setOutputChannelMappings(VirtualChannelMapping outputChannelMappings) {\n+\t\t\tthis.outputChannelMappings = checkNotNull(outputChannelMappings);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic OperatorSubtaskState build() {\n+\t\t\treturn new OperatorSubtaskState(\n+\t\t\t\tmanagedOperatorState,\n+\t\t\t\trawOperatorState,\n+\t\t\t\tmanagedKeyedState,\n+\t\t\t\trawKeyedState,\n+\t\t\t\tinputChannelState,\n+\t\t\t\tresultSubpartitionState,\n+\t\t\t\tinputChannelMappings,\n+\t\t\t\toutputChannelMappings);\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Captures ambiguous mappings of old channels to new channels.\n+\t *\n+\t * <p>For inputs, this mapping implies the following:\n+\t * <li>\n+\t *     <ul>{@link #oldTaskInstances} is set when there is a rescale on this task potentially leading to different\n+\t *     key groups. Upstream task has a corresponding {@link #partitionMappings} where it sends data over\n+\t *     virtual channel while specifying the channel index in the VirtualChannelSelector. This subtask then\n+\t *     demultiplexes over the virtual subtask index.</ul>\n+\t *     <ul>{@link #partitionMappings} is set when there is a downscale of the upstream task. Upstream task has\n+\t *     a corresponding {@link #oldTaskInstances} where it sends data over virtual channel while specifying the\n+\t *     subtask index in the VirtualChannelSelector. This subtask then demultiplexes over channel indexes.</ul>\n+\t * </li>\n+\t *\n+\t * <p>For outputs, it's vice-versa. The information must be kept in sync but they are used in opposite ways for\n+\t * multiplexing/demultiplexing.\n+\t *\n+\t * <p>Note that in the common rescaling case both information is set and need to be simultaneously used. If the\n+\t * input subtask subsumes the state of 3 old subtasks and a channel corresponds to 2 old channels, then there are\n+\t * 6 virtual channels to be demultiplexed.\n+\t */\n+\tpublic static class VirtualChannelMapping implements Serializable {\n+\t\tpublic static final PartitionMapping NO_CHANNEL_MAPPING = new PartitionMapping(emptyList());\n+\t\tpublic static final List<PartitionMapping> NO_PARTITIONS = emptyList();\n+\t\tpublic static final BitSet NO_SUBTASKS = new BitSet();\n+\t\tpublic static final VirtualChannelMapping NO_MAPPING = new VirtualChannelMapping(NO_SUBTASKS, NO_PARTITIONS);\n+\n+\t\t/**\n+\t\t * Set when several operator instances are merged into one.\n+\t\t */\n+\t\tprivate final BitSet oldTaskInstances;\n+\n+\t\t/**\n+\t\t * Set when channels are merged because the connected operator has been rescaled.\n+\t\t */\n+\t\tprivate final List<PartitionMapping> partitionMappings;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkwNjU1MQ=="}, "originalCommit": {"oid": "9cbbcb24751268c0b5289b86606eb28baa1287eb"}, "originalPosition": 374}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzM4NTA0MA==", "bodyText": "Isn't array and array-list the same in complexity?\n\nYes, but here it is List, which can be a LinkedList.\nIf not arrays, then I'd go with Map, just because it makes obvious how elements are indexed and accessed. I don't think overhead will be visible here.", "url": "https://github.com/apache/flink/pull/13735#discussion_r517385040", "createdAt": "2020-11-04T14:31:00Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/OperatorSubtaskState.java", "diffHunk": "@@ -327,4 +289,252 @@ public boolean hasState() {\n \t\t\t|| inputChannelState.hasState()\n \t\t\t|| resultSubpartitionState.hasState();\n \t}\n+\n+\tpublic static Builder builder() {\n+\t\treturn new Builder();\n+\t}\n+\n+\t/**\n+\t * The builder for a new {@link OperatorSubtaskState} which can be obtained by {@link #builder()}.\n+\t */\n+\tpublic static class Builder {\n+\t\tprivate StateObjectCollection<OperatorStateHandle> managedOperatorState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<OperatorStateHandle> rawOperatorState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<KeyedStateHandle> managedKeyedState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<KeyedStateHandle> rawKeyedState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<InputChannelStateHandle> inputChannelState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<ResultSubpartitionStateHandle> resultSubpartitionState = StateObjectCollection.empty();\n+\t\tprivate VirtualChannelMapping inputChannelMappings = VirtualChannelMapping.NO_MAPPING;\n+\t\tprivate VirtualChannelMapping outputChannelMappings = VirtualChannelMapping.NO_MAPPING;\n+\n+\t\tprivate Builder() {\n+\t\t}\n+\n+\t\tpublic Builder setManagedOperatorState(StateObjectCollection<OperatorStateHandle> managedOperatorState) {\n+\t\t\tthis.managedOperatorState = checkNotNull(managedOperatorState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setManagedOperatorState(OperatorStateHandle managedOperatorState) {\n+\t\t\treturn setManagedOperatorState(StateObjectCollection.singleton(checkNotNull(managedOperatorState)));\n+\t\t}\n+\n+\t\tpublic Builder setRawOperatorState(StateObjectCollection<OperatorStateHandle> rawOperatorState) {\n+\t\t\tthis.rawOperatorState = checkNotNull(rawOperatorState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setRawOperatorState(OperatorStateHandle rawOperatorState) {\n+\t\t\treturn setRawOperatorState(StateObjectCollection.singleton(checkNotNull(rawOperatorState)));\n+\t\t}\n+\n+\t\tpublic Builder setManagedKeyedState(StateObjectCollection<KeyedStateHandle> managedKeyedState) {\n+\t\t\tthis.managedKeyedState = checkNotNull(managedKeyedState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setManagedKeyedState(KeyedStateHandle managedKeyedState) {\n+\t\t\treturn setManagedKeyedState(StateObjectCollection.singleton(checkNotNull(managedKeyedState)));\n+\t\t}\n+\n+\t\tpublic Builder setRawKeyedState(StateObjectCollection<KeyedStateHandle> rawKeyedState) {\n+\t\t\tthis.rawKeyedState = checkNotNull(rawKeyedState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setRawKeyedState(KeyedStateHandle rawKeyedState) {\n+\t\t\treturn setRawKeyedState(StateObjectCollection.singleton(checkNotNull(rawKeyedState)));\n+\t\t}\n+\n+\t\tpublic Builder setInputChannelState(StateObjectCollection<InputChannelStateHandle> inputChannelState) {\n+\t\t\tthis.inputChannelState = checkNotNull(inputChannelState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setResultSubpartitionState(StateObjectCollection<ResultSubpartitionStateHandle> resultSubpartitionState) {\n+\t\t\tthis.resultSubpartitionState = checkNotNull(resultSubpartitionState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setInputChannelMappings(VirtualChannelMapping inputChannelMappings) {\n+\t\t\tthis.inputChannelMappings = checkNotNull(inputChannelMappings);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setOutputChannelMappings(VirtualChannelMapping outputChannelMappings) {\n+\t\t\tthis.outputChannelMappings = checkNotNull(outputChannelMappings);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic OperatorSubtaskState build() {\n+\t\t\treturn new OperatorSubtaskState(\n+\t\t\t\tmanagedOperatorState,\n+\t\t\t\trawOperatorState,\n+\t\t\t\tmanagedKeyedState,\n+\t\t\t\trawKeyedState,\n+\t\t\t\tinputChannelState,\n+\t\t\t\tresultSubpartitionState,\n+\t\t\t\tinputChannelMappings,\n+\t\t\t\toutputChannelMappings);\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Captures ambiguous mappings of old channels to new channels.\n+\t *\n+\t * <p>For inputs, this mapping implies the following:\n+\t * <li>\n+\t *     <ul>{@link #oldTaskInstances} is set when there is a rescale on this task potentially leading to different\n+\t *     key groups. Upstream task has a corresponding {@link #partitionMappings} where it sends data over\n+\t *     virtual channel while specifying the channel index in the VirtualChannelSelector. This subtask then\n+\t *     demultiplexes over the virtual subtask index.</ul>\n+\t *     <ul>{@link #partitionMappings} is set when there is a downscale of the upstream task. Upstream task has\n+\t *     a corresponding {@link #oldTaskInstances} where it sends data over virtual channel while specifying the\n+\t *     subtask index in the VirtualChannelSelector. This subtask then demultiplexes over channel indexes.</ul>\n+\t * </li>\n+\t *\n+\t * <p>For outputs, it's vice-versa. The information must be kept in sync but they are used in opposite ways for\n+\t * multiplexing/demultiplexing.\n+\t *\n+\t * <p>Note that in the common rescaling case both information is set and need to be simultaneously used. If the\n+\t * input subtask subsumes the state of 3 old subtasks and a channel corresponds to 2 old channels, then there are\n+\t * 6 virtual channels to be demultiplexed.\n+\t */\n+\tpublic static class VirtualChannelMapping implements Serializable {\n+\t\tpublic static final PartitionMapping NO_CHANNEL_MAPPING = new PartitionMapping(emptyList());\n+\t\tpublic static final List<PartitionMapping> NO_PARTITIONS = emptyList();\n+\t\tpublic static final BitSet NO_SUBTASKS = new BitSet();\n+\t\tpublic static final VirtualChannelMapping NO_MAPPING = new VirtualChannelMapping(NO_SUBTASKS, NO_PARTITIONS);\n+\n+\t\t/**\n+\t\t * Set when several operator instances are merged into one.\n+\t\t */\n+\t\tprivate final BitSet oldTaskInstances;\n+\n+\t\t/**\n+\t\t * Set when channels are merged because the connected operator has been rescaled.\n+\t\t */\n+\t\tprivate final List<PartitionMapping> partitionMappings;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkwNjU1MQ=="}, "originalCommit": {"oid": "9cbbcb24751268c0b5289b86606eb28baa1287eb"}, "originalPosition": 374}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIzOTU5MjEwOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/OperatorSubtaskState.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QxOTozMzoxOFrOHs9kfw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QxOTozMzoxOFrOHs9kfw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkwODE1OQ==", "bodyText": "PartitionMapping associates with the ResultPartition, but this class maps input channels and subPartitions, right? How about RescaledChannelsMapping?\nserialVersionUID?\nnit: I'd extract this class too", "url": "https://github.com/apache/flink/pull/13735#discussion_r516908159", "createdAt": "2020-11-03T19:33:18Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/OperatorSubtaskState.java", "diffHunk": "@@ -327,4 +289,252 @@ public boolean hasState() {\n \t\t\t|| inputChannelState.hasState()\n \t\t\t|| resultSubpartitionState.hasState();\n \t}\n+\n+\tpublic static Builder builder() {\n+\t\treturn new Builder();\n+\t}\n+\n+\t/**\n+\t * The builder for a new {@link OperatorSubtaskState} which can be obtained by {@link #builder()}.\n+\t */\n+\tpublic static class Builder {\n+\t\tprivate StateObjectCollection<OperatorStateHandle> managedOperatorState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<OperatorStateHandle> rawOperatorState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<KeyedStateHandle> managedKeyedState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<KeyedStateHandle> rawKeyedState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<InputChannelStateHandle> inputChannelState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<ResultSubpartitionStateHandle> resultSubpartitionState = StateObjectCollection.empty();\n+\t\tprivate VirtualChannelMapping inputChannelMappings = VirtualChannelMapping.NO_MAPPING;\n+\t\tprivate VirtualChannelMapping outputChannelMappings = VirtualChannelMapping.NO_MAPPING;\n+\n+\t\tprivate Builder() {\n+\t\t}\n+\n+\t\tpublic Builder setManagedOperatorState(StateObjectCollection<OperatorStateHandle> managedOperatorState) {\n+\t\t\tthis.managedOperatorState = checkNotNull(managedOperatorState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setManagedOperatorState(OperatorStateHandle managedOperatorState) {\n+\t\t\treturn setManagedOperatorState(StateObjectCollection.singleton(checkNotNull(managedOperatorState)));\n+\t\t}\n+\n+\t\tpublic Builder setRawOperatorState(StateObjectCollection<OperatorStateHandle> rawOperatorState) {\n+\t\t\tthis.rawOperatorState = checkNotNull(rawOperatorState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setRawOperatorState(OperatorStateHandle rawOperatorState) {\n+\t\t\treturn setRawOperatorState(StateObjectCollection.singleton(checkNotNull(rawOperatorState)));\n+\t\t}\n+\n+\t\tpublic Builder setManagedKeyedState(StateObjectCollection<KeyedStateHandle> managedKeyedState) {\n+\t\t\tthis.managedKeyedState = checkNotNull(managedKeyedState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setManagedKeyedState(KeyedStateHandle managedKeyedState) {\n+\t\t\treturn setManagedKeyedState(StateObjectCollection.singleton(checkNotNull(managedKeyedState)));\n+\t\t}\n+\n+\t\tpublic Builder setRawKeyedState(StateObjectCollection<KeyedStateHandle> rawKeyedState) {\n+\t\t\tthis.rawKeyedState = checkNotNull(rawKeyedState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setRawKeyedState(KeyedStateHandle rawKeyedState) {\n+\t\t\treturn setRawKeyedState(StateObjectCollection.singleton(checkNotNull(rawKeyedState)));\n+\t\t}\n+\n+\t\tpublic Builder setInputChannelState(StateObjectCollection<InputChannelStateHandle> inputChannelState) {\n+\t\t\tthis.inputChannelState = checkNotNull(inputChannelState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setResultSubpartitionState(StateObjectCollection<ResultSubpartitionStateHandle> resultSubpartitionState) {\n+\t\t\tthis.resultSubpartitionState = checkNotNull(resultSubpartitionState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setInputChannelMappings(VirtualChannelMapping inputChannelMappings) {\n+\t\t\tthis.inputChannelMappings = checkNotNull(inputChannelMappings);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setOutputChannelMappings(VirtualChannelMapping outputChannelMappings) {\n+\t\t\tthis.outputChannelMappings = checkNotNull(outputChannelMappings);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic OperatorSubtaskState build() {\n+\t\t\treturn new OperatorSubtaskState(\n+\t\t\t\tmanagedOperatorState,\n+\t\t\t\trawOperatorState,\n+\t\t\t\tmanagedKeyedState,\n+\t\t\t\trawKeyedState,\n+\t\t\t\tinputChannelState,\n+\t\t\t\tresultSubpartitionState,\n+\t\t\t\tinputChannelMappings,\n+\t\t\t\toutputChannelMappings);\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Captures ambiguous mappings of old channels to new channels.\n+\t *\n+\t * <p>For inputs, this mapping implies the following:\n+\t * <li>\n+\t *     <ul>{@link #oldTaskInstances} is set when there is a rescale on this task potentially leading to different\n+\t *     key groups. Upstream task has a corresponding {@link #partitionMappings} where it sends data over\n+\t *     virtual channel while specifying the channel index in the VirtualChannelSelector. This subtask then\n+\t *     demultiplexes over the virtual subtask index.</ul>\n+\t *     <ul>{@link #partitionMappings} is set when there is a downscale of the upstream task. Upstream task has\n+\t *     a corresponding {@link #oldTaskInstances} where it sends data over virtual channel while specifying the\n+\t *     subtask index in the VirtualChannelSelector. This subtask then demultiplexes over channel indexes.</ul>\n+\t * </li>\n+\t *\n+\t * <p>For outputs, it's vice-versa. The information must be kept in sync but they are used in opposite ways for\n+\t * multiplexing/demultiplexing.\n+\t *\n+\t * <p>Note that in the common rescaling case both information is set and need to be simultaneously used. If the\n+\t * input subtask subsumes the state of 3 old subtasks and a channel corresponds to 2 old channels, then there are\n+\t * 6 virtual channels to be demultiplexed.\n+\t */\n+\tpublic static class VirtualChannelMapping implements Serializable {\n+\t\tpublic static final PartitionMapping NO_CHANNEL_MAPPING = new PartitionMapping(emptyList());\n+\t\tpublic static final List<PartitionMapping> NO_PARTITIONS = emptyList();\n+\t\tpublic static final BitSet NO_SUBTASKS = new BitSet();\n+\t\tpublic static final VirtualChannelMapping NO_MAPPING = new VirtualChannelMapping(NO_SUBTASKS, NO_PARTITIONS);\n+\n+\t\t/**\n+\t\t * Set when several operator instances are merged into one.\n+\t\t */\n+\t\tprivate final BitSet oldTaskInstances;\n+\n+\t\t/**\n+\t\t * Set when channels are merged because the connected operator has been rescaled.\n+\t\t */\n+\t\tprivate final List<PartitionMapping> partitionMappings;\n+\n+\t\tpublic VirtualChannelMapping(BitSet oldTaskInstances, List<PartitionMapping> partitionMappings) {\n+\t\t\tthis.oldTaskInstances = oldTaskInstances;\n+\t\t\tthis.partitionMappings = partitionMappings;\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic boolean equals(Object o) {\n+\t\t\tif (this == o) {\n+\t\t\t\treturn true;\n+\t\t\t}\n+\t\t\tif (o == null || getClass() != o.getClass()) {\n+\t\t\t\treturn false;\n+\t\t\t}\n+\t\t\tfinal VirtualChannelMapping that = (VirtualChannelMapping) o;\n+\t\t\treturn oldTaskInstances.equals(that.oldTaskInstances) &&\n+\t\t\t\tpartitionMappings.equals(that.partitionMappings);\n+\t\t}\n+\n+\t\tpublic int[] getOldTaskInstances(int defaultSubtask) {\n+\t\t\treturn oldTaskInstances.equals(NO_SUBTASKS) ?\n+\t\t\t\tnew int[] {defaultSubtask} :\n+\t\t\t\toldTaskInstances.stream().toArray();\n+\t\t}\n+\n+\t\tpublic PartitionMapping getPartitionMapping(int partitionIndex) {\n+\t\t\tif (partitionMappings.isEmpty()) {\n+\t\t\t\treturn NO_CHANNEL_MAPPING;\n+\t\t\t}\n+\t\t\treturn partitionMappings.get(partitionIndex);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic int hashCode() {\n+\t\t\treturn Objects.hash(oldTaskInstances, partitionMappings);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic String toString() {\n+\t\t\treturn \"VirtualChannelMapping{\" +\n+\t\t\t\t\"oldTaskInstances=\" + oldTaskInstances +\n+\t\t\t\t\", partitionMappings=\" + partitionMappings +\n+\t\t\t\t'}';\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Contains the fine-grain channel mappings that occur when a connected operator has been rescaled.\n+\t */\n+\tpublic static class PartitionMapping implements Serializable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9cbbcb24751268c0b5289b86606eb28baa1287eb"}, "originalPosition": 424}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIzOTU5OTMzOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/OperatorSubtaskState.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QxOTozNToxN1rOHs9o0g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQxNDo0MzowMVrOHtbN3w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkwOTI2Ng==", "bodyText": "Again, the choice of data structures isn't obvious. Why not Map<Int, Int>?\n(ditto oldToNewChannelIndexes)", "url": "https://github.com/apache/flink/pull/13735#discussion_r516909266", "createdAt": "2020-11-03T19:35:17Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/OperatorSubtaskState.java", "diffHunk": "@@ -327,4 +289,252 @@ public boolean hasState() {\n \t\t\t|| inputChannelState.hasState()\n \t\t\t|| resultSubpartitionState.hasState();\n \t}\n+\n+\tpublic static Builder builder() {\n+\t\treturn new Builder();\n+\t}\n+\n+\t/**\n+\t * The builder for a new {@link OperatorSubtaskState} which can be obtained by {@link #builder()}.\n+\t */\n+\tpublic static class Builder {\n+\t\tprivate StateObjectCollection<OperatorStateHandle> managedOperatorState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<OperatorStateHandle> rawOperatorState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<KeyedStateHandle> managedKeyedState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<KeyedStateHandle> rawKeyedState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<InputChannelStateHandle> inputChannelState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<ResultSubpartitionStateHandle> resultSubpartitionState = StateObjectCollection.empty();\n+\t\tprivate VirtualChannelMapping inputChannelMappings = VirtualChannelMapping.NO_MAPPING;\n+\t\tprivate VirtualChannelMapping outputChannelMappings = VirtualChannelMapping.NO_MAPPING;\n+\n+\t\tprivate Builder() {\n+\t\t}\n+\n+\t\tpublic Builder setManagedOperatorState(StateObjectCollection<OperatorStateHandle> managedOperatorState) {\n+\t\t\tthis.managedOperatorState = checkNotNull(managedOperatorState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setManagedOperatorState(OperatorStateHandle managedOperatorState) {\n+\t\t\treturn setManagedOperatorState(StateObjectCollection.singleton(checkNotNull(managedOperatorState)));\n+\t\t}\n+\n+\t\tpublic Builder setRawOperatorState(StateObjectCollection<OperatorStateHandle> rawOperatorState) {\n+\t\t\tthis.rawOperatorState = checkNotNull(rawOperatorState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setRawOperatorState(OperatorStateHandle rawOperatorState) {\n+\t\t\treturn setRawOperatorState(StateObjectCollection.singleton(checkNotNull(rawOperatorState)));\n+\t\t}\n+\n+\t\tpublic Builder setManagedKeyedState(StateObjectCollection<KeyedStateHandle> managedKeyedState) {\n+\t\t\tthis.managedKeyedState = checkNotNull(managedKeyedState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setManagedKeyedState(KeyedStateHandle managedKeyedState) {\n+\t\t\treturn setManagedKeyedState(StateObjectCollection.singleton(checkNotNull(managedKeyedState)));\n+\t\t}\n+\n+\t\tpublic Builder setRawKeyedState(StateObjectCollection<KeyedStateHandle> rawKeyedState) {\n+\t\t\tthis.rawKeyedState = checkNotNull(rawKeyedState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setRawKeyedState(KeyedStateHandle rawKeyedState) {\n+\t\t\treturn setRawKeyedState(StateObjectCollection.singleton(checkNotNull(rawKeyedState)));\n+\t\t}\n+\n+\t\tpublic Builder setInputChannelState(StateObjectCollection<InputChannelStateHandle> inputChannelState) {\n+\t\t\tthis.inputChannelState = checkNotNull(inputChannelState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setResultSubpartitionState(StateObjectCollection<ResultSubpartitionStateHandle> resultSubpartitionState) {\n+\t\t\tthis.resultSubpartitionState = checkNotNull(resultSubpartitionState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setInputChannelMappings(VirtualChannelMapping inputChannelMappings) {\n+\t\t\tthis.inputChannelMappings = checkNotNull(inputChannelMappings);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setOutputChannelMappings(VirtualChannelMapping outputChannelMappings) {\n+\t\t\tthis.outputChannelMappings = checkNotNull(outputChannelMappings);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic OperatorSubtaskState build() {\n+\t\t\treturn new OperatorSubtaskState(\n+\t\t\t\tmanagedOperatorState,\n+\t\t\t\trawOperatorState,\n+\t\t\t\tmanagedKeyedState,\n+\t\t\t\trawKeyedState,\n+\t\t\t\tinputChannelState,\n+\t\t\t\tresultSubpartitionState,\n+\t\t\t\tinputChannelMappings,\n+\t\t\t\toutputChannelMappings);\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Captures ambiguous mappings of old channels to new channels.\n+\t *\n+\t * <p>For inputs, this mapping implies the following:\n+\t * <li>\n+\t *     <ul>{@link #oldTaskInstances} is set when there is a rescale on this task potentially leading to different\n+\t *     key groups. Upstream task has a corresponding {@link #partitionMappings} where it sends data over\n+\t *     virtual channel while specifying the channel index in the VirtualChannelSelector. This subtask then\n+\t *     demultiplexes over the virtual subtask index.</ul>\n+\t *     <ul>{@link #partitionMappings} is set when there is a downscale of the upstream task. Upstream task has\n+\t *     a corresponding {@link #oldTaskInstances} where it sends data over virtual channel while specifying the\n+\t *     subtask index in the VirtualChannelSelector. This subtask then demultiplexes over channel indexes.</ul>\n+\t * </li>\n+\t *\n+\t * <p>For outputs, it's vice-versa. The information must be kept in sync but they are used in opposite ways for\n+\t * multiplexing/demultiplexing.\n+\t *\n+\t * <p>Note that in the common rescaling case both information is set and need to be simultaneously used. If the\n+\t * input subtask subsumes the state of 3 old subtasks and a channel corresponds to 2 old channels, then there are\n+\t * 6 virtual channels to be demultiplexed.\n+\t */\n+\tpublic static class VirtualChannelMapping implements Serializable {\n+\t\tpublic static final PartitionMapping NO_CHANNEL_MAPPING = new PartitionMapping(emptyList());\n+\t\tpublic static final List<PartitionMapping> NO_PARTITIONS = emptyList();\n+\t\tpublic static final BitSet NO_SUBTASKS = new BitSet();\n+\t\tpublic static final VirtualChannelMapping NO_MAPPING = new VirtualChannelMapping(NO_SUBTASKS, NO_PARTITIONS);\n+\n+\t\t/**\n+\t\t * Set when several operator instances are merged into one.\n+\t\t */\n+\t\tprivate final BitSet oldTaskInstances;\n+\n+\t\t/**\n+\t\t * Set when channels are merged because the connected operator has been rescaled.\n+\t\t */\n+\t\tprivate final List<PartitionMapping> partitionMappings;\n+\n+\t\tpublic VirtualChannelMapping(BitSet oldTaskInstances, List<PartitionMapping> partitionMappings) {\n+\t\t\tthis.oldTaskInstances = oldTaskInstances;\n+\t\t\tthis.partitionMappings = partitionMappings;\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic boolean equals(Object o) {\n+\t\t\tif (this == o) {\n+\t\t\t\treturn true;\n+\t\t\t}\n+\t\t\tif (o == null || getClass() != o.getClass()) {\n+\t\t\t\treturn false;\n+\t\t\t}\n+\t\t\tfinal VirtualChannelMapping that = (VirtualChannelMapping) o;\n+\t\t\treturn oldTaskInstances.equals(that.oldTaskInstances) &&\n+\t\t\t\tpartitionMappings.equals(that.partitionMappings);\n+\t\t}\n+\n+\t\tpublic int[] getOldTaskInstances(int defaultSubtask) {\n+\t\t\treturn oldTaskInstances.equals(NO_SUBTASKS) ?\n+\t\t\t\tnew int[] {defaultSubtask} :\n+\t\t\t\toldTaskInstances.stream().toArray();\n+\t\t}\n+\n+\t\tpublic PartitionMapping getPartitionMapping(int partitionIndex) {\n+\t\t\tif (partitionMappings.isEmpty()) {\n+\t\t\t\treturn NO_CHANNEL_MAPPING;\n+\t\t\t}\n+\t\t\treturn partitionMappings.get(partitionIndex);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic int hashCode() {\n+\t\t\treturn Objects.hash(oldTaskInstances, partitionMappings);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic String toString() {\n+\t\t\treturn \"VirtualChannelMapping{\" +\n+\t\t\t\t\"oldTaskInstances=\" + oldTaskInstances +\n+\t\t\t\t\", partitionMappings=\" + partitionMappings +\n+\t\t\t\t'}';\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Contains the fine-grain channel mappings that occur when a connected operator has been rescaled.\n+\t */\n+\tpublic static class PartitionMapping implements Serializable {\n+\n+\t\t/**\n+\t\t * For each new channel (=index), all old channels are set.\n+\t\t */\n+\t\tprivate final List<BitSet> newToOldChannelIndexes;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9cbbcb24751268c0b5289b86606eb28baa1287eb"}, "originalPosition": 429}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzM0ODk5NA==", "bodyText": "If we have consecutive indexes from 0..n, what's wrong with List<Set<Integer>>? (I got the BitSet part)\nbtw it would be Map<Int, Set<Int>>.", "url": "https://github.com/apache/flink/pull/13735#discussion_r517348994", "createdAt": "2020-11-04T13:40:07Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/OperatorSubtaskState.java", "diffHunk": "@@ -327,4 +289,252 @@ public boolean hasState() {\n \t\t\t|| inputChannelState.hasState()\n \t\t\t|| resultSubpartitionState.hasState();\n \t}\n+\n+\tpublic static Builder builder() {\n+\t\treturn new Builder();\n+\t}\n+\n+\t/**\n+\t * The builder for a new {@link OperatorSubtaskState} which can be obtained by {@link #builder()}.\n+\t */\n+\tpublic static class Builder {\n+\t\tprivate StateObjectCollection<OperatorStateHandle> managedOperatorState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<OperatorStateHandle> rawOperatorState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<KeyedStateHandle> managedKeyedState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<KeyedStateHandle> rawKeyedState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<InputChannelStateHandle> inputChannelState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<ResultSubpartitionStateHandle> resultSubpartitionState = StateObjectCollection.empty();\n+\t\tprivate VirtualChannelMapping inputChannelMappings = VirtualChannelMapping.NO_MAPPING;\n+\t\tprivate VirtualChannelMapping outputChannelMappings = VirtualChannelMapping.NO_MAPPING;\n+\n+\t\tprivate Builder() {\n+\t\t}\n+\n+\t\tpublic Builder setManagedOperatorState(StateObjectCollection<OperatorStateHandle> managedOperatorState) {\n+\t\t\tthis.managedOperatorState = checkNotNull(managedOperatorState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setManagedOperatorState(OperatorStateHandle managedOperatorState) {\n+\t\t\treturn setManagedOperatorState(StateObjectCollection.singleton(checkNotNull(managedOperatorState)));\n+\t\t}\n+\n+\t\tpublic Builder setRawOperatorState(StateObjectCollection<OperatorStateHandle> rawOperatorState) {\n+\t\t\tthis.rawOperatorState = checkNotNull(rawOperatorState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setRawOperatorState(OperatorStateHandle rawOperatorState) {\n+\t\t\treturn setRawOperatorState(StateObjectCollection.singleton(checkNotNull(rawOperatorState)));\n+\t\t}\n+\n+\t\tpublic Builder setManagedKeyedState(StateObjectCollection<KeyedStateHandle> managedKeyedState) {\n+\t\t\tthis.managedKeyedState = checkNotNull(managedKeyedState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setManagedKeyedState(KeyedStateHandle managedKeyedState) {\n+\t\t\treturn setManagedKeyedState(StateObjectCollection.singleton(checkNotNull(managedKeyedState)));\n+\t\t}\n+\n+\t\tpublic Builder setRawKeyedState(StateObjectCollection<KeyedStateHandle> rawKeyedState) {\n+\t\t\tthis.rawKeyedState = checkNotNull(rawKeyedState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setRawKeyedState(KeyedStateHandle rawKeyedState) {\n+\t\t\treturn setRawKeyedState(StateObjectCollection.singleton(checkNotNull(rawKeyedState)));\n+\t\t}\n+\n+\t\tpublic Builder setInputChannelState(StateObjectCollection<InputChannelStateHandle> inputChannelState) {\n+\t\t\tthis.inputChannelState = checkNotNull(inputChannelState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setResultSubpartitionState(StateObjectCollection<ResultSubpartitionStateHandle> resultSubpartitionState) {\n+\t\t\tthis.resultSubpartitionState = checkNotNull(resultSubpartitionState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setInputChannelMappings(VirtualChannelMapping inputChannelMappings) {\n+\t\t\tthis.inputChannelMappings = checkNotNull(inputChannelMappings);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setOutputChannelMappings(VirtualChannelMapping outputChannelMappings) {\n+\t\t\tthis.outputChannelMappings = checkNotNull(outputChannelMappings);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic OperatorSubtaskState build() {\n+\t\t\treturn new OperatorSubtaskState(\n+\t\t\t\tmanagedOperatorState,\n+\t\t\t\trawOperatorState,\n+\t\t\t\tmanagedKeyedState,\n+\t\t\t\trawKeyedState,\n+\t\t\t\tinputChannelState,\n+\t\t\t\tresultSubpartitionState,\n+\t\t\t\tinputChannelMappings,\n+\t\t\t\toutputChannelMappings);\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Captures ambiguous mappings of old channels to new channels.\n+\t *\n+\t * <p>For inputs, this mapping implies the following:\n+\t * <li>\n+\t *     <ul>{@link #oldTaskInstances} is set when there is a rescale on this task potentially leading to different\n+\t *     key groups. Upstream task has a corresponding {@link #partitionMappings} where it sends data over\n+\t *     virtual channel while specifying the channel index in the VirtualChannelSelector. This subtask then\n+\t *     demultiplexes over the virtual subtask index.</ul>\n+\t *     <ul>{@link #partitionMappings} is set when there is a downscale of the upstream task. Upstream task has\n+\t *     a corresponding {@link #oldTaskInstances} where it sends data over virtual channel while specifying the\n+\t *     subtask index in the VirtualChannelSelector. This subtask then demultiplexes over channel indexes.</ul>\n+\t * </li>\n+\t *\n+\t * <p>For outputs, it's vice-versa. The information must be kept in sync but they are used in opposite ways for\n+\t * multiplexing/demultiplexing.\n+\t *\n+\t * <p>Note that in the common rescaling case both information is set and need to be simultaneously used. If the\n+\t * input subtask subsumes the state of 3 old subtasks and a channel corresponds to 2 old channels, then there are\n+\t * 6 virtual channels to be demultiplexed.\n+\t */\n+\tpublic static class VirtualChannelMapping implements Serializable {\n+\t\tpublic static final PartitionMapping NO_CHANNEL_MAPPING = new PartitionMapping(emptyList());\n+\t\tpublic static final List<PartitionMapping> NO_PARTITIONS = emptyList();\n+\t\tpublic static final BitSet NO_SUBTASKS = new BitSet();\n+\t\tpublic static final VirtualChannelMapping NO_MAPPING = new VirtualChannelMapping(NO_SUBTASKS, NO_PARTITIONS);\n+\n+\t\t/**\n+\t\t * Set when several operator instances are merged into one.\n+\t\t */\n+\t\tprivate final BitSet oldTaskInstances;\n+\n+\t\t/**\n+\t\t * Set when channels are merged because the connected operator has been rescaled.\n+\t\t */\n+\t\tprivate final List<PartitionMapping> partitionMappings;\n+\n+\t\tpublic VirtualChannelMapping(BitSet oldTaskInstances, List<PartitionMapping> partitionMappings) {\n+\t\t\tthis.oldTaskInstances = oldTaskInstances;\n+\t\t\tthis.partitionMappings = partitionMappings;\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic boolean equals(Object o) {\n+\t\t\tif (this == o) {\n+\t\t\t\treturn true;\n+\t\t\t}\n+\t\t\tif (o == null || getClass() != o.getClass()) {\n+\t\t\t\treturn false;\n+\t\t\t}\n+\t\t\tfinal VirtualChannelMapping that = (VirtualChannelMapping) o;\n+\t\t\treturn oldTaskInstances.equals(that.oldTaskInstances) &&\n+\t\t\t\tpartitionMappings.equals(that.partitionMappings);\n+\t\t}\n+\n+\t\tpublic int[] getOldTaskInstances(int defaultSubtask) {\n+\t\t\treturn oldTaskInstances.equals(NO_SUBTASKS) ?\n+\t\t\t\tnew int[] {defaultSubtask} :\n+\t\t\t\toldTaskInstances.stream().toArray();\n+\t\t}\n+\n+\t\tpublic PartitionMapping getPartitionMapping(int partitionIndex) {\n+\t\t\tif (partitionMappings.isEmpty()) {\n+\t\t\t\treturn NO_CHANNEL_MAPPING;\n+\t\t\t}\n+\t\t\treturn partitionMappings.get(partitionIndex);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic int hashCode() {\n+\t\t\treturn Objects.hash(oldTaskInstances, partitionMappings);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic String toString() {\n+\t\t\treturn \"VirtualChannelMapping{\" +\n+\t\t\t\t\"oldTaskInstances=\" + oldTaskInstances +\n+\t\t\t\t\", partitionMappings=\" + partitionMappings +\n+\t\t\t\t'}';\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Contains the fine-grain channel mappings that occur when a connected operator has been rescaled.\n+\t */\n+\tpublic static class PartitionMapping implements Serializable {\n+\n+\t\t/**\n+\t\t * For each new channel (=index), all old channels are set.\n+\t\t */\n+\t\tprivate final List<BitSet> newToOldChannelIndexes;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkwOTI2Ng=="}, "originalCommit": {"oid": "9cbbcb24751268c0b5289b86606eb28baa1287eb"}, "originalPosition": 429}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzM5Mzg4Nw==", "bodyText": "Nothing wrong performance-wise, but Map<Int, ...> just better captures the purpose:\nnewToOldChannelIndexes.get(newChannelIndex)\n\nFor the list I'd assume some iteration.", "url": "https://github.com/apache/flink/pull/13735#discussion_r517393887", "createdAt": "2020-11-04T14:43:01Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/OperatorSubtaskState.java", "diffHunk": "@@ -327,4 +289,252 @@ public boolean hasState() {\n \t\t\t|| inputChannelState.hasState()\n \t\t\t|| resultSubpartitionState.hasState();\n \t}\n+\n+\tpublic static Builder builder() {\n+\t\treturn new Builder();\n+\t}\n+\n+\t/**\n+\t * The builder for a new {@link OperatorSubtaskState} which can be obtained by {@link #builder()}.\n+\t */\n+\tpublic static class Builder {\n+\t\tprivate StateObjectCollection<OperatorStateHandle> managedOperatorState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<OperatorStateHandle> rawOperatorState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<KeyedStateHandle> managedKeyedState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<KeyedStateHandle> rawKeyedState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<InputChannelStateHandle> inputChannelState = StateObjectCollection.empty();\n+\t\tprivate StateObjectCollection<ResultSubpartitionStateHandle> resultSubpartitionState = StateObjectCollection.empty();\n+\t\tprivate VirtualChannelMapping inputChannelMappings = VirtualChannelMapping.NO_MAPPING;\n+\t\tprivate VirtualChannelMapping outputChannelMappings = VirtualChannelMapping.NO_MAPPING;\n+\n+\t\tprivate Builder() {\n+\t\t}\n+\n+\t\tpublic Builder setManagedOperatorState(StateObjectCollection<OperatorStateHandle> managedOperatorState) {\n+\t\t\tthis.managedOperatorState = checkNotNull(managedOperatorState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setManagedOperatorState(OperatorStateHandle managedOperatorState) {\n+\t\t\treturn setManagedOperatorState(StateObjectCollection.singleton(checkNotNull(managedOperatorState)));\n+\t\t}\n+\n+\t\tpublic Builder setRawOperatorState(StateObjectCollection<OperatorStateHandle> rawOperatorState) {\n+\t\t\tthis.rawOperatorState = checkNotNull(rawOperatorState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setRawOperatorState(OperatorStateHandle rawOperatorState) {\n+\t\t\treturn setRawOperatorState(StateObjectCollection.singleton(checkNotNull(rawOperatorState)));\n+\t\t}\n+\n+\t\tpublic Builder setManagedKeyedState(StateObjectCollection<KeyedStateHandle> managedKeyedState) {\n+\t\t\tthis.managedKeyedState = checkNotNull(managedKeyedState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setManagedKeyedState(KeyedStateHandle managedKeyedState) {\n+\t\t\treturn setManagedKeyedState(StateObjectCollection.singleton(checkNotNull(managedKeyedState)));\n+\t\t}\n+\n+\t\tpublic Builder setRawKeyedState(StateObjectCollection<KeyedStateHandle> rawKeyedState) {\n+\t\t\tthis.rawKeyedState = checkNotNull(rawKeyedState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setRawKeyedState(KeyedStateHandle rawKeyedState) {\n+\t\t\treturn setRawKeyedState(StateObjectCollection.singleton(checkNotNull(rawKeyedState)));\n+\t\t}\n+\n+\t\tpublic Builder setInputChannelState(StateObjectCollection<InputChannelStateHandle> inputChannelState) {\n+\t\t\tthis.inputChannelState = checkNotNull(inputChannelState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setResultSubpartitionState(StateObjectCollection<ResultSubpartitionStateHandle> resultSubpartitionState) {\n+\t\t\tthis.resultSubpartitionState = checkNotNull(resultSubpartitionState);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setInputChannelMappings(VirtualChannelMapping inputChannelMappings) {\n+\t\t\tthis.inputChannelMappings = checkNotNull(inputChannelMappings);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder setOutputChannelMappings(VirtualChannelMapping outputChannelMappings) {\n+\t\t\tthis.outputChannelMappings = checkNotNull(outputChannelMappings);\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic OperatorSubtaskState build() {\n+\t\t\treturn new OperatorSubtaskState(\n+\t\t\t\tmanagedOperatorState,\n+\t\t\t\trawOperatorState,\n+\t\t\t\tmanagedKeyedState,\n+\t\t\t\trawKeyedState,\n+\t\t\t\tinputChannelState,\n+\t\t\t\tresultSubpartitionState,\n+\t\t\t\tinputChannelMappings,\n+\t\t\t\toutputChannelMappings);\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Captures ambiguous mappings of old channels to new channels.\n+\t *\n+\t * <p>For inputs, this mapping implies the following:\n+\t * <li>\n+\t *     <ul>{@link #oldTaskInstances} is set when there is a rescale on this task potentially leading to different\n+\t *     key groups. Upstream task has a corresponding {@link #partitionMappings} where it sends data over\n+\t *     virtual channel while specifying the channel index in the VirtualChannelSelector. This subtask then\n+\t *     demultiplexes over the virtual subtask index.</ul>\n+\t *     <ul>{@link #partitionMappings} is set when there is a downscale of the upstream task. Upstream task has\n+\t *     a corresponding {@link #oldTaskInstances} where it sends data over virtual channel while specifying the\n+\t *     subtask index in the VirtualChannelSelector. This subtask then demultiplexes over channel indexes.</ul>\n+\t * </li>\n+\t *\n+\t * <p>For outputs, it's vice-versa. The information must be kept in sync but they are used in opposite ways for\n+\t * multiplexing/demultiplexing.\n+\t *\n+\t * <p>Note that in the common rescaling case both information is set and need to be simultaneously used. If the\n+\t * input subtask subsumes the state of 3 old subtasks and a channel corresponds to 2 old channels, then there are\n+\t * 6 virtual channels to be demultiplexed.\n+\t */\n+\tpublic static class VirtualChannelMapping implements Serializable {\n+\t\tpublic static final PartitionMapping NO_CHANNEL_MAPPING = new PartitionMapping(emptyList());\n+\t\tpublic static final List<PartitionMapping> NO_PARTITIONS = emptyList();\n+\t\tpublic static final BitSet NO_SUBTASKS = new BitSet();\n+\t\tpublic static final VirtualChannelMapping NO_MAPPING = new VirtualChannelMapping(NO_SUBTASKS, NO_PARTITIONS);\n+\n+\t\t/**\n+\t\t * Set when several operator instances are merged into one.\n+\t\t */\n+\t\tprivate final BitSet oldTaskInstances;\n+\n+\t\t/**\n+\t\t * Set when channels are merged because the connected operator has been rescaled.\n+\t\t */\n+\t\tprivate final List<PartitionMapping> partitionMappings;\n+\n+\t\tpublic VirtualChannelMapping(BitSet oldTaskInstances, List<PartitionMapping> partitionMappings) {\n+\t\t\tthis.oldTaskInstances = oldTaskInstances;\n+\t\t\tthis.partitionMappings = partitionMappings;\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic boolean equals(Object o) {\n+\t\t\tif (this == o) {\n+\t\t\t\treturn true;\n+\t\t\t}\n+\t\t\tif (o == null || getClass() != o.getClass()) {\n+\t\t\t\treturn false;\n+\t\t\t}\n+\t\t\tfinal VirtualChannelMapping that = (VirtualChannelMapping) o;\n+\t\t\treturn oldTaskInstances.equals(that.oldTaskInstances) &&\n+\t\t\t\tpartitionMappings.equals(that.partitionMappings);\n+\t\t}\n+\n+\t\tpublic int[] getOldTaskInstances(int defaultSubtask) {\n+\t\t\treturn oldTaskInstances.equals(NO_SUBTASKS) ?\n+\t\t\t\tnew int[] {defaultSubtask} :\n+\t\t\t\toldTaskInstances.stream().toArray();\n+\t\t}\n+\n+\t\tpublic PartitionMapping getPartitionMapping(int partitionIndex) {\n+\t\t\tif (partitionMappings.isEmpty()) {\n+\t\t\t\treturn NO_CHANNEL_MAPPING;\n+\t\t\t}\n+\t\t\treturn partitionMappings.get(partitionIndex);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic int hashCode() {\n+\t\t\treturn Objects.hash(oldTaskInstances, partitionMappings);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic String toString() {\n+\t\t\treturn \"VirtualChannelMapping{\" +\n+\t\t\t\t\"oldTaskInstances=\" + oldTaskInstances +\n+\t\t\t\t\", partitionMappings=\" + partitionMappings +\n+\t\t\t\t'}';\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Contains the fine-grain channel mappings that occur when a connected operator has been rescaled.\n+\t */\n+\tpublic static class PartitionMapping implements Serializable {\n+\n+\t\t/**\n+\t\t * For each new channel (=index), all old channels are set.\n+\t\t */\n+\t\tprivate final List<BitSet> newToOldChannelIndexes;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkwOTI2Ng=="}, "originalCommit": {"oid": "9cbbcb24751268c0b5289b86606eb28baa1287eb"}, "originalPosition": 429}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIzOTYyNDUzOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/StateAssignmentOperation.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QxOTo0MjozNFrOHs94Hw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQxMzoxODoyMlrOHtXp7w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkxMzE4Mw==", "bodyText": "IIUC, this is a cache, right?\nI doubt that we really need it: it's only used on re/starts and can save maybe hundreds of ms with DOP=1K. And without it, the code would be much simpler.\nWDYT?", "url": "https://github.com/apache/flink/pull/13735#discussion_r516913183", "createdAt": "2020-11-03T19:42:34Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/StateAssignmentOperation.java", "diffHunk": "@@ -67,29 +83,33 @@\n \tprivate final long restoreCheckpointId;\n \tprivate final boolean allowNonRestoredState;\n \n+\tprivate final Map<IntermediateResult, TaskStateAssignment> consumerAssignment = new HashMap<>();\n+\tprivate final Map<ChannelStateRescaler, ChannelRescalerRepartitioner<Object>> rescalerRepartitioners =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9cbbcb24751268c0b5289b86606eb28baa1287eb"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzMzNTUzNQ==", "bodyText": "rescalerRepartitioners would save much more as ChannelRescalerRepartitioner internally caches as well.\nBut I can take it out for now and we first measure before optimizing.", "url": "https://github.com/apache/flink/pull/13735#discussion_r517335535", "createdAt": "2020-11-04T13:18:22Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/StateAssignmentOperation.java", "diffHunk": "@@ -67,29 +83,33 @@\n \tprivate final long restoreCheckpointId;\n \tprivate final boolean allowNonRestoredState;\n \n+\tprivate final Map<IntermediateResult, TaskStateAssignment> consumerAssignment = new HashMap<>();\n+\tprivate final Map<ChannelStateRescaler, ChannelRescalerRepartitioner<Object>> rescalerRepartitioners =", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkxMzE4Mw=="}, "originalCommit": {"oid": "9cbbcb24751268c0b5289b86606eb28baa1287eb"}, "originalPosition": 47}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIzOTYzNDg5OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/StateAssignmentOperation.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QxOTo0NTozMFrOHs9-Wg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQxNDo0NDo0NVrOHtbS8A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkxNDc3OA==", "bodyText": "I wonder if this put can override existing assignment (e.g. with a UnionGate).\nIntermediateResult use as a key doesn't override equals/hashCode - is it intentional?", "url": "https://github.com/apache/flink/pull/13735#discussion_r516914778", "createdAt": "2020-11-03T19:45:30Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/StateAssignmentOperation.java", "diffHunk": "@@ -99,32 +119,40 @@ public void assignStates() {\n \t\t\t\t\t\toperatorID,\n \t\t\t\t\t\texecutionJobVertex.getParallelism(),\n \t\t\t\t\t\texecutionJobVertex.getMaxParallelism());\n-\t\t\t\t} else if (operatorState.getNumberCollectedStates() > 0) {\n-\t\t\t\t\tstatelessSubTasks = false;\n \t\t\t\t}\n-\t\t\t\toperatorStates.add(operatorState);\n+\t\t\t\toperatorStates.put(operatorIDPair.getGeneratedOperatorID(), operatorState);\n \t\t\t}\n-\t\t\tif (!statelessSubTasks) { // skip tasks where no operator has any state\n-\t\t\t\tassignAttemptState(executionJobVertex, operatorStates);\n+\n+\t\t\tfinal TaskStateAssignment stateAssignment = new TaskStateAssignment(executionJobVertex,\toperatorStates);\n+\t\t\tvertexAssignments.put(executionJobVertex, stateAssignment);\n+\t\t\tfor (final IntermediateResult producedDataSet : executionJobVertex.getInputs()) {\n+\t\t\t\tconsumerAssignment.put(producedDataSet, stateAssignment);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9cbbcb24751268c0b5289b86606eb28baa1287eb"}, "originalPosition": 100}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzMzNzU1Mg==", "bodyText": "UnionGate reads two or more different IntermediateResult. IntermediateResult translates directly into subpartition/gate.\nHowever, it's a good point that IntermediateResult doesn't override equals/hashCode. It currently works, because the JobGraph is a graph where the objects are connected, but I don't know if we can rely on the assumption. I'm switching to IntermediateDataSetID.", "url": "https://github.com/apache/flink/pull/13735#discussion_r517337552", "createdAt": "2020-11-04T13:21:40Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/StateAssignmentOperation.java", "diffHunk": "@@ -99,32 +119,40 @@ public void assignStates() {\n \t\t\t\t\t\toperatorID,\n \t\t\t\t\t\texecutionJobVertex.getParallelism(),\n \t\t\t\t\t\texecutionJobVertex.getMaxParallelism());\n-\t\t\t\t} else if (operatorState.getNumberCollectedStates() > 0) {\n-\t\t\t\t\tstatelessSubTasks = false;\n \t\t\t\t}\n-\t\t\t\toperatorStates.add(operatorState);\n+\t\t\t\toperatorStates.put(operatorIDPair.getGeneratedOperatorID(), operatorState);\n \t\t\t}\n-\t\t\tif (!statelessSubTasks) { // skip tasks where no operator has any state\n-\t\t\t\tassignAttemptState(executionJobVertex, operatorStates);\n+\n+\t\t\tfinal TaskStateAssignment stateAssignment = new TaskStateAssignment(executionJobVertex,\toperatorStates);\n+\t\t\tvertexAssignments.put(executionJobVertex, stateAssignment);\n+\t\t\tfor (final IntermediateResult producedDataSet : executionJobVertex.getInputs()) {\n+\t\t\t\tconsumerAssignment.put(producedDataSet, stateAssignment);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkxNDc3OA=="}, "originalCommit": {"oid": "9cbbcb24751268c0b5289b86606eb28baa1287eb"}, "originalPosition": 100}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzM5NTE4NA==", "bodyText": "I see, thanks for the clarification and update.", "url": "https://github.com/apache/flink/pull/13735#discussion_r517395184", "createdAt": "2020-11-04T14:44:45Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/StateAssignmentOperation.java", "diffHunk": "@@ -99,32 +119,40 @@ public void assignStates() {\n \t\t\t\t\t\toperatorID,\n \t\t\t\t\t\texecutionJobVertex.getParallelism(),\n \t\t\t\t\t\texecutionJobVertex.getMaxParallelism());\n-\t\t\t\t} else if (operatorState.getNumberCollectedStates() > 0) {\n-\t\t\t\t\tstatelessSubTasks = false;\n \t\t\t\t}\n-\t\t\t\toperatorStates.add(operatorState);\n+\t\t\t\toperatorStates.put(operatorIDPair.getGeneratedOperatorID(), operatorState);\n \t\t\t}\n-\t\t\tif (!statelessSubTasks) { // skip tasks where no operator has any state\n-\t\t\t\tassignAttemptState(executionJobVertex, operatorStates);\n+\n+\t\t\tfinal TaskStateAssignment stateAssignment = new TaskStateAssignment(executionJobVertex,\toperatorStates);\n+\t\t\tvertexAssignments.put(executionJobVertex, stateAssignment);\n+\t\t\tfor (final IntermediateResult producedDataSet : executionJobVertex.getInputs()) {\n+\t\t\t\tconsumerAssignment.put(producedDataSet, stateAssignment);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkxNDc3OA=="}, "originalCommit": {"oid": "9cbbcb24751268c0b5289b86606eb28baa1287eb"}, "originalPosition": 100}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIzOTY0NjM1OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/StateAssignmentOperation.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QxOTo0ODo1N1rOHs-FWA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQyMjo0NzowOFrOHuZo2Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkxNjU2OA==", "bodyText": "It would ease review if this class was introduced in a separate refactoring commit (though it's probably too difficult at this stage)\nCan we extract this class to a separate file?", "url": "https://github.com/apache/flink/pull/13735#discussion_r516916568", "createdAt": "2020-11-03T19:48:57Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/StateAssignmentOperation.java", "diffHunk": "@@ -620,18 +758,112 @@ private static void checkStateMappingCompleteness(\n \t\t\tchainOpParallelStates,\n \t\t\toldParallelism,\n \t\t\tnewParallelism);\n+\t}\n+\n+\tstatic class TaskStateAssignment {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9cbbcb24751268c0b5289b86606eb28baa1287eb"}, "originalPosition": 631}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzM3MjMzNA==", "bodyText": "Isn't it introduced by the two-pass refactoring commit?\nIt's a purely internal class of StateAssignmentOperation. Would it be easier because of side-by-side view or is there a different reason?", "url": "https://github.com/apache/flink/pull/13735#discussion_r517372334", "createdAt": "2020-11-04T14:13:40Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/StateAssignmentOperation.java", "diffHunk": "@@ -620,18 +758,112 @@ private static void checkStateMappingCompleteness(\n \t\t\tchainOpParallelStates,\n \t\t\toldParallelism,\n \t\t\tnewParallelism);\n+\t}\n+\n+\tstatic class TaskStateAssignment {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkxNjU2OA=="}, "originalCommit": {"oid": "9cbbcb24751268c0b5289b86606eb28baa1287eb"}, "originalPosition": 631}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzQwMzY3Mg==", "bodyText": "Yes, but IIUC TaskStateAssignment could be added before\nReviewing is one reason, but also in general why some helper code shouldn't reside in a separate file? Member lookup would be easier for example\n\nHowever, it's probably a matter of taste.", "url": "https://github.com/apache/flink/pull/13735#discussion_r517403672", "createdAt": "2020-11-04T14:56:12Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/StateAssignmentOperation.java", "diffHunk": "@@ -620,18 +758,112 @@ private static void checkStateMappingCompleteness(\n \t\t\tchainOpParallelStates,\n \t\t\toldParallelism,\n \t\t\tnewParallelism);\n+\t}\n+\n+\tstatic class TaskStateAssignment {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkxNjU2OA=="}, "originalCommit": {"oid": "9cbbcb24751268c0b5289b86606eb28baa1287eb"}, "originalPosition": 631}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcxNzUxMA==", "bodyText": "I split the two pass commit into two, but they are strongly related, so I'm not sure if the should exist on their own.", "url": "https://github.com/apache/flink/pull/13735#discussion_r517717510", "createdAt": "2020-11-05T00:51:20Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/StateAssignmentOperation.java", "diffHunk": "@@ -620,18 +758,112 @@ private static void checkStateMappingCompleteness(\n \t\t\tchainOpParallelStates,\n \t\t\toldParallelism,\n \t\t\tnewParallelism);\n+\t}\n+\n+\tstatic class TaskStateAssignment {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkxNjU2OA=="}, "originalCommit": {"oid": "9cbbcb24751268c0b5289b86606eb28baa1287eb"}, "originalPosition": 631}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQxNjYwMQ==", "bodyText": "Thanks a lot! To me, it's easier to understand changes now.", "url": "https://github.com/apache/flink/pull/13735#discussion_r518416601", "createdAt": "2020-11-05T22:47:08Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/StateAssignmentOperation.java", "diffHunk": "@@ -620,18 +758,112 @@ private static void checkStateMappingCompleteness(\n \t\t\tchainOpParallelStates,\n \t\t\toldParallelism,\n \t\t\tnewParallelism);\n+\t}\n+\n+\tstatic class TaskStateAssignment {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkxNjU2OA=="}, "originalCommit": {"oid": "9cbbcb24751268c0b5289b86606eb28baa1287eb"}, "originalPosition": 631}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIzOTY1OTI0OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/Execution.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QxOTo1MjozMlrOHs-NIw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQxMzoyMzo1NlrOHtX21g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkxODU2Mw==", "bodyText": "This doesn't compile (cannot find symbol getInputChannelMappings)\nProbably makes sense to extract testing methods (unless it's a temporary method)", "url": "https://github.com/apache/flink/pull/13735#discussion_r516918563", "createdAt": "2020-11-03T19:52:32Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/Execution.java", "diffHunk": "@@ -725,6 +727,15 @@ public void deploy() throws JobException {\n \t\t\tLOG.info(\"Deploying {} (attempt #{}) with attempt id {} to {} with allocation id {}\", vertex.getTaskNameWithSubtaskIndex(),\n \t\t\t\tattemptNumber, vertex.getCurrentExecutionAttempt().getAttemptId(), getAssignedResourceLocation(), slot.getAllocationId());\n \n+\t\t\tif (taskRestore != null) {\n+\t\t\t\tcheckState(taskRestore.getTaskStateSnapshot().getSubtaskStateMappings().stream().allMatch(entry ->\n+\t\t\t\t\tentry.getValue().getInputChannelMappings().stream()\n+\t\t\t\t\t\t.allMatch(mapping -> mapping.equals(OperatorSubtaskState.VirtualChannelMapping.NO_MAPPING)) &&\n+\t\t\t\t\t\tentry.getValue().getOutputChannelMappings().stream()\n+\t\t\t\t\t\t\t.allMatch(mapping -> mapping.equals(OperatorSubtaskState.VirtualChannelMapping.NO_MAPPING))\n+\t\t\t\t), \"Rescaling from unaligned checkpoint is not yet supported.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9cbbcb24751268c0b5289b86606eb28baa1287eb"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzMzODgzOA==", "bodyText": "This is only temporary and could be avoided by having the second PR merged into the first PR. I needed a point to cancel while still allowing tests to run on the different pieces.", "url": "https://github.com/apache/flink/pull/13735#discussion_r517338838", "createdAt": "2020-11-04T13:23:56Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/Execution.java", "diffHunk": "@@ -725,6 +727,15 @@ public void deploy() throws JobException {\n \t\t\tLOG.info(\"Deploying {} (attempt #{}) with attempt id {} to {} with allocation id {}\", vertex.getTaskNameWithSubtaskIndex(),\n \t\t\t\tattemptNumber, vertex.getCurrentExecutionAttempt().getAttemptId(), getAssignedResourceLocation(), slot.getAllocationId());\n \n+\t\t\tif (taskRestore != null) {\n+\t\t\t\tcheckState(taskRestore.getTaskStateSnapshot().getSubtaskStateMappings().stream().allMatch(entry ->\n+\t\t\t\t\tentry.getValue().getInputChannelMappings().stream()\n+\t\t\t\t\t\t.allMatch(mapping -> mapping.equals(OperatorSubtaskState.VirtualChannelMapping.NO_MAPPING)) &&\n+\t\t\t\t\t\tentry.getValue().getOutputChannelMappings().stream()\n+\t\t\t\t\t\t\t.allMatch(mapping -> mapping.equals(OperatorSubtaskState.VirtualChannelMapping.NO_MAPPING))\n+\t\t\t\t), \"Rescaling from unaligned checkpoint is not yet supported.\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkxODU2Mw=="}, "originalCommit": {"oid": "9cbbcb24751268c0b5289b86606eb28baa1287eb"}, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIzOTY5MzIwOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/state/AbstractChannelStateHandle.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QyMDowMjowOVrOHs-hzw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQxNToxNzoyMFrOHuIHnA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkyMzg1NQ==", "bodyText": "You probably should serialize this field and add it to the equals/hashCode.", "url": "https://github.com/apache/flink/pull/13735#discussion_r516923855", "createdAt": "2020-11-03T20:02:09Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/state/AbstractChannelStateHandle.java", "diffHunk": "@@ -46,6 +46,11 @@\n \tprivate final List<Long> offsets;\n \tprivate final long size;\n \n+\t/**\n+\t * The original subtask index before rescaling recovery.\n+\t */\n+\tprivate int originalSubtaskIndex;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9cbbcb24751268c0b5289b86606eb28baa1287eb"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzM0MDE2OQ==", "bodyText": "It is serialized when transferring the OperatorSubtaskState through Serializable. It's currently not needed in the checkpoints (as the information can be easily inferred). Is it still necessary from your perspective?\nI'd add it to equals/hashCode anyways.", "url": "https://github.com/apache/flink/pull/13735#discussion_r517340169", "createdAt": "2020-11-04T13:26:04Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/state/AbstractChannelStateHandle.java", "diffHunk": "@@ -46,6 +46,11 @@\n \tprivate final List<Long> offsets;\n \tprivate final long size;\n \n+\t/**\n+\t * The original subtask index before rescaling recovery.\n+\t */\n+\tprivate int originalSubtaskIndex;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkyMzg1NQ=="}, "originalCommit": {"oid": "9cbbcb24751268c0b5289b86606eb28baa1287eb"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzQwNjc0Nw==", "bodyText": "That means that after recovery it's not valid until explicitly set, right?\nI think it's quite error-prone. I'd at least document this behavior and mark it deprecated to give a warning.", "url": "https://github.com/apache/flink/pull/13735#discussion_r517406747", "createdAt": "2020-11-04T15:00:05Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/state/AbstractChannelStateHandle.java", "diffHunk": "@@ -46,6 +46,11 @@\n \tprivate final List<Long> offsets;\n \tprivate final long size;\n \n+\t/**\n+\t * The original subtask index before rescaling recovery.\n+\t */\n+\tprivate int originalSubtaskIndex;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkyMzg1NQ=="}, "originalCommit": {"oid": "9cbbcb24751268c0b5289b86606eb28baa1287eb"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODEyOTU2NA==", "bodyText": "I made it part of the handle and it's fully serialized now. It's renamed to subtaskIndex.", "url": "https://github.com/apache/flink/pull/13735#discussion_r518129564", "createdAt": "2020-11-05T15:17:20Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/state/AbstractChannelStateHandle.java", "diffHunk": "@@ -46,6 +46,11 @@\n \tprivate final List<Long> offsets;\n \tprivate final long size;\n \n+\t/**\n+\t * The original subtask index before rescaling recovery.\n+\t */\n+\tprivate int originalSubtaskIndex;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkyMzg1NQ=="}, "originalCommit": {"oid": "9cbbcb24751268c0b5289b86606eb28baa1287eb"}, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIzOTcwNjE4OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/partitioner/ForwardPartitioner.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QyMDowNTo1NVrOHs-pcA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQxNToxMDoxNFrOHtcdGg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkyNTgwOA==", "bodyText": "Why isn't channel state distributed to the same subtask as before (or 1st if out of range)?\n(ditto upstream)\nShouldn't recovered buffers sent from the upstream match what is on the downstream?", "url": "https://github.com/apache/flink/pull/13735#discussion_r516925808", "createdAt": "2020-11-03T20:05:55Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/partitioner/ForwardPartitioner.java", "diffHunk": "@@ -43,4 +44,14 @@ public int selectChannel(SerializationDelegate<StreamRecord<T>> record) {\n \tpublic String toString() {\n \t\treturn \"FORWARD\";\n \t}\n+\n+\t@Override\n+\tpublic ChannelStateRescaler getUpstreamChannelStateRescaler() {\n+\t\treturn ChannelStateRescaler.FIRST_CHANNEL;\n+\t}\n+\n+\t@Override\n+\tpublic ChannelStateRescaler getDownstreamChannelStateRescaler() {\n+\t\treturn ChannelStateRescaler.ROUND_ROBIN;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9cbbcb24751268c0b5289b86606eb28baa1287eb"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzMzMjY2NA==", "bodyText": "You are right that things should match. However, for channel state there are two dimensions on how to scale: on subtask-level and on channel-level. If you think of a keyed exchange, a rescale on downstream means that the key ranges are changing. A rescale on upstream just means that we need to redistribute the channel state to an arbitrary other subtask.\nThat's true for all exchanges except broadcast (where we need to discard extra state). I could also opt to just have a boolean shouldRedistributeUpstreamState instead of using ChannelStateRescaler. WDYT?", "url": "https://github.com/apache/flink/pull/13735#discussion_r517332664", "createdAt": "2020-11-04T13:13:21Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/partitioner/ForwardPartitioner.java", "diffHunk": "@@ -43,4 +44,14 @@ public int selectChannel(SerializationDelegate<StreamRecord<T>> record) {\n \tpublic String toString() {\n \t\treturn \"FORWARD\";\n \t}\n+\n+\t@Override\n+\tpublic ChannelStateRescaler getUpstreamChannelStateRescaler() {\n+\t\treturn ChannelStateRescaler.FIRST_CHANNEL;\n+\t}\n+\n+\t@Override\n+\tpublic ChannelStateRescaler getDownstreamChannelStateRescaler() {\n+\t\treturn ChannelStateRescaler.ROUND_ROBIN;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkyNTgwOA=="}, "originalCommit": {"oid": "9cbbcb24751268c0b5289b86606eb28baa1287eb"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzQxNDE3MA==", "bodyText": "I agree about using ROUND_ROBIN for the upstream.\nMy concern was mostly about the dowstream (which should be resolved by addressing the comment below).\nAs for boolean, I'd prefer ChannelStateRescaler as it's more flexible and consistent (with downstream).", "url": "https://github.com/apache/flink/pull/13735#discussion_r517414170", "createdAt": "2020-11-04T15:10:14Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/partitioner/ForwardPartitioner.java", "diffHunk": "@@ -43,4 +44,14 @@ public int selectChannel(SerializationDelegate<StreamRecord<T>> record) {\n \tpublic String toString() {\n \t\treturn \"FORWARD\";\n \t}\n+\n+\t@Override\n+\tpublic ChannelStateRescaler getUpstreamChannelStateRescaler() {\n+\t\treturn ChannelStateRescaler.FIRST_CHANNEL;\n+\t}\n+\n+\t@Override\n+\tpublic ChannelStateRescaler getDownstreamChannelStateRescaler() {\n+\t\treturn ChannelStateRescaler.ROUND_ROBIN;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkyNTgwOA=="}, "originalCommit": {"oid": "9cbbcb24751268c0b5289b86606eb28baa1287eb"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIzOTcyNzE1OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/StateAssignmentOperation.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QyMDoxMjowN1rOHs-1vQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQwOToyNDozNFrOHtPkZQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkyODk1Nw==", "bodyText": "How about storing a reference to the downstream/upstream TaskStateAssignment and get the mappings from there?\nI think it would be more readable.", "url": "https://github.com/apache/flink/pull/13735#discussion_r516928957", "createdAt": "2020-11-03T20:12:07Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/StateAssignmentOperation.java", "diffHunk": "@@ -620,18 +758,112 @@ private static void checkStateMappingCompleteness(\n \t\t\tchainOpParallelStates,\n \t\t\toldParallelism,\n \t\t\tnewParallelism);\n+\t}\n+\n+\tstatic class TaskStateAssignment {\n+\t\tfinal ExecutionJobVertex executionJobVertex;\n+\t\tfinal Map<OperatorID, OperatorState> oldState;\n+\t\tfinal boolean hasState;\n+\t\tfinal int newParallelism;\n+\t\tfinal OperatorID inputOperatorID;\n+\t\tfinal OperatorID outputOperatorID;\n+\n+\t\tfinal Map<OperatorInstanceID, List<OperatorStateHandle>> subManagedOperatorState;\n+\t\tfinal Map<OperatorInstanceID, List<OperatorStateHandle>> subRawOperatorState;\n+\t\tfinal Map<OperatorInstanceID, List<KeyedStateHandle>> subManagedKeyedState;\n+\t\tfinal Map<OperatorInstanceID, List<KeyedStateHandle>> subRawKeyedState;\n+\n+\t\tfinal Map<OperatorInstanceID, List<InputChannelStateHandle>> inputChannelStates;\n+\t\tfinal Map<OperatorInstanceID, List<ResultSubpartitionStateHandle>> resultSubpartitionStates;\n+\t\t/** The subpartitions mappings per partition set when the output operator for a partition was rescaled. */\n+\t\tList<BitSet> outputOperatorInstanceMappings = emptyList();\n+\t\t/** The input channel mappings per input set when the input operator for a gate was rescaled. */\n+\t\tList<BitSet> inputOperatorInstanceMappings = emptyList();\n+\t\t/** The subpartitions mappings of the upstream task per input set when its output operator was rescaled. */\n+\t\tfinal Map<Integer, List<BitSet>> upstreamVirtualChannels;\n+\t\t/** The input channel mappings of the downstream task per partition set when its input operator was rescaled. */\n+\t\tfinal Map<Integer, List<BitSet>> downStreamVirtualChannels;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9cbbcb24751268c0b5289b86606eb28baa1287eb"}, "originalPosition": 653}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzIwMzA0NQ==", "bodyText": "I like it!", "url": "https://github.com/apache/flink/pull/13735#discussion_r517203045", "createdAt": "2020-11-04T09:24:34Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/StateAssignmentOperation.java", "diffHunk": "@@ -620,18 +758,112 @@ private static void checkStateMappingCompleteness(\n \t\t\tchainOpParallelStates,\n \t\t\toldParallelism,\n \t\t\tnewParallelism);\n+\t}\n+\n+\tstatic class TaskStateAssignment {\n+\t\tfinal ExecutionJobVertex executionJobVertex;\n+\t\tfinal Map<OperatorID, OperatorState> oldState;\n+\t\tfinal boolean hasState;\n+\t\tfinal int newParallelism;\n+\t\tfinal OperatorID inputOperatorID;\n+\t\tfinal OperatorID outputOperatorID;\n+\n+\t\tfinal Map<OperatorInstanceID, List<OperatorStateHandle>> subManagedOperatorState;\n+\t\tfinal Map<OperatorInstanceID, List<OperatorStateHandle>> subRawOperatorState;\n+\t\tfinal Map<OperatorInstanceID, List<KeyedStateHandle>> subManagedKeyedState;\n+\t\tfinal Map<OperatorInstanceID, List<KeyedStateHandle>> subRawKeyedState;\n+\n+\t\tfinal Map<OperatorInstanceID, List<InputChannelStateHandle>> inputChannelStates;\n+\t\tfinal Map<OperatorInstanceID, List<ResultSubpartitionStateHandle>> resultSubpartitionStates;\n+\t\t/** The subpartitions mappings per partition set when the output operator for a partition was rescaled. */\n+\t\tList<BitSet> outputOperatorInstanceMappings = emptyList();\n+\t\t/** The input channel mappings per input set when the input operator for a gate was rescaled. */\n+\t\tList<BitSet> inputOperatorInstanceMappings = emptyList();\n+\t\t/** The subpartitions mappings of the upstream task per input set when its output operator was rescaled. */\n+\t\tfinal Map<Integer, List<BitSet>> upstreamVirtualChannels;\n+\t\t/** The input channel mappings of the downstream task per partition set when its input operator was rescaled. */\n+\t\tfinal Map<Integer, List<BitSet>> downStreamVirtualChannels;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkyODk1Nw=="}, "originalCommit": {"oid": "9cbbcb24751268c0b5289b86606eb28baa1287eb"}, "originalPosition": 653}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIzOTczNzkyOnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/partitioner/GlobalPartitioner.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QyMDoxNToyNlrOHs-8Sw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQwODo0MDoyNVrOHtN8xw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkzMDYzNQ==", "bodyText": "I'm probably misunderstanding it, but it seems it should be the opposite:\nupstream: ROUND_ROBING (or both FIRST)\ndownstream: FIRST_CHANNEL", "url": "https://github.com/apache/flink/pull/13735#discussion_r516930635", "createdAt": "2020-11-03T20:15:26Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/partitioner/GlobalPartitioner.java", "diffHunk": "@@ -40,6 +41,16 @@ public int selectChannel(SerializationDelegate<StreamRecord<T>> record) {\n \t\treturn this;\n \t}\n \n+\t@Override\n+\tpublic ChannelStateRescaler getUpstreamChannelStateRescaler() {\n+\t\treturn ChannelStateRescaler.FIRST_CHANNEL;\n+\t}\n+\n+\t@Override\n+\tpublic ChannelStateRescaler getDownstreamChannelStateRescaler() {\n+\t\treturn ChannelStateRescaler.ROUND_ROBIN;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9cbbcb24751268c0b5289b86606eb28baa1287eb"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzE3NjUxOQ==", "bodyText": "Yes changed that (see comment below). On upstream it should be almost always round robin (broadcasting partitioner is the only exception where we drop extra state).", "url": "https://github.com/apache/flink/pull/13735#discussion_r517176519", "createdAt": "2020-11-04T08:40:25Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/partitioner/GlobalPartitioner.java", "diffHunk": "@@ -40,6 +41,16 @@ public int selectChannel(SerializationDelegate<StreamRecord<T>> record) {\n \t\treturn this;\n \t}\n \n+\t@Override\n+\tpublic ChannelStateRescaler getUpstreamChannelStateRescaler() {\n+\t\treturn ChannelStateRescaler.FIRST_CHANNEL;\n+\t}\n+\n+\t@Override\n+\tpublic ChannelStateRescaler getDownstreamChannelStateRescaler() {\n+\t\treturn ChannelStateRescaler.ROUND_ROBIN;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkzMDYzNQ=="}, "originalCommit": {"oid": "9cbbcb24751268c0b5289b86606eb28baa1287eb"}, "originalPosition": 19}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIzOTc1MDIyOnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/graph/StreamingJobGraphGenerator.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QyMDoxOTozNFrOHs_D1g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQxNToxMjo0NFrOHtcjyA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkzMjU2Ng==", "bodyText": "OK now I see why the Rescalers used seemed inverted to me :)\nSo why is it inverted here? (maybe add a comment?)", "url": "https://github.com/apache/flink/pull/13735#discussion_r516932566", "createdAt": "2020-11-03T20:19:34Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/graph/StreamingJobGraphGenerator.java", "diffHunk": "@@ -692,6 +692,8 @@ private void connect(Integer headOfChain, StreamEdge edge) {\n \t\t}\n \t\t// set strategy name so that web interface can show it.\n \t\tjobEdge.setShipStrategyName(partitioner.toString());\n+\t\tjobEdge.setDownstreamChannelStateRescaler(partitioner.getUpstreamChannelStateRescaler());\n+\t\tjobEdge.setUpstreamChannelStateRescaler(partitioner.getDownstreamChannelStateRescaler());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9cbbcb24751268c0b5289b86606eb28baa1287eb"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzE3NjEwNg==", "bodyText": "There is no good reason except me screwing up. I did a couple of renamings prior to republishing PR and apparently renamed things asymetrically. I adjusted it (so upstream is now set to upstream).\nSorry for the confusion and good catch.", "url": "https://github.com/apache/flink/pull/13735#discussion_r517176106", "createdAt": "2020-11-04T08:39:42Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/graph/StreamingJobGraphGenerator.java", "diffHunk": "@@ -692,6 +692,8 @@ private void connect(Integer headOfChain, StreamEdge edge) {\n \t\t}\n \t\t// set strategy name so that web interface can show it.\n \t\tjobEdge.setShipStrategyName(partitioner.toString());\n+\t\tjobEdge.setDownstreamChannelStateRescaler(partitioner.getUpstreamChannelStateRescaler());\n+\t\tjobEdge.setUpstreamChannelStateRescaler(partitioner.getDownstreamChannelStateRescaler());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkzMjU2Ng=="}, "originalCommit": {"oid": "9cbbcb24751268c0b5289b86606eb28baa1287eb"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzQxNTg4MA==", "bodyText": "No worries, thanks for updating.", "url": "https://github.com/apache/flink/pull/13735#discussion_r517415880", "createdAt": "2020-11-04T15:12:44Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/graph/StreamingJobGraphGenerator.java", "diffHunk": "@@ -692,6 +692,8 @@ private void connect(Integer headOfChain, StreamEdge edge) {\n \t\t}\n \t\t// set strategy name so that web interface can show it.\n \t\tjobEdge.setShipStrategyName(partitioner.toString());\n+\t\tjobEdge.setDownstreamChannelStateRescaler(partitioner.getUpstreamChannelStateRescaler());\n+\t\tjobEdge.setUpstreamChannelStateRescaler(partitioner.getDownstreamChannelStateRescaler());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkzMjU2Ng=="}, "originalCommit": {"oid": "9cbbcb24751268c0b5289b86606eb28baa1287eb"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI0NjQ1MTc0OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/partitioner/CustomPartitionerWrapper.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQxMTowMzozNVrOHt-LYw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQyMjo0OTozOVrOHuZsvw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzk2NjY5MQ==", "bodyText": "This will not distribute state to the newer tasks in case of up-scaling, right?\nI think it can cause problems if the user-supplied partitioner relies on the new DOP.\nOTH, if not supported officially, we can leave it as it.\nWDYT?", "url": "https://github.com/apache/flink/pull/13735#discussion_r517966691", "createdAt": "2020-11-05T11:03:35Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/partitioner/CustomPartitionerWrapper.java", "diffHunk": "@@ -55,6 +56,14 @@ public int selectChannel(SerializationDelegate<StreamRecord<T>> record) {\n \t\treturn partitioner.partition(key, numberOfChannels);\n \t}\n \n+\t@Override\n+\tpublic ChannelStateRescaler getDownstreamChannelStateRescaler() {\n+\t\t// fully rely on filtering downstream\n+\t\t// note that custom partitioners are not officially supported - the user has to force rescaling\n+\t\t// in that case, we assume that the custom partitioner is deterministic\n+\t\treturn ChannelStateRescaler.BROADCAST;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bfd138a5fda6a4eeb4544cc88f9e5660063ab084"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODAzMzEzNw==", "bodyText": "BROADCAST would replicate each channel state to each subtask (very costly) including all new states. All superfluous replicas are filtered out downstream by the partitioner.\nNote that I will extend your check for cyclic graphs to customer partitioners for disabling UC. So the user has to force it to make it work. However, I do not see a reason to then fail on the second level again.", "url": "https://github.com/apache/flink/pull/13735#discussion_r518033137", "createdAt": "2020-11-05T13:02:01Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/partitioner/CustomPartitionerWrapper.java", "diffHunk": "@@ -55,6 +56,14 @@ public int selectChannel(SerializationDelegate<StreamRecord<T>> record) {\n \t\treturn partitioner.partition(key, numberOfChannels);\n \t}\n \n+\t@Override\n+\tpublic ChannelStateRescaler getDownstreamChannelStateRescaler() {\n+\t\t// fully rely on filtering downstream\n+\t\t// note that custom partitioners are not officially supported - the user has to force rescaling\n+\t\t// in that case, we assume that the custom partitioner is deterministic\n+\t\treturn ChannelStateRescaler.BROADCAST;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzk2NjY5MQ=="}, "originalCommit": {"oid": "bfd138a5fda6a4eeb4544cc88f9e5660063ab084"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQxNzU5OQ==", "bodyText": "Yes, you are right.", "url": "https://github.com/apache/flink/pull/13735#discussion_r518417599", "createdAt": "2020-11-05T22:49:39Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/partitioner/CustomPartitionerWrapper.java", "diffHunk": "@@ -55,6 +56,14 @@ public int selectChannel(SerializationDelegate<StreamRecord<T>> record) {\n \t\treturn partitioner.partition(key, numberOfChannels);\n \t}\n \n+\t@Override\n+\tpublic ChannelStateRescaler getDownstreamChannelStateRescaler() {\n+\t\t// fully rely on filtering downstream\n+\t\t// note that custom partitioners are not officially supported - the user has to force rescaling\n+\t\t// in that case, we assume that the custom partitioner is deterministic\n+\t\treturn ChannelStateRescaler.BROADCAST;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzk2NjY5MQ=="}, "originalCommit": {"oid": "bfd138a5fda6a4eeb4544cc88f9e5660063ab084"}, "originalPosition": 17}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI0NjQ5NzE0OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/partitioner/ForwardPartitioner.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQxMToxNjowNVrOHt-m4g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQyMzoxODoxMFrOHuaYGg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzk3MzczMA==", "bodyText": "Is FIRST_CHANNEL here (i.e. during the assignment) the same as in selectChannel (i.e. during sending the data)?\nIn other words, I think this will put all InputChannel state into a single subtask, while it should go to the same subtasks as before the rescaling.\nWDYT?", "url": "https://github.com/apache/flink/pull/13735#discussion_r517973730", "createdAt": "2020-11-05T11:16:05Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/partitioner/ForwardPartitioner.java", "diffHunk": "@@ -43,4 +44,9 @@ public int selectChannel(SerializationDelegate<StreamRecord<T>> record) {\n \tpublic String toString() {\n \t\treturn \"FORWARD\";\n \t}\n+\n+\t@Override\n+\tpublic ChannelStateRescaler getDownstreamChannelStateRescaler() {\n+\t\treturn ChannelStateRescaler.FIRST_CHANNEL;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bfd138a5fda6a4eeb4544cc88f9e5660063ab084"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODE3NTQwOA==", "bodyText": "Really good catch. I was confused by the selection process of ForwardPartitioner always selecting 0. But what we want is to have a round robin distribution (so assign same as before in case of upscaling), redistribute on downscale to avoid data loss.\nI used this find to rethink the nomenclature and actually everything that is related to ChannelStateRescaler is actually about subtask instance mapping, so I renamed to SubtaskStateMapper. Then it becomes immediately apparent that choosing the first task is plain wrong here.", "url": "https://github.com/apache/flink/pull/13735#discussion_r518175408", "createdAt": "2020-11-05T16:15:00Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/partitioner/ForwardPartitioner.java", "diffHunk": "@@ -43,4 +44,9 @@ public int selectChannel(SerializationDelegate<StreamRecord<T>> record) {\n \tpublic String toString() {\n \t\treturn \"FORWARD\";\n \t}\n+\n+\t@Override\n+\tpublic ChannelStateRescaler getDownstreamChannelStateRescaler() {\n+\t\treturn ChannelStateRescaler.FIRST_CHANNEL;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzk3MzczMA=="}, "originalCommit": {"oid": "bfd138a5fda6a4eeb4544cc88f9e5660063ab084"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQyODY5OA==", "bodyText": "Yes, ROUND_ROBIN makes sense here and the new naming looks good!", "url": "https://github.com/apache/flink/pull/13735#discussion_r518428698", "createdAt": "2020-11-05T23:18:10Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/partitioner/ForwardPartitioner.java", "diffHunk": "@@ -43,4 +44,9 @@ public int selectChannel(SerializationDelegate<StreamRecord<T>> record) {\n \tpublic String toString() {\n \t\treturn \"FORWARD\";\n \t}\n+\n+\t@Override\n+\tpublic ChannelStateRescaler getDownstreamChannelStateRescaler() {\n+\t\treturn ChannelStateRescaler.FIRST_CHANNEL;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzk3MzczMA=="}, "originalCommit": {"oid": "bfd138a5fda6a4eeb4544cc88f9e5660063ab084"}, "originalPosition": 15}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI0NjUwMzI4OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/OperatorSubtaskState.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQxMToxNzo1MlrOHt-qkQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNlQwNjo1NzoyMFrOHuiI8A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzk3NDY3Mw==", "bodyText": "I think this field needs to be (de)serialized by MetadataSerializer as other fields are.\n(ditto outputRescalingDescriptor)", "url": "https://github.com/apache/flink/pull/13735#discussion_r517974673", "createdAt": "2020-11-05T11:17:52Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/OperatorSubtaskState.java", "diffHunk": "@@ -64,81 +61,64 @@\n \t/**\n \t * Snapshot from the {@link org.apache.flink.runtime.state.OperatorStateBackend}.\n \t */\n-\t@Nonnull\n \tprivate final StateObjectCollection<OperatorStateHandle> managedOperatorState;\n \n \t/**\n \t * Snapshot written using {@link org.apache.flink.runtime.state.OperatorStateCheckpointOutputStream}.\n \t */\n-\t@Nonnull\n \tprivate final StateObjectCollection<OperatorStateHandle> rawOperatorState;\n \n \t/**\n \t * Snapshot from {@link org.apache.flink.runtime.state.KeyedStateBackend}.\n \t */\n-\t@Nonnull\n \tprivate final StateObjectCollection<KeyedStateHandle> managedKeyedState;\n \n \t/**\n \t * Snapshot written using {@link org.apache.flink.runtime.state.KeyedStateCheckpointOutputStream}.\n \t */\n-\t@Nonnull\n \tprivate final StateObjectCollection<KeyedStateHandle> rawKeyedState;\n \n-\t@Nonnull\n \tprivate final StateObjectCollection<InputChannelStateHandle> inputChannelState;\n \n-\t@Nonnull\n \tprivate final StateObjectCollection<ResultSubpartitionStateHandle> resultSubpartitionState;\n \n \t/**\n-\t * The state size. This is also part of the deserialized state handle.\n-\t * We store it here in order to not deserialize the state handle when\n-\t * gathering stats.\n+\t * The subpartitions mappings per partition set when the output operator for a partition was rescaled. The key is\n+\t * the partition id and the value contains all subtask indexes of the output operator before rescaling.\n \t */\n-\tprivate final long stateSize;\n+\tprivate final InflightDataRescalingDescriptor inputRescalingDescriptor;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bfd138a5fda6a4eeb4544cc88f9e5660063ab084"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODE3ODQ1Mw==", "bodyText": "Hm in the serialized form it would always be empty, so I'm not sure what the advantage is (it can only be filled when you know the post-scale parallelism, which you wouldn't know in a checkpoint).", "url": "https://github.com/apache/flink/pull/13735#discussion_r518178453", "createdAt": "2020-11-05T16:18:58Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/OperatorSubtaskState.java", "diffHunk": "@@ -64,81 +61,64 @@\n \t/**\n \t * Snapshot from the {@link org.apache.flink.runtime.state.OperatorStateBackend}.\n \t */\n-\t@Nonnull\n \tprivate final StateObjectCollection<OperatorStateHandle> managedOperatorState;\n \n \t/**\n \t * Snapshot written using {@link org.apache.flink.runtime.state.OperatorStateCheckpointOutputStream}.\n \t */\n-\t@Nonnull\n \tprivate final StateObjectCollection<OperatorStateHandle> rawOperatorState;\n \n \t/**\n \t * Snapshot from {@link org.apache.flink.runtime.state.KeyedStateBackend}.\n \t */\n-\t@Nonnull\n \tprivate final StateObjectCollection<KeyedStateHandle> managedKeyedState;\n \n \t/**\n \t * Snapshot written using {@link org.apache.flink.runtime.state.KeyedStateCheckpointOutputStream}.\n \t */\n-\t@Nonnull\n \tprivate final StateObjectCollection<KeyedStateHandle> rawKeyedState;\n \n-\t@Nonnull\n \tprivate final StateObjectCollection<InputChannelStateHandle> inputChannelState;\n \n-\t@Nonnull\n \tprivate final StateObjectCollection<ResultSubpartitionStateHandle> resultSubpartitionState;\n \n \t/**\n-\t * The state size. This is also part of the deserialized state handle.\n-\t * We store it here in order to not deserialize the state handle when\n-\t * gathering stats.\n+\t * The subpartitions mappings per partition set when the output operator for a partition was rescaled. The key is\n+\t * the partition id and the value contains all subtask indexes of the output operator before rescaling.\n \t */\n-\tprivate final long stateSize;\n+\tprivate final InflightDataRescalingDescriptor inputRescalingDescriptor;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzk3NDY3Mw=="}, "originalCommit": {"oid": "bfd138a5fda6a4eeb4544cc88f9e5660063ab084"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQyNTk4MQ==", "bodyText": "Yes, you are right (nit: maybe comment that it's only computed upon assignment?)", "url": "https://github.com/apache/flink/pull/13735#discussion_r518425981", "createdAt": "2020-11-05T23:11:04Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/OperatorSubtaskState.java", "diffHunk": "@@ -64,81 +61,64 @@\n \t/**\n \t * Snapshot from the {@link org.apache.flink.runtime.state.OperatorStateBackend}.\n \t */\n-\t@Nonnull\n \tprivate final StateObjectCollection<OperatorStateHandle> managedOperatorState;\n \n \t/**\n \t * Snapshot written using {@link org.apache.flink.runtime.state.OperatorStateCheckpointOutputStream}.\n \t */\n-\t@Nonnull\n \tprivate final StateObjectCollection<OperatorStateHandle> rawOperatorState;\n \n \t/**\n \t * Snapshot from {@link org.apache.flink.runtime.state.KeyedStateBackend}.\n \t */\n-\t@Nonnull\n \tprivate final StateObjectCollection<KeyedStateHandle> managedKeyedState;\n \n \t/**\n \t * Snapshot written using {@link org.apache.flink.runtime.state.KeyedStateCheckpointOutputStream}.\n \t */\n-\t@Nonnull\n \tprivate final StateObjectCollection<KeyedStateHandle> rawKeyedState;\n \n-\t@Nonnull\n \tprivate final StateObjectCollection<InputChannelStateHandle> inputChannelState;\n \n-\t@Nonnull\n \tprivate final StateObjectCollection<ResultSubpartitionStateHandle> resultSubpartitionState;\n \n \t/**\n-\t * The state size. This is also part of the deserialized state handle.\n-\t * We store it here in order to not deserialize the state handle when\n-\t * gathering stats.\n+\t * The subpartitions mappings per partition set when the output operator for a partition was rescaled. The key is\n+\t * the partition id and the value contains all subtask indexes of the output operator before rescaling.\n \t */\n-\tprivate final long stateSize;\n+\tprivate final InflightDataRescalingDescriptor inputRescalingDescriptor;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzk3NDY3Mw=="}, "originalCommit": {"oid": "bfd138a5fda6a4eeb4544cc88f9e5660063ab084"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODU1NTg4OA==", "bodyText": "Added a comment.\nNote that this field is only set by {@link StateAssignmentOperation} and will not be persisted in the checkpoint itself as it can only be calculated if the the post-recovery scale factor is known.", "url": "https://github.com/apache/flink/pull/13735#discussion_r518555888", "createdAt": "2020-11-06T06:57:20Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/OperatorSubtaskState.java", "diffHunk": "@@ -64,81 +61,64 @@\n \t/**\n \t * Snapshot from the {@link org.apache.flink.runtime.state.OperatorStateBackend}.\n \t */\n-\t@Nonnull\n \tprivate final StateObjectCollection<OperatorStateHandle> managedOperatorState;\n \n \t/**\n \t * Snapshot written using {@link org.apache.flink.runtime.state.OperatorStateCheckpointOutputStream}.\n \t */\n-\t@Nonnull\n \tprivate final StateObjectCollection<OperatorStateHandle> rawOperatorState;\n \n \t/**\n \t * Snapshot from {@link org.apache.flink.runtime.state.KeyedStateBackend}.\n \t */\n-\t@Nonnull\n \tprivate final StateObjectCollection<KeyedStateHandle> managedKeyedState;\n \n \t/**\n \t * Snapshot written using {@link org.apache.flink.runtime.state.KeyedStateCheckpointOutputStream}.\n \t */\n-\t@Nonnull\n \tprivate final StateObjectCollection<KeyedStateHandle> rawKeyedState;\n \n-\t@Nonnull\n \tprivate final StateObjectCollection<InputChannelStateHandle> inputChannelState;\n \n-\t@Nonnull\n \tprivate final StateObjectCollection<ResultSubpartitionStateHandle> resultSubpartitionState;\n \n \t/**\n-\t * The state size. This is also part of the deserialized state handle.\n-\t * We store it here in order to not deserialize the state handle when\n-\t * gathering stats.\n+\t * The subpartitions mappings per partition set when the output operator for a partition was rescaled. The key is\n+\t * the partition id and the value contains all subtask indexes of the output operator before rescaling.\n \t */\n-\tprivate final long stateSize;\n+\tprivate final InflightDataRescalingDescriptor inputRescalingDescriptor;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzk3NDY3Mw=="}, "originalCommit": {"oid": "bfd138a5fda6a4eeb4544cc88f9e5660063ab084"}, "originalPosition": 68}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI0NjUxMTAyOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/RescaledChannelsMapping.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQxMToxOTo1OVrOHt-vIA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQxNjoxOTo0MFrOHuLI1Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzk3NTg0MA==", "bodyText": "nit:\nThis field makes this class non-thread-safe, which is not obvious for a pre-computed mapping.\nSo I'd mark this class @NotThreadSafe.", "url": "https://github.com/apache/flink/pull/13735#discussion_r517975840", "createdAt": "2020-11-05T11:19:59Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/RescaledChannelsMapping.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint;\n+\n+import java.io.Serializable;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import static java.util.Collections.emptyMap;\n+\n+/**\n+ * Contains the fine-grain channel mappings that occur when a connected operator has been rescaled.\n+ */\n+public class RescaledChannelsMapping implements Serializable {\n+\tpublic static final RescaledChannelsMapping NO_CHANNEL_MAPPING = new RescaledChannelsMapping(emptyMap());\n+\n+\tprivate static final long serialVersionUID = -8719670050630674631L;\n+\n+\t/**\n+\t * For each new channel (=index), all old channels are set.\n+\t */\n+\tprivate final Map<Integer, Set<Integer>> newToOldChannelIndexes;\n+\n+\t/**\n+\t * For each old channel (=index), all new channels are set. Lazily calculated to keep {@link OperatorSubtaskState}\n+\t * small in terms of serialization cost.\n+\t */\n+\tprivate transient Map<Integer, Set<Integer>> oldToNewChannelIndexes;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bfd138a5fda6a4eeb4544cc88f9e5660063ab084"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODE3OTAyOQ==", "bodyText": "Actually I made it quasi-thread safe, where no fields are updated anymore (see your other suggestion). I refrain from doing defensive copies as it's purely internal.", "url": "https://github.com/apache/flink/pull/13735#discussion_r518179029", "createdAt": "2020-11-05T16:19:40Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/RescaledChannelsMapping.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint;\n+\n+import java.io.Serializable;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import static java.util.Collections.emptyMap;\n+\n+/**\n+ * Contains the fine-grain channel mappings that occur when a connected operator has been rescaled.\n+ */\n+public class RescaledChannelsMapping implements Serializable {\n+\tpublic static final RescaledChannelsMapping NO_CHANNEL_MAPPING = new RescaledChannelsMapping(emptyMap());\n+\n+\tprivate static final long serialVersionUID = -8719670050630674631L;\n+\n+\t/**\n+\t * For each new channel (=index), all old channels are set.\n+\t */\n+\tprivate final Map<Integer, Set<Integer>> newToOldChannelIndexes;\n+\n+\t/**\n+\t * For each old channel (=index), all new channels are set. Lazily calculated to keep {@link OperatorSubtaskState}\n+\t * small in terms of serialization cost.\n+\t */\n+\tprivate transient Map<Integer, Set<Integer>> oldToNewChannelIndexes;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzk3NTg0MA=="}, "originalCommit": {"oid": "bfd138a5fda6a4eeb4544cc88f9e5660063ab084"}, "originalPosition": 45}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI0NjUyMDY3OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/ChannelRescalerRepartitioner.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQxMToyMjo0NVrOHt-1RQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQxNTo0NDo0MVrOHuJhRw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzk3NzQxMw==", "bodyText": "nit:\nAfter removing the higher level cache, this field can also be computed eagerly think (as it will be used anyways if the is being object is constructed).", "url": "https://github.com/apache/flink/pull/13735#discussion_r517977413", "createdAt": "2020-11-05T11:22:45Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/ChannelRescalerRepartitioner.java", "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.api.writer.ChannelStateRescaler;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.IntStream;\n+\n+/**\n+ * A repartitioner that assigns the same channel state to multiple subtasks according to some mapping.\n+ *\n+ * <p>The replicated data will then be filtered before processing the record.\n+ *\n+ * <p>Note that channel mappings are cached for the same parallelism changes.\n+ */\n+public class ChannelRescalerRepartitioner<T> implements OperatorStateRepartitioner<T> {\n+\tprivate final ChannelStateRescaler channelStateRescaler;\n+\tprivate final Map<Tuple2<Integer, Integer>, Map<Integer, Set<Integer>>> newToOldMappingCache = new HashMap<>(2);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bfd138a5fda6a4eeb4544cc88f9e5660063ab084"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODE1MjUxOQ==", "bodyText": "You are right. I needed to adjust abstractions a bit (and I think it's more logical now):\n\ncreateNewToOldMapping is now part of ChannelStateRescaler (which is now named SubtaskStateMapper).\nChannelRescalerRepartitioner is renamed to MappingBasedRepartitioner. It's an pseudo-immutable class that simply applies the mapping to the state.", "url": "https://github.com/apache/flink/pull/13735#discussion_r518152519", "createdAt": "2020-11-05T15:44:41Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/ChannelRescalerRepartitioner.java", "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.api.writer.ChannelStateRescaler;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.IntStream;\n+\n+/**\n+ * A repartitioner that assigns the same channel state to multiple subtasks according to some mapping.\n+ *\n+ * <p>The replicated data will then be filtered before processing the record.\n+ *\n+ * <p>Note that channel mappings are cached for the same parallelism changes.\n+ */\n+public class ChannelRescalerRepartitioner<T> implements OperatorStateRepartitioner<T> {\n+\tprivate final ChannelStateRescaler channelStateRescaler;\n+\tprivate final Map<Tuple2<Integer, Integer>, Map<Integer, Set<Integer>>> newToOldMappingCache = new HashMap<>(2);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzk3NzQxMw=="}, "originalCommit": {"oid": "bfd138a5fda6a4eeb4544cc88f9e5660063ab084"}, "originalPosition": 43}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI0NzA1OTEwOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/ChannelRescalerRepartitioner.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQxMzo0Njo0M1rOHuD-xg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQyMzowNTozNVrOHuaFiA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA2MTc2Ng==", "bodyText": "(nit) I was a bit confused by this method. Maybe this version would be more readable:\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t\tfinal Map<Integer, Set<Integer>> newToOldMapping = getNewToOldMapping(oldParallelism, newParallelism);\n          \n          \n            \n            \t\treturn IntStream.range(0, newParallelism)\n          \n          \n            \n            \t\t\t.mapToObj(newIndex -> getOldState(previousParallelSubtaskStates, newToOldMapping.get(newIndex)))\n          \n          \n            \n            \t\t\t.collect(Collectors.toList());\n          \n          \n            \n            \t\treturn getNewToOldMapping(oldParallelism, newParallelism)\n          \n          \n            \n            \t\t\t.entrySet().stream()\n          \n          \n            \n            \t\t\t.sorted(Comparator.comparingInt(Map.Entry::getKey)).map(Map.Entry::getValue)\n          \n          \n            \n            \t\t\t.map(oldIndices -> getOldState(previousParallelSubtaskStates, oldIndices))\n          \n          \n            \n            \t\t\t.collect(Collectors.toList());", "url": "https://github.com/apache/flink/pull/13735#discussion_r518061766", "createdAt": "2020-11-05T13:46:43Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/ChannelRescalerRepartitioner.java", "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.api.writer.ChannelStateRescaler;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.IntStream;\n+\n+/**\n+ * A repartitioner that assigns the same channel state to multiple subtasks according to some mapping.\n+ *\n+ * <p>The replicated data will then be filtered before processing the record.\n+ *\n+ * <p>Note that channel mappings are cached for the same parallelism changes.\n+ */\n+public class ChannelRescalerRepartitioner<T> implements OperatorStateRepartitioner<T> {\n+\tprivate final ChannelStateRescaler channelStateRescaler;\n+\tprivate final Map<Tuple2<Integer, Integer>, Map<Integer, Set<Integer>>> newToOldMappingCache = new HashMap<>(2);\n+\n+\tpublic ChannelRescalerRepartitioner(ChannelStateRescaler channelStateRescaler) {\n+\t\tthis.channelStateRescaler = channelStateRescaler;\n+\t}\n+\n+\tprivate static <T> List<T> getOldState(List<List<T>> previousParallelSubtaskStates, Set<Integer> oldIndexes) {\n+\t\tswitch (oldIndexes.size()) {\n+\t\t\tcase 0:\n+\t\t\t\treturn Collections.emptyList();\n+\t\t\tcase 1:\n+\t\t\t\treturn previousParallelSubtaskStates.get(Iterables.getOnlyElement(oldIndexes));\n+\t\t\tdefault:\n+\t\t\t\treturn oldIndexes.stream()\n+\t\t\t\t\t.flatMap(oldIndex -> previousParallelSubtaskStates.get(oldIndex).stream())\n+\t\t\t\t\t.collect(Collectors.toList());\n+\t\t}\n+\t}\n+\n+\tprotected Map<Integer, Set<Integer>> createNewToOldMapping(int oldParallelism, int newParallelism) {\n+\t\treturn IntStream.range(0, newParallelism).boxed().\n+\t\t\tcollect(Collectors.toMap(\n+\t\t\t\tFunction.identity(),\n+\t\t\t\tchannelIndex -> channelStateRescaler.getOldChannels(\n+\t\t\t\t\tchannelIndex,\n+\t\t\t\t\toldParallelism,\n+\t\t\t\t\tnewParallelism)));\n+\t}\n+\n+\t@Override\n+\tpublic List<List<T>> repartitionState(\n+\t\t\tList<List<T>> previousParallelSubtaskStates,\n+\t\t\tint oldParallelism,\n+\t\t\tint newParallelism) {\n+\t\tfinal Map<Integer, Set<Integer>> newToOldMapping = getNewToOldMapping(oldParallelism, newParallelism);\n+\t\treturn IntStream.range(0, newParallelism)\n+\t\t\t.mapToObj(newIndex -> getOldState(previousParallelSubtaskStates, newToOldMapping.get(newIndex)))\n+\t\t\t.collect(Collectors.toList());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bfd138a5fda6a4eeb4544cc88f9e5660063ab084"}, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODE2Mzk4OA==", "bodyText": "It's good feedback if stuff is confusing. I'll offer an alternative that avoids using streams:\n\t\tList<List<T>> repartitioned = new ArrayList<>();\n\t\tfor (int newIndex = 0; newIndex < newParallelism; newIndex++) {\n\t\t\trepartitioned.add(getOldState(previousParallelSubtaskStates, newToOldSubtasksMapping.get(newIndex)));\n\t\t}\n\t\treturn repartitioned;", "url": "https://github.com/apache/flink/pull/13735#discussion_r518163988", "createdAt": "2020-11-05T15:59:28Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/ChannelRescalerRepartitioner.java", "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.api.writer.ChannelStateRescaler;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.IntStream;\n+\n+/**\n+ * A repartitioner that assigns the same channel state to multiple subtasks according to some mapping.\n+ *\n+ * <p>The replicated data will then be filtered before processing the record.\n+ *\n+ * <p>Note that channel mappings are cached for the same parallelism changes.\n+ */\n+public class ChannelRescalerRepartitioner<T> implements OperatorStateRepartitioner<T> {\n+\tprivate final ChannelStateRescaler channelStateRescaler;\n+\tprivate final Map<Tuple2<Integer, Integer>, Map<Integer, Set<Integer>>> newToOldMappingCache = new HashMap<>(2);\n+\n+\tpublic ChannelRescalerRepartitioner(ChannelStateRescaler channelStateRescaler) {\n+\t\tthis.channelStateRescaler = channelStateRescaler;\n+\t}\n+\n+\tprivate static <T> List<T> getOldState(List<List<T>> previousParallelSubtaskStates, Set<Integer> oldIndexes) {\n+\t\tswitch (oldIndexes.size()) {\n+\t\t\tcase 0:\n+\t\t\t\treturn Collections.emptyList();\n+\t\t\tcase 1:\n+\t\t\t\treturn previousParallelSubtaskStates.get(Iterables.getOnlyElement(oldIndexes));\n+\t\t\tdefault:\n+\t\t\t\treturn oldIndexes.stream()\n+\t\t\t\t\t.flatMap(oldIndex -> previousParallelSubtaskStates.get(oldIndex).stream())\n+\t\t\t\t\t.collect(Collectors.toList());\n+\t\t}\n+\t}\n+\n+\tprotected Map<Integer, Set<Integer>> createNewToOldMapping(int oldParallelism, int newParallelism) {\n+\t\treturn IntStream.range(0, newParallelism).boxed().\n+\t\t\tcollect(Collectors.toMap(\n+\t\t\t\tFunction.identity(),\n+\t\t\t\tchannelIndex -> channelStateRescaler.getOldChannels(\n+\t\t\t\t\tchannelIndex,\n+\t\t\t\t\toldParallelism,\n+\t\t\t\t\tnewParallelism)));\n+\t}\n+\n+\t@Override\n+\tpublic List<List<T>> repartitionState(\n+\t\t\tList<List<T>> previousParallelSubtaskStates,\n+\t\t\tint oldParallelism,\n+\t\t\tint newParallelism) {\n+\t\tfinal Map<Integer, Set<Integer>> newToOldMapping = getNewToOldMapping(oldParallelism, newParallelism);\n+\t\treturn IntStream.range(0, newParallelism)\n+\t\t\t.mapToObj(newIndex -> getOldState(previousParallelSubtaskStates, newToOldMapping.get(newIndex)))\n+\t\t\t.collect(Collectors.toList());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA2MTc2Ng=="}, "originalCommit": {"oid": "bfd138a5fda6a4eeb4544cc88f9e5660063ab084"}, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQyMzk0NA==", "bodyText": "Even better!", "url": "https://github.com/apache/flink/pull/13735#discussion_r518423944", "createdAt": "2020-11-05T23:05:35Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/ChannelRescalerRepartitioner.java", "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.api.writer.ChannelStateRescaler;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.IntStream;\n+\n+/**\n+ * A repartitioner that assigns the same channel state to multiple subtasks according to some mapping.\n+ *\n+ * <p>The replicated data will then be filtered before processing the record.\n+ *\n+ * <p>Note that channel mappings are cached for the same parallelism changes.\n+ */\n+public class ChannelRescalerRepartitioner<T> implements OperatorStateRepartitioner<T> {\n+\tprivate final ChannelStateRescaler channelStateRescaler;\n+\tprivate final Map<Tuple2<Integer, Integer>, Map<Integer, Set<Integer>>> newToOldMappingCache = new HashMap<>(2);\n+\n+\tpublic ChannelRescalerRepartitioner(ChannelStateRescaler channelStateRescaler) {\n+\t\tthis.channelStateRescaler = channelStateRescaler;\n+\t}\n+\n+\tprivate static <T> List<T> getOldState(List<List<T>> previousParallelSubtaskStates, Set<Integer> oldIndexes) {\n+\t\tswitch (oldIndexes.size()) {\n+\t\t\tcase 0:\n+\t\t\t\treturn Collections.emptyList();\n+\t\t\tcase 1:\n+\t\t\t\treturn previousParallelSubtaskStates.get(Iterables.getOnlyElement(oldIndexes));\n+\t\t\tdefault:\n+\t\t\t\treturn oldIndexes.stream()\n+\t\t\t\t\t.flatMap(oldIndex -> previousParallelSubtaskStates.get(oldIndex).stream())\n+\t\t\t\t\t.collect(Collectors.toList());\n+\t\t}\n+\t}\n+\n+\tprotected Map<Integer, Set<Integer>> createNewToOldMapping(int oldParallelism, int newParallelism) {\n+\t\treturn IntStream.range(0, newParallelism).boxed().\n+\t\t\tcollect(Collectors.toMap(\n+\t\t\t\tFunction.identity(),\n+\t\t\t\tchannelIndex -> channelStateRescaler.getOldChannels(\n+\t\t\t\t\tchannelIndex,\n+\t\t\t\t\toldParallelism,\n+\t\t\t\t\tnewParallelism)));\n+\t}\n+\n+\t@Override\n+\tpublic List<List<T>> repartitionState(\n+\t\t\tList<List<T>> previousParallelSubtaskStates,\n+\t\t\tint oldParallelism,\n+\t\t\tint newParallelism) {\n+\t\tfinal Map<Integer, Set<Integer>> newToOldMapping = getNewToOldMapping(oldParallelism, newParallelism);\n+\t\treturn IntStream.range(0, newParallelism)\n+\t\t\t.mapToObj(newIndex -> getOldState(previousParallelSubtaskStates, newToOldMapping.get(newIndex)))\n+\t\t\t.collect(Collectors.toList());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA2MTc2Ng=="}, "originalCommit": {"oid": "bfd138a5fda6a4eeb4544cc88f9e5660063ab084"}, "originalPosition": 80}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 70, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}