{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTEyMzYwMTg2", "number": 13845, "reviewThreads": {"totalCount": 25, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QxMDozODowOVrOE2V5bw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yNlQxMDoxNTo0MFrOFfDyig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI1NDE3MzI3OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QxMDozODowOVrOHvHNkg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QyMjo1MToxN1rOHvLQTA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2MzI4Mg==", "bodyText": "Here, selector.getSubtaskIndex() is expected to be this subtask old index, right? This is correct for the input channel state recovered on this subtask.\nBut, when the upstream sends its subpartition recovered data, it uses its own oldSubtaskIndex.", "url": "https://github.com/apache/flink/pull/13845#discussion_r519163282", "createdAt": "2020-11-07T10:38:09Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "diffHunk": "@@ -0,0 +1,402 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+/**\n+ * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n+ * non-recovery hotpath, this interface is not extending RecordDeserializer.\n+ */\n+interface Demultiplexer extends AutoCloseable {\n+\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n+\n+\tvoid setNextBuffer(Buffer buffer) throws IOException;\n+\n+\tvoid select(VirtualChannelSelector event);\n+\n+\t@Override\n+\tvoid close();\n+}\n+\n+class NoDataDemultiplexer implements Demultiplexer {\n+\tprivate final InputChannelInfo channelInfo;\n+\n+\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n+\t\tthis.channelInfo = channelInfo;\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void select(VirtualChannelSelector event) {\n+\t\tthrow getException();\n+\t}\n+\n+\tprivate IllegalStateException getException() {\n+\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t}\n+}\n+\n+/**\n+ * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n+ */\n+class DemultiplexParameters {\n+\tfinal IOManager ioManager;\n+\tfinal InflightDataRescalingDescriptor channelMapping;\n+\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n+\tfinal SerializationDelegate<StreamRecord> delegate;\n+\tfinal int numberOfChannels;\n+\tfinal int subtaskIndex;\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tDemultiplexParameters(\n+\t\t\tTypeSerializer<?> inputSerializer,\n+\t\t\tIOManager ioManager,\n+\t\t\tInflightDataRescalingDescriptor channelMapping,\n+\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n+\t\t\tint numberOfChannels,\n+\t\t\tint subtaskIndex) {\n+\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n+\t\tthis.ioManager = ioManager;\n+\t\tthis.channelMapping = channelMapping;\n+\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n+\t\tthis.numberOfChannels = numberOfChannels;\n+\t\tthis.subtaskIndex = subtaskIndex;\n+\t}\n+}\n+\n+/**\n+ * Demultiplexes buffers on subtask-level.\n+ *\n+ * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n+ * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n+ * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n+ *\n+ * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n+ * statuses of the (nested) virtual channels.\n+ */\n+class SubtaskDemultiplexer implements Demultiplexer {\n+\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n+\n+\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n+\n+\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n+\n+\tprivate VirtualChannelSelector currentSelector;\n+\n+\tprivate ChannelDemultiplexer selectedSubtask;\n+\n+\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n+\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n+\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n+\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n+\t\tselectedSubtask = defaultSelection.getValue();\n+\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n+\t\t\tselectedSubtask.selectedChannelIndex);\n+\n+\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n+\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tgetChannelSelectors().forEach(selector -> {\n+\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n+\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n+\t\t});\n+\t}\n+\n+\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n+\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);\n+\t}\n+\n+\tpublic void select(VirtualChannelSelector selector) {\n+\t\tcurrentSelector = selector;\n+\t\tselectedSubtask = demultiplexersForSubtasks.get(selector.getSubtaskIndex());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 173}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTIyOTUxNg==", "bodyText": "Yes that's mostly correct. That's why on subpartition recovery, the information subtask <=> subpartition index is swapped. Please note that I also renamed the fields of VirtualChannelSelector (inputSubtaskIndex and inputChannelIndex) to make it clearer.\n\t\t\t\t// channel selector is created from the downstream's point of view: the subtask of downstream = subpartition index of recovered buffer\n\t\t\t\tfinal VirtualChannelSelector channelSelector = new VirtualChannelSelector(subpartitionInfo.getSubPartitionIdx(), oldSubtaskIndex);\n\t\t\t\tchannel.add(EventSerializer.toBufferConsumer(channelSelector, false), Integer.MIN_VALUE);\n\nsubpartitionInfo.getSubPartitionIdx() is set as the inputSubtaskIndex and oldSubtaskIndex is inputChannelIndex.", "url": "https://github.com/apache/flink/pull/13845#discussion_r519229516", "createdAt": "2020-11-07T22:51:17Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "diffHunk": "@@ -0,0 +1,402 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+/**\n+ * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n+ * non-recovery hotpath, this interface is not extending RecordDeserializer.\n+ */\n+interface Demultiplexer extends AutoCloseable {\n+\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n+\n+\tvoid setNextBuffer(Buffer buffer) throws IOException;\n+\n+\tvoid select(VirtualChannelSelector event);\n+\n+\t@Override\n+\tvoid close();\n+}\n+\n+class NoDataDemultiplexer implements Demultiplexer {\n+\tprivate final InputChannelInfo channelInfo;\n+\n+\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n+\t\tthis.channelInfo = channelInfo;\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void select(VirtualChannelSelector event) {\n+\t\tthrow getException();\n+\t}\n+\n+\tprivate IllegalStateException getException() {\n+\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t}\n+}\n+\n+/**\n+ * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n+ */\n+class DemultiplexParameters {\n+\tfinal IOManager ioManager;\n+\tfinal InflightDataRescalingDescriptor channelMapping;\n+\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n+\tfinal SerializationDelegate<StreamRecord> delegate;\n+\tfinal int numberOfChannels;\n+\tfinal int subtaskIndex;\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tDemultiplexParameters(\n+\t\t\tTypeSerializer<?> inputSerializer,\n+\t\t\tIOManager ioManager,\n+\t\t\tInflightDataRescalingDescriptor channelMapping,\n+\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n+\t\t\tint numberOfChannels,\n+\t\t\tint subtaskIndex) {\n+\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n+\t\tthis.ioManager = ioManager;\n+\t\tthis.channelMapping = channelMapping;\n+\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n+\t\tthis.numberOfChannels = numberOfChannels;\n+\t\tthis.subtaskIndex = subtaskIndex;\n+\t}\n+}\n+\n+/**\n+ * Demultiplexes buffers on subtask-level.\n+ *\n+ * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n+ * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n+ * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n+ *\n+ * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n+ * statuses of the (nested) virtual channels.\n+ */\n+class SubtaskDemultiplexer implements Demultiplexer {\n+\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n+\n+\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n+\n+\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n+\n+\tprivate VirtualChannelSelector currentSelector;\n+\n+\tprivate ChannelDemultiplexer selectedSubtask;\n+\n+\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n+\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n+\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n+\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n+\t\tselectedSubtask = defaultSelection.getValue();\n+\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n+\t\t\tselectedSubtask.selectedChannelIndex);\n+\n+\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n+\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tgetChannelSelectors().forEach(selector -> {\n+\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n+\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n+\t\t});\n+\t}\n+\n+\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n+\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);\n+\t}\n+\n+\tpublic void select(VirtualChannelSelector selector) {\n+\t\tcurrentSelector = selector;\n+\t\tselectedSubtask = demultiplexersForSubtasks.get(selector.getSubtaskIndex());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2MzI4Mg=="}, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 173}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI1NDE3NDgwOnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QxMDozOTo1OVrOHvHOPA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QxMDozOTo1OVrOHvHOPA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2MzQ1Mg==", "bodyText": "nit: rename to subtaskToDemultiplexer to make the meaning of Integer clear?", "url": "https://github.com/apache/flink/pull/13845#discussion_r519163452", "createdAt": "2020-11-07T10:39:59Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "diffHunk": "@@ -0,0 +1,402 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+/**\n+ * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n+ * non-recovery hotpath, this interface is not extending RecordDeserializer.\n+ */\n+interface Demultiplexer extends AutoCloseable {\n+\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n+\n+\tvoid setNextBuffer(Buffer buffer) throws IOException;\n+\n+\tvoid select(VirtualChannelSelector event);\n+\n+\t@Override\n+\tvoid close();\n+}\n+\n+class NoDataDemultiplexer implements Demultiplexer {\n+\tprivate final InputChannelInfo channelInfo;\n+\n+\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n+\t\tthis.channelInfo = channelInfo;\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void select(VirtualChannelSelector event) {\n+\t\tthrow getException();\n+\t}\n+\n+\tprivate IllegalStateException getException() {\n+\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t}\n+}\n+\n+/**\n+ * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n+ */\n+class DemultiplexParameters {\n+\tfinal IOManager ioManager;\n+\tfinal InflightDataRescalingDescriptor channelMapping;\n+\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n+\tfinal SerializationDelegate<StreamRecord> delegate;\n+\tfinal int numberOfChannels;\n+\tfinal int subtaskIndex;\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tDemultiplexParameters(\n+\t\t\tTypeSerializer<?> inputSerializer,\n+\t\t\tIOManager ioManager,\n+\t\t\tInflightDataRescalingDescriptor channelMapping,\n+\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n+\t\t\tint numberOfChannels,\n+\t\t\tint subtaskIndex) {\n+\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n+\t\tthis.ioManager = ioManager;\n+\t\tthis.channelMapping = channelMapping;\n+\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n+\t\tthis.numberOfChannels = numberOfChannels;\n+\t\tthis.subtaskIndex = subtaskIndex;\n+\t}\n+}\n+\n+/**\n+ * Demultiplexes buffers on subtask-level.\n+ *\n+ * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n+ * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n+ * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n+ *\n+ * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n+ * statuses of the (nested) virtual channels.\n+ */\n+class SubtaskDemultiplexer implements Demultiplexer {\n+\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 138}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI1NDE3NzA1OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QxMDo0MzozNlrOHvHPRA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QyMjozODowOFrOHvLLxw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2MzcxNg==", "bodyText": "Make it static?\nThis method is called from the constructor and refers to a field. This makes it error-prone because the field may not be initialized.", "url": "https://github.com/apache/flink/pull/13845#discussion_r519163716", "createdAt": "2020-11-07T10:43:36Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "diffHunk": "@@ -0,0 +1,402 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+/**\n+ * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n+ * non-recovery hotpath, this interface is not extending RecordDeserializer.\n+ */\n+interface Demultiplexer extends AutoCloseable {\n+\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n+\n+\tvoid setNextBuffer(Buffer buffer) throws IOException;\n+\n+\tvoid select(VirtualChannelSelector event);\n+\n+\t@Override\n+\tvoid close();\n+}\n+\n+class NoDataDemultiplexer implements Demultiplexer {\n+\tprivate final InputChannelInfo channelInfo;\n+\n+\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n+\t\tthis.channelInfo = channelInfo;\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void select(VirtualChannelSelector event) {\n+\t\tthrow getException();\n+\t}\n+\n+\tprivate IllegalStateException getException() {\n+\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t}\n+}\n+\n+/**\n+ * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n+ */\n+class DemultiplexParameters {\n+\tfinal IOManager ioManager;\n+\tfinal InflightDataRescalingDescriptor channelMapping;\n+\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n+\tfinal SerializationDelegate<StreamRecord> delegate;\n+\tfinal int numberOfChannels;\n+\tfinal int subtaskIndex;\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tDemultiplexParameters(\n+\t\t\tTypeSerializer<?> inputSerializer,\n+\t\t\tIOManager ioManager,\n+\t\t\tInflightDataRescalingDescriptor channelMapping,\n+\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n+\t\t\tint numberOfChannels,\n+\t\t\tint subtaskIndex) {\n+\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n+\t\tthis.ioManager = ioManager;\n+\t\tthis.channelMapping = channelMapping;\n+\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n+\t\tthis.numberOfChannels = numberOfChannels;\n+\t\tthis.subtaskIndex = subtaskIndex;\n+\t}\n+}\n+\n+/**\n+ * Demultiplexes buffers on subtask-level.\n+ *\n+ * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n+ * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n+ * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n+ *\n+ * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n+ * statuses of the (nested) virtual channels.\n+ */\n+class SubtaskDemultiplexer implements Demultiplexer {\n+\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n+\n+\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n+\n+\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n+\n+\tprivate VirtualChannelSelector currentSelector;\n+\n+\tprivate ChannelDemultiplexer selectedSubtask;\n+\n+\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n+\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n+\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n+\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n+\t\tselectedSubtask = defaultSelection.getValue();\n+\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n+\t\t\tselectedSubtask.selectedChannelIndex);\n+\n+\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n+\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tgetChannelSelectors().forEach(selector -> {\n+\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n+\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n+\t\t});\n+\t}\n+\n+\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n+\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 168}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTIyODM1OQ==", "bodyText": "I inlined it in ctor. It's using an instance field and is called from SubtaskDemultplexer, so I don't see a good way to make it static.", "url": "https://github.com/apache/flink/pull/13845#discussion_r519228359", "createdAt": "2020-11-07T22:38:08Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "diffHunk": "@@ -0,0 +1,402 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+/**\n+ * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n+ * non-recovery hotpath, this interface is not extending RecordDeserializer.\n+ */\n+interface Demultiplexer extends AutoCloseable {\n+\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n+\n+\tvoid setNextBuffer(Buffer buffer) throws IOException;\n+\n+\tvoid select(VirtualChannelSelector event);\n+\n+\t@Override\n+\tvoid close();\n+}\n+\n+class NoDataDemultiplexer implements Demultiplexer {\n+\tprivate final InputChannelInfo channelInfo;\n+\n+\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n+\t\tthis.channelInfo = channelInfo;\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void select(VirtualChannelSelector event) {\n+\t\tthrow getException();\n+\t}\n+\n+\tprivate IllegalStateException getException() {\n+\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t}\n+}\n+\n+/**\n+ * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n+ */\n+class DemultiplexParameters {\n+\tfinal IOManager ioManager;\n+\tfinal InflightDataRescalingDescriptor channelMapping;\n+\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n+\tfinal SerializationDelegate<StreamRecord> delegate;\n+\tfinal int numberOfChannels;\n+\tfinal int subtaskIndex;\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tDemultiplexParameters(\n+\t\t\tTypeSerializer<?> inputSerializer,\n+\t\t\tIOManager ioManager,\n+\t\t\tInflightDataRescalingDescriptor channelMapping,\n+\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n+\t\t\tint numberOfChannels,\n+\t\t\tint subtaskIndex) {\n+\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n+\t\tthis.ioManager = ioManager;\n+\t\tthis.channelMapping = channelMapping;\n+\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n+\t\tthis.numberOfChannels = numberOfChannels;\n+\t\tthis.subtaskIndex = subtaskIndex;\n+\t}\n+}\n+\n+/**\n+ * Demultiplexes buffers on subtask-level.\n+ *\n+ * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n+ * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n+ * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n+ *\n+ * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n+ * statuses of the (nested) virtual channels.\n+ */\n+class SubtaskDemultiplexer implements Demultiplexer {\n+\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n+\n+\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n+\n+\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n+\n+\tprivate VirtualChannelSelector currentSelector;\n+\n+\tprivate ChannelDemultiplexer selectedSubtask;\n+\n+\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n+\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n+\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n+\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n+\t\tselectedSubtask = defaultSelection.getValue();\n+\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n+\t\t\tselectedSubtask.selectedChannelIndex);\n+\n+\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n+\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tgetChannelSelectors().forEach(selector -> {\n+\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n+\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n+\t\t});\n+\t}\n+\n+\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n+\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2MzcxNg=="}, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 168}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI1NDE3NzkyOnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QxMDo0NDoyOFrOHvHPog==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QyMjozNjoxMFrOHvLLFg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2MzgxMA==", "bodyText": "Shouldn't we check here that the new watermark is higher than the old one?", "url": "https://github.com/apache/flink/pull/13845#discussion_r519163810", "createdAt": "2020-11-07T10:44:28Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "diffHunk": "@@ -0,0 +1,402 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+/**\n+ * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n+ * non-recovery hotpath, this interface is not extending RecordDeserializer.\n+ */\n+interface Demultiplexer extends AutoCloseable {\n+\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n+\n+\tvoid setNextBuffer(Buffer buffer) throws IOException;\n+\n+\tvoid select(VirtualChannelSelector event);\n+\n+\t@Override\n+\tvoid close();\n+}\n+\n+class NoDataDemultiplexer implements Demultiplexer {\n+\tprivate final InputChannelInfo channelInfo;\n+\n+\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n+\t\tthis.channelInfo = channelInfo;\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void select(VirtualChannelSelector event) {\n+\t\tthrow getException();\n+\t}\n+\n+\tprivate IllegalStateException getException() {\n+\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t}\n+}\n+\n+/**\n+ * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n+ */\n+class DemultiplexParameters {\n+\tfinal IOManager ioManager;\n+\tfinal InflightDataRescalingDescriptor channelMapping;\n+\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n+\tfinal SerializationDelegate<StreamRecord> delegate;\n+\tfinal int numberOfChannels;\n+\tfinal int subtaskIndex;\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tDemultiplexParameters(\n+\t\t\tTypeSerializer<?> inputSerializer,\n+\t\t\tIOManager ioManager,\n+\t\t\tInflightDataRescalingDescriptor channelMapping,\n+\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n+\t\t\tint numberOfChannels,\n+\t\t\tint subtaskIndex) {\n+\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n+\t\tthis.ioManager = ioManager;\n+\t\tthis.channelMapping = channelMapping;\n+\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n+\t\tthis.numberOfChannels = numberOfChannels;\n+\t\tthis.subtaskIndex = subtaskIndex;\n+\t}\n+}\n+\n+/**\n+ * Demultiplexes buffers on subtask-level.\n+ *\n+ * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n+ * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n+ * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n+ *\n+ * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n+ * statuses of the (nested) virtual channels.\n+ */\n+class SubtaskDemultiplexer implements Demultiplexer {\n+\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n+\n+\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n+\n+\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n+\n+\tprivate VirtualChannelSelector currentSelector;\n+\n+\tprivate ChannelDemultiplexer selectedSubtask;\n+\n+\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n+\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n+\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n+\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n+\t\tselectedSubtask = defaultSelection.getValue();\n+\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n+\t\t\tselectedSubtask.selectedChannelIndex);\n+\n+\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n+\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tgetChannelSelectors().forEach(selector -> {\n+\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n+\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n+\t\t});\n+\t}\n+\n+\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n+\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);\n+\t}\n+\n+\tpublic void select(VirtualChannelSelector selector) {\n+\t\tcurrentSelector = selector;\n+\t\tselectedSubtask = demultiplexersForSubtasks.get(selector.getSubtaskIndex());\n+\t\tif (selectedSubtask == null) {\n+\t\t\tthrow new IllegalStateException(\n+\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n+\t\t}\n+\t\tselectedSubtask.select(selector);\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n+\t\tselectedSubtask.setNextBuffer(buffer);\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n+\t\tdo {\n+\t\t\tRecordDeserializer.DeserializationResult result = selectedSubtask.getNextRecord(deserializationDelegate);\n+\n+\t\t\t// special handling of watermarks and stream status\n+\t\t\tif (result.isFullRecord()) {\n+\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n+\t\t\t\tif (element.isWatermark()) {\n+\t\t\t\t\t// basically, do not emit a watermark if not all virtual channel are past it\n+\t\t\t\t\tlastWatermarks.put(currentSelector, element.asWatermark());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 196}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTIyODE4Mg==", "bodyText": "There should not be any harm to write out the same watermark twice. (in fact most standard implementation of watermark emitter do not guarantee strict monotony). Performance impact should be rather small but we could optimize later.", "url": "https://github.com/apache/flink/pull/13845#discussion_r519228182", "createdAt": "2020-11-07T22:36:10Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "diffHunk": "@@ -0,0 +1,402 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+/**\n+ * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n+ * non-recovery hotpath, this interface is not extending RecordDeserializer.\n+ */\n+interface Demultiplexer extends AutoCloseable {\n+\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n+\n+\tvoid setNextBuffer(Buffer buffer) throws IOException;\n+\n+\tvoid select(VirtualChannelSelector event);\n+\n+\t@Override\n+\tvoid close();\n+}\n+\n+class NoDataDemultiplexer implements Demultiplexer {\n+\tprivate final InputChannelInfo channelInfo;\n+\n+\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n+\t\tthis.channelInfo = channelInfo;\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void select(VirtualChannelSelector event) {\n+\t\tthrow getException();\n+\t}\n+\n+\tprivate IllegalStateException getException() {\n+\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t}\n+}\n+\n+/**\n+ * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n+ */\n+class DemultiplexParameters {\n+\tfinal IOManager ioManager;\n+\tfinal InflightDataRescalingDescriptor channelMapping;\n+\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n+\tfinal SerializationDelegate<StreamRecord> delegate;\n+\tfinal int numberOfChannels;\n+\tfinal int subtaskIndex;\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tDemultiplexParameters(\n+\t\t\tTypeSerializer<?> inputSerializer,\n+\t\t\tIOManager ioManager,\n+\t\t\tInflightDataRescalingDescriptor channelMapping,\n+\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n+\t\t\tint numberOfChannels,\n+\t\t\tint subtaskIndex) {\n+\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n+\t\tthis.ioManager = ioManager;\n+\t\tthis.channelMapping = channelMapping;\n+\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n+\t\tthis.numberOfChannels = numberOfChannels;\n+\t\tthis.subtaskIndex = subtaskIndex;\n+\t}\n+}\n+\n+/**\n+ * Demultiplexes buffers on subtask-level.\n+ *\n+ * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n+ * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n+ * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n+ *\n+ * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n+ * statuses of the (nested) virtual channels.\n+ */\n+class SubtaskDemultiplexer implements Demultiplexer {\n+\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n+\n+\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n+\n+\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n+\n+\tprivate VirtualChannelSelector currentSelector;\n+\n+\tprivate ChannelDemultiplexer selectedSubtask;\n+\n+\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n+\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n+\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n+\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n+\t\tselectedSubtask = defaultSelection.getValue();\n+\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n+\t\t\tselectedSubtask.selectedChannelIndex);\n+\n+\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n+\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tgetChannelSelectors().forEach(selector -> {\n+\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n+\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n+\t\t});\n+\t}\n+\n+\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n+\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);\n+\t}\n+\n+\tpublic void select(VirtualChannelSelector selector) {\n+\t\tcurrentSelector = selector;\n+\t\tselectedSubtask = demultiplexersForSubtasks.get(selector.getSubtaskIndex());\n+\t\tif (selectedSubtask == null) {\n+\t\t\tthrow new IllegalStateException(\n+\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n+\t\t}\n+\t\tselectedSubtask.select(selector);\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n+\t\tselectedSubtask.setNextBuffer(buffer);\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n+\t\tdo {\n+\t\t\tRecordDeserializer.DeserializationResult result = selectedSubtask.getNextRecord(deserializationDelegate);\n+\n+\t\t\t// special handling of watermarks and stream status\n+\t\t\tif (result.isFullRecord()) {\n+\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n+\t\t\t\tif (element.isWatermark()) {\n+\t\t\t\t\t// basically, do not emit a watermark if not all virtual channel are past it\n+\t\t\t\t\tlastWatermarks.put(currentSelector, element.asWatermark());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2MzgxMA=="}, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 196}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI1NDE3ODUxOnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QxMDo0NTowMVrOHvHP6A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QxMDo0NTowMVrOHvHP6A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2Mzg4MA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t\t\t\t\tif (streamStatuses.values().stream().anyMatch(s -> s.equals(StreamStatus.ACTIVE))) {\n          \n          \n            \n            \t\t\t\t\tif (streamStatuses.values().stream().anyMatch(StreamStatus::isActive)) {", "url": "https://github.com/apache/flink/pull/13845#discussion_r519163880", "createdAt": "2020-11-07T10:45:01Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "diffHunk": "@@ -0,0 +1,402 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+/**\n+ * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n+ * non-recovery hotpath, this interface is not extending RecordDeserializer.\n+ */\n+interface Demultiplexer extends AutoCloseable {\n+\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n+\n+\tvoid setNextBuffer(Buffer buffer) throws IOException;\n+\n+\tvoid select(VirtualChannelSelector event);\n+\n+\t@Override\n+\tvoid close();\n+}\n+\n+class NoDataDemultiplexer implements Demultiplexer {\n+\tprivate final InputChannelInfo channelInfo;\n+\n+\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n+\t\tthis.channelInfo = channelInfo;\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void select(VirtualChannelSelector event) {\n+\t\tthrow getException();\n+\t}\n+\n+\tprivate IllegalStateException getException() {\n+\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t}\n+}\n+\n+/**\n+ * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n+ */\n+class DemultiplexParameters {\n+\tfinal IOManager ioManager;\n+\tfinal InflightDataRescalingDescriptor channelMapping;\n+\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n+\tfinal SerializationDelegate<StreamRecord> delegate;\n+\tfinal int numberOfChannels;\n+\tfinal int subtaskIndex;\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tDemultiplexParameters(\n+\t\t\tTypeSerializer<?> inputSerializer,\n+\t\t\tIOManager ioManager,\n+\t\t\tInflightDataRescalingDescriptor channelMapping,\n+\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n+\t\t\tint numberOfChannels,\n+\t\t\tint subtaskIndex) {\n+\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n+\t\tthis.ioManager = ioManager;\n+\t\tthis.channelMapping = channelMapping;\n+\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n+\t\tthis.numberOfChannels = numberOfChannels;\n+\t\tthis.subtaskIndex = subtaskIndex;\n+\t}\n+}\n+\n+/**\n+ * Demultiplexes buffers on subtask-level.\n+ *\n+ * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n+ * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n+ * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n+ *\n+ * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n+ * statuses of the (nested) virtual channels.\n+ */\n+class SubtaskDemultiplexer implements Demultiplexer {\n+\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n+\n+\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n+\n+\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n+\n+\tprivate VirtualChannelSelector currentSelector;\n+\n+\tprivate ChannelDemultiplexer selectedSubtask;\n+\n+\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n+\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n+\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n+\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n+\t\tselectedSubtask = defaultSelection.getValue();\n+\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n+\t\t\tselectedSubtask.selectedChannelIndex);\n+\n+\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n+\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tgetChannelSelectors().forEach(selector -> {\n+\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n+\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n+\t\t});\n+\t}\n+\n+\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n+\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);\n+\t}\n+\n+\tpublic void select(VirtualChannelSelector selector) {\n+\t\tcurrentSelector = selector;\n+\t\tselectedSubtask = demultiplexersForSubtasks.get(selector.getSubtaskIndex());\n+\t\tif (selectedSubtask == null) {\n+\t\t\tthrow new IllegalStateException(\n+\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n+\t\t}\n+\t\tselectedSubtask.select(selector);\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n+\t\tselectedSubtask.setNextBuffer(buffer);\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n+\t\tdo {\n+\t\t\tRecordDeserializer.DeserializationResult result = selectedSubtask.getNextRecord(deserializationDelegate);\n+\n+\t\t\t// special handling of watermarks and stream status\n+\t\t\tif (result.isFullRecord()) {\n+\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n+\t\t\t\tif (element.isWatermark()) {\n+\t\t\t\t\t// basically, do not emit a watermark if not all virtual channel are past it\n+\t\t\t\t\tlastWatermarks.put(currentSelector, element.asWatermark());\n+\t\t\t\t\tfinal Watermark minWatermark = lastWatermarks.values().stream()\n+\t\t\t\t\t\t.min(Comparator.comparing(Watermark::getTimestamp))\n+\t\t\t\t\t\t.orElseThrow(() -> new IllegalStateException(\"Should always have a min watermark\"));\n+\t\t\t\t\t// at least one virtual channel has no watermark, so don't emit any watermark yet\n+\t\t\t\t\tif (minWatermark.equals(Watermark.UNINITIALIZED)) {\n+\t\t\t\t\t\tcontinue;\n+\t\t\t\t\t}\n+\t\t\t\t\tdeserializationDelegate.setInstance(minWatermark);\n+\t\t\t\t} else if (element.isStreamStatus()) {\n+\t\t\t\t\tstreamStatuses.put(currentSelector, element.asStreamStatus());\n+\t\t\t\t\t// summarize statuses across all virtual channels\n+\t\t\t\t\t// duplicate statuses are filtered in StatusWatermarkValve\n+\t\t\t\t\tif (streamStatuses.values().stream().anyMatch(s -> s.equals(StreamStatus.ACTIVE))) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 209}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI1NDE3OTQ0OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QxMDo0NjozMlrOHvHQUw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QyMjoxOTozMlrOHvLEtA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2Mzk4Nw==", "bodyText": "Is it intentional that filter is only applied to records?\nCan't watermarks be misinterpreted then?", "url": "https://github.com/apache/flink/pull/13845#discussion_r519163987", "createdAt": "2020-11-07T10:46:32Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "diffHunk": "@@ -0,0 +1,402 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+/**\n+ * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n+ * non-recovery hotpath, this interface is not extending RecordDeserializer.\n+ */\n+interface Demultiplexer extends AutoCloseable {\n+\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n+\n+\tvoid setNextBuffer(Buffer buffer) throws IOException;\n+\n+\tvoid select(VirtualChannelSelector event);\n+\n+\t@Override\n+\tvoid close();\n+}\n+\n+class NoDataDemultiplexer implements Demultiplexer {\n+\tprivate final InputChannelInfo channelInfo;\n+\n+\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n+\t\tthis.channelInfo = channelInfo;\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void select(VirtualChannelSelector event) {\n+\t\tthrow getException();\n+\t}\n+\n+\tprivate IllegalStateException getException() {\n+\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t}\n+}\n+\n+/**\n+ * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n+ */\n+class DemultiplexParameters {\n+\tfinal IOManager ioManager;\n+\tfinal InflightDataRescalingDescriptor channelMapping;\n+\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n+\tfinal SerializationDelegate<StreamRecord> delegate;\n+\tfinal int numberOfChannels;\n+\tfinal int subtaskIndex;\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tDemultiplexParameters(\n+\t\t\tTypeSerializer<?> inputSerializer,\n+\t\t\tIOManager ioManager,\n+\t\t\tInflightDataRescalingDescriptor channelMapping,\n+\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n+\t\t\tint numberOfChannels,\n+\t\t\tint subtaskIndex) {\n+\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n+\t\tthis.ioManager = ioManager;\n+\t\tthis.channelMapping = channelMapping;\n+\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n+\t\tthis.numberOfChannels = numberOfChannels;\n+\t\tthis.subtaskIndex = subtaskIndex;\n+\t}\n+}\n+\n+/**\n+ * Demultiplexes buffers on subtask-level.\n+ *\n+ * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n+ * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n+ * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n+ *\n+ * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n+ * statuses of the (nested) virtual channels.\n+ */\n+class SubtaskDemultiplexer implements Demultiplexer {\n+\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n+\n+\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n+\n+\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n+\n+\tprivate VirtualChannelSelector currentSelector;\n+\n+\tprivate ChannelDemultiplexer selectedSubtask;\n+\n+\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n+\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n+\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n+\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n+\t\tselectedSubtask = defaultSelection.getValue();\n+\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n+\t\t\tselectedSubtask.selectedChannelIndex);\n+\n+\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n+\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tgetChannelSelectors().forEach(selector -> {\n+\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n+\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n+\t\t});\n+\t}\n+\n+\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n+\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);\n+\t}\n+\n+\tpublic void select(VirtualChannelSelector selector) {\n+\t\tcurrentSelector = selector;\n+\t\tselectedSubtask = demultiplexersForSubtasks.get(selector.getSubtaskIndex());\n+\t\tif (selectedSubtask == null) {\n+\t\t\tthrow new IllegalStateException(\n+\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n+\t\t}\n+\t\tselectedSubtask.select(selector);\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n+\t\tselectedSubtask.setNextBuffer(buffer);\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n+\t\tdo {\n+\t\t\tRecordDeserializer.DeserializationResult result = selectedSubtask.getNextRecord(deserializationDelegate);\n+\n+\t\t\t// special handling of watermarks and stream status\n+\t\t\tif (result.isFullRecord()) {\n+\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n+\t\t\t\tif (element.isWatermark()) {\n+\t\t\t\t\t// basically, do not emit a watermark if not all virtual channel are past it\n+\t\t\t\t\tlastWatermarks.put(currentSelector, element.asWatermark());\n+\t\t\t\t\tfinal Watermark minWatermark = lastWatermarks.values().stream()\n+\t\t\t\t\t\t.min(Comparator.comparing(Watermark::getTimestamp))\n+\t\t\t\t\t\t.orElseThrow(() -> new IllegalStateException(\"Should always have a min watermark\"));\n+\t\t\t\t\t// at least one virtual channel has no watermark, so don't emit any watermark yet\n+\t\t\t\t\tif (minWatermark.equals(Watermark.UNINITIALIZED)) {\n+\t\t\t\t\t\tcontinue;\n+\t\t\t\t\t}\n+\t\t\t\t\tdeserializationDelegate.setInstance(minWatermark);\n+\t\t\t\t} else if (element.isStreamStatus()) {\n+\t\t\t\t\tstreamStatuses.put(currentSelector, element.asStreamStatus());\n+\t\t\t\t\t// summarize statuses across all virtual channels\n+\t\t\t\t\t// duplicate statuses are filtered in StatusWatermarkValve\n+\t\t\t\t\tif (streamStatuses.values().stream().anyMatch(s -> s.equals(StreamStatus.ACTIVE))) {\n+\t\t\t\t\t\tdeserializationDelegate.setInstance(StreamStatus.ACTIVE);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\treturn result;\n+\t\t\t// loop is only re-executed for suppressed watermark\n+\t\t} while (true);\n+\t}\n+\n+\tpublic void close() {\n+\t\tdemultiplexersForSubtasks.values().forEach(Demultiplexer::close);\n+\t}\n+\n+\tstatic Demultiplexer forChannel(InputChannelInfo info, DemultiplexParameters parameters) {\n+\t\tfinal int[] oldSubtaskIndexes = parameters.channelMapping.getOldSubtaskIndexes(parameters.subtaskIndex);\n+\t\tif (oldSubtaskIndexes.length == 0) {\n+\t\t\treturn new NoDataDemultiplexer(info);\n+\t\t}\n+\t\tfinal int[] oldChannelIndexes = parameters.channelMapping.getChannelMapping(info.getGateIdx())\n+\t\t\t.getOldChannelIndexes(info.getInputChannelIdx());\n+\t\tif (oldChannelIndexes.length == 0) {\n+\t\t\treturn new NoDataDemultiplexer(info);\n+\t\t}\n+\t\tint totalChannels = oldSubtaskIndexes.length * oldChannelIndexes.length;\n+\t\tMap<Integer, ChannelDemultiplexer> demultiplexersForSubtasks = Arrays.stream(oldSubtaskIndexes).boxed()\n+\t\t\t.collect(Collectors.toMap(\n+\t\t\t\tFunction.identity(),\n+\t\t\t\toldSubtaskIndex -> ChannelDemultiplexer.forChannel(oldSubtaskIndex, info, parameters, totalChannels)\n+\t\t\t));\n+\t\treturn new SubtaskDemultiplexer(demultiplexersForSubtasks, totalChannels);\n+\t}\n+\n+\t@Override\n+\tpublic String toString() {\n+\t\treturn \"SubtaskDemultiplexer{\" +\n+\t\t\t\"demultiplexersForSubtasks=\" + demultiplexersForSubtasks +\n+\t\t\t'}';\n+\t}\n+}\n+\n+/**\n+ * Demultiplexes buffers on channel-level.\n+ *\n+ * <p>Example: If the upstream task has been downscaled from 2 to 1. Then, old channels 0 and 1 are both\n+ * processed over new channel 0. So this channel demultiplexer has two {@link #recordDeserializersForChannels} associated\n+ * with the respective old channels.\n+ *\n+ * <p>For all non-unique mappings of new channels to old channels (see\n+ * {@link org.apache.flink.runtime.io.network.api.writer.SubtaskStateMapper} for more details), a filter\n+ * verifies if the restored record should be indeed processed by this subtask or if it should be filtered out and\n+ * be processed at a different subtask.\n+ */\n+class ChannelDemultiplexer implements Demultiplexer {\n+\tprivate final Map<Integer, RecordDeserializer<DeserializationDelegate<StreamElement>>> recordDeserializersForChannels;\n+\n+\tprivate static final Predicate<StreamRecord> NO_FILTER = record -> true;\n+\n+\tprivate final Map<Integer, Predicate<StreamRecord>> filters;\n+\n+\tprivate final int subtaskIndex;\n+\n+\t@Nullable\n+\tprivate RecordDeserializer<DeserializationDelegate<StreamElement>> selectedChannel;\n+\n+\tint selectedChannelIndex;\n+\n+\tChannelDemultiplexer(\n+\t\t\tint subtaskIndex,\n+\t\t\tMap<Integer, Predicate<StreamRecord>> oldChannelsWithFilters,\n+\t\t\tDemultiplexParameters parameters,\n+\t\t\tint totalChannels) {\n+\t\tthis.subtaskIndex = subtaskIndex;\n+\t\tthis.filters = oldChannelsWithFilters;\n+\t\trecordDeserializersForChannels = Maps.newHashMapWithExpectedSize(oldChannelsWithFilters.size());\n+\t\tfor (final Integer oldChannel : oldChannelsWithFilters.keySet()) {\n+\t\t\trecordDeserializersForChannels.put(oldChannel,\n+\t\t\t\tnew SpillingAdaptiveSpanningRecordDeserializer<>(parameters.ioManager.getSpillingDirectoriesPaths(),\n+\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_THRESHOLD_FOR_SPILLING / totalChannels,\n+\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_FILE_BUFFER_SIZE / totalChannels));\n+\t\t}\n+\n+\t\trecordDeserializersForChannels.entrySet().stream().findFirst().ifPresent(firstEntry -> {\n+\t\t\tselectedChannel = firstEntry.getValue();\n+\t\t\tselectedChannelIndex = firstEntry.getKey();\n+\t\t});\n+\t}\n+\n+\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n+\t\treturn recordDeserializersForChannels.keySet().stream()\n+\t\t\t.map(channelIndex -> new VirtualChannelSelector(subtaskIndex, channelIndex));\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n+\t\tdo {\n+\t\t\tfinal RecordDeserializer.DeserializationResult result = selectedChannel.getNextRecord(deserializationDelegate);\n+\n+\t\t\tif (result.isBufferConsumed()) {\n+\t\t\t\tselectedChannel.getCurrentBuffer().recycleBuffer();\n+\t\t\t}\n+\t\t\tif (result.isFullRecord()) {\n+\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n+\t\t\t\tif (element.isRecord() && !filters.get(selectedChannelIndex).test(element.asRecord())) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 313}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTIyNjU0OA==", "bodyText": "The filter (ChannelSelector/Partitioner) can only deal with StreamRecord. Watermarks are interpreted differently. I'll add a comment.", "url": "https://github.com/apache/flink/pull/13845#discussion_r519226548", "createdAt": "2020-11-07T22:19:32Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "diffHunk": "@@ -0,0 +1,402 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+/**\n+ * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n+ * non-recovery hotpath, this interface is not extending RecordDeserializer.\n+ */\n+interface Demultiplexer extends AutoCloseable {\n+\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n+\n+\tvoid setNextBuffer(Buffer buffer) throws IOException;\n+\n+\tvoid select(VirtualChannelSelector event);\n+\n+\t@Override\n+\tvoid close();\n+}\n+\n+class NoDataDemultiplexer implements Demultiplexer {\n+\tprivate final InputChannelInfo channelInfo;\n+\n+\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n+\t\tthis.channelInfo = channelInfo;\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void select(VirtualChannelSelector event) {\n+\t\tthrow getException();\n+\t}\n+\n+\tprivate IllegalStateException getException() {\n+\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t}\n+}\n+\n+/**\n+ * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n+ */\n+class DemultiplexParameters {\n+\tfinal IOManager ioManager;\n+\tfinal InflightDataRescalingDescriptor channelMapping;\n+\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n+\tfinal SerializationDelegate<StreamRecord> delegate;\n+\tfinal int numberOfChannels;\n+\tfinal int subtaskIndex;\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tDemultiplexParameters(\n+\t\t\tTypeSerializer<?> inputSerializer,\n+\t\t\tIOManager ioManager,\n+\t\t\tInflightDataRescalingDescriptor channelMapping,\n+\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n+\t\t\tint numberOfChannels,\n+\t\t\tint subtaskIndex) {\n+\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n+\t\tthis.ioManager = ioManager;\n+\t\tthis.channelMapping = channelMapping;\n+\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n+\t\tthis.numberOfChannels = numberOfChannels;\n+\t\tthis.subtaskIndex = subtaskIndex;\n+\t}\n+}\n+\n+/**\n+ * Demultiplexes buffers on subtask-level.\n+ *\n+ * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n+ * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n+ * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n+ *\n+ * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n+ * statuses of the (nested) virtual channels.\n+ */\n+class SubtaskDemultiplexer implements Demultiplexer {\n+\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n+\n+\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n+\n+\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n+\n+\tprivate VirtualChannelSelector currentSelector;\n+\n+\tprivate ChannelDemultiplexer selectedSubtask;\n+\n+\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n+\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n+\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n+\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n+\t\tselectedSubtask = defaultSelection.getValue();\n+\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n+\t\t\tselectedSubtask.selectedChannelIndex);\n+\n+\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n+\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tgetChannelSelectors().forEach(selector -> {\n+\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n+\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n+\t\t});\n+\t}\n+\n+\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n+\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);\n+\t}\n+\n+\tpublic void select(VirtualChannelSelector selector) {\n+\t\tcurrentSelector = selector;\n+\t\tselectedSubtask = demultiplexersForSubtasks.get(selector.getSubtaskIndex());\n+\t\tif (selectedSubtask == null) {\n+\t\t\tthrow new IllegalStateException(\n+\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n+\t\t}\n+\t\tselectedSubtask.select(selector);\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n+\t\tselectedSubtask.setNextBuffer(buffer);\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n+\t\tdo {\n+\t\t\tRecordDeserializer.DeserializationResult result = selectedSubtask.getNextRecord(deserializationDelegate);\n+\n+\t\t\t// special handling of watermarks and stream status\n+\t\t\tif (result.isFullRecord()) {\n+\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n+\t\t\t\tif (element.isWatermark()) {\n+\t\t\t\t\t// basically, do not emit a watermark if not all virtual channel are past it\n+\t\t\t\t\tlastWatermarks.put(currentSelector, element.asWatermark());\n+\t\t\t\t\tfinal Watermark minWatermark = lastWatermarks.values().stream()\n+\t\t\t\t\t\t.min(Comparator.comparing(Watermark::getTimestamp))\n+\t\t\t\t\t\t.orElseThrow(() -> new IllegalStateException(\"Should always have a min watermark\"));\n+\t\t\t\t\t// at least one virtual channel has no watermark, so don't emit any watermark yet\n+\t\t\t\t\tif (minWatermark.equals(Watermark.UNINITIALIZED)) {\n+\t\t\t\t\t\tcontinue;\n+\t\t\t\t\t}\n+\t\t\t\t\tdeserializationDelegate.setInstance(minWatermark);\n+\t\t\t\t} else if (element.isStreamStatus()) {\n+\t\t\t\t\tstreamStatuses.put(currentSelector, element.asStreamStatus());\n+\t\t\t\t\t// summarize statuses across all virtual channels\n+\t\t\t\t\t// duplicate statuses are filtered in StatusWatermarkValve\n+\t\t\t\t\tif (streamStatuses.values().stream().anyMatch(s -> s.equals(StreamStatus.ACTIVE))) {\n+\t\t\t\t\t\tdeserializationDelegate.setInstance(StreamStatus.ACTIVE);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\treturn result;\n+\t\t\t// loop is only re-executed for suppressed watermark\n+\t\t} while (true);\n+\t}\n+\n+\tpublic void close() {\n+\t\tdemultiplexersForSubtasks.values().forEach(Demultiplexer::close);\n+\t}\n+\n+\tstatic Demultiplexer forChannel(InputChannelInfo info, DemultiplexParameters parameters) {\n+\t\tfinal int[] oldSubtaskIndexes = parameters.channelMapping.getOldSubtaskIndexes(parameters.subtaskIndex);\n+\t\tif (oldSubtaskIndexes.length == 0) {\n+\t\t\treturn new NoDataDemultiplexer(info);\n+\t\t}\n+\t\tfinal int[] oldChannelIndexes = parameters.channelMapping.getChannelMapping(info.getGateIdx())\n+\t\t\t.getOldChannelIndexes(info.getInputChannelIdx());\n+\t\tif (oldChannelIndexes.length == 0) {\n+\t\t\treturn new NoDataDemultiplexer(info);\n+\t\t}\n+\t\tint totalChannels = oldSubtaskIndexes.length * oldChannelIndexes.length;\n+\t\tMap<Integer, ChannelDemultiplexer> demultiplexersForSubtasks = Arrays.stream(oldSubtaskIndexes).boxed()\n+\t\t\t.collect(Collectors.toMap(\n+\t\t\t\tFunction.identity(),\n+\t\t\t\toldSubtaskIndex -> ChannelDemultiplexer.forChannel(oldSubtaskIndex, info, parameters, totalChannels)\n+\t\t\t));\n+\t\treturn new SubtaskDemultiplexer(demultiplexersForSubtasks, totalChannels);\n+\t}\n+\n+\t@Override\n+\tpublic String toString() {\n+\t\treturn \"SubtaskDemultiplexer{\" +\n+\t\t\t\"demultiplexersForSubtasks=\" + demultiplexersForSubtasks +\n+\t\t\t'}';\n+\t}\n+}\n+\n+/**\n+ * Demultiplexes buffers on channel-level.\n+ *\n+ * <p>Example: If the upstream task has been downscaled from 2 to 1. Then, old channels 0 and 1 are both\n+ * processed over new channel 0. So this channel demultiplexer has two {@link #recordDeserializersForChannels} associated\n+ * with the respective old channels.\n+ *\n+ * <p>For all non-unique mappings of new channels to old channels (see\n+ * {@link org.apache.flink.runtime.io.network.api.writer.SubtaskStateMapper} for more details), a filter\n+ * verifies if the restored record should be indeed processed by this subtask or if it should be filtered out and\n+ * be processed at a different subtask.\n+ */\n+class ChannelDemultiplexer implements Demultiplexer {\n+\tprivate final Map<Integer, RecordDeserializer<DeserializationDelegate<StreamElement>>> recordDeserializersForChannels;\n+\n+\tprivate static final Predicate<StreamRecord> NO_FILTER = record -> true;\n+\n+\tprivate final Map<Integer, Predicate<StreamRecord>> filters;\n+\n+\tprivate final int subtaskIndex;\n+\n+\t@Nullable\n+\tprivate RecordDeserializer<DeserializationDelegate<StreamElement>> selectedChannel;\n+\n+\tint selectedChannelIndex;\n+\n+\tChannelDemultiplexer(\n+\t\t\tint subtaskIndex,\n+\t\t\tMap<Integer, Predicate<StreamRecord>> oldChannelsWithFilters,\n+\t\t\tDemultiplexParameters parameters,\n+\t\t\tint totalChannels) {\n+\t\tthis.subtaskIndex = subtaskIndex;\n+\t\tthis.filters = oldChannelsWithFilters;\n+\t\trecordDeserializersForChannels = Maps.newHashMapWithExpectedSize(oldChannelsWithFilters.size());\n+\t\tfor (final Integer oldChannel : oldChannelsWithFilters.keySet()) {\n+\t\t\trecordDeserializersForChannels.put(oldChannel,\n+\t\t\t\tnew SpillingAdaptiveSpanningRecordDeserializer<>(parameters.ioManager.getSpillingDirectoriesPaths(),\n+\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_THRESHOLD_FOR_SPILLING / totalChannels,\n+\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_FILE_BUFFER_SIZE / totalChannels));\n+\t\t}\n+\n+\t\trecordDeserializersForChannels.entrySet().stream().findFirst().ifPresent(firstEntry -> {\n+\t\t\tselectedChannel = firstEntry.getValue();\n+\t\t\tselectedChannelIndex = firstEntry.getKey();\n+\t\t});\n+\t}\n+\n+\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n+\t\treturn recordDeserializersForChannels.keySet().stream()\n+\t\t\t.map(channelIndex -> new VirtualChannelSelector(subtaskIndex, channelIndex));\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n+\t\tdo {\n+\t\t\tfinal RecordDeserializer.DeserializationResult result = selectedChannel.getNextRecord(deserializationDelegate);\n+\n+\t\t\tif (result.isBufferConsumed()) {\n+\t\t\t\tselectedChannel.getCurrentBuffer().recycleBuffer();\n+\t\t\t}\n+\t\t\tif (result.isFullRecord()) {\n+\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n+\t\t\t\tif (element.isRecord() && !filters.get(selectedChannelIndex).test(element.asRecord())) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2Mzk4Nw=="}, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 313}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI1NDE4NDc4OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QxMDo1NDoxN1rOHvHSww==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QyMjoyMzoyOFrOHvLGFw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2NDYxMQ==", "bodyText": "This delegate is shared across all the channels, but this is the only place where it's used.\nI think it's a bit risky. Why not create it in this method (createFilter)?", "url": "https://github.com/apache/flink/pull/13845#discussion_r519164611", "createdAt": "2020-11-07T10:54:17Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "diffHunk": "@@ -0,0 +1,402 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+/**\n+ * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n+ * non-recovery hotpath, this interface is not extending RecordDeserializer.\n+ */\n+interface Demultiplexer extends AutoCloseable {\n+\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n+\n+\tvoid setNextBuffer(Buffer buffer) throws IOException;\n+\n+\tvoid select(VirtualChannelSelector event);\n+\n+\t@Override\n+\tvoid close();\n+}\n+\n+class NoDataDemultiplexer implements Demultiplexer {\n+\tprivate final InputChannelInfo channelInfo;\n+\n+\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n+\t\tthis.channelInfo = channelInfo;\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void select(VirtualChannelSelector event) {\n+\t\tthrow getException();\n+\t}\n+\n+\tprivate IllegalStateException getException() {\n+\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t}\n+}\n+\n+/**\n+ * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n+ */\n+class DemultiplexParameters {\n+\tfinal IOManager ioManager;\n+\tfinal InflightDataRescalingDescriptor channelMapping;\n+\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n+\tfinal SerializationDelegate<StreamRecord> delegate;\n+\tfinal int numberOfChannels;\n+\tfinal int subtaskIndex;\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tDemultiplexParameters(\n+\t\t\tTypeSerializer<?> inputSerializer,\n+\t\t\tIOManager ioManager,\n+\t\t\tInflightDataRescalingDescriptor channelMapping,\n+\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n+\t\t\tint numberOfChannels,\n+\t\t\tint subtaskIndex) {\n+\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n+\t\tthis.ioManager = ioManager;\n+\t\tthis.channelMapping = channelMapping;\n+\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n+\t\tthis.numberOfChannels = numberOfChannels;\n+\t\tthis.subtaskIndex = subtaskIndex;\n+\t}\n+}\n+\n+/**\n+ * Demultiplexes buffers on subtask-level.\n+ *\n+ * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n+ * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n+ * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n+ *\n+ * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n+ * statuses of the (nested) virtual channels.\n+ */\n+class SubtaskDemultiplexer implements Demultiplexer {\n+\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n+\n+\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n+\n+\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n+\n+\tprivate VirtualChannelSelector currentSelector;\n+\n+\tprivate ChannelDemultiplexer selectedSubtask;\n+\n+\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n+\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n+\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n+\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n+\t\tselectedSubtask = defaultSelection.getValue();\n+\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n+\t\t\tselectedSubtask.selectedChannelIndex);\n+\n+\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n+\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tgetChannelSelectors().forEach(selector -> {\n+\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n+\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n+\t\t});\n+\t}\n+\n+\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n+\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);\n+\t}\n+\n+\tpublic void select(VirtualChannelSelector selector) {\n+\t\tcurrentSelector = selector;\n+\t\tselectedSubtask = demultiplexersForSubtasks.get(selector.getSubtaskIndex());\n+\t\tif (selectedSubtask == null) {\n+\t\t\tthrow new IllegalStateException(\n+\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n+\t\t}\n+\t\tselectedSubtask.select(selector);\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n+\t\tselectedSubtask.setNextBuffer(buffer);\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n+\t\tdo {\n+\t\t\tRecordDeserializer.DeserializationResult result = selectedSubtask.getNextRecord(deserializationDelegate);\n+\n+\t\t\t// special handling of watermarks and stream status\n+\t\t\tif (result.isFullRecord()) {\n+\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n+\t\t\t\tif (element.isWatermark()) {\n+\t\t\t\t\t// basically, do not emit a watermark if not all virtual channel are past it\n+\t\t\t\t\tlastWatermarks.put(currentSelector, element.asWatermark());\n+\t\t\t\t\tfinal Watermark minWatermark = lastWatermarks.values().stream()\n+\t\t\t\t\t\t.min(Comparator.comparing(Watermark::getTimestamp))\n+\t\t\t\t\t\t.orElseThrow(() -> new IllegalStateException(\"Should always have a min watermark\"));\n+\t\t\t\t\t// at least one virtual channel has no watermark, so don't emit any watermark yet\n+\t\t\t\t\tif (minWatermark.equals(Watermark.UNINITIALIZED)) {\n+\t\t\t\t\t\tcontinue;\n+\t\t\t\t\t}\n+\t\t\t\t\tdeserializationDelegate.setInstance(minWatermark);\n+\t\t\t\t} else if (element.isStreamStatus()) {\n+\t\t\t\t\tstreamStatuses.put(currentSelector, element.asStreamStatus());\n+\t\t\t\t\t// summarize statuses across all virtual channels\n+\t\t\t\t\t// duplicate statuses are filtered in StatusWatermarkValve\n+\t\t\t\t\tif (streamStatuses.values().stream().anyMatch(s -> s.equals(StreamStatus.ACTIVE))) {\n+\t\t\t\t\t\tdeserializationDelegate.setInstance(StreamStatus.ACTIVE);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\treturn result;\n+\t\t\t// loop is only re-executed for suppressed watermark\n+\t\t} while (true);\n+\t}\n+\n+\tpublic void close() {\n+\t\tdemultiplexersForSubtasks.values().forEach(Demultiplexer::close);\n+\t}\n+\n+\tstatic Demultiplexer forChannel(InputChannelInfo info, DemultiplexParameters parameters) {\n+\t\tfinal int[] oldSubtaskIndexes = parameters.channelMapping.getOldSubtaskIndexes(parameters.subtaskIndex);\n+\t\tif (oldSubtaskIndexes.length == 0) {\n+\t\t\treturn new NoDataDemultiplexer(info);\n+\t\t}\n+\t\tfinal int[] oldChannelIndexes = parameters.channelMapping.getChannelMapping(info.getGateIdx())\n+\t\t\t.getOldChannelIndexes(info.getInputChannelIdx());\n+\t\tif (oldChannelIndexes.length == 0) {\n+\t\t\treturn new NoDataDemultiplexer(info);\n+\t\t}\n+\t\tint totalChannels = oldSubtaskIndexes.length * oldChannelIndexes.length;\n+\t\tMap<Integer, ChannelDemultiplexer> demultiplexersForSubtasks = Arrays.stream(oldSubtaskIndexes).boxed()\n+\t\t\t.collect(Collectors.toMap(\n+\t\t\t\tFunction.identity(),\n+\t\t\t\toldSubtaskIndex -> ChannelDemultiplexer.forChannel(oldSubtaskIndex, info, parameters, totalChannels)\n+\t\t\t));\n+\t\treturn new SubtaskDemultiplexer(demultiplexersForSubtasks, totalChannels);\n+\t}\n+\n+\t@Override\n+\tpublic String toString() {\n+\t\treturn \"SubtaskDemultiplexer{\" +\n+\t\t\t\"demultiplexersForSubtasks=\" + demultiplexersForSubtasks +\n+\t\t\t'}';\n+\t}\n+}\n+\n+/**\n+ * Demultiplexes buffers on channel-level.\n+ *\n+ * <p>Example: If the upstream task has been downscaled from 2 to 1. Then, old channels 0 and 1 are both\n+ * processed over new channel 0. So this channel demultiplexer has two {@link #recordDeserializersForChannels} associated\n+ * with the respective old channels.\n+ *\n+ * <p>For all non-unique mappings of new channels to old channels (see\n+ * {@link org.apache.flink.runtime.io.network.api.writer.SubtaskStateMapper} for more details), a filter\n+ * verifies if the restored record should be indeed processed by this subtask or if it should be filtered out and\n+ * be processed at a different subtask.\n+ */\n+class ChannelDemultiplexer implements Demultiplexer {\n+\tprivate final Map<Integer, RecordDeserializer<DeserializationDelegate<StreamElement>>> recordDeserializersForChannels;\n+\n+\tprivate static final Predicate<StreamRecord> NO_FILTER = record -> true;\n+\n+\tprivate final Map<Integer, Predicate<StreamRecord>> filters;\n+\n+\tprivate final int subtaskIndex;\n+\n+\t@Nullable\n+\tprivate RecordDeserializer<DeserializationDelegate<StreamElement>> selectedChannel;\n+\n+\tint selectedChannelIndex;\n+\n+\tChannelDemultiplexer(\n+\t\t\tint subtaskIndex,\n+\t\t\tMap<Integer, Predicate<StreamRecord>> oldChannelsWithFilters,\n+\t\t\tDemultiplexParameters parameters,\n+\t\t\tint totalChannels) {\n+\t\tthis.subtaskIndex = subtaskIndex;\n+\t\tthis.filters = oldChannelsWithFilters;\n+\t\trecordDeserializersForChannels = Maps.newHashMapWithExpectedSize(oldChannelsWithFilters.size());\n+\t\tfor (final Integer oldChannel : oldChannelsWithFilters.keySet()) {\n+\t\t\trecordDeserializersForChannels.put(oldChannel,\n+\t\t\t\tnew SpillingAdaptiveSpanningRecordDeserializer<>(parameters.ioManager.getSpillingDirectoriesPaths(),\n+\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_THRESHOLD_FOR_SPILLING / totalChannels,\n+\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_FILE_BUFFER_SIZE / totalChannels));\n+\t\t}\n+\n+\t\trecordDeserializersForChannels.entrySet().stream().findFirst().ifPresent(firstEntry -> {\n+\t\t\tselectedChannel = firstEntry.getValue();\n+\t\t\tselectedChannelIndex = firstEntry.getKey();\n+\t\t});\n+\t}\n+\n+\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n+\t\treturn recordDeserializersForChannels.keySet().stream()\n+\t\t\t.map(channelIndex -> new VirtualChannelSelector(subtaskIndex, channelIndex));\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n+\t\tdo {\n+\t\t\tfinal RecordDeserializer.DeserializationResult result = selectedChannel.getNextRecord(deserializationDelegate);\n+\n+\t\t\tif (result.isBufferConsumed()) {\n+\t\t\t\tselectedChannel.getCurrentBuffer().recycleBuffer();\n+\t\t\t}\n+\t\t\tif (result.isFullRecord()) {\n+\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n+\t\t\t\tif (element.isRecord() && !filters.get(selectedChannelIndex).test(element.asRecord())) {\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\treturn result;\n+\t\t\t// loop is re-executed for filtered full records.\n+\t\t} while (true);\n+\t}\n+\n+\tpublic void select(VirtualChannelSelector selector) {\n+\t\tselectedChannelIndex = selector.getChannelIndex();\n+\t\tselectedChannel = recordDeserializersForChannels.get(selectedChannelIndex);\n+\t\tif (selectedChannel == null) {\n+\t\t\tthrow new IllegalStateException(\n+\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n+\t\tselectedChannel.setNextBuffer(buffer);\n+\t}\n+\n+\tpublic void close() {\n+\t\tfor (RecordDeserializer<DeserializationDelegate<StreamElement>> deserializer :\n+\t\t\trecordDeserializersForChannels.values()) {\n+\t\t\t// recycle buffers and clear the deserializer.\n+\t\t\tBuffer buffer = deserializer.getCurrentBuffer();\n+\t\t\tif (buffer != null && !buffer.isRecycled()) {\n+\t\t\t\tbuffer.recycleBuffer();\n+\t\t\t}\n+\t\t\tdeserializer.clear();\n+\t\t}\n+\t}\n+\n+\tstatic ChannelDemultiplexer forChannel(\n+\t\t\tint subtaskIndex,\n+\t\t\tInputChannelInfo channelInfo,\n+\t\t\tDemultiplexParameters parameters,\n+\t\t\tint totalChannels) {\n+\t\tfinal InflightDataRescalingDescriptor mapping = parameters.channelMapping;\n+\t\tfinal RescaledChannelsMapping rescaledChannelsMapping =\n+\t\t\tmapping.getChannelMapping(channelInfo.getGateIdx());\n+\t\tfinal int[] oldChannels = rescaledChannelsMapping.getOldChannelIndexes(channelInfo.getInputChannelIdx());\n+\n+\t\tfinal Map<Integer, Predicate<StreamRecord>> oldChannelsWithFilters =\n+\t\t\tArrays.stream(oldChannels).boxed()\n+\t\t\t\t.collect(Collectors.toMap(\n+\t\t\t\t\tFunction.identity(),\n+\t\t\t\t\toldChannel -> getFilterForChannel(channelInfo, parameters, rescaledChannelsMapping, oldChannel)));\n+\n+\t\treturn new ChannelDemultiplexer(\n+\t\t\tsubtaskIndex,\n+\t\t\toldChannelsWithFilters,\n+\t\t\tparameters,\n+\t\t\ttotalChannels);\n+\t}\n+\n+\tprivate static Predicate<StreamRecord> getFilterForChannel(\n+\t\t\tInputChannelInfo channelInfo,\n+\t\t\tDemultiplexParameters parameters,\n+\t\t\tRescaledChannelsMapping rescaledChannelsMapping,\n+\t\t\tInteger oldChannel) {\n+\t\treturn rescaledChannelsMapping.getNewChannelIndexes(oldChannel).length <= 1 ?\n+\t\t\tNO_FILTER :\n+\t\t\tcreateFilter(channelInfo, parameters);\n+\t}\n+\n+\tprivate static Predicate<StreamRecord> createFilter(InputChannelInfo channelInfo, DemultiplexParameters parameters) {\n+\t\tfinal StreamPartitioner partitioner = parameters.gatePartitionerRetriever.apply(channelInfo.getGateIdx());\n+\t\tfinal int inputChannelIdx = channelInfo.getInputChannelIdx();\n+\t\tfinal SerializationDelegate<StreamRecord> delegate = parameters.delegate;\n+\t\tpartitioner.setup(parameters.numberOfChannels);\n+\t\tif (partitioner instanceof ConfigurableStreamPartitioner) {\n+\t\t\t((ConfigurableStreamPartitioner) partitioner).configure(KeyGroupRangeAssignment.UPPER_BOUND_MAX_PARALLELISM);\n+\t\t}\n+\t\treturn streamRecord -> {\n+\t\t\tdelegate.setInstance(streamRecord);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 391}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTIyNjkwMw==", "bodyText": "Since it's only used for the specific call inside the same thread it should be safe. However, it's cheap enough to create for each filter and it's probably much easier to reason about, so I changed it as you suggested.", "url": "https://github.com/apache/flink/pull/13845#discussion_r519226903", "createdAt": "2020-11-07T22:23:28Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "diffHunk": "@@ -0,0 +1,402 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+/**\n+ * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n+ * non-recovery hotpath, this interface is not extending RecordDeserializer.\n+ */\n+interface Demultiplexer extends AutoCloseable {\n+\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n+\n+\tvoid setNextBuffer(Buffer buffer) throws IOException;\n+\n+\tvoid select(VirtualChannelSelector event);\n+\n+\t@Override\n+\tvoid close();\n+}\n+\n+class NoDataDemultiplexer implements Demultiplexer {\n+\tprivate final InputChannelInfo channelInfo;\n+\n+\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n+\t\tthis.channelInfo = channelInfo;\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void select(VirtualChannelSelector event) {\n+\t\tthrow getException();\n+\t}\n+\n+\tprivate IllegalStateException getException() {\n+\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t}\n+}\n+\n+/**\n+ * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n+ */\n+class DemultiplexParameters {\n+\tfinal IOManager ioManager;\n+\tfinal InflightDataRescalingDescriptor channelMapping;\n+\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n+\tfinal SerializationDelegate<StreamRecord> delegate;\n+\tfinal int numberOfChannels;\n+\tfinal int subtaskIndex;\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tDemultiplexParameters(\n+\t\t\tTypeSerializer<?> inputSerializer,\n+\t\t\tIOManager ioManager,\n+\t\t\tInflightDataRescalingDescriptor channelMapping,\n+\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n+\t\t\tint numberOfChannels,\n+\t\t\tint subtaskIndex) {\n+\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n+\t\tthis.ioManager = ioManager;\n+\t\tthis.channelMapping = channelMapping;\n+\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n+\t\tthis.numberOfChannels = numberOfChannels;\n+\t\tthis.subtaskIndex = subtaskIndex;\n+\t}\n+}\n+\n+/**\n+ * Demultiplexes buffers on subtask-level.\n+ *\n+ * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n+ * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n+ * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n+ *\n+ * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n+ * statuses of the (nested) virtual channels.\n+ */\n+class SubtaskDemultiplexer implements Demultiplexer {\n+\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n+\n+\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n+\n+\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n+\n+\tprivate VirtualChannelSelector currentSelector;\n+\n+\tprivate ChannelDemultiplexer selectedSubtask;\n+\n+\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n+\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n+\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n+\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n+\t\tselectedSubtask = defaultSelection.getValue();\n+\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n+\t\t\tselectedSubtask.selectedChannelIndex);\n+\n+\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n+\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tgetChannelSelectors().forEach(selector -> {\n+\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n+\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n+\t\t});\n+\t}\n+\n+\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n+\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);\n+\t}\n+\n+\tpublic void select(VirtualChannelSelector selector) {\n+\t\tcurrentSelector = selector;\n+\t\tselectedSubtask = demultiplexersForSubtasks.get(selector.getSubtaskIndex());\n+\t\tif (selectedSubtask == null) {\n+\t\t\tthrow new IllegalStateException(\n+\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n+\t\t}\n+\t\tselectedSubtask.select(selector);\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n+\t\tselectedSubtask.setNextBuffer(buffer);\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n+\t\tdo {\n+\t\t\tRecordDeserializer.DeserializationResult result = selectedSubtask.getNextRecord(deserializationDelegate);\n+\n+\t\t\t// special handling of watermarks and stream status\n+\t\t\tif (result.isFullRecord()) {\n+\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n+\t\t\t\tif (element.isWatermark()) {\n+\t\t\t\t\t// basically, do not emit a watermark if not all virtual channel are past it\n+\t\t\t\t\tlastWatermarks.put(currentSelector, element.asWatermark());\n+\t\t\t\t\tfinal Watermark minWatermark = lastWatermarks.values().stream()\n+\t\t\t\t\t\t.min(Comparator.comparing(Watermark::getTimestamp))\n+\t\t\t\t\t\t.orElseThrow(() -> new IllegalStateException(\"Should always have a min watermark\"));\n+\t\t\t\t\t// at least one virtual channel has no watermark, so don't emit any watermark yet\n+\t\t\t\t\tif (minWatermark.equals(Watermark.UNINITIALIZED)) {\n+\t\t\t\t\t\tcontinue;\n+\t\t\t\t\t}\n+\t\t\t\t\tdeserializationDelegate.setInstance(minWatermark);\n+\t\t\t\t} else if (element.isStreamStatus()) {\n+\t\t\t\t\tstreamStatuses.put(currentSelector, element.asStreamStatus());\n+\t\t\t\t\t// summarize statuses across all virtual channels\n+\t\t\t\t\t// duplicate statuses are filtered in StatusWatermarkValve\n+\t\t\t\t\tif (streamStatuses.values().stream().anyMatch(s -> s.equals(StreamStatus.ACTIVE))) {\n+\t\t\t\t\t\tdeserializationDelegate.setInstance(StreamStatus.ACTIVE);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\treturn result;\n+\t\t\t// loop is only re-executed for suppressed watermark\n+\t\t} while (true);\n+\t}\n+\n+\tpublic void close() {\n+\t\tdemultiplexersForSubtasks.values().forEach(Demultiplexer::close);\n+\t}\n+\n+\tstatic Demultiplexer forChannel(InputChannelInfo info, DemultiplexParameters parameters) {\n+\t\tfinal int[] oldSubtaskIndexes = parameters.channelMapping.getOldSubtaskIndexes(parameters.subtaskIndex);\n+\t\tif (oldSubtaskIndexes.length == 0) {\n+\t\t\treturn new NoDataDemultiplexer(info);\n+\t\t}\n+\t\tfinal int[] oldChannelIndexes = parameters.channelMapping.getChannelMapping(info.getGateIdx())\n+\t\t\t.getOldChannelIndexes(info.getInputChannelIdx());\n+\t\tif (oldChannelIndexes.length == 0) {\n+\t\t\treturn new NoDataDemultiplexer(info);\n+\t\t}\n+\t\tint totalChannels = oldSubtaskIndexes.length * oldChannelIndexes.length;\n+\t\tMap<Integer, ChannelDemultiplexer> demultiplexersForSubtasks = Arrays.stream(oldSubtaskIndexes).boxed()\n+\t\t\t.collect(Collectors.toMap(\n+\t\t\t\tFunction.identity(),\n+\t\t\t\toldSubtaskIndex -> ChannelDemultiplexer.forChannel(oldSubtaskIndex, info, parameters, totalChannels)\n+\t\t\t));\n+\t\treturn new SubtaskDemultiplexer(demultiplexersForSubtasks, totalChannels);\n+\t}\n+\n+\t@Override\n+\tpublic String toString() {\n+\t\treturn \"SubtaskDemultiplexer{\" +\n+\t\t\t\"demultiplexersForSubtasks=\" + demultiplexersForSubtasks +\n+\t\t\t'}';\n+\t}\n+}\n+\n+/**\n+ * Demultiplexes buffers on channel-level.\n+ *\n+ * <p>Example: If the upstream task has been downscaled from 2 to 1. Then, old channels 0 and 1 are both\n+ * processed over new channel 0. So this channel demultiplexer has two {@link #recordDeserializersForChannels} associated\n+ * with the respective old channels.\n+ *\n+ * <p>For all non-unique mappings of new channels to old channels (see\n+ * {@link org.apache.flink.runtime.io.network.api.writer.SubtaskStateMapper} for more details), a filter\n+ * verifies if the restored record should be indeed processed by this subtask or if it should be filtered out and\n+ * be processed at a different subtask.\n+ */\n+class ChannelDemultiplexer implements Demultiplexer {\n+\tprivate final Map<Integer, RecordDeserializer<DeserializationDelegate<StreamElement>>> recordDeserializersForChannels;\n+\n+\tprivate static final Predicate<StreamRecord> NO_FILTER = record -> true;\n+\n+\tprivate final Map<Integer, Predicate<StreamRecord>> filters;\n+\n+\tprivate final int subtaskIndex;\n+\n+\t@Nullable\n+\tprivate RecordDeserializer<DeserializationDelegate<StreamElement>> selectedChannel;\n+\n+\tint selectedChannelIndex;\n+\n+\tChannelDemultiplexer(\n+\t\t\tint subtaskIndex,\n+\t\t\tMap<Integer, Predicate<StreamRecord>> oldChannelsWithFilters,\n+\t\t\tDemultiplexParameters parameters,\n+\t\t\tint totalChannels) {\n+\t\tthis.subtaskIndex = subtaskIndex;\n+\t\tthis.filters = oldChannelsWithFilters;\n+\t\trecordDeserializersForChannels = Maps.newHashMapWithExpectedSize(oldChannelsWithFilters.size());\n+\t\tfor (final Integer oldChannel : oldChannelsWithFilters.keySet()) {\n+\t\t\trecordDeserializersForChannels.put(oldChannel,\n+\t\t\t\tnew SpillingAdaptiveSpanningRecordDeserializer<>(parameters.ioManager.getSpillingDirectoriesPaths(),\n+\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_THRESHOLD_FOR_SPILLING / totalChannels,\n+\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_FILE_BUFFER_SIZE / totalChannels));\n+\t\t}\n+\n+\t\trecordDeserializersForChannels.entrySet().stream().findFirst().ifPresent(firstEntry -> {\n+\t\t\tselectedChannel = firstEntry.getValue();\n+\t\t\tselectedChannelIndex = firstEntry.getKey();\n+\t\t});\n+\t}\n+\n+\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n+\t\treturn recordDeserializersForChannels.keySet().stream()\n+\t\t\t.map(channelIndex -> new VirtualChannelSelector(subtaskIndex, channelIndex));\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n+\t\tdo {\n+\t\t\tfinal RecordDeserializer.DeserializationResult result = selectedChannel.getNextRecord(deserializationDelegate);\n+\n+\t\t\tif (result.isBufferConsumed()) {\n+\t\t\t\tselectedChannel.getCurrentBuffer().recycleBuffer();\n+\t\t\t}\n+\t\t\tif (result.isFullRecord()) {\n+\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n+\t\t\t\tif (element.isRecord() && !filters.get(selectedChannelIndex).test(element.asRecord())) {\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\treturn result;\n+\t\t\t// loop is re-executed for filtered full records.\n+\t\t} while (true);\n+\t}\n+\n+\tpublic void select(VirtualChannelSelector selector) {\n+\t\tselectedChannelIndex = selector.getChannelIndex();\n+\t\tselectedChannel = recordDeserializersForChannels.get(selectedChannelIndex);\n+\t\tif (selectedChannel == null) {\n+\t\t\tthrow new IllegalStateException(\n+\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n+\t\tselectedChannel.setNextBuffer(buffer);\n+\t}\n+\n+\tpublic void close() {\n+\t\tfor (RecordDeserializer<DeserializationDelegate<StreamElement>> deserializer :\n+\t\t\trecordDeserializersForChannels.values()) {\n+\t\t\t// recycle buffers and clear the deserializer.\n+\t\t\tBuffer buffer = deserializer.getCurrentBuffer();\n+\t\t\tif (buffer != null && !buffer.isRecycled()) {\n+\t\t\t\tbuffer.recycleBuffer();\n+\t\t\t}\n+\t\t\tdeserializer.clear();\n+\t\t}\n+\t}\n+\n+\tstatic ChannelDemultiplexer forChannel(\n+\t\t\tint subtaskIndex,\n+\t\t\tInputChannelInfo channelInfo,\n+\t\t\tDemultiplexParameters parameters,\n+\t\t\tint totalChannels) {\n+\t\tfinal InflightDataRescalingDescriptor mapping = parameters.channelMapping;\n+\t\tfinal RescaledChannelsMapping rescaledChannelsMapping =\n+\t\t\tmapping.getChannelMapping(channelInfo.getGateIdx());\n+\t\tfinal int[] oldChannels = rescaledChannelsMapping.getOldChannelIndexes(channelInfo.getInputChannelIdx());\n+\n+\t\tfinal Map<Integer, Predicate<StreamRecord>> oldChannelsWithFilters =\n+\t\t\tArrays.stream(oldChannels).boxed()\n+\t\t\t\t.collect(Collectors.toMap(\n+\t\t\t\t\tFunction.identity(),\n+\t\t\t\t\toldChannel -> getFilterForChannel(channelInfo, parameters, rescaledChannelsMapping, oldChannel)));\n+\n+\t\treturn new ChannelDemultiplexer(\n+\t\t\tsubtaskIndex,\n+\t\t\toldChannelsWithFilters,\n+\t\t\tparameters,\n+\t\t\ttotalChannels);\n+\t}\n+\n+\tprivate static Predicate<StreamRecord> getFilterForChannel(\n+\t\t\tInputChannelInfo channelInfo,\n+\t\t\tDemultiplexParameters parameters,\n+\t\t\tRescaledChannelsMapping rescaledChannelsMapping,\n+\t\t\tInteger oldChannel) {\n+\t\treturn rescaledChannelsMapping.getNewChannelIndexes(oldChannel).length <= 1 ?\n+\t\t\tNO_FILTER :\n+\t\t\tcreateFilter(channelInfo, parameters);\n+\t}\n+\n+\tprivate static Predicate<StreamRecord> createFilter(InputChannelInfo channelInfo, DemultiplexParameters parameters) {\n+\t\tfinal StreamPartitioner partitioner = parameters.gatePartitionerRetriever.apply(channelInfo.getGateIdx());\n+\t\tfinal int inputChannelIdx = channelInfo.getInputChannelIdx();\n+\t\tfinal SerializationDelegate<StreamRecord> delegate = parameters.delegate;\n+\t\tpartitioner.setup(parameters.numberOfChannels);\n+\t\tif (partitioner instanceof ConfigurableStreamPartitioner) {\n+\t\t\t((ConfigurableStreamPartitioner) partitioner).configure(KeyGroupRangeAssignment.UPPER_BOUND_MAX_PARALLELISM);\n+\t\t}\n+\t\treturn streamRecord -> {\n+\t\t\tdelegate.setInstance(streamRecord);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2NDYxMQ=="}, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 391}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI1NDE4Nzc0OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QxMDo1NzoxOFrOHvHUFQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QyMjoyOTowNVrOHvLIFA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2NDk0OQ==", "bodyText": "Shouldn't it be old DOP (not UPPER_BOUND_MAX_PARALLELISM)?", "url": "https://github.com/apache/flink/pull/13845#discussion_r519164949", "createdAt": "2020-11-07T10:57:18Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "diffHunk": "@@ -0,0 +1,402 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+/**\n+ * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n+ * non-recovery hotpath, this interface is not extending RecordDeserializer.\n+ */\n+interface Demultiplexer extends AutoCloseable {\n+\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n+\n+\tvoid setNextBuffer(Buffer buffer) throws IOException;\n+\n+\tvoid select(VirtualChannelSelector event);\n+\n+\t@Override\n+\tvoid close();\n+}\n+\n+class NoDataDemultiplexer implements Demultiplexer {\n+\tprivate final InputChannelInfo channelInfo;\n+\n+\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n+\t\tthis.channelInfo = channelInfo;\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void select(VirtualChannelSelector event) {\n+\t\tthrow getException();\n+\t}\n+\n+\tprivate IllegalStateException getException() {\n+\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t}\n+}\n+\n+/**\n+ * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n+ */\n+class DemultiplexParameters {\n+\tfinal IOManager ioManager;\n+\tfinal InflightDataRescalingDescriptor channelMapping;\n+\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n+\tfinal SerializationDelegate<StreamRecord> delegate;\n+\tfinal int numberOfChannels;\n+\tfinal int subtaskIndex;\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tDemultiplexParameters(\n+\t\t\tTypeSerializer<?> inputSerializer,\n+\t\t\tIOManager ioManager,\n+\t\t\tInflightDataRescalingDescriptor channelMapping,\n+\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n+\t\t\tint numberOfChannels,\n+\t\t\tint subtaskIndex) {\n+\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n+\t\tthis.ioManager = ioManager;\n+\t\tthis.channelMapping = channelMapping;\n+\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n+\t\tthis.numberOfChannels = numberOfChannels;\n+\t\tthis.subtaskIndex = subtaskIndex;\n+\t}\n+}\n+\n+/**\n+ * Demultiplexes buffers on subtask-level.\n+ *\n+ * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n+ * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n+ * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n+ *\n+ * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n+ * statuses of the (nested) virtual channels.\n+ */\n+class SubtaskDemultiplexer implements Demultiplexer {\n+\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n+\n+\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n+\n+\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n+\n+\tprivate VirtualChannelSelector currentSelector;\n+\n+\tprivate ChannelDemultiplexer selectedSubtask;\n+\n+\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n+\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n+\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n+\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n+\t\tselectedSubtask = defaultSelection.getValue();\n+\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n+\t\t\tselectedSubtask.selectedChannelIndex);\n+\n+\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n+\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tgetChannelSelectors().forEach(selector -> {\n+\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n+\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n+\t\t});\n+\t}\n+\n+\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n+\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);\n+\t}\n+\n+\tpublic void select(VirtualChannelSelector selector) {\n+\t\tcurrentSelector = selector;\n+\t\tselectedSubtask = demultiplexersForSubtasks.get(selector.getSubtaskIndex());\n+\t\tif (selectedSubtask == null) {\n+\t\t\tthrow new IllegalStateException(\n+\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n+\t\t}\n+\t\tselectedSubtask.select(selector);\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n+\t\tselectedSubtask.setNextBuffer(buffer);\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n+\t\tdo {\n+\t\t\tRecordDeserializer.DeserializationResult result = selectedSubtask.getNextRecord(deserializationDelegate);\n+\n+\t\t\t// special handling of watermarks and stream status\n+\t\t\tif (result.isFullRecord()) {\n+\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n+\t\t\t\tif (element.isWatermark()) {\n+\t\t\t\t\t// basically, do not emit a watermark if not all virtual channel are past it\n+\t\t\t\t\tlastWatermarks.put(currentSelector, element.asWatermark());\n+\t\t\t\t\tfinal Watermark minWatermark = lastWatermarks.values().stream()\n+\t\t\t\t\t\t.min(Comparator.comparing(Watermark::getTimestamp))\n+\t\t\t\t\t\t.orElseThrow(() -> new IllegalStateException(\"Should always have a min watermark\"));\n+\t\t\t\t\t// at least one virtual channel has no watermark, so don't emit any watermark yet\n+\t\t\t\t\tif (minWatermark.equals(Watermark.UNINITIALIZED)) {\n+\t\t\t\t\t\tcontinue;\n+\t\t\t\t\t}\n+\t\t\t\t\tdeserializationDelegate.setInstance(minWatermark);\n+\t\t\t\t} else if (element.isStreamStatus()) {\n+\t\t\t\t\tstreamStatuses.put(currentSelector, element.asStreamStatus());\n+\t\t\t\t\t// summarize statuses across all virtual channels\n+\t\t\t\t\t// duplicate statuses are filtered in StatusWatermarkValve\n+\t\t\t\t\tif (streamStatuses.values().stream().anyMatch(s -> s.equals(StreamStatus.ACTIVE))) {\n+\t\t\t\t\t\tdeserializationDelegate.setInstance(StreamStatus.ACTIVE);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\treturn result;\n+\t\t\t// loop is only re-executed for suppressed watermark\n+\t\t} while (true);\n+\t}\n+\n+\tpublic void close() {\n+\t\tdemultiplexersForSubtasks.values().forEach(Demultiplexer::close);\n+\t}\n+\n+\tstatic Demultiplexer forChannel(InputChannelInfo info, DemultiplexParameters parameters) {\n+\t\tfinal int[] oldSubtaskIndexes = parameters.channelMapping.getOldSubtaskIndexes(parameters.subtaskIndex);\n+\t\tif (oldSubtaskIndexes.length == 0) {\n+\t\t\treturn new NoDataDemultiplexer(info);\n+\t\t}\n+\t\tfinal int[] oldChannelIndexes = parameters.channelMapping.getChannelMapping(info.getGateIdx())\n+\t\t\t.getOldChannelIndexes(info.getInputChannelIdx());\n+\t\tif (oldChannelIndexes.length == 0) {\n+\t\t\treturn new NoDataDemultiplexer(info);\n+\t\t}\n+\t\tint totalChannels = oldSubtaskIndexes.length * oldChannelIndexes.length;\n+\t\tMap<Integer, ChannelDemultiplexer> demultiplexersForSubtasks = Arrays.stream(oldSubtaskIndexes).boxed()\n+\t\t\t.collect(Collectors.toMap(\n+\t\t\t\tFunction.identity(),\n+\t\t\t\toldSubtaskIndex -> ChannelDemultiplexer.forChannel(oldSubtaskIndex, info, parameters, totalChannels)\n+\t\t\t));\n+\t\treturn new SubtaskDemultiplexer(demultiplexersForSubtasks, totalChannels);\n+\t}\n+\n+\t@Override\n+\tpublic String toString() {\n+\t\treturn \"SubtaskDemultiplexer{\" +\n+\t\t\t\"demultiplexersForSubtasks=\" + demultiplexersForSubtasks +\n+\t\t\t'}';\n+\t}\n+}\n+\n+/**\n+ * Demultiplexes buffers on channel-level.\n+ *\n+ * <p>Example: If the upstream task has been downscaled from 2 to 1. Then, old channels 0 and 1 are both\n+ * processed over new channel 0. So this channel demultiplexer has two {@link #recordDeserializersForChannels} associated\n+ * with the respective old channels.\n+ *\n+ * <p>For all non-unique mappings of new channels to old channels (see\n+ * {@link org.apache.flink.runtime.io.network.api.writer.SubtaskStateMapper} for more details), a filter\n+ * verifies if the restored record should be indeed processed by this subtask or if it should be filtered out and\n+ * be processed at a different subtask.\n+ */\n+class ChannelDemultiplexer implements Demultiplexer {\n+\tprivate final Map<Integer, RecordDeserializer<DeserializationDelegate<StreamElement>>> recordDeserializersForChannels;\n+\n+\tprivate static final Predicate<StreamRecord> NO_FILTER = record -> true;\n+\n+\tprivate final Map<Integer, Predicate<StreamRecord>> filters;\n+\n+\tprivate final int subtaskIndex;\n+\n+\t@Nullable\n+\tprivate RecordDeserializer<DeserializationDelegate<StreamElement>> selectedChannel;\n+\n+\tint selectedChannelIndex;\n+\n+\tChannelDemultiplexer(\n+\t\t\tint subtaskIndex,\n+\t\t\tMap<Integer, Predicate<StreamRecord>> oldChannelsWithFilters,\n+\t\t\tDemultiplexParameters parameters,\n+\t\t\tint totalChannels) {\n+\t\tthis.subtaskIndex = subtaskIndex;\n+\t\tthis.filters = oldChannelsWithFilters;\n+\t\trecordDeserializersForChannels = Maps.newHashMapWithExpectedSize(oldChannelsWithFilters.size());\n+\t\tfor (final Integer oldChannel : oldChannelsWithFilters.keySet()) {\n+\t\t\trecordDeserializersForChannels.put(oldChannel,\n+\t\t\t\tnew SpillingAdaptiveSpanningRecordDeserializer<>(parameters.ioManager.getSpillingDirectoriesPaths(),\n+\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_THRESHOLD_FOR_SPILLING / totalChannels,\n+\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_FILE_BUFFER_SIZE / totalChannels));\n+\t\t}\n+\n+\t\trecordDeserializersForChannels.entrySet().stream().findFirst().ifPresent(firstEntry -> {\n+\t\t\tselectedChannel = firstEntry.getValue();\n+\t\t\tselectedChannelIndex = firstEntry.getKey();\n+\t\t});\n+\t}\n+\n+\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n+\t\treturn recordDeserializersForChannels.keySet().stream()\n+\t\t\t.map(channelIndex -> new VirtualChannelSelector(subtaskIndex, channelIndex));\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n+\t\tdo {\n+\t\t\tfinal RecordDeserializer.DeserializationResult result = selectedChannel.getNextRecord(deserializationDelegate);\n+\n+\t\t\tif (result.isBufferConsumed()) {\n+\t\t\t\tselectedChannel.getCurrentBuffer().recycleBuffer();\n+\t\t\t}\n+\t\t\tif (result.isFullRecord()) {\n+\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n+\t\t\t\tif (element.isRecord() && !filters.get(selectedChannelIndex).test(element.asRecord())) {\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\treturn result;\n+\t\t\t// loop is re-executed for filtered full records.\n+\t\t} while (true);\n+\t}\n+\n+\tpublic void select(VirtualChannelSelector selector) {\n+\t\tselectedChannelIndex = selector.getChannelIndex();\n+\t\tselectedChannel = recordDeserializersForChannels.get(selectedChannelIndex);\n+\t\tif (selectedChannel == null) {\n+\t\t\tthrow new IllegalStateException(\n+\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n+\t\tselectedChannel.setNextBuffer(buffer);\n+\t}\n+\n+\tpublic void close() {\n+\t\tfor (RecordDeserializer<DeserializationDelegate<StreamElement>> deserializer :\n+\t\t\trecordDeserializersForChannels.values()) {\n+\t\t\t// recycle buffers and clear the deserializer.\n+\t\t\tBuffer buffer = deserializer.getCurrentBuffer();\n+\t\t\tif (buffer != null && !buffer.isRecycled()) {\n+\t\t\t\tbuffer.recycleBuffer();\n+\t\t\t}\n+\t\t\tdeserializer.clear();\n+\t\t}\n+\t}\n+\n+\tstatic ChannelDemultiplexer forChannel(\n+\t\t\tint subtaskIndex,\n+\t\t\tInputChannelInfo channelInfo,\n+\t\t\tDemultiplexParameters parameters,\n+\t\t\tint totalChannels) {\n+\t\tfinal InflightDataRescalingDescriptor mapping = parameters.channelMapping;\n+\t\tfinal RescaledChannelsMapping rescaledChannelsMapping =\n+\t\t\tmapping.getChannelMapping(channelInfo.getGateIdx());\n+\t\tfinal int[] oldChannels = rescaledChannelsMapping.getOldChannelIndexes(channelInfo.getInputChannelIdx());\n+\n+\t\tfinal Map<Integer, Predicate<StreamRecord>> oldChannelsWithFilters =\n+\t\t\tArrays.stream(oldChannels).boxed()\n+\t\t\t\t.collect(Collectors.toMap(\n+\t\t\t\t\tFunction.identity(),\n+\t\t\t\t\toldChannel -> getFilterForChannel(channelInfo, parameters, rescaledChannelsMapping, oldChannel)));\n+\n+\t\treturn new ChannelDemultiplexer(\n+\t\t\tsubtaskIndex,\n+\t\t\toldChannelsWithFilters,\n+\t\t\tparameters,\n+\t\t\ttotalChannels);\n+\t}\n+\n+\tprivate static Predicate<StreamRecord> getFilterForChannel(\n+\t\t\tInputChannelInfo channelInfo,\n+\t\t\tDemultiplexParameters parameters,\n+\t\t\tRescaledChannelsMapping rescaledChannelsMapping,\n+\t\t\tInteger oldChannel) {\n+\t\treturn rescaledChannelsMapping.getNewChannelIndexes(oldChannel).length <= 1 ?\n+\t\t\tNO_FILTER :\n+\t\t\tcreateFilter(channelInfo, parameters);\n+\t}\n+\n+\tprivate static Predicate<StreamRecord> createFilter(InputChannelInfo channelInfo, DemultiplexParameters parameters) {\n+\t\tfinal StreamPartitioner partitioner = parameters.gatePartitionerRetriever.apply(channelInfo.getGateIdx());\n+\t\tfinal int inputChannelIdx = channelInfo.getInputChannelIdx();\n+\t\tfinal SerializationDelegate<StreamRecord> delegate = parameters.delegate;\n+\t\tpartitioner.setup(parameters.numberOfChannels);\n+\t\tif (partitioner instanceof ConfigurableStreamPartitioner) {\n+\t\t\t((ConfigurableStreamPartitioner) partitioner).configure(KeyGroupRangeAssignment.UPPER_BOUND_MAX_PARALLELISM);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 388}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTIyNzQxMg==", "bodyText": "Don't ask me who came up with the great method names, but configure is only used to set the max parallelism of KeyGroupStreamPartitioner. Only the method setup is used to set the real parallelism but must be the new DOP here.", "url": "https://github.com/apache/flink/pull/13845#discussion_r519227412", "createdAt": "2020-11-07T22:29:05Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "diffHunk": "@@ -0,0 +1,402 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+/**\n+ * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n+ * non-recovery hotpath, this interface is not extending RecordDeserializer.\n+ */\n+interface Demultiplexer extends AutoCloseable {\n+\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n+\n+\tvoid setNextBuffer(Buffer buffer) throws IOException;\n+\n+\tvoid select(VirtualChannelSelector event);\n+\n+\t@Override\n+\tvoid close();\n+}\n+\n+class NoDataDemultiplexer implements Demultiplexer {\n+\tprivate final InputChannelInfo channelInfo;\n+\n+\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n+\t\tthis.channelInfo = channelInfo;\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void select(VirtualChannelSelector event) {\n+\t\tthrow getException();\n+\t}\n+\n+\tprivate IllegalStateException getException() {\n+\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t}\n+}\n+\n+/**\n+ * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n+ */\n+class DemultiplexParameters {\n+\tfinal IOManager ioManager;\n+\tfinal InflightDataRescalingDescriptor channelMapping;\n+\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n+\tfinal SerializationDelegate<StreamRecord> delegate;\n+\tfinal int numberOfChannels;\n+\tfinal int subtaskIndex;\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tDemultiplexParameters(\n+\t\t\tTypeSerializer<?> inputSerializer,\n+\t\t\tIOManager ioManager,\n+\t\t\tInflightDataRescalingDescriptor channelMapping,\n+\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n+\t\t\tint numberOfChannels,\n+\t\t\tint subtaskIndex) {\n+\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n+\t\tthis.ioManager = ioManager;\n+\t\tthis.channelMapping = channelMapping;\n+\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n+\t\tthis.numberOfChannels = numberOfChannels;\n+\t\tthis.subtaskIndex = subtaskIndex;\n+\t}\n+}\n+\n+/**\n+ * Demultiplexes buffers on subtask-level.\n+ *\n+ * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n+ * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n+ * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n+ *\n+ * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n+ * statuses of the (nested) virtual channels.\n+ */\n+class SubtaskDemultiplexer implements Demultiplexer {\n+\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n+\n+\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n+\n+\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n+\n+\tprivate VirtualChannelSelector currentSelector;\n+\n+\tprivate ChannelDemultiplexer selectedSubtask;\n+\n+\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n+\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n+\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n+\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n+\t\tselectedSubtask = defaultSelection.getValue();\n+\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n+\t\t\tselectedSubtask.selectedChannelIndex);\n+\n+\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n+\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tgetChannelSelectors().forEach(selector -> {\n+\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n+\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n+\t\t});\n+\t}\n+\n+\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n+\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);\n+\t}\n+\n+\tpublic void select(VirtualChannelSelector selector) {\n+\t\tcurrentSelector = selector;\n+\t\tselectedSubtask = demultiplexersForSubtasks.get(selector.getSubtaskIndex());\n+\t\tif (selectedSubtask == null) {\n+\t\t\tthrow new IllegalStateException(\n+\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n+\t\t}\n+\t\tselectedSubtask.select(selector);\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n+\t\tselectedSubtask.setNextBuffer(buffer);\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n+\t\tdo {\n+\t\t\tRecordDeserializer.DeserializationResult result = selectedSubtask.getNextRecord(deserializationDelegate);\n+\n+\t\t\t// special handling of watermarks and stream status\n+\t\t\tif (result.isFullRecord()) {\n+\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n+\t\t\t\tif (element.isWatermark()) {\n+\t\t\t\t\t// basically, do not emit a watermark if not all virtual channel are past it\n+\t\t\t\t\tlastWatermarks.put(currentSelector, element.asWatermark());\n+\t\t\t\t\tfinal Watermark minWatermark = lastWatermarks.values().stream()\n+\t\t\t\t\t\t.min(Comparator.comparing(Watermark::getTimestamp))\n+\t\t\t\t\t\t.orElseThrow(() -> new IllegalStateException(\"Should always have a min watermark\"));\n+\t\t\t\t\t// at least one virtual channel has no watermark, so don't emit any watermark yet\n+\t\t\t\t\tif (minWatermark.equals(Watermark.UNINITIALIZED)) {\n+\t\t\t\t\t\tcontinue;\n+\t\t\t\t\t}\n+\t\t\t\t\tdeserializationDelegate.setInstance(minWatermark);\n+\t\t\t\t} else if (element.isStreamStatus()) {\n+\t\t\t\t\tstreamStatuses.put(currentSelector, element.asStreamStatus());\n+\t\t\t\t\t// summarize statuses across all virtual channels\n+\t\t\t\t\t// duplicate statuses are filtered in StatusWatermarkValve\n+\t\t\t\t\tif (streamStatuses.values().stream().anyMatch(s -> s.equals(StreamStatus.ACTIVE))) {\n+\t\t\t\t\t\tdeserializationDelegate.setInstance(StreamStatus.ACTIVE);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\treturn result;\n+\t\t\t// loop is only re-executed for suppressed watermark\n+\t\t} while (true);\n+\t}\n+\n+\tpublic void close() {\n+\t\tdemultiplexersForSubtasks.values().forEach(Demultiplexer::close);\n+\t}\n+\n+\tstatic Demultiplexer forChannel(InputChannelInfo info, DemultiplexParameters parameters) {\n+\t\tfinal int[] oldSubtaskIndexes = parameters.channelMapping.getOldSubtaskIndexes(parameters.subtaskIndex);\n+\t\tif (oldSubtaskIndexes.length == 0) {\n+\t\t\treturn new NoDataDemultiplexer(info);\n+\t\t}\n+\t\tfinal int[] oldChannelIndexes = parameters.channelMapping.getChannelMapping(info.getGateIdx())\n+\t\t\t.getOldChannelIndexes(info.getInputChannelIdx());\n+\t\tif (oldChannelIndexes.length == 0) {\n+\t\t\treturn new NoDataDemultiplexer(info);\n+\t\t}\n+\t\tint totalChannels = oldSubtaskIndexes.length * oldChannelIndexes.length;\n+\t\tMap<Integer, ChannelDemultiplexer> demultiplexersForSubtasks = Arrays.stream(oldSubtaskIndexes).boxed()\n+\t\t\t.collect(Collectors.toMap(\n+\t\t\t\tFunction.identity(),\n+\t\t\t\toldSubtaskIndex -> ChannelDemultiplexer.forChannel(oldSubtaskIndex, info, parameters, totalChannels)\n+\t\t\t));\n+\t\treturn new SubtaskDemultiplexer(demultiplexersForSubtasks, totalChannels);\n+\t}\n+\n+\t@Override\n+\tpublic String toString() {\n+\t\treturn \"SubtaskDemultiplexer{\" +\n+\t\t\t\"demultiplexersForSubtasks=\" + demultiplexersForSubtasks +\n+\t\t\t'}';\n+\t}\n+}\n+\n+/**\n+ * Demultiplexes buffers on channel-level.\n+ *\n+ * <p>Example: If the upstream task has been downscaled from 2 to 1. Then, old channels 0 and 1 are both\n+ * processed over new channel 0. So this channel demultiplexer has two {@link #recordDeserializersForChannels} associated\n+ * with the respective old channels.\n+ *\n+ * <p>For all non-unique mappings of new channels to old channels (see\n+ * {@link org.apache.flink.runtime.io.network.api.writer.SubtaskStateMapper} for more details), a filter\n+ * verifies if the restored record should be indeed processed by this subtask or if it should be filtered out and\n+ * be processed at a different subtask.\n+ */\n+class ChannelDemultiplexer implements Demultiplexer {\n+\tprivate final Map<Integer, RecordDeserializer<DeserializationDelegate<StreamElement>>> recordDeserializersForChannels;\n+\n+\tprivate static final Predicate<StreamRecord> NO_FILTER = record -> true;\n+\n+\tprivate final Map<Integer, Predicate<StreamRecord>> filters;\n+\n+\tprivate final int subtaskIndex;\n+\n+\t@Nullable\n+\tprivate RecordDeserializer<DeserializationDelegate<StreamElement>> selectedChannel;\n+\n+\tint selectedChannelIndex;\n+\n+\tChannelDemultiplexer(\n+\t\t\tint subtaskIndex,\n+\t\t\tMap<Integer, Predicate<StreamRecord>> oldChannelsWithFilters,\n+\t\t\tDemultiplexParameters parameters,\n+\t\t\tint totalChannels) {\n+\t\tthis.subtaskIndex = subtaskIndex;\n+\t\tthis.filters = oldChannelsWithFilters;\n+\t\trecordDeserializersForChannels = Maps.newHashMapWithExpectedSize(oldChannelsWithFilters.size());\n+\t\tfor (final Integer oldChannel : oldChannelsWithFilters.keySet()) {\n+\t\t\trecordDeserializersForChannels.put(oldChannel,\n+\t\t\t\tnew SpillingAdaptiveSpanningRecordDeserializer<>(parameters.ioManager.getSpillingDirectoriesPaths(),\n+\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_THRESHOLD_FOR_SPILLING / totalChannels,\n+\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_FILE_BUFFER_SIZE / totalChannels));\n+\t\t}\n+\n+\t\trecordDeserializersForChannels.entrySet().stream().findFirst().ifPresent(firstEntry -> {\n+\t\t\tselectedChannel = firstEntry.getValue();\n+\t\t\tselectedChannelIndex = firstEntry.getKey();\n+\t\t});\n+\t}\n+\n+\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n+\t\treturn recordDeserializersForChannels.keySet().stream()\n+\t\t\t.map(channelIndex -> new VirtualChannelSelector(subtaskIndex, channelIndex));\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n+\t\tdo {\n+\t\t\tfinal RecordDeserializer.DeserializationResult result = selectedChannel.getNextRecord(deserializationDelegate);\n+\n+\t\t\tif (result.isBufferConsumed()) {\n+\t\t\t\tselectedChannel.getCurrentBuffer().recycleBuffer();\n+\t\t\t}\n+\t\t\tif (result.isFullRecord()) {\n+\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n+\t\t\t\tif (element.isRecord() && !filters.get(selectedChannelIndex).test(element.asRecord())) {\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\treturn result;\n+\t\t\t// loop is re-executed for filtered full records.\n+\t\t} while (true);\n+\t}\n+\n+\tpublic void select(VirtualChannelSelector selector) {\n+\t\tselectedChannelIndex = selector.getChannelIndex();\n+\t\tselectedChannel = recordDeserializersForChannels.get(selectedChannelIndex);\n+\t\tif (selectedChannel == null) {\n+\t\t\tthrow new IllegalStateException(\n+\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n+\t\tselectedChannel.setNextBuffer(buffer);\n+\t}\n+\n+\tpublic void close() {\n+\t\tfor (RecordDeserializer<DeserializationDelegate<StreamElement>> deserializer :\n+\t\t\trecordDeserializersForChannels.values()) {\n+\t\t\t// recycle buffers and clear the deserializer.\n+\t\t\tBuffer buffer = deserializer.getCurrentBuffer();\n+\t\t\tif (buffer != null && !buffer.isRecycled()) {\n+\t\t\t\tbuffer.recycleBuffer();\n+\t\t\t}\n+\t\t\tdeserializer.clear();\n+\t\t}\n+\t}\n+\n+\tstatic ChannelDemultiplexer forChannel(\n+\t\t\tint subtaskIndex,\n+\t\t\tInputChannelInfo channelInfo,\n+\t\t\tDemultiplexParameters parameters,\n+\t\t\tint totalChannels) {\n+\t\tfinal InflightDataRescalingDescriptor mapping = parameters.channelMapping;\n+\t\tfinal RescaledChannelsMapping rescaledChannelsMapping =\n+\t\t\tmapping.getChannelMapping(channelInfo.getGateIdx());\n+\t\tfinal int[] oldChannels = rescaledChannelsMapping.getOldChannelIndexes(channelInfo.getInputChannelIdx());\n+\n+\t\tfinal Map<Integer, Predicate<StreamRecord>> oldChannelsWithFilters =\n+\t\t\tArrays.stream(oldChannels).boxed()\n+\t\t\t\t.collect(Collectors.toMap(\n+\t\t\t\t\tFunction.identity(),\n+\t\t\t\t\toldChannel -> getFilterForChannel(channelInfo, parameters, rescaledChannelsMapping, oldChannel)));\n+\n+\t\treturn new ChannelDemultiplexer(\n+\t\t\tsubtaskIndex,\n+\t\t\toldChannelsWithFilters,\n+\t\t\tparameters,\n+\t\t\ttotalChannels);\n+\t}\n+\n+\tprivate static Predicate<StreamRecord> getFilterForChannel(\n+\t\t\tInputChannelInfo channelInfo,\n+\t\t\tDemultiplexParameters parameters,\n+\t\t\tRescaledChannelsMapping rescaledChannelsMapping,\n+\t\t\tInteger oldChannel) {\n+\t\treturn rescaledChannelsMapping.getNewChannelIndexes(oldChannel).length <= 1 ?\n+\t\t\tNO_FILTER :\n+\t\t\tcreateFilter(channelInfo, parameters);\n+\t}\n+\n+\tprivate static Predicate<StreamRecord> createFilter(InputChannelInfo channelInfo, DemultiplexParameters parameters) {\n+\t\tfinal StreamPartitioner partitioner = parameters.gatePartitionerRetriever.apply(channelInfo.getGateIdx());\n+\t\tfinal int inputChannelIdx = channelInfo.getInputChannelIdx();\n+\t\tfinal SerializationDelegate<StreamRecord> delegate = parameters.delegate;\n+\t\tpartitioner.setup(parameters.numberOfChannels);\n+\t\tif (partitioner instanceof ConfigurableStreamPartitioner) {\n+\t\t\t((ConfigurableStreamPartitioner) partitioner).configure(KeyGroupRangeAssignment.UPPER_BOUND_MAX_PARALLELISM);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2NDk0OQ=="}, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 388}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI1NDE5MTEwOnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/RescalingStreamTaskNetworkInput.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QxMTowMjowMFrOHvHVkQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QyMjozMzozNlrOHvLJ5Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2NTMyOQ==", "bodyText": "Can't we use just Map<InputChannelInfo, Demultiplexer> instead of this map and channelDemultiplexers array?", "url": "https://github.com/apache/flink/pull/13845#discussion_r519165329", "createdAt": "2020-11-07T11:02:00Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/RescalingStreamTaskNetworkInput.java", "diffHunk": "@@ -0,0 +1,283 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.io.InputStatus;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.event.AbstractEvent;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.EndOfPartitionEvent;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer.DeserializationResult;\n+import org.apache.flink.runtime.io.network.partition.consumer.BufferOrEvent;\n+import org.apache.flink.runtime.io.network.partition.consumer.EndOfChannelStateEvent;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.runtime.plugable.NonReusingDeserializationDelegate;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElementSerializer;\n+import org.apache.flink.streaming.runtime.streamstatus.StatusWatermarkValve;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.Function;\n+\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * A {@link StreamTaskNetworkInput} implementation that demultiplexes virtual channels.\n+ *\n+ * <p>The demultiplexing works in two dimensions for the following cases.\n+ * <ul>\n+ *     <li> Subtasks of the current operator have been collapsed in a round-robin fashion.\n+ *     <li> The connected output operator has been rescaled (up and down!) and there is an overlap of channels (mostly\n+ * relevant to keyed exchanges).\n+ * </ul>\n+ * In both cases, records from multiple old channels are received over one new physical channel, which need to\n+ * demultiplex the record to correctly restore spanning records (similar to how StreamTaskNetworkInput works).\n+ *\n+ * <p>Note that when both cases occur at the same time (downscaling of several operators), there is the cross product of\n+ * channels. So if two subtasks are collapsed and two channels overlap from the output side, there is a total of 4\n+ * virtual channels.\n+ */\n+@Internal\n+public final class RescalingStreamTaskNetworkInput<T> implements RecoverableStreamTaskInput<T> {\n+\n+\tprivate final CheckpointedInputGate checkpointedInputGate;\n+\n+\tprivate final DeserializationDelegate<StreamElement> deserializationDelegate;\n+\n+\tprivate final Demultiplexer[] channelDemultiplexers;\n+\n+\t/** Valve that controls how watermarks and stream statuses are forwarded. */\n+\tprivate final StatusWatermarkValve statusWatermarkValve;\n+\n+\tprivate final int inputIndex;\n+\n+\tprivate final Map<InputChannelInfo, Integer> channelIndexes;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTIyNzg3Nw==", "bodyText": "StatusWatermarkValve operators on indexes, so we need this indirection. We should probably refactor that (it's the same in StreamTaskNetworkInput).", "url": "https://github.com/apache/flink/pull/13845#discussion_r519227877", "createdAt": "2020-11-07T22:33:36Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/RescalingStreamTaskNetworkInput.java", "diffHunk": "@@ -0,0 +1,283 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.io.InputStatus;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.event.AbstractEvent;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.EndOfPartitionEvent;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer.DeserializationResult;\n+import org.apache.flink.runtime.io.network.partition.consumer.BufferOrEvent;\n+import org.apache.flink.runtime.io.network.partition.consumer.EndOfChannelStateEvent;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.runtime.plugable.NonReusingDeserializationDelegate;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElementSerializer;\n+import org.apache.flink.streaming.runtime.streamstatus.StatusWatermarkValve;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.Function;\n+\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * A {@link StreamTaskNetworkInput} implementation that demultiplexes virtual channels.\n+ *\n+ * <p>The demultiplexing works in two dimensions for the following cases.\n+ * <ul>\n+ *     <li> Subtasks of the current operator have been collapsed in a round-robin fashion.\n+ *     <li> The connected output operator has been rescaled (up and down!) and there is an overlap of channels (mostly\n+ * relevant to keyed exchanges).\n+ * </ul>\n+ * In both cases, records from multiple old channels are received over one new physical channel, which need to\n+ * demultiplex the record to correctly restore spanning records (similar to how StreamTaskNetworkInput works).\n+ *\n+ * <p>Note that when both cases occur at the same time (downscaling of several operators), there is the cross product of\n+ * channels. So if two subtasks are collapsed and two channels overlap from the output side, there is a total of 4\n+ * virtual channels.\n+ */\n+@Internal\n+public final class RescalingStreamTaskNetworkInput<T> implements RecoverableStreamTaskInput<T> {\n+\n+\tprivate final CheckpointedInputGate checkpointedInputGate;\n+\n+\tprivate final DeserializationDelegate<StreamElement> deserializationDelegate;\n+\n+\tprivate final Demultiplexer[] channelDemultiplexers;\n+\n+\t/** Valve that controls how watermarks and stream statuses are forwarded. */\n+\tprivate final StatusWatermarkValve statusWatermarkValve;\n+\n+\tprivate final int inputIndex;\n+\n+\tprivate final Map<InputChannelInfo, Integer> channelIndexes;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2NTMyOQ=="}, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 83}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI1NDE5MjE5OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QxMTowMzo1MVrOHvHWGA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QyMjo0MTozMVrOHvLNAA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2NTQ2NA==", "bodyText": "According to javadoc above, it's a type of RecordDeserializer, just not explicitly implementing it.\nSo the name DemultiplexingRecordDeserializer would make more sense to me.", "url": "https://github.com/apache/flink/pull/13845#discussion_r519165464", "createdAt": "2020-11-07T11:03:51Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "diffHunk": "@@ -0,0 +1,402 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+/**\n+ * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n+ * non-recovery hotpath, this interface is not extending RecordDeserializer.\n+ */\n+interface Demultiplexer extends AutoCloseable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTIyODY3Mg==", "bodyText": "Good idea. Would it be okay to keep the implementation names as is to avoid super-long names?", "url": "https://github.com/apache/flink/pull/13845#discussion_r519228672", "createdAt": "2020-11-07T22:41:31Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "diffHunk": "@@ -0,0 +1,402 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+/**\n+ * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n+ * non-recovery hotpath, this interface is not extending RecordDeserializer.\n+ */\n+interface Demultiplexer extends AutoCloseable {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2NTQ2NA=="}, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 57}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI1NDIxOTMzOnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/RescalingStreamTaskNetworkInput.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QxMTo0MDo1MlrOHvHihA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QyMjo0NTo1MVrOHvLOeg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2ODY0NA==", "bodyText": "This class duplicates StreamTaskNetworkInput by most part (the same with much less extent goes to Demultiplexer).\nI guess the motivation not to reuse was performance, right?\nHow big was the impact?", "url": "https://github.com/apache/flink/pull/13845#discussion_r519168644", "createdAt": "2020-11-07T11:40:52Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/RescalingStreamTaskNetworkInput.java", "diffHunk": "@@ -0,0 +1,283 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.io.InputStatus;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.event.AbstractEvent;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.EndOfPartitionEvent;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer.DeserializationResult;\n+import org.apache.flink.runtime.io.network.partition.consumer.BufferOrEvent;\n+import org.apache.flink.runtime.io.network.partition.consumer.EndOfChannelStateEvent;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.runtime.plugable.NonReusingDeserializationDelegate;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElementSerializer;\n+import org.apache.flink.streaming.runtime.streamstatus.StatusWatermarkValve;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.Function;\n+\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * A {@link StreamTaskNetworkInput} implementation that demultiplexes virtual channels.\n+ *\n+ * <p>The demultiplexing works in two dimensions for the following cases.\n+ * <ul>\n+ *     <li> Subtasks of the current operator have been collapsed in a round-robin fashion.\n+ *     <li> The connected output operator has been rescaled (up and down!) and there is an overlap of channels (mostly\n+ * relevant to keyed exchanges).\n+ * </ul>\n+ * In both cases, records from multiple old channels are received over one new physical channel, which need to\n+ * demultiplex the record to correctly restore spanning records (similar to how StreamTaskNetworkInput works).\n+ *\n+ * <p>Note that when both cases occur at the same time (downscaling of several operators), there is the cross product of\n+ * channels. So if two subtasks are collapsed and two channels overlap from the output side, there is a total of 4\n+ * virtual channels.\n+ */\n+@Internal\n+public final class RescalingStreamTaskNetworkInput<T> implements RecoverableStreamTaskInput<T> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTIyOTA1MA==", "bodyText": "The main motivation was to avoid a secondary implementations of RecordDeserializer as that would translate to virtual calls in the regular StreamTaskNetworkInput. I have not measured the impact but it was a major concern of @pnowojski .\nNow, it would be very well possible to subclass StreamTaskNetworkInput or extract a common super class. However, because recordDeserializers is of a different type without common ancestor (for CHA), it's hard to generalize.\nI had hoped for some input on how to solve it.", "url": "https://github.com/apache/flink/pull/13845#discussion_r519229050", "createdAt": "2020-11-07T22:45:51Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/RescalingStreamTaskNetworkInput.java", "diffHunk": "@@ -0,0 +1,283 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.io.InputStatus;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.event.AbstractEvent;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.EndOfPartitionEvent;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer.DeserializationResult;\n+import org.apache.flink.runtime.io.network.partition.consumer.BufferOrEvent;\n+import org.apache.flink.runtime.io.network.partition.consumer.EndOfChannelStateEvent;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.runtime.plugable.NonReusingDeserializationDelegate;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElementSerializer;\n+import org.apache.flink.streaming.runtime.streamstatus.StatusWatermarkValve;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.Function;\n+\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * A {@link StreamTaskNetworkInput} implementation that demultiplexes virtual channels.\n+ *\n+ * <p>The demultiplexing works in two dimensions for the following cases.\n+ * <ul>\n+ *     <li> Subtasks of the current operator have been collapsed in a round-robin fashion.\n+ *     <li> The connected output operator has been rescaled (up and down!) and there is an overlap of channels (mostly\n+ * relevant to keyed exchanges).\n+ * </ul>\n+ * In both cases, records from multiple old channels are received over one new physical channel, which need to\n+ * demultiplex the record to correctly restore spanning records (similar to how StreamTaskNetworkInput works).\n+ *\n+ * <p>Note that when both cases occur at the same time (downscaling of several operators), there is the cross product of\n+ * channels. So if two subtasks are collapsed and two channels overlap from the output side, there is a total of 4\n+ * virtual channels.\n+ */\n+@Internal\n+public final class RescalingStreamTaskNetworkInput<T> implements RecoverableStreamTaskInput<T> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2ODY0NA=="}, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 70}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI1NDIyMjE3OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QxMTo0NDo0NFrOHvHj3A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QxMTo0NDo0NFrOHvHj3A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2ODk4OA==", "bodyText": "nit: if channels is empty then a more informative error message would be helpful", "url": "https://github.com/apache/flink/pull/13845#discussion_r519168988", "createdAt": "2020-11-07T11:44:44Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java", "diffHunk": "@@ -88,38 +127,66 @@ private RecoveredInputChannel getChannel(InputChannelInfo info) {\n \tprivate final ResultPartitionWriter[] writers;\n \tprivate final boolean notifyAndBlockOnCompletion;\n \n-\tResultSubpartitionRecoveredStateHandler(ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion) {\n+\tprivate final InflightDataRescalingDescriptor channelMapping;\n+\n+\tprivate final Map<ResultSubpartitionInfo, List<CheckpointedResultSubpartition>> rescaledChannels = new HashMap<>();\n+\n+\tResultSubpartitionRecoveredStateHandler(ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion, InflightDataRescalingDescriptor channelMapping) {\n \t\tthis.writers = writers;\n+\t\tthis.channelMapping = channelMapping;\n \t\tthis.notifyAndBlockOnCompletion = notifyAndBlockOnCompletion;\n \t}\n \n \t@Override\n \tpublic BufferWithContext<Tuple2<BufferBuilder, BufferConsumer>> getBuffer(ResultSubpartitionInfo subpartitionInfo) throws IOException, InterruptedException {\n-\t\tBufferBuilder bufferBuilder = getSubpartition(subpartitionInfo).requestBufferBuilderBlocking();\n+\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n+\t\tBufferBuilder bufferBuilder = channels.get(0).requestBufferBuilderBlocking();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 124}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI1NDIyMjkxOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QxMTo0NTo0M1rOHvHkMA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QyMjo0NjoxMFrOHvLOmw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2OTA3Mg==", "bodyText": "nit: move to top?", "url": "https://github.com/apache/flink/pull/13845#discussion_r519169072", "createdAt": "2020-11-07T11:45:43Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java", "diffHunk": "@@ -88,38 +127,66 @@ private RecoveredInputChannel getChannel(InputChannelInfo info) {\n \tprivate final ResultPartitionWriter[] writers;\n \tprivate final boolean notifyAndBlockOnCompletion;\n \n-\tResultSubpartitionRecoveredStateHandler(ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion) {\n+\tprivate final InflightDataRescalingDescriptor channelMapping;\n+\n+\tprivate final Map<ResultSubpartitionInfo, List<CheckpointedResultSubpartition>> rescaledChannels = new HashMap<>();\n+\n+\tResultSubpartitionRecoveredStateHandler(ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion, InflightDataRescalingDescriptor channelMapping) {\n \t\tthis.writers = writers;\n+\t\tthis.channelMapping = channelMapping;\n \t\tthis.notifyAndBlockOnCompletion = notifyAndBlockOnCompletion;\n \t}\n \n \t@Override\n \tpublic BufferWithContext<Tuple2<BufferBuilder, BufferConsumer>> getBuffer(ResultSubpartitionInfo subpartitionInfo) throws IOException, InterruptedException {\n-\t\tBufferBuilder bufferBuilder = getSubpartition(subpartitionInfo).requestBufferBuilderBlocking();\n+\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n+\t\tBufferBuilder bufferBuilder = channels.get(0).requestBufferBuilderBlocking();\n \t\treturn new BufferWithContext<>(wrap(bufferBuilder), Tuple2.of(bufferBuilder, bufferBuilder.createBufferConsumer()));\n \t}\n \n \t@Override\n-\tpublic void recover(ResultSubpartitionInfo subpartitionInfo, Tuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer) throws IOException {\n+\tpublic void recover(\n+\t\t\tResultSubpartitionInfo subpartitionInfo,\n+\t\t\tint oldSubtaskIndex,\n+\t\t\tTuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer) throws IOException {\n \t\tbufferBuilderAndConsumer.f0.finish();\n \t\tif (bufferBuilderAndConsumer.f1.isDataAvailable()) {\n-\t\t\tboolean added = getSubpartition(subpartitionInfo).add(bufferBuilderAndConsumer.f1, Integer.MIN_VALUE);\n-\t\t\tif (!added) {\n-\t\t\t\tthrow new IOException(\"Buffer consumer couldn't be added to ResultSubpartition\");\n+\t\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n+\t\t\tfor (final CheckpointedResultSubpartition channel : channels) {\n+\t\t\t\t// channel selector is created from the downstream's point of view: the subtask of downstream = subpartition index of recovered buffer\n+\t\t\t\tfinal VirtualChannelSelector channelSelector = new VirtualChannelSelector(subpartitionInfo.getSubPartitionIdx(), oldSubtaskIndex);\n+\t\t\t\tchannel.add(EventSerializer.toBufferConsumer(channelSelector, false), Integer.MIN_VALUE);\n+\t\t\t\tboolean added = channel.add(bufferBuilderAndConsumer.f1.copy(), Integer.MIN_VALUE);\n+\t\t\t\tif (!added) {\n+\t\t\t\t\tthrow new IOException(\"Buffer consumer couldn't be added to ResultSubpartition\");\n+\t\t\t\t}\n \t\t\t}\n-\t\t} else {\n-\t\t\tbufferBuilderAndConsumer.f1.close();\n \t\t}\n+\t\tbufferBuilderAndConsumer.f1.close();\n \t}\n \n-\tprivate CheckpointedResultSubpartition getSubpartition(ResultSubpartitionInfo subpartitionInfo) {\n-\t\tResultPartitionWriter writer = writers[subpartitionInfo.getPartitionIdx()];\n-\t\tif (writer instanceof CheckpointedResultPartition) {\n-\t\t\treturn ((CheckpointedResultPartition) writer).getCheckpointedSubpartition(subpartitionInfo.getSubPartitionIdx());\n-\t\t} else {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot restore state to a non-checkpointable partition type: \" + writer);\n+\tprivate CheckpointedResultSubpartition getSubpartition(int partitionIndex, int subPartitionIdx) {\n+\t\tResultPartitionWriter writer = writers[partitionIndex];\n+\t\tif (!(writer instanceof CheckpointedResultPartition)) {\n+\t\t\tthrow new IllegalStateException(\"Cannot restore state to a non-checkpointable partition type: \" + writer);\n \t\t}\n+\t\treturn ((CheckpointedResultPartition) writer).getCheckpointedSubpartition(subPartitionIdx);\n+\t}\n+\n+\tprivate List<CheckpointedResultSubpartition> getMappedChannels(ResultSubpartitionInfo subpartitionInfo) {\n+\t\treturn rescaledChannels.computeIfAbsent(subpartitionInfo, this::calculateMapping);\n+\t}\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ResultSubpartitionRecoveredStateHandler.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 174}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTIyOTA4Mw==", "bodyText": "I'll remove the whole commit; it's just for debugging tests.", "url": "https://github.com/apache/flink/pull/13845#discussion_r519229083", "createdAt": "2020-11-07T22:46:10Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java", "diffHunk": "@@ -88,38 +127,66 @@ private RecoveredInputChannel getChannel(InputChannelInfo info) {\n \tprivate final ResultPartitionWriter[] writers;\n \tprivate final boolean notifyAndBlockOnCompletion;\n \n-\tResultSubpartitionRecoveredStateHandler(ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion) {\n+\tprivate final InflightDataRescalingDescriptor channelMapping;\n+\n+\tprivate final Map<ResultSubpartitionInfo, List<CheckpointedResultSubpartition>> rescaledChannels = new HashMap<>();\n+\n+\tResultSubpartitionRecoveredStateHandler(ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion, InflightDataRescalingDescriptor channelMapping) {\n \t\tthis.writers = writers;\n+\t\tthis.channelMapping = channelMapping;\n \t\tthis.notifyAndBlockOnCompletion = notifyAndBlockOnCompletion;\n \t}\n \n \t@Override\n \tpublic BufferWithContext<Tuple2<BufferBuilder, BufferConsumer>> getBuffer(ResultSubpartitionInfo subpartitionInfo) throws IOException, InterruptedException {\n-\t\tBufferBuilder bufferBuilder = getSubpartition(subpartitionInfo).requestBufferBuilderBlocking();\n+\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n+\t\tBufferBuilder bufferBuilder = channels.get(0).requestBufferBuilderBlocking();\n \t\treturn new BufferWithContext<>(wrap(bufferBuilder), Tuple2.of(bufferBuilder, bufferBuilder.createBufferConsumer()));\n \t}\n \n \t@Override\n-\tpublic void recover(ResultSubpartitionInfo subpartitionInfo, Tuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer) throws IOException {\n+\tpublic void recover(\n+\t\t\tResultSubpartitionInfo subpartitionInfo,\n+\t\t\tint oldSubtaskIndex,\n+\t\t\tTuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer) throws IOException {\n \t\tbufferBuilderAndConsumer.f0.finish();\n \t\tif (bufferBuilderAndConsumer.f1.isDataAvailable()) {\n-\t\t\tboolean added = getSubpartition(subpartitionInfo).add(bufferBuilderAndConsumer.f1, Integer.MIN_VALUE);\n-\t\t\tif (!added) {\n-\t\t\t\tthrow new IOException(\"Buffer consumer couldn't be added to ResultSubpartition\");\n+\t\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n+\t\t\tfor (final CheckpointedResultSubpartition channel : channels) {\n+\t\t\t\t// channel selector is created from the downstream's point of view: the subtask of downstream = subpartition index of recovered buffer\n+\t\t\t\tfinal VirtualChannelSelector channelSelector = new VirtualChannelSelector(subpartitionInfo.getSubPartitionIdx(), oldSubtaskIndex);\n+\t\t\t\tchannel.add(EventSerializer.toBufferConsumer(channelSelector, false), Integer.MIN_VALUE);\n+\t\t\t\tboolean added = channel.add(bufferBuilderAndConsumer.f1.copy(), Integer.MIN_VALUE);\n+\t\t\t\tif (!added) {\n+\t\t\t\t\tthrow new IOException(\"Buffer consumer couldn't be added to ResultSubpartition\");\n+\t\t\t\t}\n \t\t\t}\n-\t\t} else {\n-\t\t\tbufferBuilderAndConsumer.f1.close();\n \t\t}\n+\t\tbufferBuilderAndConsumer.f1.close();\n \t}\n \n-\tprivate CheckpointedResultSubpartition getSubpartition(ResultSubpartitionInfo subpartitionInfo) {\n-\t\tResultPartitionWriter writer = writers[subpartitionInfo.getPartitionIdx()];\n-\t\tif (writer instanceof CheckpointedResultPartition) {\n-\t\t\treturn ((CheckpointedResultPartition) writer).getCheckpointedSubpartition(subpartitionInfo.getSubPartitionIdx());\n-\t\t} else {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot restore state to a non-checkpointable partition type: \" + writer);\n+\tprivate CheckpointedResultSubpartition getSubpartition(int partitionIndex, int subPartitionIdx) {\n+\t\tResultPartitionWriter writer = writers[partitionIndex];\n+\t\tif (!(writer instanceof CheckpointedResultPartition)) {\n+\t\t\tthrow new IllegalStateException(\"Cannot restore state to a non-checkpointable partition type: \" + writer);\n \t\t}\n+\t\treturn ((CheckpointedResultPartition) writer).getCheckpointedSubpartition(subPartitionIdx);\n+\t}\n+\n+\tprivate List<CheckpointedResultSubpartition> getMappedChannels(ResultSubpartitionInfo subpartitionInfo) {\n+\t\treturn rescaledChannels.computeIfAbsent(subpartitionInfo, this::calculateMapping);\n+\t}\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ResultSubpartitionRecoveredStateHandler.class);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2OTA3Mg=="}, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 174}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI1NDIyMzM3OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QxMTo0NjoxOVrOHvHkYg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QyMjoxNDowNVrOHvLCiA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2OTEyMg==", "bodyText": "I think the log level should be debug here.", "url": "https://github.com/apache/flink/pull/13845#discussion_r519169122", "createdAt": "2020-11-07T11:46:19Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java", "diffHunk": "@@ -88,38 +127,66 @@ private RecoveredInputChannel getChannel(InputChannelInfo info) {\n \tprivate final ResultPartitionWriter[] writers;\n \tprivate final boolean notifyAndBlockOnCompletion;\n \n-\tResultSubpartitionRecoveredStateHandler(ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion) {\n+\tprivate final InflightDataRescalingDescriptor channelMapping;\n+\n+\tprivate final Map<ResultSubpartitionInfo, List<CheckpointedResultSubpartition>> rescaledChannels = new HashMap<>();\n+\n+\tResultSubpartitionRecoveredStateHandler(ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion, InflightDataRescalingDescriptor channelMapping) {\n \t\tthis.writers = writers;\n+\t\tthis.channelMapping = channelMapping;\n \t\tthis.notifyAndBlockOnCompletion = notifyAndBlockOnCompletion;\n \t}\n \n \t@Override\n \tpublic BufferWithContext<Tuple2<BufferBuilder, BufferConsumer>> getBuffer(ResultSubpartitionInfo subpartitionInfo) throws IOException, InterruptedException {\n-\t\tBufferBuilder bufferBuilder = getSubpartition(subpartitionInfo).requestBufferBuilderBlocking();\n+\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n+\t\tBufferBuilder bufferBuilder = channels.get(0).requestBufferBuilderBlocking();\n \t\treturn new BufferWithContext<>(wrap(bufferBuilder), Tuple2.of(bufferBuilder, bufferBuilder.createBufferConsumer()));\n \t}\n \n \t@Override\n-\tpublic void recover(ResultSubpartitionInfo subpartitionInfo, Tuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer) throws IOException {\n+\tpublic void recover(\n+\t\t\tResultSubpartitionInfo subpartitionInfo,\n+\t\t\tint oldSubtaskIndex,\n+\t\t\tTuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer) throws IOException {\n \t\tbufferBuilderAndConsumer.f0.finish();\n \t\tif (bufferBuilderAndConsumer.f1.isDataAvailable()) {\n-\t\t\tboolean added = getSubpartition(subpartitionInfo).add(bufferBuilderAndConsumer.f1, Integer.MIN_VALUE);\n-\t\t\tif (!added) {\n-\t\t\t\tthrow new IOException(\"Buffer consumer couldn't be added to ResultSubpartition\");\n+\t\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n+\t\t\tfor (final CheckpointedResultSubpartition channel : channels) {\n+\t\t\t\t// channel selector is created from the downstream's point of view: the subtask of downstream = subpartition index of recovered buffer\n+\t\t\t\tfinal VirtualChannelSelector channelSelector = new VirtualChannelSelector(subpartitionInfo.getSubPartitionIdx(), oldSubtaskIndex);\n+\t\t\t\tchannel.add(EventSerializer.toBufferConsumer(channelSelector, false), Integer.MIN_VALUE);\n+\t\t\t\tboolean added = channel.add(bufferBuilderAndConsumer.f1.copy(), Integer.MIN_VALUE);\n+\t\t\t\tif (!added) {\n+\t\t\t\t\tthrow new IOException(\"Buffer consumer couldn't be added to ResultSubpartition\");\n+\t\t\t\t}\n \t\t\t}\n-\t\t} else {\n-\t\t\tbufferBuilderAndConsumer.f1.close();\n \t\t}\n+\t\tbufferBuilderAndConsumer.f1.close();\n \t}\n \n-\tprivate CheckpointedResultSubpartition getSubpartition(ResultSubpartitionInfo subpartitionInfo) {\n-\t\tResultPartitionWriter writer = writers[subpartitionInfo.getPartitionIdx()];\n-\t\tif (writer instanceof CheckpointedResultPartition) {\n-\t\t\treturn ((CheckpointedResultPartition) writer).getCheckpointedSubpartition(subpartitionInfo.getSubPartitionIdx());\n-\t\t} else {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot restore state to a non-checkpointable partition type: \" + writer);\n+\tprivate CheckpointedResultSubpartition getSubpartition(int partitionIndex, int subPartitionIdx) {\n+\t\tResultPartitionWriter writer = writers[partitionIndex];\n+\t\tif (!(writer instanceof CheckpointedResultPartition)) {\n+\t\t\tthrow new IllegalStateException(\"Cannot restore state to a non-checkpointable partition type: \" + writer);\n \t\t}\n+\t\treturn ((CheckpointedResultPartition) writer).getCheckpointedSubpartition(subPartitionIdx);\n+\t}\n+\n+\tprivate List<CheckpointedResultSubpartition> getMappedChannels(ResultSubpartitionInfo subpartitionInfo) {\n+\t\treturn rescaledChannels.computeIfAbsent(subpartitionInfo, this::calculateMapping);\n+\t}\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ResultSubpartitionRecoveredStateHandler.class);\n+\tprivate List<CheckpointedResultSubpartition> calculateMapping(ResultSubpartitionInfo info) {\n+\t\tfinal RescaledChannelsMapping rescaledChannelsMapping = channelMapping.getChannelMapping(info.getPartitionIdx());\n+\t\tfinal List<CheckpointedResultSubpartition> subpartitions = Arrays.stream(rescaledChannelsMapping.getNewChannelIndexes(info.getSubPartitionIdx()))\n+\t\t\t.mapToObj(newIndexes -> getSubpartition(info.getPartitionIdx(), newIndexes))\n+\t\t\t.collect(Collectors.toList());\n+\n+\t\tLOG.info(\"output#calculateMapping for {} using {}: {}\", info, rescaledChannelsMapping,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 181}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTIyNTk5Mg==", "bodyText": "I'll remove the whole commit; it's just for debugging tests.", "url": "https://github.com/apache/flink/pull/13845#discussion_r519225992", "createdAt": "2020-11-07T22:14:05Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java", "diffHunk": "@@ -88,38 +127,66 @@ private RecoveredInputChannel getChannel(InputChannelInfo info) {\n \tprivate final ResultPartitionWriter[] writers;\n \tprivate final boolean notifyAndBlockOnCompletion;\n \n-\tResultSubpartitionRecoveredStateHandler(ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion) {\n+\tprivate final InflightDataRescalingDescriptor channelMapping;\n+\n+\tprivate final Map<ResultSubpartitionInfo, List<CheckpointedResultSubpartition>> rescaledChannels = new HashMap<>();\n+\n+\tResultSubpartitionRecoveredStateHandler(ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion, InflightDataRescalingDescriptor channelMapping) {\n \t\tthis.writers = writers;\n+\t\tthis.channelMapping = channelMapping;\n \t\tthis.notifyAndBlockOnCompletion = notifyAndBlockOnCompletion;\n \t}\n \n \t@Override\n \tpublic BufferWithContext<Tuple2<BufferBuilder, BufferConsumer>> getBuffer(ResultSubpartitionInfo subpartitionInfo) throws IOException, InterruptedException {\n-\t\tBufferBuilder bufferBuilder = getSubpartition(subpartitionInfo).requestBufferBuilderBlocking();\n+\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n+\t\tBufferBuilder bufferBuilder = channels.get(0).requestBufferBuilderBlocking();\n \t\treturn new BufferWithContext<>(wrap(bufferBuilder), Tuple2.of(bufferBuilder, bufferBuilder.createBufferConsumer()));\n \t}\n \n \t@Override\n-\tpublic void recover(ResultSubpartitionInfo subpartitionInfo, Tuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer) throws IOException {\n+\tpublic void recover(\n+\t\t\tResultSubpartitionInfo subpartitionInfo,\n+\t\t\tint oldSubtaskIndex,\n+\t\t\tTuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer) throws IOException {\n \t\tbufferBuilderAndConsumer.f0.finish();\n \t\tif (bufferBuilderAndConsumer.f1.isDataAvailable()) {\n-\t\t\tboolean added = getSubpartition(subpartitionInfo).add(bufferBuilderAndConsumer.f1, Integer.MIN_VALUE);\n-\t\t\tif (!added) {\n-\t\t\t\tthrow new IOException(\"Buffer consumer couldn't be added to ResultSubpartition\");\n+\t\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n+\t\t\tfor (final CheckpointedResultSubpartition channel : channels) {\n+\t\t\t\t// channel selector is created from the downstream's point of view: the subtask of downstream = subpartition index of recovered buffer\n+\t\t\t\tfinal VirtualChannelSelector channelSelector = new VirtualChannelSelector(subpartitionInfo.getSubPartitionIdx(), oldSubtaskIndex);\n+\t\t\t\tchannel.add(EventSerializer.toBufferConsumer(channelSelector, false), Integer.MIN_VALUE);\n+\t\t\t\tboolean added = channel.add(bufferBuilderAndConsumer.f1.copy(), Integer.MIN_VALUE);\n+\t\t\t\tif (!added) {\n+\t\t\t\t\tthrow new IOException(\"Buffer consumer couldn't be added to ResultSubpartition\");\n+\t\t\t\t}\n \t\t\t}\n-\t\t} else {\n-\t\t\tbufferBuilderAndConsumer.f1.close();\n \t\t}\n+\t\tbufferBuilderAndConsumer.f1.close();\n \t}\n \n-\tprivate CheckpointedResultSubpartition getSubpartition(ResultSubpartitionInfo subpartitionInfo) {\n-\t\tResultPartitionWriter writer = writers[subpartitionInfo.getPartitionIdx()];\n-\t\tif (writer instanceof CheckpointedResultPartition) {\n-\t\t\treturn ((CheckpointedResultPartition) writer).getCheckpointedSubpartition(subpartitionInfo.getSubPartitionIdx());\n-\t\t} else {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot restore state to a non-checkpointable partition type: \" + writer);\n+\tprivate CheckpointedResultSubpartition getSubpartition(int partitionIndex, int subPartitionIdx) {\n+\t\tResultPartitionWriter writer = writers[partitionIndex];\n+\t\tif (!(writer instanceof CheckpointedResultPartition)) {\n+\t\t\tthrow new IllegalStateException(\"Cannot restore state to a non-checkpointable partition type: \" + writer);\n \t\t}\n+\t\treturn ((CheckpointedResultPartition) writer).getCheckpointedSubpartition(subPartitionIdx);\n+\t}\n+\n+\tprivate List<CheckpointedResultSubpartition> getMappedChannels(ResultSubpartitionInfo subpartitionInfo) {\n+\t\treturn rescaledChannels.computeIfAbsent(subpartitionInfo, this::calculateMapping);\n+\t}\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ResultSubpartitionRecoveredStateHandler.class);\n+\tprivate List<CheckpointedResultSubpartition> calculateMapping(ResultSubpartitionInfo info) {\n+\t\tfinal RescaledChannelsMapping rescaledChannelsMapping = channelMapping.getChannelMapping(info.getPartitionIdx());\n+\t\tfinal List<CheckpointedResultSubpartition> subpartitions = Arrays.stream(rescaledChannelsMapping.getNewChannelIndexes(info.getSubPartitionIdx()))\n+\t\t\t.mapToObj(newIndexes -> getSubpartition(info.getPartitionIdx(), newIndexes))\n+\t\t\t.collect(Collectors.toList());\n+\n+\t\tLOG.info(\"output#calculateMapping for {} using {}: {}\", info, rescaledChannelsMapping,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2OTEyMg=="}, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 181}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI1NDIyNDcyOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QxMTo0OTowOVrOHvHlFA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QyMjoxMzozNFrOHvLCWA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2OTMwMA==", "bodyText": "Is it guaranteed that new subpartitions include all needed old subpartitions?\nI think in case of downscaling of the downstream, the new upstream will less subpartitions than the old one.\nWDYT?", "url": "https://github.com/apache/flink/pull/13845#discussion_r519169300", "createdAt": "2020-11-07T11:49:09Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java", "diffHunk": "@@ -88,38 +127,66 @@ private RecoveredInputChannel getChannel(InputChannelInfo info) {\n \tprivate final ResultPartitionWriter[] writers;\n \tprivate final boolean notifyAndBlockOnCompletion;\n \n-\tResultSubpartitionRecoveredStateHandler(ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion) {\n+\tprivate final InflightDataRescalingDescriptor channelMapping;\n+\n+\tprivate final Map<ResultSubpartitionInfo, List<CheckpointedResultSubpartition>> rescaledChannels = new HashMap<>();\n+\n+\tResultSubpartitionRecoveredStateHandler(ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion, InflightDataRescalingDescriptor channelMapping) {\n \t\tthis.writers = writers;\n+\t\tthis.channelMapping = channelMapping;\n \t\tthis.notifyAndBlockOnCompletion = notifyAndBlockOnCompletion;\n \t}\n \n \t@Override\n \tpublic BufferWithContext<Tuple2<BufferBuilder, BufferConsumer>> getBuffer(ResultSubpartitionInfo subpartitionInfo) throws IOException, InterruptedException {\n-\t\tBufferBuilder bufferBuilder = getSubpartition(subpartitionInfo).requestBufferBuilderBlocking();\n+\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n+\t\tBufferBuilder bufferBuilder = channels.get(0).requestBufferBuilderBlocking();\n \t\treturn new BufferWithContext<>(wrap(bufferBuilder), Tuple2.of(bufferBuilder, bufferBuilder.createBufferConsumer()));\n \t}\n \n \t@Override\n-\tpublic void recover(ResultSubpartitionInfo subpartitionInfo, Tuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer) throws IOException {\n+\tpublic void recover(\n+\t\t\tResultSubpartitionInfo subpartitionInfo,\n+\t\t\tint oldSubtaskIndex,\n+\t\t\tTuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer) throws IOException {\n \t\tbufferBuilderAndConsumer.f0.finish();\n \t\tif (bufferBuilderAndConsumer.f1.isDataAvailable()) {\n-\t\t\tboolean added = getSubpartition(subpartitionInfo).add(bufferBuilderAndConsumer.f1, Integer.MIN_VALUE);\n-\t\t\tif (!added) {\n-\t\t\t\tthrow new IOException(\"Buffer consumer couldn't be added to ResultSubpartition\");\n+\t\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n+\t\t\tfor (final CheckpointedResultSubpartition channel : channels) {\n+\t\t\t\t// channel selector is created from the downstream's point of view: the subtask of downstream = subpartition index of recovered buffer\n+\t\t\t\tfinal VirtualChannelSelector channelSelector = new VirtualChannelSelector(subpartitionInfo.getSubPartitionIdx(), oldSubtaskIndex);\n+\t\t\t\tchannel.add(EventSerializer.toBufferConsumer(channelSelector, false), Integer.MIN_VALUE);\n+\t\t\t\tboolean added = channel.add(bufferBuilderAndConsumer.f1.copy(), Integer.MIN_VALUE);\n+\t\t\t\tif (!added) {\n+\t\t\t\t\tthrow new IOException(\"Buffer consumer couldn't be added to ResultSubpartition\");\n+\t\t\t\t}\n \t\t\t}\n-\t\t} else {\n-\t\t\tbufferBuilderAndConsumer.f1.close();\n \t\t}\n+\t\tbufferBuilderAndConsumer.f1.close();\n \t}\n \n-\tprivate CheckpointedResultSubpartition getSubpartition(ResultSubpartitionInfo subpartitionInfo) {\n-\t\tResultPartitionWriter writer = writers[subpartitionInfo.getPartitionIdx()];\n-\t\tif (writer instanceof CheckpointedResultPartition) {\n-\t\t\treturn ((CheckpointedResultPartition) writer).getCheckpointedSubpartition(subpartitionInfo.getSubPartitionIdx());\n-\t\t} else {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot restore state to a non-checkpointable partition type: \" + writer);\n+\tprivate CheckpointedResultSubpartition getSubpartition(int partitionIndex, int subPartitionIdx) {\n+\t\tResultPartitionWriter writer = writers[partitionIndex];\n+\t\tif (!(writer instanceof CheckpointedResultPartition)) {\n+\t\t\tthrow new IllegalStateException(\"Cannot restore state to a non-checkpointable partition type: \" + writer);\n \t\t}\n+\t\treturn ((CheckpointedResultPartition) writer).getCheckpointedSubpartition(subPartitionIdx);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 167}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTIyNTk0NA==", "bodyText": "In the event of downscaling on input side, the state on output side is exactly recovered by the upstream subtasks that produced it.\nHowever, as you pointed out, there might be fewer subpartitions. In this case the SubtaskStateMapper of the input side will create a mapping that is also set to the InflightDataRescalingDescriptor of the output side in the rescaledChannelsMappings part.\nSo the sequential reader recovers a buffer with old SubpartitionInfo and the mapping is used to find all new channels to which to send the buffer. At this point, the mapping guarantees that all old channels are remapped to new channels.\nFor example, consider the following downscaling of a key range on input side.\n3 partitions: [0; 43) [43; 87) [87; 128)\n2 partitions: [0; 64) [64; 128)\nmapping: 0->[0; 1]; 1->[1;2] (new to old)\nreverse mapping used in sequential reader: 0->[0]; 1->[0;1]; 2->[1] (old to new)\n\nWhen a buffer from subpartition 1 is recovered (from 3 partitions), it needs to be send to subpartition 0 and 1. Similarly, if a buffer from subpartition 2 is recovered, it needs to be send to subpartition 1.", "url": "https://github.com/apache/flink/pull/13845#discussion_r519225944", "createdAt": "2020-11-07T22:13:34Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java", "diffHunk": "@@ -88,38 +127,66 @@ private RecoveredInputChannel getChannel(InputChannelInfo info) {\n \tprivate final ResultPartitionWriter[] writers;\n \tprivate final boolean notifyAndBlockOnCompletion;\n \n-\tResultSubpartitionRecoveredStateHandler(ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion) {\n+\tprivate final InflightDataRescalingDescriptor channelMapping;\n+\n+\tprivate final Map<ResultSubpartitionInfo, List<CheckpointedResultSubpartition>> rescaledChannels = new HashMap<>();\n+\n+\tResultSubpartitionRecoveredStateHandler(ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion, InflightDataRescalingDescriptor channelMapping) {\n \t\tthis.writers = writers;\n+\t\tthis.channelMapping = channelMapping;\n \t\tthis.notifyAndBlockOnCompletion = notifyAndBlockOnCompletion;\n \t}\n \n \t@Override\n \tpublic BufferWithContext<Tuple2<BufferBuilder, BufferConsumer>> getBuffer(ResultSubpartitionInfo subpartitionInfo) throws IOException, InterruptedException {\n-\t\tBufferBuilder bufferBuilder = getSubpartition(subpartitionInfo).requestBufferBuilderBlocking();\n+\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n+\t\tBufferBuilder bufferBuilder = channels.get(0).requestBufferBuilderBlocking();\n \t\treturn new BufferWithContext<>(wrap(bufferBuilder), Tuple2.of(bufferBuilder, bufferBuilder.createBufferConsumer()));\n \t}\n \n \t@Override\n-\tpublic void recover(ResultSubpartitionInfo subpartitionInfo, Tuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer) throws IOException {\n+\tpublic void recover(\n+\t\t\tResultSubpartitionInfo subpartitionInfo,\n+\t\t\tint oldSubtaskIndex,\n+\t\t\tTuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer) throws IOException {\n \t\tbufferBuilderAndConsumer.f0.finish();\n \t\tif (bufferBuilderAndConsumer.f1.isDataAvailable()) {\n-\t\t\tboolean added = getSubpartition(subpartitionInfo).add(bufferBuilderAndConsumer.f1, Integer.MIN_VALUE);\n-\t\t\tif (!added) {\n-\t\t\t\tthrow new IOException(\"Buffer consumer couldn't be added to ResultSubpartition\");\n+\t\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n+\t\t\tfor (final CheckpointedResultSubpartition channel : channels) {\n+\t\t\t\t// channel selector is created from the downstream's point of view: the subtask of downstream = subpartition index of recovered buffer\n+\t\t\t\tfinal VirtualChannelSelector channelSelector = new VirtualChannelSelector(subpartitionInfo.getSubPartitionIdx(), oldSubtaskIndex);\n+\t\t\t\tchannel.add(EventSerializer.toBufferConsumer(channelSelector, false), Integer.MIN_VALUE);\n+\t\t\t\tboolean added = channel.add(bufferBuilderAndConsumer.f1.copy(), Integer.MIN_VALUE);\n+\t\t\t\tif (!added) {\n+\t\t\t\t\tthrow new IOException(\"Buffer consumer couldn't be added to ResultSubpartition\");\n+\t\t\t\t}\n \t\t\t}\n-\t\t} else {\n-\t\t\tbufferBuilderAndConsumer.f1.close();\n \t\t}\n+\t\tbufferBuilderAndConsumer.f1.close();\n \t}\n \n-\tprivate CheckpointedResultSubpartition getSubpartition(ResultSubpartitionInfo subpartitionInfo) {\n-\t\tResultPartitionWriter writer = writers[subpartitionInfo.getPartitionIdx()];\n-\t\tif (writer instanceof CheckpointedResultPartition) {\n-\t\t\treturn ((CheckpointedResultPartition) writer).getCheckpointedSubpartition(subpartitionInfo.getSubPartitionIdx());\n-\t\t} else {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot restore state to a non-checkpointable partition type: \" + writer);\n+\tprivate CheckpointedResultSubpartition getSubpartition(int partitionIndex, int subPartitionIdx) {\n+\t\tResultPartitionWriter writer = writers[partitionIndex];\n+\t\tif (!(writer instanceof CheckpointedResultPartition)) {\n+\t\t\tthrow new IllegalStateException(\"Cannot restore state to a non-checkpointable partition type: \" + writer);\n \t\t}\n+\t\treturn ((CheckpointedResultPartition) writer).getCheckpointedSubpartition(subPartitionIdx);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2OTMwMA=="}, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 167}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI1NDIyNzU5OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/VirtualChannelSelector.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QxMTo1MjoxN1rOHvHmXA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QyMTo1OTozN1rOHvK8sA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2OTYyOA==", "bodyText": "The meaning of these fields is a bit ambiguous to me\n\nboth: is it upstream or downstream?\nchannelIndex: is it subPartition or inputChannel?\n\nSome javadoc would be helpful.", "url": "https://github.com/apache/flink/pull/13845#discussion_r519169628", "createdAt": "2020-11-07T11:52:17Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/VirtualChannelSelector.java", "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.io.network.api;\n+\n+import org.apache.flink.core.memory.DataInputView;\n+import org.apache.flink.core.memory.DataOutputView;\n+import org.apache.flink.runtime.event.RuntimeEvent;\n+\n+import java.util.Objects;\n+\n+/**\n+ * An event that is used to demultiplex virtual channels over the same physical channel.\n+ */\n+public final class VirtualChannelSelector extends RuntimeEvent {\n+\n+\tprivate final int subtaskIndex;\n+\tprivate final int channelIndex;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTIyNDQ5Ng==", "bodyText": "I changed it to the following to clarify that it's always meant to be from the perspective of the input side (where demultiplexing is happening).\n/**\n * An event that is used to demultiplex virtual channels over the same physical channel. The information is to be interpreted from\n * the point of view of the downstream node.\n */\npublic final class VirtualChannelSelector extends RuntimeEvent {\n\n\tprivate final int inputSubtaskIndex;\n\tprivate final int inputChannelIndex;", "url": "https://github.com/apache/flink/pull/13845#discussion_r519224496", "createdAt": "2020-11-07T21:59:37Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/VirtualChannelSelector.java", "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.io.network.api;\n+\n+import org.apache.flink.core.memory.DataInputView;\n+import org.apache.flink.core.memory.DataOutputView;\n+import org.apache.flink.runtime.event.RuntimeEvent;\n+\n+import java.util.Objects;\n+\n+/**\n+ * An event that is used to demultiplex virtual channels over the same physical channel.\n+ */\n+public final class VirtualChannelSelector extends RuntimeEvent {\n+\n+\tprivate final int subtaskIndex;\n+\tprivate final int channelIndex;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2OTYyOA=="}, "originalCommit": {"oid": "215a25d83260a048877bdf8462a06473676efb8a"}, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzY4MDg2MzM4OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RecordFilter.java", "isResolved": true, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yNlQwOToxMDo0N1rOIsdYeg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0xMFQxMTo0ODo0OVrOI0AjyQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzQ4OTY1OA==", "bodyText": "I'm wondering whether it's possible that the record will be discarded because the partitioner always chooses the \"other\" subtask?\nFor example, in an up-scaling from 1 to 2 scenario with RoundRobin partitioner:\n\nlet subtask0.rrPartitioner.nextChannelToSendTo = 0\nselectChannel returns 1 - filtered out\nlet subtask1.rrPartitioner.nextChannelToSendTo = 1 (some record was already processed)\nselectChannel returns 0 - filtered out", "url": "https://github.com/apache/flink/pull/13845#discussion_r583489658", "createdAt": "2021-02-26T09:10:47Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RecordFilter.java", "diffHunk": "@@ -0,0 +1,64 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io.recovery;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.io.network.api.writer.ChannelSelector;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElementSerializer;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+\n+import java.util.function.Predicate;\n+\n+/**\n+ * Filters records for ambiguous channel mappings.\n+ *\n+ * <p>For example, when the downstream node of a keyed exchange is scaled from 1 to 2, the state of\n+ * the output side on te upstream node needs to be replicated to both channels. This filter then\n+ * checks the deserialized records on both downstream subtasks and filters out the irrelevant\n+ * records.\n+ *\n+ * @param <T>\n+ */\n+class RecordFilter<T> implements Predicate<StreamRecord<T>> {\n+    private final ChannelSelector<SerializationDelegate<StreamRecord<T>>> partitioner;\n+\n+    private final SerializationDelegate<StreamRecord<T>> delegate;\n+\n+    private final int subtaskIndex;\n+\n+    public RecordFilter(\n+            ChannelSelector<SerializationDelegate<StreamRecord<T>>> partitioner,\n+            TypeSerializer<T> inputSerializer,\n+            int subtaskIndex) {\n+        this.partitioner = partitioner;\n+        delegate = new SerializationDelegate<>(new StreamElementSerializer(inputSerializer));\n+        this.subtaskIndex = subtaskIndex;\n+    }\n+\n+    public static <T> Predicate<StreamRecord<T>> all() {\n+        return record -> true;\n+    }\n+\n+    @Override\n+    public boolean test(StreamRecord<T> streamRecord) {\n+        delegate.setInstance(streamRecord);\n+        // check if record would have arrived at this subtask if it had been partitioned upstream\n+        return partitioner.selectChannel(delegate) == subtaskIndex;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd18dbb4154a033a55320c2740e2499ac7d63ff9"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzI1ODgxNQ==", "bodyText": "That is a viable concern that I also had. In general, as long as the partitioner is deterministic, it shouldn't happen though:\n\nThe filter is only applied for ambiguous channels. That is, the same data on upstream and downstream is sent to multiple subtasks.\nThe respective channel under filter sees the same buffers in the same order on all subtasks.\nIf the partitioner is deterministic, then all filters of the ambiguous channel have the same state on all subtasks.\nThe partitioner should only yield exactly one channel per replicated record across the subtasks.\n\nNote that Flink's non-deterministic partitioner (ShufflePartitioner) is not ambiguous. Custom partitioners are not supported for that reason unless forced and we should clearly add this reason to the docs.", "url": "https://github.com/apache/flink/pull/13845#discussion_r587258815", "createdAt": "2021-03-04T08:33:31Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RecordFilter.java", "diffHunk": "@@ -0,0 +1,64 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io.recovery;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.io.network.api.writer.ChannelSelector;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElementSerializer;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+\n+import java.util.function.Predicate;\n+\n+/**\n+ * Filters records for ambiguous channel mappings.\n+ *\n+ * <p>For example, when the downstream node of a keyed exchange is scaled from 1 to 2, the state of\n+ * the output side on te upstream node needs to be replicated to both channels. This filter then\n+ * checks the deserialized records on both downstream subtasks and filters out the irrelevant\n+ * records.\n+ *\n+ * @param <T>\n+ */\n+class RecordFilter<T> implements Predicate<StreamRecord<T>> {\n+    private final ChannelSelector<SerializationDelegate<StreamRecord<T>>> partitioner;\n+\n+    private final SerializationDelegate<StreamRecord<T>> delegate;\n+\n+    private final int subtaskIndex;\n+\n+    public RecordFilter(\n+            ChannelSelector<SerializationDelegate<StreamRecord<T>>> partitioner,\n+            TypeSerializer<T> inputSerializer,\n+            int subtaskIndex) {\n+        this.partitioner = partitioner;\n+        delegate = new SerializationDelegate<>(new StreamElementSerializer(inputSerializer));\n+        this.subtaskIndex = subtaskIndex;\n+    }\n+\n+    public static <T> Predicate<StreamRecord<T>> all() {\n+        return record -> true;\n+    }\n+\n+    @Override\n+    public boolean test(StreamRecord<T> streamRecord) {\n+        delegate.setInstance(streamRecord);\n+        // check if record would have arrived at this subtask if it had been partitioned upstream\n+        return partitioner.selectChannel(delegate) == subtaskIndex;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzQ4OTY1OA=="}, "originalCommit": {"oid": "bd18dbb4154a033a55320c2740e2499ac7d63ff9"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODMxNzYyOQ==", "bodyText": "The respective channel under filter sees the same buffers in the same order on all subtasks.\n\nCould you explain why is it the case? E.g. if we upscale form 2 to 3?", "url": "https://github.com/apache/flink/pull/13845#discussion_r588317629", "createdAt": "2021-03-05T14:03:21Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RecordFilter.java", "diffHunk": "@@ -0,0 +1,64 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io.recovery;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.io.network.api.writer.ChannelSelector;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElementSerializer;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+\n+import java.util.function.Predicate;\n+\n+/**\n+ * Filters records for ambiguous channel mappings.\n+ *\n+ * <p>For example, when the downstream node of a keyed exchange is scaled from 1 to 2, the state of\n+ * the output side on te upstream node needs to be replicated to both channels. This filter then\n+ * checks the deserialized records on both downstream subtasks and filters out the irrelevant\n+ * records.\n+ *\n+ * @param <T>\n+ */\n+class RecordFilter<T> implements Predicate<StreamRecord<T>> {\n+    private final ChannelSelector<SerializationDelegate<StreamRecord<T>>> partitioner;\n+\n+    private final SerializationDelegate<StreamRecord<T>> delegate;\n+\n+    private final int subtaskIndex;\n+\n+    public RecordFilter(\n+            ChannelSelector<SerializationDelegate<StreamRecord<T>>> partitioner,\n+            TypeSerializer<T> inputSerializer,\n+            int subtaskIndex) {\n+        this.partitioner = partitioner;\n+        delegate = new SerializationDelegate<>(new StreamElementSerializer(inputSerializer));\n+        this.subtaskIndex = subtaskIndex;\n+    }\n+\n+    public static <T> Predicate<StreamRecord<T>> all() {\n+        return record -> true;\n+    }\n+\n+    @Override\n+    public boolean test(StreamRecord<T> streamRecord) {\n+        delegate.setInstance(streamRecord);\n+        // check if record would have arrived at this subtask if it had been partitioned upstream\n+        return partitioner.selectChannel(delegate) == subtaskIndex;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzQ4OTY1OA=="}, "originalCommit": {"oid": "bd18dbb4154a033a55320c2740e2499ac7d63ff9"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5MTMwMTc0Ng==", "bodyText": "I was assuming that each partitioner is used at most by one filter and that in turn is uniquely associated with exactly one virtual channel. Upon reinspection, it turned out that the partitioner cache inside the RecordFilterFactory actually violated that assumption and it turns out that you are correct.\nCurrently, the filter is only used for keyed exchanges and blinks hash partitioner where the partitioners are stateless. However, that may not be true in the future and it also doesn't necessarily hold for custom partitioners when they are forced.\nHowever, since the retrieval of the partitioner is rather costly for one input tasks, I retained the cache and instead rely on a proper StreamPartitioner#copy implementation. Note that indeed quite a few of these implementations are a bit whacky (returning this although the partitioner is stateful), but none of that applies to the partitioner that produce ambiguous channels, so I left as is for now.", "url": "https://github.com/apache/flink/pull/13845#discussion_r591301746", "createdAt": "2021-03-10T10:02:44Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RecordFilter.java", "diffHunk": "@@ -0,0 +1,64 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io.recovery;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.io.network.api.writer.ChannelSelector;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElementSerializer;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+\n+import java.util.function.Predicate;\n+\n+/**\n+ * Filters records for ambiguous channel mappings.\n+ *\n+ * <p>For example, when the downstream node of a keyed exchange is scaled from 1 to 2, the state of\n+ * the output side on te upstream node needs to be replicated to both channels. This filter then\n+ * checks the deserialized records on both downstream subtasks and filters out the irrelevant\n+ * records.\n+ *\n+ * @param <T>\n+ */\n+class RecordFilter<T> implements Predicate<StreamRecord<T>> {\n+    private final ChannelSelector<SerializationDelegate<StreamRecord<T>>> partitioner;\n+\n+    private final SerializationDelegate<StreamRecord<T>> delegate;\n+\n+    private final int subtaskIndex;\n+\n+    public RecordFilter(\n+            ChannelSelector<SerializationDelegate<StreamRecord<T>>> partitioner,\n+            TypeSerializer<T> inputSerializer,\n+            int subtaskIndex) {\n+        this.partitioner = partitioner;\n+        delegate = new SerializationDelegate<>(new StreamElementSerializer(inputSerializer));\n+        this.subtaskIndex = subtaskIndex;\n+    }\n+\n+    public static <T> Predicate<StreamRecord<T>> all() {\n+        return record -> true;\n+    }\n+\n+    @Override\n+    public boolean test(StreamRecord<T> streamRecord) {\n+        delegate.setInstance(streamRecord);\n+        // check if record would have arrived at this subtask if it had been partitioned upstream\n+        return partitioner.selectChannel(delegate) == subtaskIndex;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzQ4OTY1OA=="}, "originalCommit": {"oid": "bd18dbb4154a033a55320c2740e2499ac7d63ff9"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5MTM2ODMyNg==", "bodyText": "I'm afraid we can't rely on KeyGroupStreamPartitioner.copy (actually all except Shuffle return this):\n    public StreamPartitioner<T> copy() {\n        return this;\n    }\n\nedit:  KeyGroupStreamPartitioner uses SubtaskStateMapper.RANGE which is ambiguous", "url": "https://github.com/apache/flink/pull/13845#discussion_r591368326", "createdAt": "2021-03-10T11:09:20Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RecordFilter.java", "diffHunk": "@@ -0,0 +1,64 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io.recovery;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.io.network.api.writer.ChannelSelector;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElementSerializer;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+\n+import java.util.function.Predicate;\n+\n+/**\n+ * Filters records for ambiguous channel mappings.\n+ *\n+ * <p>For example, when the downstream node of a keyed exchange is scaled from 1 to 2, the state of\n+ * the output side on te upstream node needs to be replicated to both channels. This filter then\n+ * checks the deserialized records on both downstream subtasks and filters out the irrelevant\n+ * records.\n+ *\n+ * @param <T>\n+ */\n+class RecordFilter<T> implements Predicate<StreamRecord<T>> {\n+    private final ChannelSelector<SerializationDelegate<StreamRecord<T>>> partitioner;\n+\n+    private final SerializationDelegate<StreamRecord<T>> delegate;\n+\n+    private final int subtaskIndex;\n+\n+    public RecordFilter(\n+            ChannelSelector<SerializationDelegate<StreamRecord<T>>> partitioner,\n+            TypeSerializer<T> inputSerializer,\n+            int subtaskIndex) {\n+        this.partitioner = partitioner;\n+        delegate = new SerializationDelegate<>(new StreamElementSerializer(inputSerializer));\n+        this.subtaskIndex = subtaskIndex;\n+    }\n+\n+    public static <T> Predicate<StreamRecord<T>> all() {\n+        return record -> true;\n+    }\n+\n+    @Override\n+    public boolean test(StreamRecord<T> streamRecord) {\n+        delegate.setInstance(streamRecord);\n+        // check if record would have arrived at this subtask if it had been partitioned upstream\n+        return partitioner.selectChannel(delegate) == subtaskIndex;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzQ4OTY1OA=="}, "originalCommit": {"oid": "bd18dbb4154a033a55320c2740e2499ac7d63ff9"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5MTQwNjAyNQ==", "bodyText": "Discussed offline:\n\nRebalancePartitioner is stateful but uses non-ambiguous SubtaskStateMapper.ROUND_ROBIN\nKeyGroupStreamPartitioner uses ambiguous SubtaskStateMapper.RANGE but is stateless", "url": "https://github.com/apache/flink/pull/13845#discussion_r591406025", "createdAt": "2021-03-10T11:48:49Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RecordFilter.java", "diffHunk": "@@ -0,0 +1,64 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io.recovery;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.io.network.api.writer.ChannelSelector;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElementSerializer;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+\n+import java.util.function.Predicate;\n+\n+/**\n+ * Filters records for ambiguous channel mappings.\n+ *\n+ * <p>For example, when the downstream node of a keyed exchange is scaled from 1 to 2, the state of\n+ * the output side on te upstream node needs to be replicated to both channels. This filter then\n+ * checks the deserialized records on both downstream subtasks and filters out the irrelevant\n+ * records.\n+ *\n+ * @param <T>\n+ */\n+class RecordFilter<T> implements Predicate<StreamRecord<T>> {\n+    private final ChannelSelector<SerializationDelegate<StreamRecord<T>>> partitioner;\n+\n+    private final SerializationDelegate<StreamRecord<T>> delegate;\n+\n+    private final int subtaskIndex;\n+\n+    public RecordFilter(\n+            ChannelSelector<SerializationDelegate<StreamRecord<T>>> partitioner,\n+            TypeSerializer<T> inputSerializer,\n+            int subtaskIndex) {\n+        this.partitioner = partitioner;\n+        delegate = new SerializationDelegate<>(new StreamElementSerializer(inputSerializer));\n+        this.subtaskIndex = subtaskIndex;\n+    }\n+\n+    public static <T> Predicate<StreamRecord<T>> all() {\n+        return record -> true;\n+    }\n+\n+    @Override\n+    public boolean test(StreamRecord<T> streamRecord) {\n+        delegate.setInstance(streamRecord);\n+        // check if record would have arrived at this subtask if it had been partitioned upstream\n+        return partitioner.selectChannel(delegate) == subtaskIndex;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzQ4OTY1OA=="}, "originalCommit": {"oid": "bd18dbb4154a033a55320c2740e2499ac7d63ff9"}, "originalPosition": 62}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzY4MDg2ODA1OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yNlQwOToxMTo1NVrOIsdbdA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yNlQwOToxMTo1NVrOIsdbdA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzQ5MDQyMA==", "bodyText": "Should it be in finally?", "url": "https://github.com/apache/flink/pull/13845#discussion_r583490420", "createdAt": "2021-02-26T09:11:55Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java", "diffHunk": "@@ -45,32 +55,46 @@\n \n     BufferWithContext<Context> getBuffer(Info info) throws IOException, InterruptedException;\n \n-    void recover(Info info, Context context) throws IOException;\n+    void recover(Info info, int oldSubtaskIndex, Context context) throws IOException;\n }\n \n class InputChannelRecoveredStateHandler\n         implements RecoveredChannelStateHandler<InputChannelInfo, Buffer> {\n     private final InputGate[] inputGates;\n \n-    InputChannelRecoveredStateHandler(InputGate[] inputGates) {\n+    private final InflightDataRescalingDescriptor channelMapping;\n+\n+    private final Map<InputChannelInfo, List<RecoveredInputChannel>> rescaledChannels =\n+            new HashMap<>();\n+\n+    InputChannelRecoveredStateHandler(\n+            InputGate[] inputGates, InflightDataRescalingDescriptor channelMapping) {\n         this.inputGates = inputGates;\n+        this.channelMapping = channelMapping;\n     }\n \n     @Override\n     public BufferWithContext<Buffer> getBuffer(InputChannelInfo channelInfo)\n             throws IOException, InterruptedException {\n-        RecoveredInputChannel channel = getChannel(channelInfo);\n+        RecoveredInputChannel channel = getMappedChannels(channelInfo).get(0);\n         Buffer buffer = channel.requestBufferBlocking();\n         return new BufferWithContext<>(wrap(buffer), buffer);\n     }\n \n     @Override\n-    public void recover(InputChannelInfo channelInfo, Buffer buffer) {\n+    public void recover(InputChannelInfo channelInfo, int oldSubtaskIndex, Buffer buffer)\n+            throws IOException {\n         if (buffer.readableBytes() > 0) {\n-            getChannel(channelInfo).onRecoveredStateBuffer(buffer);\n-        } else {\n-            buffer.recycleBuffer();\n+            for (final RecoveredInputChannel channel : getMappedChannels(channelInfo)) {\n+                channel.onRecoveredStateBuffer(\n+                        EventSerializer.toBuffer(\n+                                new VirtualChannelSelector(\n+                                        oldSubtaskIndex, channelInfo.getInputChannelIdx()),\n+                                false));\n+                channel.onRecoveredStateBuffer(buffer.retainBuffer());\n+            }\n         }\n+        buffer.recycleBuffer();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd18dbb4154a033a55320c2740e2499ac7d63ff9"}, "originalPosition": 78}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzY4MDg3MDE3OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yNlQwOToxMjoyOVrOIsdcyQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yNlQwOToxMjoyOVrOIsdcyQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzQ5MDc2MQ==", "bodyText": "Should it be in finally?", "url": "https://github.com/apache/flink/pull/13845#discussion_r583490761", "createdAt": "2021-02-26T09:12:29Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java", "diffHunk": "@@ -121,27 +181,59 @@ public void recover(\n                     \"ResultSubpartitionRecoveredStateHandler#recover\",\n                     bufferBuilderAndConsumer.f1,\n                     subpartitionInfo);\n-            boolean added =\n-                    getSubpartition(subpartitionInfo)\n-                            .add(bufferBuilderAndConsumer.f1, Integer.MIN_VALUE);\n-            if (!added) {\n-                throw new IOException(\"Buffer consumer couldn't be added to ResultSubpartition\");\n+            final List<CheckpointedResultSubpartition> channels =\n+                    getMappedChannels(subpartitionInfo);\n+            for (final CheckpointedResultSubpartition channel : channels) {\n+                // channel selector is created from the downstream's point of view: the subtask of\n+                // downstream = subpartition index of recovered buffer\n+                final VirtualChannelSelector channelSelector =\n+                        new VirtualChannelSelector(\n+                                subpartitionInfo.getSubPartitionIdx(), oldSubtaskIndex);\n+                channel.add(\n+                        EventSerializer.toBufferConsumer(channelSelector, false),\n+                        Integer.MIN_VALUE);\n+                boolean added = channel.add(bufferBuilderAndConsumer.f1.copy(), Integer.MIN_VALUE);\n+                if (!added) {\n+                    throw new IOException(\n+                            \"Buffer consumer couldn't be added to ResultSubpartition\");\n+                }\n             }\n-        } else {\n-            bufferBuilderAndConsumer.f1.close();\n         }\n+        bufferBuilderAndConsumer.f1.close();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd18dbb4154a033a55320c2740e2499ac7d63ff9"}, "originalPosition": 188}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzY4MDg3NjkyOnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yNlQwOToxNDowOVrOIsdg7A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yNlQwOToxNDowOVrOIsdg7A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzQ5MTgyMA==", "bodyText": "I guess get(0) is used here because the actual subpartition that we use to request a buffer from doesn't matter.\nIf so, could you please add a comment in the code?", "url": "https://github.com/apache/flink/pull/13845#discussion_r583491820", "createdAt": "2021-02-26T09:14:09Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java", "diffHunk": "@@ -94,17 +145,25 @@ private RecoveredInputChannel getChannel(InputChannelInfo info) {\n     private final ResultPartitionWriter[] writers;\n     private final boolean notifyAndBlockOnCompletion;\n \n+    private final InflightDataRescalingDescriptor channelMapping;\n+\n+    private final Map<ResultSubpartitionInfo, List<CheckpointedResultSubpartition>>\n+            rescaledChannels = new HashMap<>();\n+\n     ResultSubpartitionRecoveredStateHandler(\n-            ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion) {\n+            ResultPartitionWriter[] writers,\n+            boolean notifyAndBlockOnCompletion,\n+            InflightDataRescalingDescriptor channelMapping) {\n         this.writers = writers;\n+        this.channelMapping = channelMapping;\n         this.notifyAndBlockOnCompletion = notifyAndBlockOnCompletion;\n     }\n \n     @Override\n     public BufferWithContext<Tuple2<BufferBuilder, BufferConsumer>> getBuffer(\n             ResultSubpartitionInfo subpartitionInfo) throws IOException, InterruptedException {\n-        BufferBuilder bufferBuilder =\n-                getSubpartition(subpartitionInfo).requestBufferBuilderBlocking();\n+        final List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n+        BufferBuilder bufferBuilder = channels.get(0).requestBufferBuilderBlocking();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd18dbb4154a033a55320c2740e2499ac7d63ff9"}, "originalPosition": 147}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzY4MDkxNzg0OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/VirtualChannelSelector.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yNlQwOToyMzo1NlrOIsd5gQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0wNVQxNDowNjoyN1rOIxELkg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzQ5ODExMw==", "bodyText": "nit: To me SubtaskConnectionDescriptor would be more informative. But that's a matter of taste so please ignore if you prefer VirtualChannelSelector.\nnit: virtual/physical channels in javadoc are confusing to me. How about channels before/after re-scaling? For example:\nAn event sent over a channel after re-scaling to signal what channel was used before re-scaling for the data being sent.", "url": "https://github.com/apache/flink/pull/13845#discussion_r583498113", "createdAt": "2021-02-26T09:23:56Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/VirtualChannelSelector.java", "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.io.network.api;\n+\n+import org.apache.flink.core.memory.DataInputView;\n+import org.apache.flink.core.memory.DataOutputView;\n+import org.apache.flink.runtime.event.RuntimeEvent;\n+\n+import java.util.Objects;\n+\n+/** An event that is used to demultiplex virtual channels over the same physical channel. */\n+public final class VirtualChannelSelector extends RuntimeEvent {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd18dbb4154a033a55320c2740e2499ac7d63ff9"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzI3NjgwNQ==", "bodyText": "Yes, you are right. When I started I was still using channel indexes but at some point I changed it. Please check if the javadoc is more informative to you now.", "url": "https://github.com/apache/flink/pull/13845#discussion_r587276805", "createdAt": "2021-03-04T08:54:15Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/VirtualChannelSelector.java", "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.io.network.api;\n+\n+import org.apache.flink.core.memory.DataInputView;\n+import org.apache.flink.core.memory.DataOutputView;\n+import org.apache.flink.runtime.event.RuntimeEvent;\n+\n+import java.util.Objects;\n+\n+/** An event that is used to demultiplex virtual channels over the same physical channel. */\n+public final class VirtualChannelSelector extends RuntimeEvent {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzQ5ODExMw=="}, "originalCommit": {"oid": "bd18dbb4154a033a55320c2740e2499ac7d63ff9"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODMxOTYzNA==", "bodyText": "Yes, looks good, thanks!", "url": "https://github.com/apache/flink/pull/13845#discussion_r588319634", "createdAt": "2021-03-05T14:06:27Z", "author": {"login": "rkhachatryan"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/VirtualChannelSelector.java", "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.io.network.api;\n+\n+import org.apache.flink.core.memory.DataInputView;\n+import org.apache.flink.core.memory.DataOutputView;\n+import org.apache.flink.runtime.event.RuntimeEvent;\n+\n+import java.util.Objects;\n+\n+/** An event that is used to demultiplex virtual channels over the same physical channel. */\n+public final class VirtualChannelSelector extends RuntimeEvent {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzQ5ODExMw=="}, "originalCommit": {"oid": "bd18dbb4154a033a55320c2740e2499ac7d63ff9"}, "originalPosition": 27}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzY4MDkyNzQ1OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yNlQwOToyNjowOVrOIsd_Lg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yNlQwOToyNjowOVrOIsd_Lg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzQ5OTU2Ng==", "bodyText": "How about moving this (and other) static methods to a dedicated factory class?\nTo me the responsibility of this class would be more clear.", "url": "https://github.com/apache/flink/pull/13845#discussion_r583499566", "createdAt": "2021-02-26T09:26:09Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java", "diffHunk": "@@ -0,0 +1,280 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io.recovery;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.TaskInfo;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.io.InputStatus;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.event.AbstractEvent;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.partition.consumer.BufferOrEvent;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput;\n+import org.apache.flink.streaming.runtime.io.RecoverableStreamTaskInput;\n+import org.apache.flink.streaming.runtime.io.StreamTaskInput;\n+import org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput;\n+import org.apache.flink.streaming.runtime.io.checkpointing.CheckpointedInputGate;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StatusWatermarkValve;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+\n+import static org.apache.flink.runtime.checkpoint.CheckpointFailureReason.CHECKPOINT_DECLINED_TASK_NOT_READY;\n+\n+/**\n+ * A {@link StreamTaskNetworkInput} implementation that demultiplexes virtual channels.\n+ *\n+ * <p>The demultiplexing works in two dimensions for the following cases. *\n+ *\n+ * <ul>\n+ *   <li>Subtasks of the current operator have been collapsed in a round-robin fashion.\n+ *   <li>The connected output operator has been rescaled (up and down!) and there is an overlap of\n+ *       channels (mostly relevant to keyed exchanges).\n+ * </ul>\n+ *\n+ * <p>In both cases, records from multiple old channels are received over one new physical channel,\n+ * which need to demultiplex the record to correctly restore spanning records (similar to how\n+ * StreamTaskNetworkInput works).\n+ *\n+ * <p>Note that when both cases occur at the same time (downscaling of several operators), there is\n+ * the cross product of channels. So if two subtasks are collapsed and two channels overlap from the\n+ * output side, there is a total of 4 virtual channels.\n+ */\n+@Internal\n+public final class RescalingStreamTaskNetworkInput<T>\n+        extends AbstractStreamTaskNetworkInput<T, DemultiplexingRecordDeserializer<T>>\n+        implements RecoverableStreamTaskInput<T> {\n+\n+    private static final Logger LOG =\n+            LoggerFactory.getLogger(RescalingStreamTaskNetworkInput.class);\n+    private final IOManager ioManager;\n+\n+    private RescalingStreamTaskNetworkInput(\n+            CheckpointedInputGate checkpointedInputGate,\n+            TypeSerializer<T> inputSerializer,\n+            IOManager ioManager,\n+            StatusWatermarkValve statusWatermarkValve,\n+            int inputIndex,\n+            InflightDataRescalingDescriptor inflightDataRescalingDescriptor,\n+            Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+            TaskInfo taskInfo) {\n+        super(\n+                checkpointedInputGate,\n+                inputSerializer,\n+                statusWatermarkValve,\n+                inputIndex,\n+                getRecordDeserializers(\n+                        checkpointedInputGate,\n+                        inputSerializer,\n+                        ioManager,\n+                        inflightDataRescalingDescriptor,\n+                        gatePartitioners,\n+                        taskInfo));\n+        this.ioManager = ioManager;\n+\n+        LOG.info(\n+                \"Created demultiplexer for input {} from {}\",\n+                inputIndex,\n+                inflightDataRescalingDescriptor);\n+    }\n+\n+    private static <T>\n+            Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> getRecordDeserializers(\n+                    CheckpointedInputGate checkpointedInputGate,\n+                    TypeSerializer<T> inputSerializer,\n+                    IOManager ioManager,\n+                    InflightDataRescalingDescriptor rescalingDescriptor,\n+                    Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+                    TaskInfo taskInfo) {\n+\n+        RecordFilterFactory<T> recordFilterFactory =\n+                new RecordFilterFactory<>(\n+                        taskInfo.getIndexOfThisSubtask(),\n+                        inputSerializer,\n+                        taskInfo.getNumberOfParallelSubtasks(),\n+                        gatePartitioners,\n+                        taskInfo.getMaxNumberOfParallelSubtasks());\n+        final DeserializerFactory deserializerFactory = new DeserializerFactory(ioManager);\n+        Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> deserializers =\n+                Maps.newHashMapWithExpectedSize(checkpointedInputGate.getChannelInfos().size());\n+        for (InputChannelInfo channelInfo : checkpointedInputGate.getChannelInfos()) {\n+            deserializers.put(\n+                    channelInfo,\n+                    DemultiplexingRecordDeserializer.create(\n+                            channelInfo,\n+                            rescalingDescriptor,\n+                            deserializerFactory,\n+                            recordFilterFactory));\n+        }\n+        return deserializers;\n+    }\n+\n+    @Override\n+    public StreamTaskInput<T> finishRecovery() throws IOException {\n+        close();\n+        return new StreamTaskNetworkInput<>(\n+                checkpointedInputGate,\n+                inputSerializer,\n+                ioManager,\n+                statusWatermarkValve,\n+                inputIndex);\n+    }\n+\n+    /**\n+     * Factory method for {@link StreamTaskNetworkInput} or {@link RescalingStreamTaskNetworkInput}\n+     * depending on {@link InflightDataRescalingDescriptor}.\n+     */\n+    public static <T> StreamTaskInput<T> create(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd18dbb4154a033a55320c2740e2499ac7d63ff9"}, "originalPosition": 163}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzY4MDkzMjAwOnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yNlQwOToyNzoxNVrOIseB4g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yNlQwOToyNzoxNVrOIseB4g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzUwMDI1OA==", "bodyText": "nit: super.getActiveSerializer(channelInfo);", "url": "https://github.com/apache/flink/pull/13845#discussion_r583500258", "createdAt": "2021-02-26T09:27:15Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java", "diffHunk": "@@ -0,0 +1,280 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io.recovery;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.TaskInfo;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.io.InputStatus;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.event.AbstractEvent;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.partition.consumer.BufferOrEvent;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput;\n+import org.apache.flink.streaming.runtime.io.RecoverableStreamTaskInput;\n+import org.apache.flink.streaming.runtime.io.StreamTaskInput;\n+import org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput;\n+import org.apache.flink.streaming.runtime.io.checkpointing.CheckpointedInputGate;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StatusWatermarkValve;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+\n+import static org.apache.flink.runtime.checkpoint.CheckpointFailureReason.CHECKPOINT_DECLINED_TASK_NOT_READY;\n+\n+/**\n+ * A {@link StreamTaskNetworkInput} implementation that demultiplexes virtual channels.\n+ *\n+ * <p>The demultiplexing works in two dimensions for the following cases. *\n+ *\n+ * <ul>\n+ *   <li>Subtasks of the current operator have been collapsed in a round-robin fashion.\n+ *   <li>The connected output operator has been rescaled (up and down!) and there is an overlap of\n+ *       channels (mostly relevant to keyed exchanges).\n+ * </ul>\n+ *\n+ * <p>In both cases, records from multiple old channels are received over one new physical channel,\n+ * which need to demultiplex the record to correctly restore spanning records (similar to how\n+ * StreamTaskNetworkInput works).\n+ *\n+ * <p>Note that when both cases occur at the same time (downscaling of several operators), there is\n+ * the cross product of channels. So if two subtasks are collapsed and two channels overlap from the\n+ * output side, there is a total of 4 virtual channels.\n+ */\n+@Internal\n+public final class RescalingStreamTaskNetworkInput<T>\n+        extends AbstractStreamTaskNetworkInput<T, DemultiplexingRecordDeserializer<T>>\n+        implements RecoverableStreamTaskInput<T> {\n+\n+    private static final Logger LOG =\n+            LoggerFactory.getLogger(RescalingStreamTaskNetworkInput.class);\n+    private final IOManager ioManager;\n+\n+    private RescalingStreamTaskNetworkInput(\n+            CheckpointedInputGate checkpointedInputGate,\n+            TypeSerializer<T> inputSerializer,\n+            IOManager ioManager,\n+            StatusWatermarkValve statusWatermarkValve,\n+            int inputIndex,\n+            InflightDataRescalingDescriptor inflightDataRescalingDescriptor,\n+            Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+            TaskInfo taskInfo) {\n+        super(\n+                checkpointedInputGate,\n+                inputSerializer,\n+                statusWatermarkValve,\n+                inputIndex,\n+                getRecordDeserializers(\n+                        checkpointedInputGate,\n+                        inputSerializer,\n+                        ioManager,\n+                        inflightDataRescalingDescriptor,\n+                        gatePartitioners,\n+                        taskInfo));\n+        this.ioManager = ioManager;\n+\n+        LOG.info(\n+                \"Created demultiplexer for input {} from {}\",\n+                inputIndex,\n+                inflightDataRescalingDescriptor);\n+    }\n+\n+    private static <T>\n+            Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> getRecordDeserializers(\n+                    CheckpointedInputGate checkpointedInputGate,\n+                    TypeSerializer<T> inputSerializer,\n+                    IOManager ioManager,\n+                    InflightDataRescalingDescriptor rescalingDescriptor,\n+                    Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+                    TaskInfo taskInfo) {\n+\n+        RecordFilterFactory<T> recordFilterFactory =\n+                new RecordFilterFactory<>(\n+                        taskInfo.getIndexOfThisSubtask(),\n+                        inputSerializer,\n+                        taskInfo.getNumberOfParallelSubtasks(),\n+                        gatePartitioners,\n+                        taskInfo.getMaxNumberOfParallelSubtasks());\n+        final DeserializerFactory deserializerFactory = new DeserializerFactory(ioManager);\n+        Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> deserializers =\n+                Maps.newHashMapWithExpectedSize(checkpointedInputGate.getChannelInfos().size());\n+        for (InputChannelInfo channelInfo : checkpointedInputGate.getChannelInfos()) {\n+            deserializers.put(\n+                    channelInfo,\n+                    DemultiplexingRecordDeserializer.create(\n+                            channelInfo,\n+                            rescalingDescriptor,\n+                            deserializerFactory,\n+                            recordFilterFactory));\n+        }\n+        return deserializers;\n+    }\n+\n+    @Override\n+    public StreamTaskInput<T> finishRecovery() throws IOException {\n+        close();\n+        return new StreamTaskNetworkInput<>(\n+                checkpointedInputGate,\n+                inputSerializer,\n+                ioManager,\n+                statusWatermarkValve,\n+                inputIndex);\n+    }\n+\n+    /**\n+     * Factory method for {@link StreamTaskNetworkInput} or {@link RescalingStreamTaskNetworkInput}\n+     * depending on {@link InflightDataRescalingDescriptor}.\n+     */\n+    public static <T> StreamTaskInput<T> create(\n+            CheckpointedInputGate checkpointedInputGate,\n+            TypeSerializer<T> inputSerializer,\n+            IOManager ioManager,\n+            StatusWatermarkValve statusWatermarkValve,\n+            int inputIndex,\n+            InflightDataRescalingDescriptor rescalingDescriptorinflightDataRescalingDescriptor,\n+            Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+            TaskInfo taskInfo) {\n+        return rescalingDescriptorinflightDataRescalingDescriptor.equals(\n+                        InflightDataRescalingDescriptor.NO_RESCALE)\n+                ? new StreamTaskNetworkInput<>(\n+                        checkpointedInputGate,\n+                        inputSerializer,\n+                        ioManager,\n+                        statusWatermarkValve,\n+                        inputIndex)\n+                : new RescalingStreamTaskNetworkInput<>(\n+                        checkpointedInputGate,\n+                        inputSerializer,\n+                        ioManager,\n+                        statusWatermarkValve,\n+                        inputIndex,\n+                        rescalingDescriptorinflightDataRescalingDescriptor,\n+                        gatePartitioners,\n+                        taskInfo);\n+    }\n+\n+    protected DemultiplexingRecordDeserializer<T> getActiveSerializer(\n+            InputChannelInfo channelInfo) {\n+        final DemultiplexingRecordDeserializer<T> deserialier =\n+                recordDeserializers.get(channelInfo);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd18dbb4154a033a55320c2740e2499ac7d63ff9"}, "originalPosition": 194}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzY4MDk0NDAwOnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yNlQwOTozMDowNlrOIseJNg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0wNFQwODo1Nzo0NVrOIwErJA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzUwMjEzNA==", "bodyText": "If the defaults in SpillingAdaptiveSpanningRecordDeserializer are decreased then we can get 0 here with high enough DoP.\nShould we add Math.max(some_minimum, ....) ?", "url": "https://github.com/apache/flink/pull/13845#discussion_r583502134", "createdAt": "2021-02-26T09:30:06Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java", "diffHunk": "@@ -0,0 +1,280 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io.recovery;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.TaskInfo;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.io.InputStatus;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.event.AbstractEvent;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.partition.consumer.BufferOrEvent;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput;\n+import org.apache.flink.streaming.runtime.io.RecoverableStreamTaskInput;\n+import org.apache.flink.streaming.runtime.io.StreamTaskInput;\n+import org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput;\n+import org.apache.flink.streaming.runtime.io.checkpointing.CheckpointedInputGate;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StatusWatermarkValve;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+\n+import static org.apache.flink.runtime.checkpoint.CheckpointFailureReason.CHECKPOINT_DECLINED_TASK_NOT_READY;\n+\n+/**\n+ * A {@link StreamTaskNetworkInput} implementation that demultiplexes virtual channels.\n+ *\n+ * <p>The demultiplexing works in two dimensions for the following cases. *\n+ *\n+ * <ul>\n+ *   <li>Subtasks of the current operator have been collapsed in a round-robin fashion.\n+ *   <li>The connected output operator has been rescaled (up and down!) and there is an overlap of\n+ *       channels (mostly relevant to keyed exchanges).\n+ * </ul>\n+ *\n+ * <p>In both cases, records from multiple old channels are received over one new physical channel,\n+ * which need to demultiplex the record to correctly restore spanning records (similar to how\n+ * StreamTaskNetworkInput works).\n+ *\n+ * <p>Note that when both cases occur at the same time (downscaling of several operators), there is\n+ * the cross product of channels. So if two subtasks are collapsed and two channels overlap from the\n+ * output side, there is a total of 4 virtual channels.\n+ */\n+@Internal\n+public final class RescalingStreamTaskNetworkInput<T>\n+        extends AbstractStreamTaskNetworkInput<T, DemultiplexingRecordDeserializer<T>>\n+        implements RecoverableStreamTaskInput<T> {\n+\n+    private static final Logger LOG =\n+            LoggerFactory.getLogger(RescalingStreamTaskNetworkInput.class);\n+    private final IOManager ioManager;\n+\n+    private RescalingStreamTaskNetworkInput(\n+            CheckpointedInputGate checkpointedInputGate,\n+            TypeSerializer<T> inputSerializer,\n+            IOManager ioManager,\n+            StatusWatermarkValve statusWatermarkValve,\n+            int inputIndex,\n+            InflightDataRescalingDescriptor inflightDataRescalingDescriptor,\n+            Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+            TaskInfo taskInfo) {\n+        super(\n+                checkpointedInputGate,\n+                inputSerializer,\n+                statusWatermarkValve,\n+                inputIndex,\n+                getRecordDeserializers(\n+                        checkpointedInputGate,\n+                        inputSerializer,\n+                        ioManager,\n+                        inflightDataRescalingDescriptor,\n+                        gatePartitioners,\n+                        taskInfo));\n+        this.ioManager = ioManager;\n+\n+        LOG.info(\n+                \"Created demultiplexer for input {} from {}\",\n+                inputIndex,\n+                inflightDataRescalingDescriptor);\n+    }\n+\n+    private static <T>\n+            Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> getRecordDeserializers(\n+                    CheckpointedInputGate checkpointedInputGate,\n+                    TypeSerializer<T> inputSerializer,\n+                    IOManager ioManager,\n+                    InflightDataRescalingDescriptor rescalingDescriptor,\n+                    Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+                    TaskInfo taskInfo) {\n+\n+        RecordFilterFactory<T> recordFilterFactory =\n+                new RecordFilterFactory<>(\n+                        taskInfo.getIndexOfThisSubtask(),\n+                        inputSerializer,\n+                        taskInfo.getNumberOfParallelSubtasks(),\n+                        gatePartitioners,\n+                        taskInfo.getMaxNumberOfParallelSubtasks());\n+        final DeserializerFactory deserializerFactory = new DeserializerFactory(ioManager);\n+        Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> deserializers =\n+                Maps.newHashMapWithExpectedSize(checkpointedInputGate.getChannelInfos().size());\n+        for (InputChannelInfo channelInfo : checkpointedInputGate.getChannelInfos()) {\n+            deserializers.put(\n+                    channelInfo,\n+                    DemultiplexingRecordDeserializer.create(\n+                            channelInfo,\n+                            rescalingDescriptor,\n+                            deserializerFactory,\n+                            recordFilterFactory));\n+        }\n+        return deserializers;\n+    }\n+\n+    @Override\n+    public StreamTaskInput<T> finishRecovery() throws IOException {\n+        close();\n+        return new StreamTaskNetworkInput<>(\n+                checkpointedInputGate,\n+                inputSerializer,\n+                ioManager,\n+                statusWatermarkValve,\n+                inputIndex);\n+    }\n+\n+    /**\n+     * Factory method for {@link StreamTaskNetworkInput} or {@link RescalingStreamTaskNetworkInput}\n+     * depending on {@link InflightDataRescalingDescriptor}.\n+     */\n+    public static <T> StreamTaskInput<T> create(\n+            CheckpointedInputGate checkpointedInputGate,\n+            TypeSerializer<T> inputSerializer,\n+            IOManager ioManager,\n+            StatusWatermarkValve statusWatermarkValve,\n+            int inputIndex,\n+            InflightDataRescalingDescriptor rescalingDescriptorinflightDataRescalingDescriptor,\n+            Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+            TaskInfo taskInfo) {\n+        return rescalingDescriptorinflightDataRescalingDescriptor.equals(\n+                        InflightDataRescalingDescriptor.NO_RESCALE)\n+                ? new StreamTaskNetworkInput<>(\n+                        checkpointedInputGate,\n+                        inputSerializer,\n+                        ioManager,\n+                        statusWatermarkValve,\n+                        inputIndex)\n+                : new RescalingStreamTaskNetworkInput<>(\n+                        checkpointedInputGate,\n+                        inputSerializer,\n+                        ioManager,\n+                        statusWatermarkValve,\n+                        inputIndex,\n+                        rescalingDescriptorinflightDataRescalingDescriptor,\n+                        gatePartitioners,\n+                        taskInfo);\n+    }\n+\n+    protected DemultiplexingRecordDeserializer<T> getActiveSerializer(\n+            InputChannelInfo channelInfo) {\n+        final DemultiplexingRecordDeserializer<T> deserialier =\n+                recordDeserializers.get(channelInfo);\n+        if (!deserialier.hasMappings()) {\n+            throw new IllegalStateException(\n+                    \"Channel \" + channelInfo + \" should not receive data during recovery.\");\n+        }\n+        return deserialier;\n+    }\n+\n+    protected InputStatus processEvent(BufferOrEvent bufferOrEvent) {\n+        // Event received\n+        final AbstractEvent event = bufferOrEvent.getEvent();\n+        if (event instanceof VirtualChannelSelector) {\n+            getActiveSerializer(bufferOrEvent.getChannelInfo())\n+                    .select((VirtualChannelSelector) event);\n+            return InputStatus.MORE_AVAILABLE;\n+        }\n+        return super.processEvent(bufferOrEvent);\n+    }\n+\n+    @Override\n+    public CompletableFuture<Void> prepareSnapshot(\n+            ChannelStateWriter channelStateWriter, long checkpointId) throws CheckpointException {\n+        throw new CheckpointException(CHECKPOINT_DECLINED_TASK_NOT_READY);\n+    }\n+\n+    static class RecordFilterFactory<T>\n+            implements Function<InputChannelInfo, Predicate<StreamRecord<T>>> {\n+        private final Map<Integer, StreamPartitioner<T>> partitionerCache = new HashMap<>(1);\n+        private final Function<Integer, StreamPartitioner<?>> gatePartitioners;\n+        private final TypeSerializer<T> inputSerializer;\n+        private final int numberOfChannels;\n+        private int subtaskIndex;\n+        private int maxParallelism;\n+\n+        public RecordFilterFactory(\n+                int subtaskIndex,\n+                TypeSerializer<T> inputSerializer,\n+                int numberOfChannels,\n+                Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+                int maxParallelism) {\n+            this.gatePartitioners = gatePartitioners;\n+            this.inputSerializer = inputSerializer;\n+            this.numberOfChannels = numberOfChannels;\n+            this.subtaskIndex = subtaskIndex;\n+            this.maxParallelism = maxParallelism;\n+        }\n+\n+        @Override\n+        public Predicate<StreamRecord<T>> apply(InputChannelInfo channelInfo) {\n+            return new RecordFilter<>(\n+                    partitionerCache.computeIfAbsent(\n+                            channelInfo.getGateIdx(), this::createPartitioner),\n+                    inputSerializer,\n+                    subtaskIndex);\n+        }\n+\n+        private StreamPartitioner<T> createPartitioner(Integer index) {\n+            StreamPartitioner<T> partitioner = (StreamPartitioner<T>) gatePartitioners.apply(index);\n+            partitioner.setup(numberOfChannels);\n+            if (partitioner instanceof ConfigurableStreamPartitioner) {\n+                ((ConfigurableStreamPartitioner) partitioner).configure(maxParallelism);\n+            }\n+            return partitioner;\n+        }\n+    }\n+\n+    static class DeserializerFactory\n+            implements Function<\n+                    Integer, RecordDeserializer<DeserializationDelegate<StreamElement>>> {\n+        private final IOManager ioManager;\n+\n+        public DeserializerFactory(IOManager ioManager) {\n+            this.ioManager = ioManager;\n+        }\n+\n+        @Override\n+        public RecordDeserializer<DeserializationDelegate<StreamElement>> apply(\n+                Integer totalChannels) {\n+            return new SpillingAdaptiveSpanningRecordDeserializer<>(\n+                    ioManager.getSpillingDirectoriesPaths(),\n+                    SpillingAdaptiveSpanningRecordDeserializer.DEFAULT_THRESHOLD_FOR_SPILLING\n+                            / totalChannels,\n+                    SpillingAdaptiveSpanningRecordDeserializer.DEFAULT_FILE_BUFFER_SIZE\n+                            / totalChannels);\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd18dbb4154a033a55320c2740e2499ac7d63ff9"}, "originalPosition": 278}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzI3OTE0MA==", "bodyText": "Good catch. I added some minimum (probably up to debate).", "url": "https://github.com/apache/flink/pull/13845#discussion_r587279140", "createdAt": "2021-03-04T08:57:45Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java", "diffHunk": "@@ -0,0 +1,280 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io.recovery;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.TaskInfo;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.io.InputStatus;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.event.AbstractEvent;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.partition.consumer.BufferOrEvent;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput;\n+import org.apache.flink.streaming.runtime.io.RecoverableStreamTaskInput;\n+import org.apache.flink.streaming.runtime.io.StreamTaskInput;\n+import org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput;\n+import org.apache.flink.streaming.runtime.io.checkpointing.CheckpointedInputGate;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StatusWatermarkValve;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+\n+import static org.apache.flink.runtime.checkpoint.CheckpointFailureReason.CHECKPOINT_DECLINED_TASK_NOT_READY;\n+\n+/**\n+ * A {@link StreamTaskNetworkInput} implementation that demultiplexes virtual channels.\n+ *\n+ * <p>The demultiplexing works in two dimensions for the following cases. *\n+ *\n+ * <ul>\n+ *   <li>Subtasks of the current operator have been collapsed in a round-robin fashion.\n+ *   <li>The connected output operator has been rescaled (up and down!) and there is an overlap of\n+ *       channels (mostly relevant to keyed exchanges).\n+ * </ul>\n+ *\n+ * <p>In both cases, records from multiple old channels are received over one new physical channel,\n+ * which need to demultiplex the record to correctly restore spanning records (similar to how\n+ * StreamTaskNetworkInput works).\n+ *\n+ * <p>Note that when both cases occur at the same time (downscaling of several operators), there is\n+ * the cross product of channels. So if two subtasks are collapsed and two channels overlap from the\n+ * output side, there is a total of 4 virtual channels.\n+ */\n+@Internal\n+public final class RescalingStreamTaskNetworkInput<T>\n+        extends AbstractStreamTaskNetworkInput<T, DemultiplexingRecordDeserializer<T>>\n+        implements RecoverableStreamTaskInput<T> {\n+\n+    private static final Logger LOG =\n+            LoggerFactory.getLogger(RescalingStreamTaskNetworkInput.class);\n+    private final IOManager ioManager;\n+\n+    private RescalingStreamTaskNetworkInput(\n+            CheckpointedInputGate checkpointedInputGate,\n+            TypeSerializer<T> inputSerializer,\n+            IOManager ioManager,\n+            StatusWatermarkValve statusWatermarkValve,\n+            int inputIndex,\n+            InflightDataRescalingDescriptor inflightDataRescalingDescriptor,\n+            Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+            TaskInfo taskInfo) {\n+        super(\n+                checkpointedInputGate,\n+                inputSerializer,\n+                statusWatermarkValve,\n+                inputIndex,\n+                getRecordDeserializers(\n+                        checkpointedInputGate,\n+                        inputSerializer,\n+                        ioManager,\n+                        inflightDataRescalingDescriptor,\n+                        gatePartitioners,\n+                        taskInfo));\n+        this.ioManager = ioManager;\n+\n+        LOG.info(\n+                \"Created demultiplexer for input {} from {}\",\n+                inputIndex,\n+                inflightDataRescalingDescriptor);\n+    }\n+\n+    private static <T>\n+            Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> getRecordDeserializers(\n+                    CheckpointedInputGate checkpointedInputGate,\n+                    TypeSerializer<T> inputSerializer,\n+                    IOManager ioManager,\n+                    InflightDataRescalingDescriptor rescalingDescriptor,\n+                    Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+                    TaskInfo taskInfo) {\n+\n+        RecordFilterFactory<T> recordFilterFactory =\n+                new RecordFilterFactory<>(\n+                        taskInfo.getIndexOfThisSubtask(),\n+                        inputSerializer,\n+                        taskInfo.getNumberOfParallelSubtasks(),\n+                        gatePartitioners,\n+                        taskInfo.getMaxNumberOfParallelSubtasks());\n+        final DeserializerFactory deserializerFactory = new DeserializerFactory(ioManager);\n+        Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> deserializers =\n+                Maps.newHashMapWithExpectedSize(checkpointedInputGate.getChannelInfos().size());\n+        for (InputChannelInfo channelInfo : checkpointedInputGate.getChannelInfos()) {\n+            deserializers.put(\n+                    channelInfo,\n+                    DemultiplexingRecordDeserializer.create(\n+                            channelInfo,\n+                            rescalingDescriptor,\n+                            deserializerFactory,\n+                            recordFilterFactory));\n+        }\n+        return deserializers;\n+    }\n+\n+    @Override\n+    public StreamTaskInput<T> finishRecovery() throws IOException {\n+        close();\n+        return new StreamTaskNetworkInput<>(\n+                checkpointedInputGate,\n+                inputSerializer,\n+                ioManager,\n+                statusWatermarkValve,\n+                inputIndex);\n+    }\n+\n+    /**\n+     * Factory method for {@link StreamTaskNetworkInput} or {@link RescalingStreamTaskNetworkInput}\n+     * depending on {@link InflightDataRescalingDescriptor}.\n+     */\n+    public static <T> StreamTaskInput<T> create(\n+            CheckpointedInputGate checkpointedInputGate,\n+            TypeSerializer<T> inputSerializer,\n+            IOManager ioManager,\n+            StatusWatermarkValve statusWatermarkValve,\n+            int inputIndex,\n+            InflightDataRescalingDescriptor rescalingDescriptorinflightDataRescalingDescriptor,\n+            Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+            TaskInfo taskInfo) {\n+        return rescalingDescriptorinflightDataRescalingDescriptor.equals(\n+                        InflightDataRescalingDescriptor.NO_RESCALE)\n+                ? new StreamTaskNetworkInput<>(\n+                        checkpointedInputGate,\n+                        inputSerializer,\n+                        ioManager,\n+                        statusWatermarkValve,\n+                        inputIndex)\n+                : new RescalingStreamTaskNetworkInput<>(\n+                        checkpointedInputGate,\n+                        inputSerializer,\n+                        ioManager,\n+                        statusWatermarkValve,\n+                        inputIndex,\n+                        rescalingDescriptorinflightDataRescalingDescriptor,\n+                        gatePartitioners,\n+                        taskInfo);\n+    }\n+\n+    protected DemultiplexingRecordDeserializer<T> getActiveSerializer(\n+            InputChannelInfo channelInfo) {\n+        final DemultiplexingRecordDeserializer<T> deserialier =\n+                recordDeserializers.get(channelInfo);\n+        if (!deserialier.hasMappings()) {\n+            throw new IllegalStateException(\n+                    \"Channel \" + channelInfo + \" should not receive data during recovery.\");\n+        }\n+        return deserialier;\n+    }\n+\n+    protected InputStatus processEvent(BufferOrEvent bufferOrEvent) {\n+        // Event received\n+        final AbstractEvent event = bufferOrEvent.getEvent();\n+        if (event instanceof VirtualChannelSelector) {\n+            getActiveSerializer(bufferOrEvent.getChannelInfo())\n+                    .select((VirtualChannelSelector) event);\n+            return InputStatus.MORE_AVAILABLE;\n+        }\n+        return super.processEvent(bufferOrEvent);\n+    }\n+\n+    @Override\n+    public CompletableFuture<Void> prepareSnapshot(\n+            ChannelStateWriter channelStateWriter, long checkpointId) throws CheckpointException {\n+        throw new CheckpointException(CHECKPOINT_DECLINED_TASK_NOT_READY);\n+    }\n+\n+    static class RecordFilterFactory<T>\n+            implements Function<InputChannelInfo, Predicate<StreamRecord<T>>> {\n+        private final Map<Integer, StreamPartitioner<T>> partitionerCache = new HashMap<>(1);\n+        private final Function<Integer, StreamPartitioner<?>> gatePartitioners;\n+        private final TypeSerializer<T> inputSerializer;\n+        private final int numberOfChannels;\n+        private int subtaskIndex;\n+        private int maxParallelism;\n+\n+        public RecordFilterFactory(\n+                int subtaskIndex,\n+                TypeSerializer<T> inputSerializer,\n+                int numberOfChannels,\n+                Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+                int maxParallelism) {\n+            this.gatePartitioners = gatePartitioners;\n+            this.inputSerializer = inputSerializer;\n+            this.numberOfChannels = numberOfChannels;\n+            this.subtaskIndex = subtaskIndex;\n+            this.maxParallelism = maxParallelism;\n+        }\n+\n+        @Override\n+        public Predicate<StreamRecord<T>> apply(InputChannelInfo channelInfo) {\n+            return new RecordFilter<>(\n+                    partitionerCache.computeIfAbsent(\n+                            channelInfo.getGateIdx(), this::createPartitioner),\n+                    inputSerializer,\n+                    subtaskIndex);\n+        }\n+\n+        private StreamPartitioner<T> createPartitioner(Integer index) {\n+            StreamPartitioner<T> partitioner = (StreamPartitioner<T>) gatePartitioners.apply(index);\n+            partitioner.setup(numberOfChannels);\n+            if (partitioner instanceof ConfigurableStreamPartitioner) {\n+                ((ConfigurableStreamPartitioner) partitioner).configure(maxParallelism);\n+            }\n+            return partitioner;\n+        }\n+    }\n+\n+    static class DeserializerFactory\n+            implements Function<\n+                    Integer, RecordDeserializer<DeserializationDelegate<StreamElement>>> {\n+        private final IOManager ioManager;\n+\n+        public DeserializerFactory(IOManager ioManager) {\n+            this.ioManager = ioManager;\n+        }\n+\n+        @Override\n+        public RecordDeserializer<DeserializationDelegate<StreamElement>> apply(\n+                Integer totalChannels) {\n+            return new SpillingAdaptiveSpanningRecordDeserializer<>(\n+                    ioManager.getSpillingDirectoriesPaths(),\n+                    SpillingAdaptiveSpanningRecordDeserializer.DEFAULT_THRESHOLD_FOR_SPILLING\n+                            / totalChannels,\n+                    SpillingAdaptiveSpanningRecordDeserializer.DEFAULT_FILE_BUFFER_SIZE\n+                            / totalChannels);\n+        }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzUwMjEzNA=="}, "originalCommit": {"oid": "bd18dbb4154a033a55320c2740e2499ac7d63ff9"}, "originalPosition": 278}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzY4MTEyMjY2OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yNlQxMDoxNTo0MFrOIsf2Dg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0wNFQwOTowODo1OFrOIwFKHw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzUyOTk5OA==", "bodyText": "Do we need to make sure that all the buffers in deserializers are consumed?", "url": "https://github.com/apache/flink/pull/13845#discussion_r583529998", "createdAt": "2021-02-26T10:15:40Z", "author": {"login": "rkhachatryan"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java", "diffHunk": "@@ -0,0 +1,280 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io.recovery;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.TaskInfo;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.io.InputStatus;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.event.AbstractEvent;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.partition.consumer.BufferOrEvent;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput;\n+import org.apache.flink.streaming.runtime.io.RecoverableStreamTaskInput;\n+import org.apache.flink.streaming.runtime.io.StreamTaskInput;\n+import org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput;\n+import org.apache.flink.streaming.runtime.io.checkpointing.CheckpointedInputGate;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StatusWatermarkValve;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+\n+import static org.apache.flink.runtime.checkpoint.CheckpointFailureReason.CHECKPOINT_DECLINED_TASK_NOT_READY;\n+\n+/**\n+ * A {@link StreamTaskNetworkInput} implementation that demultiplexes virtual channels.\n+ *\n+ * <p>The demultiplexing works in two dimensions for the following cases. *\n+ *\n+ * <ul>\n+ *   <li>Subtasks of the current operator have been collapsed in a round-robin fashion.\n+ *   <li>The connected output operator has been rescaled (up and down!) and there is an overlap of\n+ *       channels (mostly relevant to keyed exchanges).\n+ * </ul>\n+ *\n+ * <p>In both cases, records from multiple old channels are received over one new physical channel,\n+ * which need to demultiplex the record to correctly restore spanning records (similar to how\n+ * StreamTaskNetworkInput works).\n+ *\n+ * <p>Note that when both cases occur at the same time (downscaling of several operators), there is\n+ * the cross product of channels. So if two subtasks are collapsed and two channels overlap from the\n+ * output side, there is a total of 4 virtual channels.\n+ */\n+@Internal\n+public final class RescalingStreamTaskNetworkInput<T>\n+        extends AbstractStreamTaskNetworkInput<T, DemultiplexingRecordDeserializer<T>>\n+        implements RecoverableStreamTaskInput<T> {\n+\n+    private static final Logger LOG =\n+            LoggerFactory.getLogger(RescalingStreamTaskNetworkInput.class);\n+    private final IOManager ioManager;\n+\n+    private RescalingStreamTaskNetworkInput(\n+            CheckpointedInputGate checkpointedInputGate,\n+            TypeSerializer<T> inputSerializer,\n+            IOManager ioManager,\n+            StatusWatermarkValve statusWatermarkValve,\n+            int inputIndex,\n+            InflightDataRescalingDescriptor inflightDataRescalingDescriptor,\n+            Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+            TaskInfo taskInfo) {\n+        super(\n+                checkpointedInputGate,\n+                inputSerializer,\n+                statusWatermarkValve,\n+                inputIndex,\n+                getRecordDeserializers(\n+                        checkpointedInputGate,\n+                        inputSerializer,\n+                        ioManager,\n+                        inflightDataRescalingDescriptor,\n+                        gatePartitioners,\n+                        taskInfo));\n+        this.ioManager = ioManager;\n+\n+        LOG.info(\n+                \"Created demultiplexer for input {} from {}\",\n+                inputIndex,\n+                inflightDataRescalingDescriptor);\n+    }\n+\n+    private static <T>\n+            Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> getRecordDeserializers(\n+                    CheckpointedInputGate checkpointedInputGate,\n+                    TypeSerializer<T> inputSerializer,\n+                    IOManager ioManager,\n+                    InflightDataRescalingDescriptor rescalingDescriptor,\n+                    Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+                    TaskInfo taskInfo) {\n+\n+        RecordFilterFactory<T> recordFilterFactory =\n+                new RecordFilterFactory<>(\n+                        taskInfo.getIndexOfThisSubtask(),\n+                        inputSerializer,\n+                        taskInfo.getNumberOfParallelSubtasks(),\n+                        gatePartitioners,\n+                        taskInfo.getMaxNumberOfParallelSubtasks());\n+        final DeserializerFactory deserializerFactory = new DeserializerFactory(ioManager);\n+        Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> deserializers =\n+                Maps.newHashMapWithExpectedSize(checkpointedInputGate.getChannelInfos().size());\n+        for (InputChannelInfo channelInfo : checkpointedInputGate.getChannelInfos()) {\n+            deserializers.put(\n+                    channelInfo,\n+                    DemultiplexingRecordDeserializer.create(\n+                            channelInfo,\n+                            rescalingDescriptor,\n+                            deserializerFactory,\n+                            recordFilterFactory));\n+        }\n+        return deserializers;\n+    }\n+\n+    @Override\n+    public StreamTaskInput<T> finishRecovery() throws IOException {\n+        close();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd18dbb4154a033a55320c2740e2499ac7d63ff9"}, "originalPosition": 150}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzI4NzA3MQ==", "bodyText": "Yes good idea.", "url": "https://github.com/apache/flink/pull/13845#discussion_r587287071", "createdAt": "2021-03-04T09:08:58Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java", "diffHunk": "@@ -0,0 +1,280 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io.recovery;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.TaskInfo;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.io.InputStatus;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.event.AbstractEvent;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.partition.consumer.BufferOrEvent;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput;\n+import org.apache.flink.streaming.runtime.io.RecoverableStreamTaskInput;\n+import org.apache.flink.streaming.runtime.io.StreamTaskInput;\n+import org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput;\n+import org.apache.flink.streaming.runtime.io.checkpointing.CheckpointedInputGate;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StatusWatermarkValve;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+\n+import static org.apache.flink.runtime.checkpoint.CheckpointFailureReason.CHECKPOINT_DECLINED_TASK_NOT_READY;\n+\n+/**\n+ * A {@link StreamTaskNetworkInput} implementation that demultiplexes virtual channels.\n+ *\n+ * <p>The demultiplexing works in two dimensions for the following cases. *\n+ *\n+ * <ul>\n+ *   <li>Subtasks of the current operator have been collapsed in a round-robin fashion.\n+ *   <li>The connected output operator has been rescaled (up and down!) and there is an overlap of\n+ *       channels (mostly relevant to keyed exchanges).\n+ * </ul>\n+ *\n+ * <p>In both cases, records from multiple old channels are received over one new physical channel,\n+ * which need to demultiplex the record to correctly restore spanning records (similar to how\n+ * StreamTaskNetworkInput works).\n+ *\n+ * <p>Note that when both cases occur at the same time (downscaling of several operators), there is\n+ * the cross product of channels. So if two subtasks are collapsed and two channels overlap from the\n+ * output side, there is a total of 4 virtual channels.\n+ */\n+@Internal\n+public final class RescalingStreamTaskNetworkInput<T>\n+        extends AbstractStreamTaskNetworkInput<T, DemultiplexingRecordDeserializer<T>>\n+        implements RecoverableStreamTaskInput<T> {\n+\n+    private static final Logger LOG =\n+            LoggerFactory.getLogger(RescalingStreamTaskNetworkInput.class);\n+    private final IOManager ioManager;\n+\n+    private RescalingStreamTaskNetworkInput(\n+            CheckpointedInputGate checkpointedInputGate,\n+            TypeSerializer<T> inputSerializer,\n+            IOManager ioManager,\n+            StatusWatermarkValve statusWatermarkValve,\n+            int inputIndex,\n+            InflightDataRescalingDescriptor inflightDataRescalingDescriptor,\n+            Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+            TaskInfo taskInfo) {\n+        super(\n+                checkpointedInputGate,\n+                inputSerializer,\n+                statusWatermarkValve,\n+                inputIndex,\n+                getRecordDeserializers(\n+                        checkpointedInputGate,\n+                        inputSerializer,\n+                        ioManager,\n+                        inflightDataRescalingDescriptor,\n+                        gatePartitioners,\n+                        taskInfo));\n+        this.ioManager = ioManager;\n+\n+        LOG.info(\n+                \"Created demultiplexer for input {} from {}\",\n+                inputIndex,\n+                inflightDataRescalingDescriptor);\n+    }\n+\n+    private static <T>\n+            Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> getRecordDeserializers(\n+                    CheckpointedInputGate checkpointedInputGate,\n+                    TypeSerializer<T> inputSerializer,\n+                    IOManager ioManager,\n+                    InflightDataRescalingDescriptor rescalingDescriptor,\n+                    Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+                    TaskInfo taskInfo) {\n+\n+        RecordFilterFactory<T> recordFilterFactory =\n+                new RecordFilterFactory<>(\n+                        taskInfo.getIndexOfThisSubtask(),\n+                        inputSerializer,\n+                        taskInfo.getNumberOfParallelSubtasks(),\n+                        gatePartitioners,\n+                        taskInfo.getMaxNumberOfParallelSubtasks());\n+        final DeserializerFactory deserializerFactory = new DeserializerFactory(ioManager);\n+        Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> deserializers =\n+                Maps.newHashMapWithExpectedSize(checkpointedInputGate.getChannelInfos().size());\n+        for (InputChannelInfo channelInfo : checkpointedInputGate.getChannelInfos()) {\n+            deserializers.put(\n+                    channelInfo,\n+                    DemultiplexingRecordDeserializer.create(\n+                            channelInfo,\n+                            rescalingDescriptor,\n+                            deserializerFactory,\n+                            recordFilterFactory));\n+        }\n+        return deserializers;\n+    }\n+\n+    @Override\n+    public StreamTaskInput<T> finishRecovery() throws IOException {\n+        close();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzUyOTk5OA=="}, "originalCommit": {"oid": "bd18dbb4154a033a55320c2740e2499ac7d63ff9"}, "originalPosition": 150}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4990, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}