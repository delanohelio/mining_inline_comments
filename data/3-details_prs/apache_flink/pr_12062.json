{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE1ODI3Njg2", "number": 12062, "title": "[FLINK-17587][filesystem] Filesystem streaming sink support commit success file", "bodyText": "What is the purpose of the change\nCommitting a partition is to notify the downstream application that the partition has finished writing, the partition is ready to be read.\nAdd \u201c.succes\u201d file to directory (success file name is configurable too)\nBrief change log\n\nThis PR is based on #12053\nStreamingFileWriter(parallelism) -> StreamingFileCommitter(Single task to commit partition)\n\nVerifying this change\nStreamFileSystemTestCsvITCase\nDoes this pull request potentially affect one of the following parts:\n\nDependencies (does it add or upgrade a dependency): no\nThe public API, i.e., is any changed class annotated with @Public(Evolving): no\nThe serializers: no\nThe runtime per-record code paths (performance sensitive): no\nAnything that affects deployment or recovery: JobManager (and its components), Checkpointing, Kubernetes/Yarn/Mesos, ZooKeeper: no\nThe S3 file system connector: no\n\nDocumentation\n\nDoes this pull request introduce a new feature? (yes)\nIf yes, how is the feature documented? JavaDocs", "createdAt": "2020-05-11T02:10:15Z", "url": "https://github.com/apache/flink/pull/12062", "merged": true, "mergeCommit": {"oid": "b8434803367a8360b5f5b9ad4a711985746ac112"}, "closed": true, "closedAt": "2020-05-16T06:16:24Z", "author": {"login": "JingsongLi"}, "timelineItems": {"totalCount": 18, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcgJcf-ABqjMzMjE0MDQ5MTI=", "endCursor": "Y3Vyc29yOnYyOpPPAAABchv49QABqjMzNDMyNDQyNjE=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "38d4e669261a6fde7595223bf804b45e838476b2", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/38d4e669261a6fde7595223bf804b45e838476b2", "committedDate": "2020-05-11T02:00:10Z", "message": "[FLINK-17587][filesystem] Filesystem streaming sink support commit success file"}, "afterCommit": {"oid": "8ea1504837c815c55f8a41a7fa887285333c62a6", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/8ea1504837c815c55f8a41a7fa887285333c62a6", "committedDate": "2020-05-11T06:11:36Z", "message": "Fix"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8ea1504837c815c55f8a41a7fa887285333c62a6", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/8ea1504837c815c55f8a41a7fa887285333c62a6", "committedDate": "2020-05-11T06:11:36Z", "message": "Fix"}, "afterCommit": {"oid": "e5127c6a73d24f0c9c03deb0a7518fb18832b744", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/e5127c6a73d24f0c9c03deb0a7518fb18832b744", "committedDate": "2020-05-11T08:54:17Z", "message": "Rebase"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA4OTIyNDA1", "url": "https://github.com/apache/flink/pull/12062#pullrequestreview-408922405", "createdAt": "2020-05-11T07:26:43Z", "commit": {"oid": "8ea1504837c815c55f8a41a7fa887285333c62a6"}, "state": "COMMENTED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMVQwNzoyNjo0M1rOGTP3PA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMVQxMjoyMTozOVrOGTZ2gw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjgzNjAyOA==", "bodyText": "Why do we need this change?", "url": "https://github.com/apache/flink/pull/12062#discussion_r422836028", "createdAt": "2020-05-11T07:26:43Z", "author": {"login": "lirui-apache"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/functions/sink/filesystem/StreamingFileSink.java", "diffHunk": "@@ -467,7 +483,11 @@ public void onProcessingTime(long timestamp) throws Exception {\n \n \t@Override\n \tpublic void invoke(IN value, SinkFunction.Context context) throws Exception {\n-\t\tbuckets.onElement(value, context);\n+\t\tbuckets.onElement(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8ea1504837c815c55f8a41a7fa887285333c62a6"}, "originalPosition": 101}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjkxMjEyNQ==", "bodyText": "add descriptions", "url": "https://github.com/apache/flink/pull/12062#discussion_r422912125", "createdAt": "2020-05-11T09:35:58Z", "author": {"login": "lirui-apache"}, "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/filesystem/FileSystemOptions.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.filesystem;\n+\n+import org.apache.flink.configuration.ConfigOption;\n+\n+import java.time.Duration;\n+\n+import static org.apache.flink.configuration.ConfigOptions.key;\n+\n+/**\n+ * This class holds configuration constants used by filesystem(Including hive) connector.\n+ */\n+public class FileSystemOptions {\n+\n+\tpublic static final ConfigOption<String> PARTITION_TIME_EXTRACTOR_TYPE =\n+\t\t\tkey(\"partition.time-extractor.type\")\n+\t\t\t\t\t.stringType()\n+\t\t\t\t\t.defaultValue(\"default\")\n+\t\t\t\t\t.withDescription(\"Time extractor to extract time from partition values. Only be\" +\n+\t\t\t\t\t\t\t\" used if order is set to partition-time. Support default and custom.\" +\n+\t\t\t\t\t\t\t\" For default, can configure timestamp pattern.\" +\n+\t\t\t\t\t\t\t\" For custom, should configure extractor class.\");\n+\n+\tpublic static final ConfigOption<String> PARTITION_TIME_EXTRACTOR_CLASS =\n+\t\t\tkey(\"partition.time-extractor.class\")\n+\t\t\t\t\t.stringType()\n+\t\t\t\t\t.noDefaultValue()\n+\t\t\t\t\t.withDescription(\"The extractor class for implement PartitionTimeExtractor interface.\");\n+\n+\tpublic static final ConfigOption<String> PARTITION_TIME_EXTRACTOR_TIMESTAMP_PATTERN =\n+\t\t\tkey(\"partition.time-extractor.timestamp-pattern\")\n+\t\t\t\t\t.stringType()\n+\t\t\t\t\t.noDefaultValue()\n+\t\t\t\t\t.withDescription(\"The 'default' construction way allows users to use partition\" +\n+\t\t\t\t\t\t\t\" fields to get a legal timestamp pattern.\" +\n+\t\t\t\t\t\t\t\" Default support 'yyyy-mm-dd hh:mm:ss' from first field.\" +\n+\t\t\t\t\t\t\t\" If timestamp in partition is single field 'dt', can configure: '$dt'.\" +\n+\t\t\t\t\t\t\t\" If timestamp in partition is year, month, day, hour,\" +\n+\t\t\t\t\t\t\t\" can configure: '$year-$month-$day $hour:00:00'.\" +\n+\t\t\t\t\t\t\t\" If timestamp in partition is dt and hour, can configure: '$dt $hour:00:00'.\");\n+\n+\tpublic static final ConfigOption<Duration> PARTITION_TIME_INTERVAL =\n+\t\t\tkey(\"partition.time-interval\")\n+\t\t\t\t\t.durationType()\n+\t\t\t\t\t.noDefaultValue()\n+\t\t\t\t\t.withDescription(\"Interval time of partition,\" +\n+\t\t\t\t\t\t\t\" if it is a day partition, should be '1 d',\" +\n+\t\t\t\t\t\t\t\" if it is a hour partition, should be '1 h'\");\n+\n+\tpublic static final ConfigOption<String> PARTITION_COMMIT_POLICY_TYPE =\n+\t\t\tkey(\"partition.commit-policy.type\")\n+\t\t\t\t\t.stringType()\n+\t\t\t\t\t.noDefaultValue()\n+\t\t\t\t\t.withDescription(\"\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e5127c6a73d24f0c9c03deb0a7518fb18832b744"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjk4OTMwNA==", "bodyText": "Can we have some comments about which partitions should be in this list? My understanding is it should include partitions for which some files should be committed, right?", "url": "https://github.com/apache/flink/pull/12062#discussion_r422989304", "createdAt": "2020-05-11T12:01:15Z", "author": {"login": "lirui-apache"}, "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/filesystem/stream/StreamingFileCommitter.java", "diffHunk": "@@ -0,0 +1,175 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.filesystem.stream;\n+\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.core.fs.FileSystem;\n+import org.apache.flink.core.fs.Path;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.streaming.api.operators.AbstractStreamOperator;\n+import org.apache.flink.streaming.api.operators.OneInputStreamOperator;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.table.filesystem.TableMetaStoreFactory;\n+\n+import java.io.Serializable;\n+import java.util.HashSet;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.TreeMap;\n+\n+import static org.apache.flink.table.filesystem.FileSystemOptions.PARTITION_COMMIT_POLICY_SUCCESS_FILE_NAME;\n+import static org.apache.flink.table.filesystem.FileSystemOptions.PARTITION_COMMIT_POLICY_TYPE;\n+import static org.apache.flink.table.utils.PartitionPathUtils.extractPartitionSpecFromPath;\n+import static org.apache.flink.table.utils.PartitionPathUtils.generatePartitionPath;\n+\n+/**\n+ * Committer for {@link StreamingFileWriter}. This is the single (non-parallel) task.\n+ */\n+public class StreamingFileCommitter extends AbstractStreamOperator<Void>\n+\t\timplements OneInputStreamOperator<StreamingFileCommitter.CommitMessage, Void> {\n+\n+\tprivate static final long serialVersionUID = 1L;\n+\n+\tprivate final Configuration conf;\n+\n+\tprivate final List<String> partitionKeys;\n+\n+\tprivate final TableMetaStoreFactory metaStoreFactory;\n+\n+\tprivate transient PartitionCommitManager commitManager;\n+\n+\tprivate transient TaskTracker taskTracker;\n+\n+\tprivate transient long currentWatermark = Long.MIN_VALUE;\n+\n+\tprivate transient List<PartitionCommitPolicy> policies;\n+\n+\tpublic StreamingFileCommitter(\n+\t\t\tList<String> partitionKeys, TableMetaStoreFactory metaStoreFactory, Configuration conf) {\n+\t\tthis.partitionKeys = partitionKeys;\n+\t\tthis.metaStoreFactory = metaStoreFactory;\n+\t\tthis.conf = conf;\n+\t}\n+\n+\t@Override\n+\tpublic void initializeState(StateInitializationContext context) throws Exception {\n+\t\tsuper.initializeState(context);\n+\t\tthis.commitManager = new PartitionCommitManager(\n+\t\t\t\tcontext.isRestored(),\n+\t\t\t\tcontext.getOperatorStateStore(),\n+\t\t\t\tgetUserCodeClassloader(),\n+\t\t\t\tpartitionKeys,\n+\t\t\t\tconf);\n+\t\tthis.policies = PartitionCommitPolicy.createCommitChain(\n+\t\t\t\tconf.get(PARTITION_COMMIT_POLICY_TYPE),\n+\t\t\t\tconf.get(PARTITION_COMMIT_POLICY_SUCCESS_FILE_NAME));\n+\t}\n+\n+\t@Override\n+\tpublic void processElement(StreamRecord<CommitMessage> element) throws Exception {\n+\t\tCommitMessage message = element.getValue();\n+\t\tfor (String partition : message.partitions) {\n+\t\t\tcommitManager.addPartition(partition);\n+\t\t}\n+\n+\t\tif (taskTracker == null) {\n+\t\t\ttaskTracker = new TaskTracker(message.numberOfTasks);\n+\t\t}\n+\t\tboolean needCommit = taskTracker.add(message.checkpointId, message.taskId);\n+\t\tif (needCommit) {\n+\t\t\tcommitPartitions(commitManager.triggerCommit(message.checkpointId));\n+\t\t}\n+\t}\n+\n+\tprivate void commitPartitions(List<String> partitions) throws Exception {\n+\t\ttry (TableMetaStoreFactory.TableMetaStore metaStore = metaStoreFactory.createTableMetaStore()) {\n+\t\t\tFileSystem fs = metaStore.getLocationPath().getFileSystem();\n+\t\t\tfor (String partition : partitions) {\n+\t\t\t\tLinkedHashMap<String, String> partSpec = extractPartitionSpecFromPath(new Path(partition));\n+\t\t\t\tPath path = new Path(metaStore.getLocationPath(), generatePartitionPath(partSpec));\n+\t\t\t\tfor (PartitionCommitPolicy policy : policies) {\n+\t\t\t\t\tpolicy.commit(partSpec, path, fs, metaStore);\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void processWatermark(Watermark mark) throws Exception {\n+\t\tsuper.processWatermark(mark);\n+\t\tthis.currentWatermark = mark.getTimestamp();\n+\t}\n+\n+\t@Override\n+\tpublic void snapshotState(StateSnapshotContext context) throws Exception {\n+\t\tsuper.snapshotState(context);\n+\t\tcommitManager.snapshotState(context.getCheckpointId(), currentWatermark);\n+\t}\n+\n+\t/**\n+\t * The message sent upstream.\n+\t */\n+\tpublic static class CommitMessage implements Serializable {\n+\n+\t\tpublic long checkpointId;\n+\t\tpublic int taskId;\n+\t\tpublic int numberOfTasks;\n+\t\tpublic List<String> partitions;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8bdc31fb33986d81fe96a21019c1beaf0487cfe"}, "originalPosition": 136}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjk4OTk4Mw==", "bodyText": "I don't think this method really \"triggers\" the commit. Seems it just decides which partitions should be committed. So maybe rename to getPartitionsToCommit?", "url": "https://github.com/apache/flink/pull/12062#discussion_r422989983", "createdAt": "2020-05-11T12:02:38Z", "author": {"login": "lirui-apache"}, "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/filesystem/stream/PartitionCommitManager.java", "diffHunk": "@@ -0,0 +1,143 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.filesystem.stream;\n+\n+import org.apache.flink.api.common.state.ListState;\n+import org.apache.flink.api.common.state.ListStateDescriptor;\n+import org.apache.flink.api.common.state.OperatorStateStore;\n+import org.apache.flink.api.common.typeutils.base.ListSerializer;\n+import org.apache.flink.api.common.typeutils.base.LongSerializer;\n+import org.apache.flink.api.common.typeutils.base.MapSerializer;\n+import org.apache.flink.api.common.typeutils.base.StringSerializer;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.core.fs.Path;\n+import org.apache.flink.table.filesystem.PartitionTimeExtractor;\n+import org.apache.flink.util.StringUtils;\n+\n+import java.time.Duration;\n+import java.time.LocalDateTime;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.TreeMap;\n+\n+import static org.apache.flink.table.filesystem.DefaultPartTimeExtractor.toMills;\n+import static org.apache.flink.table.filesystem.FileSystemOptions.PARTITION_TIME_EXTRACTOR_CLASS;\n+import static org.apache.flink.table.filesystem.FileSystemOptions.PARTITION_TIME_EXTRACTOR_TIMESTAMP_PATTERN;\n+import static org.apache.flink.table.filesystem.FileSystemOptions.PARTITION_TIME_EXTRACTOR_KIND;\n+import static org.apache.flink.table.filesystem.FileSystemOptions.PARTITION_TIME_INTERVAL;\n+import static org.apache.flink.table.utils.PartitionPathUtils.extractPartitionValues;\n+\n+/**\n+ * Manage partition and watermark information.\n+ */\n+public class PartitionCommitManager {\n+\n+\tprivate static final ListStateDescriptor<Map<Long, Long>> WATERMARKS_STATE_DESC =\n+\t\t\tnew ListStateDescriptor<>(\n+\t\t\t\t\t\"checkpoint-id-to-watermark\",\n+\t\t\t\t\tnew MapSerializer<>(LongSerializer.INSTANCE, LongSerializer.INSTANCE));\n+\tprivate static final ListStateDescriptor<List<String>> PENDING_PARTITIONS_STATE_DESC =\n+\t\t\tnew ListStateDescriptor<>(\n+\t\t\t\t\t\"pending-partitions\",\n+\t\t\t\t\tnew ListSerializer<>(StringSerializer.INSTANCE));\n+\n+\tprivate final ListState<Map<Long, Long>> watermarksState;\n+\tprivate final ListState<List<String>> pendingPartitionsState;\n+\tprivate final TreeMap<Long, Long> watermarks;\n+\tprivate final Set<String> pendingPartitions;\n+\tprivate final PartitionTimeExtractor extractor;\n+\tprivate final long timeIntervalMills;\n+\tprivate final List<String> partitionKeys;\n+\n+\tpublic PartitionCommitManager(\n+\t\t\tboolean isRestored,\n+\t\t\tOperatorStateStore operatorStateStore,\n+\t\t\tClassLoader userCodeClassLoader,\n+\t\t\tList<String> partitionKeys,\n+\t\t\tConfiguration conf) throws Exception {\n+\t\tthis.partitionKeys = partitionKeys;\n+\t\tString extractorKind = conf.get(PARTITION_TIME_EXTRACTOR_KIND);\n+\t\tString extractorClass = conf.get(PARTITION_TIME_EXTRACTOR_CLASS);\n+\t\tString extractorPattern = conf.get(PARTITION_TIME_EXTRACTOR_TIMESTAMP_PATTERN);\n+\t\tthis.timeIntervalMills = conf.getOptional(PARTITION_TIME_INTERVAL)\n+\t\t\t\t.map(Duration::toMillis)\n+\t\t\t\t.orElse(Long.MAX_VALUE);\n+\t\tthis.extractor = PartitionTimeExtractor.create(\n+\t\t\t\tuserCodeClassLoader,\n+\t\t\t\textractorKind,\n+\t\t\t\textractorClass,\n+\t\t\t\textractorPattern);\n+\n+\t\tthis.watermarksState = operatorStateStore.getListState(WATERMARKS_STATE_DESC);\n+\t\tthis.pendingPartitionsState = operatorStateStore.getListState(PENDING_PARTITIONS_STATE_DESC);\n+\n+\t\tthis.watermarks = new TreeMap<>();\n+\t\tthis.pendingPartitions = new HashSet<>();\n+\t\tif (isRestored) {\n+\t\t\twatermarks.putAll(watermarksState.get().iterator().next());\n+\t\t\tpendingPartitions.addAll(pendingPartitionsState.get().iterator().next());\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Add a pending partition.\n+\t */\n+\tpublic void addPartition(String partition) {\n+\t\tif (!StringUtils.isNullOrWhitespaceOnly(partition)) {\n+\t\t\tthis.pendingPartitions.add(partition);\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Trigger commit of pending partitions, and cleanup useless watermarks and partitions.\n+\t */\n+\tpublic List<String> triggerCommit(long checkpointId) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8bdc31fb33986d81fe96a21019c1beaf0487cfe"}, "originalPosition": 115}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjk5MTk5OA==", "bodyText": "add constants for them", "url": "https://github.com/apache/flink/pull/12062#discussion_r422991998", "createdAt": "2020-05-11T12:06:40Z", "author": {"login": "lirui-apache"}, "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/filesystem/stream/PartitionCommitPolicy.java", "diffHunk": "@@ -0,0 +1,63 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.filesystem.stream;\n+\n+import org.apache.flink.core.fs.FileSystem;\n+import org.apache.flink.core.fs.Path;\n+import org.apache.flink.table.filesystem.TableMetaStoreFactory;\n+\n+import java.io.Serializable;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Policy for partition commit.\n+ */\n+public interface PartitionCommitPolicy extends Serializable {\n+\n+\t/**\n+\t * Commit partition by partitionSpec and path.\n+\t */\n+\tvoid commit(\n+\t\t\tLinkedHashMap<String, String> partitionSpec,\n+\t\t\tPath partitionPath,\n+\t\t\tFileSystem fileSystem,\n+\t\t\tTableMetaStoreFactory.TableMetaStore metaStore) throws Exception;\n+\n+\tstatic List<PartitionCommitPolicy> createCommitChain(String policy, String successFileName) {\n+\t\tif (policy == null) {\n+\t\t\treturn Collections.emptyList();\n+\t\t}\n+\t\tString[] policyStrings = policy.split(\",\");\n+\t\treturn Arrays.stream(policyStrings).map(name -> {\n+\t\t\tswitch (name) {\n+\t\t\t\tcase \"metastore\":", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8bdc31fb33986d81fe96a21019c1beaf0487cfe"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjk5NTIwMQ==", "bodyText": "Does this invoke traffic to HMS? If so maybe we should only do it when partitions is not empty.", "url": "https://github.com/apache/flink/pull/12062#discussion_r422995201", "createdAt": "2020-05-11T12:13:14Z", "author": {"login": "lirui-apache"}, "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/filesystem/stream/StreamingFileCommitter.java", "diffHunk": "@@ -0,0 +1,175 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.filesystem.stream;\n+\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.core.fs.FileSystem;\n+import org.apache.flink.core.fs.Path;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.streaming.api.operators.AbstractStreamOperator;\n+import org.apache.flink.streaming.api.operators.OneInputStreamOperator;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.table.filesystem.TableMetaStoreFactory;\n+\n+import java.io.Serializable;\n+import java.util.HashSet;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.TreeMap;\n+\n+import static org.apache.flink.table.filesystem.FileSystemOptions.PARTITION_COMMIT_POLICY_SUCCESS_FILE_NAME;\n+import static org.apache.flink.table.filesystem.FileSystemOptions.PARTITION_COMMIT_POLICY_TYPE;\n+import static org.apache.flink.table.utils.PartitionPathUtils.extractPartitionSpecFromPath;\n+import static org.apache.flink.table.utils.PartitionPathUtils.generatePartitionPath;\n+\n+/**\n+ * Committer for {@link StreamingFileWriter}. This is the single (non-parallel) task.\n+ */\n+public class StreamingFileCommitter extends AbstractStreamOperator<Void>\n+\t\timplements OneInputStreamOperator<StreamingFileCommitter.CommitMessage, Void> {\n+\n+\tprivate static final long serialVersionUID = 1L;\n+\n+\tprivate final Configuration conf;\n+\n+\tprivate final List<String> partitionKeys;\n+\n+\tprivate final TableMetaStoreFactory metaStoreFactory;\n+\n+\tprivate transient PartitionCommitManager commitManager;\n+\n+\tprivate transient TaskTracker taskTracker;\n+\n+\tprivate transient long currentWatermark = Long.MIN_VALUE;\n+\n+\tprivate transient List<PartitionCommitPolicy> policies;\n+\n+\tpublic StreamingFileCommitter(\n+\t\t\tList<String> partitionKeys, TableMetaStoreFactory metaStoreFactory, Configuration conf) {\n+\t\tthis.partitionKeys = partitionKeys;\n+\t\tthis.metaStoreFactory = metaStoreFactory;\n+\t\tthis.conf = conf;\n+\t}\n+\n+\t@Override\n+\tpublic void initializeState(StateInitializationContext context) throws Exception {\n+\t\tsuper.initializeState(context);\n+\t\tthis.commitManager = new PartitionCommitManager(\n+\t\t\t\tcontext.isRestored(),\n+\t\t\t\tcontext.getOperatorStateStore(),\n+\t\t\t\tgetUserCodeClassloader(),\n+\t\t\t\tpartitionKeys,\n+\t\t\t\tconf);\n+\t\tthis.policies = PartitionCommitPolicy.createCommitChain(\n+\t\t\t\tconf.get(PARTITION_COMMIT_POLICY_TYPE),\n+\t\t\t\tconf.get(PARTITION_COMMIT_POLICY_SUCCESS_FILE_NAME));\n+\t}\n+\n+\t@Override\n+\tpublic void processElement(StreamRecord<CommitMessage> element) throws Exception {\n+\t\tCommitMessage message = element.getValue();\n+\t\tfor (String partition : message.partitions) {\n+\t\t\tcommitManager.addPartition(partition);\n+\t\t}\n+\n+\t\tif (taskTracker == null) {\n+\t\t\ttaskTracker = new TaskTracker(message.numberOfTasks);\n+\t\t}\n+\t\tboolean needCommit = taskTracker.add(message.checkpointId, message.taskId);\n+\t\tif (needCommit) {\n+\t\t\tcommitPartitions(commitManager.triggerCommit(message.checkpointId));\n+\t\t}\n+\t}\n+\n+\tprivate void commitPartitions(List<String> partitions) throws Exception {\n+\t\ttry (TableMetaStoreFactory.TableMetaStore metaStore = metaStoreFactory.createTableMetaStore()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8bdc31fb33986d81fe96a21019c1beaf0487cfe"}, "originalPosition": 104}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjk5OTAxMg==", "bodyText": "Is it possible that there's some pending data between close and the last notifyCheckpointComplete?", "url": "https://github.com/apache/flink/pull/12062#discussion_r422999012", "createdAt": "2020-05-11T12:20:25Z", "author": {"login": "lirui-apache"}, "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/filesystem/stream/StreamingFileWriter.java", "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.filesystem.stream;\n+\n+import org.apache.flink.api.common.state.ListState;\n+import org.apache.flink.api.common.state.ListStateDescriptor;\n+import org.apache.flink.api.common.state.OperatorStateStore;\n+import org.apache.flink.api.common.typeutils.base.LongSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.streaming.api.functions.sink.filesystem.Buckets;\n+import org.apache.flink.streaming.api.functions.sink.filesystem.StreamingFileSink;\n+import org.apache.flink.streaming.api.operators.AbstractStreamOperator;\n+import org.apache.flink.streaming.api.operators.OneInputStreamOperator;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.tasks.ProcessingTimeCallback;\n+import org.apache.flink.streaming.runtime.tasks.ProcessingTimeService;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.filesystem.stream.StreamingFileCommitter.CommitMessage;\n+import org.apache.flink.util.Preconditions;\n+\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+/**\n+ * Operator for file system sink.\n+ */\n+public class StreamingFileWriter extends AbstractStreamOperator<CommitMessage>\n+\t\timplements OneInputStreamOperator<RowData, CommitMessage>, ProcessingTimeCallback {\n+\n+\tprivate static final long serialVersionUID = 1L;\n+\n+\t// -------------------------- state descriptors ---------------------------\n+\n+\tprivate static final ListStateDescriptor<byte[]> BUCKET_STATE_DESC =\n+\t\t\tnew ListStateDescriptor<>(\"bucket-states\", BytePrimitiveArraySerializer.INSTANCE);\n+\n+\tprivate static final ListStateDescriptor<Long> MAX_PART_COUNTER_STATE_DESC =\n+\t\t\tnew ListStateDescriptor<>(\"max-part-counter\", LongSerializer.INSTANCE);\n+\n+\t// ------------------------ configuration fields --------------------------\n+\n+\tprivate final long bucketCheckInterval;\n+\n+\tprivate final StreamingFileSink.BucketsBuilder<RowData, ?, ? extends\n+\t\t\tStreamingFileSink.BucketsBuilder<RowData, ?, ?>> bucketsBuilder;\n+\n+\tprivate final FileSystemBucketListener listener;\n+\n+\t// --------------------------- runtime fields -----------------------------\n+\n+\tprivate transient Buckets<RowData, ?> buckets;\n+\n+\tprivate transient ProcessingTimeService processingTimeService;\n+\n+\tprivate transient long currentWatermark = Long.MIN_VALUE;\n+\n+\tprivate transient Set<String> inactivePartitions;\n+\n+\t// --------------------------- State Related Fields -----------------------------\n+\n+\tprivate transient ListState<byte[]> bucketStates;\n+\n+\tprivate transient ListState<Long> maxPartCountersState;\n+\n+\tpublic StreamingFileWriter(\n+\t\t\tlong bucketCheckInterval,\n+\t\t\tStreamingFileSink.BucketsBuilder<RowData, ?, ? extends\n+\t\t\t\t\tStreamingFileSink.BucketsBuilder<RowData, ?, ?>> bucketsBuilder,\n+\t\t\tFileSystemBucketListener listener) {\n+\t\tthis.bucketCheckInterval = bucketCheckInterval;\n+\t\tthis.bucketsBuilder = bucketsBuilder;\n+\t\tthis.listener = listener;\n+\t}\n+\n+\t@Override\n+\tpublic void initializeState(StateInitializationContext context) throws Exception {\n+\t\tsuper.initializeState(context);\n+\t\tfinal int subtaskIndex = getRuntimeContext().getIndexOfThisSubtask();\n+\t\tthis.buckets = bucketsBuilder.createBuckets(subtaskIndex);\n+\n+\t\tfinal OperatorStateStore stateStore = context.getOperatorStateStore();\n+\t\tbucketStates = stateStore.getListState(BUCKET_STATE_DESC);\n+\t\tmaxPartCountersState = stateStore.getUnionListState(MAX_PART_COUNTER_STATE_DESC);\n+\n+\t\tif (context.isRestored()) {\n+\t\t\tbuckets.initializeState(bucketStates, maxPartCountersState);\n+\t\t}\n+\t\tinactivePartitions = new HashSet<>();\n+\t\tlistener.setInactiveConsumer(b -> inactivePartitions.add(b));\n+\t}\n+\n+\t@Override\n+\tpublic void snapshotState(StateSnapshotContext context) throws Exception {\n+\t\tsuper.snapshotState(context);\n+\t\tPreconditions.checkState(bucketStates != null && maxPartCountersState != null, \"sink has not been initialized\");\n+\t\tbuckets.snapshotState(\n+\t\t\t\tcontext.getCheckpointId(),\n+\t\t\t\tbucketStates,\n+\t\t\t\tmaxPartCountersState);\n+\t}\n+\n+\t@Override\n+\tpublic void open() throws Exception {\n+\t\tsuper.open();\n+\t\tthis.processingTimeService = getRuntimeContext().getProcessingTimeService();\n+\t\tlong currentProcessingTime = processingTimeService.getCurrentProcessingTime();\n+\t\tprocessingTimeService.registerTimer(currentProcessingTime + bucketCheckInterval, this);\n+\t}\n+\n+\t@Override\n+\tpublic void onProcessingTime(long timestamp) throws Exception {\n+\t\tfinal long currentTime = processingTimeService.getCurrentProcessingTime();\n+\t\tbuckets.onProcessingTime(currentTime);\n+\t\tprocessingTimeService.registerTimer(currentTime + bucketCheckInterval, this);\n+\t}\n+\n+\t@Override\n+\tpublic void processWatermark(Watermark mark) throws Exception {\n+\t\tsuper.processWatermark(mark);\n+\t\tthis.currentWatermark = mark.getTimestamp();\n+\t}\n+\n+\t@Override\n+\tpublic void processElement(StreamRecord<RowData> element) throws Exception {\n+\t\tbuckets.onElement(\n+\t\t\t\telement.getValue(),\n+\t\t\t\tgetProcessingTimeService().getCurrentProcessingTime(),\n+\t\t\t\telement.getTimestamp(),\n+\t\t\t\tcurrentWatermark);\n+\t}\n+\n+\t@Override\n+\tpublic void notifyCheckpointComplete(long checkpointId) throws Exception {\n+\t\tsuper.notifyCheckpointComplete(checkpointId);\n+\t\tbuckets.commitUpToCheckpoint(checkpointId);\n+\t\tCommitMessage message = new CommitMessage(\n+\t\t\t\tcheckpointId,\n+\t\t\t\tgetRuntimeContext().getIndexOfThisSubtask(),\n+\t\t\t\tgetRuntimeContext().getNumberOfParallelSubtasks(),\n+\t\t\t\tnew ArrayList<>(inactivePartitions));\n+\t\toutput.collect(new StreamRecord<>(message));\n+\t\tinactivePartitions.clear();\n+\t}\n+\n+\t@Override\n+\tpublic void close() throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8bdc31fb33986d81fe96a21019c1beaf0487cfe"}, "originalPosition": 166}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjk5OTY4Mw==", "bodyText": "incorrect java doc", "url": "https://github.com/apache/flink/pull/12062#discussion_r422999683", "createdAt": "2020-05-11T12:21:39Z", "author": {"login": "lirui-apache"}, "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/filesystem/stream/SuccessFileCommitPolicy.java", "diffHunk": "@@ -0,0 +1,46 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.filesystem.stream;\n+\n+import org.apache.flink.core.fs.FileSystem;\n+import org.apache.flink.core.fs.Path;\n+import org.apache.flink.table.filesystem.TableMetaStoreFactory;\n+\n+import java.util.LinkedHashMap;\n+\n+/**\n+ * Partition commit policy to update metastore.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8bdc31fb33986d81fe96a21019c1beaf0487cfe"}, "originalPosition": 28}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "89b43558a39741f04114f95011f784fd5414b22c", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/89b43558a39741f04114f95011f784fd5414b22c", "committedDate": "2020-05-12T02:39:40Z", "message": "Fix"}, "afterCommit": {"oid": "0317794acef460e3a2930a2ce2ee88184d3133d2", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/0317794acef460e3a2930a2ce2ee88184d3133d2", "committedDate": "2020-05-12T03:07:25Z", "message": "[FLINK-17587][filesystem] Filesystem streaming sink support commit success file"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "7c0c8354323e54a25df4fba648d457816b36ecb7", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/7c0c8354323e54a25df4fba648d457816b36ecb7", "committedDate": "2020-05-12T08:41:14Z", "message": "committer only partitionKeys not empty"}, "afterCommit": {"oid": "e7040a4ef029a828ce0ad2584ecadac9cb55522b", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/e7040a4ef029a828ce0ad2584ecadac9cb55522b", "committedDate": "2020-05-12T10:10:05Z", "message": "[FLINK-17587][filesystem] Filesystem streaming sink support commit success file"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA5OTc5ODE3", "url": "https://github.com/apache/flink/pull/12062#pullrequestreview-409979817", "createdAt": "2020-05-12T12:16:06Z", "commit": {"oid": "e7040a4ef029a828ce0ad2584ecadac9cb55522b"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxMjoxNjowNlrOGUDtYg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxMjoxNjowNlrOGUDtYg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzY4NTQ3NA==", "bodyText": "This class is copy pasting quite a bit of code/fields from StreamingFileSink. Can not we extract a common abstraction or re-use one in the another?", "url": "https://github.com/apache/flink/pull/12062#discussion_r423685474", "createdAt": "2020-05-12T12:16:06Z", "author": {"login": "pnowojski"}, "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/filesystem/stream/StreamingFileWriter.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.filesystem.stream;\n+\n+import org.apache.flink.api.common.state.ListState;\n+import org.apache.flink.api.common.state.ListStateDescriptor;\n+import org.apache.flink.api.common.state.OperatorStateStore;\n+import org.apache.flink.api.common.typeutils.base.LongSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.streaming.api.functions.sink.filesystem.Buckets;\n+import org.apache.flink.streaming.api.functions.sink.filesystem.StreamingFileSink;\n+import org.apache.flink.streaming.api.operators.AbstractStreamOperator;\n+import org.apache.flink.streaming.api.operators.BoundedOneInput;\n+import org.apache.flink.streaming.api.operators.OneInputStreamOperator;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.tasks.ProcessingTimeCallback;\n+import org.apache.flink.streaming.runtime.tasks.ProcessingTimeService;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.filesystem.stream.StreamingFileCommitter.CommitMessage;\n+import org.apache.flink.util.Preconditions;\n+\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+/**\n+ * Operator for file system sink. It is a operator version of {@link StreamingFileSink}.\n+ * It sends partition commit message to downstream for committing.\n+ *\n+ * <p>See {@link StreamingFileCommitter}.\n+ */\n+public class StreamingFileWriter extends AbstractStreamOperator<CommitMessage> implements", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e7040a4ef029a828ce0ad2584ecadac9cb55522b"}, "originalPosition": 51}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "fcc6c6cb0a0c4260a5a924e4fb2a0297c0613734", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/fcc6c6cb0a0c4260a5a924e4fb2a0297c0613734", "committedDate": "2020-05-13T08:31:35Z", "message": "checkstyle"}, "afterCommit": {"oid": "2503b8d118226338e569fbe430287eb4f47816a4", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/2503b8d118226338e569fbe430287eb4f47816a4", "committedDate": "2020-05-13T10:32:33Z", "message": "[FLINK-17587][filesystem] Filesystem streaming sink support commit success file"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "2503b8d118226338e569fbe430287eb4f47816a4", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/2503b8d118226338e569fbe430287eb4f47816a4", "committedDate": "2020-05-13T10:32:33Z", "message": "[FLINK-17587][filesystem] Filesystem streaming sink support commit success file"}, "afterCommit": {"oid": "05ef446da66d95a0c61f7f663ea1a94addec75fb", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/05ef446da66d95a0c61f7f663ea1a94addec75fb", "committedDate": "2020-05-13T10:36:34Z", "message": "[FLINK-17587][filesystem] Filesystem streaming sink support commit success file"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "05ef446da66d95a0c61f7f663ea1a94addec75fb", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/05ef446da66d95a0c61f7f663ea1a94addec75fb", "committedDate": "2020-05-13T10:36:34Z", "message": "[FLINK-17587][filesystem] Filesystem streaming sink support commit success file"}, "afterCommit": {"oid": "6c24f2b260515cef76e314b70b0e376fa1b9d8a5", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/6c24f2b260515cef76e314b70b0e376fa1b9d8a5", "committedDate": "2020-05-14T06:52:59Z", "message": "[FLINK-17587][filesystem] Filesystem streaming sink support commit success file"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "6c24f2b260515cef76e314b70b0e376fa1b9d8a5", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/6c24f2b260515cef76e314b70b0e376fa1b9d8a5", "committedDate": "2020-05-14T06:52:59Z", "message": "[FLINK-17587][filesystem] Filesystem streaming sink support commit success file"}, "afterCommit": {"oid": "e7ab892003f4268a1a4073e1a4b29f3c677154e4", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/e7ab892003f4268a1a4073e1a4b29f3c677154e4", "committedDate": "2020-05-14T06:57:59Z", "message": "[FLINK-17587][filesystem] Filesystem streaming sink support commit success file"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0d278faf6cd4d3972dd1fe64d4d851b70475c3ee", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/0d278faf6cd4d3972dd1fe64d4d851b70475c3ee", "committedDate": "2020-05-14T08:14:06Z", "message": "Optimizer codes"}, "afterCommit": {"oid": "e2b2ede56019d7b04ca9a2623eb552916d598b35", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/e2b2ede56019d7b04ca9a2623eb552916d598b35", "committedDate": "2020-05-14T12:18:58Z", "message": "[FLINK-17587][filesystem] Filesystem streaming sink support commit success file"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDEyNjIzOTU1", "url": "https://github.com/apache/flink/pull/12062#pullrequestreview-412623955", "createdAt": "2020-05-15T12:57:40Z", "commit": {"oid": "e2b2ede56019d7b04ca9a2623eb552916d598b35"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxMjo1Nzo0MFrOGWDu3w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxMzoyNzo1NVrOGWE2yg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTc4MzAwNw==", "bodyText": "I think we should explain how \"partition creation time\" is determined.", "url": "https://github.com/apache/flink/pull/12062#discussion_r425783007", "createdAt": "2020-05-15T12:57:40Z", "author": {"login": "lirui-apache"}, "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/filesystem/FileSystemOptions.java", "diffHunk": "@@ -88,4 +88,48 @@\n \t\t\t\t\t\t\t\" If timestamp in partition is year, month, day, hour,\" +\n \t\t\t\t\t\t\t\" can configure: '$year-$month-$day $hour:00:00'.\" +\n \t\t\t\t\t\t\t\" If timestamp in partition is dt and hour, can configure: '$dt $hour:00:00'.\");\n+\n+\tpublic static final ConfigOption<String> SINK_PARTITION_COMMIT_TRIGGER =\n+\t\t\tkey(\"sink.partition-commit.trigger\")\n+\t\t\t\t\t.stringType()\n+\t\t\t\t\t.defaultValue(\"partition-time\")\n+\t\t\t\t\t.withDescription(\"Trigger type for partition commit:\" +\n+\t\t\t\t\t\t\t\" 'partition-time': extract time from partition,\" +\n+\t\t\t\t\t\t\t\" if 'watermark' > 'partition-time' + 'delay', will commit the partition.\" +\n+\t\t\t\t\t\t\t\" 'process-time': use processing time, if 'current processing time' > \" +\n+\t\t\t\t\t\t\t\"'partition creation time' + 'delay', will commit the partition.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2b2ede56019d7b04ca9a2623eb552916d598b35"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTc5MTU1NA==", "bodyText": "Does this only work custom commit policy? If so it should be mentioned in the description and reflected in the config name.", "url": "https://github.com/apache/flink/pull/12062#discussion_r425791554", "createdAt": "2020-05-15T13:12:32Z", "author": {"login": "lirui-apache"}, "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/filesystem/FileSystemOptions.java", "diffHunk": "@@ -88,4 +88,48 @@\n \t\t\t\t\t\t\t\" If timestamp in partition is year, month, day, hour,\" +\n \t\t\t\t\t\t\t\" can configure: '$year-$month-$day $hour:00:00'.\" +\n \t\t\t\t\t\t\t\" If timestamp in partition is dt and hour, can configure: '$dt $hour:00:00'.\");\n+\n+\tpublic static final ConfigOption<String> SINK_PARTITION_COMMIT_TRIGGER =\n+\t\t\tkey(\"sink.partition-commit.trigger\")\n+\t\t\t\t\t.stringType()\n+\t\t\t\t\t.defaultValue(\"partition-time\")\n+\t\t\t\t\t.withDescription(\"Trigger type for partition commit:\" +\n+\t\t\t\t\t\t\t\" 'partition-time': extract time from partition,\" +\n+\t\t\t\t\t\t\t\" if 'watermark' > 'partition-time' + 'delay', will commit the partition.\" +\n+\t\t\t\t\t\t\t\" 'process-time': use processing time, if 'current processing time' > \" +\n+\t\t\t\t\t\t\t\"'partition creation time' + 'delay', will commit the partition.\");\n+\n+\tpublic static final ConfigOption<Duration> SINK_PARTITION_COMMIT_DELAY =\n+\t\t\tkey(\"sink.partition-commit.delay\")\n+\t\t\t\t\t.durationType()\n+\t\t\t\t\t.defaultValue(Duration.ofMillis(0))\n+\t\t\t\t\t.withDescription(\"The partition will not commit until the delay time.\" +\n+\t\t\t\t\t\t\t\" if it is a day partition, should be '1 d',\" +\n+\t\t\t\t\t\t\t\" if it is a hour partition, should be '1 h'\");\n+\n+\tpublic static final ConfigOption<String> SINK_PARTITION_COMMIT_POLICY_KIND =\n+\t\t\tkey(\"sink.partition-commit.policy.kind\")\n+\t\t\t\t\t.stringType()\n+\t\t\t\t\t.noDefaultValue()\n+\t\t\t\t\t.withDescription(\"Policy to commit a partition is to notify the downstream\" +\n+\t\t\t\t\t\t\t\" application that the partition has finished writing, the partition\" +\n+\t\t\t\t\t\t\t\" is ready to be read.\" +\n+\t\t\t\t\t\t\t\" metastore: add partition to metastore.\" +\n+\t\t\t\t\t\t\t\" success-file: add '_success' file to directory.\" +\n+\t\t\t\t\t\t\t\" Both can be configured at the same time: 'metastore,success-file'.\" +\n+\t\t\t\t\t\t\t\" custom: use policy class to create a commit policy.\" +\n+\t\t\t\t\t\t\t\" Support to configure multiple policies: 'metastore,success-file'.\");\n+\n+\tpublic static final ConfigOption<String> SINK_PARTITION_COMMIT_POLICY_CLASS =\n+\t\t\tkey(\"sink.partition-commit.policy.class\")\n+\t\t\t\t\t.stringType()\n+\t\t\t\t\t.noDefaultValue()\n+\t\t\t\t\t.withDescription(\"The partition commit policy class for implement PartitionCommitPolicy interface.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2b2ede56019d7b04ca9a2623eb552916d598b35"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTc5NzA4Nw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n             * <p>The implemented commit method needs to be reentrant because the same partition may be\n          \n          \n            \n             * <p>The implemented commit method needs to be idempotent because the same partition may be", "url": "https://github.com/apache/flink/pull/12062#discussion_r425797087", "createdAt": "2020-05-15T13:21:19Z", "author": {"login": "lirui-apache"}, "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/filesystem/PartitionCommitPolicy.java", "diffHunk": "@@ -0,0 +1,124 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.filesystem;\n+\n+import org.apache.flink.annotation.Experimental;\n+import org.apache.flink.core.fs.FileSystem;\n+import org.apache.flink.core.fs.Path;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Policy for commit a partition.\n+ *\n+ * <p>The implemented commit method needs to be reentrant because the same partition may be", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2b2ede56019d7b04ca9a2623eb552916d598b35"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTgwMTQxOA==", "bodyText": "If users choose metastore policy, don't they need to specify/provide a TableMetaStoreFactory implementation?", "url": "https://github.com/apache/flink/pull/12062#discussion_r425801418", "createdAt": "2020-05-15T13:27:55Z", "author": {"login": "lirui-apache"}, "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/filesystem/FileSystemOptions.java", "diffHunk": "@@ -88,4 +88,48 @@\n \t\t\t\t\t\t\t\" If timestamp in partition is year, month, day, hour,\" +\n \t\t\t\t\t\t\t\" can configure: '$year-$month-$day $hour:00:00'.\" +\n \t\t\t\t\t\t\t\" If timestamp in partition is dt and hour, can configure: '$dt $hour:00:00'.\");\n+\n+\tpublic static final ConfigOption<String> SINK_PARTITION_COMMIT_TRIGGER =\n+\t\t\tkey(\"sink.partition-commit.trigger\")\n+\t\t\t\t\t.stringType()\n+\t\t\t\t\t.defaultValue(\"partition-time\")\n+\t\t\t\t\t.withDescription(\"Trigger type for partition commit:\" +\n+\t\t\t\t\t\t\t\" 'partition-time': extract time from partition,\" +\n+\t\t\t\t\t\t\t\" if 'watermark' > 'partition-time' + 'delay', will commit the partition.\" +\n+\t\t\t\t\t\t\t\" 'process-time': use processing time, if 'current processing time' > \" +\n+\t\t\t\t\t\t\t\"'partition creation time' + 'delay', will commit the partition.\");\n+\n+\tpublic static final ConfigOption<Duration> SINK_PARTITION_COMMIT_DELAY =\n+\t\t\tkey(\"sink.partition-commit.delay\")\n+\t\t\t\t\t.durationType()\n+\t\t\t\t\t.defaultValue(Duration.ofMillis(0))\n+\t\t\t\t\t.withDescription(\"The partition will not commit until the delay time.\" +\n+\t\t\t\t\t\t\t\" if it is a day partition, should be '1 d',\" +\n+\t\t\t\t\t\t\t\" if it is a hour partition, should be '1 h'\");\n+\n+\tpublic static final ConfigOption<String> SINK_PARTITION_COMMIT_POLICY_KIND =\n+\t\t\tkey(\"sink.partition-commit.policy.kind\")\n+\t\t\t\t\t.stringType()\n+\t\t\t\t\t.noDefaultValue()\n+\t\t\t\t\t.withDescription(\"Policy to commit a partition is to notify the downstream\" +\n+\t\t\t\t\t\t\t\" application that the partition has finished writing, the partition\" +\n+\t\t\t\t\t\t\t\" is ready to be read.\" +\n+\t\t\t\t\t\t\t\" metastore: add partition to metastore.\" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2b2ede56019d7b04ca9a2623eb552916d598b35"}, "originalPosition": 30}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e2b2ede56019d7b04ca9a2623eb552916d598b35", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/e2b2ede56019d7b04ca9a2623eb552916d598b35", "committedDate": "2020-05-14T12:18:58Z", "message": "[FLINK-17587][filesystem] Filesystem streaming sink support commit success file"}, "afterCommit": {"oid": "b5c04196e6d3c0f0e88c688216913001930d3a20", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/b5c04196e6d3c0f0e88c688216913001930d3a20", "committedDate": "2020-05-15T14:24:25Z", "message": "Fix comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDEzMDM5NzY4", "url": "https://github.com/apache/flink/pull/12062#pullrequestreview-413039768", "createdAt": "2020-05-16T02:35:02Z", "commit": {"oid": "b5c04196e6d3c0f0e88c688216913001930d3a20"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b5c04196e6d3c0f0e88c688216913001930d3a20", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/b5c04196e6d3c0f0e88c688216913001930d3a20", "committedDate": "2020-05-15T14:24:25Z", "message": "Fix comments"}, "afterCommit": {"oid": "196579752867c527af380839b1f9c3f559ae4bf0", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/196579752867c527af380839b1f9c3f559ae4bf0", "committedDate": "2020-05-16T03:04:13Z", "message": "[FLINK-17587][filesystem] Filesystem streaming sink support commit success file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "27349ac964ef16dceae54bcae4cfb09ab17c14ea", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/27349ac964ef16dceae54bcae4cfb09ab17c14ea", "committedDate": "2020-05-16T05:33:08Z", "message": "[FLINK-17587][runtime] Extract StreamingFileSinkHelper from StreamingFileSink"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e0a38b8cba26ad3059e7535e277c2f50d22c5e54", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/e0a38b8cba26ad3059e7535e277c2f50d22c5e54", "committedDate": "2020-05-16T05:33:08Z", "message": "[FLINK-17587][filesystem] Filesystem streaming sink support commit success file"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "196579752867c527af380839b1f9c3f559ae4bf0", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/196579752867c527af380839b1f9c3f559ae4bf0", "committedDate": "2020-05-16T03:04:13Z", "message": "[FLINK-17587][filesystem] Filesystem streaming sink support commit success file"}, "afterCommit": {"oid": "e0a38b8cba26ad3059e7535e277c2f50d22c5e54", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/e0a38b8cba26ad3059e7535e277c2f50d22c5e54", "committedDate": "2020-05-16T05:33:08Z", "message": "[FLINK-17587][filesystem] Filesystem streaming sink support commit success file"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4243, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}