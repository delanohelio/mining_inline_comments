{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDAzMTMwMzU2", "number": 11735, "title": "[FLINK-16802][hive] Set schema info in JobConf for Hive readers", "bodyText": "What is the purpose of the change\nSome Hive readers rely on table schema for schema evolution, name mapping, etc. So we should set the schema in JobConf when creating the reader.\nBrief change log\n\nSet schema info in JobConf for Hive readers.\nAdd test cases.\n\nVerifying this change\nExisting and added test cases. Also manually run tests for all Hive versions.\nDoes this pull request potentially affect one of the following parts:\n\nDependencies (does it add or upgrade a dependency): no\nThe public API, i.e., is any changed class annotated with @Public(Evolving): no\nThe serializers: no\nThe runtime per-record code paths (performance sensitive): no\nAnything that affects deployment or recovery: JobManager (and its components), Checkpointing, Kubernetes/Yarn/Mesos, ZooKeeper: no\nThe S3 file system connector: no\n\nDocumentation\n\nDoes this pull request introduce a new feature? no\nIf yes, how is the feature documented? N/A", "createdAt": "2020-04-14T11:35:29Z", "url": "https://github.com/apache/flink/pull/11735", "merged": true, "mergeCommit": {"oid": "43cf121e77f8d001d1f601a23cc8d10e872bd747"}, "closed": true, "closedAt": "2020-04-24T03:30:01Z", "author": {"login": "lirui-apache"}, "timelineItems": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcaC8cwgFqTM5NzkwNDE0MA==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcao7yOgFqTM5OTYxNjE4Mg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk3OTA0MTQw", "url": "https://github.com/apache/flink/pull/11735#pullrequestreview-397904140", "createdAt": "2020-04-22T07:13:57Z", "commit": {"oid": "60d86e4a86f0afefe1bfbf398b1d28f139ca97f2"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQwNzoxMzo1N1rOGJnAUw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQwNzoxMzo1N1rOGJnAUw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjcyOTQyNw==", "bodyText": "Need this branch?\nWe can just:\njobConf.set(SCHEMA_EVOLUTION_COLUMNS, String.join(\",\", Arrays.copyOfRange(fieldNames, 0, firstPartColIndex)));\njobConf.set(SCHEMA_EVOLUTION_COLUMNS_TYPES, String.join(\",\", typeStrs.subList(0, firstPartColIndex)));", "url": "https://github.com/apache/flink/pull/11735#discussion_r412729427", "createdAt": "2020-04-22T07:13:57Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/read/HiveTableInputFormat.java", "diffHunk": "@@ -122,12 +131,40 @@ public void open(HiveTableInputSplit split) throws IOException {\n \t\t\tthis.reader = new HiveVectorizedParquetSplitReader(\n \t\t\t\t\thiveVersion, jobConf, fieldNames, fieldTypes, selectedFields, split);\n \t\t} else {\n-\t\t\tthis.reader = new HiveMapredSplitReader(jobConf, partitionKeys, fieldTypes, selectedFields, split,\n+\t\t\tJobConf clonedConf = new JobConf(jobConf);\n+\t\t\taddSchemaToConf(clonedConf);\n+\t\t\tthis.reader = new HiveMapredSplitReader(clonedConf, partitionKeys, fieldTypes, selectedFields, split,\n \t\t\t\t\tHiveShimLoader.loadHiveShim(hiveVersion));\n \t\t}\n \t\tcurrentReadCount = 0L;\n \t}\n \n+\t// Hive readers may rely on the schema info in configuration\n+\tprivate void addSchemaToConf(JobConf jobConf) {\n+\t\t// set columns/types -- including partition cols\n+\t\tList<String> typeStrs = Arrays.stream(fieldTypes)\n+\t\t\t\t.map(t -> HiveTypeUtil.toHiveTypeInfo(t, true).toString())\n+\t\t\t\t.collect(Collectors.toList());\n+\t\tjobConf.set(IOConstants.COLUMNS, String.join(\",\", fieldNames));\n+\t\tjobConf.set(IOConstants.COLUMNS_TYPES, String.join(\",\", typeStrs));\n+\t\t// set schema evolution -- excluding partition cols\n+\t\tint numPartCol = partitionKeys != null ? partitionKeys.size() : 0;\n+\t\tint firstPartColIndex = fieldNames.length - numPartCol;\n+\t\tif (numPartCol == 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "60d86e4a86f0afefe1bfbf398b1d28f139ca97f2"}, "originalPosition": 60}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk3OTA4NTkz", "url": "https://github.com/apache/flink/pull/11735#pullrequestreview-397908593", "createdAt": "2020-04-22T07:20:35Z", "commit": {"oid": "60d86e4a86f0afefe1bfbf398b1d28f139ca97f2"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQwNzoyMDozNVrOGJnQoQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQwNzoyMTozOFrOGJnTXw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjczMzYwMQ==", "bodyText": "partitionKeys never null", "url": "https://github.com/apache/flink/pull/11735#discussion_r412733601", "createdAt": "2020-04-22T07:20:35Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/read/HiveTableInputFormat.java", "diffHunk": "@@ -122,12 +131,40 @@ public void open(HiveTableInputSplit split) throws IOException {\n \t\t\tthis.reader = new HiveVectorizedParquetSplitReader(\n \t\t\t\t\thiveVersion, jobConf, fieldNames, fieldTypes, selectedFields, split);\n \t\t} else {\n-\t\t\tthis.reader = new HiveMapredSplitReader(jobConf, partitionKeys, fieldTypes, selectedFields, split,\n+\t\t\tJobConf clonedConf = new JobConf(jobConf);\n+\t\t\taddSchemaToConf(clonedConf);\n+\t\t\tthis.reader = new HiveMapredSplitReader(clonedConf, partitionKeys, fieldTypes, selectedFields, split,\n \t\t\t\t\tHiveShimLoader.loadHiveShim(hiveVersion));\n \t\t}\n \t\tcurrentReadCount = 0L;\n \t}\n \n+\t// Hive readers may rely on the schema info in configuration\n+\tprivate void addSchemaToConf(JobConf jobConf) {\n+\t\t// set columns/types -- including partition cols\n+\t\tList<String> typeStrs = Arrays.stream(fieldTypes)\n+\t\t\t\t.map(t -> HiveTypeUtil.toHiveTypeInfo(t, true).toString())\n+\t\t\t\t.collect(Collectors.toList());\n+\t\tjobConf.set(IOConstants.COLUMNS, String.join(\",\", fieldNames));\n+\t\tjobConf.set(IOConstants.COLUMNS_TYPES, String.join(\",\", typeStrs));\n+\t\t// set schema evolution -- excluding partition cols\n+\t\tint numPartCol = partitionKeys != null ? partitionKeys.size() : 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "60d86e4a86f0afefe1bfbf398b1d28f139ca97f2"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjczNDMwMw==", "bodyText": "numNonPartCol?", "url": "https://github.com/apache/flink/pull/11735#discussion_r412734303", "createdAt": "2020-04-22T07:21:38Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/read/HiveTableInputFormat.java", "diffHunk": "@@ -122,12 +131,40 @@ public void open(HiveTableInputSplit split) throws IOException {\n \t\t\tthis.reader = new HiveVectorizedParquetSplitReader(\n \t\t\t\t\thiveVersion, jobConf, fieldNames, fieldTypes, selectedFields, split);\n \t\t} else {\n-\t\t\tthis.reader = new HiveMapredSplitReader(jobConf, partitionKeys, fieldTypes, selectedFields, split,\n+\t\t\tJobConf clonedConf = new JobConf(jobConf);\n+\t\t\taddSchemaToConf(clonedConf);\n+\t\t\tthis.reader = new HiveMapredSplitReader(clonedConf, partitionKeys, fieldTypes, selectedFields, split,\n \t\t\t\t\tHiveShimLoader.loadHiveShim(hiveVersion));\n \t\t}\n \t\tcurrentReadCount = 0L;\n \t}\n \n+\t// Hive readers may rely on the schema info in configuration\n+\tprivate void addSchemaToConf(JobConf jobConf) {\n+\t\t// set columns/types -- including partition cols\n+\t\tList<String> typeStrs = Arrays.stream(fieldTypes)\n+\t\t\t\t.map(t -> HiveTypeUtil.toHiveTypeInfo(t, true).toString())\n+\t\t\t\t.collect(Collectors.toList());\n+\t\tjobConf.set(IOConstants.COLUMNS, String.join(\",\", fieldNames));\n+\t\tjobConf.set(IOConstants.COLUMNS_TYPES, String.join(\",\", typeStrs));\n+\t\t// set schema evolution -- excluding partition cols\n+\t\tint numPartCol = partitionKeys != null ? partitionKeys.size() : 0;\n+\t\tint firstPartColIndex = fieldNames.length - numPartCol;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "60d86e4a86f0afefe1bfbf398b1d28f139ca97f2"}, "originalPosition": 59}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "60d86e4a86f0afefe1bfbf398b1d28f139ca97f2", "author": {"user": {"login": "lirui-apache", "name": "Rui Li"}}, "url": "https://github.com/apache/flink/commit/60d86e4a86f0afefe1bfbf398b1d28f139ca97f2", "committedDate": "2020-04-14T11:30:44Z", "message": "[FLINK-16802][hive] Set schema info in JobConf for Hive readers"}, "afterCommit": {"oid": "b77e52194cbab40028c15a6ab4a747f5e900e37c", "author": {"user": {"login": "lirui-apache", "name": "Rui Li"}}, "url": "https://github.com/apache/flink/commit/b77e52194cbab40028c15a6ab4a747f5e900e37c", "committedDate": "2020-04-22T07:49:16Z", "message": "address comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f9fa39640ee8e4082f0e3d7a7963080d56689fa9", "author": {"user": {"login": "lirui-apache", "name": "Rui Li"}}, "url": "https://github.com/apache/flink/commit/f9fa39640ee8e4082f0e3d7a7963080d56689fa9", "committedDate": "2020-04-23T08:55:15Z", "message": "[FLINK-16802][hive] Set schema info in JobConf for Hive readers"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "67355f513149f11b717932a98f406b8be92bfbe2", "author": {"user": {"login": "lirui-apache", "name": "Rui Li"}}, "url": "https://github.com/apache/flink/commit/67355f513149f11b717932a98f406b8be92bfbe2", "committedDate": "2020-04-23T08:55:15Z", "message": "address comments"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b77e52194cbab40028c15a6ab4a747f5e900e37c", "author": {"user": {"login": "lirui-apache", "name": "Rui Li"}}, "url": "https://github.com/apache/flink/commit/b77e52194cbab40028c15a6ab4a747f5e900e37c", "committedDate": "2020-04-22T07:49:16Z", "message": "address comments"}, "afterCommit": {"oid": "67355f513149f11b717932a98f406b8be92bfbe2", "author": {"user": {"login": "lirui-apache", "name": "Rui Li"}}, "url": "https://github.com/apache/flink/commit/67355f513149f11b717932a98f406b8be92bfbe2", "committedDate": "2020-04-23T08:55:15Z", "message": "address comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk5NjE2MTgy", "url": "https://github.com/apache/flink/pull/11735#pullrequestreview-399616182", "createdAt": "2020-04-24T03:29:37Z", "commit": {"oid": "67355f513149f11b717932a98f406b8be92bfbe2"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4986, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}