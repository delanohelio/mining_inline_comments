{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDA1MDMwMDcx", "number": 11791, "title": "[FLINK-17210][sql-parser][hive] Implement database DDLs for Hive dialect", "bodyText": "What is the purpose of the change\nTo implement database related DDLs for Hive dialect.\nBrief change log\n\nAdd separate parser for Hive dialect.\nImplement database DDL syntax and Calcite SqlNode.\nAdd FlinkSqlParserImplFactory to create parser according to SqlConformance.\nChange PlannerContext to use FlinkSqlParserImplFactory when getting sql parser config\nChange HiveCatalog to differentiate generic and hive databases.\nAdd/update test cases.\n\nVerifying this change\nExisting and added test cases.\nDoes this pull request potentially affect one of the following parts:\n\nDependencies (does it add or upgrade a dependency): yes\nThe public API, i.e., is any changed class annotated with @Public(Evolving): no\nThe serializers: no\nThe runtime per-record code paths (performance sensitive): no\nAnything that affects deployment or recovery: JobManager (and its components), Checkpointing, Kubernetes/Yarn/Mesos, ZooKeeper: no\nThe S3 file system connector: no\n\nDocumentation\n\nDoes this pull request introduce a new feature? yes\nIf yes, how is the feature documented? docs", "createdAt": "2020-04-17T09:41:32Z", "url": "https://github.com/apache/flink/pull/11791", "merged": true, "mergeCommit": {"oid": "ddf6a0d00f1128858f987693d49b836e7161d949"}, "closed": true, "closedAt": "2020-04-28T08:37:18Z", "author": {"login": "lirui-apache"}, "timelineItems": {"totalCount": 26, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcaon04gBqjMyNjc2NDUyMzY=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcb7heaAH2gAyNDA1MDMwMDcxOjkzOTM5NjQxYzgwYjAzNjFjNmU4NGEwMTU4OGU2MzE2MzNiMjk5ZWI=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a6642cdfead306f1192f73c861e7201af9d38c56", "author": {"user": {"login": "lirui-apache", "name": "Rui Li"}}, "url": "https://github.com/apache/flink/commit/a6642cdfead306f1192f73c861e7201af9d38c56", "committedDate": "2020-04-17T09:34:40Z", "message": "[FLINK-17210][sql-parser][hive] Implement database DDLs for Hive dialect"}, "afterCommit": {"oid": "6359340c0b5b01923d7ac2824b9eb1071e0f2f37", "author": {"user": {"login": "lirui-apache", "name": "Rui Li"}}, "url": "https://github.com/apache/flink/commit/6359340c0b5b01923d7ac2824b9eb1071e0f2f37", "committedDate": "2020-04-24T03:07:37Z", "message": "rebase"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk5NjE5NTU1", "url": "https://github.com/apache/flink/pull/11791#pullrequestreview-399619555", "createdAt": "2020-04-24T03:42:35Z", "commit": {"oid": "6359340c0b5b01923d7ac2824b9eb1071e0f2f37"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQwMzo0MjozNVrOGLFAew==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQwNTozMzoyMlrOGLHMCQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDI2OTU2Mw==", "bodyText": "We usually put the properties key in the connector validator instead of the SqlNode, i think.", "url": "https://github.com/apache/flink/pull/11791#discussion_r414269563", "createdAt": "2020-04-24T03:42:35Z", "author": {"login": "danny0405"}, "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/catalog/hive/HiveCatalog.java", "diffHunk": "@@ -247,7 +253,10 @@ public CatalogDatabase getDatabase(String databaseName) throws DatabaseNotExistE\n \n \t\tMap<String, String> properties = hiveDatabase.getParameters();\n \n-\t\tproperties.put(HiveCatalogConfig.DATABASE_LOCATION_URI, hiveDatabase.getLocationUri());\n+\t\tboolean isGeneric = getObjectIsGeneric(properties);\n+\t\tif (!isGeneric) {\n+\t\t\tproperties.put(SqlCreateHiveDatabase.DATABASE_LOCATION_URI, hiveDatabase.getLocationUri());\n+\t\t}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6359340c0b5b01923d7ac2824b9eb1071e0f2f37"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDMwNTI4OQ==", "bodyText": "How about name it getObjectIsGenericDefaultTrue", "url": "https://github.com/apache/flink/pull/11791#discussion_r414305289", "createdAt": "2020-04-24T05:33:22Z", "author": {"login": "danny0405"}, "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/catalog/hive/HiveCatalog.java", "diffHunk": "@@ -1403,4 +1446,29 @@ public CatalogColumnStatistics getPartitionColumnStatistics(ObjectPath tablePath\n \t\t}\n \t}\n \n+\tprivate static boolean createObjectIsGeneric(Map<String, String> properties) {\n+\t\t// When creating an object, a hive object needs explicitly have a key is_generic = false", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6359340c0b5b01923d7ac2824b9eb1071e0f2f37"}, "originalPosition": 166}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk5NjUxMTc0", "url": "https://github.com/apache/flink/pull/11791#pullrequestreview-399651174", "createdAt": "2020-04-24T05:33:38Z", "commit": {"oid": "6359340c0b5b01923d7ac2824b9eb1071e0f2f37"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQwNTozMzozOFrOGLHMYw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQwNTozMzozOFrOGLHMYw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDMwNTM3OQ==", "bodyText": "How about name it getObjectIsGenericDefaultFalse", "url": "https://github.com/apache/flink/pull/11791#discussion_r414305379", "createdAt": "2020-04-24T05:33:38Z", "author": {"login": "danny0405"}, "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/catalog/hive/HiveCatalog.java", "diffHunk": "@@ -1403,4 +1446,29 @@ public CatalogColumnStatistics getPartitionColumnStatistics(ObjectPath tablePath\n \t\t}\n \t}\n \n+\tprivate static boolean createObjectIsGeneric(Map<String, String> properties) {\n+\t\t// When creating an object, a hive object needs explicitly have a key is_generic = false\n+\t\t// otherwise, this is a generic object if 1) the key is missing 2) is_generic = true\n+\t\t// this is opposite to reading an object. See getObjectIsGeneric().\n+\t\tif (properties == null) {\n+\t\t\treturn true;\n+\t\t}\n+\t\tboolean isGeneric;\n+\t\tif (!properties.containsKey(CatalogConfig.IS_GENERIC)) {\n+\t\t\t// must be a generic object\n+\t\t\tisGeneric = true;\n+\t\t\tproperties.put(CatalogConfig.IS_GENERIC, String.valueOf(true));\n+\t\t} else {\n+\t\t\tisGeneric = Boolean.parseBoolean(properties.get(CatalogConfig.IS_GENERIC));\n+\t\t}\n+\t\treturn isGeneric;\n+\t}\n+\n+\tprivate static boolean getObjectIsGeneric(Map<String, String> properties) {\n+\t\t// When retrieving an object, a generic object needs explicitly have a key is_generic = true", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6359340c0b5b01923d7ac2824b9eb1071e0f2f37"}, "originalPosition": 184}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk5NjUzNTI2", "url": "https://github.com/apache/flink/pull/11791#pullrequestreview-399653526", "createdAt": "2020-04-24T05:41:19Z", "commit": {"oid": "6359340c0b5b01923d7ac2824b9eb1071e0f2f37"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQwNTo0MToyMFrOGLHW4Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQwNTo0MToyMFrOGLHW4Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDMwODA2NQ==", "bodyText": "Remove the useless imports.", "url": "https://github.com/apache/flink/pull/11791#discussion_r414308065", "createdAt": "2020-04-24T05:41:20Z", "author": {"login": "danny0405"}, "path": "flink-table/flink-sql-parser/src/main/codegen-hive/data/Parser.tdd", "diffHunk": "@@ -0,0 +1,547 @@\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+# http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+{\n+  # Generated parser implementation package and class name.\n+  package: \"org.apache.flink.sql.parser.impl\",\n+  class: \"FlinkHiveSqlParserImpl\",\n+\n+  # List of additional classes and packages to import.\n+  # Example. \"org.apache.calcite.sql.*\", \"java.util.List\".\n+  # Please keep the import classes in alphabetical order if new class is added.\n+  imports: [\n+    \"org.apache.flink.sql.parser.ddl.hive.HiveDDLUtils\"\n+    \"org.apache.flink.sql.parser.ddl.hive.SqlAlterHiveDatabaseLocation\"\n+    \"org.apache.flink.sql.parser.ddl.hive.SqlAlterHiveDatabaseOwner\"\n+    \"org.apache.flink.sql.parser.ddl.hive.SqlAlterHiveDatabaseProps\"\n+    \"org.apache.flink.sql.parser.ddl.hive.SqlCreateHiveDatabase\"\n+    \"org.apache.flink.sql.parser.ddl.SqlAlterDatabase\"\n+    \"org.apache.flink.sql.parser.ddl.SqlAlterTable\"\n+    \"org.apache.flink.sql.parser.ddl.SqlAlterTableProperties\"\n+    \"org.apache.flink.sql.parser.ddl.SqlAlterTableRename\"\n+    \"org.apache.flink.sql.parser.ddl.SqlCreateCatalog\"\n+    \"org.apache.flink.sql.parser.ddl.SqlCreateFunction\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6359340c0b5b01923d7ac2824b9eb1071e0f2f37"}, "originalPosition": 36}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk5NjU4OTE5", "url": "https://github.com/apache/flink/pull/11791#pullrequestreview-399658919", "createdAt": "2020-04-24T05:56:43Z", "commit": {"oid": "6359340c0b5b01923d7ac2824b9eb1071e0f2f37"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQwNTo1Njo0M1rOGLHt1g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQwNTo1Njo0M1rOGLHt1g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDMxMzk0Mg==", "bodyText": "It seems hacky we put these properties internal through the table options, i think these properties should be kept in each SqlNode but not the property list.", "url": "https://github.com/apache/flink/pull/11791#discussion_r414313942", "createdAt": "2020-04-24T05:56:43Z", "author": {"login": "danny0405"}, "path": "flink-table/flink-sql-parser/src/main/java/org/apache/flink/sql/parser/ddl/hive/HiveDDLUtils.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.sql.parser.ddl.hive;\n+\n+import org.apache.flink.sql.parser.ddl.SqlTableOption;\n+import org.apache.flink.sql.parser.impl.ParseException;\n+import org.apache.flink.table.catalog.config.CatalogConfig;\n+\n+import org.apache.calcite.sql.SqlLiteral;\n+import org.apache.calcite.sql.SqlNode;\n+import org.apache.calcite.sql.SqlNodeList;\n+import org.apache.calcite.sql.parser.SqlParserPos;\n+\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+import static org.apache.flink.sql.parser.ddl.hive.SqlAlterHiveDatabase.ALTER_DATABASE_OP;\n+import static org.apache.flink.sql.parser.ddl.hive.SqlCreateHiveDatabase.DATABASE_LOCATION_URI;\n+\n+/**\n+ * Util methods for Hive DDL Sql nodes.\n+ */\n+public class HiveDDLUtils {\n+\n+\tprivate static final Set<String> RESERVED_DB_PROPERTIES = new HashSet<>();\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6359340c0b5b01923d7ac2824b9eb1071e0f2f37"}, "originalPosition": 43}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk5NjU5NDkz", "url": "https://github.com/apache/flink/pull/11791#pullrequestreview-399659493", "createdAt": "2020-04-24T05:58:17Z", "commit": {"oid": "6359340c0b5b01923d7ac2824b9eb1071e0f2f37"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQwNTo1ODoxN1rOGLHwGA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQwNTo1ODoxN1rOGLHwGA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDMxNDUyMA==", "bodyText": "The plugin is a mess, can we just create another module instead put the code in one ? And why we copy the parser file of Flink, it seems there is no any reuse parse code block.", "url": "https://github.com/apache/flink/pull/11791#discussion_r414314520", "createdAt": "2020-04-24T05:58:17Z", "author": {"login": "danny0405"}, "path": "flink-table/flink-sql-parser/pom.xml", "diffHunk": "@@ -298,6 +348,23 @@ under the License.\n \t\t\t\t\t\t\t<outputDirectory>${project.build.directory}/generated-sources/</outputDirectory>\n \t\t\t\t\t\t</configuration>\n \t\t\t\t\t</execution>\n+\t\t\t\t\t<execution>\n+\t\t\t\t\t\t<phase>generate-sources</phase>\n+\t\t\t\t\t\t<id>javacc-hive</id>\n+\t\t\t\t\t\t<goals>\n+\t\t\t\t\t\t\t<goal>javacc</goal>\n+\t\t\t\t\t\t</goals>\n+\t\t\t\t\t\t<configuration>\n+\t\t\t\t\t\t\t<sourceDirectory>${project.build.directory}/generated-sources-hive/</sourceDirectory>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6359340c0b5b01923d7ac2824b9eb1071e0f2f37"}, "originalPosition": 89}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk5NjU5NzMx", "url": "https://github.com/apache/flink/pull/11791#pullrequestreview-399659731", "createdAt": "2020-04-24T05:58:52Z", "commit": {"oid": "6359340c0b5b01923d7ac2824b9eb1071e0f2f37"}, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAwMzQ3Njky", "url": "https://github.com/apache/flink/pull/11791#pullrequestreview-400347692", "createdAt": "2020-04-25T02:27:48Z", "commit": {"oid": "3a861a4778cf6b4347788fd7a6cfc6e6c5bd970a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNVQwMjoyNzo0OFrOGLu6xw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNVQwMjoyNzo0OFrOGLu6xw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDk1NjIzMQ==", "bodyText": "The comment is not correct now, we actually do not switch parser dialect with the setConformance interface.", "url": "https://github.com/apache/flink/pull/11791#discussion_r414956231", "createdAt": "2020-04-25T02:27:48Z", "author": {"login": "danny0405"}, "path": "flink-table/flink-sql-parser-hive/src/main/java/org/apache/flink/sql/parser/hive/package-info.java", "diffHunk": "@@ -0,0 +1,45 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to you under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+/**\n+ * Flink sql parser for hive dialect.\n+ *\n+ * <p>This module contains the DDLs and some custom DMLs for Apache Flink.\n+ *\n+ * <p>Most of the sql grammars belong to sql standard or Flink's dialect. To support\n+ * a new sql dialect, add a new sql conformance to\n+ * {@link org.apache.flink.sql.parser.validate.FlinkSqlConformance},\n+ * then use this sql conformance to make context aware decisions in parse block. See the usage of\n+ * {@link org.apache.flink.sql.parser.validate.FlinkSqlConformance#HIVE} in {@code parserimpls.ftl}.\n+ *\n+ * <p>To use a specific sql dialect for the parser, config the parser to the specific sql conformance\n+ * with a code snippet like below:\n+ * <blockquote><pre>\n+ *   SqlParser.create(source,\n+ *   \t\tSqlParser.configBuilder()\n+ *   \t\t\t.setParserFactory(parserImplFactory())\n+ * \t\t\t\t.setQuoting(Quoting.DOUBLE_QUOTE)\n+ * \t\t\t\t.setUnquotedCasing(Casing.TO_UPPER)\n+ * \t\t\t\t.setQuotedCasing(Casing.UNCHANGED)\n+ * \t\t\t\t.setConformance(conformance0) // the sql conformance you want use.\n+ * \t\t\t\t.build());\n+ * </pre></blockquote>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3a861a4778cf6b4347788fd7a6cfc6e6c5bd970a"}, "originalPosition": 40}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAwNDUzMzIx", "url": "https://github.com/apache/flink/pull/11791#pullrequestreview-400453321", "createdAt": "2020-04-26T03:22:39Z", "commit": {"oid": "3a861a4778cf6b4347788fd7a6cfc6e6c5bd970a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNlQwMzoyMjozOVrOGL96mw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNlQwMzoyMjozOVrOGL96mw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTIwMTk0Nw==", "bodyText": "must we create a new module?", "url": "https://github.com/apache/flink/pull/11791#discussion_r415201947", "createdAt": "2020-04-26T03:22:39Z", "author": {"login": "JingsongLi"}, "path": "flink-table/pom.xml", "diffHunk": "@@ -45,6 +45,7 @@ under the License.\n \t\t<module>flink-table-uber-blink</module>\n \t\t<module>flink-sql-client</module>\n \t\t<module>flink-sql-parser</module>\n+\t\t<module>flink-sql-parser-hive</module>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3a861a4778cf6b4347788fd7a6cfc6e6c5bd970a"}, "originalPosition": 4}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAwNDU0MjY0", "url": "https://github.com/apache/flink/pull/11791#pullrequestreview-400454264", "createdAt": "2020-04-26T03:37:33Z", "commit": {"oid": "3a861a4778cf6b4347788fd7a6cfc6e6c5bd970a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNlQwMzozNzozM1rOGL-Dpg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNlQwMzozNzozM1rOGL-Dpg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTIwNDI2Mg==", "bodyText": "I can see HiveCatalog becomes big and big, can we split database related codes to a separate class?", "url": "https://github.com/apache/flink/pull/11791#discussion_r415204262", "createdAt": "2020-04-26T03:37:33Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/catalog/hive/HiveCatalog.java", "diffHunk": "@@ -292,18 +303,62 @@ public void alterDatabase(String databaseName, CatalogDatabase newDatabase, bool\n \t\tcheckNotNull(newDatabase, \"newDatabase cannot be null\");\n \n \t\t// client.alterDatabase doesn't throw any exception if there is no existing database\n-\t\tif (!databaseExists(databaseName)) {\n+\t\tDatabase hiveDB;\n+\t\ttry {\n+\t\t\thiveDB = getHiveDatabase(databaseName);\n+\t\t} catch (DatabaseNotExistException e) {\n \t\t\tif (!ignoreIfNotExists) {\n \t\t\t\tthrow new DatabaseNotExistException(getName(), databaseName);\n \t\t\t}\n \n \t\t\treturn;\n \t\t}\n-\n-\t\tDatabase newHiveDatabase = instantiateHiveDatabase(databaseName, newDatabase);\n+\t\tMap<String, String> params = hiveDB.getParameters();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3a861a4778cf6b4347788fd7a6cfc6e6c5bd970a"}, "originalPosition": 70}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAwNDg2NTE0", "url": "https://github.com/apache/flink/pull/11791#pullrequestreview-400486514", "createdAt": "2020-04-26T10:21:42Z", "commit": {"oid": "f5a365a9ea932cb758f2888c119943173f809f57"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNlQxMDoyMTo0M1rOGMCXYg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNlQxMDoyMTo0M1rOGMCXYg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTI3NDg1MA==", "bodyText": "Why the unparse SQL is different ?", "url": "https://github.com/apache/flink/pull/11791#discussion_r415274850", "createdAt": "2020-04-26T10:21:43Z", "author": {"login": "danny0405"}, "path": "flink-table/flink-sql-parser-hive/src/test/java/org/apache/flink/sql/parser/hive/FlinkHiveSqlParserImplTest.java", "diffHunk": "@@ -0,0 +1,118 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.sql.parser.hive;\n+\n+import org.apache.flink.sql.parser.hive.impl.FlinkHiveSqlParserImpl;\n+\n+import org.apache.calcite.sql.parser.SqlParserImplFactory;\n+import org.apache.calcite.sql.parser.SqlParserTest;\n+import org.junit.Test;\n+\n+/**\n+ * Tests for {@link FlinkHiveSqlParserImpl}.\n+ */\n+public class FlinkHiveSqlParserImplTest extends SqlParserTest {\n+\n+\t@Override\n+\tprotected SqlParserImplFactory parserImplFactory() {\n+\t\treturn FlinkHiveSqlParserImpl.FACTORY;\n+\t}\n+\n+\t// overrides test methods that we don't support\n+\t@Override\n+\tpublic void testDescribeStatement() {\n+\t}\n+\n+\t@Override\n+\tpublic void testTableHintsInInsert() {\n+\t}\n+\n+\t@Override\n+\tpublic void testDescribeSchema() {\n+\t}\n+\n+\t@Test\n+\tpublic void testShowDatabases() {\n+\t\tsql(\"show databases\").ok(\"SHOW DATABASES\");\n+\t}\n+\n+\t@Test\n+\tpublic void testUseDatabase() {\n+\t\t// use database\n+\t\tsql(\"use db1\").ok(\"USE `DB1`\");\n+\t}\n+\n+\t@Test\n+\tpublic void testCreateDatabase() {\n+\t\tsql(\"create database db1\")\n+\t\t\t\t.ok(\"CREATE DATABASE `DB1` WITH (\\n\" +\n+\t\t\t\t\t\t\"  'is_generic' = 'false'\\n\" +\n+\t\t\t\t\t\t\")\");\n+\t\tsql(\"create database db1 comment 'comment db1' location '/path/to/db1'\")\n+\t\t\t\t.ok(\"CREATE DATABASE `DB1`\\n\" +\n+\t\t\t\t\t\t\"COMMENT 'comment db1' WITH (\\n\" +\n+\t\t\t\t\t\t\"  'is_generic' = 'false',\\n\" +\n+\t\t\t\t\t\t\"  'database.location_uri' = '/path/to/db1'\\n\" +\n+\t\t\t\t\t\t\")\");\n+\t\tsql(\"create database db1 with dbproperties ('k1'='v1','k2'='v2')\")\n+\t\t\t\t.ok(\"CREATE DATABASE `DB1` WITH (\\n\" +\n+\t\t\t\t\t\t\"  'k1' = 'v1',\\n\" +\n+\t\t\t\t\t\t\"  'k2' = 'v2',\\n\" +\n+\t\t\t\t\t\t\"  'is_generic' = 'false'\\n\" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f5a365a9ea932cb758f2888c119943173f809f57"}, "originalPosition": 77}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAwNDg2NTQ4", "url": "https://github.com/apache/flink/pull/11791#pullrequestreview-400486548", "createdAt": "2020-04-26T10:22:13Z", "commit": {"oid": "f5a365a9ea932cb758f2888c119943173f809f57"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNlQxMDoyMjoxM1rOGMCXng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNlQxMDoyMjoxM1rOGMCXng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTI3NDkxMA==", "bodyText": "The unparse SQL is different.", "url": "https://github.com/apache/flink/pull/11791#discussion_r415274910", "createdAt": "2020-04-26T10:22:13Z", "author": {"login": "danny0405"}, "path": "flink-table/flink-sql-parser-hive/src/test/java/org/apache/flink/sql/parser/hive/FlinkHiveSqlParserImplTest.java", "diffHunk": "@@ -0,0 +1,118 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.sql.parser.hive;\n+\n+import org.apache.flink.sql.parser.hive.impl.FlinkHiveSqlParserImpl;\n+\n+import org.apache.calcite.sql.parser.SqlParserImplFactory;\n+import org.apache.calcite.sql.parser.SqlParserTest;\n+import org.junit.Test;\n+\n+/**\n+ * Tests for {@link FlinkHiveSqlParserImpl}.\n+ */\n+public class FlinkHiveSqlParserImplTest extends SqlParserTest {\n+\n+\t@Override\n+\tprotected SqlParserImplFactory parserImplFactory() {\n+\t\treturn FlinkHiveSqlParserImpl.FACTORY;\n+\t}\n+\n+\t// overrides test methods that we don't support\n+\t@Override\n+\tpublic void testDescribeStatement() {\n+\t}\n+\n+\t@Override\n+\tpublic void testTableHintsInInsert() {\n+\t}\n+\n+\t@Override\n+\tpublic void testDescribeSchema() {\n+\t}\n+\n+\t@Test\n+\tpublic void testShowDatabases() {\n+\t\tsql(\"show databases\").ok(\"SHOW DATABASES\");\n+\t}\n+\n+\t@Test\n+\tpublic void testUseDatabase() {\n+\t\t// use database\n+\t\tsql(\"use db1\").ok(\"USE `DB1`\");\n+\t}\n+\n+\t@Test\n+\tpublic void testCreateDatabase() {\n+\t\tsql(\"create database db1\")\n+\t\t\t\t.ok(\"CREATE DATABASE `DB1` WITH (\\n\" +\n+\t\t\t\t\t\t\"  'is_generic' = 'false'\\n\" +\n+\t\t\t\t\t\t\")\");\n+\t\tsql(\"create database db1 comment 'comment db1' location '/path/to/db1'\")\n+\t\t\t\t.ok(\"CREATE DATABASE `DB1`\\n\" +\n+\t\t\t\t\t\t\"COMMENT 'comment db1' WITH (\\n\" +\n+\t\t\t\t\t\t\"  'is_generic' = 'false',\\n\" +\n+\t\t\t\t\t\t\"  'database.location_uri' = '/path/to/db1'\\n\" +\n+\t\t\t\t\t\t\")\");\n+\t\tsql(\"create database db1 with dbproperties ('k1'='v1','k2'='v2')\")\n+\t\t\t\t.ok(\"CREATE DATABASE `DB1` WITH (\\n\" +\n+\t\t\t\t\t\t\"  'k1' = 'v1',\\n\" +\n+\t\t\t\t\t\t\"  'k2' = 'v2',\\n\" +\n+\t\t\t\t\t\t\"  'is_generic' = 'false'\\n\" +\n+\t\t\t\t\t\t\")\");\n+\t}\n+\n+\t@Test\n+\tpublic void testAlterDatabase() {\n+\t\tsql(\"alter database db1 set dbproperties('k1'='v1')\")\n+\t\t\t\t.ok(\"ALTER DATABASE `DB1` SET (\\n\" +\n+\t\t\t\t\t\t\"  'k1' = 'v1',\\n\" +\n+\t\t\t\t\t\t\"  'alter.database.op' = 'CHANGE_PROPS'\\n\" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f5a365a9ea932cb758f2888c119943173f809f57"}, "originalPosition": 86}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAwNDg2NjM4", "url": "https://github.com/apache/flink/pull/11791#pullrequestreview-400486638", "createdAt": "2020-04-26T10:23:13Z", "commit": {"oid": "f5a365a9ea932cb758f2888c119943173f809f57"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNlQxMDoyMzoxM1rOGMCYTQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNlQxMDoyMzoxM1rOGMCYTQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTI3NTA4NQ==", "bodyText": "Why we append a new dependency instead of override the flink-sql-parser ?", "url": "https://github.com/apache/flink/pull/11791#discussion_r415275085", "createdAt": "2020-04-26T10:23:13Z", "author": {"login": "danny0405"}, "path": "flink-table/flink-table-planner-blink/pom.xml", "diffHunk": "@@ -100,6 +100,18 @@ under the License.\n \t\t\t</exclusions>\n \t\t</dependency>\n \n+\t\t<dependency>\n+\t\t\t<groupId>org.apache.flink</groupId>\n+\t\t\t<artifactId>flink-sql-parser-hive</artifactId>\n+\t\t\t<version>${project.version}</version>\n+\t\t\t<exclusions>\n+\t\t\t\t<exclusion>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f5a365a9ea932cb758f2888c119943173f809f57"}, "originalPosition": 9}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAwNDg3MDQ0", "url": "https://github.com/apache/flink/pull/11791#pullrequestreview-400487044", "createdAt": "2020-04-26T10:27:31Z", "commit": {"oid": "f5a365a9ea932cb758f2888c119943173f809f57"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNlQxMDoyNzozMVrOGMCbdg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNlQxMDoyNzozMVrOGMCbdg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTI3NTg5NA==", "bodyText": "The provided scope is useless when it becomes an in-direct dependency.", "url": "https://github.com/apache/flink/pull/11791#discussion_r415275894", "createdAt": "2020-04-26T10:27:31Z", "author": {"login": "danny0405"}, "path": "flink-table/flink-sql-parser-hive/pom.xml", "diffHunk": "@@ -0,0 +1,217 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+  http://www.apache.org/licenses/LICENSE-2.0\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n+\t\t xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n+\t\t xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+\n+\t<modelVersion>4.0.0</modelVersion>\n+\n+\t<parent>\n+\t\t<artifactId>flink-table</artifactId>\n+\t\t<groupId>org.apache.flink</groupId>\n+\t\t<version>1.11-SNAPSHOT</version>\n+\t</parent>\n+\n+\t<artifactId>flink-sql-parser-hive</artifactId>\n+\t<name>flink-sql-parser-hive</name>\n+\n+\t<packaging>jar</packaging>\n+\n+\t<properties>\n+\t\t<!-- override parent pom -->\n+\t\t<test.excludedGroups/>\n+\t</properties>\n+\n+\t<dependencies>\n+\t\t<!-- depend on flink-sql-parser and explicitly define its provided deps -->\n+\t\t<dependency>\n+\t\t\t<groupId>org.apache.flink</groupId>\n+\t\t\t<artifactId>flink-sql-parser</artifactId>\n+\t\t\t<version>${project.version}</version>\n+\t\t\t<scope>provided</scope>\n+\t\t</dependency>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f5a365a9ea932cb758f2888c119943173f809f57"}, "originalPosition": 47}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f5a365a9ea932cb758f2888c119943173f809f57", "author": {"user": {"login": "lirui-apache", "name": "Rui Li"}}, "url": "https://github.com/apache/flink/commit/f5a365a9ea932cb758f2888c119943173f809f57", "committedDate": "2020-04-26T04:21:45Z", "message": "address comments"}, "afterCommit": {"oid": "a6a3a9e51fd9ba484d1ab4ccd0646dcacc0692ff", "author": {"user": {"login": "lirui-apache", "name": "Rui Li"}}, "url": "https://github.com/apache/flink/commit/a6a3a9e51fd9ba484d1ab4ccd0646dcacc0692ff", "committedDate": "2020-04-26T13:08:28Z", "message": "fix unparse sql"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAwNTk3Nzgy", "url": "https://github.com/apache/flink/pull/11791#pullrequestreview-400597782", "createdAt": "2020-04-27T02:56:11Z", "commit": {"oid": "a6a3a9e51fd9ba484d1ab4ccd0646dcacc0692ff"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yN1QwMjo1NjoxMlrOGMOnvA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yN1QwMjo1NjoxMlrOGMOnvA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTQ3NTY0NA==", "bodyText": "We do not need to extend SqlParserImplFactory , how about just a tool class named FlinkSqlParserFactories and there is a method to return the factory by conformance FlinkSqlParserFactories#createFactory(SqlConformance) ?", "url": "https://github.com/apache/flink/pull/11791#discussion_r415475644", "createdAt": "2020-04-27T02:56:12Z", "author": {"login": "danny0405"}, "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/delegation/FlinkSqlParserImplFactory.java", "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.delegation;\n+\n+import org.apache.flink.sql.parser.hive.impl.FlinkHiveSqlParserImpl;\n+import org.apache.flink.sql.parser.impl.FlinkSqlParserImpl;\n+import org.apache.flink.sql.parser.validate.FlinkSqlConformance;\n+\n+import org.apache.calcite.sql.parser.SqlAbstractParserImpl;\n+import org.apache.calcite.sql.parser.SqlParserImplFactory;\n+import org.apache.calcite.sql.validate.SqlConformance;\n+\n+import java.io.Reader;\n+\n+/**\n+ * A SqlParserImplFactory that creates the parser according to SqlConformance.\n+ */\n+public class FlinkSqlParserImplFactory implements SqlParserImplFactory {\n+\n+\tprivate final SqlConformance conformance;\n+\n+\tpublic FlinkSqlParserImplFactory(SqlConformance conformance) {\n+\t\tthis.conformance = conformance;\n+\t}\n+\n+\t@Override\n+\tpublic SqlAbstractParserImpl getParser(Reader stream) {\n+\t\tif (conformance == FlinkSqlConformance.HIVE) {\n+\t\t\treturn FlinkHiveSqlParserImpl.FACTORY.getParser(stream);\n+\t\t} else {\n+\t\t\treturn FlinkSqlParserImpl.FACTORY.getParser(stream);\n+\t\t}\n+\t}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a6a3a9e51fd9ba484d1ab4ccd0646dcacc0692ff"}, "originalPosition": 49}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0fe9131d725743f48cc12d7c31f2904da2329b7b", "author": {"user": {"login": "lirui-apache", "name": "Rui Li"}}, "url": "https://github.com/apache/flink/commit/0fe9131d725743f48cc12d7c31f2904da2329b7b", "committedDate": "2020-04-27T03:43:23Z", "message": "[FLINK-17210][sql-parser][hive] Implement database DDLs for Hive dialect"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5d8dd83cb42ee85a5bf268eaf9da194e57c2a29b", "author": {"user": {"login": "lirui-apache", "name": "Rui Li"}}, "url": "https://github.com/apache/flink/commit/5d8dd83cb42ee85a5bf268eaf9da194e57c2a29b", "committedDate": "2020-04-27T03:43:23Z", "message": "rebase"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "559d777c9d6c72d75da299dfee565eebf16ae192", "author": {"user": {"login": "lirui-apache", "name": "Rui Li"}}, "url": "https://github.com/apache/flink/commit/559d777c9d6c72d75da299dfee565eebf16ae192", "committedDate": "2020-04-27T03:43:23Z", "message": "move hive parser to a separate module"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5bca4b1125bd4523102c6c222fff0ba2ae8817a2", "author": {"user": {"login": "lirui-apache", "name": "Rui Li"}}, "url": "https://github.com/apache/flink/commit/5bca4b1125bd4523102c6c222fff0ba2ae8817a2", "committedDate": "2020-04-27T03:43:23Z", "message": "address comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "325f3813b762de41e5e248703b645644978f47d8", "author": {"user": {"login": "lirui-apache", "name": "Rui Li"}}, "url": "https://github.com/apache/flink/commit/325f3813b762de41e5e248703b645644978f47d8", "committedDate": "2020-04-27T03:43:23Z", "message": "fix unparse sql"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5ce52e3cda62c629df16d95ccb345d830b3a3531", "author": {"user": {"login": "lirui-apache", "name": "Rui Li"}}, "url": "https://github.com/apache/flink/commit/5ce52e3cda62c629df16d95ccb345d830b3a3531", "committedDate": "2020-04-27T03:53:57Z", "message": "add util class to create SqlParserImplFactory"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a6a3a9e51fd9ba484d1ab4ccd0646dcacc0692ff", "author": {"user": {"login": "lirui-apache", "name": "Rui Li"}}, "url": "https://github.com/apache/flink/commit/a6a3a9e51fd9ba484d1ab4ccd0646dcacc0692ff", "committedDate": "2020-04-26T13:08:28Z", "message": "fix unparse sql"}, "afterCommit": {"oid": "5ce52e3cda62c629df16d95ccb345d830b3a3531", "author": {"user": {"login": "lirui-apache", "name": "Rui Li"}}, "url": "https://github.com/apache/flink/commit/5ce52e3cda62c629df16d95ccb345d830b3a3531", "committedDate": "2020-04-27T03:53:57Z", "message": "add util class to create SqlParserImplFactory"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAwNjE4NDQy", "url": "https://github.com/apache/flink/pull/11791#pullrequestreview-400618442", "createdAt": "2020-04-27T04:27:22Z", "commit": {"oid": "5ce52e3cda62c629df16d95ccb345d830b3a3531"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAxNDQ0NzE3", "url": "https://github.com/apache/flink/pull/11791#pullrequestreview-401444717", "createdAt": "2020-04-28T01:53:47Z", "commit": {"oid": "5ce52e3cda62c629df16d95ccb345d830b3a3531"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOFQwMTo1Mzo0N1rOGM_EWw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOFQwMTo1Mzo0N1rOGM_EWw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjI2OTQwMw==", "bodyText": "You maybe need shade flink-sql-parser-hive to the jar too.", "url": "https://github.com/apache/flink/pull/11791#discussion_r416269403", "createdAt": "2020-04-28T01:53:47Z", "author": {"login": "JingsongLi"}, "path": "flink-table/flink-table-planner-blink/pom.xml", "diffHunk": "@@ -100,6 +100,18 @@ under the License.\n \t\t\t</exclusions>\n \t\t</dependency>\n \n+\t\t<dependency>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5ce52e3cda62c629df16d95ccb345d830b3a3531"}, "originalPosition": 4}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "93939641c80b0361c6e84a01588e631633b299eb", "author": {"user": {"login": "lirui-apache", "name": "Rui Li"}}, "url": "https://github.com/apache/flink/commit/93939641c80b0361c6e84a01588e631633b299eb", "committedDate": "2020-04-28T03:43:00Z", "message": "include flink-sql-parser-hive into blink planner jar"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1875, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}