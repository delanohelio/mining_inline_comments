{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTE3MTA4NTU0", "number": 13975, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QxNDozNzowNVrOE2W83A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QxNDo0MzoxNlrOE2W-tw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI1NDM0NTg4OnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/streaming/connectors/kafka/table/KafkaDynamicSource.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QxNDozNzowNVrOHvIdHQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QxNDozNzowNVrOHvIdHQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE4MzY0NQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \tprotected WatermarkStrategy<RowData> watermarkStrategy;\n          \n          \n            \n            \tprotected @Nullable WatermarkStrategy<RowData> watermarkStrategy;\n          \n      \n    \n    \n  \n\nMark it nullable.", "url": "https://github.com/apache/flink/pull/13975#discussion_r519183645", "createdAt": "2020-11-07T14:37:05Z", "author": {"login": "wuchong"}, "path": "flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/streaming/connectors/kafka/table/KafkaDynamicSource.java", "diffHunk": "@@ -73,6 +75,9 @@\n \t/** Metadata that is appended at the end of a physical source row. */\n \tprotected List<String> metadataKeys;\n \n+\t/** Watermark strategy that is used to generate per-partition watermark. */\n+\tprotected WatermarkStrategy<RowData> watermarkStrategy;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5947caaa8eca977df7bade88b4c8b576ebc06d2b"}, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI1NDM0NzEwOnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/table/KafkaTableITCase.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QxNDozODo1NlrOHvIdrQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QxNDozODo1NlrOHvIdrQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE4Mzc4OQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t\t\treturn record.getInt(PARTITION_ID_FIELD_IN_SCHEMA) % partitions.length;\n          \n          \n            \n            \t\t\treturn partitions[record.getInt(PARTITION_ID_FIELD_IN_SCHEMA) % partitions.length];", "url": "https://github.com/apache/flink/pull/13975#discussion_r519183789", "createdAt": "2020-11-07T14:38:56Z", "author": {"login": "wuchong"}, "path": "flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/table/KafkaTableITCase.java", "diffHunk": "@@ -516,10 +518,103 @@ public void testKafkaSourceSinkWithKeyAndFullValue() throws Exception {\n \t\tdeleteTestTopic(topic);\n \t}\n \n+\t@Test\n+\tpublic void testPerPartitionWatermarkKafka() throws Exception {\n+\t\tif (isLegacyConnector) {\n+\t\t\treturn;\n+\t\t}\n+\t\t// we always use a different topic name for each parameterized topic,\n+\t\t// in order to make sure the topic can be created.\n+\t\tfinal String topic = \"per_partition_watermark_topic_\" + format;\n+\t\tcreateTestTopic(topic, 4, 1);\n+\n+\t\t// ---------- Produce an event time stream into Kafka -------------------\n+\t\tString groupId = standardProps.getProperty(\"group.id\");\n+\t\tString bootstraps = standardProps.getProperty(\"bootstrap.servers\");\n+\n+\t\tfinal String createTable = String.format(\n+\t\t\t\t\"CREATE TABLE kafka (\\n\"\n+\t\t\t\t\t\t+ \"  `partition_id` INT,\\n\"\n+\t\t\t\t\t\t+ \"  `name` STRING,\\n\"\n+\t\t\t\t\t\t+ \"  `timestamp` TIMESTAMP(3),\\n\"\n+\t\t\t\t\t\t+ \"  WATERMARK FOR `timestamp` AS `timestamp`\\n\"\n+\t\t\t\t\t\t+ \") WITH (\\n\"\n+\t\t\t\t\t\t+ \"  'connector' = 'kafka',\\n\"\n+\t\t\t\t\t\t+ \"  'topic' = '%s',\\n\"\n+\t\t\t\t\t\t+ \"  'properties.bootstrap.servers' = '%s',\\n\"\n+\t\t\t\t\t\t+ \"  'properties.group.id' = '%s',\\n\"\n+\t\t\t\t\t\t+ \"  'scan.startup.mode' = 'earliest-offset',\\n\"\n+\t\t\t\t\t\t+ \"  'sink.partitioner' = 'org.apache.flink.streaming.connectors.kafka.table.KafkaTableITCase$TestPartitioner',\\n\"\n+\t\t\t\t\t\t+ \"  'format' = '%s'\\n\"\n+\t\t\t\t\t\t+ \")\",\n+\t\t\t\ttopic,\n+\t\t\t\tbootstraps,\n+\t\t\t\tgroupId,\n+\t\t\t\tformat);\n+\n+\t\ttEnv.executeSql(createTable);\n+\n+\t\tString initialValues = \"INSERT INTO kafka\\n\"\n+\t\t\t\t+ \"VALUES\\n\"\n+\t\t\t\t+ \" (0, 'partition-0-name-0', TIMESTAMP '2020-03-08 13:12:11.123'),\\n\"\n+\t\t\t\t+ \" (0, 'partition-0-name-1', TIMESTAMP '2020-03-08 14:12:12.223'),\\n\"\n+\t\t\t\t+ \" (0, 'partition-0-name-2', TIMESTAMP '2020-03-08 15:12:13.323'),\\n\"\n+\t\t\t\t+ \" (1, 'partition-1-name-0', TIMESTAMP '2020-03-09 13:13:11.123'),\\n\"\n+\t\t\t\t+ \" (1, 'partition-1-name-1', TIMESTAMP '2020-03-09 15:13:11.133'),\\n\"\n+\t\t\t\t+ \" (1, 'partition-1-name-2', TIMESTAMP '2020-03-09 16:13:11.143'),\\n\"\n+\t\t\t\t+ \" (2, 'partition-2-name-0', TIMESTAMP '2020-03-10 13:12:14.123'),\\n\"\n+\t\t\t\t+ \" (3, 'partition-3-name-0', TIMESTAMP '2020-03-11 17:12:11.123')\\n\";\n+\t\ttEnv.executeSql(initialValues).await();\n+\n+\t\t// ---------- Consume stream from Kafka -------------------\n+\t\tString createSink =\n+\t\t\t\t\"CREATE TABLE MySink(\"\n+\t\t\t\t\t\t+ \"  id INT,\"\n+\t\t\t\t\t\t+ \"  name STRING,\"\n+\t\t\t\t\t\t+ \"  ts TIMESTAMP(3)\"\n+\t\t\t\t\t\t+ \") WITH (\"\n+\t\t\t\t\t\t+ \"  'connector' = 'values',\"\n+\t\t\t\t\t\t+ \"  'sink-index-of-rowtime' = '2'\"\n+\t\t\t\t\t\t+ \")\";\n+\t\ttEnv.executeSql(createSink);\n+\t\ttEnv.executeSql(\"INSERT INTO MySink SELECT * FROM kafka\");\n+\t\tfinal List<String> expected = Arrays.asList(\n+\t\t\t\"0,partition-0-name-0,2020-03-08T13:12:11.123\",\n+\t\t\t\"0,partition-0-name-1,2020-03-08T14:12:12.223\",\n+\t\t\t\"0,partition-0-name-2,2020-03-08T15:12:13.323\",\n+\t\t\t\"1,partition-1-name-0,2020-03-09T13:13:11.123\",\n+\t\t\t\"1,partition-1-name-1,2020-03-09T15:13:11.133\",\n+\t\t\t\"1,partition-1-name-2,2020-03-09T16:13:11.143\",\n+\t\t\t\"2,partition-2-name-0,2020-03-10T13:12:14.123\",\n+\t\t\t\"3,partition-3-name-0,2020-03-11T17:12:11.123\"\n+\t\t);\n+\t\tKafkaTableTestUtils.waitingExpectedResults(\"MySink\", expected, Duration.ofSeconds(5));\n+\n+\t\t// ------------- cleanup -------------------\n+\n+\t\tdeleteTestTopic(topic);\n+\t}\n+\n+\n+\n \t// --------------------------------------------------------------------------------------------\n \t// Utilities\n \t// --------------------------------------------------------------------------------------------\n \n+\t/**\n+\t * Extract the partition id from the row and set it on the record.\n+\t */\n+\tpublic static class TestPartitioner extends FlinkKafkaPartitioner<RowData> {\n+\n+\t\tprivate static final long serialVersionUID = 1L;\n+\t\tprivate static final int PARTITION_ID_FIELD_IN_SCHEMA = 0;\n+\n+\t\t@Override\n+\t\tpublic int partition(RowData record, byte[] key, byte[] value, String targetTopic, int[] partitions) {\n+\t\t\treturn record.getInt(PARTITION_ID_FIELD_IN_SCHEMA) % partitions.length;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5947caaa8eca977df7bade88b4c8b576ebc06d2b"}, "originalPosition": 113}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI1NDM0ODk3OnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/table/KafkaTableITCase.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QxNDo0MDo0NlrOHvIegg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QxNDo0MTowOVrOHvIepw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE4NDAwMg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t\t\t\t\t\t+ \"  'sink.partitioner' = 'org.apache.flink.streaming.connectors.kafka.table.KafkaTableITCase$TestPartitioner',\\n\"\n          \n          \n            \n            \t\t\t\t\t\t+ \"  'format' = '%s'\\n\"\n          \n          \n            \n            \t\t\t\t\t\t+ \")\",\n          \n          \n            \n            \t\t\t\ttopic,\n          \n          \n            \n            \t\t\t\tbootstraps,\n          \n          \n            \n            \t\t\t\tgroupId,\n          \n          \n            \n            \t\t\t\tformat);\n          \n          \n            \n            \t\t\t\t\t\t+ \"  'sink.partitioner' = '%s',\\n\"\n          \n          \n            \n            \t\t\t\t\t\t+ \"  'format' = '%s'\\n\"\n          \n          \n            \n            \t\t\t\t\t\t+ \")\",\n          \n          \n            \n            \t\t\t\ttopic,\n          \n          \n            \n            \t\t\t\tbootstraps,\n          \n          \n            \n            \t\t\t\tgroupId,\n          \n          \n            \n            \t\t\t\tformat,\n          \n          \n            \n            \t\t\t\tTestPartitioner.class.getCanonicalName());", "url": "https://github.com/apache/flink/pull/13975#discussion_r519184002", "createdAt": "2020-11-07T14:40:46Z", "author": {"login": "wuchong"}, "path": "flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/table/KafkaTableITCase.java", "diffHunk": "@@ -516,10 +518,103 @@ public void testKafkaSourceSinkWithKeyAndFullValue() throws Exception {\n \t\tdeleteTestTopic(topic);\n \t}\n \n+\t@Test\n+\tpublic void testPerPartitionWatermarkKafka() throws Exception {\n+\t\tif (isLegacyConnector) {\n+\t\t\treturn;\n+\t\t}\n+\t\t// we always use a different topic name for each parameterized topic,\n+\t\t// in order to make sure the topic can be created.\n+\t\tfinal String topic = \"per_partition_watermark_topic_\" + format;\n+\t\tcreateTestTopic(topic, 4, 1);\n+\n+\t\t// ---------- Produce an event time stream into Kafka -------------------\n+\t\tString groupId = standardProps.getProperty(\"group.id\");\n+\t\tString bootstraps = standardProps.getProperty(\"bootstrap.servers\");\n+\n+\t\tfinal String createTable = String.format(\n+\t\t\t\t\"CREATE TABLE kafka (\\n\"\n+\t\t\t\t\t\t+ \"  `partition_id` INT,\\n\"\n+\t\t\t\t\t\t+ \"  `name` STRING,\\n\"\n+\t\t\t\t\t\t+ \"  `timestamp` TIMESTAMP(3),\\n\"\n+\t\t\t\t\t\t+ \"  WATERMARK FOR `timestamp` AS `timestamp`\\n\"\n+\t\t\t\t\t\t+ \") WITH (\\n\"\n+\t\t\t\t\t\t+ \"  'connector' = 'kafka',\\n\"\n+\t\t\t\t\t\t+ \"  'topic' = '%s',\\n\"\n+\t\t\t\t\t\t+ \"  'properties.bootstrap.servers' = '%s',\\n\"\n+\t\t\t\t\t\t+ \"  'properties.group.id' = '%s',\\n\"\n+\t\t\t\t\t\t+ \"  'scan.startup.mode' = 'earliest-offset',\\n\"\n+\t\t\t\t\t\t+ \"  'sink.partitioner' = 'org.apache.flink.streaming.connectors.kafka.table.KafkaTableITCase$TestPartitioner',\\n\"\n+\t\t\t\t\t\t+ \"  'format' = '%s'\\n\"\n+\t\t\t\t\t\t+ \")\",\n+\t\t\t\ttopic,\n+\t\t\t\tbootstraps,\n+\t\t\t\tgroupId,\n+\t\t\t\tformat);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5947caaa8eca977df7bade88b4c8b576ebc06d2b"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE4NDAzOQ==", "bodyText": "Do not hard code the class path.", "url": "https://github.com/apache/flink/pull/13975#discussion_r519184039", "createdAt": "2020-11-07T14:41:09Z", "author": {"login": "wuchong"}, "path": "flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/table/KafkaTableITCase.java", "diffHunk": "@@ -516,10 +518,103 @@ public void testKafkaSourceSinkWithKeyAndFullValue() throws Exception {\n \t\tdeleteTestTopic(topic);\n \t}\n \n+\t@Test\n+\tpublic void testPerPartitionWatermarkKafka() throws Exception {\n+\t\tif (isLegacyConnector) {\n+\t\t\treturn;\n+\t\t}\n+\t\t// we always use a different topic name for each parameterized topic,\n+\t\t// in order to make sure the topic can be created.\n+\t\tfinal String topic = \"per_partition_watermark_topic_\" + format;\n+\t\tcreateTestTopic(topic, 4, 1);\n+\n+\t\t// ---------- Produce an event time stream into Kafka -------------------\n+\t\tString groupId = standardProps.getProperty(\"group.id\");\n+\t\tString bootstraps = standardProps.getProperty(\"bootstrap.servers\");\n+\n+\t\tfinal String createTable = String.format(\n+\t\t\t\t\"CREATE TABLE kafka (\\n\"\n+\t\t\t\t\t\t+ \"  `partition_id` INT,\\n\"\n+\t\t\t\t\t\t+ \"  `name` STRING,\\n\"\n+\t\t\t\t\t\t+ \"  `timestamp` TIMESTAMP(3),\\n\"\n+\t\t\t\t\t\t+ \"  WATERMARK FOR `timestamp` AS `timestamp`\\n\"\n+\t\t\t\t\t\t+ \") WITH (\\n\"\n+\t\t\t\t\t\t+ \"  'connector' = 'kafka',\\n\"\n+\t\t\t\t\t\t+ \"  'topic' = '%s',\\n\"\n+\t\t\t\t\t\t+ \"  'properties.bootstrap.servers' = '%s',\\n\"\n+\t\t\t\t\t\t+ \"  'properties.group.id' = '%s',\\n\"\n+\t\t\t\t\t\t+ \"  'scan.startup.mode' = 'earliest-offset',\\n\"\n+\t\t\t\t\t\t+ \"  'sink.partitioner' = 'org.apache.flink.streaming.connectors.kafka.table.KafkaTableITCase$TestPartitioner',\\n\"\n+\t\t\t\t\t\t+ \"  'format' = '%s'\\n\"\n+\t\t\t\t\t\t+ \")\",\n+\t\t\t\ttopic,\n+\t\t\t\tbootstraps,\n+\t\t\t\tgroupId,\n+\t\t\t\tformat);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE4NDAwMg=="}, "originalCommit": {"oid": "5947caaa8eca977df7bade88b4c8b576ebc06d2b"}, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI1NDM1MDYzOnYy", "diffSide": "RIGHT", "path": "flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/factories/TestValuesTableFactory.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QxNDo0MzoxNlrOHvIfQg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QxNDo0MzoxNlrOHvIfQg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE4NDE5NA==", "bodyText": "If this option controls whether to drop late data, then the option name should be something like sink.drop-late-event=true.\nThe rowtime field can be derived from WATERMARK statement (can also be declared on sink), instead of a redundant option.\nBesides, I find you only support this option on append only sink, then you should throw exceptions if the sink is not append only during createDynamicTableSink.", "url": "https://github.com/apache/flink/pull/13975#discussion_r519184194", "createdAt": "2020-11-07T14:43:16Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/factories/TestValuesTableFactory.java", "diffHunk": "@@ -291,6 +291,14 @@ private static RowKind parseRowKind(String rowKindShortString) {\n \t\t\t\"Optional map of 'metadata_key:data_type'. The order will be alphabetically. \" +\n \t\t\t\"The metadata is part of the data when enabled.\");\n \n+\tprivate static final ConfigOption<Integer> SINK_INDEX_OF_ROWTIME = ConfigOptions\n+\t\t.key(\"sink-index-of-rowtime\")\n+\t\t.intType()\n+\t\t.defaultValue(-1)\n+\t\t.withDeprecatedKeys(\n+\t\t\t\"Option index of the rowtime field. The default value -1 indicate that don't drop \" +\n+\t\t\t\"the late data.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5947caaa8eca977df7bade88b4c8b576ebc06d2b"}, "originalPosition": 10}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4844, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}