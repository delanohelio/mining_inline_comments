{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTA3NDc2MTY4", "number": 13724, "title": "[FLINK-19581][orc] Introduce Orc ColumnarRow File source bulk Format", "bodyText": "What is the purpose of the change\nImplement File source ORC Vectorized Reader\nBrief change log\nThe AbstractOrcFileInputFormat reference from #13401\n\nThe base for ORC readers, Implements the reader initialization, vectorized reading, and pooling of column vector objects.\nThe format of Row and GenericRow can be implemented based on this class.\nUse OrcShim to do orc related operations.\nUse both offset and recordsAfterOffset in CheckpointedPosition for better fitting the concept of RecordReader. Avoid skipping some of the middle rows when using pushdown filter.\n\nThe OrcColumnarRowFileInputFormat:\n\nThis class can add extra fields through ColumnBatchFactory, for example, add partition fields.\nProvides ColumnarRow as a view of column batch for high performance.\n\nVerifying this change\nOrcColumnarRowFileInputFormatTest\nDoes this pull request potentially affect one of the following parts:\n\nDependencies (does it add or upgrade a dependency): no\nThe public API, i.e., is any changed class annotated with @Public(Evolving): no\nThe serializers: no\nThe runtime per-record code paths (performance sensitive): no\nAnything that affects deployment or recovery: JobManager (and its components), Checkpointing, Kubernetes/Yarn/Mesos, ZooKeeper: no\nThe S3 file system connector: no\n\nDocumentation\n\nDoes this pull request introduce a new feature? yes\nIf yes, how is the feature documented? JavaDocs", "createdAt": "2020-10-21T11:51:47Z", "url": "https://github.com/apache/flink/pull/13724", "merged": true, "mergeCommit": {"oid": "f6be70be01e36697f3962b10face3e07186f0ba9"}, "closed": true, "closedAt": "2020-11-06T14:31:03Z", "author": {"login": "JingsongLi"}, "timelineItems": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdUsEDLABqjM5MDM0NDY5NzQ=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdZdUGygFqTUyMzk4Njg1Nw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "bf777e65a831b6c6ee8f1c22ae8f6a232ee87deb", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/bf777e65a831b6c6ee8f1c22ae8f6a232ee87deb", "committedDate": "2020-10-21T11:45:19Z", "message": "[FLINK-19581][orc] Introduce Orc ColumnarRow File source bulk Format"}, "afterCommit": {"oid": "e998711a72202b142ba69096b8479f961c6c950a", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/e998711a72202b142ba69096b8479f961c6c950a", "committedDate": "2020-10-21T11:55:45Z", "message": "[FLINK-19581][orc] Introduce Orc ColumnarRow File source bulk Format"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e998711a72202b142ba69096b8479f961c6c950a", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/e998711a72202b142ba69096b8479f961c6c950a", "committedDate": "2020-10-21T11:55:45Z", "message": "[FLINK-19581][orc] Introduce Orc ColumnarRow File source bulk Format"}, "afterCommit": {"oid": "f619476bce3df1f3cff0b0579a0888a98d5312cb", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/f619476bce3df1f3cff0b0579a0888a98d5312cb", "committedDate": "2020-10-21T11:56:15Z", "message": "[FLINK-19581][orc] Introduce Orc ColumnarRow File source bulk Format"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f619476bce3df1f3cff0b0579a0888a98d5312cb", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/f619476bce3df1f3cff0b0579a0888a98d5312cb", "committedDate": "2020-10-21T11:56:15Z", "message": "[FLINK-19581][orc] Introduce Orc ColumnarRow File source bulk Format"}, "afterCommit": {"oid": "7df5517fea18dc5665a10303271a2ccd959d71e7", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/7df5517fea18dc5665a10303271a2ccd959d71e7", "committedDate": "2020-11-04T06:36:37Z", "message": "[FLINK-19581][orc] Introduce Orc ColumnarRow File source bulk Format"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "7df5517fea18dc5665a10303271a2ccd959d71e7", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/7df5517fea18dc5665a10303271a2ccd959d71e7", "committedDate": "2020-11-04T06:36:37Z", "message": "[FLINK-19581][orc] Introduce Orc ColumnarRow File source bulk Format"}, "afterCommit": {"oid": "012beed0dd7796ec1fc67a6e717431540461a7e0", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/012beed0dd7796ec1fc67a6e717431540461a7e0", "committedDate": "2020-11-04T06:38:42Z", "message": "[FLINK-19581][orc] Introduce Orc ColumnarRow File source bulk Format"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIzMDc3NzMw", "url": "https://github.com/apache/flink/pull/13724#pullrequestreview-523077730", "createdAt": "2020-11-04T06:44:08Z", "commit": {"oid": "012beed0dd7796ec1fc67a6e717431540461a7e0"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQwNjo0NDowOFrOHtK2Vw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQwNjo0NDowOFrOHtK2Vw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzEyNTcxOQ==", "bodyText": "This will be introduced in #13919", "url": "https://github.com/apache/flink/pull/13724#discussion_r517125719", "createdAt": "2020-11-04T06:44:08Z", "author": {"login": "JingsongLi"}, "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/filesystem/PartitionFieldExtractor.java", "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.filesystem;\n+\n+import org.apache.flink.connector.file.src.FileSourceSplit;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.utils.PartitionPathUtils;\n+\n+import java.io.Serializable;\n+import java.util.LinkedHashMap;\n+\n+/**\n+ * Interface to extract partition field from split.\n+ */\n+@FunctionalInterface\n+public interface PartitionFieldExtractor<T extends FileSourceSplit> extends Serializable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "012beed0dd7796ec1fc67a6e717431540461a7e0"}, "originalPosition": 32}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b90a17be9b69b6db7ff00a4db2b5096da0777673", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/b90a17be9b69b6db7ff00a4db2b5096da0777673", "committedDate": "2020-11-04T10:07:14Z", "message": "[FLINK-19581][orc] Introduce Orc ColumnarRow File source bulk Format"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3d25c91253ce75af6d2d87b0bae62bc7dbd575bb", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/3d25c91253ce75af6d2d87b0bae62bc7dbd575bb", "committedDate": "2020-11-04T10:07:14Z", "message": "[FLINK-19581][orc] Integrate orc bulk format to filesystem connector"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "83d0d21e0be0a95772549af273be5704af7b0f97", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/83d0d21e0be0a95772549af273be5704af7b0f97", "committedDate": "2020-11-04T09:52:31Z", "message": "[FLINK-19581][orc] Integrate orc bulk format to filesystem connector"}, "afterCommit": {"oid": "3d25c91253ce75af6d2d87b0bae62bc7dbd575bb", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/3d25c91253ce75af6d2d87b0bae62bc7dbd575bb", "committedDate": "2020-11-04T10:07:14Z", "message": "[FLINK-19581][orc] Integrate orc bulk format to filesystem connector"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIzOTA4NzM1", "url": "https://github.com/apache/flink/pull/13724#pullrequestreview-523908735", "createdAt": "2020-11-05T03:56:20Z", "commit": {"oid": "3d25c91253ce75af6d2d87b0bae62bc7dbd575bb"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQwMzo1NjoyMFrOHtysEg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQwNDowMzo1MFrOHtyymQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzc3ODQ1MA==", "bodyText": "Can we make this consistent with ParquetColumnarRowInputFormat? E.g. take produced RowType and no need for selectedFields?", "url": "https://github.com/apache/flink/pull/13724#discussion_r517778450", "createdAt": "2020-11-05T03:56:20Z", "author": {"login": "lirui-apache"}, "path": "flink-formats/flink-orc/src/main/java/org/apache/flink/orc/OrcColumnarRowFileInputFormat.java", "diffHunk": "@@ -0,0 +1,171 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.orc;\n+\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.connector.file.src.FileSourceSplit;\n+import org.apache.flink.connector.file.src.util.Pool;\n+import org.apache.flink.orc.shim.OrcShim;\n+import org.apache.flink.orc.vector.ColumnBatchFactory;\n+import org.apache.flink.orc.vector.OrcVectorizedBatchWrapper;\n+import org.apache.flink.table.data.ColumnarRowData;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.data.vector.ColumnVector;\n+import org.apache.flink.table.data.vector.VectorizedColumnBatch;\n+import org.apache.flink.table.filesystem.ColumnarRowIterator;\n+import org.apache.flink.table.filesystem.PartitionFieldExtractor;\n+import org.apache.flink.table.runtime.typeutils.InternalTypeInfo;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.RowType;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.ql.exec.vector.VectorizedRowBatch;\n+import org.apache.orc.TypeDescription;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.flink.orc.OrcSplitReaderUtil.convertToOrcTypeWithPart;\n+import static org.apache.flink.orc.OrcSplitReaderUtil.getNonPartNames;\n+import static org.apache.flink.orc.OrcSplitReaderUtil.getSelectedOrcFields;\n+import static org.apache.flink.orc.vector.AbstractOrcColumnVector.createFlinkVector;\n+import static org.apache.flink.orc.vector.AbstractOrcColumnVector.createFlinkVectorFromConstant;\n+\n+/**\n+ * An ORC reader that produces a stream of {@link ColumnarRowData} records.\n+ *\n+ * <p>This class can add extra fields through {@link ColumnBatchFactory}, for example,\n+ * add partition fields, which can be extracted from path. Therefore, the {@link #getProducedType()}\n+ * may be different and types of extra fields need to be added.\n+ */\n+public class OrcColumnarRowFileInputFormat<BatchT, SplitT extends FileSourceSplit> extends\n+\t\tAbstractOrcFileInputFormat<RowData, BatchT, SplitT> {\n+\n+\tprivate static final long serialVersionUID = 1L;\n+\n+\tprivate final ColumnBatchFactory<BatchT, SplitT> batchFactory;\n+\tprivate final RowType projectedOutputType;\n+\n+\tpublic OrcColumnarRowFileInputFormat(\n+\t\t\tfinal OrcShim<BatchT> shim,\n+\t\t\tfinal Configuration hadoopConfig,\n+\t\t\tfinal TypeDescription schema,\n+\t\t\tfinal int[] selectedFields,\n+\t\t\tfinal List<OrcFilters.Predicate> conjunctPredicates,\n+\t\t\tfinal int batchSize,\n+\t\t\tfinal ColumnBatchFactory<BatchT, SplitT> batchFactory,\n+\t\t\tfinal RowType projectedOutputType) {\n+\t\tsuper(shim, hadoopConfig, schema, selectedFields, conjunctPredicates, batchSize);\n+\t\tthis.batchFactory = batchFactory;\n+\t\tthis.projectedOutputType = projectedOutputType;\n+\t}\n+\n+\t@Override\n+\tpublic OrcReaderBatch<RowData, BatchT> createReaderBatch(\n+\t\t\tfinal SplitT split,\n+\t\t\tfinal OrcVectorizedBatchWrapper<BatchT> orcBatch,\n+\t\t\tfinal Pool.Recycler<OrcReaderBatch<RowData, BatchT>> recycler,\n+\t\t\tfinal int batchSize) {\n+\n+\t\tfinal VectorizedColumnBatch flinkColumnBatch = batchFactory.create(split, orcBatch.getBatch());\n+\t\treturn new VectorizedColumnReaderBatch<>(orcBatch, flinkColumnBatch, recycler);\n+\t}\n+\n+\t@Override\n+\tpublic TypeInformation<RowData> getProducedType() {\n+\t\treturn InternalTypeInfo.of(projectedOutputType);\n+\t}\n+\n+\t// ------------------------------------------------------------------------\n+\n+\t/**\n+\t * One batch of ORC columnar vectors and Flink column vectors.\n+\t */\n+\tprivate static final class VectorizedColumnReaderBatch<BatchT> extends OrcReaderBatch<RowData, BatchT> {\n+\n+\t\tprivate final VectorizedColumnBatch flinkColumnBatch;\n+\t\tprivate final ColumnarRowIterator result;\n+\n+\t\tVectorizedColumnReaderBatch(\n+\t\t\t\tfinal OrcVectorizedBatchWrapper<BatchT> orcBatch,\n+\t\t\t\tfinal VectorizedColumnBatch flinkColumnBatch,\n+\t\t\t\tfinal Pool.Recycler<OrcReaderBatch<RowData, BatchT>> recycler) {\n+\t\t\tsuper(orcBatch, recycler);\n+\t\t\tthis.flinkColumnBatch = flinkColumnBatch;\n+\t\t\tthis.result = new ColumnarRowIterator(new ColumnarRowData(flinkColumnBatch), this::recycle);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic RecordIterator<RowData> convertAndGetIterator(\n+\t\t\t\tfinal OrcVectorizedBatchWrapper<BatchT> orcBatch,\n+\t\t\t\tfinal long startingOffset) {\n+\t\t\t// no copying from the ORC column vectors to the Flink columns vectors necessary,\n+\t\t\t// because they point to the same data arrays internally design\n+\t\t\tint batchSize = orcBatch.size();\n+\t\t\tflinkColumnBatch.setNumRows(batchSize);\n+\t\t\tresult.set(batchSize, startingOffset, 0);\n+\t\t\treturn result;\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Create a partitioned {@link OrcColumnarRowFileInputFormat}, the partition columns can be\n+\t * generated by split.\n+\t */\n+\tpublic static <SplitT extends FileSourceSplit> OrcColumnarRowFileInputFormat<VectorizedRowBatch, SplitT> createPartitionedFormat(\n+\t\t\tOrcShim<VectorizedRowBatch> shim,\n+\t\t\tConfiguration hadoopConfig,\n+\t\t\tRowType tableType,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3d25c91253ce75af6d2d87b0bae62bc7dbd575bb"}, "originalPosition": 135}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzc4MDEyMQ==", "bodyText": "Rename this class since it's no longer a FileSystemFormatFactory?", "url": "https://github.com/apache/flink/pull/13724#discussion_r517780121", "createdAt": "2020-11-05T04:03:50Z", "author": {"login": "lirui-apache"}, "path": "flink-formats/flink-orc/src/main/java/org/apache/flink/orc/OrcFileSystemFormatFactory.java", "diffHunk": "@@ -18,45 +18,45 @@\n \n package org.apache.flink.orc;\n \n-import org.apache.flink.api.common.io.FileInputFormat;\n-import org.apache.flink.api.common.io.InputFormat;\n import org.apache.flink.api.common.serialization.BulkWriter;\n-import org.apache.flink.api.common.serialization.Encoder;\n import org.apache.flink.configuration.ConfigOption;\n import org.apache.flink.configuration.ReadableConfig;\n-import org.apache.flink.core.fs.FileInputSplit;\n-import org.apache.flink.core.fs.Path;\n+import org.apache.flink.connector.file.src.FileSourceSplit;\n+import org.apache.flink.connector.file.src.reader.BulkFormat;\n+import org.apache.flink.orc.shim.OrcShim;\n import org.apache.flink.orc.vector.RowDataVectorizer;\n import org.apache.flink.orc.writer.OrcBulkWriterFactory;\n+import org.apache.flink.table.connector.ChangelogMode;\n+import org.apache.flink.table.connector.format.BulkDecodingFormat;\n+import org.apache.flink.table.connector.format.EncodingFormat;\n+import org.apache.flink.table.connector.sink.DynamicTableSink;\n+import org.apache.flink.table.connector.source.DynamicTableSource;\n import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.data.vector.VectorizedColumnBatch;\n import org.apache.flink.table.expressions.Expression;\n-import org.apache.flink.table.factories.FileSystemFormatFactory;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.factories.BulkReaderFormatFactory;\n+import org.apache.flink.table.factories.BulkWriterFormatFactory;\n+import org.apache.flink.table.factories.DynamicTableFactory;\n+import org.apache.flink.table.filesystem.FileSystemOptions;\n+import org.apache.flink.table.filesystem.PartitionFieldExtractor;\n import org.apache.flink.table.types.DataType;\n import org.apache.flink.table.types.logical.LogicalType;\n import org.apache.flink.table.types.logical.RowType;\n-import org.apache.flink.table.utils.PartitionPathUtils;\n \n import org.apache.hadoop.conf.Configuration;\n-import org.apache.hadoop.hive.ql.exec.vector.VectorizedRowBatch;\n import org.apache.orc.TypeDescription;\n \n-import java.io.IOException;\n import java.util.ArrayList;\n-import java.util.Arrays;\n import java.util.HashSet;\n-import java.util.LinkedHashMap;\n import java.util.List;\n-import java.util.Optional;\n import java.util.Properties;\n import java.util.Set;\n \n-import static org.apache.flink.table.data.vector.VectorizedColumnBatch.DEFAULT_SIZE;\n-import static org.apache.flink.table.filesystem.RowPartitionComputer.restorePartValueFromType;\n-\n /**\n- * Orc {@link FileSystemFormatFactory} for file system.\n+ * Orc format factory for file system.\n  */\n-public class OrcFileSystemFormatFactory implements FileSystemFormatFactory {\n+public class OrcFileSystemFormatFactory implements BulkReaderFormatFactory, BulkWriterFormatFactory {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3d25c91253ce75af6d2d87b0bae62bc7dbd575bb"}, "originalPosition": 59}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "eff771f1557f8fe7dc60a92c22dd1db6a347e047", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/eff771f1557f8fe7dc60a92c22dd1db6a347e047", "committedDate": "2020-11-05T06:59:55Z", "message": "Address comments"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "49389de4c652a0a1736373f3c584d09036d13ac5", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/49389de4c652a0a1736373f3c584d09036d13ac5", "committedDate": "2020-11-05T06:55:24Z", "message": "Address comments"}, "afterCommit": {"oid": "eff771f1557f8fe7dc60a92c22dd1db6a347e047", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/eff771f1557f8fe7dc60a92c22dd1db6a347e047", "committedDate": "2020-11-05T06:59:55Z", "message": "Address comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIzOTg2ODU3", "url": "https://github.com/apache/flink/pull/13724#pullrequestreview-523986857", "createdAt": "2020-11-05T07:34:33Z", "commit": {"oid": "eff771f1557f8fe7dc60a92c22dd1db6a347e047"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2981, "cost": 1, "resetAt": "2021-10-28T16:48:13Z"}}}