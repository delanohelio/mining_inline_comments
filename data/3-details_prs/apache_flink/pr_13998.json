{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTE3NzM0MDQ2", "number": 13998, "title": "[FLINK-20062][hive] ContinuousHiveSplitEnumerator should be lock-free", "bodyText": "What is the purpose of the change\nMake ContinuousHiveSplitEnumerator lock-free.\nBrief change log\n\nImplement a callable for the monitor thread which keeps local state. Each time the monitor is run, it returns state and new splits to main thread. Main thread can therefore update its own state.\n\nVerifying this change\nExisting tests\nDoes this pull request potentially affect one of the following parts:\n\nDependencies (does it add or upgrade a dependency): no\nThe public API, i.e., is any changed class annotated with @Public(Evolving): no\nThe serializers: no\nThe runtime per-record code paths (performance sensitive): no\nAnything that affects deployment or recovery: JobManager (and its components), Checkpointing, Kubernetes/Yarn/Mesos, ZooKeeper: no\nThe S3 file system connector: no\n\nDocumentation\n\nDoes this pull request introduce a new feature? no\nIf yes, how is the feature documented? NA", "createdAt": "2020-11-09T12:40:27Z", "url": "https://github.com/apache/flink/pull/13998", "merged": true, "mergeCommit": {"oid": "cd833c2584810102723c49e6f0c5eb3b3f79311f"}, "closed": true, "closedAt": "2020-11-19T02:19:12Z", "author": {"login": "lirui-apache"}, "timelineItems": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdc9By0gBqjM5OTgzNTI5MjA=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdd5L8-gFqTUzNDAzMDA5Mg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "73aaf9862a1d30857c4605b26a8997eeb11281c1", "author": {"user": {"login": "lirui-apache", "name": "Rui Li"}}, "url": "https://github.com/apache/flink/commit/73aaf9862a1d30857c4605b26a8997eeb11281c1", "committedDate": "2020-11-09T12:36:50Z", "message": "[FLINK-20062][hive] ContinuousHiveSplitEnumerator should be lock-free"}, "afterCommit": {"oid": "530e65e61ae94f952ffb682f0573071724da27d6", "author": {"user": {"login": "lirui-apache", "name": "Rui Li"}}, "url": "https://github.com/apache/flink/commit/530e65e61ae94f952ffb682f0573071724da27d6", "committedDate": "2020-11-16T04:13:03Z", "message": "Throw exception in new splits handler"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f2604cf33407322990661ccd10cde560b6c801a3", "author": {"user": {"login": "lirui-apache", "name": "Rui Li"}}, "url": "https://github.com/apache/flink/commit/f2604cf33407322990661ccd10cde560b6c801a3", "committedDate": "2020-11-18T02:36:17Z", "message": "[FLINK-20062][hive] ContinuousHiveSplitEnumerator should be lock-free"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6beffeeaa6311b7d58dca3eea2d876ce03bbd816", "author": {"user": {"login": "lirui-apache", "name": "Rui Li"}}, "url": "https://github.com/apache/flink/commit/6beffeeaa6311b7d58dca3eea2d876ce03bbd816", "committedDate": "2020-11-18T02:36:17Z", "message": "Throw exception in new splits handler"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "530e65e61ae94f952ffb682f0573071724da27d6", "author": {"user": {"login": "lirui-apache", "name": "Rui Li"}}, "url": "https://github.com/apache/flink/commit/530e65e61ae94f952ffb682f0573071724da27d6", "committedDate": "2020-11-16T04:13:03Z", "message": "Throw exception in new splits handler"}, "afterCommit": {"oid": "6beffeeaa6311b7d58dca3eea2d876ce03bbd816", "author": {"user": {"login": "lirui-apache", "name": "Rui Li"}}, "url": "https://github.com/apache/flink/commit/6beffeeaa6311b7d58dca3eea2d876ce03bbd816", "committedDate": "2020-11-18T02:36:17Z", "message": "Throw exception in new splits handler"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMzMzA4OTg2", "url": "https://github.com/apache/flink/pull/13998#pullrequestreview-533308986", "createdAt": "2020-11-18T10:34:59Z", "commit": {"oid": "6beffeeaa6311b7d58dca3eea2d876ce03bbd816"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQxMDozNTowMFrOH1nUoQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQxMDozNTowMFrOH1nUoQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTk4MDgzMw==", "bodyText": "Just PartitionMonitor?", "url": "https://github.com/apache/flink/pull/13998#discussion_r525980833", "createdAt": "2020-11-18T10:35:00Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/ContinuousHiveSplitEnumerator.java", "diffHunk": "@@ -158,12 +142,64 @@ public void close() throws IOException {\n \t\t}\n \t}\n \n-\tprivate Void monitorAndGetSplits() throws Exception {\n-\t\tstateLock.writeLock().lock();\n-\t\ttry {\n+\tprivate void handleNewSplits(NewSplitsAndState<T> newSplitsAndState, Throwable error) {\n+\t\tif (error != null) {\n+\t\t\t// we need to failover because the worker thread is stateful\n+\t\t\tthrow new FlinkHiveException(\"Failed to enumerate files\", error);\n+\t\t}\n+\t\tthis.currentReadOffset = newSplitsAndState.offset;\n+\t\tthis.seenPartitionsSinceOffset = newSplitsAndState.seenPartitions;\n+\t\tsplitAssigner.addSplits(new ArrayList<>(newSplitsAndState.newSplits));\n+\t\tassignSplits();\n+\t}\n+\n+\tprivate void assignSplits() {\n+\t\tfinal Iterator<Map.Entry<Integer, String>> awaitingReader = readersAwaitingSplit.entrySet().iterator();\n+\t\twhile (awaitingReader.hasNext()) {\n+\t\t\tfinal Map.Entry<Integer, String> nextAwaiting = awaitingReader.next();\n+\t\t\tfinal String hostname = nextAwaiting.getValue();\n+\t\t\tfinal int awaitingSubtask = nextAwaiting.getKey();\n+\t\t\tfinal Optional<FileSourceSplit> nextSplit = splitAssigner.getNext(hostname);\n+\t\t\tif (nextSplit.isPresent()) {\n+\t\t\t\tenumeratorContext.assignSplit((HiveSourceSplit) nextSplit.get(), awaitingSubtask);\n+\t\t\t\tawaitingReader.remove();\n+\t\t\t} else {\n+\t\t\t\tbreak;\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate static class NewPartitionMonitor<T extends Comparable<T>> implements Callable<NewSplitsAndState<T>> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6beffeeaa6311b7d58dca3eea2d876ce03bbd816"}, "originalPosition": 122}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMzMzA5MDc5", "url": "https://github.com/apache/flink/pull/13998#pullrequestreview-533309079", "createdAt": "2020-11-18T10:35:06Z", "commit": {"oid": "6beffeeaa6311b7d58dca3eea2d876ce03bbd816"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQxMDozNTowNlrOH1nU3g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQxMDozNTowNlrOH1nU3g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTk4MDg5NA==", "bodyText": "private", "url": "https://github.com/apache/flink/pull/13998#discussion_r525980894", "createdAt": "2020-11-18T10:35:06Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/ContinuousHiveSplitEnumerator.java", "diffHunk": "@@ -158,12 +142,64 @@ public void close() throws IOException {\n \t\t}\n \t}\n \n-\tprivate Void monitorAndGetSplits() throws Exception {\n-\t\tstateLock.writeLock().lock();\n-\t\ttry {\n+\tprivate void handleNewSplits(NewSplitsAndState<T> newSplitsAndState, Throwable error) {\n+\t\tif (error != null) {\n+\t\t\t// we need to failover because the worker thread is stateful\n+\t\t\tthrow new FlinkHiveException(\"Failed to enumerate files\", error);\n+\t\t}\n+\t\tthis.currentReadOffset = newSplitsAndState.offset;\n+\t\tthis.seenPartitionsSinceOffset = newSplitsAndState.seenPartitions;\n+\t\tsplitAssigner.addSplits(new ArrayList<>(newSplitsAndState.newSplits));\n+\t\tassignSplits();\n+\t}\n+\n+\tprivate void assignSplits() {\n+\t\tfinal Iterator<Map.Entry<Integer, String>> awaitingReader = readersAwaitingSplit.entrySet().iterator();\n+\t\twhile (awaitingReader.hasNext()) {\n+\t\t\tfinal Map.Entry<Integer, String> nextAwaiting = awaitingReader.next();\n+\t\t\tfinal String hostname = nextAwaiting.getValue();\n+\t\t\tfinal int awaitingSubtask = nextAwaiting.getKey();\n+\t\t\tfinal Optional<FileSourceSplit> nextSplit = splitAssigner.getNext(hostname);\n+\t\t\tif (nextSplit.isPresent()) {\n+\t\t\t\tenumeratorContext.assignSplit((HiveSourceSplit) nextSplit.get(), awaitingSubtask);\n+\t\t\t\tawaitingReader.remove();\n+\t\t\t} else {\n+\t\t\t\tbreak;\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate static class NewPartitionMonitor<T extends Comparable<T>> implements Callable<NewSplitsAndState<T>> {\n+\n+\t\t// keep these locally so that we don't need to share state with main thread\n+\t\tprivate T currentReadOffset;\n+\t\tprivate final Set<List<String>> seenPartitionsSinceOffset;\n+\n+\t\tprivate final ObjectPath tablePath;\n+\t\tprivate final JobConf jobConf;\n+\t\tprivate final ContinuousPartitionFetcher<Partition, T> fetcher;\n+\t\tprivate final HiveTableSource.HiveContinuousPartitionFetcherContext<T> fetcherContext;\n+\n+\t\tNewPartitionMonitor(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6beffeeaa6311b7d58dca3eea2d876ce03bbd816"}, "originalPosition": 133}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMzMzA5ODYw", "url": "https://github.com/apache/flink/pull/13998#pullrequestreview-533309860", "createdAt": "2020-11-18T10:36:07Z", "commit": {"oid": "6beffeeaa6311b7d58dca3eea2d876ce03bbd816"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQxMDozNjowN1rOH1nXSg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQxMDozNjowN1rOH1nXSg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTk4MTUxNA==", "bodyText": "There is a thread safe problem? Two thread share a same seenPartitionsSinceOffset\nWe need return a immutable seenPartitionsSinceOffset", "url": "https://github.com/apache/flink/pull/13998#discussion_r525981514", "createdAt": "2020-11-18T10:36:07Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/ContinuousHiveSplitEnumerator.java", "diffHunk": "@@ -158,12 +142,64 @@ public void close() throws IOException {\n \t\t}\n \t}\n \n-\tprivate Void monitorAndGetSplits() throws Exception {\n-\t\tstateLock.writeLock().lock();\n-\t\ttry {\n+\tprivate void handleNewSplits(NewSplitsAndState<T> newSplitsAndState, Throwable error) {\n+\t\tif (error != null) {\n+\t\t\t// we need to failover because the worker thread is stateful\n+\t\t\tthrow new FlinkHiveException(\"Failed to enumerate files\", error);\n+\t\t}\n+\t\tthis.currentReadOffset = newSplitsAndState.offset;\n+\t\tthis.seenPartitionsSinceOffset = newSplitsAndState.seenPartitions;\n+\t\tsplitAssigner.addSplits(new ArrayList<>(newSplitsAndState.newSplits));\n+\t\tassignSplits();\n+\t}\n+\n+\tprivate void assignSplits() {\n+\t\tfinal Iterator<Map.Entry<Integer, String>> awaitingReader = readersAwaitingSplit.entrySet().iterator();\n+\t\twhile (awaitingReader.hasNext()) {\n+\t\t\tfinal Map.Entry<Integer, String> nextAwaiting = awaitingReader.next();\n+\t\t\tfinal String hostname = nextAwaiting.getValue();\n+\t\t\tfinal int awaitingSubtask = nextAwaiting.getKey();\n+\t\t\tfinal Optional<FileSourceSplit> nextSplit = splitAssigner.getNext(hostname);\n+\t\t\tif (nextSplit.isPresent()) {\n+\t\t\t\tenumeratorContext.assignSplit((HiveSourceSplit) nextSplit.get(), awaitingSubtask);\n+\t\t\t\tawaitingReader.remove();\n+\t\t\t} else {\n+\t\t\t\tbreak;\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate static class NewPartitionMonitor<T extends Comparable<T>> implements Callable<NewSplitsAndState<T>> {\n+\n+\t\t// keep these locally so that we don't need to share state with main thread\n+\t\tprivate T currentReadOffset;\n+\t\tprivate final Set<List<String>> seenPartitionsSinceOffset;\n+\n+\t\tprivate final ObjectPath tablePath;\n+\t\tprivate final JobConf jobConf;\n+\t\tprivate final ContinuousPartitionFetcher<Partition, T> fetcher;\n+\t\tprivate final HiveTableSource.HiveContinuousPartitionFetcherContext<T> fetcherContext;\n+\n+\t\tNewPartitionMonitor(\n+\t\t\t\tT currentReadOffset,\n+\t\t\t\tCollection<List<String>> seenPartitionsSinceOffset,\n+\t\t\t\tObjectPath tablePath,\n+\t\t\t\tJobConf jobConf,\n+\t\t\t\tContinuousPartitionFetcher<Partition, T> fetcher,\n+\t\t\t\tHiveTableSource.HiveContinuousPartitionFetcherContext<T> fetcherContext) {\n+\t\t\tthis.currentReadOffset = currentReadOffset;\n+\t\t\tthis.seenPartitionsSinceOffset = new HashSet<>(seenPartitionsSinceOffset);\n+\t\t\tthis.tablePath = tablePath;\n+\t\t\tthis.jobConf = jobConf;\n+\t\t\tthis.fetcher = fetcher;\n+\t\t\tthis.fetcherContext = fetcherContext;\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic NewSplitsAndState<T> call() throws Exception {\n \t\t\tList<Tuple2<Partition, T>> partitions = fetcher.fetchPartitions(fetcherContext, currentReadOffset);\n \t\t\tif (partitions.isEmpty()) {\n-\t\t\t\treturn null;\n+\t\t\t\treturn new NewSplitsAndState<>(Collections.emptyList(), currentReadOffset, seenPartitionsSinceOffset);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6beffeeaa6311b7d58dca3eea2d876ce03bbd816"}, "originalPosition": 153}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "98fb6be3e33813d21dff02dfc527bef97c06c1b9", "author": {"user": {"login": "lirui-apache", "name": "Rui Li"}}, "url": "https://github.com/apache/flink/commit/98fb6be3e33813d21dff02dfc527bef97c06c1b9", "committedDate": "2020-11-18T13:54:09Z", "message": "address comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM0MDMwMDky", "url": "https://github.com/apache/flink/pull/13998#pullrequestreview-534030092", "createdAt": "2020-11-19T02:18:41Z", "commit": {"oid": "98fb6be3e33813d21dff02dfc527bef97c06c1b9"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4538, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}