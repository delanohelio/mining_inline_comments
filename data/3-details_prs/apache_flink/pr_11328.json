{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg0NjUyNTYy", "number": 11328, "title": "[FLINK-16455][hive] Introduce flink-sql-connector-hive modules to provide hive uber jars", "bodyText": "What is the purpose of the change\nProvide uber jars to improve hive dependencies out-of-box experience.\nBrief change log\n\nIntroduce flink-sql-connector-hive-1.2.2\nIntroduce flink-sql-connector-hive-2.2.0\nIntroduce flink-sql-connector-hive-2.3.6\nIntroduce flink-sql-connector-hive-3.1.2\n\nVerifying this change\nManual testing\nDoes this pull request potentially affect one of the following parts:\n\nDependencies (does it add or upgrade a dependency): (yes / no)\nThe public API, i.e., is any changed class annotated with @Public(Evolving): (yes / no)\nThe serializers: (yes / no / don't know)\nThe runtime per-record code paths (performance sensitive): (yes / no / don't know)\nAnything that affects deployment or recovery: JobManager (and its components), Checkpointing, Kubernetes/Yarn/Mesos, ZooKeeper: (yes / no / don't know)\nThe S3 file system connector: (yes / no / don't know)\n\nDocumentation\n\nDoes this pull request introduce a new feature? (yes / no)\nIf yes, how is the feature documented? (not applicable / docs / JavaDocs / not documented)", "createdAt": "2020-03-06T06:14:18Z", "url": "https://github.com/apache/flink/pull/11328", "merged": true, "mergeCommit": {"oid": "bd18b8715466bfe49d8b31019075f8081a618875"}, "closed": true, "closedAt": "2020-03-11T01:46:39Z", "author": {"login": "JingsongLi"}, "timelineItems": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcK52O4gH2gAyMzg0NjUyNTYyOmQ0MmUwYWIyOTBjMTc3NjA1YTc4ZWI1Y2ViOWVhY2JjNzJlNTRhMTU=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcMVsEhgFqTM3MjE1MzkwMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "d42e0ab290c177605a78eb5ceb9eacbc72e54a15", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/d42e0ab290c177605a78eb5ceb9eacbc72e54a15", "committedDate": "2020-03-06T06:09:09Z", "message": "[FLINK-16455][hive] Introduce flink-sql-connector-hive modules to provide hive uber jars"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "26ec0ffd7aa85f2b38f9742aca4d5ea112567081", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/26ec0ffd7aa85f2b38f9742aca4d5ea112567081", "committedDate": "2020-03-09T08:14:18Z", "message": "Update document"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f1d94b9792a597e9b935fe08001930a3eb27d789", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/f1d94b9792a597e9b935fe08001930a3eb27d789", "committedDate": "2020-03-09T08:25:52Z", "message": "Update document"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcwOTk5NDkw", "url": "https://github.com/apache/flink/pull/11328#pullrequestreview-370999490", "createdAt": "2020-03-09T09:01:36Z", "commit": {"oid": "f1d94b9792a597e9b935fe08001930a3eb27d789"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQwOTowMTozNlrOFzfERw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQwOToxMToyMlrOFzfVUA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTUzMDY5NQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            There are two way to hive dependencies. First way, using bundled hive jar, providing multiple bundle\n          \n          \n            \n            hive jars that can cover all remote metastore versions. Second way, user defined dependencies, you\n          \n          \n            \n            can build your own dependencies if you need to. \n          \n          \n            \n            There are two ways to add Hive dependencies. First is to use Flink's bundled Hive jars. You can choose a bundled Hive jar according to the version of the metastore you use. Second is to add each of the required jars separately. The second way can be useful if the Hive version you're using is not listed here.", "url": "https://github.com/apache/flink/pull/11328#discussion_r389530695", "createdAt": "2020-03-09T09:01:36Z", "author": {"login": "lirui-apache"}, "path": "docs/dev/table/hive/index.md", "diffHunk": "@@ -92,6 +92,34 @@ to make the integration work in Table API program or SQL in SQL Client.\n Alternatively, you can put these dependencies in a dedicated folder, and add them to classpath with the `-C`\n or `-l` option for Table API program or SQL Client respectively.\n \n+Apache Hive is built on Hadoop, so you need Hadoop dependency first, please refer to\n+[Providing Hadoop classes]({{ site.baseurl }}/ops/deployment/hadoop.html#providing-hadoop-classes).\n+\n+There are two way to hive dependencies. First way, using bundled hive jar, providing multiple bundle\n+hive jars that can cover all remote metastore versions. Second way, user defined dependencies, you\n+can build your own dependencies if you need to. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1d94b9792a597e9b935fe08001930a3eb27d789"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTUzMzA3NA==", "bodyText": "I don't think the Dependency Version column is useful. We just need to let users know which jar to download (or which mvn dependency to use), given the version of their HMS.", "url": "https://github.com/apache/flink/pull/11328#discussion_r389533074", "createdAt": "2020-03-09T09:06:54Z", "author": {"login": "lirui-apache"}, "path": "docs/dev/table/hive/index.md", "diffHunk": "@@ -92,6 +92,34 @@ to make the integration work in Table API program or SQL in SQL Client.\n Alternatively, you can put these dependencies in a dedicated folder, and add them to classpath with the `-C`\n or `-l` option for Table API program or SQL Client respectively.\n \n+Apache Hive is built on Hadoop, so you need Hadoop dependency first, please refer to\n+[Providing Hadoop classes]({{ site.baseurl }}/ops/deployment/hadoop.html#providing-hadoop-classes).\n+\n+There are two way to hive dependencies. First way, using bundled hive jar, providing multiple bundle\n+hive jars that can cover all remote metastore versions. Second way, user defined dependencies, you\n+can build your own dependencies if you need to. \n+\n+#### Using bundled hive jar\n+\n+The following tables list all available bundled hive jars. You can pick one to the `/lib/` directory in Flink distribution.\n+\n+{% if site.is_stable %}\n+\n+| Remote Metastore   | Dependency Version  | Maven dependency             | SQL Client JAR         |", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1d94b9792a597e9b935fe08001930a3eb27d789"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTUzNTA1Ng==", "bodyText": "I think providing an example for this would be more helpful", "url": "https://github.com/apache/flink/pull/11328#discussion_r389535056", "createdAt": "2020-03-09T09:11:22Z", "author": {"login": "lirui-apache"}, "path": "docs/dev/table/hive/index.md", "diffHunk": "@@ -281,6 +261,11 @@ Please find the required dependencies for different Hive major versions below.\n </div>\n </div>\n \n+If you use the hive version of HDP or CDH, you need to refer to the dependency in the previous section and select a similar version.\n+\n+And you need to specify selected and supported \"hive-version\" in yaml, HiveCatalog and HiveModule.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1d94b9792a597e9b935fe08001930a3eb27d789"}, "originalPosition": 145}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "002438e9d9969f32d050cae3da8cf2bd93667d53", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/002438e9d9969f32d050cae3da8cf2bd93667d53", "committedDate": "2020-03-10T01:50:10Z", "message": "Update docs/dev/table/hive/index.md\n\nCo-Authored-By: Rui Li <lirui@apache.org>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b4a76d76d2c1e9722befabc03b2191d053c70fa8", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/b4a76d76d2c1e9722befabc03b2191d053c70fa8", "committedDate": "2020-03-10T01:56:31Z", "message": "Fix comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcxNjk4NTE0", "url": "https://github.com/apache/flink/pull/11328#pullrequestreview-371698514", "createdAt": "2020-03-10T06:04:47Z", "commit": {"oid": "b4a76d76d2c1e9722befabc03b2191d053c70fa8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQwNjowNDo0OFrOF0CbMw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQwNjowNDo0OFrOF0CbMw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDExMDAwMw==", "bodyText": "what does this part mean? exclude all the dependencies?", "url": "https://github.com/apache/flink/pull/11328#discussion_r390110003", "createdAt": "2020-03-10T06:04:48Z", "author": {"login": "bowenli86"}, "path": "flink-connectors/flink-sql-connector-hive-1.2.2/pom.xml", "diffHunk": "@@ -0,0 +1,142 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n+\t\t xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n+\t\t xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\">\n+\n+\t<modelVersion>4.0.0</modelVersion>\n+\n+\t<parent>\n+\t\t<groupId>org.apache.flink</groupId>\n+\t\t<artifactId>flink-connectors</artifactId>\n+\t\t<version>1.11-SNAPSHOT</version>\n+\t\t<relativePath>..</relativePath>\n+\t</parent>\n+\n+\t<artifactId>flink-sql-connector-hive-1.2.2_${scala.binary.version}</artifactId>\n+\t<name>flink-sql-connector-hive-1.2.2</name>\n+\n+\t<packaging>jar</packaging>\n+\n+\t<dependencies>\n+\t\t<dependency>\n+\t\t\t<groupId>org.apache.flink</groupId>\n+\t\t\t<artifactId>flink-connector-hive_${scala.binary.version}</artifactId>\n+\t\t\t<version>${project.version}</version>\n+\t\t\t<exclusions>\n+\t\t\t\t<exclusion>\n+\t\t\t\t\t<groupId>*</groupId>\n+\t\t\t\t\t<artifactId>*</artifactId>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b4a76d76d2c1e9722befabc03b2191d053c70fa8"}, "originalPosition": 46}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcyMTUzOTAx", "url": "https://github.com/apache/flink/pull/11328#pullrequestreview-372153901", "createdAt": "2020-03-10T17:09:19Z", "commit": {"oid": "b4a76d76d2c1e9722befabc03b2191d053c70fa8"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3108, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}