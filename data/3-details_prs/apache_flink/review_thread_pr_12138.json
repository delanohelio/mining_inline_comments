{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE3Njc2NjY4", "number": 12138, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNFQwODoyNToxMVrOD8X7kQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQwMzo0MzozNVrOD9oFpQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0NjMzMjMzOnYy", "diffSide": "RIGHT", "path": "flink-metrics/flink-metrics-datadog/src/main/java/org/apache/flink/metrics/datadog/DatadogHttpReporter.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNFQwODoyNToxMlrOGVRWug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQwNjoyOTozMlrOGWpD1Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDk1NzYyNg==", "bodyText": "hmm, I don't really like that we're always sending at least 2 requests, as long as at least one counter and gauge exist.\nUltimately, all we need to do is slice the currently created DSeries, which we could do using ArrayList#subList.\nint fromIndex = 0;\nArrayList<DMetric> series = request.getSeries();\nwhile (fromIndex < series.size()) {\n  int toIndex = Math.Min(currentCount + maxMetricsPerRequestValue, series.size());\n  client.send(series.subList(fromIndex, toIndex));\n  fromIndex = toIndex;\n}\n\nWDYT? We could even wrap this logic into a stateful Consumer that resets the DSeries on each client.send, so we don't have to assemble the full list.", "url": "https://github.com/apache/flink/pull/12138#discussion_r424957626", "createdAt": "2020-05-14T08:25:12Z", "author": {"login": "zentol"}, "path": "flink-metrics/flink-metrics-datadog/src/main/java/org/apache/flink/metrics/datadog/DatadogHttpReporter.java", "diffHunk": "@@ -157,6 +181,11 @@ private void addGaugesAndUnregisterOnException(DSeries request) {\n \t\t\t\t// Flink uses Gauge to store many types other than Number\n \t\t\t\tg.getMetricValue();\n \t\t\t\trequest.addGauge(g);\n+\t\t\t\t++currentCount;\n+\t\t\t\tif (currentCount % maxMetricsPerRequestValue == 0 || currentCount >= totalGauges) {\n+\t\t\t\t\tclient.send(request);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a6af75021894504c6515472be86f1e490ae32e27"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjAxOTQ0Mg==", "bodyText": "I do like the sublist approach although DatadogHttpClient serializes a DSeries not a List.\nmaybe something like:\nList<DMetric> metrics = new ArrayList();\naddGaugesAndUnregisterOnException(metrics);\nmetrics.addAll(counters.values());\nmetrics.addAll(meters.values());\n\nint fromIndex = 0;\nwhile (fromIndex < metrics.size()) {\n    int toIndex = Math.Min(fromIndex + maxMetricsPerRequestValue, metrics.size());\n    client.send(new DSeries(metrics.subList(fromIndex, toIndex)));\n    fromIndex = toIndex;\n}", "url": "https://github.com/apache/flink/pull/12138#discussion_r426019442", "createdAt": "2020-05-15T20:00:22Z", "author": {"login": "swhelan091"}, "path": "flink-metrics/flink-metrics-datadog/src/main/java/org/apache/flink/metrics/datadog/DatadogHttpReporter.java", "diffHunk": "@@ -157,6 +181,11 @@ private void addGaugesAndUnregisterOnException(DSeries request) {\n \t\t\t\t// Flink uses Gauge to store many types other than Number\n \t\t\t\tg.getMetricValue();\n \t\t\t\trequest.addGauge(g);\n+\t\t\t\t++currentCount;\n+\t\t\t\tif (currentCount % maxMetricsPerRequestValue == 0 || currentCount >= totalGauges) {\n+\t\t\t\t\tclient.send(request);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDk1NzYyNg=="}, "originalCommit": {"oid": "a6af75021894504c6515472be86f1e490ae32e27"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjM5NDU4MQ==", "bodyText": "yes, you'D of course have to rap the subList in a DSeries again, requiring a new constructor.", "url": "https://github.com/apache/flink/pull/12138#discussion_r426394581", "createdAt": "2020-05-18T06:29:32Z", "author": {"login": "zentol"}, "path": "flink-metrics/flink-metrics-datadog/src/main/java/org/apache/flink/metrics/datadog/DatadogHttpReporter.java", "diffHunk": "@@ -157,6 +181,11 @@ private void addGaugesAndUnregisterOnException(DSeries request) {\n \t\t\t\t// Flink uses Gauge to store many types other than Number\n \t\t\t\tg.getMetricValue();\n \t\t\t\trequest.addGauge(g);\n+\t\t\t\t++currentCount;\n+\t\t\t\tif (currentCount % maxMetricsPerRequestValue == 0 || currentCount >= totalGauges) {\n+\t\t\t\t\tclient.send(request);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDk1NzYyNg=="}, "originalCommit": {"oid": "a6af75021894504c6515472be86f1e490ae32e27"}, "originalPosition": 94}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1OTQ2NTMzOnYy", "diffSide": "RIGHT", "path": "flink-metrics/flink-metrics-datadog/src/main/java/org/apache/flink/metrics/datadog/DatadogHttpReporter.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQwMzo0MzozNVrOGXOzvw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQxMDo0OTo1M1rOGXatvA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzAxMzA1NQ==", "bodyText": "One question here. Should ackReport only be called on counters that were successfully emitted to Datadog?", "url": "https://github.com/apache/flink/pull/12138#discussion_r427013055", "createdAt": "2020-05-19T03:43:35Z", "author": {"login": "swhelan091"}, "path": "flink-metrics/flink-metrics-datadog/src/main/java/org/apache/flink/metrics/datadog/DatadogHttpReporter.java", "diffHunk": "@@ -137,15 +140,21 @@ public void report() {\n \t\tcounters.values().forEach(request::addCounter);\n \t\tmeters.values().forEach(request::addMeter);\n \n-\t\ttry {\n-\t\t\tclient.send(request);\n-\t\t\tcounters.values().forEach(DCounter::ackReport);\n-\t\t\tLOGGER.debug(\"Reported series with size {}.\", request.getSeries().size());\n-\t\t} catch (SocketTimeoutException e) {\n-\t\t\tLOGGER.warn(\"Failed reporting metrics to Datadog because of socket timeout: {}\", e.getMessage());\n-\t\t} catch (Exception e) {\n-\t\t\tLOGGER.warn(\"Failed reporting metrics to Datadog.\", e);\n+\t\tint totalMetrics = request.getSeries().size();\n+\t\tint fromIndex = 0;\n+\t\twhile (fromIndex < totalMetrics) {\n+\t\t\tint toIndex = Math.min(fromIndex + maxMetricsPerRequestValue, totalMetrics);\n+\t\t\ttry {\n+\t\t\t\tclient.send(new DSeries(request.getSeries().subList(fromIndex, toIndex)));\n+\t\t\t} catch (SocketTimeoutException e) {\n+\t\t\t\tLOGGER.warn(\"Failed reporting metrics to Datadog because of socket timeout: {}\", e.getMessage());\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tLOGGER.warn(\"Failed reporting metrics to Datadog.\", e);\n+\t\t\t}\n+\t\t\tfromIndex = toIndex;\n \t\t}\n+\t\tLOGGER.debug(\"Reported series with size {}.\", totalMetrics);\n+\t\tcounters.values().forEach(DCounter::ackReport);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3fa364afeda36c6e3de19804317d7470ecfcbd21"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzIwODEyNA==", "bodyText": "yes; if an exception occurred for a sublist that contained a counter then we should not ack it.\nAs a quick solution (which is somewhat hacky, but I do want this in 1.11.0), we could add a no-op DMetric#ackReport() method that is overridden by DCounter. You could then ack them in the try section by iterating over the sub DSeries.", "url": "https://github.com/apache/flink/pull/12138#discussion_r427208124", "createdAt": "2020-05-19T10:49:53Z", "author": {"login": "zentol"}, "path": "flink-metrics/flink-metrics-datadog/src/main/java/org/apache/flink/metrics/datadog/DatadogHttpReporter.java", "diffHunk": "@@ -137,15 +140,21 @@ public void report() {\n \t\tcounters.values().forEach(request::addCounter);\n \t\tmeters.values().forEach(request::addMeter);\n \n-\t\ttry {\n-\t\t\tclient.send(request);\n-\t\t\tcounters.values().forEach(DCounter::ackReport);\n-\t\t\tLOGGER.debug(\"Reported series with size {}.\", request.getSeries().size());\n-\t\t} catch (SocketTimeoutException e) {\n-\t\t\tLOGGER.warn(\"Failed reporting metrics to Datadog because of socket timeout: {}\", e.getMessage());\n-\t\t} catch (Exception e) {\n-\t\t\tLOGGER.warn(\"Failed reporting metrics to Datadog.\", e);\n+\t\tint totalMetrics = request.getSeries().size();\n+\t\tint fromIndex = 0;\n+\t\twhile (fromIndex < totalMetrics) {\n+\t\t\tint toIndex = Math.min(fromIndex + maxMetricsPerRequestValue, totalMetrics);\n+\t\t\ttry {\n+\t\t\t\tclient.send(new DSeries(request.getSeries().subList(fromIndex, toIndex)));\n+\t\t\t} catch (SocketTimeoutException e) {\n+\t\t\t\tLOGGER.warn(\"Failed reporting metrics to Datadog because of socket timeout: {}\", e.getMessage());\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tLOGGER.warn(\"Failed reporting metrics to Datadog.\", e);\n+\t\t\t}\n+\t\t\tfromIndex = toIndex;\n \t\t}\n+\t\tLOGGER.debug(\"Reported series with size {}.\", totalMetrics);\n+\t\tcounters.values().forEach(DCounter::ackReport);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzAxMzA1NQ=="}, "originalCommit": {"oid": "3fa364afeda36c6e3de19804317d7470ecfcbd21"}, "originalPosition": 59}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1310, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}