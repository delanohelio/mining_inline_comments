{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTI1NTQ2Mzkx", "number": 14165, "title": "[FLINK-19687][table] Support to get execution plan from StatementSet", "bodyText": "What is the purpose of the change\nSupport to introduce the execution plan in  json format by StatementSet#explain.\nBrief change log\n\nAdd an enum JSON_EXECUTION_PLAN to ExplainDetail.\nUpdate all implementations of Planner#explain.\nAppend the execution plan in json format to the result when Planner#explain execute with parameter ExplainDetail.JSON_EXECUTION_PLAN.\n\nVerifying this change\n(Please pick either of the following options)\nThis change is a trivial rework / code cleanup without any test coverage.\n(or)\nThis change is already covered by existing tests, such as (please describe tests).\n(or)\nThis change added tests and can be verified as follows:\n(example:)\n\nAdded integration tests for end-to-end deployment with large payloads (100MB)\nExtended integration test for recovery after master (JobManager) failure\nAdded test that validates that TaskInfo is transferred only once across recoveries\nManually verified the change by running a 4 node cluser with 2 JobManagers and 4 TaskManagers, a stateful streaming program, and killing one JobManager and two TaskManagers during the execution, verifying that recovery happens correctly.\n\nDoes this pull request potentially affect one of the following parts:\n\nDependencies (does it add or upgrade a dependency): (yes / no)\nThe public API, i.e., is any changed class annotated with @Public(Evolving): (yes / no)\nThe serializers: (yes / no / don't know)\nThe runtime per-record code paths (performance sensitive): (yes / no / don't know)\nAnything that affects deployment or recovery: JobManager (and its components), Checkpointing, Kubernetes/Yarn/Mesos, ZooKeeper: (yes / no / don't know)\nThe S3 file system connector: (yes / no / don't know)\n\nDocumentation\n\nDoes this pull request introduce a new feature? (yes / no)\nIf yes, how is the feature documented? (not applicable / docs / JavaDocs / not documented)", "createdAt": "2020-11-23T08:14:31Z", "url": "https://github.com/apache/flink/pull/14165", "merged": true, "mergeCommit": {"oid": "144d92e49d6ed834c04bae902adb92cb0bd262aa"}, "closed": true, "closedAt": "2020-12-07T09:51:34Z", "author": {"login": "V1ncentzzZ"}, "timelineItems": {"totalCount": 15, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdfQnA9gH2gAyNTI1NTQ2MzkxOmVkYzJiNDhlOTQxYjY2OWQwM2I2N2QwOTYwZjNjY2EzY2RlOTFhMmI=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdjyZzGgFqTU0NTk4MTg3NQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "edc2b48e941b669d03b67d0960f3cca3cde91a2b", "author": {"user": null}, "url": "https://github.com/apache/flink/commit/edc2b48e941b669d03b67d0960f3cca3cde91a2b", "committedDate": "2020-11-23T08:09:59Z", "message": "[FLINK-19687][table] Support to introduce the execution plan in json format by `StatementSet#explain`"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "452c291a21493b2ae4e722de1879b5a94fca9ca9", "author": {"user": null}, "url": "https://github.com/apache/flink/commit/452c291a21493b2ae4e722de1879b5a94fca9ca9", "committedDate": "2020-11-23T09:03:27Z", "message": "[FLINK-19687][table] Add line separator before streaming execution plan"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM4MTkyOTQy", "url": "https://github.com/apache/flink/pull/14165#pullrequestreview-538192942", "createdAt": "2020-11-25T06:39:00Z", "commit": {"oid": "452c291a21493b2ae4e722de1879b5a94fca9ca9"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwNjozOTowMFrOH5lByg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwNjo0MDo0N1rOH5lEKQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDEzNzU0Ng==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t *                     e.g. estimated cost, changelog mode for streaming, execution plan in json format\n          \n          \n            \n            \t *                     e.g. estimated cost, changelog mode for streaming, displaying execution plan in json format", "url": "https://github.com/apache/flink/pull/14165#discussion_r530137546", "createdAt": "2020-11-25T06:39:00Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/api/StatementSet.java", "diffHunk": "@@ -51,7 +51,7 @@\n \t * all statements and Tables.\n \t *\n \t * @param extraDetails The extra explain details which the explain result should include,\n-\t *                     e.g. estimated cost, changelog mode for streaming\n+\t *                     e.g. estimated cost, changelog mode for streaming, execution plan in json format", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "452c291a21493b2ae4e722de1879b5a94fca9ca9"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDEzODE1Mw==", "bodyText": "I have discussed with @godfreyhe . We think that we don't need to add a new entry for the \"Streaming Execution Plan\". Because it describes the same plan with \"Physical Execution Plan\", just in different format.\nThus, we suggest to replace the content of \"Physical Execution Plan\" using the json string when ExplainDetail is in JSON_EXECUTION_PLAN.", "url": "https://github.com/apache/flink/pull/14165#discussion_r530138153", "createdAt": "2020-11-25T06:40:47Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/delegation/StreamPlanner.scala", "diffHunk": "@@ -129,6 +129,13 @@ class StreamPlanner(\n     sb.append(\"== Physical Execution Plan ==\")\n     sb.append(System.lineSeparator)\n     sb.append(executionPlan)\n+\n+    if (extraDetails.contains(ExplainDetail.JSON_EXECUTION_PLAN)) {\n+      sb.append(System.lineSeparator)\n+      sb.append(\"== Streaming Execution Plan ==\")\n+      sb.append(System.lineSeparator)\n+      sb.append(streamGraph.getStreamingPlanAsJSON)\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "452c291a21493b2ae4e722de1879b5a94fca9ca9"}, "originalPosition": 10}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "789968fa16af46908bf7094d6b4e391eaf989035", "author": {"user": null}, "url": "https://github.com/apache/flink/commit/789968fa16af46908bf7094d6b4e391eaf989035", "committedDate": "2020-11-27T06:48:30Z", "message": "[FLINK-19687][table] Modify code comments for `StatementSet#explain`"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c3f61dd588cda6d90b75f65f96f800ecc51aa6fb", "author": {"user": null}, "url": "https://github.com/apache/flink/commit/c3f61dd588cda6d90b75f65f96f800ecc51aa6fb", "committedDate": "2020-11-28T04:01:09Z", "message": "[FLINK-19687][table] Remove entry `Streaming Execution Plan` and reuse `Physical Execution Plan`"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7c554a8e388693a7f243f211726bbb763dddcb60", "author": {"user": null}, "url": "https://github.com/apache/flink/commit/7c554a8e388693a7f243f211726bbb763dddcb60", "committedDate": "2020-11-28T04:03:13Z", "message": "[FLINK-19687][table] Add test cases for `StatementSet#explain` and ``(Stream)TableEnvironment#explainSql`"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "df3a80a44692c8b13d0026673b463a451d44608d", "author": {"user": null}, "url": "https://github.com/apache/flink/commit/df3a80a44692c8b13d0026673b463a451d44608d", "committedDate": "2020-11-28T06:19:42Z", "message": "[FLINK-19687][table] Fix scala style error"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5967841ac958d8aa54754ff036045c34241676c7", "author": {"user": null}, "url": "https://github.com/apache/flink/commit/5967841ac958d8aa54754ff036045c34241676c7", "committedDate": "2020-11-28T09:01:50Z", "message": "[FLINK-19687][table] Add docs for `TableEnvironment#explainSql` and `Planner#explain`"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "560977065e15581698d2eec2307cd19a319ee918", "author": {"user": null}, "url": "https://github.com/apache/flink/commit/560977065e15581698d2eec2307cd19a319ee918", "committedDate": "2020-11-28T14:32:11Z", "message": "[FLINK-19687][table] Fix exception from ci/cd"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c5728be97ab3b29a7dc4834b9fb2bbf63a0143dd", "author": {"user": null}, "url": "https://github.com/apache/flink/commit/c5728be97ab3b29a7dc4834b9fb2bbf63a0143dd", "committedDate": "2020-11-30T02:11:14Z", "message": "[FLINK-19687][table] Fix exception from ci/cd"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ0Njk0MDI5", "url": "https://github.com/apache/flink/pull/14165#pullrequestreview-544694029", "createdAt": "2020-12-04T06:47:54Z", "commit": {"oid": "c5728be97ab3b29a7dc4834b9fb2bbf63a0143dd"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQwNjo0Nzo1NFrOH_DH3Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQwNjo1MDozMFrOH_DLgw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTg3MzUwMQ==", "bodyText": "This test case is a unit test, not an integration test, so this test case should be moved to TableEnvironmentTest\nnit: sink1Path and sink2Path are unnecessary", "url": "https://github.com/apache/flink/pull/14165#discussion_r535873501", "createdAt": "2020-12-04T06:47:54Z", "author": {"login": "godfreyhe"}, "path": "flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/api/TableEnvironmentITCase.scala", "diffHunk": "@@ -429,6 +429,26 @@ class TableEnvironmentITCase(tableEnvName: String, isStreaming: Boolean) extends\n     assertLastValues(sink2Path)\n   }\n \n+  @Test\n+  def testExecutionPlanFromStatementSet(): Unit = {\n+    val sink1Path = TestTableSourceSinks.createCsvTemporarySinkTable(\n+      tEnv, new TableSchema(Array(\"first\"), Array(STRING)), \"MySink1\")\n+\n+    val sink2Path = TestTableSourceSinks.createCsvTemporarySinkTable(\n+      tEnv, new TableSchema(Array(\"last\"), Array(STRING)), \"MySink2\")\n+\n+    val stmtSet = tEnv.createStatementSet()\n+    stmtSet.addInsert(\"MySink1\", tEnv.sqlQuery(\"select first from MyTable\"))\n+        .addInsertSql(\"insert into MySink2 select last from MyTable\")\n+\n+    val actual = stmtSet.explain(ExplainDetail.JSON_EXECUTION_PLAN)\n+    val expected =\n+      TableTestUtil.readFromResource(\"/explain/testExecutionPlanFromStatementSet.out\")\n+\n+    assertEquals(replaceStreamNodeIdAndParallelism(expected),\n+      replaceStreamNodeIdAndParallelism(actual))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c5728be97ab3b29a7dc4834b9fb2bbf63a0143dd"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTg3NDQzNQ==", "bodyText": "please also add some test cases for legacy planner", "url": "https://github.com/apache/flink/pull/14165#discussion_r535874435", "createdAt": "2020-12-04T06:50:30Z", "author": {"login": "godfreyhe"}, "path": "flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/api/TableEnvironmentTest.scala", "diffHunk": "@@ -103,6 +103,26 @@ class TableEnvironmentTest {\n     assertEquals(TableTestUtil.replaceStageId(expected), TableTestUtil.replaceStageId(actual))\n   }\n \n+  @Test\n+  def testStreamTableEnvironmentExecutionExplain(): Unit = {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c5728be97ab3b29a7dc4834b9fb2bbf63a0143dd"}, "originalPosition": 5}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "61cdd876e27d23952da5c66f6d201c7c7102ad3f", "author": {"user": null}, "url": "https://github.com/apache/flink/commit/61cdd876e27d23952da5c66f6d201c7c7102ad3f", "committedDate": "2020-12-04T15:05:19Z", "message": "[FLINK-19687][table] Update and add tests"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ1NDQ1MDc2", "url": "https://github.com/apache/flink/pull/14165#pullrequestreview-545445076", "createdAt": "2020-12-05T07:31:59Z", "commit": {"oid": "61cdd876e27d23952da5c66f6d201c7c7102ad3f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwNzozMTo1OVrOH_rjQg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwNzozMTo1OVrOH_rjQg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjUzNTg3NA==", "bodyText": "A minor concern: the estimated cost maybe unstable, so it's better the value can be normalized to zero or unknown to avoid unstable test.\nbtw, the parallelism value is a key information and the value is determinate except the default parallelism is the number of cpu cores for LocalStreamEnvironment, we can explicitly set the value var setParallelism method", "url": "https://github.com/apache/flink/pull/14165#discussion_r536535874", "createdAt": "2020-12-05T07:31:59Z", "author": {"login": "godfreyhe"}, "path": "flink-table/flink-table-planner/src/test/scala/resources/testStatementSetExecutionExplain1.out", "diffHunk": "@@ -0,0 +1,121 @@\n+== Abstract Syntax Tree ==\n+LogicalSink(name=[`default_catalog`.`default_database`.`targetTable`], fields=[d, e])\n+  LogicalProject(first=[$0], id=[$1])\n+    LogicalTableScan(table=[[default_catalog, default_database, sourceTable]])\n+\n+== Optimized Logical Plan ==\n+DataSetSink(name=[`default_catalog`.`default_database`.`targetTable`], fields=[d, e])\n+  BatchTableSourceScan(table=[[default_catalog, default_database, sourceTable]], fields=[first, id], source=[CsvTableSource(read fields: first, id)])\n+\n+== Physical Execution Plan ==\n+{\n+\t\"nodes\": [\n+\n+\t{\n+\t\t\"id\": ,\n+\t\t\"type\": \"source\",\n+\t\t\"pact\": \"Data Source\",\n+\t\t\"contents\": \"CsvTableSource(read fields: first, id)\",\n+\t\t\"parallelism\":,\n+\t\t\"global_properties\": [\n+\t\t\t{ \"name\": \"Partitioning\", \"value\": \"RANDOM_PARTITIONED\" },\n+\t\t\t{ \"name\": \"Partitioning Order\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Uniqueness\", \"value\": \"not unique\" }\n+\t\t],\n+\t\t\"local_properties\": [\n+\t\t\t{ \"name\": \"Order\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Grouping\", \"value\": \"not grouped\" },\n+\t\t\t{ \"name\": \"Uniqueness\", \"value\": \"not unique\" }\n+\t\t],\n+\t\t\"estimates\": [\n+\t\t\t{ \"name\": \"Est. Output Size\", \"value\": \"190.00\" },\n+\t\t\t{ \"name\": \"Est. Cardinality\", \"value\": \"10.00\" }\t\t],\n+\t\t\"costs\": [\n+\t\t\t{ \"name\": \"Network\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"Disk I/O\", \"value\": \"190.00\" },\n+\t\t\t{ \"name\": \"CPU\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"Cumulative Network\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"Cumulative Disk I/O\", \"value\": \"190.00\" },\n+\t\t\t{ \"name\": \"Cumulative CPU\", \"value\": \"0.0\" }\n+\t\t],\n+\t\t\"compiler_hints\": [\n+\t\t\t{ \"name\": \"Output Size (bytes)\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Output Cardinality\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Avg. Output Record Size (bytes)\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Filter Factor\", \"value\": \"(none)\" }\t\t]\n+\t},\n+\t{\n+\t\t\"id\": ,\n+\t\t\"type\": \"pact\",\n+\t\t\"pact\": \"Map\",\n+\t\t\"contents\": \"to: Row\",\n+\t\t\"parallelism\":,\n+\t\t\"predecessors\": [\n+\t\t\t{\"id\": , \"ship_strategy\": \"Forward\", \"exchange_mode\": \"PIPELINED\"}\n+\t\t],\n+\t\t\"driver_strategy\": \"Map\",\n+\t\t\"global_properties\": [\n+\t\t\t{ \"name\": \"Partitioning\", \"value\": \"RANDOM_PARTITIONED\" },\n+\t\t\t{ \"name\": \"Partitioning Order\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Uniqueness\", \"value\": \"not unique\" }\n+\t\t],\n+\t\t\"local_properties\": [\n+\t\t\t{ \"name\": \"Order\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Grouping\", \"value\": \"not grouped\" },\n+\t\t\t{ \"name\": \"Uniqueness\", \"value\": \"not unique\" }\n+\t\t],\n+\t\t\"estimates\": [\n+\t\t\t{ \"name\": \"Est. Output Size\", \"value\": \"(unknown)\" },\n+\t\t\t{ \"name\": \"Est. Cardinality\", \"value\": \"10.00\" }\t\t],\n+\t\t\"costs\": [\n+\t\t\t{ \"name\": \"Network\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"Disk I/O\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"CPU\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"Cumulative Network\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"Cumulative Disk I/O\", \"value\": \"190.00\" },\n+\t\t\t{ \"name\": \"Cumulative CPU\", \"value\": \"0.0\" }\n+\t\t],\n+\t\t\"compiler_hints\": [\n+\t\t\t{ \"name\": \"Output Size (bytes)\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Output Cardinality\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Avg. Output Record Size (bytes)\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Filter Factor\", \"value\": \"(none)\" }\t\t]\n+\t},\n+\t{\n+\t\t\"id\": ,\n+\t\t\"type\": \"sink\",\n+\t\t\"pact\": \"Data Sink\",\n+\t\t\"contents\": \"UnsafeMemoryAppendTableSink(d, e)\",\n+\t\t\"parallelism\":,\n+\t\t\"predecessors\": [\n+\t\t\t{\"id\": , \"ship_strategy\": \"Forward\", \"exchange_mode\": \"PIPELINED\"}\n+\t\t],\n+\t\t\"global_properties\": [\n+\t\t\t{ \"name\": \"Partitioning\", \"value\": \"RANDOM_PARTITIONED\" },\n+\t\t\t{ \"name\": \"Partitioning Order\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Uniqueness\", \"value\": \"not unique\" }\n+\t\t],\n+\t\t\"local_properties\": [\n+\t\t\t{ \"name\": \"Order\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Grouping\", \"value\": \"not grouped\" },\n+\t\t\t{ \"name\": \"Uniqueness\", \"value\": \"not unique\" }\n+\t\t],\n+\t\t\"estimates\": [\n+\t\t\t{ \"name\": \"Est. Output Size\", \"value\": \"(unknown)\" },\n+\t\t\t{ \"name\": \"Est. Cardinality\", \"value\": \"10.00\" }\t\t],\n+\t\t\"costs\": [\n+\t\t\t{ \"name\": \"Network\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"Disk I/O\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"CPU\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"Cumulative Network\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"Cumulative Disk I/O\", \"value\": \"190.00\" },\n+\t\t\t{ \"name\": \"Cumulative CPU\", \"value\": \"0.0\" }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "61cdd876e27d23952da5c66f6d201c7c7102ad3f"}, "originalPosition": 112}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9a54066e688f3de335b646b40b1888be88b41beb", "author": {"user": null}, "url": "https://github.com/apache/flink/commit/9a54066e688f3de335b646b40b1888be88b41beb", "committedDate": "2020-12-07T03:15:56Z", "message": "[FLINK-19687][table] Update tests"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ1OTgxODc1", "url": "https://github.com/apache/flink/pull/14165#pullrequestreview-545981875", "createdAt": "2020-12-07T09:48:01Z", "commit": {"oid": "9a54066e688f3de335b646b40b1888be88b41beb"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4041, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}