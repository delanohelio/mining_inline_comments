{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDA2NDMxMDQw", "number": 11837, "reviewThreads": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yM1QwMjo1MDowMlrOD1EFcg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QwNjo0Nzo0OFrOD77j7A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU2OTY4MDUwOnYy", "diffSide": "RIGHT", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/catalog/CatalogSchemaTable.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yM1QwMjo1MDowMlrOGKULcw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yM1QwMjo1NTo1OVrOGKUTWQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzQ2OTU1NQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t\tOptional<TableSource> sourceOpt = findAndCreateTableSource(new TableConfig().getConfiguration());\n          \n          \n            \n            \t\tOptional<TableSource<?>> sourceOpt = findAndCreateTableSource(new TableConfig().getConfiguration());\n          \n      \n    \n    \n  \n\nAdd <?> to TableSource to avoid IDEA warning.", "url": "https://github.com/apache/flink/pull/11837#discussion_r413469555", "createdAt": "2020-04-23T02:50:02Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/catalog/CatalogSchemaTable.java", "diffHunk": "@@ -153,6 +166,27 @@ private static RelDataType getRowType(RelDataTypeFactory typeFactory,\n \t\t\t\t}\n \t\t\t}\n \t\t}\n+\n+\t\t// The following block is a workaround to support tables defined by TableEnvironment.connect() and\n+\t\t// the actual table sources implement DefinedProctimeAttribute/DefinedRowtimeAttributes.\n+\t\t// It should be removed after we remove DefinedProctimeAttribute/DefinedRowtimeAttributes.\n+\t\tOptional<TableSource> sourceOpt = findAndCreateTableSource(new TableConfig().getConfiguration());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "38df357bc5c54d93159c2d460833cf80c42b5e0c"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzQ3MTU3Nw==", "bodyText": "If the ReadableConfig is always an empty configuration. Please remove the parameter and construct in the findAndCreateTableSource method with a comment to explain why we use an empty configuration.", "url": "https://github.com/apache/flink/pull/11837#discussion_r413471577", "createdAt": "2020-04-23T02:55:59Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/catalog/CatalogSchemaTable.java", "diffHunk": "@@ -153,6 +166,27 @@ private static RelDataType getRowType(RelDataTypeFactory typeFactory,\n \t\t\t\t}\n \t\t\t}\n \t\t}\n+\n+\t\t// The following block is a workaround to support tables defined by TableEnvironment.connect() and\n+\t\t// the actual table sources implement DefinedProctimeAttribute/DefinedRowtimeAttributes.\n+\t\t// It should be removed after we remove DefinedProctimeAttribute/DefinedRowtimeAttributes.\n+\t\tOptional<TableSource> sourceOpt = findAndCreateTableSource(new TableConfig().getConfiguration());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzQ2OTU1NQ=="}, "originalCommit": {"oid": "38df357bc5c54d93159c2d460833cf80c42b5e0c"}, "originalPosition": 46}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU2OTY5MDU3OnYy", "diffSide": "RIGHT", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/catalog/CatalogSchemaTable.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yM1QwMjo1Mzo0NVrOGKUQjA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yM1QwMjo1Mzo0NVrOGKUQjA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzQ3MDg2MA==", "bodyText": "Add a hasProctimeAttribute to TableSourceValidation and the condition can be simplified into\nif (hasRowtimeAttribute(source) && hasProctimeAttribute(source))", "url": "https://github.com/apache/flink/pull/11837#discussion_r413470860", "createdAt": "2020-04-23T02:53:45Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/catalog/CatalogSchemaTable.java", "diffHunk": "@@ -153,6 +166,27 @@ private static RelDataType getRowType(RelDataTypeFactory typeFactory,\n \t\t\t\t}\n \t\t\t}\n \t\t}\n+\n+\t\t// The following block is a workaround to support tables defined by TableEnvironment.connect() and\n+\t\t// the actual table sources implement DefinedProctimeAttribute/DefinedRowtimeAttributes.\n+\t\t// It should be removed after we remove DefinedProctimeAttribute/DefinedRowtimeAttributes.\n+\t\tOptional<TableSource> sourceOpt = findAndCreateTableSource(new TableConfig().getConfiguration());\n+\t\tif (tableSchema.getTableColumns().stream().noneMatch(TableColumn::isGenerated)\n+\t\t\t&& tableSchema.getWatermarkSpecs().isEmpty()\n+\t\t\t&& sourceOpt.isPresent()) {\n+\t\t\tTableSource source = sourceOpt.get();\n+\t\t\tif ((source instanceof DefinedProctimeAttribute\n+\t\t\t\t\t&& ((DefinedProctimeAttribute) source).getProctimeAttribute() != null)\n+\t\t\t\t\t||\n+\t\t\t\t\t(source instanceof DefinedRowtimeAttributes\n+\t\t\t\t\t\t\t&& ((DefinedRowtimeAttributes) source).getRowtimeAttributeDescriptors() != null\n+\t\t\t\t\t\t\t&& !((DefinedRowtimeAttributes) source).getRowtimeAttributeDescriptors().isEmpty())) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "38df357bc5c54d93159c2d460833cf80c42b5e0c"}, "originalPosition": 56}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU2OTcyNzk1OnYy", "diffSide": "RIGHT", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/catalog/CatalogSchemaTable.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yM1QwMzowOToyOVrOGKUktw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yM1QwMzowOToyOVrOGKUktw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzQ3NjAyMw==", "bodyText": "Add isStreamingMode into this condition, and findAndCreateTableSource  when the condition is satisfied.", "url": "https://github.com/apache/flink/pull/11837#discussion_r413476023", "createdAt": "2020-04-23T03:09:29Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/catalog/CatalogSchemaTable.java", "diffHunk": "@@ -153,6 +166,27 @@ private static RelDataType getRowType(RelDataTypeFactory typeFactory,\n \t\t\t\t}\n \t\t\t}\n \t\t}\n+\n+\t\t// The following block is a workaround to support tables defined by TableEnvironment.connect() and\n+\t\t// the actual table sources implement DefinedProctimeAttribute/DefinedRowtimeAttributes.\n+\t\t// It should be removed after we remove DefinedProctimeAttribute/DefinedRowtimeAttributes.\n+\t\tOptional<TableSource> sourceOpt = findAndCreateTableSource(new TableConfig().getConfiguration());\n+\t\tif (tableSchema.getTableColumns().stream().noneMatch(TableColumn::isGenerated)\n+\t\t\t&& tableSchema.getWatermarkSpecs().isEmpty()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "38df357bc5c54d93159c2d460833cf80c42b5e0c"}, "originalPosition": 48}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU2OTczMTk0OnYy", "diffSide": "RIGHT", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/schema/CatalogSourceTable.scala", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yM1QwMzoxMToxOVrOGKUm3w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yM1QwMzoxMToxOVrOGKUm3w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzQ3NjU3NQ==", "bodyText": "val legacyTimeAttributeDefined = hasRowtimeAttribute(source) && hasProctimeAttribute(source)", "url": "https://github.com/apache/flink/pull/11837#discussion_r413476575", "createdAt": "2020-04-23T03:11:19Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/schema/CatalogSourceTable.scala", "diffHunk": "@@ -210,20 +208,37 @@ class CatalogSourceTable[T](\n    */\n   private def eraseTimeIndicator(\n       relDataType: RelDataType,\n-      factory: FlinkTypeFactory): RelDataType = {\n-    val logicalRowType = FlinkTypeFactory.toLogicalRowType(relDataType)\n-    val fieldNames = logicalRowType.getFieldNames\n-    val fieldTypes = logicalRowType.getFields.map { f =>\n-      if (FlinkTypeFactory.isTimeIndicatorType(f.getType)) {\n-        val timeIndicatorType = f.getType.asInstanceOf[TimestampType]\n-        new TimestampType(\n-          timeIndicatorType.isNullable,\n-          TimestampKind.REGULAR,\n-          timeIndicatorType.getPrecision)\n-      } else {\n-        f.getType\n+      factory: FlinkTypeFactory,\n+      tableSource: TableSource[_]): RelDataType = {\n+    val isLegacySource = tableSource match {\n+      case rts: DefinedRowtimeAttributes\n+        if (rts.getRowtimeAttributeDescriptors != null\n+          && rts.getRowtimeAttributeDescriptors.nonEmpty) =>\n+        true\n+      case pts: DefinedProctimeAttribute if pts.getProctimeAttribute != null =>\n+         true\n+      case _ => false\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "38df357bc5c54d93159c2d460833cf80c42b5e0c"}, "originalPosition": 85}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU2OTczNTY1OnYy", "diffSide": "RIGHT", "path": "flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/plan/stream/sql/TableSourceTest.scala", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yM1QwMzoxMzowM1rOGKUo1A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQwMjo1Njo1OFrOGLEJjQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzQ3NzA3Ng==", "bodyText": "Can we have a dedicated descriptor for TestTableSourceWithTime? This code looks confusing.", "url": "https://github.com/apache/flink/pull/11837#discussion_r413477076", "createdAt": "2020-04-23T03:13:03Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/plan/stream/sql/TableSourceTest.scala", "diffHunk": "@@ -130,6 +131,60 @@ class TableSourceTest extends TableTestBase {\n     util.verifyPlan(sqlQuery)\n   }\n \n+\n+  @Test\n+  def testLegacyRowTimeTableGroupWindow(): Unit = {\n+    util.tableEnv.connect(new ConnectorDescriptor(\"TestTableSourceWithTime\", 1, false) {\n+      override protected def toConnectorProperties: JMap[String, String] = {\n+        Collections.emptyMap()\n+      }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "38df357bc5c54d93159c2d460833cf80c42b5e0c"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDI1NDE3Mw==", "bodyText": "I don't think so. A dedicated descriptor for every custom table source is wasteful and should be avoid. Maybe we can use CustomConnectorDescriptor after we port it in FLINK-16029?", "url": "https://github.com/apache/flink/pull/11837#discussion_r414254173", "createdAt": "2020-04-24T02:52:44Z", "author": {"login": "docete"}, "path": "flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/plan/stream/sql/TableSourceTest.scala", "diffHunk": "@@ -130,6 +131,60 @@ class TableSourceTest extends TableTestBase {\n     util.verifyPlan(sqlQuery)\n   }\n \n+\n+  @Test\n+  def testLegacyRowTimeTableGroupWindow(): Unit = {\n+    util.tableEnv.connect(new ConnectorDescriptor(\"TestTableSourceWithTime\", 1, false) {\n+      override protected def toConnectorProperties: JMap[String, String] = {\n+        Collections.emptyMap()\n+      }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzQ3NzA3Ng=="}, "originalCommit": {"oid": "38df357bc5c54d93159c2d460833cf80c42b5e0c"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDI1NTUwMQ==", "bodyText": "Introducing a generic connector descriptor is another topic, and I'm concerned CustomConnectorDescriptor is not easy-to-use enough.\nMaybe we can introduce a general TestConnectorDescriptor in tests.", "url": "https://github.com/apache/flink/pull/11837#discussion_r414255501", "createdAt": "2020-04-24T02:56:58Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/plan/stream/sql/TableSourceTest.scala", "diffHunk": "@@ -130,6 +131,60 @@ class TableSourceTest extends TableTestBase {\n     util.verifyPlan(sqlQuery)\n   }\n \n+\n+  @Test\n+  def testLegacyRowTimeTableGroupWindow(): Unit = {\n+    util.tableEnv.connect(new ConnectorDescriptor(\"TestTableSourceWithTime\", 1, false) {\n+      override protected def toConnectorProperties: JMap[String, String] = {\n+        Collections.emptyMap()\n+      }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzQ3NzA3Ng=="}, "originalCommit": {"oid": "38df357bc5c54d93159c2d460833cf80c42b5e0c"}, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU2OTczNzg0OnYy", "diffSide": "RIGHT", "path": "flink-table/flink-table-planner-blink/src/test/resources/META-INF/services/org.apache.flink.table.factories.TableFactory", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yM1QwMzoxNDowMlrOGKUqCw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yM1QwMzoxNDowMlrOGKUqCw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzQ3NzM4Nw==", "bodyText": "remove empty line?", "url": "https://github.com/apache/flink/pull/11837#discussion_r413477387", "createdAt": "2020-04-23T03:14:02Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-planner-blink/src/test/resources/META-INF/services/org.apache.flink.table.factories.TableFactory", "diffHunk": "@@ -20,3 +20,5 @@ org.apache.flink.table.planner.utils.TestFilterableTableSourceFactory\n org.apache.flink.table.planner.utils.TestProjectableTableSourceFactory\n org.apache.flink.table.planner.utils.TestCsvFileSystemFormatFactory\n org.apache.flink.table.planner.utils.TestOptionsTableFactory\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "38df357bc5c54d93159c2d460833cf80c42b5e0c"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU2OTc0Njc0OnYy", "diffSide": "RIGHT", "path": "flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/utils/testTableSourceSinks.scala", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yM1QwMzoxNzo0OFrOGKUuqQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQwNzowMjo0MFrOGLJeuQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzQ3ODU2OQ==", "bodyText": "Why the returnType is null? Use tableSchema.toRowType ?", "url": "https://github.com/apache/flink/pull/11837#discussion_r413478569", "createdAt": "2020-04-23T03:17:48Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/utils/testTableSourceSinks.scala", "diffHunk": "@@ -200,6 +199,65 @@ class TestTableSourceWithTime[T](\n   }\n }\n \n+class TestTableSourceWithTimeFactory[T] extends StreamTableSourceFactory[T] {\n+  override def createStreamTableSource(properties: JMap[String, String]): StreamTableSource[T] = {\n+    val dp = new DescriptorProperties()\n+    dp.putProperties(properties)\n+\n+    val isBounded = dp.getOptionalBoolean(\"is-bounded\").orElse(false)\n+    val tableSchema = dp.getTableSchema(Schema.SCHEMA)\n+    val serializedData = dp.getOptionalString(\"data\").orElse(null)\n+    val data = if (serializedData != null) {\n+      EncodingUtils.decodeStringToObject(serializedData, classOf[List[T]])\n+    } else {\n+      Seq.empty[T]\n+    }\n+    val rowtimeAttributes = SchemaValidator.deriveRowtimeAttributes(dp)\n+    val rowtime = if (rowtimeAttributes.isEmpty) {\n+      null\n+    } else {\n+      rowtimeAttributes.head.getAttributeName\n+    }\n+    val proctimeAttribute = SchemaValidator.deriveProctimeAttribute(dp)\n+    val proctime = if (proctimeAttribute.isPresent) {\n+      proctimeAttribute.get()\n+    } else {\n+      null\n+    }\n+\n+    val serializedMapKeys = dp.getOptionalString(\"map-keys\").orElse(null)\n+    val serializedMapVals = dp.getOptionalString(\"map-vals\").orElse(null)\n+    val mapping = if (serializedMapKeys != null && serializedMapVals != null) {\n+      val mapKeys = EncodingUtils.decodeStringToObject(serializedMapKeys, classOf[List[String]])\n+      val mapVals = EncodingUtils.decodeStringToObject(serializedMapVals, classOf[List[String]])\n+      if (mapKeys.length != mapVals.length) {\n+        null\n+      } else {\n+        mapKeys.zip(mapVals).toMap\n+      }\n+    } else {\n+      null\n+    }\n+\n+    val existingTs = dp.getOptionalString(\"existingTs\").orElse(null)\n+\n+    new TestTableSourceWithTime[T](\n+      isBounded, tableSchema, null, data, rowtime, proctime, mapping, existingTs)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "38df357bc5c54d93159c2d460833cf80c42b5e0c"}, "originalPosition": 73}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzQ3OTQ4Mg==", "bodyText": "If we only use this for planning, do you need to support extracting the data and mapping and existingTs ?", "url": "https://github.com/apache/flink/pull/11837#discussion_r413479482", "createdAt": "2020-04-23T03:20:58Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/utils/testTableSourceSinks.scala", "diffHunk": "@@ -200,6 +199,65 @@ class TestTableSourceWithTime[T](\n   }\n }\n \n+class TestTableSourceWithTimeFactory[T] extends StreamTableSourceFactory[T] {\n+  override def createStreamTableSource(properties: JMap[String, String]): StreamTableSource[T] = {\n+    val dp = new DescriptorProperties()\n+    dp.putProperties(properties)\n+\n+    val isBounded = dp.getOptionalBoolean(\"is-bounded\").orElse(false)\n+    val tableSchema = dp.getTableSchema(Schema.SCHEMA)\n+    val serializedData = dp.getOptionalString(\"data\").orElse(null)\n+    val data = if (serializedData != null) {\n+      EncodingUtils.decodeStringToObject(serializedData, classOf[List[T]])\n+    } else {\n+      Seq.empty[T]\n+    }\n+    val rowtimeAttributes = SchemaValidator.deriveRowtimeAttributes(dp)\n+    val rowtime = if (rowtimeAttributes.isEmpty) {\n+      null\n+    } else {\n+      rowtimeAttributes.head.getAttributeName\n+    }\n+    val proctimeAttribute = SchemaValidator.deriveProctimeAttribute(dp)\n+    val proctime = if (proctimeAttribute.isPresent) {\n+      proctimeAttribute.get()\n+    } else {\n+      null\n+    }\n+\n+    val serializedMapKeys = dp.getOptionalString(\"map-keys\").orElse(null)\n+    val serializedMapVals = dp.getOptionalString(\"map-vals\").orElse(null)\n+    val mapping = if (serializedMapKeys != null && serializedMapVals != null) {\n+      val mapKeys = EncodingUtils.decodeStringToObject(serializedMapKeys, classOf[List[String]])\n+      val mapVals = EncodingUtils.decodeStringToObject(serializedMapVals, classOf[List[String]])\n+      if (mapKeys.length != mapVals.length) {\n+        null\n+      } else {\n+        mapKeys.zip(mapVals).toMap\n+      }\n+    } else {\n+      null\n+    }\n+\n+    val existingTs = dp.getOptionalString(\"existingTs\").orElse(null)\n+\n+    new TestTableSourceWithTime[T](\n+      isBounded, tableSchema, null, data, rowtime, proctime, mapping, existingTs)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzQ3ODU2OQ=="}, "originalCommit": {"oid": "38df357bc5c54d93159c2d460833cf80c42b5e0c"}, "originalPosition": 73}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDI1MTc1OA==", "bodyText": "the TestTableSourceWithTime also used for ITs. IMO the factory should be for general use for all TestTableSourceWithTime cases and should support data, mapping and existingTs.", "url": "https://github.com/apache/flink/pull/11837#discussion_r414251758", "createdAt": "2020-04-24T02:45:40Z", "author": {"login": "docete"}, "path": "flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/utils/testTableSourceSinks.scala", "diffHunk": "@@ -200,6 +199,65 @@ class TestTableSourceWithTime[T](\n   }\n }\n \n+class TestTableSourceWithTimeFactory[T] extends StreamTableSourceFactory[T] {\n+  override def createStreamTableSource(properties: JMap[String, String]): StreamTableSource[T] = {\n+    val dp = new DescriptorProperties()\n+    dp.putProperties(properties)\n+\n+    val isBounded = dp.getOptionalBoolean(\"is-bounded\").orElse(false)\n+    val tableSchema = dp.getTableSchema(Schema.SCHEMA)\n+    val serializedData = dp.getOptionalString(\"data\").orElse(null)\n+    val data = if (serializedData != null) {\n+      EncodingUtils.decodeStringToObject(serializedData, classOf[List[T]])\n+    } else {\n+      Seq.empty[T]\n+    }\n+    val rowtimeAttributes = SchemaValidator.deriveRowtimeAttributes(dp)\n+    val rowtime = if (rowtimeAttributes.isEmpty) {\n+      null\n+    } else {\n+      rowtimeAttributes.head.getAttributeName\n+    }\n+    val proctimeAttribute = SchemaValidator.deriveProctimeAttribute(dp)\n+    val proctime = if (proctimeAttribute.isPresent) {\n+      proctimeAttribute.get()\n+    } else {\n+      null\n+    }\n+\n+    val serializedMapKeys = dp.getOptionalString(\"map-keys\").orElse(null)\n+    val serializedMapVals = dp.getOptionalString(\"map-vals\").orElse(null)\n+    val mapping = if (serializedMapKeys != null && serializedMapVals != null) {\n+      val mapKeys = EncodingUtils.decodeStringToObject(serializedMapKeys, classOf[List[String]])\n+      val mapVals = EncodingUtils.decodeStringToObject(serializedMapVals, classOf[List[String]])\n+      if (mapKeys.length != mapVals.length) {\n+        null\n+      } else {\n+        mapKeys.zip(mapVals).toMap\n+      }\n+    } else {\n+      null\n+    }\n+\n+    val existingTs = dp.getOptionalString(\"existingTs\").orElse(null)\n+\n+    new TestTableSourceWithTime[T](\n+      isBounded, tableSchema, null, data, rowtime, proctime, mapping, existingTs)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzQ3ODU2OQ=="}, "originalCommit": {"oid": "38df357bc5c54d93159c2d460833cf80c42b5e0c"}, "originalPosition": 73}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDI1NDI3NQ==", "bodyText": "Then, please add IT cases which uses these properties. Otherwise, it's hard to know whether this code is correct.", "url": "https://github.com/apache/flink/pull/11837#discussion_r414254275", "createdAt": "2020-04-24T02:53:06Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/utils/testTableSourceSinks.scala", "diffHunk": "@@ -200,6 +199,65 @@ class TestTableSourceWithTime[T](\n   }\n }\n \n+class TestTableSourceWithTimeFactory[T] extends StreamTableSourceFactory[T] {\n+  override def createStreamTableSource(properties: JMap[String, String]): StreamTableSource[T] = {\n+    val dp = new DescriptorProperties()\n+    dp.putProperties(properties)\n+\n+    val isBounded = dp.getOptionalBoolean(\"is-bounded\").orElse(false)\n+    val tableSchema = dp.getTableSchema(Schema.SCHEMA)\n+    val serializedData = dp.getOptionalString(\"data\").orElse(null)\n+    val data = if (serializedData != null) {\n+      EncodingUtils.decodeStringToObject(serializedData, classOf[List[T]])\n+    } else {\n+      Seq.empty[T]\n+    }\n+    val rowtimeAttributes = SchemaValidator.deriveRowtimeAttributes(dp)\n+    val rowtime = if (rowtimeAttributes.isEmpty) {\n+      null\n+    } else {\n+      rowtimeAttributes.head.getAttributeName\n+    }\n+    val proctimeAttribute = SchemaValidator.deriveProctimeAttribute(dp)\n+    val proctime = if (proctimeAttribute.isPresent) {\n+      proctimeAttribute.get()\n+    } else {\n+      null\n+    }\n+\n+    val serializedMapKeys = dp.getOptionalString(\"map-keys\").orElse(null)\n+    val serializedMapVals = dp.getOptionalString(\"map-vals\").orElse(null)\n+    val mapping = if (serializedMapKeys != null && serializedMapVals != null) {\n+      val mapKeys = EncodingUtils.decodeStringToObject(serializedMapKeys, classOf[List[String]])\n+      val mapVals = EncodingUtils.decodeStringToObject(serializedMapVals, classOf[List[String]])\n+      if (mapKeys.length != mapVals.length) {\n+        null\n+      } else {\n+        mapKeys.zip(mapVals).toMap\n+      }\n+    } else {\n+      null\n+    }\n+\n+    val existingTs = dp.getOptionalString(\"existingTs\").orElse(null)\n+\n+    new TestTableSourceWithTime[T](\n+      isBounded, tableSchema, null, data, rowtime, proctime, mapping, existingTs)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzQ3ODU2OQ=="}, "originalCommit": {"oid": "38df357bc5c54d93159c2d460833cf80c42b5e0c"}, "originalPosition": 73}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDM0Mjg0MQ==", "bodyText": "See TableScanITCase#testProctimeTableSource()\nIt should use this factory after we remove tableEnv.registerTableSource()", "url": "https://github.com/apache/flink/pull/11837#discussion_r414342841", "createdAt": "2020-04-24T07:02:40Z", "author": {"login": "docete"}, "path": "flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/utils/testTableSourceSinks.scala", "diffHunk": "@@ -200,6 +199,65 @@ class TestTableSourceWithTime[T](\n   }\n }\n \n+class TestTableSourceWithTimeFactory[T] extends StreamTableSourceFactory[T] {\n+  override def createStreamTableSource(properties: JMap[String, String]): StreamTableSource[T] = {\n+    val dp = new DescriptorProperties()\n+    dp.putProperties(properties)\n+\n+    val isBounded = dp.getOptionalBoolean(\"is-bounded\").orElse(false)\n+    val tableSchema = dp.getTableSchema(Schema.SCHEMA)\n+    val serializedData = dp.getOptionalString(\"data\").orElse(null)\n+    val data = if (serializedData != null) {\n+      EncodingUtils.decodeStringToObject(serializedData, classOf[List[T]])\n+    } else {\n+      Seq.empty[T]\n+    }\n+    val rowtimeAttributes = SchemaValidator.deriveRowtimeAttributes(dp)\n+    val rowtime = if (rowtimeAttributes.isEmpty) {\n+      null\n+    } else {\n+      rowtimeAttributes.head.getAttributeName\n+    }\n+    val proctimeAttribute = SchemaValidator.deriveProctimeAttribute(dp)\n+    val proctime = if (proctimeAttribute.isPresent) {\n+      proctimeAttribute.get()\n+    } else {\n+      null\n+    }\n+\n+    val serializedMapKeys = dp.getOptionalString(\"map-keys\").orElse(null)\n+    val serializedMapVals = dp.getOptionalString(\"map-vals\").orElse(null)\n+    val mapping = if (serializedMapKeys != null && serializedMapVals != null) {\n+      val mapKeys = EncodingUtils.decodeStringToObject(serializedMapKeys, classOf[List[String]])\n+      val mapVals = EncodingUtils.decodeStringToObject(serializedMapVals, classOf[List[String]])\n+      if (mapKeys.length != mapVals.length) {\n+        null\n+      } else {\n+        mapKeys.zip(mapVals).toMap\n+      }\n+    } else {\n+      null\n+    }\n+\n+    val existingTs = dp.getOptionalString(\"existingTs\").orElse(null)\n+\n+    new TestTableSourceWithTime[T](\n+      isBounded, tableSchema, null, data, rowtime, proctime, mapping, existingTs)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzQ3ODU2OQ=="}, "originalCommit": {"oid": "38df357bc5c54d93159c2d460833cf80c42b5e0c"}, "originalPosition": 73}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0MTY4Mzk2OnYy", "diffSide": "RIGHT", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/sources/TableSourceUtil.scala", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QwNjo0Nzo0MFrOGUjlRA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QwNjo0Nzo0MFrOGUjlRA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDIwNzY4NA==", "bodyText": "Not used. Remove?", "url": "https://github.com/apache/flink/pull/11837#discussion_r424207684", "createdAt": "2020-05-13T06:47:40Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/sources/TableSourceUtil.scala", "diffHunk": "@@ -303,6 +303,28 @@ object TableSourceUtil {\n     expr\n   }\n \n+  /** Returns whether a table source defines rowtime attributes in legacy way **/\n+  def hasRowtimeAttributes(tableSource: TableSource[_]): Boolean = {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b62fcd03a583ef204f21a313f6969c8aaa4ee61d"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0MTY4NDI4OnYy", "diffSide": "RIGHT", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/sources/TableSourceUtil.scala", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QwNjo0Nzo0OFrOGUjlfg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QwNjo0Nzo0OFrOGUjlfg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDIwNzc0Mg==", "bodyText": "Not used. Remove?", "url": "https://github.com/apache/flink/pull/11837#discussion_r424207742", "createdAt": "2020-05-13T06:47:48Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/sources/TableSourceUtil.scala", "diffHunk": "@@ -303,6 +303,28 @@ object TableSourceUtil {\n     expr\n   }\n \n+  /** Returns whether a table source defines rowtime attributes in legacy way **/\n+  def hasRowtimeAttributes(tableSource: TableSource[_]): Boolean = {\n+    tableSource match {\n+      case ts: DefinedRowtimeAttributes\n+        if ts.getRowtimeAttributeDescriptors != null\n+          && ts.getRowtimeAttributeDescriptors.nonEmpty =>\n+        true\n+      case _ =>\n+        false\n+    }\n+  }\n+\n+  /** Returns whether a table source defines proctime attribute in legacy way **/\n+  def hasProctimeAttribute(tableSource: TableSource[_]): Boolean = {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b62fcd03a583ef204f21a313f6969c8aaa4ee61d"}, "originalPosition": 17}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1547, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}