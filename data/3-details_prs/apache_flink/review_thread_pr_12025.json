{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE0NzExNjM2", "number": 12025, "reviewThreads": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQwMjo0NDo1N1rOD8to5Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQwMjo1NzoxNVrOD8twNg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0OTg4OTAxOnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/ConsumeOrder.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQwMjo0NDo1N1rOGV0ouA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQwMjo0NDo1N1rOGV0ouA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTUzNTY3Mg==", "bodyText": "Above should have a blank line.", "url": "https://github.com/apache/flink/pull/12025#discussion_r425535672", "createdAt": "2020-05-15T02:44:57Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/ConsumeOrder.java", "diffHunk": "@@ -0,0 +1,59 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connectors.hive;\n+\n+/**\n+ * {@link ConsumeOrder} defines the orders to continuously consume stream source.\n+ */\n+public enum ConsumeOrder {\n+\n+\t/**\n+\t * create-time compare partition/file creation time,\n+\t * this is not the partition create time in Hive metaStore,\n+\t * but the folder/file create time in filesystem.\n+\t */\n+\tCREATE_TIME_ORDER(\"create-time\"),\n+\n+\t/**\n+\t * partition-time compare time represented by partition name.\n+\t */\n+\tPARTITION_TIME_ORDER(\"partition-time\");\n+\n+\tprivate final String order;\n+\tConsumeOrder(String order) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4b70dbd62d22edbaf0c3ff54ca61a35ac93c04e"}, "originalPosition": 39}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0OTg5MTMzOnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/ConsumeOrder.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQwMjo0NjoyN1rOGV0qKA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQwMjo0NjoyN1rOGV0qKA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTUzNjA0MA==", "bodyText": "ConsumeOrder.values() -> values()", "url": "https://github.com/apache/flink/pull/12025#discussion_r425536040", "createdAt": "2020-05-15T02:46:27Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/ConsumeOrder.java", "diffHunk": "@@ -0,0 +1,59 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connectors.hive;\n+\n+/**\n+ * {@link ConsumeOrder} defines the orders to continuously consume stream source.\n+ */\n+public enum ConsumeOrder {\n+\n+\t/**\n+\t * create-time compare partition/file creation time,\n+\t * this is not the partition create time in Hive metaStore,\n+\t * but the folder/file create time in filesystem.\n+\t */\n+\tCREATE_TIME_ORDER(\"create-time\"),\n+\n+\t/**\n+\t * partition-time compare time represented by partition name.\n+\t */\n+\tPARTITION_TIME_ORDER(\"partition-time\");\n+\n+\tprivate final String order;\n+\tConsumeOrder(String order) {\n+\t\tthis.order = order;\n+\t}\n+\n+\t@Override\n+\tpublic String toString() {\n+\t\treturn order;\n+\t}\n+\n+\t/**\n+\t * Get {@link ConsumeOrder} from consume order string.\n+\t */\n+\tpublic static ConsumeOrder getConsumeOrder(String consumeOrderStr) {\n+\t\tfor (ConsumeOrder consumeOrder : ConsumeOrder.values()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4b70dbd62d22edbaf0c3ff54ca61a35ac93c04e"}, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0OTg5MTc1OnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/ConsumeOrder.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQwMjo0Njo0N1rOGV0qcA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQwMjo0Njo0N1rOGV0qcA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTUzNjExMg==", "bodyText": "equalsIgnoreCase", "url": "https://github.com/apache/flink/pull/12025#discussion_r425536112", "createdAt": "2020-05-15T02:46:47Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/ConsumeOrder.java", "diffHunk": "@@ -0,0 +1,59 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connectors.hive;\n+\n+/**\n+ * {@link ConsumeOrder} defines the orders to continuously consume stream source.\n+ */\n+public enum ConsumeOrder {\n+\n+\t/**\n+\t * create-time compare partition/file creation time,\n+\t * this is not the partition create time in Hive metaStore,\n+\t * but the folder/file create time in filesystem.\n+\t */\n+\tCREATE_TIME_ORDER(\"create-time\"),\n+\n+\t/**\n+\t * partition-time compare time represented by partition name.\n+\t */\n+\tPARTITION_TIME_ORDER(\"partition-time\");\n+\n+\tprivate final String order;\n+\tConsumeOrder(String order) {\n+\t\tthis.order = order;\n+\t}\n+\n+\t@Override\n+\tpublic String toString() {\n+\t\treturn order;\n+\t}\n+\n+\t/**\n+\t * Get {@link ConsumeOrder} from consume order string.\n+\t */\n+\tpublic static ConsumeOrder getConsumeOrder(String consumeOrderStr) {\n+\t\tfor (ConsumeOrder consumeOrder : ConsumeOrder.values()) {\n+\t\t\tif (consumeOrder.order.equals(consumeOrderStr)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4b70dbd62d22edbaf0c3ff54ca61a35ac93c04e"}, "originalPosition": 53}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0OTg5MjY4OnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/ConsumeOrder.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQwMjo0NzoyM1rOGV0rAw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQwMjo0NzoyM1rOGV0rAw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTUzNjI1OQ==", "bodyText": "throw exception, we should not pass a null to operators.", "url": "https://github.com/apache/flink/pull/12025#discussion_r425536259", "createdAt": "2020-05-15T02:47:23Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/ConsumeOrder.java", "diffHunk": "@@ -0,0 +1,59 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connectors.hive;\n+\n+/**\n+ * {@link ConsumeOrder} defines the orders to continuously consume stream source.\n+ */\n+public enum ConsumeOrder {\n+\n+\t/**\n+\t * create-time compare partition/file creation time,\n+\t * this is not the partition create time in Hive metaStore,\n+\t * but the folder/file create time in filesystem.\n+\t */\n+\tCREATE_TIME_ORDER(\"create-time\"),\n+\n+\t/**\n+\t * partition-time compare time represented by partition name.\n+\t */\n+\tPARTITION_TIME_ORDER(\"partition-time\");\n+\n+\tprivate final String order;\n+\tConsumeOrder(String order) {\n+\t\tthis.order = order;\n+\t}\n+\n+\t@Override\n+\tpublic String toString() {\n+\t\treturn order;\n+\t}\n+\n+\t/**\n+\t * Get {@link ConsumeOrder} from consume order string.\n+\t */\n+\tpublic static ConsumeOrder getConsumeOrder(String consumeOrderStr) {\n+\t\tfor (ConsumeOrder consumeOrder : ConsumeOrder.values()) {\n+\t\t\tif (consumeOrder.order.equals(consumeOrderStr)) {\n+\t\t\t\treturn consumeOrder;\n+\t\t\t}\n+\t\t}\n+\t\treturn null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4b70dbd62d22edbaf0c3ff54ca61a35ac93c04e"}, "originalPosition": 57}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0OTg5NTUwOnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/HiveTableSource.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQwMjo0OToxOVrOGV0svA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQwMjo0OToxOVrOGV0svA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTUzNjcwMA==", "bodyText": "Configuration configuration = new Configuration();\noptions.forEach(configuration::setString)\n\nWe can use Configuration to get option.", "url": "https://github.com/apache/flink/pull/12025#discussion_r425536700", "createdAt": "2020-05-15T02:49:19Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/HiveTableSource.java", "diffHunk": "@@ -261,6 +267,57 @@ private boolean isStreamingSource() {\n \t\treturn new DataStreamSource<>(source);\n \t}\n \n+\tprivate DataStream<RowData> createStreamSourceForNonPartitionTable(\n+\t\t\tStreamExecutionEnvironment execEnv,\n+\t\t\tTypeInformation<RowData> typeInfo,\n+\t\t\tHiveTableInputFormat inputFormat,\n+\t\t\tHiveTablePartition hiveTable) {\n+\t\tHiveTableFileInputFormat fileInputFormat = new HiveTableFileInputFormat(\n+\t\t\t\tinputFormat,\n+\t\t\t\thiveTable);\n+\t\tfileInputFormat.setFilePath(getFilePath());\n+\n+\t\tfinal Map<String, String> properties = catalogTable.getOptions();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4b70dbd62d22edbaf0c3ff54ca61a35ac93c04e"}, "originalPosition": 73}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0OTg5ODI1OnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/HiveTableSource.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQwMjo1MDo1NlrOGV0uWg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQwMjo1MDo1NlrOGV0uWg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTUzNzExNA==", "bodyText": "never null.", "url": "https://github.com/apache/flink/pull/12025#discussion_r425537114", "createdAt": "2020-05-15T02:50:56Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/HiveTableSource.java", "diffHunk": "@@ -261,6 +267,57 @@ private boolean isStreamingSource() {\n \t\treturn new DataStreamSource<>(source);\n \t}\n \n+\tprivate DataStream<RowData> createStreamSourceForNonPartitionTable(\n+\t\t\tStreamExecutionEnvironment execEnv,\n+\t\t\tTypeInformation<RowData> typeInfo,\n+\t\t\tHiveTableInputFormat inputFormat,\n+\t\t\tHiveTablePartition hiveTable) {\n+\t\tHiveTableFileInputFormat fileInputFormat = new HiveTableFileInputFormat(\n+\t\t\t\tinputFormat,\n+\t\t\t\thiveTable);\n+\t\tfileInputFormat.setFilePath(getFilePath());\n+\n+\t\tfinal Map<String, String> properties = catalogTable.getOptions();\n+\n+\t\tString consumeOrderStr = properties.getOrDefault(\n+\t\t\t\tSTREAMING_SOURCE_CONSUME_ORDER.key(),\n+\t\t\t\tSTREAMING_SOURCE_CONSUME_ORDER.defaultValue());\n+\t\tConsumeOrder consumeOrder = ConsumeOrder.getConsumeOrder(consumeOrderStr);\n+\t\tif (consumeOrder != ConsumeOrder.CREATE_TIME_ORDER) {\n+\t\t\tthrow new UnsupportedOperationException(\"Unsupported consumer order: \" + consumeOrder);\n+\t\t}\n+\n+\t\tString consumeOffset = properties.getOrDefault(\n+\t\t\t\tSTREAMING_SOURCE_CONSUME_START_OFFSET.key(),\n+\t\t\t\tSTREAMING_SOURCE_CONSUME_START_OFFSET.defaultValue());\n+\t\tlong currentReadTime = Long.MIN_VALUE;\n+\t\tif (consumeOffset != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4b70dbd62d22edbaf0c3ff54ca61a35ac93c04e"}, "originalPosition": 87}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0OTkwMTUwOnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/HiveTableSource.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQwMjo1MzoxMFrOGV0waQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQwMjo1MzoxMFrOGV0waQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTUzNzY0MQ==", "bodyText": "Remove getFilePath, we can get path from allHivePartitions(should be a single object when no partitions.).", "url": "https://github.com/apache/flink/pull/12025#discussion_r425537641", "createdAt": "2020-05-15T02:53:10Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/HiveTableSource.java", "diffHunk": "@@ -261,6 +267,57 @@ private boolean isStreamingSource() {\n \t\treturn new DataStreamSource<>(source);\n \t}\n \n+\tprivate DataStream<RowData> createStreamSourceForNonPartitionTable(\n+\t\t\tStreamExecutionEnvironment execEnv,\n+\t\t\tTypeInformation<RowData> typeInfo,\n+\t\t\tHiveTableInputFormat inputFormat,\n+\t\t\tHiveTablePartition hiveTable) {\n+\t\tHiveTableFileInputFormat fileInputFormat = new HiveTableFileInputFormat(\n+\t\t\t\tinputFormat,\n+\t\t\t\thiveTable);\n+\t\tfileInputFormat.setFilePath(getFilePath());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4b70dbd62d22edbaf0c3ff54ca61a35ac93c04e"}, "originalPosition": 71}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0OTkwNDIzOnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/read/HiveTableFileInputFormat.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQwMjo1NTowNVrOGV0yPQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQwMzoyODo0NFrOGV1R8w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTUzODEwOQ==", "bodyText": "Please add comments:\n\nOnly support FileInputSplit\nOnly support renaming inserting\ngetSplit use flinks instead format.", "url": "https://github.com/apache/flink/pull/12025#discussion_r425538109", "createdAt": "2020-05-15T02:55:05Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/read/HiveTableFileInputFormat.java", "diffHunk": "@@ -0,0 +1,100 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connectors.hive.read;\n+\n+import org.apache.flink.api.common.functions.RuntimeContext;\n+import org.apache.flink.api.common.io.FileInputFormat;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.connectors.hive.HiveTablePartition;\n+import org.apache.flink.core.fs.FileInputSplit;\n+import org.apache.flink.table.data.RowData;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.mapred.FileSplit;\n+\n+import java.io.IOException;\n+import java.net.URI;\n+\n+/**\n+ * A {@link FileInputFormat} that wraps a {@link HiveTableInputFormat}.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4b70dbd62d22edbaf0c3ff54ca61a35ac93c04e"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTU0NjIyNw==", "bodyText": "\"Only support renaming inserting\" is not the limitation of HiveTableFileInputFormat, it's the limit of ContinuousFileMonitoringFunction, I have add some documents in FileSystemOptions.", "url": "https://github.com/apache/flink/pull/12025#discussion_r425546227", "createdAt": "2020-05-15T03:28:44Z", "author": {"login": "godfreyhe"}, "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/read/HiveTableFileInputFormat.java", "diffHunk": "@@ -0,0 +1,100 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connectors.hive.read;\n+\n+import org.apache.flink.api.common.functions.RuntimeContext;\n+import org.apache.flink.api.common.io.FileInputFormat;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.connectors.hive.HiveTablePartition;\n+import org.apache.flink.core.fs.FileInputSplit;\n+import org.apache.flink.table.data.RowData;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.mapred.FileSplit;\n+\n+import java.io.IOException;\n+import java.net.URI;\n+\n+/**\n+ * A {@link FileInputFormat} that wraps a {@link HiveTableInputFormat}.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTUzODEwOQ=="}, "originalCommit": {"oid": "d4b70dbd62d22edbaf0c3ff54ca61a35ac93c04e"}, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0OTkwNTQ1OnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/read/HiveTableFileInputFormat.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQwMjo1NTo0N1rOGV0y8w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQwMjo1NTo0N1rOGV0y8w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTUzODI5MQ==", "bodyText": "A better way is first super., second do own works.\nsame below.", "url": "https://github.com/apache/flink/pull/12025#discussion_r425538291", "createdAt": "2020-05-15T02:55:47Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/read/HiveTableFileInputFormat.java", "diffHunk": "@@ -0,0 +1,100 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connectors.hive.read;\n+\n+import org.apache.flink.api.common.functions.RuntimeContext;\n+import org.apache.flink.api.common.io.FileInputFormat;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.connectors.hive.HiveTablePartition;\n+import org.apache.flink.core.fs.FileInputSplit;\n+import org.apache.flink.table.data.RowData;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.mapred.FileSplit;\n+\n+import java.io.IOException;\n+import java.net.URI;\n+\n+/**\n+ * A {@link FileInputFormat} that wraps a {@link HiveTableInputFormat}.\n+ */\n+public class HiveTableFileInputFormat extends FileInputFormat<RowData> {\n+\n+\tprivate HiveTableInputFormat inputFormat;\n+\tprivate HiveTablePartition hiveTablePartition;\n+\n+\tpublic HiveTableFileInputFormat(\n+\t\t\tHiveTableInputFormat inputFormat,\n+\t\t\tHiveTablePartition hiveTablePartition) {\n+\t\tthis.inputFormat = inputFormat;\n+\t\tthis.hiveTablePartition = hiveTablePartition;\n+\t}\n+\n+\t@Override\n+\tpublic void open(FileInputSplit fileSplit) throws IOException {\n+\t\tURI uri = fileSplit.getPath().toUri();\n+\t\tHiveTableInputSplit split = new HiveTableInputSplit(\n+\t\t\t\tfileSplit.getSplitNumber(),\n+\t\t\t\tnew FileSplit(new Path(uri), fileSplit.getStart(), fileSplit.getLength(), (String[]) null),\n+\t\t\t\tinputFormat.getJobConf(),\n+\t\t\t\thiveTablePartition\n+\t\t);\n+\t\tinputFormat.open(split);\n+\t}\n+\n+\t@Override\n+\tpublic boolean reachedEnd() throws IOException {\n+\t\treturn inputFormat.reachedEnd();\n+\t}\n+\n+\t@Override\n+\tpublic RowData nextRecord(RowData reuse) throws IOException {\n+\t\treturn inputFormat.nextRecord(reuse);\n+\t}\n+\n+\t@Override\n+\tpublic void configure(Configuration parameters) {\n+\t\tinputFormat.configure(parameters);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4b70dbd62d22edbaf0c3ff54ca61a35ac93c04e"}, "originalPosition": 73}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0OTkwNzc0OnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveTableSourceTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQwMjo1NzoxNVrOGV00ag==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQwMjo1NzoxNVrOGV00ag==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTUzODY2Ng==", "bodyText": "useMapredReader only works in parquet and orc, you should use them.", "url": "https://github.com/apache/flink/pull/12025#discussion_r425538666", "createdAt": "2020-05-15T02:57:15Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveTableSourceTest.java", "diffHunk": "@@ -531,6 +534,76 @@ public void testStreamPartitionRead() throws Exception {\n \t\tjob.cancel();\n \t}\n \n+\t@Test(timeout = 30000)\n+\tpublic void testNonPartitionStreamingSourceWithMapredReader() throws Exception {\n+\t\ttestNonPartitionStreamingSource(true, \"test_mapred_reader\");\n+\t}\n+\n+\t@Test(timeout = 30000)\n+\tpublic void testNonPartitionStreamingSourceWithVectorizedReader() throws Exception {\n+\t\ttestNonPartitionStreamingSource(false, \"test_vectorized_reader\");\n+\t}\n+\n+\tprivate void testNonPartitionStreamingSource(Boolean useMapredReader, String tblName) throws Exception {\n+\t\tfinal String catalogName = \"hive\";\n+\t\tfinal String dbName = \"source_db\";\n+\t\thiveShell.execute(\"CREATE TABLE source_db.\" + tblName + \" (\" +\n+\t\t\t\t\"  a INT,\" +\n+\t\t\t\t\"  b CHAR(1) \" +\n+\t\t\t\t\") TBLPROPERTIES (\" +\n+\t\t\t\t\"  'streaming-source.enable'='true',\" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4b70dbd62d22edbaf0c3ff54ca61a35ac93c04e"}, "originalPosition": 53}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1535, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}