{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTI3NDc5OTk1", "number": 14222, "title": "[FLINK-20343] Add new Deployment overview documentation page", "bodyText": "For convenience, I rendered the page here:", "createdAt": "2020-11-25T14:20:04Z", "url": "https://github.com/apache/flink/pull/14222", "merged": true, "mergeCommit": {"oid": "d219466196f4fd9577c3587fd865325649fd0efb"}, "closed": true, "closedAt": "2020-11-27T11:09:26Z", "author": {"login": "rmetzger"}, "timelineItems": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdgA0rYgFqTUzODU3NjUwMA==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdgjzO9gBqjQwNDUyMDU3MDE=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM4NTc2NTAw", "url": "https://github.com/apache/flink/pull/14222#pullrequestreview-538576500", "createdAt": "2020-11-25T14:50:57Z", "commit": {"oid": "2091ef6d8bc44d6b1381b2818e3a00c055641aac"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxNDo1MDo1N1rOH525Fw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxNjoxOToyMlrOH560pA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDQzMDIzMQ==", "bodyText": "I still think that the explanation of the different job submission modes are not necessary here as we're talking about components. IMHO, removing the listing and just linking to the job submission mode section would be good enough.", "url": "https://github.com/apache/flink/pull/14222#discussion_r530430231", "createdAt": "2020-11-25T14:50:57Z", "author": {"login": "XComp"}, "path": "docs/ops/deployment/overview.md", "diffHunk": "@@ -0,0 +1,358 @@\n+---\n+title: \"Clusters & Deployment\"\n+nav-id: deployment\n+nav-parent_id: ops\n+nav-pos: 1\n+nav-show_overview: true\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+Flink is a versatile framework, supporting many different deployment scenarios in a mix and match fashion.\n+\n+Below, we briefly explain the building blocks of a Flink cluster, their purpose and available implementations.\n+If you just want to start Flink locally, we recommend setting up a [Standalone Cluster]({% link ops/deployment/local.md %}).\n+\n+* This will be replaced by the TOC\n+{:toc}\n+\n+\n+## Overview and Reference Architecture\n+\n+The figure below shows the building blocks of every Flink cluster. There is always somewhere a client running. It takes the code of the Flink applications, transforms it into a job graph and submits it to the JobManager.\n+\n+The JobManager distributes the work onto the TaskManagers, where the actual operators (such as sources, transformations and sinks) are running.\n+\n+When deploying Flink, there are often multiple options available for each building block. We have listed them in the table below the figure.\n+\n+If you don't know where to start, we recommend using the Command Line Interface for submitting Flink applications to a Standalone Cluster.\n+\n+<!-- Image source: https://docs.google.com/drawings/d/1s_ZlXXvADqxWfTMNRVwQeg7HZ3hN1Xb7goxDPjTEPrI/edit?usp=sharing -->\n+<img width=\"100%\" src=\"{% link fig/deployment_overview.svg %}\" alt=\"Figure for Overview and Reference Architecture\" />\n+\n+\n+<table class=\"table table-bordered\">\n+  <thead>\n+    <tr>\n+      <th class=\"text-left\" style=\"width: 25%\">Component</th>\n+      <th class=\"text-left\" style=\"width: 50%\">Purpose</th>\n+      <th class=\"text-left\">Implementations</th>\n+    </tr>\n+   </thead>\n+   <tbody>\n+        <tr>\n+            <td>Flink Client</td>\n+            <td>\n+              Flink batch or streaming applications are compiled into a dataflow graph, which is submitted to the JobManager.\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Command Line Interface</a></li>\n+                    <li><a href=\"\">REST Endpoint</a></li>\n+                    <li><a href=\"\">SQL Client</a></li>\n+                    <li><a href=\"\">Python REPL</a></li>\n+                    <li><a href=\"\">Scala REPL</a></li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>JobManager</td>\n+            <td>\n+                JobManager is the name of the central work coordination component of Flink. It has implementations for different resource providers, which differ on high-availability, resource allocation behavior and supported job submission modes. <br />\n+                JobManager <a href=\"\">modes for job submissions</a>:\n+                <ul>\n+                    <li><b>Session Mode</b>: one JobManager instance manages multiple jobs sharing the same cluster of TaskManagers</li>\n+                    <li><b>Application Mode</b>: runs the cluster exclusively for one job. The job main method (or client) gets executed on the JobManager.</li>\n+                    <li><b>Per-Job Mode</b>: runs the cluster exclusively for one job. The job main method (or client) runs only prior to the cluster creation.</li>\n+                </ul>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2091ef6d8bc44d6b1381b2818e3a00c055641aac"}, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDQzMjQzOA==", "bodyText": "Naturally, I would put the Standalone option as the one a beginner would try first. Therefore, I would expect this option to be listed on the top of this enumeration.", "url": "https://github.com/apache/flink/pull/14222#discussion_r530432438", "createdAt": "2020-11-25T14:53:55Z", "author": {"login": "XComp"}, "path": "docs/ops/deployment/overview.md", "diffHunk": "@@ -0,0 +1,358 @@\n+---\n+title: \"Clusters & Deployment\"\n+nav-id: deployment\n+nav-parent_id: ops\n+nav-pos: 1\n+nav-show_overview: true\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+Flink is a versatile framework, supporting many different deployment scenarios in a mix and match fashion.\n+\n+Below, we briefly explain the building blocks of a Flink cluster, their purpose and available implementations.\n+If you just want to start Flink locally, we recommend setting up a [Standalone Cluster]({% link ops/deployment/local.md %}).\n+\n+* This will be replaced by the TOC\n+{:toc}\n+\n+\n+## Overview and Reference Architecture\n+\n+The figure below shows the building blocks of every Flink cluster. There is always somewhere a client running. It takes the code of the Flink applications, transforms it into a job graph and submits it to the JobManager.\n+\n+The JobManager distributes the work onto the TaskManagers, where the actual operators (such as sources, transformations and sinks) are running.\n+\n+When deploying Flink, there are often multiple options available for each building block. We have listed them in the table below the figure.\n+\n+If you don't know where to start, we recommend using the Command Line Interface for submitting Flink applications to a Standalone Cluster.\n+\n+<!-- Image source: https://docs.google.com/drawings/d/1s_ZlXXvADqxWfTMNRVwQeg7HZ3hN1Xb7goxDPjTEPrI/edit?usp=sharing -->\n+<img width=\"100%\" src=\"{% link fig/deployment_overview.svg %}\" alt=\"Figure for Overview and Reference Architecture\" />\n+\n+\n+<table class=\"table table-bordered\">\n+  <thead>\n+    <tr>\n+      <th class=\"text-left\" style=\"width: 25%\">Component</th>\n+      <th class=\"text-left\" style=\"width: 50%\">Purpose</th>\n+      <th class=\"text-left\">Implementations</th>\n+    </tr>\n+   </thead>\n+   <tbody>\n+        <tr>\n+            <td>Flink Client</td>\n+            <td>\n+              Flink batch or streaming applications are compiled into a dataflow graph, which is submitted to the JobManager.\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Command Line Interface</a></li>\n+                    <li><a href=\"\">REST Endpoint</a></li>\n+                    <li><a href=\"\">SQL Client</a></li>\n+                    <li><a href=\"\">Python REPL</a></li>\n+                    <li><a href=\"\">Scala REPL</a></li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>JobManager</td>\n+            <td>\n+                JobManager is the name of the central work coordination component of Flink. It has implementations for different resource providers, which differ on high-availability, resource allocation behavior and supported job submission modes. <br />\n+                JobManager <a href=\"\">modes for job submissions</a>:\n+                <ul>\n+                    <li><b>Session Mode</b>: one JobManager instance manages multiple jobs sharing the same cluster of TaskManagers</li>\n+                    <li><b>Application Mode</b>: runs the cluster exclusively for one job. The job main method (or client) gets executed on the JobManager.</li>\n+                    <li><b>Per-Job Mode</b>: runs the cluster exclusively for one job. The job main method (or client) runs only prior to the cluster creation.</li>\n+                </ul>\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Kubernetes</a></li>\n+                    <li><a href=\"\">YARN</a></li>\n+                    <li><a href=\"\">Mesos</a></li>\n+                    <li><a href=\"\">Standalone</a> (this is the barebone mode that requires just JVMs to be launched. Deployment with Docker, Docker Swarm / Compose, non-native Kubernetes and other models is possible through manual setup in this mode)\n+                    </li>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2091ef6d8bc44d6b1381b2818e3a00c055641aac"}, "originalPosition": 91}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDQzNDk1Ng==", "bodyText": "Aren't we missing the TaskManager in this table?", "url": "https://github.com/apache/flink/pull/14222#discussion_r530434956", "createdAt": "2020-11-25T14:57:07Z", "author": {"login": "XComp"}, "path": "docs/ops/deployment/overview.md", "diffHunk": "@@ -0,0 +1,358 @@\n+---\n+title: \"Clusters & Deployment\"\n+nav-id: deployment\n+nav-parent_id: ops\n+nav-pos: 1\n+nav-show_overview: true\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+Flink is a versatile framework, supporting many different deployment scenarios in a mix and match fashion.\n+\n+Below, we briefly explain the building blocks of a Flink cluster, their purpose and available implementations.\n+If you just want to start Flink locally, we recommend setting up a [Standalone Cluster]({% link ops/deployment/local.md %}).\n+\n+* This will be replaced by the TOC\n+{:toc}\n+\n+\n+## Overview and Reference Architecture\n+\n+The figure below shows the building blocks of every Flink cluster. There is always somewhere a client running. It takes the code of the Flink applications, transforms it into a job graph and submits it to the JobManager.\n+\n+The JobManager distributes the work onto the TaskManagers, where the actual operators (such as sources, transformations and sinks) are running.\n+\n+When deploying Flink, there are often multiple options available for each building block. We have listed them in the table below the figure.\n+\n+If you don't know where to start, we recommend using the Command Line Interface for submitting Flink applications to a Standalone Cluster.\n+\n+<!-- Image source: https://docs.google.com/drawings/d/1s_ZlXXvADqxWfTMNRVwQeg7HZ3hN1Xb7goxDPjTEPrI/edit?usp=sharing -->\n+<img width=\"100%\" src=\"{% link fig/deployment_overview.svg %}\" alt=\"Figure for Overview and Reference Architecture\" />\n+\n+\n+<table class=\"table table-bordered\">", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2091ef6d8bc44d6b1381b2818e3a00c055641aac"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDQ4ODYwMg==", "bodyText": "Could we match the order of the job submission modes of the picture and the sections below?", "url": "https://github.com/apache/flink/pull/14222#discussion_r530488602", "createdAt": "2020-11-25T16:10:34Z", "author": {"login": "XComp"}, "path": "docs/ops/deployment/overview.md", "diffHunk": "@@ -0,0 +1,358 @@\n+---\n+title: \"Clusters & Deployment\"\n+nav-id: deployment\n+nav-parent_id: ops\n+nav-pos: 1\n+nav-show_overview: true\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+Flink is a versatile framework, supporting many different deployment scenarios in a mix and match fashion.\n+\n+Below, we briefly explain the building blocks of a Flink cluster, their purpose and available implementations.\n+If you just want to start Flink locally, we recommend setting up a [Standalone Cluster]({% link ops/deployment/local.md %}).\n+\n+* This will be replaced by the TOC\n+{:toc}\n+\n+\n+## Overview and Reference Architecture\n+\n+The figure below shows the building blocks of every Flink cluster. There is always somewhere a client running. It takes the code of the Flink applications, transforms it into a job graph and submits it to the JobManager.\n+\n+The JobManager distributes the work onto the TaskManagers, where the actual operators (such as sources, transformations and sinks) are running.\n+\n+When deploying Flink, there are often multiple options available for each building block. We have listed them in the table below the figure.\n+\n+If you don't know where to start, we recommend using the Command Line Interface for submitting Flink applications to a Standalone Cluster.\n+\n+<!-- Image source: https://docs.google.com/drawings/d/1s_ZlXXvADqxWfTMNRVwQeg7HZ3hN1Xb7goxDPjTEPrI/edit?usp=sharing -->\n+<img width=\"100%\" src=\"{% link fig/deployment_overview.svg %}\" alt=\"Figure for Overview and Reference Architecture\" />\n+\n+\n+<table class=\"table table-bordered\">\n+  <thead>\n+    <tr>\n+      <th class=\"text-left\" style=\"width: 25%\">Component</th>\n+      <th class=\"text-left\" style=\"width: 50%\">Purpose</th>\n+      <th class=\"text-left\">Implementations</th>\n+    </tr>\n+   </thead>\n+   <tbody>\n+        <tr>\n+            <td>Flink Client</td>\n+            <td>\n+              Flink batch or streaming applications are compiled into a dataflow graph, which is submitted to the JobManager.\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Command Line Interface</a></li>\n+                    <li><a href=\"\">REST Endpoint</a></li>\n+                    <li><a href=\"\">SQL Client</a></li>\n+                    <li><a href=\"\">Python REPL</a></li>\n+                    <li><a href=\"\">Scala REPL</a></li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>JobManager</td>\n+            <td>\n+                JobManager is the name of the central work coordination component of Flink. It has implementations for different resource providers, which differ on high-availability, resource allocation behavior and supported job submission modes. <br />\n+                JobManager <a href=\"\">modes for job submissions</a>:\n+                <ul>\n+                    <li><b>Session Mode</b>: one JobManager instance manages multiple jobs sharing the same cluster of TaskManagers</li>\n+                    <li><b>Application Mode</b>: runs the cluster exclusively for one job. The job main method (or client) gets executed on the JobManager.</li>\n+                    <li><b>Per-Job Mode</b>: runs the cluster exclusively for one job. The job main method (or client) runs only prior to the cluster creation.</li>\n+                </ul>\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Kubernetes</a></li>\n+                    <li><a href=\"\">YARN</a></li>\n+                    <li><a href=\"\">Mesos</a></li>\n+                    <li><a href=\"\">Standalone</a> (this is the barebone mode that requires just JVMs to be launched. Deployment with Docker, Docker Swarm / Compose, non-native Kubernetes and other models is possible through manual setup in this mode)\n+                    </li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td colspan=\"3\" class=\"text-center\">\n+                <b>External Components</b> (all optional)\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>High Availability Service Provider</td>\n+            <td>\n+                Flink\u2019s JobManager supports a high availability mode, where multiple JobManagers participate in a leader election process, resulting in an active JobManager and potentially multiple standby JobManagers, allowing for fast failover in case the active JobManager is lost.\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Zookeeper</a></li>\n+                    <li><a href=\"\">Kubernetes HA</a></li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>File Storage and Persistency</td>\n+            <td>\n+                For checkpointing (recovery mechanism for streaming jobs) Flink relies on external file storage systems\n+            </td>\n+            <td>See <a href=\"\">FileSystems</a> page.</td>\n+        </tr>\n+        <tr>\n+            <td>Resource Provider</td>\n+            <td>\n+                Flink can be deployed through different Resource Provider Frameworks, such as Kubernetes, YARN or Mesos.\n+            </td>\n+            <td>See \"JobManager\" implementations above.</td>\n+        </tr>\n+        <tr>\n+            <td>Metrics Storage</td>\n+            <td>\n+                Flink components report internal metrics and Flink jobs can report additional, job specific metrics as well.\n+            </td>\n+            <td>See <a href=\"\">Metrics Reporter</a> page.</td>\n+        </tr>\n+        <tr>\n+            <td>Application-level data sources and sinks</td>\n+            <td>\n+                While application-level data sources and sinks are not technically part of the deployment of Flink cluster components, they should be considered when planning a new Flink production deployment. Colocating frequently used data with Flink can have significant performance benefits\n+            </td>\n+            <td>\n+                For example:\n+                <ul>\n+                    <li>Apache Kafka</li>\n+                    <li>Amazon S3</li>\n+                    <li>ElasticSearch</li>\n+                    <li>Apache Cassandra</li>\n+                </ul>\n+                See <a href=\"\">Connectors</a> page.\n+            </td>\n+        </tr>\n+    </tbody>\n+</table>\n+\n+\n+\n+## Deployment Modes\n+\n+Flink can execute applications in one of three ways:\n+ - in Session Mode, \n+ - in a Per-Job Mode, or\n+ - in Application Mode.\n+\n+ The above modes differ in:\n+ - the cluster lifecycle and resource isolation guarantees\n+ - whether the application's `main()` method is executed on the client or on the cluster.\n+\n+\n+\n+<!-- Image source: https://docs.google.com/drawings/d/1EfloufuOp1A7YDwZmBEsHKRLIrrbtRkoWRPcfZI5RYQ/edit?usp=sharing -->\n+<img width=\"100%\" src=\"{% link fig/deployment_modes.svg %}\" alt=\"Figure for Deployment Modes\" />", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2091ef6d8bc44d6b1381b2818e3a00c055641aac"}, "originalPosition": 168}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDQ4OTQwMw==", "bodyText": "We should name these things in the same way where possible: The overview calls this the \"job submission modes\".", "url": "https://github.com/apache/flink/pull/14222#discussion_r530489403", "createdAt": "2020-11-25T16:11:48Z", "author": {"login": "XComp"}, "path": "docs/ops/deployment/overview.md", "diffHunk": "@@ -0,0 +1,358 @@\n+---\n+title: \"Clusters & Deployment\"\n+nav-id: deployment\n+nav-parent_id: ops\n+nav-pos: 1\n+nav-show_overview: true\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+Flink is a versatile framework, supporting many different deployment scenarios in a mix and match fashion.\n+\n+Below, we briefly explain the building blocks of a Flink cluster, their purpose and available implementations.\n+If you just want to start Flink locally, we recommend setting up a [Standalone Cluster]({% link ops/deployment/local.md %}).\n+\n+* This will be replaced by the TOC\n+{:toc}\n+\n+\n+## Overview and Reference Architecture\n+\n+The figure below shows the building blocks of every Flink cluster. There is always somewhere a client running. It takes the code of the Flink applications, transforms it into a job graph and submits it to the JobManager.\n+\n+The JobManager distributes the work onto the TaskManagers, where the actual operators (such as sources, transformations and sinks) are running.\n+\n+When deploying Flink, there are often multiple options available for each building block. We have listed them in the table below the figure.\n+\n+If you don't know where to start, we recommend using the Command Line Interface for submitting Flink applications to a Standalone Cluster.\n+\n+<!-- Image source: https://docs.google.com/drawings/d/1s_ZlXXvADqxWfTMNRVwQeg7HZ3hN1Xb7goxDPjTEPrI/edit?usp=sharing -->\n+<img width=\"100%\" src=\"{% link fig/deployment_overview.svg %}\" alt=\"Figure for Overview and Reference Architecture\" />\n+\n+\n+<table class=\"table table-bordered\">\n+  <thead>\n+    <tr>\n+      <th class=\"text-left\" style=\"width: 25%\">Component</th>\n+      <th class=\"text-left\" style=\"width: 50%\">Purpose</th>\n+      <th class=\"text-left\">Implementations</th>\n+    </tr>\n+   </thead>\n+   <tbody>\n+        <tr>\n+            <td>Flink Client</td>\n+            <td>\n+              Flink batch or streaming applications are compiled into a dataflow graph, which is submitted to the JobManager.\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Command Line Interface</a></li>\n+                    <li><a href=\"\">REST Endpoint</a></li>\n+                    <li><a href=\"\">SQL Client</a></li>\n+                    <li><a href=\"\">Python REPL</a></li>\n+                    <li><a href=\"\">Scala REPL</a></li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>JobManager</td>\n+            <td>\n+                JobManager is the name of the central work coordination component of Flink. It has implementations for different resource providers, which differ on high-availability, resource allocation behavior and supported job submission modes. <br />\n+                JobManager <a href=\"\">modes for job submissions</a>:\n+                <ul>\n+                    <li><b>Session Mode</b>: one JobManager instance manages multiple jobs sharing the same cluster of TaskManagers</li>\n+                    <li><b>Application Mode</b>: runs the cluster exclusively for one job. The job main method (or client) gets executed on the JobManager.</li>\n+                    <li><b>Per-Job Mode</b>: runs the cluster exclusively for one job. The job main method (or client) runs only prior to the cluster creation.</li>\n+                </ul>\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Kubernetes</a></li>\n+                    <li><a href=\"\">YARN</a></li>\n+                    <li><a href=\"\">Mesos</a></li>\n+                    <li><a href=\"\">Standalone</a> (this is the barebone mode that requires just JVMs to be launched. Deployment with Docker, Docker Swarm / Compose, non-native Kubernetes and other models is possible through manual setup in this mode)\n+                    </li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td colspan=\"3\" class=\"text-center\">\n+                <b>External Components</b> (all optional)\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>High Availability Service Provider</td>\n+            <td>\n+                Flink\u2019s JobManager supports a high availability mode, where multiple JobManagers participate in a leader election process, resulting in an active JobManager and potentially multiple standby JobManagers, allowing for fast failover in case the active JobManager is lost.\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Zookeeper</a></li>\n+                    <li><a href=\"\">Kubernetes HA</a></li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>File Storage and Persistency</td>\n+            <td>\n+                For checkpointing (recovery mechanism for streaming jobs) Flink relies on external file storage systems\n+            </td>\n+            <td>See <a href=\"\">FileSystems</a> page.</td>\n+        </tr>\n+        <tr>\n+            <td>Resource Provider</td>\n+            <td>\n+                Flink can be deployed through different Resource Provider Frameworks, such as Kubernetes, YARN or Mesos.\n+            </td>\n+            <td>See \"JobManager\" implementations above.</td>\n+        </tr>\n+        <tr>\n+            <td>Metrics Storage</td>\n+            <td>\n+                Flink components report internal metrics and Flink jobs can report additional, job specific metrics as well.\n+            </td>\n+            <td>See <a href=\"\">Metrics Reporter</a> page.</td>\n+        </tr>\n+        <tr>\n+            <td>Application-level data sources and sinks</td>\n+            <td>\n+                While application-level data sources and sinks are not technically part of the deployment of Flink cluster components, they should be considered when planning a new Flink production deployment. Colocating frequently used data with Flink can have significant performance benefits\n+            </td>\n+            <td>\n+                For example:\n+                <ul>\n+                    <li>Apache Kafka</li>\n+                    <li>Amazon S3</li>\n+                    <li>ElasticSearch</li>\n+                    <li>Apache Cassandra</li>\n+                </ul>\n+                See <a href=\"\">Connectors</a> page.\n+            </td>\n+        </tr>\n+    </tbody>\n+</table>\n+\n+\n+\n+## Deployment Modes", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2091ef6d8bc44d6b1381b2818e3a00c055641aac"}, "originalPosition": 154}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDQ5NDYyOA==", "bodyText": "That's personal taste now, but: Could we have a bit of margin around this picture here? :-)", "url": "https://github.com/apache/flink/pull/14222#discussion_r530494628", "createdAt": "2020-11-25T16:19:22Z", "author": {"login": "XComp"}, "path": "docs/ops/deployment/overview.md", "diffHunk": "@@ -0,0 +1,358 @@\n+---\n+title: \"Clusters & Deployment\"\n+nav-id: deployment\n+nav-parent_id: ops\n+nav-pos: 1\n+nav-show_overview: true\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+Flink is a versatile framework, supporting many different deployment scenarios in a mix and match fashion.\n+\n+Below, we briefly explain the building blocks of a Flink cluster, their purpose and available implementations.\n+If you just want to start Flink locally, we recommend setting up a [Standalone Cluster]({% link ops/deployment/local.md %}).\n+\n+* This will be replaced by the TOC\n+{:toc}\n+\n+\n+## Overview and Reference Architecture\n+\n+The figure below shows the building blocks of every Flink cluster. There is always somewhere a client running. It takes the code of the Flink applications, transforms it into a job graph and submits it to the JobManager.\n+\n+The JobManager distributes the work onto the TaskManagers, where the actual operators (such as sources, transformations and sinks) are running.\n+\n+When deploying Flink, there are often multiple options available for each building block. We have listed them in the table below the figure.\n+\n+If you don't know where to start, we recommend using the Command Line Interface for submitting Flink applications to a Standalone Cluster.\n+\n+<!-- Image source: https://docs.google.com/drawings/d/1s_ZlXXvADqxWfTMNRVwQeg7HZ3hN1Xb7goxDPjTEPrI/edit?usp=sharing -->\n+<img width=\"100%\" src=\"{% link fig/deployment_overview.svg %}\" alt=\"Figure for Overview and Reference Architecture\" />", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2091ef6d8bc44d6b1381b2818e3a00c055641aac"}, "originalPosition": 47}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM5NDUwOTgw", "url": "https://github.com/apache/flink/pull/14222#pullrequestreview-539450980", "createdAt": "2020-11-26T16:31:58Z", "commit": {"oid": "2091ef6d8bc44d6b1381b2818e3a00c055641aac"}, "state": "APPROVED", "comments": {"totalCount": 22, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQxNjozMTo1OFrOH6iA5g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQxNzo1NDo1OFrOH6kJHg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTEzNjc0Mg==", "bodyText": "Could we maybe ask marketing to help us with beautifying this picture?", "url": "https://github.com/apache/flink/pull/14222#discussion_r531136742", "createdAt": "2020-11-26T16:31:58Z", "author": {"login": "tillrohrmann"}, "path": "docs/ops/deployment/overview.md", "diffHunk": "@@ -0,0 +1,358 @@\n+---\n+title: \"Clusters & Deployment\"\n+nav-id: deployment\n+nav-parent_id: ops\n+nav-pos: 1\n+nav-show_overview: true\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+Flink is a versatile framework, supporting many different deployment scenarios in a mix and match fashion.\n+\n+Below, we briefly explain the building blocks of a Flink cluster, their purpose and available implementations.\n+If you just want to start Flink locally, we recommend setting up a [Standalone Cluster]({% link ops/deployment/local.md %}).\n+\n+* This will be replaced by the TOC\n+{:toc}\n+\n+\n+## Overview and Reference Architecture\n+\n+The figure below shows the building blocks of every Flink cluster. There is always somewhere a client running. It takes the code of the Flink applications, transforms it into a job graph and submits it to the JobManager.\n+\n+The JobManager distributes the work onto the TaskManagers, where the actual operators (such as sources, transformations and sinks) are running.\n+\n+When deploying Flink, there are often multiple options available for each building block. We have listed them in the table below the figure.\n+\n+If you don't know where to start, we recommend using the Command Line Interface for submitting Flink applications to a Standalone Cluster.\n+\n+<!-- Image source: https://docs.google.com/drawings/d/1s_ZlXXvADqxWfTMNRVwQeg7HZ3hN1Xb7goxDPjTEPrI/edit?usp=sharing -->\n+<img width=\"100%\" src=\"{% link fig/deployment_overview.svg %}\" alt=\"Figure for Overview and Reference Architecture\" />", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDQ5NDYyOA=="}, "originalCommit": {"oid": "2091ef6d8bc44d6b1381b2818e3a00c055641aac"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTEzNzEzMg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            If you just want to start Flink locally, we recommend setting up a [Standalone Cluster]({% link ops/deployment/local.md %}).\n          \n          \n            \n            If you just want to start Flink locally, we recommend setting up a [Standalone Cluster]({% link deployment/resource-providers/standalone/index.md %}).", "url": "https://github.com/apache/flink/pull/14222#discussion_r531137132", "createdAt": "2020-11-26T16:32:44Z", "author": {"login": "tillrohrmann"}, "path": "docs/ops/deployment/overview.md", "diffHunk": "@@ -0,0 +1,358 @@\n+---\n+title: \"Clusters & Deployment\"\n+nav-id: deployment\n+nav-parent_id: ops\n+nav-pos: 1\n+nav-show_overview: true\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+Flink is a versatile framework, supporting many different deployment scenarios in a mix and match fashion.\n+\n+Below, we briefly explain the building blocks of a Flink cluster, their purpose and available implementations.\n+If you just want to start Flink locally, we recommend setting up a [Standalone Cluster]({% link ops/deployment/local.md %}).", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2091ef6d8bc44d6b1381b2818e3a00c055641aac"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTEzNzQwMQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            The figure below shows the building blocks of every Flink cluster. There is always somewhere a client running. It takes the code of the Flink applications, transforms it into a job graph and submits it to the JobManager.\n          \n          \n            \n            The figure below shows the building blocks of every Flink cluster. There is always somewhere a client running. It takes the code of the Flink applications, transforms it into a `JobGraph` and submits it to the `JobManager`.", "url": "https://github.com/apache/flink/pull/14222#discussion_r531137401", "createdAt": "2020-11-26T16:33:21Z", "author": {"login": "tillrohrmann"}, "path": "docs/ops/deployment/overview.md", "diffHunk": "@@ -0,0 +1,358 @@\n+---\n+title: \"Clusters & Deployment\"\n+nav-id: deployment\n+nav-parent_id: ops\n+nav-pos: 1\n+nav-show_overview: true\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+Flink is a versatile framework, supporting many different deployment scenarios in a mix and match fashion.\n+\n+Below, we briefly explain the building blocks of a Flink cluster, their purpose and available implementations.\n+If you just want to start Flink locally, we recommend setting up a [Standalone Cluster]({% link ops/deployment/local.md %}).\n+\n+* This will be replaced by the TOC\n+{:toc}\n+\n+\n+## Overview and Reference Architecture\n+\n+The figure below shows the building blocks of every Flink cluster. There is always somewhere a client running. It takes the code of the Flink applications, transforms it into a job graph and submits it to the JobManager.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2091ef6d8bc44d6b1381b2818e3a00c055641aac"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTEzNzYwMw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            The JobManager distributes the work onto the TaskManagers, where the actual operators (such as sources, transformations and sinks) are running.\n          \n          \n            \n            The `JobManager` distributes the work onto the `TaskManagers`, where the actual operators (such as sources, transformations and sinks) are running.", "url": "https://github.com/apache/flink/pull/14222#discussion_r531137603", "createdAt": "2020-11-26T16:33:48Z", "author": {"login": "tillrohrmann"}, "path": "docs/ops/deployment/overview.md", "diffHunk": "@@ -0,0 +1,358 @@\n+---\n+title: \"Clusters & Deployment\"\n+nav-id: deployment\n+nav-parent_id: ops\n+nav-pos: 1\n+nav-show_overview: true\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+Flink is a versatile framework, supporting many different deployment scenarios in a mix and match fashion.\n+\n+Below, we briefly explain the building blocks of a Flink cluster, their purpose and available implementations.\n+If you just want to start Flink locally, we recommend setting up a [Standalone Cluster]({% link ops/deployment/local.md %}).\n+\n+* This will be replaced by the TOC\n+{:toc}\n+\n+\n+## Overview and Reference Architecture\n+\n+The figure below shows the building blocks of every Flink cluster. There is always somewhere a client running. It takes the code of the Flink applications, transforms it into a job graph and submits it to the JobManager.\n+\n+The JobManager distributes the work onto the TaskManagers, where the actual operators (such as sources, transformations and sinks) are running.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2091ef6d8bc44d6b1381b2818e3a00c055641aac"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTEzODIxNA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            If you don't know where to start, we recommend using the Command Line Interface for submitting Flink applications to a Standalone Cluster.\n          \n          \n            \n            If you don't know where to start, we recommend using the [Command Line Interface]({% link deployment/cli.md %}) for submitting Flink applications to a Standalone Cluster.", "url": "https://github.com/apache/flink/pull/14222#discussion_r531138214", "createdAt": "2020-11-26T16:35:05Z", "author": {"login": "tillrohrmann"}, "path": "docs/ops/deployment/overview.md", "diffHunk": "@@ -0,0 +1,358 @@\n+---\n+title: \"Clusters & Deployment\"\n+nav-id: deployment\n+nav-parent_id: ops\n+nav-pos: 1\n+nav-show_overview: true\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+Flink is a versatile framework, supporting many different deployment scenarios in a mix and match fashion.\n+\n+Below, we briefly explain the building blocks of a Flink cluster, their purpose and available implementations.\n+If you just want to start Flink locally, we recommend setting up a [Standalone Cluster]({% link ops/deployment/local.md %}).\n+\n+* This will be replaced by the TOC\n+{:toc}\n+\n+\n+## Overview and Reference Architecture\n+\n+The figure below shows the building blocks of every Flink cluster. There is always somewhere a client running. It takes the code of the Flink applications, transforms it into a job graph and submits it to the JobManager.\n+\n+The JobManager distributes the work onto the TaskManagers, where the actual operators (such as sources, transformations and sinks) are running.\n+\n+When deploying Flink, there are often multiple options available for each building block. We have listed them in the table below the figure.\n+\n+If you don't know where to start, we recommend using the Command Line Interface for submitting Flink applications to a Standalone Cluster.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2091ef6d8bc44d6b1381b2818e3a00c055641aac"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE2MTgxNA==", "bodyText": "Maybe\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                          Flink batch or streaming applications are compiled into a dataflow graph, which is submitted to the JobManager.\n          \n          \n            \n                          Compiles batch or streaming applications into a dataflow graph, which it then submits to the JobManager.", "url": "https://github.com/apache/flink/pull/14222#discussion_r531161814", "createdAt": "2020-11-26T17:28:11Z", "author": {"login": "tillrohrmann"}, "path": "docs/ops/deployment/overview.md", "diffHunk": "@@ -0,0 +1,358 @@\n+---\n+title: \"Clusters & Deployment\"\n+nav-id: deployment\n+nav-parent_id: ops\n+nav-pos: 1\n+nav-show_overview: true\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+Flink is a versatile framework, supporting many different deployment scenarios in a mix and match fashion.\n+\n+Below, we briefly explain the building blocks of a Flink cluster, their purpose and available implementations.\n+If you just want to start Flink locally, we recommend setting up a [Standalone Cluster]({% link ops/deployment/local.md %}).\n+\n+* This will be replaced by the TOC\n+{:toc}\n+\n+\n+## Overview and Reference Architecture\n+\n+The figure below shows the building blocks of every Flink cluster. There is always somewhere a client running. It takes the code of the Flink applications, transforms it into a job graph and submits it to the JobManager.\n+\n+The JobManager distributes the work onto the TaskManagers, where the actual operators (such as sources, transformations and sinks) are running.\n+\n+When deploying Flink, there are often multiple options available for each building block. We have listed them in the table below the figure.\n+\n+If you don't know where to start, we recommend using the Command Line Interface for submitting Flink applications to a Standalone Cluster.\n+\n+<!-- Image source: https://docs.google.com/drawings/d/1s_ZlXXvADqxWfTMNRVwQeg7HZ3hN1Xb7goxDPjTEPrI/edit?usp=sharing -->\n+<img width=\"100%\" src=\"{% link fig/deployment_overview.svg %}\" alt=\"Figure for Overview and Reference Architecture\" />\n+\n+\n+<table class=\"table table-bordered\">\n+  <thead>\n+    <tr>\n+      <th class=\"text-left\" style=\"width: 25%\">Component</th>\n+      <th class=\"text-left\" style=\"width: 50%\">Purpose</th>\n+      <th class=\"text-left\">Implementations</th>\n+    </tr>\n+   </thead>\n+   <tbody>\n+        <tr>\n+            <td>Flink Client</td>\n+            <td>\n+              Flink batch or streaming applications are compiled into a dataflow graph, which is submitted to the JobManager.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2091ef6d8bc44d6b1381b2818e3a00c055641aac"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE2MTkwNw==", "bodyText": "links are missing.", "url": "https://github.com/apache/flink/pull/14222#discussion_r531161907", "createdAt": "2020-11-26T17:28:29Z", "author": {"login": "tillrohrmann"}, "path": "docs/ops/deployment/overview.md", "diffHunk": "@@ -0,0 +1,358 @@\n+---\n+title: \"Clusters & Deployment\"\n+nav-id: deployment\n+nav-parent_id: ops\n+nav-pos: 1\n+nav-show_overview: true\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+Flink is a versatile framework, supporting many different deployment scenarios in a mix and match fashion.\n+\n+Below, we briefly explain the building blocks of a Flink cluster, their purpose and available implementations.\n+If you just want to start Flink locally, we recommend setting up a [Standalone Cluster]({% link ops/deployment/local.md %}).\n+\n+* This will be replaced by the TOC\n+{:toc}\n+\n+\n+## Overview and Reference Architecture\n+\n+The figure below shows the building blocks of every Flink cluster. There is always somewhere a client running. It takes the code of the Flink applications, transforms it into a job graph and submits it to the JobManager.\n+\n+The JobManager distributes the work onto the TaskManagers, where the actual operators (such as sources, transformations and sinks) are running.\n+\n+When deploying Flink, there are often multiple options available for each building block. We have listed them in the table below the figure.\n+\n+If you don't know where to start, we recommend using the Command Line Interface for submitting Flink applications to a Standalone Cluster.\n+\n+<!-- Image source: https://docs.google.com/drawings/d/1s_ZlXXvADqxWfTMNRVwQeg7HZ3hN1Xb7goxDPjTEPrI/edit?usp=sharing -->\n+<img width=\"100%\" src=\"{% link fig/deployment_overview.svg %}\" alt=\"Figure for Overview and Reference Architecture\" />\n+\n+\n+<table class=\"table table-bordered\">\n+  <thead>\n+    <tr>\n+      <th class=\"text-left\" style=\"width: 25%\">Component</th>\n+      <th class=\"text-left\" style=\"width: 50%\">Purpose</th>\n+      <th class=\"text-left\">Implementations</th>\n+    </tr>\n+   </thead>\n+   <tbody>\n+        <tr>\n+            <td>Flink Client</td>\n+            <td>\n+              Flink batch or streaming applications are compiled into a dataflow graph, which is submitted to the JobManager.\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Command Line Interface</a></li>\n+                    <li><a href=\"\">REST Endpoint</a></li>\n+                    <li><a href=\"\">SQL Client</a></li>\n+                    <li><a href=\"\">Python REPL</a></li>\n+                    <li><a href=\"\">Scala REPL</a></li>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2091ef6d8bc44d6b1381b2818e3a00c055641aac"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE2MjM3NA==", "bodyText": "I'd suggest to put session mode last.", "url": "https://github.com/apache/flink/pull/14222#discussion_r531162374", "createdAt": "2020-11-26T17:29:38Z", "author": {"login": "tillrohrmann"}, "path": "docs/ops/deployment/overview.md", "diffHunk": "@@ -0,0 +1,358 @@\n+---\n+title: \"Clusters & Deployment\"\n+nav-id: deployment\n+nav-parent_id: ops\n+nav-pos: 1\n+nav-show_overview: true\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+Flink is a versatile framework, supporting many different deployment scenarios in a mix and match fashion.\n+\n+Below, we briefly explain the building blocks of a Flink cluster, their purpose and available implementations.\n+If you just want to start Flink locally, we recommend setting up a [Standalone Cluster]({% link ops/deployment/local.md %}).\n+\n+* This will be replaced by the TOC\n+{:toc}\n+\n+\n+## Overview and Reference Architecture\n+\n+The figure below shows the building blocks of every Flink cluster. There is always somewhere a client running. It takes the code of the Flink applications, transforms it into a job graph and submits it to the JobManager.\n+\n+The JobManager distributes the work onto the TaskManagers, where the actual operators (such as sources, transformations and sinks) are running.\n+\n+When deploying Flink, there are often multiple options available for each building block. We have listed them in the table below the figure.\n+\n+If you don't know where to start, we recommend using the Command Line Interface for submitting Flink applications to a Standalone Cluster.\n+\n+<!-- Image source: https://docs.google.com/drawings/d/1s_ZlXXvADqxWfTMNRVwQeg7HZ3hN1Xb7goxDPjTEPrI/edit?usp=sharing -->\n+<img width=\"100%\" src=\"{% link fig/deployment_overview.svg %}\" alt=\"Figure for Overview and Reference Architecture\" />\n+\n+\n+<table class=\"table table-bordered\">\n+  <thead>\n+    <tr>\n+      <th class=\"text-left\" style=\"width: 25%\">Component</th>\n+      <th class=\"text-left\" style=\"width: 50%\">Purpose</th>\n+      <th class=\"text-left\">Implementations</th>\n+    </tr>\n+   </thead>\n+   <tbody>\n+        <tr>\n+            <td>Flink Client</td>\n+            <td>\n+              Flink batch or streaming applications are compiled into a dataflow graph, which is submitted to the JobManager.\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Command Line Interface</a></li>\n+                    <li><a href=\"\">REST Endpoint</a></li>\n+                    <li><a href=\"\">SQL Client</a></li>\n+                    <li><a href=\"\">Python REPL</a></li>\n+                    <li><a href=\"\">Scala REPL</a></li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>JobManager</td>\n+            <td>\n+                JobManager is the name of the central work coordination component of Flink. It has implementations for different resource providers, which differ on high-availability, resource allocation behavior and supported job submission modes. <br />\n+                JobManager <a href=\"\">modes for job submissions</a>:\n+                <ul>\n+                    <li><b>Session Mode</b>: one JobManager instance manages multiple jobs sharing the same cluster of TaskManagers</li>\n+                    <li><b>Application Mode</b>: runs the cluster exclusively for one job. The job main method (or client) gets executed on the JobManager.</li>\n+                    <li><b>Per-Job Mode</b>: runs the cluster exclusively for one job. The job main method (or client) runs only prior to the cluster creation.</li>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2091ef6d8bc44d6b1381b2818e3a00c055641aac"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE2MjQ2Mw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                <li><b>Application Mode</b>: runs the cluster exclusively for one job. The job main method (or client) gets executed on the JobManager.</li>\n          \n          \n            \n                                <li><b>Application Mode</b>: runs the cluster exclusively for one job. The job's main method (or client) gets executed on the JobManager.</li>", "url": "https://github.com/apache/flink/pull/14222#discussion_r531162463", "createdAt": "2020-11-26T17:29:51Z", "author": {"login": "tillrohrmann"}, "path": "docs/ops/deployment/overview.md", "diffHunk": "@@ -0,0 +1,358 @@\n+---\n+title: \"Clusters & Deployment\"\n+nav-id: deployment\n+nav-parent_id: ops\n+nav-pos: 1\n+nav-show_overview: true\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+Flink is a versatile framework, supporting many different deployment scenarios in a mix and match fashion.\n+\n+Below, we briefly explain the building blocks of a Flink cluster, their purpose and available implementations.\n+If you just want to start Flink locally, we recommend setting up a [Standalone Cluster]({% link ops/deployment/local.md %}).\n+\n+* This will be replaced by the TOC\n+{:toc}\n+\n+\n+## Overview and Reference Architecture\n+\n+The figure below shows the building blocks of every Flink cluster. There is always somewhere a client running. It takes the code of the Flink applications, transforms it into a job graph and submits it to the JobManager.\n+\n+The JobManager distributes the work onto the TaskManagers, where the actual operators (such as sources, transformations and sinks) are running.\n+\n+When deploying Flink, there are often multiple options available for each building block. We have listed them in the table below the figure.\n+\n+If you don't know where to start, we recommend using the Command Line Interface for submitting Flink applications to a Standalone Cluster.\n+\n+<!-- Image source: https://docs.google.com/drawings/d/1s_ZlXXvADqxWfTMNRVwQeg7HZ3hN1Xb7goxDPjTEPrI/edit?usp=sharing -->\n+<img width=\"100%\" src=\"{% link fig/deployment_overview.svg %}\" alt=\"Figure for Overview and Reference Architecture\" />\n+\n+\n+<table class=\"table table-bordered\">\n+  <thead>\n+    <tr>\n+      <th class=\"text-left\" style=\"width: 25%\">Component</th>\n+      <th class=\"text-left\" style=\"width: 50%\">Purpose</th>\n+      <th class=\"text-left\">Implementations</th>\n+    </tr>\n+   </thead>\n+   <tbody>\n+        <tr>\n+            <td>Flink Client</td>\n+            <td>\n+              Flink batch or streaming applications are compiled into a dataflow graph, which is submitted to the JobManager.\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Command Line Interface</a></li>\n+                    <li><a href=\"\">REST Endpoint</a></li>\n+                    <li><a href=\"\">SQL Client</a></li>\n+                    <li><a href=\"\">Python REPL</a></li>\n+                    <li><a href=\"\">Scala REPL</a></li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>JobManager</td>\n+            <td>\n+                JobManager is the name of the central work coordination component of Flink. It has implementations for different resource providers, which differ on high-availability, resource allocation behavior and supported job submission modes. <br />\n+                JobManager <a href=\"\">modes for job submissions</a>:\n+                <ul>\n+                    <li><b>Session Mode</b>: one JobManager instance manages multiple jobs sharing the same cluster of TaskManagers</li>\n+                    <li><b>Application Mode</b>: runs the cluster exclusively for one job. The job main method (or client) gets executed on the JobManager.</li>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2091ef6d8bc44d6b1381b2818e3a00c055641aac"}, "originalPosition": 81}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE2MjUyMA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                <li><b>Per-Job Mode</b>: runs the cluster exclusively for one job. The job main method (or client) runs only prior to the cluster creation.</li>\n          \n          \n            \n                                <li><b>Per-Job Mode</b>: runs the cluster exclusively for one job. The job's main method (or client) runs only prior to the cluster creation.</li>", "url": "https://github.com/apache/flink/pull/14222#discussion_r531162520", "createdAt": "2020-11-26T17:30:02Z", "author": {"login": "tillrohrmann"}, "path": "docs/ops/deployment/overview.md", "diffHunk": "@@ -0,0 +1,358 @@\n+---\n+title: \"Clusters & Deployment\"\n+nav-id: deployment\n+nav-parent_id: ops\n+nav-pos: 1\n+nav-show_overview: true\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+Flink is a versatile framework, supporting many different deployment scenarios in a mix and match fashion.\n+\n+Below, we briefly explain the building blocks of a Flink cluster, their purpose and available implementations.\n+If you just want to start Flink locally, we recommend setting up a [Standalone Cluster]({% link ops/deployment/local.md %}).\n+\n+* This will be replaced by the TOC\n+{:toc}\n+\n+\n+## Overview and Reference Architecture\n+\n+The figure below shows the building blocks of every Flink cluster. There is always somewhere a client running. It takes the code of the Flink applications, transforms it into a job graph and submits it to the JobManager.\n+\n+The JobManager distributes the work onto the TaskManagers, where the actual operators (such as sources, transformations and sinks) are running.\n+\n+When deploying Flink, there are often multiple options available for each building block. We have listed them in the table below the figure.\n+\n+If you don't know where to start, we recommend using the Command Line Interface for submitting Flink applications to a Standalone Cluster.\n+\n+<!-- Image source: https://docs.google.com/drawings/d/1s_ZlXXvADqxWfTMNRVwQeg7HZ3hN1Xb7goxDPjTEPrI/edit?usp=sharing -->\n+<img width=\"100%\" src=\"{% link fig/deployment_overview.svg %}\" alt=\"Figure for Overview and Reference Architecture\" />\n+\n+\n+<table class=\"table table-bordered\">\n+  <thead>\n+    <tr>\n+      <th class=\"text-left\" style=\"width: 25%\">Component</th>\n+      <th class=\"text-left\" style=\"width: 50%\">Purpose</th>\n+      <th class=\"text-left\">Implementations</th>\n+    </tr>\n+   </thead>\n+   <tbody>\n+        <tr>\n+            <td>Flink Client</td>\n+            <td>\n+              Flink batch or streaming applications are compiled into a dataflow graph, which is submitted to the JobManager.\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Command Line Interface</a></li>\n+                    <li><a href=\"\">REST Endpoint</a></li>\n+                    <li><a href=\"\">SQL Client</a></li>\n+                    <li><a href=\"\">Python REPL</a></li>\n+                    <li><a href=\"\">Scala REPL</a></li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>JobManager</td>\n+            <td>\n+                JobManager is the name of the central work coordination component of Flink. It has implementations for different resource providers, which differ on high-availability, resource allocation behavior and supported job submission modes. <br />\n+                JobManager <a href=\"\">modes for job submissions</a>:\n+                <ul>\n+                    <li><b>Session Mode</b>: one JobManager instance manages multiple jobs sharing the same cluster of TaskManagers</li>\n+                    <li><b>Application Mode</b>: runs the cluster exclusively for one job. The job main method (or client) gets executed on the JobManager.</li>\n+                    <li><b>Per-Job Mode</b>: runs the cluster exclusively for one job. The job main method (or client) runs only prior to the cluster creation.</li>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2091ef6d8bc44d6b1381b2818e3a00c055641aac"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE2Mjc1OA==", "bodyText": "Not sure about the backticks. If we decide to go this way, then it needs to be applied consistently throughout the whole document.", "url": "https://github.com/apache/flink/pull/14222#discussion_r531162758", "createdAt": "2020-11-26T17:30:34Z", "author": {"login": "tillrohrmann"}, "path": "docs/ops/deployment/overview.md", "diffHunk": "@@ -0,0 +1,358 @@\n+---\n+title: \"Clusters & Deployment\"\n+nav-id: deployment\n+nav-parent_id: ops\n+nav-pos: 1\n+nav-show_overview: true\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+Flink is a versatile framework, supporting many different deployment scenarios in a mix and match fashion.\n+\n+Below, we briefly explain the building blocks of a Flink cluster, their purpose and available implementations.\n+If you just want to start Flink locally, we recommend setting up a [Standalone Cluster]({% link ops/deployment/local.md %}).\n+\n+* This will be replaced by the TOC\n+{:toc}\n+\n+\n+## Overview and Reference Architecture\n+\n+The figure below shows the building blocks of every Flink cluster. There is always somewhere a client running. It takes the code of the Flink applications, transforms it into a job graph and submits it to the JobManager.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTEzNzQwMQ=="}, "originalCommit": {"oid": "2091ef6d8bc44d6b1381b2818e3a00c055641aac"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE2NTQ3MQ==", "bodyText": "Maybe: Flink's JobManager can be run in high availability mode which allows Flink to recover from JobManager faults. In order to failover faster, multiple standby JobManagers can be started to act as backups.", "url": "https://github.com/apache/flink/pull/14222#discussion_r531165471", "createdAt": "2020-11-26T17:37:38Z", "author": {"login": "tillrohrmann"}, "path": "docs/ops/deployment/overview.md", "diffHunk": "@@ -0,0 +1,358 @@\n+---\n+title: \"Clusters & Deployment\"\n+nav-id: deployment\n+nav-parent_id: ops\n+nav-pos: 1\n+nav-show_overview: true\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+Flink is a versatile framework, supporting many different deployment scenarios in a mix and match fashion.\n+\n+Below, we briefly explain the building blocks of a Flink cluster, their purpose and available implementations.\n+If you just want to start Flink locally, we recommend setting up a [Standalone Cluster]({% link ops/deployment/local.md %}).\n+\n+* This will be replaced by the TOC\n+{:toc}\n+\n+\n+## Overview and Reference Architecture\n+\n+The figure below shows the building blocks of every Flink cluster. There is always somewhere a client running. It takes the code of the Flink applications, transforms it into a job graph and submits it to the JobManager.\n+\n+The JobManager distributes the work onto the TaskManagers, where the actual operators (such as sources, transformations and sinks) are running.\n+\n+When deploying Flink, there are often multiple options available for each building block. We have listed them in the table below the figure.\n+\n+If you don't know where to start, we recommend using the Command Line Interface for submitting Flink applications to a Standalone Cluster.\n+\n+<!-- Image source: https://docs.google.com/drawings/d/1s_ZlXXvADqxWfTMNRVwQeg7HZ3hN1Xb7goxDPjTEPrI/edit?usp=sharing -->\n+<img width=\"100%\" src=\"{% link fig/deployment_overview.svg %}\" alt=\"Figure for Overview and Reference Architecture\" />\n+\n+\n+<table class=\"table table-bordered\">\n+  <thead>\n+    <tr>\n+      <th class=\"text-left\" style=\"width: 25%\">Component</th>\n+      <th class=\"text-left\" style=\"width: 50%\">Purpose</th>\n+      <th class=\"text-left\">Implementations</th>\n+    </tr>\n+   </thead>\n+   <tbody>\n+        <tr>\n+            <td>Flink Client</td>\n+            <td>\n+              Flink batch or streaming applications are compiled into a dataflow graph, which is submitted to the JobManager.\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Command Line Interface</a></li>\n+                    <li><a href=\"\">REST Endpoint</a></li>\n+                    <li><a href=\"\">SQL Client</a></li>\n+                    <li><a href=\"\">Python REPL</a></li>\n+                    <li><a href=\"\">Scala REPL</a></li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>JobManager</td>\n+            <td>\n+                JobManager is the name of the central work coordination component of Flink. It has implementations for different resource providers, which differ on high-availability, resource allocation behavior and supported job submission modes. <br />\n+                JobManager <a href=\"\">modes for job submissions</a>:\n+                <ul>\n+                    <li><b>Session Mode</b>: one JobManager instance manages multiple jobs sharing the same cluster of TaskManagers</li>\n+                    <li><b>Application Mode</b>: runs the cluster exclusively for one job. The job main method (or client) gets executed on the JobManager.</li>\n+                    <li><b>Per-Job Mode</b>: runs the cluster exclusively for one job. The job main method (or client) runs only prior to the cluster creation.</li>\n+                </ul>\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Kubernetes</a></li>\n+                    <li><a href=\"\">YARN</a></li>\n+                    <li><a href=\"\">Mesos</a></li>\n+                    <li><a href=\"\">Standalone</a> (this is the barebone mode that requires just JVMs to be launched. Deployment with Docker, Docker Swarm / Compose, non-native Kubernetes and other models is possible through manual setup in this mode)\n+                    </li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td colspan=\"3\" class=\"text-center\">\n+                <b>External Components</b> (all optional)\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>High Availability Service Provider</td>\n+            <td>\n+                Flink\u2019s JobManager supports a high availability mode, where multiple JobManagers participate in a leader election process, resulting in an active JobManager and potentially multiple standby JobManagers, allowing for fast failover in case the active JobManager is lost.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2091ef6d8bc44d6b1381b2818e3a00c055641aac"}, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE2NjA3OA==", "bodyText": "Maybe set anchor link if possible.", "url": "https://github.com/apache/flink/pull/14222#discussion_r531166078", "createdAt": "2020-11-26T17:39:26Z", "author": {"login": "tillrohrmann"}, "path": "docs/ops/deployment/overview.md", "diffHunk": "@@ -0,0 +1,358 @@\n+---\n+title: \"Clusters & Deployment\"\n+nav-id: deployment\n+nav-parent_id: ops\n+nav-pos: 1\n+nav-show_overview: true\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+Flink is a versatile framework, supporting many different deployment scenarios in a mix and match fashion.\n+\n+Below, we briefly explain the building blocks of a Flink cluster, their purpose and available implementations.\n+If you just want to start Flink locally, we recommend setting up a [Standalone Cluster]({% link ops/deployment/local.md %}).\n+\n+* This will be replaced by the TOC\n+{:toc}\n+\n+\n+## Overview and Reference Architecture\n+\n+The figure below shows the building blocks of every Flink cluster. There is always somewhere a client running. It takes the code of the Flink applications, transforms it into a job graph and submits it to the JobManager.\n+\n+The JobManager distributes the work onto the TaskManagers, where the actual operators (such as sources, transformations and sinks) are running.\n+\n+When deploying Flink, there are often multiple options available for each building block. We have listed them in the table below the figure.\n+\n+If you don't know where to start, we recommend using the Command Line Interface for submitting Flink applications to a Standalone Cluster.\n+\n+<!-- Image source: https://docs.google.com/drawings/d/1s_ZlXXvADqxWfTMNRVwQeg7HZ3hN1Xb7goxDPjTEPrI/edit?usp=sharing -->\n+<img width=\"100%\" src=\"{% link fig/deployment_overview.svg %}\" alt=\"Figure for Overview and Reference Architecture\" />\n+\n+\n+<table class=\"table table-bordered\">\n+  <thead>\n+    <tr>\n+      <th class=\"text-left\" style=\"width: 25%\">Component</th>\n+      <th class=\"text-left\" style=\"width: 50%\">Purpose</th>\n+      <th class=\"text-left\">Implementations</th>\n+    </tr>\n+   </thead>\n+   <tbody>\n+        <tr>\n+            <td>Flink Client</td>\n+            <td>\n+              Flink batch or streaming applications are compiled into a dataflow graph, which is submitted to the JobManager.\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Command Line Interface</a></li>\n+                    <li><a href=\"\">REST Endpoint</a></li>\n+                    <li><a href=\"\">SQL Client</a></li>\n+                    <li><a href=\"\">Python REPL</a></li>\n+                    <li><a href=\"\">Scala REPL</a></li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>JobManager</td>\n+            <td>\n+                JobManager is the name of the central work coordination component of Flink. It has implementations for different resource providers, which differ on high-availability, resource allocation behavior and supported job submission modes. <br />\n+                JobManager <a href=\"\">modes for job submissions</a>:\n+                <ul>\n+                    <li><b>Session Mode</b>: one JobManager instance manages multiple jobs sharing the same cluster of TaskManagers</li>\n+                    <li><b>Application Mode</b>: runs the cluster exclusively for one job. The job main method (or client) gets executed on the JobManager.</li>\n+                    <li><b>Per-Job Mode</b>: runs the cluster exclusively for one job. The job main method (or client) runs only prior to the cluster creation.</li>\n+                </ul>\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Kubernetes</a></li>\n+                    <li><a href=\"\">YARN</a></li>\n+                    <li><a href=\"\">Mesos</a></li>\n+                    <li><a href=\"\">Standalone</a> (this is the barebone mode that requires just JVMs to be launched. Deployment with Docker, Docker Swarm / Compose, non-native Kubernetes and other models is possible through manual setup in this mode)\n+                    </li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td colspan=\"3\" class=\"text-center\">\n+                <b>External Components</b> (all optional)\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>High Availability Service Provider</td>\n+            <td>\n+                Flink\u2019s JobManager supports a high availability mode, where multiple JobManagers participate in a leader election process, resulting in an active JobManager and potentially multiple standby JobManagers, allowing for fast failover in case the active JobManager is lost.\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Zookeeper</a></li>\n+                    <li><a href=\"\">Kubernetes HA</a></li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>File Storage and Persistency</td>\n+            <td>\n+                For checkpointing (recovery mechanism for streaming jobs) Flink relies on external file storage systems\n+            </td>\n+            <td>See <a href=\"\">FileSystems</a> page.</td>\n+        </tr>\n+        <tr>\n+            <td>Resource Provider</td>\n+            <td>\n+                Flink can be deployed through different Resource Provider Frameworks, such as Kubernetes, YARN or Mesos.\n+            </td>\n+            <td>See \"JobManager\" implementations above.</td>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2091ef6d8bc44d6b1381b2818e3a00c055641aac"}, "originalPosition": 124}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE2NzkxMA==", "bodyText": "Should we order them\n\napplication mode\nper-job\napplication mode", "url": "https://github.com/apache/flink/pull/14222#discussion_r531167910", "createdAt": "2020-11-26T17:44:43Z", "author": {"login": "tillrohrmann"}, "path": "docs/ops/deployment/overview.md", "diffHunk": "@@ -0,0 +1,358 @@\n+---\n+title: \"Clusters & Deployment\"\n+nav-id: deployment\n+nav-parent_id: ops\n+nav-pos: 1\n+nav-show_overview: true\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+Flink is a versatile framework, supporting many different deployment scenarios in a mix and match fashion.\n+\n+Below, we briefly explain the building blocks of a Flink cluster, their purpose and available implementations.\n+If you just want to start Flink locally, we recommend setting up a [Standalone Cluster]({% link ops/deployment/local.md %}).\n+\n+* This will be replaced by the TOC\n+{:toc}\n+\n+\n+## Overview and Reference Architecture\n+\n+The figure below shows the building blocks of every Flink cluster. There is always somewhere a client running. It takes the code of the Flink applications, transforms it into a job graph and submits it to the JobManager.\n+\n+The JobManager distributes the work onto the TaskManagers, where the actual operators (such as sources, transformations and sinks) are running.\n+\n+When deploying Flink, there are often multiple options available for each building block. We have listed them in the table below the figure.\n+\n+If you don't know where to start, we recommend using the Command Line Interface for submitting Flink applications to a Standalone Cluster.\n+\n+<!-- Image source: https://docs.google.com/drawings/d/1s_ZlXXvADqxWfTMNRVwQeg7HZ3hN1Xb7goxDPjTEPrI/edit?usp=sharing -->\n+<img width=\"100%\" src=\"{% link fig/deployment_overview.svg %}\" alt=\"Figure for Overview and Reference Architecture\" />\n+\n+\n+<table class=\"table table-bordered\">\n+  <thead>\n+    <tr>\n+      <th class=\"text-left\" style=\"width: 25%\">Component</th>\n+      <th class=\"text-left\" style=\"width: 50%\">Purpose</th>\n+      <th class=\"text-left\">Implementations</th>\n+    </tr>\n+   </thead>\n+   <tbody>\n+        <tr>\n+            <td>Flink Client</td>\n+            <td>\n+              Flink batch or streaming applications are compiled into a dataflow graph, which is submitted to the JobManager.\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Command Line Interface</a></li>\n+                    <li><a href=\"\">REST Endpoint</a></li>\n+                    <li><a href=\"\">SQL Client</a></li>\n+                    <li><a href=\"\">Python REPL</a></li>\n+                    <li><a href=\"\">Scala REPL</a></li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>JobManager</td>\n+            <td>\n+                JobManager is the name of the central work coordination component of Flink. It has implementations for different resource providers, which differ on high-availability, resource allocation behavior and supported job submission modes. <br />\n+                JobManager <a href=\"\">modes for job submissions</a>:\n+                <ul>\n+                    <li><b>Session Mode</b>: one JobManager instance manages multiple jobs sharing the same cluster of TaskManagers</li>\n+                    <li><b>Application Mode</b>: runs the cluster exclusively for one job. The job main method (or client) gets executed on the JobManager.</li>\n+                    <li><b>Per-Job Mode</b>: runs the cluster exclusively for one job. The job main method (or client) runs only prior to the cluster creation.</li>\n+                </ul>\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Kubernetes</a></li>\n+                    <li><a href=\"\">YARN</a></li>\n+                    <li><a href=\"\">Mesos</a></li>\n+                    <li><a href=\"\">Standalone</a> (this is the barebone mode that requires just JVMs to be launched. Deployment with Docker, Docker Swarm / Compose, non-native Kubernetes and other models is possible through manual setup in this mode)\n+                    </li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td colspan=\"3\" class=\"text-center\">\n+                <b>External Components</b> (all optional)\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>High Availability Service Provider</td>\n+            <td>\n+                Flink\u2019s JobManager supports a high availability mode, where multiple JobManagers participate in a leader election process, resulting in an active JobManager and potentially multiple standby JobManagers, allowing for fast failover in case the active JobManager is lost.\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Zookeeper</a></li>\n+                    <li><a href=\"\">Kubernetes HA</a></li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>File Storage and Persistency</td>\n+            <td>\n+                For checkpointing (recovery mechanism for streaming jobs) Flink relies on external file storage systems\n+            </td>\n+            <td>See <a href=\"\">FileSystems</a> page.</td>\n+        </tr>\n+        <tr>\n+            <td>Resource Provider</td>\n+            <td>\n+                Flink can be deployed through different Resource Provider Frameworks, such as Kubernetes, YARN or Mesos.\n+            </td>\n+            <td>See \"JobManager\" implementations above.</td>\n+        </tr>\n+        <tr>\n+            <td>Metrics Storage</td>\n+            <td>\n+                Flink components report internal metrics and Flink jobs can report additional, job specific metrics as well.\n+            </td>\n+            <td>See <a href=\"\">Metrics Reporter</a> page.</td>\n+        </tr>\n+        <tr>\n+            <td>Application-level data sources and sinks</td>\n+            <td>\n+                While application-level data sources and sinks are not technically part of the deployment of Flink cluster components, they should be considered when planning a new Flink production deployment. Colocating frequently used data with Flink can have significant performance benefits\n+            </td>\n+            <td>\n+                For example:\n+                <ul>\n+                    <li>Apache Kafka</li>\n+                    <li>Amazon S3</li>\n+                    <li>ElasticSearch</li>\n+                    <li>Apache Cassandra</li>\n+                </ul>\n+                See <a href=\"\">Connectors</a> page.\n+            </td>\n+        </tr>\n+    </tbody>\n+</table>\n+\n+\n+\n+## Deployment Modes\n+\n+Flink can execute applications in one of three ways:\n+ - in Session Mode, \n+ - in a Per-Job Mode, or\n+ - in Application Mode.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2091ef6d8bc44d6b1381b2818e3a00c055641aac"}, "originalPosition": 159}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE2ODc0OQ==", "bodyText": "Maybe the marketing team could help us with beautifying this picture. No offense for your artistic skills Robert!", "url": "https://github.com/apache/flink/pull/14222#discussion_r531168749", "createdAt": "2020-11-26T17:46:48Z", "author": {"login": "tillrohrmann"}, "path": "docs/ops/deployment/overview.md", "diffHunk": "@@ -0,0 +1,358 @@\n+---\n+title: \"Clusters & Deployment\"\n+nav-id: deployment\n+nav-parent_id: ops\n+nav-pos: 1\n+nav-show_overview: true\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+Flink is a versatile framework, supporting many different deployment scenarios in a mix and match fashion.\n+\n+Below, we briefly explain the building blocks of a Flink cluster, their purpose and available implementations.\n+If you just want to start Flink locally, we recommend setting up a [Standalone Cluster]({% link ops/deployment/local.md %}).\n+\n+* This will be replaced by the TOC\n+{:toc}\n+\n+\n+## Overview and Reference Architecture\n+\n+The figure below shows the building blocks of every Flink cluster. There is always somewhere a client running. It takes the code of the Flink applications, transforms it into a job graph and submits it to the JobManager.\n+\n+The JobManager distributes the work onto the TaskManagers, where the actual operators (such as sources, transformations and sinks) are running.\n+\n+When deploying Flink, there are often multiple options available for each building block. We have listed them in the table below the figure.\n+\n+If you don't know where to start, we recommend using the Command Line Interface for submitting Flink applications to a Standalone Cluster.\n+\n+<!-- Image source: https://docs.google.com/drawings/d/1s_ZlXXvADqxWfTMNRVwQeg7HZ3hN1Xb7goxDPjTEPrI/edit?usp=sharing -->\n+<img width=\"100%\" src=\"{% link fig/deployment_overview.svg %}\" alt=\"Figure for Overview and Reference Architecture\" />\n+\n+\n+<table class=\"table table-bordered\">\n+  <thead>\n+    <tr>\n+      <th class=\"text-left\" style=\"width: 25%\">Component</th>\n+      <th class=\"text-left\" style=\"width: 50%\">Purpose</th>\n+      <th class=\"text-left\">Implementations</th>\n+    </tr>\n+   </thead>\n+   <tbody>\n+        <tr>\n+            <td>Flink Client</td>\n+            <td>\n+              Flink batch or streaming applications are compiled into a dataflow graph, which is submitted to the JobManager.\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Command Line Interface</a></li>\n+                    <li><a href=\"\">REST Endpoint</a></li>\n+                    <li><a href=\"\">SQL Client</a></li>\n+                    <li><a href=\"\">Python REPL</a></li>\n+                    <li><a href=\"\">Scala REPL</a></li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>JobManager</td>\n+            <td>\n+                JobManager is the name of the central work coordination component of Flink. It has implementations for different resource providers, which differ on high-availability, resource allocation behavior and supported job submission modes. <br />\n+                JobManager <a href=\"\">modes for job submissions</a>:\n+                <ul>\n+                    <li><b>Session Mode</b>: one JobManager instance manages multiple jobs sharing the same cluster of TaskManagers</li>\n+                    <li><b>Application Mode</b>: runs the cluster exclusively for one job. The job main method (or client) gets executed on the JobManager.</li>\n+                    <li><b>Per-Job Mode</b>: runs the cluster exclusively for one job. The job main method (or client) runs only prior to the cluster creation.</li>\n+                </ul>\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Kubernetes</a></li>\n+                    <li><a href=\"\">YARN</a></li>\n+                    <li><a href=\"\">Mesos</a></li>\n+                    <li><a href=\"\">Standalone</a> (this is the barebone mode that requires just JVMs to be launched. Deployment with Docker, Docker Swarm / Compose, non-native Kubernetes and other models is possible through manual setup in this mode)\n+                    </li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td colspan=\"3\" class=\"text-center\">\n+                <b>External Components</b> (all optional)\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>High Availability Service Provider</td>\n+            <td>\n+                Flink\u2019s JobManager supports a high availability mode, where multiple JobManagers participate in a leader election process, resulting in an active JobManager and potentially multiple standby JobManagers, allowing for fast failover in case the active JobManager is lost.\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Zookeeper</a></li>\n+                    <li><a href=\"\">Kubernetes HA</a></li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>File Storage and Persistency</td>\n+            <td>\n+                For checkpointing (recovery mechanism for streaming jobs) Flink relies on external file storage systems\n+            </td>\n+            <td>See <a href=\"\">FileSystems</a> page.</td>\n+        </tr>\n+        <tr>\n+            <td>Resource Provider</td>\n+            <td>\n+                Flink can be deployed through different Resource Provider Frameworks, such as Kubernetes, YARN or Mesos.\n+            </td>\n+            <td>See \"JobManager\" implementations above.</td>\n+        </tr>\n+        <tr>\n+            <td>Metrics Storage</td>\n+            <td>\n+                Flink components report internal metrics and Flink jobs can report additional, job specific metrics as well.\n+            </td>\n+            <td>See <a href=\"\">Metrics Reporter</a> page.</td>\n+        </tr>\n+        <tr>\n+            <td>Application-level data sources and sinks</td>\n+            <td>\n+                While application-level data sources and sinks are not technically part of the deployment of Flink cluster components, they should be considered when planning a new Flink production deployment. Colocating frequently used data with Flink can have significant performance benefits\n+            </td>\n+            <td>\n+                For example:\n+                <ul>\n+                    <li>Apache Kafka</li>\n+                    <li>Amazon S3</li>\n+                    <li>ElasticSearch</li>\n+                    <li>Apache Cassandra</li>\n+                </ul>\n+                See <a href=\"\">Connectors</a> page.\n+            </td>\n+        </tr>\n+    </tbody>\n+</table>\n+\n+\n+\n+## Deployment Modes\n+\n+Flink can execute applications in one of three ways:\n+ - in Session Mode, \n+ - in a Per-Job Mode, or\n+ - in Application Mode.\n+\n+ The above modes differ in:\n+ - the cluster lifecycle and resource isolation guarantees\n+ - whether the application's `main()` method is executed on the client or on the cluster.\n+\n+\n+\n+<!-- Image source: https://docs.google.com/drawings/d/1EfloufuOp1A7YDwZmBEsHKRLIrrbtRkoWRPcfZI5RYQ/edit?usp=sharing -->\n+<img width=\"100%\" src=\"{% link fig/deployment_modes.svg %}\" alt=\"Figure for Deployment Modes\" />", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDQ4ODYwMg=="}, "originalCommit": {"oid": "2091ef6d8bc44d6b1381b2818e3a00c055641aac"}, "originalPosition": 168}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE2OTAxMQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            then all jobs running on that Task Manager will be affected by the failure. This, apart from a negative\n          \n          \n            \n            then all jobs running on that TaskManager (or task manager) will be affected by the failure. This, apart from a negative", "url": "https://github.com/apache/flink/pull/14222#discussion_r531169011", "createdAt": "2020-11-26T17:47:38Z", "author": {"login": "tillrohrmann"}, "path": "docs/ops/deployment/overview.md", "diffHunk": "@@ -0,0 +1,358 @@\n+---\n+title: \"Clusters & Deployment\"\n+nav-id: deployment\n+nav-parent_id: ops\n+nav-pos: 1\n+nav-show_overview: true\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+Flink is a versatile framework, supporting many different deployment scenarios in a mix and match fashion.\n+\n+Below, we briefly explain the building blocks of a Flink cluster, their purpose and available implementations.\n+If you just want to start Flink locally, we recommend setting up a [Standalone Cluster]({% link ops/deployment/local.md %}).\n+\n+* This will be replaced by the TOC\n+{:toc}\n+\n+\n+## Overview and Reference Architecture\n+\n+The figure below shows the building blocks of every Flink cluster. There is always somewhere a client running. It takes the code of the Flink applications, transforms it into a job graph and submits it to the JobManager.\n+\n+The JobManager distributes the work onto the TaskManagers, where the actual operators (such as sources, transformations and sinks) are running.\n+\n+When deploying Flink, there are often multiple options available for each building block. We have listed them in the table below the figure.\n+\n+If you don't know where to start, we recommend using the Command Line Interface for submitting Flink applications to a Standalone Cluster.\n+\n+<!-- Image source: https://docs.google.com/drawings/d/1s_ZlXXvADqxWfTMNRVwQeg7HZ3hN1Xb7goxDPjTEPrI/edit?usp=sharing -->\n+<img width=\"100%\" src=\"{% link fig/deployment_overview.svg %}\" alt=\"Figure for Overview and Reference Architecture\" />\n+\n+\n+<table class=\"table table-bordered\">\n+  <thead>\n+    <tr>\n+      <th class=\"text-left\" style=\"width: 25%\">Component</th>\n+      <th class=\"text-left\" style=\"width: 50%\">Purpose</th>\n+      <th class=\"text-left\">Implementations</th>\n+    </tr>\n+   </thead>\n+   <tbody>\n+        <tr>\n+            <td>Flink Client</td>\n+            <td>\n+              Flink batch or streaming applications are compiled into a dataflow graph, which is submitted to the JobManager.\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Command Line Interface</a></li>\n+                    <li><a href=\"\">REST Endpoint</a></li>\n+                    <li><a href=\"\">SQL Client</a></li>\n+                    <li><a href=\"\">Python REPL</a></li>\n+                    <li><a href=\"\">Scala REPL</a></li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>JobManager</td>\n+            <td>\n+                JobManager is the name of the central work coordination component of Flink. It has implementations for different resource providers, which differ on high-availability, resource allocation behavior and supported job submission modes. <br />\n+                JobManager <a href=\"\">modes for job submissions</a>:\n+                <ul>\n+                    <li><b>Session Mode</b>: one JobManager instance manages multiple jobs sharing the same cluster of TaskManagers</li>\n+                    <li><b>Application Mode</b>: runs the cluster exclusively for one job. The job main method (or client) gets executed on the JobManager.</li>\n+                    <li><b>Per-Job Mode</b>: runs the cluster exclusively for one job. The job main method (or client) runs only prior to the cluster creation.</li>\n+                </ul>\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Kubernetes</a></li>\n+                    <li><a href=\"\">YARN</a></li>\n+                    <li><a href=\"\">Mesos</a></li>\n+                    <li><a href=\"\">Standalone</a> (this is the barebone mode that requires just JVMs to be launched. Deployment with Docker, Docker Swarm / Compose, non-native Kubernetes and other models is possible through manual setup in this mode)\n+                    </li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td colspan=\"3\" class=\"text-center\">\n+                <b>External Components</b> (all optional)\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>High Availability Service Provider</td>\n+            <td>\n+                Flink\u2019s JobManager supports a high availability mode, where multiple JobManagers participate in a leader election process, resulting in an active JobManager and potentially multiple standby JobManagers, allowing for fast failover in case the active JobManager is lost.\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Zookeeper</a></li>\n+                    <li><a href=\"\">Kubernetes HA</a></li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>File Storage and Persistency</td>\n+            <td>\n+                For checkpointing (recovery mechanism for streaming jobs) Flink relies on external file storage systems\n+            </td>\n+            <td>See <a href=\"\">FileSystems</a> page.</td>\n+        </tr>\n+        <tr>\n+            <td>Resource Provider</td>\n+            <td>\n+                Flink can be deployed through different Resource Provider Frameworks, such as Kubernetes, YARN or Mesos.\n+            </td>\n+            <td>See \"JobManager\" implementations above.</td>\n+        </tr>\n+        <tr>\n+            <td>Metrics Storage</td>\n+            <td>\n+                Flink components report internal metrics and Flink jobs can report additional, job specific metrics as well.\n+            </td>\n+            <td>See <a href=\"\">Metrics Reporter</a> page.</td>\n+        </tr>\n+        <tr>\n+            <td>Application-level data sources and sinks</td>\n+            <td>\n+                While application-level data sources and sinks are not technically part of the deployment of Flink cluster components, they should be considered when planning a new Flink production deployment. Colocating frequently used data with Flink can have significant performance benefits\n+            </td>\n+            <td>\n+                For example:\n+                <ul>\n+                    <li>Apache Kafka</li>\n+                    <li>Amazon S3</li>\n+                    <li>ElasticSearch</li>\n+                    <li>Apache Cassandra</li>\n+                </ul>\n+                See <a href=\"\">Connectors</a> page.\n+            </td>\n+        </tr>\n+    </tbody>\n+</table>\n+\n+\n+\n+## Deployment Modes\n+\n+Flink can execute applications in one of three ways:\n+ - in Session Mode, \n+ - in a Per-Job Mode, or\n+ - in Application Mode.\n+\n+ The above modes differ in:\n+ - the cluster lifecycle and resource isolation guarantees\n+ - whether the application's `main()` method is executed on the client or on the cluster.\n+\n+\n+\n+<!-- Image source: https://docs.google.com/drawings/d/1EfloufuOp1A7YDwZmBEsHKRLIrrbtRkoWRPcfZI5RYQ/edit?usp=sharing -->\n+<img width=\"100%\" src=\"{% link fig/deployment_modes.svg %}\" alt=\"Figure for Deployment Modes\" />\n+\n+#### Session Mode\n+\n+*Session mode* assumes an already running cluster and uses the resources of that cluster to execute any \n+submitted application. Applications executed in the same (session) cluster use, and consequently compete\n+for, the same resources. This has the advantage that you do not pay the resource overhead of spinning up\n+a full cluster for every submitted job. But, if one of the jobs misbehaves or brings down a Task Manager,\n+then all jobs running on that Task Manager will be affected by the failure. This, apart from a negative", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2091ef6d8bc44d6b1381b2818e3a00c055641aac"}, "originalPosition": 176}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE2OTA3Mg==", "bodyText": "Same here with \"Task Manager\"", "url": "https://github.com/apache/flink/pull/14222#discussion_r531169072", "createdAt": "2020-11-26T17:47:51Z", "author": {"login": "tillrohrmann"}, "path": "docs/ops/deployment/overview.md", "diffHunk": "@@ -0,0 +1,358 @@\n+---\n+title: \"Clusters & Deployment\"\n+nav-id: deployment\n+nav-parent_id: ops\n+nav-pos: 1\n+nav-show_overview: true\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+Flink is a versatile framework, supporting many different deployment scenarios in a mix and match fashion.\n+\n+Below, we briefly explain the building blocks of a Flink cluster, their purpose and available implementations.\n+If you just want to start Flink locally, we recommend setting up a [Standalone Cluster]({% link ops/deployment/local.md %}).\n+\n+* This will be replaced by the TOC\n+{:toc}\n+\n+\n+## Overview and Reference Architecture\n+\n+The figure below shows the building blocks of every Flink cluster. There is always somewhere a client running. It takes the code of the Flink applications, transforms it into a job graph and submits it to the JobManager.\n+\n+The JobManager distributes the work onto the TaskManagers, where the actual operators (such as sources, transformations and sinks) are running.\n+\n+When deploying Flink, there are often multiple options available for each building block. We have listed them in the table below the figure.\n+\n+If you don't know where to start, we recommend using the Command Line Interface for submitting Flink applications to a Standalone Cluster.\n+\n+<!-- Image source: https://docs.google.com/drawings/d/1s_ZlXXvADqxWfTMNRVwQeg7HZ3hN1Xb7goxDPjTEPrI/edit?usp=sharing -->\n+<img width=\"100%\" src=\"{% link fig/deployment_overview.svg %}\" alt=\"Figure for Overview and Reference Architecture\" />\n+\n+\n+<table class=\"table table-bordered\">\n+  <thead>\n+    <tr>\n+      <th class=\"text-left\" style=\"width: 25%\">Component</th>\n+      <th class=\"text-left\" style=\"width: 50%\">Purpose</th>\n+      <th class=\"text-left\">Implementations</th>\n+    </tr>\n+   </thead>\n+   <tbody>\n+        <tr>\n+            <td>Flink Client</td>\n+            <td>\n+              Flink batch or streaming applications are compiled into a dataflow graph, which is submitted to the JobManager.\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Command Line Interface</a></li>\n+                    <li><a href=\"\">REST Endpoint</a></li>\n+                    <li><a href=\"\">SQL Client</a></li>\n+                    <li><a href=\"\">Python REPL</a></li>\n+                    <li><a href=\"\">Scala REPL</a></li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>JobManager</td>\n+            <td>\n+                JobManager is the name of the central work coordination component of Flink. It has implementations for different resource providers, which differ on high-availability, resource allocation behavior and supported job submission modes. <br />\n+                JobManager <a href=\"\">modes for job submissions</a>:\n+                <ul>\n+                    <li><b>Session Mode</b>: one JobManager instance manages multiple jobs sharing the same cluster of TaskManagers</li>\n+                    <li><b>Application Mode</b>: runs the cluster exclusively for one job. The job main method (or client) gets executed on the JobManager.</li>\n+                    <li><b>Per-Job Mode</b>: runs the cluster exclusively for one job. The job main method (or client) runs only prior to the cluster creation.</li>\n+                </ul>\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Kubernetes</a></li>\n+                    <li><a href=\"\">YARN</a></li>\n+                    <li><a href=\"\">Mesos</a></li>\n+                    <li><a href=\"\">Standalone</a> (this is the barebone mode that requires just JVMs to be launched. Deployment with Docker, Docker Swarm / Compose, non-native Kubernetes and other models is possible through manual setup in this mode)\n+                    </li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td colspan=\"3\" class=\"text-center\">\n+                <b>External Components</b> (all optional)\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>High Availability Service Provider</td>\n+            <td>\n+                Flink\u2019s JobManager supports a high availability mode, where multiple JobManagers participate in a leader election process, resulting in an active JobManager and potentially multiple standby JobManagers, allowing for fast failover in case the active JobManager is lost.\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Zookeeper</a></li>\n+                    <li><a href=\"\">Kubernetes HA</a></li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>File Storage and Persistency</td>\n+            <td>\n+                For checkpointing (recovery mechanism for streaming jobs) Flink relies on external file storage systems\n+            </td>\n+            <td>See <a href=\"\">FileSystems</a> page.</td>\n+        </tr>\n+        <tr>\n+            <td>Resource Provider</td>\n+            <td>\n+                Flink can be deployed through different Resource Provider Frameworks, such as Kubernetes, YARN or Mesos.\n+            </td>\n+            <td>See \"JobManager\" implementations above.</td>\n+        </tr>\n+        <tr>\n+            <td>Metrics Storage</td>\n+            <td>\n+                Flink components report internal metrics and Flink jobs can report additional, job specific metrics as well.\n+            </td>\n+            <td>See <a href=\"\">Metrics Reporter</a> page.</td>\n+        </tr>\n+        <tr>\n+            <td>Application-level data sources and sinks</td>\n+            <td>\n+                While application-level data sources and sinks are not technically part of the deployment of Flink cluster components, they should be considered when planning a new Flink production deployment. Colocating frequently used data with Flink can have significant performance benefits\n+            </td>\n+            <td>\n+                For example:\n+                <ul>\n+                    <li>Apache Kafka</li>\n+                    <li>Amazon S3</li>\n+                    <li>ElasticSearch</li>\n+                    <li>Apache Cassandra</li>\n+                </ul>\n+                See <a href=\"\">Connectors</a> page.\n+            </td>\n+        </tr>\n+    </tbody>\n+</table>\n+\n+\n+\n+## Deployment Modes\n+\n+Flink can execute applications in one of three ways:\n+ - in Session Mode, \n+ - in a Per-Job Mode, or\n+ - in Application Mode.\n+\n+ The above modes differ in:\n+ - the cluster lifecycle and resource isolation guarantees\n+ - whether the application's `main()` method is executed on the client or on the cluster.\n+\n+\n+\n+<!-- Image source: https://docs.google.com/drawings/d/1EfloufuOp1A7YDwZmBEsHKRLIrrbtRkoWRPcfZI5RYQ/edit?usp=sharing -->\n+<img width=\"100%\" src=\"{% link fig/deployment_modes.svg %}\" alt=\"Figure for Deployment Modes\" />\n+\n+#### Session Mode\n+\n+*Session mode* assumes an already running cluster and uses the resources of that cluster to execute any \n+submitted application. Applications executed in the same (session) cluster use, and consequently compete\n+for, the same resources. This has the advantage that you do not pay the resource overhead of spinning up\n+a full cluster for every submitted job. But, if one of the jobs misbehaves or brings down a Task Manager,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2091ef6d8bc44d6b1381b2818e3a00c055641aac"}, "originalPosition": 175}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE2OTI0NQ==", "bodyText": "Here we write JobManager. Hence, I'd suggest to make it consistent.", "url": "https://github.com/apache/flink/pull/14222#discussion_r531169245", "createdAt": "2020-11-26T17:48:21Z", "author": {"login": "tillrohrmann"}, "path": "docs/ops/deployment/overview.md", "diffHunk": "@@ -0,0 +1,358 @@\n+---\n+title: \"Clusters & Deployment\"\n+nav-id: deployment\n+nav-parent_id: ops\n+nav-pos: 1\n+nav-show_overview: true\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+Flink is a versatile framework, supporting many different deployment scenarios in a mix and match fashion.\n+\n+Below, we briefly explain the building blocks of a Flink cluster, their purpose and available implementations.\n+If you just want to start Flink locally, we recommend setting up a [Standalone Cluster]({% link ops/deployment/local.md %}).\n+\n+* This will be replaced by the TOC\n+{:toc}\n+\n+\n+## Overview and Reference Architecture\n+\n+The figure below shows the building blocks of every Flink cluster. There is always somewhere a client running. It takes the code of the Flink applications, transforms it into a job graph and submits it to the JobManager.\n+\n+The JobManager distributes the work onto the TaskManagers, where the actual operators (such as sources, transformations and sinks) are running.\n+\n+When deploying Flink, there are often multiple options available for each building block. We have listed them in the table below the figure.\n+\n+If you don't know where to start, we recommend using the Command Line Interface for submitting Flink applications to a Standalone Cluster.\n+\n+<!-- Image source: https://docs.google.com/drawings/d/1s_ZlXXvADqxWfTMNRVwQeg7HZ3hN1Xb7goxDPjTEPrI/edit?usp=sharing -->\n+<img width=\"100%\" src=\"{% link fig/deployment_overview.svg %}\" alt=\"Figure for Overview and Reference Architecture\" />\n+\n+\n+<table class=\"table table-bordered\">\n+  <thead>\n+    <tr>\n+      <th class=\"text-left\" style=\"width: 25%\">Component</th>\n+      <th class=\"text-left\" style=\"width: 50%\">Purpose</th>\n+      <th class=\"text-left\">Implementations</th>\n+    </tr>\n+   </thead>\n+   <tbody>\n+        <tr>\n+            <td>Flink Client</td>\n+            <td>\n+              Flink batch or streaming applications are compiled into a dataflow graph, which is submitted to the JobManager.\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Command Line Interface</a></li>\n+                    <li><a href=\"\">REST Endpoint</a></li>\n+                    <li><a href=\"\">SQL Client</a></li>\n+                    <li><a href=\"\">Python REPL</a></li>\n+                    <li><a href=\"\">Scala REPL</a></li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>JobManager</td>\n+            <td>\n+                JobManager is the name of the central work coordination component of Flink. It has implementations for different resource providers, which differ on high-availability, resource allocation behavior and supported job submission modes. <br />\n+                JobManager <a href=\"\">modes for job submissions</a>:\n+                <ul>\n+                    <li><b>Session Mode</b>: one JobManager instance manages multiple jobs sharing the same cluster of TaskManagers</li>\n+                    <li><b>Application Mode</b>: runs the cluster exclusively for one job. The job main method (or client) gets executed on the JobManager.</li>\n+                    <li><b>Per-Job Mode</b>: runs the cluster exclusively for one job. The job main method (or client) runs only prior to the cluster creation.</li>\n+                </ul>\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Kubernetes</a></li>\n+                    <li><a href=\"\">YARN</a></li>\n+                    <li><a href=\"\">Mesos</a></li>\n+                    <li><a href=\"\">Standalone</a> (this is the barebone mode that requires just JVMs to be launched. Deployment with Docker, Docker Swarm / Compose, non-native Kubernetes and other models is possible through manual setup in this mode)\n+                    </li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td colspan=\"3\" class=\"text-center\">\n+                <b>External Components</b> (all optional)\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>High Availability Service Provider</td>\n+            <td>\n+                Flink\u2019s JobManager supports a high availability mode, where multiple JobManagers participate in a leader election process, resulting in an active JobManager and potentially multiple standby JobManagers, allowing for fast failover in case the active JobManager is lost.\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Zookeeper</a></li>\n+                    <li><a href=\"\">Kubernetes HA</a></li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>File Storage and Persistency</td>\n+            <td>\n+                For checkpointing (recovery mechanism for streaming jobs) Flink relies on external file storage systems\n+            </td>\n+            <td>See <a href=\"\">FileSystems</a> page.</td>\n+        </tr>\n+        <tr>\n+            <td>Resource Provider</td>\n+            <td>\n+                Flink can be deployed through different Resource Provider Frameworks, such as Kubernetes, YARN or Mesos.\n+            </td>\n+            <td>See \"JobManager\" implementations above.</td>\n+        </tr>\n+        <tr>\n+            <td>Metrics Storage</td>\n+            <td>\n+                Flink components report internal metrics and Flink jobs can report additional, job specific metrics as well.\n+            </td>\n+            <td>See <a href=\"\">Metrics Reporter</a> page.</td>\n+        </tr>\n+        <tr>\n+            <td>Application-level data sources and sinks</td>\n+            <td>\n+                While application-level data sources and sinks are not technically part of the deployment of Flink cluster components, they should be considered when planning a new Flink production deployment. Colocating frequently used data with Flink can have significant performance benefits\n+            </td>\n+            <td>\n+                For example:\n+                <ul>\n+                    <li>Apache Kafka</li>\n+                    <li>Amazon S3</li>\n+                    <li>ElasticSearch</li>\n+                    <li>Apache Cassandra</li>\n+                </ul>\n+                See <a href=\"\">Connectors</a> page.\n+            </td>\n+        </tr>\n+    </tbody>\n+</table>\n+\n+\n+\n+## Deployment Modes\n+\n+Flink can execute applications in one of three ways:\n+ - in Session Mode, \n+ - in a Per-Job Mode, or\n+ - in Application Mode.\n+\n+ The above modes differ in:\n+ - the cluster lifecycle and resource isolation guarantees\n+ - whether the application's `main()` method is executed on the client or on the cluster.\n+\n+\n+\n+<!-- Image source: https://docs.google.com/drawings/d/1EfloufuOp1A7YDwZmBEsHKRLIrrbtRkoWRPcfZI5RYQ/edit?usp=sharing -->\n+<img width=\"100%\" src=\"{% link fig/deployment_modes.svg %}\" alt=\"Figure for Deployment Modes\" />\n+\n+#### Session Mode\n+\n+*Session mode* assumes an already running cluster and uses the resources of that cluster to execute any \n+submitted application. Applications executed in the same (session) cluster use, and consequently compete\n+for, the same resources. This has the advantage that you do not pay the resource overhead of spinning up\n+a full cluster for every submitted job. But, if one of the jobs misbehaves or brings down a Task Manager,\n+then all jobs running on that Task Manager will be affected by the failure. This, apart from a negative\n+impact on the job that caused the failure, implies a potential massive recovery process with all the \n+restarting jobs accessing the filesystem concurrently and making it unavailable to other services. \n+Additionally, having a single cluster running multiple jobs implies more load for the JobManager, who ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2091ef6d8bc44d6b1381b2818e3a00c055641aac"}, "originalPosition": 179}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE2OTk5Ng==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            for downloading the dependencies locally. Furthermore, it allows for more even spread of the network load of\n          \n          \n            \n            for downloading the dependencies locally. Furthermore, it allows for more even spread of the network load for", "url": "https://github.com/apache/flink/pull/14222#discussion_r531169996", "createdAt": "2020-11-26T17:50:27Z", "author": {"login": "tillrohrmann"}, "path": "docs/ops/deployment/overview.md", "diffHunk": "@@ -0,0 +1,358 @@\n+---\n+title: \"Clusters & Deployment\"\n+nav-id: deployment\n+nav-parent_id: ops\n+nav-pos: 1\n+nav-show_overview: true\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+Flink is a versatile framework, supporting many different deployment scenarios in a mix and match fashion.\n+\n+Below, we briefly explain the building blocks of a Flink cluster, their purpose and available implementations.\n+If you just want to start Flink locally, we recommend setting up a [Standalone Cluster]({% link ops/deployment/local.md %}).\n+\n+* This will be replaced by the TOC\n+{:toc}\n+\n+\n+## Overview and Reference Architecture\n+\n+The figure below shows the building blocks of every Flink cluster. There is always somewhere a client running. It takes the code of the Flink applications, transforms it into a job graph and submits it to the JobManager.\n+\n+The JobManager distributes the work onto the TaskManagers, where the actual operators (such as sources, transformations and sinks) are running.\n+\n+When deploying Flink, there are often multiple options available for each building block. We have listed them in the table below the figure.\n+\n+If you don't know where to start, we recommend using the Command Line Interface for submitting Flink applications to a Standalone Cluster.\n+\n+<!-- Image source: https://docs.google.com/drawings/d/1s_ZlXXvADqxWfTMNRVwQeg7HZ3hN1Xb7goxDPjTEPrI/edit?usp=sharing -->\n+<img width=\"100%\" src=\"{% link fig/deployment_overview.svg %}\" alt=\"Figure for Overview and Reference Architecture\" />\n+\n+\n+<table class=\"table table-bordered\">\n+  <thead>\n+    <tr>\n+      <th class=\"text-left\" style=\"width: 25%\">Component</th>\n+      <th class=\"text-left\" style=\"width: 50%\">Purpose</th>\n+      <th class=\"text-left\">Implementations</th>\n+    </tr>\n+   </thead>\n+   <tbody>\n+        <tr>\n+            <td>Flink Client</td>\n+            <td>\n+              Flink batch or streaming applications are compiled into a dataflow graph, which is submitted to the JobManager.\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Command Line Interface</a></li>\n+                    <li><a href=\"\">REST Endpoint</a></li>\n+                    <li><a href=\"\">SQL Client</a></li>\n+                    <li><a href=\"\">Python REPL</a></li>\n+                    <li><a href=\"\">Scala REPL</a></li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>JobManager</td>\n+            <td>\n+                JobManager is the name of the central work coordination component of Flink. It has implementations for different resource providers, which differ on high-availability, resource allocation behavior and supported job submission modes. <br />\n+                JobManager <a href=\"\">modes for job submissions</a>:\n+                <ul>\n+                    <li><b>Session Mode</b>: one JobManager instance manages multiple jobs sharing the same cluster of TaskManagers</li>\n+                    <li><b>Application Mode</b>: runs the cluster exclusively for one job. The job main method (or client) gets executed on the JobManager.</li>\n+                    <li><b>Per-Job Mode</b>: runs the cluster exclusively for one job. The job main method (or client) runs only prior to the cluster creation.</li>\n+                </ul>\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Kubernetes</a></li>\n+                    <li><a href=\"\">YARN</a></li>\n+                    <li><a href=\"\">Mesos</a></li>\n+                    <li><a href=\"\">Standalone</a> (this is the barebone mode that requires just JVMs to be launched. Deployment with Docker, Docker Swarm / Compose, non-native Kubernetes and other models is possible through manual setup in this mode)\n+                    </li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td colspan=\"3\" class=\"text-center\">\n+                <b>External Components</b> (all optional)\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>High Availability Service Provider</td>\n+            <td>\n+                Flink\u2019s JobManager supports a high availability mode, where multiple JobManagers participate in a leader election process, resulting in an active JobManager and potentially multiple standby JobManagers, allowing for fast failover in case the active JobManager is lost.\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Zookeeper</a></li>\n+                    <li><a href=\"\">Kubernetes HA</a></li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>File Storage and Persistency</td>\n+            <td>\n+                For checkpointing (recovery mechanism for streaming jobs) Flink relies on external file storage systems\n+            </td>\n+            <td>See <a href=\"\">FileSystems</a> page.</td>\n+        </tr>\n+        <tr>\n+            <td>Resource Provider</td>\n+            <td>\n+                Flink can be deployed through different Resource Provider Frameworks, such as Kubernetes, YARN or Mesos.\n+            </td>\n+            <td>See \"JobManager\" implementations above.</td>\n+        </tr>\n+        <tr>\n+            <td>Metrics Storage</td>\n+            <td>\n+                Flink components report internal metrics and Flink jobs can report additional, job specific metrics as well.\n+            </td>\n+            <td>See <a href=\"\">Metrics Reporter</a> page.</td>\n+        </tr>\n+        <tr>\n+            <td>Application-level data sources and sinks</td>\n+            <td>\n+                While application-level data sources and sinks are not technically part of the deployment of Flink cluster components, they should be considered when planning a new Flink production deployment. Colocating frequently used data with Flink can have significant performance benefits\n+            </td>\n+            <td>\n+                For example:\n+                <ul>\n+                    <li>Apache Kafka</li>\n+                    <li>Amazon S3</li>\n+                    <li>ElasticSearch</li>\n+                    <li>Apache Cassandra</li>\n+                </ul>\n+                See <a href=\"\">Connectors</a> page.\n+            </td>\n+        </tr>\n+    </tbody>\n+</table>\n+\n+\n+\n+## Deployment Modes\n+\n+Flink can execute applications in one of three ways:\n+ - in Session Mode, \n+ - in a Per-Job Mode, or\n+ - in Application Mode.\n+\n+ The above modes differ in:\n+ - the cluster lifecycle and resource isolation guarantees\n+ - whether the application's `main()` method is executed on the client or on the cluster.\n+\n+\n+\n+<!-- Image source: https://docs.google.com/drawings/d/1EfloufuOp1A7YDwZmBEsHKRLIrrbtRkoWRPcfZI5RYQ/edit?usp=sharing -->\n+<img width=\"100%\" src=\"{% link fig/deployment_modes.svg %}\" alt=\"Figure for Deployment Modes\" />\n+\n+#### Session Mode\n+\n+*Session mode* assumes an already running cluster and uses the resources of that cluster to execute any \n+submitted application. Applications executed in the same (session) cluster use, and consequently compete\n+for, the same resources. This has the advantage that you do not pay the resource overhead of spinning up\n+a full cluster for every submitted job. But, if one of the jobs misbehaves or brings down a Task Manager,\n+then all jobs running on that Task Manager will be affected by the failure. This, apart from a negative\n+impact on the job that caused the failure, implies a potential massive recovery process with all the \n+restarting jobs accessing the filesystem concurrently and making it unavailable to other services. \n+Additionally, having a single cluster running multiple jobs implies more load for the JobManager, who \n+is responsible for the book-keeping of all the jobs in the cluster.\n+\n+#### Per-Job Mode\n+\n+Aiming at providing better resource isolation guarantees, the *Per-Job* mode uses the available resource provider\n+framework (e.g. YARN, Kubernetes) to spin up a cluster for each submitted job. This cluster is available to \n+that job only. When the job finishes, the cluster is torn down and any lingering resources (files, etc) are\n+cleared up. This provides better resource isolation, as a misbehaving job can only bring down its own \n+Task Managers. In addition, it spreads the load of book-keeping across multiple JobManagers, as there is \n+one per job. For these reasons, the *Per-Job* resource allocation model is the preferred mode by many \n+production reasons.\n+\n+#### Application Mode\n+    \n+In all the above modes, the application's `main()` method is executed on the client side. This process \n+includes downloading the application's dependencies locally, executing the `main()` to extract a representation\n+of the application that Flink's runtime can understand (i.e. the `JobGraph`) and ship the dependencies and\n+the `JobGraph(s)` to the cluster. This makes the Client a heavy resource consumer as it may need substantial\n+network bandwidth to download dependencies and ship binaries to the cluster, and CPU cycles to execute the\n+`main()`. This problem can be more pronounced when the Client is shared across users.\n+\n+Building on this observation, the *Application Mode* creates a cluster per submitted application, but this time,\n+the `main()` method of the application is executed on the JobManager. Creating a cluster per application can be \n+seen as creating a session cluster shared only among the jobs of a particular application, and torn down when\n+the application finishes. With this architecture, the *Application Mode* provides the same resource isolation\n+and load balancing guarantees as the *Per-Job* mode, but at the granularity of a whole application. Executing \n+the `main()` on the JobManager allows for saving the CPU cycles required, but also save the bandwidth required\n+for downloading the dependencies locally. Furthermore, it allows for more even spread of the network load of", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2091ef6d8bc44d6b1381b2818e3a00c055641aac"}, "originalPosition": 207}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE3MDQ5OA==", "bodyText": "@kl0u are we failing if we are running a multi-execute job with HA enabled?", "url": "https://github.com/apache/flink/pull/14222#discussion_r531170498", "createdAt": "2020-11-26T17:51:47Z", "author": {"login": "tillrohrmann"}, "path": "docs/ops/deployment/overview.md", "diffHunk": "@@ -0,0 +1,358 @@\n+---\n+title: \"Clusters & Deployment\"\n+nav-id: deployment\n+nav-parent_id: ops\n+nav-pos: 1\n+nav-show_overview: true\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+Flink is a versatile framework, supporting many different deployment scenarios in a mix and match fashion.\n+\n+Below, we briefly explain the building blocks of a Flink cluster, their purpose and available implementations.\n+If you just want to start Flink locally, we recommend setting up a [Standalone Cluster]({% link ops/deployment/local.md %}).\n+\n+* This will be replaced by the TOC\n+{:toc}\n+\n+\n+## Overview and Reference Architecture\n+\n+The figure below shows the building blocks of every Flink cluster. There is always somewhere a client running. It takes the code of the Flink applications, transforms it into a job graph and submits it to the JobManager.\n+\n+The JobManager distributes the work onto the TaskManagers, where the actual operators (such as sources, transformations and sinks) are running.\n+\n+When deploying Flink, there are often multiple options available for each building block. We have listed them in the table below the figure.\n+\n+If you don't know where to start, we recommend using the Command Line Interface for submitting Flink applications to a Standalone Cluster.\n+\n+<!-- Image source: https://docs.google.com/drawings/d/1s_ZlXXvADqxWfTMNRVwQeg7HZ3hN1Xb7goxDPjTEPrI/edit?usp=sharing -->\n+<img width=\"100%\" src=\"{% link fig/deployment_overview.svg %}\" alt=\"Figure for Overview and Reference Architecture\" />\n+\n+\n+<table class=\"table table-bordered\">\n+  <thead>\n+    <tr>\n+      <th class=\"text-left\" style=\"width: 25%\">Component</th>\n+      <th class=\"text-left\" style=\"width: 50%\">Purpose</th>\n+      <th class=\"text-left\">Implementations</th>\n+    </tr>\n+   </thead>\n+   <tbody>\n+        <tr>\n+            <td>Flink Client</td>\n+            <td>\n+              Flink batch or streaming applications are compiled into a dataflow graph, which is submitted to the JobManager.\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Command Line Interface</a></li>\n+                    <li><a href=\"\">REST Endpoint</a></li>\n+                    <li><a href=\"\">SQL Client</a></li>\n+                    <li><a href=\"\">Python REPL</a></li>\n+                    <li><a href=\"\">Scala REPL</a></li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>JobManager</td>\n+            <td>\n+                JobManager is the name of the central work coordination component of Flink. It has implementations for different resource providers, which differ on high-availability, resource allocation behavior and supported job submission modes. <br />\n+                JobManager <a href=\"\">modes for job submissions</a>:\n+                <ul>\n+                    <li><b>Session Mode</b>: one JobManager instance manages multiple jobs sharing the same cluster of TaskManagers</li>\n+                    <li><b>Application Mode</b>: runs the cluster exclusively for one job. The job main method (or client) gets executed on the JobManager.</li>\n+                    <li><b>Per-Job Mode</b>: runs the cluster exclusively for one job. The job main method (or client) runs only prior to the cluster creation.</li>\n+                </ul>\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Kubernetes</a></li>\n+                    <li><a href=\"\">YARN</a></li>\n+                    <li><a href=\"\">Mesos</a></li>\n+                    <li><a href=\"\">Standalone</a> (this is the barebone mode that requires just JVMs to be launched. Deployment with Docker, Docker Swarm / Compose, non-native Kubernetes and other models is possible through manual setup in this mode)\n+                    </li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td colspan=\"3\" class=\"text-center\">\n+                <b>External Components</b> (all optional)\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>High Availability Service Provider</td>\n+            <td>\n+                Flink\u2019s JobManager supports a high availability mode, where multiple JobManagers participate in a leader election process, resulting in an active JobManager and potentially multiple standby JobManagers, allowing for fast failover in case the active JobManager is lost.\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Zookeeper</a></li>\n+                    <li><a href=\"\">Kubernetes HA</a></li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>File Storage and Persistency</td>\n+            <td>\n+                For checkpointing (recovery mechanism for streaming jobs) Flink relies on external file storage systems\n+            </td>\n+            <td>See <a href=\"\">FileSystems</a> page.</td>\n+        </tr>\n+        <tr>\n+            <td>Resource Provider</td>\n+            <td>\n+                Flink can be deployed through different Resource Provider Frameworks, such as Kubernetes, YARN or Mesos.\n+            </td>\n+            <td>See \"JobManager\" implementations above.</td>\n+        </tr>\n+        <tr>\n+            <td>Metrics Storage</td>\n+            <td>\n+                Flink components report internal metrics and Flink jobs can report additional, job specific metrics as well.\n+            </td>\n+            <td>See <a href=\"\">Metrics Reporter</a> page.</td>\n+        </tr>\n+        <tr>\n+            <td>Application-level data sources and sinks</td>\n+            <td>\n+                While application-level data sources and sinks are not technically part of the deployment of Flink cluster components, they should be considered when planning a new Flink production deployment. Colocating frequently used data with Flink can have significant performance benefits\n+            </td>\n+            <td>\n+                For example:\n+                <ul>\n+                    <li>Apache Kafka</li>\n+                    <li>Amazon S3</li>\n+                    <li>ElasticSearch</li>\n+                    <li>Apache Cassandra</li>\n+                </ul>\n+                See <a href=\"\">Connectors</a> page.\n+            </td>\n+        </tr>\n+    </tbody>\n+</table>\n+\n+\n+\n+## Deployment Modes\n+\n+Flink can execute applications in one of three ways:\n+ - in Session Mode, \n+ - in a Per-Job Mode, or\n+ - in Application Mode.\n+\n+ The above modes differ in:\n+ - the cluster lifecycle and resource isolation guarantees\n+ - whether the application's `main()` method is executed on the client or on the cluster.\n+\n+\n+\n+<!-- Image source: https://docs.google.com/drawings/d/1EfloufuOp1A7YDwZmBEsHKRLIrrbtRkoWRPcfZI5RYQ/edit?usp=sharing -->\n+<img width=\"100%\" src=\"{% link fig/deployment_modes.svg %}\" alt=\"Figure for Deployment Modes\" />\n+\n+#### Session Mode\n+\n+*Session mode* assumes an already running cluster and uses the resources of that cluster to execute any \n+submitted application. Applications executed in the same (session) cluster use, and consequently compete\n+for, the same resources. This has the advantage that you do not pay the resource overhead of spinning up\n+a full cluster for every submitted job. But, if one of the jobs misbehaves or brings down a Task Manager,\n+then all jobs running on that Task Manager will be affected by the failure. This, apart from a negative\n+impact on the job that caused the failure, implies a potential massive recovery process with all the \n+restarting jobs accessing the filesystem concurrently and making it unavailable to other services. \n+Additionally, having a single cluster running multiple jobs implies more load for the JobManager, who \n+is responsible for the book-keeping of all the jobs in the cluster.\n+\n+#### Per-Job Mode\n+\n+Aiming at providing better resource isolation guarantees, the *Per-Job* mode uses the available resource provider\n+framework (e.g. YARN, Kubernetes) to spin up a cluster for each submitted job. This cluster is available to \n+that job only. When the job finishes, the cluster is torn down and any lingering resources (files, etc) are\n+cleared up. This provides better resource isolation, as a misbehaving job can only bring down its own \n+Task Managers. In addition, it spreads the load of book-keeping across multiple JobManagers, as there is \n+one per job. For these reasons, the *Per-Job* resource allocation model is the preferred mode by many \n+production reasons.\n+\n+#### Application Mode\n+    \n+In all the above modes, the application's `main()` method is executed on the client side. This process \n+includes downloading the application's dependencies locally, executing the `main()` to extract a representation\n+of the application that Flink's runtime can understand (i.e. the `JobGraph`) and ship the dependencies and\n+the `JobGraph(s)` to the cluster. This makes the Client a heavy resource consumer as it may need substantial\n+network bandwidth to download dependencies and ship binaries to the cluster, and CPU cycles to execute the\n+`main()`. This problem can be more pronounced when the Client is shared across users.\n+\n+Building on this observation, the *Application Mode* creates a cluster per submitted application, but this time,\n+the `main()` method of the application is executed on the JobManager. Creating a cluster per application can be \n+seen as creating a session cluster shared only among the jobs of a particular application, and torn down when\n+the application finishes. With this architecture, the *Application Mode* provides the same resource isolation\n+and load balancing guarantees as the *Per-Job* mode, but at the granularity of a whole application. Executing \n+the `main()` on the JobManager allows for saving the CPU cycles required, but also save the bandwidth required\n+for downloading the dependencies locally. Furthermore, it allows for more even spread of the network load of\n+downloading the dependencies of the applications in the cluster, as there is one JobManager per application.\n+\n+<div class=\"alert alert-info\" markdown=\"span\">\n+  <strong>Note:</strong> In the Application Mode, the `main()` is executed on the cluster and not on the client, \n+  as in the other modes. This may have implications for your code as, for example, any paths you register in \n+  your environment using the `registerCachedFile()` must be accessible by the JobManager of your application.\n+</div>\n+\n+Compared to the *Per-Job* mode, the *Application Mode* allows the submission of applications consisting of\n+multiple jobs. The order of job execution is not affected by the deployment mode but by the call used\n+to launch the job. Using `execute()`, which is blocking, establishes an order and it will lead to the \n+execution of the \"next\"  job being postponed until \"this\" job finishes. Using `executeAsync()`, which is \n+non-blocking, will lead to the \"next\" job starting before \"this\" job finishes.\n+\n+<div class=\"alert alert-info\" markdown=\"span\">\n+  <strong>Attention:</strong> The Application Mode allows for multi-`execute()` applications but \n+  High-Availability is not supported in these cases. High-Availability in Application Mode is only\n+  supported for single-`execute()` applications.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2091ef6d8bc44d6b1381b2818e3a00c055641aac"}, "originalPosition": 225}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE3MTI3OQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            - **`plugins/<name>/`** are loaded at runtime by Flink through separate classloaders to avoid conflicts with classes loaded and used by Flink. Only jar files which are prepared as [plugins]({% link ops/plugins.md %}) can be added here.\n          \n          \n            \n            - **`plugins/<name>/`** are loaded at runtime by Flink through separate classloaders to avoid conflicts with classes loaded and used by Flink. Only jar files which are prepared as [plugins]({% link deployment/filesystems/plugins.md %}) can be added here.", "url": "https://github.com/apache/flink/pull/14222#discussion_r531171279", "createdAt": "2020-11-26T17:53:58Z", "author": {"login": "tillrohrmann"}, "path": "docs/ops/deployment/overview.md", "diffHunk": "@@ -0,0 +1,358 @@\n+---\n+title: \"Clusters & Deployment\"\n+nav-id: deployment\n+nav-parent_id: ops\n+nav-pos: 1\n+nav-show_overview: true\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+Flink is a versatile framework, supporting many different deployment scenarios in a mix and match fashion.\n+\n+Below, we briefly explain the building blocks of a Flink cluster, their purpose and available implementations.\n+If you just want to start Flink locally, we recommend setting up a [Standalone Cluster]({% link ops/deployment/local.md %}).\n+\n+* This will be replaced by the TOC\n+{:toc}\n+\n+\n+## Overview and Reference Architecture\n+\n+The figure below shows the building blocks of every Flink cluster. There is always somewhere a client running. It takes the code of the Flink applications, transforms it into a job graph and submits it to the JobManager.\n+\n+The JobManager distributes the work onto the TaskManagers, where the actual operators (such as sources, transformations and sinks) are running.\n+\n+When deploying Flink, there are often multiple options available for each building block. We have listed them in the table below the figure.\n+\n+If you don't know where to start, we recommend using the Command Line Interface for submitting Flink applications to a Standalone Cluster.\n+\n+<!-- Image source: https://docs.google.com/drawings/d/1s_ZlXXvADqxWfTMNRVwQeg7HZ3hN1Xb7goxDPjTEPrI/edit?usp=sharing -->\n+<img width=\"100%\" src=\"{% link fig/deployment_overview.svg %}\" alt=\"Figure for Overview and Reference Architecture\" />\n+\n+\n+<table class=\"table table-bordered\">\n+  <thead>\n+    <tr>\n+      <th class=\"text-left\" style=\"width: 25%\">Component</th>\n+      <th class=\"text-left\" style=\"width: 50%\">Purpose</th>\n+      <th class=\"text-left\">Implementations</th>\n+    </tr>\n+   </thead>\n+   <tbody>\n+        <tr>\n+            <td>Flink Client</td>\n+            <td>\n+              Flink batch or streaming applications are compiled into a dataflow graph, which is submitted to the JobManager.\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Command Line Interface</a></li>\n+                    <li><a href=\"\">REST Endpoint</a></li>\n+                    <li><a href=\"\">SQL Client</a></li>\n+                    <li><a href=\"\">Python REPL</a></li>\n+                    <li><a href=\"\">Scala REPL</a></li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>JobManager</td>\n+            <td>\n+                JobManager is the name of the central work coordination component of Flink. It has implementations for different resource providers, which differ on high-availability, resource allocation behavior and supported job submission modes. <br />\n+                JobManager <a href=\"\">modes for job submissions</a>:\n+                <ul>\n+                    <li><b>Session Mode</b>: one JobManager instance manages multiple jobs sharing the same cluster of TaskManagers</li>\n+                    <li><b>Application Mode</b>: runs the cluster exclusively for one job. The job main method (or client) gets executed on the JobManager.</li>\n+                    <li><b>Per-Job Mode</b>: runs the cluster exclusively for one job. The job main method (or client) runs only prior to the cluster creation.</li>\n+                </ul>\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Kubernetes</a></li>\n+                    <li><a href=\"\">YARN</a></li>\n+                    <li><a href=\"\">Mesos</a></li>\n+                    <li><a href=\"\">Standalone</a> (this is the barebone mode that requires just JVMs to be launched. Deployment with Docker, Docker Swarm / Compose, non-native Kubernetes and other models is possible through manual setup in this mode)\n+                    </li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td colspan=\"3\" class=\"text-center\">\n+                <b>External Components</b> (all optional)\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>High Availability Service Provider</td>\n+            <td>\n+                Flink\u2019s JobManager supports a high availability mode, where multiple JobManagers participate in a leader election process, resulting in an active JobManager and potentially multiple standby JobManagers, allowing for fast failover in case the active JobManager is lost.\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Zookeeper</a></li>\n+                    <li><a href=\"\">Kubernetes HA</a></li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>File Storage and Persistency</td>\n+            <td>\n+                For checkpointing (recovery mechanism for streaming jobs) Flink relies on external file storage systems\n+            </td>\n+            <td>See <a href=\"\">FileSystems</a> page.</td>\n+        </tr>\n+        <tr>\n+            <td>Resource Provider</td>\n+            <td>\n+                Flink can be deployed through different Resource Provider Frameworks, such as Kubernetes, YARN or Mesos.\n+            </td>\n+            <td>See \"JobManager\" implementations above.</td>\n+        </tr>\n+        <tr>\n+            <td>Metrics Storage</td>\n+            <td>\n+                Flink components report internal metrics and Flink jobs can report additional, job specific metrics as well.\n+            </td>\n+            <td>See <a href=\"\">Metrics Reporter</a> page.</td>\n+        </tr>\n+        <tr>\n+            <td>Application-level data sources and sinks</td>\n+            <td>\n+                While application-level data sources and sinks are not technically part of the deployment of Flink cluster components, they should be considered when planning a new Flink production deployment. Colocating frequently used data with Flink can have significant performance benefits\n+            </td>\n+            <td>\n+                For example:\n+                <ul>\n+                    <li>Apache Kafka</li>\n+                    <li>Amazon S3</li>\n+                    <li>ElasticSearch</li>\n+                    <li>Apache Cassandra</li>\n+                </ul>\n+                See <a href=\"\">Connectors</a> page.\n+            </td>\n+        </tr>\n+    </tbody>\n+</table>\n+\n+\n+\n+## Deployment Modes\n+\n+Flink can execute applications in one of three ways:\n+ - in Session Mode, \n+ - in a Per-Job Mode, or\n+ - in Application Mode.\n+\n+ The above modes differ in:\n+ - the cluster lifecycle and resource isolation guarantees\n+ - whether the application's `main()` method is executed on the client or on the cluster.\n+\n+\n+\n+<!-- Image source: https://docs.google.com/drawings/d/1EfloufuOp1A7YDwZmBEsHKRLIrrbtRkoWRPcfZI5RYQ/edit?usp=sharing -->\n+<img width=\"100%\" src=\"{% link fig/deployment_modes.svg %}\" alt=\"Figure for Deployment Modes\" />\n+\n+#### Session Mode\n+\n+*Session mode* assumes an already running cluster and uses the resources of that cluster to execute any \n+submitted application. Applications executed in the same (session) cluster use, and consequently compete\n+for, the same resources. This has the advantage that you do not pay the resource overhead of spinning up\n+a full cluster for every submitted job. But, if one of the jobs misbehaves or brings down a Task Manager,\n+then all jobs running on that Task Manager will be affected by the failure. This, apart from a negative\n+impact on the job that caused the failure, implies a potential massive recovery process with all the \n+restarting jobs accessing the filesystem concurrently and making it unavailable to other services. \n+Additionally, having a single cluster running multiple jobs implies more load for the JobManager, who \n+is responsible for the book-keeping of all the jobs in the cluster.\n+\n+#### Per-Job Mode\n+\n+Aiming at providing better resource isolation guarantees, the *Per-Job* mode uses the available resource provider\n+framework (e.g. YARN, Kubernetes) to spin up a cluster for each submitted job. This cluster is available to \n+that job only. When the job finishes, the cluster is torn down and any lingering resources (files, etc) are\n+cleared up. This provides better resource isolation, as a misbehaving job can only bring down its own \n+Task Managers. In addition, it spreads the load of book-keeping across multiple JobManagers, as there is \n+one per job. For these reasons, the *Per-Job* resource allocation model is the preferred mode by many \n+production reasons.\n+\n+#### Application Mode\n+    \n+In all the above modes, the application's `main()` method is executed on the client side. This process \n+includes downloading the application's dependencies locally, executing the `main()` to extract a representation\n+of the application that Flink's runtime can understand (i.e. the `JobGraph`) and ship the dependencies and\n+the `JobGraph(s)` to the cluster. This makes the Client a heavy resource consumer as it may need substantial\n+network bandwidth to download dependencies and ship binaries to the cluster, and CPU cycles to execute the\n+`main()`. This problem can be more pronounced when the Client is shared across users.\n+\n+Building on this observation, the *Application Mode* creates a cluster per submitted application, but this time,\n+the `main()` method of the application is executed on the JobManager. Creating a cluster per application can be \n+seen as creating a session cluster shared only among the jobs of a particular application, and torn down when\n+the application finishes. With this architecture, the *Application Mode* provides the same resource isolation\n+and load balancing guarantees as the *Per-Job* mode, but at the granularity of a whole application. Executing \n+the `main()` on the JobManager allows for saving the CPU cycles required, but also save the bandwidth required\n+for downloading the dependencies locally. Furthermore, it allows for more even spread of the network load of\n+downloading the dependencies of the applications in the cluster, as there is one JobManager per application.\n+\n+<div class=\"alert alert-info\" markdown=\"span\">\n+  <strong>Note:</strong> In the Application Mode, the `main()` is executed on the cluster and not on the client, \n+  as in the other modes. This may have implications for your code as, for example, any paths you register in \n+  your environment using the `registerCachedFile()` must be accessible by the JobManager of your application.\n+</div>\n+\n+Compared to the *Per-Job* mode, the *Application Mode* allows the submission of applications consisting of\n+multiple jobs. The order of job execution is not affected by the deployment mode but by the call used\n+to launch the job. Using `execute()`, which is blocking, establishes an order and it will lead to the \n+execution of the \"next\"  job being postponed until \"this\" job finishes. Using `executeAsync()`, which is \n+non-blocking, will lead to the \"next\" job starting before \"this\" job finishes.\n+\n+<div class=\"alert alert-info\" markdown=\"span\">\n+  <strong>Attention:</strong> The Application Mode allows for multi-`execute()` applications but \n+  High-Availability is not supported in these cases. High-Availability in Application Mode is only\n+  supported for single-`execute()` applications.\n+</div>\n+\n+#### Summary\n+\n+In *Session Mode*, the cluster lifecycle is independent of that of any job running on the cluster\n+and the resources are shared across all jobs. The *Per-Job* mode pays the price of spinning up a cluster\n+for every submitted job, but this comes with better isolation guarantees as the resources are not shared \n+across jobs. In this case, the lifecycle of the cluster is bound to that of the job. Finally, the \n+*Application Mode* creates a session cluster per application and executes the application's `main()` \n+method on the cluster.\n+\n+\n+\n+## Vendor Solutions\n+\n+A number of vendors offer managed or fully hosted Flink solutions.\n+None of these vendors are officially supported or endorsed by the Apache Flink PMC.\n+Please refer to vendor maintained documentation on how to use these products. \n+\n+<!--\n+Please keep this list in alphabetical order\n+-->\n+\n+#### AliCloud Realtime Compute\n+\n+[Website](https://www.alibabacloud.com/products/realtime-compute)\n+\n+Supported Environments:\n+<span class=\"label label-primary\">AliCloud</span>\n+\n+#### Amazon EMR\n+\n+[Website](https://aws.amazon.com/emr/)\n+\n+Supported Environments:\n+<span class=\"label label-primary\">AWS</span>\n+\n+#### Amazon Kinesis Data Analytics for Apache Flink\n+\n+[Website](https://docs.aws.amazon.com/kinesisanalytics/latest/java/what-is.html)\n+\n+Supported Environments:\n+<span class=\"label label-primary\">AWS</span>\n+\n+#### Cloudera DataFlow\n+\n+[Website](https://www.cloudera.com/products/cdf.html)\n+\n+Supported Environment:\n+<span class=\"label label-primary\">AWS</span>\n+<span class=\"label label-primary\">Azure</span>\n+<span class=\"label label-primary\">Google Cloud</span>\n+<span class=\"label label-primary\">On-Premise</span>\n+\n+#### Eventador\n+\n+[Website](https://eventador.io)\n+\n+Supported Environment:\n+<span class=\"label label-primary\">AWS</span>\n+\n+#### Huawei Cloud Stream Service\n+\n+[Website](https://www.huaweicloud.com/en-us/product/cs.html)\n+\n+Supported Environment:\n+<span class=\"label label-primary\">Huawei Cloud</span>\n+\n+#### Ververica Platform\n+\n+[Website](https://www.ververica.com/platform-overview)\n+\n+Supported Environments:\n+<span class=\"label label-primary\">AliCloud</span>\n+<span class=\"label label-primary\">AWS</span>\n+<span class=\"label label-primary\">Azure</span>\n+<span class=\"label label-primary\">Google Cloud</span>\n+<span class=\"label label-primary\">On-Premise</span>\n+\n+## Deployment Best Practices\n+\n+### How to provide dependencies in the classpath\n+\n+Flink provides several approaches for providing dependencies (such as `*.jar` files or static data) to Flink or user-provided\n+applications. These approaches differ based on the deployment mode and target, but also have commonalities, which are described here.\n+\n+To provide a dependency, there are the following options:\n+- files in the **`lib/` folder** are added to the classpath used to start Flink. It is suitable for libraries such as Hadoop or file systems not available as plugins. Beware that classes added here can potentially interfere with Flink, for example if you are adding a different version of a library already provided by Flink.\n+\n+- **`plugins/<name>/`** are loaded at runtime by Flink through separate classloaders to avoid conflicts with classes loaded and used by Flink. Only jar files which are prepared as [plugins]({% link ops/plugins.md %}) can be added here.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2091ef6d8bc44d6b1381b2818e3a00c055641aac"}, "originalPosition": 315}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE3MTYxNA==", "bodyText": "Should this be part of the overview page? Maybe it is better suited for tips & tricks.", "url": "https://github.com/apache/flink/pull/14222#discussion_r531171614", "createdAt": "2020-11-26T17:54:58Z", "author": {"login": "tillrohrmann"}, "path": "docs/ops/deployment/overview.md", "diffHunk": "@@ -0,0 +1,358 @@\n+---\n+title: \"Clusters & Deployment\"\n+nav-id: deployment\n+nav-parent_id: ops\n+nav-pos: 1\n+nav-show_overview: true\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+Flink is a versatile framework, supporting many different deployment scenarios in a mix and match fashion.\n+\n+Below, we briefly explain the building blocks of a Flink cluster, their purpose and available implementations.\n+If you just want to start Flink locally, we recommend setting up a [Standalone Cluster]({% link ops/deployment/local.md %}).\n+\n+* This will be replaced by the TOC\n+{:toc}\n+\n+\n+## Overview and Reference Architecture\n+\n+The figure below shows the building blocks of every Flink cluster. There is always somewhere a client running. It takes the code of the Flink applications, transforms it into a job graph and submits it to the JobManager.\n+\n+The JobManager distributes the work onto the TaskManagers, where the actual operators (such as sources, transformations and sinks) are running.\n+\n+When deploying Flink, there are often multiple options available for each building block. We have listed them in the table below the figure.\n+\n+If you don't know where to start, we recommend using the Command Line Interface for submitting Flink applications to a Standalone Cluster.\n+\n+<!-- Image source: https://docs.google.com/drawings/d/1s_ZlXXvADqxWfTMNRVwQeg7HZ3hN1Xb7goxDPjTEPrI/edit?usp=sharing -->\n+<img width=\"100%\" src=\"{% link fig/deployment_overview.svg %}\" alt=\"Figure for Overview and Reference Architecture\" />\n+\n+\n+<table class=\"table table-bordered\">\n+  <thead>\n+    <tr>\n+      <th class=\"text-left\" style=\"width: 25%\">Component</th>\n+      <th class=\"text-left\" style=\"width: 50%\">Purpose</th>\n+      <th class=\"text-left\">Implementations</th>\n+    </tr>\n+   </thead>\n+   <tbody>\n+        <tr>\n+            <td>Flink Client</td>\n+            <td>\n+              Flink batch or streaming applications are compiled into a dataflow graph, which is submitted to the JobManager.\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Command Line Interface</a></li>\n+                    <li><a href=\"\">REST Endpoint</a></li>\n+                    <li><a href=\"\">SQL Client</a></li>\n+                    <li><a href=\"\">Python REPL</a></li>\n+                    <li><a href=\"\">Scala REPL</a></li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>JobManager</td>\n+            <td>\n+                JobManager is the name of the central work coordination component of Flink. It has implementations for different resource providers, which differ on high-availability, resource allocation behavior and supported job submission modes. <br />\n+                JobManager <a href=\"\">modes for job submissions</a>:\n+                <ul>\n+                    <li><b>Session Mode</b>: one JobManager instance manages multiple jobs sharing the same cluster of TaskManagers</li>\n+                    <li><b>Application Mode</b>: runs the cluster exclusively for one job. The job main method (or client) gets executed on the JobManager.</li>\n+                    <li><b>Per-Job Mode</b>: runs the cluster exclusively for one job. The job main method (or client) runs only prior to the cluster creation.</li>\n+                </ul>\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Kubernetes</a></li>\n+                    <li><a href=\"\">YARN</a></li>\n+                    <li><a href=\"\">Mesos</a></li>\n+                    <li><a href=\"\">Standalone</a> (this is the barebone mode that requires just JVMs to be launched. Deployment with Docker, Docker Swarm / Compose, non-native Kubernetes and other models is possible through manual setup in this mode)\n+                    </li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td colspan=\"3\" class=\"text-center\">\n+                <b>External Components</b> (all optional)\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>High Availability Service Provider</td>\n+            <td>\n+                Flink\u2019s JobManager supports a high availability mode, where multiple JobManagers participate in a leader election process, resulting in an active JobManager and potentially multiple standby JobManagers, allowing for fast failover in case the active JobManager is lost.\n+            </td>\n+            <td>\n+                <ul>\n+                    <li><a href=\"\">Zookeeper</a></li>\n+                    <li><a href=\"\">Kubernetes HA</a></li>\n+                </ul>\n+            </td>\n+        </tr>\n+        <tr>\n+            <td>File Storage and Persistency</td>\n+            <td>\n+                For checkpointing (recovery mechanism for streaming jobs) Flink relies on external file storage systems\n+            </td>\n+            <td>See <a href=\"\">FileSystems</a> page.</td>\n+        </tr>\n+        <tr>\n+            <td>Resource Provider</td>\n+            <td>\n+                Flink can be deployed through different Resource Provider Frameworks, such as Kubernetes, YARN or Mesos.\n+            </td>\n+            <td>See \"JobManager\" implementations above.</td>\n+        </tr>\n+        <tr>\n+            <td>Metrics Storage</td>\n+            <td>\n+                Flink components report internal metrics and Flink jobs can report additional, job specific metrics as well.\n+            </td>\n+            <td>See <a href=\"\">Metrics Reporter</a> page.</td>\n+        </tr>\n+        <tr>\n+            <td>Application-level data sources and sinks</td>\n+            <td>\n+                While application-level data sources and sinks are not technically part of the deployment of Flink cluster components, they should be considered when planning a new Flink production deployment. Colocating frequently used data with Flink can have significant performance benefits\n+            </td>\n+            <td>\n+                For example:\n+                <ul>\n+                    <li>Apache Kafka</li>\n+                    <li>Amazon S3</li>\n+                    <li>ElasticSearch</li>\n+                    <li>Apache Cassandra</li>\n+                </ul>\n+                See <a href=\"\">Connectors</a> page.\n+            </td>\n+        </tr>\n+    </tbody>\n+</table>\n+\n+\n+\n+## Deployment Modes\n+\n+Flink can execute applications in one of three ways:\n+ - in Session Mode, \n+ - in a Per-Job Mode, or\n+ - in Application Mode.\n+\n+ The above modes differ in:\n+ - the cluster lifecycle and resource isolation guarantees\n+ - whether the application's `main()` method is executed on the client or on the cluster.\n+\n+\n+\n+<!-- Image source: https://docs.google.com/drawings/d/1EfloufuOp1A7YDwZmBEsHKRLIrrbtRkoWRPcfZI5RYQ/edit?usp=sharing -->\n+<img width=\"100%\" src=\"{% link fig/deployment_modes.svg %}\" alt=\"Figure for Deployment Modes\" />\n+\n+#### Session Mode\n+\n+*Session mode* assumes an already running cluster and uses the resources of that cluster to execute any \n+submitted application. Applications executed in the same (session) cluster use, and consequently compete\n+for, the same resources. This has the advantage that you do not pay the resource overhead of spinning up\n+a full cluster for every submitted job. But, if one of the jobs misbehaves or brings down a Task Manager,\n+then all jobs running on that Task Manager will be affected by the failure. This, apart from a negative\n+impact on the job that caused the failure, implies a potential massive recovery process with all the \n+restarting jobs accessing the filesystem concurrently and making it unavailable to other services. \n+Additionally, having a single cluster running multiple jobs implies more load for the JobManager, who \n+is responsible for the book-keeping of all the jobs in the cluster.\n+\n+#### Per-Job Mode\n+\n+Aiming at providing better resource isolation guarantees, the *Per-Job* mode uses the available resource provider\n+framework (e.g. YARN, Kubernetes) to spin up a cluster for each submitted job. This cluster is available to \n+that job only. When the job finishes, the cluster is torn down and any lingering resources (files, etc) are\n+cleared up. This provides better resource isolation, as a misbehaving job can only bring down its own \n+Task Managers. In addition, it spreads the load of book-keeping across multiple JobManagers, as there is \n+one per job. For these reasons, the *Per-Job* resource allocation model is the preferred mode by many \n+production reasons.\n+\n+#### Application Mode\n+    \n+In all the above modes, the application's `main()` method is executed on the client side. This process \n+includes downloading the application's dependencies locally, executing the `main()` to extract a representation\n+of the application that Flink's runtime can understand (i.e. the `JobGraph`) and ship the dependencies and\n+the `JobGraph(s)` to the cluster. This makes the Client a heavy resource consumer as it may need substantial\n+network bandwidth to download dependencies and ship binaries to the cluster, and CPU cycles to execute the\n+`main()`. This problem can be more pronounced when the Client is shared across users.\n+\n+Building on this observation, the *Application Mode* creates a cluster per submitted application, but this time,\n+the `main()` method of the application is executed on the JobManager. Creating a cluster per application can be \n+seen as creating a session cluster shared only among the jobs of a particular application, and torn down when\n+the application finishes. With this architecture, the *Application Mode* provides the same resource isolation\n+and load balancing guarantees as the *Per-Job* mode, but at the granularity of a whole application. Executing \n+the `main()` on the JobManager allows for saving the CPU cycles required, but also save the bandwidth required\n+for downloading the dependencies locally. Furthermore, it allows for more even spread of the network load of\n+downloading the dependencies of the applications in the cluster, as there is one JobManager per application.\n+\n+<div class=\"alert alert-info\" markdown=\"span\">\n+  <strong>Note:</strong> In the Application Mode, the `main()` is executed on the cluster and not on the client, \n+  as in the other modes. This may have implications for your code as, for example, any paths you register in \n+  your environment using the `registerCachedFile()` must be accessible by the JobManager of your application.\n+</div>\n+\n+Compared to the *Per-Job* mode, the *Application Mode* allows the submission of applications consisting of\n+multiple jobs. The order of job execution is not affected by the deployment mode but by the call used\n+to launch the job. Using `execute()`, which is blocking, establishes an order and it will lead to the \n+execution of the \"next\"  job being postponed until \"this\" job finishes. Using `executeAsync()`, which is \n+non-blocking, will lead to the \"next\" job starting before \"this\" job finishes.\n+\n+<div class=\"alert alert-info\" markdown=\"span\">\n+  <strong>Attention:</strong> The Application Mode allows for multi-`execute()` applications but \n+  High-Availability is not supported in these cases. High-Availability in Application Mode is only\n+  supported for single-`execute()` applications.\n+</div>\n+\n+#### Summary\n+\n+In *Session Mode*, the cluster lifecycle is independent of that of any job running on the cluster\n+and the resources are shared across all jobs. The *Per-Job* mode pays the price of spinning up a cluster\n+for every submitted job, but this comes with better isolation guarantees as the resources are not shared \n+across jobs. In this case, the lifecycle of the cluster is bound to that of the job. Finally, the \n+*Application Mode* creates a session cluster per application and executes the application's `main()` \n+method on the cluster.\n+\n+\n+\n+## Vendor Solutions\n+\n+A number of vendors offer managed or fully hosted Flink solutions.\n+None of these vendors are officially supported or endorsed by the Apache Flink PMC.\n+Please refer to vendor maintained documentation on how to use these products. \n+\n+<!--\n+Please keep this list in alphabetical order\n+-->\n+\n+#### AliCloud Realtime Compute\n+\n+[Website](https://www.alibabacloud.com/products/realtime-compute)\n+\n+Supported Environments:\n+<span class=\"label label-primary\">AliCloud</span>\n+\n+#### Amazon EMR\n+\n+[Website](https://aws.amazon.com/emr/)\n+\n+Supported Environments:\n+<span class=\"label label-primary\">AWS</span>\n+\n+#### Amazon Kinesis Data Analytics for Apache Flink\n+\n+[Website](https://docs.aws.amazon.com/kinesisanalytics/latest/java/what-is.html)\n+\n+Supported Environments:\n+<span class=\"label label-primary\">AWS</span>\n+\n+#### Cloudera DataFlow\n+\n+[Website](https://www.cloudera.com/products/cdf.html)\n+\n+Supported Environment:\n+<span class=\"label label-primary\">AWS</span>\n+<span class=\"label label-primary\">Azure</span>\n+<span class=\"label label-primary\">Google Cloud</span>\n+<span class=\"label label-primary\">On-Premise</span>\n+\n+#### Eventador\n+\n+[Website](https://eventador.io)\n+\n+Supported Environment:\n+<span class=\"label label-primary\">AWS</span>\n+\n+#### Huawei Cloud Stream Service\n+\n+[Website](https://www.huaweicloud.com/en-us/product/cs.html)\n+\n+Supported Environment:\n+<span class=\"label label-primary\">Huawei Cloud</span>\n+\n+#### Ververica Platform\n+\n+[Website](https://www.ververica.com/platform-overview)\n+\n+Supported Environments:\n+<span class=\"label label-primary\">AliCloud</span>\n+<span class=\"label label-primary\">AWS</span>\n+<span class=\"label label-primary\">Azure</span>\n+<span class=\"label label-primary\">Google Cloud</span>\n+<span class=\"label label-primary\">On-Premise</span>\n+\n+## Deployment Best Practices\n+\n+### How to provide dependencies in the classpath\n+\n+Flink provides several approaches for providing dependencies (such as `*.jar` files or static data) to Flink or user-provided\n+applications. These approaches differ based on the deployment mode and target, but also have commonalities, which are described here.\n+\n+To provide a dependency, there are the following options:\n+- files in the **`lib/` folder** are added to the classpath used to start Flink. It is suitable for libraries such as Hadoop or file systems not available as plugins. Beware that classes added here can potentially interfere with Flink, for example if you are adding a different version of a library already provided by Flink.\n+\n+- **`plugins/<name>/`** are loaded at runtime by Flink through separate classloaders to avoid conflicts with classes loaded and used by Flink. Only jar files which are prepared as [plugins]({% link ops/plugins.md %}) can be added here.\n+\n+### Download Maven dependencies locally", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2091ef6d8bc44d6b1381b2818e3a00c055641aac"}, "originalPosition": 317}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9dcc920326deb9550b59406115c709f4f9584673", "author": {"user": {"login": "rmetzger", "name": "Robert Metzger"}}, "url": "https://github.com/apache/flink/commit/9dcc920326deb9550b59406115c709f4f9584673", "committedDate": "2020-11-27T08:26:43Z", "message": "[hotfix][docs] Document classloader shutdown hooks"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "2091ef6d8bc44d6b1381b2818e3a00c055641aac", "author": {"user": {"login": "rmetzger", "name": "Robert Metzger"}}, "url": "https://github.com/apache/flink/commit/2091ef6d8bc44d6b1381b2818e3a00c055641aac", "committedDate": "2020-11-25T14:14:33Z", "message": "ready for review"}, "afterCommit": {"oid": "3031e45c39ba01cca8a676c9ea4be7adda730296", "author": {"user": {"login": "rmetzger", "name": "Robert Metzger"}}, "url": "https://github.com/apache/flink/commit/3031e45c39ba01cca8a676c9ea4be7adda730296", "committedDate": "2020-11-27T08:31:23Z", "message": "[FLINK-20343] Add new Deployment overview page"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "511ebc21df64b9d668e1d57d53a88c92978854e1", "author": {"user": {"login": "rmetzger", "name": "Robert Metzger"}}, "url": "https://github.com/apache/flink/commit/511ebc21df64b9d668e1d57d53a88c92978854e1", "committedDate": "2020-11-27T09:03:59Z", "message": "[FLINK-20343] Add new Deployment overview page"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "3031e45c39ba01cca8a676c9ea4be7adda730296", "author": {"user": {"login": "rmetzger", "name": "Robert Metzger"}}, "url": "https://github.com/apache/flink/commit/3031e45c39ba01cca8a676c9ea4be7adda730296", "committedDate": "2020-11-27T08:31:23Z", "message": "[FLINK-20343] Add new Deployment overview page"}, "afterCommit": {"oid": "511ebc21df64b9d668e1d57d53a88c92978854e1", "author": {"user": {"login": "rmetzger", "name": "Robert Metzger"}}, "url": "https://github.com/apache/flink/commit/511ebc21df64b9d668e1d57d53a88c92978854e1", "committedDate": "2020-11-27T09:03:59Z", "message": "[FLINK-20343] Add new Deployment overview page"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4157, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}