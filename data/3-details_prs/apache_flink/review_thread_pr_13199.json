{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDcwMTY0OTcx", "number": 13199, "reviewThreads": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQxNDoxOToyOFrOEZ__3Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQyMDoxMDoxNVrOEaIdiw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk1Njk4Mzk3OnYy", "diffSide": "RIGHT", "path": "docs/dev/python/user-guide/datastream/data_types.zh.md", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQxNDoxOToyOFrOHDJpSg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQxNDoxOToyOFrOHDJpSg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzA2NTgwMg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            * This will be replaced by the TOC\n          \n          \n            \n            {:toc}\n          \n          \n            \n            \n          \n          \n            \n            \n          \n          \n            \n            ## Why need Data Types\n          \n          \n            \n            \n          \n          \n            \n            In Python DataStream, a data type describes the type of a value in the DataStream ecosystem. \n          \n          \n            \n            It can be used to declare input and/or output types of operations. \n          \n          \n            \n            Similar to Python, you don't require to specify types for the parameters of a Function in Python DataStream. \n          \n          \n            \n            If the type has not been declared, data would be serialized or deserialized using Pickle. \n          \n          \n            \n            For example, the program below specifies no data types.\n          \n          \n            \n            In Apache Flink's Python DataStream API, a data type describes the type of a value in the DataStream ecosystem. \n          \n          \n            \n            It can be used to declare input and output types of operations and informs the system how to serailize elements. \n          \n          \n            \n            \n          \n          \n            \n            * This will be replaced by the TOC\n          \n          \n            \n            {:toc}\n          \n          \n            \n            \n          \n          \n            \n            \n          \n          \n            \n            ## Pickle Serialization\n          \n          \n            \n            \n          \n          \n            \n            If the type has not been declared, data would be serialized or deserialized using Pickle. \n          \n          \n            \n            For example, the program below specifies no data types.", "url": "https://github.com/apache/flink/pull/13199#discussion_r473065802", "createdAt": "2020-08-19T14:19:28Z", "author": {"login": "sjwiesman"}, "path": "docs/dev/python/user-guide/datastream/data_types.zh.md", "diffHunk": "@@ -0,0 +1,116 @@\n+---\n+title: \"Data Types\"\n+nav-parent_id: python_datastream_api\n+nav-pos: 10\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+* This will be replaced by the TOC\n+{:toc}\n+\n+\n+## Why need Data Types\n+\n+In Python DataStream, a data type describes the type of a value in the DataStream ecosystem. \n+It can be used to declare input and/or output types of operations. \n+Similar to Python, you don't require to specify types for the parameters of a Function in Python DataStream. \n+If the type has not been declared, data would be serialized or deserialized using Pickle. \n+For example, the program below specifies no data types.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a5329b994ede3de3bc97855a2dc6b302d92bd7b"}, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk1Njk4ODQxOnYy", "diffSide": "RIGHT", "path": "docs/dev/python/user-guide/datastream/data_types.zh.md", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQxNDoyMDoxMlrOHDJr3Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQxNDoyMDoxMlrOHDJr3Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzA2NjQ2MQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Since Java operators or functions can not identify Python data, types need to be provided to help to convert Python data to Java data for processing.\n          \n          \n            \n            For example, types need to be provided if you want to output data from the map into the StreamingFileSink. \n          \n          \n            \n            The StreamingFileSink is actually implemented by Java for the runtime part. \n          \n          \n            \n            Since Java operators or functions can not identify Python data, types need to be provided to help to convert Python types to Java types for processing.\n          \n          \n            \n            For example, types need to be provided if you want to output data using the StreamingFileSink which is implemented in Java.", "url": "https://github.com/apache/flink/pull/13199#discussion_r473066461", "createdAt": "2020-08-19T14:20:12Z", "author": {"login": "sjwiesman"}, "path": "docs/dev/python/user-guide/datastream/data_types.zh.md", "diffHunk": "@@ -0,0 +1,116 @@\n+---\n+title: \"Data Types\"\n+nav-parent_id: python_datastream_api\n+nav-pos: 10\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+* This will be replaced by the TOC\n+{:toc}\n+\n+\n+## Why need Data Types\n+\n+In Python DataStream, a data type describes the type of a value in the DataStream ecosystem. \n+It can be used to declare input and/or output types of operations. \n+Similar to Python, you don't require to specify types for the parameters of a Function in Python DataStream. \n+If the type has not been declared, data would be serialized or deserialized using Pickle. \n+For example, the program below specifies no data types.\n+\n+{% highlight python %}\n+from pyflink.datastream import StreamExecutionEnvironment\n+\n+\n+def processing():\n+    env = StreamExecutionEnvironment.get_execution_environment()\n+    env.set_parallelism(1)\n+    env.from_collection(collection=[(1, 'aaa'), (2, 'bbb')]) \\\n+        .map(lambda record: (record[0]+1, record[1].upper())) \\\n+        .print()  # note: print to stdout on the worker machine\n+\n+    env.execute()\n+\n+\n+if __name__ == '__main__':\n+    processing()\n+{% endhighlight %}\n+\n+However, types need to be specified when:\n+\n+- Passing Python records to Java operations.\n+- Improve serialization and deserialization performance.\n+\n+### Passing Python records to Java operations\n+\n+Since Java operators or functions can not identify Python data, types need to be provided to help to convert Python data to Java data for processing.\n+For example, types need to be provided if you want to output data from the map into the StreamingFileSink. \n+The StreamingFileSink is actually implemented by Java for the runtime part. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a5329b994ede3de3bc97855a2dc6b302d92bd7b"}, "originalPosition": 64}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk1Njk5MDM4OnYy", "diffSide": "RIGHT", "path": "docs/dev/python/user-guide/datastream/data_types.zh.md", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQxNDoyMDozOVrOHDJtKw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQxNDoyMDozOVrOHDJtKw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzA2Njc5NQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Even though data can be serialized and deserialized through Pickle, the performance should be better if types are provided. \n          \n          \n            \n            This is because PyFlink can use more efficient serializers and deserializers to serialize and deserialize data.\n          \n          \n            \n            Even though data can be serialized and deserialized through Pickle, performance will be better if types are provided.\n          \n          \n            \n            Explicit types allow PyFlink to use efficient serializers when moving records through the pipeline.", "url": "https://github.com/apache/flink/pull/13199#discussion_r473066795", "createdAt": "2020-08-19T14:20:39Z", "author": {"login": "sjwiesman"}, "path": "docs/dev/python/user-guide/datastream/data_types.zh.md", "diffHunk": "@@ -0,0 +1,116 @@\n+---\n+title: \"Data Types\"\n+nav-parent_id: python_datastream_api\n+nav-pos: 10\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+* This will be replaced by the TOC\n+{:toc}\n+\n+\n+## Why need Data Types\n+\n+In Python DataStream, a data type describes the type of a value in the DataStream ecosystem. \n+It can be used to declare input and/or output types of operations. \n+Similar to Python, you don't require to specify types for the parameters of a Function in Python DataStream. \n+If the type has not been declared, data would be serialized or deserialized using Pickle. \n+For example, the program below specifies no data types.\n+\n+{% highlight python %}\n+from pyflink.datastream import StreamExecutionEnvironment\n+\n+\n+def processing():\n+    env = StreamExecutionEnvironment.get_execution_environment()\n+    env.set_parallelism(1)\n+    env.from_collection(collection=[(1, 'aaa'), (2, 'bbb')]) \\\n+        .map(lambda record: (record[0]+1, record[1].upper())) \\\n+        .print()  # note: print to stdout on the worker machine\n+\n+    env.execute()\n+\n+\n+if __name__ == '__main__':\n+    processing()\n+{% endhighlight %}\n+\n+However, types need to be specified when:\n+\n+- Passing Python records to Java operations.\n+- Improve serialization and deserialization performance.\n+\n+### Passing Python records to Java operations\n+\n+Since Java operators or functions can not identify Python data, types need to be provided to help to convert Python data to Java data for processing.\n+For example, types need to be provided if you want to output data from the map into the StreamingFileSink. \n+The StreamingFileSink is actually implemented by Java for the runtime part. \n+\n+{% highlight python %}\n+from pyflink.common.serialization import SimpleStringEncoder\n+from pyflink.common.typeinfo import Types\n+from pyflink.datastream import StreamExecutionEnvironment\n+from pyflink.datastream.connectors import StreamingFileSink\n+\n+\n+def streaming_file_sink():\n+    env = StreamExecutionEnvironment.get_execution_environment()\n+    env.set_parallelism(1)\n+    env.from_collection(collection=[(1, 'aaa'), (2, 'bbb')]) \\\n+        .map(lambda record: (record[0]+1, record[1].upper()),\n+             result_type=Types.ROW([Types.INT(), Types.STRING()])) \\\n+        .add_sink(StreamingFileSink\n+                  .for_row_format('/tmp/output', SimpleStringEncoder())\n+                  .build())\n+\n+    env.execute()\n+\n+\n+if __name__ == '__main__':\n+    streaming_file_sink()\n+\n+{% endhighlight %}\n+\n+### Improve serialization and deserialization performance\n+\n+Even though data can be serialized and deserialized through Pickle, the performance should be better if types are provided. \n+This is because PyFlink can use more efficient serializers and deserializers to serialize and deserialize data.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a5329b994ede3de3bc97855a2dc6b302d92bd7b"}, "originalPosition": 94}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk1Njk5MjQ3OnYy", "diffSide": "RIGHT", "path": "docs/dev/python/user-guide/datastream/index.md", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQxNDoyMTowNVrOHDJubg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQxNTo0MzoyNlrOHDNa1g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzA2NzExOA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            nav-show_overview: true", "url": "https://github.com/apache/flink/pull/13199#discussion_r473067118", "createdAt": "2020-08-19T14:21:05Z", "author": {"login": "sjwiesman"}, "path": "docs/dev/python/user-guide/datastream/index.md", "diffHunk": "@@ -0,0 +1,32 @@\n+---\n+title: \"DataStream API\"\n+nav-id: python_datastream_api\n+nav-parent_id: python_user_guide\n+nav-pos: 30\n+nav-show_overview: true", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a5329b994ede3de3bc97855a2dc6b302d92bd7b"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzA2Nzc4OA==", "bodyText": "I don't think we need this page. Let's revisit this after the rest of the content is merged in.", "url": "https://github.com/apache/flink/pull/13199#discussion_r473067788", "createdAt": "2020-08-19T14:21:53Z", "author": {"login": "sjwiesman"}, "path": "docs/dev/python/user-guide/datastream/index.md", "diffHunk": "@@ -0,0 +1,32 @@\n+---\n+title: \"DataStream API\"\n+nav-id: python_datastream_api\n+nav-parent_id: python_user_guide\n+nav-pos: 30\n+nav-show_overview: true", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzA2NzExOA=="}, "originalCommit": {"oid": "9a5329b994ede3de3bc97855a2dc6b302d92bd7b"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzEyNzYzOA==", "bodyText": "ok, we can add this after all content are ready.", "url": "https://github.com/apache/flink/pull/13199#discussion_r473127638", "createdAt": "2020-08-19T15:43:26Z", "author": {"login": "hequn8128"}, "path": "docs/dev/python/user-guide/datastream/index.md", "diffHunk": "@@ -0,0 +1,32 @@\n+---\n+title: \"DataStream API\"\n+nav-id: python_datastream_api\n+nav-parent_id: python_user_guide\n+nav-pos: 30\n+nav-show_overview: true", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzA2NzExOA=="}, "originalCommit": {"oid": "9a5329b994ede3de3bc97855a2dc6b302d92bd7b"}, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk1Njk5MzY4OnYy", "diffSide": "RIGHT", "path": "docs/dev/python/user-guide/datastream/index.md", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQxNDoyMToxN1rOHDJvGA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQxNDoyMToxN1rOHDJvGA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzA2NzI4OA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Python DataStream API allows users to develop [DataStream API]({{ site.baseurl }}/dev/datastream_api.html) programs using the Python language.\n          \n          \n            \n            Apache Flink has provided Python DataStream API support since 1.12.0.\n          \n          \n            \n            \n          \n          \n            \n            ## Where to go next?\n          \n          \n            \n            \n          \n          \n            \n            - [Data Types]({{ site.baseurl }}/dev/python/user-guide/datastream/data_types.html): Lists the supported data types in Python DataStream API.", "url": "https://github.com/apache/flink/pull/13199#discussion_r473067288", "createdAt": "2020-08-19T14:21:17Z", "author": {"login": "sjwiesman"}, "path": "docs/dev/python/user-guide/datastream/index.md", "diffHunk": "@@ -0,0 +1,32 @@\n+---\n+title: \"DataStream API\"\n+nav-id: python_datastream_api\n+nav-parent_id: python_user_guide\n+nav-pos: 30\n+nav-show_overview: true\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+Python DataStream API allows users to develop [DataStream API]({{ site.baseurl }}/dev/datastream_api.html) programs using the Python language.\n+Apache Flink has provided Python DataStream API support since 1.12.0.\n+\n+## Where to go next?\n+\n+- [Data Types]({{ site.baseurl }}/dev/python/user-guide/datastream/data_types.html): Lists the supported data types in Python DataStream API.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a5329b994ede3de3bc97855a2dc6b302d92bd7b"}, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk1ODM3MDY3OnYy", "diffSide": "RIGHT", "path": "docs/dev/python/user-guide/datastream/data_types.md", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQyMDoxMDoxNVrOHDXVdw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQyMDoxMDoxNVrOHDXVdw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzI5MDEwMw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            ## Pickle Serialization\n          \n          \n            \n            If the type has not been declared, data would be serialized or deserialized using Pickle. \n          \n          \n            \n            ## Pickle Serialization\n          \n          \n            \n            \n          \n          \n            \n            If the type has not been declared, data would be serialized or deserialized using Pickle.", "url": "https://github.com/apache/flink/pull/13199#discussion_r473290103", "createdAt": "2020-08-19T20:10:15Z", "author": {"login": "sjwiesman"}, "path": "docs/dev/python/user-guide/datastream/data_types.md", "diffHunk": "@@ -0,0 +1,114 @@\n+---\n+title: \"Data Types\"\n+nav-parent_id: python_datastream_api\n+nav-pos: 10\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+In Apache Flink's Python DataStream API, a data type describes the type of a value in the DataStream ecosystem. \n+It can be used to declare input and output types of operations and informs the system how to serailize elements. \n+\n+* This will be replaced by the TOC\n+{:toc}\n+\n+\n+## Pickle Serialization\n+If the type has not been declared, data would be serialized or deserialized using Pickle. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c2d450efbdda3b25cafa41cc5b1323ab43630a38"}, "originalPosition": 33}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 479, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}