{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDYzMjYxNDUy", "number": 13066, "reviewThreads": {"totalCount": 60, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQwOTo0OTo0OFrOEVV3Rg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwOTo0OTo1OFrOEWJvdw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwODEzNzY2OnYy", "diffSide": "RIGHT", "path": "flink-python/pyflink/proto/flink-fn-execution.proto", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQwOTo0OTo0OFrOG8Ccqg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQwOTo0OTo0OFrOG8Ccqg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTYwNzg1MA==", "bodyText": "Please remove the useless type, e.g., VOID, LOCAL_DATE, etc.", "url": "https://github.com/apache/flink/pull/13066#discussion_r465607850", "createdAt": "2020-08-05T09:49:48Z", "author": {"login": "hequn8128"}, "path": "flink-python/pyflink/proto/flink-fn-execution.proto", "diffHunk": "@@ -147,3 +163,50 @@ message Schema {\n \n   repeated Field fields = 1;\n }\n+\n+// A representation of the data type information of a data stream.\n+message TypeInfo {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7"}, "originalPosition": 29}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwODE3ODQ5OnYy", "diffSide": "RIGHT", "path": "flink-python/pyflink/fn_execution/coders.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxMDowMTozM1rOG8C2KQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxMDowMTozM1rOG8C2KQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTYxNDM3Nw==", "bodyText": "I think return None is not a good chocie. Maybe you can raise a exception", "url": "https://github.com/apache/flink/pull/13066#discussion_r465614377", "createdAt": "2020-08-05T10:01:33Z", "author": {"login": "HuangXingBo"}, "path": "flink-python/pyflink/fn_execution/coders.py", "diffHunk": "@@ -332,6 +400,39 @@ def __init__(self, precision, timezone):\n     def get_impl(self):\n         return coder_impl.LocalZonedTimestampCoderImpl(self.precision, self.timezone)\n \n+    def get_slow_impl(self):\n+        return coder_impl_slow.LocalZonedTimestampCoderImpl(self.precision, self.timezone)\n+\n+\n+class PickledBytesCoder(FieldCoder):\n+\n+    def get_impl(self):\n+        return None", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1379a882e8dd7bcfea2a855847ba672f9fc4047d"}, "originalPosition": 218}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwODE3OTEzOnYy", "diffSide": "RIGHT", "path": "flink-python/pyflink/fn_execution/coders.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxMDowMTo0NFrOG8C2jA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxMDowMTo0NFrOG8C2jA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTYxNDQ3Ng==", "bodyText": "ditto", "url": "https://github.com/apache/flink/pull/13066#discussion_r465614476", "createdAt": "2020-08-05T10:01:44Z", "author": {"login": "HuangXingBo"}, "path": "flink-python/pyflink/fn_execution/coders.py", "diffHunk": "@@ -332,6 +400,39 @@ def __init__(self, precision, timezone):\n     def get_impl(self):\n         return coder_impl.LocalZonedTimestampCoderImpl(self.precision, self.timezone)\n \n+    def get_slow_impl(self):\n+        return coder_impl_slow.LocalZonedTimestampCoderImpl(self.precision, self.timezone)\n+\n+\n+class PickledBytesCoder(FieldCoder):\n+\n+    def get_impl(self):\n+        return None\n+\n+    def get_slow_impl(self):\n+        return coder_impl_slow.PickledBytesCoderImpl()\n+\n+\n+class TupleCoder(FieldCoder):\n+\n+    def __init__(self, field_coders):\n+        self._field_coders = field_coders\n+\n+    def get_slow_impl(self):\n+        return self._create_impl()\n+\n+    def get_impl(self):\n+        return None", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1379a882e8dd7bcfea2a855847ba672f9fc4047d"}, "originalPosition": 233}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwODIyNDU2OnYy", "diffSide": "RIGHT", "path": "flink-python/pyflink/fn_execution/coders.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxMDoxNToyOVrOG8DSlQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxMDoxNToyOVrOG8DSlQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTYyMTY1Mw==", "bodyText": "Maybe we can write a more python code:\ntry:\nreturn catch _type_info_name_mappings[field_type_name]\ncatch KeyError:\n# other coder logic", "url": "https://github.com/apache/flink/pull/13066#discussion_r465621653", "createdAt": "2020-08-05T10:15:29Z", "author": {"login": "HuangXingBo"}, "path": "flink-python/pyflink/fn_execution/coders.py", "diffHunk": "@@ -379,3 +480,40 @@ def from_proto(field_type):\n                             field_type.decimal_info.scale)\n     else:\n         raise ValueError(\"field_type %s is not supported.\" % field_type)\n+\n+\n+# for data stream type information.\n+type_info_name = flink_fn_execution_pb2.TypeInfo\n+_type_info_name_mappings = {\n+    type_info_name.STRING: CharCoder(),\n+    type_info_name.BYTE: TinyIntCoder(),\n+    type_info_name.BOOLEAN: BooleanCoder(),\n+    type_info_name.SHORT: SmallIntCoder(),\n+    type_info_name.INT: IntCoder(),\n+    type_info_name.LONG: BigIntCoder(),\n+    type_info_name.FLOAT: FloatCoder(),\n+    type_info_name.DOUBLE: DoubleCoder(),\n+    type_info_name.CHAR: CharCoder(),\n+    type_info_name.BIG_INT: BigIntCoder(),\n+    type_info_name.BIG_DEC: BasicDecimalCoder(),\n+    type_info_name.SQL_DATE: DateCoder(),\n+    type_info_name.SQL_TIME: TimeCoder(),\n+    type_info_name.SQL_TIMESTAMP: TimeCoder(),\n+    type_info_name.LOCAL_DATE: DateCoder(),\n+    type_info_name.PICKLED_BYTES: PickledBytesCoder()\n+}\n+\n+\n+def from_type_info_proto(field_type):\n+    field_type_name = field_type.type_name\n+    coder = _type_info_name_mappings.get(field_type_name)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1379a882e8dd7bcfea2a855847ba672f9fc4047d"}, "originalPosition": 277}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwODIyODUxOnYy", "diffSide": "RIGHT", "path": "flink-python/pyflink/fn_execution/coders.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxMDoxNjo0M1rOG8DVDQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxMDoxNjo0M1rOG8DVDQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTYyMjI4NQ==", "bodyText": "I think it is a temporary solution for no-cython coder.Right?", "url": "https://github.com/apache/flink/pull/13066#discussion_r465622285", "createdAt": "2020-08-05T10:16:43Z", "author": {"login": "HuangXingBo"}, "path": "flink-python/pyflink/fn_execution/coders.py", "diffHunk": "@@ -109,6 +112,10 @@ def __hash__(self):\n \n \n class FieldCoder(ABC):\n+\n+    def get_slow_impl(self):\n+        pass", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1379a882e8dd7bcfea2a855847ba672f9fc4047d"}, "originalPosition": 29}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwODIzMTQwOnYy", "diffSide": "RIGHT", "path": "flink-python/pyflink/fn_execution/beam/beam_operations_slow.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxMDoxNzozOVrOG8DW8w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxMDoxNzozOVrOG8DW8w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTYyMjc3MQ==", "bodyText": "Use operation_utils . DATA_STREAM_FUNCTION_URN  and Don't import DATA_STREAM_FUNCTION_URN directly.", "url": "https://github.com/apache/flink/pull/13066#discussion_r465622771", "createdAt": "2020-08-05T10:17:39Z", "author": {"login": "HuangXingBo"}, "path": "flink-python/pyflink/fn_execution/beam/beam_operations_slow.py", "diffHunk": "@@ -154,6 +167,13 @@ def create_table_function(factory, transform_id, transform_proto, parameter, con\n         factory, transform_proto, consumers, parameter, TableFunctionOperation)\n \n \n+@bundle_processor.BeamTransformFactory.register_urn(\n+    DATA_STREAM_FUNCTION_URN, flink_fn_execution_pb2.UserDefinedDataStreamFunctions)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1379a882e8dd7bcfea2a855847ba672f9fc4047d"}, "originalPosition": 42}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwODQ0MjA0OnYy", "diffSide": "RIGHT", "path": "flink-python/pyflink/fn_execution/beam/beam_coder_impl_slow.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxMToyMTowNlrOG8FZHQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxMToyMTowNlrOG8FZHQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTY1NjA5Mw==", "bodyText": "Maybe we can use list comprehension", "url": "https://github.com/apache/flink/pull/13066#discussion_r465656093", "createdAt": "2020-08-05T11:21:06Z", "author": {"login": "HuangXingBo"}, "path": "flink-python/pyflink/fn_execution/beam/beam_coder_impl_slow.py", "diffHunk": "@@ -305,6 +368,39 @@ def decode_from_stream(self, in_stream, nested):\n         return value\n \n \n+class BasicDecimalCoderImpl(StreamCoderImpl):\n+\n+    def encode_to_stream(self, value, stream, nested):\n+        bytes_value = str(value).encode(\"utf-8\")\n+        stream.write_bigendian_int32(len(bytes_value))\n+        stream.write(bytes_value, False)\n+\n+    def decode_from_stream(self, stream, nested):\n+        size = stream.read_bigendian_int32()\n+        value = decimal.Decimal(stream.read(size).decode(\"utf-8\"))\n+        return value\n+\n+\n+class TupleCoderImpl(StreamCoderImpl):\n+    def __init__(self, field_coders):\n+        self._field_coders = field_coders\n+        self._field_count = len(field_coders)\n+\n+    def encode_to_stream(self, value, out_stream, nested):\n+        field_coders = self._field_coders\n+        for i in range(self._field_count):\n+            field_coders[i].encode_to_stream(value[i], out_stream, nested)\n+\n+    def decode_from_stream(self, stream, nested):\n+        decoded_list = []\n+        for idx in range(self._field_count):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1379a882e8dd7bcfea2a855847ba672f9fc4047d"}, "originalPosition": 106}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwODQ1MDE3OnYy", "diffSide": "RIGHT", "path": "flink-python/pyflink/fn_execution/beam/beam_coders.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxMToyNDowM1rOG8FeUA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwMzowMzozOVrOG9K4tA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTY1NzQyNA==", "bodyText": "use typehints.Generator", "url": "https://github.com/apache/flink/pull/13066#discussion_r465657424", "createdAt": "2020-08-05T11:24:03Z", "author": {"login": "HuangXingBo"}, "path": "flink-python/pyflink/fn_execution/beam/beam_coders.py", "diffHunk": "@@ -209,3 +211,51 @@ def _to_row_type(row_schema):\n \n     def __repr__(self):\n         return 'ArrowCoder[%s]' % self._schema\n+\n+\n+class DataStreamStatelessMapCoder(FastCoder):\n+\n+    def __init__(self, field_coder):\n+        self._field_coder = field_coder\n+\n+    def _create_impl(self):\n+        return beam_coder_impl_slow.DataStreamStatelessMapCoderImpl(\n+            self._field_coder.get_slow_impl())\n+\n+    def is_deterministic(self):  # type: () -> bool\n+        return all(c.is_deterministic() for c in self._field_coder)\n+\n+    @Coder.register_urn(FLINK_MAP_FUNCTION_DATA_STREAM_CODER_URN, flink_fn_execution_pb2.TypeInfo)\n+    def _pickled_from_runner_api_parameter(type_info_proto, unused_components, unused_context):\n+        return DataStreamStatelessMapCoder(from_type_info_proto(type_info_proto.field[0].type))\n+\n+    def to_type_hint(self):\n+        pass", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1379a882e8dd7bcfea2a855847ba672f9fc4047d"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njc5NDY3Ng==", "bodyText": "return self._field_coder.to_type_hint ?", "url": "https://github.com/apache/flink/pull/13066#discussion_r466794676", "createdAt": "2020-08-07T03:03:39Z", "author": {"login": "hequn8128"}, "path": "flink-python/pyflink/fn_execution/beam/beam_coders.py", "diffHunk": "@@ -209,3 +211,51 @@ def _to_row_type(row_schema):\n \n     def __repr__(self):\n         return 'ArrowCoder[%s]' % self._schema\n+\n+\n+class DataStreamStatelessMapCoder(FastCoder):\n+\n+    def __init__(self, field_coder):\n+        self._field_coder = field_coder\n+\n+    def _create_impl(self):\n+        return beam_coder_impl_slow.DataStreamStatelessMapCoderImpl(\n+            self._field_coder.get_slow_impl())\n+\n+    def is_deterministic(self):  # type: () -> bool\n+        return all(c.is_deterministic() for c in self._field_coder)\n+\n+    @Coder.register_urn(FLINK_MAP_FUNCTION_DATA_STREAM_CODER_URN, flink_fn_execution_pb2.TypeInfo)\n+    def _pickled_from_runner_api_parameter(type_info_proto, unused_components, unused_context):\n+        return DataStreamStatelessMapCoder(from_type_info_proto(type_info_proto.field[0].type))\n+\n+    def to_type_hint(self):\n+        pass", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTY1NzQyNA=="}, "originalCommit": {"oid": "1379a882e8dd7bcfea2a855847ba672f9fc4047d"}, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwODQ1NDAxOnYy", "diffSide": "RIGHT", "path": "flink-python/pyflink/fn_execution/beam/beam_coders.py", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxMToyNToxNVrOG8FgrA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxMToyNToxNVrOG8FgrA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTY1ODAyOA==", "bodyText": "ditto", "url": "https://github.com/apache/flink/pull/13066#discussion_r465658028", "createdAt": "2020-08-05T11:25:15Z", "author": {"login": "HuangXingBo"}, "path": "flink-python/pyflink/fn_execution/beam/beam_coders.py", "diffHunk": "@@ -209,3 +211,51 @@ def _to_row_type(row_schema):\n \n     def __repr__(self):\n         return 'ArrowCoder[%s]' % self._schema\n+\n+\n+class DataStreamStatelessMapCoder(FastCoder):\n+\n+    def __init__(self, field_coder):\n+        self._field_coder = field_coder\n+\n+    def _create_impl(self):\n+        return beam_coder_impl_slow.DataStreamStatelessMapCoderImpl(\n+            self._field_coder.get_slow_impl())\n+\n+    def is_deterministic(self):  # type: () -> bool\n+        return all(c.is_deterministic() for c in self._field_coder)\n+\n+    @Coder.register_urn(FLINK_MAP_FUNCTION_DATA_STREAM_CODER_URN, flink_fn_execution_pb2.TypeInfo)\n+    def _pickled_from_runner_api_parameter(type_info_proto, unused_components, unused_context):\n+        return DataStreamStatelessMapCoder(from_type_info_proto(type_info_proto.field[0].type))\n+\n+    def to_type_hint(self):\n+        pass\n+\n+    def __repr__(self):\n+        return 'DataStreamStatelessMapCoder[%s]' % repr(self._field_coder)\n+\n+\n+class DataStreamStatelessFlatMapCoder(FastCoder):\n+\n+    def __init__(self, field_coder):\n+        self._field_coder = field_coder\n+\n+    def _create_impl(self):\n+        return beam_coder_impl_slow.DataStreamStatelessFlatMapCoderImpl(\n+            self._field_coder.get_impl())\n+\n+    def is_deterministic(self):  # type: () -> bool\n+        return all(c.is_deterministic() for c in self._field_coder)\n+\n+    @Coder.register_urn(FLINK_FLAT_MAP_FUNCTION_DATA_STREAM_CODER_URN,\n+                        flink_fn_execution_pb2.TypeInfo)\n+    def _pickled_from_runner_api_parameter(type_info_proto, unused_components, unused_context):\n+        return DataStreamStatelessFlatMapCoder(DataStreamStatelessMapCoder(\n+            from_type_info_proto(type_info_proto.field[0].type)))\n+\n+    def to_type_hint(self):\n+        pass", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1379a882e8dd7bcfea2a855847ba672f9fc4047d"}, "originalPosition": 57}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwODQ2NzM5OnYy", "diffSide": "RIGHT", "path": "flink-python/pyflink/fn_execution/beam/beam_coder_impl_slow.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxMToyOTozMlrOG8FotQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxMToyOTozMlrOG8FotQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTY2MDA4NQ==", "bodyText": "Why not call the method encode_to_stream of the field_coder? The method of encode will create a temporary buffer.", "url": "https://github.com/apache/flink/pull/13066#discussion_r465660085", "createdAt": "2020-08-05T11:29:32Z", "author": {"login": "HuangXingBo"}, "path": "flink-python/pyflink/fn_execution/beam/beam_coder_impl_slow.py", "diffHunk": "@@ -186,6 +187,68 @@ def __repr__(self):\n         return 'ArrayCoderImpl[%s]' % repr(self._elem_coder)\n \n \n+class PickledBytesCoderImpl(StreamCoderImpl):\n+\n+    def __init__(self):\n+        self.field_coder = BinaryCoderImpl()\n+\n+    def encode_to_stream(self, value, out_stream, nested):\n+        coded_data = pickle.dumps(value)\n+        real_coded_data = self.field_coder.encode(coded_data)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1379a882e8dd7bcfea2a855847ba672f9fc4047d"}, "originalPosition": 19}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwODQ5ODUxOnYy", "diffSide": "RIGHT", "path": "flink-python/pyflink/fn_execution/beam/beam_coders.py", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxMTozOTozNVrOG8F7kg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxMTozOTozNVrOG8F7kg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTY2NDkxNA==", "bodyText": "Since its filed coder is a certain type, we can use a more specific name", "url": "https://github.com/apache/flink/pull/13066#discussion_r465664914", "createdAt": "2020-08-05T11:39:35Z", "author": {"login": "HuangXingBo"}, "path": "flink-python/pyflink/fn_execution/beam/beam_coders.py", "diffHunk": "@@ -209,3 +211,51 @@ def _to_row_type(row_schema):\n \n     def __repr__(self):\n         return 'ArrowCoder[%s]' % self._schema\n+\n+\n+class DataStreamStatelessMapCoder(FastCoder):\n+\n+    def __init__(self, field_coder):\n+        self._field_coder = field_coder", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1379a882e8dd7bcfea2a855847ba672f9fc4047d"}, "originalPosition": 18}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwODUwNzAyOnYy", "diffSide": "RIGHT", "path": "flink-python/pyflink/fn_execution/tests/test_coders.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxMTo0MjozMVrOG8GA4g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxMTo0MjozMVrOG8GA4g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTY2NjI3NA==", "bodyText": "1.200 is a float, not a Decimal.", "url": "https://github.com/apache/flink/pull/13066#discussion_r465666274", "createdAt": "2020-08-05T11:42:31Z", "author": {"login": "HuangXingBo"}, "path": "flink-python/pyflink/fn_execution/tests/test_coders.py", "diffHunk": "@@ -154,6 +154,17 @@ def test_row_coder(self):\n         v = Row(*[None if i % 2 == 0 else i for i in range(field_count)])\n         self.check_coder(coder, v)\n \n+    def test_basic_decimal_coder(self):\n+        basic_dec_coder = BasicDecimalCoder()\n+        value = 1.200", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1379a882e8dd7bcfea2a855847ba672f9fc4047d"}, "originalPosition": 15}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwODUxMzIxOnYy", "diffSide": "RIGHT", "path": "flink-python/pyflink/fn_execution/coders.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxMTo0NDozNFrOG8GEuA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxMTo0NDozNFrOG8GEuA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTY2NzI1Ng==", "bodyText": "You should use typehints.Tuple", "url": "https://github.com/apache/flink/pull/13066#discussion_r465667256", "createdAt": "2020-08-05T11:44:34Z", "author": {"login": "HuangXingBo"}, "path": "flink-python/pyflink/fn_execution/coders.py", "diffHunk": "@@ -332,6 +400,39 @@ def __init__(self, precision, timezone):\n     def get_impl(self):\n         return coder_impl.LocalZonedTimestampCoderImpl(self.precision, self.timezone)\n \n+    def get_slow_impl(self):\n+        return coder_impl_slow.LocalZonedTimestampCoderImpl(self.precision, self.timezone)\n+\n+\n+class PickledBytesCoder(FieldCoder):\n+\n+    def get_impl(self):\n+        return None\n+\n+    def get_slow_impl(self):\n+        return coder_impl_slow.PickledBytesCoderImpl()\n+\n+\n+class TupleCoder(FieldCoder):\n+\n+    def __init__(self, field_coders):\n+        self._field_coders = field_coders\n+\n+    def get_slow_impl(self):\n+        return self._create_impl()\n+\n+    def get_impl(self):\n+        return None\n+\n+    def _create_impl(self):\n+        return coder_impl_slow.TupleCoderImpl([c.get_impl() for c in self._field_coders])\n+\n+    def to_type_hint(self):\n+        return tuple", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1379a882e8dd7bcfea2a855847ba672f9fc4047d"}, "originalPosition": 239}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwODUxODA0OnYy", "diffSide": "RIGHT", "path": "flink-python/pyflink/fn_execution/coders.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxMTo0NTo1NFrOG8GHeA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxMTo0NTo1NFrOG8GHeA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTY2Nzk2MA==", "bodyText": "Maybe it is return coder_impl_slow.TupleCoderImpl([c. get_slow_impl() for c in self._field_coders]) ?", "url": "https://github.com/apache/flink/pull/13066#discussion_r465667960", "createdAt": "2020-08-05T11:45:54Z", "author": {"login": "HuangXingBo"}, "path": "flink-python/pyflink/fn_execution/coders.py", "diffHunk": "@@ -332,6 +400,39 @@ def __init__(self, precision, timezone):\n     def get_impl(self):\n         return coder_impl.LocalZonedTimestampCoderImpl(self.precision, self.timezone)\n \n+    def get_slow_impl(self):\n+        return coder_impl_slow.LocalZonedTimestampCoderImpl(self.precision, self.timezone)\n+\n+\n+class PickledBytesCoder(FieldCoder):\n+\n+    def get_impl(self):\n+        return None\n+\n+    def get_slow_impl(self):\n+        return coder_impl_slow.PickledBytesCoderImpl()\n+\n+\n+class TupleCoder(FieldCoder):\n+\n+    def __init__(self, field_coders):\n+        self._field_coders = field_coders\n+\n+    def get_slow_impl(self):\n+        return self._create_impl()\n+\n+    def get_impl(self):\n+        return None\n+\n+    def _create_impl(self):\n+        return coder_impl_slow.TupleCoderImpl([c.get_impl() for c in self._field_coders])", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1379a882e8dd7bcfea2a855847ba672f9fc4047d"}, "originalPosition": 236}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwODUyNDI5OnYy", "diffSide": "RIGHT", "path": "flink-python/pyflink/fn_execution/coders.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxMTo0Nzo1NFrOG8GLXQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxMTo0Nzo1NFrOG8GLXQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTY2ODk1Nw==", "bodyText": "I think return None is not a good chocie. Maybe you can raise a exception", "url": "https://github.com/apache/flink/pull/13066#discussion_r465668957", "createdAt": "2020-08-05T11:47:54Z", "author": {"login": "HuangXingBo"}, "path": "flink-python/pyflink/fn_execution/coders.py", "diffHunk": "@@ -271,6 +309,21 @@ def __init__(self, precision, scale):\n     def get_impl(self):\n         return coder_impl.DecimalCoderImpl(self.precision, self.scale)\n \n+    def get_slow_impl(self):\n+        return coder_impl_slow.DecimalCoderImpl(self.precision, self.scale)\n+\n+\n+class BasicDecimalCoder(FieldCoder):\n+    \"\"\"\n+    Coder for Basic Decimal that no need to have precision and scale specified.\n+    \"\"\"\n+\n+    def get_impl(self):\n+        pass", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1379a882e8dd7bcfea2a855847ba672f9fc4047d"}, "originalPosition": 149}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMTIyNzkxOnYy", "diffSide": "RIGHT", "path": "flink-python/pyflink/fn_execution/coders.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMTo0Njo1NlrOG8gV4A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMTo0Njo1NlrOG8gV4A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjA5NzYzMg==", "bodyText": "Rename to BigDecimalCoder?", "url": "https://github.com/apache/flink/pull/13066#discussion_r466097632", "createdAt": "2020-08-06T01:46:56Z", "author": {"login": "hequn8128"}, "path": "flink-python/pyflink/fn_execution/coders.py", "diffHunk": "@@ -271,6 +309,21 @@ def __init__(self, precision, scale):\n     def get_impl(self):\n         return coder_impl.DecimalCoderImpl(self.precision, self.scale)\n \n+    def get_slow_impl(self):\n+        return coder_impl_slow.DecimalCoderImpl(self.precision, self.scale)\n+\n+\n+class BasicDecimalCoder(FieldCoder):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7"}, "originalPosition": 143}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMTIzODc4OnYy", "diffSide": "RIGHT", "path": "flink-python/pyflink/fn_execution/operation_utils.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMTo1MzoxN1rOG8gcGQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMTo1MzoxN1rOG8gcGQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjA5OTIyNQ==", "bodyText": "DATA_STREAM_STATELESS_FUNCTION_URN?", "url": "https://github.com/apache/flink/pull/13066#discussion_r466099225", "createdAt": "2020-08-06T01:53:17Z", "author": {"login": "hequn8128"}, "path": "flink-python/pyflink/fn_execution/operation_utils.py", "diffHunk": "@@ -20,11 +20,13 @@\n import cloudpickle\n from typing import Any, Tuple, Dict, List\n \n+from pyflink.fn_execution import flink_fn_execution_pb2\n from pyflink.serializers import PickleSerializer\n from pyflink.table.udf import DelegationTableFunction, DelegatingScalarFunction\n \n SCALAR_FUNCTION_URN = \"flink:transform:scalar_function:v1\"\n TABLE_FUNCTION_URN = \"flink:transform:table_function:v1\"\n+DATA_STREAM_FUNCTION_URN = \"flink:transform:datastream_stateless_function:v1\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7"}, "originalPosition": 10}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMTI0MDMzOnYy", "diffSide": "RIGHT", "path": "flink-python/pyflink/proto/flink-fn-execution.proto", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMTo1NDowOVrOG8gdBQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMTo1NDowOVrOG8gdBQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjA5OTQ2MQ==", "bodyText": "data stream => DataStream. And for other places.", "url": "https://github.com/apache/flink/pull/13066#discussion_r466099461", "createdAt": "2020-08-06T01:54:09Z", "author": {"login": "hequn8128"}, "path": "flink-python/pyflink/proto/flink-fn-execution.proto", "diffHunk": "@@ -52,6 +52,22 @@ message UserDefinedFunctions {\n   bool metric_enabled = 2;\n }\n \n+// User defined data stream function definition.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMTI0NTY5OnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/functions/python/DataStreamPythonFunction.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMTo1NzowMlrOG8ggIg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMTo1NzowMlrOG8ggIg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwMDI1OA==", "bodyText": "maintains", "url": "https://github.com/apache/flink/pull/13066#discussion_r466100258", "createdAt": "2020-08-06T01:57:02Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/functions/python/DataStreamPythonFunction.java", "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.datastream.runtime.functions.python;\n+\n+import org.apache.flink.table.functions.python.PythonEnv;\n+import org.apache.flink.table.functions.python.PythonFunction;\n+\n+/**\n+ * DataStreamPythonFunction maintain the serialized python function and its function type, which will be used in", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMTI0ODExOnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/functions/python/DataStreamPythonFunction.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMTo1ODozM1rOG8ghjg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMTo1ODozM1rOG8ghjg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwMDYyMg==", "bodyText": "DataStreamPythonFunction => {@link DataStreamPythonFunction}. Same for other places.", "url": "https://github.com/apache/flink/pull/13066#discussion_r466100622", "createdAt": "2020-08-06T01:58:33Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/functions/python/DataStreamPythonFunction.java", "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.datastream.runtime.functions.python;\n+\n+import org.apache.flink.table.functions.python.PythonEnv;\n+import org.apache.flink.table.functions.python.PythonFunction;\n+\n+/**\n+ * DataStreamPythonFunction maintain the serialized python function and its function type, which will be used in", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMTI1MDM2OnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/functions/python/DataStreamPythonFunctionInfo.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMTo1OTo1M1rOG8gi2g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMTo1OTo1M1rOG8gi2g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwMDk1NA==", "bodyText": "DataStreamPythonFunctionInfo => {@link DataStreamPythonFunctionInfo}", "url": "https://github.com/apache/flink/pull/13066#discussion_r466100954", "createdAt": "2020-08-06T01:59:53Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/functions/python/DataStreamPythonFunctionInfo.java", "diffHunk": "@@ -0,0 +1,46 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.datastream.runtime.functions.python;\n+\n+import org.apache.flink.table.functions.python.PythonFunction;\n+\n+import java.io.Serializable;\n+\n+/**\n+ * DataStreamPythonFunctionInfo holds a PythonFunction and its function type.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMTI1ODUxOnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/functions/python/DataStreamPythonFunction.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjowNDoxOFrOG8gnjw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjowNDoxOFrOG8gnjw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwMjE1OQ==", "bodyText": "private static final long serialVersionUID = 1L;", "url": "https://github.com/apache/flink/pull/13066#discussion_r466102159", "createdAt": "2020-08-06T02:04:18Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/functions/python/DataStreamPythonFunction.java", "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.datastream.runtime.functions.python;\n+\n+import org.apache.flink.table.functions.python.PythonEnv;\n+import org.apache.flink.table.functions.python.PythonFunction;\n+\n+/**\n+ * DataStreamPythonFunction maintain the serialized python function and its function type, which will be used in\n+ * DataStreamPythonFunctionRunner.\n+ */\n+public class DataStreamPythonFunction implements PythonFunction {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7"}, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMTI2MTY4OnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/functions/python/DataStreamPythonFunctionInfo.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjowNTozNVrOG8gpKg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjowNTozNVrOG8gpKg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwMjU3MA==", "bodyText": "We don't need to separate lines here.", "url": "https://github.com/apache/flink/pull/13066#discussion_r466102570", "createdAt": "2020-08-06T02:05:35Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/functions/python/DataStreamPythonFunctionInfo.java", "diffHunk": "@@ -0,0 +1,46 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.datastream.runtime.functions.python;\n+\n+import org.apache.flink.table.functions.python.PythonFunction;\n+\n+import java.io.Serializable;\n+\n+/**\n+ * DataStreamPythonFunctionInfo holds a PythonFunction and its function type.\n+ * */\n+public class DataStreamPythonFunctionInfo implements Serializable {\n+\tprivate static final long serialVersionUID = 1L;\n+\n+\tprivate final PythonFunction pythonFunction;\n+\tprivate final int functionType;\n+\n+\tpublic DataStreamPythonFunctionInfo(PythonFunction pythonFunction,\n+\t\t\t\t\t\t\t\t\t\tint functionType) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7"}, "originalPosition": 34}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMTI2MzA5OnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/operators/python/DataStreamPythonStatelessFunctionOperator.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjowNjoyM1rOG8gp9w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjowNjoyM1rOG8gp9w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwMjc3NQ==", "bodyText": "DataStreamPythonFunctionOperator => {@link DataStreamPythonFunctionOperator}", "url": "https://github.com/apache/flink/pull/13066#discussion_r466102775", "createdAt": "2020-08-06T02:06:23Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/operators/python/DataStreamPythonStatelessFunctionOperator.java", "diffHunk": "@@ -0,0 +1,154 @@\n+package org.apache.flink.datastream.runtime.operators.python;\n+\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.core.memory.ByteArrayInputStreamWithPos;\n+import org.apache.flink.core.memory.ByteArrayOutputStreamWithPos;\n+import org.apache.flink.core.memory.DataInputViewStreamWrapper;\n+import org.apache.flink.core.memory.DataOutputViewStreamWrapper;\n+import org.apache.flink.datastream.runtime.functions.python.DataStreamPythonFunctionInfo;\n+import org.apache.flink.datastream.runtime.runners.python.beam.BeamDataStreamPythonStatelessFunctionRunner;\n+import org.apache.flink.datastream.runtime.typeutils.python.PythonTypeUtils;\n+import org.apache.flink.fnexecution.v1.FlinkFnApi;\n+import org.apache.flink.python.PythonFunctionRunner;\n+import org.apache.flink.streaming.api.operators.python.AbstractPythonFunctionOperator;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.table.functions.python.PythonEnv;\n+import org.apache.flink.table.runtime.util.StreamRecordCollector;\n+\n+import com.google.protobuf.ByteString;\n+\n+import java.util.Map;\n+import java.util.concurrent.LinkedBlockingQueue;\n+\n+/**\n+ * DataStreamPythonFunctionOperator is responsible for launching beam runner which will start a python harness to", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7"}, "originalPosition": 27}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMTI2NTE4OnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/operators/python/DataStreamPythonStatelessFunctionOperator.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjowNzozNVrOG8grLw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjowNzozNVrOG8grLw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwMzA4Nw==", "bodyText": "Please remove these unnecessary variables.", "url": "https://github.com/apache/flink/pull/13066#discussion_r466103087", "createdAt": "2020-08-06T02:07:35Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/operators/python/DataStreamPythonStatelessFunctionOperator.java", "diffHunk": "@@ -0,0 +1,154 @@\n+package org.apache.flink.datastream.runtime.operators.python;\n+\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.core.memory.ByteArrayInputStreamWithPos;\n+import org.apache.flink.core.memory.ByteArrayOutputStreamWithPos;\n+import org.apache.flink.core.memory.DataInputViewStreamWrapper;\n+import org.apache.flink.core.memory.DataOutputViewStreamWrapper;\n+import org.apache.flink.datastream.runtime.functions.python.DataStreamPythonFunctionInfo;\n+import org.apache.flink.datastream.runtime.runners.python.beam.BeamDataStreamPythonStatelessFunctionRunner;\n+import org.apache.flink.datastream.runtime.typeutils.python.PythonTypeUtils;\n+import org.apache.flink.fnexecution.v1.FlinkFnApi;\n+import org.apache.flink.python.PythonFunctionRunner;\n+import org.apache.flink.streaming.api.operators.python.AbstractPythonFunctionOperator;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.table.functions.python.PythonEnv;\n+import org.apache.flink.table.runtime.util.StreamRecordCollector;\n+\n+import com.google.protobuf.ByteString;\n+\n+import java.util.Map;\n+import java.util.concurrent.LinkedBlockingQueue;\n+\n+/**\n+ * DataStreamPythonFunctionOperator is responsible for launching beam runner which will start a python harness to\n+ * execute user defined python function.\n+ */\n+public class DataStreamPythonStatelessFunctionOperator<IN, OUT> extends AbstractPythonFunctionOperator<IN, OUT> {\n+\n+\tprivate static final long serialVersionUID = 1L;\n+\n+\tprivate static final String DATA_STREAM_STATELESS_PYTHON_FUNCTION_URN = \"flink:transform:datastream_stateless_function:v1\";\n+\tprivate static final String DATA_STREAM_MAP_FUNCTION_CODER_URN = \"flink:coder:datastream:map_function:v1\";\n+\tprivate static final String DATA_STREAM_FLAT_MAP_FUNCTION_CODER_URN = \"flink:coder:datastream:flatmap_function:v1\";\n+\n+\n+\tprotected final DataStreamPythonFunctionInfo pythonFunctionInfo;\n+\n+\tprivate final TypeInformation<IN> inputTypeInfo;\n+\n+\tprivate final TypeInformation<OUT> outputTypeInfo;\n+\n+\tprivate final Map<String, String> jobOptions;\n+\n+\tprivate transient TypeSerializer<IN> inputTypeSerializer;\n+\n+\tprivate transient TypeSerializer<OUT> outputTypeSerializer;\n+\n+\tprotected transient LinkedBlockingQueue<byte[]> userDefinedFunctionResultQueue;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7"}, "originalPosition": 51}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMTI2NzY4OnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/operators/python/DataStreamPythonStatelessFunctionOperator.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjowODo1N1rOG8gspA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjowODo1N1rOG8gspA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwMzQ2MA==", "bodyText": "Add license text for this class. Please check the test failures.", "url": "https://github.com/apache/flink/pull/13066#discussion_r466103460", "createdAt": "2020-08-06T02:08:57Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/operators/python/DataStreamPythonStatelessFunctionOperator.java", "diffHunk": "@@ -0,0 +1,154 @@\n+package org.apache.flink.datastream.runtime.operators.python;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7"}, "originalPosition": 1}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMTI3MDc2OnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/runners/python/beam/BeamDataStreamPythonStatelessFunctionRunner.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjoxMDozN1rOG8gubQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjoxMDozN1rOG8gubQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwMzkxNw==", "bodyText": "private static final long serialVersionUID = 1L;", "url": "https://github.com/apache/flink/pull/13066#discussion_r466103917", "createdAt": "2020-08-06T02:10:37Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/runners/python/beam/BeamDataStreamPythonStatelessFunctionRunner.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.datastream.runtime.runners.python.beam;\n+\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.datastream.runtime.typeutils.python.PythonTypeUtils;\n+import org.apache.flink.fnexecution.v1.FlinkFnApi;\n+import org.apache.flink.python.env.PythonEnvironmentManager;\n+import org.apache.flink.python.metric.FlinkMetricContainer;\n+import org.apache.flink.streaming.api.runners.python.beam.BeamPythonStatelessFunctionRunner;\n+\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.Map;\n+\n+/**\n+ * DataStreamPythonFunctionRunner is responsible for starting a beam python harness to execute user defined python\n+ * function.\n+ */\n+public class BeamDataStreamPythonStatelessFunctionRunner extends BeamPythonStatelessFunctionRunner {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7"}, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMTI3MjI4OnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/runners/python/beam/BeamDataStreamPythonStatelessFunctionRunner.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjoxMTozM1rOG8gvUg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjoxMTozM1rOG8gvUg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwNDE0Ng==", "bodyText": "DataStreamPythonFunctionRunner => {@link DataStreamPythonFunctionRunner}", "url": "https://github.com/apache/flink/pull/13066#discussion_r466104146", "createdAt": "2020-08-06T02:11:33Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/runners/python/beam/BeamDataStreamPythonStatelessFunctionRunner.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.datastream.runtime.runners.python.beam;\n+\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.datastream.runtime.typeutils.python.PythonTypeUtils;\n+import org.apache.flink.fnexecution.v1.FlinkFnApi;\n+import org.apache.flink.python.env.PythonEnvironmentManager;\n+import org.apache.flink.python.metric.FlinkMetricContainer;\n+import org.apache.flink.streaming.api.runners.python.beam.BeamPythonStatelessFunctionRunner;\n+\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.Map;\n+\n+/**\n+ * DataStreamPythonFunctionRunner is responsible for starting a beam python harness to execute user defined python", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7"}, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMTI3NTc5OnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/typeutils/python/PythonTypeUtils.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjoxMzo0MlrOG8gxZw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjoxMzo0MlrOG8gxZw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwNDY3OQ==", "bodyText": "We don't have VOID type.", "url": "https://github.com/apache/flink/pull/13066#discussion_r466104679", "createdAt": "2020-08-06T02:13:42Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/typeutils/python/PythonTypeUtils.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.datastream.runtime.typeutils.python;\n+\n+import org.apache.flink.api.common.typeinfo.BasicTypeInfo;\n+import org.apache.flink.api.common.typeinfo.PrimitiveArrayTypeInfo;\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.BigIntSerializer;\n+import org.apache.flink.api.common.typeutils.base.BooleanSerializer;\n+import org.apache.flink.api.common.typeutils.base.CharSerializer;\n+import org.apache.flink.api.common.typeutils.base.DoubleSerializer;\n+import org.apache.flink.api.common.typeutils.base.FloatSerializer;\n+import org.apache.flink.api.common.typeutils.base.InstantSerializer;\n+import org.apache.flink.api.common.typeutils.base.IntSerializer;\n+import org.apache.flink.api.common.typeutils.base.LongSerializer;\n+import org.apache.flink.api.common.typeutils.base.ShortSerializer;\n+import org.apache.flink.api.common.typeutils.base.VoidSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple;\n+import org.apache.flink.api.java.typeutils.RowTypeInfo;\n+import org.apache.flink.api.java.typeutils.TupleTypeInfo;\n+import org.apache.flink.api.java.typeutils.runtime.RowSerializer;\n+import org.apache.flink.api.java.typeutils.runtime.TupleSerializer;\n+import org.apache.flink.datastream.typeinfo.python.PickledByteArrayTypeInfo;\n+import org.apache.flink.fnexecution.v1.FlinkFnApi;\n+import org.apache.flink.table.runtime.typeutils.serializers.python.BigDecSerializer;\n+import org.apache.flink.table.runtime.typeutils.serializers.python.DateSerializer;\n+import org.apache.flink.table.runtime.typeutils.serializers.python.StringSerializer;\n+\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+/**\n+ * A util class for converting the given TypeInformation to other objects.\n+ */\n+public class PythonTypeUtils {\n+\n+\t/**\n+\t * Get coder proto according to the given type information.\n+\t */\n+\tpublic static class TypeInfoToProtoConverter {\n+\n+\t\tpublic static FlinkFnApi.TypeInfo.FieldType getFieldType(TypeInformation typeInformation) {\n+\n+\t\t\tif (typeInformation instanceof BasicTypeInfo) {\n+\t\t\t\treturn buildBasicTypeProto((BasicTypeInfo) typeInformation);\n+\t\t\t}\n+\n+\t\t\tif (typeInformation instanceof PrimitiveArrayTypeInfo) {\n+\t\t\t\treturn buildPrimitiveArrayTypeProto((PrimitiveArrayTypeInfo) typeInformation);\n+\t\t\t}\n+\n+\t\t\tif (typeInformation instanceof RowTypeInfo) {\n+\t\t\t\treturn buildRowTypeProto((RowTypeInfo) typeInformation);\n+\t\t\t}\n+\n+\t\t\tif (typeInformation instanceof PickledByteArrayTypeInfo) {\n+\t\t\t\treturn buildPickledBytesTypeProto((PickledByteArrayTypeInfo) typeInformation);\n+\t\t\t}\n+\n+\t\t\tif (typeInformation instanceof TupleTypeInfo) {\n+\t\t\t\treturn buildTupleTypeProto((TupleTypeInfo) typeInformation);\n+\t\t\t}\n+\n+\t\t\tthrow new UnsupportedOperationException(\n+\t\t\t\tString.format(\"The type information: %s is not supported in PyFlink currently.\",\n+\t\t\t\t\ttypeInformation.toString()));\n+\t\t}\n+\n+\t\tpublic static FlinkFnApi.TypeInfo toTypeInfoProto(FlinkFnApi.TypeInfo.FieldType fieldType) {\n+\t\t\treturn FlinkFnApi.TypeInfo.newBuilder().addField(FlinkFnApi.TypeInfo.Field.newBuilder().setType(fieldType).build()).build();\n+\t\t}\n+\n+\t\tprivate static FlinkFnApi.TypeInfo.FieldType buildBasicTypeProto(BasicTypeInfo basicTypeInfo) {\n+\n+\t\t\tFlinkFnApi.TypeInfo.TypeName typeName = null;\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.BOOLEAN_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.BOOLEAN;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.BYTE_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.BYTE;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.STRING_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.STRING;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.SHORT_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.SHORT;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.INT_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.INT;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.LONG_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.LONG;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.FLOAT_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.FLOAT;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.DOUBLE_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.DOUBLE;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.CHAR_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.CHAR;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.DATE_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.LOCAL_DATE;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.VOID_TYPE_INFO)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7"}, "originalPosition": 136}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMTI3NjI1OnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/typeutils/python/PythonTypeUtils.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjoxNDowNlrOG8gxvg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjoxNDowNlrOG8gxvg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwNDc2Ng==", "bodyText": "Don't have INSTANCE type in datastream", "url": "https://github.com/apache/flink/pull/13066#discussion_r466104766", "createdAt": "2020-08-06T02:14:06Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/typeutils/python/PythonTypeUtils.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.datastream.runtime.typeutils.python;\n+\n+import org.apache.flink.api.common.typeinfo.BasicTypeInfo;\n+import org.apache.flink.api.common.typeinfo.PrimitiveArrayTypeInfo;\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.BigIntSerializer;\n+import org.apache.flink.api.common.typeutils.base.BooleanSerializer;\n+import org.apache.flink.api.common.typeutils.base.CharSerializer;\n+import org.apache.flink.api.common.typeutils.base.DoubleSerializer;\n+import org.apache.flink.api.common.typeutils.base.FloatSerializer;\n+import org.apache.flink.api.common.typeutils.base.InstantSerializer;\n+import org.apache.flink.api.common.typeutils.base.IntSerializer;\n+import org.apache.flink.api.common.typeutils.base.LongSerializer;\n+import org.apache.flink.api.common.typeutils.base.ShortSerializer;\n+import org.apache.flink.api.common.typeutils.base.VoidSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple;\n+import org.apache.flink.api.java.typeutils.RowTypeInfo;\n+import org.apache.flink.api.java.typeutils.TupleTypeInfo;\n+import org.apache.flink.api.java.typeutils.runtime.RowSerializer;\n+import org.apache.flink.api.java.typeutils.runtime.TupleSerializer;\n+import org.apache.flink.datastream.typeinfo.python.PickledByteArrayTypeInfo;\n+import org.apache.flink.fnexecution.v1.FlinkFnApi;\n+import org.apache.flink.table.runtime.typeutils.serializers.python.BigDecSerializer;\n+import org.apache.flink.table.runtime.typeutils.serializers.python.DateSerializer;\n+import org.apache.flink.table.runtime.typeutils.serializers.python.StringSerializer;\n+\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+/**\n+ * A util class for converting the given TypeInformation to other objects.\n+ */\n+public class PythonTypeUtils {\n+\n+\t/**\n+\t * Get coder proto according to the given type information.\n+\t */\n+\tpublic static class TypeInfoToProtoConverter {\n+\n+\t\tpublic static FlinkFnApi.TypeInfo.FieldType getFieldType(TypeInformation typeInformation) {\n+\n+\t\t\tif (typeInformation instanceof BasicTypeInfo) {\n+\t\t\t\treturn buildBasicTypeProto((BasicTypeInfo) typeInformation);\n+\t\t\t}\n+\n+\t\t\tif (typeInformation instanceof PrimitiveArrayTypeInfo) {\n+\t\t\t\treturn buildPrimitiveArrayTypeProto((PrimitiveArrayTypeInfo) typeInformation);\n+\t\t\t}\n+\n+\t\t\tif (typeInformation instanceof RowTypeInfo) {\n+\t\t\t\treturn buildRowTypeProto((RowTypeInfo) typeInformation);\n+\t\t\t}\n+\n+\t\t\tif (typeInformation instanceof PickledByteArrayTypeInfo) {\n+\t\t\t\treturn buildPickledBytesTypeProto((PickledByteArrayTypeInfo) typeInformation);\n+\t\t\t}\n+\n+\t\t\tif (typeInformation instanceof TupleTypeInfo) {\n+\t\t\t\treturn buildTupleTypeProto((TupleTypeInfo) typeInformation);\n+\t\t\t}\n+\n+\t\t\tthrow new UnsupportedOperationException(\n+\t\t\t\tString.format(\"The type information: %s is not supported in PyFlink currently.\",\n+\t\t\t\t\ttypeInformation.toString()));\n+\t\t}\n+\n+\t\tpublic static FlinkFnApi.TypeInfo toTypeInfoProto(FlinkFnApi.TypeInfo.FieldType fieldType) {\n+\t\t\treturn FlinkFnApi.TypeInfo.newBuilder().addField(FlinkFnApi.TypeInfo.Field.newBuilder().setType(fieldType).build()).build();\n+\t\t}\n+\n+\t\tprivate static FlinkFnApi.TypeInfo.FieldType buildBasicTypeProto(BasicTypeInfo basicTypeInfo) {\n+\n+\t\t\tFlinkFnApi.TypeInfo.TypeName typeName = null;\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.BOOLEAN_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.BOOLEAN;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.BYTE_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.BYTE;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.STRING_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.STRING;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.SHORT_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.SHORT;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.INT_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.INT;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.LONG_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.LONG;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.FLOAT_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.FLOAT;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.DOUBLE_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.DOUBLE;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.CHAR_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.CHAR;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.DATE_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.LOCAL_DATE;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.VOID_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.VOID;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.BIG_INT_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.BIG_INT;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.BIG_DEC_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.BIG_DEC;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.INSTANT_TYPE_INFO)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7"}, "originalPosition": 148}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMTI3NzE5OnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/typeutils/python/PythonTypeUtils.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjoxNDozNFrOG8gyRA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjoxNDozNFrOG8gyRA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwNDkwMA==", "bodyText": "Remove void and instance.", "url": "https://github.com/apache/flink/pull/13066#discussion_r466104900", "createdAt": "2020-08-06T02:14:34Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/typeutils/python/PythonTypeUtils.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.datastream.runtime.typeutils.python;\n+\n+import org.apache.flink.api.common.typeinfo.BasicTypeInfo;\n+import org.apache.flink.api.common.typeinfo.PrimitiveArrayTypeInfo;\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.BigIntSerializer;\n+import org.apache.flink.api.common.typeutils.base.BooleanSerializer;\n+import org.apache.flink.api.common.typeutils.base.CharSerializer;\n+import org.apache.flink.api.common.typeutils.base.DoubleSerializer;\n+import org.apache.flink.api.common.typeutils.base.FloatSerializer;\n+import org.apache.flink.api.common.typeutils.base.InstantSerializer;\n+import org.apache.flink.api.common.typeutils.base.IntSerializer;\n+import org.apache.flink.api.common.typeutils.base.LongSerializer;\n+import org.apache.flink.api.common.typeutils.base.ShortSerializer;\n+import org.apache.flink.api.common.typeutils.base.VoidSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple;\n+import org.apache.flink.api.java.typeutils.RowTypeInfo;\n+import org.apache.flink.api.java.typeutils.TupleTypeInfo;\n+import org.apache.flink.api.java.typeutils.runtime.RowSerializer;\n+import org.apache.flink.api.java.typeutils.runtime.TupleSerializer;\n+import org.apache.flink.datastream.typeinfo.python.PickledByteArrayTypeInfo;\n+import org.apache.flink.fnexecution.v1.FlinkFnApi;\n+import org.apache.flink.table.runtime.typeutils.serializers.python.BigDecSerializer;\n+import org.apache.flink.table.runtime.typeutils.serializers.python.DateSerializer;\n+import org.apache.flink.table.runtime.typeutils.serializers.python.StringSerializer;\n+\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+/**\n+ * A util class for converting the given TypeInformation to other objects.\n+ */\n+public class PythonTypeUtils {\n+\n+\t/**\n+\t * Get coder proto according to the given type information.\n+\t */\n+\tpublic static class TypeInfoToProtoConverter {\n+\n+\t\tpublic static FlinkFnApi.TypeInfo.FieldType getFieldType(TypeInformation typeInformation) {\n+\n+\t\t\tif (typeInformation instanceof BasicTypeInfo) {\n+\t\t\t\treturn buildBasicTypeProto((BasicTypeInfo) typeInformation);\n+\t\t\t}\n+\n+\t\t\tif (typeInformation instanceof PrimitiveArrayTypeInfo) {\n+\t\t\t\treturn buildPrimitiveArrayTypeProto((PrimitiveArrayTypeInfo) typeInformation);\n+\t\t\t}\n+\n+\t\t\tif (typeInformation instanceof RowTypeInfo) {\n+\t\t\t\treturn buildRowTypeProto((RowTypeInfo) typeInformation);\n+\t\t\t}\n+\n+\t\t\tif (typeInformation instanceof PickledByteArrayTypeInfo) {\n+\t\t\t\treturn buildPickledBytesTypeProto((PickledByteArrayTypeInfo) typeInformation);\n+\t\t\t}\n+\n+\t\t\tif (typeInformation instanceof TupleTypeInfo) {\n+\t\t\t\treturn buildTupleTypeProto((TupleTypeInfo) typeInformation);\n+\t\t\t}\n+\n+\t\t\tthrow new UnsupportedOperationException(\n+\t\t\t\tString.format(\"The type information: %s is not supported in PyFlink currently.\",\n+\t\t\t\t\ttypeInformation.toString()));\n+\t\t}\n+\n+\t\tpublic static FlinkFnApi.TypeInfo toTypeInfoProto(FlinkFnApi.TypeInfo.FieldType fieldType) {\n+\t\t\treturn FlinkFnApi.TypeInfo.newBuilder().addField(FlinkFnApi.TypeInfo.Field.newBuilder().setType(fieldType).build()).build();\n+\t\t}\n+\n+\t\tprivate static FlinkFnApi.TypeInfo.FieldType buildBasicTypeProto(BasicTypeInfo basicTypeInfo) {\n+\n+\t\t\tFlinkFnApi.TypeInfo.TypeName typeName = null;\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.BOOLEAN_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.BOOLEAN;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.BYTE_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.BYTE;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.STRING_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.STRING;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.SHORT_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.SHORT;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.INT_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.INT;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.LONG_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.LONG;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.FLOAT_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.FLOAT;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.DOUBLE_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.DOUBLE;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.CHAR_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.CHAR;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.DATE_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.LOCAL_DATE;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.VOID_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.VOID;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.BIG_INT_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.BIG_INT;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.BIG_DEC_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.BIG_DEC;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.INSTANT_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.INSTANT;\n+\t\t\t}\n+\n+\t\t\tif (typeName == null) {\n+\t\t\t\tthrow new UnsupportedOperationException(\n+\t\t\t\t\tString.format(\"The BasicTypeInfo: %s is not supported in PyFlink currently.\",\n+\t\t\t\t\t\tbasicTypeInfo.toString()));\n+\t\t\t}\n+\n+\t\t\treturn FlinkFnApi.TypeInfo.FieldType.newBuilder()\n+\t\t\t\t.setTypeName(typeName).build();\n+\t\t}\n+\n+\t\tprivate static FlinkFnApi.TypeInfo.FieldType buildPrimitiveArrayTypeProto(\n+\t\t\tPrimitiveArrayTypeInfo primitiveArrayTypeInfo) {\n+\t\t\tFlinkFnApi.TypeInfo.FieldType elementFieldType = null;\n+\t\t\tif (primitiveArrayTypeInfo.equals(PrimitiveArrayTypeInfo.BOOLEAN_PRIMITIVE_ARRAY_TYPE_INFO)) {\n+\t\t\t\telementFieldType = buildBasicTypeProto(BasicTypeInfo.BOOLEAN_TYPE_INFO);\n+\t\t\t}\n+\n+\t\t\tif (primitiveArrayTypeInfo.equals(PrimitiveArrayTypeInfo.BYTE_PRIMITIVE_ARRAY_TYPE_INFO)) {\n+\t\t\t\telementFieldType = buildBasicTypeProto(BasicTypeInfo.BYTE_TYPE_INFO);\n+\t\t\t}\n+\n+\t\t\tif (primitiveArrayTypeInfo.equals(PrimitiveArrayTypeInfo.SHORT_PRIMITIVE_ARRAY_TYPE_INFO)) {\n+\t\t\t\telementFieldType = buildBasicTypeProto(BasicTypeInfo.SHORT_TYPE_INFO);\n+\t\t\t}\n+\n+\t\t\tif (primitiveArrayTypeInfo.equals(PrimitiveArrayTypeInfo.INT_PRIMITIVE_ARRAY_TYPE_INFO)) {\n+\t\t\t\telementFieldType = buildBasicTypeProto(BasicTypeInfo.INT_TYPE_INFO);\n+\t\t\t}\n+\n+\t\t\tif (primitiveArrayTypeInfo.equals(PrimitiveArrayTypeInfo.LONG_PRIMITIVE_ARRAY_TYPE_INFO)) {\n+\t\t\t\telementFieldType = buildBasicTypeProto(BasicTypeInfo.LONG_TYPE_INFO);\n+\t\t\t}\n+\n+\t\t\tif (primitiveArrayTypeInfo.equals(PrimitiveArrayTypeInfo.FLOAT_PRIMITIVE_ARRAY_TYPE_INFO)) {\n+\t\t\t\telementFieldType = buildBasicTypeProto(BasicTypeInfo.FLOAT_TYPE_INFO);\n+\t\t\t}\n+\n+\t\t\tif (primitiveArrayTypeInfo.equals(PrimitiveArrayTypeInfo.DOUBLE_PRIMITIVE_ARRAY_TYPE_INFO)) {\n+\t\t\t\telementFieldType = buildBasicTypeProto(BasicTypeInfo.DOUBLE_TYPE_INFO);\n+\t\t\t}\n+\n+\t\t\tif (primitiveArrayTypeInfo.equals(PrimitiveArrayTypeInfo.CHAR_PRIMITIVE_ARRAY_TYPE_INFO)) {\n+\t\t\t\telementFieldType = buildBasicTypeProto(BasicTypeInfo.CHAR_TYPE_INFO);\n+\t\t\t}\n+\n+\t\t\tif (elementFieldType == null) {\n+\t\t\t\tthrow new UnsupportedOperationException(\n+\t\t\t\t\tString.format(\"The element type of PrimitiveArrayTypeInfo: %s is not supported in PyFlink currently.\"\n+\t\t\t\t\t\t, primitiveArrayTypeInfo.toString()));\n+\t\t\t}\n+\n+\t\t\tFlinkFnApi.TypeInfo.FieldType.Builder builder = FlinkFnApi.TypeInfo.FieldType.newBuilder()\n+\t\t\t\t.setTypeName(FlinkFnApi.TypeInfo.TypeName.ARRAY);\n+\t\t\tbuilder.setCollectionElementType(elementFieldType);\n+\t\t\treturn builder.build();\n+\t\t}\n+\n+\t\tprivate static FlinkFnApi.TypeInfo.FieldType buildRowTypeProto(RowTypeInfo rowTypeInfo) {\n+\t\t\tFlinkFnApi.TypeInfo.FieldType.Builder builder =\n+\t\t\t\tFlinkFnApi.TypeInfo.FieldType.newBuilder()\n+\t\t\t\t\t.setTypeName(FlinkFnApi.TypeInfo.TypeName.ROW);\n+\n+\t\t\tFlinkFnApi.TypeInfo.Builder rowTypeInfoBuilder = FlinkFnApi.TypeInfo.newBuilder();\n+\n+\t\t\tint arity = rowTypeInfo.getArity();\n+\t\t\tfor (int index = 0; index < arity; index++) {\n+\t\t\t\trowTypeInfoBuilder.addField(\n+\t\t\t\t\tFlinkFnApi.TypeInfo.Field.newBuilder()\n+\t\t\t\t\t\t.setName(rowTypeInfo.getFieldNames()[index])\n+\t\t\t\t\t\t.setType(TypeInfoToProtoConverter.getFieldType(rowTypeInfo.getTypeAt(index)))\n+\t\t\t\t\t\t.build());\n+\t\t\t}\n+\t\t\tbuilder.setRowTypeInfo(rowTypeInfoBuilder.build());\n+\t\t\treturn builder.build();\n+\t\t}\n+\n+\t\tprivate static FlinkFnApi.TypeInfo.FieldType buildPickledBytesTypeProto(PickledByteArrayTypeInfo pickledByteArrayTypeInfo) {\n+\t\t\treturn FlinkFnApi.TypeInfo.FieldType.newBuilder()\n+\t\t\t\t.setTypeName(FlinkFnApi.TypeInfo.TypeName.PICKLED_BYTES).build();\n+\t\t}\n+\n+\t\tprivate static FlinkFnApi.TypeInfo.FieldType buildTupleTypeProto(TupleTypeInfo tupleTypeInfo) {\n+\t\t\tFlinkFnApi.TypeInfo.FieldType.Builder builder =\n+\t\t\t\tFlinkFnApi.TypeInfo.FieldType.newBuilder()\n+\t\t\t\t\t.setTypeName(FlinkFnApi.TypeInfo.TypeName.TUPLE);\n+\n+\t\t\tFlinkFnApi.TypeInfo.Builder tupleTypeInfoBuilder = FlinkFnApi.TypeInfo.newBuilder();\n+\n+\t\t\tint arity = tupleTypeInfo.getArity();\n+\t\t\tfor (int index = 0; index < arity; index++) {\n+\t\t\t\ttupleTypeInfoBuilder.addField(\n+\t\t\t\t\tFlinkFnApi.TypeInfo.Field.newBuilder()\n+\t\t\t\t\t\t.setName(tupleTypeInfo.getFieldNames()[index])\n+\t\t\t\t\t\t.setType(TypeInfoToProtoConverter.getFieldType(tupleTypeInfo.getTypeAt(index)))\n+\t\t\t\t\t\t.build());\n+\t\t\t}\n+\t\t\tbuilder.setTupleTypeInfo(tupleTypeInfoBuilder.build());\n+\t\t\treturn builder.build();\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Get serializers according to the given typeInformation.\n+\t */\n+\tpublic static class TypeInfoToSerializerConverter {\n+\t\tprivate static final Map<Class, TypeSerializer> typeInfoToSerialzerMap = new HashMap<>();\n+\n+\t\tstatic {\n+\t\t\ttypeInfoToSerialzerMap.put(BasicTypeInfo.BOOLEAN_TYPE_INFO.getTypeClass(), BooleanSerializer.INSTANCE);\n+\t\t\ttypeInfoToSerialzerMap.put(BasicTypeInfo.INT_TYPE_INFO.getTypeClass(), IntSerializer.INSTANCE);\n+\t\t\ttypeInfoToSerialzerMap.put(BasicTypeInfo.STRING_TYPE_INFO.getTypeClass(), StringSerializer.INSTANCE);\n+\t\t\ttypeInfoToSerialzerMap.put(BasicTypeInfo.SHORT_TYPE_INFO.getTypeClass(), ShortSerializer.INSTANCE);\n+\t\t\ttypeInfoToSerialzerMap.put(BasicTypeInfo.LONG_TYPE_INFO.getTypeClass(), LongSerializer.INSTANCE);\n+\t\t\ttypeInfoToSerialzerMap.put(BasicTypeInfo.FLOAT_TYPE_INFO.getTypeClass(), FloatSerializer.INSTANCE);\n+\t\t\ttypeInfoToSerialzerMap.put(BasicTypeInfo.DOUBLE_TYPE_INFO.getTypeClass(), DoubleSerializer.INSTANCE);\n+\t\t\ttypeInfoToSerialzerMap.put(BasicTypeInfo.CHAR_TYPE_INFO.getTypeClass(), CharSerializer.INSTANCE);\n+\t\t\ttypeInfoToSerialzerMap.put(BasicTypeInfo.DATE_TYPE_INFO.getTypeClass(), DateSerializer.INSTANCE);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7"}, "originalPosition": 268}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMTI3NzkyOnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/typeutils/python/PythonTypeUtils.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjoxNDo1NVrOG8gytA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjoxNDo1NVrOG8gytA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwNTAxMg==", "bodyText": "Add tests for this class.", "url": "https://github.com/apache/flink/pull/13066#discussion_r466105012", "createdAt": "2020-08-06T02:14:55Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/typeutils/python/PythonTypeUtils.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.datastream.runtime.typeutils.python;\n+\n+import org.apache.flink.api.common.typeinfo.BasicTypeInfo;\n+import org.apache.flink.api.common.typeinfo.PrimitiveArrayTypeInfo;\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.BigIntSerializer;\n+import org.apache.flink.api.common.typeutils.base.BooleanSerializer;\n+import org.apache.flink.api.common.typeutils.base.CharSerializer;\n+import org.apache.flink.api.common.typeutils.base.DoubleSerializer;\n+import org.apache.flink.api.common.typeutils.base.FloatSerializer;\n+import org.apache.flink.api.common.typeutils.base.InstantSerializer;\n+import org.apache.flink.api.common.typeutils.base.IntSerializer;\n+import org.apache.flink.api.common.typeutils.base.LongSerializer;\n+import org.apache.flink.api.common.typeutils.base.ShortSerializer;\n+import org.apache.flink.api.common.typeutils.base.VoidSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple;\n+import org.apache.flink.api.java.typeutils.RowTypeInfo;\n+import org.apache.flink.api.java.typeutils.TupleTypeInfo;\n+import org.apache.flink.api.java.typeutils.runtime.RowSerializer;\n+import org.apache.flink.api.java.typeutils.runtime.TupleSerializer;\n+import org.apache.flink.datastream.typeinfo.python.PickledByteArrayTypeInfo;\n+import org.apache.flink.fnexecution.v1.FlinkFnApi;\n+import org.apache.flink.table.runtime.typeutils.serializers.python.BigDecSerializer;\n+import org.apache.flink.table.runtime.typeutils.serializers.python.DateSerializer;\n+import org.apache.flink.table.runtime.typeutils.serializers.python.StringSerializer;\n+\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+/**\n+ * A util class for converting the given TypeInformation to other objects.\n+ */\n+public class PythonTypeUtils {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7"}, "originalPosition": 54}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMTI4MTQ0OnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/python/util/PythonConfigUtil.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjoxNjo1NlrOG8g0yA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjoxNjo1NlrOG8g0yA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwNTU0NA==", "bodyText": "StreamExecutionEnvironment => {@link StreamExecutionEnvironment}", "url": "https://github.com/apache/flink/pull/13066#discussion_r466105544", "createdAt": "2020-08-06T02:16:56Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/python/util/PythonConfigUtil.java", "diffHunk": "@@ -0,0 +1,66 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.python.util;\n+\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\n+\n+import java.lang.reflect.InvocationTargetException;\n+import java.lang.reflect.Method;\n+\n+/**\n+ * A Util class to get the StreamExecutionEnvironment configuration and merged configuration with environment settings.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7"}, "originalPosition": 27}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMTI4MjE4OnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/python/util/PythonConfigUtil.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjoxNzozMFrOG8g1Qg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjoxNzozMFrOG8g1Qg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwNTY2Ng==", "bodyText": "{@link StreamExecutionEnvironment#getConfiguration()}", "url": "https://github.com/apache/flink/pull/13066#discussion_r466105666", "createdAt": "2020-08-06T02:17:30Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/python/util/PythonConfigUtil.java", "diffHunk": "@@ -0,0 +1,66 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.python.util;\n+\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\n+\n+import java.lang.reflect.InvocationTargetException;\n+import java.lang.reflect.Method;\n+\n+/**\n+ * A Util class to get the StreamExecutionEnvironment configuration and merged configuration with environment settings.\n+ */\n+public class PythonConfigUtil {\n+\n+\t/**\n+\t * A static method to get the StreamExecutionEnvironment configuration merged with python dependency management\n+\t * configurations.\n+\t */\n+\tpublic static Configuration getMergedConfig(StreamExecutionEnvironment env) throws InvocationTargetException,\n+\t\tIllegalAccessException, NoSuchMethodException {\n+\t\tConfiguration envConfiguration = getEnvironmentConfig(env);\n+\t\tConfiguration config = PythonDependencyUtils.configurePythonDependencies(env.getCachedFiles(), envConfiguration);\n+\t\treturn config;\n+\t}\n+\n+\t/**\n+\t * Get the private method StreamExecutionEnvironment.getConfiguration() by reflection recursively. Then access the", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7"}, "originalPosition": 43}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMTI4MjUxOnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/python/util/PythonConfigUtil.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjoxNzo0NlrOG8g1cQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjoxNzo0NlrOG8g1cQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwNTcxMw==", "bodyText": "Add tests for this class.", "url": "https://github.com/apache/flink/pull/13066#discussion_r466105713", "createdAt": "2020-08-06T02:17:46Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/python/util/PythonConfigUtil.java", "diffHunk": "@@ -0,0 +1,66 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.python.util;\n+\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\n+\n+import java.lang.reflect.InvocationTargetException;\n+import java.lang.reflect.Method;\n+\n+/**\n+ * A Util class to get the StreamExecutionEnvironment configuration and merged configuration with environment settings.\n+ */\n+public class PythonConfigUtil {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7"}, "originalPosition": 29}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMTI4NjQyOnYy", "diffSide": "LEFT", "path": "flink-python/src/main/java/org/apache/flink/streaming/api/runners/python/beam/BeamPythonStatelessFunctionRunner.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjoxOTo1OFrOG8g3vQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjoxOTo1OFrOG8g3vQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwNjMwMQ==", "bodyText": "Recovery the change.", "url": "https://github.com/apache/flink/pull/13066#discussion_r466106301", "createdAt": "2020-08-06T02:19:58Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/streaming/api/runners/python/beam/BeamPythonStatelessFunctionRunner.java", "diffHunk": "@@ -53,8 +48,7 @@\n /**\n  * A {@link BeamPythonFunctionRunner} used to execute Python stateless functions.\n  */\n-@Internal", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMTI5MTIwOnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/streaming/api/runners/python/beam/BeamPythonStatelessFunctionRunner.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjoyMjo0MVrOG8g6pw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjoyMjo0MVrOG8g6pw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwNzA0Nw==", "bodyText": "Keep one blank between protected and abstract.", "url": "https://github.com/apache/flink/pull/13066#discussion_r466107047", "createdAt": "2020-08-06T02:22:41Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/streaming/api/runners/python/beam/BeamPythonStatelessFunctionRunner.java", "diffHunk": "@@ -170,34 +150,11 @@ public ExecutableStage createExecutableStage() throws Exception {\n \t\t\t.build();\n \t}\n \n-\t/**\n-\t * Gets the proto representation of the input coder.\n-\t */\n-\tprivate RunnerApi.Coder getInputCoderProto() {\n-\t\treturn getRowCoderProto(inputType);\n-\t}\n-\n-\t/**\n-\t * Gets the proto representation of the output coder.\n-\t */\n-\tprivate RunnerApi.Coder getOutputCoderProto() {\n-\t\treturn getRowCoderProto(outputType);\n-\t}\n+\tprotected  abstract byte[] getUserDefinedFunctionsProtoBytes();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7"}, "originalPosition": 83}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMTI5MjQ0OnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/table/runtime/runners/python/beam/BeamTablePythonStatelessFunctionRunner.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjoyMzozMlrOG8g7Zw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjoyMzozMlrOG8g7Zw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwNzIzOQ==", "bodyText": "private static final long serialVersionUID = 1L;", "url": "https://github.com/apache/flink/pull/13066#discussion_r466107239", "createdAt": "2020-08-06T02:23:32Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/table/runtime/runners/python/beam/BeamTablePythonStatelessFunctionRunner.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.runners.python.beam;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.fnexecution.v1.FlinkFnApi;\n+import org.apache.flink.python.env.PythonEnvironmentManager;\n+import org.apache.flink.python.metric.FlinkMetricContainer;\n+import org.apache.flink.streaming.api.runners.python.beam.BeamPythonFunctionRunner;\n+import org.apache.flink.streaming.api.runners.python.beam.BeamPythonStatelessFunctionRunner;\n+import org.apache.flink.table.runtime.typeutils.PythonTypeUtils;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+\n+import java.util.Map;\n+\n+/**\n+ * A {@link BeamPythonFunctionRunner} used to execute Python stateless functions.\n+ */\n+@Internal\n+public class BeamTablePythonStatelessFunctionRunner extends BeamPythonStatelessFunctionRunner {\n+\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7"}, "originalPosition": 42}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMTI5MzI3OnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/table/runtime/runners/python/beam/BeamTablePythonStatelessFunctionRunner.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjoyMzo1N1rOG8g74g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjoyMzo1N1rOG8g74g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwNzM2Mg==", "bodyText": "BeamTablePythonStatelessFunctionRunner", "url": "https://github.com/apache/flink/pull/13066#discussion_r466107362", "createdAt": "2020-08-06T02:23:57Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/table/runtime/runners/python/beam/BeamTablePythonStatelessFunctionRunner.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.runners.python.beam;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.fnexecution.v1.FlinkFnApi;\n+import org.apache.flink.python.env.PythonEnvironmentManager;\n+import org.apache.flink.python.metric.FlinkMetricContainer;\n+import org.apache.flink.streaming.api.runners.python.beam.BeamPythonFunctionRunner;\n+import org.apache.flink.streaming.api.runners.python.beam.BeamPythonStatelessFunctionRunner;\n+import org.apache.flink.table.runtime.typeutils.PythonTypeUtils;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+\n+import java.util.Map;\n+\n+/**\n+ * A {@link BeamPythonFunctionRunner} used to execute Python stateless functions.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7"}, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMTI5NTQ4OnYy", "diffSide": "RIGHT", "path": "flink-python/src/test/java/org/apache/flink/table/runtime/utils/PassThroughPythonScalarFunctionRunner.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjoyNDo1OFrOG8g9Hw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjoyNDo1OFrOG8g9Hw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwNzY3OQ==", "bodyText": "PassThroughPythonScalarFunctionRunner", "url": "https://github.com/apache/flink/pull/13066#discussion_r466107679", "createdAt": "2020-08-06T02:24:58Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/test/java/org/apache/flink/table/runtime/utils/PassThroughPythonScalarFunctionRunner.java", "diffHunk": "@@ -32,9 +32,9 @@\n import java.util.Map;\n \n /**\n- * A BeamPythonStatelessFunctionRunner runner that just return the input elements as the execution results.\n+ * A BeamTablePythonStatelessFunctionRunner runner that just return the input elements as the execution results.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMTI5NTY5OnYy", "diffSide": "RIGHT", "path": "flink-python/src/test/java/org/apache/flink/table/runtime/utils/PassThroughPythonTableFunctionRunner.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjoyNTowNlrOG8g9Qg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjoyNTowNlrOG8g9Qg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwNzcxNA==", "bodyText": "PassThroughPythonTableFunctionRunner", "url": "https://github.com/apache/flink/pull/13066#discussion_r466107714", "createdAt": "2020-08-06T02:25:06Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/test/java/org/apache/flink/table/runtime/utils/PassThroughPythonTableFunctionRunner.java", "diffHunk": "@@ -32,10 +32,10 @@\n import java.util.Map;\n \n /**\n- * A BeamPythonStatelessFunctionRunner that emit each input element in inner join and emit null in\n+ * A BeamTablePythonStatelessFunctionRunner that emit each input element in inner join and emit null in", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMTMyNTkyOnYy", "diffSide": "RIGHT", "path": "flink-python/pyflink/datastream/data_stream.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjo0MTo0OFrOG8hOzw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjo0MTo0OFrOG8hOzw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjExMjIwNw==", "bodyText": "Add type hint.\nfrom typing import Union, Callable\ndef map(self, func: Union[Callable, MapFunction], type_info: TypeInformation = None) -> 'DataStream':", "url": "https://github.com/apache/flink/pull/13066#discussion_r466112207", "createdAt": "2020-08-06T02:41:48Z", "author": {"login": "hequn8128"}, "path": "flink-python/pyflink/datastream/data_stream.py", "diffHunk": "@@ -160,3 +167,120 @@ def set_buffer_timeout(self, timeout_millis: int):\n         \"\"\"\n         self._j_data_stream.setBufferTimeout(timeout_millis)\n         return self\n+\n+    def map(self, func, type_info=None):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMTMyODk1OnYy", "diffSide": "RIGHT", "path": "flink-python/pyflink/datastream/data_stream.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjo0MzoyNVrOG8hQhw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjo0MzoyNVrOG8hQhw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjExMjY0Nw==", "bodyText": "The input must be a MapFunction", "url": "https://github.com/apache/flink/pull/13066#discussion_r466112647", "createdAt": "2020-08-06T02:43:25Z", "author": {"login": "hequn8128"}, "path": "flink-python/pyflink/datastream/data_stream.py", "diffHunk": "@@ -160,3 +167,120 @@ def set_buffer_timeout(self, timeout_millis: int):\n         \"\"\"\n         self._j_data_stream.setBufferTimeout(timeout_millis)\n         return self\n+\n+    def map(self, func, type_info=None):\n+        \"\"\"\n+        Applies a Map transformation on a DataStream. The transformation calls a MapFunction for\n+        each element of the DataStream. Each MapFunction call returns exactly one element. The user\n+        can also extend RichMapFunction to gain access to other features provided by the\n+        RichFunction interface.\n+\n+        Note that If user does not specify the output data type, the output data will be serialized\n+        as pickle primitive byte array.\n+\n+        :param func: The MapFunction that is called for each element of the DataStream.\n+        :param type_info: The type information of the MapFunction output data.\n+        :return: The transformed DataStream.\n+        \"\"\"\n+        if not isinstance(func, MapFunction):\n+            if callable(func):\n+                func = MapFunctionWrapper(func)\n+            else:\n+                raise TypeError(\"The input muster be MapFunction or a callable function\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7"}, "originalPosition": 39}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMTMyOTc3OnYy", "diffSide": "RIGHT", "path": "flink-python/pyflink/datastream/data_stream.py", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjo0Mzo1NVrOG8hQ_w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjo0Mzo1NVrOG8hQ_w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjExMjc2Nw==", "bodyText": "Add an example in the python docs.", "url": "https://github.com/apache/flink/pull/13066#discussion_r466112767", "createdAt": "2020-08-06T02:43:55Z", "author": {"login": "hequn8128"}, "path": "flink-python/pyflink/datastream/data_stream.py", "diffHunk": "@@ -160,3 +167,120 @@ def set_buffer_timeout(self, timeout_millis: int):\n         \"\"\"\n         self._j_data_stream.setBufferTimeout(timeout_millis)\n         return self\n+\n+    def map(self, func, type_info=None):\n+        \"\"\"\n+        Applies a Map transformation on a DataStream. The transformation calls a MapFunction for\n+        each element of the DataStream. Each MapFunction call returns exactly one element. The user\n+        can also extend RichMapFunction to gain access to other features provided by the\n+        RichFunction interface.\n+\n+        Note that If user does not specify the output data type, the output data will be serialized\n+        as pickle primitive byte array.\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7"}, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMTMzMDI3OnYy", "diffSide": "RIGHT", "path": "flink-python/pyflink/datastream/data_stream.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjo0NDoxMVrOG8hRVQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjo0NDoxMVrOG8hRVQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjExMjg1Mw==", "bodyText": "Type hint.", "url": "https://github.com/apache/flink/pull/13066#discussion_r466112853", "createdAt": "2020-08-06T02:44:11Z", "author": {"login": "hequn8128"}, "path": "flink-python/pyflink/datastream/data_stream.py", "diffHunk": "@@ -160,3 +167,120 @@ def set_buffer_timeout(self, timeout_millis: int):\n         \"\"\"\n         self._j_data_stream.setBufferTimeout(timeout_millis)\n         return self\n+\n+    def map(self, func, type_info=None):\n+        \"\"\"\n+        Applies a Map transformation on a DataStream. The transformation calls a MapFunction for\n+        each element of the DataStream. Each MapFunction call returns exactly one element. The user\n+        can also extend RichMapFunction to gain access to other features provided by the\n+        RichFunction interface.\n+\n+        Note that If user does not specify the output data type, the output data will be serialized\n+        as pickle primitive byte array.\n+\n+        :param func: The MapFunction that is called for each element of the DataStream.\n+        :param type_info: The type information of the MapFunction output data.\n+        :return: The transformed DataStream.\n+        \"\"\"\n+        if not isinstance(func, MapFunction):\n+            if callable(func):\n+                func = MapFunctionWrapper(func)\n+            else:\n+                raise TypeError(\"The input muster be MapFunction or a callable function\")\n+        func_name = \"m_map_\" + str(uuid.uuid1())\n+        j_python_data_stream_scalar_function_operator, output_type_info = \\\n+            self._get_java_python_function_operator(func,\n+                                                    type_info,\n+                                                    func_name,\n+                                                    flink_fn_execution_pb2\n+                                                    .UserDefinedDataStreamFunction.MAP)\n+        return DataStream(self._j_data_stream.transform(\n+            func_name,\n+            output_type_info.get_java_type_info(),\n+            j_python_data_stream_scalar_function_operator\n+        ))\n+\n+    def flat_map(self, func, type_info=None):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7"}, "originalPosition": 53}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMTMzMDkwOnYy", "diffSide": "RIGHT", "path": "flink-python/pyflink/datastream/data_stream.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjo0NDo0MFrOG8hRzg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwMjo0NDo0MFrOG8hRzg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjExMjk3NA==", "bodyText": "The input must be a FlatMapFunction", "url": "https://github.com/apache/flink/pull/13066#discussion_r466112974", "createdAt": "2020-08-06T02:44:40Z", "author": {"login": "hequn8128"}, "path": "flink-python/pyflink/datastream/data_stream.py", "diffHunk": "@@ -160,3 +167,120 @@ def set_buffer_timeout(self, timeout_millis: int):\n         \"\"\"\n         self._j_data_stream.setBufferTimeout(timeout_millis)\n         return self\n+\n+    def map(self, func, type_info=None):\n+        \"\"\"\n+        Applies a Map transformation on a DataStream. The transformation calls a MapFunction for\n+        each element of the DataStream. Each MapFunction call returns exactly one element. The user\n+        can also extend RichMapFunction to gain access to other features provided by the\n+        RichFunction interface.\n+\n+        Note that If user does not specify the output data type, the output data will be serialized\n+        as pickle primitive byte array.\n+\n+        :param func: The MapFunction that is called for each element of the DataStream.\n+        :param type_info: The type information of the MapFunction output data.\n+        :return: The transformed DataStream.\n+        \"\"\"\n+        if not isinstance(func, MapFunction):\n+            if callable(func):\n+                func = MapFunctionWrapper(func)\n+            else:\n+                raise TypeError(\"The input muster be MapFunction or a callable function\")\n+        func_name = \"m_map_\" + str(uuid.uuid1())\n+        j_python_data_stream_scalar_function_operator, output_type_info = \\\n+            self._get_java_python_function_operator(func,\n+                                                    type_info,\n+                                                    func_name,\n+                                                    flink_fn_execution_pb2\n+                                                    .UserDefinedDataStreamFunction.MAP)\n+        return DataStream(self._j_data_stream.transform(\n+            func_name,\n+            output_type_info.get_java_type_info(),\n+            j_python_data_stream_scalar_function_operator\n+        ))\n+\n+    def flat_map(self, func, type_info=None):\n+        \"\"\"\n+        Applies a FlatMap transformation on a DataStream. The transformation calls a FlatMapFunction\n+        for each element of the DataStream. Each FlatMapFunction call can return any number of\n+        elements including none. The user can also extend RichFlatMapFunction to gain access to\n+        other features provided by the RichFUnction.\n+\n+        :param func: The FlatMapFunction that is called for each element of the DataStream.\n+        :param type_info: The type information of output data.\n+        :return: The transformed DataStream.\n+        \"\"\"\n+        if not isinstance(func, FlatMapFunction):\n+            if callable(func):\n+                func = FlatMapFunctionWrapper(func)\n+            else:\n+                raise TypeError(\"The input muster be FlatMapFunction or a callable function\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7"}, "originalPosition": 68}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxNTY4OTY2OnYy", "diffSide": "RIGHT", "path": "flink-python/pyflink/fn_execution/beam/beam_coder_impl_slow.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwMzowNjo0MFrOG9K7qQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwMzowNjo0MFrOG9K7qQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njc5NTQzMw==", "bodyText": "This comment has not been addressed?", "url": "https://github.com/apache/flink/pull/13066#discussion_r466795433", "createdAt": "2020-08-07T03:06:40Z", "author": {"login": "hequn8128"}, "path": "flink-python/pyflink/fn_execution/beam/beam_coder_impl_slow.py", "diffHunk": "@@ -186,6 +187,68 @@ def __repr__(self):\n         return 'ArrayCoderImpl[%s]' % repr(self._elem_coder)\n \n \n+class PickledBytesCoderImpl(StreamCoderImpl):\n+\n+    def __init__(self):\n+        self.field_coder = BinaryCoderImpl()\n+\n+    def encode_to_stream(self, value, out_stream, nested):\n+        coded_data = pickle.dumps(value)\n+        real_coded_data = self.field_coder.encode(coded_data)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ea614633c68f672acca22af3d912c12cde8974c"}, "originalPosition": 19}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxNTcwMTQwOnYy", "diffSide": "RIGHT", "path": "flink-python/pyflink/proto/flink-fn-execution.proto", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwMzoxMzo1N1rOG9LCTg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwMzoxMzo1N1rOG9LCTg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njc5NzEzNA==", "bodyText": "A representation of the Table API Schema", "url": "https://github.com/apache/flink/pull/13066#discussion_r466797134", "createdAt": "2020-08-07T03:13:57Z", "author": {"login": "hequn8128"}, "path": "flink-python/pyflink/proto/flink-fn-execution.proto", "diffHunk": "@@ -52,7 +52,23 @@ message UserDefinedFunctions {\n   bool metric_enabled = 2;\n }\n \n-// A representation of the data schema.\n+// User defined DataStream function definition.\n+message UserDefinedDataStreamFunction {\n+  enum FunctionType {\n+    MAP = 0;\n+    FLAT_MAP = 1;\n+  }\n+  FunctionType functionType = 1;\n+  bytes payload = 2;\n+}\n+\n+// A list of user-defined DataStream functions to be executed in a batch.\n+message UserDefinedDataStreamFunctions {\n+  repeated UserDefinedDataStreamFunction udfs = 1;\n+  bool metric_enabled = 2;\n+}\n+\n+// A representation of the DataStream.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ea614633c68f672acca22af3d912c12cde8974c"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxNTcwMzY4OnYy", "diffSide": "RIGHT", "path": "flink-python/pyflink/proto/flink-fn-execution.proto", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwMzoxNTowNlrOG9LDfg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwMzoxNTowNlrOG9LDfg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njc5NzQzOA==", "bodyText": "Please remove the INSTANT type!", "url": "https://github.com/apache/flink/pull/13066#discussion_r466797438", "createdAt": "2020-08-07T03:15:06Z", "author": {"login": "hequn8128"}, "path": "flink-python/pyflink/proto/flink-fn-execution.proto", "diffHunk": "@@ -147,3 +163,46 @@ message Schema {\n \n   repeated Field fields = 1;\n }\n+\n+// A representation of the data type information of a DataStream.\n+message TypeInfo {\n+  enum TypeName {\n+    ROW = 0;\n+    STRING = 1;\n+    BYTE = 2;\n+    BOOLEAN = 3;\n+    SHORT = 4;\n+    INT = 5;\n+    LONG = 6;\n+    FLOAT = 7;\n+    DOUBLE = 8;\n+    CHAR = 9;\n+    BIG_INT = 10;\n+    BIG_DEC = 11;\n+    SQL_DATE = 12;\n+    SQL_TIME = 13;\n+    SQL_TIMESTAMP = 14;\n+    INSTANT = 15;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ea614633c68f672acca22af3d912c12cde8974c"}, "originalPosition": 48}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxNTcwOTEzOnYy", "diffSide": "RIGHT", "path": "flink-python/pyflink/proto/flink-fn-execution.proto", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwMzoxODoxOFrOG9LGaA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwMzoxODoxOFrOG9LGaA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njc5ODE4NA==", "bodyText": "A representation of the data type information in DataStream.", "url": "https://github.com/apache/flink/pull/13066#discussion_r466798184", "createdAt": "2020-08-07T03:18:18Z", "author": {"login": "hequn8128"}, "path": "flink-python/pyflink/proto/flink-fn-execution.proto", "diffHunk": "@@ -147,3 +163,46 @@ message Schema {\n \n   repeated Field fields = 1;\n }\n+\n+// A representation of the data type information of a DataStream.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ea614633c68f672acca22af3d912c12cde8974c"}, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxNTcxMzMzOnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/operators/python/DataStreamPythonStatelessFunctionOperator.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwMzoyMDo0OFrOG9LIqQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwMzoyMDo0OFrOG9LIqQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njc5ODc2MQ==", "bodyText": "The comment has not been addressed!\nAdd license text for this class. Please check the test failures", "url": "https://github.com/apache/flink/pull/13066#discussion_r466798761", "createdAt": "2020-08-07T03:20:48Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/operators/python/DataStreamPythonStatelessFunctionOperator.java", "diffHunk": "@@ -0,0 +1,152 @@\n+package org.apache.flink.datastream.runtime.operators.python;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ea614633c68f672acca22af3d912c12cde8974c"}, "originalPosition": 1}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxNTcxODg1OnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/streaming/api/runners/python/beam/BeamPythonStatelessFunctionRunner.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwMzoyNDoyNlrOG9LLwg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwMzoyNDoyNlrOG9LLwg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njc5OTU1NA==", "bodyText": "The comment has not been addressed!\nKeep one blank between protected and abstract.", "url": "https://github.com/apache/flink/pull/13066#discussion_r466799554", "createdAt": "2020-08-07T03:24:26Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/streaming/api/runners/python/beam/BeamPythonStatelessFunctionRunner.java", "diffHunk": "@@ -170,34 +152,11 @@ public ExecutableStage createExecutableStage() throws Exception {\n \t\t\t.build();\n \t}\n \n-\t/**\n-\t * Gets the proto representation of the input coder.\n-\t */\n-\tprivate RunnerApi.Coder getInputCoderProto() {\n-\t\treturn getRowCoderProto(inputType);\n-\t}\n+\tprotected  abstract byte[] getUserDefinedFunctionsProtoBytes();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ea614633c68f672acca22af3d912c12cde8974c"}, "originalPosition": 77}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxNTcyMTA0OnYy", "diffSide": "RIGHT", "path": "flink-python/src/main/java/org/apache/flink/table/runtime/runners/python/beam/BeamTablePythonStatelessFunctionRunner.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwMzoyNTozMFrOG9LM8g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwMzoyNTozMFrOG9LM8g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njc5OTg1OA==", "bodyText": "The comment has not been addressed!\nprivate static final long serialVersionUID = 1L;", "url": "https://github.com/apache/flink/pull/13066#discussion_r466799858", "createdAt": "2020-08-07T03:25:30Z", "author": {"login": "hequn8128"}, "path": "flink-python/src/main/java/org/apache/flink/table/runtime/runners/python/beam/BeamTablePythonStatelessFunctionRunner.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.runners.python.beam;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.fnexecution.v1.FlinkFnApi;\n+import org.apache.flink.python.env.PythonEnvironmentManager;\n+import org.apache.flink.python.metric.FlinkMetricContainer;\n+import org.apache.flink.streaming.api.runners.python.beam.BeamPythonStatelessFunctionRunner;\n+import org.apache.flink.table.runtime.typeutils.PythonTypeUtils;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+\n+import java.util.Map;\n+\n+/**\n+ * A {@link BeamTablePythonStatelessFunctionRunner} used to execute Python stateless functions.\n+ */\n+@Internal\n+public class BeamTablePythonStatelessFunctionRunner extends BeamPythonStatelessFunctionRunner {\n+\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ea614633c68f672acca22af3d912c12cde8974c"}, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxNTcyNDI0OnYy", "diffSide": "RIGHT", "path": "flink-python/pyflink/datastream/data_stream.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwMzoyNzozNVrOG9LO1w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwMzoyNzozNVrOG9LO1w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjgwMDM0Mw==", "bodyText": "must be a MapFunction", "url": "https://github.com/apache/flink/pull/13066#discussion_r466800343", "createdAt": "2020-08-07T03:27:35Z", "author": {"login": "hequn8128"}, "path": "flink-python/pyflink/datastream/data_stream.py", "diffHunk": "@@ -160,3 +171,122 @@ def set_buffer_timeout(self, timeout_millis: int):\n         \"\"\"\n         self._j_data_stream.setBufferTimeout(timeout_millis)\n         return self\n+\n+    def map(self, func: Union[Callable, MapFunction], type_info: TypeInformation = None) \\\n+            -> DataStream:\n+        \"\"\"\n+        Applies a Map transformation on a DataStream. The transformation calls a MapFunction for\n+        each element of the DataStream. Each MapFunction call returns exactly one element. The user\n+        can also extend RichMapFunction to gain access to other features provided by the\n+        RichFunction interface.\n+\n+        Note that If user does not specify the output data type, the output data will be serialized\n+        as pickle primitive byte array.\n+\n+        :param func: The MapFunction that is called for each element of the DataStream.\n+        :param type_info: The type information of the MapFunction output data.\n+        :return: The transformed DataStream.\n+        \"\"\"\n+        if not isinstance(func, MapFunction):\n+            if callable(func):\n+                func = MapFunctionWrapper(func)\n+            else:\n+                raise TypeError(\"The input must be MapFunction or a callable function\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ea614633c68f672acca22af3d912c12cde8974c"}, "originalPosition": 44}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxNTcyNDc3OnYy", "diffSide": "RIGHT", "path": "flink-python/pyflink/datastream/data_stream.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwMzoyNzo1MlrOG9LPIg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwMzoyNzo1MlrOG9LPIg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjgwMDQxOA==", "bodyText": "a FlatMapFunction", "url": "https://github.com/apache/flink/pull/13066#discussion_r466800418", "createdAt": "2020-08-07T03:27:52Z", "author": {"login": "hequn8128"}, "path": "flink-python/pyflink/datastream/data_stream.py", "diffHunk": "@@ -160,3 +171,122 @@ def set_buffer_timeout(self, timeout_millis: int):\n         \"\"\"\n         self._j_data_stream.setBufferTimeout(timeout_millis)\n         return self\n+\n+    def map(self, func: Union[Callable, MapFunction], type_info: TypeInformation = None) \\\n+            -> DataStream:\n+        \"\"\"\n+        Applies a Map transformation on a DataStream. The transformation calls a MapFunction for\n+        each element of the DataStream. Each MapFunction call returns exactly one element. The user\n+        can also extend RichMapFunction to gain access to other features provided by the\n+        RichFunction interface.\n+\n+        Note that If user does not specify the output data type, the output data will be serialized\n+        as pickle primitive byte array.\n+\n+        :param func: The MapFunction that is called for each element of the DataStream.\n+        :param type_info: The type information of the MapFunction output data.\n+        :return: The transformed DataStream.\n+        \"\"\"\n+        if not isinstance(func, MapFunction):\n+            if callable(func):\n+                func = MapFunctionWrapper(func)\n+            else:\n+                raise TypeError(\"The input must be MapFunction or a callable function\")\n+        func_name = \"m_map_\" + str(uuid.uuid1())\n+        j_python_data_stream_scalar_function_operator, output_type_info = \\\n+            self._get_java_python_function_operator(func,\n+                                                    type_info,\n+                                                    func_name,\n+                                                    flink_fn_execution_pb2\n+                                                    .UserDefinedDataStreamFunction.MAP)\n+        return DataStream(self._j_data_stream.transform(\n+            func_name,\n+            output_type_info.get_java_type_info(),\n+            j_python_data_stream_scalar_function_operator\n+        ))\n+\n+    def flat_map(self, func: Union[Callable, FlatMapFunction], type_info: TypeInformation = None)\\\n+            -> DataStream:\n+        \"\"\"\n+        Applies a FlatMap transformation on a DataStream. The transformation calls a FlatMapFunction\n+        for each element of the DataStream. Each FlatMapFunction call can return any number of\n+        elements including none. The user can also extend RichFlatMapFunction to gain access to\n+        other features provided by the RichFUnction.\n+\n+        :param func: The FlatMapFunction that is called for each element of the DataStream.\n+        :param type_info: The type information of output data.\n+        :return: The transformed DataStream.\n+        \"\"\"\n+        if not isinstance(func, FlatMapFunction):\n+            if callable(func):\n+                func = FlatMapFunctionWrapper(func)\n+            else:\n+                raise TypeError(\"The input must be FlatMapFunction or a callable function\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ea614633c68f672acca22af3d912c12cde8974c"}, "originalPosition": 74}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxNTcyODU5OnYy", "diffSide": "RIGHT", "path": "flink-python/pyflink/datastream/data_stream.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwMzozMDoyMFrOG9LRWQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwMzozMDoyMFrOG9LRWQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjgwMDk4NQ==", "bodyText": "func_name => \"Map\". Keep consistent with Java. Same for flatMap\n        return DataStream(self._j_data_stream.transform(\n            \"Map\",\n            output_type_info.get_java_type_info(),\n            j_python_data_stream_scalar_function_operator\n        ))", "url": "https://github.com/apache/flink/pull/13066#discussion_r466800985", "createdAt": "2020-08-07T03:30:20Z", "author": {"login": "hequn8128"}, "path": "flink-python/pyflink/datastream/data_stream.py", "diffHunk": "@@ -160,3 +171,122 @@ def set_buffer_timeout(self, timeout_millis: int):\n         \"\"\"\n         self._j_data_stream.setBufferTimeout(timeout_millis)\n         return self\n+\n+    def map(self, func: Union[Callable, MapFunction], type_info: TypeInformation = None) \\\n+            -> DataStream:\n+        \"\"\"\n+        Applies a Map transformation on a DataStream. The transformation calls a MapFunction for\n+        each element of the DataStream. Each MapFunction call returns exactly one element. The user\n+        can also extend RichMapFunction to gain access to other features provided by the\n+        RichFunction interface.\n+\n+        Note that If user does not specify the output data type, the output data will be serialized\n+        as pickle primitive byte array.\n+\n+        :param func: The MapFunction that is called for each element of the DataStream.\n+        :param type_info: The type information of the MapFunction output data.\n+        :return: The transformed DataStream.\n+        \"\"\"\n+        if not isinstance(func, MapFunction):\n+            if callable(func):\n+                func = MapFunctionWrapper(func)\n+            else:\n+                raise TypeError(\"The input must be MapFunction or a callable function\")\n+        func_name = \"m_map_\" + str(uuid.uuid1())\n+        j_python_data_stream_scalar_function_operator, output_type_info = \\\n+            self._get_java_python_function_operator(func,\n+                                                    type_info,\n+                                                    func_name,\n+                                                    flink_fn_execution_pb2\n+                                                    .UserDefinedDataStreamFunction.MAP)\n+        return DataStream(self._j_data_stream.transform(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ea614633c68f672acca22af3d912c12cde8974c"}, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxNjUxODk1OnYy", "diffSide": "RIGHT", "path": "flink-python/pyflink/datastream/data_stream.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwOToxMjoxOVrOG9Smbw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwOToxMjoxOVrOG9Smbw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjkyMTA3MQ==", "bodyText": "func_name = str(func)\nperform transform with \"Map\"\n\n        func_name = str(func)\n        j_python_data_stream_scalar_function_operator, output_type_info = \\\n            self._get_java_python_function_operator(func,\n                                                    type_info,\n                                                    func_name,\n                                                    flink_fn_execution_pb2\n                                                    .UserDefinedDataStreamFunction.MAP)\n        return DataStream(self._j_data_stream.transform(\n           \"Map\",\n            output_type_info.get_java_type_info(),\n            j_python_data_stream_scalar_function_operator\n        ))", "url": "https://github.com/apache/flink/pull/13066#discussion_r466921071", "createdAt": "2020-08-07T09:12:19Z", "author": {"login": "hequn8128"}, "path": "flink-python/pyflink/datastream/data_stream.py", "diffHunk": "@@ -160,3 +169,122 @@ def set_buffer_timeout(self, timeout_millis: int):\n         \"\"\"\n         self._j_data_stream.setBufferTimeout(timeout_millis)\n         return self\n+\n+    def map(self, func: Union[Callable, MapFunction], type_info: TypeInformation = None):\n+        \"\"\"\n+        Applies a Map transformation on a DataStream. The transformation calls a MapFunction for\n+        each element of the DataStream. Each MapFunction call returns exactly one element. The user\n+        can also extend RichMapFunction to gain access to other features provided by the\n+        RichFunction interface.\n+\n+        Note that If user does not specify the output data type, the output data will be serialized\n+        as pickle primitive byte array.\n+\n+        :param func: The MapFunction that is called for each element of the DataStream.\n+        :param type_info: The type information of the MapFunction output data.\n+        :return: The transformed DataStream.\n+        \"\"\"\n+        if not isinstance(func, MapFunction):\n+            if callable(func):\n+                func = MapFunctionWrapper(func)\n+            else:\n+                raise TypeError(\"The input must be a MapFunction or a callable function\")\n+        func_name = \"Map\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5450ead81ef4af74a4f0aa2a25e76a95c39763a1"}, "originalPosition": 42}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxNjUyMTU0OnYy", "diffSide": "RIGHT", "path": "flink-python/pyflink/datastream/data_stream.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwOToxMzoyMFrOG9SoOA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwOToxMzoyMFrOG9SoOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjkyMTUyOA==", "bodyText": "ditto", "url": "https://github.com/apache/flink/pull/13066#discussion_r466921528", "createdAt": "2020-08-07T09:13:20Z", "author": {"login": "hequn8128"}, "path": "flink-python/pyflink/datastream/data_stream.py", "diffHunk": "@@ -160,3 +169,122 @@ def set_buffer_timeout(self, timeout_millis: int):\n         \"\"\"\n         self._j_data_stream.setBufferTimeout(timeout_millis)\n         return self\n+\n+    def map(self, func: Union[Callable, MapFunction], type_info: TypeInformation = None):\n+        \"\"\"\n+        Applies a Map transformation on a DataStream. The transformation calls a MapFunction for\n+        each element of the DataStream. Each MapFunction call returns exactly one element. The user\n+        can also extend RichMapFunction to gain access to other features provided by the\n+        RichFunction interface.\n+\n+        Note that If user does not specify the output data type, the output data will be serialized\n+        as pickle primitive byte array.\n+\n+        :param func: The MapFunction that is called for each element of the DataStream.\n+        :param type_info: The type information of the MapFunction output data.\n+        :return: The transformed DataStream.\n+        \"\"\"\n+        if not isinstance(func, MapFunction):\n+            if callable(func):\n+                func = MapFunctionWrapper(func)\n+            else:\n+                raise TypeError(\"The input must be a MapFunction or a callable function\")\n+        func_name = \"Map\"\n+        j_python_data_stream_scalar_function_operator, output_type_info = \\\n+            self._get_java_python_function_operator(func,\n+                                                    type_info,\n+                                                    func_name,\n+                                                    flink_fn_execution_pb2\n+                                                    .UserDefinedDataStreamFunction.MAP)\n+        return DataStream(self._j_data_stream.transform(\n+            func_name,\n+            output_type_info.get_java_type_info(),\n+            j_python_data_stream_scalar_function_operator\n+        ))\n+\n+    def flat_map(self, func: Union[Callable, FlatMapFunction], type_info: TypeInformation = None):\n+        \"\"\"\n+        Applies a FlatMap transformation on a DataStream. The transformation calls a FlatMapFunction\n+        for each element of the DataStream. Each FlatMapFunction call can return any number of\n+        elements including none. The user can also extend RichFlatMapFunction to gain access to\n+        other features provided by the RichFUnction.\n+\n+        :param func: The FlatMapFunction that is called for each element of the DataStream.\n+        :param type_info: The type information of output data.\n+        :return: The transformed DataStream.\n+        \"\"\"\n+        if not isinstance(func, FlatMapFunction):\n+            if callable(func):\n+                func = FlatMapFunctionWrapper(func)\n+            else:\n+                raise TypeError(\"The input must be a FlatMapFunction or a callable function\")\n+        func_name = \"m_flat_map\" + str(uuid.uuid1())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5450ead81ef4af74a4f0aa2a25e76a95c39763a1"}, "originalPosition": 71}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxNjUzMTgzOnYy", "diffSide": "RIGHT", "path": "flink-python/pyflink/datastream/functions.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwOToxNjo0NlrOG9SupQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwOToxNjo0NlrOG9SupQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjkyMzE3Mw==", "bodyText": "MapFUnction => MapFunction", "url": "https://github.com/apache/flink/pull/13066#discussion_r466923173", "createdAt": "2020-08-07T09:16:46Z", "author": {"login": "hequn8128"}, "path": "flink-python/pyflink/datastream/functions.py", "diffHunk": "@@ -0,0 +1,149 @@\n+################################################################################\n+#  Licensed to the Apache Software Foundation (ASF) under one\n+#  or more contributor license agreements.  See the NOTICE file\n+#  distributed with this work for additional information\n+#  regarding copyright ownership.  The ASF licenses this file\n+#  to you under the Apache License, Version 2.0 (the\n+#  \"License\"); you may not use this file except in compliance\n+#  with the License.  You may obtain a copy of the License at\n+#\n+#      http://www.apache.org/licenses/LICENSE-2.0\n+#\n+#  Unless required by applicable law or agreed to in writing, software\n+#  distributed under the License is distributed on an \"AS IS\" BASIS,\n+#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+#  See the License for the specific language governing permissions and\n+# limitations under the License.\n+################################################################################\n+\n+import abc\n+\n+from pyflink.java_gateway import get_gateway\n+\n+\n+class Function(abc.ABC):\n+    \"\"\"\n+    The base class for all user-defined functions.\n+    \"\"\"\n+    pass\n+\n+\n+class MapFunction(Function):\n+    \"\"\"\n+    Base class for Map functions. Map functions take elements and transform them, element wise. A\n+    Map function always produces a single result element for each input element. Typical\n+    applications are parsing elements, converting data types, or projecting out fields. Operations\n+    that produce multiple result elements from a single input element can be implemented using the\n+    FlatMapFunction.\n+    The basic syntax for using a MapFUnction is as follows:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "33e5e101da72c7752adc0d8c95cbaf4527312d49"}, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxNjYzNzM1OnYy", "diffSide": "RIGHT", "path": "flink-python/pyflink/fn_execution/beam/beam_coders.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwOTo0OTo1OFrOG9TumA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwOTo0OTo1OFrOG9TumA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjkzOTU0NA==", "bodyText": "remove the unnecessary change", "url": "https://github.com/apache/flink/pull/13066#discussion_r466939544", "createdAt": "2020-08-07T09:49:58Z", "author": {"login": "hequn8128"}, "path": "flink-python/pyflink/fn_execution/beam/beam_coders.py", "diffHunk": "@@ -17,6 +17,7 @@\n ################################################################################\n \n import os\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "33e5e101da72c7752adc0d8c95cbaf4527312d49"}, "originalPosition": 4}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4911, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}