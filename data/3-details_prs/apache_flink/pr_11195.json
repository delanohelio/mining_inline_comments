{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzc4Njk5MTQ5", "number": 11195, "title": "[FLINK-16222][runtime] Use plugins mechanism for initializing MetricReporters", "bodyText": "What is the purpose of the change\nFLINK-11952 introduced Plugins mechanism into Flink. This PR makes it possible to benefit from using this new functionality during the MetricReporters initialization. Instead of placing MetricReporters JARs into/libs, it is now additionally possible (and encouraged) to convert them into plugins and use the /plugins folder for initialization via independent plugin classloaders.\nNote that to enable this functionality, a bounded type of Plugin was removed from the PluginLoader/PluginManager methods. This removal did not affect any existing functionality, including FileSystems initialization. The adjustment was required for the following reason: MetricReporter interface, which is located in the flink-metrics-core module is currently not a Plugin. Plugin interface is located in flink-core and this module already has a depency on flink-metrics-core. This makes in impossible to mark MetricReporter as  Plugin without introducing a circular dependency. An  alternative approach could be extraction of the whole plugin classloading functionality out of flink-core into a separate module.\nAnother important consideration - current PluginClassLoader implementation uses parent-first initialization for classes, which start with Flink-native package prefixes, such as org.apache.flink.. Currently, metrics reporters shipped with Flink all have the same package prefix. This leads to the following situation: if there is a version of PluginMetricFactory for a particular reporter found in the /lib folder, JARs for this reporter in /plugins directory will effectively be ignored. The opposite priority might actually be desirable to improve user's experience when transitioning to plugins-based metrics initialization approach.\nBrief change log\n\nPluginManager, already created for FileSystems initialization, is propagated from all Flink entrypoints into metrics reporters initializer\nReporters initializer (ReporterSetup) combines initialization via existing ServiceLoader approach with the new approach of loading plugins\nPrometheusReporter is adjusted to be compatible with the new plugins mechanism. Proper functioning is verified with the end-to-end tests\n\nVerifying this change\nThis change added tests and can be verified as follows:\n\nAdded integration tests for end-to-end tests\n\nDoes this pull request potentially affect one of the following parts:\n\nDependencies (does it add or upgrade a dependency): (no)\nThe public API, i.e., is any changed class annotated with @Public(Evolving): (no)\nThe serializers: (no)\nThe runtime per-record code paths (performance sensitive): (no)\nAnything that affects deployment or recovery: JobManager (and its components), Checkpointing, Kubernetes/Yarn/Mesos, ZooKeeper: (yes)\nThe S3 file system connector: (no)\n\nDocumentation\n\nDoes this pull request introduce a new feature? (yes)\nIf yes, how is the feature documented? (not documented)", "createdAt": "2020-02-23T12:17:34Z", "url": "https://github.com/apache/flink/pull/11195", "merged": true, "mergeCommit": {"oid": "e25e5213054442dd3bb913437e56bfaf4f00a37b"}, "closed": true, "closedAt": "2020-03-27T21:37:57Z", "author": {"login": "afedulov"}, "timelineItems": {"totalCount": 29, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcJv1lYAFqTM2NzI5MzIzNA==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcR04JRgBqjMxNzM1MzU1Nzc=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY3MjkzMjM0", "url": "https://github.com/apache/flink/pull/11195#pullrequestreview-367293234", "createdAt": "2020-03-02T15:34:23Z", "commit": {"oid": "d693668c44effeffafc944835df873e3978f88b9"}, "state": "COMMENTED", "comments": {"totalCount": 19, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wMlQxNTozNDoyM1rOFwj-mA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wMlQxNTo1NTowNFrOFwk1sQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2NTQzMg==", "bodyText": "we don't allow star imports", "url": "https://github.com/apache/flink/pull/11195#discussion_r386465432", "createdAt": "2020-03-02T15:34:23Z", "author": {"login": "zentol"}, "path": "flink-end-to-end-tests/flink-end-to-end-tests-common/src/main/java/org/apache/flink/tests/util/FlinkDistribution.java", "diffHunk": "@@ -38,11 +38,7 @@\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n-import java.io.BufferedReader;\n-import java.io.FileInputStream;\n-import java.io.FileNotFoundException;\n-import java.io.IOException;\n-import java.io.InputStreamReader;\n+import java.io.*;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d693668c44effeffafc944835df873e3978f88b9"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2NzkwMQ==", "bodyText": "why is this passing null and not following the same approach as JobManagerHAProcessFailureRecoveryITCase?", "url": "https://github.com/apache/flink/pull/11195#discussion_r386467901", "createdAt": "2020-03-02T15:38:29Z", "author": {"login": "zentol"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/taskexecutor/TaskManagerRunnerTest.java", "diffHunk": "@@ -92,7 +92,7 @@ private static Configuration createConfiguration() {\n \t}\n \n \tprivate static TaskManagerRunner createTaskManagerRunner(final Configuration configuration) throws Exception {\n-\t\tTaskManagerRunner taskManagerRunner = new TaskManagerRunner(configuration, ResourceID.generate());\n+\t\tTaskManagerRunner taskManagerRunner = new TaskManagerRunner(configuration, ResourceID.generate(), null);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d693668c44effeffafc944835df873e3978f88b9"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2ODY5MQ==", "bodyText": "In the PRs current state pluginManager should be annotated with Nullable", "url": "https://github.com/apache/flink/pull/11195#discussion_r386468691", "createdAt": "2020-03-02T15:39:35Z", "author": {"login": "zentol"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/taskexecutor/TaskManagerRunner.java", "diffHunk": "@@ -119,7 +120,7 @@\n \n \tprivate boolean shutdown;\n \n-\tpublic TaskManagerRunner(Configuration configuration, ResourceID resourceId) throws Exception {\n+\tpublic TaskManagerRunner(Configuration configuration, ResourceID resourceId, PluginManager pluginManager) throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d693668c44effeffafc944835df873e3978f88b9"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2OTAwMw==", "bodyText": "revert", "url": "https://github.com/apache/flink/pull/11195#discussion_r386469003", "createdAt": "2020-03-02T15:40:04Z", "author": {"login": "zentol"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -273,3 +319,4 @@ private static ReporterSetup createReporterSetup(String reporterName, MetricConf\n \t\treturn Optional.of((MetricReporter) reporterClass.newInstance());\n \t}\n }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d693668c44effeffafc944835df873e3978f88b9"}, "originalPosition": 203}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2OTY5Ng==", "bodyText": "remove TODOs", "url": "https://github.com/apache/flink/pull/11195#discussion_r386469696", "createdAt": "2020-03-02T15:41:07Z", "author": {"login": "zentol"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -178,36 +164,96 @@ private static ReporterSetup createReporterSetup(String reporterName, MetricConf\n \t\t\t\tmetricReporterOptional.ifPresent(reporter -> {\n \t\t\t\t\tMetricConfig metricConfig = new MetricConfig();\n \t\t\t\t\treporterConfig.addAllToProperties(metricConfig);\n-\n-\t\t\t\t\treporterArguments.add(createReporterSetup(reporterName, metricConfig, reporter));\n+\t\t\t\t\treporterSetups.add(createReporterSetup(reporterName, metricConfig, reporter));\n \t\t\t\t});\n-\t\t\t}\n-\t\t\tcatch (Throwable t) {\n+\t\t\t} catch (Throwable t) {\n \t\t\t\tLOG.error(\"Could not instantiate metrics reporter {}. Metrics might not be exposed/reported.\", reporterName, t);\n \t\t\t}\n \t\t}\n-\t\treturn reporterArguments;\n+\t\treturn reporterSetups;\n \t}\n \n-\tprivate static Map<String, MetricReporterFactory> loadReporterFactories() {\n-\t\tfinal ServiceLoader<MetricReporterFactory> serviceLoader = ServiceLoader.load(MetricReporterFactory.class);\n+\tprivate static List<Tuple2<String, Configuration>> loadReporterConfigurations(Configuration configuration, Set<String> namedReporters) {\n+\t\tfinal List<Tuple2<String, Configuration>> reporterConfigurations = new ArrayList<>(namedReporters.size());\n+\n+\t\tfor (String namedReporter: namedReporters) {\n+\t\t\tDelegatingConfiguration delegatingConfiguration = new DelegatingConfiguration(\n+\t\t\t\tconfiguration,\n+\t\t\t\tConfigConstants.METRICS_REPORTER_PREFIX + namedReporter + '.');\n \n+\t\t\treporterConfigurations.add(Tuple2.of(namedReporter, delegatingConfiguration));\n+\t\t}\n+\t\treturn reporterConfigurations;\n+\t}\n+\n+\tprivate static Set<String> findEnabledReportersInConfiguration(Configuration configuration, String includedReportersString) {\n+\t\tSet<String> includedReporters = reporterListPattern.splitAsStream(includedReportersString)\n+\t\t\t.filter(r -> !r.isEmpty()) // splitting an empty string results in an empty string on jdk9+\n+\t\t\t.collect(Collectors.toSet());\n+\n+\t\t// use a TreeSet to make the reporter order deterministic, which is useful for testing\n+\t\tSet<String> namedOrderedReporters = new TreeSet<>(String::compareTo);\n+\n+\t\t// scan entire configuration for keys starting with METRICS_REPORTER_PREFIX and determine the set of enabled reporters\n+\t\tfor (String key : configuration.keySet()) {\n+\t\t\tif (key.startsWith(ConfigConstants.METRICS_REPORTER_PREFIX)) {\n+\t\t\t\tMatcher matcher = reporterClassPattern.matcher(key);\n+\t\t\t\tif (matcher.matches()) {\n+\t\t\t\t\tString reporterName = matcher.group(1);\n+\t\t\t\t\tif (includedReporters.isEmpty() || includedReporters.contains(reporterName)) {\n+\t\t\t\t\t\tif (namedOrderedReporters.contains(reporterName)) {\n+\t\t\t\t\t\t\tLOG.warn(\"Duplicate class configuration detected for reporter {}.\", reporterName);\n+\t\t\t\t\t\t} else {\n+\t\t\t\t\t\t\tnamedOrderedReporters.add(reporterName);\n+\t\t\t\t\t\t}\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tLOG.info(\"Excluding reporter {}, not configured in reporter list ({}).\", reporterName, includedReportersString);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t\treturn namedOrderedReporters;\n+\t}\n+\n+\tprivate static Map<String, MetricReporterFactory> loadAvailableReporterFactories(PluginManager pluginManager) {\n \t\tfinal Map<String, MetricReporterFactory> reporterFactories = new HashMap<>(2);\n-\t\tfinal Iterator<MetricReporterFactory> factoryIterator = serviceLoader.iterator();\n+\t\tfinal Iterator<MetricReporterFactory> factoryIterator = getAllReporterFactories(pluginManager);\n+\t\tLOG.debug(\"All available factories (from both SPIs and Plugins):\");\n+\t\tgetAllReporterFactories(pluginManager).forEachRemaining(i -> LOG.debug(i.toString()));\n \t\t// do not use streams or for-each loops here because they do not allow catching individual ServiceConfigurationErrors\n \t\t// such an error might be caused if the META-INF/services contains an entry to a non-existing factory class\n \t\twhile (factoryIterator.hasNext()) {\n \t\t\ttry {\n \t\t\t\tMetricReporterFactory factory = factoryIterator.next();\n-\t\t\t\treporterFactories.put(factory.getClass().getName(), factory);\n+\t\t\t\tString factoryClassName = factory.getClass().getName();\n+\t\t\t\tMetricReporterFactory existingFactory = reporterFactories.get(factoryClassName);\n+\t\t\t\tif (existingFactory == null){\n+\t\t\t\t\treporterFactories.put(factoryClassName, factory);\n+\t\t\t\t\tLOG.warn(new File(factory.getClass().getProtectionDomain().getCodeSource().getLocation()\n+\t\t\t\t\t\t.toURI()).getCanonicalPath());\n+\t\t\t\t} else {\n+\t\t\t\t\t//TODO: use path information below, when Plugin Classloader stops always prioritizing factories from /lib\n+//\t\t\t\t\tString jarPath1 = new File(existingFactory.getClass().getProtectionDomain().getCodeSource().getLocation()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d693668c44effeffafc944835df873e3978f88b9"}, "originalPosition": 174}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2OTc0MA==", "bodyText": "revert", "url": "https://github.com/apache/flink/pull/11195#discussion_r386469740", "createdAt": "2020-03-02T15:41:11Z", "author": {"login": "zentol"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -178,36 +164,96 @@ private static ReporterSetup createReporterSetup(String reporterName, MetricConf\n \t\t\t\tmetricReporterOptional.ifPresent(reporter -> {\n \t\t\t\t\tMetricConfig metricConfig = new MetricConfig();\n \t\t\t\t\treporterConfig.addAllToProperties(metricConfig);\n-\n-\t\t\t\t\treporterArguments.add(createReporterSetup(reporterName, metricConfig, reporter));\n+\t\t\t\t\treporterSetups.add(createReporterSetup(reporterName, metricConfig, reporter));\n \t\t\t\t});\n-\t\t\t}\n-\t\t\tcatch (Throwable t) {\n+\t\t\t} catch (Throwable t) {\n \t\t\t\tLOG.error(\"Could not instantiate metrics reporter {}. Metrics might not be exposed/reported.\", reporterName, t);\n \t\t\t}\n \t\t}\n-\t\treturn reporterArguments;\n+\t\treturn reporterSetups;\n \t}\n \n-\tprivate static Map<String, MetricReporterFactory> loadReporterFactories() {\n-\t\tfinal ServiceLoader<MetricReporterFactory> serviceLoader = ServiceLoader.load(MetricReporterFactory.class);\n+\tprivate static List<Tuple2<String, Configuration>> loadReporterConfigurations(Configuration configuration, Set<String> namedReporters) {\n+\t\tfinal List<Tuple2<String, Configuration>> reporterConfigurations = new ArrayList<>(namedReporters.size());\n+\n+\t\tfor (String namedReporter: namedReporters) {\n+\t\t\tDelegatingConfiguration delegatingConfiguration = new DelegatingConfiguration(\n+\t\t\t\tconfiguration,\n+\t\t\t\tConfigConstants.METRICS_REPORTER_PREFIX + namedReporter + '.');\n \n+\t\t\treporterConfigurations.add(Tuple2.of(namedReporter, delegatingConfiguration));\n+\t\t}\n+\t\treturn reporterConfigurations;\n+\t}\n+\n+\tprivate static Set<String> findEnabledReportersInConfiguration(Configuration configuration, String includedReportersString) {\n+\t\tSet<String> includedReporters = reporterListPattern.splitAsStream(includedReportersString)\n+\t\t\t.filter(r -> !r.isEmpty()) // splitting an empty string results in an empty string on jdk9+\n+\t\t\t.collect(Collectors.toSet());\n+\n+\t\t// use a TreeSet to make the reporter order deterministic, which is useful for testing\n+\t\tSet<String> namedOrderedReporters = new TreeSet<>(String::compareTo);\n+\n+\t\t// scan entire configuration for keys starting with METRICS_REPORTER_PREFIX and determine the set of enabled reporters\n+\t\tfor (String key : configuration.keySet()) {\n+\t\t\tif (key.startsWith(ConfigConstants.METRICS_REPORTER_PREFIX)) {\n+\t\t\t\tMatcher matcher = reporterClassPattern.matcher(key);\n+\t\t\t\tif (matcher.matches()) {\n+\t\t\t\t\tString reporterName = matcher.group(1);\n+\t\t\t\t\tif (includedReporters.isEmpty() || includedReporters.contains(reporterName)) {\n+\t\t\t\t\t\tif (namedOrderedReporters.contains(reporterName)) {\n+\t\t\t\t\t\t\tLOG.warn(\"Duplicate class configuration detected for reporter {}.\", reporterName);\n+\t\t\t\t\t\t} else {\n+\t\t\t\t\t\t\tnamedOrderedReporters.add(reporterName);\n+\t\t\t\t\t\t}\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tLOG.info(\"Excluding reporter {}, not configured in reporter list ({}).\", reporterName, includedReportersString);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t\treturn namedOrderedReporters;\n+\t}\n+\n+\tprivate static Map<String, MetricReporterFactory> loadAvailableReporterFactories(PluginManager pluginManager) {\n \t\tfinal Map<String, MetricReporterFactory> reporterFactories = new HashMap<>(2);\n-\t\tfinal Iterator<MetricReporterFactory> factoryIterator = serviceLoader.iterator();\n+\t\tfinal Iterator<MetricReporterFactory> factoryIterator = getAllReporterFactories(pluginManager);\n+\t\tLOG.debug(\"All available factories (from both SPIs and Plugins):\");\n+\t\tgetAllReporterFactories(pluginManager).forEachRemaining(i -> LOG.debug(i.toString()));\n \t\t// do not use streams or for-each loops here because they do not allow catching individual ServiceConfigurationErrors\n \t\t// such an error might be caused if the META-INF/services contains an entry to a non-existing factory class\n \t\twhile (factoryIterator.hasNext()) {\n \t\t\ttry {\n \t\t\t\tMetricReporterFactory factory = factoryIterator.next();\n-\t\t\t\treporterFactories.put(factory.getClass().getName(), factory);\n+\t\t\t\tString factoryClassName = factory.getClass().getName();\n+\t\t\t\tMetricReporterFactory existingFactory = reporterFactories.get(factoryClassName);\n+\t\t\t\tif (existingFactory == null){\n+\t\t\t\t\treporterFactories.put(factoryClassName, factory);\n+\t\t\t\t\tLOG.warn(new File(factory.getClass().getProtectionDomain().getCodeSource().getLocation()\n+\t\t\t\t\t\t.toURI()).getCanonicalPath());\n+\t\t\t\t} else {\n+\t\t\t\t\t//TODO: use path information below, when Plugin Classloader stops always prioritizing factories from /lib\n+//\t\t\t\t\tString jarPath1 = new File(existingFactory.getClass().getProtectionDomain().getCodeSource().getLocation()\n+//\t\t\t\t\t\t.toURI()).getCanonicalPath();\n+//\t\t\t\t\tString jarPath2 = new File(factory.getClass().getProtectionDomain().getCodeSource().getLocation()\n+//\t\t\t\t\t\t.toURI()).getCanonicalPath();\n+//\t\t\t\t\tLOG.warn(\"Multiple implementations of the same reporter were found: \\n {} and \\n{}\", jarPath1, jarPath2);\n+\t\t\t\t\tLOG.warn(\"Multiple implementations of the same reporter were found in 'lib' and 'plugins' directories for {}. It is recommended to remove redundant reporter JARs to resolve used versions' ambiguity.\", factoryClassName);\n+\t\t\t\t}\n \t\t\t} catch (Exception | ServiceConfigurationError e) {\n \t\t\t\tLOG.warn(\"Error while loading reporter factory.\", e);\n \t\t\t}\n \t\t}\n-", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d693668c44effeffafc944835df873e3978f88b9"}, "originalPosition": 185}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3MTg5MQ==", "bodyText": "Is it guaranteed that they are in opt and lib? What if 2 plugins specified the same factory class?", "url": "https://github.com/apache/flink/pull/11195#discussion_r386471891", "createdAt": "2020-03-02T15:44:25Z", "author": {"login": "zentol"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -178,36 +164,96 @@ private static ReporterSetup createReporterSetup(String reporterName, MetricConf\n \t\t\t\tmetricReporterOptional.ifPresent(reporter -> {\n \t\t\t\t\tMetricConfig metricConfig = new MetricConfig();\n \t\t\t\t\treporterConfig.addAllToProperties(metricConfig);\n-\n-\t\t\t\t\treporterArguments.add(createReporterSetup(reporterName, metricConfig, reporter));\n+\t\t\t\t\treporterSetups.add(createReporterSetup(reporterName, metricConfig, reporter));\n \t\t\t\t});\n-\t\t\t}\n-\t\t\tcatch (Throwable t) {\n+\t\t\t} catch (Throwable t) {\n \t\t\t\tLOG.error(\"Could not instantiate metrics reporter {}. Metrics might not be exposed/reported.\", reporterName, t);\n \t\t\t}\n \t\t}\n-\t\treturn reporterArguments;\n+\t\treturn reporterSetups;\n \t}\n \n-\tprivate static Map<String, MetricReporterFactory> loadReporterFactories() {\n-\t\tfinal ServiceLoader<MetricReporterFactory> serviceLoader = ServiceLoader.load(MetricReporterFactory.class);\n+\tprivate static List<Tuple2<String, Configuration>> loadReporterConfigurations(Configuration configuration, Set<String> namedReporters) {\n+\t\tfinal List<Tuple2<String, Configuration>> reporterConfigurations = new ArrayList<>(namedReporters.size());\n+\n+\t\tfor (String namedReporter: namedReporters) {\n+\t\t\tDelegatingConfiguration delegatingConfiguration = new DelegatingConfiguration(\n+\t\t\t\tconfiguration,\n+\t\t\t\tConfigConstants.METRICS_REPORTER_PREFIX + namedReporter + '.');\n \n+\t\t\treporterConfigurations.add(Tuple2.of(namedReporter, delegatingConfiguration));\n+\t\t}\n+\t\treturn reporterConfigurations;\n+\t}\n+\n+\tprivate static Set<String> findEnabledReportersInConfiguration(Configuration configuration, String includedReportersString) {\n+\t\tSet<String> includedReporters = reporterListPattern.splitAsStream(includedReportersString)\n+\t\t\t.filter(r -> !r.isEmpty()) // splitting an empty string results in an empty string on jdk9+\n+\t\t\t.collect(Collectors.toSet());\n+\n+\t\t// use a TreeSet to make the reporter order deterministic, which is useful for testing\n+\t\tSet<String> namedOrderedReporters = new TreeSet<>(String::compareTo);\n+\n+\t\t// scan entire configuration for keys starting with METRICS_REPORTER_PREFIX and determine the set of enabled reporters\n+\t\tfor (String key : configuration.keySet()) {\n+\t\t\tif (key.startsWith(ConfigConstants.METRICS_REPORTER_PREFIX)) {\n+\t\t\t\tMatcher matcher = reporterClassPattern.matcher(key);\n+\t\t\t\tif (matcher.matches()) {\n+\t\t\t\t\tString reporterName = matcher.group(1);\n+\t\t\t\t\tif (includedReporters.isEmpty() || includedReporters.contains(reporterName)) {\n+\t\t\t\t\t\tif (namedOrderedReporters.contains(reporterName)) {\n+\t\t\t\t\t\t\tLOG.warn(\"Duplicate class configuration detected for reporter {}.\", reporterName);\n+\t\t\t\t\t\t} else {\n+\t\t\t\t\t\t\tnamedOrderedReporters.add(reporterName);\n+\t\t\t\t\t\t}\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tLOG.info(\"Excluding reporter {}, not configured in reporter list ({}).\", reporterName, includedReportersString);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t\treturn namedOrderedReporters;\n+\t}\n+\n+\tprivate static Map<String, MetricReporterFactory> loadAvailableReporterFactories(PluginManager pluginManager) {\n \t\tfinal Map<String, MetricReporterFactory> reporterFactories = new HashMap<>(2);\n-\t\tfinal Iterator<MetricReporterFactory> factoryIterator = serviceLoader.iterator();\n+\t\tfinal Iterator<MetricReporterFactory> factoryIterator = getAllReporterFactories(pluginManager);\n+\t\tLOG.debug(\"All available factories (from both SPIs and Plugins):\");\n+\t\tgetAllReporterFactories(pluginManager).forEachRemaining(i -> LOG.debug(i.toString()));\n \t\t// do not use streams or for-each loops here because they do not allow catching individual ServiceConfigurationErrors\n \t\t// such an error might be caused if the META-INF/services contains an entry to a non-existing factory class\n \t\twhile (factoryIterator.hasNext()) {\n \t\t\ttry {\n \t\t\t\tMetricReporterFactory factory = factoryIterator.next();\n-\t\t\t\treporterFactories.put(factory.getClass().getName(), factory);\n+\t\t\t\tString factoryClassName = factory.getClass().getName();\n+\t\t\t\tMetricReporterFactory existingFactory = reporterFactories.get(factoryClassName);\n+\t\t\t\tif (existingFactory == null){\n+\t\t\t\t\treporterFactories.put(factoryClassName, factory);\n+\t\t\t\t\tLOG.warn(new File(factory.getClass().getProtectionDomain().getCodeSource().getLocation()\n+\t\t\t\t\t\t.toURI()).getCanonicalPath());\n+\t\t\t\t} else {\n+\t\t\t\t\t//TODO: use path information below, when Plugin Classloader stops always prioritizing factories from /lib\n+//\t\t\t\t\tString jarPath1 = new File(existingFactory.getClass().getProtectionDomain().getCodeSource().getLocation()\n+//\t\t\t\t\t\t.toURI()).getCanonicalPath();\n+//\t\t\t\t\tString jarPath2 = new File(factory.getClass().getProtectionDomain().getCodeSource().getLocation()\n+//\t\t\t\t\t\t.toURI()).getCanonicalPath();\n+//\t\t\t\t\tLOG.warn(\"Multiple implementations of the same reporter were found: \\n {} and \\n{}\", jarPath1, jarPath2);\n+\t\t\t\t\tLOG.warn(\"Multiple implementations of the same reporter were found in 'lib' and 'plugins' directories for {}. It is recommended to remove redundant reporter JARs to resolve used versions' ambiguity.\", factoryClassName);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d693668c44effeffafc944835df873e3978f88b9"}, "originalPosition": 179}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3MjQ5MQ==", "bodyText": "Given that we are iterating over all factories anyway we should be able to move this into the while loop.", "url": "https://github.com/apache/flink/pull/11195#discussion_r386472491", "createdAt": "2020-03-02T15:45:14Z", "author": {"login": "zentol"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -178,36 +164,96 @@ private static ReporterSetup createReporterSetup(String reporterName, MetricConf\n \t\t\t\tmetricReporterOptional.ifPresent(reporter -> {\n \t\t\t\t\tMetricConfig metricConfig = new MetricConfig();\n \t\t\t\t\treporterConfig.addAllToProperties(metricConfig);\n-\n-\t\t\t\t\treporterArguments.add(createReporterSetup(reporterName, metricConfig, reporter));\n+\t\t\t\t\treporterSetups.add(createReporterSetup(reporterName, metricConfig, reporter));\n \t\t\t\t});\n-\t\t\t}\n-\t\t\tcatch (Throwable t) {\n+\t\t\t} catch (Throwable t) {\n \t\t\t\tLOG.error(\"Could not instantiate metrics reporter {}. Metrics might not be exposed/reported.\", reporterName, t);\n \t\t\t}\n \t\t}\n-\t\treturn reporterArguments;\n+\t\treturn reporterSetups;\n \t}\n \n-\tprivate static Map<String, MetricReporterFactory> loadReporterFactories() {\n-\t\tfinal ServiceLoader<MetricReporterFactory> serviceLoader = ServiceLoader.load(MetricReporterFactory.class);\n+\tprivate static List<Tuple2<String, Configuration>> loadReporterConfigurations(Configuration configuration, Set<String> namedReporters) {\n+\t\tfinal List<Tuple2<String, Configuration>> reporterConfigurations = new ArrayList<>(namedReporters.size());\n+\n+\t\tfor (String namedReporter: namedReporters) {\n+\t\t\tDelegatingConfiguration delegatingConfiguration = new DelegatingConfiguration(\n+\t\t\t\tconfiguration,\n+\t\t\t\tConfigConstants.METRICS_REPORTER_PREFIX + namedReporter + '.');\n \n+\t\t\treporterConfigurations.add(Tuple2.of(namedReporter, delegatingConfiguration));\n+\t\t}\n+\t\treturn reporterConfigurations;\n+\t}\n+\n+\tprivate static Set<String> findEnabledReportersInConfiguration(Configuration configuration, String includedReportersString) {\n+\t\tSet<String> includedReporters = reporterListPattern.splitAsStream(includedReportersString)\n+\t\t\t.filter(r -> !r.isEmpty()) // splitting an empty string results in an empty string on jdk9+\n+\t\t\t.collect(Collectors.toSet());\n+\n+\t\t// use a TreeSet to make the reporter order deterministic, which is useful for testing\n+\t\tSet<String> namedOrderedReporters = new TreeSet<>(String::compareTo);\n+\n+\t\t// scan entire configuration for keys starting with METRICS_REPORTER_PREFIX and determine the set of enabled reporters\n+\t\tfor (String key : configuration.keySet()) {\n+\t\t\tif (key.startsWith(ConfigConstants.METRICS_REPORTER_PREFIX)) {\n+\t\t\t\tMatcher matcher = reporterClassPattern.matcher(key);\n+\t\t\t\tif (matcher.matches()) {\n+\t\t\t\t\tString reporterName = matcher.group(1);\n+\t\t\t\t\tif (includedReporters.isEmpty() || includedReporters.contains(reporterName)) {\n+\t\t\t\t\t\tif (namedOrderedReporters.contains(reporterName)) {\n+\t\t\t\t\t\t\tLOG.warn(\"Duplicate class configuration detected for reporter {}.\", reporterName);\n+\t\t\t\t\t\t} else {\n+\t\t\t\t\t\t\tnamedOrderedReporters.add(reporterName);\n+\t\t\t\t\t\t}\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tLOG.info(\"Excluding reporter {}, not configured in reporter list ({}).\", reporterName, includedReportersString);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t\treturn namedOrderedReporters;\n+\t}\n+\n+\tprivate static Map<String, MetricReporterFactory> loadAvailableReporterFactories(PluginManager pluginManager) {\n \t\tfinal Map<String, MetricReporterFactory> reporterFactories = new HashMap<>(2);\n-\t\tfinal Iterator<MetricReporterFactory> factoryIterator = serviceLoader.iterator();\n+\t\tfinal Iterator<MetricReporterFactory> factoryIterator = getAllReporterFactories(pluginManager);\n+\t\tLOG.debug(\"All available factories (from both SPIs and Plugins):\");\n+\t\tgetAllReporterFactories(pluginManager).forEachRemaining(i -> LOG.debug(i.toString()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d693668c44effeffafc944835df873e3978f88b9"}, "originalPosition": 159}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3MjcwMg==", "bodyText": "Should likely be removed or replaced with a meaningful INFO message that a factory was found.", "url": "https://github.com/apache/flink/pull/11195#discussion_r386472702", "createdAt": "2020-03-02T15:45:33Z", "author": {"login": "zentol"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -178,36 +164,96 @@ private static ReporterSetup createReporterSetup(String reporterName, MetricConf\n \t\t\t\tmetricReporterOptional.ifPresent(reporter -> {\n \t\t\t\t\tMetricConfig metricConfig = new MetricConfig();\n \t\t\t\t\treporterConfig.addAllToProperties(metricConfig);\n-\n-\t\t\t\t\treporterArguments.add(createReporterSetup(reporterName, metricConfig, reporter));\n+\t\t\t\t\treporterSetups.add(createReporterSetup(reporterName, metricConfig, reporter));\n \t\t\t\t});\n-\t\t\t}\n-\t\t\tcatch (Throwable t) {\n+\t\t\t} catch (Throwable t) {\n \t\t\t\tLOG.error(\"Could not instantiate metrics reporter {}. Metrics might not be exposed/reported.\", reporterName, t);\n \t\t\t}\n \t\t}\n-\t\treturn reporterArguments;\n+\t\treturn reporterSetups;\n \t}\n \n-\tprivate static Map<String, MetricReporterFactory> loadReporterFactories() {\n-\t\tfinal ServiceLoader<MetricReporterFactory> serviceLoader = ServiceLoader.load(MetricReporterFactory.class);\n+\tprivate static List<Tuple2<String, Configuration>> loadReporterConfigurations(Configuration configuration, Set<String> namedReporters) {\n+\t\tfinal List<Tuple2<String, Configuration>> reporterConfigurations = new ArrayList<>(namedReporters.size());\n+\n+\t\tfor (String namedReporter: namedReporters) {\n+\t\t\tDelegatingConfiguration delegatingConfiguration = new DelegatingConfiguration(\n+\t\t\t\tconfiguration,\n+\t\t\t\tConfigConstants.METRICS_REPORTER_PREFIX + namedReporter + '.');\n \n+\t\t\treporterConfigurations.add(Tuple2.of(namedReporter, delegatingConfiguration));\n+\t\t}\n+\t\treturn reporterConfigurations;\n+\t}\n+\n+\tprivate static Set<String> findEnabledReportersInConfiguration(Configuration configuration, String includedReportersString) {\n+\t\tSet<String> includedReporters = reporterListPattern.splitAsStream(includedReportersString)\n+\t\t\t.filter(r -> !r.isEmpty()) // splitting an empty string results in an empty string on jdk9+\n+\t\t\t.collect(Collectors.toSet());\n+\n+\t\t// use a TreeSet to make the reporter order deterministic, which is useful for testing\n+\t\tSet<String> namedOrderedReporters = new TreeSet<>(String::compareTo);\n+\n+\t\t// scan entire configuration for keys starting with METRICS_REPORTER_PREFIX and determine the set of enabled reporters\n+\t\tfor (String key : configuration.keySet()) {\n+\t\t\tif (key.startsWith(ConfigConstants.METRICS_REPORTER_PREFIX)) {\n+\t\t\t\tMatcher matcher = reporterClassPattern.matcher(key);\n+\t\t\t\tif (matcher.matches()) {\n+\t\t\t\t\tString reporterName = matcher.group(1);\n+\t\t\t\t\tif (includedReporters.isEmpty() || includedReporters.contains(reporterName)) {\n+\t\t\t\t\t\tif (namedOrderedReporters.contains(reporterName)) {\n+\t\t\t\t\t\t\tLOG.warn(\"Duplicate class configuration detected for reporter {}.\", reporterName);\n+\t\t\t\t\t\t} else {\n+\t\t\t\t\t\t\tnamedOrderedReporters.add(reporterName);\n+\t\t\t\t\t\t}\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tLOG.info(\"Excluding reporter {}, not configured in reporter list ({}).\", reporterName, includedReportersString);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t\treturn namedOrderedReporters;\n+\t}\n+\n+\tprivate static Map<String, MetricReporterFactory> loadAvailableReporterFactories(PluginManager pluginManager) {\n \t\tfinal Map<String, MetricReporterFactory> reporterFactories = new HashMap<>(2);\n-\t\tfinal Iterator<MetricReporterFactory> factoryIterator = serviceLoader.iterator();\n+\t\tfinal Iterator<MetricReporterFactory> factoryIterator = getAllReporterFactories(pluginManager);\n+\t\tLOG.debug(\"All available factories (from both SPIs and Plugins):\");\n+\t\tgetAllReporterFactories(pluginManager).forEachRemaining(i -> LOG.debug(i.toString()));\n \t\t// do not use streams or for-each loops here because they do not allow catching individual ServiceConfigurationErrors\n \t\t// such an error might be caused if the META-INF/services contains an entry to a non-existing factory class\n \t\twhile (factoryIterator.hasNext()) {\n \t\t\ttry {\n \t\t\t\tMetricReporterFactory factory = factoryIterator.next();\n-\t\t\t\treporterFactories.put(factory.getClass().getName(), factory);\n+\t\t\t\tString factoryClassName = factory.getClass().getName();\n+\t\t\t\tMetricReporterFactory existingFactory = reporterFactories.get(factoryClassName);\n+\t\t\t\tif (existingFactory == null){\n+\t\t\t\t\treporterFactories.put(factoryClassName, factory);\n+\t\t\t\t\tLOG.warn(new File(factory.getClass().getProtectionDomain().getCodeSource().getLocation()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d693668c44effeffafc944835df873e3978f88b9"}, "originalPosition": 170}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3NDE4OA==", "bodyText": "why is this necessary?", "url": "https://github.com/apache/flink/pull/11195#discussion_r386474188", "createdAt": "2020-03-02T15:47:39Z", "author": {"login": "zentol"}, "path": "flink-metrics/flink-metrics-prometheus/src/main/java/org/apache/flink/metrics/prometheus/PrometheusReporter.java", "diffHunk": "@@ -35,7 +35,7 @@\n  * {@link MetricReporter} that exports {@link Metric Metrics} via Prometheus.\n  */\n @PublicEvolving\n-public class PrometheusReporter extends AbstractPrometheusReporter {\n+public class PrometheusReporter extends AbstractPrometheusReporter implements MetricReporter {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d693668c44effeffafc944835df873e3978f88b9"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3NDU5MQ==", "bodyText": "Add @InstantiateViaFactory annotation so that all instantiations go through the factory.", "url": "https://github.com/apache/flink/pull/11195#discussion_r386474591", "createdAt": "2020-03-02T15:48:10Z", "author": {"login": "zentol"}, "path": "flink-metrics/flink-metrics-prometheus/src/main/java/org/apache/flink/metrics/prometheus/PrometheusReporter.java", "diffHunk": "@@ -35,7 +35,7 @@\n  * {@link MetricReporter} that exports {@link Metric Metrics} via Prometheus.\n  */\n @PublicEvolving", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d693668c44effeffafc944835df873e3978f88b9"}, "originalPosition": 3}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3NDcyMg==", "bodyText": "revert", "url": "https://github.com/apache/flink/pull/11195#discussion_r386474722", "createdAt": "2020-03-02T15:48:21Z", "author": {"login": "zentol"}, "path": "flink-end-to-end-tests/flink-metrics-reporter-prometheus-test/src/test/java/org/apache/flink/metrics/prometheus/tests/PrometheusReporterEndToEndITCase.java", "diffHunk": "@@ -185,6 +214,7 @@ public void testReporter() throws Exception {\n \n \t\t\tcheckMetricAvailability(client, \"flink_jobmanager_numRegisteredTaskManagers\");\n \t\t\tcheckMetricAvailability(client, \"flink_taskmanager_Status_Network_TotalMemorySegments\");\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d693668c44effeffafc944835df873e3978f88b9"}, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3NjI5MQ==", "bodyText": "ping @pnowojski / @AHeise", "url": "https://github.com/apache/flink/pull/11195#discussion_r386476291", "createdAt": "2020-03-02T15:50:33Z", "author": {"login": "zentol"}, "path": "flink-core/src/main/java/org/apache/flink/core/plugin/PluginLoader.java", "diffHunk": "@@ -69,7 +68,7 @@ public static PluginLoader create(PluginDescriptor pluginDescriptor, ClassLoader\n \t * @param <P> Type of the requested plugin service.\n \t * @return An iterator of all implementations of the given service interface that could be loaded from the plugin.\n \t */\n-\tpublic <P extends Plugin> Iterator<P> load(Class<P> service) {\n+\tpublic <P> Iterator<P> load(Class<P> service) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d693668c44effeffafc944835df873e3978f88b9"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3NzY3MA==", "bodyText": "we should actually remove this line (or exclude the metricConfig) as we may be leaking sensitive information.", "url": "https://github.com/apache/flink/pull/11195#discussion_r386477670", "createdAt": "2020-03-02T15:52:29Z", "author": {"login": "zentol"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -120,55 +124,37 @@ public static ReporterSetup forReporter(String reporterName, MetricConfig metric\n \t}\n \n \tprivate static ReporterSetup createReporterSetup(String reporterName, MetricConfig metricConfig, MetricReporter reporter) {\n-\t\tLOG.info(\"Configuring {} with {}.\", reporterName, metricConfig);\n+\t\tLOG.debug(\"Configuring {} with {}.\", reporterName, metricConfig);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d693668c44effeffafc944835df873e3978f88b9"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3Nzc0NQ==", "bodyText": "same as above", "url": "https://github.com/apache/flink/pull/11195#discussion_r386477745", "createdAt": "2020-03-02T15:52:36Z", "author": {"login": "zentol"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -120,55 +124,37 @@ public static ReporterSetup forReporter(String reporterName, MetricConfig metric\n \t}\n \n \tprivate static ReporterSetup createReporterSetup(String reporterName, MetricConfig metricConfig, MetricReporter reporter) {\n-\t\tLOG.info(\"Configuring {} with {}.\", reporterName, metricConfig);\n+\t\tLOG.debug(\"Configuring {} with {}.\", reporterName, metricConfig);\n \t\treporter.open(metricConfig);\n \n \t\treturn new ReporterSetup(reporterName, metricConfig, reporter);\n \t}\n \n-\tpublic static List<ReporterSetup> fromConfiguration(final Configuration configuration) {\n+\tpublic static List<ReporterSetup> fromConfiguration(final Configuration configuration, final PluginManager pluginManager) {\n+\t\tLOG.debug(\"Initializing Reporters from Configuration: {}\", configuration);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d693668c44effeffafc944835df873e3978f88b9"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3Nzk3Mw==", "bodyText": "revert", "url": "https://github.com/apache/flink/pull/11195#discussion_r386477973", "createdAt": "2020-03-02T15:52:55Z", "author": {"login": "zentol"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -178,36 +164,96 @@ private static ReporterSetup createReporterSetup(String reporterName, MetricConf\n \t\t\t\tmetricReporterOptional.ifPresent(reporter -> {\n \t\t\t\t\tMetricConfig metricConfig = new MetricConfig();\n \t\t\t\t\treporterConfig.addAllToProperties(metricConfig);\n-\n-\t\t\t\t\treporterArguments.add(createReporterSetup(reporterName, metricConfig, reporter));\n+\t\t\t\t\treporterSetups.add(createReporterSetup(reporterName, metricConfig, reporter));\n \t\t\t\t});\n-\t\t\t}\n-\t\t\tcatch (Throwable t) {\n+\t\t\t} catch (Throwable t) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d693668c44effeffafc944835df873e3978f88b9"}, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3ODY1Mg==", "bodyText": "reviews are a lot easier if we either a) refrain from non-critical refactorings b) move such refactorings into a separate commit.", "url": "https://github.com/apache/flink/pull/11195#discussion_r386478652", "createdAt": "2020-03-02T15:53:50Z", "author": {"login": "zentol"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -120,55 +124,37 @@ public static ReporterSetup forReporter(String reporterName, MetricConfig metric\n \t}\n \n \tprivate static ReporterSetup createReporterSetup(String reporterName, MetricConfig metricConfig, MetricReporter reporter) {\n-\t\tLOG.info(\"Configuring {} with {}.\", reporterName, metricConfig);\n+\t\tLOG.debug(\"Configuring {} with {}.\", reporterName, metricConfig);\n \t\treporter.open(metricConfig);\n \n \t\treturn new ReporterSetup(reporterName, metricConfig, reporter);\n \t}\n \n-\tpublic static List<ReporterSetup> fromConfiguration(final Configuration configuration) {\n+\tpublic static List<ReporterSetup> fromConfiguration(final Configuration configuration, final PluginManager pluginManager) {\n+\t\tLOG.debug(\"Initializing Reporters from Configuration: {}\", configuration);\n \t\tString includedReportersString = configuration.getString(MetricOptions.REPORTERS_LIST, \"\");\n-\t\tSet<String> includedReporters = reporterListPattern.splitAsStream(includedReportersString)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d693668c44effeffafc944835df873e3978f88b9"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3OTUwMA==", "bodyText": "same as above about leaking sensitive information", "url": "https://github.com/apache/flink/pull/11195#discussion_r386479500", "createdAt": "2020-03-02T15:55:01Z", "author": {"login": "zentol"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -120,55 +124,37 @@ public static ReporterSetup forReporter(String reporterName, MetricConfig metric\n \t}\n \n \tprivate static ReporterSetup createReporterSetup(String reporterName, MetricConfig metricConfig, MetricReporter reporter) {\n-\t\tLOG.info(\"Configuring {} with {}.\", reporterName, metricConfig);\n+\t\tLOG.debug(\"Configuring {} with {}.\", reporterName, metricConfig);\n \t\treporter.open(metricConfig);\n \n \t\treturn new ReporterSetup(reporterName, metricConfig, reporter);\n \t}\n \n-\tpublic static List<ReporterSetup> fromConfiguration(final Configuration configuration) {\n+\tpublic static List<ReporterSetup> fromConfiguration(final Configuration configuration, final PluginManager pluginManager) {\n+\t\tLOG.debug(\"Initializing Reporters from Configuration: {}\", configuration);\n \t\tString includedReportersString = configuration.getString(MetricOptions.REPORTERS_LIST, \"\");\n-\t\tSet<String> includedReporters = reporterListPattern.splitAsStream(includedReportersString)\n-\t\t\t.filter(r -> !r.isEmpty()) // splitting an empty string results in an empty string on jdk9+\n-\t\t\t.collect(Collectors.toSet());\n \n-\t\t// use a TreeSet to make the reporter order deterministic, which is useful for testing\n-\t\tSet<String> namedReporters = new TreeSet<>(String::compareTo);\n-\t\t// scan entire configuration for \"metric.reporter\" keys and parse individual reporter configurations\n-\t\tfor (String key : configuration.keySet()) {\n-\t\t\tif (key.startsWith(ConfigConstants.METRICS_REPORTER_PREFIX)) {\n-\t\t\t\tMatcher matcher = reporterClassPattern.matcher(key);\n-\t\t\t\tif (matcher.matches()) {\n-\t\t\t\t\tString reporterName = matcher.group(1);\n-\t\t\t\t\tif (includedReporters.isEmpty() || includedReporters.contains(reporterName)) {\n-\t\t\t\t\t\tif (namedReporters.contains(reporterName)) {\n-\t\t\t\t\t\t\tLOG.warn(\"Duplicate class configuration detected for reporter {}.\", reporterName);\n-\t\t\t\t\t\t} else {\n-\t\t\t\t\t\t\tnamedReporters.add(reporterName);\n-\t\t\t\t\t\t}\n-\t\t\t\t\t} else {\n-\t\t\t\t\t\tLOG.info(\"Excluding reporter {}, not configured in reporter list ({}).\", reporterName, includedReportersString);\n-\t\t\t\t\t}\n-\t\t\t\t}\n-\t\t\t}\n-\t\t}\n+\t\tSet<String> namedReporters = findEnabledReportersInConfiguration(configuration,\n+\t\t\tincludedReportersString);\n \n \t\tif (namedReporters.isEmpty()) {\n \t\t\treturn Collections.emptyList();\n \t\t}\n \n-\t\tList<Tuple2<String, Configuration>> reporterConfigurations = new ArrayList<>(namedReporters.size());\n+\t\tfinal Map<String, MetricReporterFactory> reporterFactories = loadAvailableReporterFactories(pluginManager);\n+\t\tLOG.debug(\"Loaded Reporter Factories: {}\", reporterFactories);\n+\t\tfinal List<Tuple2<String, Configuration>> reporterConfigurations = loadReporterConfigurations(configuration, namedReporters);\n+\t\tLOG.debug(\"Loaded Reporter Configurations: {}\", reporterConfigurations);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d693668c44effeffafc944835df873e3978f88b9"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3OTUzNw==", "bodyText": "same as above about leaking sensitive information", "url": "https://github.com/apache/flink/pull/11195#discussion_r386479537", "createdAt": "2020-03-02T15:55:04Z", "author": {"login": "zentol"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -120,55 +124,37 @@ public static ReporterSetup forReporter(String reporterName, MetricConfig metric\n \t}\n \n \tprivate static ReporterSetup createReporterSetup(String reporterName, MetricConfig metricConfig, MetricReporter reporter) {\n-\t\tLOG.info(\"Configuring {} with {}.\", reporterName, metricConfig);\n+\t\tLOG.debug(\"Configuring {} with {}.\", reporterName, metricConfig);\n \t\treporter.open(metricConfig);\n \n \t\treturn new ReporterSetup(reporterName, metricConfig, reporter);\n \t}\n \n-\tpublic static List<ReporterSetup> fromConfiguration(final Configuration configuration) {\n+\tpublic static List<ReporterSetup> fromConfiguration(final Configuration configuration, final PluginManager pluginManager) {\n+\t\tLOG.debug(\"Initializing Reporters from Configuration: {}\", configuration);\n \t\tString includedReportersString = configuration.getString(MetricOptions.REPORTERS_LIST, \"\");\n-\t\tSet<String> includedReporters = reporterListPattern.splitAsStream(includedReportersString)\n-\t\t\t.filter(r -> !r.isEmpty()) // splitting an empty string results in an empty string on jdk9+\n-\t\t\t.collect(Collectors.toSet());\n \n-\t\t// use a TreeSet to make the reporter order deterministic, which is useful for testing\n-\t\tSet<String> namedReporters = new TreeSet<>(String::compareTo);\n-\t\t// scan entire configuration for \"metric.reporter\" keys and parse individual reporter configurations\n-\t\tfor (String key : configuration.keySet()) {\n-\t\t\tif (key.startsWith(ConfigConstants.METRICS_REPORTER_PREFIX)) {\n-\t\t\t\tMatcher matcher = reporterClassPattern.matcher(key);\n-\t\t\t\tif (matcher.matches()) {\n-\t\t\t\t\tString reporterName = matcher.group(1);\n-\t\t\t\t\tif (includedReporters.isEmpty() || includedReporters.contains(reporterName)) {\n-\t\t\t\t\t\tif (namedReporters.contains(reporterName)) {\n-\t\t\t\t\t\t\tLOG.warn(\"Duplicate class configuration detected for reporter {}.\", reporterName);\n-\t\t\t\t\t\t} else {\n-\t\t\t\t\t\t\tnamedReporters.add(reporterName);\n-\t\t\t\t\t\t}\n-\t\t\t\t\t} else {\n-\t\t\t\t\t\tLOG.info(\"Excluding reporter {}, not configured in reporter list ({}).\", reporterName, includedReportersString);\n-\t\t\t\t\t}\n-\t\t\t\t}\n-\t\t\t}\n-\t\t}\n+\t\tSet<String> namedReporters = findEnabledReportersInConfiguration(configuration,\n+\t\t\tincludedReportersString);\n \n \t\tif (namedReporters.isEmpty()) {\n \t\t\treturn Collections.emptyList();\n \t\t}\n \n-\t\tList<Tuple2<String, Configuration>> reporterConfigurations = new ArrayList<>(namedReporters.size());\n+\t\tfinal Map<String, MetricReporterFactory> reporterFactories = loadAvailableReporterFactories(pluginManager);\n+\t\tLOG.debug(\"Loaded Reporter Factories: {}\", reporterFactories);\n+\t\tfinal List<Tuple2<String, Configuration>> reporterConfigurations = loadReporterConfigurations(configuration, namedReporters);\n+\t\tLOG.debug(\"Loaded Reporter Configurations: {}\", reporterConfigurations);\n \n-\t\tfor (String namedReporter: namedReporters) {\n-\t\t\tDelegatingConfiguration delegatingConfiguration = new DelegatingConfiguration(\n-\t\t\t\tconfiguration,\n-\t\t\t\tConfigConstants.METRICS_REPORTER_PREFIX + namedReporter + '.');\n+\t\tList<ReporterSetup> reporterSetups = setupReporters(reporterFactories, reporterConfigurations);\n+\t\tLOG.debug(\"All initialized Reporters:\");\n+\t\treporterSetups.forEach(i -> LOG.debug(\"{} - {}\", i.getName(), i.getConfiguration()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d693668c44effeffafc944835df873e3978f88b9"}, "originalPosition": 78}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d693668c44effeffafc944835df873e3978f88b9", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/d693668c44effeffafc944835df873e3978f88b9", "committedDate": "2020-02-23T11:07:43Z", "message": "[FLINK-16222][runtime] Use plugins load mechanism to initialize MetricsReporters"}, "afterCommit": {"oid": "738a6fd162d5ba99432438d224f3b4890961af56", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/738a6fd162d5ba99432438d224f3b4890961af56", "committedDate": "2020-03-02T20:03:21Z", "message": "[FLINK-16222][runtime] Use plugins load mechanism to initialize MetricsReporters"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "738a6fd162d5ba99432438d224f3b4890961af56", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/738a6fd162d5ba99432438d224f3b4890961af56", "committedDate": "2020-03-02T20:03:21Z", "message": "[FLINK-16222][runtime] Use plugins load mechanism to initialize MetricsReporters"}, "afterCommit": {"oid": "1613baf0244adc63bf029415e97227a6770591c9", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/1613baf0244adc63bf029415e97227a6770591c9", "committedDate": "2020-03-02T20:18:06Z", "message": "[FLINK-16222][runtime] Use plugins load mechanism to initialize MetricsReporters"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "1613baf0244adc63bf029415e97227a6770591c9", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/1613baf0244adc63bf029415e97227a6770591c9", "committedDate": "2020-03-02T20:18:06Z", "message": "[FLINK-16222][runtime] Use plugins load mechanism to initialize MetricsReporters"}, "afterCommit": {"oid": "21c0efa3b9bae9e5bb23338c23483f41f0d1e738", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/21c0efa3b9bae9e5bb23338c23483f41f0d1e738", "committedDate": "2020-03-02T21:23:39Z", "message": "[FLINK-16222][runtime] Use plugins load mechanism to initialize MetricsReporters"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "21c0efa3b9bae9e5bb23338c23483f41f0d1e738", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/21c0efa3b9bae9e5bb23338c23483f41f0d1e738", "committedDate": "2020-03-02T21:23:39Z", "message": "[FLINK-16222][runtime] Use plugins load mechanism to initialize MetricsReporters"}, "afterCommit": {"oid": "77f24b292a04fde34f4c645151484cf86a13832c", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/77f24b292a04fde34f4c645151484cf86a13832c", "committedDate": "2020-03-02T21:57:12Z", "message": "[FLINK-16222][runtime] Use plugins load mechanism to initialize MetricsReporters"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "77f24b292a04fde34f4c645151484cf86a13832c", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/77f24b292a04fde34f4c645151484cf86a13832c", "committedDate": "2020-03-02T21:57:12Z", "message": "[FLINK-16222][runtime] Use plugins load mechanism to initialize MetricsReporters"}, "afterCommit": {"oid": "666e058b3924dd6593106ccffa84ebdfb68ea1fa", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/666e058b3924dd6593106ccffa84ebdfb68ea1fa", "committedDate": "2020-03-02T22:08:35Z", "message": "[FLINK-16222][runtime] Use plugins load mechanism to initialize MetricsReporters"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "666e058b3924dd6593106ccffa84ebdfb68ea1fa", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/666e058b3924dd6593106ccffa84ebdfb68ea1fa", "committedDate": "2020-03-02T22:08:35Z", "message": "[FLINK-16222][runtime] Use plugins load mechanism to initialize MetricsReporters"}, "afterCommit": {"oid": "5dfb306ba6ff07f700b1afc21847641321705d4d", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/5dfb306ba6ff07f700b1afc21847641321705d4d", "committedDate": "2020-03-02T22:12:52Z", "message": "[FLINK-16222][runtime] Use plugins load mechanism to initialize MetricsReporters"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY5NTg5NTE1", "url": "https://github.com/apache/flink/pull/11195#pullrequestreview-369589515", "createdAt": "2020-03-05T14:00:04Z", "commit": {"oid": "bc188f48bff0c164ad2e36ef0eda3a5557e5adba"}, "state": "COMMENTED", "comments": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNVQxNDowMDowNVrOFyUkKg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNVQxNTowMDowOFrOFyW5vA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODMxMDA1OA==", "bodyText": "Just tagging TODO.", "url": "https://github.com/apache/flink/pull/11195#discussion_r388310058", "createdAt": "2020-03-05T14:00:05Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/entrypoint/ClusterEntrypoint.java", "diffHunk": "@@ -160,13 +161,14 @@ public void startCluster() throws ClusterEntrypointException {\n \t\tLOG.info(\"Starting {}.\", getClass().getSimpleName());\n \n \t\ttry {\n-\n-\t\t\tconfigureFileSystems(configuration);\n+\t\t\t//TODO: push down filesystem initialization into runCluster - initializeServices (?)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc188f48bff0c164ad2e36ef0eda3a5557e5adba"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODMxMDQwNg==", "bodyText": "Just tagging TODO.", "url": "https://github.com/apache/flink/pull/11195#discussion_r388310406", "createdAt": "2020-03-05T14:00:38Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/entrypoint/ClusterEntrypoint.java", "diffHunk": "@@ -202,9 +204,11 @@ private SecurityContext installSecurityContext(Configuration configuration) thro\n \t\treturn SecurityUtils.getInstalledContext();\n \t}\n \n-\tprivate void runCluster(Configuration configuration) throws Exception {\n+\tprivate void runCluster(Configuration configuration, PluginManager pluginManager) throws Exception {\n \t\tsynchronized (lock) {\n-\t\t\tinitializeServices(configuration);\n+\n+\t\t\t//TODO: Ask why FileSystem is not initialized here too.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc188f48bff0c164ad2e36ef0eda3a5557e5adba"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODMxMjQ5OQ==", "bodyText": "FileSystem can also take a null for plugin manager. We should probably extract an interface and have a no-op implementation instead. That's out of scope for this PR though.", "url": "https://github.com/apache/flink/pull/11195#discussion_r388312499", "createdAt": "2020-03-05T14:04:17Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/taskexecutor/TaskManagerRunner.java", "diffHunk": "@@ -119,7 +120,7 @@\n \n \tprivate boolean shutdown;\n \n-\tpublic TaskManagerRunner(Configuration configuration, ResourceID resourceId) throws Exception {\n+\tpublic TaskManagerRunner(Configuration configuration, ResourceID resourceId, PluginManager pluginManager) throws Exception {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2ODY5MQ=="}, "originalCommit": {"oid": "d693668c44effeffafc944835df873e3978f88b9"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODMxMzEwMg==", "bodyText": "Commit message should explain what's actually happening.", "url": "https://github.com/apache/flink/pull/11195#discussion_r388313102", "createdAt": "2020-03-05T14:05:20Z", "author": {"login": "AHeise"}, "path": "flink-end-to-end-tests/flink-end-to-end-tests-common/src/main/java/org/apache/flink/tests/util/FlinkDistribution.java", "diffHunk": "@@ -77,6 +77,7 @@\n \tprivate Path conf;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c2c2b9d6b545c77ed473156d7bbf54c5aecd632b"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODM0MDAyOA==", "bodyText": "That was actually my proposal, since there is no benefit from implementing Plugin and its #configure method does not work well with existing metric factories.", "url": "https://github.com/apache/flink/pull/11195#discussion_r388340028", "createdAt": "2020-03-05T14:47:52Z", "author": {"login": "AHeise"}, "path": "flink-core/src/main/java/org/apache/flink/core/plugin/PluginLoader.java", "diffHunk": "@@ -69,7 +68,7 @@ public static PluginLoader create(PluginDescriptor pluginDescriptor, ClassLoader\n \t * @param <P> Type of the requested plugin service.\n \t * @return An iterator of all implementations of the given service interface that could be loaded from the plugin.\n \t */\n-\tpublic <P extends Plugin> Iterator<P> load(Class<P> service) {\n+\tpublic <P> Iterator<P> load(Class<P> service) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3NjI5MQ=="}, "originalCommit": {"oid": "d693668c44effeffafc944835df873e3978f88b9"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODM0NDI1Mw==", "bodyText": "In general, the best option is to leave old code as is to not blow up the PR. You could make a separate hotfix to address code style fixes though.", "url": "https://github.com/apache/flink/pull/11195#discussion_r388344253", "createdAt": "2020-03-05T14:54:06Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -178,36 +164,96 @@ private static ReporterSetup createReporterSetup(String reporterName, MetricConf\n \t\t\t\tmetricReporterOptional.ifPresent(reporter -> {\n \t\t\t\t\tMetricConfig metricConfig = new MetricConfig();\n \t\t\t\t\treporterConfig.addAllToProperties(metricConfig);\n-\n-\t\t\t\t\treporterArguments.add(createReporterSetup(reporterName, metricConfig, reporter));\n+\t\t\t\t\treporterSetups.add(createReporterSetup(reporterName, metricConfig, reporter));\n \t\t\t\t});\n-\t\t\t}\n-\t\t\tcatch (Throwable t) {\n+\t\t\t} catch (Throwable t) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3Nzk3Mw=="}, "originalCommit": {"oid": "d693668c44effeffafc944835df873e3978f88b9"}, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODM0NDcyNA==", "bodyText": "\ud83d\udc4d to split up refactoring from actual commit. But in general also \ud83d\udc4d to refactorings.", "url": "https://github.com/apache/flink/pull/11195#discussion_r388344724", "createdAt": "2020-03-05T14:54:50Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -120,55 +124,37 @@ public static ReporterSetup forReporter(String reporterName, MetricConfig metric\n \t}\n \n \tprivate static ReporterSetup createReporterSetup(String reporterName, MetricConfig metricConfig, MetricReporter reporter) {\n-\t\tLOG.info(\"Configuring {} with {}.\", reporterName, metricConfig);\n+\t\tLOG.debug(\"Configuring {} with {}.\", reporterName, metricConfig);\n \t\treporter.open(metricConfig);\n \n \t\treturn new ReporterSetup(reporterName, metricConfig, reporter);\n \t}\n \n-\tpublic static List<ReporterSetup> fromConfiguration(final Configuration configuration) {\n+\tpublic static List<ReporterSetup> fromConfiguration(final Configuration configuration, final PluginManager pluginManager) {\n+\t\tLOG.debug(\"Initializing Reporters from Configuration: {}\", configuration);\n \t\tString includedReportersString = configuration.getString(MetricOptions.REPORTERS_LIST, \"\");\n-\t\tSet<String> includedReporters = reporterListPattern.splitAsStream(includedReportersString)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3ODY1Mg=="}, "originalCommit": {"oid": "d693668c44effeffafc944835df873e3978f88b9"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODM0NjI0Nw==", "bodyText": "Collectors.toCollection(TreeSet::new) to get rid of the next few lines.", "url": "https://github.com/apache/flink/pull/11195#discussion_r388346247", "createdAt": "2020-03-05T14:56:56Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -179,28 +164,82 @@ private static ReporterSetup createReporterSetup(String reporterName, MetricConf\n \t\t\t\tmetricReporterOptional.ifPresent(reporter -> {\n \t\t\t\t\tMetricConfig metricConfig = new MetricConfig();\n \t\t\t\t\treporterConfig.addAllToProperties(metricConfig);\n-\n-\t\t\t\t\treporterArguments.add(createReporterSetup(reporterName, metricConfig, reporter));\n+\t\t\t\t\treporterSetups.add(createReporterSetup(reporterName, metricConfig, reporter));\n \t\t\t\t});\n-\t\t\t}\n-\t\t\tcatch (Throwable t) {\n+\t\t\t} catch (Throwable t) {\n \t\t\t\tLOG.error(\"Could not instantiate metrics reporter {}. Metrics might not be exposed/reported.\", reporterName, t);\n \t\t\t}\n \t\t}\n-\t\treturn reporterArguments;\n+\t\treturn reporterSetups;\n \t}\n \n-\tprivate static Map<String, MetricReporterFactory> loadReporterFactories() {\n-\t\tfinal ServiceLoader<MetricReporterFactory> serviceLoader = ServiceLoader.load(MetricReporterFactory.class);\n+\tprivate static List<Tuple2<String, Configuration>> loadReporterConfigurations(Configuration configuration, Set<String> namedReporters) {\n+\t\tfinal List<Tuple2<String, Configuration>> reporterConfigurations = new ArrayList<>(namedReporters.size());\n \n+\t\tfor (String namedReporter: namedReporters) {\n+\t\t\tDelegatingConfiguration delegatingConfiguration = new DelegatingConfiguration(\n+\t\t\t\tconfiguration,\n+\t\t\t\tConfigConstants.METRICS_REPORTER_PREFIX + namedReporter + '.');\n+\n+\t\t\treporterConfigurations.add(Tuple2.of(namedReporter, delegatingConfiguration));\n+\t\t}\n+\t\treturn reporterConfigurations;\n+\t}\n+\n+\tprivate static Set<String> findEnabledReportersInConfiguration(Configuration configuration, String includedReportersString) {\n+\t\tSet<String> includedReporters = reporterListPattern.splitAsStream(includedReportersString)\n+\t\t\t.filter(r -> !r.isEmpty()) // splitting an empty string results in an empty string on jdk9+\n+\t\t\t.collect(Collectors.toSet());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5dfb306ba6ff07f700b1afc21847641321705d4d"}, "originalPosition": 120}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODM0Njg1MA==", "bodyText": "warn if it doesn't match?", "url": "https://github.com/apache/flink/pull/11195#discussion_r388346850", "createdAt": "2020-03-05T14:57:51Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -179,28 +164,82 @@ private static ReporterSetup createReporterSetup(String reporterName, MetricConf\n \t\t\t\tmetricReporterOptional.ifPresent(reporter -> {\n \t\t\t\t\tMetricConfig metricConfig = new MetricConfig();\n \t\t\t\t\treporterConfig.addAllToProperties(metricConfig);\n-\n-\t\t\t\t\treporterArguments.add(createReporterSetup(reporterName, metricConfig, reporter));\n+\t\t\t\t\treporterSetups.add(createReporterSetup(reporterName, metricConfig, reporter));\n \t\t\t\t});\n-\t\t\t}\n-\t\t\tcatch (Throwable t) {\n+\t\t\t} catch (Throwable t) {\n \t\t\t\tLOG.error(\"Could not instantiate metrics reporter {}. Metrics might not be exposed/reported.\", reporterName, t);\n \t\t\t}\n \t\t}\n-\t\treturn reporterArguments;\n+\t\treturn reporterSetups;\n \t}\n \n-\tprivate static Map<String, MetricReporterFactory> loadReporterFactories() {\n-\t\tfinal ServiceLoader<MetricReporterFactory> serviceLoader = ServiceLoader.load(MetricReporterFactory.class);\n+\tprivate static List<Tuple2<String, Configuration>> loadReporterConfigurations(Configuration configuration, Set<String> namedReporters) {\n+\t\tfinal List<Tuple2<String, Configuration>> reporterConfigurations = new ArrayList<>(namedReporters.size());\n \n+\t\tfor (String namedReporter: namedReporters) {\n+\t\t\tDelegatingConfiguration delegatingConfiguration = new DelegatingConfiguration(\n+\t\t\t\tconfiguration,\n+\t\t\t\tConfigConstants.METRICS_REPORTER_PREFIX + namedReporter + '.');\n+\n+\t\t\treporterConfigurations.add(Tuple2.of(namedReporter, delegatingConfiguration));\n+\t\t}\n+\t\treturn reporterConfigurations;\n+\t}\n+\n+\tprivate static Set<String> findEnabledReportersInConfiguration(Configuration configuration, String includedReportersString) {\n+\t\tSet<String> includedReporters = reporterListPattern.splitAsStream(includedReportersString)\n+\t\t\t.filter(r -> !r.isEmpty()) // splitting an empty string results in an empty string on jdk9+\n+\t\t\t.collect(Collectors.toSet());\n+\n+\t\t// use a TreeSet to make the reporter order deterministic, which is useful for testing\n+\t\tSet<String> namedOrderedReporters = new TreeSet<>(String::compareTo);\n+\n+\t\t// scan entire configuration for keys starting with METRICS_REPORTER_PREFIX and determine the set of enabled reporters\n+\t\tfor (String key : configuration.keySet()) {\n+\t\t\tif (key.startsWith(ConfigConstants.METRICS_REPORTER_PREFIX)) {\n+\t\t\t\tMatcher matcher = reporterClassPattern.matcher(key);\n+\t\t\t\tif (matcher.matches()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5dfb306ba6ff07f700b1afc21847641321705d4d"}, "originalPosition": 129}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODM0NzgxMg==", "bodyText": "Should be 'or'", "url": "https://github.com/apache/flink/pull/11195#discussion_r388347812", "createdAt": "2020-03-05T14:59:15Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -178,36 +164,96 @@ private static ReporterSetup createReporterSetup(String reporterName, MetricConf\n \t\t\t\tmetricReporterOptional.ifPresent(reporter -> {\n \t\t\t\t\tMetricConfig metricConfig = new MetricConfig();\n \t\t\t\t\treporterConfig.addAllToProperties(metricConfig);\n-\n-\t\t\t\t\treporterArguments.add(createReporterSetup(reporterName, metricConfig, reporter));\n+\t\t\t\t\treporterSetups.add(createReporterSetup(reporterName, metricConfig, reporter));\n \t\t\t\t});\n-\t\t\t}\n-\t\t\tcatch (Throwable t) {\n+\t\t\t} catch (Throwable t) {\n \t\t\t\tLOG.error(\"Could not instantiate metrics reporter {}. Metrics might not be exposed/reported.\", reporterName, t);\n \t\t\t}\n \t\t}\n-\t\treturn reporterArguments;\n+\t\treturn reporterSetups;\n \t}\n \n-\tprivate static Map<String, MetricReporterFactory> loadReporterFactories() {\n-\t\tfinal ServiceLoader<MetricReporterFactory> serviceLoader = ServiceLoader.load(MetricReporterFactory.class);\n+\tprivate static List<Tuple2<String, Configuration>> loadReporterConfigurations(Configuration configuration, Set<String> namedReporters) {\n+\t\tfinal List<Tuple2<String, Configuration>> reporterConfigurations = new ArrayList<>(namedReporters.size());\n+\n+\t\tfor (String namedReporter: namedReporters) {\n+\t\t\tDelegatingConfiguration delegatingConfiguration = new DelegatingConfiguration(\n+\t\t\t\tconfiguration,\n+\t\t\t\tConfigConstants.METRICS_REPORTER_PREFIX + namedReporter + '.');\n \n+\t\t\treporterConfigurations.add(Tuple2.of(namedReporter, delegatingConfiguration));\n+\t\t}\n+\t\treturn reporterConfigurations;\n+\t}\n+\n+\tprivate static Set<String> findEnabledReportersInConfiguration(Configuration configuration, String includedReportersString) {\n+\t\tSet<String> includedReporters = reporterListPattern.splitAsStream(includedReportersString)\n+\t\t\t.filter(r -> !r.isEmpty()) // splitting an empty string results in an empty string on jdk9+\n+\t\t\t.collect(Collectors.toSet());\n+\n+\t\t// use a TreeSet to make the reporter order deterministic, which is useful for testing\n+\t\tSet<String> namedOrderedReporters = new TreeSet<>(String::compareTo);\n+\n+\t\t// scan entire configuration for keys starting with METRICS_REPORTER_PREFIX and determine the set of enabled reporters\n+\t\tfor (String key : configuration.keySet()) {\n+\t\t\tif (key.startsWith(ConfigConstants.METRICS_REPORTER_PREFIX)) {\n+\t\t\t\tMatcher matcher = reporterClassPattern.matcher(key);\n+\t\t\t\tif (matcher.matches()) {\n+\t\t\t\t\tString reporterName = matcher.group(1);\n+\t\t\t\t\tif (includedReporters.isEmpty() || includedReporters.contains(reporterName)) {\n+\t\t\t\t\t\tif (namedOrderedReporters.contains(reporterName)) {\n+\t\t\t\t\t\t\tLOG.warn(\"Duplicate class configuration detected for reporter {}.\", reporterName);\n+\t\t\t\t\t\t} else {\n+\t\t\t\t\t\t\tnamedOrderedReporters.add(reporterName);\n+\t\t\t\t\t\t}\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tLOG.info(\"Excluding reporter {}, not configured in reporter list ({}).\", reporterName, includedReportersString);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t\treturn namedOrderedReporters;\n+\t}\n+\n+\tprivate static Map<String, MetricReporterFactory> loadAvailableReporterFactories(PluginManager pluginManager) {\n \t\tfinal Map<String, MetricReporterFactory> reporterFactories = new HashMap<>(2);\n-\t\tfinal Iterator<MetricReporterFactory> factoryIterator = serviceLoader.iterator();\n+\t\tfinal Iterator<MetricReporterFactory> factoryIterator = getAllReporterFactories(pluginManager);\n+\t\tLOG.debug(\"All available factories (from both SPIs and Plugins):\");\n+\t\tgetAllReporterFactories(pluginManager).forEachRemaining(i -> LOG.debug(i.toString()));\n \t\t// do not use streams or for-each loops here because they do not allow catching individual ServiceConfigurationErrors\n \t\t// such an error might be caused if the META-INF/services contains an entry to a non-existing factory class\n \t\twhile (factoryIterator.hasNext()) {\n \t\t\ttry {\n \t\t\t\tMetricReporterFactory factory = factoryIterator.next();\n-\t\t\t\treporterFactories.put(factory.getClass().getName(), factory);\n+\t\t\t\tString factoryClassName = factory.getClass().getName();\n+\t\t\t\tMetricReporterFactory existingFactory = reporterFactories.get(factoryClassName);\n+\t\t\t\tif (existingFactory == null){\n+\t\t\t\t\treporterFactories.put(factoryClassName, factory);\n+\t\t\t\t\tLOG.warn(new File(factory.getClass().getProtectionDomain().getCodeSource().getLocation()\n+\t\t\t\t\t\t.toURI()).getCanonicalPath());\n+\t\t\t\t} else {\n+\t\t\t\t\t//TODO: use path information below, when Plugin Classloader stops always prioritizing factories from /lib\n+//\t\t\t\t\tString jarPath1 = new File(existingFactory.getClass().getProtectionDomain().getCodeSource().getLocation()\n+//\t\t\t\t\t\t.toURI()).getCanonicalPath();\n+//\t\t\t\t\tString jarPath2 = new File(factory.getClass().getProtectionDomain().getCodeSource().getLocation()\n+//\t\t\t\t\t\t.toURI()).getCanonicalPath();\n+//\t\t\t\t\tLOG.warn(\"Multiple implementations of the same reporter were found: \\n {} and \\n{}\", jarPath1, jarPath2);\n+\t\t\t\t\tLOG.warn(\"Multiple implementations of the same reporter were found in 'lib' and 'plugins' directories for {}. It is recommended to remove redundant reporter JARs to resolve used versions' ambiguity.\", factoryClassName);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3MTg5MQ=="}, "originalCommit": {"oid": "d693668c44effeffafc944835df873e3978f88b9"}, "originalPosition": 179}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODM0ODM0OA==", "bodyText": "Takes a while until we get proper SPI, so I'd add the commented code to increase usability.", "url": "https://github.com/apache/flink/pull/11195#discussion_r388348348", "createdAt": "2020-03-05T15:00:08Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -178,36 +164,96 @@ private static ReporterSetup createReporterSetup(String reporterName, MetricConf\n \t\t\t\tmetricReporterOptional.ifPresent(reporter -> {\n \t\t\t\t\tMetricConfig metricConfig = new MetricConfig();\n \t\t\t\t\treporterConfig.addAllToProperties(metricConfig);\n-\n-\t\t\t\t\treporterArguments.add(createReporterSetup(reporterName, metricConfig, reporter));\n+\t\t\t\t\treporterSetups.add(createReporterSetup(reporterName, metricConfig, reporter));\n \t\t\t\t});\n-\t\t\t}\n-\t\t\tcatch (Throwable t) {\n+\t\t\t} catch (Throwable t) {\n \t\t\t\tLOG.error(\"Could not instantiate metrics reporter {}. Metrics might not be exposed/reported.\", reporterName, t);\n \t\t\t}\n \t\t}\n-\t\treturn reporterArguments;\n+\t\treturn reporterSetups;\n \t}\n \n-\tprivate static Map<String, MetricReporterFactory> loadReporterFactories() {\n-\t\tfinal ServiceLoader<MetricReporterFactory> serviceLoader = ServiceLoader.load(MetricReporterFactory.class);\n+\tprivate static List<Tuple2<String, Configuration>> loadReporterConfigurations(Configuration configuration, Set<String> namedReporters) {\n+\t\tfinal List<Tuple2<String, Configuration>> reporterConfigurations = new ArrayList<>(namedReporters.size());\n+\n+\t\tfor (String namedReporter: namedReporters) {\n+\t\t\tDelegatingConfiguration delegatingConfiguration = new DelegatingConfiguration(\n+\t\t\t\tconfiguration,\n+\t\t\t\tConfigConstants.METRICS_REPORTER_PREFIX + namedReporter + '.');\n \n+\t\t\treporterConfigurations.add(Tuple2.of(namedReporter, delegatingConfiguration));\n+\t\t}\n+\t\treturn reporterConfigurations;\n+\t}\n+\n+\tprivate static Set<String> findEnabledReportersInConfiguration(Configuration configuration, String includedReportersString) {\n+\t\tSet<String> includedReporters = reporterListPattern.splitAsStream(includedReportersString)\n+\t\t\t.filter(r -> !r.isEmpty()) // splitting an empty string results in an empty string on jdk9+\n+\t\t\t.collect(Collectors.toSet());\n+\n+\t\t// use a TreeSet to make the reporter order deterministic, which is useful for testing\n+\t\tSet<String> namedOrderedReporters = new TreeSet<>(String::compareTo);\n+\n+\t\t// scan entire configuration for keys starting with METRICS_REPORTER_PREFIX and determine the set of enabled reporters\n+\t\tfor (String key : configuration.keySet()) {\n+\t\t\tif (key.startsWith(ConfigConstants.METRICS_REPORTER_PREFIX)) {\n+\t\t\t\tMatcher matcher = reporterClassPattern.matcher(key);\n+\t\t\t\tif (matcher.matches()) {\n+\t\t\t\t\tString reporterName = matcher.group(1);\n+\t\t\t\t\tif (includedReporters.isEmpty() || includedReporters.contains(reporterName)) {\n+\t\t\t\t\t\tif (namedOrderedReporters.contains(reporterName)) {\n+\t\t\t\t\t\t\tLOG.warn(\"Duplicate class configuration detected for reporter {}.\", reporterName);\n+\t\t\t\t\t\t} else {\n+\t\t\t\t\t\t\tnamedOrderedReporters.add(reporterName);\n+\t\t\t\t\t\t}\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tLOG.info(\"Excluding reporter {}, not configured in reporter list ({}).\", reporterName, includedReportersString);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t\treturn namedOrderedReporters;\n+\t}\n+\n+\tprivate static Map<String, MetricReporterFactory> loadAvailableReporterFactories(PluginManager pluginManager) {\n \t\tfinal Map<String, MetricReporterFactory> reporterFactories = new HashMap<>(2);\n-\t\tfinal Iterator<MetricReporterFactory> factoryIterator = serviceLoader.iterator();\n+\t\tfinal Iterator<MetricReporterFactory> factoryIterator = getAllReporterFactories(pluginManager);\n+\t\tLOG.debug(\"All available factories (from both SPIs and Plugins):\");\n+\t\tgetAllReporterFactories(pluginManager).forEachRemaining(i -> LOG.debug(i.toString()));\n \t\t// do not use streams or for-each loops here because they do not allow catching individual ServiceConfigurationErrors\n \t\t// such an error might be caused if the META-INF/services contains an entry to a non-existing factory class\n \t\twhile (factoryIterator.hasNext()) {\n \t\t\ttry {\n \t\t\t\tMetricReporterFactory factory = factoryIterator.next();\n-\t\t\t\treporterFactories.put(factory.getClass().getName(), factory);\n+\t\t\t\tString factoryClassName = factory.getClass().getName();\n+\t\t\t\tMetricReporterFactory existingFactory = reporterFactories.get(factoryClassName);\n+\t\t\t\tif (existingFactory == null){\n+\t\t\t\t\treporterFactories.put(factoryClassName, factory);\n+\t\t\t\t\tLOG.warn(new File(factory.getClass().getProtectionDomain().getCodeSource().getLocation()\n+\t\t\t\t\t\t.toURI()).getCanonicalPath());\n+\t\t\t\t} else {\n+\t\t\t\t\t//TODO: use path information below, when Plugin Classloader stops always prioritizing factories from /lib\n+//\t\t\t\t\tString jarPath1 = new File(existingFactory.getClass().getProtectionDomain().getCodeSource().getLocation()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2OTY5Ng=="}, "originalCommit": {"oid": "d693668c44effeffafc944835df873e3978f88b9"}, "originalPosition": 174}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "5dfb306ba6ff07f700b1afc21847641321705d4d", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/5dfb306ba6ff07f700b1afc21847641321705d4d", "committedDate": "2020-03-02T22:12:52Z", "message": "[FLINK-16222][runtime] Use plugins load mechanism to initialize MetricsReporters"}, "afterCommit": {"oid": "3aded2be8a0019e7b025d811d204e92d36dd24e7", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/3aded2be8a0019e7b025d811d204e92d36dd24e7", "committedDate": "2020-03-17T10:25:49Z", "message": "[FLINK-16222][runtime] Use plugins load mechanism to initialize MetricsReporters"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "3aded2be8a0019e7b025d811d204e92d36dd24e7", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/3aded2be8a0019e7b025d811d204e92d36dd24e7", "committedDate": "2020-03-17T10:25:49Z", "message": "[FLINK-16222][runtime] Use plugins load mechanism to initialize MetricsReporters"}, "afterCommit": {"oid": "57db59bd20c14d5a0872f6d35b2b3220624ec96b", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/57db59bd20c14d5a0872f6d35b2b3220624ec96b", "committedDate": "2020-03-17T13:51:44Z", "message": "[FLINK-16222][runtime] Use plugins load mechanism to initialize MetricsReporters"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "57db59bd20c14d5a0872f6d35b2b3220624ec96b", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/57db59bd20c14d5a0872f6d35b2b3220624ec96b", "committedDate": "2020-03-17T13:51:44Z", "message": "[FLINK-16222][runtime] Use plugins load mechanism to initialize MetricsReporters"}, "afterCommit": {"oid": "5b0f219689e81fe11c3511c13c7f4943a997a4ef", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/5b0f219689e81fe11c3511c13c7f4943a997a4ef", "committedDate": "2020-03-17T16:58:33Z", "message": "[FLINK-16222][runtime] Use plugins load mechanism to initialize MetricsReporters"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "3e2cdca58b30cb79c92bee7fc073dc0a494069ab", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/3e2cdca58b30cb79c92bee7fc073dc0a494069ab", "committedDate": "2020-03-17T17:27:22Z", "message": "[FLINK-16222][runtime] Refactoring: direct use of TreeSet"}, "afterCommit": {"oid": "a244cee274bab74683c25f90bfd515698bc04c95", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/a244cee274bab74683c25f90bfd515698bc04c95", "committedDate": "2020-03-17T20:29:22Z", "message": "[FLINK-16222][runtime] Refactor: remove potential reporter credentials leak via logging"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc2NjExMDg2", "url": "https://github.com/apache/flink/pull/11195#pullrequestreview-376611086", "createdAt": "2020-03-18T07:17:23Z", "commit": {"oid": "bc188f48bff0c164ad2e36ef0eda3a5557e5adba"}, "state": "APPROVED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOFQwNzoxNzoyNFrOF34pKg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOFQwNzoyNjoxMVrOF343XA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE0NDA0Mg==", "bodyText": "That's something that @zentol knows much better. It sounds plausible to me.", "url": "https://github.com/apache/flink/pull/11195#discussion_r394144042", "createdAt": "2020-03-18T07:17:24Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/entrypoint/ClusterEntrypoint.java", "diffHunk": "@@ -160,13 +161,14 @@ public void startCluster() throws ClusterEntrypointException {\n \t\tLOG.info(\"Starting {}.\", getClass().getSimpleName());\n \n \t\ttry {\n-\n-\t\t\tconfigureFileSystems(configuration);\n+\t\t\t//TODO: push down filesystem initialization into runCluster - initializeServices (?)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODMxMDA1OA=="}, "originalCommit": {"oid": "bc188f48bff0c164ad2e36ef0eda3a5557e5adba"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE0NzI2NQ==", "bodyText": "So this would then only work for two plugins. I don't see a way around that without proper SPI.\nI'd probably remove the commented code completely; it shouldn't be hard to bring back and would avoid some confusion.", "url": "https://github.com/apache/flink/pull/11195#discussion_r394147265", "createdAt": "2020-03-18T07:25:09Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -178,36 +164,96 @@ private static ReporterSetup createReporterSetup(String reporterName, MetricConf\n \t\t\t\tmetricReporterOptional.ifPresent(reporter -> {\n \t\t\t\t\tMetricConfig metricConfig = new MetricConfig();\n \t\t\t\t\treporterConfig.addAllToProperties(metricConfig);\n-\n-\t\t\t\t\treporterArguments.add(createReporterSetup(reporterName, metricConfig, reporter));\n+\t\t\t\t\treporterSetups.add(createReporterSetup(reporterName, metricConfig, reporter));\n \t\t\t\t});\n-\t\t\t}\n-\t\t\tcatch (Throwable t) {\n+\t\t\t} catch (Throwable t) {\n \t\t\t\tLOG.error(\"Could not instantiate metrics reporter {}. Metrics might not be exposed/reported.\", reporterName, t);\n \t\t\t}\n \t\t}\n-\t\treturn reporterArguments;\n+\t\treturn reporterSetups;\n \t}\n \n-\tprivate static Map<String, MetricReporterFactory> loadReporterFactories() {\n-\t\tfinal ServiceLoader<MetricReporterFactory> serviceLoader = ServiceLoader.load(MetricReporterFactory.class);\n+\tprivate static List<Tuple2<String, Configuration>> loadReporterConfigurations(Configuration configuration, Set<String> namedReporters) {\n+\t\tfinal List<Tuple2<String, Configuration>> reporterConfigurations = new ArrayList<>(namedReporters.size());\n+\n+\t\tfor (String namedReporter: namedReporters) {\n+\t\t\tDelegatingConfiguration delegatingConfiguration = new DelegatingConfiguration(\n+\t\t\t\tconfiguration,\n+\t\t\t\tConfigConstants.METRICS_REPORTER_PREFIX + namedReporter + '.');\n \n+\t\t\treporterConfigurations.add(Tuple2.of(namedReporter, delegatingConfiguration));\n+\t\t}\n+\t\treturn reporterConfigurations;\n+\t}\n+\n+\tprivate static Set<String> findEnabledReportersInConfiguration(Configuration configuration, String includedReportersString) {\n+\t\tSet<String> includedReporters = reporterListPattern.splitAsStream(includedReportersString)\n+\t\t\t.filter(r -> !r.isEmpty()) // splitting an empty string results in an empty string on jdk9+\n+\t\t\t.collect(Collectors.toSet());\n+\n+\t\t// use a TreeSet to make the reporter order deterministic, which is useful for testing\n+\t\tSet<String> namedOrderedReporters = new TreeSet<>(String::compareTo);\n+\n+\t\t// scan entire configuration for keys starting with METRICS_REPORTER_PREFIX and determine the set of enabled reporters\n+\t\tfor (String key : configuration.keySet()) {\n+\t\t\tif (key.startsWith(ConfigConstants.METRICS_REPORTER_PREFIX)) {\n+\t\t\t\tMatcher matcher = reporterClassPattern.matcher(key);\n+\t\t\t\tif (matcher.matches()) {\n+\t\t\t\t\tString reporterName = matcher.group(1);\n+\t\t\t\t\tif (includedReporters.isEmpty() || includedReporters.contains(reporterName)) {\n+\t\t\t\t\t\tif (namedOrderedReporters.contains(reporterName)) {\n+\t\t\t\t\t\t\tLOG.warn(\"Duplicate class configuration detected for reporter {}.\", reporterName);\n+\t\t\t\t\t\t} else {\n+\t\t\t\t\t\t\tnamedOrderedReporters.add(reporterName);\n+\t\t\t\t\t\t}\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tLOG.info(\"Excluding reporter {}, not configured in reporter list ({}).\", reporterName, includedReportersString);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t\treturn namedOrderedReporters;\n+\t}\n+\n+\tprivate static Map<String, MetricReporterFactory> loadAvailableReporterFactories(PluginManager pluginManager) {\n \t\tfinal Map<String, MetricReporterFactory> reporterFactories = new HashMap<>(2);\n-\t\tfinal Iterator<MetricReporterFactory> factoryIterator = serviceLoader.iterator();\n+\t\tfinal Iterator<MetricReporterFactory> factoryIterator = getAllReporterFactories(pluginManager);\n+\t\tLOG.debug(\"All available factories (from both SPIs and Plugins):\");\n+\t\tgetAllReporterFactories(pluginManager).forEachRemaining(i -> LOG.debug(i.toString()));\n \t\t// do not use streams or for-each loops here because they do not allow catching individual ServiceConfigurationErrors\n \t\t// such an error might be caused if the META-INF/services contains an entry to a non-existing factory class\n \t\twhile (factoryIterator.hasNext()) {\n \t\t\ttry {\n \t\t\t\tMetricReporterFactory factory = factoryIterator.next();\n-\t\t\t\treporterFactories.put(factory.getClass().getName(), factory);\n+\t\t\t\tString factoryClassName = factory.getClass().getName();\n+\t\t\t\tMetricReporterFactory existingFactory = reporterFactories.get(factoryClassName);\n+\t\t\t\tif (existingFactory == null){\n+\t\t\t\t\treporterFactories.put(factoryClassName, factory);\n+\t\t\t\t\tLOG.warn(new File(factory.getClass().getProtectionDomain().getCodeSource().getLocation()\n+\t\t\t\t\t\t.toURI()).getCanonicalPath());\n+\t\t\t\t} else {\n+\t\t\t\t\t//TODO: use path information below, when Plugin Classloader stops always prioritizing factories from /lib\n+//\t\t\t\t\tString jarPath1 = new File(existingFactory.getClass().getProtectionDomain().getCodeSource().getLocation()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2OTY5Ng=="}, "originalCommit": {"oid": "d693668c44effeffafc944835df873e3978f88b9"}, "originalPosition": 174}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE0NzY3Ng==", "bodyText": "/ means or. and/or is and or or, which can be simplified to or. (or is not xor in English)", "url": "https://github.com/apache/flink/pull/11195#discussion_r394147676", "createdAt": "2020-03-18T07:26:11Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -210,17 +213,31 @@ private static ReporterSetup createReporterSetup(String reporterName, MetricConf\n \t\treturn namedOrderedReporters;\n \t}\n \n-\tprivate static Map<String, MetricReporterFactory> loadReporterFactories() {\n-\t\tfinal ServiceLoader<MetricReporterFactory> serviceLoader = ServiceLoader.load(MetricReporterFactory.class);\n-\n+\tprivate static Map<String, MetricReporterFactory> loadAvailableReporterFactories(PluginManager pluginManager) {\n \t\tfinal Map<String, MetricReporterFactory> reporterFactories = new HashMap<>(2);\n-\t\tfinal Iterator<MetricReporterFactory> factoryIterator = serviceLoader.iterator();\n+\t\tfinal Iterator<MetricReporterFactory> factoryIterator = getAllReporterFactories(pluginManager);\n+\t\tLOG.info(\"Prepare reporter factories (from both SPIs and Plugins):\");\n \t\t// do not use streams or for-each loops here because they do not allow catching individual ServiceConfigurationErrors\n \t\t// such an error might be caused if the META-INF/services contains an entry to a non-existing factory class\n \t\twhile (factoryIterator.hasNext()) {\n \t\t\ttry {\n \t\t\t\tMetricReporterFactory factory = factoryIterator.next();\n-\t\t\t\treporterFactories.put(factory.getClass().getName(), factory);\n+\t\t\t\tString factoryClassName = factory.getClass().getName();\n+\t\t\t\tMetricReporterFactory existingFactory = reporterFactories.get(factoryClassName);\n+\t\t\t\tif (existingFactory == null){\n+\t\t\t\t\treporterFactories.put(factoryClassName, factory);\n+\t\t\t\t\tLOG.info(\"Found reporter factory {} at {} \",\n+\t\t\t\t\t\tfactoryClassName,\n+\t\t\t\t\t\tnew File(factory.getClass().getProtectionDomain().getCodeSource().getLocation().toURI()).getCanonicalPath());\n+\t\t\t\t} else {\n+\t\t\t\t\t//TODO: use path information below, when Plugin Classloader stops always prioritizing factories from /lib\n+//\t\t\t\t\tString jarPath1 = new File(existingFactory.getClass().getProtectionDomain().getCodeSource().getLocation()\n+//\t\t\t\t\t\t.toURI()).getCanonicalPath();\n+//\t\t\t\t\tString jarPath2 = new File(factory.getClass().getProtectionDomain().getCodeSource().getLocation()\n+//\t\t\t\t\t\t.toURI()).getCanonicalPath();\n+//\t\t\t\t\tLOG.warn(\"Multiple implementations of the same reporter were found: \\n {} and \\n{}\", jarPath1, jarPath2);\n+\t\t\t\t\tLOG.warn(\"Multiple implementations of the same reporter were found in 'lib' and/or 'plugins' directories for {}. It is recommended to remove redundant reporter JARs to resolve used versions' ambiguity.\", factoryClassName);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "63001ed57dcdebbf5f0642285f6e82565caf7b4e"}, "originalPosition": 54}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc2NjU1MTky", "url": "https://github.com/apache/flink/pull/11195#pullrequestreview-376655192", "createdAt": "2020-03-18T08:38:16Z", "commit": {"oid": "a244cee274bab74683c25f90bfd515698bc04c95"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOFQwODozODoxNlrOF362Lg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOFQxMDozMTo0M1rOF3-5gA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE4MDE0Mg==", "bodyText": "This will require a rebase; we added a more generic version for copying jars so we don't have to keep adding new ones. You will have to add a JarLocation for the plugins directory, and modify FlinkDistribution#moveJar to handle this location appropriately.", "url": "https://github.com/apache/flink/pull/11195#discussion_r394180142", "createdAt": "2020-03-18T08:38:16Z", "author": {"login": "zentol"}, "path": "flink-end-to-end-tests/flink-end-to-end-tests-common/src/main/java/org/apache/flink/tests/util/FlinkDistribution.java", "diffHunk": "@@ -260,16 +262,26 @@ public void submitSQLJob(SQLJobSubmission job) throws IOException {\n \t}\n \n \tpublic void copyOptJarsToLib(String jarNamePrefix) throws FileNotFoundException, IOException {\n-\t\tfinal Optional<Path> reporterJarOptional;\n-\t\ttry (Stream<Path> logFiles = Files.walk(opt)) {\n-\t\t\treporterJarOptional = logFiles\n+\t\tcopyOptJars(jarNamePrefix, lib);\n+\t}\n+\n+\tpublic void copyOptJarsToPlugins(String jarNamePrefix) throws FileNotFoundException, IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a244cee274bab74683c25f90bfd515698bc04c95"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE4MTI4OA==", "bodyText": "this will also need adjustments after a rebase, as this test now works against the FlinkResource interface, where jar copies and configuration settings are done as part of the FlinkResource setup.", "url": "https://github.com/apache/flink/pull/11195#discussion_r394181288", "createdAt": "2020-03-18T08:40:35Z", "author": {"login": "zentol"}, "path": "flink-end-to-end-tests/flink-metrics-reporter-prometheus-test/src/test/java/org/apache/flink/metrics/prometheus/tests/PrometheusReporterEndToEndITCase.java", "diffHunk": "@@ -120,24 +122,51 @@ public static void checkOS() {\n \tpublic final DownloadCache downloadCache = DownloadCache.get();\n \n \t@Test\n-\tpublic void testReporter() throws Exception {\n-\t\tdist.copyOptJarsToLib(\"flink-metrics-prometheus\");\n+\tpublic void reporterWorksWhenFoundInLibsViaReflection() throws Exception {\n+\t\tdist.copyOptJarsToLib(PROMETHEUS_JAR_PREFIX);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a244cee274bab74683c25f90bfd515698bc04c95"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE4MzE1MA==", "bodyText": "Ideally we move the logic from PrometheusReporter#open into this method and change the constructor accordingly.", "url": "https://github.com/apache/flink/pull/11195#discussion_r394183150", "createdAt": "2020-03-18T08:43:55Z", "author": {"login": "zentol"}, "path": "flink-metrics/flink-metrics-prometheus/src/main/java/org/apache/flink/metrics/prometheus/PrometheusReporterFactory.java", "diffHunk": "@@ -0,0 +1,34 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.metrics.prometheus;\n+\n+import org.apache.flink.core.plugin.Plugin;\n+import org.apache.flink.metrics.reporter.MetricReporterFactory;\n+\n+import java.util.Properties;\n+\n+/**\n+ * {@link MetricReporterFactory} for {@link PrometheusReporter}.\n+ */\n+public class PrometheusReporterFactory implements MetricReporterFactory, Plugin {\n+\n+\t@Override\n+\tpublic PrometheusReporter createMetricReporter(Properties properties) {\n+\t\treturn new PrometheusReporter();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a244cee274bab74683c25f90bfd515698bc04c95"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE4MzMwMA==", "bodyText": "We need a second factory for the PrometheusPushGatewayReporter", "url": "https://github.com/apache/flink/pull/11195#discussion_r394183300", "createdAt": "2020-03-18T08:44:10Z", "author": {"login": "zentol"}, "path": "flink-metrics/flink-metrics-prometheus/src/main/java/org/apache/flink/metrics/prometheus/PrometheusReporterFactory.java", "diffHunk": "@@ -0,0 +1,34 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.metrics.prometheus;\n+\n+import org.apache.flink.core.plugin.Plugin;\n+import org.apache.flink.metrics.reporter.MetricReporterFactory;\n+\n+import java.util.Properties;\n+\n+/**\n+ * {@link MetricReporterFactory} for {@link PrometheusReporter}.\n+ */\n+public class PrometheusReporterFactory implements MetricReporterFactory, Plugin {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a244cee274bab74683c25f90bfd515698bc04c95"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDIzNjMyMA==", "bodyText": "I've got no clue. Maybe @tillrohrmann remembers why this was added outside runSecured in bbac4a6#diff-5334e24ac6a0d7e69599ceca71fd2e99.", "url": "https://github.com/apache/flink/pull/11195#discussion_r394236320", "createdAt": "2020-03-18T10:14:21Z", "author": {"login": "zentol"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/entrypoint/ClusterEntrypoint.java", "diffHunk": "@@ -160,13 +161,14 @@ public void startCluster() throws ClusterEntrypointException {\n \t\tLOG.info(\"Starting {}.\", getClass().getSimpleName());\n \n \t\ttry {\n-\n-\t\t\tconfigureFileSystems(configuration);\n+\t\t\t//TODO: push down filesystem initialization into runCluster - initializeServices (?)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODMxMDA1OA=="}, "originalCommit": {"oid": "bc188f48bff0c164ad2e36ef0eda3a5557e5adba"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDIzODA1MA==", "bodyText": "unused?", "url": "https://github.com/apache/flink/pull/11195#discussion_r394238050", "createdAt": "2020-03-18T10:17:12Z", "author": {"login": "zentol"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/metrics/ReporterSetupTest.java", "diffHunk": "@@ -21,6 +21,7 @@\n import org.apache.flink.configuration.ConfigConstants;\n import org.apache.flink.configuration.Configuration;\n import org.apache.flink.configuration.MetricOptions;\n+import org.apache.flink.core.plugin.PluginManager;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a244cee274bab74683c25f90bfd515698bc04c95"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDIzOTExNA==", "bodyText": "this belongs into a separate commit since it is fixing a bug in the test that can occur independently from this PR.", "url": "https://github.com/apache/flink/pull/11195#discussion_r394239114", "createdAt": "2020-03-18T10:18:59Z", "author": {"login": "zentol"}, "path": "flink-end-to-end-tests/flink-metrics-reporter-prometheus-test/src/test/java/org/apache/flink/metrics/prometheus/tests/PrometheusReporterEndToEndITCase.java", "diffHunk": "@@ -120,24 +122,51 @@ public static void checkOS() {\n \tpublic final DownloadCache downloadCache = DownloadCache.get();\n \n \t@Test\n-\tpublic void testReporter() throws Exception {\n-\t\tdist.copyOptJarsToLib(\"flink-metrics-prometheus\");\n+\tpublic void reporterWorksWhenFoundInLibsViaReflection() throws Exception {\n+\t\tdist.copyOptJarsToLib(PROMETHEUS_JAR_PREFIX);\n+\t\ttestReporter(false);\n+\t}\n+\n+\t@Test\n+\tpublic void reporterWorksWhenFoundInPluginsViaReflection() throws Exception {\n+\t\tdist.copyOptJarsToPlugins(PROMETHEUS_JAR_PREFIX);\n+\t\ttestReporter(false);\n+\t}\n+\n+\t@Test\n+\tpublic void reporterWorksWhenFoundInPluginsViaFactories() throws Exception {\n+\t\tdist.copyOptJarsToPlugins(PROMETHEUS_JAR_PREFIX);\n+\t\ttestReporter(true);\n+\t}\n \n+\t@Test\n+\tpublic void reporterWorksWhenFoundBothInPluginsAndLibsViaFactories() throws Exception {\n+\t\tdist.copyOptJarsToPlugins(PROMETHEUS_JAR_PREFIX);\n+\t\tdist.copyOptJarsToLib(PROMETHEUS_JAR_PREFIX);\n+\t\ttestReporter(true);\n+\t}\n+\n+\tprivate void testReporter(boolean useFactory) throws Exception {\n \t\tfinal Configuration config = new Configuration();\n-\t\tconfig.setString(ConfigConstants.METRICS_REPORTER_PREFIX + \"prom.\" + ConfigConstants.METRICS_REPORTER_CLASS_SUFFIX, PrometheusReporter.class.getCanonicalName());\n+\n+\t\tif (useFactory) {\n+\t\t\tconfig.setString(ConfigConstants.METRICS_REPORTER_PREFIX + \"prom.\" + ConfigConstants.METRICS_REPORTER_FACTORY_CLASS_SUFFIX, PrometheusReporterFactory.class.getName());\n+\t\t} else {\n+\t\t\tconfig.setString(ConfigConstants.METRICS_REPORTER_PREFIX + \"prom.\" + ConfigConstants.METRICS_REPORTER_CLASS_SUFFIX, PrometheusReporter.class.getCanonicalName());\n+\t\t}\n+\n \t\tconfig.setString(ConfigConstants.METRICS_REPORTER_PREFIX + \"prom.port\", \"9000-9100\");\n \n \t\tdist.appendConfiguration(config);\n \n \t\tfinal Path tmpPrometheusDir = tmp.newFolder().toPath().resolve(\"prometheus\");\n-\t\tfinal Path prometheusArchive = tmpPrometheusDir.resolve(PROMETHEUS_FILE_NAME + \".tar.gz\");\n \t\tfinal Path prometheusBinDir = tmpPrometheusDir.resolve(PROMETHEUS_FILE_NAME);\n \t\tfinal Path prometheusConfig = prometheusBinDir.resolve(\"prometheus.yml\");\n \t\tfinal Path prometheusBinary = prometheusBinDir.resolve(\"prometheus\");\n \t\tFiles.createDirectory(tmpPrometheusDir);\n \n-\t\tdownloadCache.getOrDownload(\n-\t\t\t\"https://github.com/prometheus/prometheus/releases/download/v\" + PROMETHEUS_VERSION + '/' + prometheusArchive.getFileName(),\n+\t\tfinal Path prometheusArchive = downloadCache.getOrDownload(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "37984c5d08a46b06bee75779aed813a5e1f04863"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDI0MTMyMg==", "bodyText": "our code style unfortunately does not cover the placement of such braces; hence we reject any changes such as this to existing code.", "url": "https://github.com/apache/flink/pull/11195#discussion_r394241322", "createdAt": "2020-03-18T10:22:53Z", "author": {"login": "zentol"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -178,36 +164,96 @@ private static ReporterSetup createReporterSetup(String reporterName, MetricConf\n \t\t\t\tmetricReporterOptional.ifPresent(reporter -> {\n \t\t\t\t\tMetricConfig metricConfig = new MetricConfig();\n \t\t\t\t\treporterConfig.addAllToProperties(metricConfig);\n-\n-\t\t\t\t\treporterArguments.add(createReporterSetup(reporterName, metricConfig, reporter));\n+\t\t\t\t\treporterSetups.add(createReporterSetup(reporterName, metricConfig, reporter));\n \t\t\t\t});\n-\t\t\t}\n-\t\t\tcatch (Throwable t) {\n+\t\t\t} catch (Throwable t) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3Nzk3Mw=="}, "originalCommit": {"oid": "d693668c44effeffafc944835df873e3978f88b9"}, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDI0NTc0NQ==", "bodyText": "It's frequently used in our code and documentation; I don't think we gain anything by watching out for things like this.\nPersonally I find it less ambiguous than just or.", "url": "https://github.com/apache/flink/pull/11195#discussion_r394245745", "createdAt": "2020-03-18T10:30:21Z", "author": {"login": "zentol"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -210,17 +213,31 @@ private static ReporterSetup createReporterSetup(String reporterName, MetricConf\n \t\treturn namedOrderedReporters;\n \t}\n \n-\tprivate static Map<String, MetricReporterFactory> loadReporterFactories() {\n-\t\tfinal ServiceLoader<MetricReporterFactory> serviceLoader = ServiceLoader.load(MetricReporterFactory.class);\n-\n+\tprivate static Map<String, MetricReporterFactory> loadAvailableReporterFactories(PluginManager pluginManager) {\n \t\tfinal Map<String, MetricReporterFactory> reporterFactories = new HashMap<>(2);\n-\t\tfinal Iterator<MetricReporterFactory> factoryIterator = serviceLoader.iterator();\n+\t\tfinal Iterator<MetricReporterFactory> factoryIterator = getAllReporterFactories(pluginManager);\n+\t\tLOG.info(\"Prepare reporter factories (from both SPIs and Plugins):\");\n \t\t// do not use streams or for-each loops here because they do not allow catching individual ServiceConfigurationErrors\n \t\t// such an error might be caused if the META-INF/services contains an entry to a non-existing factory class\n \t\twhile (factoryIterator.hasNext()) {\n \t\t\ttry {\n \t\t\t\tMetricReporterFactory factory = factoryIterator.next();\n-\t\t\t\treporterFactories.put(factory.getClass().getName(), factory);\n+\t\t\t\tString factoryClassName = factory.getClass().getName();\n+\t\t\t\tMetricReporterFactory existingFactory = reporterFactories.get(factoryClassName);\n+\t\t\t\tif (existingFactory == null){\n+\t\t\t\t\treporterFactories.put(factoryClassName, factory);\n+\t\t\t\t\tLOG.info(\"Found reporter factory {} at {} \",\n+\t\t\t\t\t\tfactoryClassName,\n+\t\t\t\t\t\tnew File(factory.getClass().getProtectionDomain().getCodeSource().getLocation().toURI()).getCanonicalPath());\n+\t\t\t\t} else {\n+\t\t\t\t\t//TODO: use path information below, when Plugin Classloader stops always prioritizing factories from /lib\n+//\t\t\t\t\tString jarPath1 = new File(existingFactory.getClass().getProtectionDomain().getCodeSource().getLocation()\n+//\t\t\t\t\t\t.toURI()).getCanonicalPath();\n+//\t\t\t\t\tString jarPath2 = new File(factory.getClass().getProtectionDomain().getCodeSource().getLocation()\n+//\t\t\t\t\t\t.toURI()).getCanonicalPath();\n+//\t\t\t\t\tLOG.warn(\"Multiple implementations of the same reporter were found: \\n {} and \\n{}\", jarPath1, jarPath2);\n+\t\t\t\t\tLOG.warn(\"Multiple implementations of the same reporter were found in 'lib' and/or 'plugins' directories for {}. It is recommended to remove redundant reporter JARs to resolve used versions' ambiguity.\", factoryClassName);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE0NzY3Ng=="}, "originalCommit": {"oid": "63001ed57dcdebbf5f0642285f6e82565caf7b4e"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDI0NjUyOA==", "bodyText": "We usually don't allow commented code, and I agree with arvid that it would be easy to bring back.", "url": "https://github.com/apache/flink/pull/11195#discussion_r394246528", "createdAt": "2020-03-18T10:31:43Z", "author": {"login": "zentol"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -178,36 +164,96 @@ private static ReporterSetup createReporterSetup(String reporterName, MetricConf\n \t\t\t\tmetricReporterOptional.ifPresent(reporter -> {\n \t\t\t\t\tMetricConfig metricConfig = new MetricConfig();\n \t\t\t\t\treporterConfig.addAllToProperties(metricConfig);\n-\n-\t\t\t\t\treporterArguments.add(createReporterSetup(reporterName, metricConfig, reporter));\n+\t\t\t\t\treporterSetups.add(createReporterSetup(reporterName, metricConfig, reporter));\n \t\t\t\t});\n-\t\t\t}\n-\t\t\tcatch (Throwable t) {\n+\t\t\t} catch (Throwable t) {\n \t\t\t\tLOG.error(\"Could not instantiate metrics reporter {}. Metrics might not be exposed/reported.\", reporterName, t);\n \t\t\t}\n \t\t}\n-\t\treturn reporterArguments;\n+\t\treturn reporterSetups;\n \t}\n \n-\tprivate static Map<String, MetricReporterFactory> loadReporterFactories() {\n-\t\tfinal ServiceLoader<MetricReporterFactory> serviceLoader = ServiceLoader.load(MetricReporterFactory.class);\n+\tprivate static List<Tuple2<String, Configuration>> loadReporterConfigurations(Configuration configuration, Set<String> namedReporters) {\n+\t\tfinal List<Tuple2<String, Configuration>> reporterConfigurations = new ArrayList<>(namedReporters.size());\n+\n+\t\tfor (String namedReporter: namedReporters) {\n+\t\t\tDelegatingConfiguration delegatingConfiguration = new DelegatingConfiguration(\n+\t\t\t\tconfiguration,\n+\t\t\t\tConfigConstants.METRICS_REPORTER_PREFIX + namedReporter + '.');\n \n+\t\t\treporterConfigurations.add(Tuple2.of(namedReporter, delegatingConfiguration));\n+\t\t}\n+\t\treturn reporterConfigurations;\n+\t}\n+\n+\tprivate static Set<String> findEnabledReportersInConfiguration(Configuration configuration, String includedReportersString) {\n+\t\tSet<String> includedReporters = reporterListPattern.splitAsStream(includedReportersString)\n+\t\t\t.filter(r -> !r.isEmpty()) // splitting an empty string results in an empty string on jdk9+\n+\t\t\t.collect(Collectors.toSet());\n+\n+\t\t// use a TreeSet to make the reporter order deterministic, which is useful for testing\n+\t\tSet<String> namedOrderedReporters = new TreeSet<>(String::compareTo);\n+\n+\t\t// scan entire configuration for keys starting with METRICS_REPORTER_PREFIX and determine the set of enabled reporters\n+\t\tfor (String key : configuration.keySet()) {\n+\t\t\tif (key.startsWith(ConfigConstants.METRICS_REPORTER_PREFIX)) {\n+\t\t\t\tMatcher matcher = reporterClassPattern.matcher(key);\n+\t\t\t\tif (matcher.matches()) {\n+\t\t\t\t\tString reporterName = matcher.group(1);\n+\t\t\t\t\tif (includedReporters.isEmpty() || includedReporters.contains(reporterName)) {\n+\t\t\t\t\t\tif (namedOrderedReporters.contains(reporterName)) {\n+\t\t\t\t\t\t\tLOG.warn(\"Duplicate class configuration detected for reporter {}.\", reporterName);\n+\t\t\t\t\t\t} else {\n+\t\t\t\t\t\t\tnamedOrderedReporters.add(reporterName);\n+\t\t\t\t\t\t}\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tLOG.info(\"Excluding reporter {}, not configured in reporter list ({}).\", reporterName, includedReportersString);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t\treturn namedOrderedReporters;\n+\t}\n+\n+\tprivate static Map<String, MetricReporterFactory> loadAvailableReporterFactories(PluginManager pluginManager) {\n \t\tfinal Map<String, MetricReporterFactory> reporterFactories = new HashMap<>(2);\n-\t\tfinal Iterator<MetricReporterFactory> factoryIterator = serviceLoader.iterator();\n+\t\tfinal Iterator<MetricReporterFactory> factoryIterator = getAllReporterFactories(pluginManager);\n+\t\tLOG.debug(\"All available factories (from both SPIs and Plugins):\");\n+\t\tgetAllReporterFactories(pluginManager).forEachRemaining(i -> LOG.debug(i.toString()));\n \t\t// do not use streams or for-each loops here because they do not allow catching individual ServiceConfigurationErrors\n \t\t// such an error might be caused if the META-INF/services contains an entry to a non-existing factory class\n \t\twhile (factoryIterator.hasNext()) {\n \t\t\ttry {\n \t\t\t\tMetricReporterFactory factory = factoryIterator.next();\n-\t\t\t\treporterFactories.put(factory.getClass().getName(), factory);\n+\t\t\t\tString factoryClassName = factory.getClass().getName();\n+\t\t\t\tMetricReporterFactory existingFactory = reporterFactories.get(factoryClassName);\n+\t\t\t\tif (existingFactory == null){\n+\t\t\t\t\treporterFactories.put(factoryClassName, factory);\n+\t\t\t\t\tLOG.warn(new File(factory.getClass().getProtectionDomain().getCodeSource().getLocation()\n+\t\t\t\t\t\t.toURI()).getCanonicalPath());\n+\t\t\t\t} else {\n+\t\t\t\t\t//TODO: use path information below, when Plugin Classloader stops always prioritizing factories from /lib\n+//\t\t\t\t\tString jarPath1 = new File(existingFactory.getClass().getProtectionDomain().getCodeSource().getLocation()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2OTY5Ng=="}, "originalCommit": {"oid": "d693668c44effeffafc944835df873e3978f88b9"}, "originalPosition": 174}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a244cee274bab74683c25f90bfd515698bc04c95", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/a244cee274bab74683c25f90bfd515698bc04c95", "committedDate": "2020-03-17T20:29:22Z", "message": "[FLINK-16222][runtime] Refactor: remove potential reporter credentials leak via logging"}, "afterCommit": {"oid": "7ce9ad87a780aab19b9c97680d7af5f648c13f3b", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/7ce9ad87a780aab19b9c97680d7af5f648c13f3b", "committedDate": "2020-03-19T21:12:49Z", "message": "[FLINK-16222][runtime] Refactor: remove potential reporter credentials leak via logging"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "7ce9ad87a780aab19b9c97680d7af5f648c13f3b", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/7ce9ad87a780aab19b9c97680d7af5f648c13f3b", "committedDate": "2020-03-19T21:12:49Z", "message": "[FLINK-16222][runtime] Refactor: remove potential reporter credentials leak via logging"}, "afterCommit": {"oid": "245fcd1ee6e8a5515ccb44621e86361fd9f3cd78", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/245fcd1ee6e8a5515ccb44621e86361fd9f3cd78", "committedDate": "2020-03-19T21:42:39Z", "message": "[FLINK-16222][runtime] Refactor: remove potential reporter credentials leak via logging"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "245fcd1ee6e8a5515ccb44621e86361fd9f3cd78", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/245fcd1ee6e8a5515ccb44621e86361fd9f3cd78", "committedDate": "2020-03-19T21:42:39Z", "message": "[FLINK-16222][runtime] Refactor: remove potential reporter credentials leak via logging"}, "afterCommit": {"oid": "7f6ad172474e37bbf346a7762868c9114510c4c9", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/7f6ad172474e37bbf346a7762868c9114510c4c9", "committedDate": "2020-03-19T21:47:24Z", "message": "[FLINK-16222][runtime] Refactor: remove potential reporter credentials leak via logging"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "7f6ad172474e37bbf346a7762868c9114510c4c9", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/7f6ad172474e37bbf346a7762868c9114510c4c9", "committedDate": "2020-03-19T21:47:24Z", "message": "[FLINK-16222][runtime] Refactor: remove potential reporter credentials leak via logging"}, "afterCommit": {"oid": "2590a69417bdd2b6bf2f4765b276a051040a97cf", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/2590a69417bdd2b6bf2f4765b276a051040a97cf", "committedDate": "2020-03-19T22:15:42Z", "message": "[FLINK-16222][runtime] Refactor: remove potential reporter credentials leak via logging"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "2590a69417bdd2b6bf2f4765b276a051040a97cf", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/2590a69417bdd2b6bf2f4765b276a051040a97cf", "committedDate": "2020-03-19T22:15:42Z", "message": "[FLINK-16222][runtime] Refactor: remove potential reporter credentials leak via logging"}, "afterCommit": {"oid": "d07ec693eb90e33071e710be0b774fc995f05867", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/d07ec693eb90e33071e710be0b774fc995f05867", "committedDate": "2020-03-19T22:43:07Z", "message": "[FLINK-16222][runtime] Refactor: remove potential reporter credentials leak via logging"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d07ec693eb90e33071e710be0b774fc995f05867", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/d07ec693eb90e33071e710be0b774fc995f05867", "committedDate": "2020-03-19T22:43:07Z", "message": "[FLINK-16222][runtime] Refactor: remove potential reporter credentials leak via logging"}, "afterCommit": {"oid": "a1b15671c97e8809c0301fb4c225fdc1a7f78545", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/a1b15671c97e8809c0301fb4c225fdc1a7f78545", "committedDate": "2020-03-19T23:05:05Z", "message": "[FLINK-16222][runtime] Refactor: remove potential reporter credentials leak via logging"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a1b15671c97e8809c0301fb4c225fdc1a7f78545", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/a1b15671c97e8809c0301fb4c225fdc1a7f78545", "committedDate": "2020-03-19T23:05:05Z", "message": "[FLINK-16222][runtime] Refactor: remove potential reporter credentials leak via logging"}, "afterCommit": {"oid": "eccc41d96524bd8ff6bfa6bfa36f366689255893", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/eccc41d96524bd8ff6bfa6bfa36f366689255893", "committedDate": "2020-03-26T17:29:07Z", "message": "[FLINK-16222][runtime] Refactor: remove potential reporter credentials leak via logging"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "eccc41d96524bd8ff6bfa6bfa36f366689255893", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/eccc41d96524bd8ff6bfa6bfa36f366689255893", "committedDate": "2020-03-26T17:29:07Z", "message": "[FLINK-16222][runtime] Refactor: remove potential reporter credentials leak via logging"}, "afterCommit": {"oid": "19b07382fedcab4e7c4866eb260a12cde4780538", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/19b07382fedcab4e7c4866eb260a12cde4780538", "committedDate": "2020-03-26T21:38:06Z", "message": "[FLINK-16222][runtime] Refactor: remove potential reporter credentials leak via logging"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgyNjM1ODQ5", "url": "https://github.com/apache/flink/pull/11195#pullrequestreview-382635849", "createdAt": "2020-03-27T07:45:59Z", "commit": {"oid": "19b07382fedcab4e7c4866eb260a12cde4780538"}, "state": "APPROVED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QwNzo0NjowMFrOF8mKKA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QwNzo0ODoxNFrOF8mNgA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTA4NDA3Mg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            org.apache.flink.metrics.prometheus.PrometheusReporterFactory\n          \n          \n            \n            org.apache.flink.metrics.prometheus.PrometheusReporterFactory\n          \n          \n            \n            org.apache.flink.metrics.prometheus.PrometheusPushGatewayReporterFactory", "url": "https://github.com/apache/flink/pull/11195#discussion_r399084072", "createdAt": "2020-03-27T07:46:00Z", "author": {"login": "zentol"}, "path": "flink-metrics/flink-metrics-prometheus/src/main/resources/META-INF/services/org.apache.flink.metrics.reporter.MetricReporterFactory", "diffHunk": "@@ -0,0 +1,16 @@\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+org.apache.flink.metrics.prometheus.PrometheusReporterFactory", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "19b07382fedcab4e7c4866eb260a12cde4780538"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTA4NDkyOA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t\t\treturn new FlinkResourceSetup(config,  Collections.unmodifiableCollection(jarOperations));\n          \n          \n            \n            \t\t\treturn new FlinkResourceSetup(config, Collections.unmodifiableCollection(jarOperations));", "url": "https://github.com/apache/flink/pull/11195#discussion_r399084928", "createdAt": "2020-03-27T07:48:14Z", "author": {"login": "zentol"}, "path": "flink-end-to-end-tests/flink-end-to-end-tests-common/src/main/java/org/apache/flink/tests/util/flink/FlinkResourceSetup.java", "diffHunk": "@@ -69,13 +69,13 @@ public FlinkResourceSetupBuilder addConfiguration(Configuration config) {\n \t\t\treturn this;\n \t\t}\n \n-\t\tpublic FlinkResourceSetupBuilder moveJar(String jarNamePrefix, JarLocation source, JarLocation target) {\n-\t\t\tthis.jarMoveOperations.add(new JarMove(jarNamePrefix, source, target));\n+\t\tpublic FlinkResourceSetupBuilder addJarOperation(JarOperation jarOperation) {\n+\t\t\tthis.jarOperations.add(jarOperation);\n \t\t\treturn this;\n \t\t}\n \n \t\tpublic FlinkResourceSetup build() {\n-\t\t\treturn new FlinkResourceSetup(config, Collections.unmodifiableCollection(jarMoveOperations));\n+\t\t\treturn new FlinkResourceSetup(config,  Collections.unmodifiableCollection(jarOperations));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "19b07382fedcab4e7c4866eb260a12cde4780538"}, "originalPosition": 47}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "590a281040da44deee5137b037bbabcaedd0b487", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/590a281040da44deee5137b037bbabcaedd0b487", "committedDate": "2020-03-27T15:24:35Z", "message": "[FLINK-16222][core] Relax Plugin bounded type parameter constraint"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ad42c142ec109c5fb4cf1bcccb61183c3e8b4a68", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/ad42c142ec109c5fb4cf1bcccb61183c3e8b4a68", "committedDate": "2020-03-27T18:11:23Z", "message": "[FLINK-16222][runtime] Introduce PluginManager to ReporterSetup"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "19b07382fedcab4e7c4866eb260a12cde4780538", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/19b07382fedcab4e7c4866eb260a12cde4780538", "committedDate": "2020-03-26T21:38:06Z", "message": "[FLINK-16222][runtime] Refactor: remove potential reporter credentials leak via logging"}, "afterCommit": {"oid": "3630f07793d9eba899a746df43549b971ea6b2b7", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/3630f07793d9eba899a746df43549b971ea6b2b7", "committedDate": "2020-03-27T18:11:49Z", "message": "[FLINK-16222][metrics][prometheus] Add plugin e2e test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "672c515dda8d5d659c009099b98dd6a5835bbd40", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/672c515dda8d5d659c009099b98dd6a5835bbd40", "committedDate": "2020-03-27T18:19:01Z", "message": "[FLINK-16222][metrics] Support loading reporters as plugins"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6a088a5f122ccce53e5baa97603eb8b0a9599247", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/6a088a5f122ccce53e5baa97603eb8b0a9599247", "committedDate": "2020-03-27T18:19:01Z", "message": "[FLINK-16222][metrics][prometheus] Add plugin e2e test"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "3630f07793d9eba899a746df43549b971ea6b2b7", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/3630f07793d9eba899a746df43549b971ea6b2b7", "committedDate": "2020-03-27T18:11:49Z", "message": "[FLINK-16222][metrics][prometheus] Add plugin e2e test"}, "afterCommit": {"oid": "6a088a5f122ccce53e5baa97603eb8b0a9599247", "author": {"user": {"login": "afedulov", "name": "Alexander Fedulov"}}, "url": "https://github.com/apache/flink/commit/6a088a5f122ccce53e5baa97603eb8b0a9599247", "committedDate": "2020-03-27T18:19:01Z", "message": "[FLINK-16222][metrics][prometheus] Add plugin e2e test"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4968, "cost": 1, "resetAt": "2021-10-28T16:48:13Z"}}}