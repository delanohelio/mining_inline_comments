{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDc2OTIwMDcx", "number": 13296, "reviewThreads": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxMDowNDowM1rOEk5xUQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxMDo0NjozOVrOEk6m1A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA3MTMwNzA1OnYy", "diffSide": "RIGHT", "path": "flink-formats/flink-avro-confluent-registry/src/main/java/org/apache/flink/formats/avro/registry/confluent/debezium/DebeziumAvroDeserializationSchema.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxMDowNDowM1rOHUGkTw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxMDowNDowM1rOHUGkTw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDg0MTE2Nw==", "bodyText": "Remove.", "url": "https://github.com/apache/flink/pull/13296#discussion_r490841167", "createdAt": "2020-09-18T10:04:03Z", "author": {"login": "wuchong"}, "path": "flink-formats/flink-avro-confluent-registry/src/main/java/org/apache/flink/formats/avro/registry/confluent/debezium/DebeziumAvroDeserializationSchema.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.formats.avro.registry.confluent.debezium;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.serialization.DeserializationSchema;\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.formats.avro.AvroRowDataDeserializationSchema;\n+import org.apache.flink.formats.avro.AvroToRowDataConverters;\n+import org.apache.flink.formats.avro.registry.confluent.ConfluentRegistryAvroDeserializationSchema;\n+import org.apache.flink.formats.avro.typeutils.AvroSchemaConverter;\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.data.GenericRowData;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.types.RowKind;\n+import org.apache.flink.util.Collector;\n+\n+import java.io.IOException;\n+import java.util.Objects;\n+\n+import static java.lang.String.format;\n+import static org.apache.flink.table.types.utils.TypeConversions.fromLogicalToDataType;\n+\n+/**\n+ * Deserialization schema from Debezium Avro to Flink Table/SQL internal data structure {@link RowData}.\n+ * The deserialization schema knows Debezium's schema definition and can extract the database data\n+ * and convert into {@link RowData} with {@link RowKind}.\n+ * <p>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8003ac0791570594085b8672d4d47c33fc2bbaf2"}, "originalPosition": 46}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA3MTMxMTAzOnYy", "diffSide": "RIGHT", "path": "flink-formats/flink-avro-confluent-registry/src/main/java/org/apache/flink/formats/avro/registry/confluent/debezium/DebeziumAvroDeserializationSchema.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxMDowNTowM1rOHUGmfQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxMDowNTowM1rOHUGmfQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDg0MTcyNQ==", "bodyText": "Add . at the end.\nPlease check the checkstyle agian. The compile build is failed.", "url": "https://github.com/apache/flink/pull/13296#discussion_r490841725", "createdAt": "2020-09-18T10:05:03Z", "author": {"login": "wuchong"}, "path": "flink-formats/flink-avro-confluent-registry/src/main/java/org/apache/flink/formats/avro/registry/confluent/debezium/DebeziumAvroDeserializationSchema.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.formats.avro.registry.confluent.debezium;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.serialization.DeserializationSchema;\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.formats.avro.AvroRowDataDeserializationSchema;\n+import org.apache.flink.formats.avro.AvroToRowDataConverters;\n+import org.apache.flink.formats.avro.registry.confluent.ConfluentRegistryAvroDeserializationSchema;\n+import org.apache.flink.formats.avro.typeutils.AvroSchemaConverter;\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.data.GenericRowData;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.types.RowKind;\n+import org.apache.flink.util.Collector;\n+\n+import java.io.IOException;\n+import java.util.Objects;\n+\n+import static java.lang.String.format;\n+import static org.apache.flink.table.types.utils.TypeConversions.fromLogicalToDataType;\n+\n+/**\n+ * Deserialization schema from Debezium Avro to Flink Table/SQL internal data structure {@link RowData}.\n+ * The deserialization schema knows Debezium's schema definition and can extract the database data\n+ * and convert into {@link RowData} with {@link RowKind}.\n+ * <p>\n+ * <p>Deserializes a <code>byte[]</code> message as a JSON object and reads\n+ * the specified fields.\n+ * <p>\n+ * <p>Failures during deserialization are forwarded as wrapped IOExceptions.\n+ *\n+ * @see <a href=\"https://debezium.io/\">Debezium</a>\n+ */\n+@Internal\n+public final class DebeziumAvroDeserializationSchema implements DeserializationSchema<RowData> {\n+\tprivate static final long serialVersionUID = 1L;\n+\n+\t/**\n+\t * snapshot read", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8003ac0791570594085b8672d4d47c33fc2bbaf2"}, "originalPosition": 59}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA3MTMxMzY3OnYy", "diffSide": "RIGHT", "path": "flink-formats/flink-avro-confluent-registry/src/main/java/org/apache/flink/formats/avro/registry/confluent/debezium/DebeziumAvroFormatFactory.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxMDowNTo1NFrOHUGoKw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQwMjozODoxNVrOHZWcTQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDg0MjE1NQ==", "bodyText": "Add one more indent for method arguments. Please check other methods.", "url": "https://github.com/apache/flink/pull/13296#discussion_r490842155", "createdAt": "2020-09-18T10:05:54Z", "author": {"login": "wuchong"}, "path": "flink-formats/flink-avro-confluent-registry/src/main/java/org/apache/flink/formats/avro/registry/confluent/debezium/DebeziumAvroFormatFactory.java", "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.formats.avro.registry.confluent.debezium;\n+\n+import org.apache.flink.api.common.serialization.DeserializationSchema;\n+import org.apache.flink.api.common.serialization.SerializationSchema;\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.configuration.ConfigOption;\n+import org.apache.flink.configuration.ReadableConfig;\n+import org.apache.flink.table.api.ValidationException;\n+import org.apache.flink.table.connector.ChangelogMode;\n+import org.apache.flink.table.connector.format.DecodingFormat;\n+import org.apache.flink.table.connector.format.EncodingFormat;\n+import org.apache.flink.table.connector.sink.DynamicTableSink;\n+import org.apache.flink.table.connector.source.DynamicTableSource;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.factories.DeserializationFormatFactory;\n+import org.apache.flink.table.factories.DynamicTableFactory;\n+import org.apache.flink.table.factories.FactoryUtil;\n+import org.apache.flink.table.factories.SerializationFormatFactory;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.types.RowKind;\n+\n+import java.util.HashSet;\n+import java.util.Optional;\n+import java.util.Set;\n+\n+import static org.apache.flink.formats.avro.registry.confluent.RegistryAvroOptions.SCHEMA_REGISTRY_SUBJECT;\n+import static org.apache.flink.formats.avro.registry.confluent.RegistryAvroOptions.SCHEMA_REGISTRY_URL;\n+\n+/**\n+ * Format factory for providing configured instances of Debezium Avro to RowData {@link DeserializationSchema}.\n+ */\n+public class DebeziumAvroFormatFactory implements DeserializationFormatFactory, SerializationFormatFactory {\n+\n+\tpublic static final String IDENTIFIER = \"debezium-avro-confluent\";\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\t@Override\n+\tpublic DecodingFormat<DeserializationSchema<RowData>> createDecodingFormat(\n+\t\tDynamicTableFactory.Context context,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8003ac0791570594085b8672d4d47c33fc2bbaf2"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjM0NDE0MQ==", "bodyText": "checkstyle  done.", "url": "https://github.com/apache/flink/pull/13296#discussion_r496344141", "createdAt": "2020-09-29T02:38:15Z", "author": {"login": "caozhen1937"}, "path": "flink-formats/flink-avro-confluent-registry/src/main/java/org/apache/flink/formats/avro/registry/confluent/debezium/DebeziumAvroFormatFactory.java", "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.formats.avro.registry.confluent.debezium;\n+\n+import org.apache.flink.api.common.serialization.DeserializationSchema;\n+import org.apache.flink.api.common.serialization.SerializationSchema;\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.configuration.ConfigOption;\n+import org.apache.flink.configuration.ReadableConfig;\n+import org.apache.flink.table.api.ValidationException;\n+import org.apache.flink.table.connector.ChangelogMode;\n+import org.apache.flink.table.connector.format.DecodingFormat;\n+import org.apache.flink.table.connector.format.EncodingFormat;\n+import org.apache.flink.table.connector.sink.DynamicTableSink;\n+import org.apache.flink.table.connector.source.DynamicTableSource;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.factories.DeserializationFormatFactory;\n+import org.apache.flink.table.factories.DynamicTableFactory;\n+import org.apache.flink.table.factories.FactoryUtil;\n+import org.apache.flink.table.factories.SerializationFormatFactory;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.types.RowKind;\n+\n+import java.util.HashSet;\n+import java.util.Optional;\n+import java.util.Set;\n+\n+import static org.apache.flink.formats.avro.registry.confluent.RegistryAvroOptions.SCHEMA_REGISTRY_SUBJECT;\n+import static org.apache.flink.formats.avro.registry.confluent.RegistryAvroOptions.SCHEMA_REGISTRY_URL;\n+\n+/**\n+ * Format factory for providing configured instances of Debezium Avro to RowData {@link DeserializationSchema}.\n+ */\n+public class DebeziumAvroFormatFactory implements DeserializationFormatFactory, SerializationFormatFactory {\n+\n+\tpublic static final String IDENTIFIER = \"debezium-avro-confluent\";\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\t@Override\n+\tpublic DecodingFormat<DeserializationSchema<RowData>> createDecodingFormat(\n+\t\tDynamicTableFactory.Context context,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDg0MjE1NQ=="}, "originalCommit": {"oid": "8003ac0791570594085b8672d4d47c33fc2bbaf2"}, "originalPosition": 58}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA3MTM2MjI5OnYy", "diffSide": "RIGHT", "path": "flink-formats/flink-avro-confluent-registry/src/main/java/org/apache/flink/formats/avro/registry/confluent/debezium/DebeziumAvroDeserializationSchema.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxMDoyMTo0MVrOHUHF8A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxMDoyMTo0MVrOHUHF8A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDg0OTc3Ng==", "bodyText": "We should also know the index of before and after. Shouldn't get the index dynamically.\nSee the implementation of debezium-json.", "url": "https://github.com/apache/flink/pull/13296#discussion_r490849776", "createdAt": "2020-09-18T10:21:41Z", "author": {"login": "wuchong"}, "path": "flink-formats/flink-avro-confluent-registry/src/main/java/org/apache/flink/formats/avro/registry/confluent/debezium/DebeziumAvroDeserializationSchema.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.formats.avro.registry.confluent.debezium;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.serialization.DeserializationSchema;\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.formats.avro.AvroRowDataDeserializationSchema;\n+import org.apache.flink.formats.avro.AvroToRowDataConverters;\n+import org.apache.flink.formats.avro.registry.confluent.ConfluentRegistryAvroDeserializationSchema;\n+import org.apache.flink.formats.avro.typeutils.AvroSchemaConverter;\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.data.GenericRowData;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.types.RowKind;\n+import org.apache.flink.util.Collector;\n+\n+import java.io.IOException;\n+import java.util.Objects;\n+\n+import static java.lang.String.format;\n+import static org.apache.flink.table.types.utils.TypeConversions.fromLogicalToDataType;\n+\n+/**\n+ * Deserialization schema from Debezium Avro to Flink Table/SQL internal data structure {@link RowData}.\n+ * The deserialization schema knows Debezium's schema definition and can extract the database data\n+ * and convert into {@link RowData} with {@link RowKind}.\n+ * <p>\n+ * <p>Deserializes a <code>byte[]</code> message as a JSON object and reads\n+ * the specified fields.\n+ * <p>\n+ * <p>Failures during deserialization are forwarded as wrapped IOExceptions.\n+ *\n+ * @see <a href=\"https://debezium.io/\">Debezium</a>\n+ */\n+@Internal\n+public final class DebeziumAvroDeserializationSchema implements DeserializationSchema<RowData> {\n+\tprivate static final long serialVersionUID = 1L;\n+\n+\t/**\n+\t * snapshot read\n+\t */\n+\tprivate static final String OP_READ = \"r\";\n+\t/**\n+\t * insert operation\n+\t */\n+\tprivate static final String OP_CREATE = \"c\";\n+\t/**\n+\t * update operation\n+\t */\n+\tprivate static final String OP_UPDATE = \"u\";\n+\t/**\n+\t * delete operation\n+\t */\n+\tprivate static final String OP_DELETE = \"d\";\n+\n+\tprivate static final String REPLICA_IDENTITY_EXCEPTION = \"The \\\"before\\\" field of %s message is null, \" +\n+\t\t\"if you are using Debezium Postgres Connector, \" +\n+\t\t\"please check the Postgres table has been set REPLICA IDENTITY to FULL level.\";\n+\n+\t/**\n+\t * The deserializer to deserialize Debezium Avro data.\n+\t */\n+\tprivate final AvroRowDataDeserializationSchema avroDeserializer;\n+\n+\t/**\n+\t * TypeInformation of the produced {@link RowData}.\n+\t **/\n+\tprivate final TypeInformation<RowData> resultTypeInfo;\n+\n+\t/**\n+\t * Debezium Avro data rowType\n+\t */\n+\tprivate final RowType rowType;\n+\n+\n+\tpublic DebeziumAvroDeserializationSchema(\n+\t\t\tRowType rowType,\n+\t\t\tTypeInformation<RowData> resultTypeInfo,\n+\t\t\tString schemaRegistryUrl) {\n+\t\tthis.resultTypeInfo = resultTypeInfo;\n+\t\tthis.rowType = rowType;\n+\t\tRowType debeziumAvroRowType = createDebeziumAvroRowType(fromLogicalToDataType(rowType));\n+\n+\t\tthis.avroDeserializer = new AvroRowDataDeserializationSchema(\n+\t\t\tConfluentRegistryAvroDeserializationSchema.forGeneric(\n+\t\t\t\tAvroSchemaConverter.convertToSchema(debeziumAvroRowType),\n+\t\t\t\tschemaRegistryUrl),\n+\t\t\tAvroToRowDataConverters.createRowConverter(debeziumAvroRowType),\n+\t\t\tresultTypeInfo);\n+\t}\n+\n+\tpublic DebeziumAvroDeserializationSchema(\n+\t\t\tRowType rowType,\n+\t\t\tTypeInformation<RowData> resultTypeInfo,\n+\t\t\tAvroRowDataDeserializationSchema avroDeserializer) {\n+\t\tthis.rowType = rowType;\n+\t\tthis.resultTypeInfo = resultTypeInfo;\n+\t\tthis.avroDeserializer = avroDeserializer;\n+\t}\n+\n+\t@Override\n+\tpublic RowData deserialize(byte[] message) throws IOException {\n+\t\tthrow new RuntimeException(\n+\t\t\t\"Please invoke DeserializationSchema#deserialize(byte[], Collector<RowData>) instead.\");\n+\t}\n+\n+\t@Override\n+\tpublic void deserialize(byte[] message, Collector<RowData> out) throws IOException {\n+\n+\t\tif (message == null || message.length == 0) {\n+\t\t\t// skip tombstone messages\n+\t\t\treturn;\n+\t\t}\n+\t\ttry {\n+\t\t\tGenericRowData row = (GenericRowData) avroDeserializer.deserialize(message);\n+\n+\t\t\tGenericRowData before = null;\n+\t\t\tint index = rowType.getFieldIndex(\"before\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8003ac0791570594085b8672d4d47c33fc2bbaf2"}, "originalPosition": 137}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA3MTM4MTYxOnYy", "diffSide": "RIGHT", "path": "flink-formats/flink-avro-confluent-registry/src/main/java/org/apache/flink/formats/avro/registry/confluent/debezium/DebeziumAvroSerializationSchema.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxMDoyNzowOVrOHUHRVw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNFQwODowNDoyM1rOHcF2HA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDg1MjY5NQ==", "bodyText": "We need \"before\", because the DELETE should encode data into \"before\".", "url": "https://github.com/apache/flink/pull/13296#discussion_r490852695", "createdAt": "2020-09-18T10:27:09Z", "author": {"login": "wuchong"}, "path": "flink-formats/flink-avro-confluent-registry/src/main/java/org/apache/flink/formats/avro/registry/confluent/debezium/DebeziumAvroSerializationSchema.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.formats.avro.registry.confluent.debezium;\n+\n+import org.apache.flink.api.common.serialization.SerializationSchema;\n+import org.apache.flink.formats.avro.AvroRowDataSerializationSchema;\n+import org.apache.flink.formats.avro.RowDataToAvroConverters;\n+import org.apache.flink.formats.avro.registry.confluent.ConfluentRegistryAvroSerializationSchema;\n+import org.apache.flink.formats.avro.typeutils.AvroSchemaConverter;\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.data.GenericRowData;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.data.StringData;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.types.RowKind;\n+\n+import java.util.Objects;\n+\n+import static org.apache.flink.table.types.utils.TypeConversions.fromLogicalToDataType;\n+\n+/**\n+ * Serialization schema from Flink Table/SQL internal data structure {@link RowData} to Debezium Avro.\n+ */\n+public class DebeziumAvroSerializationSchema implements SerializationSchema<RowData> {\n+\tprivate static final long serialVersionUID = 1L;\n+\n+\t/**\n+\t * insert operation\n+\t */\n+\tprivate static final StringData OP_CREATE = StringData.fromString(\"c\");\n+\t/**\n+\t * delete operation\n+\t */\n+\tprivate static final StringData OP_DELETE = StringData.fromString(\"d\");\n+\n+\t/**\n+\t * The deserializer to deserialize Debezium Avro data.\n+\t */\n+\tprivate final AvroRowDataSerializationSchema avroSerializer;\n+\n+\tprivate transient GenericRowData reuse = new GenericRowData(2);\n+\n+\tpublic DebeziumAvroSerializationSchema(\n+\t\t\tRowType rowType,\n+\t\t\tString schemaRegistryUrl,\n+\t\t\tString schemaRegistrySubject) {\n+\t\tRowType debeziumAvroRowType = createDebeziumAvroRowType(fromLogicalToDataType(rowType));\n+\n+\t\tthis.avroSerializer = new AvroRowDataSerializationSchema(\n+\t\t\tdebeziumAvroRowType,\n+\t\t\tConfluentRegistryAvroSerializationSchema.forGeneric(\n+\t\t\t\tschemaRegistrySubject,\n+\t\t\t\tAvroSchemaConverter.convertToSchema(debeziumAvroRowType),\n+\t\t\t\tschemaRegistryUrl),\n+\t\t\tRowDataToAvroConverters.createRowConverter(debeziumAvroRowType));\n+\t}\n+\n+\tpublic DebeziumAvroSerializationSchema(AvroRowDataSerializationSchema avroSerializer) {\n+\t\tthis.avroSerializer = avroSerializer;\n+\t}\n+\n+\t@Override\n+\tpublic void open(InitializationContext context) throws Exception {\n+\t}\n+\n+\t@Override\n+\tpublic byte[] serialize(RowData element) {\n+\t\treuse.setField(0, element);\n+\t\treuse.setField(1, rowKind2String(element.getRowKind()));\n+\t\treturn avroSerializer.serialize(reuse);\n+\t}\n+\n+\tprivate StringData rowKind2String(RowKind rowKind) {\n+\t\tswitch (rowKind) {\n+\t\t\tcase INSERT:\n+\t\t\tcase UPDATE_AFTER:\n+\t\t\t\treturn OP_CREATE;\n+\t\t\tcase UPDATE_BEFORE:\n+\t\t\tcase DELETE:\n+\t\t\t\treturn OP_DELETE;\n+\t\t\tdefault:\n+\t\t\t\tthrow new UnsupportedOperationException(\"Unsupported operation '\" + rowKind + \"' for row kind.\");\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic boolean equals(Object o) {\n+\t\tif (this == o) {\n+\t\t\treturn true;\n+\t\t}\n+\t\tif (o == null || getClass() != o.getClass()) {\n+\t\t\treturn false;\n+\t\t}\n+\t\tDebeziumAvroSerializationSchema that = (DebeziumAvroSerializationSchema) o;\n+\t\treturn Objects.equals(avroSerializer, that.avroSerializer);\n+\t}\n+\n+\t@Override\n+\tpublic int hashCode() {\n+\t\treturn Objects.hash(avroSerializer);\n+\t}\n+\n+\tpublic static RowType createDebeziumAvroRowType(DataType dataType) {\n+\t\t// Debezium Avro contains other information, e.g. \"source\", \"ts_ms\"\n+\t\t// but we don't need them\n+\t\t// and we don't need \"before\" , because can not support UPDATE_BEFORE,UPDATE_AFTER", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8003ac0791570594085b8672d4d47c33fc2bbaf2"}, "originalPosition": 123}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTIxNzk0OA==", "bodyText": "@wuchong  I found that when Using canal-json,debezium-json,maxwell-json serialization, the RowData of DELETE was not put old data into JSON message. I will open an issue to track it.\nhttps://issues.apache.org/jira/browse/FLINK-19500\nSorry,not a problem,I got it wrong.", "url": "https://github.com/apache/flink/pull/13296#discussion_r499217948", "createdAt": "2020-10-04T08:04:23Z", "author": {"login": "caozhen1937"}, "path": "flink-formats/flink-avro-confluent-registry/src/main/java/org/apache/flink/formats/avro/registry/confluent/debezium/DebeziumAvroSerializationSchema.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.formats.avro.registry.confluent.debezium;\n+\n+import org.apache.flink.api.common.serialization.SerializationSchema;\n+import org.apache.flink.formats.avro.AvroRowDataSerializationSchema;\n+import org.apache.flink.formats.avro.RowDataToAvroConverters;\n+import org.apache.flink.formats.avro.registry.confluent.ConfluentRegistryAvroSerializationSchema;\n+import org.apache.flink.formats.avro.typeutils.AvroSchemaConverter;\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.data.GenericRowData;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.data.StringData;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.types.RowKind;\n+\n+import java.util.Objects;\n+\n+import static org.apache.flink.table.types.utils.TypeConversions.fromLogicalToDataType;\n+\n+/**\n+ * Serialization schema from Flink Table/SQL internal data structure {@link RowData} to Debezium Avro.\n+ */\n+public class DebeziumAvroSerializationSchema implements SerializationSchema<RowData> {\n+\tprivate static final long serialVersionUID = 1L;\n+\n+\t/**\n+\t * insert operation\n+\t */\n+\tprivate static final StringData OP_CREATE = StringData.fromString(\"c\");\n+\t/**\n+\t * delete operation\n+\t */\n+\tprivate static final StringData OP_DELETE = StringData.fromString(\"d\");\n+\n+\t/**\n+\t * The deserializer to deserialize Debezium Avro data.\n+\t */\n+\tprivate final AvroRowDataSerializationSchema avroSerializer;\n+\n+\tprivate transient GenericRowData reuse = new GenericRowData(2);\n+\n+\tpublic DebeziumAvroSerializationSchema(\n+\t\t\tRowType rowType,\n+\t\t\tString schemaRegistryUrl,\n+\t\t\tString schemaRegistrySubject) {\n+\t\tRowType debeziumAvroRowType = createDebeziumAvroRowType(fromLogicalToDataType(rowType));\n+\n+\t\tthis.avroSerializer = new AvroRowDataSerializationSchema(\n+\t\t\tdebeziumAvroRowType,\n+\t\t\tConfluentRegistryAvroSerializationSchema.forGeneric(\n+\t\t\t\tschemaRegistrySubject,\n+\t\t\t\tAvroSchemaConverter.convertToSchema(debeziumAvroRowType),\n+\t\t\t\tschemaRegistryUrl),\n+\t\t\tRowDataToAvroConverters.createRowConverter(debeziumAvroRowType));\n+\t}\n+\n+\tpublic DebeziumAvroSerializationSchema(AvroRowDataSerializationSchema avroSerializer) {\n+\t\tthis.avroSerializer = avroSerializer;\n+\t}\n+\n+\t@Override\n+\tpublic void open(InitializationContext context) throws Exception {\n+\t}\n+\n+\t@Override\n+\tpublic byte[] serialize(RowData element) {\n+\t\treuse.setField(0, element);\n+\t\treuse.setField(1, rowKind2String(element.getRowKind()));\n+\t\treturn avroSerializer.serialize(reuse);\n+\t}\n+\n+\tprivate StringData rowKind2String(RowKind rowKind) {\n+\t\tswitch (rowKind) {\n+\t\t\tcase INSERT:\n+\t\t\tcase UPDATE_AFTER:\n+\t\t\t\treturn OP_CREATE;\n+\t\t\tcase UPDATE_BEFORE:\n+\t\t\tcase DELETE:\n+\t\t\t\treturn OP_DELETE;\n+\t\t\tdefault:\n+\t\t\t\tthrow new UnsupportedOperationException(\"Unsupported operation '\" + rowKind + \"' for row kind.\");\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic boolean equals(Object o) {\n+\t\tif (this == o) {\n+\t\t\treturn true;\n+\t\t}\n+\t\tif (o == null || getClass() != o.getClass()) {\n+\t\t\treturn false;\n+\t\t}\n+\t\tDebeziumAvroSerializationSchema that = (DebeziumAvroSerializationSchema) o;\n+\t\treturn Objects.equals(avroSerializer, that.avroSerializer);\n+\t}\n+\n+\t@Override\n+\tpublic int hashCode() {\n+\t\treturn Objects.hash(avroSerializer);\n+\t}\n+\n+\tpublic static RowType createDebeziumAvroRowType(DataType dataType) {\n+\t\t// Debezium Avro contains other information, e.g. \"source\", \"ts_ms\"\n+\t\t// but we don't need them\n+\t\t// and we don't need \"before\" , because can not support UPDATE_BEFORE,UPDATE_AFTER", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDg1MjY5NQ=="}, "originalCommit": {"oid": "8003ac0791570594085b8672d4d47c33fc2bbaf2"}, "originalPosition": 123}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA3MTM5MjMyOnYy", "diffSide": "RIGHT", "path": "flink-formats/flink-avro-confluent-registry/src/test/java/org/apache/flink/formats/avro/registry/confluent/debezium/DebeziumAvroFormatFactoryTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxMDoyOTo0M1rOHUHXJA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxMDoyOTo0M1rOHUHXJA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDg1NDE4MA==", "bodyText": "Use REGISTRY_URL instead of extract the value from options. This is used for asserting which should be a constant value.", "url": "https://github.com/apache/flink/pull/13296#discussion_r490854180", "createdAt": "2020-09-18T10:29:43Z", "author": {"login": "wuchong"}, "path": "flink-formats/flink-avro-confluent-registry/src/test/java/org/apache/flink/formats/avro/registry/confluent/debezium/DebeziumAvroFormatFactoryTest.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.formats.avro.registry.confluent.debezium;\n+\n+import org.apache.flink.api.common.serialization.DeserializationSchema;\n+import org.apache.flink.api.common.serialization.SerializationSchema;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.formats.avro.registry.confluent.RegistryAvroOptions;\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.catalog.CatalogTableImpl;\n+import org.apache.flink.table.catalog.ObjectIdentifier;\n+import org.apache.flink.table.connector.sink.DynamicTableSink;\n+import org.apache.flink.table.connector.source.DynamicTableSource;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.factories.FactoryUtil;\n+import org.apache.flink.table.factories.TestDynamicTableFactory;\n+import org.apache.flink.table.runtime.connector.sink.SinkRuntimeProviderContext;\n+import org.apache.flink.table.runtime.connector.source.ScanRuntimeProviderContext;\n+import org.apache.flink.table.runtime.typeutils.InternalTypeInfo;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.util.TestLogger;\n+import org.junit.Assert;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.ExpectedException;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.function.Consumer;\n+\n+import static junit.framework.TestCase.assertEquals;\n+import static org.apache.flink.core.testutils.FlinkMatchers.containsCause;\n+\n+/**\n+ * Tests for {@link DebeziumAvroFormatFactory}.\n+ */\n+public class DebeziumAvroFormatFactoryTest extends TestLogger {\n+\t@Rule\n+\tpublic ExpectedException thrown = ExpectedException.none();\n+\n+\tprivate static final TableSchema SCHEMA = TableSchema.builder()\n+\t\t.field(\"a\", DataTypes.STRING())\n+\t\t.field(\"b\", DataTypes.INT())\n+\t\t.field(\"c\", DataTypes.BOOLEAN())\n+\t\t.build();\n+\n+\tprivate static final RowType ROW_TYPE = (RowType) SCHEMA.toRowDataType().getLogicalType();\n+\n+\tprivate static final String SUBJECT = \"test-debezium-avro\";\n+\tprivate static final String REGISTRY_URL = \"http://localhost:8081\";\n+\n+\t@Test\n+\tpublic void testSeDeSchema() {\n+\t\tfinal Map<String, String> options = getAllOptions();\n+\t\tString schemaRegistryUrl = options.get(DebeziumAvroFormatFactory.IDENTIFIER + \".\" + RegistryAvroOptions.SCHEMA_REGISTRY_URL.key());\n+\t\tString schemaRegistrySubject = options.get(DebeziumAvroFormatFactory.IDENTIFIER + \".\" + RegistryAvroOptions.SCHEMA_REGISTRY_SUBJECT.key());\n+\n+\t\tfinal DebeziumAvroDeserializationSchema expectedDeser = new DebeziumAvroDeserializationSchema(\n+\t\t\tROW_TYPE,\n+\t\t\tInternalTypeInfo.of(ROW_TYPE),\n+\t\t\tschemaRegistryUrl);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8003ac0791570594085b8672d4d47c33fc2bbaf2"}, "originalPosition": 78}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA3MTM5MzU5OnYy", "diffSide": "RIGHT", "path": "flink-formats/flink-avro-confluent-registry/src/test/java/org/apache/flink/formats/avro/registry/confluent/debezium/DebeziumAvroFormatFactoryTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxMDozMDowOFrOHUHX4Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxMDozMDowOFrOHUHX4Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDg1NDM2OQ==", "bodyText": "Use SUBJECT instead.", "url": "https://github.com/apache/flink/pull/13296#discussion_r490854369", "createdAt": "2020-09-18T10:30:08Z", "author": {"login": "wuchong"}, "path": "flink-formats/flink-avro-confluent-registry/src/test/java/org/apache/flink/formats/avro/registry/confluent/debezium/DebeziumAvroFormatFactoryTest.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.formats.avro.registry.confluent.debezium;\n+\n+import org.apache.flink.api.common.serialization.DeserializationSchema;\n+import org.apache.flink.api.common.serialization.SerializationSchema;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.formats.avro.registry.confluent.RegistryAvroOptions;\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.catalog.CatalogTableImpl;\n+import org.apache.flink.table.catalog.ObjectIdentifier;\n+import org.apache.flink.table.connector.sink.DynamicTableSink;\n+import org.apache.flink.table.connector.source.DynamicTableSource;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.factories.FactoryUtil;\n+import org.apache.flink.table.factories.TestDynamicTableFactory;\n+import org.apache.flink.table.runtime.connector.sink.SinkRuntimeProviderContext;\n+import org.apache.flink.table.runtime.connector.source.ScanRuntimeProviderContext;\n+import org.apache.flink.table.runtime.typeutils.InternalTypeInfo;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.util.TestLogger;\n+import org.junit.Assert;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.ExpectedException;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.function.Consumer;\n+\n+import static junit.framework.TestCase.assertEquals;\n+import static org.apache.flink.core.testutils.FlinkMatchers.containsCause;\n+\n+/**\n+ * Tests for {@link DebeziumAvroFormatFactory}.\n+ */\n+public class DebeziumAvroFormatFactoryTest extends TestLogger {\n+\t@Rule\n+\tpublic ExpectedException thrown = ExpectedException.none();\n+\n+\tprivate static final TableSchema SCHEMA = TableSchema.builder()\n+\t\t.field(\"a\", DataTypes.STRING())\n+\t\t.field(\"b\", DataTypes.INT())\n+\t\t.field(\"c\", DataTypes.BOOLEAN())\n+\t\t.build();\n+\n+\tprivate static final RowType ROW_TYPE = (RowType) SCHEMA.toRowDataType().getLogicalType();\n+\n+\tprivate static final String SUBJECT = \"test-debezium-avro\";\n+\tprivate static final String REGISTRY_URL = \"http://localhost:8081\";\n+\n+\t@Test\n+\tpublic void testSeDeSchema() {\n+\t\tfinal Map<String, String> options = getAllOptions();\n+\t\tString schemaRegistryUrl = options.get(DebeziumAvroFormatFactory.IDENTIFIER + \".\" + RegistryAvroOptions.SCHEMA_REGISTRY_URL.key());\n+\t\tString schemaRegistrySubject = options.get(DebeziumAvroFormatFactory.IDENTIFIER + \".\" + RegistryAvroOptions.SCHEMA_REGISTRY_SUBJECT.key());\n+\n+\t\tfinal DebeziumAvroDeserializationSchema expectedDeser = new DebeziumAvroDeserializationSchema(\n+\t\t\tROW_TYPE,\n+\t\t\tInternalTypeInfo.of(ROW_TYPE),\n+\t\t\tschemaRegistryUrl);\n+\n+\t\tfinal DynamicTableSource actualSource = createTableSource(options);\n+\t\tassert actualSource instanceof TestDynamicTableFactory.DynamicTableSourceMock;\n+\t\tTestDynamicTableFactory.DynamicTableSourceMock scanSourceMock = (TestDynamicTableFactory.DynamicTableSourceMock) actualSource;\n+\n+\t\tDeserializationSchema<RowData> actualDeser = scanSourceMock.valueFormat\n+\t\t\t.createRuntimeDecoder(\n+\t\t\t\tScanRuntimeProviderContext.INSTANCE,\n+\t\t\t\tSCHEMA.toRowDataType());\n+\n+\t\tassertEquals(expectedDeser, actualDeser);\n+\n+\n+\t\tfinal DebeziumAvroSerializationSchema expectedSer = new DebeziumAvroSerializationSchema(\n+\t\t\tROW_TYPE,\n+\t\t\tschemaRegistryUrl,\n+\t\t\tschemaRegistrySubject", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8003ac0791570594085b8672d4d47c33fc2bbaf2"}, "originalPosition": 95}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA3MTQ0NDA0OnYy", "diffSide": "RIGHT", "path": "flink-formats/flink-avro-confluent-registry/src/main/java/org/apache/flink/formats/avro/registry/confluent/debezium/DebeziumAvroDeserializationSchema.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxMDo0NjozOVrOHUH1tA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQwMjoyNzoyMVrOHZWRrQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDg2MjAwNA==", "bodyText": "Why we need such a constructor? The avroDeserializer should be created by the debezium deserialization schema, otherwise it's error-prone.", "url": "https://github.com/apache/flink/pull/13296#discussion_r490862004", "createdAt": "2020-09-18T10:46:39Z", "author": {"login": "wuchong"}, "path": "flink-formats/flink-avro-confluent-registry/src/main/java/org/apache/flink/formats/avro/registry/confluent/debezium/DebeziumAvroDeserializationSchema.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.formats.avro.registry.confluent.debezium;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.serialization.DeserializationSchema;\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.formats.avro.AvroRowDataDeserializationSchema;\n+import org.apache.flink.formats.avro.AvroToRowDataConverters;\n+import org.apache.flink.formats.avro.registry.confluent.ConfluentRegistryAvroDeserializationSchema;\n+import org.apache.flink.formats.avro.typeutils.AvroSchemaConverter;\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.data.GenericRowData;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.types.RowKind;\n+import org.apache.flink.util.Collector;\n+\n+import java.io.IOException;\n+import java.util.Objects;\n+\n+import static java.lang.String.format;\n+import static org.apache.flink.table.types.utils.TypeConversions.fromLogicalToDataType;\n+\n+/**\n+ * Deserialization schema from Debezium Avro to Flink Table/SQL internal data structure {@link RowData}.\n+ * The deserialization schema knows Debezium's schema definition and can extract the database data\n+ * and convert into {@link RowData} with {@link RowKind}.\n+ * <p>\n+ * <p>Deserializes a <code>byte[]</code> message as a JSON object and reads\n+ * the specified fields.\n+ * <p>\n+ * <p>Failures during deserialization are forwarded as wrapped IOExceptions.\n+ *\n+ * @see <a href=\"https://debezium.io/\">Debezium</a>\n+ */\n+@Internal\n+public final class DebeziumAvroDeserializationSchema implements DeserializationSchema<RowData> {\n+\tprivate static final long serialVersionUID = 1L;\n+\n+\t/**\n+\t * snapshot read\n+\t */\n+\tprivate static final String OP_READ = \"r\";\n+\t/**\n+\t * insert operation\n+\t */\n+\tprivate static final String OP_CREATE = \"c\";\n+\t/**\n+\t * update operation\n+\t */\n+\tprivate static final String OP_UPDATE = \"u\";\n+\t/**\n+\t * delete operation\n+\t */\n+\tprivate static final String OP_DELETE = \"d\";\n+\n+\tprivate static final String REPLICA_IDENTITY_EXCEPTION = \"The \\\"before\\\" field of %s message is null, \" +\n+\t\t\"if you are using Debezium Postgres Connector, \" +\n+\t\t\"please check the Postgres table has been set REPLICA IDENTITY to FULL level.\";\n+\n+\t/**\n+\t * The deserializer to deserialize Debezium Avro data.\n+\t */\n+\tprivate final AvroRowDataDeserializationSchema avroDeserializer;\n+\n+\t/**\n+\t * TypeInformation of the produced {@link RowData}.\n+\t **/\n+\tprivate final TypeInformation<RowData> resultTypeInfo;\n+\n+\t/**\n+\t * Debezium Avro data rowType\n+\t */\n+\tprivate final RowType rowType;\n+\n+\n+\tpublic DebeziumAvroDeserializationSchema(\n+\t\t\tRowType rowType,\n+\t\t\tTypeInformation<RowData> resultTypeInfo,\n+\t\t\tString schemaRegistryUrl) {\n+\t\tthis.resultTypeInfo = resultTypeInfo;\n+\t\tthis.rowType = rowType;\n+\t\tRowType debeziumAvroRowType = createDebeziumAvroRowType(fromLogicalToDataType(rowType));\n+\n+\t\tthis.avroDeserializer = new AvroRowDataDeserializationSchema(\n+\t\t\tConfluentRegistryAvroDeserializationSchema.forGeneric(\n+\t\t\t\tAvroSchemaConverter.convertToSchema(debeziumAvroRowType),\n+\t\t\t\tschemaRegistryUrl),\n+\t\t\tAvroToRowDataConverters.createRowConverter(debeziumAvroRowType),\n+\t\t\tresultTypeInfo);\n+\t}\n+\n+\tpublic DebeziumAvroDeserializationSchema(\n+\t\t\tRowType rowType,\n+\t\t\tTypeInformation<RowData> resultTypeInfo,\n+\t\t\tAvroRowDataDeserializationSchema avroDeserializer) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8003ac0791570594085b8672d4d47c33fc2bbaf2"}, "originalPosition": 114}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjM0MTQyMQ==", "bodyText": "This constructor is used for unit testing because schemaRegistryUrl cannot be used to retrieve the schema.", "url": "https://github.com/apache/flink/pull/13296#discussion_r496341421", "createdAt": "2020-09-29T02:27:21Z", "author": {"login": "caozhen1937"}, "path": "flink-formats/flink-avro-confluent-registry/src/main/java/org/apache/flink/formats/avro/registry/confluent/debezium/DebeziumAvroDeserializationSchema.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.formats.avro.registry.confluent.debezium;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.serialization.DeserializationSchema;\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.formats.avro.AvroRowDataDeserializationSchema;\n+import org.apache.flink.formats.avro.AvroToRowDataConverters;\n+import org.apache.flink.formats.avro.registry.confluent.ConfluentRegistryAvroDeserializationSchema;\n+import org.apache.flink.formats.avro.typeutils.AvroSchemaConverter;\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.data.GenericRowData;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.types.RowKind;\n+import org.apache.flink.util.Collector;\n+\n+import java.io.IOException;\n+import java.util.Objects;\n+\n+import static java.lang.String.format;\n+import static org.apache.flink.table.types.utils.TypeConversions.fromLogicalToDataType;\n+\n+/**\n+ * Deserialization schema from Debezium Avro to Flink Table/SQL internal data structure {@link RowData}.\n+ * The deserialization schema knows Debezium's schema definition and can extract the database data\n+ * and convert into {@link RowData} with {@link RowKind}.\n+ * <p>\n+ * <p>Deserializes a <code>byte[]</code> message as a JSON object and reads\n+ * the specified fields.\n+ * <p>\n+ * <p>Failures during deserialization are forwarded as wrapped IOExceptions.\n+ *\n+ * @see <a href=\"https://debezium.io/\">Debezium</a>\n+ */\n+@Internal\n+public final class DebeziumAvroDeserializationSchema implements DeserializationSchema<RowData> {\n+\tprivate static final long serialVersionUID = 1L;\n+\n+\t/**\n+\t * snapshot read\n+\t */\n+\tprivate static final String OP_READ = \"r\";\n+\t/**\n+\t * insert operation\n+\t */\n+\tprivate static final String OP_CREATE = \"c\";\n+\t/**\n+\t * update operation\n+\t */\n+\tprivate static final String OP_UPDATE = \"u\";\n+\t/**\n+\t * delete operation\n+\t */\n+\tprivate static final String OP_DELETE = \"d\";\n+\n+\tprivate static final String REPLICA_IDENTITY_EXCEPTION = \"The \\\"before\\\" field of %s message is null, \" +\n+\t\t\"if you are using Debezium Postgres Connector, \" +\n+\t\t\"please check the Postgres table has been set REPLICA IDENTITY to FULL level.\";\n+\n+\t/**\n+\t * The deserializer to deserialize Debezium Avro data.\n+\t */\n+\tprivate final AvroRowDataDeserializationSchema avroDeserializer;\n+\n+\t/**\n+\t * TypeInformation of the produced {@link RowData}.\n+\t **/\n+\tprivate final TypeInformation<RowData> resultTypeInfo;\n+\n+\t/**\n+\t * Debezium Avro data rowType\n+\t */\n+\tprivate final RowType rowType;\n+\n+\n+\tpublic DebeziumAvroDeserializationSchema(\n+\t\t\tRowType rowType,\n+\t\t\tTypeInformation<RowData> resultTypeInfo,\n+\t\t\tString schemaRegistryUrl) {\n+\t\tthis.resultTypeInfo = resultTypeInfo;\n+\t\tthis.rowType = rowType;\n+\t\tRowType debeziumAvroRowType = createDebeziumAvroRowType(fromLogicalToDataType(rowType));\n+\n+\t\tthis.avroDeserializer = new AvroRowDataDeserializationSchema(\n+\t\t\tConfluentRegistryAvroDeserializationSchema.forGeneric(\n+\t\t\t\tAvroSchemaConverter.convertToSchema(debeziumAvroRowType),\n+\t\t\t\tschemaRegistryUrl),\n+\t\t\tAvroToRowDataConverters.createRowConverter(debeziumAvroRowType),\n+\t\t\tresultTypeInfo);\n+\t}\n+\n+\tpublic DebeziumAvroDeserializationSchema(\n+\t\t\tRowType rowType,\n+\t\t\tTypeInformation<RowData> resultTypeInfo,\n+\t\t\tAvroRowDataDeserializationSchema avroDeserializer) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDg2MjAwNA=="}, "originalCommit": {"oid": "8003ac0791570594085b8672d4d47c33fc2bbaf2"}, "originalPosition": 114}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 388, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}