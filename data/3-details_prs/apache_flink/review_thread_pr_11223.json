{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzgwMjY4NzAz", "number": 11223, "reviewThreads": {"totalCount": 13, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQxNDoyMDo0NlrODjGA7Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wMlQxMDo0NDowNVrODkOGmA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM4MTI1MjkzOnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-jdbc/src/main/java/org/apache/flink/api/java/io/jdbc/writer/AppendOnlyWriter.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQxNDoyMDo0NlrOFutTsw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQxNDoyMTozOVrOFutV9w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDUyMTEzOQ==", "bodyText": "List<Row> is sufficient here, we don't need to save a Tuple.", "url": "https://github.com/apache/flink/pull/11223#discussion_r384521139", "createdAt": "2020-02-26T14:20:46Z", "author": {"login": "libenchao"}, "path": "flink-connectors/flink-jdbc/src/main/java/org/apache/flink/api/java/io/jdbc/writer/AppendOnlyWriter.java", "diffHunk": "@@ -38,6 +40,7 @@\n \tprivate final String insertSQL;\n \tprivate final int[] fieldTypes;\n \n+\tprivate transient List<Tuple2<Boolean, Row>> rows;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "64692a3605478258174ec0e1b88754843170a01e"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDUyMTcxOQ==", "bodyText": "And for the name, maybe cachedRows or batchedRows be better?", "url": "https://github.com/apache/flink/pull/11223#discussion_r384521719", "createdAt": "2020-02-26T14:21:39Z", "author": {"login": "libenchao"}, "path": "flink-connectors/flink-jdbc/src/main/java/org/apache/flink/api/java/io/jdbc/writer/AppendOnlyWriter.java", "diffHunk": "@@ -38,6 +40,7 @@\n \tprivate final String insertSQL;\n \tprivate final int[] fieldTypes;\n \n+\tprivate transient List<Tuple2<Boolean, Row>> rows;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDUyMTEzOQ=="}, "originalCommit": {"oid": "64692a3605478258174ec0e1b88754843170a01e"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM4MTI4NzU0OnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-jdbc/src/test/java/org/apache/flink/api/java/io/jdbc/JDBCUpsertTableSinkITCase.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQxNDoyOTo0NFrOFutp3A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQxNDoyOTo0NFrOFutp3A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDUyNjgxMg==", "bodyText": "notExistedTable ?", "url": "https://github.com/apache/flink/pull/11223#discussion_r384526812", "createdAt": "2020-02-26T14:29:44Z", "author": {"login": "libenchao"}, "path": "flink-connectors/flink-jdbc/src/test/java/org/apache/flink/api/java/io/jdbc/JDBCUpsertTableSinkITCase.java", "diffHunk": "@@ -52,6 +53,7 @@\n \tpublic static final String DB_URL = \"jdbc:derby:memory:upsert\";\n \tpublic static final String OUTPUT_TABLE1 = \"upsertSink\";\n \tpublic static final String OUTPUT_TABLE2 = \"appendSink\";\n+\tpublic static final String NOT_EXISTS_TABLE = \"notExistsTable\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "64692a3605478258174ec0e1b88754843170a01e"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM4MTI5MTg3OnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-jdbc/src/test/java/org/apache/flink/api/java/io/jdbc/JDBCUpsertTableSinkITCase.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQxNDozMDo0OFrOFutsjA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QwNDozMjoyN1rOFvE9Fg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDUyNzUwMA==", "bodyText": "why do you test \"table not exists\" for fixing \"multiple flushing not work\" issue ?", "url": "https://github.com/apache/flink/pull/11223#discussion_r384527500", "createdAt": "2020-02-26T14:30:48Z", "author": {"login": "libenchao"}, "path": "flink-connectors/flink-jdbc/src/test/java/org/apache/flink/api/java/io/jdbc/JDBCUpsertTableSinkITCase.java", "diffHunk": "@@ -211,4 +213,31 @@ public void testAppend() throws Exception {\n \t\t\t\tRow.of(20, 6, Timestamp.valueOf(\"1970-01-01 00:00:00.02\"))\n \t\t}, DB_URL, OUTPUT_TABLE2, new String[]{\"id\", \"num\", \"ts\"});\n \t}\n+\n+\t@Test(expected = JobExecutionException.class)\n+\tpublic void testTableNotExists() throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "64692a3605478258174ec0e1b88754843170a01e"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDkwMDA2Nw==", "bodyText": "Hi\uff0c@libenchao\nAs this issue describe\uff0cthis test will hang rather than throw an Exception when the parameter connector.write.max-retries > 1\uff0c so I add this case to check that exception will throw properly after retry 3 times.", "url": "https://github.com/apache/flink/pull/11223#discussion_r384900067", "createdAt": "2020-02-27T03:50:44Z", "author": {"login": "leonardBang"}, "path": "flink-connectors/flink-jdbc/src/test/java/org/apache/flink/api/java/io/jdbc/JDBCUpsertTableSinkITCase.java", "diffHunk": "@@ -211,4 +213,31 @@ public void testAppend() throws Exception {\n \t\t\t\tRow.of(20, 6, Timestamp.valueOf(\"1970-01-01 00:00:00.02\"))\n \t\t}, DB_URL, OUTPUT_TABLE2, new String[]{\"id\", \"num\", \"ts\"});\n \t}\n+\n+\t@Test(expected = JobExecutionException.class)\n+\tpublic void testTableNotExists() throws Exception {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDUyNzUwMA=="}, "originalCommit": {"oid": "64692a3605478258174ec0e1b88754843170a01e"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDkwODU2Ng==", "bodyText": "get it.", "url": "https://github.com/apache/flink/pull/11223#discussion_r384908566", "createdAt": "2020-02-27T04:32:27Z", "author": {"login": "libenchao"}, "path": "flink-connectors/flink-jdbc/src/test/java/org/apache/flink/api/java/io/jdbc/JDBCUpsertTableSinkITCase.java", "diffHunk": "@@ -211,4 +213,31 @@ public void testAppend() throws Exception {\n \t\t\t\tRow.of(20, 6, Timestamp.valueOf(\"1970-01-01 00:00:00.02\"))\n \t\t}, DB_URL, OUTPUT_TABLE2, new String[]{\"id\", \"num\", \"ts\"});\n \t}\n+\n+\t@Test(expected = JobExecutionException.class)\n+\tpublic void testTableNotExists() throws Exception {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDUyNzUwMA=="}, "originalCommit": {"oid": "64692a3605478258174ec0e1b88754843170a01e"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM4NDYwNzI4OnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-jdbc/src/main/java/org/apache/flink/api/java/io/jdbc/writer/AppendOnlyWriter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QxMDo0MTowM1rOFvNUCA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QxMDo0MTowM1rOFvNUCA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTA0NTUxMg==", "bodyText": "See UpsertWriter.addRecord.\nTuple2<Boolean, Row> tuple2 = objectReuse ? new Tuple2<>(record.f0, Row.copy(record.f1)) : record;", "url": "https://github.com/apache/flink/pull/11223#discussion_r385045512", "createdAt": "2020-02-27T10:41:03Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-jdbc/src/main/java/org/apache/flink/api/java/io/jdbc/writer/AppendOnlyWriter.java", "diffHunk": "@@ -47,19 +50,28 @@ public AppendOnlyWriter(String insertSQL, int[] fieldTypes) {\n \n \t@Override\n \tpublic void open(Connection connection) throws SQLException {\n+\t\tthis.cachedRows = new ArrayList<>();\n \t\tthis.statement = connection.prepareStatement(insertSQL);\n \t}\n \n \t@Override\n-\tpublic void addRecord(Tuple2<Boolean, Row> record) throws SQLException {\n+\tpublic void addRecord(Tuple2<Boolean, Row> record) {\n \t\tcheckArgument(record.f0, \"Append mode can not receive retract/delete message.\");\n-\t\tsetRecordToStatement(statement, fieldTypes, record.f1);\n-\t\tstatement.addBatch();\n+\t\t//deep copy, add record to buffer\n+\t\tRow row = Row.copy(record.f1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46b60757e8d5c7b38f6c2fa04cf1b01dd4712a25"}, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM4NDYwOTQyOnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-jdbc/src/main/java/org/apache/flink/api/java/io/jdbc/writer/AppendOnlyWriter.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QxMDo0MTo0M1rOFvNVaA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QxNDoyMzoxMlrOFvUIQg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTA0NTg2NA==", "bodyText": "Both two writers need cache records. This copy could be extract to JDBCUpsertOutputFormat.", "url": "https://github.com/apache/flink/pull/11223#discussion_r385045864", "createdAt": "2020-02-27T10:41:43Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-jdbc/src/main/java/org/apache/flink/api/java/io/jdbc/writer/AppendOnlyWriter.java", "diffHunk": "@@ -47,19 +50,28 @@ public AppendOnlyWriter(String insertSQL, int[] fieldTypes) {\n \n \t@Override\n \tpublic void open(Connection connection) throws SQLException {\n+\t\tthis.cachedRows = new ArrayList<>();\n \t\tthis.statement = connection.prepareStatement(insertSQL);\n \t}\n \n \t@Override\n-\tpublic void addRecord(Tuple2<Boolean, Row> record) throws SQLException {\n+\tpublic void addRecord(Tuple2<Boolean, Row> record) {\n \t\tcheckArgument(record.f0, \"Append mode can not receive retract/delete message.\");\n-\t\tsetRecordToStatement(statement, fieldTypes, record.f1);\n-\t\tstatement.addBatch();\n+\t\t//deep copy, add record to buffer\n+\t\tRow row = Row.copy(record.f1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46b60757e8d5c7b38f6c2fa04cf1b01dd4712a25"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTE1NzE4Ng==", "bodyText": "nice tips", "url": "https://github.com/apache/flink/pull/11223#discussion_r385157186", "createdAt": "2020-02-27T14:23:12Z", "author": {"login": "leonardBang"}, "path": "flink-connectors/flink-jdbc/src/main/java/org/apache/flink/api/java/io/jdbc/writer/AppendOnlyWriter.java", "diffHunk": "@@ -47,19 +50,28 @@ public AppendOnlyWriter(String insertSQL, int[] fieldTypes) {\n \n \t@Override\n \tpublic void open(Connection connection) throws SQLException {\n+\t\tthis.cachedRows = new ArrayList<>();\n \t\tthis.statement = connection.prepareStatement(insertSQL);\n \t}\n \n \t@Override\n-\tpublic void addRecord(Tuple2<Boolean, Row> record) throws SQLException {\n+\tpublic void addRecord(Tuple2<Boolean, Row> record) {\n \t\tcheckArgument(record.f0, \"Append mode can not receive retract/delete message.\");\n-\t\tsetRecordToStatement(statement, fieldTypes, record.f1);\n-\t\tstatement.addBatch();\n+\t\t//deep copy, add record to buffer\n+\t\tRow row = Row.copy(record.f1);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTA0NTg2NA=="}, "originalCommit": {"oid": "46b60757e8d5c7b38f6c2fa04cf1b01dd4712a25"}, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM4NDY0MDg5OnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-jdbc/src/main/java/org/apache/flink/api/java/io/jdbc/writer/AppendOnlyWriter.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QxMDo1MDozNVrOFvNofQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yOFQwNjo1MDozM1rOFvrDIw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTA1MDc0OQ==", "bodyText": "Can you mock a PreparedStatement and add some unit tests?", "url": "https://github.com/apache/flink/pull/11223#discussion_r385050749", "createdAt": "2020-02-27T10:50:35Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-jdbc/src/main/java/org/apache/flink/api/java/io/jdbc/writer/AppendOnlyWriter.java", "diffHunk": "@@ -38,6 +40,7 @@\n \tprivate final String insertSQL;\n \tprivate final int[] fieldTypes;\n \n+\tprivate transient List<Row> cachedRows;\n \tprivate transient PreparedStatement statement;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46b60757e8d5c7b38f6c2fa04cf1b01dd4712a25"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTE1OTMyNQ==", "bodyText": "Could you give more tips? add some unit  tests for  checking/validating what.", "url": "https://github.com/apache/flink/pull/11223#discussion_r385159325", "createdAt": "2020-02-27T14:26:20Z", "author": {"login": "leonardBang"}, "path": "flink-connectors/flink-jdbc/src/main/java/org/apache/flink/api/java/io/jdbc/writer/AppendOnlyWriter.java", "diffHunk": "@@ -38,6 +40,7 @@\n \tprivate final String insertSQL;\n \tprivate final int[] fieldTypes;\n \n+\tprivate transient List<Row> cachedRows;\n \tprivate transient PreparedStatement statement;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTA1MDc0OQ=="}, "originalCommit": {"oid": "46b60757e8d5c7b38f6c2fa04cf1b01dd4712a25"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTUzMjcwNw==", "bodyText": "I mean you can add a unit test for AppendOnlyWriter.", "url": "https://github.com/apache/flink/pull/11223#discussion_r385532707", "createdAt": "2020-02-28T06:50:33Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-jdbc/src/main/java/org/apache/flink/api/java/io/jdbc/writer/AppendOnlyWriter.java", "diffHunk": "@@ -38,6 +40,7 @@\n \tprivate final String insertSQL;\n \tprivate final int[] fieldTypes;\n \n+\tprivate transient List<Row> cachedRows;\n \tprivate transient PreparedStatement statement;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTA1MDc0OQ=="}, "originalCommit": {"oid": "46b60757e8d5c7b38f6c2fa04cf1b01dd4712a25"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM4NDY0MzQwOnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-jdbc/src/test/java/org/apache/flink/api/java/io/jdbc/JDBCUpsertTableSinkITCase.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QxMDo1MToxN1rOFvNp_Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QxNToyMDoyN1rOFvVhvA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTA1MTEzMw==", "bodyText": "What is this test for? I ran it on master, it passed.", "url": "https://github.com/apache/flink/pull/11223#discussion_r385051133", "createdAt": "2020-02-27T10:51:17Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-jdbc/src/test/java/org/apache/flink/api/java/io/jdbc/JDBCUpsertTableSinkITCase.java", "diffHunk": "@@ -211,4 +213,31 @@ public void testAppend() throws Exception {\n \t\t\t\tRow.of(20, 6, Timestamp.valueOf(\"1970-01-01 00:00:00.02\"))\n \t\t}, DB_URL, OUTPUT_TABLE2, new String[]{\"id\", \"num\", \"ts\"});\n \t}\n+\n+\t@Test(expected = JobExecutionException.class)\n+\tpublic void testTableNotExists() throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46b60757e8d5c7b38f6c2fa04cf1b01dd4712a25"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTE4MDA5Mg==", "bodyText": "As this issue describe\uff0cthis test will hang rather than throw an Exception when the parameter connector.write.max-retries > 1\uff0c so I add this case to check that exception will throw properly after retry 3 times.\nI found this test passed in master\uff0cbecause this  'table not exists Exception' was thrown in open() function not in flush().\n@Override public void open(Connection connection) throws SQLException { this.cachedRows = new ArrayList<>(); this.statement = connection.prepareStatement(insertSQL); } \nwhen I used 'com.mysql.jdbc.Driver' it will be thrown in in flush() rather than open() function, the difference should be that we use 'org.apache.derby.jdbc.EmbeddedDriver' in ITcase.\nSo\uff0c I will drop this function and try other tests to cover this issue update.", "url": "https://github.com/apache/flink/pull/11223#discussion_r385180092", "createdAt": "2020-02-27T15:20:27Z", "author": {"login": "leonardBang"}, "path": "flink-connectors/flink-jdbc/src/test/java/org/apache/flink/api/java/io/jdbc/JDBCUpsertTableSinkITCase.java", "diffHunk": "@@ -211,4 +213,31 @@ public void testAppend() throws Exception {\n \t\t\t\tRow.of(20, 6, Timestamp.valueOf(\"1970-01-01 00:00:00.02\"))\n \t\t}, DB_URL, OUTPUT_TABLE2, new String[]{\"id\", \"num\", \"ts\"});\n \t}\n+\n+\t@Test(expected = JobExecutionException.class)\n+\tpublic void testTableNotExists() throws Exception {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTA1MTEzMw=="}, "originalCommit": {"oid": "46b60757e8d5c7b38f6c2fa04cf1b01dd4712a25"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM5MzA1NzE2OnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-jdbc/src/test/java/org/apache/flink/api/java/io/jdbc/JDBCAppenOnlyWriterTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wMlQxMDo0MjowMlrOFwa69Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wMlQxMDo0MjowMlrOFwa69Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjMxNzA0NQ==", "bodyText": "Don't need member. Just pass null.", "url": "https://github.com/apache/flink/pull/11223#discussion_r386317045", "createdAt": "2020-03-02T10:42:02Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-jdbc/src/test/java/org/apache/flink/api/java/io/jdbc/JDBCAppenOnlyWriterTest.java", "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.api.java.io.jdbc;\n+\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.functions.RuntimeContext;\n+import org.apache.flink.api.java.io.jdbc.writer.AppendOnlyWriter;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import java.sql.BatchUpdateException;\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.Statement;\n+\n+import static org.apache.flink.api.java.io.jdbc.JDBCOutputFormatTest.toRow;\n+import static org.mockito.Mockito.doReturn;\n+\n+/**\n+ * Test for the {@link AppendOnlyWriter}.\n+ */\n+public class JDBCAppenOnlyWriterTest extends JDBCTestBase {\n+\tprivate JDBCUpsertOutputFormat format;\n+\tprivate String[] fieldNames;\n+\tprivate String[] keyFields;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "be5bed759e39f445d24dad3f2a0109ddddd7ce43"}, "originalPosition": 45}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM5MzA1Nzc5OnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-jdbc/src/test/java/org/apache/flink/api/java/io/jdbc/JDBCAppenOnlyWriterTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wMlQxMDo0MjoxMlrOFwa7WQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wMlQxMDo0MjoxMlrOFwa7WQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjMxNzE0NQ==", "bodyText": "close this format?", "url": "https://github.com/apache/flink/pull/11223#discussion_r386317145", "createdAt": "2020-03-02T10:42:12Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-jdbc/src/test/java/org/apache/flink/api/java/io/jdbc/JDBCAppenOnlyWriterTest.java", "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.api.java.io.jdbc;\n+\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.functions.RuntimeContext;\n+import org.apache.flink.api.java.io.jdbc.writer.AppendOnlyWriter;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import java.sql.BatchUpdateException;\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.Statement;\n+\n+import static org.apache.flink.api.java.io.jdbc.JDBCOutputFormatTest.toRow;\n+import static org.mockito.Mockito.doReturn;\n+\n+/**\n+ * Test for the {@link AppendOnlyWriter}.\n+ */\n+public class JDBCAppenOnlyWriterTest extends JDBCTestBase {\n+\tprivate JDBCUpsertOutputFormat format;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "be5bed759e39f445d24dad3f2a0109ddddd7ce43"}, "originalPosition": 43}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM5MzA1ODY5OnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-jdbc/src/test/java/org/apache/flink/api/java/io/jdbc/JDBCAppenOnlyWriterTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wMlQxMDo0MjoyN1rOFwa72Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wMlQxMDo0MjoyN1rOFwa72Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjMxNzI3Mw==", "bodyText": "Add a empty line above.", "url": "https://github.com/apache/flink/pull/11223#discussion_r386317273", "createdAt": "2020-03-02T10:42:27Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-jdbc/src/test/java/org/apache/flink/api/java/io/jdbc/JDBCAppenOnlyWriterTest.java", "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.api.java.io.jdbc;\n+\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.functions.RuntimeContext;\n+import org.apache.flink.api.java.io.jdbc.writer.AppendOnlyWriter;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import java.sql.BatchUpdateException;\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.Statement;\n+\n+import static org.apache.flink.api.java.io.jdbc.JDBCOutputFormatTest.toRow;\n+import static org.mockito.Mockito.doReturn;\n+\n+/**\n+ * Test for the {@link AppendOnlyWriter}.\n+ */\n+public class JDBCAppenOnlyWriterTest extends JDBCTestBase {\n+\tprivate JDBCUpsertOutputFormat format;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "be5bed759e39f445d24dad3f2a0109ddddd7ce43"}, "originalPosition": 43}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM5MzA2Mjk1OnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-jdbc/src/test/java/org/apache/flink/api/java/io/jdbc/JDBCAppenOnlyWriterTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wMlQxMDo0Mzo0M1rOFwa-Xw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wMlQxMjoyOTo1N1rOFwdz3w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjMxNzkxOQ==", "bodyText": "Remove close, already have try.", "url": "https://github.com/apache/flink/pull/11223#discussion_r386317919", "createdAt": "2020-03-02T10:43:43Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-jdbc/src/test/java/org/apache/flink/api/java/io/jdbc/JDBCAppenOnlyWriterTest.java", "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.api.java.io.jdbc;\n+\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.functions.RuntimeContext;\n+import org.apache.flink.api.java.io.jdbc.writer.AppendOnlyWriter;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import java.sql.BatchUpdateException;\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.Statement;\n+\n+import static org.apache.flink.api.java.io.jdbc.JDBCOutputFormatTest.toRow;\n+import static org.mockito.Mockito.doReturn;\n+\n+/**\n+ * Test for the {@link AppendOnlyWriter}.\n+ */\n+public class JDBCAppenOnlyWriterTest extends JDBCTestBase {\n+\tprivate JDBCUpsertOutputFormat format;\n+\tprivate String[] fieldNames;\n+\tprivate String[] keyFields;\n+\n+\t@Before\n+\tpublic void setup() {\n+\t\tfieldNames = new String[]{\"id\", \"title\", \"author\", \"price\", \"qty\"};\n+\t\tkeyFields = null;\n+\t}\n+\n+\t@Test(expected = BatchUpdateException.class)\n+\tpublic void testMaxRetry() throws Exception {\n+\t\tformat = JDBCUpsertOutputFormat.builder()\n+\t\t\t.setOptions(JDBCOptions.builder()\n+\t\t\t\t.setDBUrl(DB_URL)\n+\t\t\t\t.setTableName(OUTPUT_TABLE)\n+\t\t\t\t.build())\n+\t\t\t.setFieldNames(fieldNames)\n+\t\t\t.setKeyFields(keyFields)\n+\t\t\t.build();\n+\t\tRuntimeContext context = Mockito.mock(RuntimeContext.class);\n+\t\tExecutionConfig config = Mockito.mock(ExecutionConfig.class);\n+\t\tdoReturn(config).when(context).getExecutionConfig();\n+\t\tdoReturn(true).when(config).isObjectReuseEnabled();\n+\t\tformat.setRuntimeContext(context);\n+\t\tformat.open(0, 1);\n+\n+\t\t// alter table schema to trigger retry logic after failure.\n+\t\talterTable();\n+\t\tfor (TestEntry entry : TEST_DATA) {\n+\t\t\tformat.writeRecord(Tuple2.of(true, toRow(entry)));\n+\t\t}\n+\n+\t\t// after retry default times, throws a BatchUpdateException.\n+\t\tformat.flush();\n+\t}\n+\n+\tprivate void alterTable() throws Exception {\n+\t\tClass.forName(DRIVER_CLASS);\n+\t\ttry (Connection conn = DriverManager.getConnection(DB_URL);\n+\t\t\tStatement stat = conn.createStatement()) {\n+\t\t\tstat.execute(\"ALTER  TABLE \" + OUTPUT_TABLE + \" DROP COLUMN \" + fieldNames[1]);\n+\t\t\tstat.close();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "be5bed759e39f445d24dad3f2a0109ddddd7ce43"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjM2NDM4Mw==", "bodyText": "I see many this kind of style that call resource close() function in try(){} body in our code,  I just want to align, should I keep this?", "url": "https://github.com/apache/flink/pull/11223#discussion_r386364383", "createdAt": "2020-03-02T12:29:57Z", "author": {"login": "leonardBang"}, "path": "flink-connectors/flink-jdbc/src/test/java/org/apache/flink/api/java/io/jdbc/JDBCAppenOnlyWriterTest.java", "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.api.java.io.jdbc;\n+\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.functions.RuntimeContext;\n+import org.apache.flink.api.java.io.jdbc.writer.AppendOnlyWriter;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import java.sql.BatchUpdateException;\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.Statement;\n+\n+import static org.apache.flink.api.java.io.jdbc.JDBCOutputFormatTest.toRow;\n+import static org.mockito.Mockito.doReturn;\n+\n+/**\n+ * Test for the {@link AppendOnlyWriter}.\n+ */\n+public class JDBCAppenOnlyWriterTest extends JDBCTestBase {\n+\tprivate JDBCUpsertOutputFormat format;\n+\tprivate String[] fieldNames;\n+\tprivate String[] keyFields;\n+\n+\t@Before\n+\tpublic void setup() {\n+\t\tfieldNames = new String[]{\"id\", \"title\", \"author\", \"price\", \"qty\"};\n+\t\tkeyFields = null;\n+\t}\n+\n+\t@Test(expected = BatchUpdateException.class)\n+\tpublic void testMaxRetry() throws Exception {\n+\t\tformat = JDBCUpsertOutputFormat.builder()\n+\t\t\t.setOptions(JDBCOptions.builder()\n+\t\t\t\t.setDBUrl(DB_URL)\n+\t\t\t\t.setTableName(OUTPUT_TABLE)\n+\t\t\t\t.build())\n+\t\t\t.setFieldNames(fieldNames)\n+\t\t\t.setKeyFields(keyFields)\n+\t\t\t.build();\n+\t\tRuntimeContext context = Mockito.mock(RuntimeContext.class);\n+\t\tExecutionConfig config = Mockito.mock(ExecutionConfig.class);\n+\t\tdoReturn(config).when(context).getExecutionConfig();\n+\t\tdoReturn(true).when(config).isObjectReuseEnabled();\n+\t\tformat.setRuntimeContext(context);\n+\t\tformat.open(0, 1);\n+\n+\t\t// alter table schema to trigger retry logic after failure.\n+\t\talterTable();\n+\t\tfor (TestEntry entry : TEST_DATA) {\n+\t\t\tformat.writeRecord(Tuple2.of(true, toRow(entry)));\n+\t\t}\n+\n+\t\t// after retry default times, throws a BatchUpdateException.\n+\t\tformat.flush();\n+\t}\n+\n+\tprivate void alterTable() throws Exception {\n+\t\tClass.forName(DRIVER_CLASS);\n+\t\ttry (Connection conn = DriverManager.getConnection(DB_URL);\n+\t\t\tStatement stat = conn.createStatement()) {\n+\t\t\tstat.execute(\"ALTER  TABLE \" + OUTPUT_TABLE + \" DROP COLUMN \" + fieldNames[1]);\n+\t\t\tstat.close();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjMxNzkxOQ=="}, "originalCommit": {"oid": "be5bed759e39f445d24dad3f2a0109ddddd7ce43"}, "originalPosition": 85}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM5MzA2MzExOnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-jdbc/src/test/java/org/apache/flink/api/java/io/jdbc/JDBCAppenOnlyWriterTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wMlQxMDo0Mzo0NlrOFwa-ew==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wMlQxMDo0Mzo0NlrOFwa-ew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjMxNzk0Nw==", "bodyText": "Remove close, already have try.", "url": "https://github.com/apache/flink/pull/11223#discussion_r386317947", "createdAt": "2020-03-02T10:43:46Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-jdbc/src/test/java/org/apache/flink/api/java/io/jdbc/JDBCAppenOnlyWriterTest.java", "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.api.java.io.jdbc;\n+\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.functions.RuntimeContext;\n+import org.apache.flink.api.java.io.jdbc.writer.AppendOnlyWriter;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import java.sql.BatchUpdateException;\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.Statement;\n+\n+import static org.apache.flink.api.java.io.jdbc.JDBCOutputFormatTest.toRow;\n+import static org.mockito.Mockito.doReturn;\n+\n+/**\n+ * Test for the {@link AppendOnlyWriter}.\n+ */\n+public class JDBCAppenOnlyWriterTest extends JDBCTestBase {\n+\tprivate JDBCUpsertOutputFormat format;\n+\tprivate String[] fieldNames;\n+\tprivate String[] keyFields;\n+\n+\t@Before\n+\tpublic void setup() {\n+\t\tfieldNames = new String[]{\"id\", \"title\", \"author\", \"price\", \"qty\"};\n+\t\tkeyFields = null;\n+\t}\n+\n+\t@Test(expected = BatchUpdateException.class)\n+\tpublic void testMaxRetry() throws Exception {\n+\t\tformat = JDBCUpsertOutputFormat.builder()\n+\t\t\t.setOptions(JDBCOptions.builder()\n+\t\t\t\t.setDBUrl(DB_URL)\n+\t\t\t\t.setTableName(OUTPUT_TABLE)\n+\t\t\t\t.build())\n+\t\t\t.setFieldNames(fieldNames)\n+\t\t\t.setKeyFields(keyFields)\n+\t\t\t.build();\n+\t\tRuntimeContext context = Mockito.mock(RuntimeContext.class);\n+\t\tExecutionConfig config = Mockito.mock(ExecutionConfig.class);\n+\t\tdoReturn(config).when(context).getExecutionConfig();\n+\t\tdoReturn(true).when(config).isObjectReuseEnabled();\n+\t\tformat.setRuntimeContext(context);\n+\t\tformat.open(0, 1);\n+\n+\t\t// alter table schema to trigger retry logic after failure.\n+\t\talterTable();\n+\t\tfor (TestEntry entry : TEST_DATA) {\n+\t\t\tformat.writeRecord(Tuple2.of(true, toRow(entry)));\n+\t\t}\n+\n+\t\t// after retry default times, throws a BatchUpdateException.\n+\t\tformat.flush();\n+\t}\n+\n+\tprivate void alterTable() throws Exception {\n+\t\tClass.forName(DRIVER_CLASS);\n+\t\ttry (Connection conn = DriverManager.getConnection(DB_URL);\n+\t\t\tStatement stat = conn.createStatement()) {\n+\t\t\tstat.execute(\"ALTER  TABLE \" + OUTPUT_TABLE + \" DROP COLUMN \" + fieldNames[1]);\n+\t\t\tstat.close();\n+\t\t\tconn.close();\n+\t\t}\n+\t}\n+\n+\t@After\n+\tpublic void clear() throws Exception {\n+\t\tClass.forName(DRIVER_CLASS);\n+\t\ttry (\n+\t\t\tConnection conn = DriverManager.getConnection(DB_URL);\n+\t\t\tStatement stat = conn.createStatement()) {\n+\t\t\tstat.execute(\"DELETE FROM \" + OUTPUT_TABLE);\n+\n+\t\t\tstat.close();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "be5bed759e39f445d24dad3f2a0109ddddd7ce43"}, "originalPosition": 98}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM5MzA2MzkyOnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-jdbc/src/test/java/org/apache/flink/api/java/io/jdbc/JDBCUpsertTableSinkITCase.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wMlQxMDo0NDowNVrOFwa_Aw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wMlQxMDo0NDowNVrOFwa_Aw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjMxODA4Mw==", "bodyText": "Please remove this", "url": "https://github.com/apache/flink/pull/11223#discussion_r386318083", "createdAt": "2020-03-02T10:44:05Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-jdbc/src/test/java/org/apache/flink/api/java/io/jdbc/JDBCUpsertTableSinkITCase.java", "diffHunk": "@@ -52,6 +52,7 @@\n \tpublic static final String DB_URL = \"jdbc:derby:memory:upsert\";\n \tpublic static final String OUTPUT_TABLE1 = \"upsertSink\";\n \tpublic static final String OUTPUT_TABLE2 = \"appendSink\";\n+\tpublic static final String NOT_EXISTS_TABLE = \"notExistedTable\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "be5bed759e39f445d24dad3f2a0109ddddd7ce43"}, "originalPosition": 4}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 915, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}