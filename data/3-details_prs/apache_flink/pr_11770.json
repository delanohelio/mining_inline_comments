{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDA0MjEyMTYw", "number": 11770, "title": "[FLINK-17014][runtime] Implement PipelinedRegionSchedulingStrategy", "bodyText": "What is the purpose of the change\nImplement PipelinedRegionSchedulingStrategy which schedules tasks in granularity of pipelined regions. More details see https://cwiki.apache.org/confluence/display/FLINK/FLIP-119+Pipelined+Region+Scheduling.\nBrief change log\n\nImplemented PipelinedRegionSchedulingStrategy\n\nVerifying this change\n\nAdded unit tests PipelinedRegionSchedulingStrategyTest\n\nDoes this pull request potentially affect one of the following parts:\n\nDependencies (does it add or upgrade a dependency): (yes / no)\nThe public API, i.e., is any changed class annotated with @Public(Evolving): (yes / no)\nThe serializers: (yes / no / don't know)\nThe runtime per-record code paths (performance sensitive): (yes / no / don't know)\nAnything that affects deployment or recovery: JobManager (and its components), Checkpointing, Kubernetes/Yarn/Mesos, ZooKeeper: (yes / no / don't know)\nThe S3 file system connector: (yes / no / don't know)\n\nDocumentation\n\nDoes this pull request introduce a new feature? (yes / no)\nIf yes, how is the feature documented? (not applicable / docs / JavaDocs / not documented)", "createdAt": "2020-04-16T08:53:46Z", "url": "https://github.com/apache/flink/pull/11770", "merged": true, "mergeCommit": {"oid": "99cbaa929ff9f2f5c387cbf4f76a0166f83a3a8c"}, "closed": true, "closedAt": "2020-04-21T05:49:13Z", "author": {"login": "zhuzhurk"}, "timelineItems": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcYQ3ErAFqTM5NDg3NTE0OQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcZbG36ABqjMyNTA3Mzc1NDI=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk0ODc1MTQ5", "url": "https://github.com/apache/flink/pull/11770#pullrequestreview-394875149", "createdAt": "2020-04-16T18:01:59Z", "commit": {"oid": "2577ed1f1fe568552fcec2a89366ae8dc59911c9"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQxODowMTo1OVrOGGxDtg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQxODoxODoyMlrOGGxpGQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTc0ODQwNg==", "bodyText": "I would say that such comments are redundant. checkState already implies that it is a sanity check.", "url": "https://github.com/apache/flink/pull/11770#discussion_r409748406", "createdAt": "2020-04-16T18:01:59Z", "author": {"login": "GJL"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/strategy/PipelinedRegionSchedulingStrategy.java", "diffHunk": "@@ -0,0 +1,166 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.scheduler.strategy;\n+\n+import org.apache.flink.runtime.execution.ExecutionState;\n+import org.apache.flink.runtime.io.network.partition.ResultPartitionType;\n+import org.apache.flink.runtime.jobgraph.IntermediateDataSetID;\n+import org.apache.flink.runtime.jobgraph.IntermediateResultPartitionID;\n+import org.apache.flink.runtime.scheduler.DeploymentOption;\n+import org.apache.flink.runtime.scheduler.ExecutionVertexDeploymentOption;\n+import org.apache.flink.runtime.scheduler.SchedulerOperations;\n+import org.apache.flink.util.IterableUtils;\n+\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * {@link SchedulingStrategy} instance which schedules tasks in granularity of pipelined regions.\n+ */\n+public class PipelinedRegionSchedulingStrategy implements SchedulingStrategy {\n+\n+\tprivate final SchedulerOperations schedulerOperations;\n+\n+\tprivate final SchedulingTopology<?, ?> schedulingTopology;\n+\n+\tprivate final DeploymentOption deploymentOption = new DeploymentOption(false);\n+\n+\t/** Result partitions are correlated if they have the same result id. */\n+\tprivate final Map<IntermediateDataSetID, Set<SchedulingResultPartition<?, ?>>> correlatedResultPartitions = new HashMap<>();\n+\n+\tprivate final Map<IntermediateResultPartitionID, Set<SchedulingPipelinedRegion<?, ?>>> partitionConsumerRegions = new HashMap<>();\n+\n+\tpublic PipelinedRegionSchedulingStrategy(\n+\t\t\tfinal SchedulerOperations schedulerOperations,\n+\t\t\tfinal SchedulingTopology<?, ?> schedulingTopology) {\n+\n+\t\tthis.schedulerOperations = checkNotNull(schedulerOperations);\n+\t\tthis.schedulingTopology = checkNotNull(schedulingTopology);\n+\n+\t\tinit();\n+\t}\n+\n+\tprivate void init() {\n+\t\tfor (SchedulingPipelinedRegion<?, ?> region : schedulingTopology.getAllPipelinedRegions()) {\n+\t\t\tfor (SchedulingResultPartition<?, ?> partition : region.getConsumedResults()) {\n+\t\t\t\t// sanity check", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2577ed1f1fe568552fcec2a89366ae8dc59911c9"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTc1NTEyMw==", "bodyText": "Is the first line needed? Set#add() returns false if the item was not added.\nAlso, consider using .distinct() since side effects in stream operations are frowned upon:\n\npredicate \u2013 a non-interfering, stateless predicate to apply to each element to determine if it should be included", "url": "https://github.com/apache/flink/pull/11770#discussion_r409755123", "createdAt": "2020-04-16T18:13:34Z", "author": {"login": "GJL"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/strategy/SchedulingStrategyUtils.java", "diffHunk": "@@ -60,4 +61,18 @@\n \t\t\t\tdeploymentOptionRetriever.apply(executionVertexID)))\n \t\t\t.collect(Collectors.toList());\n \t}\n+\n+\tstatic List<SchedulingPipelinedRegion<?, ?>> sortPipelinedRegionsInTopologicalOrder(\n+\t\t\tfinal SchedulingTopology<?, ?> topology,\n+\t\t\tfinal Set<SchedulingPipelinedRegion<?, ?>> regions) {\n+\n+\t\tfinal Set<SchedulingPipelinedRegion<?, ?>> deduplicator = new HashSet<>();\n+\t\treturn IterableUtils.toStream(topology.getVertices())\n+\t\t\t.map(SchedulingExecutionVertex::getId)\n+\t\t\t.map(topology::getPipelinedRegionOfVertex)\n+\t\t\t.filter(regions::contains)\n+\t\t\t.filter(region -> !deduplicator.contains(region))\n+\t\t\t.filter(deduplicator::add)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2577ed1f1fe568552fcec2a89366ae8dc59911c9"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTc1NjMyMw==", "bodyText": "Maybe checkState for consistency, and drop the // sanity check comment.", "url": "https://github.com/apache/flink/pull/11770#discussion_r409756323", "createdAt": "2020-04-16T18:15:34Z", "author": {"login": "GJL"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/strategy/PipelinedRegionSchedulingStrategy.java", "diffHunk": "@@ -0,0 +1,166 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.scheduler.strategy;\n+\n+import org.apache.flink.runtime.execution.ExecutionState;\n+import org.apache.flink.runtime.io.network.partition.ResultPartitionType;\n+import org.apache.flink.runtime.jobgraph.IntermediateDataSetID;\n+import org.apache.flink.runtime.jobgraph.IntermediateResultPartitionID;\n+import org.apache.flink.runtime.scheduler.DeploymentOption;\n+import org.apache.flink.runtime.scheduler.ExecutionVertexDeploymentOption;\n+import org.apache.flink.runtime.scheduler.SchedulerOperations;\n+import org.apache.flink.util.IterableUtils;\n+\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * {@link SchedulingStrategy} instance which schedules tasks in granularity of pipelined regions.\n+ */\n+public class PipelinedRegionSchedulingStrategy implements SchedulingStrategy {\n+\n+\tprivate final SchedulerOperations schedulerOperations;\n+\n+\tprivate final SchedulingTopology<?, ?> schedulingTopology;\n+\n+\tprivate final DeploymentOption deploymentOption = new DeploymentOption(false);\n+\n+\t/** Result partitions are correlated if they have the same result id. */\n+\tprivate final Map<IntermediateDataSetID, Set<SchedulingResultPartition<?, ?>>> correlatedResultPartitions = new HashMap<>();\n+\n+\tprivate final Map<IntermediateResultPartitionID, Set<SchedulingPipelinedRegion<?, ?>>> partitionConsumerRegions = new HashMap<>();\n+\n+\tpublic PipelinedRegionSchedulingStrategy(\n+\t\t\tfinal SchedulerOperations schedulerOperations,\n+\t\t\tfinal SchedulingTopology<?, ?> schedulingTopology) {\n+\n+\t\tthis.schedulerOperations = checkNotNull(schedulerOperations);\n+\t\tthis.schedulingTopology = checkNotNull(schedulingTopology);\n+\n+\t\tinit();\n+\t}\n+\n+\tprivate void init() {\n+\t\tfor (SchedulingPipelinedRegion<?, ?> region : schedulingTopology.getAllPipelinedRegions()) {\n+\t\t\tfor (SchedulingResultPartition<?, ?> partition : region.getConsumedResults()) {\n+\t\t\t\t// sanity check\n+\t\t\t\tcheckState(partition.getResultType() == ResultPartitionType.BLOCKING);\n+\n+\t\t\t\tpartitionConsumerRegions.computeIfAbsent(partition.getId(), pid -> new HashSet<>()).add(region);\n+\t\t\t\tcorrelatedResultPartitions.computeIfAbsent(partition.getResultId(), rid -> new HashSet<>()).add(partition);\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void startScheduling() {\n+\t\tfinal Set<SchedulingPipelinedRegion<?, ?>> sourceRegions = IterableUtils\n+\t\t\t.toStream(schedulingTopology.getAllPipelinedRegions())\n+\t\t\t.filter(region -> !region.getConsumedResults().iterator().hasNext())\n+\t\t\t.collect(Collectors.toSet());\n+\t\tmaybeScheduleRegions(sourceRegions);\n+\t}\n+\n+\t@Override\n+\tpublic void restartTasks(final Set<ExecutionVertexID> verticesToRestart) {\n+\t\tfinal Set<SchedulingPipelinedRegion<?, ?>> regionsToRestart = verticesToRestart.stream()\n+\t\t\t.map(schedulingTopology::getPipelinedRegionOfVertex)\n+\t\t\t.collect(Collectors.toSet());\n+\t\tmaybeScheduleRegions(regionsToRestart);\n+\t}\n+\n+\t@Override\n+\tpublic void onExecutionStateChange(final ExecutionVertexID executionVertexId, final ExecutionState executionState) {\n+\t\tif (executionState == ExecutionState.FINISHED) {\n+\t\t\tfinal Set<SchedulingResultPartition<?, ?>> finishedPartitions = IterableUtils\n+\t\t\t\t.toStream(schedulingTopology.getVertex(executionVertexId).getProducedResults())\n+\t\t\t\t.filter(partition -> partitionConsumerRegions.containsKey(partition.getId()))\n+\t\t\t\t.filter(partition -> partition.getState() == ResultPartitionState.CONSUMABLE)\n+\t\t\t\t.flatMap(partition -> correlatedResultPartitions.get(partition.getResultId()).stream())\n+\t\t\t\t.collect(Collectors.toSet());\n+\n+\t\t\tfinal Set<SchedulingPipelinedRegion<?, ?>> consumerRegions = finishedPartitions.stream()\n+\t\t\t\t.flatMap(partition -> partitionConsumerRegions.get(partition.getId()).stream())\n+\t\t\t\t.collect(Collectors.toSet());\n+\t\t\tmaybeScheduleRegions(consumerRegions);\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void onPartitionConsumable(final IntermediateResultPartitionID resultPartitionId) {\n+\t}\n+\n+\tprivate void maybeScheduleRegions(final Set<SchedulingPipelinedRegion<?, ?>> regions) {\n+\t\tfinal List<SchedulingPipelinedRegion<?, ?>> regionsSorted =\n+\t\t\tSchedulingStrategyUtils.sortPipelinedRegionsInTopologicalOrder(schedulingTopology, regions);\n+\t\tfor (SchedulingPipelinedRegion<?, ?> region : regionsSorted) {\n+\t\t\tmaybeScheduleRegion(region);\n+\t\t}\n+\t}\n+\n+\tprivate void maybeScheduleRegion(final SchedulingPipelinedRegion<?, ?> region) {\n+\t\tif (!areRegionInputsAllConsumable(region)) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\t// sanity check\n+\t\tif (!areRegionVerticesAllInCreatedState(region)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2577ed1f1fe568552fcec2a89366ae8dc59911c9"}, "originalPosition": 130}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTc1Nzk3Nw==", "bodyText": "consider hasSize(2)", "url": "https://github.com/apache/flink/pull/11770#discussion_r409757977", "createdAt": "2020-04-16T18:18:22Z", "author": {"login": "GJL"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/scheduler/strategy/PipelinedRegionSchedulingStrategyTest.java", "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.scheduler.strategy;\n+\n+import org.apache.flink.runtime.execution.ExecutionState;\n+import org.apache.flink.runtime.io.network.partition.ResultPartitionType;\n+import org.apache.flink.runtime.scheduler.ExecutionVertexDeploymentOption;\n+import org.apache.flink.util.TestLogger;\n+\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.lessThanOrEqualTo;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertThat;\n+\n+/**\n+ * Unit tests for {@link PipelinedRegionSchedulingStrategy}.\n+ */\n+public class PipelinedRegionSchedulingStrategyTest extends TestLogger {\n+\n+\tprivate TestingSchedulerOperations testingSchedulerOperation;\n+\n+\tprivate int parallelism = 2;\n+\n+\tprivate TestingSchedulingTopology testingSchedulingTopology;\n+\n+\tprivate List<TestingSchedulingExecutionVertex> source;\n+\n+\tprivate List<TestingSchedulingExecutionVertex> map;\n+\n+\tprivate List<TestingSchedulingExecutionVertex> sink;\n+\n+\t@Before\n+\tpublic void setUp() {\n+\t\ttestingSchedulerOperation = new TestingSchedulerOperations();\n+\n+\t\tbuildTopology();\n+\t}\n+\n+\tprivate void buildTopology() {\n+\t\ttestingSchedulingTopology = new TestingSchedulingTopology();\n+\n+\t\tsource = testingSchedulingTopology.addExecutionVertices().withParallelism(parallelism).finish();\n+\t\tmap = testingSchedulingTopology.addExecutionVertices().withParallelism(parallelism).finish();\n+\t\tsink =  testingSchedulingTopology.addExecutionVertices().withParallelism(parallelism).finish();\n+\n+\t\ttestingSchedulingTopology.connectPointwise(source, map)\n+\t\t\t.withResultPartitionState(ResultPartitionState.CREATED)\n+\t\t\t.withResultPartitionType(ResultPartitionType.PIPELINED_BOUNDED)\n+\t\t\t.finish();\n+\t\ttestingSchedulingTopology.connectAllToAll(map, sink)\n+\t\t\t.withResultPartitionState(ResultPartitionState.CREATED)\n+\t\t\t.withResultPartitionType(ResultPartitionType.BLOCKING)\n+\t\t\t.finish();\n+\n+\t\ttestingSchedulingTopology.generatePipelinedRegions();\n+\t}\n+\n+\t@Test\n+\tpublic void testStartScheduling() {\n+\t\tstartScheduling(testingSchedulingTopology);\n+\n+\t\tfinal List<List<TestingSchedulingExecutionVertex>> expectedScheduledVertices = new ArrayList<>();\n+\t\texpectedScheduledVertices.add(Arrays.asList(source.get(0), map.get(0)));\n+\t\texpectedScheduledVertices.add(Arrays.asList(source.get(1), map.get(1)));\n+\t\tassertLatestScheduledVerticesAreEqualTo(expectedScheduledVertices);\n+\t}\n+\n+\t@Test\n+\tpublic void testRestartTasks() {\n+\t\tfinal PipelinedRegionSchedulingStrategy schedulingStrategy = startScheduling(testingSchedulingTopology);\n+\n+\t\tfinal Set<ExecutionVertexID> verticesToRestart = Stream.of(source, map, sink)\n+\t\t\t.flatMap(List::stream)\n+\t\t\t.map(TestingSchedulingExecutionVertex::getId)\n+\t\t\t.collect(Collectors.toSet());\n+\n+\t\tschedulingStrategy.restartTasks(verticesToRestart);\n+\n+\t\tfinal List<List<TestingSchedulingExecutionVertex>> expectedScheduledVertices = new ArrayList<>();\n+\t\texpectedScheduledVertices.add(Arrays.asList(source.get(0), map.get(0)));\n+\t\texpectedScheduledVertices.add(Arrays.asList(source.get(1), map.get(1)));\n+\t\tassertLatestScheduledVerticesAreEqualTo(expectedScheduledVertices);\n+\t}\n+\n+\t@Test\n+\tpublic void testNotifyingBlockingResultPartitionProducerFinished() {\n+\t\tfinal PipelinedRegionSchedulingStrategy schedulingStrategy = startScheduling(testingSchedulingTopology);\n+\n+\t\tfinal TestingSchedulingExecutionVertex map1 = map.get(0);\n+\t\tmap1.getProducedResults().iterator().next().setState(ResultPartitionState.CONSUMABLE);\n+\t\tschedulingStrategy.onExecutionStateChange(map1.getId(), ExecutionState.FINISHED);\n+\n+\t\t// sinks' inputs are not all consumable yet so they are not scheduled\n+\t\tassertThat(testingSchedulerOperation.getScheduledVertices().size(), is(2));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2577ed1f1fe568552fcec2a89366ae8dc59911c9"}, "originalPosition": 120}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "2577ed1f1fe568552fcec2a89366ae8dc59911c9", "author": {"user": {"login": "zhuzhurk", "name": "Zhu Zhu"}}, "url": "https://github.com/apache/flink/commit/2577ed1f1fe568552fcec2a89366ae8dc59911c9", "committedDate": "2020-04-16T08:35:54Z", "message": "[FLINK-17014][runtime] Implement PipelinedRegionSchedulingStrategy"}, "afterCommit": {"oid": "395043eb6bbd4b1dc2dffa1a463ddf7a36401132", "author": {"user": {"login": "zhuzhurk", "name": "Zhu Zhu"}}, "url": "https://github.com/apache/flink/commit/395043eb6bbd4b1dc2dffa1a463ddf7a36401132", "committedDate": "2020-04-17T06:11:11Z", "message": "[FLINK-17014][runtime] Implement PipelinedRegionSchedulingStrategy"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "395043eb6bbd4b1dc2dffa1a463ddf7a36401132", "author": {"user": {"login": "zhuzhurk", "name": "Zhu Zhu"}}, "url": "https://github.com/apache/flink/commit/395043eb6bbd4b1dc2dffa1a463ddf7a36401132", "committedDate": "2020-04-17T06:11:11Z", "message": "[FLINK-17014][runtime] Implement PipelinedRegionSchedulingStrategy"}, "afterCommit": {"oid": "d8568c4f9d43b9cd0b9cb47e6f8a9ddd8a57ec1c", "author": {"user": {"login": "zhuzhurk", "name": "Zhu Zhu"}}, "url": "https://github.com/apache/flink/commit/d8568c4f9d43b9cd0b9cb47e6f8a9ddd8a57ec1c", "committedDate": "2020-04-19T00:58:53Z", "message": "[FLINK-17014][runtime] Implement PipelinedRegionSchedulingStrategy"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk2MTk2MzU3", "url": "https://github.com/apache/flink/pull/11770#pullrequestreview-396196357", "createdAt": "2020-04-20T07:18:15Z", "commit": {"oid": "d8568c4f9d43b9cd0b9cb47e6f8a9ddd8a57ec1c"}, "state": "APPROVED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQwNzoxODoxNVrOGIGh_w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQwNzozNzoyNFrOGIHLrA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTE0ODc5OQ==", "bodyText": "Consider making this static final or convert to a local variable.", "url": "https://github.com/apache/flink/pull/11770#discussion_r411148799", "createdAt": "2020-04-20T07:18:15Z", "author": {"login": "GJL"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/scheduler/strategy/PipelinedRegionSchedulingStrategyTest.java", "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.scheduler.strategy;\n+\n+import org.apache.flink.runtime.execution.ExecutionState;\n+import org.apache.flink.runtime.io.network.partition.ResultPartitionType;\n+import org.apache.flink.runtime.scheduler.ExecutionVertexDeploymentOption;\n+import org.apache.flink.util.TestLogger;\n+\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static org.hamcrest.Matchers.hasSize;\n+import static org.hamcrest.Matchers.lessThanOrEqualTo;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertThat;\n+\n+/**\n+ * Unit tests for {@link PipelinedRegionSchedulingStrategy}.\n+ */\n+public class PipelinedRegionSchedulingStrategyTest extends TestLogger {\n+\n+\tprivate TestingSchedulerOperations testingSchedulerOperation;\n+\n+\tprivate int parallelism = 2;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d8568c4f9d43b9cd0b9cb47e6f8a9ddd8a57ec1c"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTE1Nzk5OA==", "bodyText": "Consider wrapping it in Collections.unmodifiableCollection() for immutability or returning a copy. Same in getConsumedResults().", "url": "https://github.com/apache/flink/pull/11770#discussion_r411157998", "createdAt": "2020-04-20T07:34:43Z", "author": {"login": "GJL"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/scheduler/strategy/TestingSchedulingPipelinedRegion.java", "diffHunk": "@@ -0,0 +1,61 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.scheduler.strategy;\n+\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+\n+/**\n+ * A simple implementation of {@link SchedulingPipelinedRegion} for testing.\n+ */\n+public class TestingSchedulingPipelinedRegion implements SchedulingPipelinedRegion {\n+\n+\tprivate final Map<ExecutionVertexID, TestingSchedulingExecutionVertex> regionVertices = new HashMap<>();\n+\n+\tprivate final Set<TestingSchedulingResultPartition> consumedPartitions = new HashSet<>();\n+\n+\tpublic TestingSchedulingPipelinedRegion(final Set<TestingSchedulingExecutionVertex> vertices) {\n+\t\tfor (TestingSchedulingExecutionVertex vertex : vertices) {\n+\t\t\tregionVertices.put(vertex.getId(), vertex);\n+\n+\t\t\tfor (TestingSchedulingResultPartition consumedPartition : vertex.getConsumedResults()) {\n+\t\t\t\tif (!vertices.contains(consumedPartition.getProducer())) {\n+\t\t\t\t\tconsumedPartitions.add(consumedPartition);\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic Iterable<TestingSchedulingExecutionVertex> getVertices() {\n+\t\treturn regionVertices.values();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d8568c4f9d43b9cd0b9cb47e6f8a9ddd8a57ec1c"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTE1ODk3OA==", "bodyText": "I think that's the same as new HashSet<>(vertexRegions.values())", "url": "https://github.com/apache/flink/pull/11770#discussion_r411158978", "createdAt": "2020-04-20T07:36:26Z", "author": {"login": "GJL"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/scheduler/strategy/TestingSchedulingTopology.java", "diffHunk": "@@ -78,6 +83,31 @@ public TestingSchedulingResultPartition getResultPartition(final IntermediateRes\n \t\treturn resultPartition;\n \t}\n \n+\t@Override\n+\tpublic Iterable<SchedulingPipelinedRegion> getAllPipelinedRegions() {\n+\t\treturn vertexRegions.values().stream().collect(Collectors.toSet());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d8568c4f9d43b9cd0b9cb47e6f8a9ddd8a57ec1c"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTE1OTQ2OA==", "bodyText": "Consider invoking this method lazily in getAllPipelinedRegions() and getPipelinedRegionOfVertex() instead of relying the client (test) to invoke it.", "url": "https://github.com/apache/flink/pull/11770#discussion_r411159468", "createdAt": "2020-04-20T07:37:24Z", "author": {"login": "GJL"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/scheduler/strategy/TestingSchedulingTopology.java", "diffHunk": "@@ -78,6 +83,31 @@ public TestingSchedulingResultPartition getResultPartition(final IntermediateRes\n \t\treturn resultPartition;\n \t}\n \n+\t@Override\n+\tpublic Iterable<SchedulingPipelinedRegion> getAllPipelinedRegions() {\n+\t\treturn vertexRegions.values().stream().collect(Collectors.toSet());\n+\t}\n+\n+\t@Override\n+\tpublic SchedulingPipelinedRegion getPipelinedRegionOfVertex(ExecutionVertexID vertexId) {\n+\t\treturn vertexRegions.get(vertexId);\n+\t}\n+\n+\tvoid generatePipelinedRegions() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d8568c4f9d43b9cd0b9cb47e6f8a9ddd8a57ec1c"}, "originalPosition": 40}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d8568c4f9d43b9cd0b9cb47e6f8a9ddd8a57ec1c", "author": {"user": {"login": "zhuzhurk", "name": "Zhu Zhu"}}, "url": "https://github.com/apache/flink/commit/d8568c4f9d43b9cd0b9cb47e6f8a9ddd8a57ec1c", "committedDate": "2020-04-19T00:58:53Z", "message": "[FLINK-17014][runtime] Implement PipelinedRegionSchedulingStrategy"}, "afterCommit": {"oid": "17d9f5ed08b877c3157045271e5f6c8a884c5e87", "author": {"user": {"login": "zhuzhurk", "name": "Zhu Zhu"}}, "url": "https://github.com/apache/flink/commit/17d9f5ed08b877c3157045271e5f6c8a884c5e87", "committedDate": "2020-04-20T08:26:23Z", "message": "[FLINK-17014][runtime] Implement PipelinedRegionSchedulingStrategy"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ebbb1587ecd9d0d101a57f1b345c3ee8bc60375c", "author": {"user": {"login": "zhuzhurk", "name": "Zhu Zhu"}}, "url": "https://github.com/apache/flink/commit/ebbb1587ecd9d0d101a57f1b345c3ee8bc60375c", "committedDate": "2020-04-20T08:47:33Z", "message": "[FLINK-17014][runtime] TestingSchedulingTopology implements pipelined region getter interfaces"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a47976d0761aeffaf9a656a48b5bdae39f0bd64f", "author": {"user": {"login": "zhuzhurk", "name": "Zhu Zhu"}}, "url": "https://github.com/apache/flink/commit/a47976d0761aeffaf9a656a48b5bdae39f0bd64f", "committedDate": "2020-04-20T08:47:57Z", "message": "[FLINK-17014][runtime] Implement PipelinedRegionSchedulingStrategy"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "17d9f5ed08b877c3157045271e5f6c8a884c5e87", "author": {"user": {"login": "zhuzhurk", "name": "Zhu Zhu"}}, "url": "https://github.com/apache/flink/commit/17d9f5ed08b877c3157045271e5f6c8a884c5e87", "committedDate": "2020-04-20T08:26:23Z", "message": "[FLINK-17014][runtime] Implement PipelinedRegionSchedulingStrategy"}, "afterCommit": {"oid": "a47976d0761aeffaf9a656a48b5bdae39f0bd64f", "author": {"user": {"login": "zhuzhurk", "name": "Zhu Zhu"}}, "url": "https://github.com/apache/flink/commit/a47976d0761aeffaf9a656a48b5bdae39f0bd64f", "committedDate": "2020-04-20T08:47:57Z", "message": "[FLINK-17014][runtime] Implement PipelinedRegionSchedulingStrategy"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1828, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}