{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzgwMjY4NzAz", "number": 11223, "title": "[FLINK-16281][Table SQL / Ecosystem] parameter 'maxRetryTimes' can not work in JDBCUpsertTableSink.", "bodyText": "parameter 'maxRetryTimes' can not work in JDBCUpsertTableSink.\n\nWhat is the purpose of the change\nThis pull request fix 'maxRetryTimes' can not work properly in JDBCUpsertTableSink( only AppendOnlyWriter) .\nBrief change log\n\nCache data in AppendOnlyWriter for multiple call\nUpdate executeBatch() in AppendOnlyWriter\n\nVerifying this change\nTest exception will be thrown normally in JDBCUpsertTableSinkITCase.\nDoes this pull request potentially affect one of the following parts:\n\nDependencies (does it add or upgrade a dependency): (no)\nThe public API, i.e., is any changed class annotated with @Public(Evolving): (no)\nThe serializers: (no)\nThe runtime per-record code paths (performance sensitive): ( no)\nAnything that affects deployment or recovery: JobManager (and its components), Checkpointing, Yarn/Mesos, ZooKeeper: (no)\nThe S3 file system connector: (no)\n\nDocumentation\n\nDoes this pull request introduce a new feature? (no)\nIf yes, how is the feature documented? (not applicable / docs / JavaDocs / not documented)", "createdAt": "2020-02-26T13:40:52Z", "url": "https://github.com/apache/flink/pull/11223", "merged": true, "mergeCommit": {"oid": "3e10f0a5ca1179f8a95185c3d3c03ec9fe0dabb6"}, "closed": true, "closedAt": "2020-03-03T01:25:35Z", "author": {"login": "leonardBang"}, "timelineItems": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcIGvlggH2gAyMzgwMjY4NzAzOjY0NjkyYTM2MDU0NzgyNTgxNzRlYzBlMWI4ODc1NDg0MzE3MGEwMWU=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcJ39SHgFqTM2NzY0NTQ5Mw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "64692a3605478258174ec0e1b88754843170a01e", "author": {"user": {"login": "leonardBang", "name": "Leonard Xu"}}, "url": "https://github.com/apache/flink/commit/64692a3605478258174ec0e1b88754843170a01e", "committedDate": "2020-02-26T13:28:53Z", "message": "[FLINK-16281][Table SQL / Ecosystem] parameter 'maxRetryTimes' can not work in JDBCUpsertTableSink."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY0OTM1NTYy", "url": "https://github.com/apache/flink/pull/11223#pullrequestreview-364935562", "createdAt": "2020-02-26T14:20:45Z", "commit": {"oid": "64692a3605478258174ec0e1b88754843170a01e"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQxNDoyMDo0NlrOFutTsw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQxNDozMDo0OFrOFutsjA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDUyMTEzOQ==", "bodyText": "List<Row> is sufficient here, we don't need to save a Tuple.", "url": "https://github.com/apache/flink/pull/11223#discussion_r384521139", "createdAt": "2020-02-26T14:20:46Z", "author": {"login": "libenchao"}, "path": "flink-connectors/flink-jdbc/src/main/java/org/apache/flink/api/java/io/jdbc/writer/AppendOnlyWriter.java", "diffHunk": "@@ -38,6 +40,7 @@\n \tprivate final String insertSQL;\n \tprivate final int[] fieldTypes;\n \n+\tprivate transient List<Tuple2<Boolean, Row>> rows;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "64692a3605478258174ec0e1b88754843170a01e"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDUyMTcxOQ==", "bodyText": "And for the name, maybe cachedRows or batchedRows be better?", "url": "https://github.com/apache/flink/pull/11223#discussion_r384521719", "createdAt": "2020-02-26T14:21:39Z", "author": {"login": "libenchao"}, "path": "flink-connectors/flink-jdbc/src/main/java/org/apache/flink/api/java/io/jdbc/writer/AppendOnlyWriter.java", "diffHunk": "@@ -38,6 +40,7 @@\n \tprivate final String insertSQL;\n \tprivate final int[] fieldTypes;\n \n+\tprivate transient List<Tuple2<Boolean, Row>> rows;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDUyMTEzOQ=="}, "originalCommit": {"oid": "64692a3605478258174ec0e1b88754843170a01e"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDUyNjgxMg==", "bodyText": "notExistedTable ?", "url": "https://github.com/apache/flink/pull/11223#discussion_r384526812", "createdAt": "2020-02-26T14:29:44Z", "author": {"login": "libenchao"}, "path": "flink-connectors/flink-jdbc/src/test/java/org/apache/flink/api/java/io/jdbc/JDBCUpsertTableSinkITCase.java", "diffHunk": "@@ -52,6 +53,7 @@\n \tpublic static final String DB_URL = \"jdbc:derby:memory:upsert\";\n \tpublic static final String OUTPUT_TABLE1 = \"upsertSink\";\n \tpublic static final String OUTPUT_TABLE2 = \"appendSink\";\n+\tpublic static final String NOT_EXISTS_TABLE = \"notExistsTable\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "64692a3605478258174ec0e1b88754843170a01e"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDUyNzUwMA==", "bodyText": "why do you test \"table not exists\" for fixing \"multiple flushing not work\" issue ?", "url": "https://github.com/apache/flink/pull/11223#discussion_r384527500", "createdAt": "2020-02-26T14:30:48Z", "author": {"login": "libenchao"}, "path": "flink-connectors/flink-jdbc/src/test/java/org/apache/flink/api/java/io/jdbc/JDBCUpsertTableSinkITCase.java", "diffHunk": "@@ -211,4 +213,31 @@ public void testAppend() throws Exception {\n \t\t\t\tRow.of(20, 6, Timestamp.valueOf(\"1970-01-01 00:00:00.02\"))\n \t\t}, DB_URL, OUTPUT_TABLE2, new String[]{\"id\", \"num\", \"ts\"});\n \t}\n+\n+\t@Test(expected = JobExecutionException.class)\n+\tpublic void testTableNotExists() throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "64692a3605478258174ec0e1b88754843170a01e"}, "originalPosition": 22}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2cb96534f083b219b8652650425b2a6f8fbc1baa", "author": {"user": {"login": "leonardBang", "name": "Leonard Xu"}}, "url": "https://github.com/apache/flink/commit/2cb96534f083b219b8652650425b2a6f8fbc1baa", "committedDate": "2020-02-27T03:26:40Z", "message": "using deep copy to buffer data"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "46b60757e8d5c7b38f6c2fa04cf1b01dd4712a25", "author": {"user": {"login": "leonardBang", "name": "Leonard Xu"}}, "url": "https://github.com/apache/flink/commit/46b60757e8d5c7b38f6c2fa04cf1b01dd4712a25", "committedDate": "2020-02-27T03:55:03Z", "message": "address comment"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY1NTc3NDI4", "url": "https://github.com/apache/flink/pull/11223#pullrequestreview-365577428", "createdAt": "2020-02-27T10:41:02Z", "commit": {"oid": "46b60757e8d5c7b38f6c2fa04cf1b01dd4712a25"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QxMDo0MTowM1rOFvNUCA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QxMDo1MToxN1rOFvNp_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTA0NTUxMg==", "bodyText": "See UpsertWriter.addRecord.\nTuple2<Boolean, Row> tuple2 = objectReuse ? new Tuple2<>(record.f0, Row.copy(record.f1)) : record;", "url": "https://github.com/apache/flink/pull/11223#discussion_r385045512", "createdAt": "2020-02-27T10:41:03Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-jdbc/src/main/java/org/apache/flink/api/java/io/jdbc/writer/AppendOnlyWriter.java", "diffHunk": "@@ -47,19 +50,28 @@ public AppendOnlyWriter(String insertSQL, int[] fieldTypes) {\n \n \t@Override\n \tpublic void open(Connection connection) throws SQLException {\n+\t\tthis.cachedRows = new ArrayList<>();\n \t\tthis.statement = connection.prepareStatement(insertSQL);\n \t}\n \n \t@Override\n-\tpublic void addRecord(Tuple2<Boolean, Row> record) throws SQLException {\n+\tpublic void addRecord(Tuple2<Boolean, Row> record) {\n \t\tcheckArgument(record.f0, \"Append mode can not receive retract/delete message.\");\n-\t\tsetRecordToStatement(statement, fieldTypes, record.f1);\n-\t\tstatement.addBatch();\n+\t\t//deep copy, add record to buffer\n+\t\tRow row = Row.copy(record.f1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46b60757e8d5c7b38f6c2fa04cf1b01dd4712a25"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTA0NTg2NA==", "bodyText": "Both two writers need cache records. This copy could be extract to JDBCUpsertOutputFormat.", "url": "https://github.com/apache/flink/pull/11223#discussion_r385045864", "createdAt": "2020-02-27T10:41:43Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-jdbc/src/main/java/org/apache/flink/api/java/io/jdbc/writer/AppendOnlyWriter.java", "diffHunk": "@@ -47,19 +50,28 @@ public AppendOnlyWriter(String insertSQL, int[] fieldTypes) {\n \n \t@Override\n \tpublic void open(Connection connection) throws SQLException {\n+\t\tthis.cachedRows = new ArrayList<>();\n \t\tthis.statement = connection.prepareStatement(insertSQL);\n \t}\n \n \t@Override\n-\tpublic void addRecord(Tuple2<Boolean, Row> record) throws SQLException {\n+\tpublic void addRecord(Tuple2<Boolean, Row> record) {\n \t\tcheckArgument(record.f0, \"Append mode can not receive retract/delete message.\");\n-\t\tsetRecordToStatement(statement, fieldTypes, record.f1);\n-\t\tstatement.addBatch();\n+\t\t//deep copy, add record to buffer\n+\t\tRow row = Row.copy(record.f1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46b60757e8d5c7b38f6c2fa04cf1b01dd4712a25"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTA1MDc0OQ==", "bodyText": "Can you mock a PreparedStatement and add some unit tests?", "url": "https://github.com/apache/flink/pull/11223#discussion_r385050749", "createdAt": "2020-02-27T10:50:35Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-jdbc/src/main/java/org/apache/flink/api/java/io/jdbc/writer/AppendOnlyWriter.java", "diffHunk": "@@ -38,6 +40,7 @@\n \tprivate final String insertSQL;\n \tprivate final int[] fieldTypes;\n \n+\tprivate transient List<Row> cachedRows;\n \tprivate transient PreparedStatement statement;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46b60757e8d5c7b38f6c2fa04cf1b01dd4712a25"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTA1MTEzMw==", "bodyText": "What is this test for? I ran it on master, it passed.", "url": "https://github.com/apache/flink/pull/11223#discussion_r385051133", "createdAt": "2020-02-27T10:51:17Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-jdbc/src/test/java/org/apache/flink/api/java/io/jdbc/JDBCUpsertTableSinkITCase.java", "diffHunk": "@@ -211,4 +213,31 @@ public void testAppend() throws Exception {\n \t\t\t\tRow.of(20, 6, Timestamp.valueOf(\"1970-01-01 00:00:00.02\"))\n \t\t}, DB_URL, OUTPUT_TABLE2, new String[]{\"id\", \"num\", \"ts\"});\n \t}\n+\n+\t@Test(expected = JobExecutionException.class)\n+\tpublic void testTableNotExists() throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46b60757e8d5c7b38f6c2fa04cf1b01dd4712a25"}, "originalPosition": 22}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "70e3c71eaafa144ebc5a2fe8e19c9f205a48a277", "author": {"user": {"login": "leonardBang", "name": "Leonard Xu"}}, "url": "https://github.com/apache/flink/commit/70e3c71eaafa144ebc5a2fe8e19c9f205a48a277", "committedDate": "2020-02-27T14:38:49Z", "message": "address comment"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "be5bed759e39f445d24dad3f2a0109ddddd7ce43", "author": {"user": {"login": "leonardBang", "name": "Leonard Xu"}}, "url": "https://github.com/apache/flink/commit/be5bed759e39f445d24dad3f2a0109ddddd7ce43", "committedDate": "2020-02-28T12:55:09Z", "message": "add unit test"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY3MTAwNzgy", "url": "https://github.com/apache/flink/pull/11223#pullrequestreview-367100782", "createdAt": "2020-03-02T10:42:02Z", "commit": {"oid": "be5bed759e39f445d24dad3f2a0109ddddd7ce43"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wMlQxMDo0MjowMlrOFwa69Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wMlQxMDo0NDowNVrOFwa_Aw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjMxNzA0NQ==", "bodyText": "Don't need member. Just pass null.", "url": "https://github.com/apache/flink/pull/11223#discussion_r386317045", "createdAt": "2020-03-02T10:42:02Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-jdbc/src/test/java/org/apache/flink/api/java/io/jdbc/JDBCAppenOnlyWriterTest.java", "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.api.java.io.jdbc;\n+\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.functions.RuntimeContext;\n+import org.apache.flink.api.java.io.jdbc.writer.AppendOnlyWriter;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import java.sql.BatchUpdateException;\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.Statement;\n+\n+import static org.apache.flink.api.java.io.jdbc.JDBCOutputFormatTest.toRow;\n+import static org.mockito.Mockito.doReturn;\n+\n+/**\n+ * Test for the {@link AppendOnlyWriter}.\n+ */\n+public class JDBCAppenOnlyWriterTest extends JDBCTestBase {\n+\tprivate JDBCUpsertOutputFormat format;\n+\tprivate String[] fieldNames;\n+\tprivate String[] keyFields;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "be5bed759e39f445d24dad3f2a0109ddddd7ce43"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjMxNzE0NQ==", "bodyText": "close this format?", "url": "https://github.com/apache/flink/pull/11223#discussion_r386317145", "createdAt": "2020-03-02T10:42:12Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-jdbc/src/test/java/org/apache/flink/api/java/io/jdbc/JDBCAppenOnlyWriterTest.java", "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.api.java.io.jdbc;\n+\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.functions.RuntimeContext;\n+import org.apache.flink.api.java.io.jdbc.writer.AppendOnlyWriter;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import java.sql.BatchUpdateException;\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.Statement;\n+\n+import static org.apache.flink.api.java.io.jdbc.JDBCOutputFormatTest.toRow;\n+import static org.mockito.Mockito.doReturn;\n+\n+/**\n+ * Test for the {@link AppendOnlyWriter}.\n+ */\n+public class JDBCAppenOnlyWriterTest extends JDBCTestBase {\n+\tprivate JDBCUpsertOutputFormat format;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "be5bed759e39f445d24dad3f2a0109ddddd7ce43"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjMxNzI3Mw==", "bodyText": "Add a empty line above.", "url": "https://github.com/apache/flink/pull/11223#discussion_r386317273", "createdAt": "2020-03-02T10:42:27Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-jdbc/src/test/java/org/apache/flink/api/java/io/jdbc/JDBCAppenOnlyWriterTest.java", "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.api.java.io.jdbc;\n+\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.functions.RuntimeContext;\n+import org.apache.flink.api.java.io.jdbc.writer.AppendOnlyWriter;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import java.sql.BatchUpdateException;\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.Statement;\n+\n+import static org.apache.flink.api.java.io.jdbc.JDBCOutputFormatTest.toRow;\n+import static org.mockito.Mockito.doReturn;\n+\n+/**\n+ * Test for the {@link AppendOnlyWriter}.\n+ */\n+public class JDBCAppenOnlyWriterTest extends JDBCTestBase {\n+\tprivate JDBCUpsertOutputFormat format;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "be5bed759e39f445d24dad3f2a0109ddddd7ce43"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjMxNzkxOQ==", "bodyText": "Remove close, already have try.", "url": "https://github.com/apache/flink/pull/11223#discussion_r386317919", "createdAt": "2020-03-02T10:43:43Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-jdbc/src/test/java/org/apache/flink/api/java/io/jdbc/JDBCAppenOnlyWriterTest.java", "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.api.java.io.jdbc;\n+\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.functions.RuntimeContext;\n+import org.apache.flink.api.java.io.jdbc.writer.AppendOnlyWriter;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import java.sql.BatchUpdateException;\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.Statement;\n+\n+import static org.apache.flink.api.java.io.jdbc.JDBCOutputFormatTest.toRow;\n+import static org.mockito.Mockito.doReturn;\n+\n+/**\n+ * Test for the {@link AppendOnlyWriter}.\n+ */\n+public class JDBCAppenOnlyWriterTest extends JDBCTestBase {\n+\tprivate JDBCUpsertOutputFormat format;\n+\tprivate String[] fieldNames;\n+\tprivate String[] keyFields;\n+\n+\t@Before\n+\tpublic void setup() {\n+\t\tfieldNames = new String[]{\"id\", \"title\", \"author\", \"price\", \"qty\"};\n+\t\tkeyFields = null;\n+\t}\n+\n+\t@Test(expected = BatchUpdateException.class)\n+\tpublic void testMaxRetry() throws Exception {\n+\t\tformat = JDBCUpsertOutputFormat.builder()\n+\t\t\t.setOptions(JDBCOptions.builder()\n+\t\t\t\t.setDBUrl(DB_URL)\n+\t\t\t\t.setTableName(OUTPUT_TABLE)\n+\t\t\t\t.build())\n+\t\t\t.setFieldNames(fieldNames)\n+\t\t\t.setKeyFields(keyFields)\n+\t\t\t.build();\n+\t\tRuntimeContext context = Mockito.mock(RuntimeContext.class);\n+\t\tExecutionConfig config = Mockito.mock(ExecutionConfig.class);\n+\t\tdoReturn(config).when(context).getExecutionConfig();\n+\t\tdoReturn(true).when(config).isObjectReuseEnabled();\n+\t\tformat.setRuntimeContext(context);\n+\t\tformat.open(0, 1);\n+\n+\t\t// alter table schema to trigger retry logic after failure.\n+\t\talterTable();\n+\t\tfor (TestEntry entry : TEST_DATA) {\n+\t\t\tformat.writeRecord(Tuple2.of(true, toRow(entry)));\n+\t\t}\n+\n+\t\t// after retry default times, throws a BatchUpdateException.\n+\t\tformat.flush();\n+\t}\n+\n+\tprivate void alterTable() throws Exception {\n+\t\tClass.forName(DRIVER_CLASS);\n+\t\ttry (Connection conn = DriverManager.getConnection(DB_URL);\n+\t\t\tStatement stat = conn.createStatement()) {\n+\t\t\tstat.execute(\"ALTER  TABLE \" + OUTPUT_TABLE + \" DROP COLUMN \" + fieldNames[1]);\n+\t\t\tstat.close();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "be5bed759e39f445d24dad3f2a0109ddddd7ce43"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjMxNzk0Nw==", "bodyText": "Remove close, already have try.", "url": "https://github.com/apache/flink/pull/11223#discussion_r386317947", "createdAt": "2020-03-02T10:43:46Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-jdbc/src/test/java/org/apache/flink/api/java/io/jdbc/JDBCAppenOnlyWriterTest.java", "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.api.java.io.jdbc;\n+\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.functions.RuntimeContext;\n+import org.apache.flink.api.java.io.jdbc.writer.AppendOnlyWriter;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import java.sql.BatchUpdateException;\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.Statement;\n+\n+import static org.apache.flink.api.java.io.jdbc.JDBCOutputFormatTest.toRow;\n+import static org.mockito.Mockito.doReturn;\n+\n+/**\n+ * Test for the {@link AppendOnlyWriter}.\n+ */\n+public class JDBCAppenOnlyWriterTest extends JDBCTestBase {\n+\tprivate JDBCUpsertOutputFormat format;\n+\tprivate String[] fieldNames;\n+\tprivate String[] keyFields;\n+\n+\t@Before\n+\tpublic void setup() {\n+\t\tfieldNames = new String[]{\"id\", \"title\", \"author\", \"price\", \"qty\"};\n+\t\tkeyFields = null;\n+\t}\n+\n+\t@Test(expected = BatchUpdateException.class)\n+\tpublic void testMaxRetry() throws Exception {\n+\t\tformat = JDBCUpsertOutputFormat.builder()\n+\t\t\t.setOptions(JDBCOptions.builder()\n+\t\t\t\t.setDBUrl(DB_URL)\n+\t\t\t\t.setTableName(OUTPUT_TABLE)\n+\t\t\t\t.build())\n+\t\t\t.setFieldNames(fieldNames)\n+\t\t\t.setKeyFields(keyFields)\n+\t\t\t.build();\n+\t\tRuntimeContext context = Mockito.mock(RuntimeContext.class);\n+\t\tExecutionConfig config = Mockito.mock(ExecutionConfig.class);\n+\t\tdoReturn(config).when(context).getExecutionConfig();\n+\t\tdoReturn(true).when(config).isObjectReuseEnabled();\n+\t\tformat.setRuntimeContext(context);\n+\t\tformat.open(0, 1);\n+\n+\t\t// alter table schema to trigger retry logic after failure.\n+\t\talterTable();\n+\t\tfor (TestEntry entry : TEST_DATA) {\n+\t\t\tformat.writeRecord(Tuple2.of(true, toRow(entry)));\n+\t\t}\n+\n+\t\t// after retry default times, throws a BatchUpdateException.\n+\t\tformat.flush();\n+\t}\n+\n+\tprivate void alterTable() throws Exception {\n+\t\tClass.forName(DRIVER_CLASS);\n+\t\ttry (Connection conn = DriverManager.getConnection(DB_URL);\n+\t\t\tStatement stat = conn.createStatement()) {\n+\t\t\tstat.execute(\"ALTER  TABLE \" + OUTPUT_TABLE + \" DROP COLUMN \" + fieldNames[1]);\n+\t\t\tstat.close();\n+\t\t\tconn.close();\n+\t\t}\n+\t}\n+\n+\t@After\n+\tpublic void clear() throws Exception {\n+\t\tClass.forName(DRIVER_CLASS);\n+\t\ttry (\n+\t\t\tConnection conn = DriverManager.getConnection(DB_URL);\n+\t\t\tStatement stat = conn.createStatement()) {\n+\t\t\tstat.execute(\"DELETE FROM \" + OUTPUT_TABLE);\n+\n+\t\t\tstat.close();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "be5bed759e39f445d24dad3f2a0109ddddd7ce43"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjMxODA4Mw==", "bodyText": "Please remove this", "url": "https://github.com/apache/flink/pull/11223#discussion_r386318083", "createdAt": "2020-03-02T10:44:05Z", "author": {"login": "JingsongLi"}, "path": "flink-connectors/flink-jdbc/src/test/java/org/apache/flink/api/java/io/jdbc/JDBCUpsertTableSinkITCase.java", "diffHunk": "@@ -52,6 +52,7 @@\n \tpublic static final String DB_URL = \"jdbc:derby:memory:upsert\";\n \tpublic static final String OUTPUT_TABLE1 = \"upsertSink\";\n \tpublic static final String OUTPUT_TABLE2 = \"appendSink\";\n+\tpublic static final String NOT_EXISTS_TABLE = \"notExistedTable\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "be5bed759e39f445d24dad3f2a0109ddddd7ce43"}, "originalPosition": 4}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1f118045b3f009e3a10a8f06b8e35ec95562fbef", "author": {"user": {"login": "leonardBang", "name": "Leonard Xu"}}, "url": "https://github.com/apache/flink/commit/1f118045b3f009e3a10a8f06b8e35ec95562fbef", "committedDate": "2020-03-02T12:39:09Z", "message": "minor update"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "16f8eb6f78a933588c092306dc726aa640c2faa2", "author": {"user": {"login": "leonardBang", "name": "Leonard Xu"}}, "url": "https://github.com/apache/flink/commit/16f8eb6f78a933588c092306dc726aa640c2faa2", "committedDate": "2020-03-02T16:15:43Z", "message": "minor update"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY3NjQ1NDkz", "url": "https://github.com/apache/flink/pull/11223#pullrequestreview-367645493", "createdAt": "2020-03-03T01:23:07Z", "commit": {"oid": "16f8eb6f78a933588c092306dc726aa640c2faa2"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3222, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}