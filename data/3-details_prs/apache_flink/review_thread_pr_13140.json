{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDY3Mzc2Njk1", "number": 13140, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQwMjozNzowM1rOEYUJWg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQwNjozNToxNlrOEYWnwg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkzOTMxMzU0OnYy", "diffSide": "RIGHT", "path": "flink-python/pyflink/datastream/tests/test_data_stream.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQwMjozNzowM1rOHAllDg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQwNDowODo0NlrOHAm4nw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM3Nzc0Mg==", "bodyText": "set parallelism on this source ds is useless since the parallelism of from_collection would always be one.", "url": "https://github.com/apache/flink/pull/13140#discussion_r470377742", "createdAt": "2020-08-14T02:37:03Z", "author": {"login": "hequn8128"}, "path": "flink-python/pyflink/datastream/tests/test_data_stream.py", "diffHunk": "@@ -322,6 +323,86 @@ def test_keyed_stream_partitioning(self):\n         with self.assertRaises(Exception):\n             keyed_stream.forward()\n \n+    def test_slot_sharing_group(self):\n+        source_operator_name = 'collection source'\n+        map_operator_name = 'map_operator'\n+        slot_sharing_group_1 = 'slot_sharing_group_1'\n+        slot_sharing_group_2 = 'slot_sharing_group_2'\n+        ds_1 = self.env.from_collection([1, 2, 3]).name(source_operator_name)\n+        ds_1.slot_sharing_group(slot_sharing_group_1).map(lambda x: x + 1).set_parallelism(3)\\\n+            .name(map_operator_name).slot_sharing_group(slot_sharing_group_2)\\\n+            .add_sink(self.test_sink)\n+\n+        j_generated_stream_graph = self.env._j_stream_execution_environment \\\n+            .getStreamGraph(\"test start new_chain\", True)\n+\n+        j_stream_nodes = list(j_generated_stream_graph.getStreamNodes().toArray())\n+        for j_stream_node in j_stream_nodes:\n+            if j_stream_node.getOperatorName() == source_operator_name:\n+                self.assertEqual(j_stream_node.getSlotSharingGroup(), slot_sharing_group_1)\n+            elif j_stream_node.getOperatorName() == map_operator_name:\n+                self.assertEqual(j_stream_node.getSlotSharingGroup(), slot_sharing_group_2)\n+\n+    def test_chaining_strategy(self):\n+        chained_operator_name = \"map_operator_1\"\n+        chained_operator_name_1 = \"map_operator_2\"\n+\n+        ds = self.env.from_collection([1, 2, 3])\n+        ds.set_parallelism(2).map(lambda x: x).set_parallelism(2)\\\n+            .name(chained_operator_name).map(lambda x: x).set_parallelism(2)\\\n+            .name(chained_operator_name_1).add_sink(self.test_sink)\n+\n+        def assert_chainable(j_stream_graph, expected_upstream_chainable,\n+                             expected_downstream_chainable):\n+            j_stream_nodes = list(j_stream_graph.getStreamNodes().toArray())\n+            for j_stream_node in j_stream_nodes:\n+                if j_stream_node.getOperatorName() == chained_operator_name:\n+                    JStreamingJobGraphGenerator = get_gateway().jvm \\\n+                        .org.apache.flink.streaming.api.graph.StreamingJobGraphGenerator\n+\n+                    j_in_stream_edge = j_stream_node.getInEdges().get(0)\n+                    upstream_chainable = JStreamingJobGraphGenerator.isChainable(j_in_stream_edge,\n+                                                                                 j_stream_graph)\n+                    self.assertEqual(expected_upstream_chainable, upstream_chainable)\n+\n+                    j_out_stream_edge = j_stream_node.getOutEdges().get(0)\n+                    downstream_chainable = JStreamingJobGraphGenerator.isChainable(\n+                        j_out_stream_edge, j_stream_graph)\n+                    self.assertEqual(expected_downstream_chainable, downstream_chainable)\n+\n+        # The map_operator_1 has the same parallelism with source operator and map_operator_2, and\n+        # ship_strategy for collection source and map_operator_1 is FORWARD, so the map_operator_1\n+        # can be chained with collection source and map_operator_2.\n+        j_generated_stream_graph = self.env._j_stream_execution_environment\\\n+            .getStreamGraph(\"test start new_chain\", True)\n+        assert_chainable(j_generated_stream_graph, True, True)\n+\n+        ds = self.env.from_collection([1, 2, 3])\n+        # Start a new chain for map_operator_1\n+        ds.set_parallelism(2).map(lambda x: x).set_parallelism(2) \\", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "95d62f551c4f2215fca8982bddaccde0d0238ef0"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM5OTEzNQ==", "bodyText": "Yes, there should be followed by a new operation.", "url": "https://github.com/apache/flink/pull/13140#discussion_r470399135", "createdAt": "2020-08-14T04:08:46Z", "author": {"login": "shuiqiangchen"}, "path": "flink-python/pyflink/datastream/tests/test_data_stream.py", "diffHunk": "@@ -322,6 +323,86 @@ def test_keyed_stream_partitioning(self):\n         with self.assertRaises(Exception):\n             keyed_stream.forward()\n \n+    def test_slot_sharing_group(self):\n+        source_operator_name = 'collection source'\n+        map_operator_name = 'map_operator'\n+        slot_sharing_group_1 = 'slot_sharing_group_1'\n+        slot_sharing_group_2 = 'slot_sharing_group_2'\n+        ds_1 = self.env.from_collection([1, 2, 3]).name(source_operator_name)\n+        ds_1.slot_sharing_group(slot_sharing_group_1).map(lambda x: x + 1).set_parallelism(3)\\\n+            .name(map_operator_name).slot_sharing_group(slot_sharing_group_2)\\\n+            .add_sink(self.test_sink)\n+\n+        j_generated_stream_graph = self.env._j_stream_execution_environment \\\n+            .getStreamGraph(\"test start new_chain\", True)\n+\n+        j_stream_nodes = list(j_generated_stream_graph.getStreamNodes().toArray())\n+        for j_stream_node in j_stream_nodes:\n+            if j_stream_node.getOperatorName() == source_operator_name:\n+                self.assertEqual(j_stream_node.getSlotSharingGroup(), slot_sharing_group_1)\n+            elif j_stream_node.getOperatorName() == map_operator_name:\n+                self.assertEqual(j_stream_node.getSlotSharingGroup(), slot_sharing_group_2)\n+\n+    def test_chaining_strategy(self):\n+        chained_operator_name = \"map_operator_1\"\n+        chained_operator_name_1 = \"map_operator_2\"\n+\n+        ds = self.env.from_collection([1, 2, 3])\n+        ds.set_parallelism(2).map(lambda x: x).set_parallelism(2)\\\n+            .name(chained_operator_name).map(lambda x: x).set_parallelism(2)\\\n+            .name(chained_operator_name_1).add_sink(self.test_sink)\n+\n+        def assert_chainable(j_stream_graph, expected_upstream_chainable,\n+                             expected_downstream_chainable):\n+            j_stream_nodes = list(j_stream_graph.getStreamNodes().toArray())\n+            for j_stream_node in j_stream_nodes:\n+                if j_stream_node.getOperatorName() == chained_operator_name:\n+                    JStreamingJobGraphGenerator = get_gateway().jvm \\\n+                        .org.apache.flink.streaming.api.graph.StreamingJobGraphGenerator\n+\n+                    j_in_stream_edge = j_stream_node.getInEdges().get(0)\n+                    upstream_chainable = JStreamingJobGraphGenerator.isChainable(j_in_stream_edge,\n+                                                                                 j_stream_graph)\n+                    self.assertEqual(expected_upstream_chainable, upstream_chainable)\n+\n+                    j_out_stream_edge = j_stream_node.getOutEdges().get(0)\n+                    downstream_chainable = JStreamingJobGraphGenerator.isChainable(\n+                        j_out_stream_edge, j_stream_graph)\n+                    self.assertEqual(expected_downstream_chainable, downstream_chainable)\n+\n+        # The map_operator_1 has the same parallelism with source operator and map_operator_2, and\n+        # ship_strategy for collection source and map_operator_1 is FORWARD, so the map_operator_1\n+        # can be chained with collection source and map_operator_2.\n+        j_generated_stream_graph = self.env._j_stream_execution_environment\\\n+            .getStreamGraph(\"test start new_chain\", True)\n+        assert_chainable(j_generated_stream_graph, True, True)\n+\n+        ds = self.env.from_collection([1, 2, 3])\n+        # Start a new chain for map_operator_1\n+        ds.set_parallelism(2).map(lambda x: x).set_parallelism(2) \\", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM3Nzc0Mg=="}, "originalCommit": {"oid": "95d62f551c4f2215fca8982bddaccde0d0238ef0"}, "originalPosition": 68}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkzOTcxOTA2OnYy", "diffSide": "RIGHT", "path": "flink-python/pyflink/datastream/tests/test_data_stream.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQwNjozNToxNlrOHApLUQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQwNjo0MDowMlrOHApSMA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQzNjY4OQ==", "bodyText": "Update comments here.", "url": "https://github.com/apache/flink/pull/13140#discussion_r470436689", "createdAt": "2020-08-14T06:35:16Z", "author": {"login": "hequn8128"}, "path": "flink-python/pyflink/datastream/tests/test_data_stream.py", "diffHunk": "@@ -322,6 +322,88 @@ def test_keyed_stream_partitioning(self):\n         with self.assertRaises(Exception):\n             keyed_stream.forward()\n \n+    def test_slot_sharing_group(self):\n+        source_operator_name = 'collection source'\n+        map_operator_name = 'map_operator'\n+        slot_sharing_group_1 = 'slot_sharing_group_1'\n+        slot_sharing_group_2 = 'slot_sharing_group_2'\n+        ds_1 = self.env.from_collection([1, 2, 3]).name(source_operator_name)\n+        ds_1.slot_sharing_group(slot_sharing_group_1).map(lambda x: x + 1).set_parallelism(3)\\\n+            .name(map_operator_name).slot_sharing_group(slot_sharing_group_2)\\\n+            .add_sink(self.test_sink)\n+\n+        j_generated_stream_graph = self.env._j_stream_execution_environment \\\n+            .getStreamGraph(\"test start new_chain\", True)\n+\n+        j_stream_nodes = list(j_generated_stream_graph.getStreamNodes().toArray())\n+        for j_stream_node in j_stream_nodes:\n+            if j_stream_node.getOperatorName() == source_operator_name:\n+                self.assertEqual(j_stream_node.getSlotSharingGroup(), slot_sharing_group_1)\n+            elif j_stream_node.getOperatorName() == map_operator_name:\n+                self.assertEqual(j_stream_node.getSlotSharingGroup(), slot_sharing_group_2)\n+\n+    def test_chaining_strategy(self):\n+        chained_operator_name_0 = \"map_operator_0\"\n+        chained_operator_name_1 = \"map_operator_1\"\n+        chained_operator_name_2 = \"map_operator_2\"\n+\n+        ds = self.env.from_collection([1, 2, 3])\n+        ds.map(lambda x: x).set_parallelism(2).name(chained_operator_name_0)\\\n+            .map(lambda x: x).set_parallelism(2).name(chained_operator_name_1)\\\n+            .map(lambda x: x).set_parallelism(2).name(chained_operator_name_2)\\\n+            .add_sink(self.test_sink)\n+\n+        def assert_chainable(j_stream_graph, expected_upstream_chainable,\n+                             expected_downstream_chainable):\n+            j_stream_nodes = list(j_stream_graph.getStreamNodes().toArray())\n+            for j_stream_node in j_stream_nodes:\n+                if j_stream_node.getOperatorName() == chained_operator_name_1:\n+                    JStreamingJobGraphGenerator = get_gateway().jvm \\\n+                        .org.apache.flink.streaming.api.graph.StreamingJobGraphGenerator\n+\n+                    j_in_stream_edge = j_stream_node.getInEdges().get(0)\n+                    upstream_chainable = JStreamingJobGraphGenerator.isChainable(j_in_stream_edge,\n+                                                                                 j_stream_graph)\n+                    self.assertEqual(expected_upstream_chainable, upstream_chainable)\n+\n+                    j_out_stream_edge = j_stream_node.getOutEdges().get(0)\n+                    downstream_chainable = JStreamingJobGraphGenerator.isChainable(\n+                        j_out_stream_edge, j_stream_graph)\n+                    self.assertEqual(expected_downstream_chainable, downstream_chainable)\n+\n+        # The map_operator_1 has the same parallelism with source operator and map_operator_2, and\n+        # ship_strategy for collection source and map_operator_1 is FORWARD, so the map_operator_1\n+        # can be chained with collection source and map_operator_2.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc8ddc039efdf3720bfaa29e2bff86df4ea2e346"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQzODQ0OA==", "bodyText": "Thank you , I will update it.", "url": "https://github.com/apache/flink/pull/13140#discussion_r470438448", "createdAt": "2020-08-14T06:40:02Z", "author": {"login": "shuiqiangchen"}, "path": "flink-python/pyflink/datastream/tests/test_data_stream.py", "diffHunk": "@@ -322,6 +322,88 @@ def test_keyed_stream_partitioning(self):\n         with self.assertRaises(Exception):\n             keyed_stream.forward()\n \n+    def test_slot_sharing_group(self):\n+        source_operator_name = 'collection source'\n+        map_operator_name = 'map_operator'\n+        slot_sharing_group_1 = 'slot_sharing_group_1'\n+        slot_sharing_group_2 = 'slot_sharing_group_2'\n+        ds_1 = self.env.from_collection([1, 2, 3]).name(source_operator_name)\n+        ds_1.slot_sharing_group(slot_sharing_group_1).map(lambda x: x + 1).set_parallelism(3)\\\n+            .name(map_operator_name).slot_sharing_group(slot_sharing_group_2)\\\n+            .add_sink(self.test_sink)\n+\n+        j_generated_stream_graph = self.env._j_stream_execution_environment \\\n+            .getStreamGraph(\"test start new_chain\", True)\n+\n+        j_stream_nodes = list(j_generated_stream_graph.getStreamNodes().toArray())\n+        for j_stream_node in j_stream_nodes:\n+            if j_stream_node.getOperatorName() == source_operator_name:\n+                self.assertEqual(j_stream_node.getSlotSharingGroup(), slot_sharing_group_1)\n+            elif j_stream_node.getOperatorName() == map_operator_name:\n+                self.assertEqual(j_stream_node.getSlotSharingGroup(), slot_sharing_group_2)\n+\n+    def test_chaining_strategy(self):\n+        chained_operator_name_0 = \"map_operator_0\"\n+        chained_operator_name_1 = \"map_operator_1\"\n+        chained_operator_name_2 = \"map_operator_2\"\n+\n+        ds = self.env.from_collection([1, 2, 3])\n+        ds.map(lambda x: x).set_parallelism(2).name(chained_operator_name_0)\\\n+            .map(lambda x: x).set_parallelism(2).name(chained_operator_name_1)\\\n+            .map(lambda x: x).set_parallelism(2).name(chained_operator_name_2)\\\n+            .add_sink(self.test_sink)\n+\n+        def assert_chainable(j_stream_graph, expected_upstream_chainable,\n+                             expected_downstream_chainable):\n+            j_stream_nodes = list(j_stream_graph.getStreamNodes().toArray())\n+            for j_stream_node in j_stream_nodes:\n+                if j_stream_node.getOperatorName() == chained_operator_name_1:\n+                    JStreamingJobGraphGenerator = get_gateway().jvm \\\n+                        .org.apache.flink.streaming.api.graph.StreamingJobGraphGenerator\n+\n+                    j_in_stream_edge = j_stream_node.getInEdges().get(0)\n+                    upstream_chainable = JStreamingJobGraphGenerator.isChainable(j_in_stream_edge,\n+                                                                                 j_stream_graph)\n+                    self.assertEqual(expected_upstream_chainable, upstream_chainable)\n+\n+                    j_out_stream_edge = j_stream_node.getOutEdges().get(0)\n+                    downstream_chainable = JStreamingJobGraphGenerator.isChainable(\n+                        j_out_stream_edge, j_stream_graph)\n+                    self.assertEqual(expected_downstream_chainable, downstream_chainable)\n+\n+        # The map_operator_1 has the same parallelism with source operator and map_operator_2, and\n+        # ship_strategy for collection source and map_operator_1 is FORWARD, so the map_operator_1\n+        # can be chained with collection source and map_operator_2.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQzNjY4OQ=="}, "originalCommit": {"oid": "cc8ddc039efdf3720bfaa29e2bff86df4ea2e346"}, "originalPosition": 88}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 547, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}