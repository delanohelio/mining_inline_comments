{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzkzODYwOTIx", "number": 11515, "title": "[FLINK-16744][task] implement channel state persistence for unaligned checkpoints", "bodyText": "What is the purpose of the change\nImplement channel state persistence for unaligned checkpoints\nNOTE: This PR is based on #11491 and contains some not-yet-merged changes from it:\n\n[FLINK-16513][checkpointing] add task channel state for unaligned checkpoints\n[FLINK-16513][checkpointing] pre-requisite refactorings to add channel state to snapshot metadata\n\nVerifying this change\nThis change added tests and can be verified as follows:\n\nChannelPersistenceITCase\nChannelStateCheckpointWriterTest\nChannelStateReaderImplTest\nChannelStateSerializerImplTest\nChannelStateSerializerTest\nChannelStateWriteRequestProcessorTest\nChannelStateWriterImplTest\n\nDoes this pull request potentially affect one of the following parts:\n\nDependencies (does it add or upgrade a dependency): no\nThe public API, i.e., is any changed class annotated with @Public(Evolving): no\nThe serializers: no\nThe runtime per-record code paths (performance sensitive): no\nAnything that affects deployment or recovery: JobManager (and its components), Checkpointing, Kubernetes/Yarn/Mesos, ZooKeeper: no\nThe S3 file system connector: no\n\nDocumentation\n\nDoes this pull request introduce a new feature? no\nIf yes, how is the feature documented? not applicable", "createdAt": "2020-03-25T22:31:45Z", "url": "https://github.com/apache/flink/pull/11515", "merged": true, "mergeCommit": {"oid": "6e296ad3f30c5bab51eccbfa005b041f4a1184dc"}, "closed": true, "closedAt": "2020-04-10T09:04:44Z", "author": {"login": "rkhachatryan"}, "timelineItems": {"totalCount": 141, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcVVg1rAFqTM4OTI2NTU1NQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcWA8gHABqjMyMTk1MDkyNzE=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg5MjY1NTU1", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-389265555", "createdAt": "2020-04-07T16:02:22Z", "commit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNjowMjoyMlrOGCKzmg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNjowMjoyMlrOGCKzmg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDkyNzM4Ng==", "bodyText": "Uniform the argument form as writeInput? Buffer... or Buffer[]", "url": "https://github.com/apache/flink/pull/11515#discussion_r404927386", "createdAt": "2020-04-07T16:02:22Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateCheckpointWriter.java", "diffHunk": "@@ -0,0 +1,203 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory.CheckpointStateOutputStream;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.runtime.state.ResultSubpartitionStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.BiFunction;\n+\n+import static org.apache.flink.runtime.state.CheckpointedStateScope.EXCLUSIVE;\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * Writes channel state for a specific checkpoint-subtask-attempt triple.\n+ */\n+@NotThreadSafe\n+class ChannelStateCheckpointWriter {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateCheckpointWriter.class);\n+\n+\tprivate final DataOutputStream dataStream;\n+\tprivate final CheckpointStateOutputStream checkpointStream;\n+\tprivate final ChannelStateWriteResult result;\n+\tprivate final Map<InputChannelInfo, List<Long>> inputChannelOffsets = new HashMap<>();\n+\tprivate final Map<ResultSubpartitionInfo, List<Long>> resultSubpartitionOffsets = new HashMap<>();\n+\tprivate final ChannelStateSerializer serializer;\n+\tprivate final long checkpointId;\n+\tprivate boolean allInputsReceived = false;\n+\tprivate boolean allOutputsReceived = false;\n+\tprivate final RunnableWithException onComplete;\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tCheckpointStartRequest startCheckpointItem,\n+\t\t\tCheckpointStreamFactory streamFactory,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnableWithException onComplete) throws Exception {\n+\t\tthis(\n+\t\t\tstartCheckpointItem.getCheckpointId(),\n+\t\t\tstartCheckpointItem.getTargetResult(),\n+\t\t\tstreamFactory.createCheckpointStateOutputStream(EXCLUSIVE),\n+\t\t\tserializer,\n+\t\t\tonComplete);\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tCheckpointStateOutputStream stream,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnableWithException onComplete) throws Exception {\n+\t\tthis(checkpointId, result, serializer, onComplete, stream, new DataOutputStream(stream));\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnableWithException onComplete,\n+\t\t\tCheckpointStateOutputStream checkpointStateOutputStream,\n+\t\t\tDataOutputStream dataStream) throws Exception {\n+\t\tthis.checkpointId = checkpointId;\n+\t\tthis.result = checkNotNull(result);\n+\t\tthis.checkpointStream = checkNotNull(checkpointStateOutputStream);\n+\t\tthis.serializer = checkNotNull(serializer);\n+\t\tthis.dataStream = checkNotNull(dataStream);\n+\t\tthis.onComplete = checkNotNull(onComplete);\n+\t\trunWithChecks(() -> serializer.writeHeader(dataStream));\n+\t}\n+\n+\tvoid writeInput(InputChannelInfo info, Buffer... flinkBuffers) throws Exception {\n+\t\twrite(inputChannelOffsets, info, flinkBuffers, !allInputsReceived);\n+\t}\n+\n+\tvoid writeOutput(ResultSubpartitionInfo info, Buffer[] flinkBuffers) throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 110}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg5MjcxNDQx", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-389271441", "createdAt": "2020-04-07T16:08:56Z", "commit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNjowODo1NlrOGCLFvQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNjowODo1NlrOGCLFvQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDkzMjAyOQ==", "bodyText": "Are there any problems if checkpointStream.close() causes exception to not execute the below dataStream.close()?", "url": "https://github.com/apache/flink/pull/11515#discussion_r404932029", "createdAt": "2020-04-07T16:08:56Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateCheckpointWriter.java", "diffHunk": "@@ -0,0 +1,203 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory.CheckpointStateOutputStream;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.runtime.state.ResultSubpartitionStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.BiFunction;\n+\n+import static org.apache.flink.runtime.state.CheckpointedStateScope.EXCLUSIVE;\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * Writes channel state for a specific checkpoint-subtask-attempt triple.\n+ */\n+@NotThreadSafe\n+class ChannelStateCheckpointWriter {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateCheckpointWriter.class);\n+\n+\tprivate final DataOutputStream dataStream;\n+\tprivate final CheckpointStateOutputStream checkpointStream;\n+\tprivate final ChannelStateWriteResult result;\n+\tprivate final Map<InputChannelInfo, List<Long>> inputChannelOffsets = new HashMap<>();\n+\tprivate final Map<ResultSubpartitionInfo, List<Long>> resultSubpartitionOffsets = new HashMap<>();\n+\tprivate final ChannelStateSerializer serializer;\n+\tprivate final long checkpointId;\n+\tprivate boolean allInputsReceived = false;\n+\tprivate boolean allOutputsReceived = false;\n+\tprivate final RunnableWithException onComplete;\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tCheckpointStartRequest startCheckpointItem,\n+\t\t\tCheckpointStreamFactory streamFactory,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnableWithException onComplete) throws Exception {\n+\t\tthis(\n+\t\t\tstartCheckpointItem.getCheckpointId(),\n+\t\t\tstartCheckpointItem.getTargetResult(),\n+\t\t\tstreamFactory.createCheckpointStateOutputStream(EXCLUSIVE),\n+\t\t\tserializer,\n+\t\t\tonComplete);\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tCheckpointStateOutputStream stream,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnableWithException onComplete) throws Exception {\n+\t\tthis(checkpointId, result, serializer, onComplete, stream, new DataOutputStream(stream));\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnableWithException onComplete,\n+\t\t\tCheckpointStateOutputStream checkpointStateOutputStream,\n+\t\t\tDataOutputStream dataStream) throws Exception {\n+\t\tthis.checkpointId = checkpointId;\n+\t\tthis.result = checkNotNull(result);\n+\t\tthis.checkpointStream = checkNotNull(checkpointStateOutputStream);\n+\t\tthis.serializer = checkNotNull(serializer);\n+\t\tthis.dataStream = checkNotNull(dataStream);\n+\t\tthis.onComplete = checkNotNull(onComplete);\n+\t\trunWithChecks(() -> serializer.writeHeader(dataStream));\n+\t}\n+\n+\tvoid writeInput(InputChannelInfo info, Buffer... flinkBuffers) throws Exception {\n+\t\twrite(inputChannelOffsets, info, flinkBuffers, !allInputsReceived);\n+\t}\n+\n+\tvoid writeOutput(ResultSubpartitionInfo info, Buffer[] flinkBuffers) throws Exception {\n+\t\twrite(resultSubpartitionOffsets, info, flinkBuffers, !allOutputsReceived);\n+\t}\n+\n+\tprivate <K> void write(Map<K, List<Long>> offsets, K key, Buffer[] flinkBuffers, boolean precondition) throws Exception {\n+\t\ttry {\n+\t\t\tif (result.isDone()) {\n+\t\t\t\treturn;\n+\t\t\t}\n+\t\t\trunWithChecks(() -> {\n+\t\t\t\tcheckState(precondition);\n+\t\t\t\toffsets\n+\t\t\t\t\t.computeIfAbsent(key, unused -> new ArrayList<>())\n+\t\t\t\t\t.add(checkpointStream.getPos());\n+\t\t\t\tserializer.writeData(dataStream, flinkBuffers);\n+\t\t\t});\n+\t\t} finally {\n+\t\t\tfor (Buffer flinkBuffer : flinkBuffers) {\n+\t\t\t\tflinkBuffer.recycleBuffer();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tvoid completeInput() throws Exception {\n+\t\tLOG.debug(\"complete input, output completed: {}\", allOutputsReceived);\n+\t\tcomplete(!allInputsReceived, () -> allInputsReceived = true);\n+\t}\n+\n+\tvoid completeOutput() throws Exception {\n+\t\tLOG.debug(\"complete output, input completed: {}\", allInputsReceived);\n+\t\tcomplete(!allOutputsReceived, () -> allOutputsReceived = true);\n+\t}\n+\n+\tprivate void complete(boolean precondition, RunnableWithException complete) throws Exception {\n+\t\tif (result.isDone()) {\n+\t\t\t// likely after abort - only need to set the flag run onComplete callback\n+\t\t\tdoComplete(precondition, complete, onComplete);\n+\t\t} else {\n+\t\t\trunWithChecks(() -> doComplete(precondition, complete, onComplete, this::finishWriteAndResult));\n+\t\t}\n+\t}\n+\n+\tprivate void finishWriteAndResult() throws IOException {\n+\t\tdataStream.flush();\n+\t\tStreamStateHandle underlying = checkpointStream.closeAndGetHandle();\n+\t\tcomplete(\n+\t\t\t\tresult.inputChannelStateHandles,\n+\t\t\t\tinputChannelOffsets,\n+\t\t\t\t(chan, offsets) -> new InputChannelStateHandle(chan, underlying, offsets));\n+\t\tcomplete(\n+\t\t\t\tresult.resultSubpartitionStateHandles,\n+\t\t\t\tresultSubpartitionOffsets,\n+\t\t\t\t(chan, offsets) -> new ResultSubpartitionStateHandle(chan, underlying, offsets));\n+\t}\n+\n+\tprivate void doComplete(boolean precondition, RunnableWithException complete, RunnableWithException... callbacks) throws Exception {\n+\t\tPreconditions.checkArgument(precondition);\n+\t\tcomplete.run();\n+\t\tif (allInputsReceived && allOutputsReceived) {\n+\t\t\tfor (RunnableWithException callback : callbacks) {\n+\t\t\t\tcallback.run();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate <I, H extends AbstractChannelStateHandle<I>> void complete(\n+\t\t\tCompletableFuture<Collection<H>> future,\n+\t\t\tMap<I, List<Long>> offsets,\n+\t\t\tBiFunction<I, List<Long>, H> buildHandle) {\n+\t\tfinal Collection<H> handles = new ArrayList<>();\n+\t\tfor (Map.Entry<I, List<Long>> e : offsets.entrySet()) {\n+\t\t\thandles.add(buildHandle.apply(e.getKey(), e.getValue()));\n+\t\t}\n+\t\tfuture.complete(handles);\n+\t\tLOG.debug(\"channel state write completed, checkpointId: {}, handles: {}\", checkpointId, handles);\n+\t}\n+\n+\tprivate void runWithChecks(RunnableWithException r) throws Exception {\n+\t\ttry {\n+\t\t\tcheckState(!result.isDone(), \"result is already completed\", result);\n+\t\t\tr.run();\n+\t\t} catch (Exception e) {\n+\t\t\tfail(e);\n+\t\t\tthrow e;\n+\t\t}\n+\t}\n+\n+\tpublic void fail(Throwable e) throws Exception {\n+\t\tresult.fail(e);\n+\t\tcheckpointStream.close();\n+\t\tdataStream.close();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 200}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg5MzE0MjEz", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-389314213", "createdAt": "2020-04-07T16:59:21Z", "commit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNjo1OToyMlrOGCNPcg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNjo1OToyMlrOGCNPcg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk2NzI4Mg==", "bodyText": "nit: adjust the description because we only return the size of state in bytes now.", "url": "https://github.com/apache/flink/pull/11515#discussion_r404967282", "createdAt": "2020-04-07T16:59:22Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,182 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\tint readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\t/**\n+\t * Read up to <code>bytesToRead</code> bytes into this buffer from the given {@link InputStream}.\n+\t * @return     the total number of bytes read into this buffer.\n+\t */\n+\tint writeBytes(InputStream input, int bytesToRead) throws IOException;\n+\n+\tstatic ChannelStateByteBuffer wrap(Buffer buffer) {\n+\t\treturn new ChannelStateByteBuffer() {\n+\n+\t\t\tprivate final ByteBuf byteBuf = buffer.asByteBuf();\n+\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn byteBuf.isWritable();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\treturn byteBuf.writeBytes(input, Math.min(bytesToRead, byteBuf.writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(BufferBuilder bufferBuilder) {\n+\t\tfinal byte[] buf = new byte[1024];\n+\t\treturn new ChannelStateByteBuffer() {\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn !bufferBuilder.isFull();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\tint left = bytesToRead;\n+\t\t\t\tfor (int toRead = getToRead(left); toRead > 0; toRead = getToRead(left)) {\n+\t\t\t\t\tint read = input.read(buf, 0, toRead);\n+\t\t\t\t\tint copied = bufferBuilder.append(java.nio.ByteBuffer.wrap(buf, 0, read));\n+\t\t\t\t\tPreconditions.checkState(copied == read);\n+\t\t\t\t\tleft -= read;\n+\t\t\t\t}\n+\t\t\t\tbufferBuilder.commit();\n+\t\t\t\treturn bytesToRead - left;\n+\t\t\t}\n+\n+\t\t\tprivate int getToRead(int bytesToRead) {\n+\t\t\t\treturn min(bytesToRead, min(buf.length, bufferBuilder.getWritableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(byte[] bytes) {\n+\t\treturn new ChannelStateByteBuffer() {\n+\t\t\tprivate int written = 0;\n+\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn written < bytes.length;\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\tfinal int bytesRead = input.read(bytes, written, bytes.length - written);\n+\t\t\t\twritten += bytesRead;\n+\t\t\t\treturn bytesRead;\n+\t\t\t}\n+\t\t};\n+\t}\n+}\n+\n+class ChannelStateSerializerImpl implements ChannelStateSerializer, ChannelStateDeserializer {\n+\tprivate static final int SERIALIZATION_VERSION = 0;\n+\n+\t@Override\n+\tpublic void writeHeader(DataOutputStream dataStream) throws IOException {\n+\t\tdataStream.writeInt(SERIALIZATION_VERSION);\n+\t}\n+\n+\t@Override\n+\tpublic void writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException {\n+\t\tstream.writeInt(getSize(flinkBuffers));\n+\t\tfor (Buffer buffer : flinkBuffers) {\n+\t\t\tByteBuf nettyByteBuf = buffer.asByteBuf();\n+\t\t\tnettyByteBuf.getBytes(nettyByteBuf.readerIndex(), stream, nettyByteBuf.readableBytes());\n+\t\t}\n+\t}\n+\n+\tprivate int getSize(Buffer[] buffers) {\n+\t\tint len = 0;\n+\t\tfor (Buffer buffer : buffers) {\n+\t\t\tlen = addExact(len, buffer.readableBytes());\n+\t\t}\n+\t\treturn len;\n+\t}\n+\n+\t@Override\n+\tpublic void readHeader(InputStream stream) throws IOException {\n+\t\tint version = readInt(stream);\n+\t\tPreconditions.checkArgument(version == SERIALIZATION_VERSION, \"unsupported version: \" + version);\n+\t}\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 165}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg5MzM0OTA3", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-389334907", "createdAt": "2020-04-07T17:26:18Z", "commit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "state": "APPROVED", "comments": {"totalCount": 16, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNzoyNjoxOFrOGCOTNA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxODoxNjoxNFrOGCQNXw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk4NDYyOA==", "bodyText": "As long as you are not handing out this directly or indirectly, constructor should be atomic in terms of memory synchronization. No other thread can see this instance of ChannelStateReaderImpl and find any inconsistent state.\nChannelStateReaderImpl reader = new ChannelStateReaderImpl(...);\nreader.... // <- at this point all maps are good", "url": "https://github.com/apache/flink/pull/11515#discussion_r404984628", "createdAt": "2020-04-07T17:26:18Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImpl.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.io.Closer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * {@link ChannelStateReader} implementation. Usage considerations:\n+ * <ol>\n+ *     <li>state of a channel can be read once per instance of this class; once done it returns\n+ *     {@link org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult#NO_MORE_DATA NO_MORE_DATA}</li>\n+ *     <li>reader/writer indices of the passed buffer are respected and updated</li>\n+ *     <li>buffers must be prepared (cleared) before passing to reader</li>\n+ *     <li>buffers must be released after use</li>\n+ * </ol>\n+ */\n+@NotThreadSafe\n+@Internal\n+public class ChannelStateReaderImpl implements ChannelStateReader {\n+\tprivate static final Logger log = LoggerFactory.getLogger(ChannelStateReaderImpl.class);\n+\n+\tprivate final Map<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReaders;\n+\tprivate final Map<ResultSubpartitionInfo, ChannelStateStreamReader> resultSubpartitionHandleReaders;\n+\n+\tpublic ChannelStateReaderImpl(TaskStateSnapshot snapshot) {\n+\t\tthis(snapshot, new ChannelStateSerializerImpl());\n+\t}\n+\n+\t@SuppressWarnings(\"WeakerAccess\")\n+\tChannelStateReaderImpl(TaskStateSnapshot snapshot, ChannelStateDeserializer serializer) {\n+\t\tRefCountingFSDataInputStreamFactory streamFactory = new RefCountingFSDataInputStreamFactory(serializer);\n+\t\tfinal HashMap<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReadersTmp = new HashMap<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIwNTA0NA=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk4NTI1MA==", "bodyText": "Afaik it's fine to use guava now and I recommend to use Closer for all close-related, non-trivial operations.", "url": "https://github.com/apache/flink/pull/11515#discussion_r404985250", "createdAt": "2020-04-07T17:27:16Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImpl.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.io.Closer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * {@link ChannelStateReader} implementation. Usage considerations:\n+ * <ol>\n+ *     <li>state of a channel can be read once per instance of this class; once done it returns\n+ *     {@link org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult#NO_MORE_DATA NO_MORE_DATA}</li>\n+ *     <li>reader/writer indices of the passed buffer are respected and updated</li>\n+ *     <li>buffers must be prepared (cleared) before passing to reader</li>\n+ *     <li>buffers must be released after use</li>\n+ * </ol>\n+ */\n+@NotThreadSafe\n+@Internal\n+public class ChannelStateReaderImpl implements ChannelStateReader {\n+\tprivate static final Logger log = LoggerFactory.getLogger(ChannelStateReaderImpl.class);\n+\n+\tprivate final Map<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReaders;\n+\tprivate final Map<ResultSubpartitionInfo, ChannelStateStreamReader> resultSubpartitionHandleReaders;\n+\n+\tpublic ChannelStateReaderImpl(TaskStateSnapshot snapshot) {\n+\t\tthis(snapshot, new ChannelStateSerializerImpl());\n+\t}\n+\n+\t@SuppressWarnings(\"WeakerAccess\")\n+\tChannelStateReaderImpl(TaskStateSnapshot snapshot, ChannelStateDeserializer serializer) {\n+\t\tRefCountingFSDataInputStreamFactory streamFactory = new RefCountingFSDataInputStreamFactory(serializer);\n+\t\tfinal HashMap<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReadersTmp = new HashMap<>();\n+\t\tfinal HashMap<ResultSubpartitionInfo, ChannelStateStreamReader> resultSubpartitionHandleReadersTmp = new HashMap<>();\n+\t\tfor (Map.Entry<OperatorID, OperatorSubtaskState> e : snapshot.getSubtaskStateMappings()) {\n+\t\t\taddReaders(inputChannelHandleReadersTmp, e.getValue().getInputChannelState(), streamFactory);\n+\t\t\taddReaders(resultSubpartitionHandleReadersTmp, e.getValue().getResultSubpartitionState(), streamFactory);\n+\t\t}\n+\t\tinputChannelHandleReaders = inputChannelHandleReadersTmp;\n+\t\tresultSubpartitionHandleReaders = resultSubpartitionHandleReadersTmp;\n+\t}\n+\n+\tprivate <T> void addReaders(Map<T, ChannelStateStreamReader> readerMap, Collection<? extends AbstractChannelStateHandle<T>> handles, RefCountingFSDataInputStreamFactory streamFactory) {\n+\t\tfor (AbstractChannelStateHandle<T> handle : handles) {\n+\t\t\tcheckState(!readerMap.containsKey(handle.getInfo()), \"multiple states exist for channel: \" + handle.getInfo());\n+\t\t\treaderMap.put(handle.getInfo(), new ChannelStateStreamReader(handle, streamFactory));\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic ReadResult readInputData(InputChannelInfo info, Buffer buffer) throws IOException {\n+\t\tlog.debug(\"readInputData, resultSubpartitionInfo: {} , bufferBuilder {}\", info, buffer);\n+\t\treturn getReader(info, inputChannelHandleReaders).readInto(buffer);\n+\t}\n+\n+\t@Override\n+\tpublic ReadResult readOutputData(ResultSubpartitionInfo info, BufferBuilder bufferBuilder) throws IOException {\n+\t\tlog.debug(\"readOutputData, resultSubpartitionInfo: {} , bufferBuilder {}\", info, bufferBuilder);\n+\t\treturn getReader(info, resultSubpartitionHandleReaders).readInto(bufferBuilder);\n+\t}\n+\n+\tprivate <K> ChannelStateStreamReader getReader(K info, Map<K, ChannelStateStreamReader> readerMap) {\n+\t\tPreconditions.checkArgument(readerMap.containsKey(info), String.format(\"unknown channel %s. Known channels: %s\", info, readerMap.keySet()));\n+\t\treturn readerMap.get(info);\n+\t}\n+\n+\t@Override\n+\tpublic void close() throws Exception {\n+\t\ttry (Closer closer = Closer.create()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI4MTc2Ng=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 106}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk4OTEwOA==", "bodyText": "I'm not sure what the general agreement is, but I'm not a huge fan of adding code just to make testing easier. The only sensible exception is to add accessors to private fields. My main concern is that we blow up the production code without adding any functionality. This additional would then need additional tests, so we are testing code that is only relevant for tests...\nIf this subclass is useful only for testing, why not add it in the ChannelStateSerializerTest or in some *Util? For example, TestBufferFactory adds a convenient way to create small test buffers. If that was part of the actual Buffer interface, it would be very confusing to me.", "url": "https://github.com/apache/flink/pull/11515#discussion_r404989108", "createdAt": "2020-04-07T17:33:00Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\tTuple2<Integer, Integer> readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\tint writableBytes();\n+\n+\tint writeBytes(InputStream input, int bytesToRead) throws IOException;\n+\n+\tstatic ChannelStateByteBuffer wrap(Buffer buffer) {\n+\t\treturn new ChannelStateByteBuffer() {\n+\n+\t\t\tprivate ByteBuf byteBuf = buffer.asByteBuf();\n+\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn byteBuf.isWritable();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn byteBuf.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\treturn byteBuf.writeBytes(input, Math.min(bytesToRead, byteBuf.writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(BufferBuilder bufferBuilder) {\n+\t\tfinal byte[] buf = new byte[1024];\n+\t\treturn new ChannelStateByteBuffer() {\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn !bufferBuilder.isFull();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn bufferBuilder.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int upToBytes) throws IOException {\n+\t\t\t\tint left = upToBytes;\n+\t\t\t\tfor (int toRead = getToRead(left); toRead > 0; toRead = getToRead(left)) {\n+\t\t\t\t\tint read = input.read(buf, 0, toRead);\n+\t\t\t\t\tint copied = bufferBuilder.append(java.nio.ByteBuffer.wrap(buf, 0, read));\n+\t\t\t\t\tPreconditions.checkState(copied == read);\n+\t\t\t\t\tleft -= read;\n+\t\t\t\t}\n+\t\t\t\tbufferBuilder.commit();\n+\t\t\t\treturn upToBytes - left;\n+\t\t\t}\n+\n+\t\t\tprivate int getToRead(int bytesToRead) {\n+\t\t\t\treturn min(bytesToRead, min(buf.length, writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(byte[] bytes) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQwMTExMQ=="}, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 126}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk5MTg0Mg==", "bodyText": "Also not sure if we should add suppression for non-standard warnings (e.g. unchecked). Everyone has different settings and the code might be very cluttered if everyone adds these suppressions. And then there is the warning for unused suppressions, which turns it into a recursive mess.", "url": "https://github.com/apache/flink/pull/11515#discussion_r404991842", "createdAt": "2020-04-07T17:37:17Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateStreamReader.java", "diffHunk": "@@ -0,0 +1,111 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateByteBuffer.wrap;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.HAS_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+\n+/**\n+ * Reads the state of a single channel pointed by {@link org.apache.flink.runtime.state.AbstractChannelStateHandle AbstractChannelStateHandle}.\n+ * Once all data is read, this class can't be used anymore.\n+ * Uses {@link RefCountingFSDataInputStream} internally.\n+ */\n+@NotThreadSafe\n+class ChannelStateStreamReader implements Closeable {\n+\n+\tprivate final RefCountingFSDataInputStream stream;\n+\tprivate final ChannelStateDeserializer serializer;\n+\tprivate final Queue<Long> offsets;\n+\tprivate int remainingBytes = -1;\n+\tprivate boolean closed = false;\n+\n+\tChannelStateStreamReader(AbstractChannelStateHandle<?> handle, RefCountingFSDataInputStreamFactory streamFactory) {\n+\t\tthis(streamFactory.getOrCreate(handle), handle.getOffsets(), streamFactory.getSerializer());\n+\t}\n+\n+\tprivate ChannelStateStreamReader(RefCountingFSDataInputStream stream, List<Long> offsets, ChannelStateDeserializer serializer) {\n+\t\tthis.stream = stream;\n+\t\tthis.stream.incRef();\n+\t\tthis.serializer = serializer;\n+\t\tthis.offsets = new LinkedList<>(offsets);\n+\t}\n+\n+\tReadResult readInto(Buffer buffer) throws IOException {\n+\t\treturn readInto(wrap(buffer));\n+\t}\n+\n+\tReadResult readInto(BufferBuilder bufferBuilder) throws IOException {\n+\t\treturn readInto(wrap(bufferBuilder));\n+\t}\n+\n+\tprivate ReadResult readInto(ChannelStateByteBuffer buffer) throws IOException {\n+\t\tPreconditions.checkState(!closed, \"reader is closed\");\n+\t\treadWhilePossible(buffer);\n+\t\tif (haveMoreData()) {\n+\t\t\treturn HAS_MORE_DATA;\n+\t\t} else {\n+\t\t\tclosed = true;\n+\t\t\tstream.decRef();\n+\t\t\treturn NO_MORE_DATA;\n+\t\t}\n+\t}\n+\n+\tprivate void readWhilePossible(ChannelStateByteBuffer buffer) throws IOException {\n+\t\twhile (haveMoreData() && buffer.isWritable()) {\n+\t\t\tif (remainingBytes <= 0) {\n+\t\t\t\tadvanceOffset();\n+\t\t\t}\n+\t\t\tint bytesRead = serializer.readData(stream, buffer, remainingBytes);\n+\t\t\tremainingBytes -= bytesRead;\n+\t\t}\n+\t}\n+\n+\tprivate boolean haveMoreData() {\n+\t\treturn remainingBytes > 0 || !offsets.isEmpty();\n+\t}\n+\n+\t@SuppressWarnings(\"ConstantConditions\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk5NjYwNQ==", "bodyText": "nit: initialize field directly? (not sure what the default is, just pointing out)", "url": "https://github.com/apache/flink/pull/11515#discussion_r404996605", "createdAt": "2020-04-07T17:44:54Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestDispatcherImpl.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+/**\n+ * Maintains a set of {@link ChannelStateCheckpointWriter writers} per checkpoint and translates incoming\n+ * {@link ChannelStateWriteRequest requests} to their corresponding methods.\n+ */\n+final class ChannelStateWriteRequestDispatcherImpl implements ChannelStateWriteRequestDispatcher {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriteRequestDispatcherImpl.class);\n+\n+\tprivate final Map<Long, ChannelStateCheckpointWriter> writers; // limited indirectly by results max size\n+\tprivate final CheckpointStorageWorkerView streamFactoryResolver;\n+\tprivate final ChannelStateSerializer serializer;\n+\n+\tChannelStateWriteRequestDispatcherImpl(CheckpointStorageWorkerView streamFactoryResolver, ChannelStateSerializer serializer) {\n+\t\tthis.writers = new HashMap<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk5NzE0MA==", "bodyText": "nit: add string message (containing checkpoint id for easier debugging).", "url": "https://github.com/apache/flink/pull/11515#discussion_r404997140", "createdAt": "2020-04-07T17:45:48Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestDispatcherImpl.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+/**\n+ * Maintains a set of {@link ChannelStateCheckpointWriter writers} per checkpoint and translates incoming\n+ * {@link ChannelStateWriteRequest requests} to their corresponding methods.\n+ */\n+final class ChannelStateWriteRequestDispatcherImpl implements ChannelStateWriteRequestDispatcher {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriteRequestDispatcherImpl.class);\n+\n+\tprivate final Map<Long, ChannelStateCheckpointWriter> writers; // limited indirectly by results max size\n+\tprivate final CheckpointStorageWorkerView streamFactoryResolver;\n+\tprivate final ChannelStateSerializer serializer;\n+\n+\tChannelStateWriteRequestDispatcherImpl(CheckpointStorageWorkerView streamFactoryResolver, ChannelStateSerializer serializer) {\n+\t\tthis.writers = new HashMap<>();\n+\t\tthis.streamFactoryResolver = streamFactoryResolver;\n+\t\tthis.serializer = serializer;\n+\t}\n+\n+\t@Override\n+\tpublic void dispatch(ChannelStateWriteRequest request) throws Exception {\n+\t\tLOG.debug(\"process {}\", request);\n+\t\ttry {\n+\t\t\tdispatchInternal(request);\n+\t\t} catch (Exception e) {\n+\t\t\trequest.cancel(e);\n+\t\t\tthrow e;\n+\t\t}\n+\t}\n+\n+\tprivate void dispatchInternal(ChannelStateWriteRequest request) throws Exception {\n+\t\tif (request instanceof CheckpointStartRequest) {\n+\t\t\tPreconditions.checkState(!writers.containsKey(request.getCheckpointId()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk5ODEwNA==", "bodyText": "nit: forEach is not saving anything on for-loop and the latter is usually easier to read for java guys.", "url": "https://github.com/apache/flink/pull/11515#discussion_r404998104", "createdAt": "2020-04-07T17:47:24Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestDispatcherImpl.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+/**\n+ * Maintains a set of {@link ChannelStateCheckpointWriter writers} per checkpoint and translates incoming\n+ * {@link ChannelStateWriteRequest requests} to their corresponding methods.\n+ */\n+final class ChannelStateWriteRequestDispatcherImpl implements ChannelStateWriteRequestDispatcher {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriteRequestDispatcherImpl.class);\n+\n+\tprivate final Map<Long, ChannelStateCheckpointWriter> writers; // limited indirectly by results max size\n+\tprivate final CheckpointStorageWorkerView streamFactoryResolver;\n+\tprivate final ChannelStateSerializer serializer;\n+\n+\tChannelStateWriteRequestDispatcherImpl(CheckpointStorageWorkerView streamFactoryResolver, ChannelStateSerializer serializer) {\n+\t\tthis.writers = new HashMap<>();\n+\t\tthis.streamFactoryResolver = streamFactoryResolver;\n+\t\tthis.serializer = serializer;\n+\t}\n+\n+\t@Override\n+\tpublic void dispatch(ChannelStateWriteRequest request) throws Exception {\n+\t\tLOG.debug(\"process {}\", request);\n+\t\ttry {\n+\t\t\tdispatchInternal(request);\n+\t\t} catch (Exception e) {\n+\t\t\trequest.cancel(e);\n+\t\t\tthrow e;\n+\t\t}\n+\t}\n+\n+\tprivate void dispatchInternal(ChannelStateWriteRequest request) throws Exception {\n+\t\tif (request instanceof CheckpointStartRequest) {\n+\t\t\tPreconditions.checkState(!writers.containsKey(request.getCheckpointId()));\n+\t\t\twriters.put(request.getCheckpointId(), buildWriter((CheckpointStartRequest) request));\n+\t\t} else if (request instanceof CheckpointInProgressRequest) {\n+\t\t\tChannelStateCheckpointWriter writer = writers.get(request.getCheckpointId());\n+\t\t\tCheckpointInProgressRequest req = (CheckpointInProgressRequest) request;\n+\t\t\tif (writer == null) {\n+\t\t\t\treq.onWriterMissing();\n+\t\t\t} else {\n+\t\t\t\treq.execute(writer);\n+\t\t\t}\n+\t\t} else {\n+\t\t\tthrow new IllegalArgumentException(\"unknown request type: \" + request);\n+\t\t}\n+\t}\n+\n+\tprivate ChannelStateCheckpointWriter buildWriter(CheckpointStartRequest request) throws Exception {\n+\t\treturn new ChannelStateCheckpointWriter(\n+\t\t\trequest,\n+\t\t\tstreamFactoryResolver.resolveCheckpointStorageLocation(request.getCheckpointId(), request.getLocationReference()),\n+\t\t\tserializer,\n+\t\t\t() -> writers.remove(request.getCheckpointId()));\n+\t}\n+\n+\t@Override\n+\tpublic void close(Throwable cause) {\n+\t\twriters.values().forEach(writer -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk5OTEwMw==", "bodyText": "close is a strange name for something that belongs to the exception handling. Why not call it fail like in the writer?", "url": "https://github.com/apache/flink/pull/11515#discussion_r404999103", "createdAt": "2020-04-07T17:48:53Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestDispatcher.java", "diffHunk": "@@ -0,0 +1,36 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+interface ChannelStateWriteRequestDispatcher {\n+\n+\tvoid dispatch(ChannelStateWriteRequest request) throws Exception;\n+\n+\tvoid close(Throwable cause);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk5OTQ0MA==", "bodyText": "nit: you don't use empty lines on other classes.", "url": "https://github.com/apache/flink/pull/11515#discussion_r404999440", "createdAt": "2020-04-07T17:49:31Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestExecutor.java", "diffHunk": "@@ -0,0 +1,49 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import java.io.Closeable;\n+\n+/**\n+ * Executes {@link ChannelStateWriteRequest}s potentially asynchronously. An exception thrown during the execution\n+ * should be re-thrown on any next call.\n+ */\n+interface ChannelStateWriteRequestExecutor extends Closeable {\n+\n+\t/**\n+\t * @throws IllegalStateException if called more than once or after {@link #close()}\n+\t */\n+\tvoid start() throws IllegalStateException;\n+\n+\t/**\n+\t * Send {@link ChannelStateWriteRequest} to this worker. If this method throws an exception then client must\n+\t * {@link ChannelStateWriteRequest#cancel cancel} it.\n+\t * @throws IllegalStateException if worker is not running\n+\t * @throws Exception if any exception occurred during processing this or other items previously\n+\t */\n+\tvoid submit(ChannelStateWriteRequest r) throws Exception;\n+\n+\t/**\n+\t * Send {@link ChannelStateWriteRequest} to this worker to be processed first. If this method throws an exception then client must\n+\t * {@link ChannelStateWriteRequest#cancel cancel} it.\n+\t * @throws IllegalStateException if worker is not running\n+\t * @throws Exception if any exception occurred during processing this or other items previously\n+\t */\n+\tvoid submitPriority(ChannelStateWriteRequest r) throws Exception;\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAwNjMyNw==", "bodyText": "Is there a particular reason to bound the optionally-bouded LinkedBlockingDeque? In the end, we are most likely limited by the number of buffers anyways and I'd argue that the overhead of your data structures is minimal compared to them.", "url": "https://github.com/apache/flink/pull/11515#discussion_r405006327", "createdAt": "2020-04-07T18:00:22Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestExecutorImpl.java", "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.BlockingDeque;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.LinkedBlockingDeque;\n+\n+/**\n+ * Executes {@link ChannelStateWriteRequest}s in a separate thread. Any exception occurred during execution causes this\n+ * thread to stop and the exception to be re-thrown on any subsequent call.\n+ */\n+@ThreadSafe\n+class ChannelStateWriteRequestExecutorImpl implements ChannelStateWriteRequestExecutor {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriteRequestExecutorImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10_000;\n+\n+\tprivate final ChannelStateWriteRequestDispatcher dispatcher;\n+\tprivate final BlockingDeque<ChannelStateWriteRequest> deque;\n+\tprivate final Thread thread;\n+\tprivate volatile Exception thrown = null;\n+\tprivate volatile boolean wasClosed = false;\n+\n+\tChannelStateWriteRequestExecutorImpl(ChannelStateWriteRequestDispatcher dispatcher) {\n+\t\tthis(dispatcher, new LinkedBlockingDeque<>(DEFAULT_HANDOVER_CAPACITY));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAwODY1OQ==", "bodyText": "Since we encountered a hard error in Flink, there is no way to proceed and I'd probably also switch checkArgument to checkState.", "url": "https://github.com/apache/flink/pull/11515#discussion_r405008659", "createdAt": "2020-04-07T18:03:54Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has by default\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ * Thread-safety: this class is thread-safe when used with a thread-safe {@link ChannelStateWriteRequestExecutor executor}\n+ * (e.g. default {@link ChannelStateWriteRequestExecutorImpl}.\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate final ChannelStateWriteRequestExecutor executor;\n+\tprivate final ConcurrentMap<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.\n+\t */\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryResolver) {\n+\t\tthis(streamFactoryResolver, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link ChannelStateSerializerImpl default} {@link ChannelStateSerializer},\n+\t * and a {@link ChannelStateWriteRequestExecutorImpl}.\n+\t *\n+\t * @param maxCheckpoints        maximum number of checkpoints to be written currently or finished but not taken yet.\n+\t * @param streamFactoryResolver a factory to obtain output stream factory for a given checkpoint\n+\t */\n+\tChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryResolver, int maxCheckpoints) {\n+\t\tthis(\n+\t\t\tnew ConcurrentHashMap<>(maxCheckpoints),\n+\t\t\tnew ChannelStateWriteRequestExecutorImpl(new ChannelStateWriteRequestDispatcherImpl(streamFactoryResolver, new ChannelStateSerializerImpl())),\n+\t\t\tmaxCheckpoints\n+\t\t);\n+\t}\n+\n+\tChannelStateWriterImpl(ConcurrentMap<Long, ChannelStateWriteResult> results, ChannelStateWriteRequestExecutor executor, int maxCheckpoints) {\n+\t\tthis.results = results;\n+\t\tthis.maxCheckpoints = maxCheckpoints;\n+\t\tthis.executor = executor;\n+\t}\n+\n+\t@Override\n+\tpublic void start(long checkpointId, CheckpointOptions checkpointOptions) {\n+\t\tLOG.debug(\"start checkpoint {} ({})\", checkpointId, checkpointOptions);\n+\t\tChannelStateWriteResult result = new ChannelStateWriteResult();\n+\t\tChannelStateWriteResult put = results.computeIfAbsent(checkpointId, id -> {\n+\t\t\tPreconditions.checkState(results.size() < maxCheckpoints, \"results.size() > maxCheckpoints\", results.size(), maxCheckpoints);\n+\t\t\tenqueue(new CheckpointStartRequest(checkpointId, result, checkpointOptions.getTargetLocation()), false);\n+\t\t\treturn result;\n+\t\t});\n+\t\tPreconditions.checkArgument(put == result, \"result future already present for checkpoint id: \" + checkpointId);\n+\t}\n+\n+\t@Override\n+\tpublic void addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add input data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)), false);\n+\t}\n+\n+\t@Override\n+\tpublic void addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add output data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)), false);\n+\t}\n+\n+\t@Override\n+\tpublic void finishInput(long checkpointId) {\n+\t\tLOG.debug(\"finish input data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeInput(checkpointId), false);\n+\t}\n+\n+\t@Override\n+\tpublic void finishOutput(long checkpointId) {\n+\t\tLOG.debug(\"finish output data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeOutput(checkpointId), false);\n+\t}\n+\n+\t@Override\n+\tpublic void abort(long checkpointId, Throwable cause) {\n+\t\tLOG.debug(\"abort, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(ChannelStateWriteRequest.abort(checkpointId, cause), true); // abort already started\n+\t\tenqueue(ChannelStateWriteRequest.abort(checkpointId, cause), false); // abort enqueued but not started\n+\t}\n+\n+\t@Override\n+\tpublic ChannelStateWriteResult getWriteResult(long checkpointId) {\n+\t\tLOG.debug(\"requested write result, checkpoint id: {}\", checkpointId);\n+\t\tChannelStateWriteResult result = results.remove(checkpointId);\n+\t\tPreconditions.checkArgument(result != null, \"channel state write result not found for checkpoint id \" + checkpointId);\n+\t\treturn result;\n+\t}\n+\n+\tpublic void open() {\n+\t\texecutor.start();\n+\t}\n+\n+\t@Override\n+\tpublic void close() throws IOException {\n+\t\tresults.clear();\n+\t\texecutor.close();\n+\t}\n+\n+\tprivate void enqueue(ChannelStateWriteRequest request, boolean atTheFront) {\n+\t\t// state check and previous errors check are performed inside the worker\n+\t\ttry {\n+\t\t\tif (atTheFront) {\n+\t\t\t\texecutor.submitPriority(request);\n+\t\t\t} else {\n+\t\t\t\texecutor.submit(request);\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\trequest.cancel(e);\n+\t\t\tthrow new RuntimeException(\"unable to send request to worker\", e);\n+\t\t}\n+\t}\n+\n+\tprivate static Buffer[] checkBufferType(Buffer... data) {\n+\t\tif (data == null) {\n+\t\t\treturn new Buffer[0];\n+\t\t}\n+\t\ttry {\n+\t\t\tfor (Buffer buffer : data) {\n+\t\t\t\tPreconditions.checkArgument(buffer.isBuffer());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 173}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAwOTg4Mw==", "bodyText": "See my previous comment on suppressions.", "url": "https://github.com/apache/flink/pull/11515#discussion_r405009883", "createdAt": "2020-04-07T18:05:59Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestExecutorImplTest.java", "diffHunk": "@@ -0,0 +1,203 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.function.BiConsumerWithException;\n+\n+import org.junit.Test;\n+\n+import javax.annotation.Nonnull;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.concurrent.LinkedBlockingDeque;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequestDispatcher.NO_OP;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * {@link ChannelStateWriteRequestExecutorImpl} test.\n+ */\n+public class ChannelStateWriteRequestExecutorImplTest {\n+\n+\t@Test(expected = IllegalStateException.class)\n+\tpublic void testCloseAfterSubmit() throws Exception {\n+\t\ttestCloseAfterSubmit(ChannelStateWriteRequestExecutor::submit);\n+\t}\n+\n+\t@Test(expected = IllegalStateException.class)\n+\tpublic void testCloseAfterSubmitPriority() throws Exception {\n+\t\ttestCloseAfterSubmit(ChannelStateWriteRequestExecutor::submitPriority);\n+\t}\n+\n+\t@Test\n+\tpublic void testSubmitFailure() throws Exception {\n+\t\ttestSubmitFailure(ChannelStateWriteRequestExecutor::submit);\n+\t}\n+\n+\t@Test\n+\tpublic void testSubmitPriorityFailure() throws Exception {\n+\t\ttestSubmitFailure(ChannelStateWriteRequestExecutor::submitPriority);\n+\t}\n+\n+\tprivate void testCloseAfterSubmit(BiConsumerWithException<ChannelStateWriteRequestExecutor, ChannelStateWriteRequest, Exception> requestFun) throws Exception {\n+\t\tWorkerClosingDeque closingDeque = new WorkerClosingDeque();\n+\t\tChannelStateWriteRequestExecutorImpl worker = new ChannelStateWriteRequestExecutorImpl(NO_OP, closingDeque);\n+\t\tclosingDeque.setWorker(worker);\n+\t\tTestWriteRequest request = new TestWriteRequest();\n+\t\trequestFun.accept(worker, request);\n+\t\tassertTrue(closingDeque.isEmpty());\n+\t\tassertFalse(request.isCancelled());\n+\t}\n+\n+\tprivate void testSubmitFailure(BiConsumerWithException<ChannelStateWriteRequestExecutor, ChannelStateWriteRequest, Exception> submitAction) throws Exception {\n+\t\tTestWriteRequest request = new TestWriteRequest();\n+\t\tLinkedBlockingDeque<ChannelStateWriteRequest> deque = new LinkedBlockingDeque<>();\n+\t\ttry {\n+\t\t\tsubmitAction.accept(new ChannelStateWriteRequestExecutorImpl(NO_OP, deque), request);\n+\t\t} catch (IllegalStateException e) {\n+\t\t\t// expected: executor not started;\n+\t\t\treturn;\n+\t\t} finally {\n+\t\t\tassertTrue(request.cancelled);\n+\t\t\tassertTrue(deque.isEmpty());\n+\t\t}\n+\t\tthrow new RuntimeException(\"expected exception not thrown\");\n+\t}\n+\n+\t@Test\n+\t@SuppressWarnings(\"CallToThreadRun\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 86}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAxMDYzMA==", "bodyText": "Now this should be a real suppression ;)", "url": "https://github.com/apache/flink/pull/11515#discussion_r405010630", "createdAt": "2020-04-07T18:07:16Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/state/ChannelPersistenceITCase.java", "diffHunk": "@@ -0,0 +1,179 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.state;\n+\n+import org.apache.flink.core.memory.HeapMemorySegment;\n+import org.apache.flink.core.memory.MemorySegment;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.StateObjectCollection;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReaderImpl;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriterImpl;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.checkpoint.channel.ResultSubpartitionInfo;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.memory.NonPersistentMetadataCheckpointStorageLocation;\n+import org.apache.flink.util.function.BiFunctionWithException;\n+\n+import org.junit.Test;\n+\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.stream.Collectors;\n+\n+import static java.util.Collections.singletonMap;\n+import static org.apache.flink.runtime.checkpoint.CheckpointType.CHECKPOINT;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.SEQUENCE_NUMBER_UNKNOWN;\n+import static org.apache.flink.util.Preconditions.checkState;\n+import static org.junit.Assert.assertArrayEquals;\n+\n+/**\n+ * ChannelPersistenceITCase.\n+ */\n+public class ChannelPersistenceITCase {\n+\tprivate static final Random RANDOM = new Random(System.currentTimeMillis());\n+\n+\t@Test\n+\tpublic void testReadWritten() throws Exception {\n+\t\tlong checkpointId = 1L;\n+\n+\t\tInputChannelInfo inputChannelInfo = new InputChannelInfo(2, 3);\n+\t\tbyte[] inputChannelInfoData = randomBytes(1024);\n+\n+\t\tResultSubpartitionInfo resultSubpartitionInfo = new ResultSubpartitionInfo(4, 5);\n+\t\tbyte[] resultSubpartitionInfoData = randomBytes(1024);\n+\n+\t\tChannelStateWriteResult handles = write(\n+\t\t\tcheckpointId,\n+\t\t\tsingletonMap(inputChannelInfo, inputChannelInfoData),\n+\t\t\tsingletonMap(resultSubpartitionInfo, resultSubpartitionInfoData)\n+\t\t);\n+\n+\t\tassertArrayEquals(inputChannelInfoData, read(\n+\t\t\ttoTaskStateSnapshot(handles),\n+\t\t\tinputChannelInfoData.length,\n+\t\t\t(reader, mem) -> reader.readInputData(inputChannelInfo, new NetworkBuffer(mem, FreeingBufferRecycler.INSTANCE))\n+\t\t));\n+\n+\t\tassertArrayEquals(resultSubpartitionInfoData, read(\n+\t\t\ttoTaskStateSnapshot(handles),\n+\t\t\tresultSubpartitionInfoData.length,\n+\t\t\t(reader, mem) -> reader.readOutputData(resultSubpartitionInfo, new BufferBuilder(mem, FreeingBufferRecycler.INSTANCE))\n+\t\t));\n+\t}\n+\n+\tprivate byte[] randomBytes(int size) {\n+\t\tbyte[] bytes = new byte[size];\n+\t\tRANDOM.nextBytes(bytes);\n+\t\treturn bytes;\n+\t}\n+\n+\tprivate ChannelStateWriteResult write(long checkpointId, Map<InputChannelInfo, byte[]> icMap, Map<ResultSubpartitionInfo, byte[]> rsMap) throws Exception {\n+\t\tint maxStateSize = sizeOfBytes(icMap) + sizeOfBytes(rsMap) + Long.BYTES * 2;\n+\t\tMap<InputChannelInfo, Buffer> icBuffers = wrapWithBuffers(icMap);\n+\t\tMap<ResultSubpartitionInfo, Buffer> rsBuffers = wrapWithBuffers(rsMap);\n+\t\ttry (ChannelStateWriterImpl writer = new ChannelStateWriterImpl(getStreamFactoryFactory(maxStateSize))) {\n+\t\t\twriter.open();\n+\t\t\twriter.start(checkpointId, new CheckpointOptions(CHECKPOINT, new CheckpointStorageLocationReference(\"poly\".getBytes())));\n+\t\t\tfor (Map.Entry<InputChannelInfo, Buffer> e : icBuffers.entrySet()) {\n+\t\t\t\twriter.addInputData(checkpointId, e.getKey(), SEQUENCE_NUMBER_UNKNOWN, e.getValue());\n+\t\t\t}\n+\t\t\twriter.finishInput(checkpointId);\n+\t\t\tfor (Map.Entry<ResultSubpartitionInfo, Buffer> e : rsBuffers.entrySet()) {\n+\t\t\t\twriter.addOutputData(checkpointId, e.getKey(), SEQUENCE_NUMBER_UNKNOWN, e.getValue());\n+\t\t\t}\n+\t\t\twriter.finishOutput(checkpointId);\n+\t\t\tChannelStateWriteResult result = writer.getWriteResult(checkpointId);\n+\t\t\tresult.getResultSubpartitionStateHandles().join(); // prevent abnormal complete in close\n+\t\t\treturn result;\n+\t\t}\n+\t}\n+\n+\tpublic static CheckpointStorageWorkerView getStreamFactoryFactory() {\n+\t\treturn getStreamFactoryFactory(42);\n+\t}\n+\n+\tpublic static CheckpointStorageWorkerView getStreamFactoryFactory(int maxStateSize) {\n+\t\treturn new CheckpointStorageWorkerView() {\n+\t\t\t@Override\n+\t\t\tpublic CheckpointStreamFactory resolveCheckpointStorageLocation(long checkpointId, CheckpointStorageLocationReference reference) {\n+\t\t\t\treturn new NonPersistentMetadataCheckpointStorageLocation(maxStateSize);\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic CheckpointStreamFactory.CheckpointStateOutputStream createTaskOwnedStateStream() {\n+\t\t\t\tthrow new UnsupportedOperationException();\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tprivate byte[] read(TaskStateSnapshot taskStateSnapshot, int size, BiFunctionWithException<ChannelStateReader, MemorySegment, ReadResult, Exception> readFn) throws Exception {\n+\t\tbyte[] dst = new byte[size];\n+\t\tHeapMemorySegment mem = HeapMemorySegment.FACTORY.wrap(dst);\n+\t\ttry {\n+\t\t\tcheckState(NO_MORE_DATA == readFn.apply(new ChannelStateReaderImpl(taskStateSnapshot), mem));\n+\t\t} finally {\n+\t\t\tmem.free();\n+\t\t}\n+\t\treturn dst;\n+\t}\n+\n+\tprivate TaskStateSnapshot toTaskStateSnapshot(ChannelStateWriteResult t) throws Exception {\n+\t\treturn new TaskStateSnapshot(singletonMap(new OperatorID(),\n+\t\t\tnew OperatorSubtaskState(\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tnew StateObjectCollection<>(t.getInputChannelStateHandles().get()),\n+\t\t\t\tnew StateObjectCollection<>(t.getResultSubpartitionStateHandles().get())\n+\t\t\t)\n+\t\t));\n+\t}\n+\n+\tprivate <C> List<C> collect(Collection<StateObject> handles, Class<C> clazz) {\n+\t\t//noinspection unchecked", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 161}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAxMDg0OA==", "bodyText": "you should decide on empty line or not?", "url": "https://github.com/apache/flink/pull/11515#discussion_r405010848", "createdAt": "2020-04-07T18:07:37Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/state/ChannelPersistenceITCase.java", "diffHunk": "@@ -0,0 +1,179 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.state;\n+\n+import org.apache.flink.core.memory.HeapMemorySegment;\n+import org.apache.flink.core.memory.MemorySegment;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.StateObjectCollection;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReaderImpl;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriterImpl;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.checkpoint.channel.ResultSubpartitionInfo;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.memory.NonPersistentMetadataCheckpointStorageLocation;\n+import org.apache.flink.util.function.BiFunctionWithException;\n+\n+import org.junit.Test;\n+\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.stream.Collectors;\n+\n+import static java.util.Collections.singletonMap;\n+import static org.apache.flink.runtime.checkpoint.CheckpointType.CHECKPOINT;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.SEQUENCE_NUMBER_UNKNOWN;\n+import static org.apache.flink.util.Preconditions.checkState;\n+import static org.junit.Assert.assertArrayEquals;\n+\n+/**\n+ * ChannelPersistenceITCase.\n+ */\n+public class ChannelPersistenceITCase {\n+\tprivate static final Random RANDOM = new Random(System.currentTimeMillis());\n+\n+\t@Test\n+\tpublic void testReadWritten() throws Exception {\n+\t\tlong checkpointId = 1L;\n+\n+\t\tInputChannelInfo inputChannelInfo = new InputChannelInfo(2, 3);\n+\t\tbyte[] inputChannelInfoData = randomBytes(1024);\n+\n+\t\tResultSubpartitionInfo resultSubpartitionInfo = new ResultSubpartitionInfo(4, 5);\n+\t\tbyte[] resultSubpartitionInfoData = randomBytes(1024);\n+\n+\t\tChannelStateWriteResult handles = write(\n+\t\t\tcheckpointId,\n+\t\t\tsingletonMap(inputChannelInfo, inputChannelInfoData),\n+\t\t\tsingletonMap(resultSubpartitionInfo, resultSubpartitionInfoData)\n+\t\t);\n+\n+\t\tassertArrayEquals(inputChannelInfoData, read(\n+\t\t\ttoTaskStateSnapshot(handles),\n+\t\t\tinputChannelInfoData.length,\n+\t\t\t(reader, mem) -> reader.readInputData(inputChannelInfo, new NetworkBuffer(mem, FreeingBufferRecycler.INSTANCE))\n+\t\t));\n+\n+\t\tassertArrayEquals(resultSubpartitionInfoData, read(\n+\t\t\ttoTaskStateSnapshot(handles),\n+\t\t\tresultSubpartitionInfoData.length,\n+\t\t\t(reader, mem) -> reader.readOutputData(resultSubpartitionInfo, new BufferBuilder(mem, FreeingBufferRecycler.INSTANCE))\n+\t\t));\n+\t}\n+\n+\tprivate byte[] randomBytes(int size) {\n+\t\tbyte[] bytes = new byte[size];\n+\t\tRANDOM.nextBytes(bytes);\n+\t\treturn bytes;\n+\t}\n+\n+\tprivate ChannelStateWriteResult write(long checkpointId, Map<InputChannelInfo, byte[]> icMap, Map<ResultSubpartitionInfo, byte[]> rsMap) throws Exception {\n+\t\tint maxStateSize = sizeOfBytes(icMap) + sizeOfBytes(rsMap) + Long.BYTES * 2;\n+\t\tMap<InputChannelInfo, Buffer> icBuffers = wrapWithBuffers(icMap);\n+\t\tMap<ResultSubpartitionInfo, Buffer> rsBuffers = wrapWithBuffers(rsMap);\n+\t\ttry (ChannelStateWriterImpl writer = new ChannelStateWriterImpl(getStreamFactoryFactory(maxStateSize))) {\n+\t\t\twriter.open();\n+\t\t\twriter.start(checkpointId, new CheckpointOptions(CHECKPOINT, new CheckpointStorageLocationReference(\"poly\".getBytes())));\n+\t\t\tfor (Map.Entry<InputChannelInfo, Buffer> e : icBuffers.entrySet()) {\n+\t\t\t\twriter.addInputData(checkpointId, e.getKey(), SEQUENCE_NUMBER_UNKNOWN, e.getValue());\n+\t\t\t}\n+\t\t\twriter.finishInput(checkpointId);\n+\t\t\tfor (Map.Entry<ResultSubpartitionInfo, Buffer> e : rsBuffers.entrySet()) {\n+\t\t\t\twriter.addOutputData(checkpointId, e.getKey(), SEQUENCE_NUMBER_UNKNOWN, e.getValue());\n+\t\t\t}\n+\t\t\twriter.finishOutput(checkpointId);\n+\t\t\tChannelStateWriteResult result = writer.getWriteResult(checkpointId);\n+\t\t\tresult.getResultSubpartitionStateHandles().join(); // prevent abnormal complete in close\n+\t\t\treturn result;\n+\t\t}\n+\t}\n+\n+\tpublic static CheckpointStorageWorkerView getStreamFactoryFactory() {\n+\t\treturn getStreamFactoryFactory(42);\n+\t}\n+\n+\tpublic static CheckpointStorageWorkerView getStreamFactoryFactory(int maxStateSize) {\n+\t\treturn new CheckpointStorageWorkerView() {\n+\t\t\t@Override\n+\t\t\tpublic CheckpointStreamFactory resolveCheckpointStorageLocation(long checkpointId, CheckpointStorageLocationReference reference) {\n+\t\t\t\treturn new NonPersistentMetadataCheckpointStorageLocation(maxStateSize);\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic CheckpointStreamFactory.CheckpointStateOutputStream createTaskOwnedStateStream() {\n+\t\t\t\tthrow new UnsupportedOperationException();\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tprivate byte[] read(TaskStateSnapshot taskStateSnapshot, int size, BiFunctionWithException<ChannelStateReader, MemorySegment, ReadResult, Exception> readFn) throws Exception {\n+\t\tbyte[] dst = new byte[size];\n+\t\tHeapMemorySegment mem = HeapMemorySegment.FACTORY.wrap(dst);\n+\t\ttry {\n+\t\t\tcheckState(NO_MORE_DATA == readFn.apply(new ChannelStateReaderImpl(taskStateSnapshot), mem));\n+\t\t} finally {\n+\t\t\tmem.free();\n+\t\t}\n+\t\treturn dst;\n+\t}\n+\n+\tprivate TaskStateSnapshot toTaskStateSnapshot(ChannelStateWriteResult t) throws Exception {\n+\t\treturn new TaskStateSnapshot(singletonMap(new OperatorID(),\n+\t\t\tnew OperatorSubtaskState(\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tnew StateObjectCollection<>(t.getInputChannelStateHandles().get()),\n+\t\t\t\tnew StateObjectCollection<>(t.getResultSubpartitionStateHandles().get())\n+\t\t\t)\n+\t\t));\n+\t}\n+\n+\tprivate <C> List<C> collect(Collection<StateObject> handles, Class<C> clazz) {\n+\t\t//noinspection unchecked\n+\t\treturn handles.stream().filter(clazz::isInstance).map(h -> (C) h).collect(Collectors.toList());\n+\t}\n+\n+\tprivate static int sizeOfBytes(Map<?, byte[]> map) {\n+\t\treturn map.values().stream().mapToInt(d -> d.length).sum();\n+\t}\n+\n+\tprivate <K> Map<K, Buffer> wrapWithBuffers(Map<K, byte[]> icMap) {\n+\t\treturn icMap.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey, e -> wrapWithBuffer(e.getValue())));\n+\t}\n+\n+\tprivate static Buffer wrapWithBuffer(byte[] data) {\n+\t\tNetworkBuffer buffer = new NetworkBuffer(HeapMemorySegment.FACTORY.allocateUnpooledSegment(data.length, null), FreeingBufferRecycler.INSTANCE);\n+\t\tbuffer.writeBytes(data);\n+\t\treturn buffer;\n+\t}\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 178}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAxMjM1Mw==", "bodyText": "Usually, we don't want to push TODOs into master, but I can see that it has some value. On the other hand, it should be quite easy to find when actually adding unaligned checkpoints.", "url": "https://github.com/apache/flink/pull/11515#discussion_r405012353", "createdAt": "2020-04-07T18:10:09Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamTask.java", "diffHunk": "@@ -277,7 +277,8 @@ protected StreamTask(\n \t\t\tgetCancelables(),\n \t\t\tgetAsyncOperationsThreadPool(),\n \t\t\tgetEnvironment(),\n-\t\t\tthis);\n+\t\t\tthis,\n+\t\t\tfalse); // todo: pass true if unaligned checkpoints enabled", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bdb06fc00a0da1e0c3df87383de8ebb0a28b1ef3"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAxNTkwMw==", "bodyText": "This looks a bit suspicious. Do we actually need a dedicated open or could we open it in the constructor already. Maybe it would allow us to have more final fields?", "url": "https://github.com/apache/flink/pull/11515#discussion_r405015903", "createdAt": "2020-04-07T18:16:14Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -55,20 +68,33 @@\n \t\t\tCloseableRegistry closeableRegistry,\n \t\t\tExecutorService executorService,\n \t\t\tEnvironment env,\n-\t\t\tAsyncExceptionHandler asyncExceptionHandler) {\n-\t\tthis.checkpointStorage = checkNotNull(checkpointStorage);\n+\t\t\tAsyncExceptionHandler asyncExceptionHandler,\n+\t\t\tboolean sendChannelState) throws IOException {\n+\t\tthis.checkpointStorage = new CachingCheckpointStorageWorkerView(checkNotNull(checkpointStorage));\n \t\tthis.taskName = checkNotNull(taskName);\n \t\tthis.closeableRegistry = checkNotNull(closeableRegistry);\n \t\tthis.executorService = checkNotNull(executorService);\n \t\tthis.env = checkNotNull(env);\n \t\tthis.asyncExceptionHandler = checkNotNull(asyncExceptionHandler);\n \t\tthis.actionExecutor = actionExecutor;\n+\t\tthis.channelStateWriter = sendChannelState ? openChannelStateWriter() : ChannelStateWriter.NO_OP;\n+\t\tthis.closeableRegistry.registerCloseable(this);\n+\t}\n+\n+\tprivate ChannelStateWriterImpl openChannelStateWriter() {\n+\t\tChannelStateWriterImpl writer = new ChannelStateWriterImpl(this.checkpointStorage);\n+\t\twriter.open();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bdb06fc00a0da1e0c3df87383de8ebb0a28b1ef3"}, "originalPosition": 67}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg5NjQwODg2", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-389640886", "createdAt": "2020-04-08T04:14:10Z", "commit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNDoxNDoxMFrOGCeYDg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNDoxNDoxMFrOGCeYDg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTI0ODAxNA==", "bodyText": "nit: too long line", "url": "https://github.com/apache/flink/pull/11515#discussion_r405248014", "createdAt": "2020-04-08T04:14:10Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequest.java", "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageLocationReference;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.ThrowingConsumer;\n+\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+\n+interface ChannelStateWriteRequest {\n+\tlong getCheckpointId();\n+\n+\tvoid cancel(Throwable cause);\n+\n+\tstatic CheckpointInProgressRequest completeInput(long checkpointId) {\n+\t\treturn new CheckpointInProgressRequest(\"completeInput\", checkpointId, ChannelStateCheckpointWriter::completeInput, false);\n+\t}\n+\n+\tstatic CheckpointInProgressRequest completeOutput(long checkpointId) {\n+\t\treturn new CheckpointInProgressRequest(\"completeOutput\", checkpointId, ChannelStateCheckpointWriter::completeOutput, false);\n+\t}\n+\n+\tstatic ChannelStateWriteRequest write(long checkpointId, InputChannelInfo info, Buffer... flinkBuffers) {\n+\t\treturn new CheckpointInProgressRequest(\"writeInput\", checkpointId, writer -> writer.writeInput(info, flinkBuffers), recycle(flinkBuffers), false);\n+\t}\n+\n+\tstatic ChannelStateWriteRequest write(long checkpointId, ResultSubpartitionInfo info, Buffer... flinkBuffers) {\n+\t\treturn new CheckpointInProgressRequest(\"writeOutput\", checkpointId, writer -> writer.writeOutput(info, flinkBuffers), recycle(flinkBuffers), false);\n+\t}\n+\n+\tstatic ChannelStateWriteRequest start(long checkpointId, ChannelStateWriteResult targetResult, CheckpointStorageLocationReference locationReference) {\n+\t\treturn new CheckpointStartRequest(checkpointId, targetResult, locationReference);\n+\t}\n+\n+\tstatic ChannelStateWriteRequest abort(long checkpointId, Throwable cause) {\n+\t\treturn new CheckpointInProgressRequest(\"abort\", checkpointId, writer -> writer.fail(cause), true);\n+\t}\n+\n+\tstatic Consumer<Throwable> recycle(Buffer[] flinkBuffers) {\n+\t\treturn unused -> {\n+\t\t\tfor (Buffer b : flinkBuffers) {\n+\t\t\t\tb.recycleBuffer();\n+\t\t\t}\n+\t\t};\n+\t}\n+}\n+\n+final class CheckpointStartRequest implements ChannelStateWriteRequest {\n+\tprivate final ChannelStateWriteResult targetResult;\n+\tprivate final CheckpointStorageLocationReference locationReference;\n+\tprivate final long checkpointId;\n+\n+\tCheckpointStartRequest(long checkpointId, ChannelStateWriteResult targetResult, CheckpointStorageLocationReference locationReference) {\n+\t\tthis.checkpointId = checkpointId;\n+\t\tthis.targetResult = targetResult;\n+\t\tthis.locationReference = locationReference;\n+\t}\n+\n+\t@Override\n+\tpublic long getCheckpointId() {\n+\t\treturn checkpointId;\n+\t}\n+\n+\tChannelStateWriteResult getTargetResult() {\n+\t\treturn targetResult;\n+\t}\n+\n+\tpublic CheckpointStorageLocationReference getLocationReference() {\n+\t\treturn locationReference;\n+\t}\n+\n+\t@Override\n+\tpublic void cancel(Throwable cause) {\n+\t\ttargetResult.fail(cause);\n+\t}\n+\n+\t@Override\n+\tpublic String toString() {\n+\t\treturn \"start \" + checkpointId;\n+\t}\n+}\n+\n+final class CheckpointInProgressRequest implements ChannelStateWriteRequest {\n+\tprivate final ThrowingConsumer<ChannelStateCheckpointWriter, Exception> action;\n+\tprivate final Consumer<Throwable> discardAction;\n+\tprivate final long checkpointId;\n+\tprivate final String name;\n+\tprivate final boolean ignoreMissingWriter;\n+\tprivate final AtomicReference<CheckpointInProgressRequestState> state = new AtomicReference<>(CheckpointInProgressRequestState.NEW);\n+\n+\tCheckpointInProgressRequest(String name, long checkpointId, ThrowingConsumer<ChannelStateCheckpointWriter, Exception> action, boolean ignoreMissingWriter) {\n+\t\tthis(name, checkpointId, action, unused -> {\n+\t\t}, ignoreMissingWriter);\n+\t}\n+\n+\tCheckpointInProgressRequest(String name, long checkpointId, ThrowingConsumer<ChannelStateCheckpointWriter, Exception> action, Consumer<Throwable> discardAction, boolean ignoreMissingWriter) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 115}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg5NjUwMjk1", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-389650295", "createdAt": "2020-04-08T04:50:44Z", "commit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNDo1MDo0NFrOGCe5bA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNDo1MDo0NFrOGCe5bA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTI1NjU1Ng==", "bodyText": "I have three concerns with the cancel:\n\n\nIn CheckpointStartRequest#cancel, the targetResult.fail(cause) would be executed. For the case of CheckpointInProgressRequest, do we also need to complete the future with failure?\n\n\n#cancel is only valid to perform before executing #execute method because of the limitation of state condition, although #cancel is still triggered while performing #execute to cause any exceptions. Is it considered by design?\n\n\nI guess the introduction of state was mainly for voiding cancelling multiple times, because #execute can not be called more than once in practice. If so, maybe it is not necessary to bring in so many state values, only need one isCancelled state.", "url": "https://github.com/apache/flink/pull/11515#discussion_r405256556", "createdAt": "2020-04-08T04:50:44Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequest.java", "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageLocationReference;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.ThrowingConsumer;\n+\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+\n+interface ChannelStateWriteRequest {\n+\tlong getCheckpointId();\n+\n+\tvoid cancel(Throwable cause);\n+\n+\tstatic CheckpointInProgressRequest completeInput(long checkpointId) {\n+\t\treturn new CheckpointInProgressRequest(\"completeInput\", checkpointId, ChannelStateCheckpointWriter::completeInput, false);\n+\t}\n+\n+\tstatic CheckpointInProgressRequest completeOutput(long checkpointId) {\n+\t\treturn new CheckpointInProgressRequest(\"completeOutput\", checkpointId, ChannelStateCheckpointWriter::completeOutput, false);\n+\t}\n+\n+\tstatic ChannelStateWriteRequest write(long checkpointId, InputChannelInfo info, Buffer... flinkBuffers) {\n+\t\treturn new CheckpointInProgressRequest(\"writeInput\", checkpointId, writer -> writer.writeInput(info, flinkBuffers), recycle(flinkBuffers), false);\n+\t}\n+\n+\tstatic ChannelStateWriteRequest write(long checkpointId, ResultSubpartitionInfo info, Buffer... flinkBuffers) {\n+\t\treturn new CheckpointInProgressRequest(\"writeOutput\", checkpointId, writer -> writer.writeOutput(info, flinkBuffers), recycle(flinkBuffers), false);\n+\t}\n+\n+\tstatic ChannelStateWriteRequest start(long checkpointId, ChannelStateWriteResult targetResult, CheckpointStorageLocationReference locationReference) {\n+\t\treturn new CheckpointStartRequest(checkpointId, targetResult, locationReference);\n+\t}\n+\n+\tstatic ChannelStateWriteRequest abort(long checkpointId, Throwable cause) {\n+\t\treturn new CheckpointInProgressRequest(\"abort\", checkpointId, writer -> writer.fail(cause), true);\n+\t}\n+\n+\tstatic Consumer<Throwable> recycle(Buffer[] flinkBuffers) {\n+\t\treturn unused -> {\n+\t\t\tfor (Buffer b : flinkBuffers) {\n+\t\t\t\tb.recycleBuffer();\n+\t\t\t}\n+\t\t};\n+\t}\n+}\n+\n+final class CheckpointStartRequest implements ChannelStateWriteRequest {\n+\tprivate final ChannelStateWriteResult targetResult;\n+\tprivate final CheckpointStorageLocationReference locationReference;\n+\tprivate final long checkpointId;\n+\n+\tCheckpointStartRequest(long checkpointId, ChannelStateWriteResult targetResult, CheckpointStorageLocationReference locationReference) {\n+\t\tthis.checkpointId = checkpointId;\n+\t\tthis.targetResult = targetResult;\n+\t\tthis.locationReference = locationReference;\n+\t}\n+\n+\t@Override\n+\tpublic long getCheckpointId() {\n+\t\treturn checkpointId;\n+\t}\n+\n+\tChannelStateWriteResult getTargetResult() {\n+\t\treturn targetResult;\n+\t}\n+\n+\tpublic CheckpointStorageLocationReference getLocationReference() {\n+\t\treturn locationReference;\n+\t}\n+\n+\t@Override\n+\tpublic void cancel(Throwable cause) {\n+\t\ttargetResult.fail(cause);\n+\t}\n+\n+\t@Override\n+\tpublic String toString() {\n+\t\treturn \"start \" + checkpointId;\n+\t}\n+}\n+\n+final class CheckpointInProgressRequest implements ChannelStateWriteRequest {\n+\tprivate final ThrowingConsumer<ChannelStateCheckpointWriter, Exception> action;\n+\tprivate final Consumer<Throwable> discardAction;\n+\tprivate final long checkpointId;\n+\tprivate final String name;\n+\tprivate final boolean ignoreMissingWriter;\n+\tprivate final AtomicReference<CheckpointInProgressRequestState> state = new AtomicReference<>(CheckpointInProgressRequestState.NEW);\n+\n+\tCheckpointInProgressRequest(String name, long checkpointId, ThrowingConsumer<ChannelStateCheckpointWriter, Exception> action, boolean ignoreMissingWriter) {\n+\t\tthis(name, checkpointId, action, unused -> {\n+\t\t}, ignoreMissingWriter);\n+\t}\n+\n+\tCheckpointInProgressRequest(String name, long checkpointId, ThrowingConsumer<ChannelStateCheckpointWriter, Exception> action, Consumer<Throwable> discardAction, boolean ignoreMissingWriter) {\n+\t\tthis.checkpointId = checkpointId;\n+\t\tthis.action = action;\n+\t\tthis.discardAction = discardAction;\n+\t\tthis.name = name;\n+\t\tthis.ignoreMissingWriter = ignoreMissingWriter;\n+\t}\n+\n+\t@Override\n+\tpublic long getCheckpointId() {\n+\t\treturn checkpointId;\n+\t}\n+\n+\t@Override\n+\tpublic void cancel(Throwable cause) {\n+\t\tif (state.compareAndSet(CheckpointInProgressRequestState.NEW, CheckpointInProgressRequestState.CANCELLED)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 130}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg5NjU3Mzkz", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-389657393", "createdAt": "2020-04-08T05:15:48Z", "commit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNToxNTo0OFrOGCfRhQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNToxNTo0OFrOGCfRhQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTI2MjcyNQ==", "bodyText": "If the thread is still alive, do we also need to Thread.currentThread().interrupt()?", "url": "https://github.com/apache/flink/pull/11515#discussion_r405262725", "createdAt": "2020-04-08T05:15:48Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestExecutorImpl.java", "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.BlockingDeque;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.LinkedBlockingDeque;\n+\n+/**\n+ * Executes {@link ChannelStateWriteRequest}s in a separate thread. Any exception occurred during execution causes this\n+ * thread to stop and the exception to be re-thrown on any subsequent call.\n+ */\n+@ThreadSafe\n+class ChannelStateWriteRequestExecutorImpl implements ChannelStateWriteRequestExecutor {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriteRequestExecutorImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10_000;\n+\n+\tprivate final ChannelStateWriteRequestDispatcher dispatcher;\n+\tprivate final BlockingDeque<ChannelStateWriteRequest> deque;\n+\tprivate final Thread thread;\n+\tprivate volatile Exception thrown = null;\n+\tprivate volatile boolean wasClosed = false;\n+\n+\tChannelStateWriteRequestExecutorImpl(ChannelStateWriteRequestDispatcher dispatcher) {\n+\t\tthis(dispatcher, new LinkedBlockingDeque<>(DEFAULT_HANDOVER_CAPACITY));\n+\t}\n+\n+\tChannelStateWriteRequestExecutorImpl(ChannelStateWriteRequestDispatcher dispatcher, BlockingDeque<ChannelStateWriteRequest> deque) {\n+\t\tthis.dispatcher = dispatcher;\n+\t\tthis.deque = deque;\n+\t\tthis.thread = new Thread(this::run);\n+\t\tthis.thread.setDaemon(true);\n+\t}\n+\n+\t@VisibleForTesting\n+\tvoid run() {\n+\t\ttry {\n+\t\t\tloop();\n+\t\t} catch (Exception ex) {\n+\t\t\tthrown = ex;\n+\t\t} finally {\n+\t\t\tcleanupRequests();\n+\t\t\tdispatcher.close(thrown == null ? new CancellationException() : thrown);\n+\t\t}\n+\t\tLOG.debug(\"loop terminated\");\n+\t}\n+\n+\tprivate void loop() throws Exception {\n+\t\twhile (isActive()) {\n+\t\t\ttry {\n+\t\t\t\tdispatcher.dispatch(deque.take());\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tif (isActive()) {\n+\t\t\t\t\tLOG.debug(\"interrupted while waiting for a request (continue waiting)\", e);\n+\t\t\t\t} else {\n+\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate void cleanupRequests() {\n+\t\tThrowable cause = thrown == null ? new CancellationException() : thrown;\n+\t\tList<ChannelStateWriteRequest> drained = new ArrayList<>();\n+\t\tdeque.drainTo(drained);\n+\t\tLOG.info(\"discarding {} drained requests\", drained.size());\n+\t\tfor (ChannelStateWriteRequest request : drained) {\n+\t\t\trequest.cancel(cause);\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void start() throws IllegalStateException {\n+\t\tthis.thread.start();\n+\t}\n+\n+\t@Override\n+\tpublic void submit(ChannelStateWriteRequest request) throws Exception {\n+\t\tsubmitInternal(request, () -> deque.add(request));\n+\t}\n+\n+\t@Override\n+\tpublic void submitPriority(ChannelStateWriteRequest request) throws Exception {\n+\t\tsubmitInternal(request, () -> deque.addFirst(request));\n+\t}\n+\n+\tprivate void submitInternal(ChannelStateWriteRequest request, RunnableWithException action) throws Exception {\n+\t\ttry {\n+\t\t\taction.run();\n+\t\t} catch (Exception ex) {\n+\t\t\trequest.cancel(ex);\n+\t\t\tthrow ex;\n+\t\t}\n+\t\tensureRunning();\n+\t}\n+\n+\tprivate void ensureRunning() throws Exception {\n+\t\t// this check should be performed *at least after* enqueuing a request\n+\t\t// checking before is not enough because (check + enqueue) is not atomic\n+\t\tif (!isActive()) {\n+\t\t\tcleanupRequests();\n+\t\t\tthrow ExceptionUtils.firstOrSuppressed(new IllegalStateException(\"not running\"), thrown);\n+\t\t}\n+\t}\n+\n+\tprivate boolean isActive() {\n+\t\treturn !wasClosed && thread.isAlive();\n+\t}\n+\n+\t@Override\n+\tpublic void close() throws IOException {\n+\t\twasClosed = true;\n+\t\twhile (thread.isAlive()) {\n+\t\t\tthread.interrupt();\n+\t\t\ttry {\n+\t\t\t\tthread.join();\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tif (!thread.isAlive()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 146}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg5NjY1OTIw", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-389665920", "createdAt": "2020-04-08T05:43:06Z", "commit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNTo0MzowNlrOGCfvDA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNTo0MzowNlrOGCfvDA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTI3MDI4NA==", "bodyText": "can we judge this condition only by thread.isAlive()? In some other cases if thread was ended not via #close() method by accident, it seems still make sense for the caller to make the decision.", "url": "https://github.com/apache/flink/pull/11515#discussion_r405270284", "createdAt": "2020-04-08T05:43:06Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestExecutorImpl.java", "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.BlockingDeque;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.LinkedBlockingDeque;\n+\n+/**\n+ * Executes {@link ChannelStateWriteRequest}s in a separate thread. Any exception occurred during execution causes this\n+ * thread to stop and the exception to be re-thrown on any subsequent call.\n+ */\n+@ThreadSafe\n+class ChannelStateWriteRequestExecutorImpl implements ChannelStateWriteRequestExecutor {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriteRequestExecutorImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10_000;\n+\n+\tprivate final ChannelStateWriteRequestDispatcher dispatcher;\n+\tprivate final BlockingDeque<ChannelStateWriteRequest> deque;\n+\tprivate final Thread thread;\n+\tprivate volatile Exception thrown = null;\n+\tprivate volatile boolean wasClosed = false;\n+\n+\tChannelStateWriteRequestExecutorImpl(ChannelStateWriteRequestDispatcher dispatcher) {\n+\t\tthis(dispatcher, new LinkedBlockingDeque<>(DEFAULT_HANDOVER_CAPACITY));\n+\t}\n+\n+\tChannelStateWriteRequestExecutorImpl(ChannelStateWriteRequestDispatcher dispatcher, BlockingDeque<ChannelStateWriteRequest> deque) {\n+\t\tthis.dispatcher = dispatcher;\n+\t\tthis.deque = deque;\n+\t\tthis.thread = new Thread(this::run);\n+\t\tthis.thread.setDaemon(true);\n+\t}\n+\n+\t@VisibleForTesting\n+\tvoid run() {\n+\t\ttry {\n+\t\t\tloop();\n+\t\t} catch (Exception ex) {\n+\t\t\tthrown = ex;\n+\t\t} finally {\n+\t\t\tcleanupRequests();\n+\t\t\tdispatcher.close(thrown == null ? new CancellationException() : thrown);\n+\t\t}\n+\t\tLOG.debug(\"loop terminated\");\n+\t}\n+\n+\tprivate void loop() throws Exception {\n+\t\twhile (isActive()) {\n+\t\t\ttry {\n+\t\t\t\tdispatcher.dispatch(deque.take());\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tif (isActive()) {\n+\t\t\t\t\tLOG.debug(\"interrupted while waiting for a request (continue waiting)\", e);\n+\t\t\t\t} else {\n+\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate void cleanupRequests() {\n+\t\tThrowable cause = thrown == null ? new CancellationException() : thrown;\n+\t\tList<ChannelStateWriteRequest> drained = new ArrayList<>();\n+\t\tdeque.drainTo(drained);\n+\t\tLOG.info(\"discarding {} drained requests\", drained.size());\n+\t\tfor (ChannelStateWriteRequest request : drained) {\n+\t\t\trequest.cancel(cause);\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void start() throws IllegalStateException {\n+\t\tthis.thread.start();\n+\t}\n+\n+\t@Override\n+\tpublic void submit(ChannelStateWriteRequest request) throws Exception {\n+\t\tsubmitInternal(request, () -> deque.add(request));\n+\t}\n+\n+\t@Override\n+\tpublic void submitPriority(ChannelStateWriteRequest request) throws Exception {\n+\t\tsubmitInternal(request, () -> deque.addFirst(request));\n+\t}\n+\n+\tprivate void submitInternal(ChannelStateWriteRequest request, RunnableWithException action) throws Exception {\n+\t\ttry {\n+\t\t\taction.run();\n+\t\t} catch (Exception ex) {\n+\t\t\trequest.cancel(ex);\n+\t\t\tthrow ex;\n+\t\t}\n+\t\tensureRunning();\n+\t}\n+\n+\tprivate void ensureRunning() throws Exception {\n+\t\t// this check should be performed *at least after* enqueuing a request\n+\t\t// checking before is not enough because (check + enqueue) is not atomic\n+\t\tif (!isActive()) {\n+\t\t\tcleanupRequests();\n+\t\t\tthrow ExceptionUtils.firstOrSuppressed(new IllegalStateException(\"not running\"), thrown);\n+\t\t}\n+\t}\n+\n+\tprivate boolean isActive() {\n+\t\treturn !wasClosed && thread.isAlive();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 135}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg5NjgyMTkx", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-389682191", "createdAt": "2020-04-08T06:24:29Z", "commit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNjoyNDoyOVrOGCgoFw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNjoyNDoyOVrOGCgoFw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTI4NDg4Nw==", "bodyText": "This can be done only via SubtaskCheckpointCoordinatorImpl#close, but i do not see StreamTask or other places will call SubtaskCheckpointCoordinatorImpl#close from the current codes. What is the consideration for this?", "url": "https://github.com/apache/flink/pull/11515#discussion_r405284887", "createdAt": "2020-04-08T06:24:29Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has by default\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ * Thread-safety: this class is thread-safe when used with a thread-safe {@link ChannelStateWriteRequestExecutor executor}\n+ * (e.g. default {@link ChannelStateWriteRequestExecutorImpl}.\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate final ChannelStateWriteRequestExecutor executor;\n+\tprivate final ConcurrentMap<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.\n+\t */\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryResolver) {\n+\t\tthis(streamFactoryResolver, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link ChannelStateSerializerImpl default} {@link ChannelStateSerializer},\n+\t * and a {@link ChannelStateWriteRequestExecutorImpl}.\n+\t *\n+\t * @param maxCheckpoints        maximum number of checkpoints to be written currently or finished but not taken yet.\n+\t * @param streamFactoryResolver a factory to obtain output stream factory for a given checkpoint\n+\t */\n+\tChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryResolver, int maxCheckpoints) {\n+\t\tthis(\n+\t\t\tnew ConcurrentHashMap<>(maxCheckpoints),\n+\t\t\tnew ChannelStateWriteRequestExecutorImpl(new ChannelStateWriteRequestDispatcherImpl(streamFactoryResolver, new ChannelStateSerializerImpl())),\n+\t\t\tmaxCheckpoints\n+\t\t);\n+\t}\n+\n+\tChannelStateWriterImpl(ConcurrentMap<Long, ChannelStateWriteResult> results, ChannelStateWriteRequestExecutor executor, int maxCheckpoints) {\n+\t\tthis.results = results;\n+\t\tthis.maxCheckpoints = maxCheckpoints;\n+\t\tthis.executor = executor;\n+\t}\n+\n+\t@Override\n+\tpublic void start(long checkpointId, CheckpointOptions checkpointOptions) {\n+\t\tLOG.debug(\"start checkpoint {} ({})\", checkpointId, checkpointOptions);\n+\t\tChannelStateWriteResult result = new ChannelStateWriteResult();\n+\t\tChannelStateWriteResult put = results.computeIfAbsent(checkpointId, id -> {\n+\t\t\tPreconditions.checkState(results.size() < maxCheckpoints, \"results.size() > maxCheckpoints\", results.size(), maxCheckpoints);\n+\t\t\tenqueue(new CheckpointStartRequest(checkpointId, result, checkpointOptions.getTargetLocation()), false);\n+\t\t\treturn result;\n+\t\t});\n+\t\tPreconditions.checkArgument(put == result, \"result future already present for checkpoint id: \" + checkpointId);\n+\t}\n+\n+\t@Override\n+\tpublic void addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add input data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)), false);\n+\t}\n+\n+\t@Override\n+\tpublic void addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add output data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)), false);\n+\t}\n+\n+\t@Override\n+\tpublic void finishInput(long checkpointId) {\n+\t\tLOG.debug(\"finish input data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeInput(checkpointId), false);\n+\t}\n+\n+\t@Override\n+\tpublic void finishOutput(long checkpointId) {\n+\t\tLOG.debug(\"finish output data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeOutput(checkpointId), false);\n+\t}\n+\n+\t@Override\n+\tpublic void abort(long checkpointId, Throwable cause) {\n+\t\tLOG.debug(\"abort, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(ChannelStateWriteRequest.abort(checkpointId, cause), true); // abort already started\n+\t\tenqueue(ChannelStateWriteRequest.abort(checkpointId, cause), false); // abort enqueued but not started\n+\t}\n+\n+\t@Override\n+\tpublic ChannelStateWriteResult getWriteResult(long checkpointId) {\n+\t\tLOG.debug(\"requested write result, checkpoint id: {}\", checkpointId);\n+\t\tChannelStateWriteResult result = results.remove(checkpointId);\n+\t\tPreconditions.checkArgument(result != null, \"channel state write result not found for checkpoint id \" + checkpointId);\n+\t\treturn result;\n+\t}\n+\n+\tpublic void open() {\n+\t\texecutor.start();\n+\t}\n+\n+\t@Override\n+\tpublic void close() throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 148}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg5NjkzMzIz", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-389693323", "createdAt": "2020-04-08T06:48:19Z", "commit": {"oid": "bdb06fc00a0da1e0c3df87383de8ebb0a28b1ef3"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNjo0ODoxOVrOGChMZg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNjo0ODoxOVrOGChMZg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTI5NDE4Mg==", "bodyText": "nit: irrelevant change, better to have spaces", "url": "https://github.com/apache/flink/pull/11515#discussion_r405294182", "createdAt": "2020-04-08T06:48:19Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/taskmanager/Task.java", "diffHunk": "@@ -1057,7 +1062,7 @@ else if (current == ExecutionState.RUNNING) {\n \t\t\t\t\t\t// case the canceling could not continue\n \n \t\t\t\t\t\t// The canceller calls cancel and interrupts the executing thread once\n-\t\t\t\t\t\tRunnable canceler = new TaskCanceler(LOG, this :: closeNetworkResources, invokable, executingThread, taskNameWithSubtask);\n+\t\t\t\t\t\tRunnable canceler = new TaskCanceler(LOG, this::closeNetworkResources, invokable, executingThread, taskNameWithSubtask);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bdb06fc00a0da1e0c3df87383de8ebb0a28b1ef3"}, "originalPosition": 39}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg5Njk4Nzg3", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-389698787", "createdAt": "2020-04-08T06:58:44Z", "commit": {"oid": "bdb06fc00a0da1e0c3df87383de8ebb0a28b1ef3"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNjo1ODo0NFrOGChedA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNjo1ODo0NFrOGChedA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTI5ODgwNA==", "bodyText": "Do we have the tests coverage for this new introduced caching function in the commit [FLINK-16744][task] send channel state handles to JM?", "url": "https://github.com/apache/flink/pull/11515#discussion_r405298804", "createdAt": "2020-04-08T06:58:44Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -188,6 +221,77 @@ public void checkpointState(\n \t\t}\n \t}\n \n+\tprivate OperatorSnapshotFutures buildOperatorSnapshotFutures(\n+\t\t\tCheckpointMetaData checkpointMetaData,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tOperatorChain<?, ?> operatorChain,\n+\t\t\tStreamOperator<?> op,\n+\t\t\tSupplier<Boolean> isCanceled,\n+\t\t\tChannelStateWriteResult channelStateWriteResult) throws Exception {\n+\t\tCheckpointStreamFactory storage = checkpointStorage.resolveCheckpointStorageLocation(\n+\t\t\tcheckpointMetaData.getCheckpointId(),\n+\t\t\tcheckpointOptions.getTargetLocation());\n+\t\tOperatorSnapshotFutures snapshotInProgress = checkpointStreamOperator(\n+\t\t\top,\n+\t\t\tcheckpointMetaData,\n+\t\t\tcheckpointOptions,\n+\t\t\tstorage,\n+\t\t\tisCanceled);\n+\t\tif (op == operatorChain.getHeadOperator()) {\n+\t\t\tsnapshotInProgress.setInputChannelStateFuture(\n+\t\t\t\tchannelStateWriteResult\n+\t\t\t\t\t.getInputChannelStateHandles()\n+\t\t\t\t\t.thenApply(StateObjectCollection::new)\n+\t\t\t\t\t.thenApply(SnapshotResult::of));\n+\t\t}\n+\t\tif (op == operatorChain.getTailOperator()) {\n+\t\t\tsnapshotInProgress.setResultSubpartitionStateFuture(\n+\t\t\t\tchannelStateWriteResult\n+\t\t\t\t\t.getResultSubpartitionStateHandles()\n+\t\t\t\t\t.thenApply(StateObjectCollection::new)\n+\t\t\t\t\t.thenApply(SnapshotResult::of));\n+\t\t}\n+\t\treturn snapshotInProgress;\n+\t}\n+\n+\t@Override\n+\tpublic void close() throws IOException {\n+\t\tchannelStateWriter.close();\n+\t}\n+\n+\t// Caches checkpoint output stream factories to prevent multiple output stream per checkpoint.\n+\t// This could result from requesting output stream by different entities (this and channelStateWriter)\n+\t// We can't just pass a stream to the channelStateWriter because it can receive checkpoint call earlier than this class\n+\t// in some unaligned checkpoints scenarios\n+\tprivate static class CachingCheckpointStorageWorkerView implements CheckpointStorageWorkerView {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bdb06fc00a0da1e0c3df87383de8ebb0a28b1ef3"}, "originalPosition": 179}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg5NzA0ODIw", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-389704820", "createdAt": "2020-04-08T07:09:22Z", "commit": {"oid": "102a8f1f7c4926781fba187273cd6d324f8d0bd2"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNzowOToyMlrOGChxlw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNzowOToyMlrOGChxlw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTMwMzcwMw==", "bodyText": "it is not suggested putting multiple arguments in one line. split line for every argument", "url": "https://github.com/apache/flink/pull/11515#discussion_r405303703", "createdAt": "2020-04-08T07:09:22Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -130,95 +130,108 @@ public void checkpointState(\n \n \t\t// Step (1): Prepare the checkpoint, allow operators to do some pre-barrier work.\n \t\t//           The pre-barrier work should be nothing or minimal in the common case.\n-\t\toperatorChain.prepareSnapshotPreBarrier(checkpointId);\n+\t\toperatorChain.prepareSnapshotPreBarrier(metadata.getCheckpointId());\n \n \t\t// Step (2): Send the checkpoint barrier downstream\n-\t\toperatorChain.broadcastCheckpointBarrier(\n-\t\t\tcheckpointId,\n-\t\t\tcheckpointMetaData.getTimestamp(),\n-\t\t\tcheckpointOptions);\n+\t\toperatorChain.broadcastCheckpointBarrier(metadata.getCheckpointId(), metadata.getTimestamp(), options);\n \n-\t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not\n-\t\t//           impact progress of the streaming topology\n+\t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not impact progress of the streaming topology\n \n-\t\tlong startSyncPartNano = System.nanoTime();\n-\n-\t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress = new HashMap<>(operatorChain.getNumberOfOperators());\n-\t\tChannelStateWriteResult channelStateWriteResult =\n-\t\t\tcheckpointOptions.getCheckpointType() == CHECKPOINT ? channelStateWriter.getWriteResult(checkpointMetaData.getCheckpointId()) :\n-\t\t\t\tChannelStateWriteResult.EMPTY;\n+\t\tMap<OperatorID, OperatorSnapshotFutures> snapshotFutures = new HashMap<>(operatorChain.getNumberOfOperators());\n \t\ttry {\n-\t\t\tfor (StreamOperatorWrapper<?, ?> operatorWrapper : operatorChain.getAllOperators(true)) {\n-\t\t\t\toperatorSnapshotsInProgress.put(\n-\t\t\t\t\toperatorWrapper.getStreamOperator().getOperatorID(),\n-\t\t\t\t\tbuildOperatorSnapshotFutures(\n-\t\t\t\t\t\tcheckpointMetaData,\n-\t\t\t\t\t\tcheckpointOptions,\n-\t\t\t\t\t\toperatorChain,\n-\t\t\t\t\t\toperatorWrapper.getStreamOperator(),\n-\t\t\t\t\t\tisCanceled,\n-\t\t\t\t\t\tchannelStateWriteResult)\n-\t\t\t\t);\n-\t\t\t}\n-\t\t\tcheckpointStorage.clearCacheFor(checkpointMetaData.getCheckpointId());\n+\t\t\ttakeSnapshotSync(snapshotFutures, metadata, metrics, options, operatorChain, isCanceled);\n+\t\t\tfinishAndReportAsync(snapshotFutures, metadata, metrics);\n+\t\t} catch (Exception ex) {\n+\t\t\tcleanup(snapshotFutures, metadata, metrics, options, ex);\n+\t\t}\n+\t}\n \n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\"Finished synchronous checkpoints for checkpoint {} on task {}\",\n-\t\t\t\t\tcheckpointMetaData.getCheckpointId(), taskName);\n-\t\t\t}\n+\tprivate void cleanup(\n+\t\t\tMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress,\n+\t\t\tCheckpointMetaData metadata,\n+\t\t\tCheckpointMetrics metrics, CheckpointOptions options,\n+\t\t\tException ex) throws Exception {\n \n-\t\t\tlong startAsyncPartNano = System.nanoTime();\n-\n-\t\t\tcheckpointMetrics.setSyncDurationMillis((startAsyncPartNano - startSyncPartNano) / 1_000_000);\n-\n-\t\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n-\t\t\texecutorService.execute(new AsyncCheckpointRunnable(\n-\t\t\t\toperatorSnapshotsInProgress,\n-\t\t\t\tcheckpointMetaData,\n-\t\t\t\tcheckpointMetrics,\n-\t\t\t\tstartAsyncPartNano,\n-\t\t\t\ttaskName,\n-\t\t\t\tcloseableRegistry,\n-\t\t\t\tenv,\n-\t\t\t\tasyncExceptionHandler));\n-\n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\n-\t\t\t\t\t\"{} - finished synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n-\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n-\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n-\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n-\t\t\t}\n-\t\t} catch (Exception ex) {\n-\t\t\t// Cleanup to release resources\n-\t\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n-\t\t\t\tif (null != operatorSnapshotResult) {\n-\t\t\t\t\ttry {\n-\t\t\t\t\t\toperatorSnapshotResult.cancel();\n-\t\t\t\t\t} catch (Exception e) {\n-\t\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n-\t\t\t\t\t}\n+\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n+\t\t\tif (operatorSnapshotResult != null) {\n+\t\t\t\ttry {\n+\t\t\t\t\toperatorSnapshotResult.cancel();\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n \t\t\t\t}\n \t\t\t}\n+\t\t}\n \n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\n-\t\t\t\t\t\"{} - did NOT finish synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n-\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n-\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n-\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n-\t\t\t}\n+\t\tif (LOG.isDebugEnabled()) {\n+\t\t\tLOG.debug(\n+\t\t\t\t\"{} - did NOT finish synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n+\t\t\t\ttaskName, metadata.getCheckpointId(),\n+\t\t\t\tmetrics.getAlignmentDurationNanos() / 1_000_000,\n+\t\t\t\tmetrics.getSyncDurationMillis());\n+\t\t}\n \n-\t\t\tif (checkpointOptions.getCheckpointType().isSynchronous()) {\n-\t\t\t\t// in the case of a synchronous checkpoint, we always rethrow the exception,\n-\t\t\t\t// so that the task fails.\n-\t\t\t\t// this is because the intention is always to stop the job after this checkpointing\n-\t\t\t\t// operation, and without the failure, the task would go back to normal execution.\n-\t\t\t\tthrow ex;\n-\t\t\t} else {\n-\t\t\t\tenv.declineCheckpoint(checkpointMetaData.getCheckpointId(), ex);\n-\t\t\t}\n+\t\tif (options.getCheckpointType().isSynchronous()) {\n+\t\t\t// in the case of a synchronous checkpoint, we always rethrow the exception,\n+\t\t\t// so that the task fails.\n+\t\t\t// this is because the intention is always to stop the job after this checkpointing\n+\t\t\t// operation, and without the failure, the task would go back to normal execution.\n+\t\t\tthrow ex;\n+\t\t} else {\n+\t\t\tenv.declineCheckpoint(metadata.getCheckpointId(), ex);\n+\t\t}\n+\t}\n+\n+\tprivate void finishAndReportAsync(Map<OperatorID, OperatorSnapshotFutures> snapshotFutures, CheckpointMetaData metadata, CheckpointMetrics metrics) {\n+\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n+\t\texecutorService.execute(new AsyncCheckpointRunnable(\n+\t\t\tsnapshotFutures,\n+\t\t\tmetadata,\n+\t\t\tmetrics,\n+\t\t\tSystem.nanoTime(),\n+\t\t\ttaskName,\n+\t\t\tcloseableRegistry,\n+\t\t\tenv,\n+\t\t\tasyncExceptionHandler));\n+\t}\n+\n+\tprivate void takeSnapshotSync(\n+\t\tMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress, CheckpointMetaData checkpointMetaData,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "102a8f1f7c4926781fba187273cd6d324f8d0bd2"}, "originalPosition": 167}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg5NzA1NzYz", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-389705763", "createdAt": "2020-04-08T07:11:03Z", "commit": {"oid": "102a8f1f7c4926781fba187273cd6d324f8d0bd2"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNzoxMTowM1rOGCh0lg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNzoxMTowM1rOGCh0lg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTMwNDQ3MA==", "bodyText": "I guess the condition checkpointOptions.getCheckpointType() == CHECKPOINT should be consistent with sendChannelState in constructor?", "url": "https://github.com/apache/flink/pull/11515#discussion_r405304470", "createdAt": "2020-04-08T07:11:03Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -130,95 +130,108 @@ public void checkpointState(\n \n \t\t// Step (1): Prepare the checkpoint, allow operators to do some pre-barrier work.\n \t\t//           The pre-barrier work should be nothing or minimal in the common case.\n-\t\toperatorChain.prepareSnapshotPreBarrier(checkpointId);\n+\t\toperatorChain.prepareSnapshotPreBarrier(metadata.getCheckpointId());\n \n \t\t// Step (2): Send the checkpoint barrier downstream\n-\t\toperatorChain.broadcastCheckpointBarrier(\n-\t\t\tcheckpointId,\n-\t\t\tcheckpointMetaData.getTimestamp(),\n-\t\t\tcheckpointOptions);\n+\t\toperatorChain.broadcastCheckpointBarrier(metadata.getCheckpointId(), metadata.getTimestamp(), options);\n \n-\t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not\n-\t\t//           impact progress of the streaming topology\n+\t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not impact progress of the streaming topology\n \n-\t\tlong startSyncPartNano = System.nanoTime();\n-\n-\t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress = new HashMap<>(operatorChain.getNumberOfOperators());\n-\t\tChannelStateWriteResult channelStateWriteResult =\n-\t\t\tcheckpointOptions.getCheckpointType() == CHECKPOINT ? channelStateWriter.getWriteResult(checkpointMetaData.getCheckpointId()) :\n-\t\t\t\tChannelStateWriteResult.EMPTY;\n+\t\tMap<OperatorID, OperatorSnapshotFutures> snapshotFutures = new HashMap<>(operatorChain.getNumberOfOperators());\n \t\ttry {\n-\t\t\tfor (StreamOperatorWrapper<?, ?> operatorWrapper : operatorChain.getAllOperators(true)) {\n-\t\t\t\toperatorSnapshotsInProgress.put(\n-\t\t\t\t\toperatorWrapper.getStreamOperator().getOperatorID(),\n-\t\t\t\t\tbuildOperatorSnapshotFutures(\n-\t\t\t\t\t\tcheckpointMetaData,\n-\t\t\t\t\t\tcheckpointOptions,\n-\t\t\t\t\t\toperatorChain,\n-\t\t\t\t\t\toperatorWrapper.getStreamOperator(),\n-\t\t\t\t\t\tisCanceled,\n-\t\t\t\t\t\tchannelStateWriteResult)\n-\t\t\t\t);\n-\t\t\t}\n-\t\t\tcheckpointStorage.clearCacheFor(checkpointMetaData.getCheckpointId());\n+\t\t\ttakeSnapshotSync(snapshotFutures, metadata, metrics, options, operatorChain, isCanceled);\n+\t\t\tfinishAndReportAsync(snapshotFutures, metadata, metrics);\n+\t\t} catch (Exception ex) {\n+\t\t\tcleanup(snapshotFutures, metadata, metrics, options, ex);\n+\t\t}\n+\t}\n \n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\"Finished synchronous checkpoints for checkpoint {} on task {}\",\n-\t\t\t\t\tcheckpointMetaData.getCheckpointId(), taskName);\n-\t\t\t}\n+\tprivate void cleanup(\n+\t\t\tMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress,\n+\t\t\tCheckpointMetaData metadata,\n+\t\t\tCheckpointMetrics metrics, CheckpointOptions options,\n+\t\t\tException ex) throws Exception {\n \n-\t\t\tlong startAsyncPartNano = System.nanoTime();\n-\n-\t\t\tcheckpointMetrics.setSyncDurationMillis((startAsyncPartNano - startSyncPartNano) / 1_000_000);\n-\n-\t\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n-\t\t\texecutorService.execute(new AsyncCheckpointRunnable(\n-\t\t\t\toperatorSnapshotsInProgress,\n-\t\t\t\tcheckpointMetaData,\n-\t\t\t\tcheckpointMetrics,\n-\t\t\t\tstartAsyncPartNano,\n-\t\t\t\ttaskName,\n-\t\t\t\tcloseableRegistry,\n-\t\t\t\tenv,\n-\t\t\t\tasyncExceptionHandler));\n-\n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\n-\t\t\t\t\t\"{} - finished synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n-\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n-\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n-\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n-\t\t\t}\n-\t\t} catch (Exception ex) {\n-\t\t\t// Cleanup to release resources\n-\t\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n-\t\t\t\tif (null != operatorSnapshotResult) {\n-\t\t\t\t\ttry {\n-\t\t\t\t\t\toperatorSnapshotResult.cancel();\n-\t\t\t\t\t} catch (Exception e) {\n-\t\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n-\t\t\t\t\t}\n+\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n+\t\t\tif (operatorSnapshotResult != null) {\n+\t\t\t\ttry {\n+\t\t\t\t\toperatorSnapshotResult.cancel();\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n \t\t\t\t}\n \t\t\t}\n+\t\t}\n \n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\n-\t\t\t\t\t\"{} - did NOT finish synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n-\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n-\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n-\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n-\t\t\t}\n+\t\tif (LOG.isDebugEnabled()) {\n+\t\t\tLOG.debug(\n+\t\t\t\t\"{} - did NOT finish synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n+\t\t\t\ttaskName, metadata.getCheckpointId(),\n+\t\t\t\tmetrics.getAlignmentDurationNanos() / 1_000_000,\n+\t\t\t\tmetrics.getSyncDurationMillis());\n+\t\t}\n \n-\t\t\tif (checkpointOptions.getCheckpointType().isSynchronous()) {\n-\t\t\t\t// in the case of a synchronous checkpoint, we always rethrow the exception,\n-\t\t\t\t// so that the task fails.\n-\t\t\t\t// this is because the intention is always to stop the job after this checkpointing\n-\t\t\t\t// operation, and without the failure, the task would go back to normal execution.\n-\t\t\t\tthrow ex;\n-\t\t\t} else {\n-\t\t\t\tenv.declineCheckpoint(checkpointMetaData.getCheckpointId(), ex);\n-\t\t\t}\n+\t\tif (options.getCheckpointType().isSynchronous()) {\n+\t\t\t// in the case of a synchronous checkpoint, we always rethrow the exception,\n+\t\t\t// so that the task fails.\n+\t\t\t// this is because the intention is always to stop the job after this checkpointing\n+\t\t\t// operation, and without the failure, the task would go back to normal execution.\n+\t\t\tthrow ex;\n+\t\t} else {\n+\t\t\tenv.declineCheckpoint(metadata.getCheckpointId(), ex);\n+\t\t}\n+\t}\n+\n+\tprivate void finishAndReportAsync(Map<OperatorID, OperatorSnapshotFutures> snapshotFutures, CheckpointMetaData metadata, CheckpointMetrics metrics) {\n+\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n+\t\texecutorService.execute(new AsyncCheckpointRunnable(\n+\t\t\tsnapshotFutures,\n+\t\t\tmetadata,\n+\t\t\tmetrics,\n+\t\t\tSystem.nanoTime(),\n+\t\t\ttaskName,\n+\t\t\tcloseableRegistry,\n+\t\t\tenv,\n+\t\t\tasyncExceptionHandler));\n+\t}\n+\n+\tprivate void takeSnapshotSync(\n+\t\tMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress, CheckpointMetaData checkpointMetaData,\n+\t\tCheckpointMetrics checkpointMetrics, CheckpointOptions checkpointOptions,\n+\t\tOperatorChain<?, ?> operatorChain,\n+\t\tSupplier<Boolean> isCanceled) throws Exception {\n+\n+\t\tlong checkpointId = checkpointMetaData.getCheckpointId();\n+\t\tlong started = System.nanoTime();\n+\n+\t\tChannelStateWriteResult channelStateWriteResult = checkpointOptions.getCheckpointType() == CHECKPOINT ?", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "102a8f1f7c4926781fba187273cd6d324f8d0bd2"}, "originalPosition": 175}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg5NzA2OTcw", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-389706970", "createdAt": "2020-04-08T07:13:04Z", "commit": {"oid": "102a8f1f7c4926781fba187273cd6d324f8d0bd2"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNzoxMzowNFrOGCh4bA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNzoxMzowNFrOGCh4bA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTMwNTQ1Mg==", "bodyText": "nit: reduce indentation?", "url": "https://github.com/apache/flink/pull/11515#discussion_r405305452", "createdAt": "2020-04-08T07:13:04Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -130,95 +130,108 @@ public void checkpointState(\n \n \t\t// Step (1): Prepare the checkpoint, allow operators to do some pre-barrier work.\n \t\t//           The pre-barrier work should be nothing or minimal in the common case.\n-\t\toperatorChain.prepareSnapshotPreBarrier(checkpointId);\n+\t\toperatorChain.prepareSnapshotPreBarrier(metadata.getCheckpointId());\n \n \t\t// Step (2): Send the checkpoint barrier downstream\n-\t\toperatorChain.broadcastCheckpointBarrier(\n-\t\t\tcheckpointId,\n-\t\t\tcheckpointMetaData.getTimestamp(),\n-\t\t\tcheckpointOptions);\n+\t\toperatorChain.broadcastCheckpointBarrier(metadata.getCheckpointId(), metadata.getTimestamp(), options);\n \n-\t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not\n-\t\t//           impact progress of the streaming topology\n+\t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not impact progress of the streaming topology\n \n-\t\tlong startSyncPartNano = System.nanoTime();\n-\n-\t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress = new HashMap<>(operatorChain.getNumberOfOperators());\n-\t\tChannelStateWriteResult channelStateWriteResult =\n-\t\t\tcheckpointOptions.getCheckpointType() == CHECKPOINT ? channelStateWriter.getWriteResult(checkpointMetaData.getCheckpointId()) :\n-\t\t\t\tChannelStateWriteResult.EMPTY;\n+\t\tMap<OperatorID, OperatorSnapshotFutures> snapshotFutures = new HashMap<>(operatorChain.getNumberOfOperators());\n \t\ttry {\n-\t\t\tfor (StreamOperatorWrapper<?, ?> operatorWrapper : operatorChain.getAllOperators(true)) {\n-\t\t\t\toperatorSnapshotsInProgress.put(\n-\t\t\t\t\toperatorWrapper.getStreamOperator().getOperatorID(),\n-\t\t\t\t\tbuildOperatorSnapshotFutures(\n-\t\t\t\t\t\tcheckpointMetaData,\n-\t\t\t\t\t\tcheckpointOptions,\n-\t\t\t\t\t\toperatorChain,\n-\t\t\t\t\t\toperatorWrapper.getStreamOperator(),\n-\t\t\t\t\t\tisCanceled,\n-\t\t\t\t\t\tchannelStateWriteResult)\n-\t\t\t\t);\n-\t\t\t}\n-\t\t\tcheckpointStorage.clearCacheFor(checkpointMetaData.getCheckpointId());\n+\t\t\ttakeSnapshotSync(snapshotFutures, metadata, metrics, options, operatorChain, isCanceled);\n+\t\t\tfinishAndReportAsync(snapshotFutures, metadata, metrics);\n+\t\t} catch (Exception ex) {\n+\t\t\tcleanup(snapshotFutures, metadata, metrics, options, ex);\n+\t\t}\n+\t}\n \n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\"Finished synchronous checkpoints for checkpoint {} on task {}\",\n-\t\t\t\t\tcheckpointMetaData.getCheckpointId(), taskName);\n-\t\t\t}\n+\tprivate void cleanup(\n+\t\t\tMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress,\n+\t\t\tCheckpointMetaData metadata,\n+\t\t\tCheckpointMetrics metrics, CheckpointOptions options,\n+\t\t\tException ex) throws Exception {\n \n-\t\t\tlong startAsyncPartNano = System.nanoTime();\n-\n-\t\t\tcheckpointMetrics.setSyncDurationMillis((startAsyncPartNano - startSyncPartNano) / 1_000_000);\n-\n-\t\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n-\t\t\texecutorService.execute(new AsyncCheckpointRunnable(\n-\t\t\t\toperatorSnapshotsInProgress,\n-\t\t\t\tcheckpointMetaData,\n-\t\t\t\tcheckpointMetrics,\n-\t\t\t\tstartAsyncPartNano,\n-\t\t\t\ttaskName,\n-\t\t\t\tcloseableRegistry,\n-\t\t\t\tenv,\n-\t\t\t\tasyncExceptionHandler));\n-\n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\n-\t\t\t\t\t\"{} - finished synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n-\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n-\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n-\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n-\t\t\t}\n-\t\t} catch (Exception ex) {\n-\t\t\t// Cleanup to release resources\n-\t\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n-\t\t\t\tif (null != operatorSnapshotResult) {\n-\t\t\t\t\ttry {\n-\t\t\t\t\t\toperatorSnapshotResult.cancel();\n-\t\t\t\t\t} catch (Exception e) {\n-\t\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n-\t\t\t\t\t}\n+\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n+\t\t\tif (operatorSnapshotResult != null) {\n+\t\t\t\ttry {\n+\t\t\t\t\toperatorSnapshotResult.cancel();\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n \t\t\t\t}\n \t\t\t}\n+\t\t}\n \n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\n-\t\t\t\t\t\"{} - did NOT finish synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n-\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n-\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n-\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n-\t\t\t}\n+\t\tif (LOG.isDebugEnabled()) {\n+\t\t\tLOG.debug(\n+\t\t\t\t\"{} - did NOT finish synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n+\t\t\t\ttaskName, metadata.getCheckpointId(),\n+\t\t\t\tmetrics.getAlignmentDurationNanos() / 1_000_000,\n+\t\t\t\tmetrics.getSyncDurationMillis());\n+\t\t}\n \n-\t\t\tif (checkpointOptions.getCheckpointType().isSynchronous()) {\n-\t\t\t\t// in the case of a synchronous checkpoint, we always rethrow the exception,\n-\t\t\t\t// so that the task fails.\n-\t\t\t\t// this is because the intention is always to stop the job after this checkpointing\n-\t\t\t\t// operation, and without the failure, the task would go back to normal execution.\n-\t\t\t\tthrow ex;\n-\t\t\t} else {\n-\t\t\t\tenv.declineCheckpoint(checkpointMetaData.getCheckpointId(), ex);\n-\t\t\t}\n+\t\tif (options.getCheckpointType().isSynchronous()) {\n+\t\t\t// in the case of a synchronous checkpoint, we always rethrow the exception,\n+\t\t\t// so that the task fails.\n+\t\t\t// this is because the intention is always to stop the job after this checkpointing\n+\t\t\t// operation, and without the failure, the task would go back to normal execution.\n+\t\t\tthrow ex;\n+\t\t} else {\n+\t\t\tenv.declineCheckpoint(metadata.getCheckpointId(), ex);\n+\t\t}\n+\t}\n+\n+\tprivate void finishAndReportAsync(Map<OperatorID, OperatorSnapshotFutures> snapshotFutures, CheckpointMetaData metadata, CheckpointMetrics metrics) {\n+\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n+\t\texecutorService.execute(new AsyncCheckpointRunnable(\n+\t\t\tsnapshotFutures,\n+\t\t\tmetadata,\n+\t\t\tmetrics,\n+\t\t\tSystem.nanoTime(),\n+\t\t\ttaskName,\n+\t\t\tcloseableRegistry,\n+\t\t\tenv,\n+\t\t\tasyncExceptionHandler));\n+\t}\n+\n+\tprivate void takeSnapshotSync(\n+\t\tMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress, CheckpointMetaData checkpointMetaData,\n+\t\tCheckpointMetrics checkpointMetrics, CheckpointOptions checkpointOptions,\n+\t\tOperatorChain<?, ?> operatorChain,\n+\t\tSupplier<Boolean> isCanceled) throws Exception {\n+\n+\t\tlong checkpointId = checkpointMetaData.getCheckpointId();\n+\t\tlong started = System.nanoTime();\n+\n+\t\tChannelStateWriteResult channelStateWriteResult = checkpointOptions.getCheckpointType() == CHECKPOINT ?\n+\t\t\t\t\t\t\t\tchannelStateWriter.getWriteResult(checkpointId) :", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "102a8f1f7c4926781fba187273cd6d324f8d0bd2"}, "originalPosition": 176}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg5NzA4MTY1", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-389708165", "createdAt": "2020-04-08T07:15:09Z", "commit": {"oid": "102a8f1f7c4926781fba187273cd6d324f8d0bd2"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNzoxNTowOVrOGCh8Ug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNzoxNTowOVrOGCh8Ug==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTMwNjQ1MA==", "bodyText": "If buildOperatorSnapshotFutures encounters exception, the clear will not be executed, should place within finally?", "url": "https://github.com/apache/flink/pull/11515#discussion_r405306450", "createdAt": "2020-04-08T07:15:09Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -130,95 +130,108 @@ public void checkpointState(\n \n \t\t// Step (1): Prepare the checkpoint, allow operators to do some pre-barrier work.\n \t\t//           The pre-barrier work should be nothing or minimal in the common case.\n-\t\toperatorChain.prepareSnapshotPreBarrier(checkpointId);\n+\t\toperatorChain.prepareSnapshotPreBarrier(metadata.getCheckpointId());\n \n \t\t// Step (2): Send the checkpoint barrier downstream\n-\t\toperatorChain.broadcastCheckpointBarrier(\n-\t\t\tcheckpointId,\n-\t\t\tcheckpointMetaData.getTimestamp(),\n-\t\t\tcheckpointOptions);\n+\t\toperatorChain.broadcastCheckpointBarrier(metadata.getCheckpointId(), metadata.getTimestamp(), options);\n \n-\t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not\n-\t\t//           impact progress of the streaming topology\n+\t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not impact progress of the streaming topology\n \n-\t\tlong startSyncPartNano = System.nanoTime();\n-\n-\t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress = new HashMap<>(operatorChain.getNumberOfOperators());\n-\t\tChannelStateWriteResult channelStateWriteResult =\n-\t\t\tcheckpointOptions.getCheckpointType() == CHECKPOINT ? channelStateWriter.getWriteResult(checkpointMetaData.getCheckpointId()) :\n-\t\t\t\tChannelStateWriteResult.EMPTY;\n+\t\tMap<OperatorID, OperatorSnapshotFutures> snapshotFutures = new HashMap<>(operatorChain.getNumberOfOperators());\n \t\ttry {\n-\t\t\tfor (StreamOperatorWrapper<?, ?> operatorWrapper : operatorChain.getAllOperators(true)) {\n-\t\t\t\toperatorSnapshotsInProgress.put(\n-\t\t\t\t\toperatorWrapper.getStreamOperator().getOperatorID(),\n-\t\t\t\t\tbuildOperatorSnapshotFutures(\n-\t\t\t\t\t\tcheckpointMetaData,\n-\t\t\t\t\t\tcheckpointOptions,\n-\t\t\t\t\t\toperatorChain,\n-\t\t\t\t\t\toperatorWrapper.getStreamOperator(),\n-\t\t\t\t\t\tisCanceled,\n-\t\t\t\t\t\tchannelStateWriteResult)\n-\t\t\t\t);\n-\t\t\t}\n-\t\t\tcheckpointStorage.clearCacheFor(checkpointMetaData.getCheckpointId());\n+\t\t\ttakeSnapshotSync(snapshotFutures, metadata, metrics, options, operatorChain, isCanceled);\n+\t\t\tfinishAndReportAsync(snapshotFutures, metadata, metrics);\n+\t\t} catch (Exception ex) {\n+\t\t\tcleanup(snapshotFutures, metadata, metrics, options, ex);\n+\t\t}\n+\t}\n \n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\"Finished synchronous checkpoints for checkpoint {} on task {}\",\n-\t\t\t\t\tcheckpointMetaData.getCheckpointId(), taskName);\n-\t\t\t}\n+\tprivate void cleanup(\n+\t\t\tMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress,\n+\t\t\tCheckpointMetaData metadata,\n+\t\t\tCheckpointMetrics metrics, CheckpointOptions options,\n+\t\t\tException ex) throws Exception {\n \n-\t\t\tlong startAsyncPartNano = System.nanoTime();\n-\n-\t\t\tcheckpointMetrics.setSyncDurationMillis((startAsyncPartNano - startSyncPartNano) / 1_000_000);\n-\n-\t\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n-\t\t\texecutorService.execute(new AsyncCheckpointRunnable(\n-\t\t\t\toperatorSnapshotsInProgress,\n-\t\t\t\tcheckpointMetaData,\n-\t\t\t\tcheckpointMetrics,\n-\t\t\t\tstartAsyncPartNano,\n-\t\t\t\ttaskName,\n-\t\t\t\tcloseableRegistry,\n-\t\t\t\tenv,\n-\t\t\t\tasyncExceptionHandler));\n-\n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\n-\t\t\t\t\t\"{} - finished synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n-\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n-\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n-\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n-\t\t\t}\n-\t\t} catch (Exception ex) {\n-\t\t\t// Cleanup to release resources\n-\t\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n-\t\t\t\tif (null != operatorSnapshotResult) {\n-\t\t\t\t\ttry {\n-\t\t\t\t\t\toperatorSnapshotResult.cancel();\n-\t\t\t\t\t} catch (Exception e) {\n-\t\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n-\t\t\t\t\t}\n+\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n+\t\t\tif (operatorSnapshotResult != null) {\n+\t\t\t\ttry {\n+\t\t\t\t\toperatorSnapshotResult.cancel();\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n \t\t\t\t}\n \t\t\t}\n+\t\t}\n \n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\n-\t\t\t\t\t\"{} - did NOT finish synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n-\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n-\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n-\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n-\t\t\t}\n+\t\tif (LOG.isDebugEnabled()) {\n+\t\t\tLOG.debug(\n+\t\t\t\t\"{} - did NOT finish synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n+\t\t\t\ttaskName, metadata.getCheckpointId(),\n+\t\t\t\tmetrics.getAlignmentDurationNanos() / 1_000_000,\n+\t\t\t\tmetrics.getSyncDurationMillis());\n+\t\t}\n \n-\t\t\tif (checkpointOptions.getCheckpointType().isSynchronous()) {\n-\t\t\t\t// in the case of a synchronous checkpoint, we always rethrow the exception,\n-\t\t\t\t// so that the task fails.\n-\t\t\t\t// this is because the intention is always to stop the job after this checkpointing\n-\t\t\t\t// operation, and without the failure, the task would go back to normal execution.\n-\t\t\t\tthrow ex;\n-\t\t\t} else {\n-\t\t\t\tenv.declineCheckpoint(checkpointMetaData.getCheckpointId(), ex);\n-\t\t\t}\n+\t\tif (options.getCheckpointType().isSynchronous()) {\n+\t\t\t// in the case of a synchronous checkpoint, we always rethrow the exception,\n+\t\t\t// so that the task fails.\n+\t\t\t// this is because the intention is always to stop the job after this checkpointing\n+\t\t\t// operation, and without the failure, the task would go back to normal execution.\n+\t\t\tthrow ex;\n+\t\t} else {\n+\t\t\tenv.declineCheckpoint(metadata.getCheckpointId(), ex);\n+\t\t}\n+\t}\n+\n+\tprivate void finishAndReportAsync(Map<OperatorID, OperatorSnapshotFutures> snapshotFutures, CheckpointMetaData metadata, CheckpointMetrics metrics) {\n+\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n+\t\texecutorService.execute(new AsyncCheckpointRunnable(\n+\t\t\tsnapshotFutures,\n+\t\t\tmetadata,\n+\t\t\tmetrics,\n+\t\t\tSystem.nanoTime(),\n+\t\t\ttaskName,\n+\t\t\tcloseableRegistry,\n+\t\t\tenv,\n+\t\t\tasyncExceptionHandler));\n+\t}\n+\n+\tprivate void takeSnapshotSync(\n+\t\tMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress, CheckpointMetaData checkpointMetaData,\n+\t\tCheckpointMetrics checkpointMetrics, CheckpointOptions checkpointOptions,\n+\t\tOperatorChain<?, ?> operatorChain,\n+\t\tSupplier<Boolean> isCanceled) throws Exception {\n+\n+\t\tlong checkpointId = checkpointMetaData.getCheckpointId();\n+\t\tlong started = System.nanoTime();\n+\n+\t\tChannelStateWriteResult channelStateWriteResult = checkpointOptions.getCheckpointType() == CHECKPOINT ?\n+\t\t\t\t\t\t\t\tchannelStateWriter.getWriteResult(checkpointId) :\n+\t\t\t\t\t\t\t\tChannelStateWriteResult.EMPTY;\n+\n+\t\tCheckpointStreamFactory storage = checkpointStorage.resolveCheckpointStorageLocation(checkpointId, checkpointOptions.getTargetLocation());\n+\n+\t\tfor (StreamOperatorWrapper<?, ?> operatorWrapper : operatorChain.getAllOperators(true)) {\n+\t\t\toperatorSnapshotsInProgress.put(\n+\t\t\t\toperatorWrapper.getStreamOperator().getOperatorID(),\n+\t\t\t\tbuildOperatorSnapshotFutures(\n+\t\t\t\t\tcheckpointMetaData,\n+\t\t\t\t\tcheckpointOptions,\n+\t\t\t\t\toperatorChain,\n+\t\t\t\t\toperatorWrapper.getStreamOperator(),\n+\t\t\t\t\tisCanceled,\n+\t\t\t\t\tchannelStateWriteResult,\n+\t\t\t\t\tstorage));\n \t\t}\n+\n+\t\tcheckpointStorage.clearCacheFor(checkpointId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "102a8f1f7c4926781fba187273cd6d324f8d0bd2"}, "originalPosition": 194}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg5NzIyMDMy", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-389722032", "createdAt": "2020-04-08T07:37:15Z", "commit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNzozNzoxNlrOGCipFQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNzozNzoxNlrOGCipFQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTMxNzkwOQ==", "bodyText": "it is better to also verify the ChannelStateWriteResult#isDone when complete both input and output.", "url": "https://github.com/apache/flink/pull/11515#discussion_r405317909", "createdAt": "2020-04-08T07:37:16Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateCheckpointWriterTest.java", "diffHunk": "@@ -0,0 +1,133 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.memory.HeapMemorySegment;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.runtime.state.memory.MemCheckpointStreamFactory.MemoryCheckpointOutputStream;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.junit.Test;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Random;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * {@link ChannelStateCheckpointWriter} test.\n+ */\n+public class ChannelStateCheckpointWriterTest {\n+\tprivate static final RunnableWithException NO_OP_RUNNABLE = () -> {\n+\t};\n+\tprivate final Random random = new Random();\n+\n+\t@Test\n+\tpublic void testRecyclingBuffers() throws Exception {\n+\t\tChannelStateCheckpointWriter writer = createWriter(new ChannelStateWriteResult());\n+\t\tNetworkBuffer buffer = new NetworkBuffer(HeapMemorySegment.FACTORY.allocateUnpooledSegment(10, null), FreeingBufferRecycler.INSTANCE);\n+\t\twriter.writeInput(new InputChannelInfo(1, 2), buffer);\n+\t\tassertTrue(buffer.isRecycled());\n+\t}\n+\n+\t@Test\n+\tpublic void testFlush() throws Exception {\n+\t\tclass FlushRecorder extends DataOutputStream {\n+\t\t\tprivate boolean flushed = false;\n+\n+\t\t\tprivate FlushRecorder() {\n+\t\t\t\tsuper(new ByteArrayOutputStream());\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic void flush() throws IOException {\n+\t\t\t\tflushed = true;\n+\t\t\t\tsuper.flush();\n+\t\t\t}\n+\t\t}\n+\n+\t\tFlushRecorder dataStream = new FlushRecorder();\n+\t\tfinal ChannelStateCheckpointWriter writer = new ChannelStateCheckpointWriter(\n+\t\t\t1L,\n+\t\t\tnew ChannelStateWriteResult(),\n+\t\t\tnew ChannelStateSerializerImpl(),\n+\t\t\tNO_OP_RUNNABLE,\n+\t\t\tnew MemoryCheckpointOutputStream(42),\n+\t\t\tdataStream\n+\t\t);\n+\n+\t\twriter.completeInput();\n+\t\twriter.completeOutput();\n+\n+\t\tassertTrue(dataStream.flushed);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 85}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg5NzM0Mzcx", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-389734371", "createdAt": "2020-04-08T07:55:44Z", "commit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNzo1NTo0NFrOGCjSAw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwNzo1NTo0NFrOGCjSAw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTMyODM4Nw==", "bodyText": "All the below tests are for the  ChannelStateReader#readInput, not sure whether we also need to cover the code path for ChannelStateReader#readOutput.", "url": "https://github.com/apache/flink/pull/11515#discussion_r405328387", "createdAt": "2020-04-08T07:55:44Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImplTest.java", "diffHunk": "@@ -0,0 +1,205 @@\n+package org.apache.flink.runtime.checkpoint.channel;\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+import org.apache.flink.core.memory.HeapMemorySegment;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.StateObjectCollection;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.runtime.state.memory.ByteStreamStateHandle;\n+\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Random;\n+\n+import static java.util.Collections.singletonList;\n+import static java.util.stream.Collectors.toMap;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.HAS_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+import static org.junit.Assert.assertArrayEquals;\n+import static org.junit.Assert.assertEquals;\n+\n+/**\n+ * {@link ChannelStateReaderImpl} test.\n+ */\n+public class ChannelStateReaderImplTest {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 54}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg5ODMxMDM5", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-389831039", "createdAt": "2020-04-08T10:03:59Z", "commit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxMDowMzo1OVrOGCoKtQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxMDowMzo1OVrOGCoKtQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQwODQzNw==", "bodyText": "I have not seen any tests covering the resource release for the reader. If possible, it is better to further verify the internal RefCountingFSDataInputStream is dereferenced and closed when no more data.  Then we can confirm no resource leak.", "url": "https://github.com/apache/flink/pull/11515#discussion_r405408437", "createdAt": "2020-04-08T10:03:59Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImplTest.java", "diffHunk": "@@ -0,0 +1,205 @@\n+package org.apache.flink.runtime.checkpoint.channel;\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+import org.apache.flink.core.memory.HeapMemorySegment;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.StateObjectCollection;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.runtime.state.memory.ByteStreamStateHandle;\n+\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Random;\n+\n+import static java.util.Collections.singletonList;\n+import static java.util.stream.Collectors.toMap;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.HAS_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+import static org.junit.Assert.assertArrayEquals;\n+import static org.junit.Assert.assertEquals;\n+\n+/**\n+ * {@link ChannelStateReaderImpl} test.\n+ */\n+public class ChannelStateReaderImplTest {\n+\n+\tprivate static final InputChannelInfo CHANNEL = new InputChannelInfo(1, 2);\n+\tprivate static final byte[] DATA = generateData(10);\n+\tprivate ChannelStateReaderImpl reader;\n+\n+\t@Before\n+\tpublic void init() {\n+\t\treader = getReader(CHANNEL, DATA);\n+\t}\n+\n+\t@After\n+\tpublic void tearDown() throws Exception {\n+\t\treader.close();\n+\t}\n+\n+\t@Test\n+\tpublic void testDifferentBufferSizes() throws Exception {\n+\t\tfor (int bufferSize = 1; bufferSize < 2 * DATA.length; bufferSize++) {\n+\t\t\ttry (ChannelStateReaderImpl reader = getReader(CHANNEL, DATA)) { // re-create reader to re-read the same channel\n+\t\t\t\treadAndVerify(bufferSize, CHANNEL, DATA, reader);\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\t@Test\n+\tpublic void testWithOffsets() throws IOException {\n+\t\tMap<InputChannelStateHandle, byte[]> handlesAndBytes = generateHandlesWithBytes(10, 20);\n+\t\tChannelStateReader reader = new ChannelStateReaderImpl(taskStateSnapshot(handlesAndBytes.keySet()), new ChannelStateSerializerImpl());\n+\t\tfor (Map.Entry<InputChannelStateHandle, byte[]> e : handlesAndBytes.entrySet()) {\n+\t\t\treadAndVerify(42, e.getKey().getInfo(), e.getValue(), reader);\n+\t\t}\n+\t}\n+\n+\t@Test(expected = Exception.class)\n+\tpublic void testReadOnlyOnce() throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 89}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg5ODQ1Njg5", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-389845689", "createdAt": "2020-04-08T10:25:04Z", "commit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxMDoyNTowNVrOGCo6IA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxMDoyNTowNVrOGCo6IA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQyMDU3Ng==", "bodyText": "close the stream at the end?", "url": "https://github.com/apache/flink/pull/11515#discussion_r405420576", "createdAt": "2020-04-08T10:25:05Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializerImplTest.java", "diffHunk": "@@ -0,0 +1,108 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.memory.HeapMemorySegment;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.io.network.buffer.BufferConsumer;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+\n+import org.junit.Test;\n+\n+import java.io.ByteArrayInputStream;\n+import java.io.ByteArrayOutputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Random;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateByteBuffer.wrap;\n+import static org.junit.Assert.assertArrayEquals;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+\n+/**\n+ * {@link ChannelStateSerializerImpl} test.\n+ */\n+public class ChannelStateSerializerImplTest {\n+\n+\tprivate final Random random = new Random();\n+\n+\t@Test\n+\tpublic void testWriteRead() throws IOException {\n+\t\tint bufSize = 10;\n+\t\tint[] numBuffersToWriteAtOnce = {0, 1, 2, 3};\n+\t\tbyte[] data = getData(bufSize);\n+\t\tChannelStateSerializer s = new ChannelStateSerializerImpl();\n+\t\tByteArrayOutputStream baos = new ByteArrayOutputStream();\n+\t\tDataOutputStream out = new DataOutputStream(baos);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 55}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg5ODUxMTYy", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-389851162", "createdAt": "2020-04-08T10:33:19Z", "commit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxMDozMzoxOVrOGCpLzA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxMDozMzoxOVrOGCpLzA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQyNTEwMA==", "bodyText": "nit: this can be reused in other places, like ChannelStateSerializerImplTest#getData(int len), ChannelStateSerializerTest#randomBytes", "url": "https://github.com/apache/flink/pull/11515#discussion_r405425100", "createdAt": "2020-04-08T10:33:19Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImplTest.java", "diffHunk": "@@ -0,0 +1,205 @@\n+package org.apache.flink.runtime.checkpoint.channel;\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+import org.apache.flink.core.memory.HeapMemorySegment;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.StateObjectCollection;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.runtime.state.memory.ByteStreamStateHandle;\n+\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Random;\n+\n+import static java.util.Collections.singletonList;\n+import static java.util.stream.Collectors.toMap;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.HAS_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+import static org.junit.Assert.assertArrayEquals;\n+import static org.junit.Assert.assertEquals;\n+\n+/**\n+ * {@link ChannelStateReaderImpl} test.\n+ */\n+public class ChannelStateReaderImplTest {\n+\n+\tprivate static final InputChannelInfo CHANNEL = new InputChannelInfo(1, 2);\n+\tprivate static final byte[] DATA = generateData(10);\n+\tprivate ChannelStateReaderImpl reader;\n+\n+\t@Before\n+\tpublic void init() {\n+\t\treader = getReader(CHANNEL, DATA);\n+\t}\n+\n+\t@After\n+\tpublic void tearDown() throws Exception {\n+\t\treader.close();\n+\t}\n+\n+\t@Test\n+\tpublic void testDifferentBufferSizes() throws Exception {\n+\t\tfor (int bufferSize = 1; bufferSize < 2 * DATA.length; bufferSize++) {\n+\t\t\ttry (ChannelStateReaderImpl reader = getReader(CHANNEL, DATA)) { // re-create reader to re-read the same channel\n+\t\t\t\treadAndVerify(bufferSize, CHANNEL, DATA, reader);\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\t@Test\n+\tpublic void testWithOffsets() throws IOException {\n+\t\tMap<InputChannelStateHandle, byte[]> handlesAndBytes = generateHandlesWithBytes(10, 20);\n+\t\tChannelStateReader reader = new ChannelStateReaderImpl(taskStateSnapshot(handlesAndBytes.keySet()), new ChannelStateSerializerImpl());\n+\t\tfor (Map.Entry<InputChannelStateHandle, byte[]> e : handlesAndBytes.entrySet()) {\n+\t\t\treadAndVerify(42, e.getKey().getInfo(), e.getValue(), reader);\n+\t\t}\n+\t}\n+\n+\t@Test(expected = Exception.class)\n+\tpublic void testReadOnlyOnce() throws IOException {\n+\t\treader.readInputData(CHANNEL, getBuffer(DATA.length));\n+\t\treader.readInputData(CHANNEL, getBuffer(DATA.length));\n+\t}\n+\n+\t@Test(expected = Exception.class)\n+\tpublic void testReadClosed() throws Exception {\n+\t\treader.close();\n+\t\treader.readInputData(CHANNEL, getBuffer(DATA.length));\n+\t}\n+\n+\t@Test(expected = IllegalArgumentException.class)\n+\tpublic void testReadWrongChannelState() throws IOException {\n+\t\tInputChannelInfo wrongChannel = new InputChannelInfo(CHANNEL.getGateIdx() + 1, CHANNEL.getInputChannelIdx() + 1);\n+\t\treader.readInputData(wrongChannel, getBuffer(DATA.length));\n+\t}\n+\n+\tprivate TaskStateSnapshot taskStateSnapshot(Collection<InputChannelStateHandle> inputChannelStateHandles) {\n+\t\treturn new TaskStateSnapshot(Collections.singletonMap(\n+\t\t\tnew OperatorID(),\n+\t\t\tnew OperatorSubtaskState(\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tnew StateObjectCollection<>(inputChannelStateHandles),\n+\t\t\t\tStateObjectCollection.empty()\n+\t\t\t)));\n+\t}\n+\n+\tprivate static byte[] generateData(int len) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 119}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg5ODU1MDk3", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-389855097", "createdAt": "2020-04-08T10:39:31Z", "commit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxMDozOTozMlrOGCpYTQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxMDozOTozMlrOGCpYTQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQyODMwMQ==", "bodyText": "This class can be merged with ChannelStateSerializerImplTest, because they are all aiming for testing the ChannelStateSerializerImpl actually, for wrapping BufferBuilder, Buffer, and bytes[] separately in different tests.", "url": "https://github.com/apache/flink/pull/11515#discussion_r405428301", "createdAt": "2020-04-08T10:39:32Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializerTest.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.memory.MemorySegmentFactory;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+\n+import org.junit.Test;\n+\n+import java.io.ByteArrayInputStream;\n+import java.io.ByteArrayOutputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.util.Random;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateByteBuffer.wrap;\n+import static org.junit.Assert.assertArrayEquals;\n+import static org.junit.Assert.assertEquals;\n+\n+/**\n+ * ChannelStateSerializerTest.\n+ */\n+public class ChannelStateSerializerTest {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 40}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg5OTMzMzQ0", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-389933344", "createdAt": "2020-04-08T12:39:17Z", "commit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxMjozOToxOFrOGCtRZg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxMjozOToxOFrOGCtRZg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQ5MjA3MA==", "bodyText": "eventBuf.recycleBuffer()", "url": "https://github.com/apache/flink/pull/11515#discussion_r405492070", "createdAt": "2020-04-08T12:39:18Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImplTest.java", "diffHunk": "@@ -0,0 +1,320 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.memory.HeapMemorySegment;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.util.function.BiConsumerWithException;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.ArrayDeque;\n+import java.util.Deque;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.function.Consumer;\n+\n+import static org.apache.flink.runtime.state.ChannelPersistenceITCase.getStreamFactoryFactory;\n+import static org.apache.flink.util.ExceptionUtils.findThrowable;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * {@link ChannelStateWriterImpl} lifecycle tests.\n+ */\n+public class ChannelStateWriterImplTest {\n+\tprivate static final long CHECKPOINT_ID = 42L;\n+\n+\t@Test(expected = IllegalArgumentException.class)\n+\tpublic void testAddEventBuffer() {\n+\t\tNetworkBuffer dataBuf = getBuffer();\n+\t\tNetworkBuffer eventBuf = getBuffer();\n+\t\teventBuf.tagAsEvent();\n+\t\tChannelStateWriterImpl writer = openWriter();\n+\t\tcallStart(writer);\n+\t\ttry {\n+\t\t\twriter.addInputData(CHECKPOINT_ID, new InputChannelInfo(1, 1), 1, eventBuf, dataBuf);\n+\t\t} finally {\n+\t\t\tassertTrue(dataBuf.isRecycled());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 57}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg5OTY0OTc0", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-389964974", "createdAt": "2020-04-08T13:18:55Z", "commit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxMzoxODo1NlrOGCu1ug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxMzoxODo1NlrOGCu1ug==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTUxNzc1NA==", "bodyText": "The worker should start after created, otherwise even though we do not call close via WorkerClosingDeque, it can still encounter exception as did in testSubmitFailure.", "url": "https://github.com/apache/flink/pull/11515#discussion_r405517754", "createdAt": "2020-04-08T13:18:56Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestExecutorImplTest.java", "diffHunk": "@@ -0,0 +1,203 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.function.BiConsumerWithException;\n+\n+import org.junit.Test;\n+\n+import javax.annotation.Nonnull;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.concurrent.LinkedBlockingDeque;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequestDispatcher.NO_OP;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * {@link ChannelStateWriteRequestExecutorImpl} test.\n+ */\n+public class ChannelStateWriteRequestExecutorImplTest {\n+\n+\t@Test(expected = IllegalStateException.class)\n+\tpublic void testCloseAfterSubmit() throws Exception {\n+\t\ttestCloseAfterSubmit(ChannelStateWriteRequestExecutor::submit);\n+\t}\n+\n+\t@Test(expected = IllegalStateException.class)\n+\tpublic void testCloseAfterSubmitPriority() throws Exception {\n+\t\ttestCloseAfterSubmit(ChannelStateWriteRequestExecutor::submitPriority);\n+\t}\n+\n+\t@Test\n+\tpublic void testSubmitFailure() throws Exception {\n+\t\ttestSubmitFailure(ChannelStateWriteRequestExecutor::submit);\n+\t}\n+\n+\t@Test\n+\tpublic void testSubmitPriorityFailure() throws Exception {\n+\t\ttestSubmitFailure(ChannelStateWriteRequestExecutor::submitPriority);\n+\t}\n+\n+\tprivate void testCloseAfterSubmit(BiConsumerWithException<ChannelStateWriteRequestExecutor, ChannelStateWriteRequest, Exception> requestFun) throws Exception {\n+\t\tWorkerClosingDeque closingDeque = new WorkerClosingDeque();\n+\t\tChannelStateWriteRequestExecutorImpl worker = new ChannelStateWriteRequestExecutorImpl(NO_OP, closingDeque);\n+\t\tclosingDeque.setWorker(worker);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 63}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkwMDc1NTM2", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-390075536", "createdAt": "2020-04-08T15:18:02Z", "commit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxNToxODowMlrOGC0JLQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxNToxODowMlrOGC0JLQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTYwNDY1Mw==", "bodyText": "I am not quite clear what is this test motivation for. When the dispatcher throws exception, it would terminate the internal thread inside ChannelStateWriteRequestExecutorImpl. And when the worker#close, it should throw exception actually, i think we should verify the exception is same with testException", "url": "https://github.com/apache/flink/pull/11515#discussion_r405604653", "createdAt": "2020-04-08T15:18:02Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestExecutorImplTest.java", "diffHunk": "@@ -0,0 +1,203 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.function.BiConsumerWithException;\n+\n+import org.junit.Test;\n+\n+import javax.annotation.Nonnull;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.concurrent.LinkedBlockingDeque;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequestDispatcher.NO_OP;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * {@link ChannelStateWriteRequestExecutorImpl} test.\n+ */\n+public class ChannelStateWriteRequestExecutorImplTest {\n+\n+\t@Test(expected = IllegalStateException.class)\n+\tpublic void testCloseAfterSubmit() throws Exception {\n+\t\ttestCloseAfterSubmit(ChannelStateWriteRequestExecutor::submit);\n+\t}\n+\n+\t@Test(expected = IllegalStateException.class)\n+\tpublic void testCloseAfterSubmitPriority() throws Exception {\n+\t\ttestCloseAfterSubmit(ChannelStateWriteRequestExecutor::submitPriority);\n+\t}\n+\n+\t@Test\n+\tpublic void testSubmitFailure() throws Exception {\n+\t\ttestSubmitFailure(ChannelStateWriteRequestExecutor::submit);\n+\t}\n+\n+\t@Test\n+\tpublic void testSubmitPriorityFailure() throws Exception {\n+\t\ttestSubmitFailure(ChannelStateWriteRequestExecutor::submitPriority);\n+\t}\n+\n+\tprivate void testCloseAfterSubmit(BiConsumerWithException<ChannelStateWriteRequestExecutor, ChannelStateWriteRequest, Exception> requestFun) throws Exception {\n+\t\tWorkerClosingDeque closingDeque = new WorkerClosingDeque();\n+\t\tChannelStateWriteRequestExecutorImpl worker = new ChannelStateWriteRequestExecutorImpl(NO_OP, closingDeque);\n+\t\tclosingDeque.setWorker(worker);\n+\t\tTestWriteRequest request = new TestWriteRequest();\n+\t\trequestFun.accept(worker, request);\n+\t\tassertTrue(closingDeque.isEmpty());\n+\t\tassertFalse(request.isCancelled());\n+\t}\n+\n+\tprivate void testSubmitFailure(BiConsumerWithException<ChannelStateWriteRequestExecutor, ChannelStateWriteRequest, Exception> submitAction) throws Exception {\n+\t\tTestWriteRequest request = new TestWriteRequest();\n+\t\tLinkedBlockingDeque<ChannelStateWriteRequest> deque = new LinkedBlockingDeque<>();\n+\t\ttry {\n+\t\t\tsubmitAction.accept(new ChannelStateWriteRequestExecutorImpl(NO_OP, deque), request);\n+\t\t} catch (IllegalStateException e) {\n+\t\t\t// expected: executor not started;\n+\t\t\treturn;\n+\t\t} finally {\n+\t\t\tassertTrue(request.cancelled);\n+\t\t\tassertTrue(deque.isEmpty());\n+\t\t}\n+\t\tthrow new RuntimeException(\"expected exception not thrown\");\n+\t}\n+\n+\t@Test\n+\t@SuppressWarnings(\"CallToThreadRun\")\n+\tpublic void testCleanup() throws IOException {\n+\t\tTestWriteRequest request = new TestWriteRequest();\n+\t\tLinkedBlockingDeque<ChannelStateWriteRequest> deque = new LinkedBlockingDeque<>();\n+\t\tdeque.add(request);\n+\t\tTestRequestDispatcher requestProcessor = new TestRequestDispatcher();\n+\t\tChannelStateWriteRequestExecutorImpl worker = new ChannelStateWriteRequestExecutorImpl(requestProcessor, deque);\n+\n+\t\tworker.close();\n+\t\tworker.run();\n+\n+\t\tassertTrue(requestProcessor.isStopped());\n+\t\tassertTrue(deque.isEmpty());\n+\t\tassertTrue(request.isCancelled());\n+\t}\n+\n+\t@Test\n+\tpublic void testIgnoresInterruptsWhileRunning() throws Exception {\n+\t\tTestRequestDispatcher requestProcessor = new TestRequestDispatcher();\n+\t\tLinkedBlockingDeque<ChannelStateWriteRequest> deque = new LinkedBlockingDeque<>();\n+\t\ttry (ChannelStateWriteRequestExecutorImpl worker = new ChannelStateWriteRequestExecutorImpl(requestProcessor, deque)) {\n+\t\t\tworker.start();\n+\t\t\tworker.getThread().interrupt();\n+\t\t\tworker.submit(new TestWriteRequest());\n+\t\t\tworker.getThread().interrupt();\n+\t\t\twhile (!deque.isEmpty()) {\n+\t\t\t\tThread.sleep(100);\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\t@Test\n+\tpublic void testCanBeClosed() throws IOException {\n+\t\tTestRequestDispatcher requestProcessor = new TestRequestDispatcher();\n+\t\ttry (ChannelStateWriteRequestExecutorImpl worker = new ChannelStateWriteRequestExecutorImpl(requestProcessor)) {\n+\t\t\tworker.start();\n+\t\t}\n+\t}\n+\n+\t@Test\n+\tpublic void testRecordsException() throws Exception {\n+\t\tTestException testException = new TestException();\n+\t\tTestRequestDispatcher requestProcessor = new TestRequestDispatcher() {\n+\t\t\t@Override\n+\t\t\tpublic void dispatch(ChannelStateWriteRequest request) {\n+\t\t\t\tthrow testException;\n+\t\t\t}\n+\t\t};\n+\t\tLinkedBlockingDeque<ChannelStateWriteRequest> deque = new LinkedBlockingDeque<>(Arrays.asList(new TestWriteRequest()));\n+\t\ttry (ChannelStateWriteRequestExecutorImpl worker = new ChannelStateWriteRequestExecutorImpl(requestProcessor, deque)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 135}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkwMDk0MDIx", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-390094021", "createdAt": "2020-04-08T15:38:10Z", "commit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxNTozODoxMVrOGC1EmA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxNTozODoxMVrOGC1EmA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTYxOTg2NA==", "bodyText": "I guess it is not determined results? When the writer#close, then it relies on ChannelStateWriteRequestExecutorImpl#cleanupRequests to cancel the start request to complete the result. But if the start request was already taken away from the queue by internal thread before, then we can not take it from queue to cancel. Or I missed something else?", "url": "https://github.com/apache/flink/pull/11515#discussion_r405619864", "createdAt": "2020-04-08T15:38:11Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImplTest.java", "diffHunk": "@@ -0,0 +1,320 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.memory.HeapMemorySegment;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.util.function.BiConsumerWithException;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.ArrayDeque;\n+import java.util.Deque;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.function.Consumer;\n+\n+import static org.apache.flink.runtime.state.ChannelPersistenceITCase.getStreamFactoryFactory;\n+import static org.apache.flink.util.ExceptionUtils.findThrowable;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * {@link ChannelStateWriterImpl} lifecycle tests.\n+ */\n+public class ChannelStateWriterImplTest {\n+\tprivate static final long CHECKPOINT_ID = 42L;\n+\n+\t@Test(expected = IllegalArgumentException.class)\n+\tpublic void testAddEventBuffer() {\n+\t\tNetworkBuffer dataBuf = getBuffer();\n+\t\tNetworkBuffer eventBuf = getBuffer();\n+\t\teventBuf.tagAsEvent();\n+\t\tChannelStateWriterImpl writer = openWriter();\n+\t\tcallStart(writer);\n+\t\ttry {\n+\t\t\twriter.addInputData(CHECKPOINT_ID, new InputChannelInfo(1, 1), 1, eventBuf, dataBuf);\n+\t\t} finally {\n+\t\t\tassertTrue(dataBuf.isRecycled());\n+\t\t}\n+\t}\n+\n+\t@Test\n+\tpublic void testResultCompletion() throws IOException {\n+\t\tChannelStateWriteResult result;\n+\t\ttry (ChannelStateWriterImpl writer = openWriter()) {\n+\t\t\tcallStart(writer);\n+\t\t\tresult = writer.getWriteResult(CHECKPOINT_ID);\n+\t\t\tassertFalse(result.resultSubpartitionStateHandles.isDone());\n+\t\t\tassertFalse(result.inputChannelStateHandles.isDone());\n+\t\t}\n+\t\tassertTrue(result.inputChannelStateHandles.isDone());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 70}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkwMDk1Mjc3", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-390095277", "createdAt": "2020-04-08T15:39:36Z", "commit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxNTozOTozNlrOGC1Ijg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxNTozOTozNlrOGC1Ijg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTYyMDg3OA==", "bodyText": "indentation formatting", "url": "https://github.com/apache/flink/pull/11515#discussion_r405620878", "createdAt": "2020-04-08T15:39:36Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImplTest.java", "diffHunk": "@@ -0,0 +1,320 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.memory.HeapMemorySegment;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.util.function.BiConsumerWithException;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.ArrayDeque;\n+import java.util.Deque;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.function.Consumer;\n+\n+import static org.apache.flink.runtime.state.ChannelPersistenceITCase.getStreamFactoryFactory;\n+import static org.apache.flink.util.ExceptionUtils.findThrowable;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * {@link ChannelStateWriterImpl} lifecycle tests.\n+ */\n+public class ChannelStateWriterImplTest {\n+\tprivate static final long CHECKPOINT_ID = 42L;\n+\n+\t@Test(expected = IllegalArgumentException.class)\n+\tpublic void testAddEventBuffer() {\n+\t\tNetworkBuffer dataBuf = getBuffer();\n+\t\tNetworkBuffer eventBuf = getBuffer();\n+\t\teventBuf.tagAsEvent();\n+\t\tChannelStateWriterImpl writer = openWriter();\n+\t\tcallStart(writer);\n+\t\ttry {\n+\t\t\twriter.addInputData(CHECKPOINT_ID, new InputChannelInfo(1, 1), 1, eventBuf, dataBuf);\n+\t\t} finally {\n+\t\t\tassertTrue(dataBuf.isRecycled());\n+\t\t}\n+\t}\n+\n+\t@Test\n+\tpublic void testResultCompletion() throws IOException {\n+\t\tChannelStateWriteResult result;\n+\t\ttry (ChannelStateWriterImpl writer = openWriter()) {\n+\t\t\tcallStart(writer);\n+\t\t\tresult = writer.getWriteResult(CHECKPOINT_ID);\n+\t\t\tassertFalse(result.resultSubpartitionStateHandles.isDone());\n+\t\t\tassertFalse(result.inputChannelStateHandles.isDone());\n+\t\t}\n+\t\tassertTrue(result.inputChannelStateHandles.isDone());\n+\t\tassertTrue(result.resultSubpartitionStateHandles.isDone());\n+\t}\n+\n+\t@Test\n+\tpublic void testAbort() throws Exception {\n+\t\tNetworkBuffer buffer = getBuffer();\n+\t\trunWithSyncWorker((writer, worker) -> {\n+\t\t\tcallStart(writer);\n+\t\t\tcallAddInputData(writer, buffer);\n+\t\t\tcallAbort(writer);\n+\t\t\tworker.processAllRequests();\n+\t\t\tassertTrue(writer.getWriteResult(CHECKPOINT_ID).isDone());\n+\t\t\tassertTrue(buffer.isRecycled());\n+\t\t});\n+\t}\n+\n+\t@Test\n+\tpublic void testAbortIgnoresMissing() throws Exception {\n+\t\trunWithSyncWorker(this::callAbort);\n+\t}\n+\n+\t@Test(expected = TestException.class)\n+\tpublic void testBuffersRecycledOnError() throws Exception {\n+\t\tunwrappingError(TestException.class, () -> {\n+\t\t\tNetworkBuffer buffer = getBuffer();\n+\t\t\ttry (ChannelStateWriterImpl writer = new ChannelStateWriterImpl(new ConcurrentHashMap<>(), failingWorker(), 5)) {\n+\t\t\t\twriter.open();\n+\t\t\t\tcallAddInputData(writer, buffer);\n+\t\t\t} finally {\n+\t\t\t\tassertTrue(buffer.isRecycled());\n+\t\t\t}\n+\t\t});\n+\t}\n+\n+\t@Test\n+\tpublic void testBuffersRecycledOnClose() throws IOException {\n+\t\tNetworkBuffer buffer = getBuffer();\n+\t\ttry (ChannelStateWriterImpl writer = openWriter()) {\n+\t\t\tcallStart(writer);\n+\t\t\tcallAddInputData(writer, buffer);\n+\t\t\tassertFalse(buffer.isRecycled());\n+\t\t}\n+\t\tassertTrue(buffer.isRecycled());\n+\t}\n+\n+\t@Test(expected = IllegalArgumentException.class)\n+\tpublic void testNoAddDataAfterFinished() throws Exception {\n+\t\tunwrappingError(IllegalArgumentException.class, () -> runWithSyncWorker(\n+\t\t\twriter -> {\n+\t\t\t\tcallStart(writer);\n+\t\t\t\tcallFinish(writer);\n+\t\t\t\tcallAddInputData(writer);\n+\t\t\t}\n+\t\t));\n+\t}\n+\n+\t@Test(expected = IllegalArgumentException.class)\n+\tpublic void testAddDataNotStarted() throws Exception {\n+\t\tunwrappingError(IllegalArgumentException.class, () -> runWithSyncWorker(writer -> callAddInputData(writer)));\n+\t}\n+\n+\t@Test(expected = IllegalArgumentException.class)\n+\tpublic void testFinishNotStarted() throws Exception {\n+\t\tunwrappingError(IllegalArgumentException.class, () -> runWithSyncWorker(this::callFinish));\n+\t}\n+\n+\t@Test(expected = IllegalArgumentException.class)\n+\tpublic void testRethrowOnClose() throws Exception {\n+\t\tunwrappingError(IllegalArgumentException.class, () -> runWithSyncWorker(\n+\t\t\twriter -> {\n+\t\t\t\ttry {\n+\t\t\t\t\tcallFinish(writer);\n+\t\t\t\t} catch (IllegalArgumentException e) {\n+\t\t\t\t\t// ignore here - should rethrow in close\n+\t\t\t\t}\n+\t\t\t}\n+\t\t));\n+\t}\n+\n+\t@Test(expected = TestException.class)\n+\tpublic void testRethrowOnNextCall() throws Exception {\n+\t\tSyncChannelStateWriteRequestExecutor worker = new SyncChannelStateWriteRequestExecutor();\n+\t\tChannelStateWriterImpl writer = new ChannelStateWriterImpl(new ConcurrentHashMap<>(), worker, 5);\n+\t\twriter.open();\n+\t\tworker.setThrown(new TestException());\n+\t\tunwrappingError(TestException.class, () -> callStart(writer));\n+\t}\n+\n+\t@Test(expected = IllegalStateException.class)\n+\tpublic void testLimit() throws IOException {\n+\t\tint maxCheckpoints = 3;\n+\t\ttry (ChannelStateWriterImpl writer = new ChannelStateWriterImpl(getStreamFactoryFactory(), maxCheckpoints)) {\n+\t\t\twriter.open();\n+\t\t\tfor (int i = 0; i < maxCheckpoints; i++) {\n+\t\t\t\twriter.start(i, CheckpointOptions.forCheckpointWithDefaultLocation());\n+\t\t\t}\n+\t\t\twriter.start(maxCheckpoints, CheckpointOptions.forCheckpointWithDefaultLocation());\n+\t\t}\n+\t}\n+\n+\t@Test(expected = IllegalStateException.class)\n+\tpublic void testStartNotOpened() throws Exception {\n+\t\tunwrappingError(IllegalStateException.class, () -> {\n+\t\t\ttry (ChannelStateWriterImpl writer = new ChannelStateWriterImpl(getStreamFactoryFactory())) {\n+\t\t\t\tcallStart(writer);\n+\t\t\t}\n+\t\t});\n+\t}\n+\n+\t@Test(expected = IllegalStateException.class)\n+\tpublic void testNoStartAfterClose() throws Exception {\n+\t\tunwrappingError(IllegalStateException.class, () -> {\n+\t\t\tChannelStateWriterImpl writer = openWriter();\n+\t\t\twriter.close();\n+\t\t\twriter.start(42, CheckpointOptions.forCheckpointWithDefaultLocation());\n+\t\t});\n+\t}\n+\n+\t@Test(expected = IllegalStateException.class)\n+\tpublic void testNoAddDataAfterClose() throws Exception {\n+\t\tunwrappingError(IllegalStateException.class, () -> {\n+\t\t\tChannelStateWriterImpl writer = openWriter();\n+\t\t\tcallStart(writer);\n+\t\t\twriter.close();\n+\t\t\tcallAddInputData(writer);\n+\t\t});\n+\t}\n+\n+\tprivate static <T extends Throwable> void unwrappingError(Class<T> clazz, RunnableWithException r) throws Exception {\n+\t\ttry {\n+\t\t\tr.run();\n+\t\t} catch (Exception e) {\n+\t\t\tthrow findThrowable(e, clazz).map(te -> (Exception) te).orElse(e);\n+\t\t}\n+\t}\n+\n+\tprivate NetworkBuffer getBuffer() {\n+\t\treturn new NetworkBuffer(HeapMemorySegment.FACTORY.allocateUnpooledSegment(123, null), FreeingBufferRecycler.INSTANCE);\n+\t}\n+\n+\tprivate ChannelStateWriteRequestExecutor failingWorker() {\n+\t\treturn new ChannelStateWriteRequestExecutor() {\n+\t\t\t@Override\n+\t\t\tpublic void close() {\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic void submit(ChannelStateWriteRequest e) {\n+\t\t\t\tthrow new TestException();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic void submitPriority(ChannelStateWriteRequest e) {\n+\t\t\t\tthrow new TestException();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic void start() throws IllegalStateException {\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tprivate void runWithSyncWorker(Consumer<ChannelStateWriter> writerConsumer) throws Exception {\n+\t\trunWithSyncWorker((channelStateWriter, syncChannelStateWriterWorker) -> writerConsumer.accept(channelStateWriter));\n+\t}\n+\n+\tprivate void runWithSyncWorker(BiConsumerWithException<ChannelStateWriter, SyncChannelStateWriteRequestExecutor, Exception> testFn) throws Exception {\n+\t\ttry (\n+\t\t\t\tSyncChannelStateWriteRequestExecutor worker = new SyncChannelStateWriteRequestExecutor();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 239}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkwMTEyNDk1", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-390112495", "createdAt": "2020-04-08T15:58:43Z", "commit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxNTo1ODo0M1rOGC1-Ug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxNTo1ODo0M1rOGC1-Ug==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTYzNDY0Mg==", "bodyText": "seems unstable results? After callAddInputData, if the enqueued buffer is already dispatched to be executed by internal thread, then the buffer should be recycled when this assert calls. Although this probability is very small, but in theory it is not stable and easily fragile.", "url": "https://github.com/apache/flink/pull/11515#discussion_r405634642", "createdAt": "2020-04-08T15:58:43Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImplTest.java", "diffHunk": "@@ -0,0 +1,320 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.memory.HeapMemorySegment;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.util.function.BiConsumerWithException;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.ArrayDeque;\n+import java.util.Deque;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.function.Consumer;\n+\n+import static org.apache.flink.runtime.state.ChannelPersistenceITCase.getStreamFactoryFactory;\n+import static org.apache.flink.util.ExceptionUtils.findThrowable;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * {@link ChannelStateWriterImpl} lifecycle tests.\n+ */\n+public class ChannelStateWriterImplTest {\n+\tprivate static final long CHECKPOINT_ID = 42L;\n+\n+\t@Test(expected = IllegalArgumentException.class)\n+\tpublic void testAddEventBuffer() {\n+\t\tNetworkBuffer dataBuf = getBuffer();\n+\t\tNetworkBuffer eventBuf = getBuffer();\n+\t\teventBuf.tagAsEvent();\n+\t\tChannelStateWriterImpl writer = openWriter();\n+\t\tcallStart(writer);\n+\t\ttry {\n+\t\t\twriter.addInputData(CHECKPOINT_ID, new InputChannelInfo(1, 1), 1, eventBuf, dataBuf);\n+\t\t} finally {\n+\t\t\tassertTrue(dataBuf.isRecycled());\n+\t\t}\n+\t}\n+\n+\t@Test\n+\tpublic void testResultCompletion() throws IOException {\n+\t\tChannelStateWriteResult result;\n+\t\ttry (ChannelStateWriterImpl writer = openWriter()) {\n+\t\t\tcallStart(writer);\n+\t\t\tresult = writer.getWriteResult(CHECKPOINT_ID);\n+\t\t\tassertFalse(result.resultSubpartitionStateHandles.isDone());\n+\t\t\tassertFalse(result.inputChannelStateHandles.isDone());\n+\t\t}\n+\t\tassertTrue(result.inputChannelStateHandles.isDone());\n+\t\tassertTrue(result.resultSubpartitionStateHandles.isDone());\n+\t}\n+\n+\t@Test\n+\tpublic void testAbort() throws Exception {\n+\t\tNetworkBuffer buffer = getBuffer();\n+\t\trunWithSyncWorker((writer, worker) -> {\n+\t\t\tcallStart(writer);\n+\t\t\tcallAddInputData(writer, buffer);\n+\t\t\tcallAbort(writer);\n+\t\t\tworker.processAllRequests();\n+\t\t\tassertTrue(writer.getWriteResult(CHECKPOINT_ID).isDone());\n+\t\t\tassertTrue(buffer.isRecycled());\n+\t\t});\n+\t}\n+\n+\t@Test\n+\tpublic void testAbortIgnoresMissing() throws Exception {\n+\t\trunWithSyncWorker(this::callAbort);\n+\t}\n+\n+\t@Test(expected = TestException.class)\n+\tpublic void testBuffersRecycledOnError() throws Exception {\n+\t\tunwrappingError(TestException.class, () -> {\n+\t\t\tNetworkBuffer buffer = getBuffer();\n+\t\t\ttry (ChannelStateWriterImpl writer = new ChannelStateWriterImpl(new ConcurrentHashMap<>(), failingWorker(), 5)) {\n+\t\t\t\twriter.open();\n+\t\t\t\tcallAddInputData(writer, buffer);\n+\t\t\t} finally {\n+\t\t\t\tassertTrue(buffer.isRecycled());\n+\t\t\t}\n+\t\t});\n+\t}\n+\n+\t@Test\n+\tpublic void testBuffersRecycledOnClose() throws IOException {\n+\t\tNetworkBuffer buffer = getBuffer();\n+\t\ttry (ChannelStateWriterImpl writer = openWriter()) {\n+\t\t\tcallStart(writer);\n+\t\t\tcallAddInputData(writer, buffer);\n+\t\t\tassertFalse(buffer.isRecycled());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 111}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkwMTM3Njg1", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-390137685", "createdAt": "2020-04-08T16:28:43Z", "commit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxNjoyODo0M1rOGC3NJQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxNjoyODo0M1rOGC3NJQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTY1NDgyMQ==", "bodyText": "unused method", "url": "https://github.com/apache/flink/pull/11515#discussion_r405654821", "createdAt": "2020-04-08T16:28:43Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/state/ChannelPersistenceITCase.java", "diffHunk": "@@ -0,0 +1,179 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.state;\n+\n+import org.apache.flink.core.memory.HeapMemorySegment;\n+import org.apache.flink.core.memory.MemorySegment;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.StateObjectCollection;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReaderImpl;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriterImpl;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.checkpoint.channel.ResultSubpartitionInfo;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.memory.NonPersistentMetadataCheckpointStorageLocation;\n+import org.apache.flink.util.function.BiFunctionWithException;\n+\n+import org.junit.Test;\n+\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.stream.Collectors;\n+\n+import static java.util.Collections.singletonMap;\n+import static org.apache.flink.runtime.checkpoint.CheckpointType.CHECKPOINT;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.SEQUENCE_NUMBER_UNKNOWN;\n+import static org.apache.flink.util.Preconditions.checkState;\n+import static org.junit.Assert.assertArrayEquals;\n+\n+/**\n+ * ChannelPersistenceITCase.\n+ */\n+public class ChannelPersistenceITCase {\n+\tprivate static final Random RANDOM = new Random(System.currentTimeMillis());\n+\n+\t@Test\n+\tpublic void testReadWritten() throws Exception {\n+\t\tlong checkpointId = 1L;\n+\n+\t\tInputChannelInfo inputChannelInfo = new InputChannelInfo(2, 3);\n+\t\tbyte[] inputChannelInfoData = randomBytes(1024);\n+\n+\t\tResultSubpartitionInfo resultSubpartitionInfo = new ResultSubpartitionInfo(4, 5);\n+\t\tbyte[] resultSubpartitionInfoData = randomBytes(1024);\n+\n+\t\tChannelStateWriteResult handles = write(\n+\t\t\tcheckpointId,\n+\t\t\tsingletonMap(inputChannelInfo, inputChannelInfoData),\n+\t\t\tsingletonMap(resultSubpartitionInfo, resultSubpartitionInfoData)\n+\t\t);\n+\n+\t\tassertArrayEquals(inputChannelInfoData, read(\n+\t\t\ttoTaskStateSnapshot(handles),\n+\t\t\tinputChannelInfoData.length,\n+\t\t\t(reader, mem) -> reader.readInputData(inputChannelInfo, new NetworkBuffer(mem, FreeingBufferRecycler.INSTANCE))\n+\t\t));\n+\n+\t\tassertArrayEquals(resultSubpartitionInfoData, read(\n+\t\t\ttoTaskStateSnapshot(handles),\n+\t\t\tresultSubpartitionInfoData.length,\n+\t\t\t(reader, mem) -> reader.readOutputData(resultSubpartitionInfo, new BufferBuilder(mem, FreeingBufferRecycler.INSTANCE))\n+\t\t));\n+\t}\n+\n+\tprivate byte[] randomBytes(int size) {\n+\t\tbyte[] bytes = new byte[size];\n+\t\tRANDOM.nextBytes(bytes);\n+\t\treturn bytes;\n+\t}\n+\n+\tprivate ChannelStateWriteResult write(long checkpointId, Map<InputChannelInfo, byte[]> icMap, Map<ResultSubpartitionInfo, byte[]> rsMap) throws Exception {\n+\t\tint maxStateSize = sizeOfBytes(icMap) + sizeOfBytes(rsMap) + Long.BYTES * 2;\n+\t\tMap<InputChannelInfo, Buffer> icBuffers = wrapWithBuffers(icMap);\n+\t\tMap<ResultSubpartitionInfo, Buffer> rsBuffers = wrapWithBuffers(rsMap);\n+\t\ttry (ChannelStateWriterImpl writer = new ChannelStateWriterImpl(getStreamFactoryFactory(maxStateSize))) {\n+\t\t\twriter.open();\n+\t\t\twriter.start(checkpointId, new CheckpointOptions(CHECKPOINT, new CheckpointStorageLocationReference(\"poly\".getBytes())));\n+\t\t\tfor (Map.Entry<InputChannelInfo, Buffer> e : icBuffers.entrySet()) {\n+\t\t\t\twriter.addInputData(checkpointId, e.getKey(), SEQUENCE_NUMBER_UNKNOWN, e.getValue());\n+\t\t\t}\n+\t\t\twriter.finishInput(checkpointId);\n+\t\t\tfor (Map.Entry<ResultSubpartitionInfo, Buffer> e : rsBuffers.entrySet()) {\n+\t\t\t\twriter.addOutputData(checkpointId, e.getKey(), SEQUENCE_NUMBER_UNKNOWN, e.getValue());\n+\t\t\t}\n+\t\t\twriter.finishOutput(checkpointId);\n+\t\t\tChannelStateWriteResult result = writer.getWriteResult(checkpointId);\n+\t\t\tresult.getResultSubpartitionStateHandles().join(); // prevent abnormal complete in close\n+\t\t\treturn result;\n+\t\t}\n+\t}\n+\n+\tpublic static CheckpointStorageWorkerView getStreamFactoryFactory() {\n+\t\treturn getStreamFactoryFactory(42);\n+\t}\n+\n+\tpublic static CheckpointStorageWorkerView getStreamFactoryFactory(int maxStateSize) {\n+\t\treturn new CheckpointStorageWorkerView() {\n+\t\t\t@Override\n+\t\t\tpublic CheckpointStreamFactory resolveCheckpointStorageLocation(long checkpointId, CheckpointStorageLocationReference reference) {\n+\t\t\t\treturn new NonPersistentMetadataCheckpointStorageLocation(maxStateSize);\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic CheckpointStreamFactory.CheckpointStateOutputStream createTaskOwnedStateStream() {\n+\t\t\t\tthrow new UnsupportedOperationException();\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tprivate byte[] read(TaskStateSnapshot taskStateSnapshot, int size, BiFunctionWithException<ChannelStateReader, MemorySegment, ReadResult, Exception> readFn) throws Exception {\n+\t\tbyte[] dst = new byte[size];\n+\t\tHeapMemorySegment mem = HeapMemorySegment.FACTORY.wrap(dst);\n+\t\ttry {\n+\t\t\tcheckState(NO_MORE_DATA == readFn.apply(new ChannelStateReaderImpl(taskStateSnapshot), mem));\n+\t\t} finally {\n+\t\t\tmem.free();\n+\t\t}\n+\t\treturn dst;\n+\t}\n+\n+\tprivate TaskStateSnapshot toTaskStateSnapshot(ChannelStateWriteResult t) throws Exception {\n+\t\treturn new TaskStateSnapshot(singletonMap(new OperatorID(),\n+\t\t\tnew OperatorSubtaskState(\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tnew StateObjectCollection<>(t.getInputChannelStateHandles().get()),\n+\t\t\t\tnew StateObjectCollection<>(t.getResultSubpartitionStateHandles().get())\n+\t\t\t)\n+\t\t));\n+\t}\n+\n+\tprivate <C> List<C> collect(Collection<StateObject> handles, Class<C> clazz) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d9acbac249340422dc39bc56ff3aeba49182aa"}, "originalPosition": 160}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkwMTU0MzAz", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-390154303", "createdAt": "2020-04-08T16:50:18Z", "commit": {"oid": "102a8f1f7c4926781fba187273cd6d324f8d0bd2"}, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "102a8f1f7c4926781fba187273cd6d324f8d0bd2", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/102a8f1f7c4926781fba187273cd6d324f8d0bd2", "committedDate": "2020-04-06T19:45:32Z", "message": "[FLINK-16744][task][hotfix] refactor SubtaskCheckpointCoordinatorImpl\nMinor refactoring of  SubtaskCheckpointCoordinatorImpl\nto reduce its methods complexity"}, "afterCommit": {"oid": "393d1c7c6cf588828fa53b4b0bc8f4ef35078625", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/393d1c7c6cf588828fa53b4b0bc8f4ef35078625", "committedDate": "2020-04-08T20:14:33Z", "message": "[FLINK-16744][task][hotfix] Refactor SubtaskCheckpointCoordinatorImpl\n\nMinor refactoring of  SubtaskCheckpointCoordinatorImpl\nto reduce its methods complexity"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "393d1c7c6cf588828fa53b4b0bc8f4ef35078625", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/393d1c7c6cf588828fa53b4b0bc8f4ef35078625", "committedDate": "2020-04-08T20:14:33Z", "message": "[FLINK-16744][task][hotfix] Refactor SubtaskCheckpointCoordinatorImpl\n\nMinor refactoring of  SubtaskCheckpointCoordinatorImpl\nto reduce its methods complexity"}, "afterCommit": {"oid": "72c7b7dd1776d318c09beb6a16836dd7eeff74e8", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/72c7b7dd1776d318c09beb6a16836dd7eeff74e8", "committedDate": "2020-04-08T22:31:17Z", "message": "[FLINK-16744][task][hotfix] Refactor SubtaskCheckpointCoordinatorImpl\n\nMinor refactoring of  SubtaskCheckpointCoordinatorImpl\nto reduce its methods complexity"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "120e5440141b365c890ea402941ad5f74cebe08e", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/120e5440141b365c890ea402941ad5f74cebe08e", "committedDate": "2020-04-09T07:43:28Z", "message": "[FLINK-16744][task][hotfix] Finalize StreamTask methods used during construction\n\nMotivation: prevent access to uninitialized descendant state from\nStreamTask constructor which otherwise leads to NPE"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "72c7b7dd1776d318c09beb6a16836dd7eeff74e8", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/72c7b7dd1776d318c09beb6a16836dd7eeff74e8", "committedDate": "2020-04-08T22:31:17Z", "message": "[FLINK-16744][task][hotfix] Refactor SubtaskCheckpointCoordinatorImpl\n\nMinor refactoring of  SubtaskCheckpointCoordinatorImpl\nto reduce its methods complexity"}, "afterCommit": {"oid": "51f87a7f28e67c5af1f2e500e4364957957fe591", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/51f87a7f28e67c5af1f2e500e4364957957fe591", "committedDate": "2020-04-09T07:43:29Z", "message": "[FLINK-16744][task][hotfix] Refactor SubtaskCheckpointCoordinatorImpl\n\nMinor refactoring of  SubtaskCheckpointCoordinatorImpl\nto reduce its methods complexity"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkwODkzNTA2", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-390893506", "createdAt": "2020-04-09T15:22:44Z", "commit": {"oid": "51f87a7f28e67c5af1f2e500e4364957957fe591"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5001eeaf884a9dea356c1fcbb936564c67764fc8", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/5001eeaf884a9dea356c1fcbb936564c67764fc8", "committedDate": "2020-04-09T18:37:24Z", "message": "[FLINK-16744][task][refactor] Extract SubtaskCheckpointCoordinator\n\nMotivation:\n1. move checkpoint-related responsibilities out of StreamTask\n2. ability to cache checkpoint storage locations for unaligned checkpoints"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "db44a10215580e6ad0dd28b769a8d8c3f2b409a3", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/db44a10215580e6ad0dd28b769a8d8c3f2b409a3", "committedDate": "2020-04-09T18:37:24Z", "message": "[FLINK-16744][task] Send channel state handles to JM\n\n1. add channel state writer to SubtaskCheckpointCoordinator\n2. add handles to the reported snapshot\n3. cache checkpoint locations to prevent multiple streams\nper checkpoint. With unaligned checkpoints, checkpoint\ncan be initiated from several places which can result\n(without cache) in multiple streams/files for a single\ncheckpoint"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4ed4c52e78481c53e9c9348232a489430c3d6f2c", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/4ed4c52e78481c53e9c9348232a489430c3d6f2c", "committedDate": "2020-04-09T18:37:24Z", "message": "[FLINK-16744][task][test][hotfix] Fix formatting\n\nRemove extra newline in TestTaskStateManager"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8492dd04cdb1712069f6d1c1abf39acbae60aaa2", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/8492dd04cdb1712069f6d1c1abf39acbae60aaa2", "committedDate": "2020-04-09T18:37:24Z", "message": "[FLINK-16744][task][hotfix] Refactor SubtaskCheckpointCoordinatorImpl\n\nMinor refactoring of  SubtaskCheckpointCoordinatorImpl\nto reduce its methods complexity"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c3618403513b13e3941e199e0fddb335131a8f35", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/c3618403513b13e3941e199e0fddb335131a8f35", "committedDate": "2020-04-09T18:37:38Z", "message": "[FLINK-16744][task] Split finish() in ChannelStateWriter\n\nSplit finish() in ChannelStateWriter into finishIn and finishOut to ease client usage"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a5b7e1f68058e8342ef20f068b33192f65cdefd4", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/a5b7e1f68058e8342ef20f068b33192f65cdefd4", "committedDate": "2020-04-09T18:37:24Z", "message": "[FLINK-16744][task] Implement channel state reading and writing for unaligned checkpoints"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "51f87a7f28e67c5af1f2e500e4364957957fe591", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/51f87a7f28e67c5af1f2e500e4364957957fe591", "committedDate": "2020-04-09T07:43:29Z", "message": "[FLINK-16744][task][hotfix] Refactor SubtaskCheckpointCoordinatorImpl\n\nMinor refactoring of  SubtaskCheckpointCoordinatorImpl\nto reduce its methods complexity"}, "afterCommit": {"oid": "8492dd04cdb1712069f6d1c1abf39acbae60aaa2", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/8492dd04cdb1712069f6d1c1abf39acbae60aaa2", "committedDate": "2020-04-09T18:37:24Z", "message": "[FLINK-16744][task][hotfix] Refactor SubtaskCheckpointCoordinatorImpl\n\nMinor refactoring of  SubtaskCheckpointCoordinatorImpl\nto reduce its methods complexity"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "81ee27579a19414fba5c99d6cbea201e1632cc2b", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/81ee27579a19414fba5c99d6cbea201e1632cc2b", "committedDate": "2020-03-25T22:25:18Z", "message": "[FLINK-16744][task] send channel state handles to JM\n1. add channel state writer to SubtaskCheckpointCoordinator\n2. add handles to the reported snapshot\n3. cache checkpoint locations to prevent multiple streams\nper checkpoint. With unaligned checkpoints, checkpoint\ncan be initiated from several places which can result\n(without cache) in multiple streams/files for a single\ncheckpoint"}, "afterCommit": {"oid": "22e12ad32ac71e45f7c40fd08ad0cc4498664613", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/22e12ad32ac71e45f7c40fd08ad0cc4498664613", "committedDate": "2020-03-25T23:06:24Z", "message": "[FLINK-16744][task] send channel state handles to JM\n1. add channel state writer to SubtaskCheckpointCoordinator\n2. add handles to the reported snapshot\n3. cache checkpoint locations to prevent multiple streams\nper checkpoint. With unaligned checkpoints, checkpoint\ncan be initiated from several places which can result\n(without cache) in multiple streams/files for a single\ncheckpoint"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgxNzk4Njk3", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-381798697", "createdAt": "2020-03-26T08:45:28Z", "commit": {"oid": "5f5ca2f608caeb6d87a0697aca5da75880a1b844"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNlQwODo0NToyOFrOF78dyw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNlQwODo1OTowOFrOF789hA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODQwMDk3MQ==", "bodyText": "Could we avoid this class by binding the life-cycle of a FSDataInputStream to ChannelStateReaderImpl instead of ChannelStateStreamReader. Then only ChannelStateReader#close would close the input stream and we don't need to keep track.", "url": "https://github.com/apache/flink/pull/11515#discussion_r398400971", "createdAt": "2020-03-26T08:45:28Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RefCountingFSDataInputStream.java", "diffHunk": "@@ -0,0 +1,125 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.fs.FSDataInputStream;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.function.SupplierWithException;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+@NotThreadSafe\n+class RefCountingFSDataInputStream extends FSDataInputStream {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5f5ca2f608caeb6d87a0697aca5da75880a1b844"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODQwMjg3NQ==", "bodyText": "\ud83d\udc4d for pulling that out. Should it actually be TaskCheckpointCoordinator since it's bound to a StreamTask? Or do you consider StreamTask to be a misnomer that should be StreamSubtask (not proposing to change that, just want to understand the rational)?", "url": "https://github.com/apache/flink/pull/11515#discussion_r398402875", "createdAt": "2020-03-26T08:48:53Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinator.java", "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.tasks;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointMetaData;\n+import org.apache.flink.runtime.checkpoint.CheckpointMetrics;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+\n+import java.util.function.Supplier;\n+\n+/**\n+ * Coordinates checkpointing-related work for a task. Responsibilities:\n+ * <ol>\n+ * <li>build a snapshot (invokable)</li>\n+ * <li>report snapshot to the JobManager</li>\n+ * <li>maintain storage locations</li>\n+ * </ol>\n+ */\n+@Internal\n+interface SubtaskCheckpointCoordinator {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8f0c3d0c6c3fd55bf7b417c11de319b863fbe6c9"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODQwOTA5Mg==", "bodyText": "Probably needs some reference counting here after splitting finish into finishInput and finishOutput.", "url": "https://github.com/apache/flink/pull/11515#discussion_r398409092", "createdAt": "2020-03-26T08:59:08Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,226 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.Future;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessHandoverLoop implements Runnable {\n+\t\tprivate final Map<Long, ChannelStateWriteTask> tasks = new HashMap<>(maxCheckpoints);\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\tcleanup(thrown);\n+\t\t\t}\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\tprocessItem(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\n+\t\tprivate void processItem(ChannelStateWriteItem item) throws Exception {\n+\t\t\tif (item instanceof StartCheckpointItem) {\n+\t\t\t\ttasks.put(item.checkpointId, new ChannelStateWriteTask((StartCheckpointItem) item, streamFactory, serializer)); // tasks is limited indirectly by results max size\n+\t\t\t} else if (item instanceof InputDataItem) {\n+\t\t\t\ttasks.get(item.checkpointId).write((InputDataItem) item);\n+\t\t\t} else if (item instanceof OutputDataItem) {\n+\t\t\t\ttasks.get(item.checkpointId).write((OutputDataItem) item);\n+\t\t\t} else if (item instanceof FinishInputCheckpointItem) {\n+\t\t\t\ttasks.get(item.checkpointId).completeInput(() -> tasks.remove(item.checkpointId));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5f5ca2f608caeb6d87a0697aca5da75880a1b844"}, "originalPosition": 95}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "22e12ad32ac71e45f7c40fd08ad0cc4498664613", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/22e12ad32ac71e45f7c40fd08ad0cc4498664613", "committedDate": "2020-03-25T23:06:24Z", "message": "[FLINK-16744][task] send channel state handles to JM\n1. add channel state writer to SubtaskCheckpointCoordinator\n2. add handles to the reported snapshot\n3. cache checkpoint locations to prevent multiple streams\nper checkpoint. With unaligned checkpoints, checkpoint\ncan be initiated from several places which can result\n(without cache) in multiple streams/files for a single\ncheckpoint"}, "afterCommit": {"oid": "8665adbc70e1591e8729b9434f522892860e633b", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/8665adbc70e1591e8729b9434f522892860e633b", "committedDate": "2020-03-29T21:25:12Z", "message": "[FLINK-16744][task] send channel state handles to JM\n\n1. add channel state writer to SubtaskCheckpointCoordinator\n2. add handles to the reported snapshot\n3. cache checkpoint locations to prevent multiple streams\nper checkpoint. With unaligned checkpoints, checkpoint\ncan be initiated from several places which can result\n(without cache) in multiple streams/files for a single\ncheckpoint"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8665adbc70e1591e8729b9434f522892860e633b", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/8665adbc70e1591e8729b9434f522892860e633b", "committedDate": "2020-03-29T21:25:12Z", "message": "[FLINK-16744][task] send channel state handles to JM\n\n1. add channel state writer to SubtaskCheckpointCoordinator\n2. add handles to the reported snapshot\n3. cache checkpoint locations to prevent multiple streams\nper checkpoint. With unaligned checkpoints, checkpoint\ncan be initiated from several places which can result\n(without cache) in multiple streams/files for a single\ncheckpoint"}, "afterCommit": {"oid": "d3a26446f1c9d62e2572fa440accf95cb2d8596f", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/d3a26446f1c9d62e2572fa440accf95cb2d8596f", "committedDate": "2020-03-30T09:43:00Z", "message": "[FLINK-16744][task] send channel state handles to JM\n\n1. add channel state writer to SubtaskCheckpointCoordinator\n2. add handles to the reported snapshot\n3. cache checkpoint locations to prevent multiple streams\nper checkpoint. With unaligned checkpoints, checkpoint\ncan be initiated from several places which can result\n(without cache) in multiple streams/files for a single\ncheckpoint"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d3a26446f1c9d62e2572fa440accf95cb2d8596f", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/d3a26446f1c9d62e2572fa440accf95cb2d8596f", "committedDate": "2020-03-30T09:43:00Z", "message": "[FLINK-16744][task] send channel state handles to JM\n\n1. add channel state writer to SubtaskCheckpointCoordinator\n2. add handles to the reported snapshot\n3. cache checkpoint locations to prevent multiple streams\nper checkpoint. With unaligned checkpoints, checkpoint\ncan be initiated from several places which can result\n(without cache) in multiple streams/files for a single\ncheckpoint"}, "afterCommit": {"oid": "85c5d0044d8c8c53abc57e4e24383505462a48ae", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/85c5d0044d8c8c53abc57e4e24383505462a48ae", "committedDate": "2020-03-30T19:32:17Z", "message": "[FLINK-16744][task] send channel state handles to JM\n\n1. add channel state writer to SubtaskCheckpointCoordinator\n2. add handles to the reported snapshot\n3. cache checkpoint locations to prevent multiple streams\nper checkpoint. With unaligned checkpoints, checkpoint\ncan be initiated from several places which can result\n(without cache) in multiple streams/files for a single\ncheckpoint"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "85c5d0044d8c8c53abc57e4e24383505462a48ae", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/85c5d0044d8c8c53abc57e4e24383505462a48ae", "committedDate": "2020-03-30T19:32:17Z", "message": "[FLINK-16744][task] send channel state handles to JM\n\n1. add channel state writer to SubtaskCheckpointCoordinator\n2. add handles to the reported snapshot\n3. cache checkpoint locations to prevent multiple streams\nper checkpoint. With unaligned checkpoints, checkpoint\ncan be initiated from several places which can result\n(without cache) in multiple streams/files for a single\ncheckpoint"}, "afterCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/da674cafad1c62dde92588b94b8d44ab699b8280", "committedDate": "2020-03-30T21:35:26Z", "message": "[FLINK-16744][task] send channel state handles to JM\n\n1. add channel state writer to SubtaskCheckpointCoordinator\n2. add handles to the reported snapshot\n3. cache checkpoint locations to prevent multiple streams\nper checkpoint. With unaligned checkpoints, checkpoint\ncan be initiated from several places which can result\n(without cache) in multiple streams/files for a single\ncheckpoint"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg0NzU0MjEx", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-384754211", "createdAt": "2020-03-31T13:52:08Z", "commit": {"oid": "05c60654476141e8c0cb224d725cea99c85e7b15"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 16, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxMzo1MjowOFrOF-W2Mw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxNDo0NjowNVrOF-ZbKg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDkzMDM1NQ==", "bodyText": "why is this line still necessary?", "url": "https://github.com/apache/flink/pull/11515#discussion_r400930355", "createdAt": "2020-03-31T13:52:08Z", "author": {"login": "AHeise"}, "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/over/BufferDataOverWindowOperatorTest.java", "diffHunk": "@@ -205,9 +206,19 @@ public StreamConfig getOperatorConfig() {\n \n \t\t\t@Override\n \t\t\tpublic StreamTask<?, ?> getContainingTask() {\n-\t\t\t\tStreamTask task = mock(StreamTask.class);\n+\t\t\t\tclass MockableStreamTask extends StreamTask<Object, StreamOperator<Object>> implements EnvironmentSupport {\n+\t\t\t\t\tMockableStreamTask() throws Exception {\n+\t\t\t\t\t\tsuper(new MockEnvironmentBuilder().build());\n+\t\t\t\t\t}\n+\n+\t\t\t\t\t@Override\n+\t\t\t\t\tprotected void init() {\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\n+\t\t\t\tStreamTask<?, ?> task = mock(MockableStreamTask.class);\n \t\t\t\tEnvironment env = mock(Environment.class);\n-\t\t\t\twhen(task.getEnvironment()).thenReturn(env);\n+\t\t\t\twhen(task.getEnvironment()).thenReturn(new MockEnvironmentBuilder().build());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "05c60654476141e8c0cb224d725cea99c85e7b15"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDkzMTMwOQ==", "bodyText": "Couldn't you just override the method on the MockableStreamTask to get rid of mockito?", "url": "https://github.com/apache/flink/pull/11515#discussion_r400931309", "createdAt": "2020-03-31T13:53:20Z", "author": {"login": "AHeise"}, "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/over/BufferDataOverWindowOperatorTest.java", "diffHunk": "@@ -205,9 +206,19 @@ public StreamConfig getOperatorConfig() {\n \n \t\t\t@Override\n \t\t\tpublic StreamTask<?, ?> getContainingTask() {\n-\t\t\t\tStreamTask task = mock(StreamTask.class);\n+\t\t\t\tclass MockableStreamTask extends StreamTask<Object, StreamOperator<Object>> implements EnvironmentSupport {\n+\t\t\t\t\tMockableStreamTask() throws Exception {\n+\t\t\t\t\t\tsuper(new MockEnvironmentBuilder().build());\n+\t\t\t\t\t}\n+\n+\t\t\t\t\t@Override\n+\t\t\t\t\tprotected void init() {\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\n+\t\t\t\tStreamTask<?, ?> task = mock(MockableStreamTask.class);\n \t\t\t\tEnvironment env = mock(Environment.class);\n-\t\t\t\twhen(task.getEnvironment()).thenReturn(env);\n+\t\t\t\twhen(task.getEnvironment()).thenReturn(new MockEnvironmentBuilder().build());\n \t\t\t\twhen(env.getMemoryManager()).thenReturn(memoryManager);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "05c60654476141e8c0cb224d725cea99c85e7b15"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDkzNDE1Ng==", "bodyText": "nit: indent", "url": "https://github.com/apache/flink/pull/11515#discussion_r400934156", "createdAt": "2020-03-31T13:56:47Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.tasks;\n+\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.runtime.checkpoint.CheckpointMetaData;\n+import org.apache.flink.runtime.checkpoint.CheckpointMetrics;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.execution.Environment;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+\n+import java.util.concurrent.ExecutorService;\n+import java.util.function.Supplier;\n+\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+\n+class SubtaskCheckpointCoordinatorImpl implements SubtaskCheckpointCoordinator {\n+\tprivate final CheckpointStorageWorkerView checkpointStorage;\n+\tprivate final String taskName;\n+\tprivate final CloseableRegistry closeableRegistry;\n+\tprivate final ExecutorService executorService;\n+\tprivate final Environment env;\n+\tprivate final AsyncExceptionHandler asyncExceptionHandler;\n+\n+\tSubtaskCheckpointCoordinatorImpl(\n+\t\tCheckpointStorageWorkerView checkpointStorage,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3387596c1f3e4ed6e6cbeb586cefb59bc9f2e67"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDkzNDYzOQ==", "bodyText": "nit: indent", "url": "https://github.com/apache/flink/pull/11515#discussion_r400934639", "createdAt": "2020-03-31T13:57:24Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -89,17 +101,98 @@ public void checkpointState(\n \t\t\tcheckpointMetaData.getCheckpointId(),\n \t\t\tcheckpointOptions.getTargetLocation());\n \n-\t\tCheckpointingOperation.execute(\n-\t\t\tcheckpointMetaData,\n-\t\t\tcheckpointOptions,\n-\t\t\tcheckpointMetrics,\n-\t\t\tstorage,\n-\t\t\toperatorChain,\n-\t\t\ttaskName,\n-\t\t\tcloseableRegistry,\n-\t\t\texecutorService,\n-\t\t\tenv,\n-\t\t\tasyncExceptionHandler,\n-\t\t\tisCanceled);\n+\t\tlong startSyncPartNano = System.nanoTime();\n+\n+\t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress = new HashMap<>(operatorChain.getNumberOfOperators());\n+\t\ttry {\n+\t\t\tfor (StreamOperatorWrapper<?, ?> operatorWrapper : operatorChain.getAllOperators(true)) {\n+\t\t\t\tStreamOperator<?> op = operatorWrapper.getStreamOperator();\n+\t\t\t\tOperatorSnapshotFutures snapshotInProgress = checkpointStreamOperator(\n+\t\t\t\t\top,\n+\t\t\t\t\tcheckpointMetaData,\n+\t\t\t\t\tcheckpointOptions,\n+\t\t\t\t\tstorage,\n+\t\t\t\t\tisCanceled);\n+\t\t\t\toperatorSnapshotsInProgress.put(op.getOperatorID(), snapshotInProgress);\n+\t\t\t}\n+\n+\t\t\tif (LOG.isDebugEnabled()) {\n+\t\t\t\tLOG.debug(\"Finished synchronous checkpoints for checkpoint {} on task {}\",\n+\t\t\t\t\tcheckpointMetaData.getCheckpointId(), taskName);\n+\t\t\t}\n+\n+\t\t\tlong startAsyncPartNano = System.nanoTime();\n+\n+\t\t\tcheckpointMetrics.setSyncDurationMillis((startAsyncPartNano - startSyncPartNano) / 1_000_000);\n+\n+\t\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n+\t\t\texecutorService.execute(new AsyncCheckpointRunnable(\n+\t\t\t\toperatorSnapshotsInProgress,\n+\t\t\t\tcheckpointMetaData,\n+\t\t\t\tcheckpointMetrics,\n+\t\t\t\tstartAsyncPartNano,\n+\t\t\t\ttaskName,\n+\t\t\t\tcloseableRegistry,\n+\t\t\t\tenv,\n+\t\t\t\tasyncExceptionHandler));\n+\n+\t\t\tif (LOG.isDebugEnabled()) {\n+\t\t\t\tLOG.debug(\n+\t\t\t\t\t\"{} - finished synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n+\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n+\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n+\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n+\t\t\t}\n+\t\t} catch (Exception ex) {\n+\t\t\t// Cleanup to release resources\n+\t\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n+\t\t\t\tif (null != operatorSnapshotResult) {\n+\t\t\t\t\ttry {\n+\t\t\t\t\t\toperatorSnapshotResult.cancel();\n+\t\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\tif (LOG.isDebugEnabled()) {\n+\t\t\t\tLOG.debug(\n+\t\t\t\t\t\"{} - did NOT finish synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n+\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n+\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n+\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n+\t\t\t}\n+\n+\t\t\tif (checkpointOptions.getCheckpointType().isSynchronous()) {\n+\t\t\t\t// in the case of a synchronous checkpoint, we always rethrow the exception,\n+\t\t\t\t// so that the task fails.\n+\t\t\t\t// this is because the intention is always to stop the job after this checkpointing\n+\t\t\t\t// operation, and without the failure, the task would go back to normal execution.\n+\t\t\t\tthrow ex;\n+\t\t\t} else {\n+\t\t\t\tenv.declineCheckpoint(checkpointMetaData.getCheckpointId(), ex);\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate static OperatorSnapshotFutures checkpointStreamOperator(\n+\t\tStreamOperator<?> op,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ae7bd9f04b94f8c4810b3321df7729b11affeee4"}, "originalPosition": 126}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDkzNTM1Nw==", "bodyText": "nit: indent", "url": "https://github.com/apache/flink/pull/11515#discussion_r400935357", "createdAt": "2020-03-31T13:58:19Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateCheckpointWriter.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory.CheckpointStateOutputStream;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.runtime.state.ResultSubpartitionStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.BiFunction;\n+\n+import static org.apache.flink.runtime.state.CheckpointedStateScope.EXCLUSIVE;\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+\n+/**\n+ * Writes channel state for a specific checkpoint-subtask-attempt triple.\n+ */\n+@NotThreadSafe\n+class ChannelStateCheckpointWriter {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateCheckpointWriter.class);\n+\n+\tprivate final DataOutputStream dataStream;\n+\tprivate final CheckpointStateOutputStream checkpointStream;\n+\tprivate final ChannelStateWriteResult result;\n+\tprivate final Map<InputChannelInfo, List<Long>> inputChannelOffsets = new HashMap<>();\n+\tprivate final Map<ResultSubpartitionInfo, List<Long>> resultSubpartitionOffsets = new HashMap<>();\n+\tprivate final ChannelStateSerializer serializer;\n+\tprivate final long checkpointId;\n+\tprivate boolean inputCompleted = false;\n+\tprivate boolean outputCompleted = false;\n+\tprivate final Runnable onComplete;\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tCheckpointStartRequest startCheckpointItem,\n+\t\t\tCheckpointStreamFactory streamFactory,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete) throws Exception {\n+\t\tthis(startCheckpointItem.checkpointId, startCheckpointItem.targetResult, streamFactory.createCheckpointStateOutputStream(EXCLUSIVE), serializer, onComplete);\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tCheckpointStateOutputStream stream,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete) throws Exception {\n+\t\tthis(checkpointId, result, serializer, onComplete, stream, new DataOutputStream(stream));\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete,\n+\t\t\tCheckpointStateOutputStream checkpointStateOutputStream,\n+\t\t\tDataOutputStream dataStream) throws Exception {\n+\t\tthis.checkpointId = checkpointId;\n+\t\tthis.result = checkNotNull(result);\n+\t\tthis.checkpointStream = checkNotNull(checkpointStateOutputStream);\n+\t\tthis.serializer = checkNotNull(serializer);\n+\t\tthis.dataStream = checkNotNull(dataStream);\n+\t\tthis.onComplete = checkNotNull(onComplete);\n+\t\trunWithChecks(() -> serializer.writeHeader(dataStream));\n+\t}\n+\n+\tvoid writeInput(InputChannelInfo info, Buffer... flinkBuffers) throws Exception {\n+\t\tPreconditions.checkState(!inputCompleted);\n+\t\twrite(inputChannelOffsets, info, flinkBuffers);\n+\t}\n+\n+\tvoid writeOutput(ResultSubpartitionInfo info, Buffer[] flinkBuffers) throws Exception {\n+\t\tPreconditions.checkState(!outputCompleted);\n+\t\twrite(resultSubpartitionOffsets, info, flinkBuffers);\n+\t}\n+\n+\tprivate <K> void write(Map<K, List<Long>> offsets, K key, Buffer[] flinkBuffers) throws Exception {\n+\t\trunWithChecks(() -> {\n+\t\t\ttry {\n+\t\t\t\toffsets\n+\t\t\t\t\t.computeIfAbsent(key, unused -> new ArrayList<>())\n+\t\t\t\t\t.add(checkpointStream.getPos());\n+\t\t\t\tserializer.writeData(dataStream, flinkBuffers);\n+\t\t\t} finally {\n+\t\t\t\tfor (Buffer flinkBuffer : flinkBuffers) {\n+\t\t\t\t\tflinkBuffer.recycleBuffer();\n+\t\t\t\t}\n+\t\t\t}\n+\t\t});\n+\t}\n+\n+\tvoid completeInput() throws Exception {\n+\t\tLOG.debug(\"complete input, output completed: {}\", outputCompleted);\n+\t\trunWithChecks(() -> {\n+\t\t\tPreconditions.checkState(!inputCompleted);\n+\t\t\tinputCompleted = true;\n+\t\t\tcomplete();\n+\t\t});\n+\t}\n+\n+\tvoid completeOutput() throws Exception {\n+\t\tLOG.debug(\"complete output, input completed: {}\", inputCompleted);\n+\t\trunWithChecks(() -> {\n+\t\t\tPreconditions.checkState(!outputCompleted);\n+\t\t\toutputCompleted = true;\n+\t\t\tcomplete();\n+\t\t});\n+\t}\n+\n+\tprivate void complete() throws IOException {\n+\t\tif (inputCompleted && outputCompleted) {\n+\t\t\tonComplete.run();\n+\t\t\tdataStream.flush();\n+\t\t\tStreamStateHandle underlying = checkpointStream.closeAndGetHandle();\n+\t\t\tcomplete(\n+\t\t\t\tresult.inputChannelStateHandles,\n+\t\t\t\tinputChannelOffsets,\n+\t\t\t\t(chan, offsets) -> new InputChannelStateHandle(chan, underlying, offsets));\n+\t\t\tcomplete(\n+\t\t\t\tresult.resultSubpartitionStateHandles,\n+\t\t\t\tresultSubpartitionOffsets,\n+\t\t\t\t(chan, offsets) -> new ResultSubpartitionStateHandle(chan, underlying, offsets));\n+\t\t}\n+\t}\n+\n+\tprivate <I, H extends AbstractChannelStateHandle<I>> void complete(\n+\t\tCompletableFuture<Collection<H>> future,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 160}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDkzOTMzOA==", "bodyText": "Is that method used in later commits? Seems unused except in the implementor.", "url": "https://github.com/apache/flink/pull/11515#discussion_r400939338", "createdAt": "2020-03-31T14:03:37Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\tTuple2<Integer, Integer> readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\tint writableBytes();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk0NDM2OA==", "bodyText": "looks okay. anything particular to check?", "url": "https://github.com/apache/flink/pull/11515#discussion_r400944368", "createdAt": "2020-03-31T14:10:10Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\tTuple2<Integer, Integer> readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\tint writableBytes();\n+\n+\tint writeBytes(InputStream input, int bytesToRead) throws IOException;\n+\n+\tstatic ChannelStateByteBuffer wrap(Buffer buffer) {\n+\t\treturn new ChannelStateByteBuffer() {\n+\n+\t\t\tprivate ByteBuf byteBuf = buffer.asByteBuf();\n+\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn byteBuf.isWritable();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn byteBuf.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\treturn byteBuf.writeBytes(input, Math.min(bytesToRead, byteBuf.writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(BufferBuilder bufferBuilder) {\n+\t\tfinal byte[] buf = new byte[1024];\n+\t\treturn new ChannelStateByteBuffer() {\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn !bufferBuilder.isFull();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn bufferBuilder.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int upToBytes) throws IOException {\n+\t\t\t\tint left = upToBytes;\n+\t\t\t\tfor (int toRead = getToRead(left); toRead > 0; toRead = getToRead(left)) {\n+\t\t\t\t\tint read = input.read(buf, 0, toRead);\n+\t\t\t\t\tint copied = bufferBuilder.append(java.nio.ByteBuffer.wrap(buf, 0, read));\n+\t\t\t\t\tPreconditions.checkState(copied == read);\n+\t\t\t\t\tleft -= read;\n+\t\t\t\t}\n+\t\t\t\tbufferBuilder.commit();\n+\t\t\t\treturn upToBytes - left;\n+\t\t\t}\n+\n+\t\t\tprivate int getToRead(int bytesToRead) {\n+\t\t\t\treturn min(bytesToRead, min(buf.length, writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(byte[] bytes) {\n+\t\tint written = 0;\n+\t\treturn new ChannelStateByteBuffer() {\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn written < bytes.length;\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn bytes.length - written;\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\treturn input.read(bytes, written, writableBytes());\n+\t\t\t}\n+\t\t};\n+\t}\n+}\n+\n+class ChannelStateSerializerImpl implements ChannelStateSerializer, ChannelStateDeserializer {\n+\tprivate static final int LEN_SIZE = Integer.BYTES;\n+\tprivate static final int SERIALIZATION_VERSION = 0;\n+\n+\t@Override\n+\tpublic void writeHeader(DataOutputStream dataStream) throws IOException {\n+\t\tdataStream.writeInt(SERIALIZATION_VERSION);\n+\t}\n+\n+\t@Override\n+\tpublic void writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException {\n+\t\tstream.writeInt(getSize(flinkBuffers));\n+\t\tfor (Buffer buffer : flinkBuffers) {\n+\t\t\tByteBuf nettyByteBuf = buffer.asByteBuf();\n+\t\t\tnettyByteBuf.getBytes(nettyByteBuf.readerIndex(), stream, nettyByteBuf.readableBytes()); // todo: review me", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 161}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk0NTgxMg==", "bodyText": "Could we avoid creating the DIS adhoc? You need to read header anyways, so why not always create a DIS and pass it everywhere?", "url": "https://github.com/apache/flink/pull/11515#discussion_r400945812", "createdAt": "2020-03-31T14:12:10Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\tTuple2<Integer, Integer> readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\tint writableBytes();\n+\n+\tint writeBytes(InputStream input, int bytesToRead) throws IOException;\n+\n+\tstatic ChannelStateByteBuffer wrap(Buffer buffer) {\n+\t\treturn new ChannelStateByteBuffer() {\n+\n+\t\t\tprivate ByteBuf byteBuf = buffer.asByteBuf();\n+\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn byteBuf.isWritable();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn byteBuf.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\treturn byteBuf.writeBytes(input, Math.min(bytesToRead, byteBuf.writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(BufferBuilder bufferBuilder) {\n+\t\tfinal byte[] buf = new byte[1024];\n+\t\treturn new ChannelStateByteBuffer() {\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn !bufferBuilder.isFull();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn bufferBuilder.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int upToBytes) throws IOException {\n+\t\t\t\tint left = upToBytes;\n+\t\t\t\tfor (int toRead = getToRead(left); toRead > 0; toRead = getToRead(left)) {\n+\t\t\t\t\tint read = input.read(buf, 0, toRead);\n+\t\t\t\t\tint copied = bufferBuilder.append(java.nio.ByteBuffer.wrap(buf, 0, read));\n+\t\t\t\t\tPreconditions.checkState(copied == read);\n+\t\t\t\t\tleft -= read;\n+\t\t\t\t}\n+\t\t\t\tbufferBuilder.commit();\n+\t\t\t\treturn upToBytes - left;\n+\t\t\t}\n+\n+\t\t\tprivate int getToRead(int bytesToRead) {\n+\t\t\t\treturn min(bytesToRead, min(buf.length, writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(byte[] bytes) {\n+\t\tint written = 0;\n+\t\treturn new ChannelStateByteBuffer() {\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn written < bytes.length;\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn bytes.length - written;\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\treturn input.read(bytes, written, writableBytes());\n+\t\t\t}\n+\t\t};\n+\t}\n+}\n+\n+class ChannelStateSerializerImpl implements ChannelStateSerializer, ChannelStateDeserializer {\n+\tprivate static final int LEN_SIZE = Integer.BYTES;\n+\tprivate static final int SERIALIZATION_VERSION = 0;\n+\n+\t@Override\n+\tpublic void writeHeader(DataOutputStream dataStream) throws IOException {\n+\t\tdataStream.writeInt(SERIALIZATION_VERSION);\n+\t}\n+\n+\t@Override\n+\tpublic void writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException {\n+\t\tstream.writeInt(getSize(flinkBuffers));\n+\t\tfor (Buffer buffer : flinkBuffers) {\n+\t\t\tByteBuf nettyByteBuf = buffer.asByteBuf();\n+\t\t\tnettyByteBuf.getBytes(nettyByteBuf.readerIndex(), stream, nettyByteBuf.readableBytes()); // todo: review me\n+\t\t}\n+\t}\n+\n+\tprivate int getSize(Buffer[] buffers) {\n+\t\tint len = 0;\n+\t\tfor (Buffer buffer : buffers) {\n+\t\t\tlen = addExact(len, buffer.readableBytes());\n+\t\t}\n+\t\treturn len;\n+\t}\n+\n+\t@Override\n+\tpublic void readHeader(InputStream stream) throws IOException {\n+\t\tint version = readInt(stream);\n+\t\tPreconditions.checkArgument(version == SERIALIZATION_VERSION, \"unsupported version: \" + version);\n+\t}\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\t@Override\n+\tpublic Tuple2<Integer, Integer> readLength(InputStream stream) throws IOException {\n+\t\tint len = readInt(stream);\n+\t\tPreconditions.checkArgument(len >= 0, \"negative state size\");\n+\t\treturn Tuple2.of(len, LEN_SIZE);\n+\t}\n+\n+\t@Override\n+\tpublic int readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException {\n+\t\treturn buffer.writeBytes(stream, bytes);\n+\t}\n+\n+\tprivate static int readInt(InputStream stream) throws IOException {\n+\t\treturn new DataInputStream(stream).readInt();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 197}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk0NjkxNQ==", "bodyText": "Not a big fan of leaving inspection settings in code. If everyone does it with different IDEs/settings, it will become quickly a mess.", "url": "https://github.com/apache/flink/pull/11515#discussion_r400946915", "createdAt": "2020-03-31T14:13:34Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateStreamReader.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+\n+import static java.lang.Math.addExact;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateByteBuffer.wrap;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.HAS_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+\n+/**\n+ * Reads the state of a single channel pointed by {@link org.apache.flink.runtime.state.AbstractChannelStateHandle AbstractChannelStateHandle}.\n+ * Single-use.\n+ * Uses {@link RefCountingFSDataInputStream} internally.\n+ */\n+@NotThreadSafe\n+class ChannelStateStreamReader implements Closeable {\n+\n+\tprivate final RefCountingFSDataInputStream stream; // todo: buffer?\n+\tprivate final Queue<Long> offsets;\n+\tprivate final ChannelStateDeserializer serializer;\n+\tprivate long pos = -1;\n+\tprivate int rem;\n+\tprivate boolean closed = false;\n+\n+\tChannelStateStreamReader(AbstractChannelStateHandle<?> handle, RefCountingFSDataInputStreamFactory streamFactory) {\n+\t\tthis(streamFactory.forHandle(handle), handle.getOffsets(), streamFactory.getSerializer());\n+\t}\n+\n+\tprivate ChannelStateStreamReader(RefCountingFSDataInputStream stream, List<Long> offsets, ChannelStateDeserializer serializer) {\n+\t\tthis.stream = stream;\n+\t\tthis.stream.incNumReaders();\n+\t\tthis.serializer = serializer;\n+\t\tthis.offsets = new LinkedList<>(offsets);\n+\t}\n+\n+\tReadResult readInto(Buffer buffer) throws IOException {\n+\t\treturn readInto(wrap(buffer));\n+\t}\n+\n+\tReadResult readInto(BufferBuilder bufferBuilder) throws IOException {\n+\t\treturn readInto(wrap(bufferBuilder));\n+\t}\n+\n+\tprivate ReadResult readInto(ChannelStateByteBuffer buffer) throws IOException {\n+\t\tPreconditions.checkState(!closed, \"reader is closed\");\n+\t\treadWhilePossible(buffer);\n+\t\tif (haveMoreData()) {\n+\t\t\treturn HAS_MORE_DATA;\n+\t\t} else {\n+\t\t\tclose();\n+\t\t\treturn NO_MORE_DATA;\n+\t\t}\n+\t}\n+\n+\tprivate void readWhilePossible(ChannelStateByteBuffer buffer) throws IOException {\n+\t\twhile (haveMoreData() && buffer.isWritable()) {\n+\t\t\tif (pos < 0 || rem <= 0) {\n+\t\t\t\tadvanceOffset();\n+\t\t\t}\n+\t\t\tint bytesRead = serializer.readData(stream, buffer, rem);\n+\t\t\trem -= bytesRead;\n+\t\t\tpos = addExact(pos, bytesRead);\n+\t\t}\n+\t}\n+\n+\tprivate boolean haveMoreData() {\n+\t\treturn rem > 0 || !offsets.isEmpty();\n+\t}\n+\n+\tprivate void advanceOffset() throws IOException {\n+\t\t//noinspection ConstantConditions", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk0ODMzNQ==", "bodyText": "Add a factory for start for symmetry? Or move the factories to InProgress?", "url": "https://github.com/apache/flink/pull/11515#discussion_r400948335", "createdAt": "2020-03-31T14:15:25Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequest.java", "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageLocationReference;\n+import org.apache.flink.util.function.ThrowingConsumer;\n+\n+abstract class ChannelStateWriteRequest {\n+\tfinal long checkpointId;\n+\n+\tChannelStateWriteRequest(long checkpointId) {\n+\t\tthis.checkpointId = checkpointId;\n+\t}\n+\n+\t@Override\n+\tpublic String toString() {\n+\t\treturn getClass().getSimpleName() + \", checkpointId=\" + checkpointId;\n+\t}\n+\n+\tstatic CheckpointInProgressRequest completeInput(long checkpointId) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk0OTg4NA==", "bodyText": "Rename to fail?", "url": "https://github.com/apache/flink/pull/11515#discussion_r400949884", "createdAt": "2020-03-31T14:17:25Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestProcessor.java", "diffHunk": "@@ -0,0 +1,77 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+/**\n+ * Maintains a set of {@link ChannelStateCheckpointWriter writers} per checkpoint and translates incoming\n+ * {@link ChannelStateWriteRequest requests} to their corresponding methods.\n+ */\n+final class ChannelStateWriteRequestProcessor {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriteRequestProcessor.class);\n+\n+\tprivate final Map<Long, ChannelStateCheckpointWriter> writers; // limited indirectly by results max size\n+\tprivate final CheckpointStorageWorkerView streamFactoryFactory;\n+\tprivate final ChannelStateSerializer serializer;\n+\n+\tChannelStateWriteRequestProcessor(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\tthis.writers = new HashMap<>(maxCheckpoints);\n+\t\tthis.streamFactoryFactory = streamFactoryFactory;\n+\t\tthis.serializer = serializer;\n+\t}\n+\n+\tvoid processRequest(ChannelStateWriteRequest request) throws Exception {\n+\t\tLOG.debug(\"process {}\", request);\n+\t\tif (request instanceof CheckpointStartRequest) {\n+\t\t\tPreconditions.checkState(!writers.containsKey(request.checkpointId));\n+\t\t\twriters.put(request.checkpointId, buildWriter((CheckpointStartRequest) request));\n+\t\t} else if (request instanceof CheckpointInProgressRequest) {\n+\t\t\tPreconditions.checkState(writers.containsKey(request.checkpointId), \"writer not found for checkpoint id \" + request.checkpointId);\n+\t\t\twriters.get(request.checkpointId).process((CheckpointInProgressRequest) request);\n+\t\t} else {\n+\t\t\tthrow new IllegalArgumentException(\"unknown request type: \" + request);\n+\t\t}\n+\t}\n+\n+\tprivate ChannelStateCheckpointWriter buildWriter(CheckpointStartRequest request) throws Exception {\n+\t\treturn new ChannelStateCheckpointWriter(\n+\t\t\trequest,\n+\t\t\tstreamFactoryFactory.resolveCheckpointStorageLocation(request.checkpointId, request.locationReference),\n+\t\t\tserializer,\n+\t\t\t() -> writers.remove(request.checkpointId));\n+\t}\n+\n+\tvoid cleanup(Throwable e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 67}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk1MTI4NA==", "bodyText": "I'm also fine with either way. Just wanted to point out how we could avoid some code.", "url": "https://github.com/apache/flink/pull/11515#discussion_r400951284", "createdAt": "2020-03-31T14:19:06Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RefCountingFSDataInputStream.java", "diffHunk": "@@ -0,0 +1,125 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.fs.FSDataInputStream;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.function.SupplierWithException;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+@NotThreadSafe\n+class RefCountingFSDataInputStream extends FSDataInputStream {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODQwMDk3MQ=="}, "originalCommit": {"oid": "5f5ca2f608caeb6d87a0697aca5da75880a1b844"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk2ODAzOQ==", "bodyText": "nit: space", "url": "https://github.com/apache/flink/pull/11515#discussion_r400968039", "createdAt": "2020-03-31T14:40:25Z", "author": {"login": "AHeise"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/taskmanager/Task.java", "diffHunk": "@@ -1057,7 +1062,7 @@ else if (current == ExecutionState.RUNNING) {\n \t\t\t\t\t\t// case the canceling could not continue\n \n \t\t\t\t\t\t// The canceller calls cancel and interrupts the executing thread once\n-\t\t\t\t\t\tRunnable canceler = new TaskCanceler(LOG, this :: closeNetworkResources, invokable, executingThread, taskNameWithSubtask);\n+\t\t\t\t\t\tRunnable canceler = new TaskCanceler(LOG, this ::closeResources, invokable, executingThread, taskNameWithSubtask);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk2ODUwOQ==", "bodyText": "move to subtask commit", "url": "https://github.com/apache/flink/pull/11515#discussion_r400968509", "createdAt": "2020-03-31T14:40:59Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -21,53 +21,79 @@\n import org.apache.flink.runtime.checkpoint.CheckpointMetaData;\n import org.apache.flink.runtime.checkpoint.CheckpointMetrics;\n import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.StateObjectCollection;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriterImpl;\n import org.apache.flink.runtime.execution.Environment;\n import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.CheckpointStorageLocationReference;\n import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.SnapshotResult;\n import org.apache.flink.streaming.api.operators.OperatorSnapshotFutures;\n import org.apache.flink.streaming.api.operators.StreamOperator;\n+import org.apache.flink.util.WrappingRuntimeException;\n \n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import java.io.IOException;\n import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n import java.util.concurrent.ExecutorService;\n import java.util.function.Supplier;\n \n+import static org.apache.flink.runtime.checkpoint.CheckpointType.CHECKPOINT;\n import static org.apache.flink.util.Preconditions.checkNotNull;\n \n class SubtaskCheckpointCoordinatorImpl implements SubtaskCheckpointCoordinator {\n \n \tprivate static final Logger LOG = LoggerFactory.getLogger(SubtaskCheckpointCoordinatorImpl.class);\n \n-\tprivate final CheckpointStorageWorkerView checkpointStorage;\n+\tprivate final CachingCheckpointStorageWorkerView checkpointStorage;\n \tprivate final String taskName;\n \tprivate final CloseableRegistry closeableRegistry;\n \tprivate final ExecutorService executorService;\n \tprivate final Environment env;\n \tprivate final AsyncExceptionHandler asyncExceptionHandler;\n+\tprivate final ChannelStateWriter channelStateWriter;\n \n \tSubtaskCheckpointCoordinatorImpl(\n-\t\tCheckpointStorageWorkerView checkpointStorage,\n-\t\tString taskName,\n-\t\tCloseableRegistry closeableRegistry,\n-\t\tExecutorService executorService,\n-\t\tEnvironment env,\n-\t\tAsyncExceptionHandler asyncExceptionHandler) {\n-\t\tthis.checkpointStorage = checkNotNull(checkpointStorage);\n+\t\t\tCheckpointStorageWorkerView checkpointStorage,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk2OTg5NQ==", "bodyText": "Also cleared on abort?", "url": "https://github.com/apache/flink/pull/11515#discussion_r400969895", "createdAt": "2020-03-31T14:42:44Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -175,6 +203,77 @@ public void checkpointState(\n \t\t}\n \t}\n \n+\tprivate OperatorSnapshotFutures buildOperatorSnapshotFutures(\n+\t\t\tCheckpointMetaData checkpointMetaData,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tOperatorChain<?, ?> operatorChain,\n+\t\t\tStreamOperator<?> op,\n+\t\t\tSupplier<Boolean> isCanceled,\n+\t\t\tChannelStateWriteResult channelStateWriteResult) throws Exception {\n+\t\tCheckpointStreamFactory storage = checkpointStorage.resolveCheckpointStorageLocation(\n+\t\t\tcheckpointMetaData.getCheckpointId(),\n+\t\t\tcheckpointOptions.getTargetLocation());\n+\t\tOperatorSnapshotFutures snapshotInProgress = checkpointStreamOperator(\n+\t\t\top,\n+\t\t\tcheckpointMetaData,\n+\t\t\tcheckpointOptions,\n+\t\t\tstorage,\n+\t\t\tisCanceled);\n+\t\tif (op == operatorChain.getHeadOperator()) {\n+\t\t\tsnapshotInProgress.setInputChannelStateFuture(channelStateWriteResult\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.getInputChannelStateHandles()\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(StateObjectCollection::new)\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(SnapshotResult::of)\n+\t\t\t);\n+\t\t}\n+\t\tif (op == operatorChain.getTailOperator()) {\n+\t\t\tsnapshotInProgress.setResultSubpartitionStateFuture(channelStateWriteResult\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.getResultSubpartitionStateHandles()\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(StateObjectCollection::new)\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(SnapshotResult::of)\n+\t\t\t);\n+\t\t}\n+\t\treturn snapshotInProgress;\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tchannelStateWriter.close();\n+\t}\n+\n+\t// Caches checkpoint output stream factories to prevent multiple output stream per checkpoint.\n+\t// This could result from requesting output stream by different entities (this and channelStateWriter)\n+\t// We can't just pass a stream to the channelStateWriter because it can receive checkpoint call earlier than this class\n+\t// in some unaligned checkpoints scenarios\n+\tprivate static class CachingCheckpointStorageWorkerView implements CheckpointStorageWorkerView {\n+\t\tprivate final Map<Long, CheckpointStreamFactory> cache = new ConcurrentHashMap<>();\n+\t\tprivate final CheckpointStorageWorkerView delegate;\n+\n+\t\tprivate CachingCheckpointStorageWorkerView(CheckpointStorageWorkerView delegate) {\n+\t\t\tthis.delegate = delegate;\n+\t\t}\n+\n+\t\tvoid clearCacheFor(long checkpointId) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 181}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk3MjU4Ng==", "bodyText": "weird format.", "url": "https://github.com/apache/flink/pull/11515#discussion_r400972586", "createdAt": "2020-03-31T14:46:05Z", "author": {"login": "AHeise"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -175,6 +203,77 @@ public void checkpointState(\n \t\t}\n \t}\n \n+\tprivate OperatorSnapshotFutures buildOperatorSnapshotFutures(\n+\t\t\tCheckpointMetaData checkpointMetaData,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tOperatorChain<?, ?> operatorChain,\n+\t\t\tStreamOperator<?> op,\n+\t\t\tSupplier<Boolean> isCanceled,\n+\t\t\tChannelStateWriteResult channelStateWriteResult) throws Exception {\n+\t\tCheckpointStreamFactory storage = checkpointStorage.resolveCheckpointStorageLocation(\n+\t\t\tcheckpointMetaData.getCheckpointId(),\n+\t\t\tcheckpointOptions.getTargetLocation());\n+\t\tOperatorSnapshotFutures snapshotInProgress = checkpointStreamOperator(\n+\t\t\top,\n+\t\t\tcheckpointMetaData,\n+\t\t\tcheckpointOptions,\n+\t\t\tstorage,\n+\t\t\tisCanceled);\n+\t\tif (op == operatorChain.getHeadOperator()) {\n+\t\t\tsnapshotInProgress.setInputChannelStateFuture(channelStateWriteResult\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.getInputChannelStateHandles()\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(StateObjectCollection::new)\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(SnapshotResult::of)\n+\t\t\t);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 152}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1MjQ3MjIz", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-385247223", "createdAt": "2020-04-01T03:45:44Z", "commit": {"oid": "86d660018a3166d1cbab1e70619004d352b2bffc"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwMzo0NTo0NFrOF-v0xw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwMzo0NTo0NFrOF-v0xw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMzOTU5MQ==", "bodyText": "I did not get the point why we need this change and it seems unrelated to this PR. If the motivation is for avoiding stuck long time during await(), but it already has timeoutPerTest for ending the test after timeout.\nIf we want to refactor some previous tests, it should be a hotfix commit if minor and give some descriptions in commit message for better understanding the motivation.", "url": "https://github.com/apache/flink/pull/11515#discussion_r401339591", "createdAt": "2020-04-01T03:45:44Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/tasks/SourceTaskTerminationTest.java", "diffHunk": "@@ -82,7 +84,7 @@ private void stopWithSavepointStreamTaskTestHelper(final boolean withMaxWatermar\n \t\tfinal Thread executionThread = srcTaskTestHarness.invoke();\n \t\tfinal StreamTask<Long, ?> srcTask = srcTaskTestHarness.getTask();\n \n-\t\tready.await();\n+\t\twaitForLatchSetByTask(ready, srcTaskTestHarness);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "86d660018a3166d1cbab1e70619004d352b2bffc"}, "originalPosition": 14}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1MjQ5ODAz", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-385249803", "createdAt": "2020-04-01T03:56:16Z", "commit": {"oid": "86d660018a3166d1cbab1e70619004d352b2bffc"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwMzo1NjoxNlrOF-v-QQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwMzo1NjoxNlrOF-v-QQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM0MjAxNw==", "bodyText": "I guess we can merge the following while and if logics into this while to avoid judging srcTask.isRunning() three times separately, and make the logics more close with each other.", "url": "https://github.com/apache/flink/pull/11515#discussion_r401342017", "createdAt": "2020-04-01T03:56:16Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/tasks/SourceTaskTerminationTest.java", "diffHunk": "@@ -122,6 +124,26 @@ private void stopWithSavepointStreamTaskTestHelper(final boolean withMaxWatermar\n \t\texecutionThread.join();\n \t}\n \n+\tprivate void waitForLatchSetByTask(OneShotLatch latch, StreamTaskTestHarness<?> srcTaskTestHarness) throws Exception {\n+\t\tfinal StreamTask<?, ?> srcTask = srcTaskTestHarness.getTask();\n+\t\tfinal Thread executionThread = srcTaskTestHarness.taskThread;\n+\t\twhile (executionThread.isAlive() && srcTask.isRunning()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "86d660018a3166d1cbab1e70619004d352b2bffc"}, "originalPosition": 25}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1MjUxNDE0", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-385251414", "createdAt": "2020-04-01T04:03:03Z", "commit": {"oid": "05c60654476141e8c0cb224d725cea99c85e7b15"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNDowMzowM1rOF-wELg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNDowMzowM1rOF-wELg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM0MzUzNA==", "bodyText": "nit: unrelated change for this commit motivation", "url": "https://github.com/apache/flink/pull/11515#discussion_r401343534", "createdAt": "2020-04-01T04:03:03Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/operators/testutils/MockEnvironment.java", "diffHunk": "@@ -335,7 +335,7 @@ public void acknowledgeCheckpoint(long checkpointId, CheckpointMetrics checkpoin\n \n \t@Override\n \tpublic void declineCheckpoint(long checkpointId, Throwable cause) {\n-\t\tthrow new UnsupportedOperationException();\n+\t\tthrow new UnsupportedOperationException(cause);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "05c60654476141e8c0cb224d725cea99c85e7b15"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1MjUxODI3", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-385251827", "createdAt": "2020-04-01T04:04:30Z", "commit": {"oid": "05c60654476141e8c0cb224d725cea99c85e7b15"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNDowNDozMFrOF-wFsg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNDowNDozMFrOF-wFsg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM0MzkyMg==", "bodyText": "nit: unrelated change", "url": "https://github.com/apache/flink/pull/11515#discussion_r401343922", "createdAt": "2020-04-01T04:04:30Z", "author": {"login": "zhijiangW"}, "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/over/BufferDataOverWindowOperatorTest.java", "diffHunk": "@@ -64,7 +66,6 @@\n  * Test for {@link BufferDataOverWindowOperator}.\n  */\n public class BufferDataOverWindowOperatorTest {\n-", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "05c60654476141e8c0cb224d725cea99c85e7b15"}, "originalPosition": 14}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1MjUzNzI0", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-385253724", "createdAt": "2020-04-01T04:11:23Z", "commit": {"oid": "05c60654476141e8c0cb224d725cea99c85e7b15"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNDoxMToyNFrOF-wMBg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNDoxMToyNFrOF-wMBg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM0NTU0Mg==", "bodyText": "TBH i did not get the point why this class change is related to the commit motivation.\nIf it is necessary, can we use MockStreamTaskBuilder to build MockStreamTask instead, to avoid construct MockableStreamTask. Besides that, it is not suggested to use mock in unit tests.", "url": "https://github.com/apache/flink/pull/11515#discussion_r401345542", "createdAt": "2020-04-01T04:11:24Z", "author": {"login": "zhijiangW"}, "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/over/BufferDataOverWindowOperatorTest.java", "diffHunk": "@@ -205,9 +206,19 @@ public StreamConfig getOperatorConfig() {\n \n \t\t\t@Override\n \t\t\tpublic StreamTask<?, ?> getContainingTask() {\n-\t\t\t\tStreamTask task = mock(StreamTask.class);\n+\t\t\t\tclass MockableStreamTask extends StreamTask<Object, StreamOperator<Object>> implements EnvironmentSupport {\n+\t\t\t\t\tMockableStreamTask() throws Exception {\n+\t\t\t\t\t\tsuper(new MockEnvironmentBuilder().build());\n+\t\t\t\t\t}\n+\n+\t\t\t\t\t@Override\n+\t\t\t\t\tprotected void init() {\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\n+\t\t\t\tStreamTask<?, ?> task = mock(MockableStreamTask.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "05c60654476141e8c0cb224d725cea99c85e7b15"}, "originalPosition": 33}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1MjU4Mzgz", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-385258383", "createdAt": "2020-04-01T04:30:10Z", "commit": {"oid": "05c60654476141e8c0cb224d725cea99c85e7b15"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNDozMDoxMFrOF-wcuQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNDozMDoxMFrOF-wcuQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM0OTgxNw==", "bodyText": "I guess the motivation for defining final for related parent methods is from constructing SubtaskCheckpointCoordinatorImpl in StreamTask constructor. If so, we need also define final for AbstractInvokable#getEnvironment because it is also accessed while constructing SubtaskCheckpointCoordinatorImpl.\nActually we can avoid using getter while constructing SubtaskCheckpointCoordinatorImpl to use specific arguments instead. Anyway i think it is meaningful to define final for some methods if we confirm they should not be override by subclasses. But the requirement should not be from constructing SubtaskCheckpointCoordinatorImpl, and we should review all the methods in AbstractInvokable and StreamTask to make this thing completely.", "url": "https://github.com/apache/flink/pull/11515#discussion_r401349817", "createdAt": "2020-04-01T04:30:10Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamTask.java", "diffHunk": "@@ -651,7 +651,7 @@ boolean isSerializingTimestamps() {\n \t * Gets the name of the task, in the form \"taskname (2/5)\".\n \t * @return The name of the task.\n \t */\n-\tpublic String getName() {\n+\tpublic final String getName() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "05c60654476141e8c0cb224d725cea99c85e7b15"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1MjYwOTM5", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-385260939", "createdAt": "2020-04-01T04:40:10Z", "commit": {"oid": "c3387596c1f3e4ed6e6cbeb586cefb59bc9f2e67"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNDo0MDoxMFrOF-wlng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNDo0MDoxMFrOF-wlng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM1MjA5NA==", "bodyText": "nit: we can get environment directly from argument instead of getEnvironment(), also for getAsyncOperationsThreadPool()", "url": "https://github.com/apache/flink/pull/11515#discussion_r401352094", "createdAt": "2020-04-01T04:40:10Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamTask.java", "diffHunk": "@@ -271,7 +269,14 @@ protected StreamTask(\n \t\t\tnew ExecutorThreadFactory(\"AsyncOperations\", uncaughtExceptionHandler));\n \n \t\tthis.stateBackend = createStateBackend();\n-\t\tthis.checkpointStorage = stateBackend.createCheckpointStorage(getEnvironment().getJobID());\n+\n+\t\tthis.subtaskCheckpointCoordinator = new SubtaskCheckpointCoordinatorImpl(\n+\t\t\tstateBackend.createCheckpointStorage(getEnvironment().getJobID()),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3387596c1f3e4ed6e6cbeb586cefb59bc9f2e67"}, "originalPosition": 25}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1MjYyMDAw", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-385262000", "createdAt": "2020-04-01T04:44:28Z", "commit": {"oid": "c3387596c1f3e4ed6e6cbeb586cefb59bc9f2e67"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNDo0NDoyOFrOF-wpWw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNDo0NDoyOFrOF-wpWw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM1MzA1MQ==", "bodyText": "nit: split the arguments into every line, seem too long.", "url": "https://github.com/apache/flink/pull/11515#discussion_r401353051", "createdAt": "2020-04-01T04:44:28Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamTask.java", "diffHunk": "@@ -772,38 +777,18 @@ private boolean performCheckpoint(\n \t\tLOG.debug(\"Starting checkpoint ({}) {} on task {}\",\n \t\t\tcheckpointMetaData.getCheckpointId(), checkpointOptions.getCheckpointType(), getName());\n \n-\t\tfinal long checkpointId = checkpointMetaData.getCheckpointId();\n-\n \t\tif (isRunning) {\n \t\t\tactionExecutor.runThrowing(() -> {\n \n \t\t\t\tif (checkpointOptions.getCheckpointType().isSynchronous()) {\n-\t\t\t\t\tsetSynchronousSavepointId(checkpointId);\n+\t\t\t\t\tsetSynchronousSavepointId(checkpointMetaData.getCheckpointId());\n \n \t\t\t\t\tif (advanceToEndOfTime) {\n \t\t\t\t\t\tadvanceToEndOfEventTime();\n \t\t\t\t\t}\n \t\t\t\t}\n \n-\t\t\t\t// All of the following steps happen as an atomic step from the perspective of barriers and\n-\t\t\t\t// records/watermarks/timers/callbacks.\n-\t\t\t\t// We generally try to emit the checkpoint barrier as soon as possible to not affect downstream\n-\t\t\t\t// checkpoint alignments\n-\n-\t\t\t\t// Step (1): Prepare the checkpoint, allow operators to do some pre-barrier work.\n-\t\t\t\t//           The pre-barrier work should be nothing or minimal in the common case.\n-\t\t\t\toperatorChain.prepareSnapshotPreBarrier(checkpointId);\n-\n-\t\t\t\t// Step (2): Send the checkpoint barrier downstream\n-\t\t\t\toperatorChain.broadcastCheckpointBarrier(\n-\t\t\t\t\t\tcheckpointId,\n-\t\t\t\t\t\tcheckpointMetaData.getTimestamp(),\n-\t\t\t\t\t\tcheckpointOptions);\n-\n-\t\t\t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not\n-\t\t\t\t//           impact progress of the streaming topology\n-\t\t\t\tcheckpointState(checkpointMetaData, checkpointOptions, checkpointMetrics);\n-\n+\t\t\t\tsubtaskCheckpointCoordinator.checkpointState(checkpointMetaData, checkpointOptions, checkpointMetrics, operatorChain, this::isCanceled);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3387596c1f3e4ed6e6cbeb586cefb59bc9f2e67"}, "originalPosition": 80}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1MjY5MTQx", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-385269141", "createdAt": "2020-04-01T05:11:23Z", "commit": {"oid": "c3387596c1f3e4ed6e6cbeb586cefb59bc9f2e67"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNToxMToyM1rOF-xBxQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNToxMToyM1rOF-xBxQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM1OTMwMQ==", "bodyText": "I do not find any usages in this PR. Do you expect which component might use this getter future?", "url": "https://github.com/apache/flink/pull/11515#discussion_r401359301", "createdAt": "2020-04-01T05:11:23Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinator.java", "diffHunk": "@@ -0,0 +1,51 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.tasks;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointMetaData;\n+import org.apache.flink.runtime.checkpoint.CheckpointMetrics;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+\n+import java.util.function.Supplier;\n+\n+/**\n+ * Coordinates checkpointing-related work for a subtask (i.e. {@link org.apache.flink.runtime.taskmanager.Task Task} and\n+ * {@link StreamTask}). Responsibilities:\n+ * <ol>\n+ * <li>build a snapshot (invokable)</li>\n+ * <li>report snapshot to the JobManager</li>\n+ * <li>maintain storage locations</li>\n+ * </ol>\n+ */\n+@Internal\n+interface SubtaskCheckpointCoordinator {\n+\n+\tChannelStateWriter getChannelStateWriter();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3387596c1f3e4ed6e6cbeb586cefb59bc9f2e67"}, "originalPosition": 41}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1MjY5OTIx", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-385269921", "createdAt": "2020-04-01T05:14:10Z", "commit": {"oid": "ae7bd9f04b94f8c4810b3321df7729b11affeee4"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNToxNDoxMFrOF-xEeA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNToxNDoxMFrOF-xEeA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM1OTk5Mg==", "bodyText": "nit: better to extract a separate method for the following operation, otherwise this method seems too long for not easy tracing the steps.", "url": "https://github.com/apache/flink/pull/11515#discussion_r401359992", "createdAt": "2020-04-01T05:14:10Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -89,17 +101,98 @@ public void checkpointState(\n \t\t\tcheckpointMetaData.getCheckpointId(),\n \t\t\tcheckpointOptions.getTargetLocation());\n \n-\t\tCheckpointingOperation.execute(\n-\t\t\tcheckpointMetaData,\n-\t\t\tcheckpointOptions,\n-\t\t\tcheckpointMetrics,\n-\t\t\tstorage,\n-\t\t\toperatorChain,\n-\t\t\ttaskName,\n-\t\t\tcloseableRegistry,\n-\t\t\texecutorService,\n-\t\t\tenv,\n-\t\t\tasyncExceptionHandler,\n-\t\t\tisCanceled);\n+\t\tlong startSyncPartNano = System.nanoTime();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ae7bd9f04b94f8c4810b3321df7729b11affeee4"}, "originalPosition": 51}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1MjcwNzcz", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-385270773", "createdAt": "2020-04-01T05:17:05Z", "commit": {"oid": "ae7bd9f04b94f8c4810b3321df7729b11affeee4"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNToxNzowNVrOF-xHWg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNToxNzowNVrOF-xHWg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM2MDczMA==", "bodyText": "nit: also checkNotNull for checkpointMetaData and operatorChain, and i think they can be done with the commit [FLINK-16744][task][refactor] extract SubtaskCheckpointCoordinator", "url": "https://github.com/apache/flink/pull/11515#discussion_r401360730", "createdAt": "2020-04-01T05:17:05Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -65,6 +75,8 @@ public void checkpointState(\n \t\t\tCheckpointMetrics checkpointMetrics,\n \t\t\tOperatorChain<?, ?> operatorChain,\n \t\t\tSupplier<Boolean> isCanceled) throws Exception {\n+\t\tcheckNotNull(checkpointOptions);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ae7bd9f04b94f8c4810b3321df7729b11affeee4"}, "originalPosition": 30}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1MjczMjY4", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-385273268", "createdAt": "2020-04-01T05:25:51Z", "commit": {"oid": "ae7bd9f04b94f8c4810b3321df7729b11affeee4"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNToyNTo1MVrOF-xQFQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNToyNTo1MVrOF-xQFQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM2Mjk2NQ==", "bodyText": "nit: better to split line for every argument", "url": "https://github.com/apache/flink/pull/11515#discussion_r401362965", "createdAt": "2020-04-01T05:25:51Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -89,17 +101,98 @@ public void checkpointState(\n \t\t\tcheckpointMetaData.getCheckpointId(),\n \t\t\tcheckpointOptions.getTargetLocation());\n \n-\t\tCheckpointingOperation.execute(\n-\t\t\tcheckpointMetaData,\n-\t\t\tcheckpointOptions,\n-\t\t\tcheckpointMetrics,\n-\t\t\tstorage,\n-\t\t\toperatorChain,\n-\t\t\ttaskName,\n-\t\t\tcloseableRegistry,\n-\t\t\texecutorService,\n-\t\t\tenv,\n-\t\t\tasyncExceptionHandler,\n-\t\t\tisCanceled);\n+\t\tlong startSyncPartNano = System.nanoTime();\n+\n+\t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress = new HashMap<>(operatorChain.getNumberOfOperators());\n+\t\ttry {\n+\t\t\tfor (StreamOperatorWrapper<?, ?> operatorWrapper : operatorChain.getAllOperators(true)) {\n+\t\t\t\tStreamOperator<?> op = operatorWrapper.getStreamOperator();\n+\t\t\t\tOperatorSnapshotFutures snapshotInProgress = checkpointStreamOperator(\n+\t\t\t\t\top,\n+\t\t\t\t\tcheckpointMetaData,\n+\t\t\t\t\tcheckpointOptions,\n+\t\t\t\t\tstorage,\n+\t\t\t\t\tisCanceled);\n+\t\t\t\toperatorSnapshotsInProgress.put(op.getOperatorID(), snapshotInProgress);\n+\t\t\t}\n+\n+\t\t\tif (LOG.isDebugEnabled()) {\n+\t\t\t\tLOG.debug(\"Finished synchronous checkpoints for checkpoint {} on task {}\",\n+\t\t\t\t\tcheckpointMetaData.getCheckpointId(), taskName);\n+\t\t\t}\n+\n+\t\t\tlong startAsyncPartNano = System.nanoTime();\n+\n+\t\t\tcheckpointMetrics.setSyncDurationMillis((startAsyncPartNano - startSyncPartNano) / 1_000_000);\n+\n+\t\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n+\t\t\texecutorService.execute(new AsyncCheckpointRunnable(\n+\t\t\t\toperatorSnapshotsInProgress,\n+\t\t\t\tcheckpointMetaData,\n+\t\t\t\tcheckpointMetrics,\n+\t\t\t\tstartAsyncPartNano,\n+\t\t\t\ttaskName,\n+\t\t\t\tcloseableRegistry,\n+\t\t\t\tenv,\n+\t\t\t\tasyncExceptionHandler));\n+\n+\t\t\tif (LOG.isDebugEnabled()) {\n+\t\t\t\tLOG.debug(\n+\t\t\t\t\t\"{} - finished synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n+\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n+\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n+\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n+\t\t\t}\n+\t\t} catch (Exception ex) {\n+\t\t\t// Cleanup to release resources\n+\t\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n+\t\t\t\tif (null != operatorSnapshotResult) {\n+\t\t\t\t\ttry {\n+\t\t\t\t\t\toperatorSnapshotResult.cancel();\n+\t\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\tif (LOG.isDebugEnabled()) {\n+\t\t\t\tLOG.debug(\n+\t\t\t\t\t\"{} - did NOT finish synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n+\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ae7bd9f04b94f8c4810b3321df7729b11affeee4"}, "originalPosition": 108}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1Mjc0NDc3", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-385274477", "createdAt": "2020-04-01T05:30:04Z", "commit": {"oid": "ae7bd9f04b94f8c4810b3321df7729b11affeee4"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNTozMDowNFrOF-xUKQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNTozMDowNFrOF-xUKQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM2NDAwOQ==", "bodyText": "I see this log occur twice with the same arguments only different message, and this log actually seems a bit long to impact the normal logics review. I am not sure whether it is worth extracting a separate method for only passing different message in two usages.", "url": "https://github.com/apache/flink/pull/11515#discussion_r401364009", "createdAt": "2020-04-01T05:30:04Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -89,17 +101,98 @@ public void checkpointState(\n \t\t\tcheckpointMetaData.getCheckpointId(),\n \t\t\tcheckpointOptions.getTargetLocation());\n \n-\t\tCheckpointingOperation.execute(\n-\t\t\tcheckpointMetaData,\n-\t\t\tcheckpointOptions,\n-\t\t\tcheckpointMetrics,\n-\t\t\tstorage,\n-\t\t\toperatorChain,\n-\t\t\ttaskName,\n-\t\t\tcloseableRegistry,\n-\t\t\texecutorService,\n-\t\t\tenv,\n-\t\t\tasyncExceptionHandler,\n-\t\t\tisCanceled);\n+\t\tlong startSyncPartNano = System.nanoTime();\n+\n+\t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress = new HashMap<>(operatorChain.getNumberOfOperators());\n+\t\ttry {\n+\t\t\tfor (StreamOperatorWrapper<?, ?> operatorWrapper : operatorChain.getAllOperators(true)) {\n+\t\t\t\tStreamOperator<?> op = operatorWrapper.getStreamOperator();\n+\t\t\t\tOperatorSnapshotFutures snapshotInProgress = checkpointStreamOperator(\n+\t\t\t\t\top,\n+\t\t\t\t\tcheckpointMetaData,\n+\t\t\t\t\tcheckpointOptions,\n+\t\t\t\t\tstorage,\n+\t\t\t\t\tisCanceled);\n+\t\t\t\toperatorSnapshotsInProgress.put(op.getOperatorID(), snapshotInProgress);\n+\t\t\t}\n+\n+\t\t\tif (LOG.isDebugEnabled()) {\n+\t\t\t\tLOG.debug(\"Finished synchronous checkpoints for checkpoint {} on task {}\",\n+\t\t\t\t\tcheckpointMetaData.getCheckpointId(), taskName);\n+\t\t\t}\n+\n+\t\t\tlong startAsyncPartNano = System.nanoTime();\n+\n+\t\t\tcheckpointMetrics.setSyncDurationMillis((startAsyncPartNano - startSyncPartNano) / 1_000_000);\n+\n+\t\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n+\t\t\texecutorService.execute(new AsyncCheckpointRunnable(\n+\t\t\t\toperatorSnapshotsInProgress,\n+\t\t\t\tcheckpointMetaData,\n+\t\t\t\tcheckpointMetrics,\n+\t\t\t\tstartAsyncPartNano,\n+\t\t\t\ttaskName,\n+\t\t\t\tcloseableRegistry,\n+\t\t\t\tenv,\n+\t\t\t\tasyncExceptionHandler));\n+\n+\t\t\tif (LOG.isDebugEnabled()) {\n+\t\t\t\tLOG.debug(\n+\t\t\t\t\t\"{} - finished synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n+\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n+\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n+\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n+\t\t\t}\n+\t\t} catch (Exception ex) {\n+\t\t\t// Cleanup to release resources\n+\t\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n+\t\t\t\tif (null != operatorSnapshotResult) {\n+\t\t\t\t\ttry {\n+\t\t\t\t\t\toperatorSnapshotResult.cancel();\n+\t\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\tif (LOG.isDebugEnabled()) {\n+\t\t\t\tLOG.debug(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ae7bd9f04b94f8c4810b3321df7729b11affeee4"}, "originalPosition": 106}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1Mjc5NDAy", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-385279402", "createdAt": "2020-04-01T05:45:28Z", "commit": {"oid": "ae7bd9f04b94f8c4810b3321df7729b11affeee4"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNTo0NToyOVrOF-xllg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNTo0NToyOVrOF-xllg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM2ODQ3MA==", "bodyText": "nit: maybe warn instead of info and give some custom message to indicate which process causes the exception.", "url": "https://github.com/apache/flink/pull/11515#discussion_r401368470", "createdAt": "2020-04-01T05:45:29Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -89,17 +101,98 @@ public void checkpointState(\n \t\t\tcheckpointMetaData.getCheckpointId(),\n \t\t\tcheckpointOptions.getTargetLocation());\n \n-\t\tCheckpointingOperation.execute(\n-\t\t\tcheckpointMetaData,\n-\t\t\tcheckpointOptions,\n-\t\t\tcheckpointMetrics,\n-\t\t\tstorage,\n-\t\t\toperatorChain,\n-\t\t\ttaskName,\n-\t\t\tcloseableRegistry,\n-\t\t\texecutorService,\n-\t\t\tenv,\n-\t\t\tasyncExceptionHandler,\n-\t\t\tisCanceled);\n+\t\tlong startSyncPartNano = System.nanoTime();\n+\n+\t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress = new HashMap<>(operatorChain.getNumberOfOperators());\n+\t\ttry {\n+\t\t\tfor (StreamOperatorWrapper<?, ?> operatorWrapper : operatorChain.getAllOperators(true)) {\n+\t\t\t\tStreamOperator<?> op = operatorWrapper.getStreamOperator();\n+\t\t\t\tOperatorSnapshotFutures snapshotInProgress = checkpointStreamOperator(\n+\t\t\t\t\top,\n+\t\t\t\t\tcheckpointMetaData,\n+\t\t\t\t\tcheckpointOptions,\n+\t\t\t\t\tstorage,\n+\t\t\t\t\tisCanceled);\n+\t\t\t\toperatorSnapshotsInProgress.put(op.getOperatorID(), snapshotInProgress);\n+\t\t\t}\n+\n+\t\t\tif (LOG.isDebugEnabled()) {\n+\t\t\t\tLOG.debug(\"Finished synchronous checkpoints for checkpoint {} on task {}\",\n+\t\t\t\t\tcheckpointMetaData.getCheckpointId(), taskName);\n+\t\t\t}\n+\n+\t\t\tlong startAsyncPartNano = System.nanoTime();\n+\n+\t\t\tcheckpointMetrics.setSyncDurationMillis((startAsyncPartNano - startSyncPartNano) / 1_000_000);\n+\n+\t\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n+\t\t\texecutorService.execute(new AsyncCheckpointRunnable(\n+\t\t\t\toperatorSnapshotsInProgress,\n+\t\t\t\tcheckpointMetaData,\n+\t\t\t\tcheckpointMetrics,\n+\t\t\t\tstartAsyncPartNano,\n+\t\t\t\ttaskName,\n+\t\t\t\tcloseableRegistry,\n+\t\t\t\tenv,\n+\t\t\t\tasyncExceptionHandler));\n+\n+\t\t\tif (LOG.isDebugEnabled()) {\n+\t\t\t\tLOG.debug(\n+\t\t\t\t\t\"{} - finished synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n+\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n+\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n+\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n+\t\t\t}\n+\t\t} catch (Exception ex) {\n+\t\t\t// Cleanup to release resources\n+\t\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n+\t\t\t\tif (null != operatorSnapshotResult) {\n+\t\t\t\t\ttry {\n+\t\t\t\t\t\toperatorSnapshotResult.cancel();\n+\t\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\tif (LOG.isDebugEnabled()) {\n+\t\t\t\tLOG.debug(\n+\t\t\t\t\t\"{} - did NOT finish synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n+\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n+\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n+\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n+\t\t\t}\n+\n+\t\t\tif (checkpointOptions.getCheckpointType().isSynchronous()) {\n+\t\t\t\t// in the case of a synchronous checkpoint, we always rethrow the exception,\n+\t\t\t\t// so that the task fails.\n+\t\t\t\t// this is because the intention is always to stop the job after this checkpointing\n+\t\t\t\t// operation, and without the failure, the task would go back to normal execution.\n+\t\t\t\tthrow ex;\n+\t\t\t} else {\n+\t\t\t\tenv.declineCheckpoint(checkpointMetaData.getCheckpointId(), ex);\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate static OperatorSnapshotFutures checkpointStreamOperator(\n+\t\tStreamOperator<?> op,\n+\t\tCheckpointMetaData checkpointMetaData,\n+\t\tCheckpointOptions checkpointOptions,\n+\t\tCheckpointStreamFactory storageLocation,\n+\t\tSupplier<Boolean> isCanceled) throws Exception {\n+\t\ttry {\n+\t\t\treturn op.snapshotState(\n+\t\t\t\tcheckpointMetaData.getCheckpointId(),\n+\t\t\t\tcheckpointMetaData.getTimestamp(),\n+\t\t\t\tcheckpointOptions,\n+\t\t\t\tstorageLocation);\n+\t\t}\n+\t\tcatch (Exception ex) {\n+\t\t\tif (!isCanceled.get()) {\n+\t\t\t\tLOG.info(ex.getMessage(), ex);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ae7bd9f04b94f8c4810b3321df7729b11affeee4"}, "originalPosition": 140}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1MzMxMTI5", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-385331129", "createdAt": "2020-04-01T07:35:17Z", "commit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNzozNToxN1rOF-0OBg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNzozNToxN1rOF-0OBg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQxMTU5MA==", "bodyText": "nit: indentation alignment", "url": "https://github.com/apache/flink/pull/11515#discussion_r401411590", "createdAt": "2020-04-01T07:35:17Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/state/TaskStateManagerImpl.java", "diffHunk": "@@ -68,18 +70,36 @@\n \t/** The checkpoint responder through which this manager can report to the job manager. */\n \tprivate final CheckpointResponder checkpointResponder;\n \n+\tprivate final ChannelStateReader channelStateReader;\n+\n \tpublic TaskStateManagerImpl(\n-\t\t@Nonnull JobID jobId,\n-\t\t@Nonnull ExecutionAttemptID executionAttemptID,\n-\t\t@Nonnull TaskLocalStateStore localStateStore,\n-\t\t@Nullable JobManagerTaskRestore jobManagerTaskRestore,\n-\t\t@Nonnull CheckpointResponder checkpointResponder) {\n+\t\t\t@Nonnull JobID jobId,\n+\t\t\t@Nonnull ExecutionAttemptID executionAttemptID,\n+\t\t\t@Nonnull TaskLocalStateStore localStateStore,\n+\t\t\t@Nullable JobManagerTaskRestore jobManagerTaskRestore,\n+\t\t\t@Nonnull CheckpointResponder checkpointResponder) {\n+\t\tthis(jobId,\n+\t\t\texecutionAttemptID,\n+\t\t\tlocalStateStore,\n+\t\t\tjobManagerTaskRestore,\n+\t\t\tcheckpointResponder,\n+\t\t\tnew ChannelStateReaderImpl(jobManagerTaskRestore == null ? new TaskStateSnapshot() : jobManagerTaskRestore.getTaskStateSnapshot())\n+\t\t);\n+\t}\n \n-\t\tthis.jobId = jobId;\n+\tTaskStateManagerImpl(\n+\t\t\t@Nonnull JobID jobId,\n+\t\t\t@Nonnull ExecutionAttemptID executionAttemptID,\n+\t\t\t@Nonnull TaskLocalStateStore localStateStore,\n+\t\t\t@Nullable JobManagerTaskRestore jobManagerTaskRestore,\n+\t\t\t@Nonnull CheckpointResponder checkpointResponder,\n+\t\t\t@Nonnull ChannelStateReader channelStateReader) {\n+\t\t\tthis.jobId = jobId;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 43}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1MzM3MTI1", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-385337125", "createdAt": "2020-04-01T07:44:33Z", "commit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNzo0NDozM1rOF-0iLQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNzo0NDozM1rOF-0iLQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQxNjc0OQ==", "bodyText": "nit: also make this argument separate line", "url": "https://github.com/apache/flink/pull/11515#discussion_r401416749", "createdAt": "2020-04-01T07:44:33Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/state/TaskStateManagerImpl.java", "diffHunk": "@@ -68,18 +70,36 @@\n \t/** The checkpoint responder through which this manager can report to the job manager. */\n \tprivate final CheckpointResponder checkpointResponder;\n \n+\tprivate final ChannelStateReader channelStateReader;\n+\n \tpublic TaskStateManagerImpl(\n-\t\t@Nonnull JobID jobId,\n-\t\t@Nonnull ExecutionAttemptID executionAttemptID,\n-\t\t@Nonnull TaskLocalStateStore localStateStore,\n-\t\t@Nullable JobManagerTaskRestore jobManagerTaskRestore,\n-\t\t@Nonnull CheckpointResponder checkpointResponder) {\n+\t\t\t@Nonnull JobID jobId,\n+\t\t\t@Nonnull ExecutionAttemptID executionAttemptID,\n+\t\t\t@Nonnull TaskLocalStateStore localStateStore,\n+\t\t\t@Nullable JobManagerTaskRestore jobManagerTaskRestore,\n+\t\t\t@Nonnull CheckpointResponder checkpointResponder) {\n+\t\tthis(jobId,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 26}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1MzM3Njk2", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-385337696", "createdAt": "2020-04-01T07:45:25Z", "commit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNzo0NToyNVrOF-0kEQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNzo0NToyNVrOF-0kEQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQxNzIzMw==", "bodyText": "only need private atm", "url": "https://github.com/apache/flink/pull/11515#discussion_r401417233", "createdAt": "2020-04-01T07:45:25Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/state/TaskStateManagerImpl.java", "diffHunk": "@@ -68,18 +70,36 @@\n \t/** The checkpoint responder through which this manager can report to the job manager. */\n \tprivate final CheckpointResponder checkpointResponder;\n \n+\tprivate final ChannelStateReader channelStateReader;\n+\n \tpublic TaskStateManagerImpl(\n-\t\t@Nonnull JobID jobId,\n-\t\t@Nonnull ExecutionAttemptID executionAttemptID,\n-\t\t@Nonnull TaskLocalStateStore localStateStore,\n-\t\t@Nullable JobManagerTaskRestore jobManagerTaskRestore,\n-\t\t@Nonnull CheckpointResponder checkpointResponder) {\n+\t\t\t@Nonnull JobID jobId,\n+\t\t\t@Nonnull ExecutionAttemptID executionAttemptID,\n+\t\t\t@Nonnull TaskLocalStateStore localStateStore,\n+\t\t\t@Nullable JobManagerTaskRestore jobManagerTaskRestore,\n+\t\t\t@Nonnull CheckpointResponder checkpointResponder) {\n+\t\tthis(jobId,\n+\t\t\texecutionAttemptID,\n+\t\t\tlocalStateStore,\n+\t\t\tjobManagerTaskRestore,\n+\t\t\tcheckpointResponder,\n+\t\t\tnew ChannelStateReaderImpl(jobManagerTaskRestore == null ? new TaskStateSnapshot() : jobManagerTaskRestore.getTaskStateSnapshot())\n+\t\t);\n+\t}\n \n-\t\tthis.jobId = jobId;\n+\tTaskStateManagerImpl(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 36}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1MzQ0NzI0", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-385344724", "createdAt": "2020-04-01T07:56:06Z", "commit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNzo1NjowNlrOF-06mA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNzo1NjowNlrOF-06mA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQyMzAwMA==", "bodyText": "The precious consideration of closing network resources early is done by canceler thread, which would throw exception while task thread interacts with buffer operation to make task exit ASAP. If we add the state manager close here, does it have the same effect to throw any exceptions while interacting with task thread?", "url": "https://github.com/apache/flink/pull/11515#discussion_r401423000", "createdAt": "2020-04-01T07:56:06Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/taskmanager/Task.java", "diffHunk": "@@ -914,6 +914,11 @@ private void closeNetworkResources() {\n \t\t\t\tLOG.error(\"Failed to release input gate for task {}.\", taskNameWithSubtask, t);\n \t\t\t}\n \t\t}\n+\t\ttry {\n+\t\t\ttaskStateManager.close();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 40}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1MzQ0OTE1", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-385344915", "createdAt": "2020-04-01T07:56:22Z", "commit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNzo1NjoyMlrOF-07Lw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNzo1NjoyMlrOF-07Lw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQyMzE1MQ==", "bodyText": "also adjust the respective javadoc", "url": "https://github.com/apache/flink/pull/11515#discussion_r401423151", "createdAt": "2020-04-01T07:56:22Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/taskmanager/Task.java", "diffHunk": "@@ -889,14 +889,14 @@ private void releaseNetworkResources() {\n \t\t\t}\n \t\t}\n \n-\t\tcloseNetworkResources();\n+\t\tcloseResources();\n \t}\n \n \t/**\n \t * There are two scenarios to close the network resources. One is from {@link TaskCanceler} to early", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 27}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1MzQ3Mzg5", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-385347389", "createdAt": "2020-04-01T07:59:49Z", "commit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNzo1OTo0OVrOF-1DKA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwNzo1OTo0OVrOF-1DKA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQyNTE5Mg==", "bodyText": "unrelated change", "url": "https://github.com/apache/flink/pull/11515#discussion_r401425192", "createdAt": "2020-04-01T07:59:49Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/state/TestTaskStateManager.java", "diffHunk": "@@ -94,7 +95,6 @@ public void reportTaskStateSnapshots(\n \t\t@Nullable TaskStateSnapshot acknowledgedState,\n \t\t@Nullable TaskStateSnapshot localState) {\n \n-", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 12}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1MzQ5MTM3", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-385349137", "createdAt": "2020-04-01T08:02:24Z", "commit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwODowMjoyNVrOF-1IRQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwODowMjoyNVrOF-1IRQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQyNjUwMQ==", "bodyText": "nit: @nullable", "url": "https://github.com/apache/flink/pull/11515#discussion_r401426501", "createdAt": "2020-04-01T08:02:25Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/OperatorChain.java", "diffHunk": "@@ -544,6 +544,10 @@ private void linkOperatorWrappers(List<StreamOperatorWrapper<?, ?>> allOperatorW\n \t\t\tcontainingTask.getMailboxExecutorFactory().createExecutor(operatorConfig.getChainIndex()));\n \t}\n \n+\tStreamOperator<?> getTailOperator() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 4}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1MzU5MTE1", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-385359115", "createdAt": "2020-04-01T08:16:39Z", "commit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwODoxNjo0MFrOF-1oKA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwODoxNjo0MFrOF-1oKA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQzNDY2NA==", "bodyText": "should register this after it is constructed completely?", "url": "https://github.com/apache/flink/pull/11515#discussion_r401434664", "createdAt": "2020-04-01T08:16:40Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -21,53 +21,79 @@\n import org.apache.flink.runtime.checkpoint.CheckpointMetaData;\n import org.apache.flink.runtime.checkpoint.CheckpointMetrics;\n import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.StateObjectCollection;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriterImpl;\n import org.apache.flink.runtime.execution.Environment;\n import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.CheckpointStorageLocationReference;\n import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.SnapshotResult;\n import org.apache.flink.streaming.api.operators.OperatorSnapshotFutures;\n import org.apache.flink.streaming.api.operators.StreamOperator;\n+import org.apache.flink.util.WrappingRuntimeException;\n \n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import java.io.IOException;\n import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n import java.util.concurrent.ExecutorService;\n import java.util.function.Supplier;\n \n+import static org.apache.flink.runtime.checkpoint.CheckpointType.CHECKPOINT;\n import static org.apache.flink.util.Preconditions.checkNotNull;\n \n class SubtaskCheckpointCoordinatorImpl implements SubtaskCheckpointCoordinator {\n \n \tprivate static final Logger LOG = LoggerFactory.getLogger(SubtaskCheckpointCoordinatorImpl.class);\n \n-\tprivate final CheckpointStorageWorkerView checkpointStorage;\n+\tprivate final CachingCheckpointStorageWorkerView checkpointStorage;\n \tprivate final String taskName;\n \tprivate final CloseableRegistry closeableRegistry;\n \tprivate final ExecutorService executorService;\n \tprivate final Environment env;\n \tprivate final AsyncExceptionHandler asyncExceptionHandler;\n+\tprivate final ChannelStateWriter channelStateWriter;\n \n \tSubtaskCheckpointCoordinatorImpl(\n-\t\tCheckpointStorageWorkerView checkpointStorage,\n-\t\tString taskName,\n-\t\tCloseableRegistry closeableRegistry,\n-\t\tExecutorService executorService,\n-\t\tEnvironment env,\n-\t\tAsyncExceptionHandler asyncExceptionHandler) {\n-\t\tthis.checkpointStorage = checkNotNull(checkpointStorage);\n+\t\t\tCheckpointStorageWorkerView checkpointStorage,\n+\t\t\tString taskName,\n+\t\t\tCloseableRegistry closeableRegistry,\n+\t\t\tExecutorService executorService,\n+\t\t\tEnvironment env,\n+\t\t\tAsyncExceptionHandler asyncExceptionHandler,\n+\t\t\tboolean sendChannelState) throws IOException {\n+\t\tthis.checkpointStorage = new CachingCheckpointStorageWorkerView(checkNotNull(checkpointStorage));\n \t\tthis.taskName = checkNotNull(taskName);\n \t\tthis.closeableRegistry = checkNotNull(closeableRegistry);\n \t\tthis.executorService = checkNotNull(executorService);\n \t\tthis.env = checkNotNull(env);\n \t\tthis.asyncExceptionHandler = checkNotNull(asyncExceptionHandler);\n+\t\tthis.closeableRegistry.registerCloseable(this);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 65}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1NDQ2OTg4", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-385446988", "createdAt": "2020-04-01T10:13:22Z", "commit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxMDoxMzoyMlrOF-584w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxMDoxMzoyMlrOF-584w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTUwNTUwNw==", "bodyText": "The proper javadoc format for class should be\n/**\n*\n**/", "url": "https://github.com/apache/flink/pull/11515#discussion_r401505507", "createdAt": "2020-04-01T10:13:22Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -175,6 +203,77 @@ public void checkpointState(\n \t\t}\n \t}\n \n+\tprivate OperatorSnapshotFutures buildOperatorSnapshotFutures(\n+\t\t\tCheckpointMetaData checkpointMetaData,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tOperatorChain<?, ?> operatorChain,\n+\t\t\tStreamOperator<?> op,\n+\t\t\tSupplier<Boolean> isCanceled,\n+\t\t\tChannelStateWriteResult channelStateWriteResult) throws Exception {\n+\t\tCheckpointStreamFactory storage = checkpointStorage.resolveCheckpointStorageLocation(\n+\t\t\tcheckpointMetaData.getCheckpointId(),\n+\t\t\tcheckpointOptions.getTargetLocation());\n+\t\tOperatorSnapshotFutures snapshotInProgress = checkpointStreamOperator(\n+\t\t\top,\n+\t\t\tcheckpointMetaData,\n+\t\t\tcheckpointOptions,\n+\t\t\tstorage,\n+\t\t\tisCanceled);\n+\t\tif (op == operatorChain.getHeadOperator()) {\n+\t\t\tsnapshotInProgress.setInputChannelStateFuture(channelStateWriteResult\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.getInputChannelStateHandles()\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(StateObjectCollection::new)\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(SnapshotResult::of)\n+\t\t\t);\n+\t\t}\n+\t\tif (op == operatorChain.getTailOperator()) {\n+\t\t\tsnapshotInProgress.setResultSubpartitionStateFuture(channelStateWriteResult\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.getResultSubpartitionStateHandles()\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(StateObjectCollection::new)\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(SnapshotResult::of)\n+\t\t\t);\n+\t\t}\n+\t\treturn snapshotInProgress;\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tchannelStateWriter.close();\n+\t}\n+\n+\t// Caches checkpoint output stream factories to prevent multiple output stream per checkpoint.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 169}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1NDUxMDM1", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-385451035", "createdAt": "2020-04-01T10:19:02Z", "commit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxMDoxOTowMlrOF-6Jkg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxMDoxOTowMlrOF-6Jkg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTUwODc1NA==", "bodyText": "maybe better formatting as follow\nChannelStateWriteResult channelStateWriteResult = checkpointOptions.getCheckpointType() == CHECKPOINT ?\n\t\t\tchannelStateWriter.getWriteResult(checkpointMetaData.getCheckpointId()) :\n\t\t\tChannelStateWriteResult.EMPTY;", "url": "https://github.com/apache/flink/pull/11515#discussion_r401508754", "createdAt": "2020-04-01T10:19:02Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -97,24 +123,26 @@ public void checkpointState(\n \t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not\n \t\t//           impact progress of the streaming topology\n \n-\t\tCheckpointStreamFactory storage = checkpointStorage.resolveCheckpointStorageLocation(\n-\t\t\tcheckpointMetaData.getCheckpointId(),\n-\t\t\tcheckpointOptions.getTargetLocation());\n-\n \t\tlong startSyncPartNano = System.nanoTime();\n \n \t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress = new HashMap<>(operatorChain.getNumberOfOperators());\n+\t\tChannelStateWriteResult channelStateWriteResult =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 99}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1NDYzNTA4", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-385463508", "createdAt": "2020-04-01T10:37:37Z", "commit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxMDozNzozOFrOF-6xww==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxMDozNzozOFrOF-6xww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTUxOTA0Mw==", "bodyText": "should we add some TODO before getWriteResult, otherwise it seems hard to understand from this commit that we actually have not written anything before get the result.", "url": "https://github.com/apache/flink/pull/11515#discussion_r401519043", "createdAt": "2020-04-01T10:37:38Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -97,24 +123,26 @@ public void checkpointState(\n \t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not\n \t\t//           impact progress of the streaming topology\n \n-\t\tCheckpointStreamFactory storage = checkpointStorage.resolveCheckpointStorageLocation(\n-\t\t\tcheckpointMetaData.getCheckpointId(),\n-\t\t\tcheckpointOptions.getTargetLocation());\n-\n \t\tlong startSyncPartNano = System.nanoTime();\n \n \t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress = new HashMap<>(operatorChain.getNumberOfOperators());\n+\t\tChannelStateWriteResult channelStateWriteResult =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 99}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1NDczMDcw", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-385473070", "createdAt": "2020-04-01T10:52:28Z", "commit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxMDo1MjoyOFrOF-7P8w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxMDo1MjoyOFrOF-7P8w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTUyNjc3MQ==", "bodyText": "WrappingRuntimeException is used for wrapping non-runtime exceptions? I guess this should belong to runtime exception. Another option without wrapping exception is not using lambda way to throw IOException explicitly in the method resolveCheckpointStorageLocation", "url": "https://github.com/apache/flink/pull/11515#discussion_r401526771", "createdAt": "2020-04-01T10:52:28Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -175,6 +203,77 @@ public void checkpointState(\n \t\t}\n \t}\n \n+\tprivate OperatorSnapshotFutures buildOperatorSnapshotFutures(\n+\t\t\tCheckpointMetaData checkpointMetaData,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tOperatorChain<?, ?> operatorChain,\n+\t\t\tStreamOperator<?> op,\n+\t\t\tSupplier<Boolean> isCanceled,\n+\t\t\tChannelStateWriteResult channelStateWriteResult) throws Exception {\n+\t\tCheckpointStreamFactory storage = checkpointStorage.resolveCheckpointStorageLocation(\n+\t\t\tcheckpointMetaData.getCheckpointId(),\n+\t\t\tcheckpointOptions.getTargetLocation());\n+\t\tOperatorSnapshotFutures snapshotInProgress = checkpointStreamOperator(\n+\t\t\top,\n+\t\t\tcheckpointMetaData,\n+\t\t\tcheckpointOptions,\n+\t\t\tstorage,\n+\t\t\tisCanceled);\n+\t\tif (op == operatorChain.getHeadOperator()) {\n+\t\t\tsnapshotInProgress.setInputChannelStateFuture(channelStateWriteResult\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.getInputChannelStateHandles()\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(StateObjectCollection::new)\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(SnapshotResult::of)\n+\t\t\t);\n+\t\t}\n+\t\tif (op == operatorChain.getTailOperator()) {\n+\t\t\tsnapshotInProgress.setResultSubpartitionStateFuture(channelStateWriteResult\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.getResultSubpartitionStateHandles()\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(StateObjectCollection::new)\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(SnapshotResult::of)\n+\t\t\t);\n+\t\t}\n+\t\treturn snapshotInProgress;\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tchannelStateWriter.close();\n+\t}\n+\n+\t// Caches checkpoint output stream factories to prevent multiple output stream per checkpoint.\n+\t// This could result from requesting output stream by different entities (this and channelStateWriter)\n+\t// We can't just pass a stream to the channelStateWriter because it can receive checkpoint call earlier than this class\n+\t// in some unaligned checkpoints scenarios\n+\tprivate static class CachingCheckpointStorageWorkerView implements CheckpointStorageWorkerView {\n+\t\tprivate final Map<Long, CheckpointStreamFactory> cache = new ConcurrentHashMap<>();\n+\t\tprivate final CheckpointStorageWorkerView delegate;\n+\n+\t\tprivate CachingCheckpointStorageWorkerView(CheckpointStorageWorkerView delegate) {\n+\t\t\tthis.delegate = delegate;\n+\t\t}\n+\n+\t\tvoid clearCacheFor(long checkpointId) {\n+\t\t\tcache.remove(checkpointId);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic CheckpointStreamFactory resolveCheckpointStorageLocation(long checkpointId, CheckpointStorageLocationReference reference) {\n+\t\t\treturn cache.computeIfAbsent(checkpointId, id -> {\n+\t\t\t\ttry {\n+\t\t\t\t\treturn delegate.resolveCheckpointStorageLocation(checkpointId, reference);\n+\t\t\t\t} catch (IOException e) {\n+\t\t\t\t\tthrow new WrappingRuntimeException(e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 191}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1NDc3NzY5", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-385477769", "createdAt": "2020-04-01T10:59:52Z", "commit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxMDo1OTo1MlrOF-7eww==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxMDo1OTo1MlrOF-7eww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTUzMDU2Mw==", "bodyText": "nit: I prefer to extracting checkpointStorage.resolveCheckpointStorageLocation from buildOperatorSnapshotFutures and put it before for loop, then it is easy to trace both the creation and clear actions in the same page.", "url": "https://github.com/apache/flink/pull/11515#discussion_r401530563", "createdAt": "2020-04-01T10:59:52Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -97,24 +123,26 @@ public void checkpointState(\n \t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not\n \t\t//           impact progress of the streaming topology\n \n-\t\tCheckpointStreamFactory storage = checkpointStorage.resolveCheckpointStorageLocation(\n-\t\t\tcheckpointMetaData.getCheckpointId(),\n-\t\t\tcheckpointOptions.getTargetLocation());\n-\n \t\tlong startSyncPartNano = System.nanoTime();\n \n \t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress = new HashMap<>(operatorChain.getNumberOfOperators());\n+\t\tChannelStateWriteResult channelStateWriteResult =\n+\t\t\tcheckpointOptions.getCheckpointType() == CHECKPOINT ? channelStateWriter.getWriteResult(checkpointMetaData.getCheckpointId()) :\n+\t\t\t\tChannelStateWriteResult.EMPTY;\n \t\ttry {\n \t\t\tfor (StreamOperatorWrapper<?, ?> operatorWrapper : operatorChain.getAllOperators(true)) {\n-\t\t\t\tStreamOperator<?> op = operatorWrapper.getStreamOperator();\n-\t\t\t\tOperatorSnapshotFutures snapshotInProgress = checkpointStreamOperator(\n-\t\t\t\t\top,\n-\t\t\t\t\tcheckpointMetaData,\n-\t\t\t\t\tcheckpointOptions,\n-\t\t\t\t\tstorage,\n-\t\t\t\t\tisCanceled);\n-\t\t\t\toperatorSnapshotsInProgress.put(op.getOperatorID(), snapshotInProgress);\n+\t\t\t\toperatorSnapshotsInProgress.put(\n+\t\t\t\t\toperatorWrapper.getStreamOperator().getOperatorID(),\n+\t\t\t\t\tbuildOperatorSnapshotFutures(\n+\t\t\t\t\t\tcheckpointMetaData,\n+\t\t\t\t\t\tcheckpointOptions,\n+\t\t\t\t\t\toperatorChain,\n+\t\t\t\t\t\toperatorWrapper.getStreamOperator(),\n+\t\t\t\t\t\tisCanceled,\n+\t\t\t\t\t\tchannelStateWriteResult)\n+\t\t\t\t);\n \t\t\t}\n+\t\t\tcheckpointStorage.clearCacheFor(checkpointMetaData.getCheckpointId());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "originalPosition": 123}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MDgyNTk5", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386082599", "createdAt": "2020-04-02T03:15:19Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMzoxNToxOVrOF_Z4Rw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMzoxNToxOVrOF_Z4Rw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAyODYxNQ==", "bodyText": "weird naming streamFactoryFactory", "url": "https://github.com/apache/flink/pull/11515#discussion_r402028615", "createdAt": "2020-04-02T03:15:19Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\tprivate volatile boolean isRunning;\n+\tprivate volatile Exception thrown;\n+\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 101}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MDgzNDI2", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386083426", "createdAt": "2020-04-02T03:18:17Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMzoxODoxN1rOF_Z7Pg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMzoxODoxN1rOF_Z7Pg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAyOTM3NA==", "bodyText": "I guess it is not always using  DEFAULT_MAX_CHECKPOINTS, the maxCheckpoints can still be set explicitly, e.g. in tests.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402029374", "createdAt": "2020-04-02T03:18:17Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\tprivate volatile boolean isRunning;\n+\tprivate volatile Exception thrown;\n+\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory) {\n+\t\tthis(streamFactoryFactory, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 106}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MDgzOTI1", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386083925", "createdAt": "2020-04-02T03:20:08Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMzoyMDowOFrOF_Z9GQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMzoyMDowOFrOF_Z9GQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAyOTg0OQ==", "bodyText": "it can be private ATM", "url": "https://github.com/apache/flink/pull/11515#discussion_r402029849", "createdAt": "2020-04-02T03:20:08Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\tprivate volatile boolean isRunning;\n+\tprivate volatile Exception thrown;\n+\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory) {\n+\t\tthis(streamFactoryFactory, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.\n+\t */\n+\tChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory, int maxCheckpoints) {\n+\t\tthis(streamFactoryFactory, DEFAULT_HANDOVER_CAPACITY, new ChannelStateSerializerImpl(), maxCheckpoints);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl}.\n+\t *\n+\t * @param maxCheckpoints maximum number of checkpoints to be written currently or finished but not taken yet.\n+\t */\n+\tChannelStateWriterImpl(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 117}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MDg0MzQ0", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386084344", "createdAt": "2020-04-02T03:21:44Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMzoyMTo0NFrOF_Z-aw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMzoyMTo0NFrOF_Z-aw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAzMDE4Nw==", "bodyText": "Is it probably to pass different implementations of ChannelStateSerializer future?", "url": "https://github.com/apache/flink/pull/11515#discussion_r402030187", "createdAt": "2020-04-02T03:21:44Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\tprivate volatile boolean isRunning;\n+\tprivate volatile Exception thrown;\n+\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory) {\n+\t\tthis(streamFactoryFactory, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.\n+\t */\n+\tChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory, int maxCheckpoints) {\n+\t\tthis(streamFactoryFactory, DEFAULT_HANDOVER_CAPACITY, new ChannelStateSerializerImpl(), maxCheckpoints);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl}.\n+\t *\n+\t * @param maxCheckpoints maximum number of checkpoints to be written currently or finished but not taken yet.\n+\t */\n+\tChannelStateWriterImpl(\n+\t\t\tCheckpointStorageWorkerView streamFactory,\n+\t\t\tint handoverCapacity,\n+\t\t\tChannelStateSerializer serializer,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 120}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MDg1MDk1", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386085095", "createdAt": "2020-04-02T03:24:51Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMzoyNDo1MVrOF_aBMQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMzoyNDo1MVrOF_aBMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAzMDg5Nw==", "bodyText": "nit: better to also describe other arguments for consistent.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402030897", "createdAt": "2020-04-02T03:24:51Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\tprivate volatile boolean isRunning;\n+\tprivate volatile Exception thrown;\n+\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory) {\n+\t\tthis(streamFactoryFactory, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.\n+\t */\n+\tChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory, int maxCheckpoints) {\n+\t\tthis(streamFactoryFactory, DEFAULT_HANDOVER_CAPACITY, new ChannelStateSerializerImpl(), maxCheckpoints);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl}.\n+\t *\n+\t * @param maxCheckpoints maximum number of checkpoints to be written currently or finished but not taken yet.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 115}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MDg4MzIx", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386088321", "createdAt": "2020-04-02T03:37:53Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMzozNzo1M1rOF_aNFQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMzozNzo1M1rOF_aNFQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAzMzk0MQ==", "bodyText": "nit: maxCheckpoints is not necessary to pass.\nweird naming streamFactoryFactory.\nAnother option is to construct ChannelStateWriteRequestProcessor inside constructor of ChannelStateWriterImpl and pass it directly into ProcessRequestsLoop", "url": "https://github.com/apache/flink/pull/11515#discussion_r402033941", "createdAt": "2020-04-02T03:37:53Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 61}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MDkzMzkw", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386093390", "createdAt": "2020-04-02T03:59:00Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMzo1OTowMFrOF_afwA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMzo1OTowMFrOF_afwA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAzODcyMA==", "bodyText": "nit: IMO better to place this class after constructor, not mixed among the class fields.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402038720", "createdAt": "2020-04-02T03:59:00Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 58}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MDk0NTA2", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386094506", "createdAt": "2020-04-02T04:03:30Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNDowMzozMFrOF_ajwA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNDowMzozMFrOF_ajwA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAzOTc0NA==", "bodyText": "I am wondering  it might bring potential problems to use BlockingQueue with bounded size. The IO operations might be stuck sometimes in bad scenarios, then the request in the queue can not be consumed in time. Therefore it would block all the operations of #addInputData, especially the #addInputData might be triggered by multiple netty threads, to impact the network throughput. How about using unbounded queue if the memory overhead is not obvious?", "url": "https://github.com/apache/flink/pull/11515#discussion_r402039744", "createdAt": "2020-04-02T04:03:30Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 95}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MTAwNDky", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386100492", "createdAt": "2020-04-02T04:29:39Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNDoyOTozOVrOF_a5ZQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNDoyOTozOVrOF_a5ZQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA0NTI4NQ==", "bodyText": "Give some javadoc to explain why we do not support event data?", "url": "https://github.com/apache/flink/pull/11515#discussion_r402045285", "createdAt": "2020-04-02T04:29:39Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\tprivate volatile boolean isRunning;\n+\tprivate volatile Exception thrown;\n+\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory) {\n+\t\tthis(streamFactoryFactory, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.\n+\t */\n+\tChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory, int maxCheckpoints) {\n+\t\tthis(streamFactoryFactory, DEFAULT_HANDOVER_CAPACITY, new ChannelStateSerializerImpl(), maxCheckpoints);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl}.\n+\t *\n+\t * @param maxCheckpoints maximum number of checkpoints to be written currently or finished but not taken yet.\n+\t */\n+\tChannelStateWriterImpl(\n+\t\t\tCheckpointStorageWorkerView streamFactory,\n+\t\t\tint handoverCapacity,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tint maxCheckpoints) {\n+\t\tthis.handover = new ArrayBlockingQueue<>(handoverCapacity);\n+\t\tthis.results = new ConcurrentHashMap<>(maxCheckpoints);\n+\t\tthis.maxCheckpoints = maxCheckpoints;\n+\t\tthis.asyncWriter = new Thread(new ProcessRequestsLoop(maxCheckpoints, streamFactory, serializer));\n+\t\tthis.isRunning = true;\n+\t}\n+\n+\t@Override\n+\tpublic void start(long checkpointId, CheckpointOptions checkpointOptions) {\n+\t\tLOG.debug(\"start checkpoint {} ({})\", checkpointId, checkpointOptions);\n+\t\trethrow();\n+\t\tPreconditions.checkState(isRunning && asyncWriter.isAlive(), \"not running\");\n+\t\tChannelStateWriteResult result = new ChannelStateWriteResult();\n+\t\tChannelStateWriteResult put = results.computeIfAbsent(checkpointId, id -> {\n+\t\t\tPreconditions.checkArgument(results.size() < maxCheckpoints, \"results.size() > maxCheckpoints\", results.size(), maxCheckpoints);\n+\t\t\tenqueue(new CheckpointStartRequest(checkpointId, result, checkpointOptions.getTargetLocation()));\n+\t\t\treturn result;\n+\t\t});\n+\t\tPreconditions.checkArgument(put == result, \"result future already present for checkpoint id: \" + checkpointId);\n+\t}\n+\n+\t@Override\n+\tpublic void addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add input data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)));\n+\t}\n+\n+\t@Override\n+\tpublic void addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add output data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)));\n+\t}\n+\n+\t@Override\n+\tpublic void finishInput(long checkpointId) {\n+\t\tLOG.debug(\"finish input data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeInput(checkpointId));\n+\t}\n+\n+\t@Override\n+\tpublic void finishOutput(long checkpointId) {\n+\t\tLOG.debug(\"finish output data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeOutput(checkpointId));\n+\t}\n+\n+\t@Override\n+\tpublic ChannelStateWriteResult getWriteResult(long checkpointId) {\n+\t\tLOG.debug(\"requested write result, checkpoint id: {}\", checkpointId);\n+\t\tChannelStateWriteResult result = results.remove(checkpointId);\n+\t\tPreconditions.checkArgument(result != null, \"channel state write result not found for checkpoint id \" + checkpointId);\n+\t\treturn result;\n+\t}\n+\n+\tpublic void open() {\n+\t\tPreconditions.checkState(isRunning);\n+\t\tasyncWriter.start();\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tisRunning = false;\n+\t\tresults.clear();\n+\t\tasyncWriter.interrupt();\n+\t\twhile (asyncWriter.isAlive()) {\n+\t\t\ttry {\n+\t\t\t\tasyncWriter.join();\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tif (!asyncWriter.isAlive()) {\n+\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t}\n+\t\t\t\tLOG.debug(\"interrupted while waiting for the writer thread to die\", e);\n+\t\t\t}\n+\t\t}\n+\t\trethrow();\n+\t}\n+\n+\tprivate void enqueue(ChannelStateWriteRequest request) {\n+\t\trethrow();\n+\t\tPreconditions.checkState(isRunning);\n+\t\ttry {\n+\t\t\thandover.put(request);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new RuntimeException(\"Interrupted while trying to add new handover request\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void rethrow() {\n+\t\tif (thrown != null) {\n+\t\t\tthrow new RuntimeException(thrown); // wrap to record current stack-trace\n+\t\t}\n+\t}\n+\n+\tprivate static Buffer[] checkBufferType(Buffer... data) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 216}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MTAxMjky", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386101292", "createdAt": "2020-04-02T04:32:54Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNDozMjo1NFrOF_a8CQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNDozMjo1NFrOF_a8CQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA0NTk2MQ==", "bodyText": "should check both isRunning && asyncWriter.isAlive() as did in #start()", "url": "https://github.com/apache/flink/pull/11515#discussion_r402045961", "createdAt": "2020-04-02T04:32:54Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\tprivate volatile boolean isRunning;\n+\tprivate volatile Exception thrown;\n+\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory) {\n+\t\tthis(streamFactoryFactory, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.\n+\t */\n+\tChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory, int maxCheckpoints) {\n+\t\tthis(streamFactoryFactory, DEFAULT_HANDOVER_CAPACITY, new ChannelStateSerializerImpl(), maxCheckpoints);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl}.\n+\t *\n+\t * @param maxCheckpoints maximum number of checkpoints to be written currently or finished but not taken yet.\n+\t */\n+\tChannelStateWriterImpl(\n+\t\t\tCheckpointStorageWorkerView streamFactory,\n+\t\t\tint handoverCapacity,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tint maxCheckpoints) {\n+\t\tthis.handover = new ArrayBlockingQueue<>(handoverCapacity);\n+\t\tthis.results = new ConcurrentHashMap<>(maxCheckpoints);\n+\t\tthis.maxCheckpoints = maxCheckpoints;\n+\t\tthis.asyncWriter = new Thread(new ProcessRequestsLoop(maxCheckpoints, streamFactory, serializer));\n+\t\tthis.isRunning = true;\n+\t}\n+\n+\t@Override\n+\tpublic void start(long checkpointId, CheckpointOptions checkpointOptions) {\n+\t\tLOG.debug(\"start checkpoint {} ({})\", checkpointId, checkpointOptions);\n+\t\trethrow();\n+\t\tPreconditions.checkState(isRunning && asyncWriter.isAlive(), \"not running\");\n+\t\tChannelStateWriteResult result = new ChannelStateWriteResult();\n+\t\tChannelStateWriteResult put = results.computeIfAbsent(checkpointId, id -> {\n+\t\t\tPreconditions.checkArgument(results.size() < maxCheckpoints, \"results.size() > maxCheckpoints\", results.size(), maxCheckpoints);\n+\t\t\tenqueue(new CheckpointStartRequest(checkpointId, result, checkpointOptions.getTargetLocation()));\n+\t\t\treturn result;\n+\t\t});\n+\t\tPreconditions.checkArgument(put == result, \"result future already present for checkpoint id: \" + checkpointId);\n+\t}\n+\n+\t@Override\n+\tpublic void addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add input data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)));\n+\t}\n+\n+\t@Override\n+\tpublic void addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add output data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)));\n+\t}\n+\n+\t@Override\n+\tpublic void finishInput(long checkpointId) {\n+\t\tLOG.debug(\"finish input data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeInput(checkpointId));\n+\t}\n+\n+\t@Override\n+\tpublic void finishOutput(long checkpointId) {\n+\t\tLOG.debug(\"finish output data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeOutput(checkpointId));\n+\t}\n+\n+\t@Override\n+\tpublic ChannelStateWriteResult getWriteResult(long checkpointId) {\n+\t\tLOG.debug(\"requested write result, checkpoint id: {}\", checkpointId);\n+\t\tChannelStateWriteResult result = results.remove(checkpointId);\n+\t\tPreconditions.checkArgument(result != null, \"channel state write result not found for checkpoint id \" + checkpointId);\n+\t\treturn result;\n+\t}\n+\n+\tpublic void open() {\n+\t\tPreconditions.checkState(isRunning);\n+\t\tasyncWriter.start();\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tisRunning = false;\n+\t\tresults.clear();\n+\t\tasyncWriter.interrupt();\n+\t\twhile (asyncWriter.isAlive()) {\n+\t\t\ttry {\n+\t\t\t\tasyncWriter.join();\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tif (!asyncWriter.isAlive()) {\n+\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t}\n+\t\t\t\tLOG.debug(\"interrupted while waiting for the writer thread to die\", e);\n+\t\t\t}\n+\t\t}\n+\t\trethrow();\n+\t}\n+\n+\tprivate void enqueue(ChannelStateWriteRequest request) {\n+\t\trethrow();\n+\t\tPreconditions.checkState(isRunning);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 202}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MTA2MTg4", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386106188", "createdAt": "2020-04-02T04:53:14Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNDo1MzoxNFrOF_bOAg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNDo1MzoxNFrOF_bOAg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA1MDU2Mg==", "bodyText": "I do not think RuntimeException is a good way unless necessary. Although it seems simple to not announce exceptions explicitly in related methods, it might mislead the upper caller to think all the interactions with ChannelStateWriter would not cause any exceptions. Then the caller might lose the chance to handle exceptions in elegant way.\nAlso the RuntimeException seems have a more widely concept, I guess it probably should be IOException for writer to give more sense.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402050562", "createdAt": "2020-04-02T04:53:14Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\tprivate volatile boolean isRunning;\n+\tprivate volatile Exception thrown;\n+\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory) {\n+\t\tthis(streamFactoryFactory, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.\n+\t */\n+\tChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory, int maxCheckpoints) {\n+\t\tthis(streamFactoryFactory, DEFAULT_HANDOVER_CAPACITY, new ChannelStateSerializerImpl(), maxCheckpoints);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl}.\n+\t *\n+\t * @param maxCheckpoints maximum number of checkpoints to be written currently or finished but not taken yet.\n+\t */\n+\tChannelStateWriterImpl(\n+\t\t\tCheckpointStorageWorkerView streamFactory,\n+\t\t\tint handoverCapacity,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tint maxCheckpoints) {\n+\t\tthis.handover = new ArrayBlockingQueue<>(handoverCapacity);\n+\t\tthis.results = new ConcurrentHashMap<>(maxCheckpoints);\n+\t\tthis.maxCheckpoints = maxCheckpoints;\n+\t\tthis.asyncWriter = new Thread(new ProcessRequestsLoop(maxCheckpoints, streamFactory, serializer));\n+\t\tthis.isRunning = true;\n+\t}\n+\n+\t@Override\n+\tpublic void start(long checkpointId, CheckpointOptions checkpointOptions) {\n+\t\tLOG.debug(\"start checkpoint {} ({})\", checkpointId, checkpointOptions);\n+\t\trethrow();\n+\t\tPreconditions.checkState(isRunning && asyncWriter.isAlive(), \"not running\");\n+\t\tChannelStateWriteResult result = new ChannelStateWriteResult();\n+\t\tChannelStateWriteResult put = results.computeIfAbsent(checkpointId, id -> {\n+\t\t\tPreconditions.checkArgument(results.size() < maxCheckpoints, \"results.size() > maxCheckpoints\", results.size(), maxCheckpoints);\n+\t\t\tenqueue(new CheckpointStartRequest(checkpointId, result, checkpointOptions.getTargetLocation()));\n+\t\t\treturn result;\n+\t\t});\n+\t\tPreconditions.checkArgument(put == result, \"result future already present for checkpoint id: \" + checkpointId);\n+\t}\n+\n+\t@Override\n+\tpublic void addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add input data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)));\n+\t}\n+\n+\t@Override\n+\tpublic void addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add output data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)));\n+\t}\n+\n+\t@Override\n+\tpublic void finishInput(long checkpointId) {\n+\t\tLOG.debug(\"finish input data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeInput(checkpointId));\n+\t}\n+\n+\t@Override\n+\tpublic void finishOutput(long checkpointId) {\n+\t\tLOG.debug(\"finish output data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeOutput(checkpointId));\n+\t}\n+\n+\t@Override\n+\tpublic ChannelStateWriteResult getWriteResult(long checkpointId) {\n+\t\tLOG.debug(\"requested write result, checkpoint id: {}\", checkpointId);\n+\t\tChannelStateWriteResult result = results.remove(checkpointId);\n+\t\tPreconditions.checkArgument(result != null, \"channel state write result not found for checkpoint id \" + checkpointId);\n+\t\treturn result;\n+\t}\n+\n+\tpublic void open() {\n+\t\tPreconditions.checkState(isRunning);\n+\t\tasyncWriter.start();\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tisRunning = false;\n+\t\tresults.clear();\n+\t\tasyncWriter.interrupt();\n+\t\twhile (asyncWriter.isAlive()) {\n+\t\t\ttry {\n+\t\t\t\tasyncWriter.join();\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tif (!asyncWriter.isAlive()) {\n+\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t}\n+\t\t\t\tLOG.debug(\"interrupted while waiting for the writer thread to die\", e);\n+\t\t\t}\n+\t\t}\n+\t\trethrow();\n+\t}\n+\n+\tprivate void enqueue(ChannelStateWriteRequest request) {\n+\t\trethrow();\n+\t\tPreconditions.checkState(isRunning);\n+\t\ttry {\n+\t\t\thandover.put(request);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new RuntimeException(\"Interrupted while trying to add new handover request\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void rethrow() {\n+\t\tif (thrown != null) {\n+\t\t\tthrow new RuntimeException(thrown); // wrap to record current stack-trace", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 212}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MTA2OTUx", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386106951", "createdAt": "2020-04-02T04:56:22Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNDo1NjoyMlrOF_bQ7A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNDo1NjoyMlrOF_bQ7A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA1MTMwOA==", "bodyText": "rethrow() -> checkError(), because it is not determined to throw exception.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402051308", "createdAt": "2020-04-02T04:56:22Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\tprivate volatile boolean isRunning;\n+\tprivate volatile Exception thrown;\n+\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory) {\n+\t\tthis(streamFactoryFactory, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.\n+\t */\n+\tChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory, int maxCheckpoints) {\n+\t\tthis(streamFactoryFactory, DEFAULT_HANDOVER_CAPACITY, new ChannelStateSerializerImpl(), maxCheckpoints);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl}.\n+\t *\n+\t * @param maxCheckpoints maximum number of checkpoints to be written currently or finished but not taken yet.\n+\t */\n+\tChannelStateWriterImpl(\n+\t\t\tCheckpointStorageWorkerView streamFactory,\n+\t\t\tint handoverCapacity,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tint maxCheckpoints) {\n+\t\tthis.handover = new ArrayBlockingQueue<>(handoverCapacity);\n+\t\tthis.results = new ConcurrentHashMap<>(maxCheckpoints);\n+\t\tthis.maxCheckpoints = maxCheckpoints;\n+\t\tthis.asyncWriter = new Thread(new ProcessRequestsLoop(maxCheckpoints, streamFactory, serializer));\n+\t\tthis.isRunning = true;\n+\t}\n+\n+\t@Override\n+\tpublic void start(long checkpointId, CheckpointOptions checkpointOptions) {\n+\t\tLOG.debug(\"start checkpoint {} ({})\", checkpointId, checkpointOptions);\n+\t\trethrow();\n+\t\tPreconditions.checkState(isRunning && asyncWriter.isAlive(), \"not running\");\n+\t\tChannelStateWriteResult result = new ChannelStateWriteResult();\n+\t\tChannelStateWriteResult put = results.computeIfAbsent(checkpointId, id -> {\n+\t\t\tPreconditions.checkArgument(results.size() < maxCheckpoints, \"results.size() > maxCheckpoints\", results.size(), maxCheckpoints);\n+\t\t\tenqueue(new CheckpointStartRequest(checkpointId, result, checkpointOptions.getTargetLocation()));\n+\t\t\treturn result;\n+\t\t});\n+\t\tPreconditions.checkArgument(put == result, \"result future already present for checkpoint id: \" + checkpointId);\n+\t}\n+\n+\t@Override\n+\tpublic void addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add input data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)));\n+\t}\n+\n+\t@Override\n+\tpublic void addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add output data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)));\n+\t}\n+\n+\t@Override\n+\tpublic void finishInput(long checkpointId) {\n+\t\tLOG.debug(\"finish input data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeInput(checkpointId));\n+\t}\n+\n+\t@Override\n+\tpublic void finishOutput(long checkpointId) {\n+\t\tLOG.debug(\"finish output data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeOutput(checkpointId));\n+\t}\n+\n+\t@Override\n+\tpublic ChannelStateWriteResult getWriteResult(long checkpointId) {\n+\t\tLOG.debug(\"requested write result, checkpoint id: {}\", checkpointId);\n+\t\tChannelStateWriteResult result = results.remove(checkpointId);\n+\t\tPreconditions.checkArgument(result != null, \"channel state write result not found for checkpoint id \" + checkpointId);\n+\t\treturn result;\n+\t}\n+\n+\tpublic void open() {\n+\t\tPreconditions.checkState(isRunning);\n+\t\tasyncWriter.start();\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tisRunning = false;\n+\t\tresults.clear();\n+\t\tasyncWriter.interrupt();\n+\t\twhile (asyncWriter.isAlive()) {\n+\t\t\ttry {\n+\t\t\t\tasyncWriter.join();\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tif (!asyncWriter.isAlive()) {\n+\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t}\n+\t\t\t\tLOG.debug(\"interrupted while waiting for the writer thread to die\", e);\n+\t\t\t}\n+\t\t}\n+\t\trethrow();\n+\t}\n+\n+\tprivate void enqueue(ChannelStateWriteRequest request) {\n+\t\trethrow();\n+\t\tPreconditions.checkState(isRunning);\n+\t\ttry {\n+\t\t\thandover.put(request);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new RuntimeException(\"Interrupted while trying to add new handover request\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void rethrow() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 210}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MTE5OTkw", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386119990", "createdAt": "2020-04-02T05:40:58Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNTo0MDo1OFrOF_b-0Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNTo0MDo1OFrOF_b-0Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA2MzA1Nw==", "bodyText": "I am wondering it might have the possibility to add a request after clearing it, to make the new added one never removed.\nE.g.\nthread 1: #enqueue to execute rethrow and thrown is null atm\nthread 2: set thrown = ex and clear the handover as above\nthread 1: #enqueue to execute handover#put", "url": "https://github.com/apache/flink/pull/11515#discussion_r402063057", "createdAt": "2020-04-02T05:40:58Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 72}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MTIwNTkw", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386120590", "createdAt": "2020-04-02T05:42:55Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNTo0Mjo1NVrOF_cA0A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNTo0Mjo1NVrOF_cA0A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA2MzU2OA==", "bodyText": "It is weird to give a RuntimeException for the normal end. The requestProcessor.cleanup should allow a nullable exception.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402063568", "createdAt": "2020-04-02T05:42:55Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 73}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MTIyMDY5", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386122069", "createdAt": "2020-04-02T05:47:29Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNTo0NzoyOVrOF_cF3Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNTo0NzoyOVrOF_cF3Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA2NDg2MQ==", "bodyText": "what is the consideration to swallow the InterruptedException in this case. Do we want to exit this thread early when encountering InterruptedException? Also LOG.warn instead?", "url": "https://github.com/apache/flink/pull/11515#discussion_r402064861", "createdAt": "2020-04-02T05:47:29Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 84}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MTU1MDkz", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386155093", "createdAt": "2020-04-02T07:05:20Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNzowNToyMFrOF_d4Ng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNzowNToyMFrOF_d4Ng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA5NDEzNA==", "bodyText": "If we confirm this map has concurrent issues, then it should be defined as ConcurrentHashMap explicitly.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402094134", "createdAt": "2020-04-02T07:05:20Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 96}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MTU3NDU5", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386157459", "createdAt": "2020-04-02T07:09:41Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNzowOTo0MVrOF_eADw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNzowOTo0MVrOF_eADw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA5NjE0Mw==", "bodyText": "nit: checkNotNull for two arguments", "url": "https://github.com/apache/flink/pull/11515#discussion_r402096143", "createdAt": "2020-04-02T07:09:41Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestProcessor.java", "diffHunk": "@@ -0,0 +1,77 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+/**\n+ * Maintains a set of {@link ChannelStateCheckpointWriter writers} per checkpoint and translates incoming\n+ * {@link ChannelStateWriteRequest requests} to their corresponding methods.\n+ */\n+final class ChannelStateWriteRequestProcessor {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriteRequestProcessor.class);\n+\n+\tprivate final Map<Long, ChannelStateCheckpointWriter> writers; // limited indirectly by results max size\n+\tprivate final CheckpointStorageWorkerView streamFactoryFactory;\n+\tprivate final ChannelStateSerializer serializer;\n+\n+\tChannelStateWriteRequestProcessor(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\tthis.writers = new HashMap<>(maxCheckpoints);\n+\t\tthis.streamFactoryFactory = streamFactoryFactory;\n+\t\tthis.serializer = serializer;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 43}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MTU4NDgy", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386158482", "createdAt": "2020-04-02T07:11:37Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNzoxMTozN1rOF_eDbQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNzoxMTozN1rOF_eDbQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA5NzAwNQ==", "bodyText": "ditto: weird naming for me", "url": "https://github.com/apache/flink/pull/11515#discussion_r402097005", "createdAt": "2020-04-02T07:11:37Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestProcessor.java", "diffHunk": "@@ -0,0 +1,77 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+/**\n+ * Maintains a set of {@link ChannelStateCheckpointWriter writers} per checkpoint and translates incoming\n+ * {@link ChannelStateWriteRequest requests} to their corresponding methods.\n+ */\n+final class ChannelStateWriteRequestProcessor {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriteRequestProcessor.class);\n+\n+\tprivate final Map<Long, ChannelStateCheckpointWriter> writers; // limited indirectly by results max size\n+\tprivate final CheckpointStorageWorkerView streamFactoryFactory;\n+\tprivate final ChannelStateSerializer serializer;\n+\n+\tChannelStateWriteRequestProcessor(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\tthis.writers = new HashMap<>(maxCheckpoints);\n+\t\tthis.streamFactoryFactory = streamFactoryFactory;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 42}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MTY0NjU5", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386164659", "createdAt": "2020-04-02T07:22:23Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNzoyMjoyM1rOF_eXYA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNzoyMjoyM1rOF_eXYA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjEwMjExMg==", "bodyText": "I suggest removing this constructor to avoid introducing multiple constructors to maintain, except for easing tests purpose. But here is not that case.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402102112", "createdAt": "2020-04-02T07:22:23Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateCheckpointWriter.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory.CheckpointStateOutputStream;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.runtime.state.ResultSubpartitionStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.BiFunction;\n+\n+import static org.apache.flink.runtime.state.CheckpointedStateScope.EXCLUSIVE;\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+\n+/**\n+ * Writes channel state for a specific checkpoint-subtask-attempt triple.\n+ */\n+@NotThreadSafe\n+class ChannelStateCheckpointWriter {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateCheckpointWriter.class);\n+\n+\tprivate final DataOutputStream dataStream;\n+\tprivate final CheckpointStateOutputStream checkpointStream;\n+\tprivate final ChannelStateWriteResult result;\n+\tprivate final Map<InputChannelInfo, List<Long>> inputChannelOffsets = new HashMap<>();\n+\tprivate final Map<ResultSubpartitionInfo, List<Long>> resultSubpartitionOffsets = new HashMap<>();\n+\tprivate final ChannelStateSerializer serializer;\n+\tprivate final long checkpointId;\n+\tprivate boolean inputCompleted = false;\n+\tprivate boolean outputCompleted = false;\n+\tprivate final Runnable onComplete;\n+\n+\tChannelStateCheckpointWriter(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 67}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MTY2NzQw", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386166740", "createdAt": "2020-04-02T07:25:55Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNzoyNTo1NlrOF_eedQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNzoyNTo1NlrOF_eedQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjEwMzkyNQ==", "bodyText": "nit: better to keep the sequence as above arguments", "url": "https://github.com/apache/flink/pull/11515#discussion_r402103925", "createdAt": "2020-04-02T07:25:56Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateCheckpointWriter.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory.CheckpointStateOutputStream;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.runtime.state.ResultSubpartitionStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.BiFunction;\n+\n+import static org.apache.flink.runtime.state.CheckpointedStateScope.EXCLUSIVE;\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+\n+/**\n+ * Writes channel state for a specific checkpoint-subtask-attempt triple.\n+ */\n+@NotThreadSafe\n+class ChannelStateCheckpointWriter {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateCheckpointWriter.class);\n+\n+\tprivate final DataOutputStream dataStream;\n+\tprivate final CheckpointStateOutputStream checkpointStream;\n+\tprivate final ChannelStateWriteResult result;\n+\tprivate final Map<InputChannelInfo, List<Long>> inputChannelOffsets = new HashMap<>();\n+\tprivate final Map<ResultSubpartitionInfo, List<Long>> resultSubpartitionOffsets = new HashMap<>();\n+\tprivate final ChannelStateSerializer serializer;\n+\tprivate final long checkpointId;\n+\tprivate boolean inputCompleted = false;\n+\tprivate boolean outputCompleted = false;\n+\tprivate final Runnable onComplete;\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tCheckpointStartRequest startCheckpointItem,\n+\t\t\tCheckpointStreamFactory streamFactory,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete) throws Exception {\n+\t\tthis(startCheckpointItem.checkpointId, startCheckpointItem.targetResult, streamFactory.createCheckpointStateOutputStream(EXCLUSIVE), serializer, onComplete);\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tCheckpointStateOutputStream stream,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete) throws Exception {\n+\t\tthis(checkpointId, result, serializer, onComplete, stream, new DataOutputStream(stream));\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete,\n+\t\t\tCheckpointStateOutputStream checkpointStateOutputStream,\n+\t\t\tDataOutputStream dataStream) throws Exception {\n+\t\tthis.checkpointId = checkpointId;\n+\t\tthis.result = checkNotNull(result);\n+\t\tthis.checkpointStream = checkNotNull(checkpointStateOutputStream);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 93}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MTcxNTA1", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386171505", "createdAt": "2020-04-02T07:33:54Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNzozMzo1NFrOF_et-A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNzozMzo1NFrOF_et-A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjEwNzg5Ng==", "bodyText": "nit: it is weird for me to emphasis flinkBuffers, buffers should be ok.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402107896", "createdAt": "2020-04-02T07:33:54Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequest.java", "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageLocationReference;\n+import org.apache.flink.util.function.ThrowingConsumer;\n+\n+abstract class ChannelStateWriteRequest {\n+\tfinal long checkpointId;\n+\n+\tChannelStateWriteRequest(long checkpointId) {\n+\t\tthis.checkpointId = checkpointId;\n+\t}\n+\n+\t@Override\n+\tpublic String toString() {\n+\t\treturn getClass().getSimpleName() + \", checkpointId=\" + checkpointId;\n+\t}\n+\n+\tstatic CheckpointInProgressRequest completeInput(long checkpointId) {\n+\t\treturn new CheckpointInProgressRequest(checkpointId, ChannelStateCheckpointWriter::completeInput);\n+\t}\n+\n+\tstatic CheckpointInProgressRequest completeOutput(long checkpointId) {\n+\t\treturn new CheckpointInProgressRequest(checkpointId, ChannelStateCheckpointWriter::completeOutput);\n+\t}\n+\n+\tstatic ChannelStateWriteRequest write(long checkpointId, InputChannelInfo info, Buffer... flinkBuffers) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 45}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MTcxNjk5", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386171699", "createdAt": "2020-04-02T07:34:13Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNzozNDoxM1rOF_euxw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNzozNDoxM1rOF_euxw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjEwODEwMw==", "bodyText": "nit: checkNotNull", "url": "https://github.com/apache/flink/pull/11515#discussion_r402108103", "createdAt": "2020-04-02T07:34:13Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequest.java", "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageLocationReference;\n+import org.apache.flink.util.function.ThrowingConsumer;\n+\n+abstract class ChannelStateWriteRequest {\n+\tfinal long checkpointId;\n+\n+\tChannelStateWriteRequest(long checkpointId) {\n+\t\tthis.checkpointId = checkpointId;\n+\t}\n+\n+\t@Override\n+\tpublic String toString() {\n+\t\treturn getClass().getSimpleName() + \", checkpointId=\" + checkpointId;\n+\t}\n+\n+\tstatic CheckpointInProgressRequest completeInput(long checkpointId) {\n+\t\treturn new CheckpointInProgressRequest(checkpointId, ChannelStateCheckpointWriter::completeInput);\n+\t}\n+\n+\tstatic CheckpointInProgressRequest completeOutput(long checkpointId) {\n+\t\treturn new CheckpointInProgressRequest(checkpointId, ChannelStateCheckpointWriter::completeOutput);\n+\t}\n+\n+\tstatic ChannelStateWriteRequest write(long checkpointId, InputChannelInfo info, Buffer... flinkBuffers) {\n+\t\treturn new CheckpointInProgressRequest(checkpointId, writer -> writer.writeInput(info, flinkBuffers));\n+\t}\n+\n+\tstatic ChannelStateWriteRequest write(long checkpointId, ResultSubpartitionInfo info, Buffer... flinkBuffers) {\n+\t\treturn new CheckpointInProgressRequest(checkpointId, writer -> writer.writeOutput(info, flinkBuffers));\n+\t}\n+}\n+\n+final class CheckpointStartRequest extends ChannelStateWriteRequest {\n+\tfinal ChannelStateWriteResult targetResult;\n+\tfinal CheckpointStorageLocationReference locationReference;\n+\n+\tCheckpointStartRequest(long checkpointId, ChannelStateWriteResult targetResult, CheckpointStorageLocationReference locationReference) {\n+\t\tsuper(checkpointId);\n+\t\tthis.targetResult = targetResult;\n+\t\tthis.locationReference = locationReference;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 61}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MTcxODYx", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386171861", "createdAt": "2020-04-02T07:34:30Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNzozNDozMFrOF_evQQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNzozNDozMFrOF_evQQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjEwODIyNQ==", "bodyText": "ditto: checkNotNull", "url": "https://github.com/apache/flink/pull/11515#discussion_r402108225", "createdAt": "2020-04-02T07:34:30Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequest.java", "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageLocationReference;\n+import org.apache.flink.util.function.ThrowingConsumer;\n+\n+abstract class ChannelStateWriteRequest {\n+\tfinal long checkpointId;\n+\n+\tChannelStateWriteRequest(long checkpointId) {\n+\t\tthis.checkpointId = checkpointId;\n+\t}\n+\n+\t@Override\n+\tpublic String toString() {\n+\t\treturn getClass().getSimpleName() + \", checkpointId=\" + checkpointId;\n+\t}\n+\n+\tstatic CheckpointInProgressRequest completeInput(long checkpointId) {\n+\t\treturn new CheckpointInProgressRequest(checkpointId, ChannelStateCheckpointWriter::completeInput);\n+\t}\n+\n+\tstatic CheckpointInProgressRequest completeOutput(long checkpointId) {\n+\t\treturn new CheckpointInProgressRequest(checkpointId, ChannelStateCheckpointWriter::completeOutput);\n+\t}\n+\n+\tstatic ChannelStateWriteRequest write(long checkpointId, InputChannelInfo info, Buffer... flinkBuffers) {\n+\t\treturn new CheckpointInProgressRequest(checkpointId, writer -> writer.writeInput(info, flinkBuffers));\n+\t}\n+\n+\tstatic ChannelStateWriteRequest write(long checkpointId, ResultSubpartitionInfo info, Buffer... flinkBuffers) {\n+\t\treturn new CheckpointInProgressRequest(checkpointId, writer -> writer.writeOutput(info, flinkBuffers));\n+\t}\n+}\n+\n+final class CheckpointStartRequest extends ChannelStateWriteRequest {\n+\tfinal ChannelStateWriteResult targetResult;\n+\tfinal CheckpointStorageLocationReference locationReference;\n+\n+\tCheckpointStartRequest(long checkpointId, ChannelStateWriteResult targetResult, CheckpointStorageLocationReference locationReference) {\n+\t\tsuper(checkpointId);\n+\t\tthis.targetResult = targetResult;\n+\t\tthis.locationReference = locationReference;\n+\t}\n+}\n+\n+final class CheckpointInProgressRequest extends ChannelStateWriteRequest {\n+\tfinal ThrowingConsumer<ChannelStateCheckpointWriter, Exception> action;\n+\n+\tCheckpointInProgressRequest(long checkpointId, ThrowingConsumer<ChannelStateCheckpointWriter, Exception> action) {\n+\t\tsuper(checkpointId);\n+\t\tthis.action = action;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 70}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MTgwMzI3", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386180327", "createdAt": "2020-04-02T07:47:39Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNzo0NzozOVrOF_fJ9Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNzo0NzozOVrOF_fJ9Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjExNTA2MQ==", "bodyText": "nit: r -> runnable", "url": "https://github.com/apache/flink/pull/11515#discussion_r402115061", "createdAt": "2020-04-02T07:47:39Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateCheckpointWriter.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory.CheckpointStateOutputStream;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.runtime.state.ResultSubpartitionStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.BiFunction;\n+\n+import static org.apache.flink.runtime.state.CheckpointedStateScope.EXCLUSIVE;\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+\n+/**\n+ * Writes channel state for a specific checkpoint-subtask-attempt triple.\n+ */\n+@NotThreadSafe\n+class ChannelStateCheckpointWriter {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateCheckpointWriter.class);\n+\n+\tprivate final DataOutputStream dataStream;\n+\tprivate final CheckpointStateOutputStream checkpointStream;\n+\tprivate final ChannelStateWriteResult result;\n+\tprivate final Map<InputChannelInfo, List<Long>> inputChannelOffsets = new HashMap<>();\n+\tprivate final Map<ResultSubpartitionInfo, List<Long>> resultSubpartitionOffsets = new HashMap<>();\n+\tprivate final ChannelStateSerializer serializer;\n+\tprivate final long checkpointId;\n+\tprivate boolean inputCompleted = false;\n+\tprivate boolean outputCompleted = false;\n+\tprivate final Runnable onComplete;\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tCheckpointStartRequest startCheckpointItem,\n+\t\t\tCheckpointStreamFactory streamFactory,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete) throws Exception {\n+\t\tthis(startCheckpointItem.checkpointId, startCheckpointItem.targetResult, streamFactory.createCheckpointStateOutputStream(EXCLUSIVE), serializer, onComplete);\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tCheckpointStateOutputStream stream,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete) throws Exception {\n+\t\tthis(checkpointId, result, serializer, onComplete, stream, new DataOutputStream(stream));\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete,\n+\t\t\tCheckpointStateOutputStream checkpointStateOutputStream,\n+\t\t\tDataOutputStream dataStream) throws Exception {\n+\t\tthis.checkpointId = checkpointId;\n+\t\tthis.result = checkNotNull(result);\n+\t\tthis.checkpointStream = checkNotNull(checkpointStateOutputStream);\n+\t\tthis.serializer = checkNotNull(serializer);\n+\t\tthis.dataStream = checkNotNull(dataStream);\n+\t\tthis.onComplete = checkNotNull(onComplete);\n+\t\trunWithChecks(() -> serializer.writeHeader(dataStream));\n+\t}\n+\n+\tvoid writeInput(InputChannelInfo info, Buffer... flinkBuffers) throws Exception {\n+\t\tPreconditions.checkState(!inputCompleted);\n+\t\twrite(inputChannelOffsets, info, flinkBuffers);\n+\t}\n+\n+\tvoid writeOutput(ResultSubpartitionInfo info, Buffer[] flinkBuffers) throws Exception {\n+\t\tPreconditions.checkState(!outputCompleted);\n+\t\twrite(resultSubpartitionOffsets, info, flinkBuffers);\n+\t}\n+\n+\tprivate <K> void write(Map<K, List<Long>> offsets, K key, Buffer[] flinkBuffers) throws Exception {\n+\t\trunWithChecks(() -> {\n+\t\t\ttry {\n+\t\t\t\toffsets\n+\t\t\t\t\t.computeIfAbsent(key, unused -> new ArrayList<>())\n+\t\t\t\t\t.add(checkpointStream.getPos());\n+\t\t\t\tserializer.writeData(dataStream, flinkBuffers);\n+\t\t\t} finally {\n+\t\t\t\tfor (Buffer flinkBuffer : flinkBuffers) {\n+\t\t\t\t\tflinkBuffer.recycleBuffer();\n+\t\t\t\t}\n+\t\t\t}\n+\t\t});\n+\t}\n+\n+\tvoid completeInput() throws Exception {\n+\t\tLOG.debug(\"complete input, output completed: {}\", outputCompleted);\n+\t\trunWithChecks(() -> {\n+\t\t\tPreconditions.checkState(!inputCompleted);\n+\t\t\tinputCompleted = true;\n+\t\t\tcomplete();\n+\t\t});\n+\t}\n+\n+\tvoid completeOutput() throws Exception {\n+\t\tLOG.debug(\"complete output, input completed: {}\", inputCompleted);\n+\t\trunWithChecks(() -> {\n+\t\t\tPreconditions.checkState(!outputCompleted);\n+\t\t\toutputCompleted = true;\n+\t\t\tcomplete();\n+\t\t});\n+\t}\n+\n+\tprivate void complete() throws IOException {\n+\t\tif (inputCompleted && outputCompleted) {\n+\t\t\tonComplete.run();\n+\t\t\tdataStream.flush();\n+\t\t\tStreamStateHandle underlying = checkpointStream.closeAndGetHandle();\n+\t\t\tcomplete(\n+\t\t\t\tresult.inputChannelStateHandles,\n+\t\t\t\tinputChannelOffsets,\n+\t\t\t\t(chan, offsets) -> new InputChannelStateHandle(chan, underlying, offsets));\n+\t\t\tcomplete(\n+\t\t\t\tresult.resultSubpartitionStateHandles,\n+\t\t\t\tresultSubpartitionOffsets,\n+\t\t\t\t(chan, offsets) -> new ResultSubpartitionStateHandle(chan, underlying, offsets));\n+\t\t}\n+\t}\n+\n+\tprivate <I, H extends AbstractChannelStateHandle<I>> void complete(\n+\t\tCompletableFuture<Collection<H>> future,\n+\t\tMap<I, List<Long>> offsets,\n+\t\tBiFunction<I, List<Long>, H> buildHandle) {\n+\t\tfinal Collection<H> handles = new ArrayList<>();\n+\t\tfor (Map.Entry<I, List<Long>> e : offsets.entrySet()) {\n+\t\t\thandles.add(buildHandle.apply(e.getKey(), e.getValue()));\n+\t\t}\n+\t\tfuture.complete(handles);\n+\t\tLOG.debug(\"channel state write completed, checkpointId: {}, handles: {}\", checkpointId, handles);\n+\t}\n+\n+\tprivate void runWithChecks(RunnableWithException r) throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 171}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MTg2MjMx", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386186231", "createdAt": "2020-04-02T07:55:56Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNzo1NTo1NlrOF_fd5w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwNzo1NTo1NlrOF_fd5w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjEyMDE2Nw==", "bodyText": "chan -> info?", "url": "https://github.com/apache/flink/pull/11515#discussion_r402120167", "createdAt": "2020-04-02T07:55:56Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateCheckpointWriter.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory.CheckpointStateOutputStream;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.runtime.state.ResultSubpartitionStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.BiFunction;\n+\n+import static org.apache.flink.runtime.state.CheckpointedStateScope.EXCLUSIVE;\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+\n+/**\n+ * Writes channel state for a specific checkpoint-subtask-attempt triple.\n+ */\n+@NotThreadSafe\n+class ChannelStateCheckpointWriter {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateCheckpointWriter.class);\n+\n+\tprivate final DataOutputStream dataStream;\n+\tprivate final CheckpointStateOutputStream checkpointStream;\n+\tprivate final ChannelStateWriteResult result;\n+\tprivate final Map<InputChannelInfo, List<Long>> inputChannelOffsets = new HashMap<>();\n+\tprivate final Map<ResultSubpartitionInfo, List<Long>> resultSubpartitionOffsets = new HashMap<>();\n+\tprivate final ChannelStateSerializer serializer;\n+\tprivate final long checkpointId;\n+\tprivate boolean inputCompleted = false;\n+\tprivate boolean outputCompleted = false;\n+\tprivate final Runnable onComplete;\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tCheckpointStartRequest startCheckpointItem,\n+\t\t\tCheckpointStreamFactory streamFactory,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete) throws Exception {\n+\t\tthis(startCheckpointItem.checkpointId, startCheckpointItem.targetResult, streamFactory.createCheckpointStateOutputStream(EXCLUSIVE), serializer, onComplete);\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tCheckpointStateOutputStream stream,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete) throws Exception {\n+\t\tthis(checkpointId, result, serializer, onComplete, stream, new DataOutputStream(stream));\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete,\n+\t\t\tCheckpointStateOutputStream checkpointStateOutputStream,\n+\t\t\tDataOutputStream dataStream) throws Exception {\n+\t\tthis.checkpointId = checkpointId;\n+\t\tthis.result = checkNotNull(result);\n+\t\tthis.checkpointStream = checkNotNull(checkpointStateOutputStream);\n+\t\tthis.serializer = checkNotNull(serializer);\n+\t\tthis.dataStream = checkNotNull(dataStream);\n+\t\tthis.onComplete = checkNotNull(onComplete);\n+\t\trunWithChecks(() -> serializer.writeHeader(dataStream));\n+\t}\n+\n+\tvoid writeInput(InputChannelInfo info, Buffer... flinkBuffers) throws Exception {\n+\t\tPreconditions.checkState(!inputCompleted);\n+\t\twrite(inputChannelOffsets, info, flinkBuffers);\n+\t}\n+\n+\tvoid writeOutput(ResultSubpartitionInfo info, Buffer[] flinkBuffers) throws Exception {\n+\t\tPreconditions.checkState(!outputCompleted);\n+\t\twrite(resultSubpartitionOffsets, info, flinkBuffers);\n+\t}\n+\n+\tprivate <K> void write(Map<K, List<Long>> offsets, K key, Buffer[] flinkBuffers) throws Exception {\n+\t\trunWithChecks(() -> {\n+\t\t\ttry {\n+\t\t\t\toffsets\n+\t\t\t\t\t.computeIfAbsent(key, unused -> new ArrayList<>())\n+\t\t\t\t\t.add(checkpointStream.getPos());\n+\t\t\t\tserializer.writeData(dataStream, flinkBuffers);\n+\t\t\t} finally {\n+\t\t\t\tfor (Buffer flinkBuffer : flinkBuffers) {\n+\t\t\t\t\tflinkBuffer.recycleBuffer();\n+\t\t\t\t}\n+\t\t\t}\n+\t\t});\n+\t}\n+\n+\tvoid completeInput() throws Exception {\n+\t\tLOG.debug(\"complete input, output completed: {}\", outputCompleted);\n+\t\trunWithChecks(() -> {\n+\t\t\tPreconditions.checkState(!inputCompleted);\n+\t\t\tinputCompleted = true;\n+\t\t\tcomplete();\n+\t\t});\n+\t}\n+\n+\tvoid completeOutput() throws Exception {\n+\t\tLOG.debug(\"complete output, input completed: {}\", inputCompleted);\n+\t\trunWithChecks(() -> {\n+\t\t\tPreconditions.checkState(!outputCompleted);\n+\t\t\toutputCompleted = true;\n+\t\t\tcomplete();\n+\t\t});\n+\t}\n+\n+\tprivate void complete() throws IOException {\n+\t\tif (inputCompleted && outputCompleted) {\n+\t\t\tonComplete.run();\n+\t\t\tdataStream.flush();\n+\t\t\tStreamStateHandle underlying = checkpointStream.closeAndGetHandle();\n+\t\t\tcomplete(\n+\t\t\t\tresult.inputChannelStateHandles,\n+\t\t\t\tinputChannelOffsets,\n+\t\t\t\t(chan, offsets) -> new InputChannelStateHandle(chan, underlying, offsets));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 151}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MjAwNjQy", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386200642", "createdAt": "2020-04-02T08:17:02Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwODoxNzowMlrOF_gLhw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwODoxNzowMlrOF_gLhw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjEzMTg0Nw==", "bodyText": "chan -> info?", "url": "https://github.com/apache/flink/pull/11515#discussion_r402131847", "createdAt": "2020-04-02T08:17:02Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateCheckpointWriter.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory.CheckpointStateOutputStream;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.runtime.state.ResultSubpartitionStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.BiFunction;\n+\n+import static org.apache.flink.runtime.state.CheckpointedStateScope.EXCLUSIVE;\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+\n+/**\n+ * Writes channel state for a specific checkpoint-subtask-attempt triple.\n+ */\n+@NotThreadSafe\n+class ChannelStateCheckpointWriter {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateCheckpointWriter.class);\n+\n+\tprivate final DataOutputStream dataStream;\n+\tprivate final CheckpointStateOutputStream checkpointStream;\n+\tprivate final ChannelStateWriteResult result;\n+\tprivate final Map<InputChannelInfo, List<Long>> inputChannelOffsets = new HashMap<>();\n+\tprivate final Map<ResultSubpartitionInfo, List<Long>> resultSubpartitionOffsets = new HashMap<>();\n+\tprivate final ChannelStateSerializer serializer;\n+\tprivate final long checkpointId;\n+\tprivate boolean inputCompleted = false;\n+\tprivate boolean outputCompleted = false;\n+\tprivate final Runnable onComplete;\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tCheckpointStartRequest startCheckpointItem,\n+\t\t\tCheckpointStreamFactory streamFactory,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete) throws Exception {\n+\t\tthis(startCheckpointItem.checkpointId, startCheckpointItem.targetResult, streamFactory.createCheckpointStateOutputStream(EXCLUSIVE), serializer, onComplete);\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tCheckpointStateOutputStream stream,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete) throws Exception {\n+\t\tthis(checkpointId, result, serializer, onComplete, stream, new DataOutputStream(stream));\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete,\n+\t\t\tCheckpointStateOutputStream checkpointStateOutputStream,\n+\t\t\tDataOutputStream dataStream) throws Exception {\n+\t\tthis.checkpointId = checkpointId;\n+\t\tthis.result = checkNotNull(result);\n+\t\tthis.checkpointStream = checkNotNull(checkpointStateOutputStream);\n+\t\tthis.serializer = checkNotNull(serializer);\n+\t\tthis.dataStream = checkNotNull(dataStream);\n+\t\tthis.onComplete = checkNotNull(onComplete);\n+\t\trunWithChecks(() -> serializer.writeHeader(dataStream));\n+\t}\n+\n+\tvoid writeInput(InputChannelInfo info, Buffer... flinkBuffers) throws Exception {\n+\t\tPreconditions.checkState(!inputCompleted);\n+\t\twrite(inputChannelOffsets, info, flinkBuffers);\n+\t}\n+\n+\tvoid writeOutput(ResultSubpartitionInfo info, Buffer[] flinkBuffers) throws Exception {\n+\t\tPreconditions.checkState(!outputCompleted);\n+\t\twrite(resultSubpartitionOffsets, info, flinkBuffers);\n+\t}\n+\n+\tprivate <K> void write(Map<K, List<Long>> offsets, K key, Buffer[] flinkBuffers) throws Exception {\n+\t\trunWithChecks(() -> {\n+\t\t\ttry {\n+\t\t\t\toffsets\n+\t\t\t\t\t.computeIfAbsent(key, unused -> new ArrayList<>())\n+\t\t\t\t\t.add(checkpointStream.getPos());\n+\t\t\t\tserializer.writeData(dataStream, flinkBuffers);\n+\t\t\t} finally {\n+\t\t\t\tfor (Buffer flinkBuffer : flinkBuffers) {\n+\t\t\t\t\tflinkBuffer.recycleBuffer();\n+\t\t\t\t}\n+\t\t\t}\n+\t\t});\n+\t}\n+\n+\tvoid completeInput() throws Exception {\n+\t\tLOG.debug(\"complete input, output completed: {}\", outputCompleted);\n+\t\trunWithChecks(() -> {\n+\t\t\tPreconditions.checkState(!inputCompleted);\n+\t\t\tinputCompleted = true;\n+\t\t\tcomplete();\n+\t\t});\n+\t}\n+\n+\tvoid completeOutput() throws Exception {\n+\t\tLOG.debug(\"complete output, input completed: {}\", inputCompleted);\n+\t\trunWithChecks(() -> {\n+\t\t\tPreconditions.checkState(!outputCompleted);\n+\t\t\toutputCompleted = true;\n+\t\t\tcomplete();\n+\t\t});\n+\t}\n+\n+\tprivate void complete() throws IOException {\n+\t\tif (inputCompleted && outputCompleted) {\n+\t\t\tonComplete.run();\n+\t\t\tdataStream.flush();\n+\t\t\tStreamStateHandle underlying = checkpointStream.closeAndGetHandle();\n+\t\t\tcomplete(\n+\t\t\t\tresult.inputChannelStateHandles,\n+\t\t\t\tinputChannelOffsets,\n+\t\t\t\t(chan, offsets) -> new InputChannelStateHandle(chan, underlying, offsets));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 151}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MjAyODMz", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386202833", "createdAt": "2020-04-02T08:20:05Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwODoyMDowNVrOF_gSDA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwODoyMDowNVrOF_gSDA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjEzMzUxNg==", "bodyText": "nit: i, r give some meaningful names and split the arguments in separate line.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402133516", "createdAt": "2020-04-02T08:20:05Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriter.java", "diffHunk": "@@ -18,19 +18,51 @@\n package org.apache.flink.runtime.checkpoint.channel;\n \n import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n import org.apache.flink.runtime.io.network.buffer.Buffer;\n-import org.apache.flink.runtime.state.StateObject;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.runtime.state.ResultSubpartitionStateHandle;\n \n+import java.io.Closeable;\n import java.util.Collection;\n import java.util.Collections;\n import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.Future;\n \n /**\n  * Writes channel state during checkpoint/savepoint.\n  */\n @Internal\n-public interface ChannelStateWriter extends AutoCloseable {\n+public interface ChannelStateWriter extends Closeable {\n+\n+\t/**\n+\t * Channel state write result.\n+\t */\n+\tclass ChannelStateWriteResult {\n+\t\tfinal CompletableFuture<Collection<InputChannelStateHandle>> inputChannelStateHandles;\n+\t\tfinal CompletableFuture<Collection<ResultSubpartitionStateHandle>> resultSubpartitionStateHandles;\n+\n+\t\tChannelStateWriteResult() {\n+\t\t\tthis(new CompletableFuture<>(), new CompletableFuture<>());\n+\t\t}\n+\n+\t\tChannelStateWriteResult(CompletableFuture<Collection<InputChannelStateHandle>> i, CompletableFuture<Collection<ResultSubpartitionStateHandle>> r) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 34}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2Mjg2NDg5", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386286489", "createdAt": "2020-04-02T10:12:40Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMDoxMjo0MVrOF_kegg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMDoxMjo0MVrOF_kegg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIwMjI0Mg==", "bodyText": "@VisibleForTesting", "url": "https://github.com/apache/flink/pull/11515#discussion_r402202242", "createdAt": "2020-04-02T10:12:41Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImpl.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.io.Closer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * {@link ChannelStateReader} implementation. Usage considerations:\n+ * <ol>\n+ *     <li>state of a channel can be read once per instance of this class; once done it returns\n+ *     {@link org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult#NO_MORE_DATA NO_MORE_DATA}</li>\n+ *     <li>reader/writer indices of the passed buffer are respected and updated</li>\n+ *     <li>buffers must be prepared (cleared) before passing to reader</li>\n+ *     <li>buffers must be released after use</li>\n+ * </ol>\n+ */\n+@NotThreadSafe\n+@Internal\n+public class ChannelStateReaderImpl implements ChannelStateReader {\n+\tprivate static final Logger log = LoggerFactory.getLogger(ChannelStateReaderImpl.class);\n+\n+\tprivate final Map<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReaders;\n+\tprivate final Map<ResultSubpartitionInfo, ChannelStateStreamReader> resultSubpartitionHandleReaders;\n+\n+\tpublic ChannelStateReaderImpl(TaskStateSnapshot snapshot) {\n+\t\tthis(snapshot, new ChannelStateSerializerImpl());\n+\t}\n+\n+\t@SuppressWarnings(\"WeakerAccess\")\n+\tChannelStateReaderImpl(TaskStateSnapshot snapshot, ChannelStateDeserializer serializer) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 68}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2Mjg5OTYx", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386289961", "createdAt": "2020-04-02T10:17:55Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMDoxNzo1NVrOF_kpdA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMDoxNzo1NVrOF_kpdA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIwNTA0NA==", "bodyText": "we can pass class field inputChannelHandleReaders directly  in below addReaders to avoid temporary variables.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402205044", "createdAt": "2020-04-02T10:17:55Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImpl.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.io.Closer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * {@link ChannelStateReader} implementation. Usage considerations:\n+ * <ol>\n+ *     <li>state of a channel can be read once per instance of this class; once done it returns\n+ *     {@link org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult#NO_MORE_DATA NO_MORE_DATA}</li>\n+ *     <li>reader/writer indices of the passed buffer are respected and updated</li>\n+ *     <li>buffers must be prepared (cleared) before passing to reader</li>\n+ *     <li>buffers must be released after use</li>\n+ * </ol>\n+ */\n+@NotThreadSafe\n+@Internal\n+public class ChannelStateReaderImpl implements ChannelStateReader {\n+\tprivate static final Logger log = LoggerFactory.getLogger(ChannelStateReaderImpl.class);\n+\n+\tprivate final Map<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReaders;\n+\tprivate final Map<ResultSubpartitionInfo, ChannelStateStreamReader> resultSubpartitionHandleReaders;\n+\n+\tpublic ChannelStateReaderImpl(TaskStateSnapshot snapshot) {\n+\t\tthis(snapshot, new ChannelStateSerializerImpl());\n+\t}\n+\n+\t@SuppressWarnings(\"WeakerAccess\")\n+\tChannelStateReaderImpl(TaskStateSnapshot snapshot, ChannelStateDeserializer serializer) {\n+\t\tRefCountingFSDataInputStreamFactory streamFactory = new RefCountingFSDataInputStreamFactory(serializer);\n+\t\tfinal HashMap<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReadersTmp = new HashMap<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 70}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MjkwMjE2", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386290216", "createdAt": "2020-04-02T10:18:15Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMDoxODoxNlrOF_kqRw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMDoxODoxNlrOF_kqRw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIwNTI1NQ==", "bodyText": "too long line, should split line for arguments", "url": "https://github.com/apache/flink/pull/11515#discussion_r402205255", "createdAt": "2020-04-02T10:18:16Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImpl.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.io.Closer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * {@link ChannelStateReader} implementation. Usage considerations:\n+ * <ol>\n+ *     <li>state of a channel can be read once per instance of this class; once done it returns\n+ *     {@link org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult#NO_MORE_DATA NO_MORE_DATA}</li>\n+ *     <li>reader/writer indices of the passed buffer are respected and updated</li>\n+ *     <li>buffers must be prepared (cleared) before passing to reader</li>\n+ *     <li>buffers must be released after use</li>\n+ * </ol>\n+ */\n+@NotThreadSafe\n+@Internal\n+public class ChannelStateReaderImpl implements ChannelStateReader {\n+\tprivate static final Logger log = LoggerFactory.getLogger(ChannelStateReaderImpl.class);\n+\n+\tprivate final Map<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReaders;\n+\tprivate final Map<ResultSubpartitionInfo, ChannelStateStreamReader> resultSubpartitionHandleReaders;\n+\n+\tpublic ChannelStateReaderImpl(TaskStateSnapshot snapshot) {\n+\t\tthis(snapshot, new ChannelStateSerializerImpl());\n+\t}\n+\n+\t@SuppressWarnings(\"WeakerAccess\")\n+\tChannelStateReaderImpl(TaskStateSnapshot snapshot, ChannelStateDeserializer serializer) {\n+\t\tRefCountingFSDataInputStreamFactory streamFactory = new RefCountingFSDataInputStreamFactory(serializer);\n+\t\tfinal HashMap<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReadersTmp = new HashMap<>();\n+\t\tfinal HashMap<ResultSubpartitionInfo, ChannelStateStreamReader> resultSubpartitionHandleReadersTmp = new HashMap<>();\n+\t\tfor (Map.Entry<OperatorID, OperatorSubtaskState> e : snapshot.getSubtaskStateMappings()) {\n+\t\t\taddReaders(inputChannelHandleReadersTmp, e.getValue().getInputChannelState(), streamFactory);\n+\t\t\taddReaders(resultSubpartitionHandleReadersTmp, e.getValue().getResultSubpartitionState(), streamFactory);\n+\t\t}\n+\t\tinputChannelHandleReaders = inputChannelHandleReadersTmp;\n+\t\tresultSubpartitionHandleReaders = resultSubpartitionHandleReadersTmp;\n+\t}\n+\n+\tprivate <T> void addReaders(Map<T, ChannelStateStreamReader> readerMap, Collection<? extends AbstractChannelStateHandle<T>> handles, RefCountingFSDataInputStreamFactory streamFactory) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 80}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MjkyNDgz", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386292483", "createdAt": "2020-04-02T10:21:41Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMDoyMTo0MVrOF_kxXA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMDoyMTo0MVrOF_kxXA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIwNzA2OA==", "bodyText": "nit: bufferBuilder -> buffer:", "url": "https://github.com/apache/flink/pull/11515#discussion_r402207068", "createdAt": "2020-04-02T10:21:41Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImpl.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.io.Closer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * {@link ChannelStateReader} implementation. Usage considerations:\n+ * <ol>\n+ *     <li>state of a channel can be read once per instance of this class; once done it returns\n+ *     {@link org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult#NO_MORE_DATA NO_MORE_DATA}</li>\n+ *     <li>reader/writer indices of the passed buffer are respected and updated</li>\n+ *     <li>buffers must be prepared (cleared) before passing to reader</li>\n+ *     <li>buffers must be released after use</li>\n+ * </ol>\n+ */\n+@NotThreadSafe\n+@Internal\n+public class ChannelStateReaderImpl implements ChannelStateReader {\n+\tprivate static final Logger log = LoggerFactory.getLogger(ChannelStateReaderImpl.class);\n+\n+\tprivate final Map<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReaders;\n+\tprivate final Map<ResultSubpartitionInfo, ChannelStateStreamReader> resultSubpartitionHandleReaders;\n+\n+\tpublic ChannelStateReaderImpl(TaskStateSnapshot snapshot) {\n+\t\tthis(snapshot, new ChannelStateSerializerImpl());\n+\t}\n+\n+\t@SuppressWarnings(\"WeakerAccess\")\n+\tChannelStateReaderImpl(TaskStateSnapshot snapshot, ChannelStateDeserializer serializer) {\n+\t\tRefCountingFSDataInputStreamFactory streamFactory = new RefCountingFSDataInputStreamFactory(serializer);\n+\t\tfinal HashMap<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReadersTmp = new HashMap<>();\n+\t\tfinal HashMap<ResultSubpartitionInfo, ChannelStateStreamReader> resultSubpartitionHandleReadersTmp = new HashMap<>();\n+\t\tfor (Map.Entry<OperatorID, OperatorSubtaskState> e : snapshot.getSubtaskStateMappings()) {\n+\t\t\taddReaders(inputChannelHandleReadersTmp, e.getValue().getInputChannelState(), streamFactory);\n+\t\t\taddReaders(resultSubpartitionHandleReadersTmp, e.getValue().getResultSubpartitionState(), streamFactory);\n+\t\t}\n+\t\tinputChannelHandleReaders = inputChannelHandleReadersTmp;\n+\t\tresultSubpartitionHandleReaders = resultSubpartitionHandleReadersTmp;\n+\t}\n+\n+\tprivate <T> void addReaders(Map<T, ChannelStateStreamReader> readerMap, Collection<? extends AbstractChannelStateHandle<T>> handles, RefCountingFSDataInputStreamFactory streamFactory) {\n+\t\tfor (AbstractChannelStateHandle<T> handle : handles) {\n+\t\t\tcheckState(!readerMap.containsKey(handle.getInfo()), \"multiple states exist for channel: \" + handle.getInfo());\n+\t\t\treaderMap.put(handle.getInfo(), new ChannelStateStreamReader(handle, streamFactory));\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic ReadResult readInputData(InputChannelInfo info, Buffer buffer) throws IOException {\n+\t\tlog.debug(\"readInputData, resultSubpartitionInfo: {} , bufferBuilder {}\", info, buffer);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 89}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MzAyODgw", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386302880", "createdAt": "2020-04-02T10:36:37Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMDozNjozOFrOF_lSkg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMDozNjozOFrOF_lSkg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIxNTU3MA==", "bodyText": "nit: checkNotNull", "url": "https://github.com/apache/flink/pull/11515#discussion_r402215570", "createdAt": "2020-04-02T10:36:38Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateStreamReader.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+\n+import static java.lang.Math.addExact;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateByteBuffer.wrap;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.HAS_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+\n+/**\n+ * Reads the state of a single channel pointed by {@link org.apache.flink.runtime.state.AbstractChannelStateHandle AbstractChannelStateHandle}.\n+ * Single-use.\n+ * Uses {@link RefCountingFSDataInputStream} internally.\n+ */\n+@NotThreadSafe\n+class ChannelStateStreamReader implements Closeable {\n+\n+\tprivate final RefCountingFSDataInputStream stream; // todo: buffer?\n+\tprivate final Queue<Long> offsets;\n+\tprivate final ChannelStateDeserializer serializer;\n+\tprivate long pos = -1;\n+\tprivate int rem;\n+\tprivate boolean closed = false;\n+\n+\tChannelStateStreamReader(AbstractChannelStateHandle<?> handle, RefCountingFSDataInputStreamFactory streamFactory) {\n+\t\tthis(streamFactory.forHandle(handle), handle.getOffsets(), streamFactory.getSerializer());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 57}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MzA0NjMx", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386304631", "createdAt": "2020-04-02T10:39:15Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMDozOToxNlrOF_lYCw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMDozOToxNlrOF_lYCw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIxNjk3MQ==", "bodyText": "Better to give some descriptions for these fields for better understanding, especially for rem.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402216971", "createdAt": "2020-04-02T10:39:16Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateStreamReader.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+\n+import static java.lang.Math.addExact;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateByteBuffer.wrap;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.HAS_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+\n+/**\n+ * Reads the state of a single channel pointed by {@link org.apache.flink.runtime.state.AbstractChannelStateHandle AbstractChannelStateHandle}.\n+ * Single-use.\n+ * Uses {@link RefCountingFSDataInputStream} internally.\n+ */\n+@NotThreadSafe\n+class ChannelStateStreamReader implements Closeable {\n+\n+\tprivate final RefCountingFSDataInputStream stream; // todo: buffer?\n+\tprivate final Queue<Long> offsets;\n+\tprivate final ChannelStateDeserializer serializer;\n+\tprivate long pos = -1;\n+\tprivate int rem;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 53}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MzA2Mzk0", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386306394", "createdAt": "2020-04-02T10:42:03Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMDo0MjowM1rOF_ldOQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMDo0MjowM1rOF_ldOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIxODI5Nw==", "bodyText": "nit: What is it indicating for : Single-use.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402218297", "createdAt": "2020-04-02T10:42:03Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateStreamReader.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+\n+import static java.lang.Math.addExact;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateByteBuffer.wrap;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.HAS_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+\n+/**\n+ * Reads the state of a single channel pointed by {@link org.apache.flink.runtime.state.AbstractChannelStateHandle AbstractChannelStateHandle}.\n+ * Single-use.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 43}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MzA2ODk3", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386306897", "createdAt": "2020-04-02T10:42:46Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMDo0Mjo0NlrOF_letQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMDo0Mjo0NlrOF_letQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIxODY3Nw==", "bodyText": "should be clear for TODO", "url": "https://github.com/apache/flink/pull/11515#discussion_r402218677", "createdAt": "2020-04-02T10:42:46Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateStreamReader.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+\n+import static java.lang.Math.addExact;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateByteBuffer.wrap;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.HAS_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+\n+/**\n+ * Reads the state of a single channel pointed by {@link org.apache.flink.runtime.state.AbstractChannelStateHandle AbstractChannelStateHandle}.\n+ * Single-use.\n+ * Uses {@link RefCountingFSDataInputStream} internally.\n+ */\n+@NotThreadSafe\n+class ChannelStateStreamReader implements Closeable {\n+\n+\tprivate final RefCountingFSDataInputStream stream; // todo: buffer?", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 49}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MzUwNzc2", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386350776", "createdAt": "2020-04-02T11:52:59Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMTo1MzowMFrOF_noWw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMTo1MzowMFrOF_noWw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI1MzkxNQ==", "bodyText": "I guess we can get ride of pos field to only judge rem <= 0 to advance offset. If so we can also avoid return tuple2 in serializer.readLength(stream)", "url": "https://github.com/apache/flink/pull/11515#discussion_r402253915", "createdAt": "2020-04-02T11:53:00Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateStreamReader.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+\n+import static java.lang.Math.addExact;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateByteBuffer.wrap;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.HAS_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+\n+/**\n+ * Reads the state of a single channel pointed by {@link org.apache.flink.runtime.state.AbstractChannelStateHandle AbstractChannelStateHandle}.\n+ * Single-use.\n+ * Uses {@link RefCountingFSDataInputStream} internally.\n+ */\n+@NotThreadSafe\n+class ChannelStateStreamReader implements Closeable {\n+\n+\tprivate final RefCountingFSDataInputStream stream; // todo: buffer?\n+\tprivate final Queue<Long> offsets;\n+\tprivate final ChannelStateDeserializer serializer;\n+\tprivate long pos = -1;\n+\tprivate int rem;\n+\tprivate boolean closed = false;\n+\n+\tChannelStateStreamReader(AbstractChannelStateHandle<?> handle, RefCountingFSDataInputStreamFactory streamFactory) {\n+\t\tthis(streamFactory.forHandle(handle), handle.getOffsets(), streamFactory.getSerializer());\n+\t}\n+\n+\tprivate ChannelStateStreamReader(RefCountingFSDataInputStream stream, List<Long> offsets, ChannelStateDeserializer serializer) {\n+\t\tthis.stream = stream;\n+\t\tthis.stream.incNumReaders();\n+\t\tthis.serializer = serializer;\n+\t\tthis.offsets = new LinkedList<>(offsets);\n+\t}\n+\n+\tReadResult readInto(Buffer buffer) throws IOException {\n+\t\treturn readInto(wrap(buffer));\n+\t}\n+\n+\tReadResult readInto(BufferBuilder bufferBuilder) throws IOException {\n+\t\treturn readInto(wrap(bufferBuilder));\n+\t}\n+\n+\tprivate ReadResult readInto(ChannelStateByteBuffer buffer) throws IOException {\n+\t\tPreconditions.checkState(!closed, \"reader is closed\");\n+\t\treadWhilePossible(buffer);\n+\t\tif (haveMoreData()) {\n+\t\t\treturn HAS_MORE_DATA;\n+\t\t} else {\n+\t\t\tclose();\n+\t\t\treturn NO_MORE_DATA;\n+\t\t}\n+\t}\n+\n+\tprivate void readWhilePossible(ChannelStateByteBuffer buffer) throws IOException {\n+\t\twhile (haveMoreData() && buffer.isWritable()) {\n+\t\t\tif (pos < 0 || rem <= 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 88}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MzU1NzE5", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386355719", "createdAt": "2020-04-02T12:00:16Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjowMDoxN1rOF_n38g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjowMDoxN1rOF_n38g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI1NzkwNg==", "bodyText": "nit: i think it is better to place the factory class at the bottom of this class", "url": "https://github.com/apache/flink/pull/11515#discussion_r402257906", "createdAt": "2020-04-02T12:00:17Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RefCountingFSDataInputStream.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.fs.FSDataInputStream;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.SupplierWithException;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+@NotThreadSafe\n+class RefCountingFSDataInputStream extends FSDataInputStream {\n+\n+\t@NotThreadSafe\n+\tstatic class RefCountingFSDataInputStreamFactory {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 38}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MzU2MDc4", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386356078", "createdAt": "2020-04-02T12:00:49Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjowMDo0OVrOF_n5EQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjowMDo0OVrOF_n5EQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI1ODE5Mw==", "bodyText": "too long line for splitting the arguments", "url": "https://github.com/apache/flink/pull/11515#discussion_r402258193", "createdAt": "2020-04-02T12:00:49Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RefCountingFSDataInputStream.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.fs.FSDataInputStream;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.SupplierWithException;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+@NotThreadSafe\n+class RefCountingFSDataInputStream extends FSDataInputStream {\n+\n+\t@NotThreadSafe\n+\tstatic class RefCountingFSDataInputStreamFactory {\n+\t\tprivate final Map<StreamStateHandle, RefCountingFSDataInputStream> map = new HashMap<>(); // not clearing: expecting short life\n+\t\tprivate final ChannelStateDeserializer serializer;\n+\n+\t\tRefCountingFSDataInputStreamFactory(ChannelStateDeserializer serializer) {\n+\t\t\tthis.serializer = serializer;\n+\t\t}\n+\n+\t\t<T> RefCountingFSDataInputStream forHandle(AbstractChannelStateHandle<T> handle) {\n+\t\t\tStreamStateHandle streamStateHandle = handle.getDelegate();\n+\t\t\tRefCountingFSDataInputStream stream = map.get(streamStateHandle);\n+\t\t\tif (stream == null) {\n+\t\t\t\tstream = new RefCountingFSDataInputStream(streamStateHandle::openInputStream, serializer);\n+\t\t\t\tmap.put(streamStateHandle, stream);\n+\t\t\t}\n+\t\t\treturn stream;\n+\t\t}\n+\n+\t\tChannelStateDeserializer getSerializer() {\n+\t\t\treturn serializer;\n+\t\t}\n+\t}\n+\n+\tprivate enum State {NEW, OPENED, CLOSED}\n+\n+\tprivate final SupplierWithException<FSDataInputStream, IOException> streamSupplier;\n+\tprivate FSDataInputStream stream;\n+\tprivate final ChannelStateDeserializer serializer;\n+\tprivate int numReaders = 0;\n+\tprivate State state = State.NEW;\n+\n+\tprivate RefCountingFSDataInputStream(SupplierWithException<FSDataInputStream, IOException> streamSupplier, ChannelStateDeserializer serializer) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 69}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MzY2MDk5", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386366099", "createdAt": "2020-04-02T12:15:29Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjoxNTozMFrOF_oYKA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjoxNTozMFrOF_oYKA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI2NjE1Mg==", "bodyText": "nit: incRef seems more fit into the class name. also numReaders -> refCounter", "url": "https://github.com/apache/flink/pull/11515#discussion_r402266152", "createdAt": "2020-04-02T12:15:30Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RefCountingFSDataInputStream.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.fs.FSDataInputStream;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.SupplierWithException;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+@NotThreadSafe\n+class RefCountingFSDataInputStream extends FSDataInputStream {\n+\n+\t@NotThreadSafe\n+\tstatic class RefCountingFSDataInputStreamFactory {\n+\t\tprivate final Map<StreamStateHandle, RefCountingFSDataInputStream> map = new HashMap<>(); // not clearing: expecting short life\n+\t\tprivate final ChannelStateDeserializer serializer;\n+\n+\t\tRefCountingFSDataInputStreamFactory(ChannelStateDeserializer serializer) {\n+\t\t\tthis.serializer = serializer;\n+\t\t}\n+\n+\t\t<T> RefCountingFSDataInputStream forHandle(AbstractChannelStateHandle<T> handle) {\n+\t\t\tStreamStateHandle streamStateHandle = handle.getDelegate();\n+\t\t\tRefCountingFSDataInputStream stream = map.get(streamStateHandle);\n+\t\t\tif (stream == null) {\n+\t\t\t\tstream = new RefCountingFSDataInputStream(streamStateHandle::openInputStream, serializer);\n+\t\t\t\tmap.put(streamStateHandle, stream);\n+\t\t\t}\n+\t\t\treturn stream;\n+\t\t}\n+\n+\t\tChannelStateDeserializer getSerializer() {\n+\t\t\treturn serializer;\n+\t\t}\n+\t}\n+\n+\tprivate enum State {NEW, OPENED, CLOSED}\n+\n+\tprivate final SupplierWithException<FSDataInputStream, IOException> streamSupplier;\n+\tprivate FSDataInputStream stream;\n+\tprivate final ChannelStateDeserializer serializer;\n+\tprivate int numReaders = 0;\n+\tprivate State state = State.NEW;\n+\n+\tprivate RefCountingFSDataInputStream(SupplierWithException<FSDataInputStream, IOException> streamSupplier, ChannelStateDeserializer serializer) {\n+\t\tthis.streamSupplier = streamSupplier;\n+\t\tthis.serializer = serializer;\n+\t}\n+\n+\tvoid incNumReaders() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 74}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MzY3MzYz", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386367363", "createdAt": "2020-04-02T12:17:17Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjoxNzoxOFrOF_ob1w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjoxNzoxOFrOF_ob1w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI2NzA5NQ==", "bodyText": "nit: desired -> pos", "url": "https://github.com/apache/flink/pull/11515#discussion_r402267095", "createdAt": "2020-04-02T12:17:18Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RefCountingFSDataInputStream.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.fs.FSDataInputStream;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.SupplierWithException;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+@NotThreadSafe\n+class RefCountingFSDataInputStream extends FSDataInputStream {\n+\n+\t@NotThreadSafe\n+\tstatic class RefCountingFSDataInputStreamFactory {\n+\t\tprivate final Map<StreamStateHandle, RefCountingFSDataInputStream> map = new HashMap<>(); // not clearing: expecting short life\n+\t\tprivate final ChannelStateDeserializer serializer;\n+\n+\t\tRefCountingFSDataInputStreamFactory(ChannelStateDeserializer serializer) {\n+\t\t\tthis.serializer = serializer;\n+\t\t}\n+\n+\t\t<T> RefCountingFSDataInputStream forHandle(AbstractChannelStateHandle<T> handle) {\n+\t\t\tStreamStateHandle streamStateHandle = handle.getDelegate();\n+\t\t\tRefCountingFSDataInputStream stream = map.get(streamStateHandle);\n+\t\t\tif (stream == null) {\n+\t\t\t\tstream = new RefCountingFSDataInputStream(streamStateHandle::openInputStream, serializer);\n+\t\t\t\tmap.put(streamStateHandle, stream);\n+\t\t\t}\n+\t\t\treturn stream;\n+\t\t}\n+\n+\t\tChannelStateDeserializer getSerializer() {\n+\t\t\treturn serializer;\n+\t\t}\n+\t}\n+\n+\tprivate enum State {NEW, OPENED, CLOSED}\n+\n+\tprivate final SupplierWithException<FSDataInputStream, IOException> streamSupplier;\n+\tprivate FSDataInputStream stream;\n+\tprivate final ChannelStateDeserializer serializer;\n+\tprivate int numReaders = 0;\n+\tprivate State state = State.NEW;\n+\n+\tprivate RefCountingFSDataInputStream(SupplierWithException<FSDataInputStream, IOException> streamSupplier, ChannelStateDeserializer serializer) {\n+\t\tthis.streamSupplier = streamSupplier;\n+\t\tthis.serializer = serializer;\n+\t}\n+\n+\tvoid incNumReaders() {\n+\t\tcheckNotClosed();\n+\t\tnumReaders++;\n+\t}\n+\n+\tvoid decNumReaders() throws IOException {\n+\t\tcheckNotClosed();\n+\t\tnumReaders--;\n+\t\tif (numReaders == 0) {\n+\t\t\tclose();\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic int read() throws IOException {\n+\t\tensureOpen();\n+\t\treturn stream.read();\n+\t}\n+\n+\t@Override\n+\tpublic void seek(long desired) throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 94}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MzcwNzgw", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386370780", "createdAt": "2020-04-02T12:21:50Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjoyMTo1MFrOF_omYQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjoyMTo1MFrOF_omYQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI2OTc5Mw==", "bodyText": "map -> streams", "url": "https://github.com/apache/flink/pull/11515#discussion_r402269793", "createdAt": "2020-04-02T12:21:50Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RefCountingFSDataInputStream.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.fs.FSDataInputStream;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.SupplierWithException;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+@NotThreadSafe\n+class RefCountingFSDataInputStream extends FSDataInputStream {\n+\n+\t@NotThreadSafe\n+\tstatic class RefCountingFSDataInputStreamFactory {\n+\t\tprivate final Map<StreamStateHandle, RefCountingFSDataInputStream> map = new HashMap<>(); // not clearing: expecting short life", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 39}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MzcxMzE2", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386371316", "createdAt": "2020-04-02T12:22:29Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjoyMjozMFrOF_ooEQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjoyMjozMFrOF_ooEQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI3MDIyNQ==", "bodyText": "nit: checkNotNull", "url": "https://github.com/apache/flink/pull/11515#discussion_r402270225", "createdAt": "2020-04-02T12:22:30Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RefCountingFSDataInputStream.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.fs.FSDataInputStream;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.SupplierWithException;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+@NotThreadSafe\n+class RefCountingFSDataInputStream extends FSDataInputStream {\n+\n+\t@NotThreadSafe\n+\tstatic class RefCountingFSDataInputStreamFactory {\n+\t\tprivate final Map<StreamStateHandle, RefCountingFSDataInputStream> map = new HashMap<>(); // not clearing: expecting short life\n+\t\tprivate final ChannelStateDeserializer serializer;\n+\n+\t\tRefCountingFSDataInputStreamFactory(ChannelStateDeserializer serializer) {\n+\t\t\tthis.serializer = serializer;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 43}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2Mzc0MDY4", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386374068", "createdAt": "2020-04-02T12:25:53Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjoyNTo1M1rOF_oxPg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjoyNTo1M1rOF_oxPg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI3MjU3NA==", "bodyText": "forHandle->create/buildInputStream", "url": "https://github.com/apache/flink/pull/11515#discussion_r402272574", "createdAt": "2020-04-02T12:25:53Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RefCountingFSDataInputStream.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.fs.FSDataInputStream;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.SupplierWithException;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+@NotThreadSafe\n+class RefCountingFSDataInputStream extends FSDataInputStream {\n+\n+\t@NotThreadSafe\n+\tstatic class RefCountingFSDataInputStreamFactory {\n+\t\tprivate final Map<StreamStateHandle, RefCountingFSDataInputStream> map = new HashMap<>(); // not clearing: expecting short life\n+\t\tprivate final ChannelStateDeserializer serializer;\n+\n+\t\tRefCountingFSDataInputStreamFactory(ChannelStateDeserializer serializer) {\n+\t\t\tthis.serializer = serializer;\n+\t\t}\n+\n+\t\t<T> RefCountingFSDataInputStream forHandle(AbstractChannelStateHandle<T> handle) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 46}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2Mzc3ODk0", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386377894", "createdAt": "2020-04-02T12:30:56Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjozMDo1NlrOF_o88Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjozMDo1NlrOF_o88Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI3NTU2OQ==", "bodyText": "Will one state handle be read multiple times, so we need a map to avoid opening it multiple times?", "url": "https://github.com/apache/flink/pull/11515#discussion_r402275569", "createdAt": "2020-04-02T12:30:56Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RefCountingFSDataInputStream.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.fs.FSDataInputStream;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.SupplierWithException;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+@NotThreadSafe\n+class RefCountingFSDataInputStream extends FSDataInputStream {\n+\n+\t@NotThreadSafe\n+\tstatic class RefCountingFSDataInputStreamFactory {\n+\t\tprivate final Map<StreamStateHandle, RefCountingFSDataInputStream> map = new HashMap<>(); // not clearing: expecting short life\n+\t\tprivate final ChannelStateDeserializer serializer;\n+\n+\t\tRefCountingFSDataInputStreamFactory(ChannelStateDeserializer serializer) {\n+\t\t\tthis.serializer = serializer;\n+\t\t}\n+\n+\t\t<T> RefCountingFSDataInputStream forHandle(AbstractChannelStateHandle<T> handle) {\n+\t\t\tStreamStateHandle streamStateHandle = handle.getDelegate();\n+\t\t\tRefCountingFSDataInputStream stream = map.get(streamStateHandle);\n+\t\t\tif (stream == null) {\n+\t\t\t\tstream = new RefCountingFSDataInputStream(streamStateHandle::openInputStream, serializer);\n+\t\t\t\tmap.put(streamStateHandle, stream);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 51}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2Mzc5MjYz", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386379263", "createdAt": "2020-04-02T12:32:51Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjozMjo1MVrOF_pA9g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjozMjo1MVrOF_pA9g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI3NjU5OA==", "bodyText": "#start misses one argument", "url": "https://github.com/apache/flink/pull/11515#discussion_r402276598", "createdAt": "2020-04-02T12:32:51Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriter.java", "diffHunk": "@@ -46,60 +78,64 @@\n \t/**\n \t * Initiate write of channel state for the given checkpoint id.\n \t */\n-\tvoid start(long checkpointId);\n+\tvoid start(long checkpointId, CheckpointOptions checkpointOptions);\n \n \t/**\n \t * Add in-flight buffers from the {@link org.apache.flink.runtime.io.network.partition.consumer.InputChannel InputChannel}.\n-\t * Must be called after {@link #start(long)} and before {@link #finish(long)}.\n+\t * Must be called after {@link #start} (long)} and before {@link #finishInput(long)}.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 65}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2Mzg1NzIz", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386385723", "createdAt": "2020-04-02T12:41:39Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjo0MTozOVrOF_pVJg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjo0MTozOVrOF_pVJg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI4MTc2Ng==", "bodyText": "we can use the following for simple:\nIOUtils.closeAll(inputChannelHandleReaders.values());\nIOUtils.closeAll(resultSubpartitionHandleReaders.values());", "url": "https://github.com/apache/flink/pull/11515#discussion_r402281766", "createdAt": "2020-04-02T12:41:39Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImpl.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.io.Closer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * {@link ChannelStateReader} implementation. Usage considerations:\n+ * <ol>\n+ *     <li>state of a channel can be read once per instance of this class; once done it returns\n+ *     {@link org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult#NO_MORE_DATA NO_MORE_DATA}</li>\n+ *     <li>reader/writer indices of the passed buffer are respected and updated</li>\n+ *     <li>buffers must be prepared (cleared) before passing to reader</li>\n+ *     <li>buffers must be released after use</li>\n+ * </ol>\n+ */\n+@NotThreadSafe\n+@Internal\n+public class ChannelStateReaderImpl implements ChannelStateReader {\n+\tprivate static final Logger log = LoggerFactory.getLogger(ChannelStateReaderImpl.class);\n+\n+\tprivate final Map<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReaders;\n+\tprivate final Map<ResultSubpartitionInfo, ChannelStateStreamReader> resultSubpartitionHandleReaders;\n+\n+\tpublic ChannelStateReaderImpl(TaskStateSnapshot snapshot) {\n+\t\tthis(snapshot, new ChannelStateSerializerImpl());\n+\t}\n+\n+\t@SuppressWarnings(\"WeakerAccess\")\n+\tChannelStateReaderImpl(TaskStateSnapshot snapshot, ChannelStateDeserializer serializer) {\n+\t\tRefCountingFSDataInputStreamFactory streamFactory = new RefCountingFSDataInputStreamFactory(serializer);\n+\t\tfinal HashMap<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReadersTmp = new HashMap<>();\n+\t\tfinal HashMap<ResultSubpartitionInfo, ChannelStateStreamReader> resultSubpartitionHandleReadersTmp = new HashMap<>();\n+\t\tfor (Map.Entry<OperatorID, OperatorSubtaskState> e : snapshot.getSubtaskStateMappings()) {\n+\t\t\taddReaders(inputChannelHandleReadersTmp, e.getValue().getInputChannelState(), streamFactory);\n+\t\t\taddReaders(resultSubpartitionHandleReadersTmp, e.getValue().getResultSubpartitionState(), streamFactory);\n+\t\t}\n+\t\tinputChannelHandleReaders = inputChannelHandleReadersTmp;\n+\t\tresultSubpartitionHandleReaders = resultSubpartitionHandleReadersTmp;\n+\t}\n+\n+\tprivate <T> void addReaders(Map<T, ChannelStateStreamReader> readerMap, Collection<? extends AbstractChannelStateHandle<T>> handles, RefCountingFSDataInputStreamFactory streamFactory) {\n+\t\tfor (AbstractChannelStateHandle<T> handle : handles) {\n+\t\t\tcheckState(!readerMap.containsKey(handle.getInfo()), \"multiple states exist for channel: \" + handle.getInfo());\n+\t\t\treaderMap.put(handle.getInfo(), new ChannelStateStreamReader(handle, streamFactory));\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic ReadResult readInputData(InputChannelInfo info, Buffer buffer) throws IOException {\n+\t\tlog.debug(\"readInputData, resultSubpartitionInfo: {} , bufferBuilder {}\", info, buffer);\n+\t\treturn getReader(info, inputChannelHandleReaders).readInto(buffer);\n+\t}\n+\n+\t@Override\n+\tpublic ReadResult readOutputData(ResultSubpartitionInfo info, BufferBuilder bufferBuilder) throws IOException {\n+\t\tlog.debug(\"readOutputData, resultSubpartitionInfo: {} , bufferBuilder {}\", info, bufferBuilder);\n+\t\treturn getReader(info, resultSubpartitionHandleReaders).readInto(bufferBuilder);\n+\t}\n+\n+\tprivate <K> ChannelStateStreamReader getReader(K info, Map<K, ChannelStateStreamReader> readerMap) {\n+\t\tPreconditions.checkArgument(readerMap.containsKey(info), String.format(\"unknown channel %s. Known channels: %s\", info, readerMap.keySet()));\n+\t\treturn readerMap.get(info);\n+\t}\n+\n+\t@Override\n+\tpublic void close() throws Exception {\n+\t\ttry (Closer closer = Closer.create()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 106}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2Mzg2Nzc4", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386386778", "createdAt": "2020-04-02T12:43:05Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjo0MzowNVrOF_pYgQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjo0MzowNVrOF_pYgQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI4MjYyNQ==", "bodyText": "ditto: flinkBuffers", "url": "https://github.com/apache/flink/pull/11515#discussion_r402282625", "createdAt": "2020-04-02T12:43:05Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 42}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MzkwOTYw", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386390960", "createdAt": "2020-04-02T12:48:27Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjo0ODoyN1rOF_plCg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxMjo0ODoyN1rOF_plCg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI4NTgzNA==", "bodyText": "nit: final", "url": "https://github.com/apache/flink/pull/11515#discussion_r402285834", "createdAt": "2020-04-02T12:48:27Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\tTuple2<Integer, Integer> readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\tint writableBytes();\n+\n+\tint writeBytes(InputStream input, int bytesToRead) throws IOException;\n+\n+\tstatic ChannelStateByteBuffer wrap(Buffer buffer) {\n+\t\treturn new ChannelStateByteBuffer() {\n+\n+\t\t\tprivate ByteBuf byteBuf = buffer.asByteBuf();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 75}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2NTIzMTg4", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386523188", "createdAt": "2020-04-02T15:09:17Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNTowOToxN1rOF_v7GQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNTowOToxN1rOF_v7GQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjM4OTc4NQ==", "bodyText": "upToBytes -> bytesToRead to be consistent with above ChannelStateByteBuffer wrap(Buffer buffer)", "url": "https://github.com/apache/flink/pull/11515#discussion_r402389785", "createdAt": "2020-04-02T15:09:17Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\tTuple2<Integer, Integer> readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\tint writableBytes();\n+\n+\tint writeBytes(InputStream input, int bytesToRead) throws IOException;\n+\n+\tstatic ChannelStateByteBuffer wrap(Buffer buffer) {\n+\t\treturn new ChannelStateByteBuffer() {\n+\n+\t\t\tprivate ByteBuf byteBuf = buffer.asByteBuf();\n+\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn byteBuf.isWritable();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn byteBuf.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\treturn byteBuf.writeBytes(input, Math.min(bytesToRead, byteBuf.writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(BufferBuilder bufferBuilder) {\n+\t\tfinal byte[] buf = new byte[1024];\n+\t\treturn new ChannelStateByteBuffer() {\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn !bufferBuilder.isFull();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn bufferBuilder.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int upToBytes) throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 108}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2NTM2NTE4", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386536518", "createdAt": "2020-04-02T15:23:36Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNToyMzozNlrOF_wlZg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNToyMzozNlrOF_wlZg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQwMDYxNA==", "bodyText": "Use bufferBuilder.writableBytes() to replace writableBytes() then we can remove this explicit interface method.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402400614", "createdAt": "2020-04-02T15:23:36Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\tTuple2<Integer, Integer> readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\tint writableBytes();\n+\n+\tint writeBytes(InputStream input, int bytesToRead) throws IOException;\n+\n+\tstatic ChannelStateByteBuffer wrap(Buffer buffer) {\n+\t\treturn new ChannelStateByteBuffer() {\n+\n+\t\t\tprivate ByteBuf byteBuf = buffer.asByteBuf();\n+\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn byteBuf.isWritable();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn byteBuf.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\treturn byteBuf.writeBytes(input, Math.min(bytesToRead, byteBuf.writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(BufferBuilder bufferBuilder) {\n+\t\tfinal byte[] buf = new byte[1024];\n+\t\treturn new ChannelStateByteBuffer() {\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn !bufferBuilder.isFull();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn bufferBuilder.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int upToBytes) throws IOException {\n+\t\t\t\tint left = upToBytes;\n+\t\t\t\tfor (int toRead = getToRead(left); toRead > 0; toRead = getToRead(left)) {\n+\t\t\t\t\tint read = input.read(buf, 0, toRead);\n+\t\t\t\t\tint copied = bufferBuilder.append(java.nio.ByteBuffer.wrap(buf, 0, read));\n+\t\t\t\t\tPreconditions.checkState(copied == read);\n+\t\t\t\t\tleft -= read;\n+\t\t\t\t}\n+\t\t\t\tbufferBuilder.commit();\n+\t\t\t\treturn upToBytes - left;\n+\t\t\t}\n+\n+\t\t\tprivate int getToRead(int bytesToRead) {\n+\t\t\t\treturn min(bytesToRead, min(buf.length, writableBytes()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 121}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2NTM3MTA2", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386537106", "createdAt": "2020-04-02T15:24:12Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNToyNDoxMlrOF_wnVw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNToyNDoxMlrOF_wnVw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQwMTExMQ==", "bodyText": "I guess this wrap is never used atm", "url": "https://github.com/apache/flink/pull/11515#discussion_r402401111", "createdAt": "2020-04-02T15:24:12Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\tTuple2<Integer, Integer> readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\tint writableBytes();\n+\n+\tint writeBytes(InputStream input, int bytesToRead) throws IOException;\n+\n+\tstatic ChannelStateByteBuffer wrap(Buffer buffer) {\n+\t\treturn new ChannelStateByteBuffer() {\n+\n+\t\t\tprivate ByteBuf byteBuf = buffer.asByteBuf();\n+\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn byteBuf.isWritable();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn byteBuf.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\treturn byteBuf.writeBytes(input, Math.min(bytesToRead, byteBuf.writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(BufferBuilder bufferBuilder) {\n+\t\tfinal byte[] buf = new byte[1024];\n+\t\treturn new ChannelStateByteBuffer() {\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn !bufferBuilder.isFull();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn bufferBuilder.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int upToBytes) throws IOException {\n+\t\t\t\tint left = upToBytes;\n+\t\t\t\tfor (int toRead = getToRead(left); toRead > 0; toRead = getToRead(left)) {\n+\t\t\t\t\tint read = input.read(buf, 0, toRead);\n+\t\t\t\t\tint copied = bufferBuilder.append(java.nio.ByteBuffer.wrap(buf, 0, read));\n+\t\t\t\t\tPreconditions.checkState(copied == read);\n+\t\t\t\t\tleft -= read;\n+\t\t\t\t}\n+\t\t\t\tbufferBuilder.commit();\n+\t\t\t\treturn upToBytes - left;\n+\t\t\t}\n+\n+\t\t\tprivate int getToRead(int bytesToRead) {\n+\t\t\t\treturn min(bytesToRead, min(buf.length, writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(byte[] bytes) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 126}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2NTM4NjA5", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386538609", "createdAt": "2020-04-02T15:25:45Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNToyNTo0NVrOF_wsUA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNToyNTo0NVrOF_wsUA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQwMjM4NA==", "bodyText": "better to give javadoc for this method, then it is easy to understand the arguments especially for the meaning of the return value.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402402384", "createdAt": "2020-04-02T15:25:45Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\tTuple2<Integer, Integer> readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\tint writableBytes();\n+\n+\tint writeBytes(InputStream input, int bytesToRead) throws IOException;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 70}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2NTQ0Njg5", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386544689", "createdAt": "2020-04-02T15:32:05Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNTozMjowNVrOF_w_Mw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNTozMjowNVrOF_w_Mw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQwNzIxOQ==", "bodyText": "it seems redundant for defining this variable", "url": "https://github.com/apache/flink/pull/11515#discussion_r402407219", "createdAt": "2020-04-02T15:32:05Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\tTuple2<Integer, Integer> readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\tint writableBytes();\n+\n+\tint writeBytes(InputStream input, int bytesToRead) throws IOException;\n+\n+\tstatic ChannelStateByteBuffer wrap(Buffer buffer) {\n+\t\treturn new ChannelStateByteBuffer() {\n+\n+\t\t\tprivate ByteBuf byteBuf = buffer.asByteBuf();\n+\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn byteBuf.isWritable();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn byteBuf.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\treturn byteBuf.writeBytes(input, Math.min(bytesToRead, byteBuf.writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(BufferBuilder bufferBuilder) {\n+\t\tfinal byte[] buf = new byte[1024];\n+\t\treturn new ChannelStateByteBuffer() {\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn !bufferBuilder.isFull();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn bufferBuilder.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int upToBytes) throws IOException {\n+\t\t\t\tint left = upToBytes;\n+\t\t\t\tfor (int toRead = getToRead(left); toRead > 0; toRead = getToRead(left)) {\n+\t\t\t\t\tint read = input.read(buf, 0, toRead);\n+\t\t\t\t\tint copied = bufferBuilder.append(java.nio.ByteBuffer.wrap(buf, 0, read));\n+\t\t\t\t\tPreconditions.checkState(copied == read);\n+\t\t\t\t\tleft -= read;\n+\t\t\t\t}\n+\t\t\t\tbufferBuilder.commit();\n+\t\t\t\treturn upToBytes - left;\n+\t\t\t}\n+\n+\t\t\tprivate int getToRead(int bytesToRead) {\n+\t\t\t\treturn min(bytesToRead, min(buf.length, writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(byte[] bytes) {\n+\t\tint written = 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 127}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2NTQ5MDk3", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386549097", "createdAt": "2020-04-02T15:36:51Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNTozNjo1MVrOF_xMYw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNTozNjo1MVrOF_xMYw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQxMDU5NQ==", "bodyText": "TBH I am concerning of creating the temporary byte array for every buffer level, it might be not friendly for GC. And it also brings additional copy while reading. But i have not thought of a better option now. Maybe at-least to reuse the same buf for every wrap?", "url": "https://github.com/apache/flink/pull/11515#discussion_r402410595", "createdAt": "2020-04-02T15:36:51Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\tTuple2<Integer, Integer> readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\tint writableBytes();\n+\n+\tint writeBytes(InputStream input, int bytesToRead) throws IOException;\n+\n+\tstatic ChannelStateByteBuffer wrap(Buffer buffer) {\n+\t\treturn new ChannelStateByteBuffer() {\n+\n+\t\t\tprivate ByteBuf byteBuf = buffer.asByteBuf();\n+\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn byteBuf.isWritable();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn byteBuf.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\treturn byteBuf.writeBytes(input, Math.min(bytesToRead, byteBuf.writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(BufferBuilder bufferBuilder) {\n+\t\tfinal byte[] buf = new byte[1024];", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 95}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2NTUyNzgy", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386552782", "createdAt": "2020-04-02T15:40:54Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNTo0MDo1NFrOF_xXyQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNTo0MDo1NFrOF_xXyQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQxMzUxMw==", "bodyText": "nit: seems no need to throw this exception explicitly, because the subclass implementation actually does not throw such exception.", "url": "https://github.com/apache/flink/pull/11515#discussion_r402413513", "createdAt": "2020-04-02T15:40:54Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriter.java", "diffHunk": "@@ -46,60 +78,64 @@\n \t/**\n \t * Initiate write of channel state for the given checkpoint id.\n \t */\n-\tvoid start(long checkpointId);\n+\tvoid start(long checkpointId, CheckpointOptions checkpointOptions);\n \n \t/**\n \t * Add in-flight buffers from the {@link org.apache.flink.runtime.io.network.partition.consumer.InputChannel InputChannel}.\n-\t * Must be called after {@link #start(long)} and before {@link #finish(long)}.\n+\t * Must be called after {@link #start} (long)} and before {@link #finishInput(long)}.\n+\t * Buffers are recycled after they are written.\n \t * @param startSeqNum sequence number of the 1st passed buffer.\n \t *                    It is intended to use for incremental snapshots.\n \t *                    If no data is passed it is ignored.\n-\t * @param data zero or more buffers ordered by their sequence numbers\n+\t * @param data zero or more <b>data</b> buffers ordered by their sequence numbers\n+\t * @throws IllegalArgumentException if one or more passed buffers {@link Buffer#isBuffer()  isn't a buffer}\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_RESTORED\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_UNKNOWN\n \t */\n-\tvoid addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data);\n+\tvoid addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data) throws IllegalArgumentException;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 77}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2NTUzMjMz", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386553233", "createdAt": "2020-04-02T15:41:22Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNTo0MToyMlrOF_xZAw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNTo0MToyMlrOF_xZAw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQxMzgyNw==", "bodyText": "ditto: no need to throw explicitly", "url": "https://github.com/apache/flink/pull/11515#discussion_r402413827", "createdAt": "2020-04-02T15:41:22Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriter.java", "diffHunk": "@@ -46,60 +78,64 @@\n \t/**\n \t * Initiate write of channel state for the given checkpoint id.\n \t */\n-\tvoid start(long checkpointId);\n+\tvoid start(long checkpointId, CheckpointOptions checkpointOptions);\n \n \t/**\n \t * Add in-flight buffers from the {@link org.apache.flink.runtime.io.network.partition.consumer.InputChannel InputChannel}.\n-\t * Must be called after {@link #start(long)} and before {@link #finish(long)}.\n+\t * Must be called after {@link #start} (long)} and before {@link #finishInput(long)}.\n+\t * Buffers are recycled after they are written.\n \t * @param startSeqNum sequence number of the 1st passed buffer.\n \t *                    It is intended to use for incremental snapshots.\n \t *                    If no data is passed it is ignored.\n-\t * @param data zero or more buffers ordered by their sequence numbers\n+\t * @param data zero or more <b>data</b> buffers ordered by their sequence numbers\n+\t * @throws IllegalArgumentException if one or more passed buffers {@link Buffer#isBuffer()  isn't a buffer}\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_RESTORED\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_UNKNOWN\n \t */\n-\tvoid addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data);\n+\tvoid addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data) throws IllegalArgumentException;\n \n \t/**\n \t * Add in-flight buffers from the {@link org.apache.flink.runtime.io.network.partition.ResultSubpartition ResultSubpartition}.\n-\t * Must be called after {@link #start(long)} and before {@link #finish(long)}.\n+\t * Must be called after {@link #start} and before {@link #finishOutput(long)}.\n+\t * Buffers are recycled after they are written.\n \t * @param startSeqNum sequence number of the 1st passed buffer.\n \t *                    It is intended to use for incremental snapshots.\n \t *                    If no data is passed it is ignored.\n-\t * @param data zero or more buffers ordered by their sequence numbers\n+\t * @param data zero or more <b>data</b> buffers ordered by their sequence numbers\n+\t * @throws IllegalArgumentException if one or more passed buffers {@link Buffer#isBuffer()  isn't a buffer}\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_RESTORED\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_UNKNOWN\n \t */\n-\tvoid addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data);\n+\tvoid addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data) throws IllegalArgumentException;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 94}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2NTU3MDE0", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386557014", "createdAt": "2020-04-02T15:45:30Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNTo0NTozMFrOF_xkgA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNTo0NTozMFrOF_xkgA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQxNjc2OA==", "bodyText": "#start missing one argument", "url": "https://github.com/apache/flink/pull/11515#discussion_r402416768", "createdAt": "2020-04-02T15:45:30Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriter.java", "diffHunk": "@@ -46,60 +78,64 @@\n \t/**\n \t * Initiate write of channel state for the given checkpoint id.\n \t */\n-\tvoid start(long checkpointId);\n+\tvoid start(long checkpointId, CheckpointOptions checkpointOptions);\n \n \t/**\n \t * Add in-flight buffers from the {@link org.apache.flink.runtime.io.network.partition.consumer.InputChannel InputChannel}.\n-\t * Must be called after {@link #start(long)} and before {@link #finish(long)}.\n+\t * Must be called after {@link #start} (long)} and before {@link #finishInput(long)}.\n+\t * Buffers are recycled after they are written.\n \t * @param startSeqNum sequence number of the 1st passed buffer.\n \t *                    It is intended to use for incremental snapshots.\n \t *                    If no data is passed it is ignored.\n-\t * @param data zero or more buffers ordered by their sequence numbers\n+\t * @param data zero or more <b>data</b> buffers ordered by their sequence numbers\n+\t * @throws IllegalArgumentException if one or more passed buffers {@link Buffer#isBuffer()  isn't a buffer}\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_RESTORED\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_UNKNOWN\n \t */\n-\tvoid addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data);\n+\tvoid addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data) throws IllegalArgumentException;\n \n \t/**\n \t * Add in-flight buffers from the {@link org.apache.flink.runtime.io.network.partition.ResultSubpartition ResultSubpartition}.\n-\t * Must be called after {@link #start(long)} and before {@link #finish(long)}.\n+\t * Must be called after {@link #start} and before {@link #finishOutput(long)}.\n+\t * Buffers are recycled after they are written.\n \t * @param startSeqNum sequence number of the 1st passed buffer.\n \t *                    It is intended to use for incremental snapshots.\n \t *                    If no data is passed it is ignored.\n-\t * @param data zero or more buffers ordered by their sequence numbers\n+\t * @param data zero or more <b>data</b> buffers ordered by their sequence numbers\n+\t * @throws IllegalArgumentException if one or more passed buffers {@link Buffer#isBuffer()  isn't a buffer}\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_RESTORED\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_UNKNOWN\n \t */\n-\tvoid addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data);\n+\tvoid addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data) throws IllegalArgumentException;\n \n \t/**\n \t * Finalize write of channel state data for the given checkpoint id.\n \t * Must be called after {@link #start(long)} and all of the input data of the given checkpoint added.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 98}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2NTU3NzU3", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386557757", "createdAt": "2020-04-02T15:46:16Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNTo0NjoxNlrOF_xmow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNTo0NjoxNlrOF_xmow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQxNzMxNQ==", "bodyText": "remove this method directly?", "url": "https://github.com/apache/flink/pull/11515#discussion_r402417315", "createdAt": "2020-04-02T15:46:16Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriter.java", "diffHunk": "@@ -46,60 +78,64 @@\n \t/**\n \t * Initiate write of channel state for the given checkpoint id.\n \t */\n-\tvoid start(long checkpointId);\n+\tvoid start(long checkpointId, CheckpointOptions checkpointOptions);\n \n \t/**\n \t * Add in-flight buffers from the {@link org.apache.flink.runtime.io.network.partition.consumer.InputChannel InputChannel}.\n-\t * Must be called after {@link #start(long)} and before {@link #finish(long)}.\n+\t * Must be called after {@link #start} (long)} and before {@link #finishInput(long)}.\n+\t * Buffers are recycled after they are written.\n \t * @param startSeqNum sequence number of the 1st passed buffer.\n \t *                    It is intended to use for incremental snapshots.\n \t *                    If no data is passed it is ignored.\n-\t * @param data zero or more buffers ordered by their sequence numbers\n+\t * @param data zero or more <b>data</b> buffers ordered by their sequence numbers\n+\t * @throws IllegalArgumentException if one or more passed buffers {@link Buffer#isBuffer()  isn't a buffer}\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_RESTORED\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_UNKNOWN\n \t */\n-\tvoid addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data);\n+\tvoid addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data) throws IllegalArgumentException;\n \n \t/**\n \t * Add in-flight buffers from the {@link org.apache.flink.runtime.io.network.partition.ResultSubpartition ResultSubpartition}.\n-\t * Must be called after {@link #start(long)} and before {@link #finish(long)}.\n+\t * Must be called after {@link #start} and before {@link #finishOutput(long)}.\n+\t * Buffers are recycled after they are written.\n \t * @param startSeqNum sequence number of the 1st passed buffer.\n \t *                    It is intended to use for incremental snapshots.\n \t *                    If no data is passed it is ignored.\n-\t * @param data zero or more buffers ordered by their sequence numbers\n+\t * @param data zero or more <b>data</b> buffers ordered by their sequence numbers\n+\t * @throws IllegalArgumentException if one or more passed buffers {@link Buffer#isBuffer()  isn't a buffer}\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_RESTORED\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_UNKNOWN\n \t */\n-\tvoid addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data);\n+\tvoid addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data) throws IllegalArgumentException;\n \n \t/**\n \t * Finalize write of channel state data for the given checkpoint id.\n \t * Must be called after {@link #start(long)} and all of the input data of the given checkpoint added.\n \t * When both {@link #finishInput} and {@link #finishOutput} were called the results can be (eventually) obtained\n-\t * using {@link #getWriteCompletionFuture}\n+\t * using {@link #getWriteResult}\n \t */\n \tvoid finishInput(long checkpointId);\n \n \t/**\n \t * Finalize write of channel state data for the given checkpoint id.\n \t * Must be called after {@link #start(long)} and all of the output data of the given checkpoint added.\n \t * When both {@link #finishInput} and {@link #finishOutput} were called the results can be (eventually) obtained\n-\t * using {@link #getWriteCompletionFuture}\n+\t * using {@link #getWriteResult}\n \t */\n \tvoid finishOutput(long checkpointId);\n \n \t/**\n-\t * Must be called after {@link #start(long)}.\n+\t * Must be called after {@link #start}.\n \t */\n-\tFuture<Collection<StateObject>> getWriteCompletionFuture(long checkpointId);\n+\tChannelStateWriteResult getWriteResult(long checkpointId);\n \n \t@Override\n-\tvoid close() throws Exception;\n+\tvoid close();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 123}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2NTY4Mjc3", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386568277", "createdAt": "2020-04-02T15:57:31Z", "commit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNTo1NzozMVrOF_yHQQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNTo1NzozMVrOF_yHQQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQyNTY2NQ==", "bodyText": "nit: getWritableBytes()?", "url": "https://github.com/apache/flink/pull/11515#discussion_r402425665", "createdAt": "2020-04-02T15:57:31Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/buffer/BufferBuilder.java", "diffHunk": "@@ -117,6 +117,11 @@ public boolean isFull() {\n \t\treturn positionMarker.getCached() == getMaxCapacity();\n \t}\n \n+\tpublic int writableBytes() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dad865f157135abd13585f9b560af76cac07b127"}, "originalPosition": 4}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2NTcwNDIz", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-386570423", "createdAt": "2020-04-02T15:59:53Z", "commit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280"}, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/da674cafad1c62dde92588b94b8d44ab699b8280", "committedDate": "2020-03-30T21:35:26Z", "message": "[FLINK-16744][task] send channel state handles to JM\n\n1. add channel state writer to SubtaskCheckpointCoordinator\n2. add handles to the reported snapshot\n3. cache checkpoint locations to prevent multiple streams\nper checkpoint. With unaligned checkpoints, checkpoint\ncan be initiated from several places which can result\n(without cache) in multiple streams/files for a single\ncheckpoint"}, "afterCommit": {"oid": "102a8f1f7c4926781fba187273cd6d324f8d0bd2", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/102a8f1f7c4926781fba187273cd6d324f8d0bd2", "committedDate": "2020-04-06T19:45:32Z", "message": "[FLINK-16744][task][hotfix] refactor SubtaskCheckpointCoordinatorImpl\nMinor refactoring of  SubtaskCheckpointCoordinatorImpl\nto reduce its methods complexity"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg5MTA3NzM2", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-389107736", "createdAt": "2020-04-07T13:20:47Z", "commit": {"oid": "f1798f9618fd405fa87bfcac215fae4d4d30c469"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxMzoyMDo0N1rOGCDM_w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxMzoyMDo0N1rOGCDM_w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDgwMjgxNQ==", "bodyText": "this seems never be used.", "url": "https://github.com/apache/flink/pull/11515#discussion_r404802815", "createdAt": "2020-04-07T13:20:47Z", "author": {"login": "zhijiangW"}, "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/over/BufferDataOverWindowOperatorTest.java", "diffHunk": "@@ -237,4 +241,9 @@ public StreamingRuntimeContext getRuntimeContext() {\n \tprivate void addRow(Object... fields) throws Exception {\n \t\toperator.processElement(new StreamRecord<>(GenericRow.of(fields)));\n \t}\n+\n+\tprivate interface EnvironmentSupport {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1798f9618fd405fa87bfcac215fae4d4d30c469"}, "originalPosition": 49}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg5MTA5NzI4", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-389109728", "createdAt": "2020-04-07T13:22:58Z", "commit": {"oid": "f1798f9618fd405fa87bfcac215fae4d4d30c469"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxMzoyMjo1OFrOGCDS6Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxMzoyMjo1OFrOGCDS6Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDgwNDMyOQ==", "bodyText": "nit: actually this is not used now in all places and we can add it by demands future. If we want to rich the builder now, it is better to place it in front of #build() to make related methods close with each other.", "url": "https://github.com/apache/flink/pull/11515#discussion_r404804329", "createdAt": "2020-04-07T13:22:58Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/test/java/org/apache/flink/runtime/operators/testutils/MockEnvironmentBuilder.java", "diffHunk": "@@ -154,6 +159,12 @@ public MockEnvironment build() {\n \t\t\tsubtaskIndex,\n \t\t\tuserCodeClassLoader,\n \t\t\ttaskMetricGroup,\n-\t\t\ttaskManagerRuntimeInfo);\n+\t\t\ttaskManagerRuntimeInfo,\n+\t\t\tmemoryManager);\n+\t}\n+\n+\tpublic MockEnvironmentBuilder setMemoryManager(MemoryManager memoryManager) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1798f9618fd405fa87bfcac215fae4d4d30c469"}, "originalPosition": 76}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg5MjI0NzA3", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-389224707", "createdAt": "2020-04-07T15:20:24Z", "commit": {"oid": "a233c1fb23c6c3abdb3a3dee745750b191470aa1"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNToyMDoyNVrOGCIzdQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNToyMDoyNVrOGCIzdQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDg5NDU4MQ==", "bodyText": "nit: only missing checkNotNull for the last argument actionExecutor", "url": "https://github.com/apache/flink/pull/11515#discussion_r404894581", "createdAt": "2020-04-07T15:20:25Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -0,0 +1,124 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.tasks;\n+\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.runtime.checkpoint.CheckpointMetaData;\n+import org.apache.flink.runtime.checkpoint.CheckpointMetrics;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.execution.Environment;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.concurrent.ExecutorService;\n+import java.util.function.Supplier;\n+\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+\n+class SubtaskCheckpointCoordinatorImpl implements SubtaskCheckpointCoordinator {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(SubtaskCheckpointCoordinatorImpl.class);\n+\n+\tprivate final CheckpointStorageWorkerView checkpointStorage;\n+\tprivate final String taskName;\n+\tprivate final CloseableRegistry closeableRegistry;\n+\tprivate final ExecutorService executorService;\n+\tprivate final Environment env;\n+\tprivate final AsyncExceptionHandler asyncExceptionHandler;\n+\tprivate final StreamTaskActionExecutor actionExecutor;\n+\n+\tSubtaskCheckpointCoordinatorImpl(\n+\t\t\tCheckpointStorageWorkerView checkpointStorage,\n+\t\t\tString taskName,\n+\t\t\tStreamTaskActionExecutor actionExecutor,\n+\t\t\tCloseableRegistry closeableRegistry,\n+\t\t\tExecutorService executorService,\n+\t\t\tEnvironment env,\n+\t\t\tAsyncExceptionHandler asyncExceptionHandler) {\n+\t\tthis.checkpointStorage = checkNotNull(checkpointStorage);\n+\t\tthis.taskName = checkNotNull(taskName);\n+\t\tthis.closeableRegistry = checkNotNull(closeableRegistry);\n+\t\tthis.executorService = checkNotNull(executorService);\n+\t\tthis.env = checkNotNull(env);\n+\t\tthis.asyncExceptionHandler = checkNotNull(asyncExceptionHandler);\n+\t\tthis.actionExecutor = actionExecutor;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a233c1fb23c6c3abdb3a3dee745750b191470aa1"}, "originalPosition": 61}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg5MjMzNDQ5", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-389233449", "createdAt": "2020-04-07T15:29:22Z", "commit": {"oid": "725b18cbede97464a1fa77f984108e70c337789f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNToyOToyMlrOGCJPcw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNToyOToyMlrOGCJPcw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDkwMTc0Nw==", "bodyText": "From the commit \"[FLINK-16744][task][refactor] inline CheckpointingOperation\", it is unnecessary changes to move the position of this method, if we want to merge this commit separately.", "url": "https://github.com/apache/flink/pull/11515#discussion_r404901747", "createdAt": "2020-04-07T15:29:22Z", "author": {"login": "zhijiangW"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -61,11 +65,6 @@\n \t\tthis.actionExecutor = actionExecutor;\n \t}\n \n-\t@Override", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "725b18cbede97464a1fa77f984108e70c337789f"}, "originalPosition": 21}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg5MjU1OTQ0", "url": "https://github.com/apache/flink/pull/11515#pullrequestreview-389255944", "createdAt": "2020-04-07T15:53:14Z", "commit": {"oid": "ead3567fb7f140353779ab3a4d52e67185485e39"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNTo1MzoxNFrOGCKXdA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNTo1MzoxNFrOGCKXdA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDkyMDE4MA==", "bodyText": "we should also adjust the references of {@link #finish(long)} in above addInputData and addOutput descriptions for the commit \"[FLINK-16744][task] split finish() in ChanStateWrite\"", "url": "https://github.com/apache/flink/pull/11515#discussion_r404920180", "createdAt": "2020-04-07T15:53:14Z", "author": {"login": "zhijiangW"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriter.java", "diffHunk": "@@ -73,10 +73,20 @@\n \tvoid addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data);\n \n \t/**\n-\t * Finalize write of channel state for the given checkpoint id.\n-\t * Must be called after {@link #start(long)} and all of the data of the given checkpoint added.\n+\t * Finalize write of channel state data for the given checkpoint id.\n+\t * Must be called after {@link #start(long)} and all of the input data of the given checkpoint added.\n+\t * When both {@link #finishInput} and {@link #finishOutput} were called the results can be (eventually) obtained\n+\t * using {@link #getWriteCompletionFuture}\n \t */\n-\tvoid finish(long checkpointId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ead3567fb7f140353779ab3a4d52e67185485e39"}, "originalPosition": 11}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2548, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}