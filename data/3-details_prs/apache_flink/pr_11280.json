{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzgyMzQ0MTM0", "number": 11280, "title": "[FLINK-16377][table] Support inline user defined functions in expression dsl", "bodyText": "What is the purpose of the change\nIt adds a method call(UserDefinedFunction function, Object... params) that let users use user defined functions without registering them in a catalog before.\nIt also adds support for the new type inference stack when functions are used from the expression dsl.\nIt is extracted from #11081 . The comments there were applied.\nVerifying this change\nThis change added tests and can be verified as follows:\n\nExtended ExpressionResolverTest\nExtended `FunctionITCase\n\nDoes this pull request potentially affect one of the following parts:\n\nDependencies (does it add or upgrade a dependency): (yes / no)\nThe public API, i.e., is any changed class annotated with @Public(Evolving): (yes / no)\nThe serializers: (yes / no / don't know)\nThe runtime per-record code paths (performance sensitive): (yes / no / don't know)\nAnything that affects deployment or recovery: JobManager (and its components), Checkpointing, Kubernetes/Yarn/Mesos, ZooKeeper: (yes / no / don't know)\nThe S3 file system connector: (yes / no / don't know)\n\nDocumentation\n\nDoes this pull request introduce a new feature? (yes / no)\nIf yes, how is the feature documented? (not applicable / docs / JavaDocs / not documented)", "createdAt": "2020-03-02T11:59:35Z", "url": "https://github.com/apache/flink/pull/11280", "merged": true, "mergeCommit": {"oid": "90a9b3edf299f1f259aa3416893ba0328c8dd9a1"}, "closed": true, "closedAt": "2020-03-25T17:38:46Z", "author": {"login": "dawidwys"}, "timelineItems": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcJsiaugBqjMwODc2NjM4NTk=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcRJW4cABqjMxNjQ1MjgxNzE=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "10d251511e987c85c737c44afdf936006bdaa683", "author": {"user": {"login": "dawidwys", "name": "Dawid Wysakowicz"}}, "url": "https://github.com/apache/flink/commit/10d251511e987c85c737c44afdf936006bdaa683", "committedDate": "2020-03-02T11:56:14Z", "message": "[FLINK-16377][table-api] Enable new type inference for functions called from Table API"}, "afterCommit": {"oid": "f5de98e8347bd4652b3ba5f91cd09281d621a72a", "author": {"user": {"login": "dawidwys", "name": "Dawid Wysakowicz"}}, "url": "https://github.com/apache/flink/commit/f5de98e8347bd4652b3ba5f91cd09281d621a72a", "committedDate": "2020-03-02T12:03:44Z", "message": "[FLINK-16377][table-api] Enable new type inference for functions called from Table API"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f5de98e8347bd4652b3ba5f91cd09281d621a72a", "author": {"user": {"login": "dawidwys", "name": "Dawid Wysakowicz"}}, "url": "https://github.com/apache/flink/commit/f5de98e8347bd4652b3ba5f91cd09281d621a72a", "committedDate": "2020-03-02T12:03:44Z", "message": "[FLINK-16377][table-api] Enable new type inference for functions called from Table API"}, "afterCommit": {"oid": "69161e40e90e997a26f113cb6da10f7815ebbe0f", "author": {"user": {"login": "dawidwys", "name": "Dawid Wysakowicz"}}, "url": "https://github.com/apache/flink/commit/69161e40e90e997a26f113cb6da10f7815ebbe0f", "committedDate": "2020-03-02T15:36:37Z", "message": "[FLINK-16377][table-api] Enable new type inference for functions called from Table API"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgwNDE1ODA4", "url": "https://github.com/apache/flink/pull/11280#pullrequestreview-380415808", "createdAt": "2020-03-24T15:19:54Z", "commit": {"oid": "69161e40e90e997a26f113cb6da10f7815ebbe0f"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 24, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNFQxNToxOTo1NVrOF61XLA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNFQxNjozNDozMlrOF64-MQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzIzNjAxMg==", "bodyText": "very nit: new line between the two sentences", "url": "https://github.com/apache/flink/pull/11280#discussion_r397236012", "createdAt": "2020-03-24T15:19:55Z", "author": {"login": "twalthr"}, "path": "flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/api/Expressions.java", "diffHunk": "@@ -515,6 +516,14 @@ public static ApiExpression call(String path, Object... params) {\n \t\t\tArrays.stream(params).map(ApiExpressionUtils::objectToExpression).toArray(Expression[]::new)));\n \t}\n \n+\t/**\n+\t * A call to an unregistered, inline function. For functions that have been registered before and", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "69161e40e90e997a26f113cb6da10f7815ebbe0f"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzIzODczOQ==", "bodyText": "Something is wrong with this JavaDoc. Can you verify all parenthesis?", "url": "https://github.com/apache/flink/pull/11280#discussion_r397238739", "createdAt": "2020-03-24T15:23:28Z", "author": {"login": "twalthr"}, "path": "flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/expressions/ApiExpressionUtils.java", "diffHunk": "@@ -198,4 +204,48 @@ public static boolean isFunction(Expression expression, BuiltInFunctionDefinitio\n \t\t}\n \t\treturn false;\n \t}\n+\n+\t/**\n+\t * Extracts a {@link FunctionIdentifier} for the given {@link CallExpression}. If the call is an inline funcion\n+\t * ({@link CallExpression#getFunctionIdentifier()} returns empty)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "69161e40e90e997a26f113cb6da10f7815ebbe0f"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI0MjM3Mg==", "bodyText": "This case should not be supported. Either we are dealing with built-ins or user-defined functions.", "url": "https://github.com/apache/flink/pull/11280#discussion_r397242372", "createdAt": "2020-03-24T15:27:57Z", "author": {"login": "twalthr"}, "path": "flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/expressions/ApiExpressionUtils.java", "diffHunk": "@@ -198,4 +204,48 @@ public static boolean isFunction(Expression expression, BuiltInFunctionDefinitio\n \t\t}\n \t\treturn false;\n \t}\n+\n+\t/**\n+\t * Extracts a {@link FunctionIdentifier} for the given {@link CallExpression}. If the call is an inline funcion\n+\t * ({@link CallExpression#getFunctionIdentifier()} returns empty)\n+\t * <ul>\n+\t *     <li>it uses {@link BuiltInFunctionDefinition#getName()} ()} for built in functions</li>\n+\t *     <li>it uses {@link UserDefinedFunction#functionIdentifier()} for user defined functions</li>\n+\t *     <li>it uses {@link FunctionDefinition#toString()} ()} for any other functions</li>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "69161e40e90e997a26f113cb6da10f7815ebbe0f"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI0OTA0Ng==", "bodyText": "should we merge this logic into BuiltInFunctionDefinition?", "url": "https://github.com/apache/flink/pull/11280#discussion_r397249046", "createdAt": "2020-03-24T15:36:22Z", "author": {"login": "twalthr"}, "path": "flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/expressions/ApiExpressionUtils.java", "diffHunk": "@@ -198,4 +204,48 @@ public static boolean isFunction(Expression expression, BuiltInFunctionDefinitio\n \t\t}\n \t\treturn false;\n \t}\n+\n+\t/**\n+\t * Extracts a {@link FunctionIdentifier} for the given {@link CallExpression}. If the call is an inline funcion\n+\t * ({@link CallExpression#getFunctionIdentifier()} returns empty)\n+\t * <ul>\n+\t *     <li>it uses {@link BuiltInFunctionDefinition#getName()} ()} for built in functions</li>\n+\t *     <li>it uses {@link UserDefinedFunction#functionIdentifier()} for user defined functions</li>\n+\t *     <li>it uses {@link FunctionDefinition#toString()} ()} for any other functions</li>\n+\t * </ul>\n+\t */\n+\tpublic static FunctionIdentifier getFunctionIdentifier(CallExpression callExpression) {\n+\t\tif (callExpression.getFunctionIdentifier().isPresent()) {\n+\t\t\treturn callExpression.getFunctionIdentifier().get();\n+\t\t} else {\n+\t\t\treturn getInlineFunctionIdentifier(callExpression);\n+\t\t}\n+\t}\n+\n+\tprivate static FunctionIdentifier getInlineFunctionIdentifier(CallExpression callExpression) {\n+\t\tFunctionDefinition functionDefinition = callExpression.getFunctionDefinition();\n+\t\tif (functionDefinition instanceof BuiltInFunctionDefinition) {\n+\t\t\treturn FunctionIdentifier.of(((BuiltInFunctionDefinition) functionDefinition).getName());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "69161e40e90e997a26f113cb6da10f7815ebbe0f"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI1MDMyNg==", "bodyText": "can we call it \"arguments\" everywhere consistently? also in the call(..., params)", "url": "https://github.com/apache/flink/pull/11280#discussion_r397250326", "createdAt": "2020-03-24T15:38:04Z", "author": {"login": "twalthr"}, "path": "flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/operations/CalculatedQueryOperation.java", "diffHunk": "@@ -33,34 +34,34 @@\n  * Describes a relational operation that was created from applying a {@link TableFunction}.\n  */\n @Internal\n-public class CalculatedQueryOperation<T> implements QueryOperation {\n+public class CalculatedQueryOperation implements QueryOperation {\n \n-\tprivate final TableFunction<T> tableFunction;\n+\tprivate final FunctionDefinition functionDefinition;\n+\tprivate final FunctionIdentifier functionIdentifier;\n \tprivate final List<ResolvedExpression> parameters;\n-\tprivate final TypeInformation<T> resultType;\n \tprivate final TableSchema tableSchema;\n \n \tpublic CalculatedQueryOperation(\n-\t\t\tTableFunction<T> tableFunction,\n+\t\t\tFunctionDefinition functionDefinition,\n+\t\t\tFunctionIdentifier functionIdentifier,\n \t\t\tList<ResolvedExpression> parameters,\n-\t\t\tTypeInformation<T> resultType,\n \t\t\tTableSchema tableSchema) {\n-\t\tthis.tableFunction = tableFunction;\n+\t\tthis.functionDefinition = functionDefinition;\n+\t\tthis.functionIdentifier = functionIdentifier;\n \t\tthis.parameters = parameters;\n-\t\tthis.resultType = resultType;\n \t\tthis.tableSchema = tableSchema;\n \t}\n \n-\tpublic TableFunction<T> getTableFunction() {\n-\t\treturn tableFunction;\n+\tpublic FunctionDefinition getFunctionDefinition() {\n+\t\treturn functionDefinition;\n \t}\n \n-\tpublic List<ResolvedExpression> getParameters() {\n-\t\treturn parameters;\n+\tpublic FunctionIdentifier getFunctionIdentifier() {\n+\t\treturn functionIdentifier;\n \t}\n \n-\tpublic TypeInformation<T> getResultType() {\n-\t\treturn resultType;\n+\tpublic List<ResolvedExpression> getParameters() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "69161e40e90e997a26f113cb6da10f7815ebbe0f"}, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI1MDY4MQ==", "bodyText": "nit: unnecessary", "url": "https://github.com/apache/flink/pull/11280#discussion_r397250681", "createdAt": "2020-03-24T15:38:32Z", "author": {"login": "twalthr"}, "path": "flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/operations/CalculatedQueryOperation.java", "diffHunk": "@@ -86,4 +87,5 @@ public String asSummaryString() {\n \tpublic <U> U accept(QueryOperationVisitor<U> visitor) {\n \t\treturn visitor.visit(this);\n \t}\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "69161e40e90e997a26f113cb6da10f7815ebbe0f"}, "originalPosition": 73}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI1MTYzMA==", "bodyText": "please add a follow-up issue in FLINK-13191", "url": "https://github.com/apache/flink/pull/11280#discussion_r397251630", "createdAt": "2020-03-24T15:39:43Z", "author": {"login": "twalthr"}, "path": "flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/operations/utils/OperationTreeBuilder.java", "diffHunk": "@@ -471,9 +471,14 @@ public QueryOperation flatMap(Expression tableFunction, QueryOperation child) {\n \t\t\tthrow new ValidationException(\"Only a table function can be used in the flatMap operator.\");\n \t\t}\n \n-\t\tTypeInformation<?> resultType = ((TableFunctionDefinition) ((UnresolvedCallExpression) resolvedTableFunction)\n-\t\t\t.getFunctionDefinition())\n-\t\t\t.getResultType();\n+\t\tFunctionDefinition functionDefinition = ((UnresolvedCallExpression) resolvedTableFunction)\n+\t\t\t.getFunctionDefinition();\n+\t\tif (!(functionDefinition instanceof TableFunctionDefinition)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "69161e40e90e997a26f113cb6da10f7815ebbe0f"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI1MzI5Ng==", "bodyText": "just to make sure: we are failing now in the code gen, right?", "url": "https://github.com/apache/flink/pull/11280#discussion_r397253296", "createdAt": "2020-03-24T15:41:49Z", "author": {"login": "twalthr"}, "path": "flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/operations/utils/factories/CalculatedTableFactory.java", "diffHunk": "@@ -59,82 +59,101 @@ public QueryOperation create(ResolvedExpression callExpr, String[] leftTableFiel\n \t\treturn callExpr.accept(calculatedTableCreator);\n \t}\n \n-\tprivate class FunctionTableCallVisitor extends ResolvedExpressionDefaultVisitor<CalculatedQueryOperation<?>> {\n-\n-\t\tprivate String[] leftTableFieldNames;\n+\tprivate static class FunctionTableCallVisitor extends ResolvedExpressionDefaultVisitor<CalculatedQueryOperation> {\n+\t\tprivate List<String> leftTableFieldNames;\n+\t\tprivate static final String ATOMIC_FIELD_NAME = \"f0\";\n \n \t\tpublic FunctionTableCallVisitor(String[] leftTableFieldNames) {\n-\t\t\tthis.leftTableFieldNames = leftTableFieldNames;\n+\t\t\tthis.leftTableFieldNames = Arrays.asList(leftTableFieldNames);\n \t\t}\n \n \t\t@Override\n-\t\tpublic CalculatedQueryOperation<?> visit(CallExpression call) {\n+\t\tpublic CalculatedQueryOperation visit(CallExpression call) {\n \t\t\tFunctionDefinition definition = call.getFunctionDefinition();\n \t\t\tif (definition.equals(AS)) {\n \t\t\t\treturn unwrapFromAlias(call);\n-\t\t\t} else if (definition instanceof TableFunctionDefinition) {\n-\t\t\t\treturn createFunctionCall(\n-\t\t\t\t\t(TableFunctionDefinition) definition,\n-\t\t\t\t\tCollections.emptyList(),\n-\t\t\t\t\tcall.getResolvedChildren());\n-\t\t\t} else {\n-\t\t\t\treturn defaultMethod(call);\n \t\t\t}\n+\n+\t\t\treturn createFunctionCall(call, Collections.emptyList(), call.getResolvedChildren());\n \t\t}\n \n-\t\tprivate CalculatedQueryOperation<?> unwrapFromAlias(CallExpression call) {\n+\t\tprivate CalculatedQueryOperation unwrapFromAlias(CallExpression call) {\n \t\t\tList<Expression> children = call.getChildren();\n \t\t\tList<String> aliases = children.subList(1, children.size())\n \t\t\t\t.stream()\n \t\t\t\t.map(alias -> ExpressionUtils.extractValue(alias, String.class)\n \t\t\t\t\t.orElseThrow(() -> new ValidationException(\"Unexpected alias: \" + alias)))\n \t\t\t\t.collect(toList());\n \n-\t\t\tif (!isFunctionOfKind(children.get(0), TABLE)) {\n+\t\t\tif (!(children.get(0) instanceof CallExpression)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "69161e40e90e997a26f113cb6da10f7815ebbe0f"}, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI1NTk4MA==", "bodyText": "nit: use asSummaryString", "url": "https://github.com/apache/flink/pull/11280#discussion_r397255980", "createdAt": "2020-03-24T15:45:14Z", "author": {"login": "twalthr"}, "path": "flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/operations/utils/factories/CalculatedTableFactory.java", "diffHunk": "@@ -59,82 +59,101 @@ public QueryOperation create(ResolvedExpression callExpr, String[] leftTableFiel\n \t\treturn callExpr.accept(calculatedTableCreator);\n \t}\n \n-\tprivate class FunctionTableCallVisitor extends ResolvedExpressionDefaultVisitor<CalculatedQueryOperation<?>> {\n-\n-\t\tprivate String[] leftTableFieldNames;\n+\tprivate static class FunctionTableCallVisitor extends ResolvedExpressionDefaultVisitor<CalculatedQueryOperation> {\n+\t\tprivate List<String> leftTableFieldNames;\n+\t\tprivate static final String ATOMIC_FIELD_NAME = \"f0\";\n \n \t\tpublic FunctionTableCallVisitor(String[] leftTableFieldNames) {\n-\t\t\tthis.leftTableFieldNames = leftTableFieldNames;\n+\t\t\tthis.leftTableFieldNames = Arrays.asList(leftTableFieldNames);\n \t\t}\n \n \t\t@Override\n-\t\tpublic CalculatedQueryOperation<?> visit(CallExpression call) {\n+\t\tpublic CalculatedQueryOperation visit(CallExpression call) {\n \t\t\tFunctionDefinition definition = call.getFunctionDefinition();\n \t\t\tif (definition.equals(AS)) {\n \t\t\t\treturn unwrapFromAlias(call);\n-\t\t\t} else if (definition instanceof TableFunctionDefinition) {\n-\t\t\t\treturn createFunctionCall(\n-\t\t\t\t\t(TableFunctionDefinition) definition,\n-\t\t\t\t\tCollections.emptyList(),\n-\t\t\t\t\tcall.getResolvedChildren());\n-\t\t\t} else {\n-\t\t\t\treturn defaultMethod(call);\n \t\t\t}\n+\n+\t\t\treturn createFunctionCall(call, Collections.emptyList(), call.getResolvedChildren());\n \t\t}\n \n-\t\tprivate CalculatedQueryOperation<?> unwrapFromAlias(CallExpression call) {\n+\t\tprivate CalculatedQueryOperation unwrapFromAlias(CallExpression call) {\n \t\t\tList<Expression> children = call.getChildren();\n \t\t\tList<String> aliases = children.subList(1, children.size())\n \t\t\t\t.stream()\n \t\t\t\t.map(alias -> ExpressionUtils.extractValue(alias, String.class)\n \t\t\t\t\t.orElseThrow(() -> new ValidationException(\"Unexpected alias: \" + alias)))\n \t\t\t\t.collect(toList());\n \n-\t\t\tif (!isFunctionOfKind(children.get(0), TABLE)) {\n+\t\t\tif (!(children.get(0) instanceof CallExpression)) {\n \t\t\t\tthrow fail();\n \t\t\t}\n \n \t\t\tCallExpression tableCall = (CallExpression) children.get(0);\n-\t\t\tTableFunctionDefinition tableFunctionDefinition =\n-\t\t\t\t(TableFunctionDefinition) tableCall.getFunctionDefinition();\n-\t\t\treturn createFunctionCall(tableFunctionDefinition, aliases, tableCall.getResolvedChildren());\n+\t\t\treturn createFunctionCall(tableCall, aliases, tableCall.getResolvedChildren());\n \t\t}\n \n-\t\tprivate CalculatedQueryOperation<?> createFunctionCall(\n-\t\t\t\tTableFunctionDefinition tableFunctionDefinition,\n+\t\tprivate CalculatedQueryOperation createFunctionCall(\n+\t\t\t\tCallExpression callExpression,\n \t\t\t\tList<String> aliases,\n \t\t\t\tList<ResolvedExpression> parameters) {\n-\t\t\tTypeInformation<?> resultType = tableFunctionDefinition.getResultType();\n \n-\t\t\tint callArity = resultType.getTotalFields();\n-\t\t\tint aliasesSize = aliases.size();\n+\t\t\tFunctionDefinition functionDefinition = callExpression.getFunctionDefinition();\n+\t\t\tFunctionIdentifier functionIdentifier = ApiExpressionUtils.getFunctionIdentifier(callExpression);\n+\t\t\tfinal TableSchema tableSchema = adjustNames(\n+\t\t\t\textractSchema(callExpression.getOutputDataType()),\n+\t\t\t\taliases,\n+\t\t\t\tfunctionIdentifier);\n+\n+\t\t\treturn new CalculatedQueryOperation(\n+\t\t\t\tfunctionDefinition,\n+\t\t\t\tfunctionIdentifier,\n+\t\t\t\tparameters,\n+\t\t\t\ttableSchema);\n+\t\t}\n \n-\t\t\tString[] fieldNames;\n+\t\tprivate TableSchema extractSchema(DataType resultType) {\n+\t\t\tif (LogicalTypeChecks.isCompositeType(resultType.getLogicalType())) {\n+\t\t\t\treturn DataTypeUtils.expandCompositeTypeToSchema(resultType);\n+\t\t\t}\n+\n+\t\t\tint i = 0;\n+\t\t\tString fieldName = ATOMIC_FIELD_NAME;\n+\t\t\twhile (leftTableFieldNames.contains(fieldName)) {\n+\t\t\t\tfieldName = ATOMIC_FIELD_NAME + \"_\" + i++;\n+\t\t\t}\n+\t\t\treturn TableSchema.builder()\n+\t\t\t\t.field(fieldName, resultType)\n+\t\t\t\t.build();\n+\t\t}\n+\n+\t\tprivate TableSchema adjustNames(\n+\t\t\t\tTableSchema tableSchema,\n+\t\t\t\tList<String> aliases,\n+\t\t\t\tFunctionIdentifier identifier) {\n+\t\t\tint aliasesSize = aliases.size();\n \t\t\tif (aliasesSize == 0) {\n-\t\t\t\tfieldNames = FieldInfoUtils.getFieldNames(resultType, Arrays.asList(leftTableFieldNames));\n-\t\t\t} else if (aliasesSize != callArity) {\n+\t\t\t\treturn tableSchema;\n+\t\t\t}\n+\n+\t\t\tint callArity = tableSchema.getFieldCount();\n+\t\t\tif (callArity != aliasesSize) {\n \t\t\t\tthrow new ValidationException(String.format(\n \t\t\t\t\t\"List of column aliases must have same degree as table; \" +\n \t\t\t\t\t\t\"the returned table of function '%s' has \" +\n \t\t\t\t\t\t\"%d columns, whereas alias list has %d columns\",\n-\t\t\t\t\ttableFunctionDefinition.toString(),\n+\t\t\t\t\tidentifier.toString(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "69161e40e90e997a26f113cb6da10f7815ebbe0f"}, "originalPosition": 147}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI1OTE0Mg==", "bodyText": "nit: name it resultDataType", "url": "https://github.com/apache/flink/pull/11280#discussion_r397259142", "createdAt": "2020-03-24T15:49:01Z", "author": {"login": "twalthr"}, "path": "flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/operations/utils/factories/CalculatedTableFactory.java", "diffHunk": "@@ -59,82 +59,101 @@ public QueryOperation create(ResolvedExpression callExpr, String[] leftTableFiel\n \t\treturn callExpr.accept(calculatedTableCreator);\n \t}\n \n-\tprivate class FunctionTableCallVisitor extends ResolvedExpressionDefaultVisitor<CalculatedQueryOperation<?>> {\n-\n-\t\tprivate String[] leftTableFieldNames;\n+\tprivate static class FunctionTableCallVisitor extends ResolvedExpressionDefaultVisitor<CalculatedQueryOperation> {\n+\t\tprivate List<String> leftTableFieldNames;\n+\t\tprivate static final String ATOMIC_FIELD_NAME = \"f0\";\n \n \t\tpublic FunctionTableCallVisitor(String[] leftTableFieldNames) {\n-\t\t\tthis.leftTableFieldNames = leftTableFieldNames;\n+\t\t\tthis.leftTableFieldNames = Arrays.asList(leftTableFieldNames);\n \t\t}\n \n \t\t@Override\n-\t\tpublic CalculatedQueryOperation<?> visit(CallExpression call) {\n+\t\tpublic CalculatedQueryOperation visit(CallExpression call) {\n \t\t\tFunctionDefinition definition = call.getFunctionDefinition();\n \t\t\tif (definition.equals(AS)) {\n \t\t\t\treturn unwrapFromAlias(call);\n-\t\t\t} else if (definition instanceof TableFunctionDefinition) {\n-\t\t\t\treturn createFunctionCall(\n-\t\t\t\t\t(TableFunctionDefinition) definition,\n-\t\t\t\t\tCollections.emptyList(),\n-\t\t\t\t\tcall.getResolvedChildren());\n-\t\t\t} else {\n-\t\t\t\treturn defaultMethod(call);\n \t\t\t}\n+\n+\t\t\treturn createFunctionCall(call, Collections.emptyList(), call.getResolvedChildren());\n \t\t}\n \n-\t\tprivate CalculatedQueryOperation<?> unwrapFromAlias(CallExpression call) {\n+\t\tprivate CalculatedQueryOperation unwrapFromAlias(CallExpression call) {\n \t\t\tList<Expression> children = call.getChildren();\n \t\t\tList<String> aliases = children.subList(1, children.size())\n \t\t\t\t.stream()\n \t\t\t\t.map(alias -> ExpressionUtils.extractValue(alias, String.class)\n \t\t\t\t\t.orElseThrow(() -> new ValidationException(\"Unexpected alias: \" + alias)))\n \t\t\t\t.collect(toList());\n \n-\t\t\tif (!isFunctionOfKind(children.get(0), TABLE)) {\n+\t\t\tif (!(children.get(0) instanceof CallExpression)) {\n \t\t\t\tthrow fail();\n \t\t\t}\n \n \t\t\tCallExpression tableCall = (CallExpression) children.get(0);\n-\t\t\tTableFunctionDefinition tableFunctionDefinition =\n-\t\t\t\t(TableFunctionDefinition) tableCall.getFunctionDefinition();\n-\t\t\treturn createFunctionCall(tableFunctionDefinition, aliases, tableCall.getResolvedChildren());\n+\t\t\treturn createFunctionCall(tableCall, aliases, tableCall.getResolvedChildren());\n \t\t}\n \n-\t\tprivate CalculatedQueryOperation<?> createFunctionCall(\n-\t\t\t\tTableFunctionDefinition tableFunctionDefinition,\n+\t\tprivate CalculatedQueryOperation createFunctionCall(\n+\t\t\t\tCallExpression callExpression,\n \t\t\t\tList<String> aliases,\n \t\t\t\tList<ResolvedExpression> parameters) {\n-\t\t\tTypeInformation<?> resultType = tableFunctionDefinition.getResultType();\n \n-\t\t\tint callArity = resultType.getTotalFields();\n-\t\t\tint aliasesSize = aliases.size();\n+\t\t\tFunctionDefinition functionDefinition = callExpression.getFunctionDefinition();\n+\t\t\tFunctionIdentifier functionIdentifier = ApiExpressionUtils.getFunctionIdentifier(callExpression);\n+\t\t\tfinal TableSchema tableSchema = adjustNames(\n+\t\t\t\textractSchema(callExpression.getOutputDataType()),\n+\t\t\t\taliases,\n+\t\t\t\tfunctionIdentifier);\n+\n+\t\t\treturn new CalculatedQueryOperation(\n+\t\t\t\tfunctionDefinition,\n+\t\t\t\tfunctionIdentifier,\n+\t\t\t\tparameters,\n+\t\t\t\ttableSchema);\n+\t\t}\n \n-\t\t\tString[] fieldNames;\n+\t\tprivate TableSchema extractSchema(DataType resultType) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "69161e40e90e997a26f113cb6da10f7815ebbe0f"}, "originalPosition": 114}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI2NjUyNA==", "bodyText": "nit: a new line for every new Call? like below?", "url": "https://github.com/apache/flink/pull/11280#discussion_r397266524", "createdAt": "2020-03-24T15:58:03Z", "author": {"login": "twalthr"}, "path": "flink-table/flink-table-api-java/src/test/java/org/apache/flink/table/expressions/resolver/ExpressionResolverTest.java", "diffHunk": "@@ -157,20 +161,79 @@\n \t\t\t\t\tDataTypes.BOOLEAN()\n \t\t\t\t)),\n \n-\t\t\tTestSpec.test(\"Lookup system function call\")\n+\t\t\tTestSpec.test(\"Lookup legacy scalar function call\")\n \t\t\t\t.inputSchemas(\n \t\t\t\t\tTableSchema.builder()\n \t\t\t\t\t\t.field(\"f0\", DataTypes.INT())\n \t\t\t\t\t\t.build()\n \t\t\t\t)\n-\t\t\t\t.lookupFunction(\"func\", new ScalarFunctionDefinition(\"func\", new ScalarFunc()))\n+\t\t\t\t.lookupFunction(\"func\", new ScalarFunctionDefinition(\"func\", new LegacyScalarFunc()))\n \t\t\t\t.select(call(\"func\", 1, $(\"f0\")))\n \t\t\t\t.equalTo(new CallExpression(\n \t\t\t\t\tFunctionIdentifier.of(\"func\"),\n-\t\t\t\t\tnew ScalarFunctionDefinition(\"func\", new ScalarFunc()),\n+\t\t\t\t\tnew ScalarFunctionDefinition(\"func\", new LegacyScalarFunc()),\n \t\t\t\t\tArrays.asList(valueLiteral(1), new FieldReferenceExpression(\"f0\", DataTypes.INT(), 0, 0)),\n \t\t\t\t\tDataTypes.INT().bridgedTo(Integer.class)\n-\t\t\t\t)));\n+\t\t\t\t)),\n+\n+\t\t\tTestSpec.test(\"Lookup system function call\")\n+\t\t\t\t.inputSchemas(\n+\t\t\t\t\tTableSchema.builder()\n+\t\t\t\t\t\t.field(\"f0\", DataTypes.INT())\n+\t\t\t\t\t\t.build()\n+\t\t\t\t)\n+\t\t\t\t.lookupFunction(\"func\", new ScalarFunc())\n+\t\t\t\t.select(call(\"func\", 1, $(\"f0\")))\n+\t\t\t\t.equalTo(new CallExpression(\n+\t\t\t\t\tFunctionIdentifier.of(\"func\"),\n+\t\t\t\t\tnew ScalarFunc(),\n+\t\t\t\t\tArrays.asList(valueLiteral(1), new FieldReferenceExpression(\"f0\", DataTypes.INT(), 0, 0)),\n+\t\t\t\t\tDataTypes.INT().notNull().bridgedTo(int.class)\n+\t\t\t\t)),\n+\n+\t\t\tTestSpec.test(\"Lookup catalog function call\")\n+\t\t\t\t.inputSchemas(\n+\t\t\t\t\tTableSchema.builder()\n+\t\t\t\t\t\t.field(\"f0\", DataTypes.INT())\n+\t\t\t\t\t\t.build()\n+\t\t\t\t)\n+\t\t\t\t.lookupFunction(ObjectIdentifier.of(\"cat\", \"db\", \"func\"), new ScalarFunc())\n+\t\t\t\t.select(call(\"cat.db.func\", 1, $(\"f0\")))\n+\t\t\t\t.equalTo(new CallExpression(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "69161e40e90e997a26f113cb6da10f7815ebbe0f"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI2NzczOQ==", "bodyText": "nit: fix formatting", "url": "https://github.com/apache/flink/pull/11280#discussion_r397267739", "createdAt": "2020-03-24T15:59:36Z", "author": {"login": "twalthr"}, "path": "flink-table/flink-table-api-java/src/test/java/org/apache/flink/table/expressions/resolver/ExpressionResolverTest.java", "diffHunk": "@@ -186,13 +249,37 @@ public void testResolvingExpressions() {\n \t}\n \n \t/**\n-\t * Test scalar function that uses legacy type inference logic.\n+\t * Test scalar function.\n \t */\n+\t@FunctionHint(\n+\t\tinput = @DataTypeHint(inputGroup = InputGroup.ANY),\n+\t\tisVarArgs = true,\n+\t\toutput = @DataTypeHint(value = \"INTEGER NOT NULL\",\n+\t\tbridgedTo = int.class))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "69161e40e90e997a26f113cb6da10f7815ebbe0f"}, "originalPosition": 113}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI3MTMxNQ==", "bodyText": "Use org.apache.flink.table.planner.utils.ShortcutUtils for readability.", "url": "https://github.com/apache/flink/pull/11280#discussion_r397271315", "createdAt": "2020-03-24T16:04:04Z", "author": {"login": "twalthr"}, "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/expressions/converter/ExpressionConverter.java", "diffHunk": "@@ -71,18 +72,26 @@\n public class ExpressionConverter implements ExpressionVisitor<RexNode> {\n \n \tprivate static final List<CallExpressionConvertRule> FUNCTION_CONVERT_CHAIN = Arrays.asList(\n-\t\tnew ScalarFunctionConvertRule(),\n+\t\tnew LegacyScalarFunctionConvertRule(),\n+\t\tnew UserDefinedFunctionConvertRule(),\n \t\tnew OverConvertRule(),\n \t\tnew DirectConvertRule(),\n \t\tnew CustomizedConvertRule()\n \t);\n \n \tprivate final RelBuilder relBuilder;\n \tprivate final FlinkTypeFactory typeFactory;\n+\tprivate final DataTypeFactory dataTypeFactory;\n \n \tpublic ExpressionConverter(RelBuilder relBuilder) {\n \t\tthis.relBuilder = relBuilder;\n \t\tthis.typeFactory = (FlinkTypeFactory) relBuilder.getRexBuilder().getTypeFactory();\n+\t\tthis.dataTypeFactory = relBuilder.getCluster()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "69161e40e90e997a26f113cb6da10f7815ebbe0f"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI3MzExMg==", "bodyText": "Is it necessary to limit this code to UserDefinedFunctions?", "url": "https://github.com/apache/flink/pull/11280#discussion_r397273112", "createdAt": "2020-03-24T16:06:28Z", "author": {"login": "twalthr"}, "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/expressions/converter/UserDefinedFunctionConvertRule.java", "diffHunk": "@@ -0,0 +1,63 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.expressions.converter;\n+\n+import org.apache.flink.table.expressions.ApiExpressionUtils;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.functions.UserDefinedFunction;\n+import org.apache.flink.table.planner.functions.bridging.BridgingSqlFunction;\n+\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.sql.SqlKind;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * A call expression converter rule that converts calls to user defined functions.\n+ */\n+public class UserDefinedFunctionConvertRule implements CallExpressionConvertRule {\n+\t@Override\n+\tpublic Optional<RexNode> convert(\n+\t\t\tCallExpression call,\n+\t\t\tConvertContext context) {\n+\t\tif (!(call.getFunctionDefinition() instanceof UserDefinedFunction)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "69161e40e90e997a26f113cb6da10f7815ebbe0f"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI3NDA4MQ==", "bodyText": "This can throw errors. We should wrap the exception again like in FunctionCatalogOperatorTable.", "url": "https://github.com/apache/flink/pull/11280#discussion_r397274081", "createdAt": "2020-03-24T16:07:46Z", "author": {"login": "twalthr"}, "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/expressions/converter/UserDefinedFunctionConvertRule.java", "diffHunk": "@@ -0,0 +1,63 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.expressions.converter;\n+\n+import org.apache.flink.table.expressions.ApiExpressionUtils;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.functions.UserDefinedFunction;\n+import org.apache.flink.table.planner.functions.bridging.BridgingSqlFunction;\n+\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.sql.SqlKind;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * A call expression converter rule that converts calls to user defined functions.\n+ */\n+public class UserDefinedFunctionConvertRule implements CallExpressionConvertRule {\n+\t@Override\n+\tpublic Optional<RexNode> convert(\n+\t\t\tCallExpression call,\n+\t\t\tConvertContext context) {\n+\t\tif (!(call.getFunctionDefinition() instanceof UserDefinedFunction)) {\n+\t\t\treturn Optional.empty();\n+\t\t}\n+\n+\t\tswitch (call.getFunctionDefinition().getKind()) {\n+\t\t\tcase SCALAR:\n+\t\t\tcase TABLE:\n+\t\t\t\tList<RexNode> args = call.getChildren().stream().map(context::toRexNode).collect(Collectors.toList());\n+\t\t\t\treturn Optional.of(context.getRelBuilder().call(\n+\t\t\t\t\tBridgingSqlFunction.of(\n+\t\t\t\t\t\tcontext.getDataTypeFactory(),\n+\t\t\t\t\t\tcontext.getTypeFactory(),\n+\t\t\t\t\t\tSqlKind.OTHER_FUNCTION,\n+\t\t\t\t\t\tApiExpressionUtils.getFunctionIdentifier(call),\n+\t\t\t\t\t\tcall.getFunctionDefinition(),\n+\t\t\t\t\t\tcall.getFunctionDefinition().getTypeInference(context.getDataTypeFactory())),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "69161e40e90e997a26f113cb6da10f7815ebbe0f"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI3NjI1MQ==", "bodyText": "It seems wrong to me that we are using ApiUtils in the planner. This should be done earlier when constructing the call.", "url": "https://github.com/apache/flink/pull/11280#discussion_r397276251", "createdAt": "2020-03-24T16:10:24Z", "author": {"login": "twalthr"}, "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/expressions/converter/UserDefinedFunctionConvertRule.java", "diffHunk": "@@ -0,0 +1,63 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.expressions.converter;\n+\n+import org.apache.flink.table.expressions.ApiExpressionUtils;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.functions.UserDefinedFunction;\n+import org.apache.flink.table.planner.functions.bridging.BridgingSqlFunction;\n+\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.sql.SqlKind;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * A call expression converter rule that converts calls to user defined functions.\n+ */\n+public class UserDefinedFunctionConvertRule implements CallExpressionConvertRule {\n+\t@Override\n+\tpublic Optional<RexNode> convert(\n+\t\t\tCallExpression call,\n+\t\t\tConvertContext context) {\n+\t\tif (!(call.getFunctionDefinition() instanceof UserDefinedFunction)) {\n+\t\t\treturn Optional.empty();\n+\t\t}\n+\n+\t\tswitch (call.getFunctionDefinition().getKind()) {\n+\t\t\tcase SCALAR:\n+\t\t\tcase TABLE:\n+\t\t\t\tList<RexNode> args = call.getChildren().stream().map(context::toRexNode).collect(Collectors.toList());\n+\t\t\t\treturn Optional.of(context.getRelBuilder().call(\n+\t\t\t\t\tBridgingSqlFunction.of(\n+\t\t\t\t\t\tcontext.getDataTypeFactory(),\n+\t\t\t\t\t\tcontext.getTypeFactory(),\n+\t\t\t\t\t\tSqlKind.OTHER_FUNCTION,\n+\t\t\t\t\t\tApiExpressionUtils.getFunctionIdentifier(call),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "69161e40e90e997a26f113cb6da10f7815ebbe0f"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI3NjkzNA==", "bodyText": "Or can this be a FunctionDefinitionConvertRule?", "url": "https://github.com/apache/flink/pull/11280#discussion_r397276934", "createdAt": "2020-03-24T16:11:17Z", "author": {"login": "twalthr"}, "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/expressions/converter/UserDefinedFunctionConvertRule.java", "diffHunk": "@@ -0,0 +1,63 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.expressions.converter;\n+\n+import org.apache.flink.table.expressions.ApiExpressionUtils;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.functions.UserDefinedFunction;\n+import org.apache.flink.table.planner.functions.bridging.BridgingSqlFunction;\n+\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.sql.SqlKind;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * A call expression converter rule that converts calls to user defined functions.\n+ */\n+public class UserDefinedFunctionConvertRule implements CallExpressionConvertRule {\n+\t@Override\n+\tpublic Optional<RexNode> convert(\n+\t\t\tCallExpression call,\n+\t\t\tConvertContext context) {\n+\t\tif (!(call.getFunctionDefinition() instanceof UserDefinedFunction)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI3MzExMg=="}, "originalCommit": {"oid": "69161e40e90e997a26f113cb6da10f7815ebbe0f"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI3ODg3Ng==", "bodyText": "Same comment as in UserDefinedFunctionConverterRule. I think we should get the inference earlier in the API. Otherwise a wrong implemented UDF fails quite late.", "url": "https://github.com/apache/flink/pull/11280#discussion_r397278876", "createdAt": "2020-03-24T16:13:45Z", "author": {"login": "twalthr"}, "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/QueryOperationConverter.java", "diffHunk": "@@ -270,36 +273,69 @@ public RelNode visit(SortQueryOperation sort) {\n \t\t}\n \n \t\t@Override\n-\t\tpublic <U> RelNode visit(CalculatedQueryOperation<U> calculatedTable) {\n-\t\t\tDataType resultType = fromLegacyInfoToDataType(calculatedTable.getResultType());\n-\t\t\tTableFunction<?> tableFunction = calculatedTable.getTableFunction();\n-\t\t\tString[] fieldNames = calculatedTable.getTableSchema().getFieldNames();\n-\n-\t\t\tTypedFlinkTableFunction function = new TypedFlinkTableFunction(\n-\t\t\t\t\ttableFunction, fieldNames, resultType);\n-\n+\t\tpublic RelNode visit(CalculatedQueryOperation calculatedTable) {\n+\t\t\tFunctionDefinition functionDefinition = calculatedTable.getFunctionDefinition();\n+\t\t\tList<RexNode> parameters = convertToRexNodes(calculatedTable.getParameters());\n \t\t\tFlinkTypeFactory typeFactory = relBuilder.getTypeFactory();\n+\t\t\tif (functionDefinition instanceof TableFunctionDefinition) {\n+\t\t\t\treturn convertLegacyTableFunction(\n+\t\t\t\t\tcalculatedTable,\n+\t\t\t\t\t(TableFunctionDefinition) functionDefinition,\n+\t\t\t\t\tparameters,\n+\t\t\t\t\ttypeFactory);\n+\t\t\t}\n \n-\t\t\tTableSqlFunction sqlFunction = new TableSqlFunction(\n-\t\t\t\t\tFunctionIdentifier.of(tableFunction.functionIdentifier()),\n-\t\t\t\t\ttableFunction.toString(),\n-\t\t\t\t\ttableFunction,\n-\t\t\t\t\tresultType,\n+\t\t\tDataTypeFactory dataTypeFactory = relBuilder.getCluster()\n+\t\t\t\t.getPlanner()\n+\t\t\t\t.getContext()\n+\t\t\t\t.unwrap(FlinkContext.class)\n+\t\t\t\t.getCatalogManager()\n+\t\t\t\t.getDataTypeFactory();\n+\t\t\treturn relBuilder.functionScan(\n+\t\t\t\tBridgingSqlFunction.of(\n+\t\t\t\t\tdataTypeFactory,\n \t\t\t\t\ttypeFactory,\n-\t\t\t\t\tfunction,\n-\t\t\t\t\tscala.Option.empty());\n+\t\t\t\t\tSqlKind.OTHER_FUNCTION,\n+\t\t\t\t\tcalculatedTable.getFunctionIdentifier(),\n+\t\t\t\t\tcalculatedTable.getFunctionDefinition(),\n+\t\t\t\t\tcalculatedTable.getFunctionDefinition().getTypeInference(dataTypeFactory)),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "69161e40e90e997a26f113cb6da10f7815ebbe0f"}, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI4MDgzNA==", "bodyText": "nit: whitespace\ncould be moved into a hotfix commit and merged immediately", "url": "https://github.com/apache/flink/pull/11280#discussion_r397280834", "createdAt": "2020-03-24T16:16:15Z", "author": {"login": "twalthr"}, "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/codegen/CorrelateCodeGenerator.scala", "diffHunk": "@@ -65,9 +68,11 @@ object CorrelateCodeGenerator {\n \n     // according to the SQL standard, every scalar function should also be a table function\n     // but we don't allow that for now\n-    if (!rexCall.getOperator.isInstanceOf[BridgingSqlFunction] &&\n-        !rexCall.getOperator.isInstanceOf[TableSqlFunction]) {\n-      throw new ValidationException(\"Currently, only table functions can emit rows.\")\n+    rexCall.getOperator match {\n+      case func: BridgingSqlFunction if func.getDefinition.getKind == FunctionKind.TABLE => //ok", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "69161e40e90e997a26f113cb6da10f7815ebbe0f"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI4MTU4OQ==", "bodyText": "nit: fix indention", "url": "https://github.com/apache/flink/pull/11280#discussion_r397281589", "createdAt": "2020-03-24T16:17:13Z", "author": {"login": "twalthr"}, "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/expressions/PlannerExpressionConverter.scala", "diffHunk": "@@ -37,16 +37,29 @@ import _root_.scala.collection.JavaConverters._\n class PlannerExpressionConverter private extends ApiExpressionVisitor[PlannerExpression] {\n \n   override def visit(call: CallExpression): PlannerExpression = {\n-    translateCall(call.getFunctionDefinition, call.getChildren.asScala)\n+    val definition = call.getFunctionDefinition\n+    translateCall(\n+      definition, call.getChildren.asScala,\n+      () => if (definition.getKind == FunctionKind.AGGREGATE ||\n+        definition.getKind == FunctionKind.TABLE_AGGREGATE) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "69161e40e90e997a26f113cb6da10f7815ebbe0f"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI5MDY2OQ==", "bodyText": "remove comment", "url": "https://github.com/apache/flink/pull/11280#discussion_r397290669", "createdAt": "2020-03-24T16:28:36Z", "author": {"login": "twalthr"}, "path": "flink-table/flink-table-planner/src/test/java/org/apache/flink/table/runtime/stream/sql/FunctionITCase.java", "diffHunk": "@@ -444,6 +450,31 @@ private void testUserDefinedCatalogFunction(TableEnvironment tableEnv, String cr\n \t\ttableEnv.sqlUpdate(\"drop table t2\");\n \t}\n \n+\t@Test\n+\tpublic void testDataTypeBasedTypeInferenceNotSupported() throws Exception {\n+\t\tthrown.expect(ValidationException.class);\n+\t\tthrown.expectMessage(\"The new type inference for functions is only supported in the Blink planner.\");\n+\n+\t\tStreamExecutionEnvironment streamExecEnvironment = StreamExecutionEnvironment.getExecutionEnvironment();\n+\t\tStreamTableEnvironment tableEnvironment = StreamTableEnvironment.create(streamExecEnvironment);\n+\n+\t\ttableEnvironment.createTemporarySystemFunction(\"func\", SimpleScalarFunction.class);\n+\t\tTable table = tableEnvironment\n+\t\t\t.sqlQuery(\"SELECT func(1)\");\n+\t\ttableEnvironment.toAppendStream(table, Row.class).print();\n+\n+\t\tstreamExecEnvironment.execute();\n+\t}\n+\n+\t/**", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "69161e40e90e997a26f113cb6da10f7815ebbe0f"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI5MTgwNA==", "bodyText": "remove comment", "url": "https://github.com/apache/flink/pull/11280#discussion_r397291804", "createdAt": "2020-03-24T16:30:05Z", "author": {"login": "twalthr"}, "path": "flink-table/flink-table-planner/src/test/java/org/apache/flink/table/runtime/stream/table/FunctionITCase.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.stream.table;\n+\n+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\n+import org.apache.flink.table.annotation.DataTypeHint;\n+import org.apache.flink.table.annotation.FunctionHint;\n+import org.apache.flink.table.api.Table;\n+import org.apache.flink.table.api.ValidationException;\n+import org.apache.flink.table.api.java.StreamTableEnvironment;\n+import org.apache.flink.table.functions.ScalarFunction;\n+import org.apache.flink.table.functions.TableFunction;\n+import org.apache.flink.test.util.AbstractTestBase;\n+import org.apache.flink.types.Row;\n+\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.ExpectedException;\n+\n+import static org.apache.flink.table.api.Expressions.$;\n+import static org.apache.flink.table.api.Expressions.call;\n+\n+/**\n+ * Tests for user defined functions in the Table API.\n+ */\n+public class FunctionITCase extends AbstractTestBase {\n+\n+\t@Rule\n+\tpublic ExpectedException thrown = ExpectedException.none();\n+\n+\t@Test\n+\tpublic void testDataTypeBasedTypeInferenceNotSupported() throws Exception {\n+\t\tthrown.expect(ValidationException.class);\n+\t\tthrown.expectMessage(\"The new type inference for functions is only supported in the Blink planner.\");\n+\n+\t\tStreamExecutionEnvironment streamExecEnvironment = StreamExecutionEnvironment.getExecutionEnvironment();\n+\t\tStreamTableEnvironment tableEnvironment = StreamTableEnvironment.create(streamExecEnvironment);\n+\n+\t\tTable table = tableEnvironment\n+\t\t\t.sqlQuery(\"SELECT * FROM (VALUES (1)) AS TableName(f0)\")\n+\t\t\t.select(call(new SimpleScalarFunction(), $(\"f0\")));\n+\t\ttableEnvironment.toAppendStream(table, Row.class).print();\n+\n+\t\tstreamExecEnvironment.execute();\n+\t}\n+\n+\t@Test\n+\tpublic void testDataTypeBasedTypeInferenceNotSupportedInLateralJoin() throws Exception {\n+\t\tthrown.expect(ValidationException.class);\n+\t\tthrown.expectMessage(\"The new type inference for functions is only supported in the Blink planner.\");\n+\n+\t\tStreamExecutionEnvironment streamExecEnvironment = StreamExecutionEnvironment.getExecutionEnvironment();\n+\t\tStreamTableEnvironment tableEnvironment = StreamTableEnvironment.create(streamExecEnvironment);\n+\n+\t\tTable table = tableEnvironment\n+\t\t\t.sqlQuery(\"SELECT * FROM (VALUES ('A,B,C')) AS TableName(f0)\")\n+\t\t\t.joinLateral(call(new SimpleTableFunction(), $(\"f0\")).as(\"a\", \"b\"))\n+\t\t\t.select($(\"a\"), $(\"b\"));\n+\t\ttableEnvironment.toAppendStream(table, Row.class).print();\n+\n+\t\tstreamExecEnvironment.execute();\n+\t}\n+\n+\t/**", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "69161e40e90e997a26f113cb6da10f7815ebbe0f"}, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI5NDAzNg==", "bodyText": "remove comment and simplify code?", "url": "https://github.com/apache/flink/pull/11280#discussion_r397294036", "createdAt": "2020-03-24T16:33:02Z", "author": {"login": "twalthr"}, "path": "flink-table/flink-table-planner/src/test/java/org/apache/flink/table/runtime/stream/table/FunctionITCase.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.stream.table;\n+\n+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\n+import org.apache.flink.table.annotation.DataTypeHint;\n+import org.apache.flink.table.annotation.FunctionHint;\n+import org.apache.flink.table.api.Table;\n+import org.apache.flink.table.api.ValidationException;\n+import org.apache.flink.table.api.java.StreamTableEnvironment;\n+import org.apache.flink.table.functions.ScalarFunction;\n+import org.apache.flink.table.functions.TableFunction;\n+import org.apache.flink.test.util.AbstractTestBase;\n+import org.apache.flink.types.Row;\n+\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.ExpectedException;\n+\n+import static org.apache.flink.table.api.Expressions.$;\n+import static org.apache.flink.table.api.Expressions.call;\n+\n+/**\n+ * Tests for user defined functions in the Table API.\n+ */\n+public class FunctionITCase extends AbstractTestBase {\n+\n+\t@Rule\n+\tpublic ExpectedException thrown = ExpectedException.none();\n+\n+\t@Test\n+\tpublic void testDataTypeBasedTypeInferenceNotSupported() throws Exception {\n+\t\tthrown.expect(ValidationException.class);\n+\t\tthrown.expectMessage(\"The new type inference for functions is only supported in the Blink planner.\");\n+\n+\t\tStreamExecutionEnvironment streamExecEnvironment = StreamExecutionEnvironment.getExecutionEnvironment();\n+\t\tStreamTableEnvironment tableEnvironment = StreamTableEnvironment.create(streamExecEnvironment);\n+\n+\t\tTable table = tableEnvironment\n+\t\t\t.sqlQuery(\"SELECT * FROM (VALUES (1)) AS TableName(f0)\")\n+\t\t\t.select(call(new SimpleScalarFunction(), $(\"f0\")));\n+\t\ttableEnvironment.toAppendStream(table, Row.class).print();\n+\n+\t\tstreamExecEnvironment.execute();\n+\t}\n+\n+\t@Test\n+\tpublic void testDataTypeBasedTypeInferenceNotSupportedInLateralJoin() throws Exception {\n+\t\tthrown.expect(ValidationException.class);\n+\t\tthrown.expectMessage(\"The new type inference for functions is only supported in the Blink planner.\");\n+\n+\t\tStreamExecutionEnvironment streamExecEnvironment = StreamExecutionEnvironment.getExecutionEnvironment();\n+\t\tStreamTableEnvironment tableEnvironment = StreamTableEnvironment.create(streamExecEnvironment);\n+\n+\t\tTable table = tableEnvironment\n+\t\t\t.sqlQuery(\"SELECT * FROM (VALUES ('A,B,C')) AS TableName(f0)\")\n+\t\t\t.joinLateral(call(new SimpleTableFunction(), $(\"f0\")).as(\"a\", \"b\"))\n+\t\t\t.select($(\"a\"), $(\"b\"));\n+\t\ttableEnvironment.toAppendStream(table, Row.class).print();\n+\n+\t\tstreamExecEnvironment.execute();\n+\t}\n+\n+\t/**\n+\t * Scalar function that uses new type inference stack.\n+\t */\n+\tpublic static class SimpleScalarFunction extends ScalarFunction {\n+\t\tpublic long eval(Integer i) {\n+\t\t\treturn i;\n+\t\t}\n+\t}\n+\n+\t/**", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "69161e40e90e997a26f113cb6da10f7815ebbe0f"}, "originalPosition": 89}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI5NTE1Mw==", "bodyText": "Why is this not thrown anymore?", "url": "https://github.com/apache/flink/pull/11280#discussion_r397295153", "createdAt": "2020-03-24T16:34:32Z", "author": {"login": "twalthr"}, "path": "flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/plan/stream/table/validation/CorrelateValidationTest.scala", "diffHunk": "@@ -68,10 +68,6 @@ class CorrelateValidationTest extends TableTestBase {\n     //========= throw exception when the called function is a scalar function ====\n     util.addFunction(\"func0\", Func0)\n \n-    // Java Table API call\n-    expectExceptionThrown(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "69161e40e90e997a26f113cb6da10f7815ebbe0f"}, "originalPosition": 5}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "69161e40e90e997a26f113cb6da10f7815ebbe0f", "author": {"user": {"login": "dawidwys", "name": "Dawid Wysakowicz"}}, "url": "https://github.com/apache/flink/commit/69161e40e90e997a26f113cb6da10f7815ebbe0f", "committedDate": "2020-03-02T15:36:37Z", "message": "[FLINK-16377][table-api] Enable new type inference for functions called from Table API"}, "afterCommit": {"oid": "ea837d9968d89fd583a3aa5841b16908be1294b6", "author": {"user": {"login": "dawidwys", "name": "Dawid Wysakowicz"}}, "url": "https://github.com/apache/flink/commit/ea837d9968d89fd583a3aa5841b16908be1294b6", "committedDate": "2020-03-25T11:00:06Z", "message": "first comments applied"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ea837d9968d89fd583a3aa5841b16908be1294b6", "author": {"user": {"login": "dawidwys", "name": "Dawid Wysakowicz"}}, "url": "https://github.com/apache/flink/commit/ea837d9968d89fd583a3aa5841b16908be1294b6", "committedDate": "2020-03-25T11:00:06Z", "message": "first comments applied"}, "afterCommit": {"oid": "e4011cdc261980e822a90d1d6c1649243a924e40", "author": {"user": {"login": "dawidwys", "name": "Dawid Wysakowicz"}}, "url": "https://github.com/apache/flink/commit/e4011cdc261980e822a90d1d6c1649243a924e40", "committedDate": "2020-03-25T14:01:58Z", "message": "comments applied"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgxMjAxNzUy", "url": "https://github.com/apache/flink/pull/11280#pullrequestreview-381201752", "createdAt": "2020-03-25T14:29:08Z", "commit": {"oid": "e4011cdc261980e822a90d1d6c1649243a924e40"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQxNDozMDoyNFrOF7d1og==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQxNDozMDoyNFrOF7d1og==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzg5OTE3MA==", "bodyText": "can we integrate the case distinction in the methods createName(), createSqlIdentifier(), createSqlFunctionCategory() directly? First of all, I'm not big fan of inline if/else and more importantly, we need the same logic for BridgingSqlAggFunction which is why the BridgingUtils class exists.", "url": "https://github.com/apache/flink/pull/11280#discussion_r397899170", "createdAt": "2020-03-25T14:30:24Z", "author": {"login": "twalthr"}, "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/functions/bridging/BridgingSqlFunction.java", "diffHunk": "@@ -110,9 +114,11 @@ public static BridgingSqlFunction of(\n \t\t\tdataTypeFactory,\n \t\t\ttypeFactory,\n \t\t\tkind,\n-\t\t\tidentifier,\n+\t\t\tidentifier != null ? createName(identifier) : createInlineFunctionName(definition),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4011cdc261980e822a90d1d6c1649243a924e40"}, "originalPosition": 69}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d7e6b399fb16963d5f4e69fda745aae4fcef3cb6", "author": {"user": {"login": "dawidwys", "name": "Dawid Wysakowicz"}}, "url": "https://github.com/apache/flink/commit/d7e6b399fb16963d5f4e69fda745aae4fcef3cb6", "committedDate": "2020-03-25T14:47:53Z", "message": "Unified function identifier handling for both BridgingSqlFunction and BridgingSqlAggFunction"}, "afterCommit": {"oid": "e0df6ea361347a181a72a3f5d553860fdaaf6bc0", "author": {"user": {"login": "dawidwys", "name": "Dawid Wysakowicz"}}, "url": "https://github.com/apache/flink/commit/e0df6ea361347a181a72a3f5d553860fdaaf6bc0", "committedDate": "2020-03-25T14:49:19Z", "message": "Unified function identifier handling for both BridgingSqlFunction and BridgingSqlAggFunction"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgxMjI4NTc1", "url": "https://github.com/apache/flink/pull/11280#pullrequestreview-381228575", "createdAt": "2020-03-25T14:55:18Z", "commit": {"oid": "e0df6ea361347a181a72a3f5d553860fdaaf6bc0"}, "state": "APPROVED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQxNDo1NToxOVrOF7fEyQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQxNDo1NzoxMFrOF7fKvg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzkxOTQzMw==", "bodyText": "nit: add @Nullable to all arguments in this util", "url": "https://github.com/apache/flink/pull/11280#discussion_r397919433", "createdAt": "2020-03-25T14:55:19Z", "author": {"login": "twalthr"}, "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/functions/bridging/BridgingUtils.java", "diffHunk": "@@ -52,8 +52,15 @@\n  * Utilities for bridging {@link FunctionDefinition} with Calcite's representation of functions.\n  */\n final class BridgingUtils {\n+\tstatic String createName(FunctionIdentifier identifier, FunctionDefinition definition) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0df6ea361347a181a72a3f5d553860fdaaf6bc0"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzkyMDk1OA==", "bodyText": "nit: return Optional", "url": "https://github.com/apache/flink/pull/11280#discussion_r397920958", "createdAt": "2020-03-25T14:57:10Z", "author": {"login": "twalthr"}, "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/functions/bridging/BridgingSqlFunction.java", "diffHunk": "@@ -129,6 +125,10 @@ public FlinkTypeFactory getTypeFactory() {\n \t\treturn typeFactory;\n \t}\n \n+\tpublic FunctionIdentifier getIdentifier() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0df6ea361347a181a72a3f5d553860fdaaf6bc0"}, "originalPosition": 73}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "265ed1e4ff1400247a3720fe42ef352778bf2533", "author": {"user": {"login": "dawidwys", "name": "Dawid Wysakowicz"}}, "url": "https://github.com/apache/flink/commit/265ed1e4ff1400247a3720fe42ef352778bf2533", "committedDate": "2020-03-25T15:35:46Z", "message": "[FLINK-16377][table] Support calls to inline functions in the\nexpressions DSL."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e0df6ea361347a181a72a3f5d553860fdaaf6bc0", "author": {"user": {"login": "dawidwys", "name": "Dawid Wysakowicz"}}, "url": "https://github.com/apache/flink/commit/e0df6ea361347a181a72a3f5d553860fdaaf6bc0", "committedDate": "2020-03-25T14:49:19Z", "message": "Unified function identifier handling for both BridgingSqlFunction and BridgingSqlAggFunction"}, "afterCommit": {"oid": "265ed1e4ff1400247a3720fe42ef352778bf2533", "author": {"user": {"login": "dawidwys", "name": "Dawid Wysakowicz"}}, "url": "https://github.com/apache/flink/commit/265ed1e4ff1400247a3720fe42ef352778bf2533", "committedDate": "2020-03-25T15:35:46Z", "message": "[FLINK-16377][table] Support calls to inline functions in the\nexpressions DSL."}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2962, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}