{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDA0MTcxMjk3", "number": 11768, "title": "[FLINK-16943][python] Support set the configuration option \"pipeline.jars\" in PyFlink.", "bodyText": "What is the purpose of the change\nThis pull request supports set the configuration option \"pipeline.jars\" in PyFlink, which could be used to add user jars during the job code execution.\nBrief change log\n\nWhen the \"pipeline.jars\" is set to the python configuration object, load the jars to context class loader.\nWhen the PyFlink TableEnvironment#execute() method is called, pass the \"pipeline.jars\" configuration in TableConfig to ExecutionEnviornment#configuration\n\nVerifying this change\nThis change is already covered by existing tests, such as test_table_environment_api.py.\nDoes this pull request potentially affect one of the following parts:\n\nDependencies (does it add or upgrade a dependency): ( no)\nThe public API, i.e., is any changed class annotated with @Public(Evolving): (no)\nThe serializers: (no)\nThe runtime per-record code paths (performance sensitive): (no)\nAnything that affects deployment or recovery: JobManager (and its components), Checkpointing, Kubernetes/Yarn/Mesos, ZooKeeper: (no)\nThe S3 file system connector: (no)\n\nDocumentation\n\nDoes this pull request introduce a new feature? (yes)\nIf yes, how is the feature documented? (docs)", "createdAt": "2020-04-16T07:34:10Z", "url": "https://github.com/apache/flink/pull/11768", "merged": true, "mergeCommit": {"oid": "68142e5fc3855d3972ea749a766e9ecca97bcc5e"}, "closed": true, "closedAt": "2020-04-21T12:59:41Z", "author": {"login": "WeiZhong94"}, "timelineItems": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcYHg2igH2gAyNDA0MTcxMjk3OmEzYWE2YjZjYWI2YzBhN2UwZTI2YzBjZjNlZjBlMzhmMjY1ZTg3OTk=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcZuCwdAFqTM5NzAzNTA3Mg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "a3aa6b6cab6c0a7e0e26c0cf3ef0e38f265e8799", "author": {"user": {"login": "WeiZhong94", "name": "Wei Zhong"}}, "url": "https://github.com/apache/flink/commit/a3aa6b6cab6c0a7e0e26c0cf3ef0e38f265e8799", "committedDate": "2020-04-16T07:25:29Z", "message": "[FLINK-16943][python] support add jars in PyFlink."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk0NTU3MjM0", "url": "https://github.com/apache/flink/pull/11768#pullrequestreview-394557234", "createdAt": "2020-04-16T11:54:09Z", "commit": {"oid": "a3aa6b6cab6c0a7e0e26c0cf3ef0e38f265e8799"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQxMTo1NDowOVrOGGhrmA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQxMjozMDozMlrOGGi73g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTQ5NjQ3Mg==", "bodyText": "Rename to _add_pipeline_jars_to_j_env_config", "url": "https://github.com/apache/flink/pull/11768#discussion_r409496472", "createdAt": "2020-04-16T11:54:09Z", "author": {"login": "dianfu"}, "path": "flink-python/pyflink/table/table_environment.py", "diffHunk": "@@ -1095,6 +1096,19 @@ def _set_python_executable_for_local_executor(self):\n                 and is_local_deployment(j_config):\n             j_config.setString(jvm.PythonOptions.PYTHON_EXECUTABLE.key(), sys.executable)\n \n+    def _write_pipeline_jars_to_j_env(self):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3aa6b6cab6c0a7e0e26c0cf3ef0e38f265e8799"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTQ5Nzk1NA==", "bodyText": "existing_urls", "url": "https://github.com/apache/flink/pull/11768#discussion_r409497954", "createdAt": "2020-04-16T11:56:55Z", "author": {"login": "dianfu"}, "path": "flink-python/pyflink/util/utils.py", "diffHunk": "@@ -98,3 +98,30 @@ def is_local_deployment(j_configuration):\n     JDeploymentOptions = jvm.org.apache.flink.configuration.DeploymentOptions\n     return j_configuration.containsKey(JDeploymentOptions.TARGET.key()) \\\n         and j_configuration.getString(JDeploymentOptions.TARGET.key(), None) == \"local\"\n+\n+\n+def add_jars_to_context_class_loader(jar_urls):\n+    \"\"\"\n+    Add jars to Python gateway server for local compilation and local execution (i.e. minicluster).\n+    There are many component in Flink which won't be added to classpath by default. e.g. Kafka\n+    connector, JDBC connector, CSV format etc. This utility function can be used to hot load the\n+    jars.\n+\n+    :param jar_urls: The list of jar urls.\n+    \"\"\"\n+    gateway = get_gateway()\n+    # validate and normalize\n+    jar_urls = [gateway.jvm.java.net.URL(url).toString() for url in jar_urls]\n+    context_classloader = gateway.jvm.Thread.currentThread().getContextClassLoader()\n+    existed_urls = []", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3aa6b6cab6c0a7e0e26c0cf3ef0e38f265e8799"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTUwMzA2OA==", "bodyText": "third_class_loader -> second_class_loader", "url": "https://github.com/apache/flink/pull/11768#discussion_r409503068", "createdAt": "2020-04-16T12:06:16Z", "author": {"login": "dianfu"}, "path": "flink-python/pyflink/table/tests/test_table_environment_api.py", "diffHunk": "@@ -329,6 +334,54 @@ def test_table_environment_with_blink_planner(self):\n \n         self.assert_equals(results, ['2,hi,hello\\n', '3,hello,hello\\n'])\n \n+    def test_set_jars(self):\n+        jar_urls = []\n+        func1_class_name = \"org.apache.flink.table.planner.plan.stream.sql.Func1\"\n+        func2_class_name = \"org.apache.flink.python.util.TestScalarFunction\"\n+        jar_urls.extend(self.validate_and_return_unloaded_jar_url(\n+            func1_class_name,\n+            \"flink-table/flink-table-planner-blink/target/flink-table-planner-blink*-tests.jar\"))\n+        jar_urls.extend(self.validate_and_return_unloaded_jar_url(\n+            func2_class_name,\n+            \"flink-python/target/flink-python*-tests.jar\"))\n+\n+        # test set the \"pipeline.jars\" multiple times\n+        self.t_env.get_config().get_configuration().set_string(\"pipeline.jars\", \";\".join(jar_urls))\n+        first_class_loader = get_gateway().jvm.Thread.currentThread().getContextClassLoader()\n+\n+        self.t_env.get_config().get_configuration().set_string(\"pipeline.jars\", jar_urls[0])\n+        self.t_env.get_config().get_configuration().set_string(\"pipeline.jars\", \";\".join(jar_urls))\n+        third_class_loader = get_gateway().jvm.Thread.currentThread().getContextClassLoader()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3aa6b6cab6c0a7e0e26c0cf3ef0e38f265e8799"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTUxNTQ5MA==", "bodyText": "Change the error message to The scalar function '%s' should not be able to be loaded.  ?", "url": "https://github.com/apache/flink/pull/11768#discussion_r409515490", "createdAt": "2020-04-16T12:28:00Z", "author": {"login": "dianfu"}, "path": "flink-python/pyflink/table/tests/test_table_environment_api.py", "diffHunk": "@@ -329,6 +334,54 @@ def test_table_environment_with_blink_planner(self):\n \n         self.assert_equals(results, ['2,hi,hello\\n', '3,hello,hello\\n'])\n \n+    def test_set_jars(self):\n+        jar_urls = []\n+        func1_class_name = \"org.apache.flink.table.planner.plan.stream.sql.Func1\"\n+        func2_class_name = \"org.apache.flink.python.util.TestScalarFunction\"\n+        jar_urls.extend(self.validate_and_return_unloaded_jar_url(\n+            func1_class_name,\n+            \"flink-table/flink-table-planner-blink/target/flink-table-planner-blink*-tests.jar\"))\n+        jar_urls.extend(self.validate_and_return_unloaded_jar_url(\n+            func2_class_name,\n+            \"flink-python/target/flink-python*-tests.jar\"))\n+\n+        # test set the \"pipeline.jars\" multiple times\n+        self.t_env.get_config().get_configuration().set_string(\"pipeline.jars\", \";\".join(jar_urls))\n+        first_class_loader = get_gateway().jvm.Thread.currentThread().getContextClassLoader()\n+\n+        self.t_env.get_config().get_configuration().set_string(\"pipeline.jars\", jar_urls[0])\n+        self.t_env.get_config().get_configuration().set_string(\"pipeline.jars\", \";\".join(jar_urls))\n+        third_class_loader = get_gateway().jvm.Thread.currentThread().getContextClassLoader()\n+\n+        self.assertEqual(first_class_loader, third_class_loader)\n+\n+        source = self.t_env.from_elements([(1, \"Hi\"), (2, \"Hello\")], [\"a\", \"b\"])\n+        self.t_env.register_java_function(\"func1\", func1_class_name)\n+        self.t_env.register_java_function(\"func2\", func2_class_name)\n+        table_sink = source_sink_utils.TestAppendSink(\n+            [\"a\", \"b\"], [DataTypes.STRING(), DataTypes.STRING()])\n+        self.t_env.register_table_sink(\"sink\", table_sink)\n+        source.select(\"func1(a.cast(int), b), func2(a.cast(int), b)\").insert_into(\"sink\")\n+        self.t_env.execute(\"test\")\n+        actual = source_sink_utils.results()\n+        expected = ['1 and Hi,1 or Hi', '2 and Hello,2 or Hello']\n+        self.assert_equals(actual, expected)\n+\n+    def validate_and_return_unloaded_jar_url(self, func_class_name, jar_filename_pattern):\n+        test_jars = glob.glob(os.path.join(_find_flink_source_root(), jar_filename_pattern))\n+        if not test_jars:\n+            self.fail(\"'%s' is not available. Please compile the test jars first.\"\n+                      % jar_filename_pattern)\n+        try:\n+            self.t_env.register_java_function(\"func\", func_class_name)\n+        except Py4JJavaError:\n+            pass\n+        else:\n+            self.fail(\"The scalar function '%s' should not been loaded before this test case. \"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3aa6b6cab6c0a7e0e26c0cf3ef0e38f265e8799"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTUxNTgzOQ==", "bodyText": "Split it into two methods to make it more clear?", "url": "https://github.com/apache/flink/pull/11768#discussion_r409515839", "createdAt": "2020-04-16T12:28:35Z", "author": {"login": "dianfu"}, "path": "flink-python/pyflink/table/tests/test_table_environment_api.py", "diffHunk": "@@ -329,6 +334,54 @@ def test_table_environment_with_blink_planner(self):\n \n         self.assert_equals(results, ['2,hi,hello\\n', '3,hello,hello\\n'])\n \n+    def test_set_jars(self):\n+        jar_urls = []\n+        func1_class_name = \"org.apache.flink.table.planner.plan.stream.sql.Func1\"\n+        func2_class_name = \"org.apache.flink.python.util.TestScalarFunction\"\n+        jar_urls.extend(self.validate_and_return_unloaded_jar_url(\n+            func1_class_name,\n+            \"flink-table/flink-table-planner-blink/target/flink-table-planner-blink*-tests.jar\"))\n+        jar_urls.extend(self.validate_and_return_unloaded_jar_url(\n+            func2_class_name,\n+            \"flink-python/target/flink-python*-tests.jar\"))\n+\n+        # test set the \"pipeline.jars\" multiple times\n+        self.t_env.get_config().get_configuration().set_string(\"pipeline.jars\", \";\".join(jar_urls))\n+        first_class_loader = get_gateway().jvm.Thread.currentThread().getContextClassLoader()\n+\n+        self.t_env.get_config().get_configuration().set_string(\"pipeline.jars\", jar_urls[0])\n+        self.t_env.get_config().get_configuration().set_string(\"pipeline.jars\", \";\".join(jar_urls))\n+        third_class_loader = get_gateway().jvm.Thread.currentThread().getContextClassLoader()\n+\n+        self.assertEqual(first_class_loader, third_class_loader)\n+\n+        source = self.t_env.from_elements([(1, \"Hi\"), (2, \"Hello\")], [\"a\", \"b\"])\n+        self.t_env.register_java_function(\"func1\", func1_class_name)\n+        self.t_env.register_java_function(\"func2\", func2_class_name)\n+        table_sink = source_sink_utils.TestAppendSink(\n+            [\"a\", \"b\"], [DataTypes.STRING(), DataTypes.STRING()])\n+        self.t_env.register_table_sink(\"sink\", table_sink)\n+        source.select(\"func1(a.cast(int), b), func2(a.cast(int), b)\").insert_into(\"sink\")\n+        self.t_env.execute(\"test\")\n+        actual = source_sink_utils.results()\n+        expected = ['1 and Hi,1 or Hi', '2 and Hello,2 or Hello']\n+        self.assert_equals(actual, expected)\n+\n+    def validate_and_return_unloaded_jar_url(self, func_class_name, jar_filename_pattern):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3aa6b6cab6c0a7e0e26c0cf3ef0e38f265e8799"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTUxNzAyMg==", "bodyText": "What about generating two jars for this test purpose instead of reusing the existing test jars? It would be small and also could avoid potential problems.", "url": "https://github.com/apache/flink/pull/11768#discussion_r409517022", "createdAt": "2020-04-16T12:30:32Z", "author": {"login": "dianfu"}, "path": "tools/travis_controller.sh", "diffHunk": "@@ -148,6 +148,8 @@ if [ $STAGE == \"$STAGE_COMPILE\" ]; then\n             ! -path \"$CACHE_FLINK_DIR/flink-dist/target/flink-*-bin/flink-*/opt/flink-python*.jar\" \\\n             ! -path \"$CACHE_FLINK_DIR/flink-connectors/flink-connector-elasticsearch-base/target/flink-*.jar\" \\\n             ! -path \"$CACHE_FLINK_DIR/flink-connectors/flink-connector-kafka-base/target/flink-*.jar\" \\\n+            ! -path \"$CACHE_FLINK_DIR/flink-python/target/flink-python*-tests.jar\" \\", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3aa6b6cab6c0a7e0e26c0cf3ef0e38f265e8799"}, "originalPosition": 4}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b796de76daa408c58f6aa13391c93f1a1e88bb57", "author": {"user": {"login": "WeiZhong94", "name": "Wei Zhong"}}, "url": "https://github.com/apache/flink/commit/b796de76daa408c58f6aa13391c93f1a1e88bb57", "committedDate": "2020-04-17T04:50:20Z", "message": "address comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "01280e72a363ee72180dd385dc95e0013f60650f", "author": {"user": {"login": "WeiZhong94", "name": "Wei Zhong"}}, "url": "https://github.com/apache/flink/commit/01280e72a363ee72180dd385dc95e0013f60650f", "committedDate": "2020-04-17T11:31:41Z", "message": "also support set \"pipeline.classpaths\""}}, {"__typename": "PullRequestCommit", "commit": {"oid": "375c382d79b0eb32388aa1b6b9c2f365a91344ee", "author": {"user": {"login": "WeiZhong94", "name": "Wei Zhong"}}, "url": "https://github.com/apache/flink/commit/375c382d79b0eb32388aa1b6b9c2f365a91344ee", "committedDate": "2020-04-20T08:02:56Z", "message": "add documents for add jars."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk2OTUwMjI4", "url": "https://github.com/apache/flink/pull/11768#pullrequestreview-396950228", "createdAt": "2020-04-21T02:46:18Z", "commit": {"oid": "375c382d79b0eb32388aa1b6b9c2f365a91344ee"}, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQwMjo0NjoxOFrOGIv_sg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQwMzowNDowMVrOGIwWHQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTgyODE0Ng==", "bodyText": "What about Java Dependency?", "url": "https://github.com/apache/flink/pull/11768#discussion_r411828146", "createdAt": "2020-04-21T02:46:18Z", "author": {"login": "dianfu"}, "path": "docs/dev/table/python/dependency_management.md", "diffHunk": "@@ -22,7 +22,24 @@ specific language governing permissions and limitations\n under the License.\n -->\n \n-If third-party dependencies are used, you can specify the dependencies with the following Python Table APIs or through <a href=\"{{ site.baseurl }}/ops/cli.html#usage\">command line arguments</a> directly when submitting the job.\n+# Java Dependency Management", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "375c382d79b0eb32388aa1b6b9c2f365a91344ee"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTgyODI2MA==", "bodyText": "What about Python Dependency?", "url": "https://github.com/apache/flink/pull/11768#discussion_r411828260", "createdAt": "2020-04-21T02:46:44Z", "author": {"login": "dianfu"}, "path": "docs/dev/table/python/dependency_management.md", "diffHunk": "@@ -22,7 +22,24 @@ specific language governing permissions and limitations\n under the License.\n -->\n \n-If third-party dependencies are used, you can specify the dependencies with the following Python Table APIs or through <a href=\"{{ site.baseurl }}/ops/cli.html#usage\">command line arguments</a> directly when submitting the job.\n+# Java Dependency Management\n+\n+If third-party Java dependencies are used, you can using following code to add jars for your Python job.\n+\n+{% highlight python %}\n+# Set jar urls in \"pipeline.jars\". The jars will be uploaded to the cluster.\n+# NOTE: Only local file urls (start with \"file://\") are supported.\n+table_env.get_config.set_configuration(\"pipeline.jars\", \"file:///my/jar/path/connector.jar;file:///my/jar/path/udf.jar\")\n+\n+# Set jar urls in \"pipeline.classpaths\". The jars will be added to the classpath of the cluster.\n+# Users should ensure the urls are accessible on both the local client and the cluster.\n+# NOTE: The supported schemes includes: file,ftp,http,https,jar. \"hdfs\" is not supported by default.\n+table_env.get_config.set_configuration(\"pipeline.classpaths\", \"file:///my/jar/path/connector.jar;file:///my/jar/path/udf.jar\")\n+{% endhighlight %}\n+\n+# Python Dependency Management", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "375c382d79b0eb32388aa1b6b9c2f365a91344ee"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTgyODcwMg==", "bodyText": "Users could also specify the Java dependencies via command line arguments, could we add a link for that?", "url": "https://github.com/apache/flink/pull/11768#discussion_r411828702", "createdAt": "2020-04-21T02:48:10Z", "author": {"login": "dianfu"}, "path": "docs/dev/table/python/dependency_management.md", "diffHunk": "@@ -22,7 +22,24 @@ specific language governing permissions and limitations\n under the License.\n -->\n \n-If third-party dependencies are used, you can specify the dependencies with the following Python Table APIs or through <a href=\"{{ site.baseurl }}/ops/cli.html#usage\">command line arguments</a> directly when submitting the job.\n+# Java Dependency Management\n+\n+If third-party Java dependencies are used, you can using following code to add jars for your Python job.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "375c382d79b0eb32388aa1b6b9c2f365a91344ee"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTgzMTM0Ng==", "bodyText": "Set jar urls in \"pipeline.jars\". -> Specify a list of jar URLs via \"pipeline.jars\"", "url": "https://github.com/apache/flink/pull/11768#discussion_r411831346", "createdAt": "2020-04-21T02:56:08Z", "author": {"login": "dianfu"}, "path": "docs/dev/table/python/dependency_management.md", "diffHunk": "@@ -22,7 +22,24 @@ specific language governing permissions and limitations\n under the License.\n -->\n \n-If third-party dependencies are used, you can specify the dependencies with the following Python Table APIs or through <a href=\"{{ site.baseurl }}/ops/cli.html#usage\">command line arguments</a> directly when submitting the job.\n+# Java Dependency Management\n+\n+If third-party Java dependencies are used, you can using following code to add jars for your Python job.\n+\n+{% highlight python %}\n+# Set jar urls in \"pipeline.jars\". The jars will be uploaded to the cluster.\n+# NOTE: Only local file urls (start with \"file://\") are supported.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "375c382d79b0eb32388aa1b6b9c2f365a91344ee"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTgzMTU2OA==", "bodyText": "Set jar urls in \"pipeline.classpaths\" ->  Specify a list of jar URLs via \"pipeline.classpaths\"", "url": "https://github.com/apache/flink/pull/11768#discussion_r411831568", "createdAt": "2020-04-21T02:56:48Z", "author": {"login": "dianfu"}, "path": "docs/dev/table/python/dependency_management.md", "diffHunk": "@@ -22,7 +22,24 @@ specific language governing permissions and limitations\n under the License.\n -->\n \n-If third-party dependencies are used, you can specify the dependencies with the following Python Table APIs or through <a href=\"{{ site.baseurl }}/ops/cli.html#usage\">command line arguments</a> directly when submitting the job.\n+# Java Dependency Management\n+\n+If third-party Java dependencies are used, you can using following code to add jars for your Python job.\n+\n+{% highlight python %}\n+# Set jar urls in \"pipeline.jars\". The jars will be uploaded to the cluster.\n+# NOTE: Only local file urls (start with \"file://\") are supported.\n+table_env.get_config.set_configuration(\"pipeline.jars\", \"file:///my/jar/path/connector.jar;file:///my/jar/path/udf.jar\")\n+\n+# Set jar urls in \"pipeline.classpaths\". The jars will be added to the classpath of the cluster.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "375c382d79b0eb32388aa1b6b9c2f365a91344ee"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTgzMTcxMA==", "bodyText": "includes -> include", "url": "https://github.com/apache/flink/pull/11768#discussion_r411831710", "createdAt": "2020-04-21T02:57:29Z", "author": {"login": "dianfu"}, "path": "docs/dev/table/python/dependency_management.md", "diffHunk": "@@ -22,7 +22,24 @@ specific language governing permissions and limitations\n under the License.\n -->\n \n-If third-party dependencies are used, you can specify the dependencies with the following Python Table APIs or through <a href=\"{{ site.baseurl }}/ops/cli.html#usage\">command line arguments</a> directly when submitting the job.\n+# Java Dependency Management\n+\n+If third-party Java dependencies are used, you can using following code to add jars for your Python job.\n+\n+{% highlight python %}\n+# Set jar urls in \"pipeline.jars\". The jars will be uploaded to the cluster.\n+# NOTE: Only local file urls (start with \"file://\") are supported.\n+table_env.get_config.set_configuration(\"pipeline.jars\", \"file:///my/jar/path/connector.jar;file:///my/jar/path/udf.jar\")\n+\n+# Set jar urls in \"pipeline.classpaths\". The jars will be added to the classpath of the cluster.\n+# Users should ensure the urls are accessible on both the local client and the cluster.\n+# NOTE: The supported schemes includes: file,ftp,http,https,jar. \"hdfs\" is not supported by default.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "375c382d79b0eb32388aa1b6b9c2f365a91344ee"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTgzMzg4NQ==", "bodyText": "NOTE: Paths must specify a protocol (e.g. file://) and users should ensure that the URLs are accessible on both the client and the cluster.", "url": "https://github.com/apache/flink/pull/11768#discussion_r411833885", "createdAt": "2020-04-21T03:04:01Z", "author": {"login": "dianfu"}, "path": "docs/dev/table/python/dependency_management.md", "diffHunk": "@@ -22,7 +22,24 @@ specific language governing permissions and limitations\n under the License.\n -->\n \n-If third-party dependencies are used, you can specify the dependencies with the following Python Table APIs or through <a href=\"{{ site.baseurl }}/ops/cli.html#usage\">command line arguments</a> directly when submitting the job.\n+# Java Dependency Management\n+\n+If third-party Java dependencies are used, you can using following code to add jars for your Python job.\n+\n+{% highlight python %}\n+# Set jar urls in \"pipeline.jars\". The jars will be uploaded to the cluster.\n+# NOTE: Only local file urls (start with \"file://\") are supported.\n+table_env.get_config.set_configuration(\"pipeline.jars\", \"file:///my/jar/path/connector.jar;file:///my/jar/path/udf.jar\")\n+\n+# Set jar urls in \"pipeline.classpaths\". The jars will be added to the classpath of the cluster.\n+# Users should ensure the urls are accessible on both the local client and the cluster.\n+# NOTE: The supported schemes includes: file,ftp,http,https,jar. \"hdfs\" is not supported by default.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "375c382d79b0eb32388aa1b6b9c2f365a91344ee"}, "originalPosition": 16}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "32989f092938b29018f6a5cec052145289356dcb", "author": {"user": {"login": "WeiZhong94", "name": "Wei Zhong"}}, "url": "https://github.com/apache/flink/commit/32989f092938b29018f6a5cec052145289356dcb", "committedDate": "2020-04-21T06:41:40Z", "message": "address comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk3MDM1MDcy", "url": "https://github.com/apache/flink/pull/11768#pullrequestreview-397035072", "createdAt": "2020-04-21T06:52:50Z", "commit": {"oid": "32989f092938b29018f6a5cec052145289356dcb"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1818, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}