{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzkyMDE5MzYx", "number": 11482, "reviewThreads": {"totalCount": 17, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yOVQxNDo0NDo1MlrODsbUsg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwNzo0MDowOFrODyYIPw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ3OTExNjAyOnYy", "diffSide": "RIGHT", "path": "flink-core/src/main/java/org/apache/flink/api/common/state/StateTtlConfig.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yOVQxNDo0NDo1MlrOF9SUOg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQwNTo0OToxNFrOF9abjw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTgwNzU0Ng==", "bodyText": "We don't need to add equals method for StateTtlConfig, if you want to compare an instance with StateTtlConfig.DISABLED, you can just do it like stateTtlConfig == StateTtlConfig.DISABLED", "url": "https://github.com/apache/flink/pull/11482#discussion_r399807546", "createdAt": "2020-03-29T14:44:52Z", "author": {"login": "libenchao"}, "path": "flink-core/src/main/java/org/apache/flink/api/common/state/StateTtlConfig.java", "diffHunk": "@@ -144,6 +145,21 @@ public String toString() {\n \t\t\t'}';\n \t}\n \n+\t@Override\n+\tpublic boolean equals(Object o){", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f6bab1e9ea3eff8eaa5eab70e8fcbf2ec34d5276"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTk0MDQ5NQ==", "bodyText": "Got it, I will remove these code", "url": "https://github.com/apache/flink/pull/11482#discussion_r399940495", "createdAt": "2020-03-30T05:49:14Z", "author": {"login": "lsyldliu"}, "path": "flink-core/src/main/java/org/apache/flink/api/common/state/StateTtlConfig.java", "diffHunk": "@@ -144,6 +145,21 @@ public String toString() {\n \t\t\t'}';\n \t}\n \n+\t@Override\n+\tpublic boolean equals(Object o){", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTgwNzU0Ng=="}, "originalCommit": {"oid": "f6bab1e9ea3eff8eaa5eab70e8fcbf2ec34d5276"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ3OTExODUzOnYy", "diffSide": "RIGHT", "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/bundle/MapBundleFunctionWithStateRetention.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yOVQxNDo0NzoyNlrOF9SVdA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQwNTo0OToxMFrOF9abeA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTgwNzg2MA==", "bodyText": "Add an error message for this check.", "url": "https://github.com/apache/flink/pull/11482#discussion_r399807860", "createdAt": "2020-03-29T14:47:26Z", "author": {"login": "libenchao"}, "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/bundle/MapBundleFunctionWithStateRetention.java", "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.operators.bundle;\n+\n+import org.apache.flink.api.common.state.StateTtlConfig;\n+import org.apache.flink.api.common.state.StateTtlConfig.StateVisibility;\n+import org.apache.flink.api.common.time.Time;\n+import org.apache.flink.table.runtime.functions.CleanupState;\n+\n+import static org.apache.flink.util.Preconditions.checkArgument;\n+\n+/**\n+ * Basic interface for map bundle processing and could cleanup state.\n+ *\n+ * @param <K>   The type of the key in the bundle map\n+ * @param <V>   The type of the value in the bundle map\n+ * @param <IN>  Type of the input elements.\n+ * @param <OUT> Type of the returned elements.\n+ */\n+\n+public abstract class MapBundleFunctionWithStateRetention<K, V, IN, OUT> extends MapBundleFunction<K, V, IN, OUT> implements CleanupState {\n+\n+\tprivate final long minRetentionTime;\n+\tprivate final boolean stateCleaningEnabled;\n+\tprotected final StateTtlConfig stateTtlConfig;\n+\n+\tpublic MapBundleFunctionWithStateRetention(long minRetentionTime){\n+\t\tthis.minRetentionTime = minRetentionTime;\n+\t\tstateCleaningEnabled = minRetentionTime > 1;\n+\t\tstateTtlConfig = createTtlConfig(minRetentionTime, stateCleaningEnabled);\n+\t}\n+\n+\tprivate StateTtlConfig createTtlConfig(long retentionTime, boolean stateCleaningEnabled) {\n+\t\tif (stateCleaningEnabled) {\n+\t\t\tcheckArgument(retentionTime > 0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f6bab1e9ea3eff8eaa5eab70e8fcbf2ec34d5276"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTk0MDQ3Mg==", "bodyText": "Got it", "url": "https://github.com/apache/flink/pull/11482#discussion_r399940472", "createdAt": "2020-03-30T05:49:10Z", "author": {"login": "lsyldliu"}, "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/bundle/MapBundleFunctionWithStateRetention.java", "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.operators.bundle;\n+\n+import org.apache.flink.api.common.state.StateTtlConfig;\n+import org.apache.flink.api.common.state.StateTtlConfig.StateVisibility;\n+import org.apache.flink.api.common.time.Time;\n+import org.apache.flink.table.runtime.functions.CleanupState;\n+\n+import static org.apache.flink.util.Preconditions.checkArgument;\n+\n+/**\n+ * Basic interface for map bundle processing and could cleanup state.\n+ *\n+ * @param <K>   The type of the key in the bundle map\n+ * @param <V>   The type of the value in the bundle map\n+ * @param <IN>  Type of the input elements.\n+ * @param <OUT> Type of the returned elements.\n+ */\n+\n+public abstract class MapBundleFunctionWithStateRetention<K, V, IN, OUT> extends MapBundleFunction<K, V, IN, OUT> implements CleanupState {\n+\n+\tprivate final long minRetentionTime;\n+\tprivate final boolean stateCleaningEnabled;\n+\tprotected final StateTtlConfig stateTtlConfig;\n+\n+\tpublic MapBundleFunctionWithStateRetention(long minRetentionTime){\n+\t\tthis.minRetentionTime = minRetentionTime;\n+\t\tstateCleaningEnabled = minRetentionTime > 1;\n+\t\tstateTtlConfig = createTtlConfig(minRetentionTime, stateCleaningEnabled);\n+\t}\n+\n+\tprivate StateTtlConfig createTtlConfig(long retentionTime, boolean stateCleaningEnabled) {\n+\t\tif (stateCleaningEnabled) {\n+\t\t\tcheckArgument(retentionTime > 0);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTgwNzg2MA=="}, "originalCommit": {"oid": "f6bab1e9ea3eff8eaa5eab70e8fcbf2ec34d5276"}, "originalPosition": 51}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ3OTEyNjEwOnYy", "diffSide": "RIGHT", "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/bundle/MapBundleFunctionWithStateRetention.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yOVQxNDo1NDo0NFrOF9SZLQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQwNTo0OToyM1rOF9abrA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTgwODgxMw==", "bodyText": "why do we need to implements CleanupState?", "url": "https://github.com/apache/flink/pull/11482#discussion_r399808813", "createdAt": "2020-03-29T14:54:44Z", "author": {"login": "libenchao"}, "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/bundle/MapBundleFunctionWithStateRetention.java", "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.operators.bundle;\n+\n+import org.apache.flink.api.common.state.StateTtlConfig;\n+import org.apache.flink.api.common.state.StateTtlConfig.StateVisibility;\n+import org.apache.flink.api.common.time.Time;\n+import org.apache.flink.table.runtime.functions.CleanupState;\n+\n+import static org.apache.flink.util.Preconditions.checkArgument;\n+\n+/**\n+ * Basic interface for map bundle processing and could cleanup state.\n+ *\n+ * @param <K>   The type of the key in the bundle map\n+ * @param <V>   The type of the value in the bundle map\n+ * @param <IN>  Type of the input elements.\n+ * @param <OUT> Type of the returned elements.\n+ */\n+\n+public abstract class MapBundleFunctionWithStateRetention<K, V, IN, OUT> extends MapBundleFunction<K, V, IN, OUT> implements CleanupState {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f6bab1e9ea3eff8eaa5eab70e8fcbf2ec34d5276"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg5OTMyNA==", "bodyText": "I don't think we need an abstraction for such a simple member field. A utility to create StateTtlConfig is enough.", "url": "https://github.com/apache/flink/pull/11482#discussion_r399899324", "createdAt": "2020-03-30T02:39:53Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/bundle/MapBundleFunctionWithStateRetention.java", "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.operators.bundle;\n+\n+import org.apache.flink.api.common.state.StateTtlConfig;\n+import org.apache.flink.api.common.state.StateTtlConfig.StateVisibility;\n+import org.apache.flink.api.common.time.Time;\n+import org.apache.flink.table.runtime.functions.CleanupState;\n+\n+import static org.apache.flink.util.Preconditions.checkArgument;\n+\n+/**\n+ * Basic interface for map bundle processing and could cleanup state.\n+ *\n+ * @param <K>   The type of the key in the bundle map\n+ * @param <V>   The type of the value in the bundle map\n+ * @param <IN>  Type of the input elements.\n+ * @param <OUT> Type of the returned elements.\n+ */\n+\n+public abstract class MapBundleFunctionWithStateRetention<K, V, IN, OUT> extends MapBundleFunction<K, V, IN, OUT> implements CleanupState {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTgwODgxMw=="}, "originalCommit": {"oid": "f6bab1e9ea3eff8eaa5eab70e8fcbf2ec34d5276"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTk0MDUyNA==", "bodyText": "At first, I implemented it with timer, sorry, I forget to remove it.", "url": "https://github.com/apache/flink/pull/11482#discussion_r399940524", "createdAt": "2020-03-30T05:49:23Z", "author": {"login": "lsyldliu"}, "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/bundle/MapBundleFunctionWithStateRetention.java", "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.operators.bundle;\n+\n+import org.apache.flink.api.common.state.StateTtlConfig;\n+import org.apache.flink.api.common.state.StateTtlConfig.StateVisibility;\n+import org.apache.flink.api.common.time.Time;\n+import org.apache.flink.table.runtime.functions.CleanupState;\n+\n+import static org.apache.flink.util.Preconditions.checkArgument;\n+\n+/**\n+ * Basic interface for map bundle processing and could cleanup state.\n+ *\n+ * @param <K>   The type of the key in the bundle map\n+ * @param <V>   The type of the value in the bundle map\n+ * @param <IN>  Type of the input elements.\n+ * @param <OUT> Type of the returned elements.\n+ */\n+\n+public abstract class MapBundleFunctionWithStateRetention<K, V, IN, OUT> extends MapBundleFunction<K, V, IN, OUT> implements CleanupState {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTgwODgxMw=="}, "originalCommit": {"oid": "f6bab1e9ea3eff8eaa5eab70e8fcbf2ec34d5276"}, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ3OTEyNzA0OnYy", "diffSide": "RIGHT", "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepFirstRowFunctionTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yOVQxNDo1NjowMlrOF9SZrA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yOVQxNDo1NjowMlrOF9SZrA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTgwODk0MA==", "bodyText": "always add a space before {", "url": "https://github.com/apache/flink/pull/11482#discussion_r399808940", "createdAt": "2020-03-29T14:56:02Z", "author": {"login": "libenchao"}, "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepFirstRowFunctionTest.java", "diffHunk": "@@ -71,4 +71,41 @@ public void testKeepFirstRowWithGenerateRetraction() throws Exception {\n \t\ttestHarness.close();\n \t}\n \n+\t@Test\n+\tpublic void tesKeepFirstRowWithStateTtl() throws Exception{", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f6bab1e9ea3eff8eaa5eab70e8fcbf2ec34d5276"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ3OTEyOTMyOnYy", "diffSide": "RIGHT", "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepFirstRowFunctionTest.java", "isResolved": false, "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yOVQxNDo1ODozM1rOF9Sa4A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQxMTo1OTo0NFrOF9mTyw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTgwOTI0OA==", "bodyText": "Do we have any other way to test this, I don't think Thread.sleep is a good idea.", "url": "https://github.com/apache/flink/pull/11482#discussion_r399809248", "createdAt": "2020-03-29T14:58:33Z", "author": {"login": "libenchao"}, "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepFirstRowFunctionTest.java", "diffHunk": "@@ -71,4 +71,41 @@ public void testKeepFirstRowWithGenerateRetraction() throws Exception {\n \t\ttestHarness.close();\n \t}\n \n+\t@Test\n+\tpublic void tesKeepFirstRowWithStateTtl() throws Exception{\n+\t\tMiniBatchDeduplicateKeepFirstRowFunction func = new MiniBatchDeduplicateKeepFirstRowFunction(typeSerializer, minTime.toMilliseconds());\n+\t\tOneInputStreamOperatorTestHarness<BaseRow, BaseRow> testHarness = createTestHarness(func);\n+\t\ttestHarness.setup();\n+\t\ttestHarness.open();\n+\t\ttestHarness.processElement(record(\"book\", 1L, 12));\n+\t\ttestHarness.processElement(record(\"book\", 2L, 11));\n+\t\t// output is empty because bundle not trigger yet.\n+\t\tAssert.assertTrue(testHarness.getOutput().isEmpty());\n+\t\ttestHarness.processElement(record(\"book\", 1L, 13));\n+\n+\t\tThread.sleep(30);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f6bab1e9ea3eff8eaa5eab70e8fcbf2ec34d5276"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTkwMTQyOA==", "bodyText": "Does testHarness.setProcessingTime() work in this case? cc @Myasuka , can we use testHarness.setProcessingTime to test the expiration of state ttl?", "url": "https://github.com/apache/flink/pull/11482#discussion_r399901428", "createdAt": "2020-03-30T02:50:46Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepFirstRowFunctionTest.java", "diffHunk": "@@ -71,4 +71,41 @@ public void testKeepFirstRowWithGenerateRetraction() throws Exception {\n \t\ttestHarness.close();\n \t}\n \n+\t@Test\n+\tpublic void tesKeepFirstRowWithStateTtl() throws Exception{\n+\t\tMiniBatchDeduplicateKeepFirstRowFunction func = new MiniBatchDeduplicateKeepFirstRowFunction(typeSerializer, minTime.toMilliseconds());\n+\t\tOneInputStreamOperatorTestHarness<BaseRow, BaseRow> testHarness = createTestHarness(func);\n+\t\ttestHarness.setup();\n+\t\ttestHarness.open();\n+\t\ttestHarness.processElement(record(\"book\", 1L, 12));\n+\t\ttestHarness.processElement(record(\"book\", 2L, 11));\n+\t\t// output is empty because bundle not trigger yet.\n+\t\tAssert.assertTrue(testHarness.getOutput().isEmpty());\n+\t\ttestHarness.processElement(record(\"book\", 1L, 13));\n+\n+\t\tThread.sleep(30);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTgwOTI0OA=="}, "originalCommit": {"oid": "f6bab1e9ea3eff8eaa5eab70e8fcbf2ec34d5276"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTk0NjAyMQ==", "bodyText": "state ttl use TtlTimeProvider.DEFAULT to get current process time, testHarness.setProcessingTime doesn't work, whether it is appropriate to use TimeUnit.MILLISECONDS.sleep(30) ? Do you have any better advice?", "url": "https://github.com/apache/flink/pull/11482#discussion_r399946021", "createdAt": "2020-03-30T06:07:44Z", "author": {"login": "lsyldliu"}, "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepFirstRowFunctionTest.java", "diffHunk": "@@ -71,4 +71,41 @@ public void testKeepFirstRowWithGenerateRetraction() throws Exception {\n \t\ttestHarness.close();\n \t}\n \n+\t@Test\n+\tpublic void tesKeepFirstRowWithStateTtl() throws Exception{\n+\t\tMiniBatchDeduplicateKeepFirstRowFunction func = new MiniBatchDeduplicateKeepFirstRowFunction(typeSerializer, minTime.toMilliseconds());\n+\t\tOneInputStreamOperatorTestHarness<BaseRow, BaseRow> testHarness = createTestHarness(func);\n+\t\ttestHarness.setup();\n+\t\ttestHarness.open();\n+\t\ttestHarness.processElement(record(\"book\", 1L, 12));\n+\t\ttestHarness.processElement(record(\"book\", 2L, 11));\n+\t\t// output is empty because bundle not trigger yet.\n+\t\tAssert.assertTrue(testHarness.getOutput().isEmpty());\n+\t\ttestHarness.processElement(record(\"book\", 1L, 13));\n+\n+\t\tThread.sleep(30);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTgwOTI0OA=="}, "originalCommit": {"oid": "f6bab1e9ea3eff8eaa5eab70e8fcbf2ec34d5276"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDAwODc0OQ==", "bodyText": "Unfortunately, current we always use TtlTimeProvider.DEFAULT to create keyed state backend. One way to walk around this:\n\nDefine a new MockTtlTimeProvider which could set current time outside.\nDefine a TTLMemoryStateBackend extended from MemoryStateBackend which would ignore the given TtlTimeProvider.DEFAULT when creating keyed state backend, but use previous newly defined  MockTtlTimeProvider.\nSet the TTLMemoryStateBackend to the newly KeyedOneInputStreamOperatorTestHarness to use our customized state backend.\n\nThen you could set a new time to MockTtlTimeProvider to ensure time has passed time to live.", "url": "https://github.com/apache/flink/pull/11482#discussion_r400008749", "createdAt": "2020-03-30T08:22:23Z", "author": {"login": "Myasuka"}, "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepFirstRowFunctionTest.java", "diffHunk": "@@ -71,4 +71,41 @@ public void testKeepFirstRowWithGenerateRetraction() throws Exception {\n \t\ttestHarness.close();\n \t}\n \n+\t@Test\n+\tpublic void tesKeepFirstRowWithStateTtl() throws Exception{\n+\t\tMiniBatchDeduplicateKeepFirstRowFunction func = new MiniBatchDeduplicateKeepFirstRowFunction(typeSerializer, minTime.toMilliseconds());\n+\t\tOneInputStreamOperatorTestHarness<BaseRow, BaseRow> testHarness = createTestHarness(func);\n+\t\ttestHarness.setup();\n+\t\ttestHarness.open();\n+\t\ttestHarness.processElement(record(\"book\", 1L, 12));\n+\t\ttestHarness.processElement(record(\"book\", 2L, 11));\n+\t\t// output is empty because bundle not trigger yet.\n+\t\tAssert.assertTrue(testHarness.getOutput().isEmpty());\n+\t\ttestHarness.processElement(record(\"book\", 1L, 13));\n+\n+\t\tThread.sleep(30);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTgwOTI0OA=="}, "originalCommit": {"oid": "f6bab1e9ea3eff8eaa5eab70e8fcbf2ec34d5276"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDA4NDE2Ng==", "bodyText": "@wuchong , @Myasuka At the moment, KeyedStateBackend created in StreamTaskStateInitializerImpl#keyedStateBackend method using TtlTimeProvider.DEFAULT explicitly, didn't support pass TtlTimeProvider to it, even though we implement TTLMemoryStateBackend , we also can't  set MockTtlTimeProvider  to KeyedStateBackend. Unless, we modify relavant code in StreamTaskStateInitializerImpl, but I dare not change the code because I can't evaluate the impact, what do you think?", "url": "https://github.com/apache/flink/pull/11482#discussion_r400084166", "createdAt": "2020-03-30T10:24:43Z", "author": {"login": "lsyldliu"}, "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepFirstRowFunctionTest.java", "diffHunk": "@@ -71,4 +71,41 @@ public void testKeepFirstRowWithGenerateRetraction() throws Exception {\n \t\ttestHarness.close();\n \t}\n \n+\t@Test\n+\tpublic void tesKeepFirstRowWithStateTtl() throws Exception{\n+\t\tMiniBatchDeduplicateKeepFirstRowFunction func = new MiniBatchDeduplicateKeepFirstRowFunction(typeSerializer, minTime.toMilliseconds());\n+\t\tOneInputStreamOperatorTestHarness<BaseRow, BaseRow> testHarness = createTestHarness(func);\n+\t\ttestHarness.setup();\n+\t\ttestHarness.open();\n+\t\ttestHarness.processElement(record(\"book\", 1L, 12));\n+\t\ttestHarness.processElement(record(\"book\", 2L, 11));\n+\t\t// output is empty because bundle not trigger yet.\n+\t\tAssert.assertTrue(testHarness.getOutput().isEmpty());\n+\t\ttestHarness.processElement(record(\"book\", 1L, 13));\n+\n+\t\tThread.sleep(30);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTgwOTI0OA=="}, "originalCommit": {"oid": "f6bab1e9ea3eff8eaa5eab70e8fcbf2ec34d5276"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDEwNDQxNw==", "bodyText": "Hi @lsyldliu , I think a better way is to make  StreamTaskStateInitializerImpl accept a TtlTimeProvider constructor parameter instead of hard code TtlTimeProvider.DEFAULT in the implementation. Then, we can pass-in the MockTtlTimeProvider in AbstractStreamOperatorTestHarness#createStreamTaskStateManager.\nWhat do you think @Myasuka ? Could you help on this?", "url": "https://github.com/apache/flink/pull/11482#discussion_r400104417", "createdAt": "2020-03-30T11:01:12Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepFirstRowFunctionTest.java", "diffHunk": "@@ -71,4 +71,41 @@ public void testKeepFirstRowWithGenerateRetraction() throws Exception {\n \t\ttestHarness.close();\n \t}\n \n+\t@Test\n+\tpublic void tesKeepFirstRowWithStateTtl() throws Exception{\n+\t\tMiniBatchDeduplicateKeepFirstRowFunction func = new MiniBatchDeduplicateKeepFirstRowFunction(typeSerializer, minTime.toMilliseconds());\n+\t\tOneInputStreamOperatorTestHarness<BaseRow, BaseRow> testHarness = createTestHarness(func);\n+\t\ttestHarness.setup();\n+\t\ttestHarness.open();\n+\t\ttestHarness.processElement(record(\"book\", 1L, 12));\n+\t\ttestHarness.processElement(record(\"book\", 2L, 11));\n+\t\t// output is empty because bundle not trigger yet.\n+\t\tAssert.assertTrue(testHarness.getOutput().isEmpty());\n+\t\ttestHarness.processElement(record(\"book\", 1L, 13));\n+\n+\t\tThread.sleep(30);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTgwOTI0OA=="}, "originalCommit": {"oid": "f6bab1e9ea3eff8eaa5eab70e8fcbf2ec34d5276"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDEyMDA4Ng==", "bodyText": "@wuchong , sure I could help on this to let TtlTimeProvider configurable by opening another issue.", "url": "https://github.com/apache/flink/pull/11482#discussion_r400120086", "createdAt": "2020-03-30T11:31:37Z", "author": {"login": "Myasuka"}, "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepFirstRowFunctionTest.java", "diffHunk": "@@ -71,4 +71,41 @@ public void testKeepFirstRowWithGenerateRetraction() throws Exception {\n \t\ttestHarness.close();\n \t}\n \n+\t@Test\n+\tpublic void tesKeepFirstRowWithStateTtl() throws Exception{\n+\t\tMiniBatchDeduplicateKeepFirstRowFunction func = new MiniBatchDeduplicateKeepFirstRowFunction(typeSerializer, minTime.toMilliseconds());\n+\t\tOneInputStreamOperatorTestHarness<BaseRow, BaseRow> testHarness = createTestHarness(func);\n+\t\ttestHarness.setup();\n+\t\ttestHarness.open();\n+\t\ttestHarness.processElement(record(\"book\", 1L, 12));\n+\t\ttestHarness.processElement(record(\"book\", 2L, 11));\n+\t\t// output is empty because bundle not trigger yet.\n+\t\tAssert.assertTrue(testHarness.getOutput().isEmpty());\n+\t\ttestHarness.processElement(record(\"book\", 1L, 13));\n+\n+\t\tThread.sleep(30);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTgwOTI0OA=="}, "originalCommit": {"oid": "f6bab1e9ea3eff8eaa5eab70e8fcbf2ec34d5276"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDEyMjMxNA==", "bodyText": "Thanks @Myasuka .\n@lsyldliu , we may need to hold this PR until StreamTaskStateInitializerImpl supports custom TtlTimeProvider.", "url": "https://github.com/apache/flink/pull/11482#discussion_r400122314", "createdAt": "2020-03-30T11:35:44Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepFirstRowFunctionTest.java", "diffHunk": "@@ -71,4 +71,41 @@ public void testKeepFirstRowWithGenerateRetraction() throws Exception {\n \t\ttestHarness.close();\n \t}\n \n+\t@Test\n+\tpublic void tesKeepFirstRowWithStateTtl() throws Exception{\n+\t\tMiniBatchDeduplicateKeepFirstRowFunction func = new MiniBatchDeduplicateKeepFirstRowFunction(typeSerializer, minTime.toMilliseconds());\n+\t\tOneInputStreamOperatorTestHarness<BaseRow, BaseRow> testHarness = createTestHarness(func);\n+\t\ttestHarness.setup();\n+\t\ttestHarness.open();\n+\t\ttestHarness.processElement(record(\"book\", 1L, 12));\n+\t\ttestHarness.processElement(record(\"book\", 2L, 11));\n+\t\t// output is empty because bundle not trigger yet.\n+\t\tAssert.assertTrue(testHarness.getOutput().isEmpty());\n+\t\ttestHarness.processElement(record(\"book\", 1L, 13));\n+\n+\t\tThread.sleep(30);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTgwOTI0OA=="}, "originalCommit": {"oid": "f6bab1e9ea3eff8eaa5eab70e8fcbf2ec34d5276"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDEzNTExNQ==", "bodyText": "OK", "url": "https://github.com/apache/flink/pull/11482#discussion_r400135115", "createdAt": "2020-03-30T11:59:44Z", "author": {"login": "lsyldliu"}, "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepFirstRowFunctionTest.java", "diffHunk": "@@ -71,4 +71,41 @@ public void testKeepFirstRowWithGenerateRetraction() throws Exception {\n \t\ttestHarness.close();\n \t}\n \n+\t@Test\n+\tpublic void tesKeepFirstRowWithStateTtl() throws Exception{\n+\t\tMiniBatchDeduplicateKeepFirstRowFunction func = new MiniBatchDeduplicateKeepFirstRowFunction(typeSerializer, minTime.toMilliseconds());\n+\t\tOneInputStreamOperatorTestHarness<BaseRow, BaseRow> testHarness = createTestHarness(func);\n+\t\ttestHarness.setup();\n+\t\ttestHarness.open();\n+\t\ttestHarness.processElement(record(\"book\", 1L, 12));\n+\t\ttestHarness.processElement(record(\"book\", 2L, 11));\n+\t\t// output is empty because bundle not trigger yet.\n+\t\tAssert.assertTrue(testHarness.getOutput().isEmpty());\n+\t\ttestHarness.processElement(record(\"book\", 1L, 13));\n+\n+\t\tThread.sleep(30);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTgwOTI0OA=="}, "originalCommit": {"oid": "f6bab1e9ea3eff8eaa5eab70e8fcbf2ec34d5276"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ3OTc5MDc2OnYy", "diffSide": "RIGHT", "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepFirstRowFunction.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQwMjoyODozN1rOF9XyGA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQwNjoxNTowMlrOF9a6tA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg5NzExMg==", "bodyText": "use stateTtlConfig.isEnabled. We should also correct the implementation in JoinRecordStateViews.", "url": "https://github.com/apache/flink/pull/11482#discussion_r399897112", "createdAt": "2020-03-30T02:28:37Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepFirstRowFunction.java", "diffHunk": "@@ -46,14 +47,18 @@\n \t// state stores a boolean flag to indicate whether key appears before.\n \tprivate ValueState<Boolean> state;\n \n-\tpublic MiniBatchDeduplicateKeepFirstRowFunction(TypeSerializer<BaseRow> typeSerializer) {\n+\tpublic MiniBatchDeduplicateKeepFirstRowFunction(TypeSerializer<BaseRow> typeSerializer, long minRetentionTime) {\n+\t\tsuper(minRetentionTime);\n \t\tthis.typeSerializer = typeSerializer;\n \t}\n \n \t@Override\n \tpublic void open(ExecutionContext ctx) throws Exception {\n \t\tsuper.open(ctx);\n \t\tValueStateDescriptor<Boolean> stateDesc = new ValueStateDescriptor<>(\"existsState\", Types.BOOLEAN);\n+\t\tif (!stateTtlConfig.equals(StateTtlConfig.DISABLED)){", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f6bab1e9ea3eff8eaa5eab70e8fcbf2ec34d5276"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTk0MzEzMw==", "bodyText": "I see, tks", "url": "https://github.com/apache/flink/pull/11482#discussion_r399943133", "createdAt": "2020-03-30T05:58:18Z", "author": {"login": "lsyldliu"}, "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepFirstRowFunction.java", "diffHunk": "@@ -46,14 +47,18 @@\n \t// state stores a boolean flag to indicate whether key appears before.\n \tprivate ValueState<Boolean> state;\n \n-\tpublic MiniBatchDeduplicateKeepFirstRowFunction(TypeSerializer<BaseRow> typeSerializer) {\n+\tpublic MiniBatchDeduplicateKeepFirstRowFunction(TypeSerializer<BaseRow> typeSerializer, long minRetentionTime) {\n+\t\tsuper(minRetentionTime);\n \t\tthis.typeSerializer = typeSerializer;\n \t}\n \n \t@Override\n \tpublic void open(ExecutionContext ctx) throws Exception {\n \t\tsuper.open(ctx);\n \t\tValueStateDescriptor<Boolean> stateDesc = new ValueStateDescriptor<>(\"existsState\", Types.BOOLEAN);\n+\t\tif (!stateTtlConfig.equals(StateTtlConfig.DISABLED)){", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg5NzExMg=="}, "originalCommit": {"oid": "f6bab1e9ea3eff8eaa5eab70e8fcbf2ec34d5276"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTk0MzYxOA==", "bodyText": "By the way, should I correct the implementation in JoinRecordStateViews?", "url": "https://github.com/apache/flink/pull/11482#discussion_r399943618", "createdAt": "2020-03-30T05:59:51Z", "author": {"login": "lsyldliu"}, "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepFirstRowFunction.java", "diffHunk": "@@ -46,14 +47,18 @@\n \t// state stores a boolean flag to indicate whether key appears before.\n \tprivate ValueState<Boolean> state;\n \n-\tpublic MiniBatchDeduplicateKeepFirstRowFunction(TypeSerializer<BaseRow> typeSerializer) {\n+\tpublic MiniBatchDeduplicateKeepFirstRowFunction(TypeSerializer<BaseRow> typeSerializer, long minRetentionTime) {\n+\t\tsuper(minRetentionTime);\n \t\tthis.typeSerializer = typeSerializer;\n \t}\n \n \t@Override\n \tpublic void open(ExecutionContext ctx) throws Exception {\n \t\tsuper.open(ctx);\n \t\tValueStateDescriptor<Boolean> stateDesc = new ValueStateDescriptor<>(\"existsState\", Types.BOOLEAN);\n+\t\tif (!stateTtlConfig.equals(StateTtlConfig.DISABLED)){", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg5NzExMg=="}, "originalCommit": {"oid": "f6bab1e9ea3eff8eaa5eab70e8fcbf2ec34d5276"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTk0ODQ2OA==", "bodyText": "Yes. Thanks.", "url": "https://github.com/apache/flink/pull/11482#discussion_r399948468", "createdAt": "2020-03-30T06:15:02Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepFirstRowFunction.java", "diffHunk": "@@ -46,14 +47,18 @@\n \t// state stores a boolean flag to indicate whether key appears before.\n \tprivate ValueState<Boolean> state;\n \n-\tpublic MiniBatchDeduplicateKeepFirstRowFunction(TypeSerializer<BaseRow> typeSerializer) {\n+\tpublic MiniBatchDeduplicateKeepFirstRowFunction(TypeSerializer<BaseRow> typeSerializer, long minRetentionTime) {\n+\t\tsuper(minRetentionTime);\n \t\tthis.typeSerializer = typeSerializer;\n \t}\n \n \t@Override\n \tpublic void open(ExecutionContext ctx) throws Exception {\n \t\tsuper.open(ctx);\n \t\tValueStateDescriptor<Boolean> stateDesc = new ValueStateDescriptor<>(\"existsState\", Types.BOOLEAN);\n+\t\tif (!stateTtlConfig.equals(StateTtlConfig.DISABLED)){", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg5NzExMg=="}, "originalCommit": {"oid": "f6bab1e9ea3eff8eaa5eab70e8fcbf2ec34d5276"}, "originalPosition": 39}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ3OTc5OTAwOnYy", "diffSide": "RIGHT", "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepLastRowFunctionTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQwMjozNToxMVrOF9X26A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQwNjozNjowN1rOF9bXyA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg5ODM0NA==", "bodyText": "Is there any changes between these lines? It's not encouraged to refactor code sytle among some other changes.  If it is for code style, the later one is not good:\n\nplease add an additional indent for new line parameter.\nplease put each parameter in a speparate line if you think the method call is too long.\n\nPlease refer a more detailed code style guideline: https://flink.apache.org/contributing/code-style-and-quality-preamble.html", "url": "https://github.com/apache/flink/pull/11482#discussion_r399898344", "createdAt": "2020-03-30T02:35:11Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepLastRowFunctionTest.java", "diffHunk": "@@ -41,23 +41,28 @@\n  */\n public class MiniBatchDeduplicateKeepLastRowFunctionTest extends DeduplicateFunctionTestBase {\n \n-\tprivate TypeSerializer<BaseRow> typeSerializer = inputRowType.createSerializer(new ExecutionConfig());\n+\tprivate TypeSerializer<BaseRow> typeSerializer = inputRowType\n+\t\t.createSerializer(new ExecutionConfig());\n \n-\tprivate MiniBatchDeduplicateKeepLastRowFunction createFunction(boolean generateRetraction) {\n-\t\treturn new MiniBatchDeduplicateKeepLastRowFunction(inputRowType, generateRetraction, typeSerializer);\n+\tprivate MiniBatchDeduplicateKeepLastRowFunction createFunction(boolean generateRetraction,\n+\t\tlong minRetentionTime) {\n+\t\treturn new MiniBatchDeduplicateKeepLastRowFunction(inputRowType, generateRetraction,\n+\t\t\ttypeSerializer, minRetentionTime);\n \t}\n \n \tprivate OneInputStreamOperatorTestHarness<BaseRow, BaseRow> createTestHarness(\n-\t\t\tMiniBatchDeduplicateKeepLastRowFunction func)\n-\t\t\tthrows Exception {\n+\t\tMiniBatchDeduplicateKeepLastRowFunction func)\n+\t\tthrows Exception {\n \t\tCountBundleTrigger<Tuple2<String, String>> trigger = new CountBundleTrigger<>(3);\n \t\tKeyedMapBundleOperator op = new KeyedMapBundleOperator(func, trigger);\n-\t\treturn new KeyedOneInputStreamOperatorTestHarness<>(op, rowKeySelector, rowKeySelector.getProducedType());\n+\t\treturn new KeyedOneInputStreamOperatorTestHarness<>(op, rowKeySelector,\n+\t\t\trowKeySelector.getProducedType());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f6bab1e9ea3eff8eaa5eab70e8fcbf2ec34d5276"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTk1NTkxMg==", "bodyText": "sorry, I didn't notice that", "url": "https://github.com/apache/flink/pull/11482#discussion_r399955912", "createdAt": "2020-03-30T06:36:07Z", "author": {"login": "lsyldliu"}, "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepLastRowFunctionTest.java", "diffHunk": "@@ -41,23 +41,28 @@\n  */\n public class MiniBatchDeduplicateKeepLastRowFunctionTest extends DeduplicateFunctionTestBase {\n \n-\tprivate TypeSerializer<BaseRow> typeSerializer = inputRowType.createSerializer(new ExecutionConfig());\n+\tprivate TypeSerializer<BaseRow> typeSerializer = inputRowType\n+\t\t.createSerializer(new ExecutionConfig());\n \n-\tprivate MiniBatchDeduplicateKeepLastRowFunction createFunction(boolean generateRetraction) {\n-\t\treturn new MiniBatchDeduplicateKeepLastRowFunction(inputRowType, generateRetraction, typeSerializer);\n+\tprivate MiniBatchDeduplicateKeepLastRowFunction createFunction(boolean generateRetraction,\n+\t\tlong minRetentionTime) {\n+\t\treturn new MiniBatchDeduplicateKeepLastRowFunction(inputRowType, generateRetraction,\n+\t\t\ttypeSerializer, minRetentionTime);\n \t}\n \n \tprivate OneInputStreamOperatorTestHarness<BaseRow, BaseRow> createTestHarness(\n-\t\t\tMiniBatchDeduplicateKeepLastRowFunction func)\n-\t\t\tthrows Exception {\n+\t\tMiniBatchDeduplicateKeepLastRowFunction func)\n+\t\tthrows Exception {\n \t\tCountBundleTrigger<Tuple2<String, String>> trigger = new CountBundleTrigger<>(3);\n \t\tKeyedMapBundleOperator op = new KeyedMapBundleOperator(func, trigger);\n-\t\treturn new KeyedOneInputStreamOperatorTestHarness<>(op, rowKeySelector, rowKeySelector.getProducedType());\n+\t\treturn new KeyedOneInputStreamOperatorTestHarness<>(op, rowKeySelector,\n+\t\t\trowKeySelector.getProducedType());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg5ODM0NA=="}, "originalCommit": {"oid": "f6bab1e9ea3eff8eaa5eab70e8fcbf2ec34d5276"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ3OTgwMTM3OnYy", "diffSide": "RIGHT", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/state/ttl/AbstractTtlDecorator.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQwMjozNjo1OVrOF9X4ZA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQwNjowMToxN1rOF9apeA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg5ODcyNA==", "bodyText": "The original Javadoc is correct.", "url": "https://github.com/apache/flink/pull/11482#discussion_r399898724", "createdAt": "2020-03-30T02:36:59Z", "author": {"login": "wuchong"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/state/ttl/AbstractTtlDecorator.java", "diffHunk": "@@ -40,7 +40,7 @@\n \t/** Whether to renew expiration timestamp on state read access. */\n \tfinal boolean updateTsOnRead;\n \n-\t/** Whether to renew expiration timestamp on state read access. */\n+\t/** Whether to return expired value if not cleaned up on state read access. */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f6bab1e9ea3eff8eaa5eab70e8fcbf2ec34d5276"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTk0NDA1Ng==", "bodyText": "ok", "url": "https://github.com/apache/flink/pull/11482#discussion_r399944056", "createdAt": "2020-03-30T06:01:17Z", "author": {"login": "lsyldliu"}, "path": "flink-runtime/src/main/java/org/apache/flink/runtime/state/ttl/AbstractTtlDecorator.java", "diffHunk": "@@ -40,7 +40,7 @@\n \t/** Whether to renew expiration timestamp on state read access. */\n \tfinal boolean updateTsOnRead;\n \n-\t/** Whether to renew expiration timestamp on state read access. */\n+\t/** Whether to return expired value if not cleaned up on state read access. */", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg5ODcyNA=="}, "originalCommit": {"oid": "f6bab1e9ea3eff8eaa5eab70e8fcbf2ec34d5276"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNzMwMDE0OnYy", "diffSide": "RIGHT", "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepFirstRowFunction.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMlQwNzowODozNlrOGES6kA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMlQwNzoyMzowOFrOGETACg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzE1NzM5Mg==", "bodyText": "if (ttlConfig.isEnabled()) {\nwe always add a space before {", "url": "https://github.com/apache/flink/pull/11482#discussion_r407157392", "createdAt": "2020-04-12T07:08:36Z", "author": {"login": "libenchao"}, "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepFirstRowFunction.java", "diffHunk": "@@ -42,18 +44,25 @@\n \tprivate static final long serialVersionUID = -7994602893547654994L;\n \n \tprivate final TypeSerializer<BaseRow> typeSerializer;\n-\n+\tprivate final long minRetentionTime;\n+\tprivate final boolean stateCleaningEnabled;\n \t// state stores a boolean flag to indicate whether key appears before.\n \tprivate ValueState<Boolean> state;\n \n-\tpublic MiniBatchDeduplicateKeepFirstRowFunction(TypeSerializer<BaseRow> typeSerializer) {\n+\tpublic MiniBatchDeduplicateKeepFirstRowFunction(TypeSerializer<BaseRow> typeSerializer, long minRetentionTime) {\n+\t\tthis.minRetentionTime = minRetentionTime;\n+\t\tstateCleaningEnabled = minRetentionTime > 1;\n \t\tthis.typeSerializer = typeSerializer;\n \t}\n \n \t@Override\n \tpublic void open(ExecutionContext ctx) throws Exception {\n \t\tsuper.open(ctx);\n \t\tValueStateDescriptor<Boolean> stateDesc = new ValueStateDescriptor<>(\"existsState\", Types.BOOLEAN);\n+\t\tStateTtlConfig ttlConfig = createTtlConfig(minRetentionTime, stateCleaningEnabled);\n+\t\tif (ttlConfig.isEnabled()){", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8ed0e698785e0b47ec4721b4a242b68cc8e7059"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzE1ODc5NA==", "bodyText": "got it", "url": "https://github.com/apache/flink/pull/11482#discussion_r407158794", "createdAt": "2020-04-12T07:23:08Z", "author": {"login": "lsyldliu"}, "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepFirstRowFunction.java", "diffHunk": "@@ -42,18 +44,25 @@\n \tprivate static final long serialVersionUID = -7994602893547654994L;\n \n \tprivate final TypeSerializer<BaseRow> typeSerializer;\n-\n+\tprivate final long minRetentionTime;\n+\tprivate final boolean stateCleaningEnabled;\n \t// state stores a boolean flag to indicate whether key appears before.\n \tprivate ValueState<Boolean> state;\n \n-\tpublic MiniBatchDeduplicateKeepFirstRowFunction(TypeSerializer<BaseRow> typeSerializer) {\n+\tpublic MiniBatchDeduplicateKeepFirstRowFunction(TypeSerializer<BaseRow> typeSerializer, long minRetentionTime) {\n+\t\tthis.minRetentionTime = minRetentionTime;\n+\t\tstateCleaningEnabled = minRetentionTime > 1;\n \t\tthis.typeSerializer = typeSerializer;\n \t}\n \n \t@Override\n \tpublic void open(ExecutionContext ctx) throws Exception {\n \t\tsuper.open(ctx);\n \t\tValueStateDescriptor<Boolean> stateDesc = new ValueStateDescriptor<>(\"existsState\", Types.BOOLEAN);\n+\t\tStateTtlConfig ttlConfig = createTtlConfig(minRetentionTime, stateCleaningEnabled);\n+\t\tif (ttlConfig.isEnabled()){", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzE1NzM5Mg=="}, "originalCommit": {"oid": "f8ed0e698785e0b47ec4721b4a242b68cc8e7059"}, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNzM0MjUwOnYy", "diffSide": "RIGHT", "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepLastRowFunctionTest.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMlQwODowMDozOVrOGETPIA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMlQxNTozMzowMVrOGEWZrw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzE2MjY1Ng==", "bodyText": "nit: ) {", "url": "https://github.com/apache/flink/pull/11482#discussion_r407162656", "createdAt": "2020-04-12T08:00:39Z", "author": {"login": "libenchao"}, "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepLastRowFunctionTest.java", "diffHunk": "@@ -113,4 +113,42 @@ public void testWithGenerateRetraction() throws Exception {\n \t\ttestHarness.close();\n \t\tassertor.assertOutputEqualsSorted(\"output wrong.\", expectedOutput, testHarness.getOutput());\n \t}\n+\n+\t@Test\n+\tpublic void tesKeepLastRowWithStateTtlAndGenerateRetraction() throws Exception {\n+\t\tMiniBatchDeduplicateKeepLastRowFunction func = createFunction(true, minTime.toMilliseconds());\n+\t\tOneInputStreamOperatorTestHarness<BaseRow, BaseRow> testHarness = createTestHarness(func);\n+\t\ttestHarness.setup();\n+\t\ttestHarness.open();\n+\n+\t\ttestHarness.processElement(record(\"book\", 1L, 10));\n+\t\ttestHarness.processElement(record(\"book\", 2L, 11));\n+\t\t// output is empty because bundle not trigger yet.\n+\t\tAssert.assertTrue(testHarness.getOutput().isEmpty());\n+\t\ttestHarness.processElement(record(\"book\", 1L, 13));\n+\n+\t\ttestHarness.setStateTtlProcessingTime(30);\n+\t\t//Incremental cleanup is an eventual clean up, more state access guarantee more expired state cleaned\n+\t\tfor (long i = 3; i < 30; i++){", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a85e34346824eb2b005b157801bf576ba901ea88"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzE2Mjc5MA==", "bodyText": "just curious, if no more other state access, old state will be valid when it is accessed?", "url": "https://github.com/apache/flink/pull/11482#discussion_r407162790", "createdAt": "2020-04-12T08:02:08Z", "author": {"login": "libenchao"}, "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepLastRowFunctionTest.java", "diffHunk": "@@ -113,4 +113,42 @@ public void testWithGenerateRetraction() throws Exception {\n \t\ttestHarness.close();\n \t\tassertor.assertOutputEqualsSorted(\"output wrong.\", expectedOutput, testHarness.getOutput());\n \t}\n+\n+\t@Test\n+\tpublic void tesKeepLastRowWithStateTtlAndGenerateRetraction() throws Exception {\n+\t\tMiniBatchDeduplicateKeepLastRowFunction func = createFunction(true, minTime.toMilliseconds());\n+\t\tOneInputStreamOperatorTestHarness<BaseRow, BaseRow> testHarness = createTestHarness(func);\n+\t\ttestHarness.setup();\n+\t\ttestHarness.open();\n+\n+\t\ttestHarness.processElement(record(\"book\", 1L, 10));\n+\t\ttestHarness.processElement(record(\"book\", 2L, 11));\n+\t\t// output is empty because bundle not trigger yet.\n+\t\tAssert.assertTrue(testHarness.getOutput().isEmpty());\n+\t\ttestHarness.processElement(record(\"book\", 1L, 13));\n+\n+\t\ttestHarness.setStateTtlProcessingTime(30);\n+\t\t//Incremental cleanup is an eventual clean up, more state access guarantee more expired state cleaned\n+\t\tfor (long i = 3; i < 30; i++){", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzE2MjY1Ng=="}, "originalCommit": {"oid": "a85e34346824eb2b005b157801bf576ba901ea88"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzE2NjQxNg==", "bodyText": "sorry, I have updated it.\nYes, Incremental cleanup is eventual cleanup, needs more state access, it keeps a global iterator and might not have reached and cleaned some expired state.", "url": "https://github.com/apache/flink/pull/11482#discussion_r407166416", "createdAt": "2020-04-12T08:36:59Z", "author": {"login": "lsyldliu"}, "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepLastRowFunctionTest.java", "diffHunk": "@@ -113,4 +113,42 @@ public void testWithGenerateRetraction() throws Exception {\n \t\ttestHarness.close();\n \t\tassertor.assertOutputEqualsSorted(\"output wrong.\", expectedOutput, testHarness.getOutput());\n \t}\n+\n+\t@Test\n+\tpublic void tesKeepLastRowWithStateTtlAndGenerateRetraction() throws Exception {\n+\t\tMiniBatchDeduplicateKeepLastRowFunction func = createFunction(true, minTime.toMilliseconds());\n+\t\tOneInputStreamOperatorTestHarness<BaseRow, BaseRow> testHarness = createTestHarness(func);\n+\t\ttestHarness.setup();\n+\t\ttestHarness.open();\n+\n+\t\ttestHarness.processElement(record(\"book\", 1L, 10));\n+\t\ttestHarness.processElement(record(\"book\", 2L, 11));\n+\t\t// output is empty because bundle not trigger yet.\n+\t\tAssert.assertTrue(testHarness.getOutput().isEmpty());\n+\t\ttestHarness.processElement(record(\"book\", 1L, 13));\n+\n+\t\ttestHarness.setStateTtlProcessingTime(30);\n+\t\t//Incremental cleanup is an eventual clean up, more state access guarantee more expired state cleaned\n+\t\tfor (long i = 3; i < 30; i++){", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzE2MjY1Ng=="}, "originalCommit": {"oid": "a85e34346824eb2b005b157801bf576ba901ea88"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIxMTI4Ng==", "bodyText": "have you tested it\uff1f\nI'm asking because in state backend, we can easily check the ttl when we get the state, and even it's not cleaned physically.", "url": "https://github.com/apache/flink/pull/11482#discussion_r407211286", "createdAt": "2020-04-12T15:09:32Z", "author": {"login": "libenchao"}, "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepLastRowFunctionTest.java", "diffHunk": "@@ -113,4 +113,42 @@ public void testWithGenerateRetraction() throws Exception {\n \t\ttestHarness.close();\n \t\tassertor.assertOutputEqualsSorted(\"output wrong.\", expectedOutput, testHarness.getOutput());\n \t}\n+\n+\t@Test\n+\tpublic void tesKeepLastRowWithStateTtlAndGenerateRetraction() throws Exception {\n+\t\tMiniBatchDeduplicateKeepLastRowFunction func = createFunction(true, minTime.toMilliseconds());\n+\t\tOneInputStreamOperatorTestHarness<BaseRow, BaseRow> testHarness = createTestHarness(func);\n+\t\ttestHarness.setup();\n+\t\ttestHarness.open();\n+\n+\t\ttestHarness.processElement(record(\"book\", 1L, 10));\n+\t\ttestHarness.processElement(record(\"book\", 2L, 11));\n+\t\t// output is empty because bundle not trigger yet.\n+\t\tAssert.assertTrue(testHarness.getOutput().isEmpty());\n+\t\ttestHarness.processElement(record(\"book\", 1L, 13));\n+\n+\t\ttestHarness.setStateTtlProcessingTime(30);\n+\t\t//Incremental cleanup is an eventual clean up, more state access guarantee more expired state cleaned\n+\t\tfor (long i = 3; i < 30; i++){", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzE2MjY1Ng=="}, "originalCommit": {"oid": "a85e34346824eb2b005b157801bf576ba901ea88"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIxNDUxMQ==", "bodyText": "Yeah, I have tested it. When remove these code, the test failed. You can see FLINK-10473 for more explain.", "url": "https://github.com/apache/flink/pull/11482#discussion_r407214511", "createdAt": "2020-04-12T15:33:01Z", "author": {"login": "lsyldliu"}, "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepLastRowFunctionTest.java", "diffHunk": "@@ -113,4 +113,42 @@ public void testWithGenerateRetraction() throws Exception {\n \t\ttestHarness.close();\n \t\tassertor.assertOutputEqualsSorted(\"output wrong.\", expectedOutput, testHarness.getOutput());\n \t}\n+\n+\t@Test\n+\tpublic void tesKeepLastRowWithStateTtlAndGenerateRetraction() throws Exception {\n+\t\tMiniBatchDeduplicateKeepLastRowFunction func = createFunction(true, minTime.toMilliseconds());\n+\t\tOneInputStreamOperatorTestHarness<BaseRow, BaseRow> testHarness = createTestHarness(func);\n+\t\ttestHarness.setup();\n+\t\ttestHarness.open();\n+\n+\t\ttestHarness.processElement(record(\"book\", 1L, 10));\n+\t\ttestHarness.processElement(record(\"book\", 2L, 11));\n+\t\t// output is empty because bundle not trigger yet.\n+\t\tAssert.assertTrue(testHarness.getOutput().isEmpty());\n+\t\ttestHarness.processElement(record(\"book\", 1L, 13));\n+\n+\t\ttestHarness.setStateTtlProcessingTime(30);\n+\t\t//Incremental cleanup is an eventual clean up, more state access guarantee more expired state cleaned\n+\t\tfor (long i = 3; i < 30; i++){", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzE2MjY1Ng=="}, "originalCommit": {"oid": "a85e34346824eb2b005b157801bf576ba901ea88"}, "originalPosition": 49}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNzQ3ODMxOnYy", "diffSide": "RIGHT", "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/util/StateTtlConfigUtil.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwOTozNzowMlrOGFxuLA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwOTozNzoyMFrOGFxu7w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODcxMDcwMA==", "bodyText": "We don't need the second parameter stateCleaningEnabled. If retentionTime <= 0, then return DISABLED.", "url": "https://github.com/apache/flink/pull/11482#discussion_r408710700", "createdAt": "2020-04-15T09:37:02Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/util/StateTtlConfigUtil.java", "diffHunk": "@@ -0,0 +1,43 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.util;\n+\n+import org.apache.flink.api.common.state.StateTtlConfig;\n+import org.apache.flink.api.common.time.Time;\n+\n+import static org.apache.flink.util.Preconditions.checkArgument;\n+\n+/**\n+ * Utility to create a {@link StateTtlConfig} object.\n+ * */\n+public class StateTtlConfigUtil {\n+\n+\tpublic static StateTtlConfig createTtlConfig(long retentionTime, boolean stateCleaningEnabled) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e69403459fd014a60d06457fc46d1379bece5aae"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODcxMDg5NQ==", "bodyText": "Please also add a Javadoc on this method, esp. what's the unit of retentionTime.", "url": "https://github.com/apache/flink/pull/11482#discussion_r408710895", "createdAt": "2020-04-15T09:37:20Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/util/StateTtlConfigUtil.java", "diffHunk": "@@ -0,0 +1,43 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.util;\n+\n+import org.apache.flink.api.common.state.StateTtlConfig;\n+import org.apache.flink.api.common.time.Time;\n+\n+import static org.apache.flink.util.Preconditions.checkArgument;\n+\n+/**\n+ * Utility to create a {@link StateTtlConfig} object.\n+ * */\n+public class StateTtlConfigUtil {\n+\n+\tpublic static StateTtlConfig createTtlConfig(long retentionTime, boolean stateCleaningEnabled) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODcxMDcwMA=="}, "originalCommit": {"oid": "e69403459fd014a60d06457fc46d1379bece5aae"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNzQ5NTg1OnYy", "diffSide": "RIGHT", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/nodes/physical/stream/StreamExecDeduplicate.scala", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwOTo0MToxOVrOGFx4rQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQxMjowMjo1MVrOGF2gcA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODcxMzM4OQ==", "bodyText": "Could you unify the behavior for non-mini-batch deduplication in this PR?", "url": "https://github.com/apache/flink/pull/11482#discussion_r408713389", "createdAt": "2020-04-15T09:41:19Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/nodes/physical/stream/StreamExecDeduplicate.scala", "diffHunk": "@@ -117,21 +117,23 @@ class StreamExecDeduplicate(\n     val tableConfig = planner.getTableConfig\n     val isMiniBatchEnabled = tableConfig.getConfiguration.getBoolean(\n       ExecutionConfigOptions.TABLE_EXEC_MINIBATCH_ENABLED)\n+    val minRetentionTime = tableConfig.getMinIdleStateRetentionTime\n+    val maxRetentionTime = tableConfig.getMaxIdleStateRetentionTime\n     val operator = if (isMiniBatchEnabled) {\n       val exeConfig = planner.getExecEnv.getConfig\n       val rowSerializer = rowTypeInfo.createSerializer(exeConfig)\n       val processFunction = if (keepLastRow) {\n-        new MiniBatchDeduplicateKeepLastRowFunction(rowTypeInfo, generateRetraction, rowSerializer)\n+        new MiniBatchDeduplicateKeepLastRowFunction(rowTypeInfo, generateRetraction, rowSerializer,\n+          minRetentionTime)\n       } else {\n-        new MiniBatchDeduplicateKeepFirstRowFunction(rowSerializer)\n+        new MiniBatchDeduplicateKeepFirstRowFunction(rowSerializer,\n+          minRetentionTime)\n       }\n       val trigger = AggregateUtil.createMiniBatchTrigger(tableConfig)\n       new KeyedMapBundleOperator(\n         processFunction,\n         trigger)\n     } else {\n-      val minRetentionTime = tableConfig.getMinIdleStateRetentionTime\n-      val maxRetentionTime = tableConfig.getMaxIdleStateRetentionTime\n       val processFunction = if (keepLastRow) {\n         new DeduplicateKeepLastRowFunction(minRetentionTime, maxRetentionTime, rowTypeInfo,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e69403459fd014a60d06457fc46d1379bece5aae"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODc4OTEwNA==", "bodyText": "no problem", "url": "https://github.com/apache/flink/pull/11482#discussion_r408789104", "createdAt": "2020-04-15T12:02:51Z", "author": {"login": "lsyldliu"}, "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/nodes/physical/stream/StreamExecDeduplicate.scala", "diffHunk": "@@ -117,21 +117,23 @@ class StreamExecDeduplicate(\n     val tableConfig = planner.getTableConfig\n     val isMiniBatchEnabled = tableConfig.getConfiguration.getBoolean(\n       ExecutionConfigOptions.TABLE_EXEC_MINIBATCH_ENABLED)\n+    val minRetentionTime = tableConfig.getMinIdleStateRetentionTime\n+    val maxRetentionTime = tableConfig.getMaxIdleStateRetentionTime\n     val operator = if (isMiniBatchEnabled) {\n       val exeConfig = planner.getExecEnv.getConfig\n       val rowSerializer = rowTypeInfo.createSerializer(exeConfig)\n       val processFunction = if (keepLastRow) {\n-        new MiniBatchDeduplicateKeepLastRowFunction(rowTypeInfo, generateRetraction, rowSerializer)\n+        new MiniBatchDeduplicateKeepLastRowFunction(rowTypeInfo, generateRetraction, rowSerializer,\n+          minRetentionTime)\n       } else {\n-        new MiniBatchDeduplicateKeepFirstRowFunction(rowSerializer)\n+        new MiniBatchDeduplicateKeepFirstRowFunction(rowSerializer,\n+          minRetentionTime)\n       }\n       val trigger = AggregateUtil.createMiniBatchTrigger(tableConfig)\n       new KeyedMapBundleOperator(\n         processFunction,\n         trigger)\n     } else {\n-      val minRetentionTime = tableConfig.getMinIdleStateRetentionTime\n-      val maxRetentionTime = tableConfig.getMaxIdleStateRetentionTime\n       val processFunction = if (keepLastRow) {\n         new DeduplicateKeepLastRowFunction(minRetentionTime, maxRetentionTime, rowTypeInfo,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODcxMzM4OQ=="}, "originalCommit": {"oid": "e69403459fd014a60d06457fc46d1379bece5aae"}, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNzUwMDI4OnYy", "diffSide": "RIGHT", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/nodes/physical/stream/StreamExecDeduplicate.scala", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwOTo0MjoyNFrOGFx7Qw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwOTo0MjoyNFrOGFx7Qw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODcxNDA1MQ==", "bodyText": "Please keep parameters in separate lines if it's too long.\nnew MiniBatchDeduplicateKeepLastRowFunction(\n          rowTypeInfo,\n          generateRetraction,\n          rowSerializer,\n          minRetentionTime)", "url": "https://github.com/apache/flink/pull/11482#discussion_r408714051", "createdAt": "2020-04-15T09:42:24Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/nodes/physical/stream/StreamExecDeduplicate.scala", "diffHunk": "@@ -117,21 +117,23 @@ class StreamExecDeduplicate(\n     val tableConfig = planner.getTableConfig\n     val isMiniBatchEnabled = tableConfig.getConfiguration.getBoolean(\n       ExecutionConfigOptions.TABLE_EXEC_MINIBATCH_ENABLED)\n+    val minRetentionTime = tableConfig.getMinIdleStateRetentionTime\n+    val maxRetentionTime = tableConfig.getMaxIdleStateRetentionTime\n     val operator = if (isMiniBatchEnabled) {\n       val exeConfig = planner.getExecEnv.getConfig\n       val rowSerializer = rowTypeInfo.createSerializer(exeConfig)\n       val processFunction = if (keepLastRow) {\n-        new MiniBatchDeduplicateKeepLastRowFunction(rowTypeInfo, generateRetraction, rowSerializer)\n+        new MiniBatchDeduplicateKeepLastRowFunction(rowTypeInfo, generateRetraction, rowSerializer,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e69403459fd014a60d06457fc46d1379bece5aae"}, "originalPosition": 11}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNzUwMTY2OnYy", "diffSide": "RIGHT", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/nodes/physical/stream/StreamExecDeduplicate.scala", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwOTo0Mjo0N1rOGFx8IQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwOTo0Mjo0N1rOGFx8IQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODcxNDI3Mw==", "bodyText": "ditto", "url": "https://github.com/apache/flink/pull/11482#discussion_r408714273", "createdAt": "2020-04-15T09:42:47Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/nodes/physical/stream/StreamExecDeduplicate.scala", "diffHunk": "@@ -117,21 +117,23 @@ class StreamExecDeduplicate(\n     val tableConfig = planner.getTableConfig\n     val isMiniBatchEnabled = tableConfig.getConfiguration.getBoolean(\n       ExecutionConfigOptions.TABLE_EXEC_MINIBATCH_ENABLED)\n+    val minRetentionTime = tableConfig.getMinIdleStateRetentionTime\n+    val maxRetentionTime = tableConfig.getMaxIdleStateRetentionTime\n     val operator = if (isMiniBatchEnabled) {\n       val exeConfig = planner.getExecEnv.getConfig\n       val rowSerializer = rowTypeInfo.createSerializer(exeConfig)\n       val processFunction = if (keepLastRow) {\n-        new MiniBatchDeduplicateKeepLastRowFunction(rowTypeInfo, generateRetraction, rowSerializer)\n+        new MiniBatchDeduplicateKeepLastRowFunction(rowTypeInfo, generateRetraction, rowSerializer,\n+          minRetentionTime)\n       } else {\n-        new MiniBatchDeduplicateKeepFirstRowFunction(rowSerializer)\n+        new MiniBatchDeduplicateKeepFirstRowFunction(rowSerializer,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e69403459fd014a60d06457fc46d1379bece5aae"}, "originalPosition": 15}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNzU5MjE2OnYy", "diffSide": "RIGHT", "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepFirstRowFunctionTest.java", "isResolved": false, "comments": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQxMDowNjozNFrOGFyz5A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwODoxMDoxMFrOGGZkfg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODcyODU0OA==", "bodyText": "cc @Myasuka , is this a correct way to trigger state cleanup?\nIs there a better to make sure the expired state cleaned?", "url": "https://github.com/apache/flink/pull/11482#discussion_r408728548", "createdAt": "2020-04-15T10:06:34Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepFirstRowFunctionTest.java", "diffHunk": "@@ -71,4 +71,41 @@ public void testKeepFirstRowWithGenerateRetraction() throws Exception {\n \t\ttestHarness.close();\n \t}\n \n+\t@Test\n+\tpublic void tesKeepFirstRowWithStateTtl() throws Exception {\n+\t\tMiniBatchDeduplicateKeepFirstRowFunction func = new MiniBatchDeduplicateKeepFirstRowFunction(typeSerializer, minTime.toMilliseconds());\n+\t\tOneInputStreamOperatorTestHarness<BaseRow, BaseRow> testHarness = createTestHarness(func);\n+\t\ttestHarness.setup();\n+\t\ttestHarness.open();\n+\t\ttestHarness.processElement(record(\"book\", 1L, 12));\n+\t\ttestHarness.processElement(record(\"book\", 2L, 11));\n+\t\t// output is empty because bundle not trigger yet.\n+\t\tAssert.assertTrue(testHarness.getOutput().isEmpty());\n+\t\ttestHarness.processElement(record(\"book\", 1L, 13));\n+\n+\t\ttestHarness.setStateTtlProcessingTime(30);\n+\t\t//Incremental cleanup is an eventual clean up, more state access guarantee more expired state cleaned\n+\t\tfor (long i = 3; i < 30; i++) {\n+\t\t\ttestHarness.processElement(record(\"book\", i, 20));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e69403459fd014a60d06457fc46d1379bece5aae"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODgyMzk2OQ==", "bodyText": "Similar toTtlStateTestBase#triggerMoreIncrementalCleanupByOtherOps which is used to trigger the expired state clean eventually.", "url": "https://github.com/apache/flink/pull/11482#discussion_r408823969", "createdAt": "2020-04-15T13:03:14Z", "author": {"login": "lsyldliu"}, "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepFirstRowFunctionTest.java", "diffHunk": "@@ -71,4 +71,41 @@ public void testKeepFirstRowWithGenerateRetraction() throws Exception {\n \t\ttestHarness.close();\n \t}\n \n+\t@Test\n+\tpublic void tesKeepFirstRowWithStateTtl() throws Exception {\n+\t\tMiniBatchDeduplicateKeepFirstRowFunction func = new MiniBatchDeduplicateKeepFirstRowFunction(typeSerializer, minTime.toMilliseconds());\n+\t\tOneInputStreamOperatorTestHarness<BaseRow, BaseRow> testHarness = createTestHarness(func);\n+\t\ttestHarness.setup();\n+\t\ttestHarness.open();\n+\t\ttestHarness.processElement(record(\"book\", 1L, 12));\n+\t\ttestHarness.processElement(record(\"book\", 2L, 11));\n+\t\t// output is empty because bundle not trigger yet.\n+\t\tAssert.assertTrue(testHarness.getOutput().isEmpty());\n+\t\ttestHarness.processElement(record(\"book\", 1L, 13));\n+\n+\t\ttestHarness.setStateTtlProcessingTime(30);\n+\t\t//Incremental cleanup is an eventual clean up, more state access guarantee more expired state cleaned\n+\t\tfor (long i = 3; i < 30; i++) {\n+\t\t\ttestHarness.processElement(record(\"book\", i, 20));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODcyODU0OA=="}, "originalCommit": {"oid": "e69403459fd014a60d06457fc46d1379bece5aae"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODgzMjEzNg==", "bodyText": "My concern is that why the number is 30? Is 30 enough?", "url": "https://github.com/apache/flink/pull/11482#discussion_r408832136", "createdAt": "2020-04-15T13:15:57Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepFirstRowFunctionTest.java", "diffHunk": "@@ -71,4 +71,41 @@ public void testKeepFirstRowWithGenerateRetraction() throws Exception {\n \t\ttestHarness.close();\n \t}\n \n+\t@Test\n+\tpublic void tesKeepFirstRowWithStateTtl() throws Exception {\n+\t\tMiniBatchDeduplicateKeepFirstRowFunction func = new MiniBatchDeduplicateKeepFirstRowFunction(typeSerializer, minTime.toMilliseconds());\n+\t\tOneInputStreamOperatorTestHarness<BaseRow, BaseRow> testHarness = createTestHarness(func);\n+\t\ttestHarness.setup();\n+\t\ttestHarness.open();\n+\t\ttestHarness.processElement(record(\"book\", 1L, 12));\n+\t\ttestHarness.processElement(record(\"book\", 2L, 11));\n+\t\t// output is empty because bundle not trigger yet.\n+\t\tAssert.assertTrue(testHarness.getOutput().isEmpty());\n+\t\ttestHarness.processElement(record(\"book\", 1L, 13));\n+\n+\t\ttestHarness.setStateTtlProcessingTime(30);\n+\t\t//Incremental cleanup is an eventual clean up, more state access guarantee more expired state cleaned\n+\t\tfor (long i = 3; i < 30; i++) {\n+\t\t\ttestHarness.processElement(record(\"book\", i, 20));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODcyODU0OA=="}, "originalCommit": {"oid": "e69403459fd014a60d06457fc46d1379bece5aae"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODg4ODA3Ng==", "bodyText": "In this case, it is enough, I just picked it at random, of course, the bigger the better.", "url": "https://github.com/apache/flink/pull/11482#discussion_r408888076", "createdAt": "2020-04-15T14:31:11Z", "author": {"login": "lsyldliu"}, "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepFirstRowFunctionTest.java", "diffHunk": "@@ -71,4 +71,41 @@ public void testKeepFirstRowWithGenerateRetraction() throws Exception {\n \t\ttestHarness.close();\n \t}\n \n+\t@Test\n+\tpublic void tesKeepFirstRowWithStateTtl() throws Exception {\n+\t\tMiniBatchDeduplicateKeepFirstRowFunction func = new MiniBatchDeduplicateKeepFirstRowFunction(typeSerializer, minTime.toMilliseconds());\n+\t\tOneInputStreamOperatorTestHarness<BaseRow, BaseRow> testHarness = createTestHarness(func);\n+\t\ttestHarness.setup();\n+\t\ttestHarness.open();\n+\t\ttestHarness.processElement(record(\"book\", 1L, 12));\n+\t\ttestHarness.processElement(record(\"book\", 2L, 11));\n+\t\t// output is empty because bundle not trigger yet.\n+\t\tAssert.assertTrue(testHarness.getOutput().isEmpty());\n+\t\ttestHarness.processElement(record(\"book\", 1L, 13));\n+\n+\t\ttestHarness.setStateTtlProcessingTime(30);\n+\t\t//Incremental cleanup is an eventual clean up, more state access guarantee more expired state cleaned\n+\t\tfor (long i = 3; i < 30; i++) {\n+\t\t\ttestHarness.processElement(record(\"book\", i, 20));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODcyODU0OA=="}, "originalCommit": {"oid": "e69403459fd014a60d06457fc46d1379bece5aae"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTMzOTEzNg==", "bodyText": "Since we choose ReturnExpiredIfNotCleanedUp for better performance, and verifying the data has been physically deleted is a topic related to the implementation of clean up strategy for different state backends. For RocksDB, we have to reply on the compaction taken for sst files containing those keys. For Heap KeyedStateBackend, the records to fetch for cleaning up is related to the key groups (how many state map would existed) in one state backend.\nI think state backend module could guarantee the correctness, and this should be out of scope for SQL module. Once state backend changes the implementation of TTL cleanup strategy, verifying the data has been physically deleted in SQL module might be unstable.\nIn a nutshell, we would not need to ensure data has been physically deleted here, verifying the state in MiniBatchDeduplicateKeepFirstRowFunction has been configured with TTL is enough. Otherwise, if we use NeverReturnExpired strategy, things would be much simpler here.", "url": "https://github.com/apache/flink/pull/11482#discussion_r409339136", "createdAt": "2020-04-16T07:28:39Z", "author": {"login": "Myasuka"}, "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepFirstRowFunctionTest.java", "diffHunk": "@@ -71,4 +71,41 @@ public void testKeepFirstRowWithGenerateRetraction() throws Exception {\n \t\ttestHarness.close();\n \t}\n \n+\t@Test\n+\tpublic void tesKeepFirstRowWithStateTtl() throws Exception {\n+\t\tMiniBatchDeduplicateKeepFirstRowFunction func = new MiniBatchDeduplicateKeepFirstRowFunction(typeSerializer, minTime.toMilliseconds());\n+\t\tOneInputStreamOperatorTestHarness<BaseRow, BaseRow> testHarness = createTestHarness(func);\n+\t\ttestHarness.setup();\n+\t\ttestHarness.open();\n+\t\ttestHarness.processElement(record(\"book\", 1L, 12));\n+\t\ttestHarness.processElement(record(\"book\", 2L, 11));\n+\t\t// output is empty because bundle not trigger yet.\n+\t\tAssert.assertTrue(testHarness.getOutput().isEmpty());\n+\t\ttestHarness.processElement(record(\"book\", 1L, 13));\n+\n+\t\ttestHarness.setStateTtlProcessingTime(30);\n+\t\t//Incremental cleanup is an eventual clean up, more state access guarantee more expired state cleaned\n+\t\tfor (long i = 3; i < 30; i++) {\n+\t\t\ttestHarness.processElement(record(\"book\", i, 20));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODcyODU0OA=="}, "originalCommit": {"oid": "e69403459fd014a60d06457fc46d1379bece5aae"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTM0ODQ4OA==", "bodyText": "@Myasuka Thanks for the input.\n+1 to use NeverReturnExpired strategy. We have got other questions from user ML about this too. IMHO, NeverReturnExpired is more straight forward to understand for users.", "url": "https://github.com/apache/flink/pull/11482#discussion_r409348488", "createdAt": "2020-04-16T07:45:18Z", "author": {"login": "libenchao"}, "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepFirstRowFunctionTest.java", "diffHunk": "@@ -71,4 +71,41 @@ public void testKeepFirstRowWithGenerateRetraction() throws Exception {\n \t\ttestHarness.close();\n \t}\n \n+\t@Test\n+\tpublic void tesKeepFirstRowWithStateTtl() throws Exception {\n+\t\tMiniBatchDeduplicateKeepFirstRowFunction func = new MiniBatchDeduplicateKeepFirstRowFunction(typeSerializer, minTime.toMilliseconds());\n+\t\tOneInputStreamOperatorTestHarness<BaseRow, BaseRow> testHarness = createTestHarness(func);\n+\t\ttestHarness.setup();\n+\t\ttestHarness.open();\n+\t\ttestHarness.processElement(record(\"book\", 1L, 12));\n+\t\ttestHarness.processElement(record(\"book\", 2L, 11));\n+\t\t// output is empty because bundle not trigger yet.\n+\t\tAssert.assertTrue(testHarness.getOutput().isEmpty());\n+\t\ttestHarness.processElement(record(\"book\", 1L, 13));\n+\n+\t\ttestHarness.setStateTtlProcessingTime(30);\n+\t\t//Incremental cleanup is an eventual clean up, more state access guarantee more expired state cleaned\n+\t\tfor (long i = 3; i < 30; i++) {\n+\t\t\ttestHarness.processElement(record(\"book\", i, 20));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODcyODU0OA=="}, "originalCommit": {"oid": "e69403459fd014a60d06457fc46d1379bece5aae"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTM1NDk0MA==", "bodyText": "I also discussed with @lincoln-lil and we think NeverReturnExpired is better to give a more deterministic result for operators. +1 to use NeverReturnExpired. Could you update the strategy @lsyldliu ? And we don't need this foreach then.", "url": "https://github.com/apache/flink/pull/11482#discussion_r409354940", "createdAt": "2020-04-16T07:55:42Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepFirstRowFunctionTest.java", "diffHunk": "@@ -71,4 +71,41 @@ public void testKeepFirstRowWithGenerateRetraction() throws Exception {\n \t\ttestHarness.close();\n \t}\n \n+\t@Test\n+\tpublic void tesKeepFirstRowWithStateTtl() throws Exception {\n+\t\tMiniBatchDeduplicateKeepFirstRowFunction func = new MiniBatchDeduplicateKeepFirstRowFunction(typeSerializer, minTime.toMilliseconds());\n+\t\tOneInputStreamOperatorTestHarness<BaseRow, BaseRow> testHarness = createTestHarness(func);\n+\t\ttestHarness.setup();\n+\t\ttestHarness.open();\n+\t\ttestHarness.processElement(record(\"book\", 1L, 12));\n+\t\ttestHarness.processElement(record(\"book\", 2L, 11));\n+\t\t// output is empty because bundle not trigger yet.\n+\t\tAssert.assertTrue(testHarness.getOutput().isEmpty());\n+\t\ttestHarness.processElement(record(\"book\", 1L, 13));\n+\n+\t\ttestHarness.setStateTtlProcessingTime(30);\n+\t\t//Incremental cleanup is an eventual clean up, more state access guarantee more expired state cleaned\n+\t\tfor (long i = 3; i < 30; i++) {\n+\t\t\ttestHarness.processElement(record(\"book\", i, 20));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODcyODU0OA=="}, "originalCommit": {"oid": "e69403459fd014a60d06457fc46d1379bece5aae"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTM1NTIxNA==", "bodyText": "Hi @libenchao , what's the question in user mailing list?", "url": "https://github.com/apache/flink/pull/11482#discussion_r409355214", "createdAt": "2020-04-16T07:56:10Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepFirstRowFunctionTest.java", "diffHunk": "@@ -71,4 +71,41 @@ public void testKeepFirstRowWithGenerateRetraction() throws Exception {\n \t\ttestHarness.close();\n \t}\n \n+\t@Test\n+\tpublic void tesKeepFirstRowWithStateTtl() throws Exception {\n+\t\tMiniBatchDeduplicateKeepFirstRowFunction func = new MiniBatchDeduplicateKeepFirstRowFunction(typeSerializer, minTime.toMilliseconds());\n+\t\tOneInputStreamOperatorTestHarness<BaseRow, BaseRow> testHarness = createTestHarness(func);\n+\t\ttestHarness.setup();\n+\t\ttestHarness.open();\n+\t\ttestHarness.processElement(record(\"book\", 1L, 12));\n+\t\ttestHarness.processElement(record(\"book\", 2L, 11));\n+\t\t// output is empty because bundle not trigger yet.\n+\t\tAssert.assertTrue(testHarness.getOutput().isEmpty());\n+\t\ttestHarness.processElement(record(\"book\", 1L, 13));\n+\n+\t\ttestHarness.setStateTtlProcessingTime(30);\n+\t\t//Incremental cleanup is an eventual clean up, more state access guarantee more expired state cleaned\n+\t\tfor (long i = 3; i < 30; i++) {\n+\t\t\ttestHarness.processElement(record(\"book\", i, 20));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODcyODU0OA=="}, "originalCommit": {"oid": "e69403459fd014a60d06457fc46d1379bece5aae"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTM2MDc4OQ==", "bodyText": "@wuchong a mail titled \"\u5173\u4e8e\u72b6\u6001TTL\" in user-zh ML.", "url": "https://github.com/apache/flink/pull/11482#discussion_r409360789", "createdAt": "2020-04-16T08:05:23Z", "author": {"login": "libenchao"}, "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepFirstRowFunctionTest.java", "diffHunk": "@@ -71,4 +71,41 @@ public void testKeepFirstRowWithGenerateRetraction() throws Exception {\n \t\ttestHarness.close();\n \t}\n \n+\t@Test\n+\tpublic void tesKeepFirstRowWithStateTtl() throws Exception {\n+\t\tMiniBatchDeduplicateKeepFirstRowFunction func = new MiniBatchDeduplicateKeepFirstRowFunction(typeSerializer, minTime.toMilliseconds());\n+\t\tOneInputStreamOperatorTestHarness<BaseRow, BaseRow> testHarness = createTestHarness(func);\n+\t\ttestHarness.setup();\n+\t\ttestHarness.open();\n+\t\ttestHarness.processElement(record(\"book\", 1L, 12));\n+\t\ttestHarness.processElement(record(\"book\", 2L, 11));\n+\t\t// output is empty because bundle not trigger yet.\n+\t\tAssert.assertTrue(testHarness.getOutput().isEmpty());\n+\t\ttestHarness.processElement(record(\"book\", 1L, 13));\n+\n+\t\ttestHarness.setStateTtlProcessingTime(30);\n+\t\t//Incremental cleanup is an eventual clean up, more state access guarantee more expired state cleaned\n+\t\tfor (long i = 3; i < 30; i++) {\n+\t\t\ttestHarness.processElement(record(\"book\", i, 20));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODcyODU0OA=="}, "originalCommit": {"oid": "e69403459fd014a60d06457fc46d1379bece5aae"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTM2MzQ5MA==", "bodyText": "Thanks @libenchao .", "url": "https://github.com/apache/flink/pull/11482#discussion_r409363490", "createdAt": "2020-04-16T08:10:01Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepFirstRowFunctionTest.java", "diffHunk": "@@ -71,4 +71,41 @@ public void testKeepFirstRowWithGenerateRetraction() throws Exception {\n \t\ttestHarness.close();\n \t}\n \n+\t@Test\n+\tpublic void tesKeepFirstRowWithStateTtl() throws Exception {\n+\t\tMiniBatchDeduplicateKeepFirstRowFunction func = new MiniBatchDeduplicateKeepFirstRowFunction(typeSerializer, minTime.toMilliseconds());\n+\t\tOneInputStreamOperatorTestHarness<BaseRow, BaseRow> testHarness = createTestHarness(func);\n+\t\ttestHarness.setup();\n+\t\ttestHarness.open();\n+\t\ttestHarness.processElement(record(\"book\", 1L, 12));\n+\t\ttestHarness.processElement(record(\"book\", 2L, 11));\n+\t\t// output is empty because bundle not trigger yet.\n+\t\tAssert.assertTrue(testHarness.getOutput().isEmpty());\n+\t\ttestHarness.processElement(record(\"book\", 1L, 13));\n+\n+\t\ttestHarness.setStateTtlProcessingTime(30);\n+\t\t//Incremental cleanup is an eventual clean up, more state access guarantee more expired state cleaned\n+\t\tfor (long i = 3; i < 30; i++) {\n+\t\t\ttestHarness.processElement(record(\"book\", i, 20));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODcyODU0OA=="}, "originalCommit": {"oid": "e69403459fd014a60d06457fc46d1379bece5aae"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTM2MzU4Mg==", "bodyText": "Okay, I also prefer to NeverReturnExpired strategy, I choose ReturnExpiredIfNotCleanedUp  because stream-stream join use it currently, I think it should be unified.", "url": "https://github.com/apache/flink/pull/11482#discussion_r409363582", "createdAt": "2020-04-16T08:10:10Z", "author": {"login": "lsyldliu"}, "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepFirstRowFunctionTest.java", "diffHunk": "@@ -71,4 +71,41 @@ public void testKeepFirstRowWithGenerateRetraction() throws Exception {\n \t\ttestHarness.close();\n \t}\n \n+\t@Test\n+\tpublic void tesKeepFirstRowWithStateTtl() throws Exception {\n+\t\tMiniBatchDeduplicateKeepFirstRowFunction func = new MiniBatchDeduplicateKeepFirstRowFunction(typeSerializer, minTime.toMilliseconds());\n+\t\tOneInputStreamOperatorTestHarness<BaseRow, BaseRow> testHarness = createTestHarness(func);\n+\t\ttestHarness.setup();\n+\t\ttestHarness.open();\n+\t\ttestHarness.processElement(record(\"book\", 1L, 12));\n+\t\ttestHarness.processElement(record(\"book\", 2L, 11));\n+\t\t// output is empty because bundle not trigger yet.\n+\t\tAssert.assertTrue(testHarness.getOutput().isEmpty());\n+\t\ttestHarness.processElement(record(\"book\", 1L, 13));\n+\n+\t\ttestHarness.setStateTtlProcessingTime(30);\n+\t\t//Incremental cleanup is an eventual clean up, more state access guarantee more expired state cleaned\n+\t\tfor (long i = 3; i < 30; i++) {\n+\t\t\ttestHarness.processElement(record(\"book\", i, 20));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODcyODU0OA=="}, "originalCommit": {"oid": "e69403459fd014a60d06457fc46d1379bece5aae"}, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0MTQ3MzEzOnYy", "diffSide": "RIGHT", "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/util/StateTtlConfigUtil.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwNzozMDozMVrOGGYJBQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwNzozMDozMVrOGGYJBQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTM0MDE2NQ==", "bodyText": "StateTtlConfig would already check the TTL time larger than 0, this check might not be so useful.", "url": "https://github.com/apache/flink/pull/11482#discussion_r409340165", "createdAt": "2020-04-16T07:30:31Z", "author": {"login": "Myasuka"}, "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/util/StateTtlConfigUtil.java", "diffHunk": "@@ -0,0 +1,43 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.util;\n+\n+import org.apache.flink.api.common.state.StateTtlConfig;\n+import org.apache.flink.api.common.time.Time;\n+\n+import static org.apache.flink.util.Preconditions.checkArgument;\n+\n+/**\n+ * Utility to create a {@link StateTtlConfig} object.\n+ * */\n+public class StateTtlConfigUtil {\n+\n+\tpublic static StateTtlConfig createTtlConfig(long retentionTime, boolean stateCleaningEnabled) {\n+\t\tif (stateCleaningEnabled) {\n+\t\t\tcheckArgument(retentionTime > 0, \"ttl time must be positive when enabling state cleanup\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e69403459fd014a60d06457fc46d1379bece5aae"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0MTUwNzE5OnYy", "diffSide": "RIGHT", "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepLastRowFunction.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwNzo0MDowOFrOGGYd1g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwNzo0MDowOFrOGGYd1g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTM0NTQ5NA==", "bodyText": "No need to check here, just enable a StateTtlConfig.DISABLED is okay.", "url": "https://github.com/apache/flink/pull/11482#discussion_r409345494", "createdAt": "2020-04-16T07:40:08Z", "author": {"login": "Myasuka"}, "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepLastRowFunction.java", "diffHunk": "@@ -59,6 +64,10 @@ public MiniBatchDeduplicateKeepLastRowFunction(BaseRowTypeInfo rowTypeInfo, bool\n \tpublic void open(ExecutionContext ctx) throws Exception {\n \t\tsuper.open(ctx);\n \t\tValueStateDescriptor<BaseRow> stateDesc = new ValueStateDescriptor<>(\"preRowState\", rowTypeInfo);\n+\t\tStateTtlConfig ttlConfig = createTtlConfig(minRetentionTime, stateCleaningEnabled);\n+\t\tif (ttlConfig.isEnabled()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e69403459fd014a60d06457fc46d1379bece5aae"}, "originalPosition": 39}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 678, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}