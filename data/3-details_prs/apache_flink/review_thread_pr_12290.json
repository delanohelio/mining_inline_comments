{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDIxNzc4Mjcw", "number": 12290, "reviewThreads": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNVQwNjo1MDozN1rOD_R1Vg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNVQwNzoyNToxOVrOD_SWVg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY3Njc5MDYyOnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/table/UnsignedTypeConversionITCase.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNVQwNjo1MDozN1rOGZ2bxw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNVQwNjo1MDozN1rOGZ2bxw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTc1OTQzMQ==", "bodyText": "Can we use a random port here?", "url": "https://github.com/apache/flink/pull/12290#discussion_r429759431", "createdAt": "2020-05-25T06:50:37Z", "author": {"login": "wuchong"}, "path": "flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/table/UnsignedTypeConversionITCase.java", "diffHunk": "@@ -0,0 +1,214 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc.table;\n+\n+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.Table;\n+import org.apache.flink.table.api.bridge.java.StreamTableEnvironment;\n+import org.apache.flink.table.planner.runtime.utils.TableEnvUtil;\n+import org.apache.flink.types.Row;\n+\n+import ch.vorburger.mariadb4j.DBConfigurationBuilder;\n+import ch.vorburger.mariadb4j.junit.MariaDB4jRule;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+\n+import static org.apache.flink.table.api.Expressions.row;\n+import static org.junit.Assert.assertArrayEquals;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * Test unsigned type conversion between Flink and JDBC driver mysql, the test underlying use\n+ * MariaDB to mock a DB which use mysql driver too.\n+ */\n+public class UnsignedTypeConversionITCase {\n+\n+\tprivate static final String DEFAULT_DB_NAME = \"test\";\n+\tprivate static final String TABLE_NAME = \"unsigned_test\";\n+\tprivate static final String[] DATA = new String[]{\n+\t\t\"127\",\n+\t\t\"255\",\n+\t\t\"32767\",\n+\t\t\"65535\",\n+\t\t\"2147483647\",\n+\t\t\"4294967295\",\n+\t\t\"9223372036854775807\",\n+\t\t\"18446744073709551615\"};\n+\n+\tprivate StreamTableEnvironment tEnv;\n+\tprivate String dbUrl;\n+\tprivate Connection connection;\n+\n+\t@ClassRule\n+\tpublic static MariaDB4jRule db4jRule = new MariaDB4jRule(\n+\t\tDBConfigurationBuilder.newBuilder().setPort(3306).build(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ae9e1b8939fd8a1c5727dbdb2b7711545e1a97c3"}, "originalPosition": 75}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY3NjgwNjE5OnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/table/UnsignedTypeConversionITCase.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNVQwNjo1NzozM1rOGZ2lew==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxMzo1ODozM1rOGafkHg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTc2MTkxNQ==", "bodyText": "Can be simplify to ?\nString[] result = Lists.newArrayList(collected).stream()\n\t\t\t.map(Row::toString)\n\t\t\t.toArray(String[]::new);\nassertArrayEquals(DATA, result);", "url": "https://github.com/apache/flink/pull/12290#discussion_r429761915", "createdAt": "2020-05-25T06:57:33Z", "author": {"login": "wuchong"}, "path": "flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/table/UnsignedTypeConversionITCase.java", "diffHunk": "@@ -0,0 +1,214 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc.table;\n+\n+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.Table;\n+import org.apache.flink.table.api.bridge.java.StreamTableEnvironment;\n+import org.apache.flink.table.planner.runtime.utils.TableEnvUtil;\n+import org.apache.flink.types.Row;\n+\n+import ch.vorburger.mariadb4j.DBConfigurationBuilder;\n+import ch.vorburger.mariadb4j.junit.MariaDB4jRule;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+\n+import static org.apache.flink.table.api.Expressions.row;\n+import static org.junit.Assert.assertArrayEquals;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * Test unsigned type conversion between Flink and JDBC driver mysql, the test underlying use\n+ * MariaDB to mock a DB which use mysql driver too.\n+ */\n+public class UnsignedTypeConversionITCase {\n+\n+\tprivate static final String DEFAULT_DB_NAME = \"test\";\n+\tprivate static final String TABLE_NAME = \"unsigned_test\";\n+\tprivate static final String[] DATA = new String[]{\n+\t\t\"127\",\n+\t\t\"255\",\n+\t\t\"32767\",\n+\t\t\"65535\",\n+\t\t\"2147483647\",\n+\t\t\"4294967295\",\n+\t\t\"9223372036854775807\",\n+\t\t\"18446744073709551615\"};\n+\n+\tprivate StreamTableEnvironment tEnv;\n+\tprivate String dbUrl;\n+\tprivate Connection connection;\n+\n+\t@ClassRule\n+\tpublic static MariaDB4jRule db4jRule = new MariaDB4jRule(\n+\t\tDBConfigurationBuilder.newBuilder().setPort(3306).build(),\n+\t\tDEFAULT_DB_NAME,\n+\t\tnull);\n+\n+\t@Before\n+\tpublic void setUp() throws SQLException, ClassNotFoundException {\n+\t\tStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n+\t\ttEnv = StreamTableEnvironment.create(env);\n+\t\t//dbUrl: jdbc:mysql://localhost:3306/test\n+\t\tdbUrl = db4jRule.getURL();\n+\t\tconnection = DriverManager.getConnection(dbUrl);\n+\t\t// create mysql table\n+\t\tPreparedStatement ddlStatement = connection.prepareStatement(\"create table \" + TABLE_NAME + \" (\" +\n+\t\t\t\" tiny_c TINYINT,\" +\n+\t\t\t\" tiny_un_c TINYINT UNSIGNED,\" +\n+\t\t\t\" small_c SMALLINT,\" +\n+\t\t\t\" small_un_c SMALLINT UNSIGNED,\" +\n+\t\t\t\" int_c INTEGER ,\" +\n+\t\t\t\" int_un_c INTEGER UNSIGNED,\" +\n+\t\t\t\" big_c BIGINT,\" +\n+\t\t\t\" big_un_c BIGINT UNSIGNED);\");\n+\t\tddlStatement.execute();\n+\n+\t\t// create flink table\n+\t\tString sourceDDL = \"create table jdbc_table (\" +\n+\t\t\t\"tiny_c TINYINT,\" +\n+\t\t\t\"tiny_un_c SMALLINT,\" +\n+\t\t\t\"small_c SMALLINT,\" +\n+\t\t\t\"small_un_c INT,\" +\n+\t\t\t\"int_c INT,\" +\n+\t\t\t\"int_un_c BIGINT,\" +\n+\t\t\t\"big_c BIGINT,\" +\n+\t\t\t\"big_un_c DECIMAL(20, 0)) with(\" +\n+\t\t\t\" 'connector' = 'jdbc',\" +\n+\t\t\t\" 'url' = '\" + dbUrl + \"',\" +\n+\t\t\t\" 'table-name' = '\" + TABLE_NAME + \"'\" +\n+\t\t\t\")\";\n+\t\ttEnv.executeSql(sourceDDL);\n+\t}\n+\n+\t@Test\n+\tpublic void testReadUnsignedType() throws SQLException {\n+\t\t// insert data to db\n+\t\tString insertSql = String.format(\"insert into \" + TABLE_NAME +\n+\t\t\t\"(tiny_c, tiny_un_c, small_c, small_un_c, int_c, int_un_c, big_c, big_un_c) values (\" +\n+\t\t\t\"%s, %s, %s, %s, %s, %s, %s, %s)\", DATA);\n+\t\tPreparedStatement insertStatement = connection.prepareStatement(insertSql);\n+\t\tinsertStatement.execute();\n+\t\t// read data from db\n+\t\tIterator<Row> res = tEnv.executeSql(\"select tiny_c, tiny_un_c, small_c, small_un_c,\" +\n+\t\t\t\" int_c, int_un_c, big_c, big_un_c from jdbc_table\")\n+\t\t\t.collect();\n+\t\tList<Row> actual = new ArrayList<>();\n+\t\twhile (res.hasNext()) {\n+\t\t\tactual.add(res.next());\n+\t\t}\n+\t\tassertTrue(actual.size() == 1);\n+\t\tassertTrue(actual.get(0).getArity() == DATA.length);\n+\t\tString[] expected = new String[DATA.length];\n+\t\tfor (int i = 0; i < DATA.length; i++) {\n+\t\t\texpected[i] = actual.get(0).getField(i).toString();\n+\t\t}\n+\t\tassertArrayEquals(DATA, expected);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ae9e1b8939fd8a1c5727dbdb2b7711545e1a97c3"}, "originalPosition": 137}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDQzMzMxMA==", "bodyText": "maybe not, here only one Row and it contains multi column", "url": "https://github.com/apache/flink/pull/12290#discussion_r430433310", "createdAt": "2020-05-26T13:58:33Z", "author": {"login": "leonardBang"}, "path": "flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/table/UnsignedTypeConversionITCase.java", "diffHunk": "@@ -0,0 +1,214 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc.table;\n+\n+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.Table;\n+import org.apache.flink.table.api.bridge.java.StreamTableEnvironment;\n+import org.apache.flink.table.planner.runtime.utils.TableEnvUtil;\n+import org.apache.flink.types.Row;\n+\n+import ch.vorburger.mariadb4j.DBConfigurationBuilder;\n+import ch.vorburger.mariadb4j.junit.MariaDB4jRule;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+\n+import static org.apache.flink.table.api.Expressions.row;\n+import static org.junit.Assert.assertArrayEquals;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * Test unsigned type conversion between Flink and JDBC driver mysql, the test underlying use\n+ * MariaDB to mock a DB which use mysql driver too.\n+ */\n+public class UnsignedTypeConversionITCase {\n+\n+\tprivate static final String DEFAULT_DB_NAME = \"test\";\n+\tprivate static final String TABLE_NAME = \"unsigned_test\";\n+\tprivate static final String[] DATA = new String[]{\n+\t\t\"127\",\n+\t\t\"255\",\n+\t\t\"32767\",\n+\t\t\"65535\",\n+\t\t\"2147483647\",\n+\t\t\"4294967295\",\n+\t\t\"9223372036854775807\",\n+\t\t\"18446744073709551615\"};\n+\n+\tprivate StreamTableEnvironment tEnv;\n+\tprivate String dbUrl;\n+\tprivate Connection connection;\n+\n+\t@ClassRule\n+\tpublic static MariaDB4jRule db4jRule = new MariaDB4jRule(\n+\t\tDBConfigurationBuilder.newBuilder().setPort(3306).build(),\n+\t\tDEFAULT_DB_NAME,\n+\t\tnull);\n+\n+\t@Before\n+\tpublic void setUp() throws SQLException, ClassNotFoundException {\n+\t\tStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n+\t\ttEnv = StreamTableEnvironment.create(env);\n+\t\t//dbUrl: jdbc:mysql://localhost:3306/test\n+\t\tdbUrl = db4jRule.getURL();\n+\t\tconnection = DriverManager.getConnection(dbUrl);\n+\t\t// create mysql table\n+\t\tPreparedStatement ddlStatement = connection.prepareStatement(\"create table \" + TABLE_NAME + \" (\" +\n+\t\t\t\" tiny_c TINYINT,\" +\n+\t\t\t\" tiny_un_c TINYINT UNSIGNED,\" +\n+\t\t\t\" small_c SMALLINT,\" +\n+\t\t\t\" small_un_c SMALLINT UNSIGNED,\" +\n+\t\t\t\" int_c INTEGER ,\" +\n+\t\t\t\" int_un_c INTEGER UNSIGNED,\" +\n+\t\t\t\" big_c BIGINT,\" +\n+\t\t\t\" big_un_c BIGINT UNSIGNED);\");\n+\t\tddlStatement.execute();\n+\n+\t\t// create flink table\n+\t\tString sourceDDL = \"create table jdbc_table (\" +\n+\t\t\t\"tiny_c TINYINT,\" +\n+\t\t\t\"tiny_un_c SMALLINT,\" +\n+\t\t\t\"small_c SMALLINT,\" +\n+\t\t\t\"small_un_c INT,\" +\n+\t\t\t\"int_c INT,\" +\n+\t\t\t\"int_un_c BIGINT,\" +\n+\t\t\t\"big_c BIGINT,\" +\n+\t\t\t\"big_un_c DECIMAL(20, 0)) with(\" +\n+\t\t\t\" 'connector' = 'jdbc',\" +\n+\t\t\t\" 'url' = '\" + dbUrl + \"',\" +\n+\t\t\t\" 'table-name' = '\" + TABLE_NAME + \"'\" +\n+\t\t\t\")\";\n+\t\ttEnv.executeSql(sourceDDL);\n+\t}\n+\n+\t@Test\n+\tpublic void testReadUnsignedType() throws SQLException {\n+\t\t// insert data to db\n+\t\tString insertSql = String.format(\"insert into \" + TABLE_NAME +\n+\t\t\t\"(tiny_c, tiny_un_c, small_c, small_un_c, int_c, int_un_c, big_c, big_un_c) values (\" +\n+\t\t\t\"%s, %s, %s, %s, %s, %s, %s, %s)\", DATA);\n+\t\tPreparedStatement insertStatement = connection.prepareStatement(insertSql);\n+\t\tinsertStatement.execute();\n+\t\t// read data from db\n+\t\tIterator<Row> res = tEnv.executeSql(\"select tiny_c, tiny_un_c, small_c, small_un_c,\" +\n+\t\t\t\" int_c, int_un_c, big_c, big_un_c from jdbc_table\")\n+\t\t\t.collect();\n+\t\tList<Row> actual = new ArrayList<>();\n+\t\twhile (res.hasNext()) {\n+\t\t\tactual.add(res.next());\n+\t\t}\n+\t\tassertTrue(actual.size() == 1);\n+\t\tassertTrue(actual.get(0).getArity() == DATA.length);\n+\t\tString[] expected = new String[DATA.length];\n+\t\tfor (int i = 0; i < DATA.length; i++) {\n+\t\t\texpected[i] = actual.get(0).getField(i).toString();\n+\t\t}\n+\t\tassertArrayEquals(DATA, expected);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTc2MTkxNQ=="}, "originalCommit": {"oid": "ae9e1b8939fd8a1c5727dbdb2b7711545e1a97c3"}, "originalPosition": 137}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY3NjgxMjk0OnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/table/UnsignedTypeConversionITCase.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNVQwNzowMDozMlrOGZ2pow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNVQwNzowMDozMlrOGZ2pow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTc2Mjk3OQ==", "bodyText": "Could you combine these two tests into one? We can test writing values into the table, and verify the data using jdbc connection. And then test reading values from the table.", "url": "https://github.com/apache/flink/pull/12290#discussion_r429762979", "createdAt": "2020-05-25T07:00:32Z", "author": {"login": "wuchong"}, "path": "flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/table/UnsignedTypeConversionITCase.java", "diffHunk": "@@ -0,0 +1,214 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc.table;\n+\n+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.Table;\n+import org.apache.flink.table.api.bridge.java.StreamTableEnvironment;\n+import org.apache.flink.table.planner.runtime.utils.TableEnvUtil;\n+import org.apache.flink.types.Row;\n+\n+import ch.vorburger.mariadb4j.DBConfigurationBuilder;\n+import ch.vorburger.mariadb4j.junit.MariaDB4jRule;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+\n+import static org.apache.flink.table.api.Expressions.row;\n+import static org.junit.Assert.assertArrayEquals;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * Test unsigned type conversion between Flink and JDBC driver mysql, the test underlying use\n+ * MariaDB to mock a DB which use mysql driver too.\n+ */\n+public class UnsignedTypeConversionITCase {\n+\n+\tprivate static final String DEFAULT_DB_NAME = \"test\";\n+\tprivate static final String TABLE_NAME = \"unsigned_test\";\n+\tprivate static final String[] DATA = new String[]{\n+\t\t\"127\",\n+\t\t\"255\",\n+\t\t\"32767\",\n+\t\t\"65535\",\n+\t\t\"2147483647\",\n+\t\t\"4294967295\",\n+\t\t\"9223372036854775807\",\n+\t\t\"18446744073709551615\"};\n+\n+\tprivate StreamTableEnvironment tEnv;\n+\tprivate String dbUrl;\n+\tprivate Connection connection;\n+\n+\t@ClassRule\n+\tpublic static MariaDB4jRule db4jRule = new MariaDB4jRule(\n+\t\tDBConfigurationBuilder.newBuilder().setPort(3306).build(),\n+\t\tDEFAULT_DB_NAME,\n+\t\tnull);\n+\n+\t@Before\n+\tpublic void setUp() throws SQLException, ClassNotFoundException {\n+\t\tStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n+\t\ttEnv = StreamTableEnvironment.create(env);\n+\t\t//dbUrl: jdbc:mysql://localhost:3306/test\n+\t\tdbUrl = db4jRule.getURL();\n+\t\tconnection = DriverManager.getConnection(dbUrl);\n+\t\t// create mysql table\n+\t\tPreparedStatement ddlStatement = connection.prepareStatement(\"create table \" + TABLE_NAME + \" (\" +\n+\t\t\t\" tiny_c TINYINT,\" +\n+\t\t\t\" tiny_un_c TINYINT UNSIGNED,\" +\n+\t\t\t\" small_c SMALLINT,\" +\n+\t\t\t\" small_un_c SMALLINT UNSIGNED,\" +\n+\t\t\t\" int_c INTEGER ,\" +\n+\t\t\t\" int_un_c INTEGER UNSIGNED,\" +\n+\t\t\t\" big_c BIGINT,\" +\n+\t\t\t\" big_un_c BIGINT UNSIGNED);\");\n+\t\tddlStatement.execute();\n+\n+\t\t// create flink table\n+\t\tString sourceDDL = \"create table jdbc_table (\" +\n+\t\t\t\"tiny_c TINYINT,\" +\n+\t\t\t\"tiny_un_c SMALLINT,\" +\n+\t\t\t\"small_c SMALLINT,\" +\n+\t\t\t\"small_un_c INT,\" +\n+\t\t\t\"int_c INT,\" +\n+\t\t\t\"int_un_c BIGINT,\" +\n+\t\t\t\"big_c BIGINT,\" +\n+\t\t\t\"big_un_c DECIMAL(20, 0)) with(\" +\n+\t\t\t\" 'connector' = 'jdbc',\" +\n+\t\t\t\" 'url' = '\" + dbUrl + \"',\" +\n+\t\t\t\" 'table-name' = '\" + TABLE_NAME + \"'\" +\n+\t\t\t\")\";\n+\t\ttEnv.executeSql(sourceDDL);\n+\t}\n+\n+\t@Test\n+\tpublic void testReadUnsignedType() throws SQLException {\n+\t\t// insert data to db\n+\t\tString insertSql = String.format(\"insert into \" + TABLE_NAME +\n+\t\t\t\"(tiny_c, tiny_un_c, small_c, small_un_c, int_c, int_un_c, big_c, big_un_c) values (\" +\n+\t\t\t\"%s, %s, %s, %s, %s, %s, %s, %s)\", DATA);\n+\t\tPreparedStatement insertStatement = connection.prepareStatement(insertSql);\n+\t\tinsertStatement.execute();\n+\t\t// read data from db\n+\t\tIterator<Row> res = tEnv.executeSql(\"select tiny_c, tiny_un_c, small_c, small_un_c,\" +\n+\t\t\t\" int_c, int_un_c, big_c, big_un_c from jdbc_table\")\n+\t\t\t.collect();\n+\t\tList<Row> actual = new ArrayList<>();\n+\t\twhile (res.hasNext()) {\n+\t\t\tactual.add(res.next());\n+\t\t}\n+\t\tassertTrue(actual.size() == 1);\n+\t\tassertTrue(actual.get(0).getArity() == DATA.length);\n+\t\tString[] expected = new String[DATA.length];\n+\t\tfor (int i = 0; i < DATA.length; i++) {\n+\t\t\texpected[i] = actual.get(0).getField(i).toString();\n+\t\t}\n+\t\tassertArrayEquals(DATA, expected);\n+\t}\n+\n+\t@Test\n+\tpublic void testWriteUnsignedType() throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ae9e1b8939fd8a1c5727dbdb2b7711545e1a97c3"}, "originalPosition": 141}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY3Njg3MjU0OnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/internal/converter/AbstractJdbcRowConverter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNVQwNzoyNDoyNFrOGZ3Ohg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNVQwNzoyNDoyNFrOGZ3Ohg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTc3MjQyMg==", "bodyText": "I suggest to use the precision and scale from the DecimalType instead of hard code 20, 0, otherwise, if users use a 30, 0 in DDL, the value will be corrupt.", "url": "https://github.com/apache/flink/pull/12290#discussion_r429772422", "createdAt": "2020-05-25T07:24:24Z", "author": {"login": "wuchong"}, "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/internal/converter/AbstractJdbcRowConverter.java", "diffHunk": "@@ -114,49 +119,54 @@ protected JdbcDeserializationConverter createNullableInternalConverter(LogicalTy\n \t}\n \n \tprotected JdbcDeserializationConverter wrapIntoNullableInternalConverter(JdbcDeserializationConverter jdbcDeserializationConverter) {\n-\t\treturn v -> {\n-\t\t\tif (v == null) {\n+\t\treturn (val, sqlType, unsigned) -> {\n+\t\t\tif (val == null) {\n \t\t\t\treturn null;\n \t\t\t} else {\n-\t\t\t\treturn jdbcDeserializationConverter.deserialize(v);\n+\t\t\t\treturn jdbcDeserializationConverter.deserialize(val, sqlType, unsigned);\n \t\t\t}\n \t\t};\n \t}\n \n \tprotected JdbcDeserializationConverter createInternalConverter(LogicalType type) {\n \t\tswitch (type.getTypeRoot()) {\n \t\t\tcase NULL:\n-\t\t\t\treturn v -> null;\n+\t\t\t\treturn (val, sqlType, unsigned) -> null;\n \t\t\tcase BOOLEAN:\n-\t\t\tcase TINYINT:\n \t\t\tcase FLOAT:\n \t\t\tcase DOUBLE:\n-\t\t\tcase INTEGER:\n \t\t\tcase INTERVAL_YEAR_MONTH:\n-\t\t\tcase BIGINT:\n \t\t\tcase INTERVAL_DAY_TIME:\n-\t\t\t\treturn v -> v;\n+\t\t\t\treturn (val, sqlType, unsigned) -> val;\n+\t\t\tcase TINYINT:\n+\t\t\t\treturn (val, sqlType, unsigned) -> ((Integer) val).byteValue();\n \t\t\tcase SMALLINT:\n \t\t\t\t// Converter for small type that casts value to int and then return short value, since\n \t\t\t\t// JDBC 1.0 use int type for small values.\n-\t\t\t\treturn v -> (Integer.valueOf(v.toString())).shortValue();\n+\t\t\t\treturn (val, sqlType, unsigned) -> (Integer.valueOf(val.toString())).shortValue();\n+\t\t\tcase INTEGER:\n+\t\t\t\treturn (val, sqlType, unsigned) -> sqlType == Types.SMALLINT && unsigned ? Integer.valueOf(val.toString()) : val;\n+\t\t\tcase BIGINT:\n+\t\t\t\treturn (val, sqlType, unsigned) -> sqlType == Types.INTEGER && unsigned ? Long.valueOf(val.toString()) : val;\n+\t\t\tcase DECIMAL:\n+\t\t\t\tfinal int precision = ((DecimalType) type).getPrecision();\n+\t\t\t\tfinal int scale = ((DecimalType) type).getScale();\n+\t\t\t\t// using decimal(20, 0) to map bigint unsigned\n+\t\t\t\treturn (val, sqlType, unsigned) -> sqlType == Types.BIGINT && unsigned ?\n+\t\t\t\t\tDecimalData.fromBigDecimal(new BigDecimal((BigInteger) val, 0), 20, 0) : DecimalData.fromBigDecimal((BigDecimal) val, precision, scale);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ae9e1b8939fd8a1c5727dbdb2b7711545e1a97c3"}, "originalPosition": 83}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY3Njg3Mzc2OnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/internal/converter/AbstractJdbcRowConverter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNVQwNzoyNDo1MlrOGZ3PTA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNVQwNzoyNDo1MlrOGZ3PTA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTc3MjYyMA==", "bodyText": "Use if (val instanceOf Integer) instead of string parse.", "url": "https://github.com/apache/flink/pull/12290#discussion_r429772620", "createdAt": "2020-05-25T07:24:52Z", "author": {"login": "wuchong"}, "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/internal/converter/AbstractJdbcRowConverter.java", "diffHunk": "@@ -114,49 +119,54 @@ protected JdbcDeserializationConverter createNullableInternalConverter(LogicalTy\n \t}\n \n \tprotected JdbcDeserializationConverter wrapIntoNullableInternalConverter(JdbcDeserializationConverter jdbcDeserializationConverter) {\n-\t\treturn v -> {\n-\t\t\tif (v == null) {\n+\t\treturn (val, sqlType, unsigned) -> {\n+\t\t\tif (val == null) {\n \t\t\t\treturn null;\n \t\t\t} else {\n-\t\t\t\treturn jdbcDeserializationConverter.deserialize(v);\n+\t\t\t\treturn jdbcDeserializationConverter.deserialize(val, sqlType, unsigned);\n \t\t\t}\n \t\t};\n \t}\n \n \tprotected JdbcDeserializationConverter createInternalConverter(LogicalType type) {\n \t\tswitch (type.getTypeRoot()) {\n \t\t\tcase NULL:\n-\t\t\t\treturn v -> null;\n+\t\t\t\treturn (val, sqlType, unsigned) -> null;\n \t\t\tcase BOOLEAN:\n-\t\t\tcase TINYINT:\n \t\t\tcase FLOAT:\n \t\t\tcase DOUBLE:\n-\t\t\tcase INTEGER:\n \t\t\tcase INTERVAL_YEAR_MONTH:\n-\t\t\tcase BIGINT:\n \t\t\tcase INTERVAL_DAY_TIME:\n-\t\t\t\treturn v -> v;\n+\t\t\t\treturn (val, sqlType, unsigned) -> val;\n+\t\t\tcase TINYINT:\n+\t\t\t\treturn (val, sqlType, unsigned) -> ((Integer) val).byteValue();\n \t\t\tcase SMALLINT:\n \t\t\t\t// Converter for small type that casts value to int and then return short value, since\n \t\t\t\t// JDBC 1.0 use int type for small values.\n-\t\t\t\treturn v -> (Integer.valueOf(v.toString())).shortValue();\n+\t\t\t\treturn (val, sqlType, unsigned) -> (Integer.valueOf(val.toString())).shortValue();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ae9e1b8939fd8a1c5727dbdb2b7711545e1a97c3"}, "originalPosition": 73}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY3Njg3NTEwOnYy", "diffSide": "RIGHT", "path": "flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/table/UnsignedTypeConversionITCase.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNVQwNzoyNToxOVrOGZ3QHw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNVQwNzoyNToxOVrOGZ3QHw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTc3MjgzMQ==", "bodyText": "Please extends AbstractTestBase if it is an integration test.", "url": "https://github.com/apache/flink/pull/12290#discussion_r429772831", "createdAt": "2020-05-25T07:25:19Z", "author": {"login": "wuchong"}, "path": "flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/table/UnsignedTypeConversionITCase.java", "diffHunk": "@@ -0,0 +1,214 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc.table;\n+\n+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.Table;\n+import org.apache.flink.table.api.bridge.java.StreamTableEnvironment;\n+import org.apache.flink.table.planner.runtime.utils.TableEnvUtil;\n+import org.apache.flink.types.Row;\n+\n+import ch.vorburger.mariadb4j.DBConfigurationBuilder;\n+import ch.vorburger.mariadb4j.junit.MariaDB4jRule;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+\n+import static org.apache.flink.table.api.Expressions.row;\n+import static org.junit.Assert.assertArrayEquals;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * Test unsigned type conversion between Flink and JDBC driver mysql, the test underlying use\n+ * MariaDB to mock a DB which use mysql driver too.\n+ */\n+public class UnsignedTypeConversionITCase {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ae9e1b8939fd8a1c5727dbdb2b7711545e1a97c3"}, "originalPosition": 55}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4554, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}