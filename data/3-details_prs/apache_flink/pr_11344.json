{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg1MTQ4OTg2", "number": 11344, "title": "[FLINK-16250][python][ml] Add interfaces for PipelineStage and Pipeline", "bodyText": "What is the purpose of the change\nA pipeline is a linear workflow that chains some PipelineStages, e.g., Estimators and Transformers to execute an algorithm.\nThis pull request adds interfaces for PipelineStage and Pipeline. Based on this pr, Python users can write Python Pipelines.\nBrief change log\n\nAdd PipelineStage and Pipeline interfaces, including Transformer, JavaTransformer, Model, JavaModel, Estimator, JavaEstimator.\nAdd tests for testing PipelineStage and Pipeline.\n\nVerifying this change\nThis change added tests and can be verified as follows:\n\nAdds test_pipeline_stage to test functionalities in PipelineStage.\nAdds test_pipeline to test functionalities in Pipeline.\nAdds test_pipeline_it_case integration tests to test Pipeline.\n\nDoes this pull request potentially affect one of the following parts:\n\nDependencies (does it add or upgrade a dependency): (no)\nThe public API, i.e., is any changed class annotated with @Public(Evolving): (yes)\nThe serializers: (no)\nThe runtime per-record code paths (performance sensitive): (no)\nAnything that affects deployment or recovery: JobManager (and its components), Checkpointing, Kubernetes/Yarn/Mesos, ZooKeeper: (no)\nThe S3 file system connector: (no)\n\nDocumentation\n\nDoes this pull request introduce a new feature? (yes)\nIf yes, how is the feature documented? (PythonDocs)", "createdAt": "2020-03-07T14:18:08Z", "url": "https://github.com/apache/flink/pull/11344", "merged": true, "mergeCommit": {"oid": "6f10a23e6bca741a9357a91457eb85a8879a40c2"}, "closed": true, "closedAt": "2020-03-13T01:16:36Z", "author": {"login": "hequn8128"}, "timelineItems": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcLVVU6gH2gAyMzg1MTQ4OTg2Ojk5ZTQ3ZDBiYTFiOTc5OTc1MzFjMmJiYWVlMzIwOTFkZGMxZTM0NGU=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcM-ylEAFqTM3MzczOTcyMw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "99e47d0ba1b97997531c2bbaee32091ddc1e344e", "author": {"user": {"login": "hequn8128", "name": "Hequn Cheng"}}, "url": "https://github.com/apache/flink/commit/99e47d0ba1b97997531c2bbaee32091ddc1e344e", "committedDate": "2020-03-07T14:10:33Z", "message": "[FLINK-16250][python][ml] Add interfaces for PipelineStage and Pipeline"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcxNzM5ODE2", "url": "https://github.com/apache/flink/pull/11344#pullrequestreview-371739816", "createdAt": "2020-03-10T08:02:32Z", "commit": {"oid": "99e47d0ba1b97997531c2bbaee32091ddc1e344e"}, "state": "COMMENTED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQwODowMjozMlrOF0Eftg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQwOTowMTo0MlrOF0GKfA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDE0MzkyNg==", "bodyText": "The return type of self.get_params().to_json() is already string and so the casting could be removed?", "url": "https://github.com/apache/flink/pull/11344#discussion_r390143926", "createdAt": "2020-03-10T08:02:32Z", "author": {"login": "dianfu"}, "path": "flink-python/pyflink/ml/api/base.py", "diffHunk": "@@ -0,0 +1,270 @@\n+################################################################################\n+#  Licensed to the Apache Software Foundation (ASF) under one\n+#  or more contributor license agreements.  See the NOTICE file\n+#  distributed with this work for additional information\n+#  regarding copyright ownership.  The ASF licenses this file\n+#  to you under the Apache License, Version 2.0 (the\n+#  \"License\"); you may not use this file except in compliance\n+#  with the License.  You may obtain a copy of the License at\n+#\n+#      http://www.apache.org/licenses/LICENSE-2.0\n+#\n+#  Unless required by applicable law or agreed to in writing, software\n+#  distributed under the License is distributed on an \"AS IS\" BASIS,\n+#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+#  See the License for the specific language governing permissions and\n+# limitations under the License.\n+################################################################################\n+\n+from abc import ABCMeta, abstractmethod\n+\n+from pyflink.table.table_environment import TableEnvironment\n+from pyflink.table.table import Table\n+from pyflink.ml.api.param import WithParams, Params\n+from py4j.java_gateway import get_field\n+\n+\n+class PipelineStage(WithParams):\n+    \"\"\"\n+    Base class for a stage in a pipeline. The interface is only a concept, and does not have any\n+    actual functionality. Its subclasses must be either Estimator or Transformer. No other classes\n+    should inherit this interface directly.\n+\n+    Each pipeline stage is with parameters, and requires a public empty constructor for\n+    restoration in Pipeline.\n+    \"\"\"\n+\n+    def __init__(self, params=None):\n+        if params is None:\n+            self._params = Params()\n+        else:\n+            self._params = params\n+\n+    def get_params(self) -> Params:\n+        return self._params\n+\n+    def _convert_params_to_java(self, j_pipeline_stage):\n+        for param in self._params._param_map:\n+            java_param = self._make_java_param(j_pipeline_stage, param)\n+            java_value = self._make_java_value(self._params._param_map[param])\n+            j_pipeline_stage.set(java_param, java_value)\n+\n+    @staticmethod\n+    def _make_java_param(j_pipeline_stage, param):\n+        # camel case to snake case\n+        import re\n+        name = re.sub(r'(?<!^)(?=[A-Z])', '_', param.name).upper()\n+        return get_field(j_pipeline_stage, name)\n+\n+    def _make_java_value(self, obj):\n+        \"\"\" Convert Python object into Java \"\"\"\n+        if isinstance(obj, list):\n+            obj = [self._make_java_value(x) for x in obj]\n+        return obj\n+\n+    def to_json(self) -> str:\n+        return str(self.get_params().to_json())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "99e47d0ba1b97997531c2bbaee32091ddc1e344e"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDE1MzM1OQ==", "bodyText": "The Java PipeLine has a constructor which accepts a string of pipelineJson,  should it also be supported in the Python Pipeline?", "url": "https://github.com/apache/flink/pull/11344#discussion_r390153359", "createdAt": "2020-03-10T08:25:18Z", "author": {"login": "dianfu"}, "path": "flink-python/pyflink/ml/api/base.py", "diffHunk": "@@ -0,0 +1,270 @@\n+################################################################################\n+#  Licensed to the Apache Software Foundation (ASF) under one\n+#  or more contributor license agreements.  See the NOTICE file\n+#  distributed with this work for additional information\n+#  regarding copyright ownership.  The ASF licenses this file\n+#  to you under the Apache License, Version 2.0 (the\n+#  \"License\"); you may not use this file except in compliance\n+#  with the License.  You may obtain a copy of the License at\n+#\n+#      http://www.apache.org/licenses/LICENSE-2.0\n+#\n+#  Unless required by applicable law or agreed to in writing, software\n+#  distributed under the License is distributed on an \"AS IS\" BASIS,\n+#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+#  See the License for the specific language governing permissions and\n+# limitations under the License.\n+################################################################################\n+\n+from abc import ABCMeta, abstractmethod\n+\n+from pyflink.table.table_environment import TableEnvironment\n+from pyflink.table.table import Table\n+from pyflink.ml.api.param import WithParams, Params\n+from py4j.java_gateway import get_field\n+\n+\n+class PipelineStage(WithParams):\n+    \"\"\"\n+    Base class for a stage in a pipeline. The interface is only a concept, and does not have any\n+    actual functionality. Its subclasses must be either Estimator or Transformer. No other classes\n+    should inherit this interface directly.\n+\n+    Each pipeline stage is with parameters, and requires a public empty constructor for\n+    restoration in Pipeline.\n+    \"\"\"\n+\n+    def __init__(self, params=None):\n+        if params is None:\n+            self._params = Params()\n+        else:\n+            self._params = params\n+\n+    def get_params(self) -> Params:\n+        return self._params\n+\n+    def _convert_params_to_java(self, j_pipeline_stage):\n+        for param in self._params._param_map:\n+            java_param = self._make_java_param(j_pipeline_stage, param)\n+            java_value = self._make_java_value(self._params._param_map[param])\n+            j_pipeline_stage.set(java_param, java_value)\n+\n+    @staticmethod\n+    def _make_java_param(j_pipeline_stage, param):\n+        # camel case to snake case\n+        import re\n+        name = re.sub(r'(?<!^)(?=[A-Z])', '_', param.name).upper()\n+        return get_field(j_pipeline_stage, name)\n+\n+    def _make_java_value(self, obj):\n+        \"\"\" Convert Python object into Java \"\"\"\n+        if isinstance(obj, list):\n+            obj = [self._make_java_value(x) for x in obj]\n+        return obj\n+\n+    def to_json(self) -> str:\n+        return str(self.get_params().to_json())\n+\n+    def load_json(self, json: str) -> None:\n+        self.get_params().load_json(json)\n+\n+\n+class Transformer(PipelineStage):\n+    \"\"\"\n+    A transformer is a PipelineStage that transforms an input Table to a result Table.\n+    \"\"\"\n+\n+    __metaclass__ = ABCMeta\n+\n+    @abstractmethod\n+    def transform(self, table_env: TableEnvironment, table: Table) -> Table:\n+        \"\"\"\n+        Applies the transformer on the input table, and returns the result table.\n+\n+        :param table_env: the table environment to which the input table is bound.\n+        :param table: the table to be transformed\n+        :returns: the transformed table\n+        \"\"\"\n+        raise NotImplementedError()\n+\n+\n+class JavaTransformer(Transformer):\n+    \"\"\"\n+    Base class for Transformer that wrap Java implementations. Subclasses should\n+    ensure they have the transformer Java object available as j_obj.\n+    \"\"\"\n+\n+    def __init__(self, j_obj):\n+        super().__init__()\n+        self._j_obj = j_obj\n+\n+    def transform(self, table_env: TableEnvironment, table: Table) -> Table:\n+        \"\"\"\n+        Applies the transformer on the input table, and returns the result table.\n+\n+        :param table_env: the table environment to which the input table is bound.\n+        :param table: the table to be transformed\n+        :returns: the transformed table\n+        \"\"\"\n+        self._convert_params_to_java(self._j_obj)\n+        return Table(self._j_obj.transform(table_env._j_tenv, table._j_table))\n+\n+\n+class Model(Transformer):\n+    \"\"\"\n+    Abstract class for models that are fitted by estimators.\n+\n+    A model is an ordinary Transformer except how it is created. While ordinary transformers\n+    are defined by specifying the parameters directly, a model is usually generated by an Estimator\n+    when Estimator.fit(table_env, table) is invoked.\n+    \"\"\"\n+\n+    __metaclass__ = ABCMeta\n+\n+\n+class JavaModel(JavaTransformer, Model):\n+    \"\"\"\n+    Base class for JavaTransformer that wrap Java implementations.\n+    Subclasses should ensure they have the model Java object available as j_obj.\n+    \"\"\"\n+\n+\n+class Estimator(PipelineStage):\n+    \"\"\"\n+    Estimators are PipelineStages responsible for training and generating machine learning models.\n+\n+    The implementations are expected to take an input table as training samples and generate a\n+    Model which fits these samples.\n+    \"\"\"\n+\n+    __metaclass__ = ABCMeta\n+\n+    def fit(self, table_env: TableEnvironment, table: Table) -> Model:\n+        \"\"\"\n+        Train and produce a Model which fits the records in the given Table.\n+\n+        :param table_env: the table environment to which the input table is bound.\n+        :param table: the table with records to train the Model.\n+        :returns: a model trained to fit on the given Table.\n+        \"\"\"\n+        raise NotImplementedError()\n+\n+\n+class JavaEstimator(Estimator):\n+    \"\"\"\n+    Base class for Estimator that wrap Java implementations.\n+    Subclasses should ensure they have the estimator Java object available as j_obj.\n+    \"\"\"\n+\n+    def __init__(self, j_obj):\n+        super().__init__()\n+        self._j_obj = j_obj\n+\n+    def fit(self, table_env: TableEnvironment, table: Table) -> JavaModel:\n+        \"\"\"\n+        Train and produce a Model which fits the records in the given Table.\n+\n+        :param table_env: the table environment to which the input table is bound.\n+        :param table: the table with records to train the Model.\n+        :returns: a model trained to fit on the given Table.\n+        \"\"\"\n+        self._convert_params_to_java(self._j_obj)\n+        return JavaModel(self._j_obj.fit(table_env._j_tenv, table._j_table))\n+\n+\n+class Pipeline(Estimator, Model):\n+    \"\"\"\n+    A pipeline is a linear workflow which chains Estimators and Transformers to\n+    execute an algorithm.\n+\n+    A pipeline itself can either act as an Estimator or a Transformer, depending on the stages it\n+    includes. More specifically:\n+\n+\n+    If a Pipeline has an Estimator, one needs to call `Pipeline.fit(TableEnvironment, Table)`\n+    before use the pipeline as a Transformer. In this case the Pipeline is an Estimator and\n+    can produce a Pipeline as a `Model`.\n+\n+    If a Pipeline has noEstimator, it is a Transformer and can be applied to a Table directly.\n+    In this case, `Pipeline#fit(TableEnvironment, Table)` will simply return the pipeline itself.\n+\n+\n+    In addition, a pipeline can also be used as a PipelineStage in another pipeline, just like an\n+    ordinaryEstimator or Transformer as describe above.\n+    \"\"\"\n+\n+    def __init__(self, stages=None):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "99e47d0ba1b97997531c2bbaee32091ddc1e344e"}, "originalPosition": 196}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDE1Njg0OQ==", "bodyText": "+1", "url": "https://github.com/apache/flink/pull/11344#discussion_r390156849", "createdAt": "2020-03-10T08:32:56Z", "author": {"login": "dianfu"}, "path": "flink-python/pyflink/ml/api/param/base.py", "diffHunk": "@@ -164,17 +164,16 @@ def to_json(self) -> str:\n         import jsonpickle\n         return str(jsonpickle.encode(self._param_map, keys=True))\n \n-    def load_json(self, json: str) -> 'Params':\n+    def load_json(self, json: str) -> None:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "99e47d0ba1b97997531c2bbaee32091ddc1e344e"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDE2MzM4MA==", "bodyText": "trainTable -> train_table", "url": "https://github.com/apache/flink/pull/11344#discussion_r390163380", "createdAt": "2020-03-10T08:46:30Z", "author": {"login": "dianfu"}, "path": "flink-python/pyflink/ml/tests/test_pipeline_it_case.py", "diffHunk": "@@ -0,0 +1,154 @@\n+################################################################################\n+#  Licensed to the Apache Software Foundation (ASF) under one\n+#  or more contributor license agreements.  See the NOTICE file\n+#  distributed with this work for additional information\n+#  regarding copyright ownership.  The ASF licenses this file\n+#  to you under the Apache License, Version 2.0 (the\n+#  \"License\"); you may not use this file except in compliance\n+#  with the License.  You may obtain a copy of the License at\n+#\n+#      http://www.apache.org/licenses/LICENSE-2.0\n+#\n+#  Unless required by applicable law or agreed to in writing, software\n+#  distributed under the License is distributed on an \"AS IS\" BASIS,\n+#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+#  See the License for the specific language governing permissions and\n+# limitations under the License.\n+################################################################################\n+\n+from pyflink.table.types import DataTypes\n+from pyflink.testing.test_case_utils import MLTestCase\n+\n+from pyflink.ml.api import JavaTransformer, Transformer, Estimator, Model, \\\n+    MLEnvironmentFactory, Pipeline\n+from pyflink.ml.lib.param.colname import HasSelectedCols, HasVectorCol,\\\n+    HasPredictionCol, HasOutputCol\n+from pyflink import keyword\n+from pyflink.testing import source_sink_utils\n+from pyflink.java_gateway import get_gateway\n+\n+\n+class WrapperTransformer(JavaTransformer, HasSelectedCols):\n+    \"\"\"\n+    A Transformer wrappers Java Transformer.\n+    \"\"\"\n+    @keyword\n+    def __init__(self, *, selected_cols=None):\n+        _j_obj = get_gateway().jvm.org.apache.flink.ml.pipeline.\\\n+            UserDefinedPipelineStages.SelectColumnTransformer()\n+        super().__init__(_j_obj)\n+        kwargs = self._input_kwargs\n+        self._set(**kwargs)\n+\n+\n+class PythonAddTransformer(Transformer, HasSelectedCols, HasOutputCol):\n+    \"\"\"\n+    A Transformer which is implemented with Python. Output a column\n+    contains the sum of all columns.\n+    \"\"\"\n+    @keyword\n+    def __init__(self, *, selected_cols=None, output_col=None):\n+        super().__init__()\n+        kwargs = self._input_kwargs\n+        self._set(**kwargs)\n+\n+    def transform(self, table_env, table):\n+        input_columns = self.get_selected_cols()\n+        expr = \"+\".join(input_columns)\n+        expr = expr + \" as \" + self.get_output_col()\n+        return table.add_columns(expr)\n+\n+\n+class PythonEstimator(Estimator, HasVectorCol, HasPredictionCol):\n+\n+    def __init__(self):\n+        super().__init__()\n+\n+    def fit(self, table_env, table):\n+        return PythonModel(\n+            table_env,\n+            table.select(\"max(features) as max_sum\"),\n+            self.get_prediction_col())\n+\n+\n+class PythonModel(Model):\n+\n+    def __init__(self, table_env, model_data_table, output_col_name):\n+        self._model_data_table = model_data_table\n+        self._output_col_name = output_col_name\n+        self.max_sum = 0\n+        self.load_model(table_env)\n+\n+    def load_model(self, table_env):\n+        \"\"\"\n+        Train the model to get the max_sum value which is used to predicate data.\n+        \"\"\"\n+        table_sink = source_sink_utils.TestRetractSink([\"max_sum\"], [DataTypes.BIGINT()])\n+        table_env.register_table_sink(\"Model_Results\", table_sink)\n+        self._model_data_table.insert_into(\"Model_Results\")\n+        table_env.execute(\"load model\")\n+        actual = source_sink_utils.results()\n+        self.max_sum = actual.apply(0)\n+\n+    def transform(self, table_env, table):\n+        \"\"\"\n+        Use max_sum to predicate input. Return turn if input value is bigger than max_sum\n+        \"\"\"\n+        return table\\\n+            .add_columns(\"features > {} as {}\".format(self.max_sum, self._output_col_name))\\\n+            .select(\"{}\".format(self._output_col_name))\n+\n+\n+class PythonPipelineTest(MLTestCase):\n+\n+    def test_java_transformer(self):\n+        t_env = MLEnvironmentFactory().get_default().get_stream_table_environment()\n+\n+        table_sink = source_sink_utils.TestAppendSink(\n+            ['a', 'b'], [DataTypes.BIGINT(), DataTypes.BIGINT()])\n+        t_env.register_table_sink(\"TransformerResults\", table_sink)\n+\n+        source_table = t_env.from_elements([(1, 2, 3, 4), (4, 3, 2, 1)], ['a', 'b', 'c', 'd'])\n+        transformer = WrapperTransformer(selected_cols=[\"a\", \"b\"])\n+        transformer\\\n+            .transform(t_env, source_table)\\\n+            .insert_into(\"TransformerResults\")\n+\n+        # execute\n+        t_env.execute('JavaPipelineITCase')\n+        actual = source_sink_utils.results()\n+        self.assert_equals(actual, [\"1,2\", \"4,3\"])\n+\n+    def test_pipeline(self):\n+        t_env = MLEnvironmentFactory().get_default().get_stream_table_environment()\n+        MLEnvironmentFactory().get_default().get_stream_execution_environment().set_parallelism(1)\n+        trainTable = t_env.from_elements(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "99e47d0ba1b97997531c2bbaee32091ddc1e344e"}, "originalPosition": 125}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDE2MzQ3NQ==", "bodyText": "servingTable -> serving_table", "url": "https://github.com/apache/flink/pull/11344#discussion_r390163475", "createdAt": "2020-03-10T08:46:41Z", "author": {"login": "dianfu"}, "path": "flink-python/pyflink/ml/tests/test_pipeline_it_case.py", "diffHunk": "@@ -0,0 +1,154 @@\n+################################################################################\n+#  Licensed to the Apache Software Foundation (ASF) under one\n+#  or more contributor license agreements.  See the NOTICE file\n+#  distributed with this work for additional information\n+#  regarding copyright ownership.  The ASF licenses this file\n+#  to you under the Apache License, Version 2.0 (the\n+#  \"License\"); you may not use this file except in compliance\n+#  with the License.  You may obtain a copy of the License at\n+#\n+#      http://www.apache.org/licenses/LICENSE-2.0\n+#\n+#  Unless required by applicable law or agreed to in writing, software\n+#  distributed under the License is distributed on an \"AS IS\" BASIS,\n+#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+#  See the License for the specific language governing permissions and\n+# limitations under the License.\n+################################################################################\n+\n+from pyflink.table.types import DataTypes\n+from pyflink.testing.test_case_utils import MLTestCase\n+\n+from pyflink.ml.api import JavaTransformer, Transformer, Estimator, Model, \\\n+    MLEnvironmentFactory, Pipeline\n+from pyflink.ml.lib.param.colname import HasSelectedCols, HasVectorCol,\\\n+    HasPredictionCol, HasOutputCol\n+from pyflink import keyword\n+from pyflink.testing import source_sink_utils\n+from pyflink.java_gateway import get_gateway\n+\n+\n+class WrapperTransformer(JavaTransformer, HasSelectedCols):\n+    \"\"\"\n+    A Transformer wrappers Java Transformer.\n+    \"\"\"\n+    @keyword\n+    def __init__(self, *, selected_cols=None):\n+        _j_obj = get_gateway().jvm.org.apache.flink.ml.pipeline.\\\n+            UserDefinedPipelineStages.SelectColumnTransformer()\n+        super().__init__(_j_obj)\n+        kwargs = self._input_kwargs\n+        self._set(**kwargs)\n+\n+\n+class PythonAddTransformer(Transformer, HasSelectedCols, HasOutputCol):\n+    \"\"\"\n+    A Transformer which is implemented with Python. Output a column\n+    contains the sum of all columns.\n+    \"\"\"\n+    @keyword\n+    def __init__(self, *, selected_cols=None, output_col=None):\n+        super().__init__()\n+        kwargs = self._input_kwargs\n+        self._set(**kwargs)\n+\n+    def transform(self, table_env, table):\n+        input_columns = self.get_selected_cols()\n+        expr = \"+\".join(input_columns)\n+        expr = expr + \" as \" + self.get_output_col()\n+        return table.add_columns(expr)\n+\n+\n+class PythonEstimator(Estimator, HasVectorCol, HasPredictionCol):\n+\n+    def __init__(self):\n+        super().__init__()\n+\n+    def fit(self, table_env, table):\n+        return PythonModel(\n+            table_env,\n+            table.select(\"max(features) as max_sum\"),\n+            self.get_prediction_col())\n+\n+\n+class PythonModel(Model):\n+\n+    def __init__(self, table_env, model_data_table, output_col_name):\n+        self._model_data_table = model_data_table\n+        self._output_col_name = output_col_name\n+        self.max_sum = 0\n+        self.load_model(table_env)\n+\n+    def load_model(self, table_env):\n+        \"\"\"\n+        Train the model to get the max_sum value which is used to predicate data.\n+        \"\"\"\n+        table_sink = source_sink_utils.TestRetractSink([\"max_sum\"], [DataTypes.BIGINT()])\n+        table_env.register_table_sink(\"Model_Results\", table_sink)\n+        self._model_data_table.insert_into(\"Model_Results\")\n+        table_env.execute(\"load model\")\n+        actual = source_sink_utils.results()\n+        self.max_sum = actual.apply(0)\n+\n+    def transform(self, table_env, table):\n+        \"\"\"\n+        Use max_sum to predicate input. Return turn if input value is bigger than max_sum\n+        \"\"\"\n+        return table\\\n+            .add_columns(\"features > {} as {}\".format(self.max_sum, self._output_col_name))\\\n+            .select(\"{}\".format(self._output_col_name))\n+\n+\n+class PythonPipelineTest(MLTestCase):\n+\n+    def test_java_transformer(self):\n+        t_env = MLEnvironmentFactory().get_default().get_stream_table_environment()\n+\n+        table_sink = source_sink_utils.TestAppendSink(\n+            ['a', 'b'], [DataTypes.BIGINT(), DataTypes.BIGINT()])\n+        t_env.register_table_sink(\"TransformerResults\", table_sink)\n+\n+        source_table = t_env.from_elements([(1, 2, 3, 4), (4, 3, 2, 1)], ['a', 'b', 'c', 'd'])\n+        transformer = WrapperTransformer(selected_cols=[\"a\", \"b\"])\n+        transformer\\\n+            .transform(t_env, source_table)\\\n+            .insert_into(\"TransformerResults\")\n+\n+        # execute\n+        t_env.execute('JavaPipelineITCase')\n+        actual = source_sink_utils.results()\n+        self.assert_equals(actual, [\"1,2\", \"4,3\"])\n+\n+    def test_pipeline(self):\n+        t_env = MLEnvironmentFactory().get_default().get_stream_table_environment()\n+        MLEnvironmentFactory().get_default().get_stream_execution_environment().set_parallelism(1)\n+        trainTable = t_env.from_elements(\n+            [(1, 2), (1, 4), (1, 0), (10, 2), (10, 4), (10, 0)], ['a', 'b'])\n+        servingTable = t_env.from_elements([(0, 0), (12, 3)], ['a', 'b'])", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "99e47d0ba1b97997531c2bbaee32091ddc1e344e"}, "originalPosition": 127}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDE2NTk1Mg==", "bodyText": "Seems that there is no need to set the parallelism?", "url": "https://github.com/apache/flink/pull/11344#discussion_r390165952", "createdAt": "2020-03-10T08:51:35Z", "author": {"login": "dianfu"}, "path": "flink-python/pyflink/ml/tests/test_pipeline_it_case.py", "diffHunk": "@@ -0,0 +1,154 @@\n+################################################################################\n+#  Licensed to the Apache Software Foundation (ASF) under one\n+#  or more contributor license agreements.  See the NOTICE file\n+#  distributed with this work for additional information\n+#  regarding copyright ownership.  The ASF licenses this file\n+#  to you under the Apache License, Version 2.0 (the\n+#  \"License\"); you may not use this file except in compliance\n+#  with the License.  You may obtain a copy of the License at\n+#\n+#      http://www.apache.org/licenses/LICENSE-2.0\n+#\n+#  Unless required by applicable law or agreed to in writing, software\n+#  distributed under the License is distributed on an \"AS IS\" BASIS,\n+#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+#  See the License for the specific language governing permissions and\n+# limitations under the License.\n+################################################################################\n+\n+from pyflink.table.types import DataTypes\n+from pyflink.testing.test_case_utils import MLTestCase\n+\n+from pyflink.ml.api import JavaTransformer, Transformer, Estimator, Model, \\\n+    MLEnvironmentFactory, Pipeline\n+from pyflink.ml.lib.param.colname import HasSelectedCols, HasVectorCol,\\\n+    HasPredictionCol, HasOutputCol\n+from pyflink import keyword\n+from pyflink.testing import source_sink_utils\n+from pyflink.java_gateway import get_gateway\n+\n+\n+class WrapperTransformer(JavaTransformer, HasSelectedCols):\n+    \"\"\"\n+    A Transformer wrappers Java Transformer.\n+    \"\"\"\n+    @keyword\n+    def __init__(self, *, selected_cols=None):\n+        _j_obj = get_gateway().jvm.org.apache.flink.ml.pipeline.\\\n+            UserDefinedPipelineStages.SelectColumnTransformer()\n+        super().__init__(_j_obj)\n+        kwargs = self._input_kwargs\n+        self._set(**kwargs)\n+\n+\n+class PythonAddTransformer(Transformer, HasSelectedCols, HasOutputCol):\n+    \"\"\"\n+    A Transformer which is implemented with Python. Output a column\n+    contains the sum of all columns.\n+    \"\"\"\n+    @keyword\n+    def __init__(self, *, selected_cols=None, output_col=None):\n+        super().__init__()\n+        kwargs = self._input_kwargs\n+        self._set(**kwargs)\n+\n+    def transform(self, table_env, table):\n+        input_columns = self.get_selected_cols()\n+        expr = \"+\".join(input_columns)\n+        expr = expr + \" as \" + self.get_output_col()\n+        return table.add_columns(expr)\n+\n+\n+class PythonEstimator(Estimator, HasVectorCol, HasPredictionCol):\n+\n+    def __init__(self):\n+        super().__init__()\n+\n+    def fit(self, table_env, table):\n+        return PythonModel(\n+            table_env,\n+            table.select(\"max(features) as max_sum\"),\n+            self.get_prediction_col())\n+\n+\n+class PythonModel(Model):\n+\n+    def __init__(self, table_env, model_data_table, output_col_name):\n+        self._model_data_table = model_data_table\n+        self._output_col_name = output_col_name\n+        self.max_sum = 0\n+        self.load_model(table_env)\n+\n+    def load_model(self, table_env):\n+        \"\"\"\n+        Train the model to get the max_sum value which is used to predicate data.\n+        \"\"\"\n+        table_sink = source_sink_utils.TestRetractSink([\"max_sum\"], [DataTypes.BIGINT()])\n+        table_env.register_table_sink(\"Model_Results\", table_sink)\n+        self._model_data_table.insert_into(\"Model_Results\")\n+        table_env.execute(\"load model\")\n+        actual = source_sink_utils.results()\n+        self.max_sum = actual.apply(0)\n+\n+    def transform(self, table_env, table):\n+        \"\"\"\n+        Use max_sum to predicate input. Return turn if input value is bigger than max_sum\n+        \"\"\"\n+        return table\\\n+            .add_columns(\"features > {} as {}\".format(self.max_sum, self._output_col_name))\\\n+            .select(\"{}\".format(self._output_col_name))\n+\n+\n+class PythonPipelineTest(MLTestCase):\n+\n+    def test_java_transformer(self):\n+        t_env = MLEnvironmentFactory().get_default().get_stream_table_environment()\n+\n+        table_sink = source_sink_utils.TestAppendSink(\n+            ['a', 'b'], [DataTypes.BIGINT(), DataTypes.BIGINT()])\n+        t_env.register_table_sink(\"TransformerResults\", table_sink)\n+\n+        source_table = t_env.from_elements([(1, 2, 3, 4), (4, 3, 2, 1)], ['a', 'b', 'c', 'd'])\n+        transformer = WrapperTransformer(selected_cols=[\"a\", \"b\"])\n+        transformer\\\n+            .transform(t_env, source_table)\\\n+            .insert_into(\"TransformerResults\")\n+\n+        # execute\n+        t_env.execute('JavaPipelineITCase')\n+        actual = source_sink_utils.results()\n+        self.assert_equals(actual, [\"1,2\", \"4,3\"])\n+\n+    def test_pipeline(self):\n+        t_env = MLEnvironmentFactory().get_default().get_stream_table_environment()\n+        MLEnvironmentFactory().get_default().get_stream_execution_environment().set_parallelism(1)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "99e47d0ba1b97997531c2bbaee32091ddc1e344e"}, "originalPosition": 124}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDE2OTU0Nw==", "bodyText": "move the import to the header of this file?", "url": "https://github.com/apache/flink/pull/11344#discussion_r390169547", "createdAt": "2020-03-10T08:58:25Z", "author": {"login": "dianfu"}, "path": "flink-python/pyflink/ml/api/base.py", "diffHunk": "@@ -0,0 +1,270 @@\n+################################################################################\n+#  Licensed to the Apache Software Foundation (ASF) under one\n+#  or more contributor license agreements.  See the NOTICE file\n+#  distributed with this work for additional information\n+#  regarding copyright ownership.  The ASF licenses this file\n+#  to you under the Apache License, Version 2.0 (the\n+#  \"License\"); you may not use this file except in compliance\n+#  with the License.  You may obtain a copy of the License at\n+#\n+#      http://www.apache.org/licenses/LICENSE-2.0\n+#\n+#  Unless required by applicable law or agreed to in writing, software\n+#  distributed under the License is distributed on an \"AS IS\" BASIS,\n+#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+#  See the License for the specific language governing permissions and\n+# limitations under the License.\n+################################################################################\n+\n+from abc import ABCMeta, abstractmethod\n+\n+from pyflink.table.table_environment import TableEnvironment\n+from pyflink.table.table import Table\n+from pyflink.ml.api.param import WithParams, Params\n+from py4j.java_gateway import get_field\n+\n+\n+class PipelineStage(WithParams):\n+    \"\"\"\n+    Base class for a stage in a pipeline. The interface is only a concept, and does not have any\n+    actual functionality. Its subclasses must be either Estimator or Transformer. No other classes\n+    should inherit this interface directly.\n+\n+    Each pipeline stage is with parameters, and requires a public empty constructor for\n+    restoration in Pipeline.\n+    \"\"\"\n+\n+    def __init__(self, params=None):\n+        if params is None:\n+            self._params = Params()\n+        else:\n+            self._params = params\n+\n+    def get_params(self) -> Params:\n+        return self._params\n+\n+    def _convert_params_to_java(self, j_pipeline_stage):\n+        for param in self._params._param_map:\n+            java_param = self._make_java_param(j_pipeline_stage, param)\n+            java_value = self._make_java_value(self._params._param_map[param])\n+            j_pipeline_stage.set(java_param, java_value)\n+\n+    @staticmethod\n+    def _make_java_param(j_pipeline_stage, param):\n+        # camel case to snake case\n+        import re", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "99e47d0ba1b97997531c2bbaee32091ddc1e344e"}, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDE3MTI2MA==", "bodyText": "Should we make it a staticmethod?", "url": "https://github.com/apache/flink/pull/11344#discussion_r390171260", "createdAt": "2020-03-10T09:01:42Z", "author": {"login": "dianfu"}, "path": "flink-python/pyflink/ml/api/base.py", "diffHunk": "@@ -0,0 +1,270 @@\n+################################################################################\n+#  Licensed to the Apache Software Foundation (ASF) under one\n+#  or more contributor license agreements.  See the NOTICE file\n+#  distributed with this work for additional information\n+#  regarding copyright ownership.  The ASF licenses this file\n+#  to you under the Apache License, Version 2.0 (the\n+#  \"License\"); you may not use this file except in compliance\n+#  with the License.  You may obtain a copy of the License at\n+#\n+#      http://www.apache.org/licenses/LICENSE-2.0\n+#\n+#  Unless required by applicable law or agreed to in writing, software\n+#  distributed under the License is distributed on an \"AS IS\" BASIS,\n+#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+#  See the License for the specific language governing permissions and\n+# limitations under the License.\n+################################################################################\n+\n+from abc import ABCMeta, abstractmethod\n+\n+from pyflink.table.table_environment import TableEnvironment\n+from pyflink.table.table import Table\n+from pyflink.ml.api.param import WithParams, Params\n+from py4j.java_gateway import get_field\n+\n+\n+class PipelineStage(WithParams):\n+    \"\"\"\n+    Base class for a stage in a pipeline. The interface is only a concept, and does not have any\n+    actual functionality. Its subclasses must be either Estimator or Transformer. No other classes\n+    should inherit this interface directly.\n+\n+    Each pipeline stage is with parameters, and requires a public empty constructor for\n+    restoration in Pipeline.\n+    \"\"\"\n+\n+    def __init__(self, params=None):\n+        if params is None:\n+            self._params = Params()\n+        else:\n+            self._params = params\n+\n+    def get_params(self) -> Params:\n+        return self._params\n+\n+    def _convert_params_to_java(self, j_pipeline_stage):\n+        for param in self._params._param_map:\n+            java_param = self._make_java_param(j_pipeline_stage, param)\n+            java_value = self._make_java_value(self._params._param_map[param])\n+            j_pipeline_stage.set(java_param, java_value)\n+\n+    @staticmethod\n+    def _make_java_param(j_pipeline_stage, param):\n+        # camel case to snake case\n+        import re\n+        name = re.sub(r'(?<!^)(?=[A-Z])', '_', param.name).upper()\n+        return get_field(j_pipeline_stage, name)\n+\n+    def _make_java_value(self, obj):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "99e47d0ba1b97997531c2bbaee32091ddc1e344e"}, "originalPosition": 59}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8c0c307475110a20b22fa0e4a270fbe6f5b98e29", "author": {"user": {"login": "hequn8128", "name": "Hequn Cheng"}}, "url": "https://github.com/apache/flink/commit/8c0c307475110a20b22fa0e4a270fbe6f5b98e29", "committedDate": "2020-03-10T09:58:07Z", "message": "address comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcyNDU0NzQx", "url": "https://github.com/apache/flink/pull/11344#pullrequestreview-372454741", "createdAt": "2020-03-11T03:26:06Z", "commit": {"oid": "8c0c307475110a20b22fa0e4a270fbe6f5b98e29"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQwMzoyNjowN1rOF0oGJQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQwMzozOToxM1rOF0oQ4Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDcyNzIwNQ==", "bodyText": "was wondering why this java class is created here not earlier. is this only to test how pyflink uses JavaTransformer?\nCan we reuse the FakeTransformer class in TransfomerBaseTest? we can refactor it out or make it public if necessary IMO.", "url": "https://github.com/apache/flink/pull/11344#discussion_r390727205", "createdAt": "2020-03-11T03:26:07Z", "author": {"login": "walterddr"}, "path": "flink-ml-parent/flink-ml-lib/src/test/java/org/apache/flink/ml/pipeline/UserDefinedPipelineStages.java", "diffHunk": "@@ -0,0 +1,54 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.ml.pipeline;\n+\n+import org.apache.flink.ml.api.core.Transformer;\n+import org.apache.flink.ml.api.misc.param.Params;\n+import org.apache.flink.ml.params.shared.colname.HasSelectedCols;\n+import org.apache.flink.table.api.Table;\n+import org.apache.flink.table.api.TableEnvironment;\n+\n+/**\n+ * Util class for testing {@link org.apache.flink.ml.api.core.PipelineStage}.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8c0c307475110a20b22fa0e4a270fbe6f5b98e29"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDcyNzY1Mw==", "bodyText": "These 2 utils are extremely useful, not just to PipelineStage IMO.", "url": "https://github.com/apache/flink/pull/11344#discussion_r390727653", "createdAt": "2020-03-11T03:28:13Z", "author": {"login": "walterddr"}, "path": "flink-python/pyflink/ml/api/base.py", "diffHunk": "@@ -0,0 +1,275 @@\n+################################################################################\n+#  Licensed to the Apache Software Foundation (ASF) under one\n+#  or more contributor license agreements.  See the NOTICE file\n+#  distributed with this work for additional information\n+#  regarding copyright ownership.  The ASF licenses this file\n+#  to you under the Apache License, Version 2.0 (the\n+#  \"License\"); you may not use this file except in compliance\n+#  with the License.  You may obtain a copy of the License at\n+#\n+#      http://www.apache.org/licenses/LICENSE-2.0\n+#\n+#  Unless required by applicable law or agreed to in writing, software\n+#  distributed under the License is distributed on an \"AS IS\" BASIS,\n+#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+#  See the License for the specific language governing permissions and\n+# limitations under the License.\n+################################################################################\n+\n+import re\n+\n+from abc import ABCMeta, abstractmethod\n+\n+from pyflink.table.table_environment import TableEnvironment\n+from pyflink.table.table import Table\n+from pyflink.ml.api.param import WithParams, Params\n+from py4j.java_gateway import get_field\n+\n+\n+class PipelineStage(WithParams):\n+    \"\"\"\n+    Base class for a stage in a pipeline. The interface is only a concept, and does not have any\n+    actual functionality. Its subclasses must be either Estimator or Transformer. No other classes\n+    should inherit this interface directly.\n+\n+    Each pipeline stage is with parameters, and requires a public empty constructor for\n+    restoration in Pipeline.\n+    \"\"\"\n+\n+    def __init__(self, params=None):\n+        if params is None:\n+            self._params = Params()\n+        else:\n+            self._params = params\n+\n+    def get_params(self) -> Params:\n+        return self._params\n+\n+    def _convert_params_to_java(self, j_pipeline_stage):\n+        for param in self._params._param_map:\n+            java_param = self._make_java_param(j_pipeline_stage, param)\n+            java_value = self._make_java_value(self._params._param_map[param])\n+            j_pipeline_stage.set(java_param, java_value)\n+\n+    @staticmethod\n+    def _make_java_param(j_pipeline_stage, param):\n+        # camel case to snake case\n+        name = re.sub(r'(?<!^)(?=[A-Z])', '_', param.name).upper()\n+        return get_field(j_pipeline_stage, name)\n+\n+    @staticmethod\n+    def _make_java_value(obj):\n+        \"\"\" Convert Python object into Java \"\"\"\n+        if isinstance(obj, list):\n+            obj = [PipelineStage._make_java_value(x) for x in obj]\n+        return obj", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8c0c307475110a20b22fa0e4a270fbe6f5b98e29"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDcyOTk1Mw==", "bodyText": "Pipeline should implement Estimator, Model and Transformer I believe", "url": "https://github.com/apache/flink/pull/11344#discussion_r390729953", "createdAt": "2020-03-11T03:39:13Z", "author": {"login": "walterddr"}, "path": "flink-python/pyflink/ml/api/base.py", "diffHunk": "@@ -0,0 +1,275 @@\n+################################################################################\n+#  Licensed to the Apache Software Foundation (ASF) under one\n+#  or more contributor license agreements.  See the NOTICE file\n+#  distributed with this work for additional information\n+#  regarding copyright ownership.  The ASF licenses this file\n+#  to you under the Apache License, Version 2.0 (the\n+#  \"License\"); you may not use this file except in compliance\n+#  with the License.  You may obtain a copy of the License at\n+#\n+#      http://www.apache.org/licenses/LICENSE-2.0\n+#\n+#  Unless required by applicable law or agreed to in writing, software\n+#  distributed under the License is distributed on an \"AS IS\" BASIS,\n+#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+#  See the License for the specific language governing permissions and\n+# limitations under the License.\n+################################################################################\n+\n+import re\n+\n+from abc import ABCMeta, abstractmethod\n+\n+from pyflink.table.table_environment import TableEnvironment\n+from pyflink.table.table import Table\n+from pyflink.ml.api.param import WithParams, Params\n+from py4j.java_gateway import get_field\n+\n+\n+class PipelineStage(WithParams):\n+    \"\"\"\n+    Base class for a stage in a pipeline. The interface is only a concept, and does not have any\n+    actual functionality. Its subclasses must be either Estimator or Transformer. No other classes\n+    should inherit this interface directly.\n+\n+    Each pipeline stage is with parameters, and requires a public empty constructor for\n+    restoration in Pipeline.\n+    \"\"\"\n+\n+    def __init__(self, params=None):\n+        if params is None:\n+            self._params = Params()\n+        else:\n+            self._params = params\n+\n+    def get_params(self) -> Params:\n+        return self._params\n+\n+    def _convert_params_to_java(self, j_pipeline_stage):\n+        for param in self._params._param_map:\n+            java_param = self._make_java_param(j_pipeline_stage, param)\n+            java_value = self._make_java_value(self._params._param_map[param])\n+            j_pipeline_stage.set(java_param, java_value)\n+\n+    @staticmethod\n+    def _make_java_param(j_pipeline_stage, param):\n+        # camel case to snake case\n+        name = re.sub(r'(?<!^)(?=[A-Z])', '_', param.name).upper()\n+        return get_field(j_pipeline_stage, name)\n+\n+    @staticmethod\n+    def _make_java_value(obj):\n+        \"\"\" Convert Python object into Java \"\"\"\n+        if isinstance(obj, list):\n+            obj = [PipelineStage._make_java_value(x) for x in obj]\n+        return obj\n+\n+    def to_json(self) -> str:\n+        return self.get_params().to_json()\n+\n+    def load_json(self, json: str) -> None:\n+        self.get_params().load_json(json)\n+\n+\n+class Transformer(PipelineStage):\n+    \"\"\"\n+    A transformer is a PipelineStage that transforms an input Table to a result Table.\n+    \"\"\"\n+\n+    __metaclass__ = ABCMeta\n+\n+    @abstractmethod\n+    def transform(self, table_env: TableEnvironment, table: Table) -> Table:\n+        \"\"\"\n+        Applies the transformer on the input table, and returns the result table.\n+\n+        :param table_env: the table environment to which the input table is bound.\n+        :param table: the table to be transformed\n+        :returns: the transformed table\n+        \"\"\"\n+        raise NotImplementedError()\n+\n+\n+class JavaTransformer(Transformer):\n+    \"\"\"\n+    Base class for Transformer that wrap Java implementations. Subclasses should\n+    ensure they have the transformer Java object available as j_obj.\n+    \"\"\"\n+\n+    def __init__(self, j_obj):\n+        super().__init__()\n+        self._j_obj = j_obj\n+\n+    def transform(self, table_env: TableEnvironment, table: Table) -> Table:\n+        \"\"\"\n+        Applies the transformer on the input table, and returns the result table.\n+\n+        :param table_env: the table environment to which the input table is bound.\n+        :param table: the table to be transformed\n+        :returns: the transformed table\n+        \"\"\"\n+        self._convert_params_to_java(self._j_obj)\n+        return Table(self._j_obj.transform(table_env._j_tenv, table._j_table))\n+\n+\n+class Model(Transformer):\n+    \"\"\"\n+    Abstract class for models that are fitted by estimators.\n+\n+    A model is an ordinary Transformer except how it is created. While ordinary transformers\n+    are defined by specifying the parameters directly, a model is usually generated by an Estimator\n+    when Estimator.fit(table_env, table) is invoked.\n+    \"\"\"\n+\n+    __metaclass__ = ABCMeta\n+\n+\n+class JavaModel(JavaTransformer, Model):\n+    \"\"\"\n+    Base class for JavaTransformer that wrap Java implementations.\n+    Subclasses should ensure they have the model Java object available as j_obj.\n+    \"\"\"\n+\n+\n+class Estimator(PipelineStage):\n+    \"\"\"\n+    Estimators are PipelineStages responsible for training and generating machine learning models.\n+\n+    The implementations are expected to take an input table as training samples and generate a\n+    Model which fits these samples.\n+    \"\"\"\n+\n+    __metaclass__ = ABCMeta\n+\n+    def fit(self, table_env: TableEnvironment, table: Table) -> Model:\n+        \"\"\"\n+        Train and produce a Model which fits the records in the given Table.\n+\n+        :param table_env: the table environment to which the input table is bound.\n+        :param table: the table with records to train the Model.\n+        :returns: a model trained to fit on the given Table.\n+        \"\"\"\n+        raise NotImplementedError()\n+\n+\n+class JavaEstimator(Estimator):\n+    \"\"\"\n+    Base class for Estimator that wrap Java implementations.\n+    Subclasses should ensure they have the estimator Java object available as j_obj.\n+    \"\"\"\n+\n+    def __init__(self, j_obj):\n+        super().__init__()\n+        self._j_obj = j_obj\n+\n+    def fit(self, table_env: TableEnvironment, table: Table) -> JavaModel:\n+        \"\"\"\n+        Train and produce a Model which fits the records in the given Table.\n+\n+        :param table_env: the table environment to which the input table is bound.\n+        :param table: the table with records to train the Model.\n+        :returns: a model trained to fit on the given Table.\n+        \"\"\"\n+        self._convert_params_to_java(self._j_obj)\n+        return JavaModel(self._j_obj.fit(table_env._j_tenv, table._j_table))\n+\n+\n+class Pipeline(Estimator, Model):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8c0c307475110a20b22fa0e4a270fbe6f5b98e29"}, "originalPosition": 177}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcyNDYwNDYz", "url": "https://github.com/apache/flink/pull/11344#pullrequestreview-372460463", "createdAt": "2020-03-11T03:49:47Z", "commit": {"oid": "8c0c307475110a20b22fa0e4a270fbe6f5b98e29"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQwMzo0OTo0N1rOF0oZnA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQwMzo1NjowMVrOF0oe3w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDczMjE4OA==", "bodyText": "Is this to_json / load_json pair interoperable with java?", "url": "https://github.com/apache/flink/pull/11344#discussion_r390732188", "createdAt": "2020-03-11T03:49:47Z", "author": {"login": "becketqin"}, "path": "flink-python/pyflink/ml/api/base.py", "diffHunk": "@@ -0,0 +1,275 @@\n+################################################################################\n+#  Licensed to the Apache Software Foundation (ASF) under one\n+#  or more contributor license agreements.  See the NOTICE file\n+#  distributed with this work for additional information\n+#  regarding copyright ownership.  The ASF licenses this file\n+#  to you under the Apache License, Version 2.0 (the\n+#  \"License\"); you may not use this file except in compliance\n+#  with the License.  You may obtain a copy of the License at\n+#\n+#      http://www.apache.org/licenses/LICENSE-2.0\n+#\n+#  Unless required by applicable law or agreed to in writing, software\n+#  distributed under the License is distributed on an \"AS IS\" BASIS,\n+#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+#  See the License for the specific language governing permissions and\n+# limitations under the License.\n+################################################################################\n+\n+import re\n+\n+from abc import ABCMeta, abstractmethod\n+\n+from pyflink.table.table_environment import TableEnvironment\n+from pyflink.table.table import Table\n+from pyflink.ml.api.param import WithParams, Params\n+from py4j.java_gateway import get_field\n+\n+\n+class PipelineStage(WithParams):\n+    \"\"\"\n+    Base class for a stage in a pipeline. The interface is only a concept, and does not have any\n+    actual functionality. Its subclasses must be either Estimator or Transformer. No other classes\n+    should inherit this interface directly.\n+\n+    Each pipeline stage is with parameters, and requires a public empty constructor for\n+    restoration in Pipeline.\n+    \"\"\"\n+\n+    def __init__(self, params=None):\n+        if params is None:\n+            self._params = Params()\n+        else:\n+            self._params = params\n+\n+    def get_params(self) -> Params:\n+        return self._params\n+\n+    def _convert_params_to_java(self, j_pipeline_stage):\n+        for param in self._params._param_map:\n+            java_param = self._make_java_param(j_pipeline_stage, param)\n+            java_value = self._make_java_value(self._params._param_map[param])\n+            j_pipeline_stage.set(java_param, java_value)\n+\n+    @staticmethod\n+    def _make_java_param(j_pipeline_stage, param):\n+        # camel case to snake case\n+        name = re.sub(r'(?<!^)(?=[A-Z])', '_', param.name).upper()\n+        return get_field(j_pipeline_stage, name)\n+\n+    @staticmethod\n+    def _make_java_value(obj):\n+        \"\"\" Convert Python object into Java \"\"\"\n+        if isinstance(obj, list):\n+            obj = [PipelineStage._make_java_value(x) for x in obj]\n+        return obj\n+\n+    def to_json(self) -> str:\n+        return self.get_params().to_json()\n+\n+    def load_json(self, json: str) -> None:\n+        self.get_params().load_json(json)\n+\n+\n+class Transformer(PipelineStage):\n+    \"\"\"\n+    A transformer is a PipelineStage that transforms an input Table to a result Table.\n+    \"\"\"\n+\n+    __metaclass__ = ABCMeta\n+\n+    @abstractmethod\n+    def transform(self, table_env: TableEnvironment, table: Table) -> Table:\n+        \"\"\"\n+        Applies the transformer on the input table, and returns the result table.\n+\n+        :param table_env: the table environment to which the input table is bound.\n+        :param table: the table to be transformed\n+        :returns: the transformed table\n+        \"\"\"\n+        raise NotImplementedError()\n+\n+\n+class JavaTransformer(Transformer):\n+    \"\"\"\n+    Base class for Transformer that wrap Java implementations. Subclasses should\n+    ensure they have the transformer Java object available as j_obj.\n+    \"\"\"\n+\n+    def __init__(self, j_obj):\n+        super().__init__()\n+        self._j_obj = j_obj\n+\n+    def transform(self, table_env: TableEnvironment, table: Table) -> Table:\n+        \"\"\"\n+        Applies the transformer on the input table, and returns the result table.\n+\n+        :param table_env: the table environment to which the input table is bound.\n+        :param table: the table to be transformed\n+        :returns: the transformed table\n+        \"\"\"\n+        self._convert_params_to_java(self._j_obj)\n+        return Table(self._j_obj.transform(table_env._j_tenv, table._j_table))\n+\n+\n+class Model(Transformer):\n+    \"\"\"\n+    Abstract class for models that are fitted by estimators.\n+\n+    A model is an ordinary Transformer except how it is created. While ordinary transformers\n+    are defined by specifying the parameters directly, a model is usually generated by an Estimator\n+    when Estimator.fit(table_env, table) is invoked.\n+    \"\"\"\n+\n+    __metaclass__ = ABCMeta\n+\n+\n+class JavaModel(JavaTransformer, Model):\n+    \"\"\"\n+    Base class for JavaTransformer that wrap Java implementations.\n+    Subclasses should ensure they have the model Java object available as j_obj.\n+    \"\"\"\n+\n+\n+class Estimator(PipelineStage):\n+    \"\"\"\n+    Estimators are PipelineStages responsible for training and generating machine learning models.\n+\n+    The implementations are expected to take an input table as training samples and generate a\n+    Model which fits these samples.\n+    \"\"\"\n+\n+    __metaclass__ = ABCMeta\n+\n+    def fit(self, table_env: TableEnvironment, table: Table) -> Model:\n+        \"\"\"\n+        Train and produce a Model which fits the records in the given Table.\n+\n+        :param table_env: the table environment to which the input table is bound.\n+        :param table: the table with records to train the Model.\n+        :returns: a model trained to fit on the given Table.\n+        \"\"\"\n+        raise NotImplementedError()\n+\n+\n+class JavaEstimator(Estimator):\n+    \"\"\"\n+    Base class for Estimator that wrap Java implementations.\n+    Subclasses should ensure they have the estimator Java object available as j_obj.\n+    \"\"\"\n+\n+    def __init__(self, j_obj):\n+        super().__init__()\n+        self._j_obj = j_obj\n+\n+    def fit(self, table_env: TableEnvironment, table: Table) -> JavaModel:\n+        \"\"\"\n+        Train and produce a Model which fits the records in the given Table.\n+\n+        :param table_env: the table environment to which the input table is bound.\n+        :param table: the table with records to train the Model.\n+        :returns: a model trained to fit on the given Table.\n+        \"\"\"\n+        self._convert_params_to_java(self._j_obj)\n+        return JavaModel(self._j_obj.fit(table_env._j_tenv, table._j_table))\n+\n+\n+class Pipeline(Estimator, Model):\n+    \"\"\"\n+    A pipeline is a linear workflow which chains Estimators and Transformers to\n+    execute an algorithm.\n+\n+    A pipeline itself can either act as an Estimator or a Transformer, depending on the stages it\n+    includes. More specifically:\n+\n+\n+    If a Pipeline has an Estimator, one needs to call `Pipeline.fit(TableEnvironment, Table)`\n+    before use the pipeline as a Transformer. In this case the Pipeline is an Estimator and\n+    can produce a Pipeline as a `Model`.\n+\n+    If a Pipeline has noEstimator, it is a Transformer and can be applied to a Table directly.\n+    In this case, `Pipeline#fit(TableEnvironment, Table)` will simply return the pipeline itself.\n+\n+\n+    In addition, a pipeline can also be used as a PipelineStage in another pipeline, just like an\n+    ordinaryEstimator or Transformer as describe above.\n+    \"\"\"\n+\n+    def __init__(self, stages=None, pipeline_json=None):\n+        super().__init__()\n+        self.stages = []\n+        self.last_estimator_index = -1\n+        if stages is not None:\n+            for stage in stages:\n+                self.append_stage(stage)\n+        if pipeline_json is not None:\n+            self.load_json(pipeline_json)\n+\n+    def need_fit(self):\n+        return self.last_estimator_index >= 0\n+\n+    @staticmethod\n+    def _is_stage_need_fit(stage):\n+        return (isinstance(stage, Pipeline) and stage.need_fit()) or \\\n+               ((not isinstance(stage, Pipeline)) and isinstance(stage, Estimator))\n+\n+    def get_stages(self) -> tuple:\n+        # make it immutable by changing to tuple\n+        return tuple(self.stages)\n+\n+    def append_stage(self, stage: PipelineStage) -> 'Pipeline':\n+        if self._is_stage_need_fit(stage):\n+            self.last_estimator_index = len(self.stages)\n+        elif not isinstance(stage, Transformer):\n+            raise RuntimeError(\"All PipelineStages should be Estimator or Transformer!\")\n+        self.stages.append(stage)\n+        return self\n+\n+    def fit(self, t_env: TableEnvironment, input: Table) -> 'Pipeline':\n+        \"\"\"\n+        Train the pipeline to fit on the records in the given Table.\n+\n+        :param t_env: the table environment to which the input table is bound.\n+        :param input: the table with records to train the Pipeline.\n+        :returns: a pipeline with same stages as this Pipeline except all Estimators \\\n+        replaced with their corresponding Models.\n+        \"\"\"\n+        transform_stages = []\n+        for i in range(0, len(self.stages)):\n+            s = self.stages[i]\n+            if i <= self.last_estimator_index:\n+                need_fit = self._is_stage_need_fit(s)\n+                if need_fit:\n+                    t = s.fit(t_env, input)\n+                else:\n+                    t = s\n+                transform_stages.append(t)\n+                input = t.transform(t_env, input)\n+            else:\n+                transform_stages.append(s)\n+        return Pipeline(transform_stages)\n+\n+    def transform(self, t_env: TableEnvironment, input: Table) -> Table:\n+        \"\"\"\n+        Generate a result table by applying all the stages in this pipeline to\n+        the input table in order.\n+\n+        :param t_env: the table environment to which the input table is bound.\n+        :param input: the table to be transformed.\n+        :returns: a result table with all the stages applied to the input tables in order.\n+        \"\"\"\n+        if self.need_fit():\n+            raise RuntimeError(\"Pipeline contains Estimator, need to fit first.\")\n+        for s in self.stages:\n+            input = s.transform(t_env, input)\n+        return input\n+\n+    def to_json(self) -> str:\n+        import jsonpickle\n+        return str(jsonpickle.encode(self, keys=True))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8c0c307475110a20b22fa0e4a270fbe6f5b98e29"}, "originalPosition": 269}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDczMzUzNQ==", "bodyText": "typo -> predictResult", "url": "https://github.com/apache/flink/pull/11344#discussion_r390733535", "createdAt": "2020-03-11T03:56:01Z", "author": {"login": "becketqin"}, "path": "flink-python/pyflink/ml/tests/test_pipeline_it_case.py", "diffHunk": "@@ -0,0 +1,171 @@\n+################################################################################\n+#  Licensed to the Apache Software Foundation (ASF) under one\n+#  or more contributor license agreements.  See the NOTICE file\n+#  distributed with this work for additional information\n+#  regarding copyright ownership.  The ASF licenses this file\n+#  to you under the Apache License, Version 2.0 (the\n+#  \"License\"); you may not use this file except in compliance\n+#  with the License.  You may obtain a copy of the License at\n+#\n+#      http://www.apache.org/licenses/LICENSE-2.0\n+#\n+#  Unless required by applicable law or agreed to in writing, software\n+#  distributed under the License is distributed on an \"AS IS\" BASIS,\n+#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+#  See the License for the specific language governing permissions and\n+# limitations under the License.\n+################################################################################\n+\n+from pyflink.table.types import DataTypes\n+from pyflink.testing.test_case_utils import MLTestCase\n+\n+from pyflink.ml.api import JavaTransformer, Transformer, Estimator, Model, \\\n+    MLEnvironmentFactory, Pipeline\n+from pyflink.ml.api.param import WithParams, ParamInfo, TypeConverters\n+from pyflink.ml.lib.param.colname import HasSelectedCols,\\\n+    HasPredictionCol, HasOutputCol\n+from pyflink import keyword\n+from pyflink.testing import source_sink_utils\n+from pyflink.java_gateway import get_gateway\n+\n+\n+class HasVectorCol(WithParams):\n+    \"\"\"\n+    Trait for parameter vectorColName.\n+    \"\"\"\n+    vector_col = ParamInfo(\n+        \"vectorCol\",\n+        \"Name of a vector column\",\n+        is_optional=False,\n+        type_converter=TypeConverters.to_string)\n+\n+    def set_vector_col(self, v: str) -> 'HasVectorCol':\n+        return super().set(self.vector_col, v)\n+\n+    def get_vector_col(self) -> str:\n+        return super().get(self.vector_col)\n+\n+\n+class WrapperTransformer(JavaTransformer, HasSelectedCols):\n+    \"\"\"\n+    A Transformer wrappers Java Transformer.\n+    \"\"\"\n+    @keyword\n+    def __init__(self, *, selected_cols=None):\n+        _j_obj = get_gateway().jvm.org.apache.flink.ml.pipeline.\\\n+            UserDefinedPipelineStages.SelectColumnTransformer()\n+        super().__init__(_j_obj)\n+        kwargs = self._input_kwargs\n+        self._set(**kwargs)\n+\n+\n+class PythonAddTransformer(Transformer, HasSelectedCols, HasOutputCol):\n+    \"\"\"\n+    A Transformer which is implemented with Python. Output a column\n+    contains the sum of all columns.\n+    \"\"\"\n+    @keyword\n+    def __init__(self, *, selected_cols=None, output_col=None):\n+        super().__init__()\n+        kwargs = self._input_kwargs\n+        self._set(**kwargs)\n+\n+    def transform(self, table_env, table):\n+        input_columns = self.get_selected_cols()\n+        expr = \"+\".join(input_columns)\n+        expr = expr + \" as \" + self.get_output_col()\n+        return table.add_columns(expr)\n+\n+\n+class PythonEstimator(Estimator, HasVectorCol, HasPredictionCol):\n+\n+    def __init__(self):\n+        super().__init__()\n+\n+    def fit(self, table_env, table):\n+        return PythonModel(\n+            table_env,\n+            table.select(\"max(features) as max_sum\"),\n+            self.get_prediction_col())\n+\n+\n+class PythonModel(Model):\n+\n+    def __init__(self, table_env, model_data_table, output_col_name):\n+        self._model_data_table = model_data_table\n+        self._output_col_name = output_col_name\n+        self.max_sum = 0\n+        self.load_model(table_env)\n+\n+    def load_model(self, table_env):\n+        \"\"\"\n+        Train the model to get the max_sum value which is used to predicate data.\n+        \"\"\"\n+        table_sink = source_sink_utils.TestRetractSink([\"max_sum\"], [DataTypes.BIGINT()])\n+        table_env.register_table_sink(\"Model_Results\", table_sink)\n+        self._model_data_table.insert_into(\"Model_Results\")\n+        table_env.execute(\"load model\")\n+        actual = source_sink_utils.results()\n+        self.max_sum = actual.apply(0)\n+\n+    def transform(self, table_env, table):\n+        \"\"\"\n+        Use max_sum to predicate input. Return turn if input value is bigger than max_sum\n+        \"\"\"\n+        return table\\\n+            .add_columns(\"features > {} as {}\".format(self.max_sum, self._output_col_name))\\\n+            .select(\"{}\".format(self._output_col_name))\n+\n+\n+class PythonPipelineTest(MLTestCase):\n+\n+    def test_java_transformer(self):\n+        t_env = MLEnvironmentFactory().get_default().get_stream_table_environment()\n+\n+        table_sink = source_sink_utils.TestAppendSink(\n+            ['a', 'b'], [DataTypes.BIGINT(), DataTypes.BIGINT()])\n+        t_env.register_table_sink(\"TransformerResults\", table_sink)\n+\n+        source_table = t_env.from_elements([(1, 2, 3, 4), (4, 3, 2, 1)], ['a', 'b', 'c', 'd'])\n+        transformer = WrapperTransformer(selected_cols=[\"a\", \"b\"])\n+        transformer\\\n+            .transform(t_env, source_table)\\\n+            .insert_into(\"TransformerResults\")\n+\n+        # execute\n+        t_env.execute('JavaPipelineITCase')\n+        actual = source_sink_utils.results()\n+        self.assert_equals(actual, [\"1,2\", \"4,3\"])\n+\n+    def test_pipeline(self):\n+        t_env = MLEnvironmentFactory().get_default().get_stream_table_environment()\n+        train_table = t_env.from_elements(\n+            [(1, 2), (1, 4), (1, 0), (10, 2), (10, 4), (10, 0)], ['a', 'b'])\n+        serving_table = t_env.from_elements([(0, 0), (12, 3)], ['a', 'b'])\n+\n+        table_sink = source_sink_utils.TestAppendSink(\n+            ['predicate_result'],", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8c0c307475110a20b22fa0e4a270fbe6f5b98e29"}, "originalPosition": 147}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a976d122cca58ccf820360a2bf12a094871d0977", "author": {"user": {"login": "hequn8128", "name": "Hequn Cheng"}}, "url": "https://github.com/apache/flink/commit/a976d122cca58ccf820360a2bf12a094871d0977", "committedDate": "2020-03-11T09:37:55Z", "message": "fix typo"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "95473512ec290d571496fae32da8d33013c8f56e", "author": {"user": {"login": "hequn8128", "name": "Hequn Cheng"}}, "url": "https://github.com/apache/flink/commit/95473512ec290d571496fae32da8d33013c8f56e", "committedDate": "2020-03-12T05:38:13Z", "message": "add Transformer to make it consistent with Java"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzczNjM5NTA4", "url": "https://github.com/apache/flink/pull/11344#pullrequestreview-373639508", "createdAt": "2020-03-12T15:06:05Z", "commit": {"oid": "95473512ec290d571496fae32da8d33013c8f56e"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzczNzM5NzIz", "url": "https://github.com/apache/flink/pull/11344#pullrequestreview-373739723", "createdAt": "2020-03-12T17:02:32Z", "commit": {"oid": "95473512ec290d571496fae32da8d33013c8f56e"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3152, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}