{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE3MzQwMjc4", "number": 12126, "title": "[FLINK-17664][table] Introduce print, blackhole connector in table", "bodyText": "What is the purpose of the change\n\nIntroduce print sink connector\nIntroduce print blackhole connector\n\nprint sink:\n\neasy test for streaming job\nbe very useful in production debugging\n\nDDL:\nCREATE TABLE print_table (\n    ...\n) WITH (\n    'connector' = 'print'\n)\n\nblackhole sink\n\nvery useful for high performance testing of Flink\nI've also run into users trying UDF to output, not sink, so they need\nthis sink as well.\n\nDDL:\nCREATE TABLE blackhole_table (\n    ...\n) WITH (\n    'connector' = 'blackhole'\n)\n\nVerifying this change\nTableSinkFactoryTest\nDoes this pull request potentially affect one of the following parts:\n\nDependencies (does it add or upgrade a dependency): no\nThe public API, i.e., is any changed class annotated with @Public(Evolving): no\nThe serializers: no\nThe runtime per-record code paths (performance sensitive): no\nAnything that affects deployment or recovery: JobManager (and its components), Checkpointing, Kubernetes/Yarn/Mesos, ZooKeeper: no\nThe S3 file system connector: no\n\nDocumentation\n\nDoes this pull request introduce a new feature? (yes)\nIf yes, how is the feature documented? JavaDocs", "createdAt": "2020-05-13T12:49:48Z", "url": "https://github.com/apache/flink/pull/12126", "merged": true, "mergeCommit": {"oid": "3e820a6adbd87348fb8de87421ad4693bc19aab9"}, "closed": true, "closedAt": "2020-05-15T09:07:39Z", "author": {"login": "JingsongLi"}, "timelineItems": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcg6g8QAFqTQxMTAxNjQyOQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABchbqS2gBqjMzMzk0NzExNjY=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDExMDE2NDI5", "url": "https://github.com/apache/flink/pull/12126#pullrequestreview-411016429", "createdAt": "2020-05-13T15:01:20Z", "commit": {"oid": "9a9ae4d5447c18f4cd593e7f0ea115698026db4f"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QxNTowMToyMFrOGU178Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QxNToxOTo1N1rOGU2zWg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUwODQwMQ==", "bodyText": "Put it under org.apache.flink.table.factories ? I think org.apache.flink.table.sinks is a legacy package, all the interfaces/classes under this package will be removed in the future.", "url": "https://github.com/apache/flink/pull/12126#discussion_r424508401", "createdAt": "2020-05-13T15:01:20Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-api-java-bridge/src/main/java/org/apache/flink/table/sinks/BlackHoleTableSinkFactory.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.sinks;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a9ae4d5447c18f4cd593e7f0ea115698026db4f"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUwODU3Ng==", "bodyText": "I'm not sure what should the annotation be. But I think either @Internal or @PublicEvolving. The reason for @PublicEvolving is the connector options are public API and we should keep backward-compatible.", "url": "https://github.com/apache/flink/pull/12126#discussion_r424508576", "createdAt": "2020-05-13T15:01:35Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-api-java-bridge/src/main/java/org/apache/flink/table/sinks/BlackHoleTableSinkFactory.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.sinks;\n+\n+import org.apache.flink.annotation.Experimental;\n+import org.apache.flink.configuration.ConfigOption;\n+import org.apache.flink.streaming.api.functions.sink.SinkFunction;\n+import org.apache.flink.table.connector.ChangelogMode;\n+import org.apache.flink.table.connector.sink.DynamicTableSink;\n+import org.apache.flink.table.connector.sink.SinkFunctionProvider;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.factories.DynamicTableSinkFactory;\n+import org.apache.flink.types.RowKind;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+/**\n+ * Black hole table sink factory.\n+ */\n+@Experimental", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a9ae4d5447c18f4cd593e7f0ea115698026db4f"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUxMDE1OA==", "bodyText": "Could you add more description about this connector? The behavior and how to use it.", "url": "https://github.com/apache/flink/pull/12126#discussion_r424510158", "createdAt": "2020-05-13T15:03:37Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-api-java-bridge/src/main/java/org/apache/flink/table/sinks/BlackHoleTableSinkFactory.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.sinks;\n+\n+import org.apache.flink.annotation.Experimental;\n+import org.apache.flink.configuration.ConfigOption;\n+import org.apache.flink.streaming.api.functions.sink.SinkFunction;\n+import org.apache.flink.table.connector.ChangelogMode;\n+import org.apache.flink.table.connector.sink.DynamicTableSink;\n+import org.apache.flink.table.connector.sink.SinkFunctionProvider;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.factories.DynamicTableSinkFactory;\n+import org.apache.flink.types.RowKind;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+/**\n+ * Black hole table sink factory.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a9ae4d5447c18f4cd593e7f0ea115698026db4f"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUxMzkzNA==", "bodyText": "Could you extract this SinkFunction as a static class?", "url": "https://github.com/apache/flink/pull/12126#discussion_r424513934", "createdAt": "2020-05-13T15:08:32Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-api-java-bridge/src/main/java/org/apache/flink/table/sinks/PrintTableSinkFactory.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.sinks;\n+\n+import org.apache.flink.annotation.Experimental;\n+import org.apache.flink.configuration.ConfigOption;\n+import org.apache.flink.streaming.api.functions.sink.SinkFunction;\n+import org.apache.flink.table.connector.ChangelogMode;\n+import org.apache.flink.table.connector.sink.DynamicTableSink;\n+import org.apache.flink.table.connector.sink.SinkFunctionProvider;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.factories.DynamicTableSinkFactory;\n+import org.apache.flink.table.types.DataType;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+/**\n+ * Print table sink factory.\n+ */\n+@Experimental\n+public class PrintTableSinkFactory implements DynamicTableSinkFactory {\n+\n+\tpublic static final String IDENTIFIER = \"print\";\n+\n+\t@Override\n+\tpublic String factoryIdentifier() {\n+\t\treturn IDENTIFIER;\n+\t}\n+\n+\t@Override\n+\tpublic Set<ConfigOption<?>> requiredOptions() {\n+\t\treturn new HashSet<>();\n+\t}\n+\n+\t@Override\n+\tpublic Set<ConfigOption<?>> optionalOptions() {\n+\t\treturn new HashSet<>();\n+\t}\n+\n+\t@Override\n+\tpublic DynamicTableSink createDynamicTableSink(Context context) {\n+\t\treturn new PrintSink(context.getCatalogTable().getSchema().toRowDataType());\n+\t}\n+\n+\tstatic class PrintSink implements DynamicTableSink {\n+\n+\t\tprivate final DataType type;\n+\n+\t\tprivate PrintSink(DataType type) {\n+\t\t\tthis.type = type;\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic ChangelogMode getChangelogMode(ChangelogMode requestedMode) {\n+\t\t\treturn requestedMode;\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic SinkRuntimeProvider getSinkRuntimeProvider(DynamicTableSink.Context context) {\n+\t\t\tDataStructureConverter converter = context.createDataStructureConverter(type);\n+\t\t\treturn SinkFunctionProvider.of(new SinkFunction<RowData>() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a9ae4d5447c18f4cd593e7f0ea115698026db4f"}, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUxNDc3Mg==", "bodyText": "Use toPhysicalRowDataType to ignore the computed columns.", "url": "https://github.com/apache/flink/pull/12126#discussion_r424514772", "createdAt": "2020-05-13T15:09:40Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-api-java-bridge/src/main/java/org/apache/flink/table/sinks/PrintTableSinkFactory.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.sinks;\n+\n+import org.apache.flink.annotation.Experimental;\n+import org.apache.flink.configuration.ConfigOption;\n+import org.apache.flink.streaming.api.functions.sink.SinkFunction;\n+import org.apache.flink.table.connector.ChangelogMode;\n+import org.apache.flink.table.connector.sink.DynamicTableSink;\n+import org.apache.flink.table.connector.sink.SinkFunctionProvider;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.factories.DynamicTableSinkFactory;\n+import org.apache.flink.table.types.DataType;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+/**\n+ * Print table sink factory.\n+ */\n+@Experimental\n+public class PrintTableSinkFactory implements DynamicTableSinkFactory {\n+\n+\tpublic static final String IDENTIFIER = \"print\";\n+\n+\t@Override\n+\tpublic String factoryIdentifier() {\n+\t\treturn IDENTIFIER;\n+\t}\n+\n+\t@Override\n+\tpublic Set<ConfigOption<?>> requiredOptions() {\n+\t\treturn new HashSet<>();\n+\t}\n+\n+\t@Override\n+\tpublic Set<ConfigOption<?>> optionalOptions() {\n+\t\treturn new HashSet<>();\n+\t}\n+\n+\t@Override\n+\tpublic DynamicTableSink createDynamicTableSink(Context context) {\n+\t\treturn new PrintSink(context.getCatalogTable().getSchema().toRowDataType());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a9ae4d5447c18f4cd593e7f0ea115698026db4f"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUxNTMwNA==", "bodyText": "I think we can ignore the change flags when this print sink works in insert-only mode. The falg is verbose and meaning less for batch processing.", "url": "https://github.com/apache/flink/pull/12126#discussion_r424515304", "createdAt": "2020-05-13T15:10:20Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-api-java-bridge/src/main/java/org/apache/flink/table/sinks/PrintTableSinkFactory.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.sinks;\n+\n+import org.apache.flink.annotation.Experimental;\n+import org.apache.flink.configuration.ConfigOption;\n+import org.apache.flink.streaming.api.functions.sink.SinkFunction;\n+import org.apache.flink.table.connector.ChangelogMode;\n+import org.apache.flink.table.connector.sink.DynamicTableSink;\n+import org.apache.flink.table.connector.sink.SinkFunctionProvider;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.factories.DynamicTableSinkFactory;\n+import org.apache.flink.table.types.DataType;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+/**\n+ * Print table sink factory.\n+ */\n+@Experimental\n+public class PrintTableSinkFactory implements DynamicTableSinkFactory {\n+\n+\tpublic static final String IDENTIFIER = \"print\";\n+\n+\t@Override\n+\tpublic String factoryIdentifier() {\n+\t\treturn IDENTIFIER;\n+\t}\n+\n+\t@Override\n+\tpublic Set<ConfigOption<?>> requiredOptions() {\n+\t\treturn new HashSet<>();\n+\t}\n+\n+\t@Override\n+\tpublic Set<ConfigOption<?>> optionalOptions() {\n+\t\treturn new HashSet<>();\n+\t}\n+\n+\t@Override\n+\tpublic DynamicTableSink createDynamicTableSink(Context context) {\n+\t\treturn new PrintSink(context.getCatalogTable().getSchema().toRowDataType());\n+\t}\n+\n+\tstatic class PrintSink implements DynamicTableSink {\n+\n+\t\tprivate final DataType type;\n+\n+\t\tprivate PrintSink(DataType type) {\n+\t\t\tthis.type = type;\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic ChangelogMode getChangelogMode(ChangelogMode requestedMode) {\n+\t\t\treturn requestedMode;\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic SinkRuntimeProvider getSinkRuntimeProvider(DynamicTableSink.Context context) {\n+\t\t\tDataStructureConverter converter = context.createDataStructureConverter(type);\n+\t\t\treturn SinkFunctionProvider.of(new SinkFunction<RowData>() {\n+\t\t\t\t@Override\n+\t\t\t\tpublic void invoke(RowData value, Context context) {\n+\t\t\t\t\tObject row = converter.toExternal(value);\n+\t\t\t\t\tSystem.out.println(\n+\t\t\t\t\t\t\tvalue.getRowKind().shortString() + \"(\" + row + \")\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a9ae4d5447c18f4cd593e7f0ea115698026db4f"}, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUxNjU3MQ==", "bodyText": "This class name is too generic.. It sounds like a test for TableSinkFactory. Could you split this class into BlackHoleTableSinkITCase and PrintTableSinkITCase?\nCould you use DDL to test the connectors to have more coverage? I think it's fine to move the ITCase into blink planner.", "url": "https://github.com/apache/flink/pull/12126#discussion_r424516571", "createdAt": "2020-05-13T15:12:05Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-api-java-bridge/src/test/java/org/apache/flink/table/sinks/TableSinkFactoryTest.java", "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.sinks;\n+\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.streaming.api.functions.sink.SinkFunction;\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.catalog.CatalogTableImpl;\n+import org.apache.flink.table.catalog.ObjectIdentifier;\n+import org.apache.flink.table.connector.sink.DynamicTableSink;\n+import org.apache.flink.table.connector.sink.SinkFunctionProvider;\n+import org.apache.flink.table.data.GenericRowData;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.data.StringData;\n+import org.apache.flink.table.factories.FactoryUtil;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.types.Row;\n+\n+import org.junit.Test;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * Tests for {@link BlackHoleTableSinkFactory} and {@link PrintTableSinkFactory}.\n+ */\n+public class TableSinkFactoryTest {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a9ae4d5447c18f4cd593e7f0ea115698026db4f"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUxODk2Ng==", "bodyText": "A way to verify print sink is delegating System.out to an OutputStream, then we can verify the outputs in the OutputStream. You can take PrintSinkFunctionTest as an example.", "url": "https://github.com/apache/flink/pull/12126#discussion_r424518966", "createdAt": "2020-05-13T15:15:09Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-api-java-bridge/src/test/java/org/apache/flink/table/sinks/TableSinkFactoryTest.java", "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.sinks;\n+\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.streaming.api.functions.sink.SinkFunction;\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.catalog.CatalogTableImpl;\n+import org.apache.flink.table.catalog.ObjectIdentifier;\n+import org.apache.flink.table.connector.sink.DynamicTableSink;\n+import org.apache.flink.table.connector.sink.SinkFunctionProvider;\n+import org.apache.flink.table.data.GenericRowData;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.data.StringData;\n+import org.apache.flink.table.factories.FactoryUtil;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.types.Row;\n+\n+import org.junit.Test;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * Tests for {@link BlackHoleTableSinkFactory} and {@link PrintTableSinkFactory}.\n+ */\n+public class TableSinkFactoryTest {\n+\n+\tprivate static final TableSchema TEST_SCHEMA = TableSchema.builder()\n+\t\t.field(\"f0\", DataTypes.STRING())\n+\t\t.field(\"f1\", DataTypes.BIGINT())\n+\t\t.field(\"f2\", DataTypes.BIGINT())\n+\t\t.build();\n+\n+\t@Test\n+\tpublic void testPrint() throws Exception {\n+\t\tMap<String, String> properties = new HashMap<>();\n+\t\tproperties.put(\"connector\", \"print\");\n+\n+\t\tDynamicTableSink sink = FactoryUtil.createTableSink(\n+\t\t\t\tnull,\n+\t\t\t\tObjectIdentifier.of(\"\", \"\", \"\"),\n+\t\t\t\tnew CatalogTableImpl(TEST_SCHEMA, properties, \"\"),\n+\t\t\t\tnew Configuration(),\n+\t\t\t\tThread.currentThread().getContextClassLoader());\n+\n+\t\tassertTrue(sink instanceof PrintTableSinkFactory.PrintSink);\n+\t\tDynamicTableSink.Context context = new DynamicTableSink.Context() {\n+\n+\t\t\t@Override\n+\t\t\tpublic boolean isBounded() {\n+\t\t\t\treturn false;\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic DynamicTableSink.DataStructureConverter createDataStructureConverter(\n+\t\t\t\t\tDataType consumedDataType) {\n+\t\t\t\treturn new DynamicTableSink.DataStructureConverter() {\n+\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic void open(Context context) {\n+\t\t\t\t\t}\n+\n+\t\t\t\t\t@Nullable\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic Object toExternal(@Nullable Object o) {\n+\t\t\t\t\t\tRowData row = (RowData) o;\n+\t\t\t\t\t\treturn o == null ? null : Row.of(row.getInt(0), row.getString(1).toString());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a9ae4d5447c18f4cd593e7f0ea115698026db4f"}, "originalPosition": 89}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUyMDQwOA==", "bodyText": "Use DiscardingSink.", "url": "https://github.com/apache/flink/pull/12126#discussion_r424520408", "createdAt": "2020-05-13T15:17:04Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-api-java-bridge/src/main/java/org/apache/flink/table/sinks/BlackHoleTableSinkFactory.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.sinks;\n+\n+import org.apache.flink.annotation.Experimental;\n+import org.apache.flink.configuration.ConfigOption;\n+import org.apache.flink.streaming.api.functions.sink.SinkFunction;\n+import org.apache.flink.table.connector.ChangelogMode;\n+import org.apache.flink.table.connector.sink.DynamicTableSink;\n+import org.apache.flink.table.connector.sink.SinkFunctionProvider;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.factories.DynamicTableSinkFactory;\n+import org.apache.flink.types.RowKind;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+/**\n+ * Black hole table sink factory.\n+ */\n+@Experimental\n+public class BlackHoleTableSinkFactory implements DynamicTableSinkFactory {\n+\n+\tpublic static final String IDENTIFIER = \"blackhole\";\n+\n+\t@Override\n+\tpublic String factoryIdentifier() {\n+\t\treturn IDENTIFIER;\n+\t}\n+\n+\t@Override\n+\tpublic Set<ConfigOption<?>> requiredOptions() {\n+\t\treturn new HashSet<>();\n+\t}\n+\n+\t@Override\n+\tpublic Set<ConfigOption<?>> optionalOptions() {\n+\t\treturn new HashSet<>();\n+\t}\n+\n+\t@Override\n+\tpublic DynamicTableSink createDynamicTableSink(Context context) {\n+\t\treturn new BlackHoleSink();\n+\t}\n+\n+\tstatic class BlackHoleSink implements DynamicTableSink {\n+\n+\t\t@Override\n+\t\tpublic ChangelogMode getChangelogMode(ChangelogMode requestedMode) {\n+\t\t\tChangelogMode.Builder builder = ChangelogMode.newBuilder();\n+\t\t\tfor (RowKind kind : requestedMode.getContainedKinds()) {\n+\t\t\t\tif (kind != RowKind.UPDATE_BEFORE) {\n+\t\t\t\t\tbuilder.addContainedKind(kind);\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\treturn builder.build();\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic SinkRuntimeProvider getSinkRuntimeProvider(DynamicTableSink.Context context) {\n+\t\t\treturn SinkFunctionProvider.of(new SinkFunction<RowData>() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a9ae4d5447c18f4cd593e7f0ea115698026db4f"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUyMjU4Ng==", "bodyText": "Could you add all the data types? Especially for print sink. We should make sure all the types are displayed as expected.", "url": "https://github.com/apache/flink/pull/12126#discussion_r424522586", "createdAt": "2020-05-13T15:19:57Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-api-java-bridge/src/test/java/org/apache/flink/table/sinks/TableSinkFactoryTest.java", "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.sinks;\n+\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.streaming.api.functions.sink.SinkFunction;\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.catalog.CatalogTableImpl;\n+import org.apache.flink.table.catalog.ObjectIdentifier;\n+import org.apache.flink.table.connector.sink.DynamicTableSink;\n+import org.apache.flink.table.connector.sink.SinkFunctionProvider;\n+import org.apache.flink.table.data.GenericRowData;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.data.StringData;\n+import org.apache.flink.table.factories.FactoryUtil;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.types.Row;\n+\n+import org.junit.Test;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * Tests for {@link BlackHoleTableSinkFactory} and {@link PrintTableSinkFactory}.\n+ */\n+public class TableSinkFactoryTest {\n+\n+\tprivate static final TableSchema TEST_SCHEMA = TableSchema.builder()\n+\t\t.field(\"f0\", DataTypes.STRING())\n+\t\t.field(\"f1\", DataTypes.BIGINT())\n+\t\t.field(\"f2\", DataTypes.BIGINT())\n+\t\t.build();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a9ae4d5447c18f4cd593e7f0ea115698026db4f"}, "originalPosition": 54}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDExNTA2OTY1", "url": "https://github.com/apache/flink/pull/12126#pullrequestreview-411506965", "createdAt": "2020-05-14T06:46:12Z", "commit": {"oid": "9c81e3b4619274d580ade40a3d37f57abedc0192"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNFQwNjo0NjoxM1rOGVOLQg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNFQwNjo1NTo1MlrOGVOb9Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDkwNTUzOA==", "bodyText": "Do we need this?", "url": "https://github.com/apache/flink/pull/12126#discussion_r424905538", "createdAt": "2020-05-14T06:46:13Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-api-java-bridge/src/main/java/org/apache/flink/table/factories/PrintTableSinkFactory.java", "diffHunk": "@@ -0,0 +1,171 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.factories;\n+\n+import org.apache.flink.annotation.PublicEvolving;\n+import org.apache.flink.api.common.functions.util.PrintSinkOutputWriter;\n+import org.apache.flink.configuration.ConfigOption;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.configuration.ReadableConfig;\n+import org.apache.flink.streaming.api.functions.sink.PrintSinkFunction;\n+import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;\n+import org.apache.flink.streaming.api.operators.StreamingRuntimeContext;\n+import org.apache.flink.table.connector.ChangelogMode;\n+import org.apache.flink.table.connector.sink.DynamicTableSink;\n+import org.apache.flink.table.connector.sink.DynamicTableSink.DataStructureConverter;\n+import org.apache.flink.table.connector.sink.SinkFunctionProvider;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.types.DataType;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+import static org.apache.flink.configuration.ConfigOptions.key;\n+\n+/**\n+ * Print table sink factory writing every row to the standard output or standard error stream.\n+ * It is designed for:\n+ * - easy test for streaming job.\n+ * - very useful in production debugging.\n+ *\n+ * <p>\n+ * Four possible format options:\n+ *\t{@code PRINT_IDENTIFIER}:taskId> output  <- {@code PRINT_IDENTIFIER} provided, parallelism > 1\n+ *\t{@code PRINT_IDENTIFIER}> output         <- {@code PRINT_IDENTIFIER} provided, parallelism == 1\n+ *  taskId> output         \t\t\t\t   <- no {@code PRINT_IDENTIFIER} provided, parallelism > 1\n+ *  output                 \t\t\t\t   <- no {@code PRINT_IDENTIFIER} provided, parallelism == 1\n+ * </p>\n+ *\n+ * <p>output string format is \"$RowKind(f0,f1,f2...)\", example is: \"+I(1,1)\".\n+ */\n+@PublicEvolving\n+public class PrintTableSinkFactory implements DynamicTableSinkFactory {\n+\n+\tpublic static final String IDENTIFIER = \"print\";\n+\n+\tpublic static final ConfigOption<String> PRINT_IDENTIFIER = key(\"print-identifier\")\n+\t\t\t.stringType()\n+\t\t\t.noDefaultValue()\n+\t\t\t.withDescription(\"Message that identify print and is prefixed to the output of the value.\");\n+\n+\tpublic static final ConfigOption<Boolean> STANDARD_ERROR = key(\"standard-error\")\n+\t\t\t.booleanType()\n+\t\t\t.defaultValue(false)\n+\t\t\t.withDescription(\"True, if the format should print to standard error instead of standard out.\");\n+\n+\t@Override\n+\tpublic String factoryIdentifier() {\n+\t\treturn IDENTIFIER;\n+\t}\n+\n+\t@Override\n+\tpublic Set<ConfigOption<?>> requiredOptions() {\n+\t\treturn new HashSet<>();\n+\t}\n+\n+\t@Override\n+\tpublic Set<ConfigOption<?>> optionalOptions() {\n+\t\tSet<ConfigOption<?>> options = new HashSet<>();\n+\t\toptions.add(PRINT_IDENTIFIER);\n+\t\toptions.add(STANDARD_ERROR);\n+\t\treturn options;\n+\t}\n+\n+\t@Override\n+\tpublic DynamicTableSink createDynamicTableSink(Context context) {\n+\t\tFactoryUtil.TableFactoryHelper helper = FactoryUtil.createTableFactoryHelper(this, context);\n+\t\thelper.validate();\n+\t\tReadableConfig options = helper.getOptions();\n+\t\treturn new PrintSink(\n+\t\t\t\tcontext.getCatalogTable().getSchema().toPhysicalRowDataType(),\n+\t\t\t\toptions.get(PRINT_IDENTIFIER),\n+\t\t\t\toptions.get(STANDARD_ERROR));\n+\t}\n+\n+\tprivate static class PrintSink implements DynamicTableSink {\n+\n+\t\tprivate final DataType type;\n+\t\tprivate final String printIdentifier;\n+\t\tprivate final boolean stdErr;\n+\n+\t\tprivate PrintSink(DataType type, String printIdentifier, boolean stdErr) {\n+\t\t\tthis.type = type;\n+\t\t\tthis.printIdentifier = printIdentifier;\n+\t\t\tthis.stdErr = stdErr;\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic ChangelogMode getChangelogMode(ChangelogMode requestedMode) {\n+\t\t\treturn requestedMode;\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic SinkRuntimeProvider getSinkRuntimeProvider(DynamicTableSink.Context context) {\n+\t\t\tDataStructureConverter converter = context.createDataStructureConverter(type);\n+\t\t\treturn SinkFunctionProvider.of(new RowDataPrintFunction(converter, printIdentifier, stdErr));\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic DynamicTableSink copy() {\n+\t\t\treturn new PrintSink(type, printIdentifier, stdErr);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic String asSummaryString() {\n+\t\t\treturn \"Print to \" + (stdErr ? \"System.err\" : \"System.out\");\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Implementation of the SinkFunction converting {@link RowData} to string and\n+\t * passing to {@link PrintSinkFunction}.\n+\t */\n+\tprivate static class RowDataPrintFunction extends RichSinkFunction<RowData> {\n+\n+\t\tprivate static final long serialVersionUID = 1L;\n+\n+\t\tprivate final DataStructureConverter converter;\n+\t\tprivate final PrintSinkOutputWriter<String> writer;\n+\n+\t\tprivate RowDataPrintFunction(\n+\t\t\t\tDataStructureConverter converter, String printIdentifier, boolean stdErr) {\n+\t\t\tthis.converter = converter;\n+\t\t\tthis.writer = new PrintSinkOutputWriter<>(printIdentifier, stdErr);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void open(Configuration parameters) throws Exception {\n+\t\t\tsuper.open(parameters);\n+\t\t\tStreamingRuntimeContext context = (StreamingRuntimeContext) getRuntimeContext();\n+\t\t\twriter.open(context.getIndexOfThisSubtask(), context.getNumberOfParallelSubtasks());\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void invoke(RowData value, Context context) {\n+\t\t\tString rowKind = value.getRowKind().shortString();\n+\t\t\tObject data = converter.toExternal(value);\n+\t\t\twriter.write(rowKind + \"(\" + data + \")\");\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic String toString() {\n+\t\t\treturn writer.toString();\n+\t\t}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c81e3b4619274d580ade40a3d37f57abedc0192"}, "originalPosition": 169}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDkwNzY3NQ==", "bodyText": "Can be simplified to tEnv().fromValues(row(1, 1.1), row(2, 2.2)), use the org.apache.flink.table.api.Expressions.row.", "url": "https://github.com/apache/flink/pull/12126#discussion_r424907675", "createdAt": "2020-05-14T06:51:06Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/runtime/stream/table/BlackHoleITCase.java", "diffHunk": "@@ -0,0 +1,42 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.runtime.stream.table;\n+\n+import org.apache.flink.table.factories.BlackHoleTableSinkFactory;\n+import org.apache.flink.table.planner.runtime.utils.StreamingTestBase;\n+import org.apache.flink.types.Row;\n+\n+import org.junit.Test;\n+\n+import java.util.Arrays;\n+\n+/**\n+ * End to end tests for {@link BlackHoleTableSinkFactory}.\n+ */\n+public class BlackHoleITCase extends StreamingTestBase {\n+\n+\t@Test\n+\tpublic void testTypes() {\n+\t\ttEnv().executeSql(\n+\t\t\t\t\"create table blackhole_t (f0 int, f1 double) with ('connector' = 'blackhole')\");\n+\t\texecInsertTableAndWaitResult(\n+\t\t\t\ttEnv().fromValues(Arrays.asList(Row.of(1, 1.1), Row.of(2, 2.2))),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c81e3b4619274d580ade40a3d37f57abedc0192"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDkwODk3MQ==", "bodyText": "Could you format the DDL a bit? Put every column at a single line.", "url": "https://github.com/apache/flink/pull/12126#discussion_r424908971", "createdAt": "2020-05-14T06:54:00Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/runtime/stream/table/PrintITCase.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.runtime.stream.table;\n+\n+import org.apache.flink.table.factories.PrintTableSinkFactory;\n+import org.apache.flink.table.planner.runtime.utils.StreamingTestBase;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.types.Row;\n+\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.PrintStream;\n+import java.math.BigDecimal;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+/**\n+ * End to end tests for {@link PrintTableSinkFactory}.\n+ */\n+public class PrintITCase extends StreamingTestBase {\n+\n+\tprivate final PrintStream originalSystemOut = System.out;\n+\tprivate final PrintStream originalSystemErr = System.err;\n+\n+\tprivate final ByteArrayOutputStream arrayOutputStream = new ByteArrayOutputStream();\n+\tprivate final ByteArrayOutputStream arrayErrorStream = new ByteArrayOutputStream();\n+\n+\t@Before\n+\tpublic void setUp() {\n+\t\tSystem.setOut(new PrintStream(arrayOutputStream));\n+\t\tSystem.setErr(new PrintStream(arrayErrorStream));\n+\t}\n+\n+\t@After\n+\tpublic void tearDown() {\n+\t\tif (System.out != originalSystemOut) {\n+\t\t\tSystem.out.close();\n+\t\t}\n+\t\tif (System.err != originalSystemErr) {\n+\t\t\tSystem.err.close();\n+\t\t}\n+\t\tSystem.setOut(originalSystemOut);\n+\t\tSystem.setErr(originalSystemErr);\n+\t}\n+\n+\t@Test\n+\tpublic void testTypes() {\n+\t\ttest(false);\n+\t}\n+\n+\t@Test\n+\tpublic void testStandardError() {\n+\t\ttest(true);\n+\t}\n+\n+\tprivate void test(boolean standardError) {\n+\t\ttEnv().executeSql(String.format(\"create table print_t (\" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c81e3b4619274d580ade40a3d37f57abedc0192"}, "originalPosition": 81}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDkwOTU0Mg==", "bodyText": "PrintConnectorITCase? Make it more explicitly it's not a print IT case for Table#executeInsert()#print().", "url": "https://github.com/apache/flink/pull/12126#discussion_r424909542", "createdAt": "2020-05-14T06:55:19Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/runtime/stream/table/PrintITCase.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.runtime.stream.table;\n+\n+import org.apache.flink.table.factories.PrintTableSinkFactory;\n+import org.apache.flink.table.planner.runtime.utils.StreamingTestBase;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.types.Row;\n+\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.PrintStream;\n+import java.math.BigDecimal;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+/**\n+ * End to end tests for {@link PrintTableSinkFactory}.\n+ */\n+public class PrintITCase extends StreamingTestBase {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c81e3b4619274d580ade40a3d37f57abedc0192"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDkwOTgxMw==", "bodyText": "BlackHoleConnectorITCase?", "url": "https://github.com/apache/flink/pull/12126#discussion_r424909813", "createdAt": "2020-05-14T06:55:52Z", "author": {"login": "wuchong"}, "path": "flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/runtime/stream/table/BlackHoleITCase.java", "diffHunk": "@@ -0,0 +1,42 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.runtime.stream.table;\n+\n+import org.apache.flink.table.factories.BlackHoleTableSinkFactory;\n+import org.apache.flink.table.planner.runtime.utils.StreamingTestBase;\n+import org.apache.flink.types.Row;\n+\n+import org.junit.Test;\n+\n+import java.util.Arrays;\n+\n+/**\n+ * End to end tests for {@link BlackHoleTableSinkFactory}.\n+ */\n+public class BlackHoleITCase extends StreamingTestBase {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c81e3b4619274d580ade40a3d37f57abedc0192"}, "originalPosition": 32}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDExODE2MTE2", "url": "https://github.com/apache/flink/pull/12126#pullrequestreview-411816116", "createdAt": "2020-05-14T13:42:22Z", "commit": {"oid": "e0424357b5bdcdef98752a9b4a08f2557981e23e"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "aaf5a890b85f9fb1e1511ca3c53549afef71bd40", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/aaf5a890b85f9fb1e1511ca3c53549afef71bd40", "committedDate": "2020-05-15T05:58:53Z", "message": "[FLINK-17664][table] Introduce print, blackhole connector in table"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e0424357b5bdcdef98752a9b4a08f2557981e23e", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/e0424357b5bdcdef98752a9b4a08f2557981e23e", "committedDate": "2020-05-14T07:26:55Z", "message": "Optimizer test expected result"}, "afterCommit": {"oid": "aaf5a890b85f9fb1e1511ca3c53549afef71bd40", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/aaf5a890b85f9fb1e1511ca3c53549afef71bd40", "committedDate": "2020-05-15T05:58:53Z", "message": "[FLINK-17664][table] Introduce print, blackhole connector in table"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4375, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}