{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDMyMjYwNTE1", "number": 12573, "title": "[FLINK-18232][hive] Fix Hive streaming source bugs", "bodyText": "What is the purpose of the change\n\nHive streaming source HiveMapredSplitReader reuse row in a wrong way, if change reuse row instance, will loose partition fields.\nWhen converting Flink File split to Hadoop File split, length should not be -1.\nDirectoryMonitorDiscovery should convert DFS modificationTime to UTC time mills.\nHiveTableSource.createStreamSourceForNonPartitionTable should use local zone mills instead of UTC mills because  ContinuousFileMonitoringFunction use local zone mills.\n\nVerifying this change\n\nHiveTableSourceITCase.testStreamPartitionRead\nHiveTableFileInputFormatTest\nDirectoryMonitorDiscoveryTest\nManually testing.\n\nDoes this pull request potentially affect one of the following parts:\n\nDependencies (does it add or upgrade a dependency): no\nThe public API, i.e., is any changed class annotated with @Public(Evolving): no\nThe serializers: (no\nThe runtime per-record code paths (performance sensitive): (no\nAnything that affects deployment or recovery: JobManager (and its components), Checkpointing, Kubernetes/Yarn/Mesos, ZooKeeper: (no\nThe S3 file system connector: (no\n\nDocumentation\n\nDoes this pull request introduce a new feature? (no", "createdAt": "2020-06-10T07:32:13Z", "url": "https://github.com/apache/flink/pull/12573", "merged": true, "mergeCommit": {"oid": "f59b8b479199aa55776b3cca13b325223db984b0"}, "closed": true, "closedAt": "2020-06-11T02:30:47Z", "author": {"login": "JingsongLi"}, "timelineItems": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcp0hvvAH2gAyNDMyMjYwNTE1OmFmYzE4YzllZjViMWM3YTc2MmJhNTViMDIwNDEyNTc4YWRhYzQwMmY=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcqE1pTgH2gAyNDMyMjYwNTE1OmY2NTY4NmE1YTg2NWMyMTY1NjU5ZjE0YzcyYTZiYThiMTkxNTNkMzU=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "afc18c9ef5b1c7a762ba55b020412578adac402f", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/afc18c9ef5b1c7a762ba55b020412578adac402f", "committedDate": "2020-06-10T07:28:54Z", "message": "[FLINK-18232][hive] Fix Hive streaming source bugs"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI3ODAwMDc1", "url": "https://github.com/apache/flink/pull/12573#pullrequestreview-427800075", "createdAt": "2020-06-10T07:54:53Z", "commit": {"oid": "afc18c9ef5b1c7a762ba55b020412578adac402f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQwNzo1NDo1M1rOGhpLng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQwNzo1NDo1M1rOGhpLng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkzMDkxMA==", "bodyText": "Can we update the doc of FileInputSplit::getLength() to indicate length == -1 means to read all data from the file? I'll feel more comfortable about this change if it's guaranteed by the API contract.", "url": "https://github.com/apache/flink/pull/12573#discussion_r437930910", "createdAt": "2020-06-10T07:54:53Z", "author": {"login": "lirui-apache"}, "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/read/HiveTableFileInputFormat.java", "diffHunk": "@@ -52,16 +53,26 @@ public HiveTableFileInputFormat(\n \n \t@Override\n \tpublic void open(FileInputSplit fileSplit) throws IOException {\n-\t\tURI uri = fileSplit.getPath().toUri();\n \t\tHiveTableInputSplit split = new HiveTableInputSplit(\n \t\t\t\tfileSplit.getSplitNumber(),\n-\t\t\t\tnew FileSplit(new Path(uri), fileSplit.getStart(), fileSplit.getLength(), (String[]) null),\n+\t\t\t\ttoHadoopFileSplit(fileSplit),\n \t\t\t\tinputFormat.getJobConf(),\n-\t\t\t\thiveTablePartition\n-\t\t);\n+\t\t\t\thiveTablePartition);\n \t\tinputFormat.open(split);\n \t}\n \n+\t@VisibleForTesting\n+\tstatic FileSplit toHadoopFileSplit(FileInputSplit fileSplit) throws IOException {\n+\t\tURI uri = fileSplit.getPath().toUri();\n+\t\tlong length = fileSplit.getLength();\n+\t\t// Hadoop FileSplit should not have -1 length.\n+\t\tif (length == -1) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "afc18c9ef5b1c7a762ba55b020412578adac402f"}, "originalPosition": 29}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a6ef0628e2b21e484bfefc7fb31bf7c1649ffe34", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/a6ef0628e2b21e484bfefc7fb31bf7c1649ffe34", "committedDate": "2020-06-10T08:48:40Z", "message": "Fix"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4MDIzOTM1", "url": "https://github.com/apache/flink/pull/12573#pullrequestreview-428023935", "createdAt": "2020-06-10T12:57:35Z", "commit": {"oid": "a6ef0628e2b21e484bfefc7fb31bf7c1649ffe34"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxMjo1NzozNVrOGhzhHw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxMjo1NzozNVrOGhzhHw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODEwMDI1NQ==", "bodyText": "Add some comments for this method? What is a suitable partition?", "url": "https://github.com/apache/flink/pull/12573#discussion_r438100255", "createdAt": "2020-06-10T12:57:35Z", "author": {"login": "lirui-apache"}, "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/read/DirectoryMonitorDiscovery.java", "diffHunk": "@@ -41,18 +44,36 @@\n \t\t\tContext context, long previousTimestamp) throws Exception {\n \t\tFileStatus[] statuses = getFileStatusRecurse(\n \t\t\t\tcontext.tableLocation(), context.partitionKeys().size(), context.fileSystem());\n+\t\tList<Tuple2<List<String>, Long>> partValueList = suitablePartitions(context, previousTimestamp, statuses);\n+\n \t\tList<Tuple2<Partition, Long>> partitions = new ArrayList<>();\n+\t\tfor (Tuple2<List<String>, Long> tuple2 : partValueList) {\n+\t\t\tcontext.getPartition(tuple2.f0).ifPresent(\n+\t\t\t\t\tpartition -> partitions.add(new Tuple2<>(partition, tuple2.f1)));\n+\t\t}\n+\t\treturn partitions;\n+\t}\n+\n+\t@VisibleForTesting\n+\tstatic List<Tuple2<List<String>, Long>> suitablePartitions(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a6ef0628e2b21e484bfefc7fb31bf7c1649ffe34"}, "originalPosition": 33}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4MDI0Mjg3", "url": "https://github.com/apache/flink/pull/12573#pullrequestreview-428024287", "createdAt": "2020-06-10T12:57:59Z", "commit": {"oid": "a6ef0628e2b21e484bfefc7fb31bf7c1649ffe34"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f65686a5a865c2165659f14c72a6ba8b19153d35", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/flink/commit/f65686a5a865c2165659f14c72a6ba8b19153d35", "committedDate": "2020-06-11T02:29:07Z", "message": "Fix comments"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3976, "cost": 1, "resetAt": "2021-10-28T16:48:13Z"}}}