{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzY2MzY4NzA3", "number": 10932, "title": "[FLINK-15614][docs] Consolidate Hadoop documentation", "bodyText": "Consolidates the hadoop documentation under ops/deployment/hadoop .\nExporting the classpath is listed first as it is the easier of the 2 and applicable to most people with a fully running hadoop setup.\nInstructions for the include-hadoop profile has been removed, in an attempt to eliminate the notion that \"Flink must be built against a specific hadoop version\", when all you need do to is place the jars into /lib.", "createdAt": "2020-01-23T13:43:39Z", "url": "https://github.com/apache/flink/pull/10932", "merged": true, "mergeCommit": {"oid": "d2de15c81f9556c9ec235e98969c31b8734f5554"}, "closed": true, "closedAt": "2020-02-04T17:09:57Z", "author": {"login": "zentol"}, "timelineItems": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABb_GatrAFqTM1MDEwNTk3Mw==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcBEt1AgBqjMwMDY5NTMwMjQ=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUwMTA1OTcz", "url": "https://github.com/apache/flink/pull/10932#pullrequestreview-350105973", "createdAt": "2020-01-29T13:32:31Z", "commit": {"oid": "fb34b16d701e65ee2edcaa082869af08b4ee0482"}, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOVQxMzozMjozMVrOFjIb5w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOVQxMzo1NDozNlrOFjJJAg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjM4MjY5NQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            In order to use Hadoop features (e.g., YARN, HDFS) it is ncessary to provide Flink with the required Hadoop classes,\n          \n          \n            \n            In order to use Hadoop features (e.g., YARN, HDFS) it is necessary to provide Flink with the required Hadoop classes,", "url": "https://github.com/apache/flink/pull/10932#discussion_r372382695", "createdAt": "2020-01-29T13:32:31Z", "author": {"login": "azagrebin"}, "path": "docs/ops/deployment/hadoop.md", "diffHunk": "@@ -38,13 +38,18 @@ Referencing the HDFS configuration in the [Flink configuration]({{ site.baseurl\n \n Another way to provide the Hadoop configuration is to have it on the class path of the Flink process, see more details below.\n \n-## Adding Hadoop Classpaths\n+## Providing Hadoop classes\n \n-The required classes to use Hadoop should be available in the `lib/` folder of the Flink installation\n-(on all machines running Flink) unless Flink is built with [Hadoop shaded dependencies]({{ site.baseurl }}/flinkDev/building.html#pre-bundled-versions).\n+In order to use Hadoop features (e.g., YARN, HDFS) it is ncessary to provide Flink with the required Hadoop classes,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fb34b16d701e65ee2edcaa082869af08b4ee0482"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjM4NTU0Nw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            For these versions it is sufficient to download the corresponding `Pre-bundled Hadoop` component and placing it in\n          \n          \n            \n            For these versions it is sufficient to download the corresponding `Pre-bundled Hadoop` component and put it into", "url": "https://github.com/apache/flink/pull/10932#discussion_r372385547", "createdAt": "2020-01-29T13:38:04Z", "author": {"login": "azagrebin"}, "path": "docs/ops/deployment/hadoop.md", "diffHunk": "@@ -66,6 +71,29 @@ in the shell. Note that `hadoop` is the hadoop binary and that `classpath` is an\n \n Putting the Hadoop configuration in the same class path as the Hadoop libraries makes Flink pick up that configuration.\n \n+### Adding Hadoop to /lib\n+\n+The Flink project releases Hadoop distributions for specific versions, that relocate or exclude several dependencies\n+to reduce the risk of dependency clashes.\n+These can be found on the [downloads]({{ site.download_url }}).\n+For these versions it is sufficient to download the corresponding `Pre-bundled Hadoop` component and placing it in", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fb34b16d701e65ee2edcaa082869af08b4ee0482"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjM4NjAyNQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            then it is necessary to build [flink-shaded](https://github.com/apache/flink-shaded) against this version.\n          \n          \n            \n            then it is necessary to build [flink-shaded](https://github.com/apache/flink-shaded) dependency against this version.", "url": "https://github.com/apache/flink/pull/10932#discussion_r372386025", "createdAt": "2020-01-29T13:39:01Z", "author": {"login": "azagrebin"}, "path": "docs/ops/deployment/hadoop.md", "diffHunk": "@@ -66,6 +71,29 @@ in the shell. Note that `hadoop` is the hadoop binary and that `classpath` is an\n \n Putting the Hadoop configuration in the same class path as the Hadoop libraries makes Flink pick up that configuration.\n \n+### Adding Hadoop to /lib\n+\n+The Flink project releases Hadoop distributions for specific versions, that relocate or exclude several dependencies\n+to reduce the risk of dependency clashes.\n+These can be found on the [downloads]({{ site.download_url }}).\n+For these versions it is sufficient to download the corresponding `Pre-bundled Hadoop` component and placing it in\n+the `/lib` directory of the Flink distribution.\n+\n+If the used Hadoop version is not listed on the download page (possibly due to being a Vendor-specific version),\n+then it is necessary to build [flink-shaded](https://github.com/apache/flink-shaded) against this version.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fb34b16d701e65ee2edcaa082869af08b4ee0482"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjM4NjkzMg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            You can find the source for this project in the [Additional Components]({{ site.download_url }}#additional-components) section of the download page.\n          \n          \n            \n            You can also find the source code for this project in the [Additional Components]({{ site.download_url }}#additional-components) section of the download page.", "url": "https://github.com/apache/flink/pull/10932#discussion_r372386932", "createdAt": "2020-01-29T13:40:45Z", "author": {"login": "azagrebin"}, "path": "docs/ops/deployment/hadoop.md", "diffHunk": "@@ -66,6 +71,29 @@ in the shell. Note that `hadoop` is the hadoop binary and that `classpath` is an\n \n Putting the Hadoop configuration in the same class path as the Hadoop libraries makes Flink pick up that configuration.\n \n+### Adding Hadoop to /lib\n+\n+The Flink project releases Hadoop distributions for specific versions, that relocate or exclude several dependencies\n+to reduce the risk of dependency clashes.\n+These can be found on the [downloads]({{ site.download_url }}).\n+For these versions it is sufficient to download the corresponding `Pre-bundled Hadoop` component and placing it in\n+the `/lib` directory of the Flink distribution.\n+\n+If the used Hadoop version is not listed on the download page (possibly due to being a Vendor-specific version),\n+then it is necessary to build [flink-shaded](https://github.com/apache/flink-shaded) against this version.\n+You can find the source for this project in the [Additional Components]({{ site.download_url }}#additional-components) section of the download page.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fb34b16d701e65ee2edcaa082869af08b4ee0482"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjM5MzE2Mg==", "bodyText": "Are there no expected dependency clashes in case of just exporting HADOOP_CLASSPATH?\nIn other words, why is the relocation needed for /lib but not for HADOOP_CLASSPATH?\nI also somewhat liked the previous idea of mentioning that the first way should be a recommended way to go and only in case of problems (giving examples) go to the option 2. Is it still the case?", "url": "https://github.com/apache/flink/pull/10932#discussion_r372393162", "createdAt": "2020-01-29T13:52:36Z", "author": {"login": "azagrebin"}, "path": "docs/ops/deployment/hadoop.md", "diffHunk": "@@ -38,13 +38,18 @@ Referencing the HDFS configuration in the [Flink configuration]({{ site.baseurl\n \n Another way to provide the Hadoop configuration is to have it on the class path of the Flink process, see more details below.\n \n-## Adding Hadoop Classpaths\n+## Providing Hadoop classes\n \n-The required classes to use Hadoop should be available in the `lib/` folder of the Flink installation\n-(on all machines running Flink) unless Flink is built with [Hadoop shaded dependencies]({{ site.baseurl }}/flinkDev/building.html#pre-bundled-versions).\n+In order to use Hadoop features (e.g., YARN, HDFS) it is ncessary to provide Flink with the required Hadoop classes,\n+as these are not bundled by default.\n \n-If putting the files into the directory is not possible, Flink also respects\n-the `HADOOP_CLASSPATH` environment variable to add Hadoop jar files to the classpath.\n+This can be done in 2 ways:\n+* Adding the Hadoop classpath to Flink", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fb34b16d701e65ee2edcaa082869af08b4ee0482"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjM5MzU2OA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            After this step is complete, place the `flink-shaded-hadoop-2-uber` jar in the `/lib` directory of the Flink distribution.\n          \n          \n            \n            After this step is complete, put the `flink-shaded-hadoop-2-uber` jar into the `/lib` directory of the Flink distribution.", "url": "https://github.com/apache/flink/pull/10932#discussion_r372393568", "createdAt": "2020-01-29T13:53:21Z", "author": {"login": "azagrebin"}, "path": "docs/ops/deployment/hadoop.md", "diffHunk": "@@ -66,6 +71,29 @@ in the shell. Note that `hadoop` is the hadoop binary and that `classpath` is an\n \n Putting the Hadoop configuration in the same class path as the Hadoop libraries makes Flink pick up that configuration.\n \n+### Adding Hadoop to /lib\n+\n+The Flink project releases Hadoop distributions for specific versions, that relocate or exclude several dependencies\n+to reduce the risk of dependency clashes.\n+These can be found on the [downloads]({{ site.download_url }}).\n+For these versions it is sufficient to download the corresponding `Pre-bundled Hadoop` component and placing it in\n+the `/lib` directory of the Flink distribution.\n+\n+If the used Hadoop version is not listed on the download page (possibly due to being a Vendor-specific version),\n+then it is necessary to build [flink-shaded](https://github.com/apache/flink-shaded) against this version.\n+You can find the source for this project in the [Additional Components]({{ site.download_url }}#additional-components) section of the download page.\n+\n+<span class=\"label label-info\">Note</span> If you want to build `flink-shaded` against a vendor specific Hadoop version, you first have to configure the\n+vendor-specific maven repository in your local maven setup as described [here](https://maven.apache.org/guides/mini/guide-multiple-repositories.html).\n+\n+Run the following command to build and install `flink-shaded` against your desired Hadoop version (e.g., for version `2.6.5-custom`):\n+\n+{% highlight bash %}\n+mvn clean install -Dhadoop.version=2.6.5-custom\n+{% endhighlight %}\n+\n+After this step is complete, place the `flink-shaded-hadoop-2-uber` jar in the `/lib` directory of the Flink distribution.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fb34b16d701e65ee2edcaa082869af08b4ee0482"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjM5NDI0Mg==", "bodyText": "I would also suggest to have an expected path to the jar, like target/flink-shaded-hadoop-2-uber.jar for less advanced users.", "url": "https://github.com/apache/flink/pull/10932#discussion_r372394242", "createdAt": "2020-01-29T13:54:36Z", "author": {"login": "azagrebin"}, "path": "docs/ops/deployment/hadoop.md", "diffHunk": "@@ -66,6 +71,29 @@ in the shell. Note that `hadoop` is the hadoop binary and that `classpath` is an\n \n Putting the Hadoop configuration in the same class path as the Hadoop libraries makes Flink pick up that configuration.\n \n+### Adding Hadoop to /lib\n+\n+The Flink project releases Hadoop distributions for specific versions, that relocate or exclude several dependencies\n+to reduce the risk of dependency clashes.\n+These can be found on the [downloads]({{ site.download_url }}).\n+For these versions it is sufficient to download the corresponding `Pre-bundled Hadoop` component and placing it in\n+the `/lib` directory of the Flink distribution.\n+\n+If the used Hadoop version is not listed on the download page (possibly due to being a Vendor-specific version),\n+then it is necessary to build [flink-shaded](https://github.com/apache/flink-shaded) against this version.\n+You can find the source for this project in the [Additional Components]({{ site.download_url }}#additional-components) section of the download page.\n+\n+<span class=\"label label-info\">Note</span> If you want to build `flink-shaded` against a vendor specific Hadoop version, you first have to configure the\n+vendor-specific maven repository in your local maven setup as described [here](https://maven.apache.org/guides/mini/guide-multiple-repositories.html).\n+\n+Run the following command to build and install `flink-shaded` against your desired Hadoop version (e.g., for version `2.6.5-custom`):\n+\n+{% highlight bash %}\n+mvn clean install -Dhadoop.version=2.6.5-custom\n+{% endhighlight %}\n+\n+After this step is complete, place the `flink-shaded-hadoop-2-uber` jar in the `/lib` directory of the Flink distribution.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjM5MzU2OA=="}, "originalCommit": {"oid": "fb34b16d701e65ee2edcaa082869af08b4ee0482"}, "originalPosition": 49}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUwMTMwNDgy", "url": "https://github.com/apache/flink/pull/10932#pullrequestreview-350130482", "createdAt": "2020-01-29T14:07:39Z", "commit": {"oid": "fb34b16d701e65ee2edcaa082869af08b4ee0482"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOVQxNDowNzo0MFrOFjJkeg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOVQxNDowNzo0MFrOFjJkeg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjQwMTI3NA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            These can be found on the [downloads]({{ site.download_url }}).\n          \n          \n            \n            These can be found on the [downloads]({{ site.download_url }}) page in the optional components.", "url": "https://github.com/apache/flink/pull/10932#discussion_r372401274", "createdAt": "2020-01-29T14:07:40Z", "author": {"login": "azagrebin"}, "path": "docs/ops/deployment/hadoop.md", "diffHunk": "@@ -66,6 +71,29 @@ in the shell. Note that `hadoop` is the hadoop binary and that `classpath` is an\n \n Putting the Hadoop configuration in the same class path as the Hadoop libraries makes Flink pick up that configuration.\n \n+### Adding Hadoop to /lib\n+\n+The Flink project releases Hadoop distributions for specific versions, that relocate or exclude several dependencies\n+to reduce the risk of dependency clashes.\n+These can be found on the [downloads]({{ site.download_url }}).", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fb34b16d701e65ee2edcaa082869af08b4ee0482"}, "originalPosition": 32}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUyOTAwNjE5", "url": "https://github.com/apache/flink/pull/10932#pullrequestreview-352900619", "createdAt": "2020-02-04T11:20:58Z", "commit": {"oid": "18362a771aca442dfc07fd646f4bd98724cdd2e6"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUzMDA5MTQ1", "url": "https://github.com/apache/flink/pull/10932#pullrequestreview-353009145", "createdAt": "2020-02-04T14:19:04Z", "commit": {"oid": "18362a771aca442dfc07fd646f4bd98724cdd2e6"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQxNDoxOTowNFrOFlVosQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQxNDoxOTowNFrOFlVosQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDY5NjExMw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Option 1) requires very little work and integrates nicely with existing Hadoop setups, and should be the\n          \n          \n            \n            Option 1) requires very little work and integrates nicely with existing Hadoop setups. It should be the", "url": "https://github.com/apache/flink/pull/10932#discussion_r374696113", "createdAt": "2020-02-04T14:19:04Z", "author": {"login": "azagrebin"}, "path": "docs/ops/deployment/hadoop.md", "diffHunk": "@@ -38,13 +38,22 @@ Referencing the HDFS configuration in the [Flink configuration]({{ site.baseurl\n \n Another way to provide the Hadoop configuration is to have it on the class path of the Flink process, see more details below.\n \n-## Adding Hadoop Classpaths\n+## Providing Hadoop classes\n \n-The required classes to use Hadoop should be available in the `lib/` folder of the Flink installation\n-(on all machines running Flink) unless Flink is built with [Hadoop shaded dependencies]({{ site.baseurl }}/flinkDev/building.html#pre-bundled-versions).\n+In order to use Hadoop features (e.g., YARN, HDFS) it is necessary to provide Flink with the required Hadoop classes,\n+as these are not bundled by default.\n \n-If putting the files into the directory is not possible, Flink also respects\n-the `HADOOP_CLASSPATH` environment variable to add Hadoop jar files to the classpath.\n+This can be done by \n+1) Adding the Hadoop classpath to Flink\n+2) Putting the required jar files into /lib directory of the Flink distribution\n+Option 1) requires very little work and integrates nicely with existing Hadoop setups, and should be the", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18362a771aca442dfc07fd646f4bd98724cdd2e6"}, "originalPosition": 17}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUzMDA5NDA2", "url": "https://github.com/apache/flink/pull/10932#pullrequestreview-353009406", "createdAt": "2020-02-04T14:19:24Z", "commit": {"oid": "18362a771aca442dfc07fd646f4bd98724cdd2e6"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQxNDoxOToyNFrOFlVpew==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQxNDoxOToyNFrOFlVpew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDY5NjMxNQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            However, Hadoop has a large dependency footprint, increasing the risk of dependency conflicts occurring.\n          \n          \n            \n            However, Hadoop has a large dependency footprint that increases the risk of dependency conflicts occurring.", "url": "https://github.com/apache/flink/pull/10932#discussion_r374696315", "createdAt": "2020-02-04T14:19:24Z", "author": {"login": "azagrebin"}, "path": "docs/ops/deployment/hadoop.md", "diffHunk": "@@ -38,13 +38,22 @@ Referencing the HDFS configuration in the [Flink configuration]({{ site.baseurl\n \n Another way to provide the Hadoop configuration is to have it on the class path of the Flink process, see more details below.\n \n-## Adding Hadoop Classpaths\n+## Providing Hadoop classes\n \n-The required classes to use Hadoop should be available in the `lib/` folder of the Flink installation\n-(on all machines running Flink) unless Flink is built with [Hadoop shaded dependencies]({{ site.baseurl }}/flinkDev/building.html#pre-bundled-versions).\n+In order to use Hadoop features (e.g., YARN, HDFS) it is necessary to provide Flink with the required Hadoop classes,\n+as these are not bundled by default.\n \n-If putting the files into the directory is not possible, Flink also respects\n-the `HADOOP_CLASSPATH` environment variable to add Hadoop jar files to the classpath.\n+This can be done by \n+1) Adding the Hadoop classpath to Flink\n+2) Putting the required jar files into /lib directory of the Flink distribution\n+Option 1) requires very little work and integrates nicely with existing Hadoop setups, and should be the\n+preferred approach.\n+However, Hadoop has a large dependency footprint, increasing the risk of dependency conflicts occurring.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18362a771aca442dfc07fd646f4bd98724cdd2e6"}, "originalPosition": 19}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d6c08c376ed5bef6011e518ae47ea57cb3754ab6", "author": {"user": {"login": "zentol", "name": "Chesnay Schepler"}}, "url": "https://github.com/apache/flink/commit/d6c08c376ed5bef6011e518ae47ea57cb3754ab6", "committedDate": "2020-02-04T17:09:32Z", "message": "[FLINK-15614][docs] Consolidate Hadoop documentation"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "18362a771aca442dfc07fd646f4bd98724cdd2e6", "author": {"user": {"login": "zentol", "name": "Chesnay Schepler"}}, "url": "https://github.com/apache/flink/commit/18362a771aca442dfc07fd646f4bd98724cdd2e6", "committedDate": "2020-01-31T07:57:59Z", "message": "document reasoning"}, "afterCommit": {"oid": "d6c08c376ed5bef6011e518ae47ea57cb3754ab6", "author": {"user": {"login": "zentol", "name": "Chesnay Schepler"}}, "url": "https://github.com/apache/flink/commit/d6c08c376ed5bef6011e518ae47ea57cb3754ab6", "committedDate": "2020-02-04T17:09:32Z", "message": "[FLINK-15614][docs] Consolidate Hadoop documentation"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4453, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}