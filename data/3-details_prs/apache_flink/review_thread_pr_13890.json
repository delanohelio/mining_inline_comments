{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTE0MTAzMzM3", "number": 13890, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMlQxNDo0NzoxM1rOE0aI7g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMlQxNDo1NTo0MVrOE0aYKA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIzMzg5Njc4OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/BatchGroupedReduce.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMlQxNDo0NzoxM1rOHsHcYA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMlQxNDo0NzoxM1rOHsHcYA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjAyMTM0NA==", "bodyText": "So far we have mostly (or always? \ud83e\udd14) kept Operator in the name somehow for newer operators. For example: BatchGroupedReduceOperator.", "url": "https://github.com/apache/flink/pull/13890#discussion_r516021344", "createdAt": "2020-11-02T14:47:13Z", "author": {"login": "aljoscha"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/BatchGroupedReduce.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.RuntimeExecutionMode;\n+import org.apache.flink.api.common.functions.ReduceFunction;\n+import org.apache.flink.api.common.state.ValueState;\n+import org.apache.flink.api.common.state.ValueStateDescriptor;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.state.VoidNamespace;\n+import org.apache.flink.runtime.state.VoidNamespaceSerializer;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+\n+/**\n+ * A {@link StreamOperator} for executing a {@link ReduceFunction} on a\n+ * {@link org.apache.flink.streaming.api.datastream.KeyedStream} in a\n+ * {@link RuntimeExecutionMode#BATCH} mode.\n+ */\n+@Internal\n+public class BatchGroupedReduce<IN, KEY> extends AbstractUdfStreamOperator<IN, ReduceFunction<IN>>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4b3958fe94e9f6a9d0f2e1be302d20e0cfe3958e"}, "originalPosition": 36}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIzMzkzNTQ2OnYy", "diffSide": "RIGHT", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/BatchGroupedReduce.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMlQxNDo1NTozNlrOHsH0bQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMlQxNDo1NTozNlrOHsH0bQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjAyNzUwMQ==", "bodyText": "It's good to keep the same name! Just in case we ever want to do some batch/streaming/savepoint interop business.", "url": "https://github.com/apache/flink/pull/13890#discussion_r516027501", "createdAt": "2020-11-02T14:55:36Z", "author": {"login": "aljoscha"}, "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/BatchGroupedReduce.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.RuntimeExecutionMode;\n+import org.apache.flink.api.common.functions.ReduceFunction;\n+import org.apache.flink.api.common.state.ValueState;\n+import org.apache.flink.api.common.state.ValueStateDescriptor;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.state.VoidNamespace;\n+import org.apache.flink.runtime.state.VoidNamespaceSerializer;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+\n+/**\n+ * A {@link StreamOperator} for executing a {@link ReduceFunction} on a\n+ * {@link org.apache.flink.streaming.api.datastream.KeyedStream} in a\n+ * {@link RuntimeExecutionMode#BATCH} mode.\n+ */\n+@Internal\n+public class BatchGroupedReduce<IN, KEY> extends AbstractUdfStreamOperator<IN, ReduceFunction<IN>>\n+\t\timplements OneInputStreamOperator<IN, IN>, Triggerable<KEY, VoidNamespace> {\n+\n+\tprivate static final long serialVersionUID = 1L;\n+\n+\tprivate static final String STATE_NAME = \"_op_state\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4b3958fe94e9f6a9d0f2e1be302d20e0cfe3958e"}, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIzMzkzNTc2OnYy", "diffSide": "RIGHT", "path": "flink-tests/src/test/java/org/apache/flink/test/streaming/runtime/ReduceITCase.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMlQxNDo1NTo0MVrOHsH0nw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMlQxNToxMjoxNVrOHsIiLw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjAyNzU1MQ==", "bodyText": "Maybe we should add this to the DataStreamBatchExecutionITCase that I'm introducing in #13891. But we should at least not choose ReduceITCase because there's already too many classes with that name... \ud83d\ude05", "url": "https://github.com/apache/flink/pull/13890#discussion_r516027551", "createdAt": "2020-11-02T14:55:41Z", "author": {"login": "aljoscha"}, "path": "flink-tests/src/test/java/org/apache/flink/test/streaming/runtime/ReduceITCase.java", "diffHunk": "@@ -0,0 +1,92 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.test.streaming.runtime;\n+\n+import org.apache.flink.api.common.RuntimeExecutionMode;\n+import org.apache.flink.api.common.functions.ReduceFunction;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.configuration.ExecutionOptions;\n+import org.apache.flink.streaming.api.datastream.DataStream;\n+import org.apache.flink.streaming.api.datastream.DataStreamSource;\n+import org.apache.flink.streaming.api.datastream.KeyedStream;\n+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\n+import org.apache.flink.test.util.AbstractTestBase;\n+import org.apache.flink.util.CloseableIterator;\n+import org.apache.flink.util.CollectionUtil;\n+\n+import org.junit.Test;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.junit.Assert.assertThat;\n+\n+/**\n+ * Tests for {@link KeyedStream#reduce(ReduceFunction)}.\n+ */\n+public class ReduceITCase extends AbstractTestBase {\n+\t@Test\n+\tpublic void testStreamReduce() throws Exception {\n+\t\tStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n+\t\tenv.setParallelism(1);\n+\t\tConfiguration conf = new Configuration();\n+\t\tconf.set(ExecutionOptions.RUNTIME_MODE, RuntimeExecutionMode.STREAMING);\n+\t\tenv.configure(conf, this.getClass().getClassLoader());\n+\t\tDataStreamSource<Long> numbers = env\n+\t\t\t.fromSequence(0, 10);\n+\n+\t\t// send all records into a single reducer\n+\t\tKeyedStream<Long, Long> stream = numbers.keyBy(i -> i % 2);\n+\t\tDataStream<Long> sums = stream.reduce(\n+\t\t\tLong::sum\n+\t\t);\n+\n+\t\ttry (CloseableIterator<Long> sumsIterator = sums.executeAndCollect()) {\n+\t\t\tList<Long> results = CollectionUtil.iteratorToList(sumsIterator);\n+\t\t\tassertThat(results, equalTo(Arrays.asList(\n+\t\t\t\t0L, 1L, 2L, 4L, 6L, 9L, 12L, 16L, 20L, 25L, 30L\n+\t\t\t)));\n+\t\t}\n+\t}\n+\n+\t@Test\n+\tpublic void testBatchReduce() throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4b3958fe94e9f6a9d0f2e1be302d20e0cfe3958e"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjAzOTIxNQ==", "bodyText": "Sure, will move the tests into the DataStreamBatchExecutionITCase, once we get it in.", "url": "https://github.com/apache/flink/pull/13890#discussion_r516039215", "createdAt": "2020-11-02T15:12:15Z", "author": {"login": "dawidwys"}, "path": "flink-tests/src/test/java/org/apache/flink/test/streaming/runtime/ReduceITCase.java", "diffHunk": "@@ -0,0 +1,92 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.test.streaming.runtime;\n+\n+import org.apache.flink.api.common.RuntimeExecutionMode;\n+import org.apache.flink.api.common.functions.ReduceFunction;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.configuration.ExecutionOptions;\n+import org.apache.flink.streaming.api.datastream.DataStream;\n+import org.apache.flink.streaming.api.datastream.DataStreamSource;\n+import org.apache.flink.streaming.api.datastream.KeyedStream;\n+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\n+import org.apache.flink.test.util.AbstractTestBase;\n+import org.apache.flink.util.CloseableIterator;\n+import org.apache.flink.util.CollectionUtil;\n+\n+import org.junit.Test;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.junit.Assert.assertThat;\n+\n+/**\n+ * Tests for {@link KeyedStream#reduce(ReduceFunction)}.\n+ */\n+public class ReduceITCase extends AbstractTestBase {\n+\t@Test\n+\tpublic void testStreamReduce() throws Exception {\n+\t\tStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n+\t\tenv.setParallelism(1);\n+\t\tConfiguration conf = new Configuration();\n+\t\tconf.set(ExecutionOptions.RUNTIME_MODE, RuntimeExecutionMode.STREAMING);\n+\t\tenv.configure(conf, this.getClass().getClassLoader());\n+\t\tDataStreamSource<Long> numbers = env\n+\t\t\t.fromSequence(0, 10);\n+\n+\t\t// send all records into a single reducer\n+\t\tKeyedStream<Long, Long> stream = numbers.keyBy(i -> i % 2);\n+\t\tDataStream<Long> sums = stream.reduce(\n+\t\t\tLong::sum\n+\t\t);\n+\n+\t\ttry (CloseableIterator<Long> sumsIterator = sums.executeAndCollect()) {\n+\t\t\tList<Long> results = CollectionUtil.iteratorToList(sumsIterator);\n+\t\t\tassertThat(results, equalTo(Arrays.asList(\n+\t\t\t\t0L, 1L, 2L, 4L, 6L, 9L, 12L, 16L, 20L, 25L, 30L\n+\t\t\t)));\n+\t\t}\n+\t}\n+\n+\t@Test\n+\tpublic void testBatchReduce() throws Exception {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjAyNzU1MQ=="}, "originalCommit": {"oid": "4b3958fe94e9f6a9d0f2e1be302d20e0cfe3958e"}, "originalPosition": 70}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4896, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}