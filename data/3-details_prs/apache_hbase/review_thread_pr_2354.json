{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDgxMDIzNjI4", "number": 2354, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wN1QwNzozNjozN1rOEg0KFQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wN1QwODowMDozOVrOEg0_EQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyODQ0NDM3OnYy", "diffSide": "RIGHT", "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/CatalogFamilyFormat.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wN1QwNzozNjozN1rOHNzgJw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wN1QwODoxMjowOVrOHN1KIA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDIzNzM1MQ==", "bodyText": "Minor suggestion. Can reduce one line code. :-)\nfor (Cell cell : cells) {\nif (isMergeQualifierPrefix(cell)) {\nreturn true;\n}\n}\nreturn false;", "url": "https://github.com/apache/hbase/pull/2354#discussion_r484237351", "createdAt": "2020-09-07T07:36:37Z", "author": {"login": "infraio"}, "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/CatalogFamilyFormat.java", "diffHunk": "@@ -346,4 +347,64 @@ public static TableState getTableState(Result r) throws IOException {\n       throw new IOException(e);\n     }\n   }\n+\n+  /**\n+   * @return Deserialized values of &lt;qualifier,regioninfo&gt; pairs taken from column values that\n+   *         match the regex 'info:merge.*' in array of <code>cells</code>.\n+   */\n+  @Nullable\n+  public static Map<String, RegionInfo> getMergeRegionsWithName(Cell[] cells) {\n+    if (cells == null) {\n+      return null;\n+    }\n+    Map<String, RegionInfo> regionsToMerge = null;\n+    for (Cell cell : cells) {\n+      if (!isMergeQualifierPrefix(cell)) {\n+        continue;\n+      }\n+      // Ok. This cell is that of a info:merge* column.\n+      RegionInfo ri = RegionInfo.parseFromOrNull(cell.getValueArray(), cell.getValueOffset(),\n+        cell.getValueLength());\n+      if (ri != null) {\n+        if (regionsToMerge == null) {\n+          regionsToMerge = new LinkedHashMap<>();\n+        }\n+        regionsToMerge.put(Bytes.toString(CellUtil.cloneQualifier(cell)), ri);\n+      }\n+    }\n+    return regionsToMerge;\n+  }\n+\n+  /**\n+   * @return Deserialized regioninfo values taken from column values that match the regex\n+   *         'info:merge.*' in array of <code>cells</code>.\n+   */\n+  @Nullable\n+  public static List<RegionInfo> getMergeRegions(Cell[] cells) {\n+    Map<String, RegionInfo> mergeRegionsWithName = getMergeRegionsWithName(cells);\n+    return (mergeRegionsWithName == null) ? null : new ArrayList<>(mergeRegionsWithName.values());\n+  }\n+\n+  /**\n+   * @return True if any merge regions present in <code>cells</code>; i.e. the column in\n+   *         <code>cell</code> matches the regex 'info:merge.*'.\n+   */\n+  public static boolean hasMergeRegions(Cell[] cells) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7644720fcaacd63587e08fc2b4c5c1dd2a3ef14a"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDI2NDQ4MA==", "bodyText": "Just copy-paste. Let me change the code.", "url": "https://github.com/apache/hbase/pull/2354#discussion_r484264480", "createdAt": "2020-09-07T08:12:09Z", "author": {"login": "Apache9"}, "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/CatalogFamilyFormat.java", "diffHunk": "@@ -346,4 +347,64 @@ public static TableState getTableState(Result r) throws IOException {\n       throw new IOException(e);\n     }\n   }\n+\n+  /**\n+   * @return Deserialized values of &lt;qualifier,regioninfo&gt; pairs taken from column values that\n+   *         match the regex 'info:merge.*' in array of <code>cells</code>.\n+   */\n+  @Nullable\n+  public static Map<String, RegionInfo> getMergeRegionsWithName(Cell[] cells) {\n+    if (cells == null) {\n+      return null;\n+    }\n+    Map<String, RegionInfo> regionsToMerge = null;\n+    for (Cell cell : cells) {\n+      if (!isMergeQualifierPrefix(cell)) {\n+        continue;\n+      }\n+      // Ok. This cell is that of a info:merge* column.\n+      RegionInfo ri = RegionInfo.parseFromOrNull(cell.getValueArray(), cell.getValueOffset(),\n+        cell.getValueLength());\n+      if (ri != null) {\n+        if (regionsToMerge == null) {\n+          regionsToMerge = new LinkedHashMap<>();\n+        }\n+        regionsToMerge.put(Bytes.toString(CellUtil.cloneQualifier(cell)), ri);\n+      }\n+    }\n+    return regionsToMerge;\n+  }\n+\n+  /**\n+   * @return Deserialized regioninfo values taken from column values that match the regex\n+   *         'info:merge.*' in array of <code>cells</code>.\n+   */\n+  @Nullable\n+  public static List<RegionInfo> getMergeRegions(Cell[] cells) {\n+    Map<String, RegionInfo> mergeRegionsWithName = getMergeRegionsWithName(cells);\n+    return (mergeRegionsWithName == null) ? null : new ArrayList<>(mergeRegionsWithName.values());\n+  }\n+\n+  /**\n+   * @return True if any merge regions present in <code>cells</code>; i.e. the column in\n+   *         <code>cell</code> matches the regex 'info:merge.*'.\n+   */\n+  public static boolean hasMergeRegions(Cell[] cells) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDIzNzM1MQ=="}, "originalCommit": {"oid": "7644720fcaacd63587e08fc2b4c5c1dd2a3ef14a"}, "originalPosition": 54}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyODQ2NDg4OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/assignment/GCMergedRegionsProcedure.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wN1QwNzo0MjozN1rOHNzsxg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wN1QwODoxMTowOFrOHN1IDA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDI0MDU4Mg==", "bodyText": "Is it possible NPE in this long call chain?", "url": "https://github.com/apache/hbase/pull/2354#discussion_r484240582", "createdAt": "2020-09-07T07:42:37Z", "author": {"login": "infraio"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/assignment/GCMergedRegionsProcedure.java", "diffHunk": "@@ -88,7 +87,7 @@ protected Flow executeFromState(MasterProcedureEnv env, GCMergedRegionsState sta\n         setNextState(GCMergedRegionsState.GC_REGION_EDIT_METADATA);\n         break;\n       case GC_REGION_EDIT_METADATA:\n-        MetaTableAccessor.deleteMergeQualifiers(env.getMasterServices().getConnection(), mergedChild);\n+        env.getAssignmentManager().getRegionStateStore().deleteMergeQualifiers(mergedChild);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7644720fcaacd63587e08fc2b4c5c1dd2a3ef14a"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDI2Mzk0OA==", "bodyText": "In real deploy, no. In tests we could have null assignmentmanager or regionstatestore, but as the above pre commit is fine so I do not think it is a problem here.", "url": "https://github.com/apache/hbase/pull/2354#discussion_r484263948", "createdAt": "2020-09-07T08:11:08Z", "author": {"login": "Apache9"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/assignment/GCMergedRegionsProcedure.java", "diffHunk": "@@ -88,7 +87,7 @@ protected Flow executeFromState(MasterProcedureEnv env, GCMergedRegionsState sta\n         setNextState(GCMergedRegionsState.GC_REGION_EDIT_METADATA);\n         break;\n       case GC_REGION_EDIT_METADATA:\n-        MetaTableAccessor.deleteMergeQualifiers(env.getMasterServices().getConnection(), mergedChild);\n+        env.getAssignmentManager().getRegionStateStore().deleteMergeQualifiers(mergedChild);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDI0MDU4Mg=="}, "originalCommit": {"oid": "7644720fcaacd63587e08fc2b4c5c1dd2a3ef14a"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyODU4MDAxOnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/ReplicationBarrierFamilyFormat.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wN1QwODowMDozOVrOHN0wZA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wN1QwODoxODozM1rOHN1YZw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDI1Nzg5Mg==", "bodyText": "getReplicationBarrier => getReplicationBarriers? As this method return a arrary too.", "url": "https://github.com/apache/hbase/pull/2354#discussion_r484257892", "createdAt": "2020-09-07T08:00:39Z", "author": {"login": "infraio"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/ReplicationBarrierFamilyFormat.java", "diffHunk": "@@ -0,0 +1,261 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.replication;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.hbase.Cell;\n+import org.apache.hadoop.hbase.Cell.Type;\n+import org.apache.hadoop.hbase.CellBuilderFactory;\n+import org.apache.hadoop.hbase.CellBuilderType;\n+import org.apache.hadoop.hbase.ClientMetaTableAccessor;\n+import org.apache.hadoop.hbase.ClientMetaTableAccessor.QueryType;\n+import org.apache.hadoop.hbase.HConstants;\n+import org.apache.hadoop.hbase.MetaTableAccessor;\n+import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.Connection;\n+import org.apache.hadoop.hbase.client.Get;\n+import org.apache.hadoop.hbase.client.Put;\n+import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.Result;\n+import org.apache.hadoop.hbase.client.ResultScanner;\n+import org.apache.hadoop.hbase.client.Scan;\n+import org.apache.hadoop.hbase.client.Table;\n+import org.apache.hadoop.hbase.filter.FirstKeyOnlyFilter;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.RegionState.State;\n+import org.apache.hadoop.hbase.util.Bytes;\n+import org.apache.hadoop.hbase.util.Pair;\n+import org.apache.yetus.audience.InterfaceAudience;\n+\n+import org.apache.hbase.thirdparty.com.google.common.annotations.VisibleForTesting;\n+\n+/**\n+ * Helper class for storing replication barriers in family 'rep_barrier' of meta table.\n+ * <p/>\n+ * See SerialReplicationChecker on how to make use of the barriers.\n+ */\n+@InterfaceAudience.Private\n+public final class ReplicationBarrierFamilyFormat {\n+\n+  @VisibleForTesting\n+  public static final byte[] REPLICATION_PARENT_QUALIFIER = Bytes.toBytes(\"parent\");\n+\n+  private static final byte ESCAPE_BYTE = (byte) 0xFF;\n+\n+  private static final byte SEPARATED_BYTE = 0x00;\n+\n+  private ReplicationBarrierFamilyFormat() {\n+  }\n+\n+  public static void addReplicationBarrier(Put put, long openSeqNum) throws IOException {\n+    put.add(CellBuilderFactory.create(CellBuilderType.SHALLOW_COPY).setRow(put.getRow())\n+      .setFamily(HConstants.REPLICATION_BARRIER_FAMILY).setQualifier(HConstants.SEQNUM_QUALIFIER)\n+      .setTimestamp(put.getTimestamp()).setType(Type.Put).setValue(Bytes.toBytes(openSeqNum))\n+      .build());\n+  }\n+\n+  private static void writeRegionName(ByteArrayOutputStream out, byte[] regionName) {\n+    for (byte b : regionName) {\n+      if (b == ESCAPE_BYTE) {\n+        out.write(ESCAPE_BYTE);\n+      }\n+      out.write(b);\n+    }\n+  }\n+\n+  @VisibleForTesting\n+  public static byte[] getParentsBytes(List<RegionInfo> parents) {\n+    ByteArrayOutputStream bos = new ByteArrayOutputStream();\n+    Iterator<RegionInfo> iter = parents.iterator();\n+    writeRegionName(bos, iter.next().getRegionName());\n+    while (iter.hasNext()) {\n+      bos.write(ESCAPE_BYTE);\n+      bos.write(SEPARATED_BYTE);\n+      writeRegionName(bos, iter.next().getRegionName());\n+    }\n+    return bos.toByteArray();\n+  }\n+\n+  private static List<byte[]> parseParentsBytes(byte[] bytes) {\n+    List<byte[]> parents = new ArrayList<>();\n+    ByteArrayOutputStream bos = new ByteArrayOutputStream();\n+    for (int i = 0; i < bytes.length; i++) {\n+      if (bytes[i] == ESCAPE_BYTE) {\n+        i++;\n+        if (bytes[i] == SEPARATED_BYTE) {\n+          parents.add(bos.toByteArray());\n+          bos.reset();\n+          continue;\n+        }\n+        // fall through to append the byte\n+      }\n+      bos.write(bytes[i]);\n+    }\n+    if (bos.size() > 0) {\n+      parents.add(bos.toByteArray());\n+    }\n+    return parents;\n+  }\n+\n+  public static void addReplicationParent(Put put, List<RegionInfo> parents) throws IOException {\n+    byte[] value = getParentsBytes(parents);\n+    put.add(CellBuilderFactory.create(CellBuilderType.SHALLOW_COPY).setRow(put.getRow())\n+      .setFamily(HConstants.REPLICATION_BARRIER_FAMILY).setQualifier(REPLICATION_PARENT_QUALIFIER)\n+      .setTimestamp(put.getTimestamp()).setType(Type.Put).setValue(value).build());\n+  }\n+\n+  public static Put makePutForReplicationBarrier(RegionInfo regionInfo, long openSeqNum, long ts)\n+    throws IOException {\n+    Put put = new Put(regionInfo.getRegionName(), ts);\n+    addReplicationBarrier(put, openSeqNum);\n+    return put;\n+  }\n+\n+  public static final class ReplicationBarrierResult {\n+    private final long[] barriers;\n+    private final RegionState.State state;\n+    private final List<byte[]> parentRegionNames;\n+\n+    ReplicationBarrierResult(long[] barriers, State state, List<byte[]> parentRegionNames) {\n+      this.barriers = barriers;\n+      this.state = state;\n+      this.parentRegionNames = parentRegionNames;\n+    }\n+\n+    public long[] getBarriers() {\n+      return barriers;\n+    }\n+\n+    public RegionState.State getState() {\n+      return state;\n+    }\n+\n+    public List<byte[]> getParentRegionNames() {\n+      return parentRegionNames;\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return \"ReplicationBarrierResult [barriers=\" + Arrays.toString(barriers) + \", state=\" +\n+        state + \", parentRegionNames=\" +\n+        parentRegionNames.stream().map(Bytes::toStringBinary).collect(Collectors.joining(\", \")) +\n+        \"]\";\n+    }\n+  }\n+\n+  private static long getReplicationBarrier(Cell c) {\n+    return Bytes.toLong(c.getValueArray(), c.getValueOffset(), c.getValueLength());\n+  }\n+\n+  public static long[] getReplicationBarriers(Result result) {\n+    return result.getColumnCells(HConstants.REPLICATION_BARRIER_FAMILY, HConstants.SEQNUM_QUALIFIER)\n+      .stream().mapToLong(ReplicationBarrierFamilyFormat::getReplicationBarrier).sorted().distinct()\n+      .toArray();\n+  }\n+\n+  private static ReplicationBarrierResult getReplicationBarrierResult(Result result) {\n+    long[] barriers = getReplicationBarriers(result);\n+    byte[] stateBytes = result.getValue(HConstants.CATALOG_FAMILY, HConstants.STATE_QUALIFIER);\n+    RegionState.State state =\n+      stateBytes != null ? RegionState.State.valueOf(Bytes.toString(stateBytes)) : null;\n+    byte[] parentRegionsBytes =\n+      result.getValue(HConstants.REPLICATION_BARRIER_FAMILY, REPLICATION_PARENT_QUALIFIER);\n+    List<byte[]> parentRegionNames =\n+      parentRegionsBytes != null ? parseParentsBytes(parentRegionsBytes) : Collections.emptyList();\n+    return new ReplicationBarrierResult(barriers, state, parentRegionNames);\n+  }\n+\n+  public static ReplicationBarrierResult getReplicationBarrierResult(Connection conn,\n+    TableName tableName, byte[] row, byte[] encodedRegionName) throws IOException {\n+    byte[] metaStartKey = RegionInfo.createRegionName(tableName, row, HConstants.NINES, false);\n+    byte[] metaStopKey =\n+      RegionInfo.createRegionName(tableName, HConstants.EMPTY_START_ROW, \"\", false);\n+    Scan scan = new Scan().withStartRow(metaStartKey).withStopRow(metaStopKey)\n+      .addColumn(HConstants.CATALOG_FAMILY, HConstants.STATE_QUALIFIER)\n+      .addFamily(HConstants.REPLICATION_BARRIER_FAMILY).readAllVersions().setReversed(true)\n+      .setCaching(10);\n+    try (Table table = conn.getTable(TableName.META_TABLE_NAME);\n+      ResultScanner scanner = table.getScanner(scan)) {\n+      for (Result result;;) {\n+        result = scanner.next();\n+        if (result == null) {\n+          return new ReplicationBarrierResult(new long[0], null, Collections.emptyList());\n+        }\n+        byte[] regionName = result.getRow();\n+        // TODO: we may look up a region which has already been split or merged so we need to check\n+        // whether the encoded name matches. Need to find a way to quit earlier when there is no\n+        // record for the given region, for now it will scan to the end of the table.\n+        if (!Bytes.equals(encodedRegionName,\n+          Bytes.toBytes(RegionInfo.encodeRegionName(regionName)))) {\n+          continue;\n+        }\n+        return getReplicationBarrierResult(result);\n+      }\n+    }\n+  }\n+\n+  public static long[] getReplicationBarrier(Connection conn, byte[] regionName)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7644720fcaacd63587e08fc2b4c5c1dd2a3ef14a"}, "originalPosition": 219}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDI2ODEzNQ==", "bodyText": "Done.", "url": "https://github.com/apache/hbase/pull/2354#discussion_r484268135", "createdAt": "2020-09-07T08:18:33Z", "author": {"login": "Apache9"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/ReplicationBarrierFamilyFormat.java", "diffHunk": "@@ -0,0 +1,261 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.replication;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.hbase.Cell;\n+import org.apache.hadoop.hbase.Cell.Type;\n+import org.apache.hadoop.hbase.CellBuilderFactory;\n+import org.apache.hadoop.hbase.CellBuilderType;\n+import org.apache.hadoop.hbase.ClientMetaTableAccessor;\n+import org.apache.hadoop.hbase.ClientMetaTableAccessor.QueryType;\n+import org.apache.hadoop.hbase.HConstants;\n+import org.apache.hadoop.hbase.MetaTableAccessor;\n+import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.Connection;\n+import org.apache.hadoop.hbase.client.Get;\n+import org.apache.hadoop.hbase.client.Put;\n+import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.Result;\n+import org.apache.hadoop.hbase.client.ResultScanner;\n+import org.apache.hadoop.hbase.client.Scan;\n+import org.apache.hadoop.hbase.client.Table;\n+import org.apache.hadoop.hbase.filter.FirstKeyOnlyFilter;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.RegionState.State;\n+import org.apache.hadoop.hbase.util.Bytes;\n+import org.apache.hadoop.hbase.util.Pair;\n+import org.apache.yetus.audience.InterfaceAudience;\n+\n+import org.apache.hbase.thirdparty.com.google.common.annotations.VisibleForTesting;\n+\n+/**\n+ * Helper class for storing replication barriers in family 'rep_barrier' of meta table.\n+ * <p/>\n+ * See SerialReplicationChecker on how to make use of the barriers.\n+ */\n+@InterfaceAudience.Private\n+public final class ReplicationBarrierFamilyFormat {\n+\n+  @VisibleForTesting\n+  public static final byte[] REPLICATION_PARENT_QUALIFIER = Bytes.toBytes(\"parent\");\n+\n+  private static final byte ESCAPE_BYTE = (byte) 0xFF;\n+\n+  private static final byte SEPARATED_BYTE = 0x00;\n+\n+  private ReplicationBarrierFamilyFormat() {\n+  }\n+\n+  public static void addReplicationBarrier(Put put, long openSeqNum) throws IOException {\n+    put.add(CellBuilderFactory.create(CellBuilderType.SHALLOW_COPY).setRow(put.getRow())\n+      .setFamily(HConstants.REPLICATION_BARRIER_FAMILY).setQualifier(HConstants.SEQNUM_QUALIFIER)\n+      .setTimestamp(put.getTimestamp()).setType(Type.Put).setValue(Bytes.toBytes(openSeqNum))\n+      .build());\n+  }\n+\n+  private static void writeRegionName(ByteArrayOutputStream out, byte[] regionName) {\n+    for (byte b : regionName) {\n+      if (b == ESCAPE_BYTE) {\n+        out.write(ESCAPE_BYTE);\n+      }\n+      out.write(b);\n+    }\n+  }\n+\n+  @VisibleForTesting\n+  public static byte[] getParentsBytes(List<RegionInfo> parents) {\n+    ByteArrayOutputStream bos = new ByteArrayOutputStream();\n+    Iterator<RegionInfo> iter = parents.iterator();\n+    writeRegionName(bos, iter.next().getRegionName());\n+    while (iter.hasNext()) {\n+      bos.write(ESCAPE_BYTE);\n+      bos.write(SEPARATED_BYTE);\n+      writeRegionName(bos, iter.next().getRegionName());\n+    }\n+    return bos.toByteArray();\n+  }\n+\n+  private static List<byte[]> parseParentsBytes(byte[] bytes) {\n+    List<byte[]> parents = new ArrayList<>();\n+    ByteArrayOutputStream bos = new ByteArrayOutputStream();\n+    for (int i = 0; i < bytes.length; i++) {\n+      if (bytes[i] == ESCAPE_BYTE) {\n+        i++;\n+        if (bytes[i] == SEPARATED_BYTE) {\n+          parents.add(bos.toByteArray());\n+          bos.reset();\n+          continue;\n+        }\n+        // fall through to append the byte\n+      }\n+      bos.write(bytes[i]);\n+    }\n+    if (bos.size() > 0) {\n+      parents.add(bos.toByteArray());\n+    }\n+    return parents;\n+  }\n+\n+  public static void addReplicationParent(Put put, List<RegionInfo> parents) throws IOException {\n+    byte[] value = getParentsBytes(parents);\n+    put.add(CellBuilderFactory.create(CellBuilderType.SHALLOW_COPY).setRow(put.getRow())\n+      .setFamily(HConstants.REPLICATION_BARRIER_FAMILY).setQualifier(REPLICATION_PARENT_QUALIFIER)\n+      .setTimestamp(put.getTimestamp()).setType(Type.Put).setValue(value).build());\n+  }\n+\n+  public static Put makePutForReplicationBarrier(RegionInfo regionInfo, long openSeqNum, long ts)\n+    throws IOException {\n+    Put put = new Put(regionInfo.getRegionName(), ts);\n+    addReplicationBarrier(put, openSeqNum);\n+    return put;\n+  }\n+\n+  public static final class ReplicationBarrierResult {\n+    private final long[] barriers;\n+    private final RegionState.State state;\n+    private final List<byte[]> parentRegionNames;\n+\n+    ReplicationBarrierResult(long[] barriers, State state, List<byte[]> parentRegionNames) {\n+      this.barriers = barriers;\n+      this.state = state;\n+      this.parentRegionNames = parentRegionNames;\n+    }\n+\n+    public long[] getBarriers() {\n+      return barriers;\n+    }\n+\n+    public RegionState.State getState() {\n+      return state;\n+    }\n+\n+    public List<byte[]> getParentRegionNames() {\n+      return parentRegionNames;\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return \"ReplicationBarrierResult [barriers=\" + Arrays.toString(barriers) + \", state=\" +\n+        state + \", parentRegionNames=\" +\n+        parentRegionNames.stream().map(Bytes::toStringBinary).collect(Collectors.joining(\", \")) +\n+        \"]\";\n+    }\n+  }\n+\n+  private static long getReplicationBarrier(Cell c) {\n+    return Bytes.toLong(c.getValueArray(), c.getValueOffset(), c.getValueLength());\n+  }\n+\n+  public static long[] getReplicationBarriers(Result result) {\n+    return result.getColumnCells(HConstants.REPLICATION_BARRIER_FAMILY, HConstants.SEQNUM_QUALIFIER)\n+      .stream().mapToLong(ReplicationBarrierFamilyFormat::getReplicationBarrier).sorted().distinct()\n+      .toArray();\n+  }\n+\n+  private static ReplicationBarrierResult getReplicationBarrierResult(Result result) {\n+    long[] barriers = getReplicationBarriers(result);\n+    byte[] stateBytes = result.getValue(HConstants.CATALOG_FAMILY, HConstants.STATE_QUALIFIER);\n+    RegionState.State state =\n+      stateBytes != null ? RegionState.State.valueOf(Bytes.toString(stateBytes)) : null;\n+    byte[] parentRegionsBytes =\n+      result.getValue(HConstants.REPLICATION_BARRIER_FAMILY, REPLICATION_PARENT_QUALIFIER);\n+    List<byte[]> parentRegionNames =\n+      parentRegionsBytes != null ? parseParentsBytes(parentRegionsBytes) : Collections.emptyList();\n+    return new ReplicationBarrierResult(barriers, state, parentRegionNames);\n+  }\n+\n+  public static ReplicationBarrierResult getReplicationBarrierResult(Connection conn,\n+    TableName tableName, byte[] row, byte[] encodedRegionName) throws IOException {\n+    byte[] metaStartKey = RegionInfo.createRegionName(tableName, row, HConstants.NINES, false);\n+    byte[] metaStopKey =\n+      RegionInfo.createRegionName(tableName, HConstants.EMPTY_START_ROW, \"\", false);\n+    Scan scan = new Scan().withStartRow(metaStartKey).withStopRow(metaStopKey)\n+      .addColumn(HConstants.CATALOG_FAMILY, HConstants.STATE_QUALIFIER)\n+      .addFamily(HConstants.REPLICATION_BARRIER_FAMILY).readAllVersions().setReversed(true)\n+      .setCaching(10);\n+    try (Table table = conn.getTable(TableName.META_TABLE_NAME);\n+      ResultScanner scanner = table.getScanner(scan)) {\n+      for (Result result;;) {\n+        result = scanner.next();\n+        if (result == null) {\n+          return new ReplicationBarrierResult(new long[0], null, Collections.emptyList());\n+        }\n+        byte[] regionName = result.getRow();\n+        // TODO: we may look up a region which has already been split or merged so we need to check\n+        // whether the encoded name matches. Need to find a way to quit earlier when there is no\n+        // record for the given region, for now it will scan to the end of the table.\n+        if (!Bytes.equals(encodedRegionName,\n+          Bytes.toBytes(RegionInfo.encodeRegionName(regionName)))) {\n+          continue;\n+        }\n+        return getReplicationBarrierResult(result);\n+      }\n+    }\n+  }\n+\n+  public static long[] getReplicationBarrier(Connection conn, byte[] regionName)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDI1Nzg5Mg=="}, "originalCommit": {"oid": "7644720fcaacd63587e08fc2b4c5c1dd2a3ef14a"}, "originalPosition": 219}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2598, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}