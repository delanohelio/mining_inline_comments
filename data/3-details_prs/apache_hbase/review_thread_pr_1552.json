{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDA2MDY1ODg0", "number": 1552, "reviewThreads": {"totalCount": 31, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQxMDo1NTo0OFrOD0sYpw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQxNToyMjo0OVrOEF_X2g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU2NTc5NzUxOnYy", "diffSide": "RIGHT", "path": "hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSourceFactoryImpl.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQxMDo1NTo0OFrOGJwOLw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQxMDoxMTo1NFrOGLQmxA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg4MDQzMQ==", "bodyText": "wrapper argument can be removed?", "url": "https://github.com/apache/hbase/pull/1552#discussion_r412880431", "createdAt": "2020-04-22T10:55:48Z", "author": {"login": "virajjasani"}, "path": "hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSourceFactoryImpl.java", "diffHunk": "@@ -45,6 +46,16 @@ private synchronized MetricsRegionAggregateSourceImpl getRegionAggregate() {\n     }\n   }\n \n+  private synchronized MetricsStoreAggregateSourceImpl\n+      getStoreAggregate(MetricsStoreWrapper wrapper) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1dd15b7615f61fab4d27239c72ca970712f4b7f1"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDQ1OTU4OA==", "bodyText": "Ya not needed.", "url": "https://github.com/apache/hbase/pull/1552#discussion_r414459588", "createdAt": "2020-04-24T10:11:54Z", "author": {"login": "ramkrish86"}, "path": "hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSourceFactoryImpl.java", "diffHunk": "@@ -45,6 +46,16 @@ private synchronized MetricsRegionAggregateSourceImpl getRegionAggregate() {\n     }\n   }\n \n+  private synchronized MetricsStoreAggregateSourceImpl\n+      getStoreAggregate(MetricsStoreWrapper wrapper) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg4MDQzMQ=="}, "originalCommit": {"oid": "1dd15b7615f61fab4d27239c72ca970712f4b7f1"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU2NTgwMDA4OnYy", "diffSide": "RIGHT", "path": "hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsStoreAggregateSourceImpl.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQxMDo1NjoxOVrOGJwPnQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQxMDoxNDo0MFrOGLQtBQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg4MDc5Nw==", "bodyText": "nit: Collections.newSetFromMap(new ConcurrentHashMap<>())", "url": "https://github.com/apache/hbase/pull/1552#discussion_r412880797", "createdAt": "2020-04-22T10:56:19Z", "author": {"login": "virajjasani"}, "path": "hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsStoreAggregateSourceImpl.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.regionserver;\n+\n+import java.util.Collections;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.hadoop.hbase.metrics.BaseSourceImpl;\n+import org.apache.hadoop.hbase.metrics.MetricRegistry;\n+import org.apache.hadoop.metrics2.MetricsCollector;\n+import org.apache.hadoop.metrics2.MetricsRecordBuilder;\n+import org.apache.hadoop.metrics2.impl.JmxCacheBuster;\n+import org.apache.hadoop.metrics2.lib.MetricsExecutorImpl;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+@InterfaceAudience.Private\n+public class MetricsStoreAggregateSourceImpl extends BaseSourceImpl\n+    implements MetricsStoreAggregateSource {\n+  private static final Logger LOG = LoggerFactory.getLogger(MetricsStoreAggregateSourceImpl.class);\n+\n+  private final MetricsExecutorImpl executor = new MetricsExecutorImpl();\n+\n+  private final Set<MetricsStoreSource> storeSources =\n+      Collections.newSetFromMap(new ConcurrentHashMap<MetricsStoreSource, Boolean>());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1dd15b7615f61fab4d27239c72ca970712f4b7f1"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDQ2MTE4OQ==", "bodyText": "the compiler was saying some warnings. Hence left it as is.", "url": "https://github.com/apache/hbase/pull/1552#discussion_r414461189", "createdAt": "2020-04-24T10:14:40Z", "author": {"login": "ramkrish86"}, "path": "hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsStoreAggregateSourceImpl.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.regionserver;\n+\n+import java.util.Collections;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.hadoop.hbase.metrics.BaseSourceImpl;\n+import org.apache.hadoop.hbase.metrics.MetricRegistry;\n+import org.apache.hadoop.metrics2.MetricsCollector;\n+import org.apache.hadoop.metrics2.MetricsRecordBuilder;\n+import org.apache.hadoop.metrics2.impl.JmxCacheBuster;\n+import org.apache.hadoop.metrics2.lib.MetricsExecutorImpl;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+@InterfaceAudience.Private\n+public class MetricsStoreAggregateSourceImpl extends BaseSourceImpl\n+    implements MetricsStoreAggregateSource {\n+  private static final Logger LOG = LoggerFactory.getLogger(MetricsStoreAggregateSourceImpl.class);\n+\n+  private final MetricsExecutorImpl executor = new MetricsExecutorImpl();\n+\n+  private final Set<MetricsStoreSource> storeSources =\n+      Collections.newSetFromMap(new ConcurrentHashMap<MetricsStoreSource, Boolean>());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg4MDc5Nw=="}, "originalCommit": {"oid": "1dd15b7615f61fab4d27239c72ca970712f4b7f1"}, "originalPosition": 43}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU2NTgwMjA0OnYy", "diffSide": "RIGHT", "path": "hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsStoreAggregateSourceImpl.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQxMDo1Njo1MFrOGJwQ1w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQxMDoxODowNlrOGLQ1Jw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg4MTExMQ==", "bodyText": "Good to have LOG.error here?", "url": "https://github.com/apache/hbase/pull/1552#discussion_r412881111", "createdAt": "2020-04-22T10:56:50Z", "author": {"login": "virajjasani"}, "path": "hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsStoreAggregateSourceImpl.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.regionserver;\n+\n+import java.util.Collections;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.hadoop.hbase.metrics.BaseSourceImpl;\n+import org.apache.hadoop.hbase.metrics.MetricRegistry;\n+import org.apache.hadoop.metrics2.MetricsCollector;\n+import org.apache.hadoop.metrics2.MetricsRecordBuilder;\n+import org.apache.hadoop.metrics2.impl.JmxCacheBuster;\n+import org.apache.hadoop.metrics2.lib.MetricsExecutorImpl;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+@InterfaceAudience.Private\n+public class MetricsStoreAggregateSourceImpl extends BaseSourceImpl\n+    implements MetricsStoreAggregateSource {\n+  private static final Logger LOG = LoggerFactory.getLogger(MetricsStoreAggregateSourceImpl.class);\n+\n+  private final MetricsExecutorImpl executor = new MetricsExecutorImpl();\n+\n+  private final Set<MetricsStoreSource> storeSources =\n+      Collections.newSetFromMap(new ConcurrentHashMap<MetricsStoreSource, Boolean>());\n+\n+  public MetricsStoreAggregateSourceImpl() {\n+    this(METRICS_NAME, METRICS_DESCRIPTION, METRICS_CONTEXT, METRICS_JMX_CONTEXT);\n+  }\n+\n+\n+  public MetricsStoreAggregateSourceImpl(String metricsName,\n+                                          String metricsDescription,\n+                                          String metricsContext,\n+                                          String metricsJmxContext) {\n+    super(metricsName, metricsDescription, metricsContext, metricsJmxContext);\n+\n+    // Every few mins clean the JMX cache.\n+    executor.getExecutor().scheduleWithFixedDelay(new Runnable() {\n+      public void run() {\n+        JmxCacheBuster.clearJmxCache();\n+      }\n+    }, 5, 5, TimeUnit.MINUTES);\n+  }\n+\n+  public MetricRegistry getMetricRegistry() {\n+    return registry;\n+  }\n+\n+  @Override\n+  public void register(MetricsStoreSource source) {\n+    storeSources.add(source);\n+    clearCache();\n+  }\n+\n+  @Override\n+  public void deregister(MetricsStoreSource toRemove) {\n+    try {\n+      storeSources.remove(toRemove);\n+    } catch (Exception e) {\n+      // Ignored. If this errors out it means that someone is double\n+      // closing the region source and the region is already nulled out.\n+      LOG.info(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1dd15b7615f61fab4d27239c72ca970712f4b7f1"}, "originalPosition": 81}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDQ2MzI3MQ==", "bodyText": "Actually the removal is not needed to handle throw catch. I just used what was being done in MetricsREgionAggregateSource. Seems that is not needed.", "url": "https://github.com/apache/hbase/pull/1552#discussion_r414463271", "createdAt": "2020-04-24T10:18:06Z", "author": {"login": "ramkrish86"}, "path": "hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsStoreAggregateSourceImpl.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.regionserver;\n+\n+import java.util.Collections;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.hadoop.hbase.metrics.BaseSourceImpl;\n+import org.apache.hadoop.hbase.metrics.MetricRegistry;\n+import org.apache.hadoop.metrics2.MetricsCollector;\n+import org.apache.hadoop.metrics2.MetricsRecordBuilder;\n+import org.apache.hadoop.metrics2.impl.JmxCacheBuster;\n+import org.apache.hadoop.metrics2.lib.MetricsExecutorImpl;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+@InterfaceAudience.Private\n+public class MetricsStoreAggregateSourceImpl extends BaseSourceImpl\n+    implements MetricsStoreAggregateSource {\n+  private static final Logger LOG = LoggerFactory.getLogger(MetricsStoreAggregateSourceImpl.class);\n+\n+  private final MetricsExecutorImpl executor = new MetricsExecutorImpl();\n+\n+  private final Set<MetricsStoreSource> storeSources =\n+      Collections.newSetFromMap(new ConcurrentHashMap<MetricsStoreSource, Boolean>());\n+\n+  public MetricsStoreAggregateSourceImpl() {\n+    this(METRICS_NAME, METRICS_DESCRIPTION, METRICS_CONTEXT, METRICS_JMX_CONTEXT);\n+  }\n+\n+\n+  public MetricsStoreAggregateSourceImpl(String metricsName,\n+                                          String metricsDescription,\n+                                          String metricsContext,\n+                                          String metricsJmxContext) {\n+    super(metricsName, metricsDescription, metricsContext, metricsJmxContext);\n+\n+    // Every few mins clean the JMX cache.\n+    executor.getExecutor().scheduleWithFixedDelay(new Runnable() {\n+      public void run() {\n+        JmxCacheBuster.clearJmxCache();\n+      }\n+    }, 5, 5, TimeUnit.MINUTES);\n+  }\n+\n+  public MetricRegistry getMetricRegistry() {\n+    return registry;\n+  }\n+\n+  @Override\n+  public void register(MetricsStoreSource source) {\n+    storeSources.add(source);\n+    clearCache();\n+  }\n+\n+  @Override\n+  public void deregister(MetricsStoreSource toRemove) {\n+    try {\n+      storeSources.remove(toRemove);\n+    } catch (Exception e) {\n+      // Ignored. If this errors out it means that someone is double\n+      // closing the region source and the region is already nulled out.\n+      LOG.info(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg4MTExMQ=="}, "originalCommit": {"oid": "1dd15b7615f61fab4d27239c72ca970712f4b7f1"}, "originalPosition": 81}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU2NTgwNTUxOnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsStore.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQxMDo1Nzo0OVrOGJwS-w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQxMDoxOToxMlrOGLQ3xw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg4MTY1OQ==", "bodyText": "We can remove conf", "url": "https://github.com/apache/hbase/pull/1552#discussion_r412881659", "createdAt": "2020-04-22T10:57:49Z", "author": {"login": "virajjasani"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsStore.java", "diffHunk": "@@ -0,0 +1,59 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.regionserver;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.CompatibilitySingletonFactory;\n+import org.apache.yetus.audience.InterfaceAudience;\n+\n+@InterfaceAudience.Private\n+public class MetricsStore {\n+  private final MetricsStoreSource source;\n+  private MetricsStoreWrapper storeWrapper;\n+\n+  public MetricsStore(final MetricsStoreWrapper wrapper, Configuration conf) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1dd15b7615f61fab4d27239c72ca970712f4b7f1"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDQ2Mzk0Mw==", "bodyText": "Done.", "url": "https://github.com/apache/hbase/pull/1552#discussion_r414463943", "createdAt": "2020-04-24T10:19:12Z", "author": {"login": "ramkrish86"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsStore.java", "diffHunk": "@@ -0,0 +1,59 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.regionserver;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.CompatibilitySingletonFactory;\n+import org.apache.yetus.audience.InterfaceAudience;\n+\n+@InterfaceAudience.Private\n+public class MetricsStore {\n+  private final MetricsStoreSource source;\n+  private MetricsStoreWrapper storeWrapper;\n+\n+  public MetricsStore(final MetricsStoreWrapper wrapper, Configuration conf) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg4MTY1OQ=="}, "originalCommit": {"oid": "1dd15b7615f61fab4d27239c72ca970712f4b7f1"}, "originalPosition": 29}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU2NTgxMTI4OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsStoreWrapperImpl.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQxMDo1OTowOFrOGJwWZA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQxMDoxOTo1M1rOGLQ5hQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg4MjUzMg==", "bodyText": "Would you like to use LOG somewhere? Or maybe dropped the idea and hence it's not being used?", "url": "https://github.com/apache/hbase/pull/1552#discussion_r412882532", "createdAt": "2020-04-22T10:59:08Z", "author": {"login": "virajjasani"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsStoreWrapperImpl.java", "diffHunk": "@@ -0,0 +1,194 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.regionserver;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.hadoop.hbase.CompatibilitySingletonFactory;\n+import org.apache.hadoop.metrics2.MetricsExecutor;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+@InterfaceAudience.Private\n+public class MetricsStoreWrapperImpl implements MetricsStoreWrapper, Closeable {\n+\n+  private final HStore store;\n+  private static final Logger LOG = LoggerFactory.getLogger(MetricsStoreWrapperImpl.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1dd15b7615f61fab4d27239c72ca970712f4b7f1"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDQ2NDM4OQ==", "bodyText": "Removed it.", "url": "https://github.com/apache/hbase/pull/1552#discussion_r414464389", "createdAt": "2020-04-24T10:19:53Z", "author": {"login": "ramkrish86"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsStoreWrapperImpl.java", "diffHunk": "@@ -0,0 +1,194 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.regionserver;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.hadoop.hbase.CompatibilitySingletonFactory;\n+import org.apache.hadoop.metrics2.MetricsExecutor;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+@InterfaceAudience.Private\n+public class MetricsStoreWrapperImpl implements MetricsStoreWrapper, Closeable {\n+\n+  private final HStore store;\n+  private static final Logger LOG = LoggerFactory.getLogger(MetricsStoreWrapperImpl.class);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg4MjUzMg=="}, "originalCommit": {"oid": "1dd15b7615f61fab4d27239c72ca970712f4b7f1"}, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU2NTgxOTM4OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsStoreWrapperImpl.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQxMTowMToxMFrOGJwbIQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQxMDoyMDoxMVrOGLQ6GQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg4Mzc0NQ==", "bodyText": "Noted. For this change, is it good to give name memstoreDataSize ?", "url": "https://github.com/apache/hbase/pull/1552#discussion_r412883745", "createdAt": "2020-04-22T11:01:10Z", "author": {"login": "virajjasani"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsStoreWrapperImpl.java", "diffHunk": "@@ -0,0 +1,194 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.regionserver;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.hadoop.hbase.CompatibilitySingletonFactory;\n+import org.apache.hadoop.metrics2.MetricsExecutor;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+@InterfaceAudience.Private\n+public class MetricsStoreWrapperImpl implements MetricsStoreWrapper, Closeable {\n+\n+  private final HStore store;\n+  private static final Logger LOG = LoggerFactory.getLogger(MetricsStoreWrapperImpl.class);\n+\n+  public static final int PERIOD = 45;\n+  public static final String UNKNOWN = \"unknown\";\n+  private ScheduledExecutorService executor;\n+  private Runnable runnable;\n+  // add others also. check if anything is redundant\n+  private long numStoreFiles;\n+  private long memstoreSize;\n+  private long storeFileSize;\n+  private long getsFromMemstore;\n+  private long getsOnStore;\n+  private long getsOnFile;\n+  private long numReferenceFiles;\n+  private long minStoreFileAge;\n+  private long maxStoreFileAge;\n+  private long avgStoreFileAge;\n+  private long numHFiles;\n+  private int storeRefCount;\n+\n+  private ScheduledFuture<?> storeMetricUpdateTask;\n+\n+  public MetricsStoreWrapperImpl(HStore store) {\n+    this.store = store;\n+    this.executor = CompatibilitySingletonFactory.getInstance(MetricsExecutor.class).getExecutor();\n+    this.runnable = new HStoreMetricsWrapperRunnable();\n+    this.storeMetricUpdateTask =\n+        this.executor.scheduleWithFixedDelay(this.runnable, PERIOD, PERIOD, TimeUnit.SECONDS);\n+  }\n+\n+  @Override\n+  public void close() throws IOException {\n+    storeMetricUpdateTask.cancel(true);\n+  }\n+\n+  @Override\n+  public String getStoreName() {\n+    return store.getColumnFamilyName();\n+  }\n+\n+  @Override\n+  public String getRegionName() {\n+    return store.getRegionInfo().getRegionNameAsString();\n+  }\n+\n+  @Override\n+  public String getTableName() {\n+    return store.getRegionInfo().getTable().getNameAsString();\n+  }\n+\n+  @Override\n+  public String getNamespace() {\n+    return store.getTableName().getNamespaceAsString();\n+  }\n+\n+  @Override\n+  public long getNumStoreFiles() {\n+    return numStoreFiles;\n+  }\n+\n+  @Override\n+  public long getMemStoreSize() {\n+    // todo : change this - we need to expose data, heapsize and offheapdatasize", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1dd15b7615f61fab4d27239c72ca970712f4b7f1"}, "originalPosition": 100}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzI0NjA1OA==", "bodyText": "So that next time when we add heapsize and offheapdatasize, we can give name: memstoreHeapSize, memstoreOffHeapSize etc.\nYour call.", "url": "https://github.com/apache/hbase/pull/1552#discussion_r413246058", "createdAt": "2020-04-22T19:06:52Z", "author": {"login": "virajjasani"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsStoreWrapperImpl.java", "diffHunk": "@@ -0,0 +1,194 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.regionserver;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.hadoop.hbase.CompatibilitySingletonFactory;\n+import org.apache.hadoop.metrics2.MetricsExecutor;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+@InterfaceAudience.Private\n+public class MetricsStoreWrapperImpl implements MetricsStoreWrapper, Closeable {\n+\n+  private final HStore store;\n+  private static final Logger LOG = LoggerFactory.getLogger(MetricsStoreWrapperImpl.class);\n+\n+  public static final int PERIOD = 45;\n+  public static final String UNKNOWN = \"unknown\";\n+  private ScheduledExecutorService executor;\n+  private Runnable runnable;\n+  // add others also. check if anything is redundant\n+  private long numStoreFiles;\n+  private long memstoreSize;\n+  private long storeFileSize;\n+  private long getsFromMemstore;\n+  private long getsOnStore;\n+  private long getsOnFile;\n+  private long numReferenceFiles;\n+  private long minStoreFileAge;\n+  private long maxStoreFileAge;\n+  private long avgStoreFileAge;\n+  private long numHFiles;\n+  private int storeRefCount;\n+\n+  private ScheduledFuture<?> storeMetricUpdateTask;\n+\n+  public MetricsStoreWrapperImpl(HStore store) {\n+    this.store = store;\n+    this.executor = CompatibilitySingletonFactory.getInstance(MetricsExecutor.class).getExecutor();\n+    this.runnable = new HStoreMetricsWrapperRunnable();\n+    this.storeMetricUpdateTask =\n+        this.executor.scheduleWithFixedDelay(this.runnable, PERIOD, PERIOD, TimeUnit.SECONDS);\n+  }\n+\n+  @Override\n+  public void close() throws IOException {\n+    storeMetricUpdateTask.cancel(true);\n+  }\n+\n+  @Override\n+  public String getStoreName() {\n+    return store.getColumnFamilyName();\n+  }\n+\n+  @Override\n+  public String getRegionName() {\n+    return store.getRegionInfo().getRegionNameAsString();\n+  }\n+\n+  @Override\n+  public String getTableName() {\n+    return store.getRegionInfo().getTable().getNameAsString();\n+  }\n+\n+  @Override\n+  public String getNamespace() {\n+    return store.getTableName().getNamespaceAsString();\n+  }\n+\n+  @Override\n+  public long getNumStoreFiles() {\n+    return numStoreFiles;\n+  }\n+\n+  @Override\n+  public long getMemStoreSize() {\n+    // todo : change this - we need to expose data, heapsize and offheapdatasize", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg4Mzc0NQ=="}, "originalCommit": {"oid": "1dd15b7615f61fab4d27239c72ca970712f4b7f1"}, "originalPosition": 100}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDQ2NDUzNw==", "bodyText": "For now lets be it this way. All other metrics has to be changed. We can do it that time.", "url": "https://github.com/apache/hbase/pull/1552#discussion_r414464537", "createdAt": "2020-04-24T10:20:11Z", "author": {"login": "ramkrish86"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsStoreWrapperImpl.java", "diffHunk": "@@ -0,0 +1,194 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.regionserver;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.hadoop.hbase.CompatibilitySingletonFactory;\n+import org.apache.hadoop.metrics2.MetricsExecutor;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+@InterfaceAudience.Private\n+public class MetricsStoreWrapperImpl implements MetricsStoreWrapper, Closeable {\n+\n+  private final HStore store;\n+  private static final Logger LOG = LoggerFactory.getLogger(MetricsStoreWrapperImpl.class);\n+\n+  public static final int PERIOD = 45;\n+  public static final String UNKNOWN = \"unknown\";\n+  private ScheduledExecutorService executor;\n+  private Runnable runnable;\n+  // add others also. check if anything is redundant\n+  private long numStoreFiles;\n+  private long memstoreSize;\n+  private long storeFileSize;\n+  private long getsFromMemstore;\n+  private long getsOnStore;\n+  private long getsOnFile;\n+  private long numReferenceFiles;\n+  private long minStoreFileAge;\n+  private long maxStoreFileAge;\n+  private long avgStoreFileAge;\n+  private long numHFiles;\n+  private int storeRefCount;\n+\n+  private ScheduledFuture<?> storeMetricUpdateTask;\n+\n+  public MetricsStoreWrapperImpl(HStore store) {\n+    this.store = store;\n+    this.executor = CompatibilitySingletonFactory.getInstance(MetricsExecutor.class).getExecutor();\n+    this.runnable = new HStoreMetricsWrapperRunnable();\n+    this.storeMetricUpdateTask =\n+        this.executor.scheduleWithFixedDelay(this.runnable, PERIOD, PERIOD, TimeUnit.SECONDS);\n+  }\n+\n+  @Override\n+  public void close() throws IOException {\n+    storeMetricUpdateTask.cancel(true);\n+  }\n+\n+  @Override\n+  public String getStoreName() {\n+    return store.getColumnFamilyName();\n+  }\n+\n+  @Override\n+  public String getRegionName() {\n+    return store.getRegionInfo().getRegionNameAsString();\n+  }\n+\n+  @Override\n+  public String getTableName() {\n+    return store.getRegionInfo().getTable().getNameAsString();\n+  }\n+\n+  @Override\n+  public String getNamespace() {\n+    return store.getTableName().getNamespaceAsString();\n+  }\n+\n+  @Override\n+  public long getNumStoreFiles() {\n+    return numStoreFiles;\n+  }\n+\n+  @Override\n+  public long getMemStoreSize() {\n+    // todo : change this - we need to expose data, heapsize and offheapdatasize", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg4Mzc0NQ=="}, "originalCommit": {"oid": "1dd15b7615f61fab4d27239c72ca970712f4b7f1"}, "originalPosition": 100}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU2NTgyMzkwOnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsStoreWrapperImpl.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQxMTowMjoyNVrOGJwd9w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQxMDoyMzoyOFrOGLRBtw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg4NDQ3MQ==", "bodyText": "executor and runnable both could be local variable", "url": "https://github.com/apache/hbase/pull/1552#discussion_r412884471", "createdAt": "2020-04-22T11:02:25Z", "author": {"login": "virajjasani"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsStoreWrapperImpl.java", "diffHunk": "@@ -0,0 +1,194 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.regionserver;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.hadoop.hbase.CompatibilitySingletonFactory;\n+import org.apache.hadoop.metrics2.MetricsExecutor;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+@InterfaceAudience.Private\n+public class MetricsStoreWrapperImpl implements MetricsStoreWrapper, Closeable {\n+\n+  private final HStore store;\n+  private static final Logger LOG = LoggerFactory.getLogger(MetricsStoreWrapperImpl.class);\n+\n+  public static final int PERIOD = 45;\n+  public static final String UNKNOWN = \"unknown\";\n+  private ScheduledExecutorService executor;\n+  private Runnable runnable;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1dd15b7615f61fab4d27239c72ca970712f4b7f1"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDQ2NjQ4Nw==", "bodyText": "Sure.", "url": "https://github.com/apache/hbase/pull/1552#discussion_r414466487", "createdAt": "2020-04-24T10:23:28Z", "author": {"login": "ramkrish86"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsStoreWrapperImpl.java", "diffHunk": "@@ -0,0 +1,194 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.regionserver;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.OptionalDouble;\n+import java.util.OptionalLong;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.hadoop.hbase.CompatibilitySingletonFactory;\n+import org.apache.hadoop.metrics2.MetricsExecutor;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+@InterfaceAudience.Private\n+public class MetricsStoreWrapperImpl implements MetricsStoreWrapper, Closeable {\n+\n+  private final HStore store;\n+  private static final Logger LOG = LoggerFactory.getLogger(MetricsStoreWrapperImpl.class);\n+\n+  public static final int PERIOD = 45;\n+  public static final String UNKNOWN = \"unknown\";\n+  private ScheduledExecutorService executor;\n+  private Runnable runnable;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg4NDQ3MQ=="}, "originalCommit": {"oid": "1dd15b7615f61fab4d27239c72ca970712f4b7f1"}, "originalPosition": 43}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU2NTg0NTI3OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQxMTowODowM1rOGJwqrw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQxMTowODowM1rOGJwqrw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg4NzcyNw==", "bodyText": "Can be simplified to updateMetricsStore(!heap.current.isFileScanner())", "url": "https://github.com/apache/hbase/pull/1552#discussion_r412887727", "createdAt": "2020-04-22T11:08:03Z", "author": {"login": "virajjasani"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java", "diffHunk": "@@ -608,7 +613,17 @@ public boolean next(List<Cell> outResult, ScannerContext scannerContext) throws\n           if (f != null) {\n             cell = f.transformCell(cell);\n           }\n-\n+          // tracking gets only and currently per row\n+          // and not per cell. Even scans metrics at the region level are\n+          // being tracked row wise.\n+          if (get && !trackGets) {\n+            if (!heap.current.isFileScanner()) {\n+              updateMetricsStore(true);\n+            } else {\n+              updateMetricsStore(false);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1dd15b7615f61fab4d27239c72ca970712f4b7f1"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU2NjA3OTM3OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQxMjowNjo1NlrOGJy1UA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQxMTo0Mzo1NVrOGYv0Vw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjkyMzIxNg==", "bodyText": "This change is a must or it is an improvement? Just trying to understand it better :)", "url": "https://github.com/apache/hbase/pull/1552#discussion_r412923216", "createdAt": "2020-04-22T12:06:56Z", "author": {"login": "virajjasani"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java", "diffHunk": "@@ -2547,7 +2565,7 @@ public CacheConfig getCacheConfig() {\n   }\n \n   public static final long FIXED_OVERHEAD =\n-      ClassSize.align(ClassSize.OBJECT + (27 * ClassSize.REFERENCE) + (2 * Bytes.SIZEOF_LONG)\n+      ClassSize.align(ClassSize.OBJECT + (31 * ClassSize.REFERENCE) + (2 * Bytes.SIZEOF_LONG)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1dd15b7615f61fab4d27239c72ca970712f4b7f1"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODYwMjQ1NQ==", "bodyText": "Actually here added 5 more refs but considering 4 only. And infact 4 is enough when u keep getRequestsFromMemstore  and getRequestsFromStore .\ngetRequestsFromStore => getRequests..  This is store anyways so 'FromStore' is implicit.", "url": "https://github.com/apache/hbase/pull/1552#discussion_r428602455", "createdAt": "2020-05-21T11:43:55Z", "author": {"login": "anoopsjohn"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java", "diffHunk": "@@ -2547,7 +2565,7 @@ public CacheConfig getCacheConfig() {\n   }\n \n   public static final long FIXED_OVERHEAD =\n-      ClassSize.align(ClassSize.OBJECT + (27 * ClassSize.REFERENCE) + (2 * Bytes.SIZEOF_LONG)\n+      ClassSize.align(ClassSize.OBJECT + (31 * ClassSize.REFERENCE) + (2 * Bytes.SIZEOF_LONG)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjkyMzIxNg=="}, "originalCommit": {"oid": "1dd15b7615f61fab4d27239c72ca970712f4b7f1"}, "originalPosition": 65}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU2ODEwODczOnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQxODo1MzoxNVrOGKF66w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQxMDoyOTowNFrOGLROSw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzIzNTk0Nw==", "bodyText": "This should be an else statement?", "url": "https://github.com/apache/hbase/pull/1552#discussion_r413235947", "createdAt": "2020-04-22T18:53:15Z", "author": {"login": "virajjasani"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java", "diffHunk": "@@ -2898,4 +2915,40 @@ public int getMaxCompactedStoreFileRefCount() {\n       ? maxCompactedStoreFileRefCount.getAsInt() : 0;\n   }\n \n+  @Override\n+  public long getReadRequestsFromStoreCount() {\n+    return getRequestsFromStore.sum();\n+  }\n+\n+  @Override\n+  public long getGetRequestsCountFromMemstore() {\n+    return getRequestsFromMemstore.sum();\n+  }\n+\n+  @Override\n+  public long getGetRequestsCountFromFile() {\n+    return getRequestsFromFile.sum();\n+  }\n+\n+  void incrGetRequestsFromStore() {\n+    getRequestsFromStore.increment();\n+    if (metricsStore != null) {\n+      metricsStore.updateGet();\n+    }\n+  }\n+\n+  void updateMetricsStore(boolean memstoreRead) {\n+    if (memstoreRead) {\n+      getRequestsFromMemstore.increment();\n+    } else {\n+      getRequestsFromFile.increment();\n+    }\n+    if (metricsStore != null) {\n+      if (memstoreRead) {\n+        metricsStore.updateMemstoreGet();\n+      }\n+      metricsStore.updateFileGet();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1dd15b7615f61fab4d27239c72ca970712f4b7f1"}, "originalPosition": 115}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDQ2OTcwNw==", "bodyText": "good catch. Thanks for the reviews.", "url": "https://github.com/apache/hbase/pull/1552#discussion_r414469707", "createdAt": "2020-04-24T10:29:04Z", "author": {"login": "ramkrish86"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java", "diffHunk": "@@ -2898,4 +2915,40 @@ public int getMaxCompactedStoreFileRefCount() {\n       ? maxCompactedStoreFileRefCount.getAsInt() : 0;\n   }\n \n+  @Override\n+  public long getReadRequestsFromStoreCount() {\n+    return getRequestsFromStore.sum();\n+  }\n+\n+  @Override\n+  public long getGetRequestsCountFromMemstore() {\n+    return getRequestsFromMemstore.sum();\n+  }\n+\n+  @Override\n+  public long getGetRequestsCountFromFile() {\n+    return getRequestsFromFile.sum();\n+  }\n+\n+  void incrGetRequestsFromStore() {\n+    getRequestsFromStore.increment();\n+    if (metricsStore != null) {\n+      metricsStore.updateGet();\n+    }\n+  }\n+\n+  void updateMetricsStore(boolean memstoreRead) {\n+    if (memstoreRead) {\n+      getRequestsFromMemstore.increment();\n+    } else {\n+      getRequestsFromFile.increment();\n+    }\n+    if (metricsStore != null) {\n+      if (memstoreRead) {\n+        metricsStore.updateMemstoreGet();\n+      }\n+      metricsStore.updateFileGet();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzIzNTk0Nw=="}, "originalCommit": {"oid": "1dd15b7615f61fab4d27239c72ca970712f4b7f1"}, "originalPosition": 115}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYzNDI0MDUzOnYy", "diffSide": "RIGHT", "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsStoreAggregateSource.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMVQxMjozNzowMlrOGTaWnQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNFQwNzo1ODoyOVrOGVQZhg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzAwNzkwMQ==", "bodyText": "So this will treat only one store under a region for this aggregation.\nWhen we want to see an aggregated metric across all the store instances (under diff regions) for a table, this wont help right? (I mean metric for table CF) Do you think that will be more useful?  The stuff of memstore hit rate and all at a CF level would be useful IMO.", "url": "https://github.com/apache/hbase/pull/1552#discussion_r423007901", "createdAt": "2020-05-11T12:37:02Z", "author": {"login": "anoopsjohn"}, "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsStoreAggregateSource.java", "diffHunk": "@@ -0,0 +1,60 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.regionserver;\n+\n+import org.apache.hadoop.hbase.metrics.BaseSource;\n+import org.apache.yetus.audience.InterfaceAudience;\n+\n+\n+@InterfaceAudience.Private\n+public interface MetricsStoreAggregateSource extends BaseSource {\n+  /**\n+   * The name of the metrics\n+   */\n+  String METRICS_NAME = \"Stores\";\n+\n+  /**\n+   * The name of the metrics context that metrics will be under.\n+   */\n+  String METRICS_CONTEXT = \"regionserver\";\n+\n+  /**\n+   * Description\n+   */\n+  String METRICS_DESCRIPTION = \"Metrics about Stores under a region\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f3944c1eba56ebf1ffd22a74bce33ee7d70d728"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDk0MTk1OA==", "bodyText": "I have now tried to consolidate the metric at the table level also. Pls have a look. @anoopsjohn .", "url": "https://github.com/apache/hbase/pull/1552#discussion_r424941958", "createdAt": "2020-05-14T07:58:29Z", "author": {"login": "ramkrish86"}, "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsStoreAggregateSource.java", "diffHunk": "@@ -0,0 +1,60 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.regionserver;\n+\n+import org.apache.hadoop.hbase.metrics.BaseSource;\n+import org.apache.yetus.audience.InterfaceAudience;\n+\n+\n+@InterfaceAudience.Private\n+public interface MetricsStoreAggregateSource extends BaseSource {\n+  /**\n+   * The name of the metrics\n+   */\n+  String METRICS_NAME = \"Stores\";\n+\n+  /**\n+   * The name of the metrics context that metrics will be under.\n+   */\n+  String METRICS_CONTEXT = \"regionserver\";\n+\n+  /**\n+   * Description\n+   */\n+  String METRICS_DESCRIPTION = \"Metrics about Stores under a region\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzAwNzkwMQ=="}, "originalCommit": {"oid": "3f3944c1eba56ebf1ffd22a74bce33ee7d70d728"}, "originalPosition": 39}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2OTIwODc2OnYy", "diffSide": "RIGHT", "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSource.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQxMDo1Mjo1OFrOGYujbw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQyMjoyMzoyNFrOGeF81Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODU4MTc0Mw==", "bodyText": "#getsOnMemstore + #getsOnFile will be #get write?  Why we should keep both metric then?  We can keep only getsOnMemstore", "url": "https://github.com/apache/hbase/pull/1552#discussion_r428581743", "createdAt": "2020-05-21T10:52:58Z", "author": {"login": "anoopsjohn"}, "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSource.java", "diffHunk": "@@ -402,6 +402,8 @@\n   String DELETE_BATCH_KEY = \"deleteBatch\";\n   String GET_SIZE_KEY = \"getSize\";\n   String GET_KEY = \"get\";\n+  String MEMSTORE_GET_KEY = \"getsOnMemstore\";\n+  String FILE_GET_KEY = \"getsOnFile\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "29e5ac82028be2b5eb158ed7a86317732dfd1d4f"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc4NzQ5Mg==", "bodyText": "Some of the gets that lands on the StoreScanners does not actually get accounted into actual get. Probably that row does not exist. So I thought it is better to track both. Also the overhead is very minimal.", "url": "https://github.com/apache/hbase/pull/1552#discussion_r428787492", "createdAt": "2020-05-21T17:02:45Z", "author": {"login": "ramkrish86"}, "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSource.java", "diffHunk": "@@ -402,6 +402,8 @@\n   String DELETE_BATCH_KEY = \"deleteBatch\";\n   String GET_SIZE_KEY = \"getSize\";\n   String GET_KEY = \"get\";\n+  String MEMSTORE_GET_KEY = \"getsOnMemstore\";\n+  String FILE_GET_KEY = \"getsOnFile\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODU4MTc0Mw=="}, "originalCommit": {"oid": "29e5ac82028be2b5eb158ed7a86317732dfd1d4f"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDIwNjExNw==", "bodyText": "When discrepancy, how will operators figure out why the discrepancy?\nOr, why don't we count gets for which there is no row?", "url": "https://github.com/apache/hbase/pull/1552#discussion_r434206117", "createdAt": "2020-06-02T22:18:10Z", "author": {"login": "saintstack"}, "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSource.java", "diffHunk": "@@ -402,6 +402,8 @@\n   String DELETE_BATCH_KEY = \"deleteBatch\";\n   String GET_SIZE_KEY = \"getSize\";\n   String GET_KEY = \"get\";\n+  String MEMSTORE_GET_KEY = \"getsOnMemstore\";\n+  String FILE_GET_KEY = \"getsOnFile\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODU4MTc0Mw=="}, "originalCommit": {"oid": "29e5ac82028be2b5eb158ed7a86317732dfd1d4f"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDIwNzk1Nw==", "bodyText": "In other words, it'd be better if the accounting aligned.", "url": "https://github.com/apache/hbase/pull/1552#discussion_r434207957", "createdAt": "2020-06-02T22:23:24Z", "author": {"login": "saintstack"}, "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSource.java", "diffHunk": "@@ -402,6 +402,8 @@\n   String DELETE_BATCH_KEY = \"deleteBatch\";\n   String GET_SIZE_KEY = \"getSize\";\n   String GET_KEY = \"get\";\n+  String MEMSTORE_GET_KEY = \"getsOnMemstore\";\n+  String FILE_GET_KEY = \"getsOnFile\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODU4MTc0Mw=="}, "originalCommit": {"oid": "29e5ac82028be2b5eb158ed7a86317732dfd1d4f"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2OTI1ODc1OnYy", "diffSide": "RIGHT", "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionSourceImpl.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQxMToxMjoxOVrOGYvCuw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQyMjoyNjoxOFrOGeGA5Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODU4OTc1NQ==", "bodyText": "We are collecting the metric at every store level and then aggregating over region also?  Do we need that? A region might have say 3 CFs out of which only one is getting recent data gets. Aggregate at region level for these 3 CFs, how that can be used?  IMO we can avoid this.  And keep aggregate only at the RS level for table:cf", "url": "https://github.com/apache/hbase/pull/1552#discussion_r428589755", "createdAt": "2020-05-21T11:12:19Z", "author": {"login": "anoopsjohn"}, "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionSourceImpl.java", "diffHunk": "@@ -302,6 +302,14 @@ void snapshot(MetricsRecordBuilder mrb, boolean ignored) {\n               regionNamePrefix + MetricsRegionSource.MAX_FLUSH_QUEUE_SIZE,\n               MetricsRegionSource.MAX_FLUSH_QUEUE_DESC),\n           this.regionWrapper.getMaxFlushQueueSize());\n+      mrb.addCounter(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "29e5ac82028be2b5eb158ed7a86317732dfd1d4f"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc4ODMyNg==", "bodyText": "At the store level only it comes as per region per store. This is something we already have. Jut adding those two new metric here. So should be ok.", "url": "https://github.com/apache/hbase/pull/1552#discussion_r428788326", "createdAt": "2020-05-21T17:04:19Z", "author": {"login": "ramkrish86"}, "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionSourceImpl.java", "diffHunk": "@@ -302,6 +302,14 @@ void snapshot(MetricsRecordBuilder mrb, boolean ignored) {\n               regionNamePrefix + MetricsRegionSource.MAX_FLUSH_QUEUE_SIZE,\n               MetricsRegionSource.MAX_FLUSH_QUEUE_DESC),\n           this.regionWrapper.getMaxFlushQueueSize());\n+      mrb.addCounter(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODU4OTc1NQ=="}, "originalCommit": {"oid": "29e5ac82028be2b5eb158ed7a86317732dfd1d4f"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDIwODk5Nw==", "bodyText": "I don't follow the above. We already have account at the store level per region? Why then would we add these counters?", "url": "https://github.com/apache/hbase/pull/1552#discussion_r434208997", "createdAt": "2020-06-02T22:26:18Z", "author": {"login": "saintstack"}, "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionSourceImpl.java", "diffHunk": "@@ -302,6 +302,14 @@ void snapshot(MetricsRecordBuilder mrb, boolean ignored) {\n               regionNamePrefix + MetricsRegionSource.MAX_FLUSH_QUEUE_SIZE,\n               MetricsRegionSource.MAX_FLUSH_QUEUE_DESC),\n           this.regionWrapper.getMaxFlushQueueSize());\n+      mrb.addCounter(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODU4OTc1NQ=="}, "originalCommit": {"oid": "29e5ac82028be2b5eb158ed7a86317732dfd1d4f"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2OTI4NjkyOnYy", "diffSide": "RIGHT", "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsStoreSourceImpl.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQxMToyNDowNFrOGYvUrg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQxMToyNDowNFrOGYvUrg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODU5NDM1MA==", "bodyText": "Yes here.. No need to fileReads.", "url": "https://github.com/apache/hbase/pull/1552#discussion_r428594350", "createdAt": "2020-05-21T11:24:04Z", "author": {"login": "anoopsjohn"}, "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsStoreSourceImpl.java", "diffHunk": "@@ -0,0 +1,211 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.regionserver;\n+\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+import org.apache.hadoop.hbase.metrics.Counter;\n+import org.apache.hadoop.hbase.metrics.Interns;\n+import org.apache.hadoop.hbase.metrics.MetricRegistry;\n+import org.apache.hadoop.metrics2.MetricsRecordBuilder;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+@InterfaceAudience.Private\n+public class MetricsStoreSourceImpl implements MetricsStoreSource {\n+\n+  private MetricsStoreWrapper storeWrapper;\n+  private MetricsStoreAggregateSourceImpl aggreagate;\n+  private AtomicBoolean closed = new AtomicBoolean(false);\n+\n+  private String storeNamePrefix;\n+  private final MetricRegistry registry;\n+  private static final Logger LOG = LoggerFactory.getLogger(MetricsStoreSourceImpl.class);\n+  String storeReadsKey;\n+\n+  String memstoreReadsKey;\n+  String fileReadsKey;\n+  private final Counter storeReads;\n+  private final Counter memstoreReads;\n+  private final Counter fileReads;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "29e5ac82028be2b5eb158ed7a86317732dfd1d4f"}, "originalPosition": 46}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2OTI5OTk1OnYy", "diffSide": "RIGHT", "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsStoreSourceImpl.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQxMToyODo0NlrOGYvcZQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQxMToyODo0NlrOGYvcZQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODU5NjMyNQ==", "bodyText": "Pls correct log\nfor store storeWrapper.getRegionName() + \" : \" + storeWrapper.getStoreName()", "url": "https://github.com/apache/hbase/pull/1552#discussion_r428596325", "createdAt": "2020-05-21T11:28:46Z", "author": {"login": "anoopsjohn"}, "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsStoreSourceImpl.java", "diffHunk": "@@ -0,0 +1,211 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.regionserver;\n+\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+import org.apache.hadoop.hbase.metrics.Counter;\n+import org.apache.hadoop.hbase.metrics.Interns;\n+import org.apache.hadoop.hbase.metrics.MetricRegistry;\n+import org.apache.hadoop.metrics2.MetricsRecordBuilder;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+@InterfaceAudience.Private\n+public class MetricsStoreSourceImpl implements MetricsStoreSource {\n+\n+  private MetricsStoreWrapper storeWrapper;\n+  private MetricsStoreAggregateSourceImpl aggreagate;\n+  private AtomicBoolean closed = new AtomicBoolean(false);\n+\n+  private String storeNamePrefix;\n+  private final MetricRegistry registry;\n+  private static final Logger LOG = LoggerFactory.getLogger(MetricsStoreSourceImpl.class);\n+  String storeReadsKey;\n+\n+  String memstoreReadsKey;\n+  String fileReadsKey;\n+  private final Counter storeReads;\n+  private final Counter memstoreReads;\n+  private final Counter fileReads;\n+\n+  public MetricsStoreSourceImpl(MetricsStoreWrapper storeWrapper,\n+      MetricsStoreAggregateSourceImpl aggreagate) {\n+    this.storeWrapper = storeWrapper;\n+    this.aggreagate = aggreagate;\n+    aggreagate.register(this);\n+\n+    LOG.debug(\"Creating new MetricsRegionSourceImpl for table \" + storeWrapper.getStoreName() + \" \"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "29e5ac82028be2b5eb158ed7a86317732dfd1d4f"}, "originalPosition": 54}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2OTMxMDIwOnYy", "diffSide": "RIGHT", "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsStoreSourceImpl.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQxMTozMjowOFrOGYviKw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQxNzowNTowN1rOGY7MRw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODU5NzgwMw==", "bodyText": "Why all these storeFile related metric comes here as part of this?", "url": "https://github.com/apache/hbase/pull/1552#discussion_r428597803", "createdAt": "2020-05-21T11:32:08Z", "author": {"login": "anoopsjohn"}, "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsStoreSourceImpl.java", "diffHunk": "@@ -0,0 +1,211 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.regionserver;\n+\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+import org.apache.hadoop.hbase.metrics.Counter;\n+import org.apache.hadoop.hbase.metrics.Interns;\n+import org.apache.hadoop.hbase.metrics.MetricRegistry;\n+import org.apache.hadoop.metrics2.MetricsRecordBuilder;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+@InterfaceAudience.Private\n+public class MetricsStoreSourceImpl implements MetricsStoreSource {\n+\n+  private MetricsStoreWrapper storeWrapper;\n+  private MetricsStoreAggregateSourceImpl aggreagate;\n+  private AtomicBoolean closed = new AtomicBoolean(false);\n+\n+  private String storeNamePrefix;\n+  private final MetricRegistry registry;\n+  private static final Logger LOG = LoggerFactory.getLogger(MetricsStoreSourceImpl.class);\n+  String storeReadsKey;\n+\n+  String memstoreReadsKey;\n+  String fileReadsKey;\n+  private final Counter storeReads;\n+  private final Counter memstoreReads;\n+  private final Counter fileReads;\n+\n+  public MetricsStoreSourceImpl(MetricsStoreWrapper storeWrapper,\n+      MetricsStoreAggregateSourceImpl aggreagate) {\n+    this.storeWrapper = storeWrapper;\n+    this.aggreagate = aggreagate;\n+    aggreagate.register(this);\n+\n+    LOG.debug(\"Creating new MetricsRegionSourceImpl for table \" + storeWrapper.getStoreName() + \" \"\n+        + storeWrapper.getRegionName());\n+\n+    // we are using the hbase-metrics API\n+    registry = aggreagate.getMetricRegistry();\n+\n+    storeNamePrefix = \"Namespace_\" + storeWrapper.getNamespace() + \"_table_\"\n+        + storeWrapper.getTableName() + \"_region_\" + storeWrapper.getRegionName() + \"_store_\"\n+        + storeWrapper.getStoreName() + \"_metric_\";\n+\n+    String suffix = \"Count\";\n+\n+    storeReadsKey = storeNamePrefix + MetricsRegionServerSource.GET_KEY + suffix;\n+    // all the counters are hbase-metrics API\n+    storeReads = registry.counter(storeReadsKey);\n+\n+    memstoreReadsKey = storeNamePrefix + MetricsRegionServerSource.MEMSTORE_GET_KEY + suffix;\n+    memstoreReads = registry.counter(memstoreReadsKey);\n+\n+    fileReadsKey = storeNamePrefix + MetricsRegionServerSource.FILE_GET_KEY + suffix;\n+    fileReads = registry.counter(fileReadsKey);\n+\n+  }\n+\n+  @Override\n+  public void close() {\n+    boolean wasClosed = closed.getAndSet(true);\n+\n+    // Has someone else already closed this for us?\n+    if (wasClosed) {\n+      return;\n+    }\n+\n+    // Before removing the metrics remove this region from the aggregate region bean.\n+    // This should mean that it's unlikely that snapshot and close happen at the same time.\n+    aggreagate.deregister(this);\n+\n+    // While it's un-likely that snapshot and close happen at the same time it's still possible.\n+    // So grab the lock to ensure that all calls to snapshot are done before we remove the metrics\n+    synchronized (this) {\n+      if (LOG.isTraceEnabled()) {\n+        LOG.trace(\"Removing store Metrics: \" + storeWrapper.getStoreName());\n+      }\n+\n+      registry.remove(storeReadsKey);\n+      registry.remove(memstoreReadsKey);\n+      registry.remove(fileReadsKey);\n+\n+      storeWrapper = null;\n+    }\n+  }\n+\n+  @Override\n+  public int compareTo(MetricsStoreSource source) {\n+    if (!(source instanceof MetricsStoreSourceImpl)) {\n+      return -1;\n+    }\n+\n+    MetricsStoreSourceImpl impl = (MetricsStoreSourceImpl) source;\n+    if (impl == null) {\n+      return -1;\n+    }\n+\n+    // TODO : make this better\n+    return Long.compare(this.storeWrapper.getStoreName().hashCode(),\n+      impl.storeWrapper.getStoreName().hashCode());\n+  }\n+\n+  @Override\n+  public void updateGet() {\n+    storeReads.increment();\n+  }\n+\n+  @Override\n+  public void updateMemtoreGet() {\n+    memstoreReads.increment();\n+  }\n+\n+  @Override\n+  public void updateFileGet() {\n+    fileReads.increment();\n+  }\n+\n+  @Override\n+  public boolean equals(Object obj) {\n+    return obj == this\n+        || (obj instanceof MetricsStoreSourceImpl && compareTo((MetricsStoreSourceImpl) obj) == 0);\n+  }\n+\n+  @Override\n+  public int hashCode() {\n+    return this.storeWrapper.getStoreName().hashCode();\n+  }\n+\n+  void snapshot(MetricsRecordBuilder mrb, boolean ignored) {\n+\n+    // If there is a close that started be double extra sure\n+    // that we're not getting any locks and not putting data\n+    // into the metrics that should be removed. So early out\n+    // before even getting the lock.\n+    if (closed.get()) {\n+      return;\n+    }\n+\n+    // Grab the read\n+    // This ensures that removes of the metrics\n+    // can't happen while we are putting them back in.\n+    synchronized (this) {\n+\n+      // It's possible that a close happened between checking\n+      // the closed variable and getting the lock.\n+      if (closed.get()) {\n+        return;\n+      }\n+      mrb.addGauge(Interns.info(storeNamePrefix + MetricsRegionServerSource.STOREFILE_COUNT,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "29e5ac82028be2b5eb158ed7a86317732dfd1d4f"}, "originalPosition": 168}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc4ODgwNw==", "bodyText": "At region level we had the aggregation across stores. Here it is per store. Just aggregation . We don do anything here to evaluate all this.", "url": "https://github.com/apache/hbase/pull/1552#discussion_r428788807", "createdAt": "2020-05-21T17:05:07Z", "author": {"login": "ramkrish86"}, "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsStoreSourceImpl.java", "diffHunk": "@@ -0,0 +1,211 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.regionserver;\n+\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+import org.apache.hadoop.hbase.metrics.Counter;\n+import org.apache.hadoop.hbase.metrics.Interns;\n+import org.apache.hadoop.hbase.metrics.MetricRegistry;\n+import org.apache.hadoop.metrics2.MetricsRecordBuilder;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+@InterfaceAudience.Private\n+public class MetricsStoreSourceImpl implements MetricsStoreSource {\n+\n+  private MetricsStoreWrapper storeWrapper;\n+  private MetricsStoreAggregateSourceImpl aggreagate;\n+  private AtomicBoolean closed = new AtomicBoolean(false);\n+\n+  private String storeNamePrefix;\n+  private final MetricRegistry registry;\n+  private static final Logger LOG = LoggerFactory.getLogger(MetricsStoreSourceImpl.class);\n+  String storeReadsKey;\n+\n+  String memstoreReadsKey;\n+  String fileReadsKey;\n+  private final Counter storeReads;\n+  private final Counter memstoreReads;\n+  private final Counter fileReads;\n+\n+  public MetricsStoreSourceImpl(MetricsStoreWrapper storeWrapper,\n+      MetricsStoreAggregateSourceImpl aggreagate) {\n+    this.storeWrapper = storeWrapper;\n+    this.aggreagate = aggreagate;\n+    aggreagate.register(this);\n+\n+    LOG.debug(\"Creating new MetricsRegionSourceImpl for table \" + storeWrapper.getStoreName() + \" \"\n+        + storeWrapper.getRegionName());\n+\n+    // we are using the hbase-metrics API\n+    registry = aggreagate.getMetricRegistry();\n+\n+    storeNamePrefix = \"Namespace_\" + storeWrapper.getNamespace() + \"_table_\"\n+        + storeWrapper.getTableName() + \"_region_\" + storeWrapper.getRegionName() + \"_store_\"\n+        + storeWrapper.getStoreName() + \"_metric_\";\n+\n+    String suffix = \"Count\";\n+\n+    storeReadsKey = storeNamePrefix + MetricsRegionServerSource.GET_KEY + suffix;\n+    // all the counters are hbase-metrics API\n+    storeReads = registry.counter(storeReadsKey);\n+\n+    memstoreReadsKey = storeNamePrefix + MetricsRegionServerSource.MEMSTORE_GET_KEY + suffix;\n+    memstoreReads = registry.counter(memstoreReadsKey);\n+\n+    fileReadsKey = storeNamePrefix + MetricsRegionServerSource.FILE_GET_KEY + suffix;\n+    fileReads = registry.counter(fileReadsKey);\n+\n+  }\n+\n+  @Override\n+  public void close() {\n+    boolean wasClosed = closed.getAndSet(true);\n+\n+    // Has someone else already closed this for us?\n+    if (wasClosed) {\n+      return;\n+    }\n+\n+    // Before removing the metrics remove this region from the aggregate region bean.\n+    // This should mean that it's unlikely that snapshot and close happen at the same time.\n+    aggreagate.deregister(this);\n+\n+    // While it's un-likely that snapshot and close happen at the same time it's still possible.\n+    // So grab the lock to ensure that all calls to snapshot are done before we remove the metrics\n+    synchronized (this) {\n+      if (LOG.isTraceEnabled()) {\n+        LOG.trace(\"Removing store Metrics: \" + storeWrapper.getStoreName());\n+      }\n+\n+      registry.remove(storeReadsKey);\n+      registry.remove(memstoreReadsKey);\n+      registry.remove(fileReadsKey);\n+\n+      storeWrapper = null;\n+    }\n+  }\n+\n+  @Override\n+  public int compareTo(MetricsStoreSource source) {\n+    if (!(source instanceof MetricsStoreSourceImpl)) {\n+      return -1;\n+    }\n+\n+    MetricsStoreSourceImpl impl = (MetricsStoreSourceImpl) source;\n+    if (impl == null) {\n+      return -1;\n+    }\n+\n+    // TODO : make this better\n+    return Long.compare(this.storeWrapper.getStoreName().hashCode(),\n+      impl.storeWrapper.getStoreName().hashCode());\n+  }\n+\n+  @Override\n+  public void updateGet() {\n+    storeReads.increment();\n+  }\n+\n+  @Override\n+  public void updateMemtoreGet() {\n+    memstoreReads.increment();\n+  }\n+\n+  @Override\n+  public void updateFileGet() {\n+    fileReads.increment();\n+  }\n+\n+  @Override\n+  public boolean equals(Object obj) {\n+    return obj == this\n+        || (obj instanceof MetricsStoreSourceImpl && compareTo((MetricsStoreSourceImpl) obj) == 0);\n+  }\n+\n+  @Override\n+  public int hashCode() {\n+    return this.storeWrapper.getStoreName().hashCode();\n+  }\n+\n+  void snapshot(MetricsRecordBuilder mrb, boolean ignored) {\n+\n+    // If there is a close that started be double extra sure\n+    // that we're not getting any locks and not putting data\n+    // into the metrics that should be removed. So early out\n+    // before even getting the lock.\n+    if (closed.get()) {\n+      return;\n+    }\n+\n+    // Grab the read\n+    // This ensures that removes of the metrics\n+    // can't happen while we are putting them back in.\n+    synchronized (this) {\n+\n+      // It's possible that a close happened between checking\n+      // the closed variable and getting the lock.\n+      if (closed.get()) {\n+        return;\n+      }\n+      mrb.addGauge(Interns.info(storeNamePrefix + MetricsRegionServerSource.STOREFILE_COUNT,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODU5NzgwMw=="}, "originalCommit": {"oid": "29e5ac82028be2b5eb158ed7a86317732dfd1d4f"}, "originalPosition": 168}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2OTMyODQ2OnYy", "diffSide": "RIGHT", "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsTableSourceImpl.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQxMTozOTozOVrOGYvtuw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQxMTozOTozOVrOGYvtuw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODYwMDc2Mw==", "bodyText": "Here we are not adding aggregate of total gets on table:cf?", "url": "https://github.com/apache/hbase/pull/1552#discussion_r428600763", "createdAt": "2020-05-21T11:39:39Z", "author": {"login": "anoopsjohn"}, "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsTableSourceImpl.java", "diffHunk": "@@ -311,6 +320,25 @@ void snapshot(MetricsRecordBuilder mrb, boolean ignored) {\n         mrb.addGauge(Interns.info(tableNamePrefix + MetricsRegionServerSource.NUM_REFERENCE_FILES,\n             MetricsRegionServerSource.NUM_REFERENCE_FILES_DESC),\n             tableWrapperAgg.getNumReferenceFiles(tableName.getNameAsString()));\n+        addGauge(mrb, tableWrapperAgg.getMemstoreReadRequestCount(tableName.getNameAsString()),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "29e5ac82028be2b5eb158ed7a86317732dfd1d4f"}, "originalPosition": 39}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2OTMzMTM2OnYy", "diffSide": "RIGHT", "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsTableWrapperAggregate.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQxMTo0MDo1MlrOGYvvnQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQxMTo0MDo1MlrOGYvvnQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODYwMTI0NQ==", "bodyText": "Same here..  All places we can keep totalReads metric and memstoreReads. That should be enough to understand the pattern.", "url": "https://github.com/apache/hbase/pull/1552#discussion_r428601245", "createdAt": "2020-05-21T11:40:52Z", "author": {"login": "anoopsjohn"}, "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsTableWrapperAggregate.java", "diffHunk": "@@ -107,6 +109,13 @@\n    */\n   long getNumReferenceFiles(String table);\n \n+  /**\n+   * @return number of get requests on memstore for this table\n+   */\n+  Map<String, Long> getMemstoreReadRequestCount(String table);\n \n-\n+  /**\n+   * @return number of get requests from file for this table\n+   */\n+  Map<String, Long> getFileRequestCount(String table);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "29e5ac82028be2b5eb158ed7a86317732dfd1d4f"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2OTM0NDU4OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQxMTo0NTo1NFrOGYv34A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxMzowNToxNFrOGadSuQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODYwMzM2MA==", "bodyText": "Actually we need to keep this counter here as well as update the counter on Metrics also?  The local Counter is used by?", "url": "https://github.com/apache/hbase/pull/1552#discussion_r428603360", "createdAt": "2020-05-21T11:45:54Z", "author": {"login": "anoopsjohn"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java", "diffHunk": "@@ -2884,4 +2901,41 @@ public int getMaxCompactedStoreFileRefCount() {\n       ? maxCompactedStoreFileRefCount.getAsInt() : 0;\n   }\n \n+  @Override\n+  public long getReadRequestsFromStoreCount() {\n+    return getRequestsFromStore.sum();\n+  }\n+\n+  @Override\n+  public long getGetRequestsCountFromMemstore() {\n+    return getRequestsFromMemstore.sum();\n+  }\n+\n+  @Override\n+  public long getGetRequestsCountFromFile() {\n+    return getRequestsFromFile.sum();\n+  }\n+\n+  void incrGetRequestsFromStore() {\n+    getRequestsFromStore.increment();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "29e5ac82028be2b5eb158ed7a86317732dfd1d4f"}, "originalPosition": 99}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDM5NjA4OQ==", "bodyText": "The one direclty inder HStore is used by the Region level and Table level aggregators which deals with HStore. This gets printed periodically. The other one is at the MetricsStore level which is the real time one. For every request it will be displayed at JMX MBean level.", "url": "https://github.com/apache/hbase/pull/1552#discussion_r430396089", "createdAt": "2020-05-26T13:05:14Z", "author": {"login": "ramkrish86"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java", "diffHunk": "@@ -2884,4 +2901,41 @@ public int getMaxCompactedStoreFileRefCount() {\n       ? maxCompactedStoreFileRefCount.getAsInt() : 0;\n   }\n \n+  @Override\n+  public long getReadRequestsFromStoreCount() {\n+    return getRequestsFromStore.sum();\n+  }\n+\n+  @Override\n+  public long getGetRequestsCountFromMemstore() {\n+    return getRequestsFromMemstore.sum();\n+  }\n+\n+  @Override\n+  public long getGetRequestsCountFromFile() {\n+    return getRequestsFromFile.sum();\n+  }\n+\n+  void incrGetRequestsFromStore() {\n+    getRequestsFromStore.increment();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODYwMzM2MA=="}, "originalCommit": {"oid": "29e5ac82028be2b5eb158ed7a86317732dfd1d4f"}, "originalPosition": 99}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2OTM2MDQ5OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsTableWrapperAggregateImpl.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQxMTo1MjowN1rOGYwBzQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxMzoyMDowNlrOGad4ww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODYwNTkwMQ==", "bodyText": "Why this change? If any bug fix, pls keep it as another Jira", "url": "https://github.com/apache/hbase/pull/1552#discussion_r428605901", "createdAt": "2020-05-21T11:52:07Z", "author": {"login": "anoopsjohn"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsTableWrapperAggregateImpl.java", "diffHunk": "@@ -70,25 +69,36 @@ public void run() {\n           localMetricsTableMap.put(tbl, mt);\n         }\n         if (r.getStores() != null) {\n+          long memstoreReadCount = 0l;\n+          long fileReadCount = 0l;\n+          String familyName = null;\n           for (Store store : r.getStores()) {\n+            familyName = store.getColumnFamilyName();\n+\n             mt.storeFileCount += store.getStorefilesCount();\n-            mt.memstoreSize += (store.getMemStoreSize().getDataSize() +\n-              store.getMemStoreSize().getHeapSize() + store.getMemStoreSize().getOffHeapSize());\n+            mt.memstoreSize += (store.getMemStoreSize().getDataSize()\n+                + store.getMemStoreSize().getHeapSize() + store.getMemStoreSize().getOffHeapSize());\n             mt.storeFileSize += store.getStorefilesSize();\n             mt.referenceFileCount += store.getNumReferenceFiles();\n \n-            mt.maxStoreFileAge = Math.max(mt.maxStoreFileAge, store.getMaxStoreFileAge().getAsLong());\n-            mt.minStoreFileAge = Math.min(mt.minStoreFileAge, store.getMinStoreFileAge().getAsLong());\n-            mt.totalStoreFileAge = (long)store.getAvgStoreFileAge().getAsDouble() *\n-                store.getStorefilesCount();\n+            mt.maxStoreFileAge =\n+                Math.max(mt.maxStoreFileAge, store.getMaxStoreFileAge().getAsLong());\n+            mt.minStoreFileAge =\n+                Math.min(mt.minStoreFileAge, store.getMinStoreFileAge().getAsLong());\n+            mt.totalStoreFileAge =\n+                (long) store.getAvgStoreFileAge().getAsDouble() * store.getStorefilesCount();\n             mt.storeCount += 1;\n+            memstoreReadCount += store.getGetRequestsCountFromMemstore();\n+            fileReadCount += store.getGetRequestsCountFromFile();\n+            mt.storeMemstoreGetCount.putIfAbsent(familyName, memstoreReadCount);\n+            mt.storeFileGetCount.putIfAbsent(familyName, fileReadCount);\n           }\n+\n           mt.regionCount += 1;\n \n           mt.readRequestCount += r.getReadRequestsCount();\n-          mt.filteredReadRequestCount += getFilteredReadRequestCount(tbl.getNameAsString());\n+          mt.filteredReadRequestCount += r.getFilteredReadRequestsCount();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "29e5ac82028be2b5eb158ed7a86317732dfd1d4f"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDQwNTgyNw==", "bodyText": "This was wrong. It is a simple change. So I thought it is better to make this change hhere. If you are particular i can make the change in separete JIRA.", "url": "https://github.com/apache/hbase/pull/1552#discussion_r430405827", "createdAt": "2020-05-26T13:20:06Z", "author": {"login": "ramkrish86"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsTableWrapperAggregateImpl.java", "diffHunk": "@@ -70,25 +69,36 @@ public void run() {\n           localMetricsTableMap.put(tbl, mt);\n         }\n         if (r.getStores() != null) {\n+          long memstoreReadCount = 0l;\n+          long fileReadCount = 0l;\n+          String familyName = null;\n           for (Store store : r.getStores()) {\n+            familyName = store.getColumnFamilyName();\n+\n             mt.storeFileCount += store.getStorefilesCount();\n-            mt.memstoreSize += (store.getMemStoreSize().getDataSize() +\n-              store.getMemStoreSize().getHeapSize() + store.getMemStoreSize().getOffHeapSize());\n+            mt.memstoreSize += (store.getMemStoreSize().getDataSize()\n+                + store.getMemStoreSize().getHeapSize() + store.getMemStoreSize().getOffHeapSize());\n             mt.storeFileSize += store.getStorefilesSize();\n             mt.referenceFileCount += store.getNumReferenceFiles();\n \n-            mt.maxStoreFileAge = Math.max(mt.maxStoreFileAge, store.getMaxStoreFileAge().getAsLong());\n-            mt.minStoreFileAge = Math.min(mt.minStoreFileAge, store.getMinStoreFileAge().getAsLong());\n-            mt.totalStoreFileAge = (long)store.getAvgStoreFileAge().getAsDouble() *\n-                store.getStorefilesCount();\n+            mt.maxStoreFileAge =\n+                Math.max(mt.maxStoreFileAge, store.getMaxStoreFileAge().getAsLong());\n+            mt.minStoreFileAge =\n+                Math.min(mt.minStoreFileAge, store.getMinStoreFileAge().getAsLong());\n+            mt.totalStoreFileAge =\n+                (long) store.getAvgStoreFileAge().getAsDouble() * store.getStorefilesCount();\n             mt.storeCount += 1;\n+            memstoreReadCount += store.getGetRequestsCountFromMemstore();\n+            fileReadCount += store.getGetRequestsCountFromFile();\n+            mt.storeMemstoreGetCount.putIfAbsent(familyName, memstoreReadCount);\n+            mt.storeFileGetCount.putIfAbsent(familyName, fileReadCount);\n           }\n+\n           mt.regionCount += 1;\n \n           mt.readRequestCount += r.getReadRequestsCount();\n-          mt.filteredReadRequestCount += getFilteredReadRequestCount(tbl.getNameAsString());\n+          mt.filteredReadRequestCount += r.getFilteredReadRequestsCount();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODYwNTkwMQ=="}, "originalCommit": {"oid": "29e5ac82028be2b5eb158ed7a86317732dfd1d4f"}, "originalPosition": 47}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2OTQyMzQ5OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQxMjoxNTo1MlrOGYwn_w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQxNzowNTo0OVrOGY7Nyg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODYxNTY3OQ==", "bodyText": "This will do all the deregister stuff?", "url": "https://github.com/apache/hbase/pull/1552#discussion_r428615679", "createdAt": "2020-05-21T12:15:52Z", "author": {"login": "anoopsjohn"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java", "diffHunk": "@@ -1002,6 +1012,14 @@ public Void call() throws IOException {\n     } finally {\n       this.lock.writeLock().unlock();\n       this.archiveLock.unlock();\n+      // moving it after the unlocking so\n+      // that metrics closure does not affect them\n+      if (this.metricsStore != null) {\n+        metricsStore.close();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "29e5ac82028be2b5eb158ed7a86317732dfd1d4f"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc4OTE5NA==", "bodyText": "Yes. It will do the deregister.", "url": "https://github.com/apache/hbase/pull/1552#discussion_r428789194", "createdAt": "2020-05-21T17:05:49Z", "author": {"login": "ramkrish86"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java", "diffHunk": "@@ -1002,6 +1012,14 @@ public Void call() throws IOException {\n     } finally {\n       this.lock.writeLock().unlock();\n       this.archiveLock.unlock();\n+      // moving it after the unlocking so\n+      // that metrics closure does not affect them\n+      if (this.metricsStore != null) {\n+        metricsStore.close();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODYxNTY3OQ=="}, "originalCommit": {"oid": "29e5ac82028be2b5eb158ed7a86317732dfd1d4f"}, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcwNDY5NDc2OnYy", "diffSide": "RIGHT", "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionSource.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQyMjoyNDo1MlrOGeF-zA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wM1QwNDo0Mzo0N1rOGeL1gA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDIwODQ2MA==", "bodyText": "Yeah, don't we have this accounted already? Seems redundant.", "url": "https://github.com/apache/hbase/pull/1552#discussion_r434208460", "createdAt": "2020-06-02T22:24:52Z", "author": {"login": "saintstack"}, "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionSource.java", "diffHunk": "@@ -53,6 +53,10 @@\n   String COPROCESSOR_EXECUTION_STATISTICS_DESC = \"Statistics for coprocessor execution times\";\n   String REPLICA_ID = \"replicaid\";\n   String REPLICA_ID_DESC = \"The replica ID of a region. 0 is primary, otherwise is secondary\";\n+  String READ_REQUEST_ON_MEMSTORE = \"readRequestCountOnMemstore\";\n+  String READ_REQUEST_ON_MEMSTORE_DESC = \"Reads happening out of memstore\";\n+  String MIXED_READ_REQUEST_ON_STORE = \"mixedReadRequestCountOnStore\";\n+  String MIXED_READ_REQUEST_ON_STORE_DESC = \"Reads happening out of files and memstore on store\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "66e0d8ffb5122019916a420a35c0372e17774212"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDMwNDM0MQ==", "bodyText": "The one above is not needed - MEMSTORE_GET_KEY  and FILE_GET_KEY  in MetricsREgionServerSource because I had removed all those additional metric.", "url": "https://github.com/apache/hbase/pull/1552#discussion_r434304341", "createdAt": "2020-06-03T04:43:34Z", "author": {"login": "ramkrish86"}, "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionSource.java", "diffHunk": "@@ -53,6 +53,10 @@\n   String COPROCESSOR_EXECUTION_STATISTICS_DESC = \"Statistics for coprocessor execution times\";\n   String REPLICA_ID = \"replicaid\";\n   String REPLICA_ID_DESC = \"The replica ID of a region. 0 is primary, otherwise is secondary\";\n+  String READ_REQUEST_ON_MEMSTORE = \"readRequestCountOnMemstore\";\n+  String READ_REQUEST_ON_MEMSTORE_DESC = \"Reads happening out of memstore\";\n+  String MIXED_READ_REQUEST_ON_STORE = \"mixedReadRequestCountOnStore\";\n+  String MIXED_READ_REQUEST_ON_STORE_DESC = \"Reads happening out of files and memstore on store\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDIwODQ2MA=="}, "originalCommit": {"oid": "66e0d8ffb5122019916a420a35c0372e17774212"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDMwNDM4NA==", "bodyText": "That constants I did not clean up.", "url": "https://github.com/apache/hbase/pull/1552#discussion_r434304384", "createdAt": "2020-06-03T04:43:47Z", "author": {"login": "ramkrish86"}, "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionSource.java", "diffHunk": "@@ -53,6 +53,10 @@\n   String COPROCESSOR_EXECUTION_STATISTICS_DESC = \"Statistics for coprocessor execution times\";\n   String REPLICA_ID = \"replicaid\";\n   String REPLICA_ID_DESC = \"The replica ID of a region. 0 is primary, otherwise is secondary\";\n+  String READ_REQUEST_ON_MEMSTORE = \"readRequestCountOnMemstore\";\n+  String READ_REQUEST_ON_MEMSTORE_DESC = \"Reads happening out of memstore\";\n+  String MIXED_READ_REQUEST_ON_STORE = \"mixedReadRequestCountOnStore\";\n+  String MIXED_READ_REQUEST_ON_STORE_DESC = \"Reads happening out of files and memstore on store\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDIwODQ2MA=="}, "originalCommit": {"oid": "66e0d8ffb5122019916a420a35c0372e17774212"}, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcwNDcwMDIzOnYy", "diffSide": "RIGHT", "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionWrapper.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQyMjoyNzowNFrOGeGCAw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wM1QwNDo0NTozNFrOGeL3Mg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDIwOTI4Mw==", "bodyText": "... this if for the Region?  Can I ask for the number of reads on memstore on a Store?", "url": "https://github.com/apache/hbase/pull/1552#discussion_r434209283", "createdAt": "2020-06-02T22:27:04Z", "author": {"login": "saintstack"}, "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionWrapper.java", "diffHunk": "@@ -170,4 +170,15 @@\n    *   all compacted store files that belong to this region\n    */\n   long getMaxCompactedStoreFileRefCount();\n+\n+  /**\n+   * @return the number of reads on memstore\n+   */\n+  long getMemstoreReadRequestsCount();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "66e0d8ffb5122019916a420a35c0372e17774212"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDMwNDgxOA==", "bodyText": "I just followed a model where currently we have accouting at table level and region level. So following the same path - We added per region per store metric and this one is nothing but a region level aggregation. This will tell on the region how many reads are from memstore. (across all stores).", "url": "https://github.com/apache/hbase/pull/1552#discussion_r434304818", "createdAt": "2020-06-03T04:45:34Z", "author": {"login": "ramkrish86"}, "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionWrapper.java", "diffHunk": "@@ -170,4 +170,15 @@\n    *   all compacted store files that belong to this region\n    */\n   long getMaxCompactedStoreFileRefCount();\n+\n+  /**\n+   * @return the number of reads on memstore\n+   */\n+  long getMemstoreReadRequestsCount();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDIwOTI4Mw=="}, "originalCommit": {"oid": "66e0d8ffb5122019916a420a35c0372e17774212"}, "originalPosition": 8}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcwNDcwMjM4OnYy", "diffSide": "RIGHT", "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsStoreAggregateSource.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQyMjoyNzo1N1rOGeGDTw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wM1QwNDo0NTo1M1rOGeL3ew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDIwOTYxNQ==", "bodyText": "Metrics for a Store for more than one Store? If for more than one Store, why not in Region?", "url": "https://github.com/apache/hbase/pull/1552#discussion_r434209615", "createdAt": "2020-06-02T22:27:57Z", "author": {"login": "saintstack"}, "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsStoreAggregateSource.java", "diffHunk": "@@ -0,0 +1,60 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.regionserver;\n+\n+import org.apache.hadoop.hbase.metrics.BaseSource;\n+import org.apache.yetus.audience.InterfaceAudience;\n+\n+\n+@InterfaceAudience.Private\n+public interface MetricsStoreAggregateSource extends BaseSource {\n+  /**\n+   * The name of the metrics\n+   */\n+  String METRICS_NAME = \"Stores\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "66e0d8ffb5122019916a420a35c0372e17774212"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDIwOTc2Mg==", "bodyText": "If a single Store, should be called 'Store' not 'Stores'?", "url": "https://github.com/apache/hbase/pull/1552#discussion_r434209762", "createdAt": "2020-06-02T22:28:21Z", "author": {"login": "saintstack"}, "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsStoreAggregateSource.java", "diffHunk": "@@ -0,0 +1,60 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.regionserver;\n+\n+import org.apache.hadoop.hbase.metrics.BaseSource;\n+import org.apache.yetus.audience.InterfaceAudience;\n+\n+\n+@InterfaceAudience.Private\n+public interface MetricsStoreAggregateSource extends BaseSource {\n+  /**\n+   * The name of the metrics\n+   */\n+  String METRICS_NAME = \"Stores\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDIwOTYxNQ=="}, "originalCommit": {"oid": "66e0d8ffb5122019916a420a35c0372e17774212"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDMwNDg5MQ==", "bodyText": "Ok .will make it Store.", "url": "https://github.com/apache/hbase/pull/1552#discussion_r434304891", "createdAt": "2020-06-03T04:45:53Z", "author": {"login": "ramkrish86"}, "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsStoreAggregateSource.java", "diffHunk": "@@ -0,0 +1,60 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.regionserver;\n+\n+import org.apache.hadoop.hbase.metrics.BaseSource;\n+import org.apache.yetus.audience.InterfaceAudience;\n+\n+\n+@InterfaceAudience.Private\n+public interface MetricsStoreAggregateSource extends BaseSource {\n+  /**\n+   * The name of the metrics\n+   */\n+  String METRICS_NAME = \"Stores\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDIwOTYxNQ=="}, "originalCommit": {"oid": "66e0d8ffb5122019916a420a35c0372e17774212"}, "originalPosition": 29}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcwNDcwOTg0OnYy", "diffSide": "RIGHT", "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsStoreAggregateSource.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQyMjozMToxNlrOGeGH1g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wM1QxNDoxMTo1OVrOGedxWA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDIxMDc3NA==", "bodyText": "This model doesn't seem right. There is no such thing as a Store on a RegionServer. The RegionServer hosts Regions. A Region hosts Stores.  This is an aggregate of all Stores on the RegionServer?\nI could imagine RegionServer,sub=Region,sub=Store... with a Bean per Store but then we'd probably have too many MBeans.\nDo we have a Region at this level in MBean hierarchy?", "url": "https://github.com/apache/hbase/pull/1552#discussion_r434210774", "createdAt": "2020-06-02T22:31:16Z", "author": {"login": "saintstack"}, "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsStoreAggregateSource.java", "diffHunk": "@@ -0,0 +1,60 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.regionserver;\n+\n+import org.apache.hadoop.hbase.metrics.BaseSource;\n+import org.apache.yetus.audience.InterfaceAudience;\n+\n+\n+@InterfaceAudience.Private\n+public interface MetricsStoreAggregateSource extends BaseSource {\n+  /**\n+   * The name of the metrics\n+   */\n+  String METRICS_NAME = \"Stores\";\n+\n+  /**\n+   * The name of the metrics context that metrics will be under.\n+   */\n+  String METRICS_CONTEXT = \"regionserver\";\n+\n+  /**\n+   * Description\n+   */\n+  String METRICS_DESCRIPTION = \"Metrics about Stores under a region\";\n+\n+  /**\n+   * The name of the metrics context that metrics will be under in jmx\n+   */\n+  String METRICS_JMX_CONTEXT = \"RegionServer,sub=\" + METRICS_NAME;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "66e0d8ffb5122019916a420a35c0372e17774212"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDM2OTEzNA==", "bodyText": "I was just trying to push all the store level metric per region under this. that is why collected it under RegionServer.", "url": "https://github.com/apache/hbase/pull/1552#discussion_r434369134", "createdAt": "2020-06-03T07:39:50Z", "author": {"login": "ramkrish86"}, "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsStoreAggregateSource.java", "diffHunk": "@@ -0,0 +1,60 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.regionserver;\n+\n+import org.apache.hadoop.hbase.metrics.BaseSource;\n+import org.apache.yetus.audience.InterfaceAudience;\n+\n+\n+@InterfaceAudience.Private\n+public interface MetricsStoreAggregateSource extends BaseSource {\n+  /**\n+   * The name of the metrics\n+   */\n+  String METRICS_NAME = \"Stores\";\n+\n+  /**\n+   * The name of the metrics context that metrics will be under.\n+   */\n+  String METRICS_CONTEXT = \"regionserver\";\n+\n+  /**\n+   * Description\n+   */\n+  String METRICS_DESCRIPTION = \"Metrics about Stores under a region\";\n+\n+  /**\n+   * The name of the metrics context that metrics will be under in jmx\n+   */\n+  String METRICS_JMX_CONTEXT = \"RegionServer,sub=\" + METRICS_NAME;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDIxMDc3NA=="}, "originalCommit": {"oid": "66e0d8ffb5122019916a420a35c0372e17774212"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDM3NjQ3OA==", "bodyText": "And seeing ur other comment -  this is where yo uwill get per region under each store I have how many requests. If I want to remove this then I may have to do something like how it has been done for Table vs Store - we will have region vs store (and it will be at the region level only).", "url": "https://github.com/apache/hbase/pull/1552#discussion_r434376478", "createdAt": "2020-06-03T07:53:20Z", "author": {"login": "ramkrish86"}, "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsStoreAggregateSource.java", "diffHunk": "@@ -0,0 +1,60 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.regionserver;\n+\n+import org.apache.hadoop.hbase.metrics.BaseSource;\n+import org.apache.yetus.audience.InterfaceAudience;\n+\n+\n+@InterfaceAudience.Private\n+public interface MetricsStoreAggregateSource extends BaseSource {\n+  /**\n+   * The name of the metrics\n+   */\n+  String METRICS_NAME = \"Stores\";\n+\n+  /**\n+   * The name of the metrics context that metrics will be under.\n+   */\n+  String METRICS_CONTEXT = \"regionserver\";\n+\n+  /**\n+   * Description\n+   */\n+  String METRICS_DESCRIPTION = \"Metrics about Stores under a region\";\n+\n+  /**\n+   * The name of the metrics context that metrics will be under in jmx\n+   */\n+  String METRICS_JMX_CONTEXT = \"RegionServer,sub=\" + METRICS_NAME;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDIxMDc3NA=="}, "originalCommit": {"oid": "66e0d8ffb5122019916a420a35c0372e17774212"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDU5ODIzMg==", "bodyText": "I think to avoid this problem of having another metric exposed at Store level which will list all the region names and its corresponding read metrics and also we have a region level metric where we expose across all stores in that region how many reads happened.\nBoth come under different Mbean - one is sub=Regions and another is sub=Stores. (this is added newly in this patch)\nThe patch already has an aggregated metric at the Table level where we report a metric\n\nNameSpace_table_store_metric\nWe will just use this and add a similar metric at the region level which aggregates it per store\nas we have for table level. Will that be ok ?\n@saintstack - what you think?", "url": "https://github.com/apache/hbase/pull/1552#discussion_r434598232", "createdAt": "2020-06-03T14:11:59Z", "author": {"login": "ramkrish86"}, "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsStoreAggregateSource.java", "diffHunk": "@@ -0,0 +1,60 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.regionserver;\n+\n+import org.apache.hadoop.hbase.metrics.BaseSource;\n+import org.apache.yetus.audience.InterfaceAudience;\n+\n+\n+@InterfaceAudience.Private\n+public interface MetricsStoreAggregateSource extends BaseSource {\n+  /**\n+   * The name of the metrics\n+   */\n+  String METRICS_NAME = \"Stores\";\n+\n+  /**\n+   * The name of the metrics context that metrics will be under.\n+   */\n+  String METRICS_CONTEXT = \"regionserver\";\n+\n+  /**\n+   * Description\n+   */\n+  String METRICS_DESCRIPTION = \"Metrics about Stores under a region\";\n+\n+  /**\n+   * The name of the metrics context that metrics will be under in jmx\n+   */\n+  String METRICS_JMX_CONTEXT = \"RegionServer,sub=\" + METRICS_NAME;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDIxMDc3NA=="}, "originalCommit": {"oid": "66e0d8ffb5122019916a420a35c0372e17774212"}, "originalPosition": 44}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczMjkxOTk2OnYy", "diffSide": "RIGHT", "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsTableSourceImpl.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMVQxMDo0MTowNlrOGiX57Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQxNToyNDo1MFrOGkg0qA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODY5NjQyOQ==", "bodyText": "Here the key will be <regionName>_<storeName>?\nAt this level we should call CF not store?", "url": "https://github.com/apache/hbase/pull/1552#discussion_r438696429", "createdAt": "2020-06-11T10:41:06Z", "author": {"login": "anoopsjohn"}, "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsTableSourceImpl.java", "diffHunk": "@@ -311,6 +322,27 @@ void snapshot(MetricsRecordBuilder mrb, boolean ignored) {\n         mrb.addGauge(Interns.info(tableNamePrefix + MetricsRegionServerSource.NUM_REFERENCE_FILES,\n             MetricsRegionServerSource.NUM_REFERENCE_FILES_DESC),\n             tableWrapperAgg.getNumReferenceFiles(tableName.getNameAsString()));\n+        addGauge(mrb, tableWrapperAgg.getMemstoreReadRequestsCount(tableName.getNameAsString()),\n+          MetricsRegionSource.READ_REQUEST_ON_MEMSTORE,\n+          MetricsRegionSource.READ_REQUEST_ON_MEMSTORE_DESC);\n+        addGauge(mrb, tableWrapperAgg.getMixedRequestsCount(tableName.getNameAsString()),\n+          MetricsRegionSource.MIXED_READ_REQUEST_ON_STORE,\n+          MetricsRegionSource.MIXED_READ_REQUEST_ON_STORE_DESC);\n+      }\n+    }\n+  }\n+\n+  private void addGauge(MetricsRecordBuilder mrb, Map<String, Long> metricMap, String metricName,\n+      String metricDesc) {\n+    if (metricMap != null) {\n+      Iterator<Entry<String, Long>> iterator = metricMap.entrySet().iterator();\n+      while (iterator.hasNext()) {\n+        Entry<String, Long> entry = iterator.next();\n+        // append 'store' and its name to the metric\n+        mrb.addGauge(Interns.info(this.tableNamePrefixPart1 + _STORE\n+            + entry.getKey().split(MetricsTableWrapperAggregate.UNDERSCORE)[1]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "04836c048d54b44c533465377776c9a70e3fa101"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTU4MTE2Mw==", "bodyText": "You mean the key should be Columnfamily? So _STORE - that should be _ColumnFamily?", "url": "https://github.com/apache/hbase/pull/1552#discussion_r439581163", "createdAt": "2020-06-12T18:32:06Z", "author": {"login": "ramkrish86"}, "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsTableSourceImpl.java", "diffHunk": "@@ -311,6 +322,27 @@ void snapshot(MetricsRecordBuilder mrb, boolean ignored) {\n         mrb.addGauge(Interns.info(tableNamePrefix + MetricsRegionServerSource.NUM_REFERENCE_FILES,\n             MetricsRegionServerSource.NUM_REFERENCE_FILES_DESC),\n             tableWrapperAgg.getNumReferenceFiles(tableName.getNameAsString()));\n+        addGauge(mrb, tableWrapperAgg.getMemstoreReadRequestsCount(tableName.getNameAsString()),\n+          MetricsRegionSource.READ_REQUEST_ON_MEMSTORE,\n+          MetricsRegionSource.READ_REQUEST_ON_MEMSTORE_DESC);\n+        addGauge(mrb, tableWrapperAgg.getMixedRequestsCount(tableName.getNameAsString()),\n+          MetricsRegionSource.MIXED_READ_REQUEST_ON_STORE,\n+          MetricsRegionSource.MIXED_READ_REQUEST_ON_STORE_DESC);\n+      }\n+    }\n+  }\n+\n+  private void addGauge(MetricsRecordBuilder mrb, Map<String, Long> metricMap, String metricName,\n+      String metricDesc) {\n+    if (metricMap != null) {\n+      Iterator<Entry<String, Long>> iterator = metricMap.entrySet().iterator();\n+      while (iterator.hasNext()) {\n+        Entry<String, Long> entry = iterator.next();\n+        // append 'store' and its name to the metric\n+        mrb.addGauge(Interns.info(this.tableNamePrefixPart1 + _STORE\n+            + entry.getKey().split(MetricsTableWrapperAggregate.UNDERSCORE)[1]", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODY5NjQyOQ=="}, "originalCommit": {"oid": "04836c048d54b44c533465377776c9a70e3fa101"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTYxMTkyMg==", "bodyText": "Store is an instance of CF. So here what we have is an aggregated value across all instances (Stores) of a given CF in a table. So the name CF make sense than STORE? WDYT", "url": "https://github.com/apache/hbase/pull/1552#discussion_r439611922", "createdAt": "2020-06-12T19:46:29Z", "author": {"login": "anoopsjohn"}, "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsTableSourceImpl.java", "diffHunk": "@@ -311,6 +322,27 @@ void snapshot(MetricsRecordBuilder mrb, boolean ignored) {\n         mrb.addGauge(Interns.info(tableNamePrefix + MetricsRegionServerSource.NUM_REFERENCE_FILES,\n             MetricsRegionServerSource.NUM_REFERENCE_FILES_DESC),\n             tableWrapperAgg.getNumReferenceFiles(tableName.getNameAsString()));\n+        addGauge(mrb, tableWrapperAgg.getMemstoreReadRequestsCount(tableName.getNameAsString()),\n+          MetricsRegionSource.READ_REQUEST_ON_MEMSTORE,\n+          MetricsRegionSource.READ_REQUEST_ON_MEMSTORE_DESC);\n+        addGauge(mrb, tableWrapperAgg.getMixedRequestsCount(tableName.getNameAsString()),\n+          MetricsRegionSource.MIXED_READ_REQUEST_ON_STORE,\n+          MetricsRegionSource.MIXED_READ_REQUEST_ON_STORE_DESC);\n+      }\n+    }\n+  }\n+\n+  private void addGauge(MetricsRecordBuilder mrb, Map<String, Long> metricMap, String metricName,\n+      String metricDesc) {\n+    if (metricMap != null) {\n+      Iterator<Entry<String, Long>> iterator = metricMap.entrySet().iterator();\n+      while (iterator.hasNext()) {\n+        Entry<String, Long> entry = iterator.next();\n+        // append 'store' and its name to the metric\n+        mrb.addGauge(Interns.info(this.tableNamePrefixPart1 + _STORE\n+            + entry.getKey().split(MetricsTableWrapperAggregate.UNDERSCORE)[1]", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODY5NjQyOQ=="}, "originalCommit": {"oid": "04836c048d54b44c533465377776c9a70e3fa101"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDkzOTY4OA==", "bodyText": "This looks like it was addressed.", "url": "https://github.com/apache/hbase/pull/1552#discussion_r440939688", "createdAt": "2020-06-16T15:24:50Z", "author": {"login": "saintstack"}, "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsTableSourceImpl.java", "diffHunk": "@@ -311,6 +322,27 @@ void snapshot(MetricsRecordBuilder mrb, boolean ignored) {\n         mrb.addGauge(Interns.info(tableNamePrefix + MetricsRegionServerSource.NUM_REFERENCE_FILES,\n             MetricsRegionServerSource.NUM_REFERENCE_FILES_DESC),\n             tableWrapperAgg.getNumReferenceFiles(tableName.getNameAsString()));\n+        addGauge(mrb, tableWrapperAgg.getMemstoreReadRequestsCount(tableName.getNameAsString()),\n+          MetricsRegionSource.READ_REQUEST_ON_MEMSTORE,\n+          MetricsRegionSource.READ_REQUEST_ON_MEMSTORE_DESC);\n+        addGauge(mrb, tableWrapperAgg.getMixedRequestsCount(tableName.getNameAsString()),\n+          MetricsRegionSource.MIXED_READ_REQUEST_ON_STORE,\n+          MetricsRegionSource.MIXED_READ_REQUEST_ON_STORE_DESC);\n+      }\n+    }\n+  }\n+\n+  private void addGauge(MetricsRecordBuilder mrb, Map<String, Long> metricMap, String metricName,\n+      String metricDesc) {\n+    if (metricMap != null) {\n+      Iterator<Entry<String, Long>> iterator = metricMap.entrySet().iterator();\n+      while (iterator.hasNext()) {\n+        Entry<String, Long> entry = iterator.next();\n+        // append 'store' and its name to the metric\n+        mrb.addGauge(Interns.info(this.tableNamePrefixPart1 + _STORE\n+            + entry.getKey().split(MetricsTableWrapperAggregate.UNDERSCORE)[1]", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODY5NjQyOQ=="}, "originalCommit": {"oid": "04836c048d54b44c533465377776c9a70e3fa101"}, "originalPosition": 66}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczMjkyNDAxOnYy", "diffSide": "RIGHT", "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsTableWrapperAggregate.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMVQxMDo0MjozN1rOGiX8sQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMVQxMDo0MjozN1rOGiX8sQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODY5NzEzNw==", "bodyText": "We dont say whether it is read reqs in this method name.  This is the total  #rows reads from this Store right?  Can we name in that way and avoid the term mixed?", "url": "https://github.com/apache/hbase/pull/1552#discussion_r438697137", "createdAt": "2020-06-11T10:42:37Z", "author": {"login": "anoopsjohn"}, "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsTableWrapperAggregate.java", "diffHunk": "@@ -107,6 +109,13 @@\n    */\n   long getNumReferenceFiles(String table);\n \n+  /**\n+   * @return number of get requests from memstore per store for this table\n+   */\n+  Map<String, Long> getMemstoreReadRequestsCount(String table);\n \n-\n+  /**\n+   * @return number of get requests from file per store for this table\n+   */\n+  Map<String, Long> getMixedRequestsCount(String table);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "04836c048d54b44c533465377776c9a70e3fa101"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczODIzMTUyOnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsTableWrapperAggregateImpl.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQxNzozMjozN1rOGjMO7g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQxOTo0NDozNlrOGjPvHg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTU1Mzc3NA==", "bodyText": "Is this a bug fix? (Like the one below) .. Can u explain .. Previously it was a config based thing and now hard coded.", "url": "https://github.com/apache/hbase/pull/1552#discussion_r439553774", "createdAt": "2020-06-12T17:32:37Z", "author": {"login": "anoopsjohn"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsTableWrapperAggregateImpl.java", "diffHunk": "@@ -41,39 +40,42 @@\n   private final HRegionServer regionServer;\n   private ScheduledExecutorService executor;\n   private Runnable runnable;\n-  private long period;\n+  private static final int PERIOD = 45;\n   private ScheduledFuture<?> tableMetricsUpdateTask;\n   private ConcurrentHashMap<TableName, MetricsTableValues> metricsTableMap\n     = new ConcurrentHashMap<>();\n \n   public MetricsTableWrapperAggregateImpl(final HRegionServer regionServer) {\n     this.regionServer = regionServer;\n-    this.period = regionServer.getConfiguration().getLong(HConstants.REGIONSERVER_METRICS_PERIOD,\n-      HConstants.DEFAULT_REGIONSERVER_METRICS_PERIOD) + 1000;\n     this.executor = CompatibilitySingletonFactory.getInstance(MetricsExecutor.class).getExecutor();\n     this.runnable = new TableMetricsWrapperRunnable();\n-    this.tableMetricsUpdateTask = this.executor.scheduleWithFixedDelay(this.runnable, period,\n-      this.period, TimeUnit.MILLISECONDS);\n+    this.tableMetricsUpdateTask = this.executor.scheduleWithFixedDelay(this.runnable, PERIOD,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a46d74fbdf256b342b7b06ab78e739cca17e3b8f"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTU4MDYwOA==", "bodyText": "This is not a bug fix and also the config based update I believe it was just added because the MetricsREgionServer based aggregate therad was having that config. But if you see the MetricRegionSource it is same 45 sec. The period of updation was rather too frequent. I just changed it to be in sync with MetricREgionSource.", "url": "https://github.com/apache/hbase/pull/1552#discussion_r439580608", "createdAt": "2020-06-12T18:30:51Z", "author": {"login": "ramkrish86"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsTableWrapperAggregateImpl.java", "diffHunk": "@@ -41,39 +40,42 @@\n   private final HRegionServer regionServer;\n   private ScheduledExecutorService executor;\n   private Runnable runnable;\n-  private long period;\n+  private static final int PERIOD = 45;\n   private ScheduledFuture<?> tableMetricsUpdateTask;\n   private ConcurrentHashMap<TableName, MetricsTableValues> metricsTableMap\n     = new ConcurrentHashMap<>();\n \n   public MetricsTableWrapperAggregateImpl(final HRegionServer regionServer) {\n     this.regionServer = regionServer;\n-    this.period = regionServer.getConfiguration().getLong(HConstants.REGIONSERVER_METRICS_PERIOD,\n-      HConstants.DEFAULT_REGIONSERVER_METRICS_PERIOD) + 1000;\n     this.executor = CompatibilitySingletonFactory.getInstance(MetricsExecutor.class).getExecutor();\n     this.runnable = new TableMetricsWrapperRunnable();\n-    this.tableMetricsUpdateTask = this.executor.scheduleWithFixedDelay(this.runnable, period,\n-      this.period, TimeUnit.MILLISECONDS);\n+    this.tableMetricsUpdateTask = this.executor.scheduleWithFixedDelay(this.runnable, PERIOD,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTU1Mzc3NA=="}, "originalCommit": {"oid": "a46d74fbdf256b342b7b06ab78e739cca17e3b8f"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTYxMTE2Ng==", "bodyText": "I would request to keep this out of this PR.  Raise another specific Jira to address this issue and may be below one also and get it committed as part of that. Later it will be easy for some one who is searching the change history/ bug fix history.", "url": "https://github.com/apache/hbase/pull/1552#discussion_r439611166", "createdAt": "2020-06-12T19:44:36Z", "author": {"login": "anoopsjohn"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsTableWrapperAggregateImpl.java", "diffHunk": "@@ -41,39 +40,42 @@\n   private final HRegionServer regionServer;\n   private ScheduledExecutorService executor;\n   private Runnable runnable;\n-  private long period;\n+  private static final int PERIOD = 45;\n   private ScheduledFuture<?> tableMetricsUpdateTask;\n   private ConcurrentHashMap<TableName, MetricsTableValues> metricsTableMap\n     = new ConcurrentHashMap<>();\n \n   public MetricsTableWrapperAggregateImpl(final HRegionServer regionServer) {\n     this.regionServer = regionServer;\n-    this.period = regionServer.getConfiguration().getLong(HConstants.REGIONSERVER_METRICS_PERIOD,\n-      HConstants.DEFAULT_REGIONSERVER_METRICS_PERIOD) + 1000;\n     this.executor = CompatibilitySingletonFactory.getInstance(MetricsExecutor.class).getExecutor();\n     this.runnable = new TableMetricsWrapperRunnable();\n-    this.tableMetricsUpdateTask = this.executor.scheduleWithFixedDelay(this.runnable, period,\n-      this.period, TimeUnit.MILLISECONDS);\n+    this.tableMetricsUpdateTask = this.executor.scheduleWithFixedDelay(this.runnable, PERIOD,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTU1Mzc3NA=="}, "originalCommit": {"oid": "a46d74fbdf256b342b7b06ab78e739cca17e3b8f"}, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc0NzE0ODQxOnYy", "diffSide": "RIGHT", "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionSourceImpl.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQxNToyMDowMVrOGkgkmQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QwNzoyNjoyMFrOGk5AqA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDkzNTU3Nw==", "bodyText": "We still need this count? We don't have it already with the general read count?", "url": "https://github.com/apache/hbase/pull/1552#discussion_r440935577", "createdAt": "2020-06-16T15:20:01Z", "author": {"login": "saintstack"}, "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionSourceImpl.java", "diffHunk": "@@ -302,6 +308,24 @@ void snapshot(MetricsRecordBuilder mrb, boolean ignored) {\n               regionNamePrefix + MetricsRegionSource.MAX_FLUSH_QUEUE_SIZE,\n               MetricsRegionSource.MAX_FLUSH_QUEUE_DESC),\n           this.regionWrapper.getMaxFlushQueueSize());\n+      addCounter(mrb, this.regionWrapper.getMemstoreOnlyRowReadsCount(),\n+        MetricsRegionSource.ROW_READS_ONLY_ON_MEMSTORE,\n+        MetricsRegionSource.ROW_READS_ONLY_ON_MEMSTORE_DESC);\n+      addCounter(mrb, this.regionWrapper.getMixedRowReadsCount(),\n+        MetricsRegionSource.MIXED_ROW_READS,\n+        MetricsRegionSource.MIXED_ROW_READS_ON_STORE_DESC);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4252420b08217bd33ee15f890bc791769640a4ab"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDk0MDUxNQ==", "bodyText": "My aversion to the extra counting is that we already do so much; it costs us loads in cpu. Was trying to do less if we can.", "url": "https://github.com/apache/hbase/pull/1552#discussion_r440940515", "createdAt": "2020-06-16T15:25:53Z", "author": {"login": "saintstack"}, "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionSourceImpl.java", "diffHunk": "@@ -302,6 +308,24 @@ void snapshot(MetricsRecordBuilder mrb, boolean ignored) {\n               regionNamePrefix + MetricsRegionSource.MAX_FLUSH_QUEUE_SIZE,\n               MetricsRegionSource.MAX_FLUSH_QUEUE_DESC),\n           this.regionWrapper.getMaxFlushQueueSize());\n+      addCounter(mrb, this.regionWrapper.getMemstoreOnlyRowReadsCount(),\n+        MetricsRegionSource.ROW_READS_ONLY_ON_MEMSTORE,\n+        MetricsRegionSource.ROW_READS_ONLY_ON_MEMSTORE_DESC);\n+      addCounter(mrb, this.regionWrapper.getMixedRowReadsCount(),\n+        MetricsRegionSource.MIXED_ROW_READS,\n+        MetricsRegionSource.MIXED_ROW_READS_ON_STORE_DESC);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDkzNTU3Nw=="}, "originalCommit": {"oid": "4252420b08217bd33ee15f890bc791769640a4ab"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTMzMzcyMQ==", "bodyText": "Are asking in terms of CPU that we add on while collecting the metric? Ifyou see we do collect the metric at the HStore level per row when the StoreScanner completes a row process. That is now a longadder. Seems it is more performant than AtomicLong. Also the above change that we have done at the region level is nothing but just get that metric when that runnable thread keeps running. We don do any metric collection at this level. Are you still thinking it may be a problem. @saintstack ? BTW thanks for your review here.", "url": "https://github.com/apache/hbase/pull/1552#discussion_r441333721", "createdAt": "2020-06-17T07:22:08Z", "author": {"login": "ramkrish86"}, "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionSourceImpl.java", "diffHunk": "@@ -302,6 +308,24 @@ void snapshot(MetricsRecordBuilder mrb, boolean ignored) {\n               regionNamePrefix + MetricsRegionSource.MAX_FLUSH_QUEUE_SIZE,\n               MetricsRegionSource.MAX_FLUSH_QUEUE_DESC),\n           this.regionWrapper.getMaxFlushQueueSize());\n+      addCounter(mrb, this.regionWrapper.getMemstoreOnlyRowReadsCount(),\n+        MetricsRegionSource.ROW_READS_ONLY_ON_MEMSTORE,\n+        MetricsRegionSource.ROW_READS_ONLY_ON_MEMSTORE_DESC);\n+      addCounter(mrb, this.regionWrapper.getMixedRowReadsCount(),\n+        MetricsRegionSource.MIXED_ROW_READS,\n+        MetricsRegionSource.MIXED_ROW_READS_ON_STORE_DESC);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDkzNTU3Nw=="}, "originalCommit": {"oid": "4252420b08217bd33ee15f890bc791769640a4ab"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTMzNTk3Ng==", "bodyText": "We don't have it already with the general read count?\n\nThis is a read count across all stores. But now what we get additionally is per store how much is the read count that hit both memstore and files - also one more where we say how many rows per store came out of memstore only. Ideally the sum of these values per store should be equal to the total read count per region.", "url": "https://github.com/apache/hbase/pull/1552#discussion_r441335976", "createdAt": "2020-06-17T07:26:20Z", "author": {"login": "ramkrish86"}, "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionSourceImpl.java", "diffHunk": "@@ -302,6 +308,24 @@ void snapshot(MetricsRecordBuilder mrb, boolean ignored) {\n               regionNamePrefix + MetricsRegionSource.MAX_FLUSH_QUEUE_SIZE,\n               MetricsRegionSource.MAX_FLUSH_QUEUE_DESC),\n           this.regionWrapper.getMaxFlushQueueSize());\n+      addCounter(mrb, this.regionWrapper.getMemstoreOnlyRowReadsCount(),\n+        MetricsRegionSource.ROW_READS_ONLY_ON_MEMSTORE,\n+        MetricsRegionSource.ROW_READS_ONLY_ON_MEMSTORE_DESC);\n+      addCounter(mrb, this.regionWrapper.getMixedRowReadsCount(),\n+        MetricsRegionSource.MIXED_ROW_READS,\n+        MetricsRegionSource.MIXED_ROW_READS_ON_STORE_DESC);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDkzNTU3Nw=="}, "originalCommit": {"oid": "4252420b08217bd33ee15f890bc791769640a4ab"}, "originalPosition": 51}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc0NzE2MTMzOnYy", "diffSide": "RIGHT", "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionSourceImpl.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQxNToyMTo1MVrOGkgrxg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQxNToyMTo1MVrOGkgrxg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDkzNzQxNA==", "bodyText": "This 'metric' addition to name was of no value?", "url": "https://github.com/apache/hbase/pull/1552#discussion_r440937414", "createdAt": "2020-06-16T15:21:51Z", "author": {"login": "saintstack"}, "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionSourceImpl.java", "diffHunk": "@@ -77,10 +83,10 @@ public MetricsRegionSourceImpl(MetricsRegionWrapper regionWrapper,\n \n     registry = agg.getMetricsRegistry();\n \n-    regionNamePrefix = \"Namespace_\" + regionWrapper.getNamespace() +\n-        \"_table_\" + regionWrapper.getTableName() +\n-        \"_region_\" + regionWrapper.getRegionName()  +\n-        \"_metric_\";\n+    regionNamePrefix1 = \"Namespace_\" + regionWrapper.getNamespace() + \"_table_\"\n+        + regionWrapper.getTableName() + \"_region_\" + regionWrapper.getRegionName();\n+    regionNamePrefix2 = \"_metric_\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4252420b08217bd33ee15f890bc791769640a4ab"}, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc0NzE2NjM0OnYy", "diffSide": "RIGHT", "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionWrapper.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQxNToyMjo0OVrOGkgu6g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQxNToyMjo0OVrOGkgu6g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDkzODIxOA==", "bodyText": "Yeah, do we need to keep this count? It doesn't overlap w/ another?", "url": "https://github.com/apache/hbase/pull/1552#discussion_r440938218", "createdAt": "2020-06-16T15:22:49Z", "author": {"login": "saintstack"}, "path": "hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionWrapper.java", "diffHunk": "@@ -170,4 +172,15 @@\n    *   all compacted store files that belong to this region\n    */\n   long getMaxCompactedStoreFileRefCount();\n+\n+  /**\n+   * @return the number of row reads completely on memstore per store\n+   */\n+  Map<String, Long> getMemstoreOnlyRowReadsCount();\n+\n+  /**\n+   * @return the number of row reads on memstore and file per store\n+   */\n+  Map<String, Long> getMixedRowReadsCount();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4252420b08217bd33ee15f890bc791769640a4ab"}, "originalPosition": 22}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1812, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}