{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDU0NDIyMTM4", "number": 2111, "title": "HBASE-24683 Add a basic ReplicationServer which only implement Replic\u2026", "bodyText": "\u2026ationSink Service", "createdAt": "2020-07-21T11:42:39Z", "url": "https://github.com/apache/hbase/pull/2111", "merged": true, "mergeCommit": {"oid": "4d581fa256ace8f270842a66a6c80f67c46d4947"}, "closed": true, "closedAt": "2020-09-04T10:53:47Z", "author": {"login": "ddupg"}, "timelineItems": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc3SaMSgBqjM1NzM5NDYyMjE=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdFi_0QAFqTQ4MjU1NTEyMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "00f15465a6cdcd7577e908421d6d5a8a19e8bdf6", "author": {"user": {"login": "ddupg", "name": "XinSun"}}, "url": "https://github.com/apache/hbase/commit/00f15465a6cdcd7577e908421d6d5a8a19e8bdf6", "committedDate": "2020-07-21T11:39:30Z", "message": "HBASE-24683 Add a basic ReplicationServer which only implement ReplicationSink Service"}, "afterCommit": {"oid": "a93bac612767dc715cebcad214f0efc01a2c4724", "author": {"user": {"login": "ddupg", "name": "XinSun"}}, "url": "https://github.com/apache/hbase/commit/a93bac612767dc715cebcad214f0efc01a2c4724", "committedDate": "2020-07-22T03:38:38Z", "message": "HBASE-24683 Add a basic ReplicationServer which only implement ReplicationSink Service"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDYzOTg4NjE1", "url": "https://github.com/apache/hbase/pull/2111#pullrequestreview-463988615", "createdAt": "2020-08-10T06:49:32Z", "commit": {"oid": "a93bac612767dc715cebcad214f0efc01a2c4724"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQwNjo0OTozMlrOG-DCow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQwNjo0OTozMlrOG-DCow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzcxNDcyMw==", "bodyText": "Do not need to implements RegionServerServices?", "url": "https://github.com/apache/hbase/pull/2111#discussion_r467714723", "createdAt": "2020-08-10T06:49:32Z", "author": {"login": "infraio"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/HReplicationServer.java", "diffHunk": "@@ -0,0 +1,683 @@\n+/**\n+ *\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.replication;\n+\n+import java.io.IOException;\n+import java.lang.reflect.Constructor;\n+import java.net.InetSocketAddress;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map.Entry;\n+import java.util.Optional;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.Abortable;\n+import org.apache.hadoop.hbase.ChoreService;\n+import org.apache.hadoop.hbase.CoordinatedStateManager;\n+import org.apache.hadoop.hbase.DoNotRetryIOException;\n+import org.apache.hadoop.hbase.HBaseConfiguration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.HConstants;\n+import org.apache.hadoop.hbase.Server;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.TableDescriptors;\n+import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.AsyncClusterConnection;\n+import org.apache.hadoop.hbase.client.ClusterConnectionFactory;\n+import org.apache.hadoop.hbase.client.Connection;\n+import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.locking.EntityLock;\n+import org.apache.hadoop.hbase.executor.ExecutorService;\n+import org.apache.hadoop.hbase.io.hfile.BlockCache;\n+import org.apache.hadoop.hbase.ipc.RpcServerInterface;\n+import org.apache.hadoop.hbase.log.HBaseMarkers;\n+import org.apache.hadoop.hbase.mob.MobFileCache;\n+import org.apache.hadoop.hbase.quotas.RegionServerRpcQuotaManager;\n+import org.apache.hadoop.hbase.quotas.RegionServerSpaceQuotaManager;\n+import org.apache.hadoop.hbase.quotas.RegionSizeStore;\n+import org.apache.hadoop.hbase.regionserver.FlushRequester;\n+import org.apache.hadoop.hbase.regionserver.HRegion;\n+import org.apache.hadoop.hbase.regionserver.HeapMemoryManager;\n+import org.apache.hadoop.hbase.regionserver.LeaseManager;\n+import org.apache.hadoop.hbase.regionserver.MetricsRegionServer;\n+import org.apache.hadoop.hbase.regionserver.Region;\n+import org.apache.hadoop.hbase.regionserver.RegionServerAccounting;\n+import org.apache.hadoop.hbase.regionserver.RegionServerServices;\n+import org.apache.hadoop.hbase.regionserver.ReplicationService;\n+import org.apache.hadoop.hbase.regionserver.ReplicationSinkService;\n+import org.apache.hadoop.hbase.regionserver.ReplicationSourceService;\n+import org.apache.hadoop.hbase.regionserver.SecureBulkLoadManager;\n+import org.apache.hadoop.hbase.regionserver.ServerNonceManager;\n+import org.apache.hadoop.hbase.regionserver.compactions.CompactionRequester;\n+import org.apache.hadoop.hbase.regionserver.throttle.ThroughputController;\n+import org.apache.hadoop.hbase.security.User;\n+import org.apache.hadoop.hbase.security.UserProvider;\n+import org.apache.hadoop.hbase.security.access.AccessChecker;\n+import org.apache.hadoop.hbase.security.access.ZKPermissionWatcher;\n+import org.apache.hadoop.hbase.trace.TraceUtil;\n+import org.apache.hadoop.hbase.util.Sleeper;\n+import org.apache.hadoop.hbase.util.VersionInfo;\n+import org.apache.hadoop.hbase.wal.WAL;\n+import org.apache.hadoop.hbase.zookeeper.ZKWatcher;\n+import org.apache.hadoop.util.ReflectionUtils;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos;\n+\n+import org.apache.hbase.thirdparty.com.google.protobuf.Service;\n+\n+/**\n+ * HReplicationServer which is responsible to all replication stuff. It checks in with\n+ * the HMaster. There are many HReplicationServers in a single HBase deployment.\n+ */\n+@InterfaceAudience.LimitedPrivate(HBaseInterfaceAudience.TOOLS)\n+@SuppressWarnings({ \"deprecation\"})\n+public class HReplicationServer extends Thread implements Server, RegionServerServices {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a93bac612767dc715cebcad214f0efc01a2c4724"}, "originalPosition": 95}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDYzOTg5MTA4", "url": "https://github.com/apache/hbase/pull/2111#pullrequestreview-463989108", "createdAt": "2020-08-10T06:50:40Z", "commit": {"oid": "a93bac612767dc715cebcad214f0efc01a2c4724"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQwNjo1MDo0MFrOG-DEOQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQwNjo1MDo0MFrOG-DEOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzcxNTEyOQ==", "bodyText": "No need to impl AdminService.BlockingInterface?", "url": "https://github.com/apache/hbase/pull/2111#discussion_r467715129", "createdAt": "2020-08-10T06:50:40Z", "author": {"login": "infraio"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/ReplicationServerRpcServices.java", "diffHunk": "@@ -0,0 +1,544 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.replication;\n+\n+import java.io.IOException;\n+import java.lang.reflect.InvocationTargetException;\n+import java.net.BindException;\n+import java.net.InetSocketAddress;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.atomic.LongAdder;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.CellScanner;\n+import org.apache.hadoop.hbase.DoNotRetryIOException;\n+import org.apache.hadoop.hbase.HConstants;\n+import org.apache.hadoop.hbase.Server;\n+import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.ConnectionUtils;\n+import org.apache.hadoop.hbase.io.ByteBuffAllocator;\n+import org.apache.hadoop.hbase.ipc.HBaseRPCErrorHandler;\n+import org.apache.hadoop.hbase.ipc.HBaseRpcController;\n+import org.apache.hadoop.hbase.ipc.PriorityFunction;\n+import org.apache.hadoop.hbase.ipc.QosPriority;\n+import org.apache.hadoop.hbase.ipc.RpcServer.BlockingServiceAndInterface;\n+import org.apache.hadoop.hbase.ipc.RpcServerFactory;\n+import org.apache.hadoop.hbase.ipc.RpcServerInterface;\n+import org.apache.hadoop.hbase.ipc.ServerNotRunningYetException;\n+import org.apache.hadoop.hbase.log.HBaseMarkers;\n+import org.apache.hadoop.hbase.net.Address;\n+import org.apache.hadoop.hbase.regionserver.RSRpcServices;\n+import org.apache.hadoop.hbase.regionserver.RegionServerAbortedException;\n+import org.apache.hadoop.hbase.regionserver.RegionServerStoppedException;\n+import org.apache.hadoop.hbase.regionserver.ReplicationSourceService;\n+import org.apache.hadoop.hbase.regionserver.RpcSchedulerFactory;\n+import org.apache.hadoop.hbase.regionserver.SimpleRpcSchedulerFactory;\n+import org.apache.hadoop.hbase.replication.regionserver.RejectReplicationRequestStateChecker;\n+import org.apache.hadoop.hbase.security.User;\n+import org.apache.hadoop.hbase.security.access.AccessChecker;\n+import org.apache.hadoop.hbase.security.access.NoopAccessChecker;\n+import org.apache.hadoop.hbase.security.access.ZKPermissionWatcher;\n+import org.apache.hadoop.hbase.util.DNS;\n+import org.apache.hadoop.hbase.util.DNS.ServerType;\n+import org.apache.hadoop.hbase.zookeeper.ZKWatcher;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.apache.zookeeper.KeeperException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.AdminService;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.QuotaProtos.GetSpaceQuotaSnapshotsRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.QuotaProtos.GetSpaceQuotaSnapshotsResponse;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.RequestHeader;\n+\n+import org.apache.hbase.thirdparty.com.google.common.annotations.VisibleForTesting;\n+import org.apache.hbase.thirdparty.com.google.protobuf.Message;\n+import org.apache.hbase.thirdparty.com.google.protobuf.RpcController;\n+import org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;\n+\n+/**\n+ * Implements the regionserver RPC services for {@link HReplicationServer}.\n+ */\n+@InterfaceAudience.Private\n+@SuppressWarnings(\"deprecation\")\n+public class ReplicationServerRpcServices implements HBaseRPCErrorHandler,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a93bac612767dc715cebcad214f0efc01a2c4724"}, "originalPosition": 123}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY0MzMwMDQ4", "url": "https://github.com/apache/hbase/pull/2111#pullrequestreview-464330048", "createdAt": "2020-08-10T15:23:19Z", "commit": {"oid": "a93bac612767dc715cebcad214f0efc01a2c4724"}, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQxNToyMzoxOVrOG-TU8Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQxNTo1OTo1MVrOG-VMMg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Nzk4MTU1Mw==", "bodyText": "At the level of HReplicationServer, we only need to call methods from ReplicationService. I found a bit confusing that we were referring directly a sink only here, until I realised replicationSinkHandler is an instance of Replication. Can we just refer to ReplicationService interface here?", "url": "https://github.com/apache/hbase/pull/2111#discussion_r467981553", "createdAt": "2020-08-10T15:23:19Z", "author": {"login": "wchevreuil"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/HReplicationServer.java", "diffHunk": "@@ -0,0 +1,683 @@\n+/**\n+ *\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.replication;\n+\n+import java.io.IOException;\n+import java.lang.reflect.Constructor;\n+import java.net.InetSocketAddress;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map.Entry;\n+import java.util.Optional;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.Abortable;\n+import org.apache.hadoop.hbase.ChoreService;\n+import org.apache.hadoop.hbase.CoordinatedStateManager;\n+import org.apache.hadoop.hbase.DoNotRetryIOException;\n+import org.apache.hadoop.hbase.HBaseConfiguration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.HConstants;\n+import org.apache.hadoop.hbase.Server;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.TableDescriptors;\n+import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.AsyncClusterConnection;\n+import org.apache.hadoop.hbase.client.ClusterConnectionFactory;\n+import org.apache.hadoop.hbase.client.Connection;\n+import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.locking.EntityLock;\n+import org.apache.hadoop.hbase.executor.ExecutorService;\n+import org.apache.hadoop.hbase.io.hfile.BlockCache;\n+import org.apache.hadoop.hbase.ipc.RpcServerInterface;\n+import org.apache.hadoop.hbase.log.HBaseMarkers;\n+import org.apache.hadoop.hbase.mob.MobFileCache;\n+import org.apache.hadoop.hbase.quotas.RegionServerRpcQuotaManager;\n+import org.apache.hadoop.hbase.quotas.RegionServerSpaceQuotaManager;\n+import org.apache.hadoop.hbase.quotas.RegionSizeStore;\n+import org.apache.hadoop.hbase.regionserver.FlushRequester;\n+import org.apache.hadoop.hbase.regionserver.HRegion;\n+import org.apache.hadoop.hbase.regionserver.HeapMemoryManager;\n+import org.apache.hadoop.hbase.regionserver.LeaseManager;\n+import org.apache.hadoop.hbase.regionserver.MetricsRegionServer;\n+import org.apache.hadoop.hbase.regionserver.Region;\n+import org.apache.hadoop.hbase.regionserver.RegionServerAccounting;\n+import org.apache.hadoop.hbase.regionserver.RegionServerServices;\n+import org.apache.hadoop.hbase.regionserver.ReplicationService;\n+import org.apache.hadoop.hbase.regionserver.ReplicationSinkService;\n+import org.apache.hadoop.hbase.regionserver.ReplicationSourceService;\n+import org.apache.hadoop.hbase.regionserver.SecureBulkLoadManager;\n+import org.apache.hadoop.hbase.regionserver.ServerNonceManager;\n+import org.apache.hadoop.hbase.regionserver.compactions.CompactionRequester;\n+import org.apache.hadoop.hbase.regionserver.throttle.ThroughputController;\n+import org.apache.hadoop.hbase.security.User;\n+import org.apache.hadoop.hbase.security.UserProvider;\n+import org.apache.hadoop.hbase.security.access.AccessChecker;\n+import org.apache.hadoop.hbase.security.access.ZKPermissionWatcher;\n+import org.apache.hadoop.hbase.trace.TraceUtil;\n+import org.apache.hadoop.hbase.util.Sleeper;\n+import org.apache.hadoop.hbase.util.VersionInfo;\n+import org.apache.hadoop.hbase.wal.WAL;\n+import org.apache.hadoop.hbase.zookeeper.ZKWatcher;\n+import org.apache.hadoop.util.ReflectionUtils;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos;\n+\n+import org.apache.hbase.thirdparty.com.google.protobuf.Service;\n+\n+/**\n+ * HReplicationServer which is responsible to all replication stuff. It checks in with\n+ * the HMaster. There are many HReplicationServers in a single HBase deployment.\n+ */\n+@InterfaceAudience.LimitedPrivate(HBaseInterfaceAudience.TOOLS)\n+@SuppressWarnings({ \"deprecation\"})\n+public class HReplicationServer extends Thread implements Server, RegionServerServices {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(HReplicationServer.class);\n+\n+  /** Parameter name for what region server implementation to use. */\n+  public static final String REPLICATION_SERVER_IMPL = \"hbase.replicationserver.impl\";\n+\n+  /** replication server process name */\n+  public static final String REPLICATIONSERVER = \"replicationserver\";\n+\n+  /**\n+   * This servers startcode.\n+   */\n+  protected final long startcode;\n+\n+  private volatile boolean stopped = false;\n+\n+  // A state before we go into stopped state.  At this stage we're closing user\n+  // space regions.\n+  private boolean stopping = false;\n+  private volatile boolean killed = false;\n+  private volatile boolean shutDown = false;\n+\n+  // Go down hard. Used if file system becomes unavailable and also in\n+  // debugging and unit tests.\n+  private AtomicBoolean abortRequested;\n+\n+  // flag set after we're done setting up server threads\n+  final AtomicBoolean online = new AtomicBoolean(false);\n+\n+  /**\n+   * The server name the Master sees us as.  Its made from the hostname the\n+   * master passes us, port, and server startcode. Gets set after registration\n+   * against Master.\n+   */\n+  private ServerName serverName;\n+\n+  protected final Configuration conf;\n+\n+  private ReplicationSinkService replicationSinkHandler;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a93bac612767dc715cebcad214f0efc01a2c4724"}, "originalPosition": 134}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Nzk4MjMyNg==", "bodyText": "Nit: camel case?", "url": "https://github.com/apache/hbase/pull/2111#discussion_r467982326", "createdAt": "2020-08-10T15:24:32Z", "author": {"login": "wchevreuil"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/HReplicationServer.java", "diffHunk": "@@ -0,0 +1,683 @@\n+/**\n+ *\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.replication;\n+\n+import java.io.IOException;\n+import java.lang.reflect.Constructor;\n+import java.net.InetSocketAddress;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map.Entry;\n+import java.util.Optional;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.Abortable;\n+import org.apache.hadoop.hbase.ChoreService;\n+import org.apache.hadoop.hbase.CoordinatedStateManager;\n+import org.apache.hadoop.hbase.DoNotRetryIOException;\n+import org.apache.hadoop.hbase.HBaseConfiguration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.HConstants;\n+import org.apache.hadoop.hbase.Server;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.TableDescriptors;\n+import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.AsyncClusterConnection;\n+import org.apache.hadoop.hbase.client.ClusterConnectionFactory;\n+import org.apache.hadoop.hbase.client.Connection;\n+import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.locking.EntityLock;\n+import org.apache.hadoop.hbase.executor.ExecutorService;\n+import org.apache.hadoop.hbase.io.hfile.BlockCache;\n+import org.apache.hadoop.hbase.ipc.RpcServerInterface;\n+import org.apache.hadoop.hbase.log.HBaseMarkers;\n+import org.apache.hadoop.hbase.mob.MobFileCache;\n+import org.apache.hadoop.hbase.quotas.RegionServerRpcQuotaManager;\n+import org.apache.hadoop.hbase.quotas.RegionServerSpaceQuotaManager;\n+import org.apache.hadoop.hbase.quotas.RegionSizeStore;\n+import org.apache.hadoop.hbase.regionserver.FlushRequester;\n+import org.apache.hadoop.hbase.regionserver.HRegion;\n+import org.apache.hadoop.hbase.regionserver.HeapMemoryManager;\n+import org.apache.hadoop.hbase.regionserver.LeaseManager;\n+import org.apache.hadoop.hbase.regionserver.MetricsRegionServer;\n+import org.apache.hadoop.hbase.regionserver.Region;\n+import org.apache.hadoop.hbase.regionserver.RegionServerAccounting;\n+import org.apache.hadoop.hbase.regionserver.RegionServerServices;\n+import org.apache.hadoop.hbase.regionserver.ReplicationService;\n+import org.apache.hadoop.hbase.regionserver.ReplicationSinkService;\n+import org.apache.hadoop.hbase.regionserver.ReplicationSourceService;\n+import org.apache.hadoop.hbase.regionserver.SecureBulkLoadManager;\n+import org.apache.hadoop.hbase.regionserver.ServerNonceManager;\n+import org.apache.hadoop.hbase.regionserver.compactions.CompactionRequester;\n+import org.apache.hadoop.hbase.regionserver.throttle.ThroughputController;\n+import org.apache.hadoop.hbase.security.User;\n+import org.apache.hadoop.hbase.security.UserProvider;\n+import org.apache.hadoop.hbase.security.access.AccessChecker;\n+import org.apache.hadoop.hbase.security.access.ZKPermissionWatcher;\n+import org.apache.hadoop.hbase.trace.TraceUtil;\n+import org.apache.hadoop.hbase.util.Sleeper;\n+import org.apache.hadoop.hbase.util.VersionInfo;\n+import org.apache.hadoop.hbase.wal.WAL;\n+import org.apache.hadoop.hbase.zookeeper.ZKWatcher;\n+import org.apache.hadoop.util.ReflectionUtils;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos;\n+\n+import org.apache.hbase.thirdparty.com.google.protobuf.Service;\n+\n+/**\n+ * HReplicationServer which is responsible to all replication stuff. It checks in with\n+ * the HMaster. There are many HReplicationServers in a single HBase deployment.\n+ */\n+@InterfaceAudience.LimitedPrivate(HBaseInterfaceAudience.TOOLS)\n+@SuppressWarnings({ \"deprecation\"})\n+public class HReplicationServer extends Thread implements Server, RegionServerServices {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(HReplicationServer.class);\n+\n+  /** Parameter name for what region server implementation to use. */\n+  public static final String REPLICATION_SERVER_IMPL = \"hbase.replicationserver.impl\";\n+\n+  /** replication server process name */\n+  public static final String REPLICATIONSERVER = \"replicationserver\";\n+\n+  /**\n+   * This servers startcode.\n+   */\n+  protected final long startcode;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a93bac612767dc715cebcad214f0efc01a2c4724"}, "originalPosition": 108}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Nzk4NDMyMA==", "bodyText": "Why having these two methods? setupReplication apparently doing nothing extra to  _ createNewReplicationInstance_.", "url": "https://github.com/apache/hbase/pull/2111#discussion_r467984320", "createdAt": "2020-08-10T15:27:27Z", "author": {"login": "wchevreuil"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/HReplicationServer.java", "diffHunk": "@@ -0,0 +1,683 @@\n+/**\n+ *\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.replication;\n+\n+import java.io.IOException;\n+import java.lang.reflect.Constructor;\n+import java.net.InetSocketAddress;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map.Entry;\n+import java.util.Optional;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.Abortable;\n+import org.apache.hadoop.hbase.ChoreService;\n+import org.apache.hadoop.hbase.CoordinatedStateManager;\n+import org.apache.hadoop.hbase.DoNotRetryIOException;\n+import org.apache.hadoop.hbase.HBaseConfiguration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.HConstants;\n+import org.apache.hadoop.hbase.Server;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.TableDescriptors;\n+import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.AsyncClusterConnection;\n+import org.apache.hadoop.hbase.client.ClusterConnectionFactory;\n+import org.apache.hadoop.hbase.client.Connection;\n+import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.locking.EntityLock;\n+import org.apache.hadoop.hbase.executor.ExecutorService;\n+import org.apache.hadoop.hbase.io.hfile.BlockCache;\n+import org.apache.hadoop.hbase.ipc.RpcServerInterface;\n+import org.apache.hadoop.hbase.log.HBaseMarkers;\n+import org.apache.hadoop.hbase.mob.MobFileCache;\n+import org.apache.hadoop.hbase.quotas.RegionServerRpcQuotaManager;\n+import org.apache.hadoop.hbase.quotas.RegionServerSpaceQuotaManager;\n+import org.apache.hadoop.hbase.quotas.RegionSizeStore;\n+import org.apache.hadoop.hbase.regionserver.FlushRequester;\n+import org.apache.hadoop.hbase.regionserver.HRegion;\n+import org.apache.hadoop.hbase.regionserver.HeapMemoryManager;\n+import org.apache.hadoop.hbase.regionserver.LeaseManager;\n+import org.apache.hadoop.hbase.regionserver.MetricsRegionServer;\n+import org.apache.hadoop.hbase.regionserver.Region;\n+import org.apache.hadoop.hbase.regionserver.RegionServerAccounting;\n+import org.apache.hadoop.hbase.regionserver.RegionServerServices;\n+import org.apache.hadoop.hbase.regionserver.ReplicationService;\n+import org.apache.hadoop.hbase.regionserver.ReplicationSinkService;\n+import org.apache.hadoop.hbase.regionserver.ReplicationSourceService;\n+import org.apache.hadoop.hbase.regionserver.SecureBulkLoadManager;\n+import org.apache.hadoop.hbase.regionserver.ServerNonceManager;\n+import org.apache.hadoop.hbase.regionserver.compactions.CompactionRequester;\n+import org.apache.hadoop.hbase.regionserver.throttle.ThroughputController;\n+import org.apache.hadoop.hbase.security.User;\n+import org.apache.hadoop.hbase.security.UserProvider;\n+import org.apache.hadoop.hbase.security.access.AccessChecker;\n+import org.apache.hadoop.hbase.security.access.ZKPermissionWatcher;\n+import org.apache.hadoop.hbase.trace.TraceUtil;\n+import org.apache.hadoop.hbase.util.Sleeper;\n+import org.apache.hadoop.hbase.util.VersionInfo;\n+import org.apache.hadoop.hbase.wal.WAL;\n+import org.apache.hadoop.hbase.zookeeper.ZKWatcher;\n+import org.apache.hadoop.util.ReflectionUtils;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos;\n+\n+import org.apache.hbase.thirdparty.com.google.protobuf.Service;\n+\n+/**\n+ * HReplicationServer which is responsible to all replication stuff. It checks in with\n+ * the HMaster. There are many HReplicationServers in a single HBase deployment.\n+ */\n+@InterfaceAudience.LimitedPrivate(HBaseInterfaceAudience.TOOLS)\n+@SuppressWarnings({ \"deprecation\"})\n+public class HReplicationServer extends Thread implements Server, RegionServerServices {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(HReplicationServer.class);\n+\n+  /** Parameter name for what region server implementation to use. */\n+  public static final String REPLICATION_SERVER_IMPL = \"hbase.replicationserver.impl\";\n+\n+  /** replication server process name */\n+  public static final String REPLICATIONSERVER = \"replicationserver\";\n+\n+  /**\n+   * This servers startcode.\n+   */\n+  protected final long startcode;\n+\n+  private volatile boolean stopped = false;\n+\n+  // A state before we go into stopped state.  At this stage we're closing user\n+  // space regions.\n+  private boolean stopping = false;\n+  private volatile boolean killed = false;\n+  private volatile boolean shutDown = false;\n+\n+  // Go down hard. Used if file system becomes unavailable and also in\n+  // debugging and unit tests.\n+  private AtomicBoolean abortRequested;\n+\n+  // flag set after we're done setting up server threads\n+  final AtomicBoolean online = new AtomicBoolean(false);\n+\n+  /**\n+   * The server name the Master sees us as.  Its made from the hostname the\n+   * master passes us, port, and server startcode. Gets set after registration\n+   * against Master.\n+   */\n+  private ServerName serverName;\n+\n+  protected final Configuration conf;\n+\n+  private ReplicationSinkService replicationSinkHandler;\n+\n+  final int msgInterval;\n+  // A sleeper that sleeps for msgInterval.\n+  protected final Sleeper sleeper;\n+\n+  // zookeeper connection and watcher\n+  protected final ZKWatcher zooKeeper;\n+\n+  /**\n+   * The asynchronous cluster connection to be shared by services.\n+   */\n+  protected AsyncClusterConnection asyncClusterConnection;\n+\n+  private UserProvider userProvider;\n+\n+  protected final ReplicationServerRpcServices rpcServices;\n+\n+  public HReplicationServer(final Configuration conf) throws IOException {\n+    TraceUtil.initTracer(conf);\n+    try {\n+      this.startcode = System.currentTimeMillis();\n+      this.conf = conf;\n+\n+      this.abortRequested = new AtomicBoolean(false);\n+\n+      this.rpcServices = createRpcServices();\n+\n+      String hostName = this.rpcServices.isa.getHostName();\n+      serverName = ServerName.valueOf(hostName, this.rpcServices.isa.getPort(), this.startcode);\n+\n+      this.userProvider = UserProvider.instantiate(conf);\n+\n+      this.msgInterval = conf.getInt(\"hbase.replicationserver.msginterval\", 3 * 1000);\n+      this.sleeper = new Sleeper(this.msgInterval, this);\n+\n+      // Some unit tests don't need a cluster, so no zookeeper at all\n+      if (!conf.getBoolean(\"hbase.testing.nocluster\", false)) {\n+        // Open connection to zookeeper and set primary watcher\n+        zooKeeper = new ZKWatcher(conf, getProcessName() + \":\" +\n+            rpcServices.isa.getPort(), this, false);\n+      } else {\n+        zooKeeper = null;\n+      }\n+\n+      this.rpcServices.start(zooKeeper);\n+    } catch (Throwable t) {\n+      // Make sure we log the exception. HReplicationServer is often started via reflection and the\n+      // cause of failed startup is lost.\n+      LOG.error(\"Failed construction ReplicationServer\", t);\n+      throw t;\n+    }\n+  }\n+\n+  /**\n+   * Utility for constructing an instance of the passed HRegionServer class.\n+   */\n+  static HReplicationServer constructReplicationServer(\n+      final Class<? extends HReplicationServer> replicationServerClass,\n+      final Configuration conf) {\n+    try {\n+      Constructor<? extends HReplicationServer> c =\n+          replicationServerClass.getConstructor(Configuration.class);\n+      return c.newInstance(conf);\n+    } catch (Exception e) {\n+      throw new RuntimeException(\"Failed construction of \" + \"ReplicationServer: \"\n+          + replicationServerClass.toString(), e);\n+    }\n+  }\n+\n+  public String getProcessName() {\n+    return REPLICATIONSERVER;\n+  }\n+\n+  @Override\n+  public void run() {\n+    if (isStopped()) {\n+      LOG.info(\"Skipping run; stopped\");\n+      return;\n+    }\n+    try {\n+      // Do pre-registration initializations; zookeeper, lease threads, etc.\n+      preRegistrationInitialization();\n+    } catch (Throwable e) {\n+      abort(\"Fatal exception during initialization\", e);\n+    }\n+    try {\n+      setupReplication();\n+      startReplicationService();\n+\n+      // Wake up anyone waiting for this server to online\n+      synchronized (online) {\n+        online.set(true);\n+        online.notifyAll();\n+      }\n+\n+      long lastMsg = System.currentTimeMillis();\n+      // The main run loop.\n+      while (!isStopped()) {\n+        if (!isClusterUp()) {\n+          if (!this.stopping) {\n+            this.stopping = true;\n+          }\n+        }\n+        long now = System.currentTimeMillis();\n+        if ((now - lastMsg) >= msgInterval) {\n+          lastMsg = System.currentTimeMillis();\n+        }\n+        if (!isStopped() && !isAborted()) {\n+          this.sleeper.sleep();\n+        }\n+      }\n+\n+      if (!killed) {\n+        stopServiceThreads();\n+      }\n+      if (this.rpcServices != null) {\n+        this.rpcServices.stop();\n+      }\n+    } catch (Throwable t) {\n+      abort(t.getMessage(), t);\n+    }\n+\n+    if (this.zooKeeper != null) {\n+      this.zooKeeper.close();\n+    }\n+    this.shutDown = true;\n+    LOG.info(\"Exiting; stopping=\" + this.serverName + \"; zookeeper connection closed.\");\n+  }\n+\n+  private Configuration cleanupConfiguration() {\n+    Configuration conf = this.conf;\n+    // We use ZKConnectionRegistry for all the internal communication, primarily for these reasons:\n+    // - Decouples RS and master life cycles. RegionServers can continue be up independent of\n+    //   masters' availability.\n+    // - Configuration management for region servers (cluster internal) is much simpler when adding\n+    //   new masters or removing existing masters, since only clients' config needs to be updated.\n+    // - We need to retain ZKConnectionRegistry for replication use anyway, so we just extend it for\n+    //   other internal connections too.\n+    conf.set(HConstants.CLIENT_CONNECTION_REGISTRY_IMPL_CONF_KEY,\n+        HConstants.ZK_CONNECTION_REGISTRY_CLASS);\n+    if (conf.get(HConstants.CLIENT_ZOOKEEPER_QUORUM) != null) {\n+      // Use server ZK cluster for server-issued connections, so we clone\n+      // the conf and unset the client ZK related properties\n+      conf = new Configuration(this.conf);\n+      conf.unset(HConstants.CLIENT_ZOOKEEPER_QUORUM);\n+    }\n+    return conf;\n+  }\n+\n+  /**\n+   * All initialization needed before we go register with Master.<br>\n+   * Do bare minimum. Do bulk of initializations AFTER we've connected to the Master.<br>\n+   * In here we just put up the RpcServer, setup Connection, and ZooKeeper.\n+   */\n+  private void preRegistrationInitialization() {\n+    try {\n+      setupClusterConnection();\n+    } catch (Throwable t) {\n+      // Call stop if error or process will stick around for ever since server\n+      // puts up non-daemon threads.\n+      this.rpcServices.stop();\n+      abort(\"Initialization of RS failed.  Hence aborting RS.\", t);\n+    }\n+  }\n+\n+  /**\n+   * Setup our cluster connection if not already initialized.\n+   */\n+  protected final synchronized void setupClusterConnection() throws IOException {\n+    if (asyncClusterConnection == null) {\n+      Configuration conf = cleanupConfiguration();\n+      InetSocketAddress localAddress = new InetSocketAddress(this.rpcServices.isa.getAddress(), 0);\n+      User user = userProvider.getCurrent();\n+      asyncClusterConnection =\n+          ClusterConnectionFactory.createAsyncClusterConnection(conf, localAddress, user);\n+    }\n+  }\n+\n+  /**\n+   * Wait on all threads to finish. Presumption is that all closes and stops\n+   * have already been called.\n+   */\n+  protected void stopServiceThreads() {\n+    if (this.replicationSinkHandler != null) {\n+      this.replicationSinkHandler.stopReplicationService();\n+    }\n+  }\n+\n+  public static void main(String[] args) {\n+    LOG.info(\"STARTING executorService \" + HReplicationServer.class.getSimpleName());\n+    VersionInfo.logVersion();\n+    Configuration conf = HBaseConfiguration.create();\n+    @SuppressWarnings(\"unchecked\")\n+    Class<? extends HReplicationServer> replicationServerClass =\n+        (Class<? extends HReplicationServer>)\n+            conf.getClass(REPLICATION_SERVER_IMPL, HReplicationServer.class);\n+\n+    new HReplicationServerCommandLine(replicationServerClass).doMain(args);\n+  }\n+\n+  @Override\n+  public WAL getWAL(RegionInfo regionInfo) throws IOException {\n+    throw new DoNotRetryIOException(new UnsupportedOperationException(\"This's ReplicationServer.\"));\n+  }\n+\n+  @Override\n+  public List<WAL> getWALs() throws IOException {\n+    throw new DoNotRetryIOException(new UnsupportedOperationException(\"This's ReplicationServer.\"));\n+  }\n+\n+  @Override\n+  public FlushRequester getFlushRequester() {\n+    return null;\n+  }\n+\n+  @Override\n+  public CompactionRequester getCompactionRequestor() {\n+    return null;\n+  }\n+\n+  @Override\n+  public RegionServerAccounting getRegionServerAccounting() {\n+    return null;\n+  }\n+\n+  @Override\n+  public RegionServerRpcQuotaManager getRegionServerRpcQuotaManager() {\n+    return null;\n+  }\n+\n+  @Override\n+  public SecureBulkLoadManager getSecureBulkLoadManager() {\n+    return null;\n+  }\n+\n+  @Override\n+  public RegionServerSpaceQuotaManager getRegionServerSpaceQuotaManager() {\n+    return null;\n+  }\n+\n+  @Override\n+  public void postOpenDeployTasks(PostOpenDeployContext context) throws IOException {\n+    throw new DoNotRetryIOException(new UnsupportedOperationException(\"This's ReplicationServer.\"));\n+  }\n+\n+  @Override\n+  public boolean reportRegionStateTransition(RegionStateTransitionContext context) {\n+    return false;\n+  }\n+\n+  @Override\n+  public RpcServerInterface getRpcServer() {\n+    return null;\n+  }\n+\n+  @Override\n+  public ConcurrentMap<byte[], Boolean> getRegionsInTransitionInRS() {\n+    return null;\n+  }\n+\n+  @Override\n+  public LeaseManager getLeaseManager() {\n+    return null;\n+  }\n+\n+  @Override\n+  public ExecutorService getExecutorService() {\n+    return null;\n+  }\n+\n+  @Override\n+  public ServerNonceManager getNonceManager() {\n+    return null;\n+  }\n+\n+  @Override\n+  public boolean registerService(Service service) {\n+    return false;\n+  }\n+\n+  @Override\n+  public HeapMemoryManager getHeapMemoryManager() {\n+    return null;\n+  }\n+\n+  @Override\n+  public double getCompactionPressure() {\n+    return 0;\n+  }\n+\n+  @Override\n+  public ThroughputController getFlushThroughputController() {\n+    return null;\n+  }\n+\n+  @Override\n+  public double getFlushPressure() {\n+    return 0;\n+  }\n+\n+  @Override\n+  public MetricsRegionServer getMetrics() {\n+    return null;\n+  }\n+\n+  @Override\n+  public EntityLock regionLock(List<RegionInfo> regionInfos, String description, Abortable abort)\n+      throws IOException {\n+    throw new DoNotRetryIOException(new UnsupportedOperationException(\"This's ReplicationServer.\"));\n+  }\n+\n+  @Override\n+  public void unassign(byte[] regionName) throws IOException {\n+    throw new DoNotRetryIOException(new UnsupportedOperationException(\"This's ReplicationServer.\"));\n+  }\n+\n+  @Override\n+  public boolean reportRegionSizesForQuotas(RegionSizeStore sizeStore) {\n+    return false;\n+  }\n+\n+  @Override\n+  public boolean reportFileArchivalForQuotas(TableName tableName,\n+      Collection<Entry<String, Long>> archivedFiles) {\n+    return false;\n+  }\n+\n+  @Override\n+  public boolean isClusterUp() {\n+    return false;\n+  }\n+\n+  @Override\n+  public ReplicationSourceService getReplicationSourceService() {\n+    return null;\n+  }\n+\n+  @Override\n+  public TableDescriptors getTableDescriptors() {\n+    return null;\n+  }\n+\n+  @Override\n+  public Optional<BlockCache> getBlockCache() {\n+    return Optional.empty();\n+  }\n+\n+  @Override\n+  public Optional<MobFileCache> getMobFileCache() {\n+    return Optional.empty();\n+  }\n+\n+  @Override\n+  public AccessChecker getAccessChecker() {\n+    return null;\n+  }\n+\n+  @Override\n+  public ZKPermissionWatcher getZKPermissionWatcher() {\n+    return null;\n+  }\n+\n+  @Override\n+  public Configuration getConfiguration() {\n+    return conf;\n+  }\n+\n+  @Override\n+  public ZKWatcher getZooKeeper() {\n+    return zooKeeper;\n+  }\n+\n+  @Override\n+  public Connection getConnection() {\n+    return getAsyncConnection().toConnection();\n+  }\n+\n+  @Override\n+  public Connection createConnection(Configuration conf) throws IOException {\n+    throw new DoNotRetryIOException(new UnsupportedOperationException(\"This's ReplicationServer.\"));\n+  }\n+\n+  @Override\n+  public AsyncClusterConnection getAsyncClusterConnection() {\n+    return null;\n+  }\n+\n+  @Override\n+  public ServerName getServerName() {\n+    return serverName;\n+  }\n+\n+  @Override\n+  public CoordinatedStateManager getCoordinatedStateManager() {\n+    return null;\n+  }\n+\n+  @Override\n+  public ChoreService getChoreService() {\n+    return null;\n+  }\n+\n+  @Override\n+  public void abort(String why, Throwable cause) {\n+    if (!setAbortRequested()) {\n+      // Abort already in progress, ignore the new request.\n+      LOG.debug(\n+          \"Abort already in progress. Ignoring the current request with reason: {}\", why);\n+      return;\n+    }\n+    String msg = \"***** ABORTING replication server \" + this + \": \" + why + \" *****\";\n+    if (cause != null) {\n+      LOG.error(HBaseMarkers.FATAL, msg, cause);\n+    } else {\n+      LOG.error(HBaseMarkers.FATAL, msg);\n+    }\n+    stop(why);\n+  }\n+\n+  @Override\n+  public boolean isAborted() {\n+    return abortRequested.get();\n+  }\n+\n+  @Override\n+  public void stop(String why) {\n+    stopped = true;\n+  }\n+\n+  @Override\n+  public boolean isStopped() {\n+    return this.stopped;\n+  }\n+\n+  @Override\n+  public void updateRegionFavoredNodesMapping(String encodedRegionName,\n+      List<HBaseProtos.ServerName> favoredNodes) {\n+  }\n+\n+  @Override\n+  public InetSocketAddress[] getFavoredNodesForRegion(String encodedRegionName) {\n+    return new InetSocketAddress[0];\n+  }\n+\n+  @Override\n+  public void addRegion(HRegion r) {\n+\n+  }\n+\n+  @Override\n+  public boolean removeRegion(HRegion r, ServerName destination) {\n+    return false;\n+  }\n+\n+  @Override\n+  public Region getRegion(String encodedRegionName) {\n+    return null;\n+  }\n+\n+  @Override\n+  public List<? extends Region> getRegions(TableName tableName) throws IOException {\n+    throw new DoNotRetryIOException(new UnsupportedOperationException(\"This's ReplicationServer.\"));\n+  }\n+\n+  @Override\n+  public List<? extends Region> getRegions() {\n+    return null;\n+  }\n+\n+  /**\n+   * Setup WAL log and replication if enabled. Replication setup is done in here because it wants to\n+   * be hooked up to WAL.\n+   */\n+  private void setupReplication() throws IOException {\n+    // Instantiate replication if replication enabled. Pass it the log directories.\n+    createNewReplicationInstance(conf, this);\n+  }\n+\n+  /**\n+   * Load the replication executorService objects, if any\n+   */\n+  private static void createNewReplicationInstance(Configuration conf, HReplicationServer server)\n+      throws IOException {\n+    // read in the name of the sink replication class from the config file.\n+    String sinkClassname = conf.get(HConstants.REPLICATION_SINK_SERVICE_CLASSNAME,\n+        HConstants.REPLICATION_SERVICE_CLASSNAME_DEFAULT);\n+\n+    server.replicationSinkHandler = newReplicationInstance(sinkClassname,\n+        ReplicationSinkService.class, conf, server);\n+  }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a93bac612767dc715cebcad214f0efc01a2c4724"}, "originalPosition": 624}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Nzk5NjQ1OQ==", "bodyText": "Why all those null params? Can we remove those from the interface?", "url": "https://github.com/apache/hbase/pull/2111#discussion_r467996459", "createdAt": "2020-08-10T15:38:48Z", "author": {"login": "wchevreuil"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/HReplicationServer.java", "diffHunk": "@@ -0,0 +1,683 @@\n+/**\n+ *\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.replication;\n+\n+import java.io.IOException;\n+import java.lang.reflect.Constructor;\n+import java.net.InetSocketAddress;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map.Entry;\n+import java.util.Optional;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.Abortable;\n+import org.apache.hadoop.hbase.ChoreService;\n+import org.apache.hadoop.hbase.CoordinatedStateManager;\n+import org.apache.hadoop.hbase.DoNotRetryIOException;\n+import org.apache.hadoop.hbase.HBaseConfiguration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.HConstants;\n+import org.apache.hadoop.hbase.Server;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.TableDescriptors;\n+import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.AsyncClusterConnection;\n+import org.apache.hadoop.hbase.client.ClusterConnectionFactory;\n+import org.apache.hadoop.hbase.client.Connection;\n+import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.locking.EntityLock;\n+import org.apache.hadoop.hbase.executor.ExecutorService;\n+import org.apache.hadoop.hbase.io.hfile.BlockCache;\n+import org.apache.hadoop.hbase.ipc.RpcServerInterface;\n+import org.apache.hadoop.hbase.log.HBaseMarkers;\n+import org.apache.hadoop.hbase.mob.MobFileCache;\n+import org.apache.hadoop.hbase.quotas.RegionServerRpcQuotaManager;\n+import org.apache.hadoop.hbase.quotas.RegionServerSpaceQuotaManager;\n+import org.apache.hadoop.hbase.quotas.RegionSizeStore;\n+import org.apache.hadoop.hbase.regionserver.FlushRequester;\n+import org.apache.hadoop.hbase.regionserver.HRegion;\n+import org.apache.hadoop.hbase.regionserver.HeapMemoryManager;\n+import org.apache.hadoop.hbase.regionserver.LeaseManager;\n+import org.apache.hadoop.hbase.regionserver.MetricsRegionServer;\n+import org.apache.hadoop.hbase.regionserver.Region;\n+import org.apache.hadoop.hbase.regionserver.RegionServerAccounting;\n+import org.apache.hadoop.hbase.regionserver.RegionServerServices;\n+import org.apache.hadoop.hbase.regionserver.ReplicationService;\n+import org.apache.hadoop.hbase.regionserver.ReplicationSinkService;\n+import org.apache.hadoop.hbase.regionserver.ReplicationSourceService;\n+import org.apache.hadoop.hbase.regionserver.SecureBulkLoadManager;\n+import org.apache.hadoop.hbase.regionserver.ServerNonceManager;\n+import org.apache.hadoop.hbase.regionserver.compactions.CompactionRequester;\n+import org.apache.hadoop.hbase.regionserver.throttle.ThroughputController;\n+import org.apache.hadoop.hbase.security.User;\n+import org.apache.hadoop.hbase.security.UserProvider;\n+import org.apache.hadoop.hbase.security.access.AccessChecker;\n+import org.apache.hadoop.hbase.security.access.ZKPermissionWatcher;\n+import org.apache.hadoop.hbase.trace.TraceUtil;\n+import org.apache.hadoop.hbase.util.Sleeper;\n+import org.apache.hadoop.hbase.util.VersionInfo;\n+import org.apache.hadoop.hbase.wal.WAL;\n+import org.apache.hadoop.hbase.zookeeper.ZKWatcher;\n+import org.apache.hadoop.util.ReflectionUtils;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos;\n+\n+import org.apache.hbase.thirdparty.com.google.protobuf.Service;\n+\n+/**\n+ * HReplicationServer which is responsible to all replication stuff. It checks in with\n+ * the HMaster. There are many HReplicationServers in a single HBase deployment.\n+ */\n+@InterfaceAudience.LimitedPrivate(HBaseInterfaceAudience.TOOLS)\n+@SuppressWarnings({ \"deprecation\"})\n+public class HReplicationServer extends Thread implements Server, RegionServerServices {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(HReplicationServer.class);\n+\n+  /** Parameter name for what region server implementation to use. */\n+  public static final String REPLICATION_SERVER_IMPL = \"hbase.replicationserver.impl\";\n+\n+  /** replication server process name */\n+  public static final String REPLICATIONSERVER = \"replicationserver\";\n+\n+  /**\n+   * This servers startcode.\n+   */\n+  protected final long startcode;\n+\n+  private volatile boolean stopped = false;\n+\n+  // A state before we go into stopped state.  At this stage we're closing user\n+  // space regions.\n+  private boolean stopping = false;\n+  private volatile boolean killed = false;\n+  private volatile boolean shutDown = false;\n+\n+  // Go down hard. Used if file system becomes unavailable and also in\n+  // debugging and unit tests.\n+  private AtomicBoolean abortRequested;\n+\n+  // flag set after we're done setting up server threads\n+  final AtomicBoolean online = new AtomicBoolean(false);\n+\n+  /**\n+   * The server name the Master sees us as.  Its made from the hostname the\n+   * master passes us, port, and server startcode. Gets set after registration\n+   * against Master.\n+   */\n+  private ServerName serverName;\n+\n+  protected final Configuration conf;\n+\n+  private ReplicationSinkService replicationSinkHandler;\n+\n+  final int msgInterval;\n+  // A sleeper that sleeps for msgInterval.\n+  protected final Sleeper sleeper;\n+\n+  // zookeeper connection and watcher\n+  protected final ZKWatcher zooKeeper;\n+\n+  /**\n+   * The asynchronous cluster connection to be shared by services.\n+   */\n+  protected AsyncClusterConnection asyncClusterConnection;\n+\n+  private UserProvider userProvider;\n+\n+  protected final ReplicationServerRpcServices rpcServices;\n+\n+  public HReplicationServer(final Configuration conf) throws IOException {\n+    TraceUtil.initTracer(conf);\n+    try {\n+      this.startcode = System.currentTimeMillis();\n+      this.conf = conf;\n+\n+      this.abortRequested = new AtomicBoolean(false);\n+\n+      this.rpcServices = createRpcServices();\n+\n+      String hostName = this.rpcServices.isa.getHostName();\n+      serverName = ServerName.valueOf(hostName, this.rpcServices.isa.getPort(), this.startcode);\n+\n+      this.userProvider = UserProvider.instantiate(conf);\n+\n+      this.msgInterval = conf.getInt(\"hbase.replicationserver.msginterval\", 3 * 1000);\n+      this.sleeper = new Sleeper(this.msgInterval, this);\n+\n+      // Some unit tests don't need a cluster, so no zookeeper at all\n+      if (!conf.getBoolean(\"hbase.testing.nocluster\", false)) {\n+        // Open connection to zookeeper and set primary watcher\n+        zooKeeper = new ZKWatcher(conf, getProcessName() + \":\" +\n+            rpcServices.isa.getPort(), this, false);\n+      } else {\n+        zooKeeper = null;\n+      }\n+\n+      this.rpcServices.start(zooKeeper);\n+    } catch (Throwable t) {\n+      // Make sure we log the exception. HReplicationServer is often started via reflection and the\n+      // cause of failed startup is lost.\n+      LOG.error(\"Failed construction ReplicationServer\", t);\n+      throw t;\n+    }\n+  }\n+\n+  /**\n+   * Utility for constructing an instance of the passed HRegionServer class.\n+   */\n+  static HReplicationServer constructReplicationServer(\n+      final Class<? extends HReplicationServer> replicationServerClass,\n+      final Configuration conf) {\n+    try {\n+      Constructor<? extends HReplicationServer> c =\n+          replicationServerClass.getConstructor(Configuration.class);\n+      return c.newInstance(conf);\n+    } catch (Exception e) {\n+      throw new RuntimeException(\"Failed construction of \" + \"ReplicationServer: \"\n+          + replicationServerClass.toString(), e);\n+    }\n+  }\n+\n+  public String getProcessName() {\n+    return REPLICATIONSERVER;\n+  }\n+\n+  @Override\n+  public void run() {\n+    if (isStopped()) {\n+      LOG.info(\"Skipping run; stopped\");\n+      return;\n+    }\n+    try {\n+      // Do pre-registration initializations; zookeeper, lease threads, etc.\n+      preRegistrationInitialization();\n+    } catch (Throwable e) {\n+      abort(\"Fatal exception during initialization\", e);\n+    }\n+    try {\n+      setupReplication();\n+      startReplicationService();\n+\n+      // Wake up anyone waiting for this server to online\n+      synchronized (online) {\n+        online.set(true);\n+        online.notifyAll();\n+      }\n+\n+      long lastMsg = System.currentTimeMillis();\n+      // The main run loop.\n+      while (!isStopped()) {\n+        if (!isClusterUp()) {\n+          if (!this.stopping) {\n+            this.stopping = true;\n+          }\n+        }\n+        long now = System.currentTimeMillis();\n+        if ((now - lastMsg) >= msgInterval) {\n+          lastMsg = System.currentTimeMillis();\n+        }\n+        if (!isStopped() && !isAborted()) {\n+          this.sleeper.sleep();\n+        }\n+      }\n+\n+      if (!killed) {\n+        stopServiceThreads();\n+      }\n+      if (this.rpcServices != null) {\n+        this.rpcServices.stop();\n+      }\n+    } catch (Throwable t) {\n+      abort(t.getMessage(), t);\n+    }\n+\n+    if (this.zooKeeper != null) {\n+      this.zooKeeper.close();\n+    }\n+    this.shutDown = true;\n+    LOG.info(\"Exiting; stopping=\" + this.serverName + \"; zookeeper connection closed.\");\n+  }\n+\n+  private Configuration cleanupConfiguration() {\n+    Configuration conf = this.conf;\n+    // We use ZKConnectionRegistry for all the internal communication, primarily for these reasons:\n+    // - Decouples RS and master life cycles. RegionServers can continue be up independent of\n+    //   masters' availability.\n+    // - Configuration management for region servers (cluster internal) is much simpler when adding\n+    //   new masters or removing existing masters, since only clients' config needs to be updated.\n+    // - We need to retain ZKConnectionRegistry for replication use anyway, so we just extend it for\n+    //   other internal connections too.\n+    conf.set(HConstants.CLIENT_CONNECTION_REGISTRY_IMPL_CONF_KEY,\n+        HConstants.ZK_CONNECTION_REGISTRY_CLASS);\n+    if (conf.get(HConstants.CLIENT_ZOOKEEPER_QUORUM) != null) {\n+      // Use server ZK cluster for server-issued connections, so we clone\n+      // the conf and unset the client ZK related properties\n+      conf = new Configuration(this.conf);\n+      conf.unset(HConstants.CLIENT_ZOOKEEPER_QUORUM);\n+    }\n+    return conf;\n+  }\n+\n+  /**\n+   * All initialization needed before we go register with Master.<br>\n+   * Do bare minimum. Do bulk of initializations AFTER we've connected to the Master.<br>\n+   * In here we just put up the RpcServer, setup Connection, and ZooKeeper.\n+   */\n+  private void preRegistrationInitialization() {\n+    try {\n+      setupClusterConnection();\n+    } catch (Throwable t) {\n+      // Call stop if error or process will stick around for ever since server\n+      // puts up non-daemon threads.\n+      this.rpcServices.stop();\n+      abort(\"Initialization of RS failed.  Hence aborting RS.\", t);\n+    }\n+  }\n+\n+  /**\n+   * Setup our cluster connection if not already initialized.\n+   */\n+  protected final synchronized void setupClusterConnection() throws IOException {\n+    if (asyncClusterConnection == null) {\n+      Configuration conf = cleanupConfiguration();\n+      InetSocketAddress localAddress = new InetSocketAddress(this.rpcServices.isa.getAddress(), 0);\n+      User user = userProvider.getCurrent();\n+      asyncClusterConnection =\n+          ClusterConnectionFactory.createAsyncClusterConnection(conf, localAddress, user);\n+    }\n+  }\n+\n+  /**\n+   * Wait on all threads to finish. Presumption is that all closes and stops\n+   * have already been called.\n+   */\n+  protected void stopServiceThreads() {\n+    if (this.replicationSinkHandler != null) {\n+      this.replicationSinkHandler.stopReplicationService();\n+    }\n+  }\n+\n+  public static void main(String[] args) {\n+    LOG.info(\"STARTING executorService \" + HReplicationServer.class.getSimpleName());\n+    VersionInfo.logVersion();\n+    Configuration conf = HBaseConfiguration.create();\n+    @SuppressWarnings(\"unchecked\")\n+    Class<? extends HReplicationServer> replicationServerClass =\n+        (Class<? extends HReplicationServer>)\n+            conf.getClass(REPLICATION_SERVER_IMPL, HReplicationServer.class);\n+\n+    new HReplicationServerCommandLine(replicationServerClass).doMain(args);\n+  }\n+\n+  @Override\n+  public WAL getWAL(RegionInfo regionInfo) throws IOException {\n+    throw new DoNotRetryIOException(new UnsupportedOperationException(\"This's ReplicationServer.\"));\n+  }\n+\n+  @Override\n+  public List<WAL> getWALs() throws IOException {\n+    throw new DoNotRetryIOException(new UnsupportedOperationException(\"This's ReplicationServer.\"));\n+  }\n+\n+  @Override\n+  public FlushRequester getFlushRequester() {\n+    return null;\n+  }\n+\n+  @Override\n+  public CompactionRequester getCompactionRequestor() {\n+    return null;\n+  }\n+\n+  @Override\n+  public RegionServerAccounting getRegionServerAccounting() {\n+    return null;\n+  }\n+\n+  @Override\n+  public RegionServerRpcQuotaManager getRegionServerRpcQuotaManager() {\n+    return null;\n+  }\n+\n+  @Override\n+  public SecureBulkLoadManager getSecureBulkLoadManager() {\n+    return null;\n+  }\n+\n+  @Override\n+  public RegionServerSpaceQuotaManager getRegionServerSpaceQuotaManager() {\n+    return null;\n+  }\n+\n+  @Override\n+  public void postOpenDeployTasks(PostOpenDeployContext context) throws IOException {\n+    throw new DoNotRetryIOException(new UnsupportedOperationException(\"This's ReplicationServer.\"));\n+  }\n+\n+  @Override\n+  public boolean reportRegionStateTransition(RegionStateTransitionContext context) {\n+    return false;\n+  }\n+\n+  @Override\n+  public RpcServerInterface getRpcServer() {\n+    return null;\n+  }\n+\n+  @Override\n+  public ConcurrentMap<byte[], Boolean> getRegionsInTransitionInRS() {\n+    return null;\n+  }\n+\n+  @Override\n+  public LeaseManager getLeaseManager() {\n+    return null;\n+  }\n+\n+  @Override\n+  public ExecutorService getExecutorService() {\n+    return null;\n+  }\n+\n+  @Override\n+  public ServerNonceManager getNonceManager() {\n+    return null;\n+  }\n+\n+  @Override\n+  public boolean registerService(Service service) {\n+    return false;\n+  }\n+\n+  @Override\n+  public HeapMemoryManager getHeapMemoryManager() {\n+    return null;\n+  }\n+\n+  @Override\n+  public double getCompactionPressure() {\n+    return 0;\n+  }\n+\n+  @Override\n+  public ThroughputController getFlushThroughputController() {\n+    return null;\n+  }\n+\n+  @Override\n+  public double getFlushPressure() {\n+    return 0;\n+  }\n+\n+  @Override\n+  public MetricsRegionServer getMetrics() {\n+    return null;\n+  }\n+\n+  @Override\n+  public EntityLock regionLock(List<RegionInfo> regionInfos, String description, Abortable abort)\n+      throws IOException {\n+    throw new DoNotRetryIOException(new UnsupportedOperationException(\"This's ReplicationServer.\"));\n+  }\n+\n+  @Override\n+  public void unassign(byte[] regionName) throws IOException {\n+    throw new DoNotRetryIOException(new UnsupportedOperationException(\"This's ReplicationServer.\"));\n+  }\n+\n+  @Override\n+  public boolean reportRegionSizesForQuotas(RegionSizeStore sizeStore) {\n+    return false;\n+  }\n+\n+  @Override\n+  public boolean reportFileArchivalForQuotas(TableName tableName,\n+      Collection<Entry<String, Long>> archivedFiles) {\n+    return false;\n+  }\n+\n+  @Override\n+  public boolean isClusterUp() {\n+    return false;\n+  }\n+\n+  @Override\n+  public ReplicationSourceService getReplicationSourceService() {\n+    return null;\n+  }\n+\n+  @Override\n+  public TableDescriptors getTableDescriptors() {\n+    return null;\n+  }\n+\n+  @Override\n+  public Optional<BlockCache> getBlockCache() {\n+    return Optional.empty();\n+  }\n+\n+  @Override\n+  public Optional<MobFileCache> getMobFileCache() {\n+    return Optional.empty();\n+  }\n+\n+  @Override\n+  public AccessChecker getAccessChecker() {\n+    return null;\n+  }\n+\n+  @Override\n+  public ZKPermissionWatcher getZKPermissionWatcher() {\n+    return null;\n+  }\n+\n+  @Override\n+  public Configuration getConfiguration() {\n+    return conf;\n+  }\n+\n+  @Override\n+  public ZKWatcher getZooKeeper() {\n+    return zooKeeper;\n+  }\n+\n+  @Override\n+  public Connection getConnection() {\n+    return getAsyncConnection().toConnection();\n+  }\n+\n+  @Override\n+  public Connection createConnection(Configuration conf) throws IOException {\n+    throw new DoNotRetryIOException(new UnsupportedOperationException(\"This's ReplicationServer.\"));\n+  }\n+\n+  @Override\n+  public AsyncClusterConnection getAsyncClusterConnection() {\n+    return null;\n+  }\n+\n+  @Override\n+  public ServerName getServerName() {\n+    return serverName;\n+  }\n+\n+  @Override\n+  public CoordinatedStateManager getCoordinatedStateManager() {\n+    return null;\n+  }\n+\n+  @Override\n+  public ChoreService getChoreService() {\n+    return null;\n+  }\n+\n+  @Override\n+  public void abort(String why, Throwable cause) {\n+    if (!setAbortRequested()) {\n+      // Abort already in progress, ignore the new request.\n+      LOG.debug(\n+          \"Abort already in progress. Ignoring the current request with reason: {}\", why);\n+      return;\n+    }\n+    String msg = \"***** ABORTING replication server \" + this + \": \" + why + \" *****\";\n+    if (cause != null) {\n+      LOG.error(HBaseMarkers.FATAL, msg, cause);\n+    } else {\n+      LOG.error(HBaseMarkers.FATAL, msg);\n+    }\n+    stop(why);\n+  }\n+\n+  @Override\n+  public boolean isAborted() {\n+    return abortRequested.get();\n+  }\n+\n+  @Override\n+  public void stop(String why) {\n+    stopped = true;\n+  }\n+\n+  @Override\n+  public boolean isStopped() {\n+    return this.stopped;\n+  }\n+\n+  @Override\n+  public void updateRegionFavoredNodesMapping(String encodedRegionName,\n+      List<HBaseProtos.ServerName> favoredNodes) {\n+  }\n+\n+  @Override\n+  public InetSocketAddress[] getFavoredNodesForRegion(String encodedRegionName) {\n+    return new InetSocketAddress[0];\n+  }\n+\n+  @Override\n+  public void addRegion(HRegion r) {\n+\n+  }\n+\n+  @Override\n+  public boolean removeRegion(HRegion r, ServerName destination) {\n+    return false;\n+  }\n+\n+  @Override\n+  public Region getRegion(String encodedRegionName) {\n+    return null;\n+  }\n+\n+  @Override\n+  public List<? extends Region> getRegions(TableName tableName) throws IOException {\n+    throw new DoNotRetryIOException(new UnsupportedOperationException(\"This's ReplicationServer.\"));\n+  }\n+\n+  @Override\n+  public List<? extends Region> getRegions() {\n+    return null;\n+  }\n+\n+  /**\n+   * Setup WAL log and replication if enabled. Replication setup is done in here because it wants to\n+   * be hooked up to WAL.\n+   */\n+  private void setupReplication() throws IOException {\n+    // Instantiate replication if replication enabled. Pass it the log directories.\n+    createNewReplicationInstance(conf, this);\n+  }\n+\n+  /**\n+   * Load the replication executorService objects, if any\n+   */\n+  private static void createNewReplicationInstance(Configuration conf, HReplicationServer server)\n+      throws IOException {\n+    // read in the name of the sink replication class from the config file.\n+    String sinkClassname = conf.get(HConstants.REPLICATION_SINK_SERVICE_CLASSNAME,\n+        HConstants.REPLICATION_SERVICE_CLASSNAME_DEFAULT);\n+\n+    server.replicationSinkHandler = newReplicationInstance(sinkClassname,\n+        ReplicationSinkService.class, conf, server);\n+  }\n+\n+  private static <T extends ReplicationService> T newReplicationInstance(String classname,\n+      Class<T> xface, Configuration conf, HReplicationServer server) throws IOException {\n+    final Class<? extends T> clazz;\n+    try {\n+      ClassLoader classLoader = Thread.currentThread().getContextClassLoader();\n+      clazz = Class.forName(classname, true, classLoader).asSubclass(xface);\n+    } catch (java.lang.ClassNotFoundException nfe) {\n+      throw new IOException(\"Could not find class for \" + classname);\n+    }\n+    T service = ReflectionUtils.newInstance(clazz, conf);\n+    service.initialize(server, null, null, null, null);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a93bac612767dc715cebcad214f0efc01a2c4724"}, "originalPosition": 636}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Nzk5OTY1Ng==", "bodyText": "Should throw UnsupportedOperationException? (And same applies to all non implemented methods currently returning null).", "url": "https://github.com/apache/hbase/pull/2111#discussion_r467999656", "createdAt": "2020-08-10T15:41:15Z", "author": {"login": "wchevreuil"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/HReplicationServer.java", "diffHunk": "@@ -0,0 +1,683 @@\n+/**\n+ *\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.replication;\n+\n+import java.io.IOException;\n+import java.lang.reflect.Constructor;\n+import java.net.InetSocketAddress;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map.Entry;\n+import java.util.Optional;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.Abortable;\n+import org.apache.hadoop.hbase.ChoreService;\n+import org.apache.hadoop.hbase.CoordinatedStateManager;\n+import org.apache.hadoop.hbase.DoNotRetryIOException;\n+import org.apache.hadoop.hbase.HBaseConfiguration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.HConstants;\n+import org.apache.hadoop.hbase.Server;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.TableDescriptors;\n+import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.AsyncClusterConnection;\n+import org.apache.hadoop.hbase.client.ClusterConnectionFactory;\n+import org.apache.hadoop.hbase.client.Connection;\n+import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.locking.EntityLock;\n+import org.apache.hadoop.hbase.executor.ExecutorService;\n+import org.apache.hadoop.hbase.io.hfile.BlockCache;\n+import org.apache.hadoop.hbase.ipc.RpcServerInterface;\n+import org.apache.hadoop.hbase.log.HBaseMarkers;\n+import org.apache.hadoop.hbase.mob.MobFileCache;\n+import org.apache.hadoop.hbase.quotas.RegionServerRpcQuotaManager;\n+import org.apache.hadoop.hbase.quotas.RegionServerSpaceQuotaManager;\n+import org.apache.hadoop.hbase.quotas.RegionSizeStore;\n+import org.apache.hadoop.hbase.regionserver.FlushRequester;\n+import org.apache.hadoop.hbase.regionserver.HRegion;\n+import org.apache.hadoop.hbase.regionserver.HeapMemoryManager;\n+import org.apache.hadoop.hbase.regionserver.LeaseManager;\n+import org.apache.hadoop.hbase.regionserver.MetricsRegionServer;\n+import org.apache.hadoop.hbase.regionserver.Region;\n+import org.apache.hadoop.hbase.regionserver.RegionServerAccounting;\n+import org.apache.hadoop.hbase.regionserver.RegionServerServices;\n+import org.apache.hadoop.hbase.regionserver.ReplicationService;\n+import org.apache.hadoop.hbase.regionserver.ReplicationSinkService;\n+import org.apache.hadoop.hbase.regionserver.ReplicationSourceService;\n+import org.apache.hadoop.hbase.regionserver.SecureBulkLoadManager;\n+import org.apache.hadoop.hbase.regionserver.ServerNonceManager;\n+import org.apache.hadoop.hbase.regionserver.compactions.CompactionRequester;\n+import org.apache.hadoop.hbase.regionserver.throttle.ThroughputController;\n+import org.apache.hadoop.hbase.security.User;\n+import org.apache.hadoop.hbase.security.UserProvider;\n+import org.apache.hadoop.hbase.security.access.AccessChecker;\n+import org.apache.hadoop.hbase.security.access.ZKPermissionWatcher;\n+import org.apache.hadoop.hbase.trace.TraceUtil;\n+import org.apache.hadoop.hbase.util.Sleeper;\n+import org.apache.hadoop.hbase.util.VersionInfo;\n+import org.apache.hadoop.hbase.wal.WAL;\n+import org.apache.hadoop.hbase.zookeeper.ZKWatcher;\n+import org.apache.hadoop.util.ReflectionUtils;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos;\n+\n+import org.apache.hbase.thirdparty.com.google.protobuf.Service;\n+\n+/**\n+ * HReplicationServer which is responsible to all replication stuff. It checks in with\n+ * the HMaster. There are many HReplicationServers in a single HBase deployment.\n+ */\n+@InterfaceAudience.LimitedPrivate(HBaseInterfaceAudience.TOOLS)\n+@SuppressWarnings({ \"deprecation\"})\n+public class HReplicationServer extends Thread implements Server, RegionServerServices {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(HReplicationServer.class);\n+\n+  /** Parameter name for what region server implementation to use. */\n+  public static final String REPLICATION_SERVER_IMPL = \"hbase.replicationserver.impl\";\n+\n+  /** replication server process name */\n+  public static final String REPLICATIONSERVER = \"replicationserver\";\n+\n+  /**\n+   * This servers startcode.\n+   */\n+  protected final long startcode;\n+\n+  private volatile boolean stopped = false;\n+\n+  // A state before we go into stopped state.  At this stage we're closing user\n+  // space regions.\n+  private boolean stopping = false;\n+  private volatile boolean killed = false;\n+  private volatile boolean shutDown = false;\n+\n+  // Go down hard. Used if file system becomes unavailable and also in\n+  // debugging and unit tests.\n+  private AtomicBoolean abortRequested;\n+\n+  // flag set after we're done setting up server threads\n+  final AtomicBoolean online = new AtomicBoolean(false);\n+\n+  /**\n+   * The server name the Master sees us as.  Its made from the hostname the\n+   * master passes us, port, and server startcode. Gets set after registration\n+   * against Master.\n+   */\n+  private ServerName serverName;\n+\n+  protected final Configuration conf;\n+\n+  private ReplicationSinkService replicationSinkHandler;\n+\n+  final int msgInterval;\n+  // A sleeper that sleeps for msgInterval.\n+  protected final Sleeper sleeper;\n+\n+  // zookeeper connection and watcher\n+  protected final ZKWatcher zooKeeper;\n+\n+  /**\n+   * The asynchronous cluster connection to be shared by services.\n+   */\n+  protected AsyncClusterConnection asyncClusterConnection;\n+\n+  private UserProvider userProvider;\n+\n+  protected final ReplicationServerRpcServices rpcServices;\n+\n+  public HReplicationServer(final Configuration conf) throws IOException {\n+    TraceUtil.initTracer(conf);\n+    try {\n+      this.startcode = System.currentTimeMillis();\n+      this.conf = conf;\n+\n+      this.abortRequested = new AtomicBoolean(false);\n+\n+      this.rpcServices = createRpcServices();\n+\n+      String hostName = this.rpcServices.isa.getHostName();\n+      serverName = ServerName.valueOf(hostName, this.rpcServices.isa.getPort(), this.startcode);\n+\n+      this.userProvider = UserProvider.instantiate(conf);\n+\n+      this.msgInterval = conf.getInt(\"hbase.replicationserver.msginterval\", 3 * 1000);\n+      this.sleeper = new Sleeper(this.msgInterval, this);\n+\n+      // Some unit tests don't need a cluster, so no zookeeper at all\n+      if (!conf.getBoolean(\"hbase.testing.nocluster\", false)) {\n+        // Open connection to zookeeper and set primary watcher\n+        zooKeeper = new ZKWatcher(conf, getProcessName() + \":\" +\n+            rpcServices.isa.getPort(), this, false);\n+      } else {\n+        zooKeeper = null;\n+      }\n+\n+      this.rpcServices.start(zooKeeper);\n+    } catch (Throwable t) {\n+      // Make sure we log the exception. HReplicationServer is often started via reflection and the\n+      // cause of failed startup is lost.\n+      LOG.error(\"Failed construction ReplicationServer\", t);\n+      throw t;\n+    }\n+  }\n+\n+  /**\n+   * Utility for constructing an instance of the passed HRegionServer class.\n+   */\n+  static HReplicationServer constructReplicationServer(\n+      final Class<? extends HReplicationServer> replicationServerClass,\n+      final Configuration conf) {\n+    try {\n+      Constructor<? extends HReplicationServer> c =\n+          replicationServerClass.getConstructor(Configuration.class);\n+      return c.newInstance(conf);\n+    } catch (Exception e) {\n+      throw new RuntimeException(\"Failed construction of \" + \"ReplicationServer: \"\n+          + replicationServerClass.toString(), e);\n+    }\n+  }\n+\n+  public String getProcessName() {\n+    return REPLICATIONSERVER;\n+  }\n+\n+  @Override\n+  public void run() {\n+    if (isStopped()) {\n+      LOG.info(\"Skipping run; stopped\");\n+      return;\n+    }\n+    try {\n+      // Do pre-registration initializations; zookeeper, lease threads, etc.\n+      preRegistrationInitialization();\n+    } catch (Throwable e) {\n+      abort(\"Fatal exception during initialization\", e);\n+    }\n+    try {\n+      setupReplication();\n+      startReplicationService();\n+\n+      // Wake up anyone waiting for this server to online\n+      synchronized (online) {\n+        online.set(true);\n+        online.notifyAll();\n+      }\n+\n+      long lastMsg = System.currentTimeMillis();\n+      // The main run loop.\n+      while (!isStopped()) {\n+        if (!isClusterUp()) {\n+          if (!this.stopping) {\n+            this.stopping = true;\n+          }\n+        }\n+        long now = System.currentTimeMillis();\n+        if ((now - lastMsg) >= msgInterval) {\n+          lastMsg = System.currentTimeMillis();\n+        }\n+        if (!isStopped() && !isAborted()) {\n+          this.sleeper.sleep();\n+        }\n+      }\n+\n+      if (!killed) {\n+        stopServiceThreads();\n+      }\n+      if (this.rpcServices != null) {\n+        this.rpcServices.stop();\n+      }\n+    } catch (Throwable t) {\n+      abort(t.getMessage(), t);\n+    }\n+\n+    if (this.zooKeeper != null) {\n+      this.zooKeeper.close();\n+    }\n+    this.shutDown = true;\n+    LOG.info(\"Exiting; stopping=\" + this.serverName + \"; zookeeper connection closed.\");\n+  }\n+\n+  private Configuration cleanupConfiguration() {\n+    Configuration conf = this.conf;\n+    // We use ZKConnectionRegistry for all the internal communication, primarily for these reasons:\n+    // - Decouples RS and master life cycles. RegionServers can continue be up independent of\n+    //   masters' availability.\n+    // - Configuration management for region servers (cluster internal) is much simpler when adding\n+    //   new masters or removing existing masters, since only clients' config needs to be updated.\n+    // - We need to retain ZKConnectionRegistry for replication use anyway, so we just extend it for\n+    //   other internal connections too.\n+    conf.set(HConstants.CLIENT_CONNECTION_REGISTRY_IMPL_CONF_KEY,\n+        HConstants.ZK_CONNECTION_REGISTRY_CLASS);\n+    if (conf.get(HConstants.CLIENT_ZOOKEEPER_QUORUM) != null) {\n+      // Use server ZK cluster for server-issued connections, so we clone\n+      // the conf and unset the client ZK related properties\n+      conf = new Configuration(this.conf);\n+      conf.unset(HConstants.CLIENT_ZOOKEEPER_QUORUM);\n+    }\n+    return conf;\n+  }\n+\n+  /**\n+   * All initialization needed before we go register with Master.<br>\n+   * Do bare minimum. Do bulk of initializations AFTER we've connected to the Master.<br>\n+   * In here we just put up the RpcServer, setup Connection, and ZooKeeper.\n+   */\n+  private void preRegistrationInitialization() {\n+    try {\n+      setupClusterConnection();\n+    } catch (Throwable t) {\n+      // Call stop if error or process will stick around for ever since server\n+      // puts up non-daemon threads.\n+      this.rpcServices.stop();\n+      abort(\"Initialization of RS failed.  Hence aborting RS.\", t);\n+    }\n+  }\n+\n+  /**\n+   * Setup our cluster connection if not already initialized.\n+   */\n+  protected final synchronized void setupClusterConnection() throws IOException {\n+    if (asyncClusterConnection == null) {\n+      Configuration conf = cleanupConfiguration();\n+      InetSocketAddress localAddress = new InetSocketAddress(this.rpcServices.isa.getAddress(), 0);\n+      User user = userProvider.getCurrent();\n+      asyncClusterConnection =\n+          ClusterConnectionFactory.createAsyncClusterConnection(conf, localAddress, user);\n+    }\n+  }\n+\n+  /**\n+   * Wait on all threads to finish. Presumption is that all closes and stops\n+   * have already been called.\n+   */\n+  protected void stopServiceThreads() {\n+    if (this.replicationSinkHandler != null) {\n+      this.replicationSinkHandler.stopReplicationService();\n+    }\n+  }\n+\n+  public static void main(String[] args) {\n+    LOG.info(\"STARTING executorService \" + HReplicationServer.class.getSimpleName());\n+    VersionInfo.logVersion();\n+    Configuration conf = HBaseConfiguration.create();\n+    @SuppressWarnings(\"unchecked\")\n+    Class<? extends HReplicationServer> replicationServerClass =\n+        (Class<? extends HReplicationServer>)\n+            conf.getClass(REPLICATION_SERVER_IMPL, HReplicationServer.class);\n+\n+    new HReplicationServerCommandLine(replicationServerClass).doMain(args);\n+  }\n+\n+  @Override\n+  public WAL getWAL(RegionInfo regionInfo) throws IOException {\n+    throw new DoNotRetryIOException(new UnsupportedOperationException(\"This's ReplicationServer.\"));\n+  }\n+\n+  @Override\n+  public List<WAL> getWALs() throws IOException {\n+    throw new DoNotRetryIOException(new UnsupportedOperationException(\"This's ReplicationServer.\"));\n+  }\n+\n+  @Override\n+  public FlushRequester getFlushRequester() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a93bac612767dc715cebcad214f0efc01a2c4724"}, "originalPosition": 346}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODAwMDY4OA==", "bodyText": "Have similar feeling, given the high number of methods where an implementation is not applicable in this context.", "url": "https://github.com/apache/hbase/pull/2111#discussion_r468000688", "createdAt": "2020-08-10T15:42:11Z", "author": {"login": "wchevreuil"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/HReplicationServer.java", "diffHunk": "@@ -0,0 +1,683 @@\n+/**\n+ *\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.replication;\n+\n+import java.io.IOException;\n+import java.lang.reflect.Constructor;\n+import java.net.InetSocketAddress;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map.Entry;\n+import java.util.Optional;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.Abortable;\n+import org.apache.hadoop.hbase.ChoreService;\n+import org.apache.hadoop.hbase.CoordinatedStateManager;\n+import org.apache.hadoop.hbase.DoNotRetryIOException;\n+import org.apache.hadoop.hbase.HBaseConfiguration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.HConstants;\n+import org.apache.hadoop.hbase.Server;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.TableDescriptors;\n+import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.AsyncClusterConnection;\n+import org.apache.hadoop.hbase.client.ClusterConnectionFactory;\n+import org.apache.hadoop.hbase.client.Connection;\n+import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.locking.EntityLock;\n+import org.apache.hadoop.hbase.executor.ExecutorService;\n+import org.apache.hadoop.hbase.io.hfile.BlockCache;\n+import org.apache.hadoop.hbase.ipc.RpcServerInterface;\n+import org.apache.hadoop.hbase.log.HBaseMarkers;\n+import org.apache.hadoop.hbase.mob.MobFileCache;\n+import org.apache.hadoop.hbase.quotas.RegionServerRpcQuotaManager;\n+import org.apache.hadoop.hbase.quotas.RegionServerSpaceQuotaManager;\n+import org.apache.hadoop.hbase.quotas.RegionSizeStore;\n+import org.apache.hadoop.hbase.regionserver.FlushRequester;\n+import org.apache.hadoop.hbase.regionserver.HRegion;\n+import org.apache.hadoop.hbase.regionserver.HeapMemoryManager;\n+import org.apache.hadoop.hbase.regionserver.LeaseManager;\n+import org.apache.hadoop.hbase.regionserver.MetricsRegionServer;\n+import org.apache.hadoop.hbase.regionserver.Region;\n+import org.apache.hadoop.hbase.regionserver.RegionServerAccounting;\n+import org.apache.hadoop.hbase.regionserver.RegionServerServices;\n+import org.apache.hadoop.hbase.regionserver.ReplicationService;\n+import org.apache.hadoop.hbase.regionserver.ReplicationSinkService;\n+import org.apache.hadoop.hbase.regionserver.ReplicationSourceService;\n+import org.apache.hadoop.hbase.regionserver.SecureBulkLoadManager;\n+import org.apache.hadoop.hbase.regionserver.ServerNonceManager;\n+import org.apache.hadoop.hbase.regionserver.compactions.CompactionRequester;\n+import org.apache.hadoop.hbase.regionserver.throttle.ThroughputController;\n+import org.apache.hadoop.hbase.security.User;\n+import org.apache.hadoop.hbase.security.UserProvider;\n+import org.apache.hadoop.hbase.security.access.AccessChecker;\n+import org.apache.hadoop.hbase.security.access.ZKPermissionWatcher;\n+import org.apache.hadoop.hbase.trace.TraceUtil;\n+import org.apache.hadoop.hbase.util.Sleeper;\n+import org.apache.hadoop.hbase.util.VersionInfo;\n+import org.apache.hadoop.hbase.wal.WAL;\n+import org.apache.hadoop.hbase.zookeeper.ZKWatcher;\n+import org.apache.hadoop.util.ReflectionUtils;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos;\n+\n+import org.apache.hbase.thirdparty.com.google.protobuf.Service;\n+\n+/**\n+ * HReplicationServer which is responsible to all replication stuff. It checks in with\n+ * the HMaster. There are many HReplicationServers in a single HBase deployment.\n+ */\n+@InterfaceAudience.LimitedPrivate(HBaseInterfaceAudience.TOOLS)\n+@SuppressWarnings({ \"deprecation\"})\n+public class HReplicationServer extends Thread implements Server, RegionServerServices {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzcxNDcyMw=="}, "originalCommit": {"oid": "a93bac612767dc715cebcad214f0efc01a2c4724"}, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODAxMjA4Mg==", "bodyText": "There's been a discussion, lately, about removing VisibleForTesting annotation, since it's not mentioned on our compatibility promises. The outcome is that we should rather rely on IA.Private only, and avoid VisibleForTesting.\nSee: https://lists.apache.org/thread.html/r9a2df6a3b58e00c0c482d8660434d8ce6075863c18700978e6ea8b21%40%3Cdev.hbase.apache.org%3E", "url": "https://github.com/apache/hbase/pull/2111#discussion_r468012082", "createdAt": "2020-08-10T15:59:51Z", "author": {"login": "wchevreuil"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/ReplicationServerRpcServices.java", "diffHunk": "@@ -0,0 +1,544 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.replication;\n+\n+import java.io.IOException;\n+import java.lang.reflect.InvocationTargetException;\n+import java.net.BindException;\n+import java.net.InetSocketAddress;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.atomic.LongAdder;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.CellScanner;\n+import org.apache.hadoop.hbase.DoNotRetryIOException;\n+import org.apache.hadoop.hbase.HConstants;\n+import org.apache.hadoop.hbase.Server;\n+import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.ConnectionUtils;\n+import org.apache.hadoop.hbase.io.ByteBuffAllocator;\n+import org.apache.hadoop.hbase.ipc.HBaseRPCErrorHandler;\n+import org.apache.hadoop.hbase.ipc.HBaseRpcController;\n+import org.apache.hadoop.hbase.ipc.PriorityFunction;\n+import org.apache.hadoop.hbase.ipc.QosPriority;\n+import org.apache.hadoop.hbase.ipc.RpcServer.BlockingServiceAndInterface;\n+import org.apache.hadoop.hbase.ipc.RpcServerFactory;\n+import org.apache.hadoop.hbase.ipc.RpcServerInterface;\n+import org.apache.hadoop.hbase.ipc.ServerNotRunningYetException;\n+import org.apache.hadoop.hbase.log.HBaseMarkers;\n+import org.apache.hadoop.hbase.net.Address;\n+import org.apache.hadoop.hbase.regionserver.RSRpcServices;\n+import org.apache.hadoop.hbase.regionserver.RegionServerAbortedException;\n+import org.apache.hadoop.hbase.regionserver.RegionServerStoppedException;\n+import org.apache.hadoop.hbase.regionserver.ReplicationSourceService;\n+import org.apache.hadoop.hbase.regionserver.RpcSchedulerFactory;\n+import org.apache.hadoop.hbase.regionserver.SimpleRpcSchedulerFactory;\n+import org.apache.hadoop.hbase.replication.regionserver.RejectReplicationRequestStateChecker;\n+import org.apache.hadoop.hbase.security.User;\n+import org.apache.hadoop.hbase.security.access.AccessChecker;\n+import org.apache.hadoop.hbase.security.access.NoopAccessChecker;\n+import org.apache.hadoop.hbase.security.access.ZKPermissionWatcher;\n+import org.apache.hadoop.hbase.util.DNS;\n+import org.apache.hadoop.hbase.util.DNS.ServerType;\n+import org.apache.hadoop.hbase.zookeeper.ZKWatcher;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.apache.zookeeper.KeeperException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.AdminService;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.QuotaProtos.GetSpaceQuotaSnapshotsRequest;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.QuotaProtos.GetSpaceQuotaSnapshotsResponse;\n+import org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.RequestHeader;\n+\n+import org.apache.hbase.thirdparty.com.google.common.annotations.VisibleForTesting;\n+import org.apache.hbase.thirdparty.com.google.protobuf.Message;\n+import org.apache.hbase.thirdparty.com.google.protobuf.RpcController;\n+import org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;\n+\n+/**\n+ * Implements the regionserver RPC services for {@link HReplicationServer}.\n+ */\n+@InterfaceAudience.Private\n+@SuppressWarnings(\"deprecation\")\n+public class ReplicationServerRpcServices implements HBaseRPCErrorHandler,\n+    AdminService.BlockingInterface, PriorityFunction {\n+\n+  protected static final Logger LOG = LoggerFactory.getLogger(ReplicationServerRpcServices.class);\n+\n+  /** Parameter name for port replication server listens on. */\n+  public static final String REPLICATION_SERVER_PORT = \"hbase.replicationserver.port\";\n+\n+  /** Default port replication server listens on. */\n+  public static final int DEFAULT_REPLICATION_SERVER_PORT = 16040;\n+\n+  /** default port for replication server web api */\n+  public static final int DEFAULT_REPLICATION_SERVER_INFOPORT = 16050;\n+\n+  // Request counter.\n+  final LongAdder requestCount = new LongAdder();\n+\n+  // Server to handle client requests.\n+  final RpcServerInterface rpcServer;\n+  final InetSocketAddress isa;\n+\n+  @VisibleForTesting", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a93bac612767dc715cebcad214f0efc01a2c4724"}, "originalPosition": 144}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a93bac612767dc715cebcad214f0efc01a2c4724", "author": {"user": {"login": "ddupg", "name": "XinSun"}}, "url": "https://github.com/apache/hbase/commit/a93bac612767dc715cebcad214f0efc01a2c4724", "committedDate": "2020-07-22T03:38:38Z", "message": "HBASE-24683 Add a basic ReplicationServer which only implement ReplicationSink Service"}, "afterCommit": {"oid": "96f54b34390da9ec71610af2590c39640a7dae17", "author": {"user": {"login": "ddupg", "name": "XinSun"}}, "url": "https://github.com/apache/hbase/commit/96f54b34390da9ec71610af2590c39640a7dae17", "committedDate": "2020-08-21T10:36:29Z", "message": "HBASE-24683 Add a basic ReplicationServer which only implement ReplicationSink Service"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "96f54b34390da9ec71610af2590c39640a7dae17", "author": {"user": {"login": "ddupg", "name": "XinSun"}}, "url": "https://github.com/apache/hbase/commit/96f54b34390da9ec71610af2590c39640a7dae17", "committedDate": "2020-08-21T10:36:29Z", "message": "HBASE-24683 Add a basic ReplicationServer which only implement ReplicationSink Service"}, "afterCommit": {"oid": "e4b4ab3da437853b1077f246aba93ff9f91a9f3a", "author": {"user": {"login": "ddupg", "name": "XinSun"}}, "url": "https://github.com/apache/hbase/commit/e4b4ab3da437853b1077f246aba93ff9f91a9f3a", "committedDate": "2020-09-04T03:28:39Z", "message": "HBASE-24683 Add a basic ReplicationServer which only implement ReplicationSink Service"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e4b4ab3da437853b1077f246aba93ff9f91a9f3a", "author": {"user": {"login": "ddupg", "name": "XinSun"}}, "url": "https://github.com/apache/hbase/commit/e4b4ab3da437853b1077f246aba93ff9f91a9f3a", "committedDate": "2020-09-04T03:28:39Z", "message": "HBASE-24683 Add a basic ReplicationServer which only implement ReplicationSink Service"}, "afterCommit": {"oid": "a9d89a7ac4ade8da245896de0acbbb482f2472c1", "author": {"user": {"login": "ddupg", "name": "XinSun"}}, "url": "https://github.com/apache/hbase/commit/a9d89a7ac4ade8da245896de0acbbb482f2472c1", "committedDate": "2020-09-04T03:39:17Z", "message": "HBASE-24683 Add a basic ReplicationServer which only implement ReplicationSink Service"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a9d89a7ac4ade8da245896de0acbbb482f2472c1", "author": {"user": {"login": "ddupg", "name": "XinSun"}}, "url": "https://github.com/apache/hbase/commit/a9d89a7ac4ade8da245896de0acbbb482f2472c1", "committedDate": "2020-09-04T03:39:17Z", "message": "HBASE-24683 Add a basic ReplicationServer which only implement ReplicationSink Service"}, "afterCommit": {"oid": "187c73448d65f5c6d578624910aeb06e58d0c2fb", "author": {"user": {"login": "ddupg", "name": "XinSun"}}, "url": "https://github.com/apache/hbase/commit/187c73448d65f5c6d578624910aeb06e58d0c2fb", "committedDate": "2020-09-04T08:11:58Z", "message": "HBASE-24683 Add a basic ReplicationServer which only implement ReplicationSink Service"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6e5ecd5163dcd370aec1cda28494a02fd1ad335d", "author": {"user": {"login": "ddupg", "name": "XinSun"}}, "url": "https://github.com/apache/hbase/commit/6e5ecd5163dcd370aec1cda28494a02fd1ad335d", "committedDate": "2020-09-04T09:28:39Z", "message": "HBASE-24683 Add a basic ReplicationServer which only implement ReplicationSink Service"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "187c73448d65f5c6d578624910aeb06e58d0c2fb", "author": {"user": {"login": "ddupg", "name": "XinSun"}}, "url": "https://github.com/apache/hbase/commit/187c73448d65f5c6d578624910aeb06e58d0c2fb", "committedDate": "2020-09-04T08:11:58Z", "message": "HBASE-24683 Add a basic ReplicationServer which only implement ReplicationSink Service"}, "afterCommit": {"oid": "6e5ecd5163dcd370aec1cda28494a02fd1ad335d", "author": {"user": {"login": "ddupg", "name": "XinSun"}}, "url": "https://github.com/apache/hbase/commit/6e5ecd5163dcd370aec1cda28494a02fd1ad335d", "committedDate": "2020-09-04T09:28:39Z", "message": "HBASE-24683 Add a basic ReplicationServer which only implement ReplicationSink Service"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDgyNTU1MTIx", "url": "https://github.com/apache/hbase/pull/2111#pullrequestreview-482555121", "createdAt": "2020-09-04T10:53:20Z", "commit": {"oid": "6e5ecd5163dcd370aec1cda28494a02fd1ad335d"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4981, "cost": 1, "resetAt": "2021-10-28T16:48:13Z"}}}