{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTA4MDc4Njcx", "number": 2579, "title": "HBASE-24999 Master manages ReplicationServers", "bodyText": "", "createdAt": "2020-10-22T07:25:17Z", "url": "https://github.com/apache/hbase/pull/2579", "merged": true, "mergeCommit": {"oid": "f67c3dfc5abc558c944fa7e5319d03df3a05f4f3"}, "closed": true, "closedAt": "2020-10-28T10:59:57Z", "author": {"login": "ddupg"}, "timelineItems": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdU98baABqjM5MDc4NDI0MzE=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdW7c7fAFqTUxODU0MjEwNA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ecbfcdb8271756bae807f38077f467533e33fcab", "author": {"user": {"login": "ddupg", "name": "XinSun"}}, "url": "https://github.com/apache/hbase/commit/ecbfcdb8271756bae807f38077f467533e33fcab", "committedDate": "2020-10-22T07:06:50Z", "message": "HBASE-24999 Master manages ReplicationServers"}, "afterCommit": {"oid": "00f78bac9699aff4578744eee6ba799375f6fbab", "author": {"user": {"login": "ddupg", "name": "XinSun"}}, "url": "https://github.com/apache/hbase/commit/00f78bac9699aff4578744eee6ba799375f6fbab", "committedDate": "2020-10-22T08:45:40Z", "message": "HBASE-24999 Master manages ReplicationServers"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE0NjMyNjcz", "url": "https://github.com/apache/hbase/pull/2579#pullrequestreview-514632673", "createdAt": "2020-10-22T11:40:35Z", "commit": {"oid": "00f78bac9699aff4578744eee6ba799375f6fbab"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQxMTo0MDozNVrOHmdi8g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQxNToxNDozMVrOHmm2Dg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDA5MjAxOA==", "bodyText": "Would it make sense to extend ServerManager, or maybe both this one and ServerManager could implement a common interface? It seems there is a common workflow for server managers.", "url": "https://github.com/apache/hbase/pull/2579#discussion_r510092018", "createdAt": "2020-10-22T11:40:35Z", "author": {"login": "wchevreuil"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/ReplicationServerManager.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.master;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentNavigableMap;\n+import java.util.concurrent.ConcurrentSkipListMap;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.ScheduledChore;\n+import org.apache.hadoop.hbase.ServerMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * The ServerManager class manages info about replication servers.\n+ * <p>\n+ * Maintains lists of online and dead servers.\n+ * <p>\n+ * Servers are distinguished in two different ways.  A given server has a\n+ * location, specified by hostname and port, and of which there can only be one\n+ * online at any given time.  A server instance is specified by the location\n+ * (hostname and port) as well as the startcode (timestamp from when the server\n+ * was started).  This is used to differentiate a restarted instance of a given\n+ * server from the original instance.\n+ */\n+@InterfaceAudience.Private\n+public class ReplicationServerManager {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "00f78bac9699aff4578744eee6ba799375f6fbab"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDA5NjUzOA==", "bodyText": "Nit: should we log server is getting expired?", "url": "https://github.com/apache/hbase/pull/2579#discussion_r510096538", "createdAt": "2020-10-22T11:48:43Z", "author": {"login": "wchevreuil"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/ReplicationServerManager.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.master;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentNavigableMap;\n+import java.util.concurrent.ConcurrentSkipListMap;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.ScheduledChore;\n+import org.apache.hadoop.hbase.ServerMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * The ServerManager class manages info about replication servers.\n+ * <p>\n+ * Maintains lists of online and dead servers.\n+ * <p>\n+ * Servers are distinguished in two different ways.  A given server has a\n+ * location, specified by hostname and port, and of which there can only be one\n+ * online at any given time.  A server instance is specified by the location\n+ * (hostname and port) as well as the startcode (timestamp from when the server\n+ * was started).  This is used to differentiate a restarted instance of a given\n+ * server from the original instance.\n+ */\n+@InterfaceAudience.Private\n+public class ReplicationServerManager {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(ReplicationServerManager.class);\n+\n+  public static final String ONLINE_SERVER_REFRESH_INTERVAL =\n+      \"hbase.master.replication.server.refresh.interval\";\n+  public static final int ONLINE_SERVER_REFRESH_INTERVAL_DEFAULT = 60 * 1000; // 1 mins\n+\n+  private final MasterServices master;\n+\n+  /** Map of registered servers to their current load */\n+  private final ConcurrentNavigableMap<ServerName, ServerMetrics> onlineServers =\n+    new ConcurrentSkipListMap<>();\n+\n+  private OnlineServerRefresher onlineServerRefresher;\n+  private int refreshPeriod;\n+\n+  /**\n+   * Constructor.\n+   */\n+  public ReplicationServerManager(final MasterServices master) {\n+    this.master = master;\n+  }\n+\n+  /**\n+   * start chore in ServerManager\n+   */\n+  public void startChore() {\n+    Configuration conf = master.getConfiguration();\n+    refreshPeriod = conf.getInt(ONLINE_SERVER_REFRESH_INTERVAL,\n+        ONLINE_SERVER_REFRESH_INTERVAL_DEFAULT);\n+    onlineServerRefresher = new OnlineServerRefresher(\"ReplicationServerRefresher\", refreshPeriod);\n+    master.getChoreService().scheduleChore(onlineServerRefresher);\n+  }\n+\n+  /**\n+   * Stop the ServerManager.\n+   */\n+  public void stop() {\n+    if (onlineServerRefresher != null) {\n+      onlineServerRefresher.cancel();\n+    }\n+  }\n+\n+  public void serverReport(ServerName sn, ServerMetrics sl) {\n+    if (null == this.onlineServers.replace(sn, sl)) {\n+      if (!checkAndRecordNewServer(sn, sl)) {\n+        LOG.info(\"ReplicationServerReport ignored, could not record the server: {}\", sn);\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Check is a server of same host and port already exists,\n+   * if not, or the existed one got a smaller start code, record it.\n+   *\n+   * @param serverName the server to check and record\n+   * @param sl the server load on the server\n+   * @return true if the server is recorded, otherwise, false\n+   */\n+  boolean checkAndRecordNewServer(final ServerName serverName, final ServerMetrics sl) {\n+    ServerName existingServer = null;\n+    synchronized (this.onlineServers) {\n+      existingServer = findServerWithSameHostnamePortWithLock(serverName);\n+      if (existingServer != null && (existingServer.getStartcode() > serverName.getStartcode())) {\n+        LOG.info(\"ReplicationServer serverName={} rejected; we already have {} registered with \"\n+          + \"same hostname and port\", serverName, existingServer);\n+        return false;\n+      }\n+      recordNewServerWithLock(serverName, sl);\n+      // Note that we assume that same ts means same server, and don't expire in that case.\n+      if (existingServer != null && (existingServer.getStartcode() < serverName.getStartcode())) {\n+        LOG.info(\"Triggering server recovery; existingServer {} looks stale, new server: {}\",\n+            existingServer, serverName);\n+        expireServerWithLock(existingServer);\n+      }\n+    }\n+    return true;\n+  }\n+\n+  /**\n+   * Assumes onlineServers is locked.\n+   * @return ServerName with matching hostname and port.\n+   */\n+  private ServerName findServerWithSameHostnamePortWithLock(final ServerName serverName) {\n+    ServerName end = ServerName.valueOf(serverName.getHostname(), serverName.getPort(),\n+      Long.MAX_VALUE);\n+\n+    ServerName r = onlineServers.lowerKey(end);\n+    if (r != null && ServerName.isSameAddress(r, serverName)) {\n+      return r;\n+    }\n+    return null;\n+  }\n+\n+  private void recordNewServerWithLock(final ServerName serverName, final ServerMetrics sl) {\n+    LOG.info(\"Registering ReplicationServer={}\", serverName);\n+    this.onlineServers.put(serverName, sl);\n+  }\n+\n+  /**\n+   * Expire the passed server. Remove it from list of online servers\n+   */\n+  public void expireServerWithLock(final ServerName serverName) {\n+    onlineServers.remove(serverName);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "00f78bac9699aff4578744eee6ba799375f6fbab"}, "originalPosition": 152}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDI0NDM2Ng==", "bodyText": "Is it true that an empty list would be returned if we can't reach slave master? Looks like we either throw an IOException or a RemoteException.", "url": "https://github.com/apache/hbase/pull/2579#discussion_r510244366", "createdAt": "2020-10-22T15:14:31Z", "author": {"login": "wchevreuil"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/HBaseReplicationEndpoint.java", "diffHunk": "@@ -288,39 +258,26 @@ public boolean isAborted() {\n     return false;\n   }\n \n-  /**\n-   * Get the connection to peer cluster\n-   * @return connection to peer cluster\n-   * @throws IOException If anything goes wrong connecting\n-   */\n-  private synchronized AsyncClusterConnection getPeerConnection() throws IOException {\n-    if (peerConnection == null) {\n-      Configuration conf = ctx.getConfiguration();\n-      peerConnection = ClusterConnectionFactory.createAsyncClusterConnection(conf, null,\n-          UserProvider.instantiate(conf).getCurrent());\n-    }\n-    return peerConnection;\n-  }\n-\n   /**\n    * Get the list of all the servers that are responsible for replication sink\n    * from the specified peer master\n    * @return list of server addresses or an empty list if the slave is unavailable", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "00f78bac9699aff4578744eee6ba799375f6fbab"}, "originalPosition": 155}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "00f78bac9699aff4578744eee6ba799375f6fbab", "author": {"user": {"login": "ddupg", "name": "XinSun"}}, "url": "https://github.com/apache/hbase/commit/00f78bac9699aff4578744eee6ba799375f6fbab", "committedDate": "2020-10-22T08:45:40Z", "message": "HBASE-24999 Master manages ReplicationServers"}, "afterCommit": {"oid": "6140c03a48c6e3d67869b5cdae9f97ab3ab5eecc", "author": {"user": {"login": "ddupg", "name": "XinSun"}}, "url": "https://github.com/apache/hbase/commit/6140c03a48c6e3d67869b5cdae9f97ab3ab5eecc", "committedDate": "2020-10-26T03:50:09Z", "message": "HBASE-24999 Master manages ReplicationServers"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE2NDkwNDQx", "url": "https://github.com/apache/hbase/pull/2579#pullrequestreview-516490441", "createdAt": "2020-10-26T06:19:08Z", "commit": {"oid": "6140c03a48c6e3d67869b5cdae9f97ab3ab5eecc"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQwNjoxOTowOFrOHoCBVg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQwNjoxOTowOFrOHoCBVg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTczODE5OA==", "bodyText": "ServerManager\u3000=> ReplicationServerManager?", "url": "https://github.com/apache/hbase/pull/2579#discussion_r511738198", "createdAt": "2020-10-26T06:19:08Z", "author": {"login": "infraio"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/ReplicationServerManager.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.master;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentNavigableMap;\n+import java.util.concurrent.ConcurrentSkipListMap;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.ScheduledChore;\n+import org.apache.hadoop.hbase.ServerMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * The ServerManager class manages info about replication servers.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6140c03a48c6e3d67869b5cdae9f97ab3ab5eecc"}, "originalPosition": 36}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE2NDkwODQw", "url": "https://github.com/apache/hbase/pull/2579#pullrequestreview-516490840", "createdAt": "2020-10-26T06:20:23Z", "commit": {"oid": "6140c03a48c6e3d67869b5cdae9f97ab3ab5eecc"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQwNjoyMDoyM1rOHoCCoA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQwNjoyMDoyM1rOHoCCoA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTczODUyOA==", "bodyText": "private method?", "url": "https://github.com/apache/hbase/pull/2579#discussion_r511738528", "createdAt": "2020-10-26T06:20:23Z", "author": {"login": "infraio"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/ReplicationServerManager.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.master;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentNavigableMap;\n+import java.util.concurrent.ConcurrentSkipListMap;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.ScheduledChore;\n+import org.apache.hadoop.hbase.ServerMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * The ServerManager class manages info about replication servers.\n+ * <p>\n+ * Maintains lists of online and dead servers.\n+ * <p>\n+ * Servers are distinguished in two different ways.  A given server has a\n+ * location, specified by hostname and port, and of which there can only be one\n+ * online at any given time.  A server instance is specified by the location\n+ * (hostname and port) as well as the startcode (timestamp from when the server\n+ * was started).  This is used to differentiate a restarted instance of a given\n+ * server from the original instance.\n+ */\n+@InterfaceAudience.Private\n+public class ReplicationServerManager {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(ReplicationServerManager.class);\n+\n+  public static final String ONLINE_SERVER_REFRESH_INTERVAL =\n+      \"hbase.master.replication.server.refresh.interval\";\n+  public static final int ONLINE_SERVER_REFRESH_INTERVAL_DEFAULT = 60 * 1000; // 1 mins\n+\n+  private final MasterServices master;\n+\n+  /** Map of registered servers to their current load */\n+  private final ConcurrentNavigableMap<ServerName, ServerMetrics> onlineServers =\n+    new ConcurrentSkipListMap<>();\n+\n+  private OnlineServerRefresher onlineServerRefresher;\n+  private int refreshPeriod;\n+\n+  /**\n+   * Constructor.\n+   */\n+  public ReplicationServerManager(final MasterServices master) {\n+    this.master = master;\n+  }\n+\n+  /**\n+   * start chore in ServerManager\n+   */\n+  public void startChore() {\n+    Configuration conf = master.getConfiguration();\n+    refreshPeriod = conf.getInt(ONLINE_SERVER_REFRESH_INTERVAL,\n+        ONLINE_SERVER_REFRESH_INTERVAL_DEFAULT);\n+    onlineServerRefresher = new OnlineServerRefresher(\"ReplicationServerRefresher\", refreshPeriod);\n+    master.getChoreService().scheduleChore(onlineServerRefresher);\n+  }\n+\n+  /**\n+   * Stop the ServerManager.\n+   */\n+  public void stop() {\n+    if (onlineServerRefresher != null) {\n+      onlineServerRefresher.cancel();\n+    }\n+  }\n+\n+  public void serverReport(ServerName sn, ServerMetrics sl) {\n+    if (null == this.onlineServers.replace(sn, sl)) {\n+      if (!checkAndRecordNewServer(sn, sl)) {\n+        LOG.info(\"ReplicationServerReport ignored, could not record the server: {}\", sn);\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Check is a server of same host and port already exists,\n+   * if not, or the existed one got a smaller start code, record it.\n+   *\n+   * @param serverName the server to check and record\n+   * @param sl the server load on the server\n+   * @return true if the server is recorded, otherwise, false\n+   */\n+  boolean checkAndRecordNewServer(final ServerName serverName, final ServerMetrics sl) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6140c03a48c6e3d67869b5cdae9f97ab3ab5eecc"}, "originalPosition": 108}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE2NDkzNDkz", "url": "https://github.com/apache/hbase/pull/2579#pullrequestreview-516493493", "createdAt": "2020-10-26T06:28:27Z", "commit": {"oid": "6140c03a48c6e3d67869b5cdae9f97ab3ab5eecc"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQwNjoyODoyOFrOHoCLLA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQwNjoyODoyOFrOHoCLLA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTc0MDcxNg==", "bodyText": "So in the new impl, it will always register zk listener but ignored the zk event if not use zk?", "url": "https://github.com/apache/hbase/pull/2579#discussion_r511740716", "createdAt": "2020-10-26T06:28:28Z", "author": {"login": "infraio"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/HBaseReplicationEndpoint.java", "diffHunk": "@@ -445,7 +418,7 @@ public PeerRegionServerListener(HBaseReplicationEndpoint endpoint) {\n \n     @Override\n     public synchronized void nodeChildrenChanged(String path) {\n-      if (path.equals(regionServerListNode)) {\n+      if (replicationEndpoint.fetchServersUseZk && path.equals(regionServerListNode)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6140c03a48c6e3d67869b5cdae9f97ab3ab5eecc"}, "originalPosition": 258}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE2NDk0Mzc2", "url": "https://github.com/apache/hbase/pull/2579#pullrequestreview-516494376", "createdAt": "2020-10-26T06:30:53Z", "commit": {"oid": "6140c03a48c6e3d67869b5cdae9f97ab3ab5eecc"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQwNjozMDo1M1rOHoCOHQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQwNjozMDo1M1rOHoCOHQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTc0MTQ2OQ==", "bodyText": "private method is enough?", "url": "https://github.com/apache/hbase/pull/2579#discussion_r511741469", "createdAt": "2020-10-26T06:30:53Z", "author": {"login": "infraio"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/HReplicationServer.java", "diffHunk": "@@ -388,4 +446,152 @@ protected ReplicationServerRpcServices createRpcServices() throws IOException {\n   protected boolean setAbortRequested() {\n     return abortRequested.compareAndSet(false, true);\n   }\n+\n+  protected void tryReplicationServerReport(long reportStartTime, long reportEndTime)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6140c03a48c6e3d67869b5cdae9f97ab3ab5eecc"}, "originalPosition": 180}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE2NDk0NDI1", "url": "https://github.com/apache/hbase/pull/2579#pullrequestreview-516494425", "createdAt": "2020-10-26T06:31:03Z", "commit": {"oid": "6140c03a48c6e3d67869b5cdae9f97ab3ab5eecc"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQwNjozMTowM1rOHoCOQQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQwNjozMTowM1rOHoCOQQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTc0MTUwNQ==", "bodyText": "Ditto.", "url": "https://github.com/apache/hbase/pull/2579#discussion_r511741505", "createdAt": "2020-10-26T06:31:03Z", "author": {"login": "infraio"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/HReplicationServer.java", "diffHunk": "@@ -388,4 +446,152 @@ protected ReplicationServerRpcServices createRpcServices() throws IOException {\n   protected boolean setAbortRequested() {\n     return abortRequested.compareAndSet(false, true);\n   }\n+\n+  protected void tryReplicationServerReport(long reportStartTime, long reportEndTime)\n+      throws IOException {\n+    ReplicationServerStatusService.BlockingInterface rss = rssStub;\n+    if (rss == null) {\n+      createReplicationServerStatusStub(true);\n+      rss = rssStub;\n+      if (rss == null) {\n+        return;\n+      }\n+    }\n+    ClusterStatusProtos.ServerLoad sl = buildServerLoad(reportStartTime, reportEndTime);\n+    try {\n+      RegionServerReportRequest.Builder request = RegionServerReportRequest\n+          .newBuilder();\n+      request.setServer(ProtobufUtil.toServerName(this.serverName));\n+      request.setLoad(sl);\n+      rss.replicationServerReport(null, request.build());\n+    } catch (ServiceException se) {\n+      IOException ioe = ProtobufUtil.getRemoteException(se);\n+      if (ioe instanceof YouAreDeadException) {\n+        // This will be caught and handled as a fatal error in run()\n+        throw ioe;\n+      }\n+      if (rssStub == rss) {\n+        rssStub = null;\n+      }\n+      // Couldn't connect to the master, get location from zk and reconnect\n+      // Method blocks until new master is found or we are stopped\n+      createReplicationServerStatusStub(true);\n+    }\n+  }\n+\n+  private ClusterStatusProtos.ServerLoad buildServerLoad(long reportStartTime, long reportEndTime) {\n+    long usedMemory = -1L;\n+    long maxMemory = -1L;\n+    final MemoryUsage usage = MemorySizeUtil.safeGetHeapMemoryUsage();\n+    if (usage != null) {\n+      usedMemory = usage.getUsed();\n+      maxMemory = usage.getMax();\n+    }\n+\n+    ClusterStatusProtos.ServerLoad.Builder serverLoad = ClusterStatusProtos.ServerLoad.newBuilder();\n+    serverLoad.setTotalNumberOfRequests(rpcServices.requestCount.sum());\n+    serverLoad.setUsedHeapMB((int) (usedMemory / 1024 / 1024));\n+    serverLoad.setMaxHeapMB((int) (maxMemory / 1024 / 1024));\n+\n+    serverLoad.setReportStartTime(reportStartTime);\n+    serverLoad.setReportEndTime(reportEndTime);\n+\n+    // for the replicationLoad purpose. Only need to get from one executorService\n+    // either source or sink will get the same info\n+    ReplicationSinkService sinks = getReplicationSinkService();\n+\n+    if (sinks != null) {\n+      // always refresh first to get the latest value\n+      ReplicationLoad rLoad = sinks.refreshAndGetReplicationLoad();\n+      if (rLoad != null) {\n+        serverLoad.setReplLoadSink(rLoad.getReplicationLoadSink());\n+      }\n+    }\n+    return serverLoad.build();\n+  }\n+\n+  /**\n+   * Get the current master from ZooKeeper and open the RPC connection to it. To get a fresh\n+   * connection, the current rssStub must be null. Method will block until a master is available.\n+   * You can break from this block by requesting the server stop.\n+   * @param refresh If true then master address will be read from ZK, otherwise use cached data\n+   * @return master + port, or null if server has been stopped\n+   */\n+  protected synchronized ServerName createReplicationServerStatusStub(boolean refresh) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6140c03a48c6e3d67869b5cdae9f97ab3ab5eecc"}, "originalPosition": 250}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "6140c03a48c6e3d67869b5cdae9f97ab3ab5eecc", "author": {"user": {"login": "ddupg", "name": "XinSun"}}, "url": "https://github.com/apache/hbase/commit/6140c03a48c6e3d67869b5cdae9f97ab3ab5eecc", "committedDate": "2020-10-26T03:50:09Z", "message": "HBASE-24999 Master manages ReplicationServers"}, "afterCommit": {"oid": "cb2c73feda971dd9cbbde171f07c8ed753acc1b8", "author": {"user": {"login": "ddupg", "name": "XinSun"}}, "url": "https://github.com/apache/hbase/commit/cb2c73feda971dd9cbbde171f07c8ed753acc1b8", "committedDate": "2020-10-26T10:14:01Z", "message": "HBASE-24999 Master manages ReplicationServers"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE3Mjc3NTI2", "url": "https://github.com/apache/hbase/pull/2579#pullrequestreview-517277526", "createdAt": "2020-10-27T01:02:02Z", "commit": {"oid": "cb2c73feda971dd9cbbde171f07c8ed753acc1b8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yN1QwMTowMjowM1rOHonsHw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yN1QwMTowMjowM1rOHonsHw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjM1NTM1OQ==", "bodyText": "One new question: ReplicationServer should not have request count metric? Because this metric should mean that read metric or write metric?", "url": "https://github.com/apache/hbase/pull/2579#discussion_r512355359", "createdAt": "2020-10-27T01:02:03Z", "author": {"login": "infraio"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterRpcServices.java", "diffHunk": "@@ -3402,4 +3406,33 @@ public ListReplicationSinkServersResponse listReplicationSinkServers(\n     }\n     return builder.build();\n   }\n+\n+  @Override\n+  public RegionServerReportResponse replicationServerReport(RpcController controller,\n+      RegionServerReportRequest request) throws ServiceException {\n+    try {\n+      master.checkServiceStarted();\n+      int versionNumber = 0;\n+      String version = \"0.0.0\";\n+      VersionInfo versionInfo = VersionInfoUtil.getCurrentClientVersionInfo();\n+      if (versionInfo != null) {\n+        version = versionInfo.getVersion();\n+        versionNumber = VersionInfoUtil.getVersionNumber(versionInfo);\n+      }\n+      ClusterStatusProtos.ServerLoad sl = request.getLoad();\n+      ServerName serverName = ProtobufUtil.toServerName(request.getServer());\n+      ServerMetrics oldMetrics = master.getReplicationServerManager().getServerMetrics(serverName);\n+      ServerMetrics newMetrics =\n+          ServerMetricsBuilder.toServerMetrics(serverName, versionNumber, version, sl);\n+      master.getReplicationServerManager().serverReport(serverName, newMetrics);\n+      if (sl != null && master.metricsMaster != null) {\n+        // Up our metrics.\n+        master.metricsMaster.incrementRequests(sl.getTotalNumberOfRequests()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb2c73feda971dd9cbbde171f07c8ed753acc1b8"}, "originalPosition": 61}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE3Mjg0ODQx", "url": "https://github.com/apache/hbase/pull/2579#pullrequestreview-517284841", "createdAt": "2020-10-27T01:25:51Z", "commit": {"oid": "cb2c73feda971dd9cbbde171f07c8ed753acc1b8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yN1QwMToyNTo1MVrOHooFOQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yN1QwMToyNTo1MVrOHooFOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjM2MTc4NQ==", "bodyText": "The return ServerName never used?", "url": "https://github.com/apache/hbase/pull/2579#discussion_r512361785", "createdAt": "2020-10-27T01:25:51Z", "author": {"login": "infraio"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/HReplicationServer.java", "diffHunk": "@@ -388,4 +446,152 @@ protected ReplicationServerRpcServices createRpcServices() throws IOException {\n   protected boolean setAbortRequested() {\n     return abortRequested.compareAndSet(false, true);\n   }\n+\n+  private void tryReplicationServerReport(long reportStartTime, long reportEndTime)\n+      throws IOException {\n+    ReplicationServerStatusService.BlockingInterface rss = rssStub;\n+    if (rss == null) {\n+      createReplicationServerStatusStub(true);\n+      rss = rssStub;\n+      if (rss == null) {\n+        return;\n+      }\n+    }\n+    ClusterStatusProtos.ServerLoad sl = buildServerLoad(reportStartTime, reportEndTime);\n+    try {\n+      RegionServerReportRequest.Builder request = RegionServerReportRequest\n+          .newBuilder();\n+      request.setServer(ProtobufUtil.toServerName(this.serverName));\n+      request.setLoad(sl);\n+      rss.replicationServerReport(null, request.build());\n+    } catch (ServiceException se) {\n+      IOException ioe = ProtobufUtil.getRemoteException(se);\n+      if (ioe instanceof YouAreDeadException) {\n+        // This will be caught and handled as a fatal error in run()\n+        throw ioe;\n+      }\n+      if (rssStub == rss) {\n+        rssStub = null;\n+      }\n+      // Couldn't connect to the master, get location from zk and reconnect\n+      // Method blocks until new master is found or we are stopped\n+      createReplicationServerStatusStub(true);\n+    }\n+  }\n+\n+  private ClusterStatusProtos.ServerLoad buildServerLoad(long reportStartTime, long reportEndTime) {\n+    long usedMemory = -1L;\n+    long maxMemory = -1L;\n+    final MemoryUsage usage = MemorySizeUtil.safeGetHeapMemoryUsage();\n+    if (usage != null) {\n+      usedMemory = usage.getUsed();\n+      maxMemory = usage.getMax();\n+    }\n+\n+    ClusterStatusProtos.ServerLoad.Builder serverLoad = ClusterStatusProtos.ServerLoad.newBuilder();\n+    serverLoad.setTotalNumberOfRequests(rpcServices.requestCount.sum());\n+    serverLoad.setUsedHeapMB((int) (usedMemory / 1024 / 1024));\n+    serverLoad.setMaxHeapMB((int) (maxMemory / 1024 / 1024));\n+\n+    serverLoad.setReportStartTime(reportStartTime);\n+    serverLoad.setReportEndTime(reportEndTime);\n+\n+    // for the replicationLoad purpose. Only need to get from one executorService\n+    // either source or sink will get the same info\n+    ReplicationSinkService sinks = getReplicationSinkService();\n+\n+    if (sinks != null) {\n+      // always refresh first to get the latest value\n+      ReplicationLoad rLoad = sinks.refreshAndGetReplicationLoad();\n+      if (rLoad != null) {\n+        serverLoad.setReplLoadSink(rLoad.getReplicationLoadSink());\n+      }\n+    }\n+    return serverLoad.build();\n+  }\n+\n+  /**\n+   * Get the current master from ZooKeeper and open the RPC connection to it. To get a fresh\n+   * connection, the current rssStub must be null. Method will block until a master is available.\n+   * You can break from this block by requesting the server stop.\n+   * @param refresh If true then master address will be read from ZK, otherwise use cached data\n+   * @return master + port, or null if server has been stopped\n+   */\n+  private synchronized ServerName createReplicationServerStatusStub(boolean refresh) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb2c73feda971dd9cbbde171f07c8ed753acc1b8"}, "originalPosition": 250}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a84cabfa51dd886f2448b9477e89db5f3e6ee5fd", "author": {"user": {"login": "ddupg", "name": "XinSun"}}, "url": "https://github.com/apache/hbase/commit/a84cabfa51dd886f2448b9477e89db5f3e6ee5fd", "committedDate": "2020-10-27T03:43:33Z", "message": "HBASE-24999 Master manages ReplicationServers"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "cb2c73feda971dd9cbbde171f07c8ed753acc1b8", "author": {"user": {"login": "ddupg", "name": "XinSun"}}, "url": "https://github.com/apache/hbase/commit/cb2c73feda971dd9cbbde171f07c8ed753acc1b8", "committedDate": "2020-10-26T10:14:01Z", "message": "HBASE-24999 Master manages ReplicationServers"}, "afterCommit": {"oid": "a84cabfa51dd886f2448b9477e89db5f3e6ee5fd", "author": {"user": {"login": "ddupg", "name": "XinSun"}}, "url": "https://github.com/apache/hbase/commit/a84cabfa51dd886f2448b9477e89db5f3e6ee5fd", "committedDate": "2020-10-27T03:43:33Z", "message": "HBASE-24999 Master manages ReplicationServers"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE4NTQyMTA0", "url": "https://github.com/apache/hbase/pull/2579#pullrequestreview-518542104", "createdAt": "2020-10-28T10:59:34Z", "commit": {"oid": "a84cabfa51dd886f2448b9477e89db5f3e6ee5fd"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4446, "cost": 1, "resetAt": "2021-10-28T16:48:13Z"}}}