{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDI0MDA2NjIw", "number": 1791, "title": "HBASE-23202 ExportSnapshot (import) will fail if copying files to roo\u2026", "bodyText": "\u2026t directory takes longer than cleaner TTL", "createdAt": "2020-05-27T17:35:02Z", "url": "https://github.com/apache/hbase/pull/1791", "merged": true, "mergeCommit": {"oid": "f862f3d9b53d1c7148ae3e04a339f733b3cfbd96"}, "closed": true, "closedAt": "2020-06-08T21:48:22Z", "author": {"login": "huaxiangsun"}, "timelineItems": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABclew68AFqTQxOTU1ODU2OA==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcpUNvMgBqjM0MjEzMDU5OTY=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE5NTU4NTY4", "url": "https://github.com/apache/hbase/pull/1791#pullrequestreview-419558568", "createdAt": "2020-05-27T19:50:19Z", "commit": {"oid": "059cdb1edfc7631067c820cfaa41ba8c2c7c3176"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxOTo1MDoxOVrOGbayng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxOTo1MDoxOVrOGbayng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQwMzY3OA==", "bodyText": "Could this be handled better? It seems that in the event of an exception, the entirety of the in-progress snapshot would excluded.\nLogging the exception doesn't tell us anything useful because the SnapshotDescription isn't party to the message. Maybe we should log the snapshot name and table name. At WARN level?", "url": "https://github.com/apache/hbase/pull/1791#discussion_r431403678", "createdAt": "2020-05-27T19:50:19Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotFileCache.java", "diffHunk": "@@ -251,6 +260,25 @@ private void refreshCache() throws IOException {\n     this.snapshots.putAll(newSnapshots);\n   }\n \n+  @VisibleForTesting\n+  List<String> getSnapshotsInProgress() throws IOException {\n+    List<String> snapshotInProgress = Lists.newArrayList();\n+    // only add those files to the cache, but not to the known snapshots\n+    FileStatus[] snapshotsInProgress = CommonFSUtils.listStatus(fs,\n+      new Path(snapshotDir, SnapshotDescriptionUtils.SNAPSHOT_TMP_DIR_NAME));\n+\n+    if (!ArrayUtils.isEmpty(snapshotsInProgress)) {\n+      for (FileStatus snapshot : snapshotsInProgress) {\n+        try {\n+          snapshotInProgress.addAll(fileInspector.filesUnderSnapshot(snapshot.getPath()));\n+        } catch (CorruptedSnapshotException cse) {\n+          LOG.debug(\"Corrupted in-progress snapshot file exception, ignored.\", cse);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "059cdb1edfc7631067c820cfaa41ba8c2c7c3176"}, "originalPosition": 53}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIwNDAwMjA2", "url": "https://github.com/apache/hbase/pull/1791#pullrequestreview-420400206", "createdAt": "2020-05-28T18:56:40Z", "commit": {"oid": "059cdb1edfc7631067c820cfaa41ba8c2c7c3176"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQxODo1Njo0MFrOGcCZQg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQxOToxMDowN1rOGcC2AA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjA1MjU0Ng==", "bodyText": "Please use https://github.com/apache/hbase/blob/master/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotDescriptionUtils.java#L198 to get the temporary directory. Currently, this will break https://issues.apache.org/jira/browse/HBASE-21098.\nIt's probably worth adding a similar test with the config value for working snapshot dir set to avoid any regressions.", "url": "https://github.com/apache/hbase/pull/1791#discussion_r432052546", "createdAt": "2020-05-28T18:56:40Z", "author": {"login": "z-york"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotFileCache.java", "diffHunk": "@@ -251,6 +260,25 @@ private void refreshCache() throws IOException {\n     this.snapshots.putAll(newSnapshots);\n   }\n \n+  @VisibleForTesting\n+  List<String> getSnapshotsInProgress() throws IOException {\n+    List<String> snapshotInProgress = Lists.newArrayList();\n+    // only add those files to the cache, but not to the known snapshots\n+    FileStatus[] snapshotsInProgress = CommonFSUtils.listStatus(fs,\n+      new Path(snapshotDir, SnapshotDescriptionUtils.SNAPSHOT_TMP_DIR_NAME));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "059cdb1edfc7631067c820cfaa41ba8c2c7c3176"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjA1NDQ0MQ==", "bodyText": "What is this testing?", "url": "https://github.com/apache/hbase/pull/1791#discussion_r432054441", "createdAt": "2020-05-28T19:00:02Z", "author": {"login": "z-york"}, "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotHFileCleaner.java", "diffHunk": "@@ -156,7 +164,29 @@ public void testCorruptedDataManifest() throws IOException {\n     builder.consolidate();\n     builder.corruptDataManifest();\n \n-    fs.delete(SnapshotDescriptionUtils.getWorkingSnapshotDir(rootDir,\n+    long period = Long.MAX_VALUE;\n+    SnapshotFileCache cache = new SnapshotFileCache(fs, rootDir, period, 10000000,\n+        \"test-snapshot-file-cache-refresh\", new SnapshotFiles());\n+    try {\n+      cache.getSnapshotsInProgress();\n+    } finally {\n+      fs.delete(SnapshotDescriptionUtils.getWorkingSnapshotDir(rootDir,\n           TEST_UTIL.getConfiguration()), true);\n+    }\n+  }\n+\n+  @Test\n+  public void testMissedTmpSnapshot() throws IOException {\n+    SnapshotTestingUtils.SnapshotMock snapshotMock =\n+        new SnapshotTestingUtils.SnapshotMock(TEST_UTIL.getConfiguration(), fs, rootDir);\n+    SnapshotTestingUtils.SnapshotMock.SnapshotBuilder builder = snapshotMock.createSnapshotV2(\n+        SNAPSHOT_NAME_STR, TABLE_NAME_STR);\n+    builder.addRegionV2();\n+    builder.missOneRegionSnapshotFile();\n+    long period = Long.MAX_VALUE;\n+    SnapshotFileCache cache = new SnapshotFileCache(fs, rootDir, period, 10000000,\n+        \"test-snapshot-file-cache-refresh\", new SnapshotFiles());\n+    cache.getSnapshotsInProgress();\n+    assertTrue(fs.exists(builder.getSnapshotsDir()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "059cdb1edfc7631067c820cfaa41ba8c2c7c3176"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjA1NTgyMg==", "bodyText": "Is this testing that we don't throw an exception when the snapshot is corrupted?", "url": "https://github.com/apache/hbase/pull/1791#discussion_r432055822", "createdAt": "2020-05-28T19:02:31Z", "author": {"login": "z-york"}, "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotHFileCleaner.java", "diffHunk": "@@ -137,8 +138,15 @@ public void testCorruptedRegionManifest() throws IOException {\n     builder.addRegionV2();\n     builder.corruptOneRegionManifest();\n \n-    fs.delete(SnapshotDescriptionUtils.getWorkingSnapshotDir(rootDir, TEST_UTIL.getConfiguration()),\n-      true);\n+    long period = Long.MAX_VALUE;\n+    SnapshotFileCache cache = new SnapshotFileCache(fs, rootDir, period, 10000000,\n+        \"test-snapshot-file-cache-refresh\", new SnapshotFiles());\n+    try {\n+      cache.getSnapshotsInProgress();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "059cdb1edfc7631067c820cfaa41ba8c2c7c3176"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjA1OTkwNA==", "bodyText": "This tests the case where getSnapshotsInProgress is and isn't called, but we should also directly test the getSnapshotsInProgress method to test the case where a file is correctly included if the file is in progress (and the negative case).", "url": "https://github.com/apache/hbase/pull/1791#discussion_r432059904", "createdAt": "2020-05-28T19:10:07Z", "author": {"login": "z-york"}, "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotFileCache.java", "diffHunk": "@@ -133,6 +145,71 @@ public void testCacheUpdatedWhenLastModifiedOfSnapDirNotUpdated() throws IOExcep\n     createAndTestSnapshotV2(cache, \"snapshot2v2\", true, false, true);\n   }\n \n+  @Test\n+  public void testWeNeverCacheTmpDirAndLoadIt() throws Exception {\n+\n+    final AtomicInteger count = new AtomicInteger(0);\n+    // don't refresh the cache unless we tell it to\n+    long period = Long.MAX_VALUE;\n+    SnapshotFileCache cache = new SnapshotFileCache(fs, rootDir, period, 10000000,\n+        \"test-snapshot-file-cache-refresh\", new SnapshotFiles()) {\n+      @Override\n+      List<String> getSnapshotsInProgress()\n+              throws IOException {\n+        List<String> result = super.getSnapshotsInProgress();\n+        count.incrementAndGet();\n+        return result;\n+      }\n+\n+      @Override public void triggerCacheRefreshForTesting() {\n+        super.triggerCacheRefreshForTesting();\n+      }\n+    };\n+\n+    SnapshotMock.SnapshotBuilder complete =\n+        createAndTestSnapshotV1(cache, \"snapshot\", false, false, false);\n+\n+    int countBeforeCheck = count.get();\n+\n+    CommonFSUtils.logFileSystemState(fs, rootDir, LOG);\n+\n+    List<FileStatus> allStoreFiles = getStoreFilesForSnapshot(complete);\n+    Iterable<FileStatus> deletableFiles = cache.getUnreferencedFiles(allStoreFiles, null);\n+    assertTrue(Iterables.isEmpty(deletableFiles));\n+    // no need for tmp dir check as all files are accounted for.\n+    assertEquals(0, count.get() - countBeforeCheck);\n+\n+    // add a random file to make sure we refresh\n+    FileStatus randomFile = mockStoreFile(UTIL.getRandomUUID().toString());\n+    allStoreFiles.add(randomFile);\n+    deletableFiles = cache.getUnreferencedFiles(allStoreFiles, null);\n+    assertEquals(randomFile, Iterables.getOnlyElement(deletableFiles));\n+    assertEquals(1, count.get() - countBeforeCheck); // we check the tmp directory", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "059cdb1edfc7631067c820cfaa41ba8c2c7c3176"}, "originalPosition": 92}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "059cdb1edfc7631067c820cfaa41ba8c2c7c3176", "author": {"user": {"login": "guangxuCheng", "name": "Guangxu Cheng"}}, "url": "https://github.com/apache/hbase/commit/059cdb1edfc7631067c820cfaa41ba8c2c7c3176", "committedDate": "2020-05-27T17:32:20Z", "message": "HBASE-23202 ExportSnapshot (import) will fail if copying files to root directory takes longer than cleaner TTL"}, "afterCommit": {"oid": "6f1a191d329207916a3bdda10a99cf10681e4f23", "author": {"user": {"login": "guangxuCheng", "name": "Guangxu Cheng"}}, "url": "https://github.com/apache/hbase/commit/6f1a191d329207916a3bdda10a99cf10681e4f23", "committedDate": "2020-06-02T23:19:08Z", "message": "HBASE-23202 ExportSnapshot (import) will fail if copying files to root directory takes longer than cleaner TTL"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "6f1a191d329207916a3bdda10a99cf10681e4f23", "author": {"user": {"login": "guangxuCheng", "name": "Guangxu Cheng"}}, "url": "https://github.com/apache/hbase/commit/6f1a191d329207916a3bdda10a99cf10681e4f23", "committedDate": "2020-06-02T23:19:08Z", "message": "HBASE-23202 ExportSnapshot (import) will fail if copying files to root directory takes longer than cleaner TTL"}, "afterCommit": {"oid": "d42f46227f0d8f309e6db7534eed249dcc1407c5", "author": {"user": {"login": "guangxuCheng", "name": "Guangxu Cheng"}}, "url": "https://github.com/apache/hbase/commit/d42f46227f0d8f309e6db7534eed249dcc1407c5", "committedDate": "2020-06-02T23:38:05Z", "message": "HBASE-23202 ExportSnapshot (import) will fail if copying files to root directory takes longer than cleaner TTL"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIzMTU1ODI5", "url": "https://github.com/apache/hbase/pull/1791#pullrequestreview-423155829", "createdAt": "2020-06-03T01:13:40Z", "commit": {"oid": "d42f46227f0d8f309e6db7534eed249dcc1407c5"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wM1QwMToxMzo0MFrOGeI7Wg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wM1QwMToyMjo1OVrOGeJDyQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDI1NjczMA==", "bodyText": "This should just be be fs because workingFs or fs could be passed in", "url": "https://github.com/apache/hbase/pull/1791#discussion_r434256730", "createdAt": "2020-06-03T01:13:40Z", "author": {"login": "z-york"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotHFileCleaner.java", "diffHunk": "@@ -93,12 +94,17 @@ public void setConf(final Configuration conf) {\n         DEFAULT_HFILE_CACHE_REFRESH_PERIOD);\n       final FileSystem fs = CommonFSUtils.getCurrentFileSystem(conf);\n       Path rootDir = CommonFSUtils.getRootDir(conf);\n-      cache = new SnapshotFileCache(fs, rootDir, cacheRefreshPeriod, cacheRefreshPeriod,\n-          \"snapshot-hfile-cleaner-cache-refresher\", new SnapshotFileCache.SnapshotFileInspector() {\n+      Path workingDir = SnapshotDescriptionUtils.getWorkingSnapshotDir(rootDir, conf);\n+      FileSystem workingFs = workingDir.getFileSystem(conf);\n+\n+      cache = new SnapshotFileCache(fs, rootDir, workingFs, workingDir, cacheRefreshPeriod,\n+        cacheRefreshPeriod, \"snapshot-hfile-cleaner-cache-refresher\",\n+        new SnapshotFileCache.SnapshotFileInspector() {\n             @Override\n-            public Collection<String> filesUnderSnapshot(final Path snapshotDir)\n+            public Collection<String> filesUnderSnapshot(final FileSystem workingFs,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d42f46227f0d8f309e6db7534eed249dcc1407c5"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDI1NzcyMw==", "bodyText": "Hmm, weird that this is duplicated. +1 on merging/removing one. Does it make more sense to be part of TakeSnapshotHandler? Why does it need to be in SnapshotDescriptionUtils?", "url": "https://github.com/apache/hbase/pull/1791#discussion_r434257723", "createdAt": "2020-06-03T01:17:55Z", "author": {"login": "z-york"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotDescriptionUtils.java", "diffHunk": "@@ -383,25 +385,38 @@ public static SnapshotDescription readSnapshotInfo(FileSystem fs, Path snapshotD\n   }\n \n   /**\n-   * Move the finished snapshot to its final, publicly visible directory - this marks the snapshot\n-   * as 'complete'.\n-   * @param snapshot description of the snapshot being tabken\n-   * @param rootdir root directory of the hbase installation\n-   * @param workingDir directory where the in progress snapshot was built\n-   * @param fs {@link FileSystem} where the snapshot was built\n-   * @throws org.apache.hadoop.hbase.snapshot.SnapshotCreationException if the\n-   * snapshot could not be moved\n+   * Commits the snapshot process by moving the working snapshot\n+   * to the finalized filepath\n+   *\n+   * @param snapshotDir The file path of the completed snapshots\n+   * @param workingDir  The file path of the in progress snapshots\n+   * @param fs The file system of the completed snapshots\n+   * @param workingDirFs The file system of the in progress snapshots\n+   * @param conf Configuration\n+   *\n+   * @throws SnapshotCreationException if the snapshot could not be moved\n    * @throws IOException the filesystem could not be reached\n    */\n-  public static void completeSnapshot(SnapshotDescription snapshot, Path rootdir, Path workingDir,\n-      FileSystem fs) throws SnapshotCreationException, IOException {\n-    Path finishedDir = getCompletedSnapshotDir(snapshot, rootdir);\n-    LOG.debug(\"Snapshot is done, just moving the snapshot from \" + workingDir + \" to \"\n-        + finishedDir);\n-    if (!fs.rename(workingDir, finishedDir)) {\n-      throw new SnapshotCreationException(\n-          \"Failed to move working directory(\" + workingDir + \") to completed directory(\"\n-              + finishedDir + \").\", ProtobufUtil.createSnapshotDesc(snapshot));\n+  public static void completeSnapshot(Path snapshotDir, Path workingDir, FileSystem fs,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d42f46227f0d8f309e6db7534eed249dcc1407c5"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDI1ODYyMQ==", "bodyText": "In this case, shouldn't the try{} be removed (since it might mask a true failure)?", "url": "https://github.com/apache/hbase/pull/1791#discussion_r434258621", "createdAt": "2020-06-03T01:21:54Z", "author": {"login": "z-york"}, "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotHFileCleaner.java", "diffHunk": "@@ -137,8 +138,15 @@ public void testCorruptedRegionManifest() throws IOException {\n     builder.addRegionV2();\n     builder.corruptOneRegionManifest();\n \n-    fs.delete(SnapshotDescriptionUtils.getWorkingSnapshotDir(rootDir, TEST_UTIL.getConfiguration()),\n-      true);\n+    long period = Long.MAX_VALUE;\n+    SnapshotFileCache cache = new SnapshotFileCache(fs, rootDir, period, 10000000,\n+        \"test-snapshot-file-cache-refresh\", new SnapshotFiles());\n+    try {\n+      cache.getSnapshotsInProgress();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjA1NTgyMg=="}, "originalCommit": {"oid": "059cdb1edfc7631067c820cfaa41ba8c2c7c3176"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDI1ODg4OQ==", "bodyText": "Same here", "url": "https://github.com/apache/hbase/pull/1791#discussion_r434258889", "createdAt": "2020-06-03T01:22:59Z", "author": {"login": "z-york"}, "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotHFileCleaner.java", "diffHunk": "@@ -148,15 +156,37 @@ public void testCorruptedRegionManifest() throws IOException {\n   @Test\n   public void testCorruptedDataManifest() throws IOException {\n     SnapshotTestingUtils.SnapshotMock\n-        snapshotMock = new SnapshotTestingUtils.SnapshotMock(TEST_UTIL.getConfiguration(), fs, rootDir);\n+        snapshotMock = new SnapshotTestingUtils.SnapshotMock(conf, fs, rootDir);\n     SnapshotTestingUtils.SnapshotMock.SnapshotBuilder builder = snapshotMock.createSnapshotV2(\n         SNAPSHOT_NAME_STR, TABLE_NAME_STR);\n     builder.addRegionV2();\n     // consolidate to generate a data.manifest file\n     builder.consolidate();\n     builder.corruptDataManifest();\n \n-    fs.delete(SnapshotDescriptionUtils.getWorkingSnapshotDir(rootDir,\n+    long period = Long.MAX_VALUE;\n+    SnapshotFileCache cache = new SnapshotFileCache(conf, period, 10000000,\n+        \"test-snapshot-file-cache-refresh\", new SnapshotFiles());\n+    try {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d42f46227f0d8f309e6db7534eed249dcc1407c5"}, "originalPosition": 87}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d42f46227f0d8f309e6db7534eed249dcc1407c5", "author": {"user": {"login": "guangxuCheng", "name": "Guangxu Cheng"}}, "url": "https://github.com/apache/hbase/commit/d42f46227f0d8f309e6db7534eed249dcc1407c5", "committedDate": "2020-06-02T23:38:05Z", "message": "HBASE-23202 ExportSnapshot (import) will fail if copying files to root directory takes longer than cleaner TTL"}, "afterCommit": {"oid": "4375fec4ee34507d64b622a3985b7e19f9a9727e", "author": {"user": {"login": "guangxuCheng", "name": "Guangxu Cheng"}}, "url": "https://github.com/apache/hbase/commit/4375fec4ee34507d64b622a3985b7e19f9a9727e", "committedDate": "2020-06-03T18:39:00Z", "message": "HBASE-23202 ExportSnapshot (import) will fail if copying files to root directory takes longer than cleaner TTL"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI0MDA3OTU5", "url": "https://github.com/apache/hbase/pull/1791#pullrequestreview-424007959", "createdAt": "2020-06-03T23:39:53Z", "commit": {"oid": "4375fec4ee34507d64b622a3985b7e19f9a9727e"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI0ODY2NDQ0", "url": "https://github.com/apache/hbase/pull/1791#pullrequestreview-424866444", "createdAt": "2020-06-04T22:02:11Z", "commit": {"oid": "4375fec4ee34507d64b622a3985b7e19f9a9727e"}, "state": "APPROVED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQyMjowMjoxMVrOGfZh6w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQyMjoxMTozNVrOGfZwXw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTU3NzMyMw==", "bodyText": "I missed the reason for changing this test parameter. By the comment there between method invocations, it seems repetition of the name, a.k.a, the directory, \"snapshot1\" was intentional. Why have two different parameters? Doesn't that negate the purpose of this test?", "url": "https://github.com/apache/hbase/pull/1791#discussion_r435577323", "createdAt": "2020-06-04T22:02:11Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotFileCache.java", "diffHunk": "@@ -85,32 +106,34 @@ public void cleanupFiles() throws Exception {\n \n   @Test\n   public void testLoadAndDelete() throws IOException {\n-    SnapshotFileCache cache = new SnapshotFileCache(fs, rootDir, PERIOD, 10000000,\n-        \"test-snapshot-file-cache-refresh\", new SnapshotFiles());\n+    SnapshotFileCache cache = new SnapshotFileCache(fs, rootDir, workingFs, workingDir, PERIOD,\n+      10000000, \"test-snapshot-file-cache-refresh\", new SnapshotFiles());\n \n     createAndTestSnapshotV1(cache, \"snapshot1a\", false, true, false);\n+    createAndTestSnapshotV1(cache, \"snapshot1b\", true, true, false);\n \n     createAndTestSnapshotV2(cache, \"snapshot2a\", false, true, false);\n+    createAndTestSnapshotV2(cache, \"snapshot2b\", true, true, false);\n   }\n \n   @Test\n   public void testReloadModifiedDirectory() throws IOException {\n-    SnapshotFileCache cache = new SnapshotFileCache(fs, rootDir, PERIOD, 10000000,\n-        \"test-snapshot-file-cache-refresh\", new SnapshotFiles());\n+    SnapshotFileCache cache = new SnapshotFileCache(fs, rootDir, workingFs, workingDir, PERIOD,\n+      10000000, \"test-snapshot-file-cache-refresh\", new SnapshotFiles());\n \n-    createAndTestSnapshotV1(cache, \"snapshot1\", false, true, false);\n+    createAndTestSnapshotV1(cache, \"snapshot1v1\", false, true, false);\n     // now delete the snapshot and add a file with a different name\n-    createAndTestSnapshotV1(cache, \"snapshot1\", false, false, false);\n+    createAndTestSnapshotV1(cache, \"snapshot1v2\", false, false, false);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4375fec4ee34507d64b622a3985b7e19f9a9727e"}, "originalPosition": 106}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTU4MDI4MA==", "bodyText": "nit: you're mixing java.nio and Hadoop APIs for building this path. I'm not quite sure, but maybe you want something like Paths.get(\".\", UUID.randomUUID().toString()).toAbsolutePath().toString()? I'm not sure where Paths.get(\"\") would drop you, but I assume it's the same as pwd.", "url": "https://github.com/apache/hbase/pull/1791#discussion_r435580280", "createdAt": "2020-06-04T22:09:46Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotFileCacheWithDifferentWorkingDir.java", "diffHunk": "@@ -0,0 +1,64 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.master.snapshot;\n+\n+import java.io.File;\n+import java.nio.file.Paths;\n+import java.util.UUID;\n+import org.apache.commons.io.FileUtils;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hbase.HBaseClassTestRule;\n+import org.apache.hadoop.hbase.snapshot.SnapshotDescriptionUtils;\n+import org.apache.hadoop.hbase.testclassification.LargeTests;\n+import org.apache.hadoop.hbase.testclassification.MasterTests;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.experimental.categories.Category;\n+\n+/**\n+ * Test that we correctly reload the cache, filter directories, etc.\n+ * while the temporary directory is on a different file system than the root directory\n+ */\n+@Category({MasterTests.class, LargeTests.class})\n+public class TestSnapshotFileCacheWithDifferentWorkingDir extends TestSnapshotFileCache {\n+\n+  @ClassRule\n+  public static final HBaseClassTestRule CLASS_RULE =\n+    HBaseClassTestRule.forClass(TestSnapshotFileCacheWithDifferentWorkingDir.class);\n+\n+  protected static String TEMP_DIR =\n+    Paths.get(\"\").toAbsolutePath().toString() + Path.SEPARATOR + UUID.randomUUID().toString();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4375fec4ee34507d64b622a3985b7e19f9a9727e"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTU4MTAyMw==", "bodyText": "nit: it would require a good bit of refactor, but I find that test case inheritance is really unreliable to maintain. Maybe better to make TestSnapshotFileCache a parameterized test.", "url": "https://github.com/apache/hbase/pull/1791#discussion_r435581023", "createdAt": "2020-06-04T22:11:35Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotFileCacheWithDifferentWorkingDir.java", "diffHunk": "@@ -0,0 +1,64 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.master.snapshot;\n+\n+import java.io.File;\n+import java.nio.file.Paths;\n+import java.util.UUID;\n+import org.apache.commons.io.FileUtils;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hbase.HBaseClassTestRule;\n+import org.apache.hadoop.hbase.snapshot.SnapshotDescriptionUtils;\n+import org.apache.hadoop.hbase.testclassification.LargeTests;\n+import org.apache.hadoop.hbase.testclassification.MasterTests;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.experimental.categories.Category;\n+\n+/**\n+ * Test that we correctly reload the cache, filter directories, etc.\n+ * while the temporary directory is on a different file system than the root directory\n+ */\n+@Category({MasterTests.class, LargeTests.class})\n+public class TestSnapshotFileCacheWithDifferentWorkingDir extends TestSnapshotFileCache {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4375fec4ee34507d64b622a3985b7e19f9a9727e"}, "originalPosition": 39}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ede033b26c172a6ea6b07e6e0d4e2a8e37eb765b", "author": {"user": {"login": "guangxuCheng", "name": "Guangxu Cheng"}}, "url": "https://github.com/apache/hbase/commit/ede033b26c172a6ea6b07e6e0d4e2a8e37eb765b", "committedDate": "2020-06-08T17:44:46Z", "message": "HBASE-23202 ExportSnapshot (import) will fail if copying files to root directory takes longer than cleaner TTL"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "4375fec4ee34507d64b622a3985b7e19f9a9727e", "author": {"user": {"login": "guangxuCheng", "name": "Guangxu Cheng"}}, "url": "https://github.com/apache/hbase/commit/4375fec4ee34507d64b622a3985b7e19f9a9727e", "committedDate": "2020-06-03T18:39:00Z", "message": "HBASE-23202 ExportSnapshot (import) will fail if copying files to root directory takes longer than cleaner TTL"}, "afterCommit": {"oid": "ede033b26c172a6ea6b07e6e0d4e2a8e37eb765b", "author": {"user": {"login": "guangxuCheng", "name": "Guangxu Cheng"}}, "url": "https://github.com/apache/hbase/commit/ede033b26c172a6ea6b07e6e0d4e2a8e37eb765b", "committedDate": "2020-06-08T17:44:46Z", "message": "HBASE-23202 ExportSnapshot (import) will fail if copying files to root directory takes longer than cleaner TTL"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4788, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}