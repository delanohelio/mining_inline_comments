{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDY1NDE2MjA1", "number": 2228, "reviewThreads": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxNTo0MDoyMFrOEXrxsg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxNjowODo1OFrOEXspqQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkzMjY5OTM4OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxNTo0MDoyMFrOG_nFVQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxNTo0MDoyMFrOG_nFVQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTM1MzgxMw==", "bodyText": "nit: preferred", "url": "https://github.com/apache/hbase/pull/2228#discussion_r469353813", "createdAt": "2020-08-12T15:40:20Z", "author": {"login": "joshelser"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java", "diffHunk": "@@ -3805,6 +3838,196 @@ public void prepareMiniBatchOperations(MiniBatchOperationInProgress<Mutation> mi\n       }\n     }\n \n+    /**\n+     * Do coprocessor pre-increment or pre-append call.\n+     * @return Result returned out of the coprocessor, which means bypass all further processing\n+     *   and return the proffered Result instead, or null which means proceed.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fb1ba98fc05a52018b39babdec945679f358b490"}, "originalPosition": 117}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkzMjcxNTU4OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxNTo0MjoyOVrOG_nODQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQwNjoyNTo1N1rOHAo_Zg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTM1NjA0NQ==", "bodyText": "Maybe doCoprocessorPreCallAfterRowLock() and indicate that this method is a no-op for Mutations which do not have a pre*AfterRowLock() method in the javadoc?", "url": "https://github.com/apache/hbase/pull/2228#discussion_r469356045", "createdAt": "2020-08-12T15:42:29Z", "author": {"login": "joshelser"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java", "diffHunk": "@@ -3805,6 +3838,196 @@ public void prepareMiniBatchOperations(MiniBatchOperationInProgress<Mutation> mi\n       }\n     }\n \n+    /**\n+     * Do coprocessor pre-increment or pre-append call.\n+     * @return Result returned out of the coprocessor, which means bypass all further processing\n+     *   and return the proffered Result instead, or null which means proceed.\n+     */\n+    private Result doCoprocessorPreCall(Mutation mutation) throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fb1ba98fc05a52018b39babdec945679f358b490"}, "originalPosition": 119}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQzMzYzOA==", "bodyText": "Will change the name. This method is only for Increment and Append operations. It's called in the following if statement only:\nhttps://github.com/apache/hbase/pull/2228/files#diff-6205e907851ed4f650499f7111cbd91cR3799", "url": "https://github.com/apache/hbase/pull/2228#discussion_r470433638", "createdAt": "2020-08-14T06:25:57Z", "author": {"login": "brfrn169"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java", "diffHunk": "@@ -3805,6 +3838,196 @@ public void prepareMiniBatchOperations(MiniBatchOperationInProgress<Mutation> mi\n       }\n     }\n \n+    /**\n+     * Do coprocessor pre-increment or pre-append call.\n+     * @return Result returned out of the coprocessor, which means bypass all further processing\n+     *   and return the proffered Result instead, or null which means proceed.\n+     */\n+    private Result doCoprocessorPreCall(Mutation mutation) throws IOException {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTM1NjA0NQ=="}, "originalCommit": {"oid": "fb1ba98fc05a52018b39babdec945679f358b490"}, "originalPosition": 119}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkzMjczMjU4OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxNTo0NDoyMlrOG_nW3w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxNTo1MjoxMFrOG_nuoA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTM1ODMwMw==", "bodyText": "What about compute or calculate instead of reckon? I had to go to a dictionary :)", "url": "https://github.com/apache/hbase/pull/2228#discussion_r469358303", "createdAt": "2020-08-12T15:44:22Z", "author": {"login": "joshelser"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java", "diffHunk": "@@ -3805,6 +3838,196 @@ public void prepareMiniBatchOperations(MiniBatchOperationInProgress<Mutation> mi\n       }\n     }\n \n+    /**\n+     * Do coprocessor pre-increment or pre-append call.\n+     * @return Result returned out of the coprocessor, which means bypass all further processing\n+     *   and return the proffered Result instead, or null which means proceed.\n+     */\n+    private Result doCoprocessorPreCall(Mutation mutation) throws IOException {\n+      assert mutation instanceof Increment || mutation instanceof Append;\n+      Result result = null;\n+      if (region.coprocessorHost != null) {\n+        if (mutation instanceof Increment) {\n+          result = region.coprocessorHost.preIncrementAfterRowLock((Increment) mutation);\n+        } else {\n+          result = region.coprocessorHost.preAppendAfterRowLock((Append) mutation);\n+        }\n+      }\n+      return result;\n+    }\n+\n+    private Map<byte[], List<Cell>> reckonDeltas(Mutation mutation, List<Cell> results)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fb1ba98fc05a52018b39babdec945679f358b490"}, "originalPosition": 132}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTM1ODgxNA==", "bodyText": "Javadoc here would also be great to supplement reckonDeltasByStore's javadoc.", "url": "https://github.com/apache/hbase/pull/2228#discussion_r469358814", "createdAt": "2020-08-12T15:44:50Z", "author": {"login": "joshelser"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java", "diffHunk": "@@ -3805,6 +3838,196 @@ public void prepareMiniBatchOperations(MiniBatchOperationInProgress<Mutation> mi\n       }\n     }\n \n+    /**\n+     * Do coprocessor pre-increment or pre-append call.\n+     * @return Result returned out of the coprocessor, which means bypass all further processing\n+     *   and return the proffered Result instead, or null which means proceed.\n+     */\n+    private Result doCoprocessorPreCall(Mutation mutation) throws IOException {\n+      assert mutation instanceof Increment || mutation instanceof Append;\n+      Result result = null;\n+      if (region.coprocessorHost != null) {\n+        if (mutation instanceof Increment) {\n+          result = region.coprocessorHost.preIncrementAfterRowLock((Increment) mutation);\n+        } else {\n+          result = region.coprocessorHost.preAppendAfterRowLock((Append) mutation);\n+        }\n+      }\n+      return result;\n+    }\n+\n+    private Map<byte[], List<Cell>> reckonDeltas(Mutation mutation, List<Cell> results)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTM1ODMwMw=="}, "originalCommit": {"oid": "fb1ba98fc05a52018b39babdec945679f358b490"}, "originalPosition": 132}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTM2NDM4NA==", "bodyText": "I see now that these were moving existing code. Better to keep the naming.", "url": "https://github.com/apache/hbase/pull/2228#discussion_r469364384", "createdAt": "2020-08-12T15:52:10Z", "author": {"login": "joshelser"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java", "diffHunk": "@@ -3805,6 +3838,196 @@ public void prepareMiniBatchOperations(MiniBatchOperationInProgress<Mutation> mi\n       }\n     }\n \n+    /**\n+     * Do coprocessor pre-increment or pre-append call.\n+     * @return Result returned out of the coprocessor, which means bypass all further processing\n+     *   and return the proffered Result instead, or null which means proceed.\n+     */\n+    private Result doCoprocessorPreCall(Mutation mutation) throws IOException {\n+      assert mutation instanceof Increment || mutation instanceof Append;\n+      Result result = null;\n+      if (region.coprocessorHost != null) {\n+        if (mutation instanceof Increment) {\n+          result = region.coprocessorHost.preIncrementAfterRowLock((Increment) mutation);\n+        } else {\n+          result = region.coprocessorHost.preAppendAfterRowLock((Append) mutation);\n+        }\n+      }\n+      return result;\n+    }\n+\n+    private Map<byte[], List<Cell>> reckonDeltas(Mutation mutation, List<Cell> results)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTM1ODMwMw=="}, "originalCommit": {"oid": "fb1ba98fc05a52018b39babdec945679f358b490"}, "originalPosition": 132}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkzMjc0NjE0OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxNTo0NjoxMlrOG_neXg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQwNjozMToxN1rOHApGKQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTM2MDIyMg==", "bodyText": "Genuine question, will this save us anything? Not sure how the JIT will (or won't) optimize such a thing away. I guess, at a minimum, it would save construction of an Iterator object?", "url": "https://github.com/apache/hbase/pull/2228#discussion_r469360222", "createdAt": "2020-08-12T15:46:12Z", "author": {"login": "joshelser"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java", "diffHunk": "@@ -3805,6 +3838,196 @@ public void prepareMiniBatchOperations(MiniBatchOperationInProgress<Mutation> mi\n       }\n     }\n \n+    /**\n+     * Do coprocessor pre-increment or pre-append call.\n+     * @return Result returned out of the coprocessor, which means bypass all further processing\n+     *   and return the proffered Result instead, or null which means proceed.\n+     */\n+    private Result doCoprocessorPreCall(Mutation mutation) throws IOException {\n+      assert mutation instanceof Increment || mutation instanceof Append;\n+      Result result = null;\n+      if (region.coprocessorHost != null) {\n+        if (mutation instanceof Increment) {\n+          result = region.coprocessorHost.preIncrementAfterRowLock((Increment) mutation);\n+        } else {\n+          result = region.coprocessorHost.preAppendAfterRowLock((Append) mutation);\n+        }\n+      }\n+      return result;\n+    }\n+\n+    private Map<byte[], List<Cell>> reckonDeltas(Mutation mutation, List<Cell> results)\n+      throws IOException {\n+      long now = EnvironmentEdgeManager.currentTime();\n+      Map<byte[], List<Cell>> ret = new HashMap<>();\n+      // Process a Store/family at a time.\n+      for (Map.Entry<byte [], List<Cell>> entry: mutation.getFamilyCellMap().entrySet()) {\n+        final byte[] columnFamilyName = entry.getKey();\n+        List<Cell> deltas = entry.getValue();\n+        // Reckon for the Store what to apply to WAL and MemStore.\n+        List<Cell> toApply = reckonDeltasByStore(region.stores.get(columnFamilyName), mutation,\n+          now, deltas, results);\n+        if (!toApply.isEmpty()) {\n+          for (Cell cell : toApply) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fb1ba98fc05a52018b39babdec945679f358b490"}, "originalPosition": 144}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQzNTM2OQ==", "bodyText": "These were also moving existing code. Will keep this. Thanks.", "url": "https://github.com/apache/hbase/pull/2228#discussion_r470435369", "createdAt": "2020-08-14T06:31:17Z", "author": {"login": "brfrn169"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java", "diffHunk": "@@ -3805,6 +3838,196 @@ public void prepareMiniBatchOperations(MiniBatchOperationInProgress<Mutation> mi\n       }\n     }\n \n+    /**\n+     * Do coprocessor pre-increment or pre-append call.\n+     * @return Result returned out of the coprocessor, which means bypass all further processing\n+     *   and return the proffered Result instead, or null which means proceed.\n+     */\n+    private Result doCoprocessorPreCall(Mutation mutation) throws IOException {\n+      assert mutation instanceof Increment || mutation instanceof Append;\n+      Result result = null;\n+      if (region.coprocessorHost != null) {\n+        if (mutation instanceof Increment) {\n+          result = region.coprocessorHost.preIncrementAfterRowLock((Increment) mutation);\n+        } else {\n+          result = region.coprocessorHost.preAppendAfterRowLock((Append) mutation);\n+        }\n+      }\n+      return result;\n+    }\n+\n+    private Map<byte[], List<Cell>> reckonDeltas(Mutation mutation, List<Cell> results)\n+      throws IOException {\n+      long now = EnvironmentEdgeManager.currentTime();\n+      Map<byte[], List<Cell>> ret = new HashMap<>();\n+      // Process a Store/family at a time.\n+      for (Map.Entry<byte [], List<Cell>> entry: mutation.getFamilyCellMap().entrySet()) {\n+        final byte[] columnFamilyName = entry.getKey();\n+        List<Cell> deltas = entry.getValue();\n+        // Reckon for the Store what to apply to WAL and MemStore.\n+        List<Cell> toApply = reckonDeltasByStore(region.stores.get(columnFamilyName), mutation,\n+          now, deltas, results);\n+        if (!toApply.isEmpty()) {\n+          for (Cell cell : toApply) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTM2MDIyMg=="}, "originalCommit": {"oid": "fb1ba98fc05a52018b39babdec945679f358b490"}, "originalPosition": 144}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkzMjc2MDQxOnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxNTo0OToyMlrOG_nnQQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQwNjozMTo1NlrOHApHAQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTM2MjQ5Nw==", "bodyText": "Better to check that it's an Append and throw an exception if it isn't?", "url": "https://github.com/apache/hbase/pull/2228#discussion_r469362497", "createdAt": "2020-08-12T15:49:22Z", "author": {"login": "joshelser"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java", "diffHunk": "@@ -3805,6 +3838,196 @@ public void prepareMiniBatchOperations(MiniBatchOperationInProgress<Mutation> mi\n       }\n     }\n \n+    /**\n+     * Do coprocessor pre-increment or pre-append call.\n+     * @return Result returned out of the coprocessor, which means bypass all further processing\n+     *   and return the proffered Result instead, or null which means proceed.\n+     */\n+    private Result doCoprocessorPreCall(Mutation mutation) throws IOException {\n+      assert mutation instanceof Increment || mutation instanceof Append;\n+      Result result = null;\n+      if (region.coprocessorHost != null) {\n+        if (mutation instanceof Increment) {\n+          result = region.coprocessorHost.preIncrementAfterRowLock((Increment) mutation);\n+        } else {\n+          result = region.coprocessorHost.preAppendAfterRowLock((Append) mutation);\n+        }\n+      }\n+      return result;\n+    }\n+\n+    private Map<byte[], List<Cell>> reckonDeltas(Mutation mutation, List<Cell> results)\n+      throws IOException {\n+      long now = EnvironmentEdgeManager.currentTime();\n+      Map<byte[], List<Cell>> ret = new HashMap<>();\n+      // Process a Store/family at a time.\n+      for (Map.Entry<byte [], List<Cell>> entry: mutation.getFamilyCellMap().entrySet()) {\n+        final byte[] columnFamilyName = entry.getKey();\n+        List<Cell> deltas = entry.getValue();\n+        // Reckon for the Store what to apply to WAL and MemStore.\n+        List<Cell> toApply = reckonDeltasByStore(region.stores.get(columnFamilyName), mutation,\n+          now, deltas, results);\n+        if (!toApply.isEmpty()) {\n+          for (Cell cell : toApply) {\n+            HStore store = region.getStore(cell);\n+            if (store == null) {\n+              region.checkFamily(CellUtil.cloneFamily(cell));\n+            } else {\n+              ret.computeIfAbsent(store.getColumnFamilyDescriptor().getName(),\n+                key -> new ArrayList<>()).add(cell);\n+            }\n+          }\n+        }\n+      }\n+      return ret;\n+    }\n+\n+    /**\n+     * Reckon the Cells to apply to WAL, memstore, and to return to the Client in passed\n+     * column family/Store.\n+     *\n+     * Does Get of current value and then adds passed in deltas for this Store returning the\n+     * result.\n+     *\n+     * @param mutation The encompassing Mutation object\n+     * @param deltas Changes to apply to this Store; either increment amount or data to append\n+     * @param results In here we accumulate all the Cells we are to return to the client. If null,\n+     *   client doesn't want results returned.\n+     * @return Resulting Cells after <code>deltas</code> have been applied to current\n+     *   values. Side effect is our filling out of the <code>results</code> List.\n+     */\n+    private List<Cell> reckonDeltasByStore(HStore store, Mutation mutation, long now,\n+      List<Cell> deltas, List<Cell> results) throws IOException {\n+      assert mutation instanceof Increment || mutation instanceof Append;\n+      byte[] columnFamily = store.getColumnFamilyDescriptor().getName();\n+      List<Pair<Cell, Cell>> cellPairs = new ArrayList<>(deltas.size());\n+\n+      // Get previous values for all columns in this family.\n+      TimeRange tr;\n+      if (mutation instanceof Increment) {\n+        tr = ((Increment) mutation).getTimeRange();\n+      } else {\n+        tr = ((Append) mutation).getTimeRange();\n+      }\n+      List<Cell> currentValues = get(mutation, store, deltas, tr);\n+\n+      // Iterate the input columns and update existing values if they were found, otherwise\n+      // add new column initialized to the delta amount\n+      int currentValuesIndex = 0;\n+      for (int i = 0; i < deltas.size(); i++) {\n+        Cell delta = deltas.get(i);\n+        Cell currentValue = null;\n+        if (currentValuesIndex < currentValues.size() &&\n+          CellUtil.matchingQualifier(currentValues.get(currentValuesIndex), delta)) {\n+          currentValue = currentValues.get(currentValuesIndex);\n+          if (i < (deltas.size() - 1) && !CellUtil.matchingQualifier(delta, deltas.get(i + 1))) {\n+            currentValuesIndex++;\n+          }\n+        }\n+        // Switch on whether this an increment or an append building the new Cell to apply.\n+        Cell newCell;\n+        if (mutation instanceof Increment) {\n+          long deltaAmount = getLongValue(delta);\n+          final long newValue = currentValue == null ?\n+            deltaAmount : getLongValue(currentValue) + deltaAmount;\n+          newCell = reckonDelta(delta, currentValue, columnFamily, now, mutation,\n+            (oldCell) -> Bytes.toBytes(newValue));\n+        } else {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fb1ba98fc05a52018b39babdec945679f358b490"}, "originalPosition": 208}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQzNTU4NQ==", "bodyText": "These were also moving existing code. Will keep this. Thanks.", "url": "https://github.com/apache/hbase/pull/2228#discussion_r470435585", "createdAt": "2020-08-14T06:31:56Z", "author": {"login": "brfrn169"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java", "diffHunk": "@@ -3805,6 +3838,196 @@ public void prepareMiniBatchOperations(MiniBatchOperationInProgress<Mutation> mi\n       }\n     }\n \n+    /**\n+     * Do coprocessor pre-increment or pre-append call.\n+     * @return Result returned out of the coprocessor, which means bypass all further processing\n+     *   and return the proffered Result instead, or null which means proceed.\n+     */\n+    private Result doCoprocessorPreCall(Mutation mutation) throws IOException {\n+      assert mutation instanceof Increment || mutation instanceof Append;\n+      Result result = null;\n+      if (region.coprocessorHost != null) {\n+        if (mutation instanceof Increment) {\n+          result = region.coprocessorHost.preIncrementAfterRowLock((Increment) mutation);\n+        } else {\n+          result = region.coprocessorHost.preAppendAfterRowLock((Append) mutation);\n+        }\n+      }\n+      return result;\n+    }\n+\n+    private Map<byte[], List<Cell>> reckonDeltas(Mutation mutation, List<Cell> results)\n+      throws IOException {\n+      long now = EnvironmentEdgeManager.currentTime();\n+      Map<byte[], List<Cell>> ret = new HashMap<>();\n+      // Process a Store/family at a time.\n+      for (Map.Entry<byte [], List<Cell>> entry: mutation.getFamilyCellMap().entrySet()) {\n+        final byte[] columnFamilyName = entry.getKey();\n+        List<Cell> deltas = entry.getValue();\n+        // Reckon for the Store what to apply to WAL and MemStore.\n+        List<Cell> toApply = reckonDeltasByStore(region.stores.get(columnFamilyName), mutation,\n+          now, deltas, results);\n+        if (!toApply.isEmpty()) {\n+          for (Cell cell : toApply) {\n+            HStore store = region.getStore(cell);\n+            if (store == null) {\n+              region.checkFamily(CellUtil.cloneFamily(cell));\n+            } else {\n+              ret.computeIfAbsent(store.getColumnFamilyDescriptor().getName(),\n+                key -> new ArrayList<>()).add(cell);\n+            }\n+          }\n+        }\n+      }\n+      return ret;\n+    }\n+\n+    /**\n+     * Reckon the Cells to apply to WAL, memstore, and to return to the Client in passed\n+     * column family/Store.\n+     *\n+     * Does Get of current value and then adds passed in deltas for this Store returning the\n+     * result.\n+     *\n+     * @param mutation The encompassing Mutation object\n+     * @param deltas Changes to apply to this Store; either increment amount or data to append\n+     * @param results In here we accumulate all the Cells we are to return to the client. If null,\n+     *   client doesn't want results returned.\n+     * @return Resulting Cells after <code>deltas</code> have been applied to current\n+     *   values. Side effect is our filling out of the <code>results</code> List.\n+     */\n+    private List<Cell> reckonDeltasByStore(HStore store, Mutation mutation, long now,\n+      List<Cell> deltas, List<Cell> results) throws IOException {\n+      assert mutation instanceof Increment || mutation instanceof Append;\n+      byte[] columnFamily = store.getColumnFamilyDescriptor().getName();\n+      List<Pair<Cell, Cell>> cellPairs = new ArrayList<>(deltas.size());\n+\n+      // Get previous values for all columns in this family.\n+      TimeRange tr;\n+      if (mutation instanceof Increment) {\n+        tr = ((Increment) mutation).getTimeRange();\n+      } else {\n+        tr = ((Append) mutation).getTimeRange();\n+      }\n+      List<Cell> currentValues = get(mutation, store, deltas, tr);\n+\n+      // Iterate the input columns and update existing values if they were found, otherwise\n+      // add new column initialized to the delta amount\n+      int currentValuesIndex = 0;\n+      for (int i = 0; i < deltas.size(); i++) {\n+        Cell delta = deltas.get(i);\n+        Cell currentValue = null;\n+        if (currentValuesIndex < currentValues.size() &&\n+          CellUtil.matchingQualifier(currentValues.get(currentValuesIndex), delta)) {\n+          currentValue = currentValues.get(currentValuesIndex);\n+          if (i < (deltas.size() - 1) && !CellUtil.matchingQualifier(delta, deltas.get(i + 1))) {\n+            currentValuesIndex++;\n+          }\n+        }\n+        // Switch on whether this an increment or an append building the new Cell to apply.\n+        Cell newCell;\n+        if (mutation instanceof Increment) {\n+          long deltaAmount = getLongValue(delta);\n+          final long newValue = currentValue == null ?\n+            deltaAmount : getLongValue(currentValue) + deltaAmount;\n+          newCell = reckonDelta(delta, currentValue, columnFamily, now, mutation,\n+            (oldCell) -> Bytes.toBytes(newValue));\n+        } else {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTM2MjQ5Nw=="}, "originalCommit": {"oid": "fb1ba98fc05a52018b39babdec945679f358b490"}, "originalPosition": 208}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkzMjgwNTU2OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java", "isResolved": false, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxNTo1OTozM1rOG_oC2g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMFQwMzoxMDoxN1rOHJfeUA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTM2OTU2Mg==", "bodyText": "You've changed the semantics here. Before, we would call preIncrement and then create a new nonce'd operation. Now, we'll always make a new nonce operation, even if the CP is about to say \"skip this increment\"\nIs that intentional?", "url": "https://github.com/apache/hbase/pull/2228#discussion_r469369562", "createdAt": "2020-08-12T15:59:33Z", "author": {"login": "joshelser"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java", "diffHunk": "@@ -742,36 +741,35 @@ private Result increment(final HRegion region, final OperationQuota quota,\n     spaceQuota.getPolicyEnforcement(region).check(increment);\n     quota.addMutation(increment);\n     Result r = null;\n-    if (region.getCoprocessorHost() != null) {\n-      r = region.getCoprocessorHost().preIncrement(increment);\n-    }\n-    if (r == null) {\n-      boolean canProceed = startNonceOperation(mutation, nonceGroup);\n-      boolean success = false;\n-      try {\n-        long nonce = mutation.hasNonce() ? mutation.getNonce() : HConstants.NO_NONCE;\n-        if (canProceed) {\n-          r = region.increment(increment, nonceGroup, nonce);\n-        } else {\n+    boolean canProceed = startNonceOperation(mutation, nonceGroup);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fb1ba98fc05a52018b39babdec945679f358b490"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM3NDUxNA==", "bodyText": "Yes, I changed the semantics. This is because we call preIncrement in region.increment() after this change. I don't think this change breaks anything, but it just changes the order of preIncrement and the nonce operation. What do you think?", "url": "https://github.com/apache/hbase/pull/2228#discussion_r470374514", "createdAt": "2020-08-14T02:22:46Z", "author": {"login": "brfrn169"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java", "diffHunk": "@@ -742,36 +741,35 @@ private Result increment(final HRegion region, final OperationQuota quota,\n     spaceQuota.getPolicyEnforcement(region).check(increment);\n     quota.addMutation(increment);\n     Result r = null;\n-    if (region.getCoprocessorHost() != null) {\n-      r = region.getCoprocessorHost().preIncrement(increment);\n-    }\n-    if (r == null) {\n-      boolean canProceed = startNonceOperation(mutation, nonceGroup);\n-      boolean success = false;\n-      try {\n-        long nonce = mutation.hasNonce() ? mutation.getNonce() : HConstants.NO_NONCE;\n-        if (canProceed) {\n-          r = region.increment(increment, nonceGroup, nonce);\n-        } else {\n+    boolean canProceed = startNonceOperation(mutation, nonceGroup);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTM2OTU2Mg=="}, "originalCommit": {"oid": "fb1ba98fc05a52018b39babdec945679f358b490"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA5ODQ2Mw==", "bodyText": "I think this is a behavior change. We need to make it clear and then we could say whether it is OK. In general, call startNonceOperation will store a new entry in ServerNonceManager, and it will effect the later retries.", "url": "https://github.com/apache/hbase/pull/2228#discussion_r475098463", "createdAt": "2020-08-22T14:52:58Z", "author": {"login": "Apache9"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java", "diffHunk": "@@ -742,36 +741,35 @@ private Result increment(final HRegion region, final OperationQuota quota,\n     spaceQuota.getPolicyEnforcement(region).check(increment);\n     quota.addMutation(increment);\n     Result r = null;\n-    if (region.getCoprocessorHost() != null) {\n-      r = region.getCoprocessorHost().preIncrement(increment);\n-    }\n-    if (r == null) {\n-      boolean canProceed = startNonceOperation(mutation, nonceGroup);\n-      boolean success = false;\n-      try {\n-        long nonce = mutation.hasNonce() ? mutation.getNonce() : HConstants.NO_NONCE;\n-        if (canProceed) {\n-          r = region.increment(increment, nonceGroup, nonce);\n-        } else {\n+    boolean canProceed = startNonceOperation(mutation, nonceGroup);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTM2OTU2Mg=="}, "originalCommit": {"oid": "fb1ba98fc05a52018b39babdec945679f358b490"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTIyOTAwOA==", "bodyText": "Thank you for taking a look at this! @Apache9\nLet me clarify this.\nThe pseudo codes of before and after the change are as follows:\nThe pseudo code before the change:\nr = preIncrement(increment)\nif (r == null) {\n  canProceed = startNonceOperation()\n\n  if (canProceed) {\n    // Process increment...\n    r = ...\n  } else {\n    // Get the incremented cells...\n    r = ...\n  }\n\n  r = postIncrement(increment, r)\n\n  if (canProceed) {\n    endNonceOperation()\n  }\n}\n\nreturn r;\n\nThe pseudo code after the change:\ncanProceed = startNonceOperation()\n\nif (canProceed) {\n  // The following logic is actually executed in HRegion.batchMutate()\n  r = preIncrement(increment)\n  if (r != null) {\n    // Process increment...\n    r = ...\n\n    r = postIncrement(increment, r)\n  }\n} else {\n  r = preIncrement(increment)\n  if (r != null) {\n    // Get the incremented cells...\n    r = ...\n\n    r = postIncrement(increment, r)\n  }\n}\n\nif (canProceed) {\n  endNonceOperation()\n}\n\nreturn r\n\nI think we can discuss two cases when we don't set any RegionObserver or not.\nThe case when we don't set any RegionObserver (preIncrement() always returns null)\nThe behavior of the code before the change when startNonceOperation() returns true:\n\nr = preIncrement(increment) -> This returns null\ncanProceed = startNonceOperation() -> This returns true\n// Process increment...\nr = postIncrement(increment, r)\nendNonceOperation()\nreturn r\n\nThe behavior of the code before the change when startNonceOperation() returns false:\n\nr = preIncrement(increment) -> This returns null\ncanProceed = startNonceOperation() -> This returns false\n// Get the incremented cells...\nr = postIncrement(increment, r)\nreturn r\n\nThe behavior of the code after the change when startNonceOperation() returns true:\n\ncanProceed = startNonceOperation() -> This returns true\nr = preIncrement(increment) -> This returns null\n// Process increment...\nr = postIncrement(increment, r)\nendNonceOperation()\nreturn r\n\nThe behavior of the code after the change when startNonceOperation() returns false:\n\ncanProceed = startNonceOperation() -> This returns false\nr = preIncrement(increment) -> This returns null\n// Get the incremented cells...\nr = postIncrement(increment, r)\nreturn r\n\nI don't think the behaviors in this case are essentially changed.\nThe case when we set RegionObserver with implementing preIncrement()\nThe behavior of the code before the change:\n\nr = preIncrement(increment) -> This returns a non-null value\nreturn r\n\nThe behavior of the code after the change when startNonceOperation() returns true:\n\ncanProceed = startNonceOperation() -> This returns true\nr = preIncrement(increment) -> This returns a non-null value\nendNonceOperation()\nreturn r\n\nThe behavior of the code after the change when startNonceOperation() returns false:\n\ncanProceed = startNonceOperation() -> This returns false\nr = preIncrement(increment)  -> This returns a non-null value\nreturn r\n\nThe behaviors in this case are a bit changed. After the change, we always call startNonceOperation(). However, I don't think that affects the result itself and when we don't set any RegionObserver, we always call startNonceOperation(), too. So I don't think it's a big problem.\nWhat do you think? Thanks.", "url": "https://github.com/apache/hbase/pull/2228#discussion_r475229008", "createdAt": "2020-08-23T14:54:00Z", "author": {"login": "brfrn169"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java", "diffHunk": "@@ -742,36 +741,35 @@ private Result increment(final HRegion region, final OperationQuota quota,\n     spaceQuota.getPolicyEnforcement(region).check(increment);\n     quota.addMutation(increment);\n     Result r = null;\n-    if (region.getCoprocessorHost() != null) {\n-      r = region.getCoprocessorHost().preIncrement(increment);\n-    }\n-    if (r == null) {\n-      boolean canProceed = startNonceOperation(mutation, nonceGroup);\n-      boolean success = false;\n-      try {\n-        long nonce = mutation.hasNonce() ? mutation.getNonce() : HConstants.NO_NONCE;\n-        if (canProceed) {\n-          r = region.increment(increment, nonceGroup, nonce);\n-        } else {\n+    boolean canProceed = startNonceOperation(mutation, nonceGroup);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTM2OTU2Mg=="}, "originalCommit": {"oid": "fb1ba98fc05a52018b39babdec945679f358b490"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODc3MDU1MQ==", "bodyText": "Ping @Apache9 and @joshelser. Thanks.", "url": "https://github.com/apache/hbase/pull/2228#discussion_r478770551", "createdAt": "2020-08-28T00:47:24Z", "author": {"login": "brfrn169"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java", "diffHunk": "@@ -742,36 +741,35 @@ private Result increment(final HRegion region, final OperationQuota quota,\n     spaceQuota.getPolicyEnforcement(region).check(increment);\n     quota.addMutation(increment);\n     Result r = null;\n-    if (region.getCoprocessorHost() != null) {\n-      r = region.getCoprocessorHost().preIncrement(increment);\n-    }\n-    if (r == null) {\n-      boolean canProceed = startNonceOperation(mutation, nonceGroup);\n-      boolean success = false;\n-      try {\n-        long nonce = mutation.hasNonce() ? mutation.getNonce() : HConstants.NO_NONCE;\n-        if (canProceed) {\n-          r = region.increment(increment, nonceGroup, nonce);\n-        } else {\n+    boolean canProceed = startNonceOperation(mutation, nonceGroup);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTM2OTU2Mg=="}, "originalCommit": {"oid": "fb1ba98fc05a52018b39babdec945679f358b490"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTcxNDg5Ng==", "bodyText": "I will modify the patch to keep the behavior of the nonce operations. Thanks.", "url": "https://github.com/apache/hbase/pull/2228#discussion_r479714896", "createdAt": "2020-08-30T03:10:17Z", "author": {"login": "brfrn169"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java", "diffHunk": "@@ -742,36 +741,35 @@ private Result increment(final HRegion region, final OperationQuota quota,\n     spaceQuota.getPolicyEnforcement(region).check(increment);\n     quota.addMutation(increment);\n     Result r = null;\n-    if (region.getCoprocessorHost() != null) {\n-      r = region.getCoprocessorHost().preIncrement(increment);\n-    }\n-    if (r == null) {\n-      boolean canProceed = startNonceOperation(mutation, nonceGroup);\n-      boolean success = false;\n-      try {\n-        long nonce = mutation.hasNonce() ? mutation.getNonce() : HConstants.NO_NONCE;\n-        if (canProceed) {\n-          r = region.increment(increment, nonceGroup, nonce);\n-        } else {\n+    boolean canProceed = startNonceOperation(mutation, nonceGroup);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTM2OTU2Mg=="}, "originalCommit": {"oid": "fb1ba98fc05a52018b39babdec945679f358b490"}, "originalPosition": 77}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkzMjgxNzU4OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxNjowMjozOVrOG_oKrA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQwNzoxMzozMlrOHAqB0g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTM3MTU2NA==", "bodyText": "Is it more optimal to check for the single action case? What does this get us over the previous method of using the \"collection of Actions\" method even if we only have a single action?", "url": "https://github.com/apache/hbase/pull/2228#discussion_r469371564", "createdAt": "2020-08-12T16:02:39Z", "author": {"login": "joshelser"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java", "diffHunk": "@@ -2910,23 +2908,35 @@ public MultiResponse multi(final RpcController rpcc, final MultiRequest request)\n           }\n \n           try {\n-            CheckAndMutateResult result = checkAndMutate(region, regionAction.getActionList(),\n-              cellScanner, regionAction.getCondition(), spaceQuotaEnforcement);\n-            regionActionResultBuilder.setProcessed(result.isSuccess());\n             ClientProtos.ResultOrException.Builder resultOrExceptionOrBuilder =\n               ClientProtos.ResultOrException.newBuilder();\n-            for (int i = 0; i < regionAction.getActionCount(); i++) {\n-              if (i == 0 && result.getResult() != null) {\n-                resultOrExceptionOrBuilder.setIndex(i);\n-                regionActionResultBuilder.addResultOrException(resultOrExceptionOrBuilder\n-                  .setResult(ProtobufUtil.toResult(result.getResult())).build());\n-                continue;\n+            if (regionAction.getActionCount() == 1) {\n+              CheckAndMutateResult result = checkAndMutate(region, quota,\n+                regionAction.getAction(0).getMutation(), cellScanner,\n+                regionAction.getCondition(), spaceQuotaEnforcement);\n+              regionActionResultBuilder.setProcessed(result.isSuccess());\n+              resultOrExceptionOrBuilder.setIndex(0);\n+              if (result.getResult() != null) {\n+                resultOrExceptionOrBuilder.setResult(ProtobufUtil.toResult(result.getResult()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fb1ba98fc05a52018b39babdec945679f358b490"}, "originalPosition": 140}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQ1MDY0Mg==", "bodyText": "Actually, this change supports a CheckAndMutate operation only with a single Increment/Append. That's why I needed the if statement to check whether a single action or not. BTW, I'm going to handle CheckAndMutate operations with multiple Increments/Appends in HBASE-24210.", "url": "https://github.com/apache/hbase/pull/2228#discussion_r470450642", "createdAt": "2020-08-14T07:13:32Z", "author": {"login": "brfrn169"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java", "diffHunk": "@@ -2910,23 +2908,35 @@ public MultiResponse multi(final RpcController rpcc, final MultiRequest request)\n           }\n \n           try {\n-            CheckAndMutateResult result = checkAndMutate(region, regionAction.getActionList(),\n-              cellScanner, regionAction.getCondition(), spaceQuotaEnforcement);\n-            regionActionResultBuilder.setProcessed(result.isSuccess());\n             ClientProtos.ResultOrException.Builder resultOrExceptionOrBuilder =\n               ClientProtos.ResultOrException.newBuilder();\n-            for (int i = 0; i < regionAction.getActionCount(); i++) {\n-              if (i == 0 && result.getResult() != null) {\n-                resultOrExceptionOrBuilder.setIndex(i);\n-                regionActionResultBuilder.addResultOrException(resultOrExceptionOrBuilder\n-                  .setResult(ProtobufUtil.toResult(result.getResult())).build());\n-                continue;\n+            if (regionAction.getActionCount() == 1) {\n+              CheckAndMutateResult result = checkAndMutate(region, quota,\n+                regionAction.getAction(0).getMutation(), cellScanner,\n+                regionAction.getCondition(), spaceQuotaEnforcement);\n+              regionActionResultBuilder.setProcessed(result.isSuccess());\n+              resultOrExceptionOrBuilder.setIndex(0);\n+              if (result.getResult() != null) {\n+                resultOrExceptionOrBuilder.setResult(ProtobufUtil.toResult(result.getResult()));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTM3MTU2NA=="}, "originalCommit": {"oid": "fb1ba98fc05a52018b39babdec945679f358b490"}, "originalPosition": 140}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkzMjg0MjY1OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestAsyncTable.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxNjowODo1OFrOG_oaeg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQwNjozNTozOVrOHApL0A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTM3NTYxMA==", "bodyText": "Can I send multiple CheckAndMutate's (each with their own Increment or Append) to the same row in one batch?", "url": "https://github.com/apache/hbase/pull/2228#discussion_r469375610", "createdAt": "2020-08-12T16:08:58Z", "author": {"login": "joshelser"}, "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestAsyncTable.java", "diffHunk": "@@ -1282,6 +1438,80 @@ public void testCheckAndMutateBatchWithFilterAndTimeRange() throws Throwable {\n     assertEquals(\"f\", Bytes.toString(result.getValue(FAMILY, Bytes.toBytes(\"F\"))));\n   }\n \n+  @Test\n+  public void testCheckAndIncrementBatch() throws Throwable {\n+    AsyncTable<?> table = getTable.get();\n+    byte[] row2 = Bytes.toBytes(Bytes.toString(row) + \"2\");\n+\n+    table.putAll(Arrays.asList(\n+      new Put(row).addColumn(FAMILY, Bytes.toBytes(\"A\"), Bytes.toBytes(\"a\"))\n+        .addColumn(FAMILY, Bytes.toBytes(\"B\"), Bytes.toBytes(0L)),\n+      new Put(row2).addColumn(FAMILY, Bytes.toBytes(\"C\"), Bytes.toBytes(\"c\"))\n+        .addColumn(FAMILY, Bytes.toBytes(\"D\"), Bytes.toBytes(0L)))).get();\n+\n+    // CheckAndIncrement with correct value\n+    CheckAndMutate checkAndMutate1 = CheckAndMutate.newBuilder(row)\n+      .ifEquals(FAMILY, Bytes.toBytes(\"A\"), Bytes.toBytes(\"a\"))\n+      .build(new Increment(row).addColumn(FAMILY, Bytes.toBytes(\"B\"), 1));\n+\n+    // CheckAndIncrement with wrong value\n+    CheckAndMutate checkAndMutate2 = CheckAndMutate.newBuilder(row2)\n+      .ifEquals(FAMILY, Bytes.toBytes(\"C\"), Bytes.toBytes(\"d\"))\n+      .build(new Increment(row2).addColumn(FAMILY, Bytes.toBytes(\"D\"), 1));\n+\n+    List<CheckAndMutateResult> results =\n+      table.checkAndMutateAll(Arrays.asList(checkAndMutate1, checkAndMutate2)).get();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fb1ba98fc05a52018b39babdec945679f358b490"}, "originalPosition": 416}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQzNjgxNg==", "bodyText": "No for now. I'm going to handle that case in HBASE-24210.", "url": "https://github.com/apache/hbase/pull/2228#discussion_r470436816", "createdAt": "2020-08-14T06:35:39Z", "author": {"login": "brfrn169"}, "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestAsyncTable.java", "diffHunk": "@@ -1282,6 +1438,80 @@ public void testCheckAndMutateBatchWithFilterAndTimeRange() throws Throwable {\n     assertEquals(\"f\", Bytes.toString(result.getValue(FAMILY, Bytes.toBytes(\"F\"))));\n   }\n \n+  @Test\n+  public void testCheckAndIncrementBatch() throws Throwable {\n+    AsyncTable<?> table = getTable.get();\n+    byte[] row2 = Bytes.toBytes(Bytes.toString(row) + \"2\");\n+\n+    table.putAll(Arrays.asList(\n+      new Put(row).addColumn(FAMILY, Bytes.toBytes(\"A\"), Bytes.toBytes(\"a\"))\n+        .addColumn(FAMILY, Bytes.toBytes(\"B\"), Bytes.toBytes(0L)),\n+      new Put(row2).addColumn(FAMILY, Bytes.toBytes(\"C\"), Bytes.toBytes(\"c\"))\n+        .addColumn(FAMILY, Bytes.toBytes(\"D\"), Bytes.toBytes(0L)))).get();\n+\n+    // CheckAndIncrement with correct value\n+    CheckAndMutate checkAndMutate1 = CheckAndMutate.newBuilder(row)\n+      .ifEquals(FAMILY, Bytes.toBytes(\"A\"), Bytes.toBytes(\"a\"))\n+      .build(new Increment(row).addColumn(FAMILY, Bytes.toBytes(\"B\"), 1));\n+\n+    // CheckAndIncrement with wrong value\n+    CheckAndMutate checkAndMutate2 = CheckAndMutate.newBuilder(row2)\n+      .ifEquals(FAMILY, Bytes.toBytes(\"C\"), Bytes.toBytes(\"d\"))\n+      .build(new Increment(row2).addColumn(FAMILY, Bytes.toBytes(\"D\"), 1));\n+\n+    List<CheckAndMutateResult> results =\n+      table.checkAndMutateAll(Arrays.asList(checkAndMutate1, checkAndMutate2)).get();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTM3NTYxMA=="}, "originalCommit": {"oid": "fb1ba98fc05a52018b39babdec945679f358b490"}, "originalPosition": 416}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2638, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}