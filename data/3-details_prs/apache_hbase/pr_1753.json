{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDIxNDI0OTI0", "number": 1753, "title": "HBASE-24408 Introduce a general 'local region' to store data on master", "bodyText": "", "createdAt": "2020-05-21T15:34:15Z", "url": "https://github.com/apache/hbase/pull/1753", "merged": true, "mergeCommit": {"oid": "c303f9d329d578d31140e507bdbcbe3aa097042b"}, "closed": true, "closedAt": "2020-05-23T07:59:51Z", "author": {"login": "Apache9"}, "timelineItems": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcjmdoDgBqjMzNjI3MTE5NDA=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcmLNMJAFqTQyMTM0OTcwMg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "6111f5aa725d3d8b6cd4c80a5b3ccafb6be5f7ab", "author": {"user": {"login": "Apache9", "name": "Duo Zhang"}}, "url": "https://github.com/apache/hbase/commit/6111f5aa725d3d8b6cd4c80a5b3ccafb6be5f7ab", "committedDate": "2020-05-21T15:32:53Z", "message": "HBAE-24408 Introduce a general 'local region' to store data on master"}, "afterCommit": {"oid": "b5ecafb52606eee213d26073237598a04d7736f6", "author": {"user": {"login": "Apache9", "name": "Duo Zhang"}}, "url": "https://github.com/apache/hbase/commit/b5ecafb52606eee213d26073237598a04d7736f6", "committedDate": "2020-05-21T23:38:52Z", "message": "HBAE-24408 Introduce a general 'local region' to store data on master"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE2NjM1ODUy", "url": "https://github.com/apache/hbase/pull/1753#pullrequestreview-416635852", "createdAt": "2020-05-22T04:09:54Z", "commit": {"oid": "b5ecafb52606eee213d26073237598a04d7736f6"}, "state": "COMMENTED", "comments": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQwNDowOTo1NFrOGZKE_w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQwNDozNzoyM1rOGZKbFA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzMjcwMw==", "bodyText": "Great", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429032703", "createdAt": "2020-05-22T04:09:54Z", "author": {"login": "saintstack"}, "path": "hbase-common/src/main/resources/hbase-default.xml", "diffHunk": "@@ -139,16 +139,9 @@ possible configurations would overwhelm and obscure the important.\n     <description>How long a WAL remain in the archive ({hbase.rootdir}/oldWALs) directory,\n     after which it will be cleaned by a Master thread. The value is in milliseconds.</description>\n   </property>\n-  <property>\n-    <name>hbase.master.procedurewalcleaner.ttl</name>\n-    <value>604800000</value>\n-    <description>How long a Procedure WAL will remain in the\n-    archive directory, after which it will be cleaned\n-    by a Master thread. The value is in milliseconds.</description>\n-  </property>\n   <property>\n     <name>hbase.master.hfilecleaner.plugins</name>\n-    <value>org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner</value>\n+    <value>org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner,org.apache.hadoop.hbase.master.cleaner.TimeToLiveMasterLocalStoreHFileCleaner</value>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b5ecafb52606eee213d26073237598a04d7736f6"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzMjkwNQ==", "bodyText": "We want the procedureWALCleaner here still ? Different from the general master local store cleaner?", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429032905", "createdAt": "2020-05-22T04:10:49Z", "author": {"login": "saintstack"}, "path": "hbase-common/src/main/resources/hbase-default.xml", "diffHunk": "@@ -125,7 +125,7 @@ possible configurations would overwhelm and obscure the important.\n   </property>\n   <property>\n     <name>hbase.master.logcleaner.plugins</name>\n-    <value>org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner,org.apache.hadoop.hbase.master.cleaner.TimeToLiveProcedureWALCleaner</value>\n+    <value>org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner,org.apache.hadoop.hbase.master.cleaner.TimeToLiveProcedureWALCleaner,org.apache.hadoop.hbase.master.cleaner.TimeToLiveMasterLocalStoreWALCleaner</value>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b5ecafb52606eee213d26073237598a04d7736f6"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzMzA1OA==", "bodyText": "Need to be volatile?", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429033058", "createdAt": "2020-05-22T04:11:33Z", "author": {"login": "saintstack"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/cleaner/BaseTimeToLiveFileCleaner.java", "diffHunk": "@@ -0,0 +1,92 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.master.cleaner;\n+\n+import java.time.Instant;\n+import java.time.ZoneOffset;\n+import java.time.format.DateTimeFormatter;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Base class for time to live file cleaner.\n+ */\n+@InterfaceAudience.Private\n+public abstract class BaseTimeToLiveFileCleaner extends BaseLogCleanerDelegate {\n+\n+  private static final Logger LOG =\n+    LoggerFactory.getLogger(BaseTimeToLiveFileCleaner.class.getName());\n+\n+  private static final DateTimeFormatter FORMATTER =\n+    DateTimeFormatter.ISO_DATE_TIME.withZone(ZoneOffset.systemDefault());\n+\n+  // Configured time a log can be kept after it was closed\n+  private long ttlMs;\n+\n+  private boolean stopped = false;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b5ecafb52606eee213d26073237598a04d7736f6"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzMzE5OQ==", "bodyText": "s/valiate/validate/", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429033199", "createdAt": "2020-05-22T04:12:07Z", "author": {"login": "saintstack"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/cleaner/BaseTimeToLiveFileCleaner.java", "diffHunk": "@@ -0,0 +1,92 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.master.cleaner;\n+\n+import java.time.Instant;\n+import java.time.ZoneOffset;\n+import java.time.format.DateTimeFormatter;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Base class for time to live file cleaner.\n+ */\n+@InterfaceAudience.Private\n+public abstract class BaseTimeToLiveFileCleaner extends BaseLogCleanerDelegate {\n+\n+  private static final Logger LOG =\n+    LoggerFactory.getLogger(BaseTimeToLiveFileCleaner.class.getName());\n+\n+  private static final DateTimeFormatter FORMATTER =\n+    DateTimeFormatter.ISO_DATE_TIME.withZone(ZoneOffset.systemDefault());\n+\n+  // Configured time a log can be kept after it was closed\n+  private long ttlMs;\n+\n+  private boolean stopped = false;\n+\n+  @Override\n+  public final void setConf(Configuration conf) {\n+    super.setConf(conf);\n+    this.ttlMs = getTtlMs(conf);\n+  }\n+\n+  @Override\n+  public boolean isFileDeletable(FileStatus status) {\n+    // Files are validated for the second time here,\n+    // if it causes a bottleneck this logic needs refactored\n+    if (!valiateFilename(status.getPath())) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b5ecafb52606eee213d26073237598a04d7736f6"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzMzM2OQ==", "bodyText": "Someone logs the 'why'?", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429033369", "createdAt": "2020-05-22T04:12:52Z", "author": {"login": "saintstack"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/cleaner/BaseTimeToLiveFileCleaner.java", "diffHunk": "@@ -0,0 +1,92 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.master.cleaner;\n+\n+import java.time.Instant;\n+import java.time.ZoneOffset;\n+import java.time.format.DateTimeFormatter;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Base class for time to live file cleaner.\n+ */\n+@InterfaceAudience.Private\n+public abstract class BaseTimeToLiveFileCleaner extends BaseLogCleanerDelegate {\n+\n+  private static final Logger LOG =\n+    LoggerFactory.getLogger(BaseTimeToLiveFileCleaner.class.getName());\n+\n+  private static final DateTimeFormatter FORMATTER =\n+    DateTimeFormatter.ISO_DATE_TIME.withZone(ZoneOffset.systemDefault());\n+\n+  // Configured time a log can be kept after it was closed\n+  private long ttlMs;\n+\n+  private boolean stopped = false;\n+\n+  @Override\n+  public final void setConf(Configuration conf) {\n+    super.setConf(conf);\n+    this.ttlMs = getTtlMs(conf);\n+  }\n+\n+  @Override\n+  public boolean isFileDeletable(FileStatus status) {\n+    // Files are validated for the second time here,\n+    // if it causes a bottleneck this logic needs refactored\n+    if (!valiateFilename(status.getPath())) {\n+      return true;\n+    }\n+    long currentTime = EnvironmentEdgeManager.currentTime();\n+    long time = status.getModificationTime();\n+    long life = currentTime - time;\n+\n+    if (LOG.isTraceEnabled()) {\n+      LOG.trace(\"File life:{}ms, ttl:{}ms, current:{}, from{}\", life, ttlMs,\n+        FORMATTER.format(Instant.ofEpochMilli(currentTime)),\n+        FORMATTER.format(Instant.ofEpochMilli(time)));\n+    }\n+    if (life < 0) {\n+      LOG.warn(\"Found a file ({}) newer than current time ({} < {}), probably a clock skew\",\n+        status.getPath(), FORMATTER.format(Instant.ofEpochMilli(currentTime)),\n+        FORMATTER.format(Instant.ofEpochMilli(time)));\n+      return false;\n+    }\n+    return life > ttlMs;\n+  }\n+\n+  @Override\n+  public void stop(String why) {\n+    this.stopped = true;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b5ecafb52606eee213d26073237598a04d7736f6"}, "originalPosition": 81}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzMzQzNg==", "bodyText": "Maybe it is not important enough to log.", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429033436", "createdAt": "2020-05-22T04:13:06Z", "author": {"login": "saintstack"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/cleaner/BaseTimeToLiveFileCleaner.java", "diffHunk": "@@ -0,0 +1,92 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.master.cleaner;\n+\n+import java.time.Instant;\n+import java.time.ZoneOffset;\n+import java.time.format.DateTimeFormatter;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Base class for time to live file cleaner.\n+ */\n+@InterfaceAudience.Private\n+public abstract class BaseTimeToLiveFileCleaner extends BaseLogCleanerDelegate {\n+\n+  private static final Logger LOG =\n+    LoggerFactory.getLogger(BaseTimeToLiveFileCleaner.class.getName());\n+\n+  private static final DateTimeFormatter FORMATTER =\n+    DateTimeFormatter.ISO_DATE_TIME.withZone(ZoneOffset.systemDefault());\n+\n+  // Configured time a log can be kept after it was closed\n+  private long ttlMs;\n+\n+  private boolean stopped = false;\n+\n+  @Override\n+  public final void setConf(Configuration conf) {\n+    super.setConf(conf);\n+    this.ttlMs = getTtlMs(conf);\n+  }\n+\n+  @Override\n+  public boolean isFileDeletable(FileStatus status) {\n+    // Files are validated for the second time here,\n+    // if it causes a bottleneck this logic needs refactored\n+    if (!valiateFilename(status.getPath())) {\n+      return true;\n+    }\n+    long currentTime = EnvironmentEdgeManager.currentTime();\n+    long time = status.getModificationTime();\n+    long life = currentTime - time;\n+\n+    if (LOG.isTraceEnabled()) {\n+      LOG.trace(\"File life:{}ms, ttl:{}ms, current:{}, from{}\", life, ttlMs,\n+        FORMATTER.format(Instant.ofEpochMilli(currentTime)),\n+        FORMATTER.format(Instant.ofEpochMilli(time)));\n+    }\n+    if (life < 0) {\n+      LOG.warn(\"Found a file ({}) newer than current time ({} < {}), probably a clock skew\",\n+        status.getPath(), FORMATTER.format(Instant.ofEpochMilli(currentTime)),\n+        FORMATTER.format(Instant.ofEpochMilli(time)));\n+      return false;\n+    }\n+    return life > ttlMs;\n+  }\n+\n+  @Override\n+  public void stop(String why) {\n+    this.stopped = true;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzMzM2OQ=="}, "originalCommit": {"oid": "b5ecafb52606eee213d26073237598a04d7736f6"}, "originalPosition": 81}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzMzg4NA==", "bodyText": "Man, we should have called this file the WALCleaner, not LogCleaner. Not your fault.", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429033884", "createdAt": "2020-05-22T04:15:19Z", "author": {"login": "saintstack"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/cleaner/LogCleaner.java", "diffHunk": "@@ -86,8 +87,9 @@ public LogCleaner(final int period, final Stoppable stopper, Configuration conf,\n \n   @Override\n   protected boolean validate(Path file) {\n-    return AbstractFSWALProvider.validateWALFilename(file.getName())\n-        || MasterProcedureUtil.validateProcedureWALFilename(file.getName());\n+    return AbstractFSWALProvider.validateWALFilename(file.getName()) ||\n+      MasterProcedureUtil.validateProcedureWALFilename(file.getName()) ||\n+      file.getName().endsWith(LocalStore.ARCHIVED_WAL_SUFFIX);\n   }\n \n   @Override", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b5ecafb52606eee213d26073237598a04d7736f6"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzNDE1MA==", "bodyText": "Why a second time? Just-in-case? Can you say why we do it twice in comment? What you are afraid of?", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429034150", "createdAt": "2020-05-22T04:16:40Z", "author": {"login": "saintstack"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/cleaner/BaseTimeToLiveFileCleaner.java", "diffHunk": "@@ -0,0 +1,92 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.master.cleaner;\n+\n+import java.time.Instant;\n+import java.time.ZoneOffset;\n+import java.time.format.DateTimeFormatter;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Base class for time to live file cleaner.\n+ */\n+@InterfaceAudience.Private\n+public abstract class BaseTimeToLiveFileCleaner extends BaseLogCleanerDelegate {\n+\n+  private static final Logger LOG =\n+    LoggerFactory.getLogger(BaseTimeToLiveFileCleaner.class.getName());\n+\n+  private static final DateTimeFormatter FORMATTER =\n+    DateTimeFormatter.ISO_DATE_TIME.withZone(ZoneOffset.systemDefault());\n+\n+  // Configured time a log can be kept after it was closed\n+  private long ttlMs;\n+\n+  private boolean stopped = false;\n+\n+  @Override\n+  public final void setConf(Configuration conf) {\n+    super.setConf(conf);\n+    this.ttlMs = getTtlMs(conf);\n+  }\n+\n+  @Override\n+  public boolean isFileDeletable(FileStatus status) {\n+    // Files are validated for the second time here,\n+    // if it causes a bottleneck this logic needs refactored\n+    if (!valiateFilename(status.getPath())) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzMzE5OQ=="}, "originalCommit": {"oid": "b5ecafb52606eee213d26073237598a04d7736f6"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzNTI0Mw==", "bodyText": "Whats this?", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429035243", "createdAt": "2020-05-22T04:22:06Z", "author": {"login": "saintstack"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/store/LocalRegion.java", "diffHunk": "@@ -0,0 +1,325 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.master.store;\n+\n+import static org.apache.hadoop.hbase.HConstants.HREGION_LOGDIR_NAME;\n+\n+import java.io.IOException;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hbase.HBaseIOException;\n+import org.apache.hadoop.hbase.Server;\n+import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.Get;\n+import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.RegionInfoBuilder;\n+import org.apache.hadoop.hbase.client.Result;\n+import org.apache.hadoop.hbase.client.Scan;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.regionserver.HRegion;\n+import org.apache.hadoop.hbase.regionserver.HRegion.FlushResult;\n+import org.apache.hadoop.hbase.regionserver.HRegionFileSystem;\n+import org.apache.hadoop.hbase.regionserver.RegionScanner;\n+import org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL;\n+import org.apache.hadoop.hbase.util.Bytes;\n+import org.apache.hadoop.hbase.util.CommonFSUtils;\n+import org.apache.hadoop.hbase.util.FSUtils;\n+import org.apache.hadoop.hbase.util.HFileArchiveUtil;\n+import org.apache.hadoop.hbase.util.RecoverLeaseFSUtils;\n+import org.apache.hadoop.hbase.wal.AbstractFSWALProvider;\n+import org.apache.hadoop.hbase.wal.WAL;\n+import org.apache.hadoop.hbase.wal.WALFactory;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hbase.thirdparty.com.google.common.annotations.VisibleForTesting;\n+import org.apache.hbase.thirdparty.com.google.common.math.IntMath;\n+\n+/**\n+ * A region that stores data in a separated directory.\n+ * <p/>\n+ * FileSystem layout:\n+ *\n+ * <pre>\n+ * hbase\n+ *   |\n+ *   --&lt;region dir&gt;\n+ *       |\n+ *       --data\n+ *       |  |\n+ *       |  --/&lt;ns&gt/&lt;table&gt/&lt;encoded-region-name&gt; <---- The region data\n+ *       |      |\n+ *       |      --replay <---- The edits to replay\n+ *       |\n+ *       --WALs\n+ *          |\n+ *          --&lt;master-server-name&gt; <---- The WAL dir for active master\n+ *          |\n+ *          --&lt;master-server-name&gt;-dead <---- The WAL dir for dead master\n+ * </pre>\n+ *\n+ * Notice that, you can use different root file system and WAL file system. Then the above directory\n+ * will be on two file systems, the root file system will have the data directory while the WAL\n+ * filesystem will have the WALs directory. The archived HFile will be moved to the global HFile\n+ * archived directory with the {@link LocalRegionParams#archivedWalSuffix()} suffix. The archived\n+ * WAL will be moved to the global WAL archived directory with the\n+ * {@link LocalRegionParams#archivedHFileSuffix()} suffix.\n+ */\n+@InterfaceAudience.Private\n+public final class LocalRegion {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(LocalRegion.class);\n+\n+  private static final String REPLAY_EDITS_DIR = \"recovered.wals\";\n+\n+  private static final String DEAD_WAL_DIR_SUFFIX = \"-dead\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b5ecafb52606eee213d26073237598a04d7736f6"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzNTI4MQ==", "bodyText": "What goes here?", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429035281", "createdAt": "2020-05-22T04:22:18Z", "author": {"login": "saintstack"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/store/LocalRegion.java", "diffHunk": "@@ -0,0 +1,325 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.master.store;\n+\n+import static org.apache.hadoop.hbase.HConstants.HREGION_LOGDIR_NAME;\n+\n+import java.io.IOException;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hbase.HBaseIOException;\n+import org.apache.hadoop.hbase.Server;\n+import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.Get;\n+import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.RegionInfoBuilder;\n+import org.apache.hadoop.hbase.client.Result;\n+import org.apache.hadoop.hbase.client.Scan;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.regionserver.HRegion;\n+import org.apache.hadoop.hbase.regionserver.HRegion.FlushResult;\n+import org.apache.hadoop.hbase.regionserver.HRegionFileSystem;\n+import org.apache.hadoop.hbase.regionserver.RegionScanner;\n+import org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL;\n+import org.apache.hadoop.hbase.util.Bytes;\n+import org.apache.hadoop.hbase.util.CommonFSUtils;\n+import org.apache.hadoop.hbase.util.FSUtils;\n+import org.apache.hadoop.hbase.util.HFileArchiveUtil;\n+import org.apache.hadoop.hbase.util.RecoverLeaseFSUtils;\n+import org.apache.hadoop.hbase.wal.AbstractFSWALProvider;\n+import org.apache.hadoop.hbase.wal.WAL;\n+import org.apache.hadoop.hbase.wal.WALFactory;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hbase.thirdparty.com.google.common.annotations.VisibleForTesting;\n+import org.apache.hbase.thirdparty.com.google.common.math.IntMath;\n+\n+/**\n+ * A region that stores data in a separated directory.\n+ * <p/>\n+ * FileSystem layout:\n+ *\n+ * <pre>\n+ * hbase\n+ *   |\n+ *   --&lt;region dir&gt;\n+ *       |\n+ *       --data\n+ *       |  |\n+ *       |  --/&lt;ns&gt/&lt;table&gt/&lt;encoded-region-name&gt; <---- The region data\n+ *       |      |\n+ *       |      --replay <---- The edits to replay\n+ *       |\n+ *       --WALs\n+ *          |\n+ *          --&lt;master-server-name&gt; <---- The WAL dir for active master\n+ *          |\n+ *          --&lt;master-server-name&gt;-dead <---- The WAL dir for dead master\n+ * </pre>\n+ *\n+ * Notice that, you can use different root file system and WAL file system. Then the above directory\n+ * will be on two file systems, the root file system will have the data directory while the WAL\n+ * filesystem will have the WALs directory. The archived HFile will be moved to the global HFile\n+ * archived directory with the {@link LocalRegionParams#archivedWalSuffix()} suffix. The archived\n+ * WAL will be moved to the global WAL archived directory with the\n+ * {@link LocalRegionParams#archivedHFileSuffix()} suffix.\n+ */\n+@InterfaceAudience.Private\n+public final class LocalRegion {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(LocalRegion.class);\n+\n+  private static final String REPLAY_EDITS_DIR = \"recovered.wals\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b5ecafb52606eee213d26073237598a04d7736f6"}, "originalPosition": 91}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzNzAwMg==", "bodyText": "Good", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429037002", "createdAt": "2020-05-22T04:30:22Z", "author": {"login": "saintstack"}, "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/master/store/TestLocalRegionOnTwoFileSystems.java", "diffHunk": "@@ -0,0 +1,170 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.master.store;\n+\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hbase.ChoreService;\n+import org.apache.hadoop.hbase.HBaseClassTestRule;\n+import org.apache.hadoop.hbase.HBaseCommonTestingUtility;\n+import org.apache.hadoop.hbase.HBaseTestingUtility;\n+import org.apache.hadoop.hbase.HConstants;\n+import org.apache.hadoop.hbase.Server;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.ColumnFamilyDescriptorBuilder;\n+import org.apache.hadoop.hbase.client.Put;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.client.TableDescriptorBuilder;\n+import org.apache.hadoop.hbase.master.cleaner.DirScanPool;\n+import org.apache.hadoop.hbase.regionserver.MemStoreLAB;\n+import org.apache.hadoop.hbase.testclassification.MasterTests;\n+import org.apache.hadoop.hbase.testclassification.MediumTests;\n+import org.apache.hadoop.hbase.util.Bytes;\n+import org.apache.hadoop.hbase.util.CommonFSUtils;\n+import org.apache.hadoop.hbase.util.HFileArchiveUtil;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+\n+import org.apache.hbase.thirdparty.com.google.common.collect.Iterables;\n+\n+@Category({ MasterTests.class, MediumTests.class })\n+public class TestLocalRegionOnTwoFileSystems {\n+\n+  @ClassRule\n+  public static final HBaseClassTestRule CLASS_RULE =\n+    HBaseClassTestRule.forClass(TestLocalRegionOnTwoFileSystems.class);\n+\n+  private static final HBaseCommonTestingUtility HFILE_UTIL = new HBaseCommonTestingUtility();\n+\n+  private static final HBaseTestingUtility WAL_UTIL = new HBaseTestingUtility();\n+\n+  private static ChoreService CHORE_SERVICE;\n+\n+  private static DirScanPool CLEANER_POOL;\n+\n+  private static LocalRegion REGION;\n+\n+  private static byte[] CF = Bytes.toBytes(\"f\");\n+\n+  private static byte[] QUALIFIER = Bytes.toBytes(\"q\");\n+\n+  private static String REGION_DIR_NAME = \"local\";\n+\n+  private static TableDescriptor TD =\n+    TableDescriptorBuilder.newBuilder(TableName.valueOf(\"test:local\"))\n+      .setColumnFamily(ColumnFamilyDescriptorBuilder.of(CF)).build();\n+\n+  private static int COMPACT_MIN = 4;\n+\n+  @BeforeClass\n+  public static void setUp() throws Exception {\n+    WAL_UTIL.startMiniCluster(3);\n+    Configuration conf = HFILE_UTIL.getConfiguration();\n+    conf.setBoolean(MemStoreLAB.USEMSLAB_KEY, false);\n+    CHORE_SERVICE = new ChoreService(\"TestLocalRegionOnTwoFileSystems\");\n+    CLEANER_POOL = new DirScanPool(conf);\n+    Server server = mock(Server.class);\n+    when(server.getConfiguration()).thenReturn(conf);\n+    when(server.getServerName())\n+      .thenReturn(ServerName.valueOf(\"localhost\", 12345, System.currentTimeMillis()));\n+    when(server.getChoreService()).thenReturn(CHORE_SERVICE);\n+    Path rootDir = HFILE_UTIL.getDataTestDir();\n+    CommonFSUtils.setRootDir(conf, rootDir);\n+    Path walRootDir = WAL_UTIL.getDataTestDirOnTestFS();\n+    FileSystem walFs = WAL_UTIL.getTestFileSystem();\n+    CommonFSUtils.setWALRootDir(conf,\n+      walRootDir.makeQualified(walFs.getUri(), walFs.getWorkingDirectory()));\n+    LocalRegionParams params = new LocalRegionParams();\n+    params.server(server).regionDirName(REGION_DIR_NAME).tableDescriptor(TD)\n+      .flushSize(TableDescriptorBuilder.DEFAULT_MEMSTORE_FLUSH_SIZE).flushPerChanges(1_000_000)\n+      .flushIntervalMs(TimeUnit.MINUTES.toMillis(15)).compactMin(COMPACT_MIN).maxWals(32)\n+      .useHsync(false).ringBufferSlotCount(16).rollPeriodMs(TimeUnit.MINUTES.toMillis(15))\n+      .archivedWalSuffix(LocalStore.ARCHIVED_WAL_SUFFIX)\n+      .archivedHFileSuffix(LocalStore.ARCHIVED_HFILE_SUFFIX);\n+    REGION = LocalRegion.create(params);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b5ecafb52606eee213d26073237598a04d7736f6"}, "originalPosition": 111}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzNzA4Ng==", "bodyText": "Are there params to set for local regions walfs and hfilefs?", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429037086", "createdAt": "2020-05-22T04:30:49Z", "author": {"login": "saintstack"}, "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/master/store/TestLocalRegionOnTwoFileSystems.java", "diffHunk": "@@ -0,0 +1,170 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.master.store;\n+\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hbase.ChoreService;\n+import org.apache.hadoop.hbase.HBaseClassTestRule;\n+import org.apache.hadoop.hbase.HBaseCommonTestingUtility;\n+import org.apache.hadoop.hbase.HBaseTestingUtility;\n+import org.apache.hadoop.hbase.HConstants;\n+import org.apache.hadoop.hbase.Server;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.ColumnFamilyDescriptorBuilder;\n+import org.apache.hadoop.hbase.client.Put;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.client.TableDescriptorBuilder;\n+import org.apache.hadoop.hbase.master.cleaner.DirScanPool;\n+import org.apache.hadoop.hbase.regionserver.MemStoreLAB;\n+import org.apache.hadoop.hbase.testclassification.MasterTests;\n+import org.apache.hadoop.hbase.testclassification.MediumTests;\n+import org.apache.hadoop.hbase.util.Bytes;\n+import org.apache.hadoop.hbase.util.CommonFSUtils;\n+import org.apache.hadoop.hbase.util.HFileArchiveUtil;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+\n+import org.apache.hbase.thirdparty.com.google.common.collect.Iterables;\n+\n+@Category({ MasterTests.class, MediumTests.class })\n+public class TestLocalRegionOnTwoFileSystems {\n+\n+  @ClassRule\n+  public static final HBaseClassTestRule CLASS_RULE =\n+    HBaseClassTestRule.forClass(TestLocalRegionOnTwoFileSystems.class);\n+\n+  private static final HBaseCommonTestingUtility HFILE_UTIL = new HBaseCommonTestingUtility();\n+\n+  private static final HBaseTestingUtility WAL_UTIL = new HBaseTestingUtility();\n+\n+  private static ChoreService CHORE_SERVICE;\n+\n+  private static DirScanPool CLEANER_POOL;\n+\n+  private static LocalRegion REGION;\n+\n+  private static byte[] CF = Bytes.toBytes(\"f\");\n+\n+  private static byte[] QUALIFIER = Bytes.toBytes(\"q\");\n+\n+  private static String REGION_DIR_NAME = \"local\";\n+\n+  private static TableDescriptor TD =\n+    TableDescriptorBuilder.newBuilder(TableName.valueOf(\"test:local\"))\n+      .setColumnFamily(ColumnFamilyDescriptorBuilder.of(CF)).build();\n+\n+  private static int COMPACT_MIN = 4;\n+\n+  @BeforeClass\n+  public static void setUp() throws Exception {\n+    WAL_UTIL.startMiniCluster(3);\n+    Configuration conf = HFILE_UTIL.getConfiguration();\n+    conf.setBoolean(MemStoreLAB.USEMSLAB_KEY, false);\n+    CHORE_SERVICE = new ChoreService(\"TestLocalRegionOnTwoFileSystems\");\n+    CLEANER_POOL = new DirScanPool(conf);\n+    Server server = mock(Server.class);\n+    when(server.getConfiguration()).thenReturn(conf);\n+    when(server.getServerName())\n+      .thenReturn(ServerName.valueOf(\"localhost\", 12345, System.currentTimeMillis()));\n+    when(server.getChoreService()).thenReturn(CHORE_SERVICE);\n+    Path rootDir = HFILE_UTIL.getDataTestDir();\n+    CommonFSUtils.setRootDir(conf, rootDir);\n+    Path walRootDir = WAL_UTIL.getDataTestDirOnTestFS();\n+    FileSystem walFs = WAL_UTIL.getTestFileSystem();\n+    CommonFSUtils.setWALRootDir(conf,\n+      walRootDir.makeQualified(walFs.getUri(), walFs.getWorkingDirectory()));\n+    LocalRegionParams params = new LocalRegionParams();\n+    params.server(server).regionDirName(REGION_DIR_NAME).tableDescriptor(TD)\n+      .flushSize(TableDescriptorBuilder.DEFAULT_MEMSTORE_FLUSH_SIZE).flushPerChanges(1_000_000)\n+      .flushIntervalMs(TimeUnit.MINUTES.toMillis(15)).compactMin(COMPACT_MIN).maxWals(32)\n+      .useHsync(false).ringBufferSlotCount(16).rollPeriodMs(TimeUnit.MINUTES.toMillis(15))\n+      .archivedWalSuffix(LocalStore.ARCHIVED_WAL_SUFFIX)\n+      .archivedHFileSuffix(LocalStore.ARCHIVED_HFILE_SUFFIX);\n+    REGION = LocalRegion.create(params);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzNzAwMg=="}, "originalCommit": {"oid": "b5ecafb52606eee213d26073237598a04d7736f6"}, "originalPosition": 111}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzNzc1OQ==", "bodyText": "Is this the right place to stop this? Should the localStore be made by the Master, owned and shutdown by the Master? It passes it in here to the RPS to use? Master shuts it down. Makes sure it doesn't shut it down before other users are done with it?", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429037759", "createdAt": "2020-05-22T04:34:26Z", "author": {"login": "saintstack"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/procedure2/store/region/RegionProcedureStore.java", "diffHunk": "@@ -183,51 +106,14 @@ public void start(int numThreads) throws IOException {\n     this.numThreads = numThreads;\n   }\n \n-  private void shutdownWAL() {\n-    if (walFactory != null) {\n-      try {\n-        walFactory.shutdown();\n-      } catch (IOException e) {\n-        LOG.warn(\"Failed to shutdown WAL\", e);\n-      }\n-    }\n-  }\n-\n-  private void closeRegion(boolean abort) {\n-    if (region != null) {\n-      try {\n-        region.close(abort);\n-      } catch (IOException e) {\n-        LOG.warn(\"Failed to close region\", e);\n-      }\n-    }\n-\n-  }\n-\n   @Override\n   public void stop(boolean abort) {\n     if (!setRunning(false)) {\n       return;\n     }\n     LOG.info(\"Stopping the Region Procedure Store, isAbort={}\", abort);\n-    if (cleaner != null) {\n-      cleaner.cancel(abort);\n-    }\n-    if (flusherAndCompactor != null) {\n-      flusherAndCompactor.close();\n-    }\n-    // if abort, we shutdown wal first to fail the ongoing updates to the region, and then close the\n-    // region, otherwise there will be dead lock.\n-    if (abort) {\n-      shutdownWAL();\n-      closeRegion(true);\n-    } else {\n-      closeRegion(false);\n-      shutdownWAL();\n-    }\n-\n-    if (walRoller != null) {\n-      walRoller.close();\n+    if (localStore != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b5ecafb52606eee213d26073237598a04d7736f6"}, "originalPosition": 210}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzODM1Ng==", "bodyText": "oh, the second family will come in here if we decide to store root table in here?  Not till then. Ok. I think that makes sense. If table already exists, will have to alter it when we add the root table CF?", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429038356", "createdAt": "2020-05-22T04:37:23Z", "author": {"login": "saintstack"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/store/LocalStore.java", "diffHunk": "@@ -0,0 +1,148 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.master.store;\n+\n+import java.io.IOException;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.Server;\n+import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.ColumnFamilyDescriptorBuilder;\n+import org.apache.hadoop.hbase.client.Get;\n+import org.apache.hadoop.hbase.client.Result;\n+import org.apache.hadoop.hbase.client.Scan;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.client.TableDescriptorBuilder;\n+import org.apache.hadoop.hbase.regionserver.HRegion.FlushResult;\n+import org.apache.hadoop.hbase.regionserver.RegionScanner;\n+import org.apache.hadoop.hbase.util.Bytes;\n+import org.apache.yetus.audience.InterfaceAudience;\n+\n+import org.apache.hbase.thirdparty.com.google.common.annotations.VisibleForTesting;\n+\n+/**\n+ * Used for storing data at master side. The data will be stored in a {@link LocalRegion}.\n+ */\n+@InterfaceAudience.Private\n+public final class LocalStore {\n+\n+  // Use the character $ to let the log cleaner know that this is not the normal wal file.\n+  public static final String ARCHIVED_WAL_SUFFIX = \"$masterlocalwal$\";\n+\n+  public static final String ARCHIVED_HFILE_SUFFIX = \"$masterlocalhfile$\";\n+\n+  private static final String MAX_WALS_KEY = \"hbase.master.store.region.maxwals\";\n+\n+  private static final int DEFAULT_MAX_WALS = 10;\n+\n+  public static final String USE_HSYNC_KEY = \"hbase.master.store.region.wal.hsync\";\n+\n+  public static final String MASTER_STORE_DIR = \"MasterData\";\n+\n+  private static final String FLUSH_SIZE_KEY = \"hbase.master.store.region.flush.size\";\n+\n+  private static final long DEFAULT_FLUSH_SIZE = TableDescriptorBuilder.DEFAULT_MEMSTORE_FLUSH_SIZE;\n+\n+  private static final String FLUSH_PER_CHANGES_KEY = \"hbase.master.store.region.flush.per.changes\";\n+\n+  private static final long DEFAULT_FLUSH_PER_CHANGES = 1_000_000;\n+\n+  private static final String FLUSH_INTERVAL_MS_KEY = \"hbase.master.store.region.flush.interval.ms\";\n+\n+  // default to flush every 15 minutes, for safety\n+  private static final long DEFAULT_FLUSH_INTERVAL_MS = TimeUnit.MINUTES.toMillis(15);\n+\n+  private static final String COMPACT_MIN_KEY = \"hbase.master.store.region.compact.min\";\n+\n+  private static final int DEFAULT_COMPACT_MIN = 4;\n+\n+  private static final String ROLL_PERIOD_MS_KEY = \"hbase.master.store.region.walroll.period.ms\";\n+\n+  private static final long DEFAULT_ROLL_PERIOD_MS = TimeUnit.MINUTES.toMillis(15);\n+\n+  private static final String RING_BUFFER_SLOT_COUNT = \"hbase.master.store.ringbuffer.slot.count\";\n+\n+  private static final int DEFAULT_RING_BUFFER_SLOT_COUNT = 128;\n+\n+  public static final TableName TABLE_NAME = TableName.valueOf(\"master:store\");\n+\n+  public static final byte[] PROC_FAMILY = Bytes.toBytes(\"proc\");\n+\n+  private static final TableDescriptor TABLE_DESC = TableDescriptorBuilder.newBuilder(TABLE_NAME)\n+    .setColumnFamily(ColumnFamilyDescriptorBuilder.of(PROC_FAMILY)).build();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b5ecafb52606eee213d26073237598a04d7736f6"}, "originalPosition": 87}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b5ecafb52606eee213d26073237598a04d7736f6", "author": {"user": {"login": "Apache9", "name": "Duo Zhang"}}, "url": "https://github.com/apache/hbase/commit/b5ecafb52606eee213d26073237598a04d7736f6", "committedDate": "2020-05-21T23:38:52Z", "message": "HBAE-24408 Introduce a general 'local region' to store data on master"}, "afterCommit": {"oid": "b065f2702476271dfcb32d53ece11a54a1ac1cf5", "author": {"user": {"login": "Apache9", "name": "Duo Zhang"}}, "url": "https://github.com/apache/hbase/commit/b065f2702476271dfcb32d53ece11a54a1ac1cf5", "committedDate": "2020-05-22T08:08:38Z", "message": "HBAE-24408 Introduce a general 'local region' to store data on master"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b065f2702476271dfcb32d53ece11a54a1ac1cf5", "author": {"user": {"login": "Apache9", "name": "Duo Zhang"}}, "url": "https://github.com/apache/hbase/commit/b065f2702476271dfcb32d53ece11a54a1ac1cf5", "committedDate": "2020-05-22T08:08:38Z", "message": "HBAE-24408 Introduce a general 'local region' to store data on master"}, "afterCommit": {"oid": "15f5fc9ee48b5557c2e8029725210207abb1cc2f", "author": {"user": {"login": "Apache9", "name": "Duo Zhang"}}, "url": "https://github.com/apache/hbase/commit/15f5fc9ee48b5557c2e8029725210207abb1cc2f", "committedDate": "2020-05-22T15:22:25Z", "message": "HBASE-24408 Introduce a general 'local region' to store data on master"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "15f5fc9ee48b5557c2e8029725210207abb1cc2f", "author": {"user": {"login": "Apache9", "name": "Duo Zhang"}}, "url": "https://github.com/apache/hbase/commit/15f5fc9ee48b5557c2e8029725210207abb1cc2f", "committedDate": "2020-05-22T15:22:25Z", "message": "HBASE-24408 Introduce a general 'local region' to store data on master"}, "afterCommit": {"oid": "0f5d045d417d239556cfcb79b6e028bf25501342", "author": {"user": {"login": "Apache9", "name": "Duo Zhang"}}, "url": "https://github.com/apache/hbase/commit/0f5d045d417d239556cfcb79b6e028bf25501342", "committedDate": "2020-05-22T15:23:58Z", "message": "HBASE-24408 Introduce a general 'local region' to store data on master"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE3MDQyNDA3", "url": "https://github.com/apache/hbase/pull/1753#pullrequestreview-417042407", "createdAt": "2020-05-22T16:37:18Z", "commit": {"oid": "0f5d045d417d239556cfcb79b6e028bf25501342"}, "state": "APPROVED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQxNjozNzoxOFrOGZdMyg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQxNjo0Mzo1OVrOGZdZDg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTM0NTk5NA==", "bodyText": "nice", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429345994", "createdAt": "2020-05-22T16:37:18Z", "author": {"login": "saintstack"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "diffHunk": "@@ -1550,10 +1563,8 @@ protected void stopServiceThreads() {\n \n   private void createProcedureExecutor() throws IOException {\n     MasterProcedureEnv procEnv = new MasterProcedureEnv(this);\n-    // Create cleaner thread pool\n-    cleanerPool = new DirScanPool(conf);\n-    procedureStore = new RegionProcedureStore(this, cleanerPool,\n-      new MasterProcedureEnv.FsUtilsLeaseRecovery(this));\n+    procedureStore =\n+      new RegionProcedureStore(this, localStore, new MasterProcedureEnv.FsUtilsLeaseRecovery(this));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0f5d045d417d239556cfcb79b6e028bf25501342"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTM0NjEzOQ==", "bodyText": "The passing of an already initialized localregion is what is nice.", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429346139", "createdAt": "2020-05-22T16:37:37Z", "author": {"login": "saintstack"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "diffHunk": "@@ -1550,10 +1563,8 @@ protected void stopServiceThreads() {\n \n   private void createProcedureExecutor() throws IOException {\n     MasterProcedureEnv procEnv = new MasterProcedureEnv(this);\n-    // Create cleaner thread pool\n-    cleanerPool = new DirScanPool(conf);\n-    procedureStore = new RegionProcedureStore(this, cleanerPool,\n-      new MasterProcedureEnv.FsUtilsLeaseRecovery(this));\n+    procedureStore =\n+      new RegionProcedureStore(this, localStore, new MasterProcedureEnv.FsUtilsLeaseRecovery(this));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTM0NTk5NA=="}, "originalCommit": {"oid": "0f5d045d417d239556cfcb79b6e028bf25501342"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTM0NjYyMA==", "bodyText": "Yes. Of course.", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429346620", "createdAt": "2020-05-22T16:38:40Z", "author": {"login": "saintstack"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/cleaner/LogCleaner.java", "diffHunk": "@@ -86,8 +87,9 @@ public LogCleaner(final int period, final Stoppable stopper, Configuration conf,\n \n   @Override\n   protected boolean validate(Path file) {\n-    return AbstractFSWALProvider.validateWALFilename(file.getName())\n-        || MasterProcedureUtil.validateProcedureWALFilename(file.getName());\n+    return AbstractFSWALProvider.validateWALFilename(file.getName()) ||\n+      MasterProcedureUtil.validateProcedureWALFilename(file.getName()) ||\n+      file.getName().endsWith(LocalStore.ARCHIVED_WAL_SUFFIX);\n   }\n \n   @Override", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzMzg4NA=="}, "originalCommit": {"oid": "b5ecafb52606eee213d26073237598a04d7736f6"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTM0NzM2OA==", "bodyText": "ok", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429347368", "createdAt": "2020-05-22T16:40:22Z", "author": {"login": "saintstack"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/store/LocalRegion.java", "diffHunk": "@@ -0,0 +1,325 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.master.store;\n+\n+import static org.apache.hadoop.hbase.HConstants.HREGION_LOGDIR_NAME;\n+\n+import java.io.IOException;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hbase.HBaseIOException;\n+import org.apache.hadoop.hbase.Server;\n+import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.Get;\n+import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.RegionInfoBuilder;\n+import org.apache.hadoop.hbase.client.Result;\n+import org.apache.hadoop.hbase.client.Scan;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.regionserver.HRegion;\n+import org.apache.hadoop.hbase.regionserver.HRegion.FlushResult;\n+import org.apache.hadoop.hbase.regionserver.HRegionFileSystem;\n+import org.apache.hadoop.hbase.regionserver.RegionScanner;\n+import org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL;\n+import org.apache.hadoop.hbase.util.Bytes;\n+import org.apache.hadoop.hbase.util.CommonFSUtils;\n+import org.apache.hadoop.hbase.util.FSUtils;\n+import org.apache.hadoop.hbase.util.HFileArchiveUtil;\n+import org.apache.hadoop.hbase.util.RecoverLeaseFSUtils;\n+import org.apache.hadoop.hbase.wal.AbstractFSWALProvider;\n+import org.apache.hadoop.hbase.wal.WAL;\n+import org.apache.hadoop.hbase.wal.WALFactory;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hbase.thirdparty.com.google.common.annotations.VisibleForTesting;\n+import org.apache.hbase.thirdparty.com.google.common.math.IntMath;\n+\n+/**\n+ * A region that stores data in a separated directory.\n+ * <p/>\n+ * FileSystem layout:\n+ *\n+ * <pre>\n+ * hbase\n+ *   |\n+ *   --&lt;region dir&gt;\n+ *       |\n+ *       --data\n+ *       |  |\n+ *       |  --/&lt;ns&gt/&lt;table&gt/&lt;encoded-region-name&gt; <---- The region data\n+ *       |      |\n+ *       |      --replay <---- The edits to replay\n+ *       |\n+ *       --WALs\n+ *          |\n+ *          --&lt;master-server-name&gt; <---- The WAL dir for active master\n+ *          |\n+ *          --&lt;master-server-name&gt;-dead <---- The WAL dir for dead master\n+ * </pre>\n+ *\n+ * Notice that, you can use different root file system and WAL file system. Then the above directory\n+ * will be on two file systems, the root file system will have the data directory while the WAL\n+ * filesystem will have the WALs directory. The archived HFile will be moved to the global HFile\n+ * archived directory with the {@link LocalRegionParams#archivedWalSuffix()} suffix. The archived\n+ * WAL will be moved to the global WAL archived directory with the\n+ * {@link LocalRegionParams#archivedHFileSuffix()} suffix.\n+ */\n+@InterfaceAudience.Private\n+public final class LocalRegion {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(LocalRegion.class);\n+\n+  private static final String REPLAY_EDITS_DIR = \"recovered.wals\";\n+\n+  private static final String DEAD_WAL_DIR_SUFFIX = \"-dead\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzNTI0Mw=="}, "originalCommit": {"oid": "b5ecafb52606eee213d26073237598a04d7736f6"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTM0OTEzNA==", "bodyText": "Nice. This is cleaner w/ the passing in of the local region.", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429349134", "createdAt": "2020-05-22T16:43:59Z", "author": {"login": "saintstack"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/procedure2/store/region/RegionProcedureStore.java", "diffHunk": "@@ -688,11 +444,12 @@ public void cleanup() {\n         Cell cell = cells.get(0);\n         cells.clear();\n         if (cell.getValueLength() == 0) {\n-          region.delete(new Delete(cell.getRowArray(), cell.getRowOffset(), cell.getRowLength()));\n+          localStore.update(r -> r\n+            .delete(new Delete(cell.getRowArray(), cell.getRowOffset(), cell.getRowLength())));\n         }\n       }\n     } catch (IOException e) {\n       LOG.warn(\"Failed to clean up delete procedures\", e);\n     }\n   }\n-}\n+}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0f5d045d417d239556cfcb79b6e028bf25501342"}, "originalPosition": 509}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "162da681072c87678a4dc9a81b1d868308ffc871", "author": {"user": {"login": "Apache9", "name": "Duo Zhang"}}, "url": "https://github.com/apache/hbase/commit/162da681072c87678a4dc9a81b1d868308ffc871", "committedDate": "2020-05-22T23:47:21Z", "message": "HBASE-24408 Introduce a general 'local region' to store data on master"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0f5d045d417d239556cfcb79b6e028bf25501342", "author": {"user": {"login": "Apache9", "name": "Duo Zhang"}}, "url": "https://github.com/apache/hbase/commit/0f5d045d417d239556cfcb79b6e028bf25501342", "committedDate": "2020-05-22T15:23:58Z", "message": "HBASE-24408 Introduce a general 'local region' to store data on master"}, "afterCommit": {"oid": "162da681072c87678a4dc9a81b1d868308ffc871", "author": {"user": {"login": "Apache9", "name": "Duo Zhang"}}, "url": "https://github.com/apache/hbase/commit/162da681072c87678a4dc9a81b1d868308ffc871", "committedDate": "2020-05-22T23:47:21Z", "message": "HBASE-24408 Introduce a general 'local region' to store data on master"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIxMzQ5NzAy", "url": "https://github.com/apache/hbase/pull/1753#pullrequestreview-421349702", "createdAt": "2020-05-29T23:38:33Z", "commit": {"oid": "162da681072c87678a4dc9a81b1d868308ffc871"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQyMzozODozNFrOGcu_Cw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQyMzozODozNFrOGcu_Cw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjc4MzExNQ==", "bodyText": "This class name confuses me. I see now that it uses \"store\" as a legacy of what was earlier called the \"ProcedureStore\". The confusion is this: our Regions also have an internal structure called a \"Store\".\nMaybe o.a.h.h.master.store should now be called o.a.h.h.master.region. This class is apparently just a delegate to the region instance. Maybe we can rename LocalRegion to MasterRegion, do away with this LocalStore, replace it with a MasterRegionFactory, and let the caller invoke methods directly on the MasterRegion.", "url": "https://github.com/apache/hbase/pull/1753#discussion_r432783115", "createdAt": "2020-05-29T23:38:34Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/store/LocalStore.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.master.store;\n+\n+import java.io.IOException;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.Server;\n+import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.ColumnFamilyDescriptorBuilder;\n+import org.apache.hadoop.hbase.client.Get;\n+import org.apache.hadoop.hbase.client.Result;\n+import org.apache.hadoop.hbase.client.Scan;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.client.TableDescriptorBuilder;\n+import org.apache.hadoop.hbase.regionserver.HRegion.FlushResult;\n+import org.apache.hadoop.hbase.regionserver.RegionScanner;\n+import org.apache.hadoop.hbase.util.Bytes;\n+import org.apache.yetus.audience.InterfaceAudience;\n+\n+import org.apache.hbase.thirdparty.com.google.common.annotations.VisibleForTesting;\n+\n+/**\n+ * Used for storing data at master side. The data will be stored in a {@link LocalRegion}.\n+ */\n+@InterfaceAudience.Private\n+public final class LocalStore {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "162da681072c87678a4dc9a81b1d868308ffc871"}, "originalPosition": 42}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4707, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}