{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTEzNzY3NDc0", "number": 2614, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QxNTowNjoyMVrOE02Upg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QxNToxOTowOFrOE02rwA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIzODUxNDMwOnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/zksyncer/ClientZKSyncer.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QxNTowNjoyMVrOHszEUw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QxNTowNjoyMVrOHszEUw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjczNjA4Mw==", "bodyText": "The newly introduced ZKData structure is more efficient, shall we update the comments here and add some javadoc for the ZKData class?", "url": "https://github.com/apache/hbase/pull/2614#discussion_r516736083", "createdAt": "2020-11-03T15:06:21Z", "author": {"login": "carp84"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/zksyncer/ClientZKSyncer.java", "diffHunk": "@@ -34,30 +33,69 @@\n import org.apache.yetus.audience.InterfaceAudience;\n import org.apache.zookeeper.CreateMode;\n import org.apache.zookeeper.KeeperException;\n-\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n /**\n  * Tracks the target znode(s) on server ZK cluster and synchronize them to client ZK cluster if\n  * changed\n  * <p/>\n- * The target znode(s) is given through {@link #getNodesToWatch()} method\n+ * The target znode(s) is given through {@link #getPathsToWatch()} method\n  */\n @InterfaceAudience.Private\n public abstract class ClientZKSyncer extends ZKListener {\n   private static final Logger LOG = LoggerFactory.getLogger(ClientZKSyncer.class);\n   private final Server server;\n   private final ZKWatcher clientZkWatcher;\n+\n+  private static final class ZKData {\n+\n+    byte[] data;\n+\n+    boolean delete = false;\n+\n+    synchronized void set(byte[] data) {\n+      this.data = data;\n+      notifyAll();\n+    }\n+\n+    synchronized byte[] get() throws InterruptedException {\n+      while (!delete && data == null) {\n+        wait();\n+      }\n+      byte[] d = data;\n+      data = null;\n+      return d;\n+    }\n+\n+    synchronized void delete() {\n+      this.delete = true;\n+      notifyAll();\n+    }\n+\n+    synchronized boolean isDeleted() {\n+      return delete;\n+    }\n+  }\n+\n   // We use queues and daemon threads to synchronize the data to client ZK cluster", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8ad90d35a2b992ab88a3f7b00fc75b5602426a15"}, "originalPosition": 68}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIzODU1MTU0OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/zksyncer/ClientZKSyncer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QxNToxNDoyNFrOHszb1A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQwMzoyNjowOVrOHtH7LQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc0MjEwMA==", "bodyText": "So we choose not to reconnect if there are some issue on network stability that cause zookeeper connection loss? And it seems the reconnectAfterExpiration is not following the same handling on line 173-174", "url": "https://github.com/apache/hbase/pull/2614#discussion_r516742100", "createdAt": "2020-11-03T15:14:24Z", "author": {"login": "carp84"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/zksyncer/ClientZKSyncer.java", "diffHunk": "@@ -145,8 +177,7 @@ private final void setDataForClientZkUntilSuccess(String node, byte[] data)\n           LOG.warn(\n             \"Failed to create znode \" + node + \" due to: \" + e.getMessage() + \", will retry later\");\n         }\n-      } catch (KeeperException.ConnectionLossException\n-          | KeeperException.SessionExpiredException ee) {\n+      } catch (KeeperException.SessionExpiredException see) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8ad90d35a2b992ab88a3f7b00fc75b5602426a15"}, "originalPosition": 143}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzA3NzgwNQ==", "bodyText": "ConnectionLoss just means the connection is broken, the zk library will reconnect automatically to resume the session if possible.", "url": "https://github.com/apache/hbase/pull/2614#discussion_r517077805", "createdAt": "2020-11-04T03:26:09Z", "author": {"login": "Apache9"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/zksyncer/ClientZKSyncer.java", "diffHunk": "@@ -145,8 +177,7 @@ private final void setDataForClientZkUntilSuccess(String node, byte[] data)\n           LOG.warn(\n             \"Failed to create znode \" + node + \" due to: \" + e.getMessage() + \", will retry later\");\n         }\n-      } catch (KeeperException.ConnectionLossException\n-          | KeeperException.SessionExpiredException ee) {\n+      } catch (KeeperException.SessionExpiredException see) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc0MjEwMA=="}, "originalCommit": {"oid": "8ad90d35a2b992ab88a3f7b00fc75b5602426a15"}, "originalPosition": 143}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIzODU3MzQ0OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestSeparateClientZKCluster.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QxNToxOTowOFrOHszpmg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQwODoxODoxMVrOHtNM2w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc0NTYyNg==", "bodyText": "Maybe adding more logics to verify the ClientZKSyncer is working well when meta replica changes, especially when reducing from multiple to single replica?", "url": "https://github.com/apache/hbase/pull/2614#discussion_r516745626", "createdAt": "2020-11-03T15:19:08Z", "author": {"login": "carp84"}, "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestSeparateClientZKCluster.java", "diffHunk": "@@ -255,7 +260,20 @@ public void testAsyncTable() throws Exception {\n       Get get = new Get(row);\n       Result result = table.get(get).get();\n       LOG.debug(\"Result: \" + Bytes.toString(result.getValue(family, qualifier)));\n-      Assert.assertArrayEquals(value, result.getValue(family, qualifier));\n+      assertArrayEquals(value, result.getValue(family, qualifier));\n+    }\n+  }\n+\n+  @Test\n+  public void testChangeMetaReplicaCount() throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8ad90d35a2b992ab88a3f7b00fc75b5602426a15"}, "originalPosition": 163}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzA3ODA3NA==", "bodyText": "In the test we increase from 1 to 3, and then reduce back to 2, you mean we should add one more assert to reduce to 1?", "url": "https://github.com/apache/hbase/pull/2614#discussion_r517078074", "createdAt": "2020-11-04T03:27:17Z", "author": {"login": "Apache9"}, "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestSeparateClientZKCluster.java", "diffHunk": "@@ -255,7 +260,20 @@ public void testAsyncTable() throws Exception {\n       Get get = new Get(row);\n       Result result = table.get(get).get();\n       LOG.debug(\"Result: \" + Bytes.toString(result.getValue(family, qualifier)));\n-      Assert.assertArrayEquals(value, result.getValue(family, qualifier));\n+      assertArrayEquals(value, result.getValue(family, qualifier));\n+    }\n+  }\n+\n+  @Test\n+  public void testChangeMetaReplicaCount() throws Exception {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc0NTYyNg=="}, "originalCommit": {"oid": "8ad90d35a2b992ab88a3f7b00fc75b5602426a15"}, "originalPosition": 163}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzE1ODMxMg==", "bodyText": "Yes, and it seems the test now didn't test any ClientZKSyncer logics, like if the client could still correctly access meta through client ZK, but checks against meta region locator?", "url": "https://github.com/apache/hbase/pull/2614#discussion_r517158312", "createdAt": "2020-11-04T08:06:20Z", "author": {"login": "carp84"}, "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestSeparateClientZKCluster.java", "diffHunk": "@@ -255,7 +260,20 @@ public void testAsyncTable() throws Exception {\n       Get get = new Get(row);\n       Result result = table.get(get).get();\n       LOG.debug(\"Result: \" + Bytes.toString(result.getValue(family, qualifier)));\n-      Assert.assertArrayEquals(value, result.getValue(family, qualifier));\n+      assertArrayEquals(value, result.getValue(family, qualifier));\n+    }\n+  }\n+\n+  @Test\n+  public void testChangeMetaReplicaCount() throws Exception {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc0NTYyNg=="}, "originalCommit": {"oid": "8ad90d35a2b992ab88a3f7b00fc75b5602426a15"}, "originalPosition": 163}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzE2MTE2NA==", "bodyText": "RegionLocator will go to ConnectionRegistry to ask for the meta locations and we have already set the ConnectionRegistry to ZKConnectionRegistry against the client zk in the setup method, so it is testing the ClientZKSyncer logics, you could try comment out the set data logic in ClientZKSyncer, the test will fail with timeout...", "url": "https://github.com/apache/hbase/pull/2614#discussion_r517161164", "createdAt": "2020-11-04T08:12:02Z", "author": {"login": "Apache9"}, "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestSeparateClientZKCluster.java", "diffHunk": "@@ -255,7 +260,20 @@ public void testAsyncTable() throws Exception {\n       Get get = new Get(row);\n       Result result = table.get(get).get();\n       LOG.debug(\"Result: \" + Bytes.toString(result.getValue(family, qualifier)));\n-      Assert.assertArrayEquals(value, result.getValue(family, qualifier));\n+      assertArrayEquals(value, result.getValue(family, qualifier));\n+    }\n+  }\n+\n+  @Test\n+  public void testChangeMetaReplicaCount() throws Exception {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc0NTYyNg=="}, "originalCommit": {"oid": "8ad90d35a2b992ab88a3f7b00fc75b5602426a15"}, "originalPosition": 163}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzE2NDI1MQ==", "bodyText": "ok, got it, makes sense. Thanks for the clarification.", "url": "https://github.com/apache/hbase/pull/2614#discussion_r517164251", "createdAt": "2020-11-04T08:18:11Z", "author": {"login": "carp84"}, "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestSeparateClientZKCluster.java", "diffHunk": "@@ -255,7 +260,20 @@ public void testAsyncTable() throws Exception {\n       Get get = new Get(row);\n       Result result = table.get(get).get();\n       LOG.debug(\"Result: \" + Bytes.toString(result.getValue(family, qualifier)));\n-      Assert.assertArrayEquals(value, result.getValue(family, qualifier));\n+      assertArrayEquals(value, result.getValue(family, qualifier));\n+    }\n+  }\n+\n+  @Test\n+  public void testChangeMetaReplicaCount() throws Exception {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc0NTYyNg=="}, "originalCommit": {"oid": "8ad90d35a2b992ab88a3f7b00fc75b5602426a15"}, "originalPosition": 163}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2360, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}