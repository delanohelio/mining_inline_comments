{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzk5MTI0OTQy", "number": 1437, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQyMzo0NzoxOVrODvWHmw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQyMzo0ODowMFrODvWIOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwOTcyMDU5OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/io/asyncfs/FanOutOneBlockAsyncDFSOutputHelper.java", "isResolved": false, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQyMzo0NzoxOVrOGBt8pQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QwNDoyMjo0NFrOGByVtQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQ1NDU2NQ==", "bodyText": "Should this be logged at warn instead?", "url": "https://github.com/apache/hbase/pull/1437#discussion_r404454565", "createdAt": "2020-04-06T23:47:19Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/io/asyncfs/FanOutOneBlockAsyncDFSOutputHelper.java", "diffHunk": "@@ -272,6 +272,15 @@ private static FileCreator createFileCreator() throws NoSuchMethodException {\n     return createFileCreator2();\n   }\n \n+  private static CreateFlag loadShouldReplicateFlag() {\n+    try {\n+      return CreateFlag.valueOf(\"SHOULD_REPLICATE\");\n+    } catch (IllegalArgumentException e) {\n+      LOG.debug(\"can not find SHOULD_REPLICATE flag, should be hadoop 2.x\", e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1a1a3202501db69730c93b1400fbafb76fbfe5e7"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQ2Nzk4Nw==", "bodyText": "I used to make all the adaptor code to log as WARN but it was proven to be annoying for most users and we changed them all to debug...", "url": "https://github.com/apache/hbase/pull/1437#discussion_r404467987", "createdAt": "2020-04-07T00:31:19Z", "author": {"login": "Apache9"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/io/asyncfs/FanOutOneBlockAsyncDFSOutputHelper.java", "diffHunk": "@@ -272,6 +272,15 @@ private static FileCreator createFileCreator() throws NoSuchMethodException {\n     return createFileCreator2();\n   }\n \n+  private static CreateFlag loadShouldReplicateFlag() {\n+    try {\n+      return CreateFlag.valueOf(\"SHOULD_REPLICATE\");\n+    } catch (IllegalArgumentException e) {\n+      LOG.debug(\"can not find SHOULD_REPLICATE flag, should be hadoop 2.x\", e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQ1NDU2NQ=="}, "originalCommit": {"oid": "1a1a3202501db69730c93b1400fbafb76fbfe5e7"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQ4MzQ5NA==", "bodyText": "This happens every time we open a file in hadoop2? Or just once on class loading? (Looks like the latter).", "url": "https://github.com/apache/hbase/pull/1437#discussion_r404483494", "createdAt": "2020-04-07T01:27:39Z", "author": {"login": "saintstack"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/io/asyncfs/FanOutOneBlockAsyncDFSOutputHelper.java", "diffHunk": "@@ -272,6 +272,15 @@ private static FileCreator createFileCreator() throws NoSuchMethodException {\n     return createFileCreator2();\n   }\n \n+  private static CreateFlag loadShouldReplicateFlag() {\n+    try {\n+      return CreateFlag.valueOf(\"SHOULD_REPLICATE\");\n+    } catch (IllegalArgumentException e) {\n+      LOG.debug(\"can not find SHOULD_REPLICATE flag, should be hadoop 2.x\", e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQ1NDU2NQ=="}, "originalCommit": {"oid": "1a1a3202501db69730c93b1400fbafb76fbfe5e7"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQ4NDUzNA==", "bodyText": "This is how we test if the the SHOULD_REPLICATE flag is available? It is not available if hadoop2? If so, can we have a comment on the method to this effect? The log is a little confusing. Suggest: \"SHOULD_REPLICATE is not available; this is a problem if we are running on hadoop3 (Its expected if hadoop2)\".", "url": "https://github.com/apache/hbase/pull/1437#discussion_r404484534", "createdAt": "2020-04-07T01:31:26Z", "author": {"login": "saintstack"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/io/asyncfs/FanOutOneBlockAsyncDFSOutputHelper.java", "diffHunk": "@@ -272,6 +272,15 @@ private static FileCreator createFileCreator() throws NoSuchMethodException {\n     return createFileCreator2();\n   }\n \n+  private static CreateFlag loadShouldReplicateFlag() {\n+    try {\n+      return CreateFlag.valueOf(\"SHOULD_REPLICATE\");\n+    } catch (IllegalArgumentException e) {\n+      LOG.debug(\"can not find SHOULD_REPLICATE flag, should be hadoop 2.x\", e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQ1NDU2NQ=="}, "originalCommit": {"oid": "1a1a3202501db69730c93b1400fbafb76fbfe5e7"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQ4OTI5NQ==", "bodyText": "Only once when loading.", "url": "https://github.com/apache/hbase/pull/1437#discussion_r404489295", "createdAt": "2020-04-07T01:48:27Z", "author": {"login": "Apache9"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/io/asyncfs/FanOutOneBlockAsyncDFSOutputHelper.java", "diffHunk": "@@ -272,6 +272,15 @@ private static FileCreator createFileCreator() throws NoSuchMethodException {\n     return createFileCreator2();\n   }\n \n+  private static CreateFlag loadShouldReplicateFlag() {\n+    try {\n+      return CreateFlag.valueOf(\"SHOULD_REPLICATE\");\n+    } catch (IllegalArgumentException e) {\n+      LOG.debug(\"can not find SHOULD_REPLICATE flag, should be hadoop 2.x\", e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQ1NDU2NQ=="}, "originalCommit": {"oid": "1a1a3202501db69730c93b1400fbafb76fbfe5e7"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDUyNjUxNw==", "bodyText": "All the other log messages are just like this, so do not want to only change this one. Let me add some comments on the field.", "url": "https://github.com/apache/hbase/pull/1437#discussion_r404526517", "createdAt": "2020-04-07T04:22:44Z", "author": {"login": "Apache9"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/io/asyncfs/FanOutOneBlockAsyncDFSOutputHelper.java", "diffHunk": "@@ -272,6 +272,15 @@ private static FileCreator createFileCreator() throws NoSuchMethodException {\n     return createFileCreator2();\n   }\n \n+  private static CreateFlag loadShouldReplicateFlag() {\n+    try {\n+      return CreateFlag.valueOf(\"SHOULD_REPLICATE\");\n+    } catch (IllegalArgumentException e) {\n+      LOG.debug(\"can not find SHOULD_REPLICATE flag, should be hadoop 2.x\", e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQ1NDU2NQ=="}, "originalCommit": {"oid": "1a1a3202501db69730c93b1400fbafb76fbfe5e7"}, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwOTcyMjE2OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/io/asyncfs/FanOutOneBlockAsyncDFSOutputHelper.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQyMzo0ODowMFrOGBt9pg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQyMzo0ODowMFrOGBt9pg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQ1NDgyMg==", "bodyText": "nice cleanup.", "url": "https://github.com/apache/hbase/pull/1437#discussion_r404454822", "createdAt": "2020-04-06T23:48:00Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/io/asyncfs/FanOutOneBlockAsyncDFSOutputHelper.java", "diffHunk": "@@ -502,8 +524,8 @@ private static FanOutOneBlockAsyncDFSOutput createOutput(DistributedFileSystem d\n       try {\n         stat = FILE_CREATOR.create(namenode, src,\n           FsPermission.getFileDefault().applyUMask(FsPermission.getUMask(conf)), clientName,\n-          new EnumSetWritable<>(overwrite ? EnumSet.of(CREATE, OVERWRITE) : EnumSet.of(CREATE)),\n-          createParent, replication, blockSize, CryptoProtocolVersion.supported());\n+          getCreateFlags(overwrite), createParent, replication, blockSize,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1a1a3202501db69730c93b1400fbafb76fbfe5e7"}, "originalPosition": 67}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1866, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}