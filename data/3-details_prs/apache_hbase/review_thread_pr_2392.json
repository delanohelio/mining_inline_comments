{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDg2MTg5MTI3", "number": 2392, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOVQwNTozMToyMlrOElLDTg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOVQwNTo1MDo1NFrOElLSMg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA3NDEzODM4OnYy", "diffSide": "RIGHT", "path": "hbase-balancer/src/main/java/org/apache/hadoop/hbase/MetaTableAccessor.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOVQwNTozMToyMlrOHUg4mQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOVQwOToyNDozMlrOHUlggw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTI3MjM0NQ==", "bodyText": "This may log a negative number?", "url": "https://github.com/apache/hbase/pull/2392#discussion_r491272345", "createdAt": "2020-09-19T05:31:22Z", "author": {"login": "infraio"}, "path": "hbase-balancer/src/main/java/org/apache/hadoop/hbase/MetaTableAccessor.java", "diffHunk": "@@ -486,26 +485,12 @@ public static void scanMeta(Connection connection, @Nullable final byte[] startR\n \n     if (LOG.isTraceEnabled()) {\n       LOG.trace(\"Scanning META\" + \" starting at row=\" + Bytes.toStringBinary(startRow) +\n-        \" stopping at row=\" + Bytes.toStringBinary(stopRow) + \" for max=\" + rowUpperLimit +\n+        \" stopping at row=\" + Bytes.toStringBinary(stopRow) + \" for max=\" + maxRows +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a0e3c8e7bda7b93b01651ea73dc13217a0cbbdb2"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTM0ODA5OQ==", "bodyText": "I think it is fine? We know that -1 means no limit here.", "url": "https://github.com/apache/hbase/pull/2392#discussion_r491348099", "createdAt": "2020-09-19T09:24:32Z", "author": {"login": "Apache9"}, "path": "hbase-balancer/src/main/java/org/apache/hadoop/hbase/MetaTableAccessor.java", "diffHunk": "@@ -486,26 +485,12 @@ public static void scanMeta(Connection connection, @Nullable final byte[] startR\n \n     if (LOG.isTraceEnabled()) {\n       LOG.trace(\"Scanning META\" + \" starting at row=\" + Bytes.toStringBinary(startRow) +\n-        \" stopping at row=\" + Bytes.toStringBinary(stopRow) + \" for max=\" + rowUpperLimit +\n+        \" stopping at row=\" + Bytes.toStringBinary(stopRow) + \" for max=\" + maxRows +", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTI3MjM0NQ=="}, "originalCommit": {"oid": "a0e3c8e7bda7b93b01651ea73dc13217a0cbbdb2"}, "originalPosition": 15}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA3NDE3NjUwOnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/MetaLocationCache.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOVQwNTo1MDo1NFrOHUhRNA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOVQwOToyMzozOVrOHUlffw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTI3ODY0NA==", "bodyText": "What is the key thing of this jira? Just refactor getAllMetaRegionLocations to syncRoot? And I thought maybe need a better name for understand.", "url": "https://github.com/apache/hbase/pull/2392#discussion_r491278644", "createdAt": "2020-09-19T05:50:54Z", "author": {"login": "infraio"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/MetaLocationCache.java", "diffHunk": "@@ -102,34 +111,43 @@\n       master.getConfiguration().getInt(SYNC_INTERVAL_SECONDS, DEFAULT_SYNC_INTERVAL_SECONDS);\n     int fetchTimeoutMs =\n       master.getConfiguration().getInt(FETCH_TIMEOUT_MS, DEFAULT_FETCH_TIMEOUT_MS);\n-    master.getChoreService().scheduleChore(new ScheduledChore(\n-      getClass().getSimpleName() + \"-Sync-Chore\", this, syncIntervalSeconds, 0, TimeUnit.SECONDS) {\n+    refreshChore = new ScheduledChore(getClass().getSimpleName() + \"-Sync-Chore\", this,\n+      syncIntervalSeconds, 0, TimeUnit.SECONDS) {\n \n       @Override\n       protected void chore() {\n         AsyncClusterConnection conn = master.getAsyncClusterConnection();\n         if (conn != null) {\n-          addListener(conn.getAllMetaRegionLocations(fetchTimeoutMs), (locs, error) -> {\n+          final CacheHolder ch = holder.get();\n+          long lastSyncSeqId = ch != null ? ch.lastSyncSeqId : HConstants.NO_SEQNUM;\n+          addListener(conn.syncRoot(lastSyncSeqId, fetchTimeoutMs), (resp, error) -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a0e3c8e7bda7b93b01651ea73dc13217a0cbbdb2"}, "originalPosition": 67}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTM0NzgzOQ==", "bodyText": "The key change is the syncRoot method. The getAllMetaRegionLocations method is also used at client side, so it is not suitable to add parameters which are not useful for client.\nThe point here is that, we should test the MVCC number of the catalog family when syncing root, if there is no change, then we do not need to recreate the meta cache.\nAnd there is a follow on issue to fan out the edits to catalog family to backup masters.", "url": "https://github.com/apache/hbase/pull/2392#discussion_r491347839", "createdAt": "2020-09-19T09:23:39Z", "author": {"login": "Apache9"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/MetaLocationCache.java", "diffHunk": "@@ -102,34 +111,43 @@\n       master.getConfiguration().getInt(SYNC_INTERVAL_SECONDS, DEFAULT_SYNC_INTERVAL_SECONDS);\n     int fetchTimeoutMs =\n       master.getConfiguration().getInt(FETCH_TIMEOUT_MS, DEFAULT_FETCH_TIMEOUT_MS);\n-    master.getChoreService().scheduleChore(new ScheduledChore(\n-      getClass().getSimpleName() + \"-Sync-Chore\", this, syncIntervalSeconds, 0, TimeUnit.SECONDS) {\n+    refreshChore = new ScheduledChore(getClass().getSimpleName() + \"-Sync-Chore\", this,\n+      syncIntervalSeconds, 0, TimeUnit.SECONDS) {\n \n       @Override\n       protected void chore() {\n         AsyncClusterConnection conn = master.getAsyncClusterConnection();\n         if (conn != null) {\n-          addListener(conn.getAllMetaRegionLocations(fetchTimeoutMs), (locs, error) -> {\n+          final CacheHolder ch = holder.get();\n+          long lastSyncSeqId = ch != null ? ch.lastSyncSeqId : HConstants.NO_SEQNUM;\n+          addListener(conn.syncRoot(lastSyncSeqId, fetchTimeoutMs), (resp, error) -> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTI3ODY0NA=="}, "originalCommit": {"oid": "a0e3c8e7bda7b93b01651ea73dc13217a0cbbdb2"}, "originalPosition": 67}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2617, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}