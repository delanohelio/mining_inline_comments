{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDM3MTE1NDkx", "number": 1933, "reviewThreads": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQxNTo1OTowNlrOEHooVw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQyMTo1MTo1N1rOEIiqZQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2NDQxMTc1OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQxNTo1OTowNlrOGnHIZw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQyMzoxNzo1MVrOGnUBQA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzY2NDQ4Nw==", "bodyText": "This changes behaviors for normalizer. Can we give some timeout for blocking so it wont block forever if something goes wrong with one of plans?", "url": "https://github.com/apache/hbase/pull/1933#discussion_r443664487", "createdAt": "2020-06-22T15:59:06Z", "author": {"login": "huaxiangsun"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "diffHunk": "@@ -1957,17 +1959,27 @@ public boolean normalizeRegions() throws IOException {\n             continue;\n           }\n \n-          // as of this writing, `plan.execute()` is non-blocking, so there's no artificial rate-\n-          // limiting of merge requests due to this serial loop.\n+          // as of this writing, `plan.submit()` is non-blocking and uses Async Admin APIs to\n+          // submit task , so there's no artificial rate-\n+          // limiting of merge/split requests due to this serial loop.\n           for (NormalizationPlan plan : plans) {\n-            plan.execute(admin);\n+            Future<Void> future = plan.submit(admin);\n+            submittedPlanList.add(future);\n             if (plan.getType() == PlanType.SPLIT) {\n               splitPlanCount++;\n             } else if (plan.getType() == PlanType.MERGE) {\n               mergePlanCount++;\n             }\n           }\n         }\n+        for (Future<?> submittedPlan : submittedPlanList) {\n+          try {\n+            submittedPlan.get();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "86c475c539184ca5e853c3e4dbe2f6569781643b"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzY4MDA1MA==", "bodyText": "True, there are either of these options we can follow:\n\nTimeout with Future.get()\nPerform all .get() operations asynchronously\n\nWith huge no of submitted plans, do you think it makes sense to even perform .get() asynchronously by ThreadPoolExecutor and let it block until all plans are done and even update normalizationPlanFailureCount count. What do you think?", "url": "https://github.com/apache/hbase/pull/1933#discussion_r443680050", "createdAt": "2020-06-22T16:23:50Z", "author": {"login": "virajjasani"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "diffHunk": "@@ -1957,17 +1959,27 @@ public boolean normalizeRegions() throws IOException {\n             continue;\n           }\n \n-          // as of this writing, `plan.execute()` is non-blocking, so there's no artificial rate-\n-          // limiting of merge requests due to this serial loop.\n+          // as of this writing, `plan.submit()` is non-blocking and uses Async Admin APIs to\n+          // submit task , so there's no artificial rate-\n+          // limiting of merge/split requests due to this serial loop.\n           for (NormalizationPlan plan : plans) {\n-            plan.execute(admin);\n+            Future<Void> future = plan.submit(admin);\n+            submittedPlanList.add(future);\n             if (plan.getType() == PlanType.SPLIT) {\n               splitPlanCount++;\n             } else if (plan.getType() == PlanType.MERGE) {\n               mergePlanCount++;\n             }\n           }\n         }\n+        for (Future<?> submittedPlan : submittedPlanList) {\n+          try {\n+            submittedPlan.get();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzY2NDQ4Nw=="}, "originalCommit": {"oid": "86c475c539184ca5e853c3e4dbe2f6569781643b"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzcwNDYyNQ==", "bodyText": "I don't think the counter as a metric will help an operator very much. Regions can split or merge in the background, causing a planed action to fail. The failure should be logged, I think (maybe the normal split/merge pathways do this already? I haven't checked).\nIt would be nice to have a final log message for the normalizer run that says something like \"successfully executed x of y normalization actions.\"", "url": "https://github.com/apache/hbase/pull/1933#discussion_r443704625", "createdAt": "2020-06-22T17:05:53Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "diffHunk": "@@ -1957,17 +1959,27 @@ public boolean normalizeRegions() throws IOException {\n             continue;\n           }\n \n-          // as of this writing, `plan.execute()` is non-blocking, so there's no artificial rate-\n-          // limiting of merge requests due to this serial loop.\n+          // as of this writing, `plan.submit()` is non-blocking and uses Async Admin APIs to\n+          // submit task , so there's no artificial rate-\n+          // limiting of merge/split requests due to this serial loop.\n           for (NormalizationPlan plan : plans) {\n-            plan.execute(admin);\n+            Future<Void> future = plan.submit(admin);\n+            submittedPlanList.add(future);\n             if (plan.getType() == PlanType.SPLIT) {\n               splitPlanCount++;\n             } else if (plan.getType() == PlanType.MERGE) {\n               mergePlanCount++;\n             }\n           }\n         }\n+        for (Future<?> submittedPlan : submittedPlanList) {\n+          try {\n+            submittedPlan.get();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzY2NDQ4Nw=="}, "originalCommit": {"oid": "86c475c539184ca5e853c3e4dbe2f6569781643b"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mzg3NTY0OA==", "bodyText": "As Nick commented, need to think about the purpose of this change. I think the purpose is to know the result of plans, which comes with cost.\n1). Timeout with Future.get().\nWhen it times out, we do not know if plan succeeds or not. The only info it gives us is that the plan does not finish within a certain amount of time.\n2). Perform all.get() asynchronously.\nIf get() blocks for whatever reason, there will be huge number of threads blocking for get(), system resource leak.\nMaybe the best approach is per Nick's comments, log how many plans submitted. If some plans fail, we can go to procedure system for root cause.", "url": "https://github.com/apache/hbase/pull/1933#discussion_r443875648", "createdAt": "2020-06-22T23:17:51Z", "author": {"login": "huaxiangsun"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "diffHunk": "@@ -1957,17 +1959,27 @@ public boolean normalizeRegions() throws IOException {\n             continue;\n           }\n \n-          // as of this writing, `plan.execute()` is non-blocking, so there's no artificial rate-\n-          // limiting of merge requests due to this serial loop.\n+          // as of this writing, `plan.submit()` is non-blocking and uses Async Admin APIs to\n+          // submit task , so there's no artificial rate-\n+          // limiting of merge/split requests due to this serial loop.\n           for (NormalizationPlan plan : plans) {\n-            plan.execute(admin);\n+            Future<Void> future = plan.submit(admin);\n+            submittedPlanList.add(future);\n             if (plan.getType() == PlanType.SPLIT) {\n               splitPlanCount++;\n             } else if (plan.getType() == PlanType.MERGE) {\n               mergePlanCount++;\n             }\n           }\n         }\n+        for (Future<?> submittedPlan : submittedPlanList) {\n+          try {\n+            submittedPlan.get();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzY2NDQ4Nw=="}, "originalCommit": {"oid": "86c475c539184ca5e853c3e4dbe2f6569781643b"}, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2NDQxODc2OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQxNjowMDo0NFrOGnHMvg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQyMDoyMTo0MVrOGnPngw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzY2NTU5OA==", "bodyText": "Do not see count is being used. Want to add a logging message at the end to see how many plans fail.", "url": "https://github.com/apache/hbase/pull/1933#discussion_r443665598", "createdAt": "2020-06-22T16:00:44Z", "author": {"login": "huaxiangsun"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "diffHunk": "@@ -1957,17 +1959,27 @@ public boolean normalizeRegions() throws IOException {\n             continue;\n           }\n \n-          // as of this writing, `plan.execute()` is non-blocking, so there's no artificial rate-\n-          // limiting of merge requests due to this serial loop.\n+          // as of this writing, `plan.submit()` is non-blocking and uses Async Admin APIs to\n+          // submit task , so there's no artificial rate-\n+          // limiting of merge/split requests due to this serial loop.\n           for (NormalizationPlan plan : plans) {\n-            plan.execute(admin);\n+            Future<Void> future = plan.submit(admin);\n+            submittedPlanList.add(future);\n             if (plan.getType() == PlanType.SPLIT) {\n               splitPlanCount++;\n             } else if (plan.getType() == PlanType.MERGE) {\n               mergePlanCount++;\n             }\n           }\n         }\n+        for (Future<?> submittedPlan : submittedPlanList) {\n+          try {\n+            submittedPlan.get();\n+          } catch (Exception e) {\n+            normalizationPlanFailureCount++;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "86c475c539184ca5e853c3e4dbe2f6569781643b"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzY3ODQxNg==", "bodyText": "Yeah sure, we can put logger but my intention was to expose this as metric. Intentionally kept this as is for now, if you and other reviewers are fine with exposing this count as metric, we should be good to add it.", "url": "https://github.com/apache/hbase/pull/1933#discussion_r443678416", "createdAt": "2020-06-22T16:21:09Z", "author": {"login": "virajjasani"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "diffHunk": "@@ -1957,17 +1959,27 @@ public boolean normalizeRegions() throws IOException {\n             continue;\n           }\n \n-          // as of this writing, `plan.execute()` is non-blocking, so there's no artificial rate-\n-          // limiting of merge requests due to this serial loop.\n+          // as of this writing, `plan.submit()` is non-blocking and uses Async Admin APIs to\n+          // submit task , so there's no artificial rate-\n+          // limiting of merge/split requests due to this serial loop.\n           for (NormalizationPlan plan : plans) {\n-            plan.execute(admin);\n+            Future<Void> future = plan.submit(admin);\n+            submittedPlanList.add(future);\n             if (plan.getType() == PlanType.SPLIT) {\n               splitPlanCount++;\n             } else if (plan.getType() == PlanType.MERGE) {\n               mergePlanCount++;\n             }\n           }\n         }\n+        for (Future<?> submittedPlan : submittedPlanList) {\n+          try {\n+            submittedPlan.get();\n+          } catch (Exception e) {\n+            normalizationPlanFailureCount++;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzY2NTU5OA=="}, "originalCommit": {"oid": "86c475c539184ca5e853c3e4dbe2f6569781643b"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzcwNDQ2Nw==", "bodyText": "Going through the client's admin interface seems unnecessary for this as well. There's no way, for example, to log the PID of the action procedure that failed (unless it happens to be included in an exception message).\n\nCan the action be taken via the MasterServices interface?\nMaybe it's fine to not wait on these actions, so long as the PIDs are successfully submitted. I wonder what kind of back-pressure the system has, though, if multiple normalizer runs result in 1000's of split/merge actions that can't be completed backing up over time. Right now, our protection against this is the lock against multiple concurrent normalizer runs.", "url": "https://github.com/apache/hbase/pull/1933#discussion_r443704467", "createdAt": "2020-06-22T17:05:36Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "diffHunk": "@@ -1957,17 +1959,27 @@ public boolean normalizeRegions() throws IOException {\n             continue;\n           }\n \n-          // as of this writing, `plan.execute()` is non-blocking, so there's no artificial rate-\n-          // limiting of merge requests due to this serial loop.\n+          // as of this writing, `plan.submit()` is non-blocking and uses Async Admin APIs to\n+          // submit task , so there's no artificial rate-\n+          // limiting of merge/split requests due to this serial loop.\n           for (NormalizationPlan plan : plans) {\n-            plan.execute(admin);\n+            Future<Void> future = plan.submit(admin);\n+            submittedPlanList.add(future);\n             if (plan.getType() == PlanType.SPLIT) {\n               splitPlanCount++;\n             } else if (plan.getType() == PlanType.MERGE) {\n               mergePlanCount++;\n             }\n           }\n         }\n+        for (Future<?> submittedPlan : submittedPlanList) {\n+          try {\n+            submittedPlan.get();\n+          } catch (Exception e) {\n+            normalizationPlanFailureCount++;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzY2NTU5OA=="}, "originalCommit": {"oid": "86c475c539184ca5e853c3e4dbe2f6569781643b"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mzc4MzUzOQ==", "bodyText": "Although going through client interface is not necessary, in some way it might simplify things:\n\nWe won't have to re-write the code to convert encodedRegionName to RegionInfo, derive TableName etc and then use MasterServices interface, which requires additional info.\nSince our goal is to submit async plans and not execute blocking operations, Admin interface already has nice non-blocking utility, which is again something we will have to implement on our own if we directly want to use MasterServices (which does use ProcV2 but we want to finally log: x/y plans succeeded, and for that to happen, using Future.get() and handling Exceptions sound better plan).", "url": "https://github.com/apache/hbase/pull/1933#discussion_r443783539", "createdAt": "2020-06-22T19:40:01Z", "author": {"login": "virajjasani"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "diffHunk": "@@ -1957,17 +1959,27 @@ public boolean normalizeRegions() throws IOException {\n             continue;\n           }\n \n-          // as of this writing, `plan.execute()` is non-blocking, so there's no artificial rate-\n-          // limiting of merge requests due to this serial loop.\n+          // as of this writing, `plan.submit()` is non-blocking and uses Async Admin APIs to\n+          // submit task , so there's no artificial rate-\n+          // limiting of merge/split requests due to this serial loop.\n           for (NormalizationPlan plan : plans) {\n-            plan.execute(admin);\n+            Future<Void> future = plan.submit(admin);\n+            submittedPlanList.add(future);\n             if (plan.getType() == PlanType.SPLIT) {\n               splitPlanCount++;\n             } else if (plan.getType() == PlanType.MERGE) {\n               mergePlanCount++;\n             }\n           }\n         }\n+        for (Future<?> submittedPlan : submittedPlanList) {\n+          try {\n+            submittedPlan.get();\n+          } catch (Exception e) {\n+            normalizationPlanFailureCount++;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzY2NTU5OA=="}, "originalCommit": {"oid": "86c475c539184ca5e853c3e4dbe2f6569781643b"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzgwMzUyMw==", "bodyText": "Maybe we don't actually want to log \"plans succeeded\". Maybe it's enough that we log \"N plans submitted\". I would be okay with that. Even better if the debug level could log the PIDs  of the submitted plans, which, I believe, requires going through MasterServices.", "url": "https://github.com/apache/hbase/pull/1933#discussion_r443803523", "createdAt": "2020-06-22T20:21:41Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "diffHunk": "@@ -1957,17 +1959,27 @@ public boolean normalizeRegions() throws IOException {\n             continue;\n           }\n \n-          // as of this writing, `plan.execute()` is non-blocking, so there's no artificial rate-\n-          // limiting of merge requests due to this serial loop.\n+          // as of this writing, `plan.submit()` is non-blocking and uses Async Admin APIs to\n+          // submit task , so there's no artificial rate-\n+          // limiting of merge/split requests due to this serial loop.\n           for (NormalizationPlan plan : plans) {\n-            plan.execute(admin);\n+            Future<Void> future = plan.submit(admin);\n+            submittedPlanList.add(future);\n             if (plan.getType() == PlanType.SPLIT) {\n               splitPlanCount++;\n             } else if (plan.getType() == PlanType.MERGE) {\n               mergePlanCount++;\n             }\n           }\n         }\n+        for (Future<?> submittedPlan : submittedPlanList) {\n+          try {\n+            submittedPlan.get();\n+          } catch (Exception e) {\n+            normalizationPlanFailureCount++;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzY2NTU5OA=="}, "originalCommit": {"oid": "86c475c539184ca5e853c3e4dbe2f6569781643b"}, "originalPosition": 40}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2NDYxMDg1OnYy", "diffSide": "RIGHT", "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/RawAsyncHBaseAdmin.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQxNjo1MToyN1rOGnJF4g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQxNjo1MToyN1rOGnJF4g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzY5NjYxMA==", "bodyText": "Can this be made final as well?", "url": "https://github.com/apache/hbase/pull/1933#discussion_r443696610", "createdAt": "2020-06-22T16:51:27Z", "author": {"login": "ndimiduk"}, "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/RawAsyncHBaseAdmin.java", "diffHunk": "@@ -1294,7 +1294,7 @@ private void checkAndGetTableName(byte[] encodeRegionName, AtomicReference<Table\n         return;\n       }\n \n-      MergeTableRegionsRequest request = null;\n+      MergeTableRegionsRequest request;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "86c475c539184ca5e853c3e4dbe2f6569781643b"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2NDY3NjAzOnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/EmptyNormalizationPlan.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQxNzoxMDo1NFrOGnJvmg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQxNzoxMDo1NFrOGnJvmg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzcwNzI5MA==", "bodyText": "No need for an anonymous class, just use CompletableFuture.completedFuture.", "url": "https://github.com/apache/hbase/pull/1933#discussion_r443707290", "createdAt": "2020-06-22T17:10:54Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/EmptyNormalizationPlan.java", "diffHunk": "@@ -44,7 +45,34 @@ public static EmptyNormalizationPlan getInstance(){\n    * No-op for empty plan.\n    */\n   @Override\n-  public void execute(Admin admin) {\n+  public Future<Void> submit(Admin admin) {\n+    return new Future<Void>() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "86c475c539184ca5e853c3e4dbe2f6569781643b"}, "originalPosition": 16}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2NTI3NTY5OnYy", "diffSide": "RIGHT", "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/RawAsyncHBaseAdmin.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQyMDoyNDoyMFrOGnPszg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQyMDoyNDoyMFrOGnPszg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzgwNDg3OA==", "bodyText": "yes please for method references, \ud83d\udc4d", "url": "https://github.com/apache/hbase/pull/1933#discussion_r443804878", "createdAt": "2020-06-22T20:24:20Z", "author": {"login": "ndimiduk"}, "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/RawAsyncHBaseAdmin.java", "diffHunk": "@@ -1304,8 +1304,8 @@ private void checkAndGetTableName(byte[] encodeRegionName, AtomicReference<Table\n       }\n \n       addListener(\n-        this.<MergeTableRegionsRequest, MergeTableRegionsResponse> procedureCall(tableName, request,\n-          (s, c, req, done) -> s.mergeTableRegions(c, req, done), (resp) -> resp.getProcId(),\n+        this.procedureCall(tableName, request,\n+          MasterService.Interface::mergeTableRegions, MergeTableRegionsResponse::getProcId,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c7ab8efc24f7bb8c69a743fe9f3c387e57783627"}, "originalPosition": 16}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2NTI3OTAxOnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQyMDoyNToxOVrOGnPu9w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQyMDoyNTo0MFrOGnPvvw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzgwNTQzMQ==", "bodyText": "nit: i like to include a unit in these types of constants. i.e., NORMALIZATION_PLAN_WAIT_TIMEOUT_SEC.", "url": "https://github.com/apache/hbase/pull/1933#discussion_r443805431", "createdAt": "2020-06-22T20:25:19Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "diffHunk": "@@ -473,6 +473,10 @@ public void run() {\n   // Cached clusterId on stand by masters to serve clusterID requests from clients.\n   private final CachedClusterId cachedClusterId;\n \n+  // Split/Merge Normalization plan executes asynchronously and the caller blocks on\n+  // waiting max 5 sec for single plan to complete with success/failure.\n+  private static final int NORMALIZATION_PLAN_WAIT_TIMEOUT = 5;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c7ab8efc24f7bb8c69a743fe9f3c387e57783627"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzgwNTYzMQ==", "bodyText": "I'm still not convinced we should do this, per my other comment :)", "url": "https://github.com/apache/hbase/pull/1933#discussion_r443805631", "createdAt": "2020-06-22T20:25:40Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "diffHunk": "@@ -473,6 +473,10 @@ public void run() {\n   // Cached clusterId on stand by masters to serve clusterID requests from clients.\n   private final CachedClusterId cachedClusterId;\n \n+  // Split/Merge Normalization plan executes asynchronously and the caller blocks on\n+  // waiting max 5 sec for single plan to complete with success/failure.\n+  private static final int NORMALIZATION_PLAN_WAIT_TIMEOUT = 5;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzgwNTQzMQ=="}, "originalCommit": {"oid": "c7ab8efc24f7bb8c69a743fe9f3c387e57783627"}, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3MzkxMjI3OnYy", "diffSide": "RIGHT", "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/Admin.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQyMTo0OToxOFrOGokU_A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQyMTo0OToxOFrOGokU_A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTE5MTQyMA==", "bodyText": "nit: \"means the request was submitted successfully.\"", "url": "https://github.com/apache/hbase/pull/1933#discussion_r445191420", "createdAt": "2020-06-24T21:49:18Z", "author": {"login": "ndimiduk"}, "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/Admin.java", "diffHunk": "@@ -833,6 +833,9 @@ void unassign(byte[] regionName, boolean force)\n \n   /**\n    * Invoke region normalizer. Can NOT run for various reasons.  Check logs.\n+   * This is a non-blocking invocation to region normalizer. If return value is true, it means\n+   * the invocation was successful. We need to check logs for the details of which regions", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0071d872c013a6718a428a48c305af085dc6e107"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3MzkxOTczOnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/EmptyNormalizationPlan.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQyMTo1MTo1N1rOGokZow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNVQxOTo0MjoyOVrOGpJPew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTE5MjYxMQ==", "bodyText": "@huaxiangsun does the pid -1 carry a special meaning? Just in case...", "url": "https://github.com/apache/hbase/pull/1933#discussion_r445192611", "createdAt": "2020-06-24T21:51:57Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/EmptyNormalizationPlan.java", "diffHunk": "@@ -44,7 +44,8 @@ public static EmptyNormalizationPlan getInstance(){\n    * No-op for empty plan.\n    */\n   @Override\n-  public void execute(Admin admin) {\n+  public long submit(MasterServices masterServices) throws IOException {\n+    return -1;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0071d872c013a6718a428a48c305af085dc6e107"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTc5NjIxOQ==", "bodyText": "Actually, this class isn't even used. I think you can delete it.", "url": "https://github.com/apache/hbase/pull/1933#discussion_r445796219", "createdAt": "2020-06-25T19:42:29Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/EmptyNormalizationPlan.java", "diffHunk": "@@ -44,7 +44,8 @@ public static EmptyNormalizationPlan getInstance(){\n    * No-op for empty plan.\n    */\n   @Override\n-  public void execute(Admin admin) {\n+  public long submit(MasterServices masterServices) throws IOException {\n+    return -1;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTE5MjYxMQ=="}, "originalCommit": {"oid": "0071d872c013a6718a428a48c305af085dc6e107"}, "originalPosition": 18}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2842, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}