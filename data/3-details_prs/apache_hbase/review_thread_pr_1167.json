{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzc0NjQ0Nzkw", "number": 1167, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xM1QxNTowNzo0NlrODflL-w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xM1QxNToxMzoxM1rODflUJA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM0NDQxNzIzOnYy", "diffSide": "RIGHT", "path": "src/main/asciidoc/_chapters/architecture.adoc", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xM1QxNTowNzo0NlrOFpXYOg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xM1QyMjoyNzo1NFrOFplyRg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODkxODk3MA==", "bodyText": "Should phrase this change in uptime needs of the master ensemble in terms of when the feature is enabled rather than in terms of hbase versions.", "url": "https://github.com/apache/hbase/pull/1167#discussion_r378918970", "createdAt": "2020-02-13T15:07:46Z", "author": {"login": "busbey"}, "path": "src/main/asciidoc/_chapters/architecture.adoc", "diffHunk": "@@ -577,11 +644,24 @@ If the active Master loses its lease in ZooKeeper (or the Master shuts down), th\n [[master.runtime]]\n === Runtime Impact\n \n-A common dist-list question involves what happens to an HBase cluster when the Master goes down.\n+A common dist-list question involves what happens to an HBase cluster when the Master goes down. This information has changed staring 3.0.0.\n+\n+==== Up until releases 2.x.y\n Because the HBase client talks directly to the RegionServers, the cluster can still function in a \"steady state\". Additionally, per <<arch.catalog>>, `hbase:meta` exists as an HBase table and is not resident in the Master.\n However, the Master controls critical functions such as RegionServer failover and completing region splits.\n So while the cluster can still run for a short time without the Master, the Master should be restarted as soon as possible.\n \n+==== Staring release 3.0.0\n+As mentioned in section <<client.masterregistry>>, the default connection registry for clients is now based on master rpc end points. Hence the requirements for\n+masters' uptime are even tighter starting this release.\n+\n+- At least one active or stand by master is needed for a connection set up, unlike before when all the clients needed was a ZooKeeper ensemble.\n+- Master is now in critical path for read/write operations. For example, if the meta region bounces off to a different region server, clients\n+need master to fetch the new locations. Earlier this was done by fetching this information directly from ZooKeeper.\n+- Masters will now have higher connection load than before. So, the server side configuration might need adjustment depending on the load.\n+\n+Overall, the master uptime requirements starting with this version are even higher for the client operations to go through.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "69f4c403ac3bfe53855bd5030b357d1adb4fd345"}, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTE1NTAxNA==", "bodyText": "Done.", "url": "https://github.com/apache/hbase/pull/1167#discussion_r379155014", "createdAt": "2020-02-13T22:27:54Z", "author": {"login": "bharathv"}, "path": "src/main/asciidoc/_chapters/architecture.adoc", "diffHunk": "@@ -577,11 +644,24 @@ If the active Master loses its lease in ZooKeeper (or the Master shuts down), th\n [[master.runtime]]\n === Runtime Impact\n \n-A common dist-list question involves what happens to an HBase cluster when the Master goes down.\n+A common dist-list question involves what happens to an HBase cluster when the Master goes down. This information has changed staring 3.0.0.\n+\n+==== Up until releases 2.x.y\n Because the HBase client talks directly to the RegionServers, the cluster can still function in a \"steady state\". Additionally, per <<arch.catalog>>, `hbase:meta` exists as an HBase table and is not resident in the Master.\n However, the Master controls critical functions such as RegionServer failover and completing region splits.\n So while the cluster can still run for a short time without the Master, the Master should be restarted as soon as possible.\n \n+==== Staring release 3.0.0\n+As mentioned in section <<client.masterregistry>>, the default connection registry for clients is now based on master rpc end points. Hence the requirements for\n+masters' uptime are even tighter starting this release.\n+\n+- At least one active or stand by master is needed for a connection set up, unlike before when all the clients needed was a ZooKeeper ensemble.\n+- Master is now in critical path for read/write operations. For example, if the meta region bounces off to a different region server, clients\n+need master to fetch the new locations. Earlier this was done by fetching this information directly from ZooKeeper.\n+- Masters will now have higher connection load than before. So, the server side configuration might need adjustment depending on the load.\n+\n+Overall, the master uptime requirements starting with this version are even higher for the client operations to go through.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODkxODk3MA=="}, "originalCommit": {"oid": "69f4c403ac3bfe53855bd5030b357d1adb4fd345"}, "originalPosition": 95}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM0NDQyNDMyOnYy", "diffSide": "RIGHT", "path": "dev-support/design-docs/HBASE-18095-Zookeeper-less-client-connection-design.adoc", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xM1QxNTowOTo0NVrOFpXcug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xM1QyMjoyNTo1OFrOFplvEA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODkyMDEyMg==", "bodyText": "Also clients need an additional set of config files in secure deployments because zk uses JAAS", "url": "https://github.com/apache/hbase/pull/1167#discussion_r378920122", "createdAt": "2020-02-13T15:09:45Z", "author": {"login": "busbey"}, "path": "dev-support/design-docs/HBASE-18095-Zookeeper-less-client-connection-design.adoc", "diffHunk": "@@ -0,0 +1,112 @@\n+////\n+/**\n+ *\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+////\n+\n+= HBASE-18095: Zookeeper-less client connection\n+\n+\n+== Context\n+Currently, Zookeeper (ZK) lies in the critical code path of connection init. To set up a connection to a given HBase cluster, client relies on the zookeeper quorum configured in the client hbase-site.xml and attempts to fetch the following information.\n+\n+* ClusterID\n+* Active HMaster server name\n+* Meta table region locations\n+\n+ZK is deemed the source of truth since other processes that maintain the cluster state persist the changes to this data into ZK. So it is an obvious place to look at for clients to fetch the latest cluster state.  However this comes with it\u2019s own set of problems, some of them are below.\n+\n+* Timeouts and retry logic for ZK clients are managed separately from HBase configuration. This is more administration overhead for end users (example: multiple timeouts are to be configured for different types of RPCs. client->master, client->ZK etc.). This prevents HBase from having a single holistic timeout configuration that applies to any RPCs.\n+* If there is any issue with ZK (like connection overload / timeouts), the entire HBase service appears frozen and there is little visibility into it.\n+* Exposing zookeeper to all the clients can be risky since it can potentially be abused to DDOS.\n+* Embedded ZK client is bundled with hbase client jar as a dependency (with it\u2019s log spew :-]).", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "69f4c403ac3bfe53855bd5030b357d1adb4fd345"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTE1NDE5Mg==", "bodyText": "Good point, added.", "url": "https://github.com/apache/hbase/pull/1167#discussion_r379154192", "createdAt": "2020-02-13T22:25:58Z", "author": {"login": "bharathv"}, "path": "dev-support/design-docs/HBASE-18095-Zookeeper-less-client-connection-design.adoc", "diffHunk": "@@ -0,0 +1,112 @@\n+////\n+/**\n+ *\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+////\n+\n+= HBASE-18095: Zookeeper-less client connection\n+\n+\n+== Context\n+Currently, Zookeeper (ZK) lies in the critical code path of connection init. To set up a connection to a given HBase cluster, client relies on the zookeeper quorum configured in the client hbase-site.xml and attempts to fetch the following information.\n+\n+* ClusterID\n+* Active HMaster server name\n+* Meta table region locations\n+\n+ZK is deemed the source of truth since other processes that maintain the cluster state persist the changes to this data into ZK. So it is an obvious place to look at for clients to fetch the latest cluster state.  However this comes with it\u2019s own set of problems, some of them are below.\n+\n+* Timeouts and retry logic for ZK clients are managed separately from HBase configuration. This is more administration overhead for end users (example: multiple timeouts are to be configured for different types of RPCs. client->master, client->ZK etc.). This prevents HBase from having a single holistic timeout configuration that applies to any RPCs.\n+* If there is any issue with ZK (like connection overload / timeouts), the entire HBase service appears frozen and there is little visibility into it.\n+* Exposing zookeeper to all the clients can be risky since it can potentially be abused to DDOS.\n+* Embedded ZK client is bundled with hbase client jar as a dependency (with it\u2019s log spew :-]).", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODkyMDEyMg=="}, "originalCommit": {"oid": "69f4c403ac3bfe53855bd5030b357d1adb4fd345"}, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM0NDQzODEyOnYy", "diffSide": "RIGHT", "path": "src/main/asciidoc/_chapters/configuration.adoc", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xM1QxNToxMzoxM1rOFpXlpA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xM1QyMjozMDowMlrOFpl1xQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODkyMjQwNA==", "bodyText": "This specifically doesn't need to be all of the Masters configured for the cluster, right?\nSo if I wanted to hedge against clients ddosing masters to the point that I can't get an active master for the cluster I could e.g. only give them half of the Masters.\nPresuming that's the case, a brief entry in the troubleshooting section that basically says to do this in case clients are causing masters to die would help us get ahead of that concern.\nI say this as someone who has had to troubleshoot clusters where bad client behavior essentially meant every hbase operation hit ZK for meta and as a result said cluster would die.", "url": "https://github.com/apache/hbase/pull/1167#discussion_r378922404", "createdAt": "2020-02-13T15:13:13Z", "author": {"login": "busbey"}, "path": "src/main/asciidoc/_chapters/configuration.adoc", "diffHunk": "@@ -563,38 +563,63 @@ Changes here will require a cluster restart for HBase to notice the change thoug\n \n If you are running HBase in standalone mode, you don't need to configure anything for your client to work provided that they are all on the same machine.\n \n-Since the HBase Master may move around, clients bootstrap by looking to ZooKeeper for current critical locations.\n-ZooKeeper is where all these values are kept.\n-Thus clients require the location of the ZooKeeper ensemble before they can do anything else.\n-Usually this ensemble location is kept out in the _hbase-site.xml_ and is picked up by the client from the `CLASSPATH`.\n+Starting release 3.0.0, the default connection registry has been switched to a master based implementation. Refer to <<client.masterregistry>> for more details about\n+what a connection registry is and implications of this change. Depending on your HBase version, following is the expected minimal client configuration.\n \n-If you are configuring an IDE to run an HBase client, you should include the _conf/_ directory on your classpath so _hbase-site.xml_ settings can be found (or add _src/test/resources_ to pick up the hbase-site.xml used by tests).\n+==== Up until 2.x.y releases\n+In 2.x.y releases, the default connection registry was based on ZooKeeper as the source of truth. This means that the clients always looked up ZooKeeper znodes to fetch\n+the required metadata. For example, if an active master crashed and the a new master is elected, clients looked up the master znode to fetch\n+the active master address (similarly for meta locations). This meant that the clients needed to have access to ZooKeeper and need to know\n+the ZooKeeper ensemble information before they can do anything. This can be configured in the client configuration xml as follows:\n \n-For Java applications using Maven, including the hbase-shaded-client module is the recommended dependency when connecting to a cluster:\n [source,xml]\n ----\n-<dependency>\n-  <groupId>org.apache.hbase</groupId>\n-  <artifactId>hbase-shaded-client</artifactId>\n-  <version>2.0.0</version>\n-</dependency>\n+<?xml version=\"1.0\"?>\n+<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n+<configuration>\n+  <property>\n+    <name>hbase.zookeeper.quorum</name>\n+    <value>example1,example2,example3</value>\n+    <description> Zookeeper ensemble information</description>\n+  </property>\n+</configuration>\n ----\n \n-A basic example _hbase-site.xml_ for client only may look as follows:\n+==== Starting 3.0.0 release\n+\n+The default implementation was switched to a master based connection registry. With this implementation, clients always contact the active or\n+stand-by master RPC end points to fetch the the connection registry information. This means that the clients should have access to the list of active and master\n+end points before they can do anything. This can be configured in the client configuration xml as follows:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "69f4c403ac3bfe53855bd5030b357d1adb4fd345"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTE1NTkwOQ==", "bodyText": "This specifically doesn't need to be all of the Masters configured for the cluster, right?\nRight.\n\nAdded some notes on trouble shooting.", "url": "https://github.com/apache/hbase/pull/1167#discussion_r379155909", "createdAt": "2020-02-13T22:30:02Z", "author": {"login": "bharathv"}, "path": "src/main/asciidoc/_chapters/configuration.adoc", "diffHunk": "@@ -563,38 +563,63 @@ Changes here will require a cluster restart for HBase to notice the change thoug\n \n If you are running HBase in standalone mode, you don't need to configure anything for your client to work provided that they are all on the same machine.\n \n-Since the HBase Master may move around, clients bootstrap by looking to ZooKeeper for current critical locations.\n-ZooKeeper is where all these values are kept.\n-Thus clients require the location of the ZooKeeper ensemble before they can do anything else.\n-Usually this ensemble location is kept out in the _hbase-site.xml_ and is picked up by the client from the `CLASSPATH`.\n+Starting release 3.0.0, the default connection registry has been switched to a master based implementation. Refer to <<client.masterregistry>> for more details about\n+what a connection registry is and implications of this change. Depending on your HBase version, following is the expected minimal client configuration.\n \n-If you are configuring an IDE to run an HBase client, you should include the _conf/_ directory on your classpath so _hbase-site.xml_ settings can be found (or add _src/test/resources_ to pick up the hbase-site.xml used by tests).\n+==== Up until 2.x.y releases\n+In 2.x.y releases, the default connection registry was based on ZooKeeper as the source of truth. This means that the clients always looked up ZooKeeper znodes to fetch\n+the required metadata. For example, if an active master crashed and the a new master is elected, clients looked up the master znode to fetch\n+the active master address (similarly for meta locations). This meant that the clients needed to have access to ZooKeeper and need to know\n+the ZooKeeper ensemble information before they can do anything. This can be configured in the client configuration xml as follows:\n \n-For Java applications using Maven, including the hbase-shaded-client module is the recommended dependency when connecting to a cluster:\n [source,xml]\n ----\n-<dependency>\n-  <groupId>org.apache.hbase</groupId>\n-  <artifactId>hbase-shaded-client</artifactId>\n-  <version>2.0.0</version>\n-</dependency>\n+<?xml version=\"1.0\"?>\n+<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n+<configuration>\n+  <property>\n+    <name>hbase.zookeeper.quorum</name>\n+    <value>example1,example2,example3</value>\n+    <description> Zookeeper ensemble information</description>\n+  </property>\n+</configuration>\n ----\n \n-A basic example _hbase-site.xml_ for client only may look as follows:\n+==== Starting 3.0.0 release\n+\n+The default implementation was switched to a master based connection registry. With this implementation, clients always contact the active or\n+stand-by master RPC end points to fetch the the connection registry information. This means that the clients should have access to the list of active and master\n+end points before they can do anything. This can be configured in the client configuration xml as follows:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODkyMjQwNA=="}, "originalCommit": {"oid": "69f4c403ac3bfe53855bd5030b357d1adb4fd345"}, "originalPosition": 42}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2074, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}