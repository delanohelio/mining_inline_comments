{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDU4MjMzMzQy", "number": 2167, "reviewThreads": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwNzowOToxNVrOETH5ng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QwMzoyMTozMlrOEUdIkw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NDg3ODM4OnYy", "diffSide": "LEFT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwNzowOToxNVrOG4rbFQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwNzo0Mjo0NFrOG4sfLw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjA4NDg4NQ==", "bodyText": "Remove HBASE-24790  related change in this PR.", "url": "https://github.com/apache/hbase/pull/2167#discussion_r462084885", "createdAt": "2020-07-29T07:09:15Z", "author": {"login": "pankaj72981"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java", "diffHunk": "@@ -32,8 +32,6 @@\n   public final static LongAdder tot_mgr_log_split_batch_start = new LongAdder();\n   public final static LongAdder tot_mgr_log_split_batch_success = new LongAdder();\n   public final static LongAdder tot_mgr_log_split_batch_err = new LongAdder();\n-  public final static LongAdder tot_mgr_new_unexpected_wals = new LongAdder();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e7553034bd68b13666e4571530974df0a7625ebd"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjEwMjMxOQ==", "bodyText": "Thanks for view @pankaj72981\nI will remove the HBASE-24790 related change in this PR", "url": "https://github.com/apache/hbase/pull/2167#discussion_r462102319", "createdAt": "2020-07-29T07:42:44Z", "author": {"login": "utf7"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogCounters.java", "diffHunk": "@@ -32,8 +32,6 @@\n   public final static LongAdder tot_mgr_log_split_batch_start = new LongAdder();\n   public final static LongAdder tot_mgr_log_split_batch_success = new LongAdder();\n   public final static LongAdder tot_mgr_log_split_batch_err = new LongAdder();\n-  public final static LongAdder tot_mgr_new_unexpected_wals = new LongAdder();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjA4NDg4NQ=="}, "originalCommit": {"oid": "e7553034bd68b13666e4571530974df0a7625ebd"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NTAwNzc2OnYy", "diffSide": "LEFT", "path": "hbase-mapreduce/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat2.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwNzo0Nzo0OFrOG4spqA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwODoxNTo0NFrOG4tnyw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjEwNTAwMA==", "bodyText": "That is a nice find.\nBTW reading this part of code, I think so much of optimization we can do.  It might not be relevant as this change. Though good to do IMO\n...\n} else {\ntableNameBytes = Bytes.toBytes(writeTableNames);\n}\nString tableName = Bytes.toString(tableNameBytes);\n...\nOnly in case of multiTable, we need create tableName  and tableNameBytes  again and again for every write. So we can make sure this is created at 1st and do not create every time for not multiTable case.\nprivate Path getTableRelativePath(byte[] tableNameBytes) {\nString tableName = Bytes.toString(tableNameBytes);\nString[] tableNameParts = tableName.split(\":\");\nPath tableRelPath = new Path(tableName.split(\":\")[0]);\nif (tableNameParts.length > 1) {\ntableRelPath = new Path(tableRelPath, tableName.split(\":\")[1]);\n}\nreturn tableRelPath;\n}\nsplit is done 3 times. We can just refer tableNameParts[0], tableNameParts[1] and other places.\nCan u pls include these kind of fixes also in PR?", "url": "https://github.com/apache/hbase/pull/2167#discussion_r462105000", "createdAt": "2020-07-29T07:47:48Z", "author": {"login": "anoopsjohn"}, "path": "hbase-mapreduce/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat2.java", "diffHunk": "@@ -248,7 +248,6 @@ public void write(ImmutableBytesWritable row, V cell) throws IOException {\n           tableNameBytes = Bytes.toBytes(writeTableNames);\n         }\n         String tableName = Bytes.toString(tableNameBytes);\n-        Path tableRelPath = getTableRelativePath(tableNameBytes);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e7553034bd68b13666e4571530974df0a7625ebd"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjEyMDkwNw==", "bodyText": "tableName split 3 times int  getTableRelativePath method has fixed in this PR\ni will do some other fixes  in next commit , the code there is a little mess", "url": "https://github.com/apache/hbase/pull/2167#discussion_r462120907", "createdAt": "2020-07-29T08:15:44Z", "author": {"login": "utf7"}, "path": "hbase-mapreduce/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat2.java", "diffHunk": "@@ -248,7 +248,6 @@ public void write(ImmutableBytesWritable row, V cell) throws IOException {\n           tableNameBytes = Bytes.toBytes(writeTableNames);\n         }\n         String tableName = Bytes.toString(tableNameBytes);\n-        Path tableRelPath = getTableRelativePath(tableNameBytes);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjEwNTAwMA=="}, "originalCommit": {"oid": "e7553034bd68b13666e4571530974df0a7625ebd"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NTYzOTg2OnYy", "diffSide": "RIGHT", "path": "hbase-mapreduce/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat2.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxMDozNjo0MVrOG4yrWQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxNDoyNzoyOFrOG47H7A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjIwMzczNw==", "bodyText": "Remove extra semicolon at end.", "url": "https://github.com/apache/hbase/pull/2167#discussion_r462203737", "createdAt": "2020-07-29T10:36:41Z", "author": {"login": "pankaj72981"}, "path": "hbase-mapreduce/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat2.java", "diffHunk": "@@ -222,6 +222,7 @@ public RegionLocator getRegionLocator() {\n       private final Map<byte[], WriterLength> writers = new TreeMap<>(Bytes.BYTES_COMPARATOR);\n       private final Map<byte[], byte[]> previousRows = new TreeMap<>(Bytes.BYTES_COMPARATOR);\n       private final long now = EnvironmentEdgeManager.currentTime();\n+      private byte[] tableNameBytes =  Bytes.toBytes(writeTableNames);;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "68dcef9376b8ec9e5f97834d53a439e7d40bed9e"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjMyNTU1NQ==", "bodyText": "ok,thanks for ponit it", "url": "https://github.com/apache/hbase/pull/2167#discussion_r462325555", "createdAt": "2020-07-29T14:06:33Z", "author": {"login": "utf7"}, "path": "hbase-mapreduce/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat2.java", "diffHunk": "@@ -222,6 +222,7 @@ public RegionLocator getRegionLocator() {\n       private final Map<byte[], WriterLength> writers = new TreeMap<>(Bytes.BYTES_COMPARATOR);\n       private final Map<byte[], byte[]> previousRows = new TreeMap<>(Bytes.BYTES_COMPARATOR);\n       private final long now = EnvironmentEdgeManager.currentTime();\n+      private byte[] tableNameBytes =  Bytes.toBytes(writeTableNames);;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjIwMzczNw=="}, "originalCommit": {"oid": "68dcef9376b8ec9e5f97834d53a439e7d40bed9e"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjM0MjEyNA==", "bodyText": "has finished", "url": "https://github.com/apache/hbase/pull/2167#discussion_r462342124", "createdAt": "2020-07-29T14:27:28Z", "author": {"login": "utf7"}, "path": "hbase-mapreduce/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat2.java", "diffHunk": "@@ -222,6 +222,7 @@ public RegionLocator getRegionLocator() {\n       private final Map<byte[], WriterLength> writers = new TreeMap<>(Bytes.BYTES_COMPARATOR);\n       private final Map<byte[], byte[]> previousRows = new TreeMap<>(Bytes.BYTES_COMPARATOR);\n       private final long now = EnvironmentEdgeManager.currentTime();\n+      private byte[] tableNameBytes =  Bytes.toBytes(writeTableNames);;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjIwMzczNw=="}, "originalCommit": {"oid": "68dcef9376b8ec9e5f97834d53a439e7d40bed9e"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4ODAzMTYzOnYy", "diffSide": "RIGHT", "path": "hbase-mapreduce/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat2.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMDo1NzoxM1rOG5J4OA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQwMDo1NzozMlrOG5PSEQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU4Mzg2NA==", "bodyText": "Does this apply when LOCALITY_SENSITIVE_CONF_KEY check on line 274 is false ?", "url": "https://github.com/apache/hbase/pull/2167#discussion_r462583864", "createdAt": "2020-07-29T20:57:13Z", "author": {"login": "tedyu"}, "path": "hbase-mapreduce/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat2.java", "diffHunk": "@@ -274,39 +270,36 @@ public void write(ImmutableBytesWritable row, V cell) throws IOException {\n \n         // create a new WAL writer, if necessary\n         if (wl == null || wl.writer == null) {\n+          InetSocketAddress[] favoredNodes = null;\n           if (conf.getBoolean(LOCALITY_SENSITIVE_CONF_KEY, DEFAULT_LOCALITY_SENSITIVE)) {\n             HRegionLocation loc = null;\n-\n+            String tableName = Bytes.toString(tableNameBytes);\n             if (tableName != null) {\n               try (Connection connection = ConnectionFactory.createConnection(conf);\n-                     RegionLocator locator =\n-                       connection.getRegionLocator(TableName.valueOf(tableName))) {\n+                RegionLocator locator = connection.getRegionLocator(TableName.valueOf(tableName))) {\n                 loc = locator.getRegionLocation(rowKey);\n               } catch (Throwable e) {\n-                LOG.warn(\"Something wrong locating rowkey {} in {}\",\n-                  Bytes.toString(rowKey), tableName, e);\n+                LOG.warn(\"Something wrong locating rowkey {} in {}\", Bytes.toString(rowKey),\n+                  tableName, e);\n                 loc = null;\n-              } }\n-\n+              }\n+            }\n             if (null == loc) {\n               LOG.trace(\"Failed get of location, use default writer {}\", Bytes.toString(rowKey));\n-              wl = getNewWriter(tableNameBytes, family, conf, null);\n             } else {\n               LOG.debug(\"First rowkey: [{}]\", Bytes.toString(rowKey));\n               InetSocketAddress initialIsa =\n                   new InetSocketAddress(loc.getHostname(), loc.getPort());\n               if (initialIsa.isUnresolved()) {\n                 LOG.trace(\"Failed resolve address {}, use default writer\", loc.getHostnamePort());\n-                wl = getNewWriter(tableNameBytes, family, conf, null);\n               } else {\n                 LOG.debug(\"Use favored nodes writer: {}\", initialIsa.getHostString());\n-                wl = getNewWriter(tableNameBytes, family, conf, new InetSocketAddress[] { initialIsa\n-                });\n+                favoredNodes = new InetSocketAddress[] { initialIsa};", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bd75fac9e8256e2c5135a5da7981823aa6afe9a"}, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjY3MjQwMQ==", "bodyText": "Yes, if the LOCALITY_SENSITIVE_CONF_KEY  is false or get locality failed,the favoredNodes  will be null\nif LOCALITY_SENSITIVE_CONF_KEY   = true and get localicy success ,the favoredNodes will be not null\nsame logic with before , just code clean\nbefore this pr, too much  wl = getNewWriter  in the code", "url": "https://github.com/apache/hbase/pull/2167#discussion_r462672401", "createdAt": "2020-07-30T00:57:32Z", "author": {"login": "utf7"}, "path": "hbase-mapreduce/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat2.java", "diffHunk": "@@ -274,39 +270,36 @@ public void write(ImmutableBytesWritable row, V cell) throws IOException {\n \n         // create a new WAL writer, if necessary\n         if (wl == null || wl.writer == null) {\n+          InetSocketAddress[] favoredNodes = null;\n           if (conf.getBoolean(LOCALITY_SENSITIVE_CONF_KEY, DEFAULT_LOCALITY_SENSITIVE)) {\n             HRegionLocation loc = null;\n-\n+            String tableName = Bytes.toString(tableNameBytes);\n             if (tableName != null) {\n               try (Connection connection = ConnectionFactory.createConnection(conf);\n-                     RegionLocator locator =\n-                       connection.getRegionLocator(TableName.valueOf(tableName))) {\n+                RegionLocator locator = connection.getRegionLocator(TableName.valueOf(tableName))) {\n                 loc = locator.getRegionLocation(rowKey);\n               } catch (Throwable e) {\n-                LOG.warn(\"Something wrong locating rowkey {} in {}\",\n-                  Bytes.toString(rowKey), tableName, e);\n+                LOG.warn(\"Something wrong locating rowkey {} in {}\", Bytes.toString(rowKey),\n+                  tableName, e);\n                 loc = null;\n-              } }\n-\n+              }\n+            }\n             if (null == loc) {\n               LOG.trace(\"Failed get of location, use default writer {}\", Bytes.toString(rowKey));\n-              wl = getNewWriter(tableNameBytes, family, conf, null);\n             } else {\n               LOG.debug(\"First rowkey: [{}]\", Bytes.toString(rowKey));\n               InetSocketAddress initialIsa =\n                   new InetSocketAddress(loc.getHostname(), loc.getPort());\n               if (initialIsa.isUnresolved()) {\n                 LOG.trace(\"Failed resolve address {}, use default writer\", loc.getHostnamePort());\n-                wl = getNewWriter(tableNameBytes, family, conf, null);\n               } else {\n                 LOG.debug(\"Use favored nodes writer: {}\", initialIsa.getHostString());\n-                wl = getNewWriter(tableNameBytes, family, conf, new InetSocketAddress[] { initialIsa\n-                });\n+                favoredNodes = new InetSocketAddress[] { initialIsa};", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU4Mzg2NA=="}, "originalCommit": {"oid": "0bd75fac9e8256e2c5135a5da7981823aa6afe9a"}, "originalPosition": 80}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5ODgzMDMzOnYy", "diffSide": "RIGHT", "path": "hbase-mapreduce/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat2.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QwMzoxMjozOVrOG6q30A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QwMzoxMjozOVrOG6q30A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDE3MzAwOA==", "bodyText": "Looks like a format issue here?", "url": "https://github.com/apache/hbase/pull/2167#discussion_r464173008", "createdAt": "2020-08-03T03:12:39Z", "author": {"login": "anoopsjohn"}, "path": "hbase-mapreduce/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat2.java", "diffHunk": "@@ -274,39 +270,36 @@ public void write(ImmutableBytesWritable row, V cell) throws IOException {\n \n         // create a new WAL writer, if necessary\n         if (wl == null || wl.writer == null) {\n+          InetSocketAddress[] favoredNodes = null;\n           if (conf.getBoolean(LOCALITY_SENSITIVE_CONF_KEY, DEFAULT_LOCALITY_SENSITIVE)) {\n             HRegionLocation loc = null;\n-\n+            String tableName = Bytes.toString(tableNameBytes);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bd75fac9e8256e2c5135a5da7981823aa6afe9a"}, "originalPosition": 49}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5ODgzMTIxOnYy", "diffSide": "RIGHT", "path": "hbase-mapreduce/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat2.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QwMzoxMzoxN1rOG6q4Uw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QwMzoxMzoxN1rOG6q4Uw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDE3MzEzOQ==", "bodyText": "Here also.", "url": "https://github.com/apache/hbase/pull/2167#discussion_r464173139", "createdAt": "2020-08-03T03:13:17Z", "author": {"login": "anoopsjohn"}, "path": "hbase-mapreduce/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat2.java", "diffHunk": "@@ -274,39 +270,36 @@ public void write(ImmutableBytesWritable row, V cell) throws IOException {\n \n         // create a new WAL writer, if necessary\n         if (wl == null || wl.writer == null) {\n+          InetSocketAddress[] favoredNodes = null;\n           if (conf.getBoolean(LOCALITY_SENSITIVE_CONF_KEY, DEFAULT_LOCALITY_SENSITIVE)) {\n             HRegionLocation loc = null;\n-\n+            String tableName = Bytes.toString(tableNameBytes);\n             if (tableName != null) {\n               try (Connection connection = ConnectionFactory.createConnection(conf);\n-                     RegionLocator locator =\n-                       connection.getRegionLocator(TableName.valueOf(tableName))) {\n+                RegionLocator locator = connection.getRegionLocator(TableName.valueOf(tableName))) {\n                 loc = locator.getRegionLocation(rowKey);\n               } catch (Throwable e) {\n-                LOG.warn(\"Something wrong locating rowkey {} in {}\",\n-                  Bytes.toString(rowKey), tableName, e);\n+                LOG.warn(\"Something wrong locating rowkey {} in {}\", Bytes.toString(rowKey),\n+                  tableName, e);\n                 loc = null;\n-              } }\n-\n+              }\n+            }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bd75fac9e8256e2c5135a5da7981823aa6afe9a"}, "originalPosition": 65}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5ODgzMjc4OnYy", "diffSide": "RIGHT", "path": "hbase-mapreduce/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat2.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QwMzoxNDoyMVrOG6q5SA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QwNjowNDoyMFrOG6tHig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDE3MzM4NA==", "bodyText": "Pls check format issue at these changed/added lines once.", "url": "https://github.com/apache/hbase/pull/2167#discussion_r464173384", "createdAt": "2020-08-03T03:14:21Z", "author": {"login": "anoopsjohn"}, "path": "hbase-mapreduce/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat2.java", "diffHunk": "@@ -376,16 +369,15 @@ private WriterLength getNewWriter(byte[] tableName, byte[] family, Configuration\n         DataBlockEncoding encoding = overriddenEncoding;\n         encoding = encoding == null ? datablockEncodingMap.get(tableAndFamily) : encoding;\n         encoding = encoding == null ? DataBlockEncoding.NONE : encoding;\n-        HFileContextBuilder contextBuilder = new HFileContextBuilder()\n-          .withCompression(compression).withChecksumType(HStore.getChecksumType(conf))\n-          .withBytesPerCheckSum(HStore.getBytesPerChecksum(conf)).withBlockSize(blockSize)\n-          .withColumnFamily(family).withTableName(tableName);\n+        HFileContextBuilder contextBuilder = new HFileContextBuilder().withCompression(compression)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bd75fac9e8256e2c5135a5da7981823aa6afe9a"}, "originalPosition": 111}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDIwOTgwMg==", "bodyText": "i move the compression set config to here and has been use hbase-eclipse-format format the code here", "url": "https://github.com/apache/hbase/pull/2167#discussion_r464209802", "createdAt": "2020-08-03T06:04:20Z", "author": {"login": "utf7"}, "path": "hbase-mapreduce/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat2.java", "diffHunk": "@@ -376,16 +369,15 @@ private WriterLength getNewWriter(byte[] tableName, byte[] family, Configuration\n         DataBlockEncoding encoding = overriddenEncoding;\n         encoding = encoding == null ? datablockEncodingMap.get(tableAndFamily) : encoding;\n         encoding = encoding == null ? DataBlockEncoding.NONE : encoding;\n-        HFileContextBuilder contextBuilder = new HFileContextBuilder()\n-          .withCompression(compression).withChecksumType(HStore.getChecksumType(conf))\n-          .withBytesPerCheckSum(HStore.getBytesPerChecksum(conf)).withBlockSize(blockSize)\n-          .withColumnFamily(family).withTableName(tableName);\n+        HFileContextBuilder contextBuilder = new HFileContextBuilder().withCompression(compression)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDE3MzM4NA=="}, "originalCommit": {"oid": "0bd75fac9e8256e2c5135a5da7981823aa6afe9a"}, "originalPosition": 111}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5ODg0MzA3OnYy", "diffSide": "RIGHT", "path": "hbase-mapreduce/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat2.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QwMzoyMTozMlrOG6q_Bg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QwNTo1NjoyMFrOG6s-3Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDE3NDg1NA==", "bodyText": "Should we do this under writeMultipleTables check?\nprivate byte[] tableNameBytes = (writeMultipleTables)? null: Bytes.toBytes(writeTableNames);", "url": "https://github.com/apache/hbase/pull/2167#discussion_r464174854", "createdAt": "2020-08-03T03:21:32Z", "author": {"login": "anoopsjohn"}, "path": "hbase-mapreduce/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat2.java", "diffHunk": "@@ -222,6 +222,7 @@ public RegionLocator getRegionLocator() {\n       private final Map<byte[], WriterLength> writers = new TreeMap<>(Bytes.BYTES_COMPARATOR);\n       private final Map<byte[], byte[]> previousRows = new TreeMap<>(Bytes.BYTES_COMPARATOR);\n       private final long now = EnvironmentEdgeManager.currentTime();\n+      private byte[] tableNameBytes = Bytes.toBytes(writeTableNames);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bd75fac9e8256e2c5135a5da7981823aa6afe9a"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDIwNzU4MQ==", "bodyText": "yes\uff0ci want to make code simple, so just keep init no matter multiple or not\nIt is a good ponit to  use use writeMultipleTables  check,will address it", "url": "https://github.com/apache/hbase/pull/2167#discussion_r464207581", "createdAt": "2020-08-03T05:56:20Z", "author": {"login": "utf7"}, "path": "hbase-mapreduce/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat2.java", "diffHunk": "@@ -222,6 +222,7 @@ public RegionLocator getRegionLocator() {\n       private final Map<byte[], WriterLength> writers = new TreeMap<>(Bytes.BYTES_COMPARATOR);\n       private final Map<byte[], byte[]> previousRows = new TreeMap<>(Bytes.BYTES_COMPARATOR);\n       private final long now = EnvironmentEdgeManager.currentTime();\n+      private byte[] tableNameBytes = Bytes.toBytes(writeTableNames);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDE3NDg1NA=="}, "originalCommit": {"oid": "0bd75fac9e8256e2c5135a5da7981823aa6afe9a"}, "originalPosition": 4}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2720, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}