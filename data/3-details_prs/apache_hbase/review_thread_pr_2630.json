{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTE3MTQzNTEy", "number": 2630, "reviewThreads": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQwNzoxOToyMlrOE3F0tg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMlQxNToxMzo0OVrOE7-uLw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI2MjAyNTUwOnYy", "diffSide": "RIGHT", "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/shaded/protobuf/ProtobufUtil.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQwNzoxOToyMlrOHwPCtw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMVQxNjoxNTo0NlrOH3vlUA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDM0MDE1MQ==", "bodyText": "Let's also test for Append and keep the last else branch throwing DoNotRetryIOException?", "url": "https://github.com/apache/hbase/pull/2630#discussion_r520340151", "createdAt": "2020-11-10T07:19:22Z", "author": {"login": "Apache9"}, "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/shaded/protobuf/ProtobufUtil.java", "diffHunk": "@@ -3657,9 +3657,10 @@ public static CheckAndMutate toCheckAndMutate(ClientProtos.Condition condition,\n           return builder.build((Put) m);\n         } else if (m instanceof Delete) {\n           return builder.build((Delete) m);\n+        } else if (m instanceof Increment) {\n+          return builder.build((Increment) m);\n         } else {\n-          throw new DoNotRetryIOException(\"Unsupported mutate type: \" + mutations.get(0)\n-            .getClass().getSimpleName().toUpperCase());\n+          return builder.build((Append) m);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d086fea73cd92687610bc15882f59a1a6a771902"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjkyMzMyMA==", "bodyText": "After this change, only Put/Delete/Increment/Append inherit Mutation. Do we still need to test for Append and keep the last else branch throwing DoNotRetryIOException?", "url": "https://github.com/apache/hbase/pull/2630#discussion_r522923320", "createdAt": "2020-11-13T12:36:31Z", "author": {"login": "brfrn169"}, "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/shaded/protobuf/ProtobufUtil.java", "diffHunk": "@@ -3657,9 +3657,10 @@ public static CheckAndMutate toCheckAndMutate(ClientProtos.Condition condition,\n           return builder.build((Put) m);\n         } else if (m instanceof Delete) {\n           return builder.build((Delete) m);\n+        } else if (m instanceof Increment) {\n+          return builder.build((Increment) m);\n         } else {\n-          throw new DoNotRetryIOException(\"Unsupported mutate type: \" + mutations.get(0)\n-            .getClass().getSimpleName().toUpperCase());\n+          return builder.build((Append) m);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDM0MDE1MQ=="}, "originalCommit": {"oid": "d086fea73cd92687610bc15882f59a1a6a771902"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODIwNTM5MQ==", "bodyText": "This is for safety. Maybe in the future someone other than us two will implement a new type of Mutation and we will throw a DoNotRetryIOException directly here which will be easy to know what's wrong here, otherwise the behavior will be confusing.", "url": "https://github.com/apache/hbase/pull/2630#discussion_r528205391", "createdAt": "2020-11-21T15:01:02Z", "author": {"login": "Apache9"}, "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/shaded/protobuf/ProtobufUtil.java", "diffHunk": "@@ -3657,9 +3657,10 @@ public static CheckAndMutate toCheckAndMutate(ClientProtos.Condition condition,\n           return builder.build((Put) m);\n         } else if (m instanceof Delete) {\n           return builder.build((Delete) m);\n+        } else if (m instanceof Increment) {\n+          return builder.build((Increment) m);\n         } else {\n-          throw new DoNotRetryIOException(\"Unsupported mutate type: \" + mutations.get(0)\n-            .getClass().getSimpleName().toUpperCase());\n+          return builder.build((Append) m);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDM0MDE1MQ=="}, "originalCommit": {"oid": "d086fea73cd92687610bc15882f59a1a6a771902"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODIxMzMyOA==", "bodyText": "Sure. I will add testing for Append and keep the last else branch throwing DoNotRetryIOException.", "url": "https://github.com/apache/hbase/pull/2630#discussion_r528213328", "createdAt": "2020-11-21T16:15:46Z", "author": {"login": "brfrn169"}, "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/shaded/protobuf/ProtobufUtil.java", "diffHunk": "@@ -3657,9 +3657,10 @@ public static CheckAndMutate toCheckAndMutate(ClientProtos.Condition condition,\n           return builder.build((Put) m);\n         } else if (m instanceof Delete) {\n           return builder.build((Delete) m);\n+        } else if (m instanceof Increment) {\n+          return builder.build((Increment) m);\n         } else {\n-          throw new DoNotRetryIOException(\"Unsupported mutate type: \" + mutations.get(0)\n-            .getClass().getSimpleName().toUpperCase());\n+          return builder.build((Append) m);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDM0MDE1MQ=="}, "originalCommit": {"oid": "d086fea73cd92687610bc15882f59a1a6a771902"}, "originalPosition": 9}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI2MjAyODA4OnYy", "diffSide": "RIGHT", "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/CheckAndMutate.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQwNzoyMDoyMlrOHwPEOQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMVQxNjoxMzo0N1rOH3vkTA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDM0MDUzNw==", "bodyText": "Why this change?", "url": "https://github.com/apache/hbase/pull/2630#discussion_r520340537", "createdAt": "2020-11-10T07:20:22Z", "author": {"login": "Apache9"}, "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/CheckAndMutate.java", "diffHunk": "@@ -60,7 +53,7 @@\n  */\n @InterfaceAudience.Public\n @InterfaceStability.Evolving\n-public final class CheckAndMutate extends Mutation {\n+public final class CheckAndMutate implements Row {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d086fea73cd92687610bc15882f59a1a6a771902"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjkyMDg4NA==", "bodyText": "In HBASE-24996 and HBASE-24210, I gave up treating CheckAndMutate as Mutation where we can perform CheckAndMutate with other mutations atomically. Given that, I thought it would be better to make CheckAndMutate implement Row because CheckAndMutate had a lot of unsupported methods. What do you think?", "url": "https://github.com/apache/hbase/pull/2630#discussion_r522920884", "createdAt": "2020-11-13T12:31:23Z", "author": {"login": "brfrn169"}, "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/CheckAndMutate.java", "diffHunk": "@@ -60,7 +53,7 @@\n  */\n @InterfaceAudience.Public\n @InterfaceStability.Evolving\n-public final class CheckAndMutate extends Mutation {\n+public final class CheckAndMutate implements Row {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDM0MDUzNw=="}, "originalCommit": {"oid": "d086fea73cd92687610bc15882f59a1a6a771902"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODIwNTYyNQ==", "bodyText": "OK, I'm fine with it, but since this is IA.Public, we need to make sure that we haven't release this class out yet? There will be a 2.4.0 release soon.", "url": "https://github.com/apache/hbase/pull/2630#discussion_r528205625", "createdAt": "2020-11-21T15:03:00Z", "author": {"login": "Apache9"}, "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/CheckAndMutate.java", "diffHunk": "@@ -60,7 +53,7 @@\n  */\n @InterfaceAudience.Public\n @InterfaceStability.Evolving\n-public final class CheckAndMutate extends Mutation {\n+public final class CheckAndMutate implements Row {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDM0MDUzNw=="}, "originalCommit": {"oid": "d086fea73cd92687610bc15882f59a1a6a771902"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODIxMzA2OA==", "bodyText": "We haven't released the CheckAndMutate class yet. It's introduced in 2.4.0. We need to commit this change before releasing 2.4.0.", "url": "https://github.com/apache/hbase/pull/2630#discussion_r528213068", "createdAt": "2020-11-21T16:13:47Z", "author": {"login": "brfrn169"}, "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/CheckAndMutate.java", "diffHunk": "@@ -60,7 +53,7 @@\n  */\n @InterfaceAudience.Public\n @InterfaceStability.Evolving\n-public final class CheckAndMutate extends Mutation {\n+public final class CheckAndMutate implements Row {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDM0MDUzNw=="}, "originalCommit": {"oid": "d086fea73cd92687610bc15882f59a1a6a771902"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI2MjAzODY2OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQwNzoyNDoxOVrOHwPKZw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xM1QxMjo0Mzo1NlrOHys7Gg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDM0MjExOQ==", "bodyText": "This is an optimization?", "url": "https://github.com/apache/hbase/pull/2630#discussion_r520342119", "createdAt": "2020-11-10T07:24:19Z", "author": {"login": "Apache9"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java", "diffHunk": "@@ -3900,33 +3903,51 @@ public void prepareMiniBatchOperations(MiniBatchOperationInProgress<Mutation> mi\n             Bytes.toBytes(timestamp));\n           miniBatchOp.incrementNumOfDeletes();\n         } else if (mutation instanceof Increment || mutation instanceof Append) {\n+          boolean returnResults;\n+          if (mutation instanceof Increment) {\n+            returnResults = ((Increment) mutation).isReturnResults();\n+          } else {\n+            returnResults = ((Append) mutation).isReturnResults();\n+          }\n+\n           // For nonce operations\n           canProceed[index] = startNonceOperation(nonceGroup, nonce);\n           if (!canProceed[index]) {\n-            // convert duplicate increment/append to get\n-            List<Cell> results = region.get(toGet(mutation), false, nonceGroup, nonce);\n-            retCodeDetails[index] = new OperationStatus(OperationStatusCode.SUCCESS,\n-              Result.create(results));\n+            Result result;\n+            if (returnResults) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d086fea73cd92687610bc15882f59a1a6a771902"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjkyNjg3NA==", "bodyText": "This change is that if Increment/Append.isReturnResults() is true, we will return an empty result in case of the retry situation. Originally, it looks like in case of the retry situation, we returned actual result whatever Increment/Append.isReturnResults() is.", "url": "https://github.com/apache/hbase/pull/2630#discussion_r522926874", "createdAt": "2020-11-13T12:43:56Z", "author": {"login": "brfrn169"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java", "diffHunk": "@@ -3900,33 +3903,51 @@ public void prepareMiniBatchOperations(MiniBatchOperationInProgress<Mutation> mi\n             Bytes.toBytes(timestamp));\n           miniBatchOp.incrementNumOfDeletes();\n         } else if (mutation instanceof Increment || mutation instanceof Append) {\n+          boolean returnResults;\n+          if (mutation instanceof Increment) {\n+            returnResults = ((Increment) mutation).isReturnResults();\n+          } else {\n+            returnResults = ((Append) mutation).isReturnResults();\n+          }\n+\n           // For nonce operations\n           canProceed[index] = startNonceOperation(nonceGroup, nonce);\n           if (!canProceed[index]) {\n-            // convert duplicate increment/append to get\n-            List<Cell> results = region.get(toGet(mutation), false, nonceGroup, nonce);\n-            retCodeDetails[index] = new OperationStatus(OperationStatusCode.SUCCESS,\n-              Result.create(results));\n+            Result result;\n+            if (returnResults) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDM0MjExOQ=="}, "originalCommit": {"oid": "d086fea73cd92687610bc15882f59a1a6a771902"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI2MjA2OTkxOnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQwNzozNToxMVrOHwPcow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xM1QxMjo0NDo1N1rOHys9bw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDM0Njc4Nw==", "bodyText": "At least for JDK8, stream is slow so let's avoid stream on critical read/write path as much as possible for now.", "url": "https://github.com/apache/hbase/pull/2630#discussion_r520346787", "createdAt": "2020-11-10T07:35:11Z", "author": {"login": "Apache9"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java", "diffHunk": "@@ -8303,11 +8289,23 @@ void metricsUpdateForGet(List<Cell> results, long before) {\n   }\n \n   @Override\n-  public void mutateRow(RowMutations rm) throws IOException {\n-    // Don't need nonces here - RowMutations only supports puts and deletes\n+  public Result mutateRow(RowMutations rm) throws IOException {\n     final List<Mutation> m = rm.getMutations();\n-    batchMutate(m.toArray(new Mutation[m.size()]), true, HConstants.NO_NONCE,\n-        HConstants.NO_NONCE);\n+    OperationStatus[] operationStatuses = batchMutate(m.toArray(new Mutation[0]), true,\n+      HConstants.NO_NONCE, HConstants.NO_NONCE);\n+\n+    List<Result> results = Arrays.stream(operationStatuses)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d086fea73cd92687610bc15882f59a1a6a771902"}, "originalPosition": 223}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjkyNzQ3MQ==", "bodyText": "Sure, I will change it not to use stream. Thanks.", "url": "https://github.com/apache/hbase/pull/2630#discussion_r522927471", "createdAt": "2020-11-13T12:44:57Z", "author": {"login": "brfrn169"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java", "diffHunk": "@@ -8303,11 +8289,23 @@ void metricsUpdateForGet(List<Cell> results, long before) {\n   }\n \n   @Override\n-  public void mutateRow(RowMutations rm) throws IOException {\n-    // Don't need nonces here - RowMutations only supports puts and deletes\n+  public Result mutateRow(RowMutations rm) throws IOException {\n     final List<Mutation> m = rm.getMutations();\n-    batchMutate(m.toArray(new Mutation[m.size()]), true, HConstants.NO_NONCE,\n-        HConstants.NO_NONCE);\n+    OperationStatus[] operationStatuses = batchMutate(m.toArray(new Mutation[0]), true,\n+      HConstants.NO_NONCE, HConstants.NO_NONCE);\n+\n+    List<Result> results = Arrays.stream(operationStatuses)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDM0Njc4Nw=="}, "originalCommit": {"oid": "d086fea73cd92687610bc15882f59a1a6a771902"}, "originalPosition": 223}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI2MjA3MzY0OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQwNzozNjozN1rOHwPfAg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMVQxNjoxNzozMlrOH3vmHw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDM0NzM5NA==", "bodyText": "Why change to AssertionError?", "url": "https://github.com/apache/hbase/pull/2630#discussion_r520347394", "createdAt": "2020-11-10T07:36:37Z", "author": {"login": "Apache9"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java", "diffHunk": "@@ -620,8 +622,22 @@ private CheckAndMutateResult checkAndMutate(HRegion region, List<ClientProtos.Ac\n             spaceQuotaEnforcement.getPolicyEnforcement(region).check(del);\n             mutations.add(del);\n             break;\n+          case INCREMENT:\n+            Increment increment = ProtobufUtil.toIncrement(action.getMutation(), cellScanner);\n+            ++countOfCompleteMutation;\n+            checkCellSizeLimit(region, increment);\n+            spaceQuotaEnforcement.getPolicyEnforcement(region).check(increment);\n+            mutations.add(increment);\n+            break;\n+          case APPEND:\n+            Append append = ProtobufUtil.toAppend(action.getMutation(), cellScanner);\n+            ++countOfCompleteMutation;\n+            checkCellSizeLimit(region, append);\n+            spaceQuotaEnforcement.getPolicyEnforcement(region).check(append);\n+            mutations.add(append);\n+            break;\n           default:\n-            throw new DoNotRetryIOException(\"Atomic put and/or delete only, not \" + type.name());\n+            throw new AssertionError(\"invalid mutation type : \" + type);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d086fea73cd92687610bc15882f59a1a6a771902"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjkzMDEzNQ==", "bodyText": "MutationType can be set to only Put/Delete/Increment/Append. And this switch statement has all the cases (Put/Delete/Increment/Append) after this change, so it is impossible to go the default case. That's why I change it to AssertionError, which means if we hit this AssertionError, it's something a bug. Do you think we should still use DoNotRetryIOException?", "url": "https://github.com/apache/hbase/pull/2630#discussion_r522930135", "createdAt": "2020-11-13T12:50:30Z", "author": {"login": "brfrn169"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java", "diffHunk": "@@ -620,8 +622,22 @@ private CheckAndMutateResult checkAndMutate(HRegion region, List<ClientProtos.Ac\n             spaceQuotaEnforcement.getPolicyEnforcement(region).check(del);\n             mutations.add(del);\n             break;\n+          case INCREMENT:\n+            Increment increment = ProtobufUtil.toIncrement(action.getMutation(), cellScanner);\n+            ++countOfCompleteMutation;\n+            checkCellSizeLimit(region, increment);\n+            spaceQuotaEnforcement.getPolicyEnforcement(region).check(increment);\n+            mutations.add(increment);\n+            break;\n+          case APPEND:\n+            Append append = ProtobufUtil.toAppend(action.getMutation(), cellScanner);\n+            ++countOfCompleteMutation;\n+            checkCellSizeLimit(region, append);\n+            spaceQuotaEnforcement.getPolicyEnforcement(region).check(append);\n+            mutations.add(append);\n+            break;\n           default:\n-            throw new DoNotRetryIOException(\"Atomic put and/or delete only, not \" + type.name());\n+            throw new AssertionError(\"invalid mutation type : \" + type);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDM0NzM5NA=="}, "originalCommit": {"oid": "d086fea73cd92687610bc15882f59a1a6a771902"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODIwNTg3Mw==", "bodyText": "I think what you said is also reasonable, but since this is an rpc method, we can not make sure whether the remote side has the same code with us at server side, so I still prefer a DoNotRetryIOException here. Let's not change it for now.", "url": "https://github.com/apache/hbase/pull/2630#discussion_r528205873", "createdAt": "2020-11-21T15:05:10Z", "author": {"login": "Apache9"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java", "diffHunk": "@@ -620,8 +622,22 @@ private CheckAndMutateResult checkAndMutate(HRegion region, List<ClientProtos.Ac\n             spaceQuotaEnforcement.getPolicyEnforcement(region).check(del);\n             mutations.add(del);\n             break;\n+          case INCREMENT:\n+            Increment increment = ProtobufUtil.toIncrement(action.getMutation(), cellScanner);\n+            ++countOfCompleteMutation;\n+            checkCellSizeLimit(region, increment);\n+            spaceQuotaEnforcement.getPolicyEnforcement(region).check(increment);\n+            mutations.add(increment);\n+            break;\n+          case APPEND:\n+            Append append = ProtobufUtil.toAppend(action.getMutation(), cellScanner);\n+            ++countOfCompleteMutation;\n+            checkCellSizeLimit(region, append);\n+            spaceQuotaEnforcement.getPolicyEnforcement(region).check(append);\n+            mutations.add(append);\n+            break;\n           default:\n-            throw new DoNotRetryIOException(\"Atomic put and/or delete only, not \" + type.name());\n+            throw new AssertionError(\"invalid mutation type : \" + type);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDM0NzM5NA=="}, "originalCommit": {"oid": "d086fea73cd92687610bc15882f59a1a6a771902"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODIxMzUzNQ==", "bodyText": "Sure. I will revert this change.", "url": "https://github.com/apache/hbase/pull/2630#discussion_r528213535", "createdAt": "2020-11-21T16:17:32Z", "author": {"login": "brfrn169"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java", "diffHunk": "@@ -620,8 +622,22 @@ private CheckAndMutateResult checkAndMutate(HRegion region, List<ClientProtos.Ac\n             spaceQuotaEnforcement.getPolicyEnforcement(region).check(del);\n             mutations.add(del);\n             break;\n+          case INCREMENT:\n+            Increment increment = ProtobufUtil.toIncrement(action.getMutation(), cellScanner);\n+            ++countOfCompleteMutation;\n+            checkCellSizeLimit(region, increment);\n+            spaceQuotaEnforcement.getPolicyEnforcement(region).check(increment);\n+            mutations.add(increment);\n+            break;\n+          case APPEND:\n+            Append append = ProtobufUtil.toAppend(action.getMutation(), cellScanner);\n+            ++countOfCompleteMutation;\n+            checkCellSizeLimit(region, append);\n+            spaceQuotaEnforcement.getPolicyEnforcement(region).check(append);\n+            mutations.add(append);\n+            break;\n           default:\n-            throw new DoNotRetryIOException(\"Atomic put and/or delete only, not \" + type.name());\n+            throw new AssertionError(\"invalid mutation type : \" + type);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDM0NzM5NA=="}, "originalCommit": {"oid": "d086fea73cd92687610bc15882f59a1a6a771902"}, "originalPosition": 36}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI2MjA3NjMxOnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQwNzozNzozNlrOHwPgow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMVQxNToyMjoxOFrOH3vPSQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDM0NzgxMQ==", "bodyText": "Why remove atomic?", "url": "https://github.com/apache/hbase/pull/2630#discussion_r520347811", "createdAt": "2020-11-10T07:37:36Z", "author": {"login": "Apache9"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java", "diffHunk": "@@ -972,11 +1003,41 @@ private void doBatchOp(final RegionActionResult.Builder builder, final HRegion r\n \n       OperationStatus[] codes = region.batchMutate(mArray, atomic, HConstants.NO_NONCE,\n         HConstants.NO_NONCE);\n+      if (atomic) {\n+        LinkedList<ResultOrException> resultOrExceptions = new LinkedList<>();\n+        List<Result> results = new ArrayList<>();\n+        for (i = 0; i < codes.length; i++) {\n+          if (codes[i].getResult() != null) {\n+            results.add(codes[i].getResult());\n+          }\n+          if (i != 0) {\n+            resultOrExceptions.add(getResultOrException(\n+              ClientProtos.Result.getDefaultInstance(), i));\n+          }\n+        }\n+\n+        if (results.isEmpty()) {\n+          resultOrExceptions.addFirst(getResultOrException(\n+            ClientProtos.Result.getDefaultInstance(), 0));\n+        } else {\n+          // Set the result of the Increment/Append operations to the first element of the\n+          // ResultOrException list\n+          Result result = Result.create(results.stream()\n+            .filter(r -> r.rawCells() != null)\n+            .flatMap(r -> Arrays.stream(r.rawCells()))\n+            .collect(Collectors.toList()));\n+          resultOrExceptions.addFirst(getResultOrException(ProtobufUtil.toResult(result), 0));\n+        }\n+\n+        builder.addAllResultOrException(resultOrExceptions);\n+        return;\n+      }\n+\n       for (i = 0; i < codes.length; i++) {\n         Mutation currentMutation = mArray[i];\n         ClientProtos.Action currentAction = mutationActionMap.get(currentMutation);\n-        int index = currentAction.hasIndex() || !atomic ? currentAction.getIndex() : i;\n-        Exception e = null;\n+        int index = currentAction.hasIndex() ? currentAction.getIndex() : i;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d086fea73cd92687610bc15882f59a1a6a771902"}, "originalPosition": 122}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjkzMzI5Ng==", "bodyText": "This is because I added if statement when atomic is true the above. So atomic is always false here.", "url": "https://github.com/apache/hbase/pull/2630#discussion_r522933296", "createdAt": "2020-11-13T12:56:59Z", "author": {"login": "brfrn169"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java", "diffHunk": "@@ -972,11 +1003,41 @@ private void doBatchOp(final RegionActionResult.Builder builder, final HRegion r\n \n       OperationStatus[] codes = region.batchMutate(mArray, atomic, HConstants.NO_NONCE,\n         HConstants.NO_NONCE);\n+      if (atomic) {\n+        LinkedList<ResultOrException> resultOrExceptions = new LinkedList<>();\n+        List<Result> results = new ArrayList<>();\n+        for (i = 0; i < codes.length; i++) {\n+          if (codes[i].getResult() != null) {\n+            results.add(codes[i].getResult());\n+          }\n+          if (i != 0) {\n+            resultOrExceptions.add(getResultOrException(\n+              ClientProtos.Result.getDefaultInstance(), i));\n+          }\n+        }\n+\n+        if (results.isEmpty()) {\n+          resultOrExceptions.addFirst(getResultOrException(\n+            ClientProtos.Result.getDefaultInstance(), 0));\n+        } else {\n+          // Set the result of the Increment/Append operations to the first element of the\n+          // ResultOrException list\n+          Result result = Result.create(results.stream()\n+            .filter(r -> r.rawCells() != null)\n+            .flatMap(r -> Arrays.stream(r.rawCells()))\n+            .collect(Collectors.toList()));\n+          resultOrExceptions.addFirst(getResultOrException(ProtobufUtil.toResult(result), 0));\n+        }\n+\n+        builder.addAllResultOrException(resultOrExceptions);\n+        return;\n+      }\n+\n       for (i = 0; i < codes.length; i++) {\n         Mutation currentMutation = mArray[i];\n         ClientProtos.Action currentAction = mutationActionMap.get(currentMutation);\n-        int index = currentAction.hasIndex() || !atomic ? currentAction.getIndex() : i;\n-        Exception e = null;\n+        int index = currentAction.hasIndex() ? currentAction.getIndex() : i;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDM0NzgxMQ=="}, "originalCommit": {"oid": "d086fea73cd92687610bc15882f59a1a6a771902"}, "originalPosition": 122}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODIwNzY4OQ==", "bodyText": "OK, just saw that there is a return above.", "url": "https://github.com/apache/hbase/pull/2630#discussion_r528207689", "createdAt": "2020-11-21T15:22:18Z", "author": {"login": "Apache9"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java", "diffHunk": "@@ -972,11 +1003,41 @@ private void doBatchOp(final RegionActionResult.Builder builder, final HRegion r\n \n       OperationStatus[] codes = region.batchMutate(mArray, atomic, HConstants.NO_NONCE,\n         HConstants.NO_NONCE);\n+      if (atomic) {\n+        LinkedList<ResultOrException> resultOrExceptions = new LinkedList<>();\n+        List<Result> results = new ArrayList<>();\n+        for (i = 0; i < codes.length; i++) {\n+          if (codes[i].getResult() != null) {\n+            results.add(codes[i].getResult());\n+          }\n+          if (i != 0) {\n+            resultOrExceptions.add(getResultOrException(\n+              ClientProtos.Result.getDefaultInstance(), i));\n+          }\n+        }\n+\n+        if (results.isEmpty()) {\n+          resultOrExceptions.addFirst(getResultOrException(\n+            ClientProtos.Result.getDefaultInstance(), 0));\n+        } else {\n+          // Set the result of the Increment/Append operations to the first element of the\n+          // ResultOrException list\n+          Result result = Result.create(results.stream()\n+            .filter(r -> r.rawCells() != null)\n+            .flatMap(r -> Arrays.stream(r.rawCells()))\n+            .collect(Collectors.toList()));\n+          resultOrExceptions.addFirst(getResultOrException(ProtobufUtil.toResult(result), 0));\n+        }\n+\n+        builder.addAllResultOrException(resultOrExceptions);\n+        return;\n+      }\n+\n       for (i = 0; i < codes.length; i++) {\n         Mutation currentMutation = mArray[i];\n         ClientProtos.Action currentAction = mutationActionMap.get(currentMutation);\n-        int index = currentAction.hasIndex() || !atomic ? currentAction.getIndex() : i;\n-        Exception e = null;\n+        int index = currentAction.hasIndex() ? currentAction.getIndex() : i;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDM0NzgxMQ=="}, "originalCommit": {"oid": "d086fea73cd92687610bc15882f59a1a6a771902"}, "originalPosition": 122}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMxMjA4ODg3OnYy", "diffSide": "RIGHT", "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/Table.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMVQxNToxMjo0NVrOH3vLZQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMVQxNjoxNDoyN1rOH3vkhg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODIwNjY5Mw==", "bodyText": "nits: could remove the empty throws so we could fix on checkstyle warning.", "url": "https://github.com/apache/hbase/pull/2630#discussion_r528206693", "createdAt": "2020-11-21T15:12:45Z", "author": {"login": "Apache9"}, "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/Table.java", "diffHunk": "@@ -459,9 +459,10 @@ default CheckAndMutateResult checkAndMutate(CheckAndMutate checkAndMutate) throw\n    * {@link Put} and {@link Delete} are supported.\n    *\n    * @param rm object that specifies the set of mutations to perform atomically\n+   * @return results of Increment/Append operations\n    * @throws IOException", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "399e3fd41fb02d0ec45bd91fe368c63828ca721b"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODIxMzEyNg==", "bodyText": "Sure. I will do that.", "url": "https://github.com/apache/hbase/pull/2630#discussion_r528213126", "createdAt": "2020-11-21T16:14:27Z", "author": {"login": "brfrn169"}, "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/Table.java", "diffHunk": "@@ -459,9 +459,10 @@ default CheckAndMutateResult checkAndMutate(CheckAndMutate checkAndMutate) throw\n    * {@link Put} and {@link Delete} are supported.\n    *\n    * @param rm object that specifies the set of mutations to perform atomically\n+   * @return results of Increment/Append operations\n    * @throws IOException", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODIwNjY5Mw=="}, "originalCommit": {"oid": "399e3fd41fb02d0ec45bd91fe368c63828ca721b"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMxMjA5MTg2OnYy", "diffSide": "RIGHT", "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/shaded/protobuf/ResponseConverter.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMVQxNToxNjowNFrOH3vMug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMVQxNjozMjowNFrOH3vsjw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODIwNzAzNA==", "bodyText": "Mind explaing a bit about this change here? Seems the logic is changed?", "url": "https://github.com/apache/hbase/pull/2630#discussion_r528207034", "createdAt": "2020-11-21T15:16:04Z", "author": {"login": "Apache9"}, "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/shaded/protobuf/ResponseConverter.java", "diffHunk": "@@ -158,52 +156,30 @@ public static SingleResponse getResult(final ClientProtos.MutateRequest request,\n         // If there is an exception from the server, the exception is set at\n         // the RegionActionResult level, which has been handled above.\n         if (actions.hasCondition()) {\n-          Result result = null;\n-          if (actionResult.getResultOrExceptionCount() > 0) {\n-            ResultOrException roe = actionResult.getResultOrException(0);\n-            if (roe.hasResult()) {\n-              Result r = ProtobufUtil.toResult(roe.getResult(), cells);\n-              if (!r.isEmpty()) {\n-                result = r;\n-              }\n-            }\n-          }\n-          responseValue = new CheckAndMutateResult(actionResult.getProcessed(), result);\n+          results.add(regionName, index, getCheckAndMutateResult(actionResult, cells));\n         } else {\n-          responseValue = actionResult.getProcessed() ?\n-            ProtobufUtil.EMPTY_RESULT_EXISTS_TRUE :\n-            ProtobufUtil.EMPTY_RESULT_EXISTS_FALSE;\n+          results.add(regionName, index, getMutateRowResult(actionResult, cells));\n         }\n-        results.add(regionName, index, responseValue);\n         continue;\n       }\n \n       if (actions.hasCondition()) {\n-        Result result = null;\n-        if (actionResult.getResultOrExceptionCount() > 0) {\n-          ResultOrException roe = actionResult.getResultOrException(0);\n-          Result r = ProtobufUtil.toResult(roe.getResult(), cells);\n-          if (!r.isEmpty()) {\n-            result = r;\n-          }\n-        }\n-        responseValue = new CheckAndMutateResult(actionResult.getProcessed(), result);\n-        results.add(regionName, 0, responseValue);\n+        results.add(regionName, 0, getCheckAndMutateResult(actionResult, cells));\n       } else {\n+        if (actionResult.hasProcessed()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "399e3fd41fb02d0ec45bd91fe368c63828ca721b"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODIxNTE4Mw==", "bodyText": "The case where actions.hasCondition() is false and actionResult.hasProcessed() is true is the case for a result of mutateRow(). After this change, mutateRow() can return results of Increment/Append operations. That's why we need to add this logic here.", "url": "https://github.com/apache/hbase/pull/2630#discussion_r528215183", "createdAt": "2020-11-21T16:32:04Z", "author": {"login": "brfrn169"}, "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/shaded/protobuf/ResponseConverter.java", "diffHunk": "@@ -158,52 +156,30 @@ public static SingleResponse getResult(final ClientProtos.MutateRequest request,\n         // If there is an exception from the server, the exception is set at\n         // the RegionActionResult level, which has been handled above.\n         if (actions.hasCondition()) {\n-          Result result = null;\n-          if (actionResult.getResultOrExceptionCount() > 0) {\n-            ResultOrException roe = actionResult.getResultOrException(0);\n-            if (roe.hasResult()) {\n-              Result r = ProtobufUtil.toResult(roe.getResult(), cells);\n-              if (!r.isEmpty()) {\n-                result = r;\n-              }\n-            }\n-          }\n-          responseValue = new CheckAndMutateResult(actionResult.getProcessed(), result);\n+          results.add(regionName, index, getCheckAndMutateResult(actionResult, cells));\n         } else {\n-          responseValue = actionResult.getProcessed() ?\n-            ProtobufUtil.EMPTY_RESULT_EXISTS_TRUE :\n-            ProtobufUtil.EMPTY_RESULT_EXISTS_FALSE;\n+          results.add(regionName, index, getMutateRowResult(actionResult, cells));\n         }\n-        results.add(regionName, index, responseValue);\n         continue;\n       }\n \n       if (actions.hasCondition()) {\n-        Result result = null;\n-        if (actionResult.getResultOrExceptionCount() > 0) {\n-          ResultOrException roe = actionResult.getResultOrException(0);\n-          Result r = ProtobufUtil.toResult(roe.getResult(), cells);\n-          if (!r.isEmpty()) {\n-            result = r;\n-          }\n-        }\n-        responseValue = new CheckAndMutateResult(actionResult.getProcessed(), result);\n-        results.add(regionName, 0, responseValue);\n+        results.add(regionName, 0, getCheckAndMutateResult(actionResult, cells));\n       } else {\n+        if (actionResult.hasProcessed()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODIwNzAzNA=="}, "originalCommit": {"oid": "399e3fd41fb02d0ec45bd91fe368c63828ca721b"}, "originalPosition": 48}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMxMjA5Mzg4OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMVQxNToxODozNVrOH3vNpw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMVQxNToxODozNVrOH3vNpw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODIwNzI3MQ==", "bodyText": "Good. It is usually dangerous to use byte[] as the key of a HashMap...", "url": "https://github.com/apache/hbase/pull/2630#discussion_r528207271", "createdAt": "2020-11-21T15:18:35Z", "author": {"login": "Apache9"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java", "diffHunk": "@@ -4008,28 +4029,10 @@ private static Get toGet(final Mutation mutation) throws IOException {\n       return get;\n     }\n \n-    /**\n-     * Do coprocessor pre-increment or pre-append after row lock call.\n-     * @return Result returned out of the coprocessor, which means bypass all further processing\n-     *   and return the preferred Result instead, or null which means proceed.\n-     */\n-    private Result doCoprocessorPreCallAfterRowLock(Mutation mutation) throws IOException {\n-      assert mutation instanceof Increment || mutation instanceof Append;\n-      Result result = null;\n-      if (region.coprocessorHost != null) {\n-        if (mutation instanceof Increment) {\n-          result = region.coprocessorHost.preIncrementAfterRowLock((Increment) mutation);\n-        } else {\n-          result = region.coprocessorHost.preAppendAfterRowLock((Append) mutation);\n-        }\n-      }\n-      return result;\n-    }\n-\n     private Map<byte[], List<Cell>> reckonDeltas(Mutation mutation, List<Cell> results,\n       long now) throws IOException {\n       assert mutation instanceof Increment || mutation instanceof Append;\n-      Map<byte[], List<Cell>> ret = new HashMap<>();\n+      Map<byte[], List<Cell>> ret = new TreeMap<>(Bytes.BYTES_COMPARATOR);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "399e3fd41fb02d0ec45bd91fe368c63828ca721b"}, "originalPosition": 105}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMxMjA5ODcwOnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMVQxNToyNDoyNFrOH3vP6A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMlQxMzowNDowNFrOH3235w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODIwNzg0OA==", "bodyText": "Better to use ArrayList instead of LinkedList. ArrayList is faster than LinkedList for most cases. I can not recall the exact number but at least for thousands elements ArrayList is still faster.", "url": "https://github.com/apache/hbase/pull/2630#discussion_r528207848", "createdAt": "2020-11-21T15:24:24Z", "author": {"login": "Apache9"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java", "diffHunk": "@@ -972,11 +1002,44 @@ private void doBatchOp(final RegionActionResult.Builder builder, final HRegion r\n \n       OperationStatus[] codes = region.batchMutate(mArray, atomic, HConstants.NO_NONCE,\n         HConstants.NO_NONCE);\n+      if (atomic) {\n+        LinkedList<ResultOrException> resultOrExceptions = new LinkedList<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "399e3fd41fb02d0ec45bd91fe368c63828ca721b"}, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODIxNDY3NQ==", "bodyText": "The reason why I use LinkedList here is that I need to add a element at the beginning of the list as follows:\nhttps://github.com/apache/hbase/pull/2630/files#diff-e4052cd5a1f1c93375e3fbc931dc4df220deebc78c0d53fd2435b47fd04cd807R1019-R1020\nhttps://github.com/apache/hbase/pull/2630/files#diff-e4052cd5a1f1c93375e3fbc931dc4df220deebc78c0d53fd2435b47fd04cd807R1031\nStill ArrayList is faster in that case?", "url": "https://github.com/apache/hbase/pull/2630#discussion_r528214675", "createdAt": "2020-11-21T16:27:08Z", "author": {"login": "brfrn169"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java", "diffHunk": "@@ -972,11 +1002,44 @@ private void doBatchOp(final RegionActionResult.Builder builder, final HRegion r\n \n       OperationStatus[] codes = region.batchMutate(mArray, atomic, HConstants.NO_NONCE,\n         HConstants.NO_NONCE);\n+      if (atomic) {\n+        LinkedList<ResultOrException> resultOrExceptions = new LinkedList<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODIwNzg0OA=="}, "originalCommit": {"oid": "399e3fd41fb02d0ec45bd91fe368c63828ca721b"}, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODMzMjc3NQ==", "bodyText": "Oh, if we want to add element at first then ArrayList is not suitable. But usually we could use other array based data structure such as ArrayDeque. Let me take a look at the code.", "url": "https://github.com/apache/hbase/pull/2630#discussion_r528332775", "createdAt": "2020-11-22T13:04:04Z", "author": {"login": "Apache9"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java", "diffHunk": "@@ -972,11 +1002,44 @@ private void doBatchOp(final RegionActionResult.Builder builder, final HRegion r\n \n       OperationStatus[] codes = region.batchMutate(mArray, atomic, HConstants.NO_NONCE,\n         HConstants.NO_NONCE);\n+      if (atomic) {\n+        LinkedList<ResultOrException> resultOrExceptions = new LinkedList<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODIwNzg0OA=="}, "originalCommit": {"oid": "399e3fd41fb02d0ec45bd91fe368c63828ca721b"}, "originalPosition": 80}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMxMzI4OTczOnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMlQxNToxMjozMFrOH333nw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMlQxNTozMToxNlrOH34BHw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODM0OTA4Nw==", "bodyText": "I think here we could just call builder.addResultOrException directly to add the first ResultOrException? And then call addAllResultOrException to add the remaining ResultOrExceptions in the list, so we do not need to add a new element in front?", "url": "https://github.com/apache/hbase/pull/2630#discussion_r528349087", "createdAt": "2020-11-22T15:12:30Z", "author": {"login": "Apache9"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java", "diffHunk": "@@ -972,11 +1001,44 @@ private void doBatchOp(final RegionActionResult.Builder builder, final HRegion r\n \n       OperationStatus[] codes = region.batchMutate(mArray, atomic, HConstants.NO_NONCE,\n         HConstants.NO_NONCE);\n+      if (atomic) {\n+        List<ResultOrException> resultOrExceptions = new ArrayList<>();\n+        List<Result> results = new ArrayList<>();\n+        for (i = 0; i < codes.length; i++) {\n+          if (codes[i].getResult() != null) {\n+            results.add(codes[i].getResult());\n+          }\n+          if (i != 0) {\n+            resultOrExceptions.add(getResultOrException(\n+              ClientProtos.Result.getDefaultInstance(), i));\n+          }\n+        }\n+\n+        if (results.isEmpty()) {\n+          resultOrExceptions.add(0, getResultOrException(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2baf627e968559cd48e02581092e422e413ca3fb"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODM1MTUxOQ==", "bodyText": "Yes, you are right. I will do that. Thanks.", "url": "https://github.com/apache/hbase/pull/2630#discussion_r528351519", "createdAt": "2020-11-22T15:31:16Z", "author": {"login": "brfrn169"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java", "diffHunk": "@@ -972,11 +1001,44 @@ private void doBatchOp(final RegionActionResult.Builder builder, final HRegion r\n \n       OperationStatus[] codes = region.batchMutate(mArray, atomic, HConstants.NO_NONCE,\n         HConstants.NO_NONCE);\n+      if (atomic) {\n+        List<ResultOrException> resultOrExceptions = new ArrayList<>();\n+        List<Result> results = new ArrayList<>();\n+        for (i = 0; i < codes.length; i++) {\n+          if (codes[i].getResult() != null) {\n+            results.add(codes[i].getResult());\n+          }\n+          if (i != 0) {\n+            resultOrExceptions.add(getResultOrException(\n+              ClientProtos.Result.getDefaultInstance(), i));\n+          }\n+        }\n+\n+        if (results.isEmpty()) {\n+          resultOrExceptions.add(0, getResultOrException(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODM0OTA4Nw=="}, "originalCommit": {"oid": "2baf627e968559cd48e02581092e422e413ca3fb"}, "originalPosition": 85}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMxMzI5MDcxOnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMlQxNToxMzo0OVrOH334Gg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxMjozNDoyMlrOH5xaBw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODM0OTIxMA==", "bodyText": "Mind explaining a bit about the logic here?  I think batchMutate is for multiple operations? Why here we could merge the cells from different Results? We can make sure they are always for the same row?", "url": "https://github.com/apache/hbase/pull/2630#discussion_r528349210", "createdAt": "2020-11-22T15:13:49Z", "author": {"login": "Apache9"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java", "diffHunk": "@@ -972,11 +1001,44 @@ private void doBatchOp(final RegionActionResult.Builder builder, final HRegion r\n \n       OperationStatus[] codes = region.batchMutate(mArray, atomic, HConstants.NO_NONCE,\n         HConstants.NO_NONCE);\n+      if (atomic) {\n+        List<ResultOrException> resultOrExceptions = new ArrayList<>();\n+        List<Result> results = new ArrayList<>();\n+        for (i = 0; i < codes.length; i++) {\n+          if (codes[i].getResult() != null) {\n+            results.add(codes[i].getResult());\n+          }\n+          if (i != 0) {\n+            resultOrExceptions.add(getResultOrException(\n+              ClientProtos.Result.getDefaultInstance(), i));\n+          }\n+        }\n+\n+        if (results.isEmpty()) {\n+          resultOrExceptions.add(0, getResultOrException(\n+            ClientProtos.Result.getDefaultInstance(), 0));\n+        } else {\n+          // Set the result of the Increment/Append operations to the first element of the\n+          // ResultOrException list\n+          List<Cell> cellList = new ArrayList<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2baf627e968559cd48e02581092e422e413ca3fb"}, "originalPosition": 90}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODM1MTI0NA==", "bodyText": "batchMutate can also be used by mutateRow(), and the case that atomic is true is when a client calls mutateRow(). In this case, of course, the results are always for the same row, and we need to return the results of Increment/Append operations as one Result object. That's why we need to merge the cell from different Results. And this logic sets the result to the first element of the ResultOrException list. Thanks.", "url": "https://github.com/apache/hbase/pull/2630#discussion_r528351244", "createdAt": "2020-11-22T15:29:13Z", "author": {"login": "brfrn169"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java", "diffHunk": "@@ -972,11 +1001,44 @@ private void doBatchOp(final RegionActionResult.Builder builder, final HRegion r\n \n       OperationStatus[] codes = region.batchMutate(mArray, atomic, HConstants.NO_NONCE,\n         HConstants.NO_NONCE);\n+      if (atomic) {\n+        List<ResultOrException> resultOrExceptions = new ArrayList<>();\n+        List<Result> results = new ArrayList<>();\n+        for (i = 0; i < codes.length; i++) {\n+          if (codes[i].getResult() != null) {\n+            results.add(codes[i].getResult());\n+          }\n+          if (i != 0) {\n+            resultOrExceptions.add(getResultOrException(\n+              ClientProtos.Result.getDefaultInstance(), i));\n+          }\n+        }\n+\n+        if (results.isEmpty()) {\n+          resultOrExceptions.add(0, getResultOrException(\n+            ClientProtos.Result.getDefaultInstance(), 0));\n+        } else {\n+          // Set the result of the Increment/Append operations to the first element of the\n+          // ResultOrException list\n+          List<Cell> cellList = new ArrayList<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODM0OTIxMA=="}, "originalCommit": {"oid": "2baf627e968559cd48e02581092e422e413ca3fb"}, "originalPosition": 90}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDA1NzExNA==", "bodyText": "Seems my comment is disappeared, maybe I forgot to push the comment button. The concern here is how we can make sure that when arriving this branch, we are going to treat the result for mutateRow. Here we are in doBatchOp method, which will be called in RSRpcService.multi method, and the atomic flag is read from the protobuf message. This means the only place where we set atomic to true is for mutateRow? Maybe this is the case as for atomic batching we need to use the MultiRowMutationEndpoint, just asking. And I suggest that if this is the case then we should add more comments in the code to explicitly say this so other developers will not be confusing.", "url": "https://github.com/apache/hbase/pull/2630#discussion_r530057114", "createdAt": "2020-11-25T01:54:08Z", "author": {"login": "Apache9"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java", "diffHunk": "@@ -972,11 +1001,44 @@ private void doBatchOp(final RegionActionResult.Builder builder, final HRegion r\n \n       OperationStatus[] codes = region.batchMutate(mArray, atomic, HConstants.NO_NONCE,\n         HConstants.NO_NONCE);\n+      if (atomic) {\n+        List<ResultOrException> resultOrExceptions = new ArrayList<>();\n+        List<Result> results = new ArrayList<>();\n+        for (i = 0; i < codes.length; i++) {\n+          if (codes[i].getResult() != null) {\n+            results.add(codes[i].getResult());\n+          }\n+          if (i != 0) {\n+            resultOrExceptions.add(getResultOrException(\n+              ClientProtos.Result.getDefaultInstance(), i));\n+          }\n+        }\n+\n+        if (results.isEmpty()) {\n+          resultOrExceptions.add(0, getResultOrException(\n+            ClientProtos.Result.getDefaultInstance(), 0));\n+        } else {\n+          // Set the result of the Increment/Append operations to the first element of the\n+          // ResultOrException list\n+          List<Cell> cellList = new ArrayList<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODM0OTIxMA=="}, "originalCommit": {"oid": "2baf627e968559cd48e02581092e422e413ca3fb"}, "originalPosition": 90}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDM0MDM1OQ==", "bodyText": "Here we are in doBatchOp method, which will be called in RSRpcService.multi method, and the atomic flag is read from the protobuf message. This means the only place where we set atomic to true is for mutateRow? Maybe this is the case as for atomic batching we need to use the MultiRowMutationEndpoint, just asking.\n\nYes, the only place where we set atomic to true is for mutateRow. In case of MultiRowMutationEndpoint, it calls Region.mutateRowsWithLocks() directly. So it doesn't call the doBatchOp method.\n\nI suggest that if this is the case then we should add more comments in the code to explicitly say this so other developers will not be confusing.\n\nSure I will add some more comments. Thanks.", "url": "https://github.com/apache/hbase/pull/2630#discussion_r530340359", "createdAt": "2020-11-25T12:34:22Z", "author": {"login": "brfrn169"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java", "diffHunk": "@@ -972,11 +1001,44 @@ private void doBatchOp(final RegionActionResult.Builder builder, final HRegion r\n \n       OperationStatus[] codes = region.batchMutate(mArray, atomic, HConstants.NO_NONCE,\n         HConstants.NO_NONCE);\n+      if (atomic) {\n+        List<ResultOrException> resultOrExceptions = new ArrayList<>();\n+        List<Result> results = new ArrayList<>();\n+        for (i = 0; i < codes.length; i++) {\n+          if (codes[i].getResult() != null) {\n+            results.add(codes[i].getResult());\n+          }\n+          if (i != 0) {\n+            resultOrExceptions.add(getResultOrException(\n+              ClientProtos.Result.getDefaultInstance(), i));\n+          }\n+        }\n+\n+        if (results.isEmpty()) {\n+          resultOrExceptions.add(0, getResultOrException(\n+            ClientProtos.Result.getDefaultInstance(), 0));\n+        } else {\n+          // Set the result of the Increment/Append operations to the first element of the\n+          // ResultOrException list\n+          List<Cell> cellList = new ArrayList<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODM0OTIxMA=="}, "originalCommit": {"oid": "2baf627e968559cd48e02581092e422e413ca3fb"}, "originalPosition": 90}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2367, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}