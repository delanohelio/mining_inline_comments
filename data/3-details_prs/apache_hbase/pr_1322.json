{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzkxOTg1NDM1", "number": 1322, "title": "HBASE-24033 Add ut for loading the corrupt recovered hfiles", "bodyText": "", "createdAt": "2020-03-22T10:36:51Z", "url": "https://github.com/apache/hbase/pull/1322", "merged": true, "mergeCommit": {"oid": "2a60a61a73d3b001324e159397b2083dfcbbc2aa"}, "closed": true, "closedAt": "2020-03-22T14:56:31Z", "author": {"login": "infraio"}, "timelineItems": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcQIR8xgFqTM3ODk5NjY5Mw==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcQJYM3gFqTM3OTAwMzAxMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc4OTk2Njkz", "url": "https://github.com/apache/hbase/pull/1322#pullrequestreview-378996693", "createdAt": "2020-03-22T11:44:38Z", "commit": {"oid": "347fe5728f484ae62dbd8e6ab774c8a63b7c6e63"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMlQxMTo0NDozOFrOF5vDRg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMlQxMTo0Njo1N1rOF5vEFA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjA4NDAzOA==", "bodyText": "Why this name changing? Because for HFile based split we will write HFile to the root fs instead of wal fs?", "url": "https://github.com/apache/hbase/pull/1322#discussion_r396084038", "createdAt": "2020-03-22T11:44:38Z", "author": {"login": "Apache9"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/wal/WALSplitUtil.java", "diffHunk": "@@ -345,16 +345,16 @@ public boolean accept(Path p) {\n \n   /**\n    * Move aside a bad edits file.\n-   * @param walFS WAL FileSystem used to rename bad edits file.\n+   * @param fs the file system used to rename bad edits file.\n    * @param edits Edits file to move aside.\n    * @return The name of the moved aside file.\n    * @throws IOException\n    */\n-  public static Path moveAsideBadEditsFile(final FileSystem walFS, final Path edits)\n+  public static Path moveAsideBadEditsFile(final FileSystem fs, final Path edits)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "347fe5728f484ae62dbd8e6ab774c8a63b7c6e63"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjA4NDE5Nw==", "bodyText": "Better move this line into setUp or tearDown if necessary?", "url": "https://github.com/apache/hbase/pull/1322#discussion_r396084197", "createdAt": "2020-03-22T11:46:21Z", "author": {"login": "Apache9"}, "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/wal/TestWALSplitToHFile.java", "diffHunk": "@@ -163,24 +175,88 @@ private WAL createWAL(Configuration c, Path hbaseRootDir, String logName) throws\n     return wal;\n   }\n \n-  /**\n-   * Test writing edits into an HRegion, closing it, splitting logs, opening\n-   * Region again.  Verify seqids.\n-   */\n-  @Test\n-  public void testReplayEditsWrittenViaHRegion()\n-      throws IOException, SecurityException, IllegalArgumentException, InterruptedException {\n+  private Pair<TableDescriptor, RegionInfo> setupTableAndRegion() throws IOException {\n     final TableName tableName = TableName.valueOf(TEST_NAME.getMethodName());\n     final TableDescriptor td = createBasic3FamilyTD(tableName);\n     final RegionInfo ri = RegionInfoBuilder.newBuilder(tableName).build();\n     final Path tableDir = FSUtils.getTableDir(this.rootDir, tableName);\n     deleteDir(tableDir);\n     FSTableDescriptors.createTableDescriptorForTableDirectory(fs, tableDir, td, false);\n-    final byte[] rowName = tableName.getName();\n-    final int countPerFamily = 10;\n+    HRegion region = HBaseTestingUtility.createRegionAndWAL(ri, rootDir, this.conf, td);\n+    HBaseTestingUtility.closeRegionAndWAL(region);\n+    return new Pair<>(td, ri);\n+  }\n+\n+  @Test\n+  public void testCorruptRecoveredHFile() throws Exception {\n+    Pair<TableDescriptor, RegionInfo> pair = setupTableAndRegion();\n+    TableDescriptor td = pair.getFirst();\n+    RegionInfo ri = pair.getSecond();\n+\n+    WAL wal = createWAL(this.conf, rootDir, logName);\n+    HRegion region = HRegion.openHRegion(this.conf, this.fs, rootDir, ri, td, wal);\n+    final long timestamp = this.ee.currentTime();\n+    // Write data and flush\n+    for (ColumnFamilyDescriptor cfd : td.getColumnFamilies()) {\n+      region.put(new Put(ROW).addColumn(cfd.getName(), Bytes.toBytes(\"x\"), timestamp, VALUE1));\n+    }\n+    region.flush(true);\n+\n+    // Now assert edits made it in.\n+    Result result1 = region.get(new Get(ROW));\n+    assertEquals(td.getColumnFamilies().length, result1.size());\n+    for (ColumnFamilyDescriptor cfd : td.getColumnFamilies()) {\n+      assertTrue(Bytes.equals(VALUE1, result1.getValue(cfd.getName(), Bytes.toBytes(\"x\"))));\n+    }\n+\n+    // Now close the region\n+    region.close(true);\n+    wal.shutdown();\n+    // split the log\n+    WALSplitter.split(rootDir, logDir, oldLogDir, FileSystem.get(this.conf), this.conf, wals);\n+\n+    // Write a corrupt recovered hfile\n+    Path regionDir =\n+        new Path(CommonFSUtils.getTableDir(rootDir, td.getTableName()), ri.getEncodedName());\n+    for (ColumnFamilyDescriptor cfd : td.getColumnFamilies()) {\n+      FileStatus[] files =\n+          WALSplitUtil.getRecoveredHFiles(this.fs, regionDir, cfd.getNameAsString());\n+      assertNotNull(files);\n+      assertTrue(files.length > 0);\n+      writeCorruptRecoveredHFile(files[0].getPath());\n+    }\n+\n+    // Failed to reopen the region\n+    WAL wal2 = createWAL(this.conf, rootDir, logName);\n+    try {\n+      HRegion.openHRegion(this.conf, this.fs, rootDir, ri, td, wal2);\n+      fail(\"Should fail to open region\");\n+    } catch (CorruptHFileException che) {\n+      // Expected\n+    }\n+\n+    // Set skip errors to true and reopen the region\n+    this.conf.setBoolean(HConstants.HREGION_EDITS_REPLAY_SKIP_ERRORS, true);\n+    HRegion region2 = HRegion.openHRegion(this.conf, this.fs, rootDir, ri, td, wal2);\n+    Result result2 = region2.get(new Get(ROW));\n+    assertEquals(td.getColumnFamilies().length, result2.size());\n+    for (ColumnFamilyDescriptor cfd : td.getColumnFamilies()) {\n+      assertTrue(Bytes.equals(VALUE1, result2.getValue(cfd.getName(), Bytes.toBytes(\"x\"))));\n+    }\n+    this.conf.setBoolean(HConstants.HREGION_EDITS_REPLAY_SKIP_ERRORS, false);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "347fe5728f484ae62dbd8e6ab774c8a63b7c6e63"}, "originalPosition": 132}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjA4NDI0NA==", "bodyText": "Add an assert to confirm that we move the broken HFile to the expected place?", "url": "https://github.com/apache/hbase/pull/1322#discussion_r396084244", "createdAt": "2020-03-22T11:46:57Z", "author": {"login": "Apache9"}, "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/wal/TestWALSplitToHFile.java", "diffHunk": "@@ -163,24 +175,88 @@ private WAL createWAL(Configuration c, Path hbaseRootDir, String logName) throws\n     return wal;\n   }\n \n-  /**\n-   * Test writing edits into an HRegion, closing it, splitting logs, opening\n-   * Region again.  Verify seqids.\n-   */\n-  @Test\n-  public void testReplayEditsWrittenViaHRegion()\n-      throws IOException, SecurityException, IllegalArgumentException, InterruptedException {\n+  private Pair<TableDescriptor, RegionInfo> setupTableAndRegion() throws IOException {\n     final TableName tableName = TableName.valueOf(TEST_NAME.getMethodName());\n     final TableDescriptor td = createBasic3FamilyTD(tableName);\n     final RegionInfo ri = RegionInfoBuilder.newBuilder(tableName).build();\n     final Path tableDir = FSUtils.getTableDir(this.rootDir, tableName);\n     deleteDir(tableDir);\n     FSTableDescriptors.createTableDescriptorForTableDirectory(fs, tableDir, td, false);\n-    final byte[] rowName = tableName.getName();\n-    final int countPerFamily = 10;\n+    HRegion region = HBaseTestingUtility.createRegionAndWAL(ri, rootDir, this.conf, td);\n+    HBaseTestingUtility.closeRegionAndWAL(region);\n+    return new Pair<>(td, ri);\n+  }\n+\n+  @Test\n+  public void testCorruptRecoveredHFile() throws Exception {\n+    Pair<TableDescriptor, RegionInfo> pair = setupTableAndRegion();\n+    TableDescriptor td = pair.getFirst();\n+    RegionInfo ri = pair.getSecond();\n+\n+    WAL wal = createWAL(this.conf, rootDir, logName);\n+    HRegion region = HRegion.openHRegion(this.conf, this.fs, rootDir, ri, td, wal);\n+    final long timestamp = this.ee.currentTime();\n+    // Write data and flush\n+    for (ColumnFamilyDescriptor cfd : td.getColumnFamilies()) {\n+      region.put(new Put(ROW).addColumn(cfd.getName(), Bytes.toBytes(\"x\"), timestamp, VALUE1));\n+    }\n+    region.flush(true);\n+\n+    // Now assert edits made it in.\n+    Result result1 = region.get(new Get(ROW));\n+    assertEquals(td.getColumnFamilies().length, result1.size());\n+    for (ColumnFamilyDescriptor cfd : td.getColumnFamilies()) {\n+      assertTrue(Bytes.equals(VALUE1, result1.getValue(cfd.getName(), Bytes.toBytes(\"x\"))));\n+    }\n+\n+    // Now close the region\n+    region.close(true);\n+    wal.shutdown();\n+    // split the log\n+    WALSplitter.split(rootDir, logDir, oldLogDir, FileSystem.get(this.conf), this.conf, wals);\n+\n+    // Write a corrupt recovered hfile\n+    Path regionDir =\n+        new Path(CommonFSUtils.getTableDir(rootDir, td.getTableName()), ri.getEncodedName());\n+    for (ColumnFamilyDescriptor cfd : td.getColumnFamilies()) {\n+      FileStatus[] files =\n+          WALSplitUtil.getRecoveredHFiles(this.fs, regionDir, cfd.getNameAsString());\n+      assertNotNull(files);\n+      assertTrue(files.length > 0);\n+      writeCorruptRecoveredHFile(files[0].getPath());\n+    }\n+\n+    // Failed to reopen the region\n+    WAL wal2 = createWAL(this.conf, rootDir, logName);\n+    try {\n+      HRegion.openHRegion(this.conf, this.fs, rootDir, ri, td, wal2);\n+      fail(\"Should fail to open region\");\n+    } catch (CorruptHFileException che) {\n+      // Expected\n+    }\n+\n+    // Set skip errors to true and reopen the region\n+    this.conf.setBoolean(HConstants.HREGION_EDITS_REPLAY_SKIP_ERRORS, true);\n+    HRegion region2 = HRegion.openHRegion(this.conf, this.fs, rootDir, ri, td, wal2);\n+    Result result2 = region2.get(new Get(ROW));\n+    assertEquals(td.getColumnFamilies().length, result2.size());\n+    for (ColumnFamilyDescriptor cfd : td.getColumnFamilies()) {\n+      assertTrue(Bytes.equals(VALUE1, result2.getValue(cfd.getName(), Bytes.toBytes(\"x\"))));\n+    }\n+    this.conf.setBoolean(HConstants.HREGION_EDITS_REPLAY_SKIP_ERRORS, false);\n+  }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "347fe5728f484ae62dbd8e6ab774c8a63b7c6e63"}, "originalPosition": 133}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5a8698cad64d595d6195e41883ab273cd560752b", "author": {"user": {"login": "infraio", "name": "Guanghao Zhang"}}, "url": "https://github.com/apache/hbase/commit/5a8698cad64d595d6195e41883ab273cd560752b", "committedDate": "2020-03-22T12:24:58Z", "message": "HBASE-24033 Add ut for loading the corrupt recovered hfiles"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "347fe5728f484ae62dbd8e6ab774c8a63b7c6e63", "author": {"user": {"login": "infraio", "name": "Guanghao Zhang"}}, "url": "https://github.com/apache/hbase/commit/347fe5728f484ae62dbd8e6ab774c8a63b7c6e63", "committedDate": "2020-03-22T10:33:57Z", "message": "HBASE-24033 Add ut for loading the corrupt recovered hfiles"}, "afterCommit": {"oid": "5a8698cad64d595d6195e41883ab273cd560752b", "author": {"user": {"login": "infraio", "name": "Guanghao Zhang"}}, "url": "https://github.com/apache/hbase/commit/5a8698cad64d595d6195e41883ab273cd560752b", "committedDate": "2020-03-22T12:24:58Z", "message": "HBASE-24033 Add ut for loading the corrupt recovered hfiles"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc5MDAzMDEx", "url": "https://github.com/apache/hbase/pull/1322#pullrequestreview-379003011", "createdAt": "2020-03-22T13:03:50Z", "commit": {"oid": "5a8698cad64d595d6195e41883ab273cd560752b"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMlQxMzowMzo1MFrOF5vfng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMlQxMzowMzo1MFrOF5vfng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjA5MTI5NA==", "bodyText": "This is a bug?", "url": "https://github.com/apache/hbase/pull/1322#discussion_r396091294", "createdAt": "2020-03-22T13:03:50Z", "author": {"login": "Apache9"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java", "diffHunk": "@@ -5449,6 +5449,7 @@ private long loadRecoveredHFilesIfAny(Collection<HStore> stores) throws IOExcept\n             store.assertBulkLoadHFileOk(filePath);\n           } catch (IOException e) {\n             handleException(fs.getFileSystem(), filePath, e);\n+            continue;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5a8698cad64d595d6195e41883ab273cd560752b"}, "originalPosition": 4}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2733, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}