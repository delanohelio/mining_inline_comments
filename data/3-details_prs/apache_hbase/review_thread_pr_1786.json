{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDIzNTM4OTIx", "number": 1786, "reviewThreads": {"totalCount": 28, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxMzowMzoyNFrOEAFBJA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQxNzo1Mzo1MVrOEB2s0A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4NTE3NjY4OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/RegionNormalizer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxMzowMzoyNFrOGbIa5w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QyMDowMzowN1rOGbbLrA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTEwMjY5NQ==", "bodyText": "We can remove this import.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431102695", "createdAt": "2020-05-27T13:03:24Z", "author": {"login": "virajjasani"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/RegionNormalizer.java", "diffHunk": "@@ -19,17 +19,18 @@\n package org.apache.hadoop.hbase.master.normalizer;\n \n import java.util.List;\n-\n+import org.apache.hadoop.conf.Configurable;\n import org.apache.hadoop.hbase.HBaseIOException;\n import org.apache.hadoop.hbase.TableName;\n import org.apache.hadoop.hbase.client.RegionInfo;\n import org.apache.hadoop.hbase.master.MasterRpcServices;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQxMDA5Mg==", "bodyText": "yep, missed it.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431410092", "createdAt": "2020-05-27T20:03:07Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/RegionNormalizer.java", "diffHunk": "@@ -19,17 +19,18 @@\n package org.apache.hadoop.hbase.master.normalizer;\n \n import java.util.List;\n-\n+import org.apache.hadoop.conf.Configurable;\n import org.apache.hadoop.hbase.HBaseIOException;\n import org.apache.hadoop.hbase.TableName;\n import org.apache.hadoop.hbase.client.RegionInfo;\n import org.apache.hadoop.hbase.master.MasterRpcServices;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTEwMjY5NQ=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 15}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4NTI0MTM5OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxMzoxMjozNFrOGbJHXQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QyMDowMjoyMVrOGbbKHA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTExNDA3Nw==", "bodyText": "Although nothing is wrong with this, do you think inverted check will provide better readability?\nif(lock.tryLock()){\n  try{\n     // do things\n  }finally{\n     lock.unlock();\n  }\n}else{\n  log.info(\"lock in progress\");\n}", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431114077", "createdAt": "2020-05-27T13:12:34Z", "author": {"login": "virajjasani"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "diffHunk": "@@ -1911,43 +1912,51 @@ public boolean normalizeRegions() throws IOException {\n       return false;\n     }\n \n-    synchronized (this.normalizer) {\n+    if (!normalizationInProgressLock.tryLock()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQwOTY5Mg==", "bodyText": "I wrote the check this way because I prefer, whenever possible, to short-circuit a logic path -- the less context a reader needs to have in their mind, the better. In this case, the inverted path is shorter, so i put it up front, so the reader can see what happens and they that path out of their mind.\nActually, looks like I can short-circuit with a return statement, so it can be simplified. Thanks for pointing it out.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431409692", "createdAt": "2020-05-27T20:02:21Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "diffHunk": "@@ -1911,43 +1912,51 @@ public boolean normalizeRegions() throws IOException {\n       return false;\n     }\n \n-    synchronized (this.normalizer) {\n+    if (!normalizationInProgressLock.tryLock()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTExNDA3Nw=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4NTI4MTUwOnYy", "diffSide": "RIGHT", "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/master/normalizer/TestSimpleRegionNormalizer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxMzoxODoyN1rOGbJkGw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QyMDo0NzowM1rOGbcg-Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTEyMTQzNQ==", "bodyText": "This assert might not be necessary given that we are anyways casting NormalizationPlan to SplitNormalizationPlan and MergeNormalizationPlan for next set of asserts.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431121435", "createdAt": "2020-05-27T13:18:27Z", "author": {"login": "virajjasani"}, "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/master/normalizer/TestSimpleRegionNormalizer.java", "diffHunk": "@@ -69,517 +78,347 @@\n   public static final HBaseClassTestRule CLASS_RULE =\n       HBaseClassTestRule.forClass(TestSimpleRegionNormalizer.class);\n \n-  private static final Logger LOG = LoggerFactory.getLogger(TestSimpleRegionNormalizer.class);\n-\n-  private RegionNormalizer normalizer;\n+  private Configuration conf;\n+  private SimpleRegionNormalizer normalizer;\n   private MasterServices masterServices;\n \n   @Rule\n   public TestName name = new TestName();\n \n-  @Test\n-  public void testPlanComparator() {\n-    Comparator<NormalizationPlan> comparator = new SimpleRegionNormalizer.PlanComparator();\n-    NormalizationPlan splitPlan1 = new SplitNormalizationPlan(null, null);\n-    NormalizationPlan splitPlan2 = new SplitNormalizationPlan(null, null);\n-    NormalizationPlan mergePlan1 = new MergeNormalizationPlan(null, null);\n-    NormalizationPlan mergePlan2 = new MergeNormalizationPlan(null, null);\n-\n-    assertEquals(0, comparator.compare(splitPlan1, splitPlan2));\n-    assertEquals(0, comparator.compare(splitPlan2, splitPlan1));\n-    assertEquals(0, comparator.compare(mergePlan1, mergePlan2));\n-    assertEquals(0, comparator.compare(mergePlan2, mergePlan1));\n-    assertTrue(comparator.compare(splitPlan1, mergePlan1) < 0);\n-    assertTrue(comparator.compare(mergePlan1, splitPlan1) > 0);\n+  @Before\n+  public void before() {\n+    conf = HBaseConfiguration.create();\n   }\n \n   @Test\n-  public void testNoNormalizationForMetaTable() throws HBaseIOException {\n+  public void testNoNormalizationForMetaTable() {\n     TableName testTable = TableName.META_TABLE_NAME;\n     List<RegionInfo> RegionInfo = new ArrayList<>();\n     Map<byte[], Integer> regionSizes = new HashMap<>();\n \n     setupMocksForNormalizer(regionSizes, RegionInfo);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(testTable);\n-    assertNull(plans);\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(testTable);\n+    assertThat(plans, empty());\n   }\n \n   @Test\n-  public void testNoNormalizationIfTooFewRegions() throws HBaseIOException {\n+  public void testNoNormalizationIfTooFewRegions() {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\"))\n-        .build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 10);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\"))\n-        .build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 15);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 2);\n+    final Map<byte[], Integer> regionSizes = createRegionSizesMap(regionInfos, 10, 15);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n \n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(tableName);\n-    assertNull(plans);\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, empty());\n   }\n \n   @Test\n-  public void testNoNormalizationOnNormalizedCluster() throws HBaseIOException {\n+  public void testNoNormalizationOnNormalizedCluster() {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n-\n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\"))\n-        .build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 10);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\"))\n-        .build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 15);\n-\n-    RegionInfo hri3 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ccc\"))\n-        .setEndKey(Bytes.toBytes(\"ddd\"))\n-        .build();\n-    RegionInfo.add(hri3);\n-    regionSizes.put(hri3.getRegionName(), 8);\n-\n-    RegionInfo hri4 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ddd\"))\n-        .setEndKey(Bytes.toBytes(\"eee\"))\n-        .build();\n-    regionSizes.put(hri4.getRegionName(), 10);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 4);\n+    final Map<byte[], Integer> regionSizes = createRegionSizesMap(regionInfos, 10, 15, 8, 10);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n \n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(tableName);\n-    assertNull(plans);\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, empty());\n   }\n \n-  private void noNormalizationOnTransitioningRegions(final RegionState.State state)\n-    throws Exception {\n+  private void noNormalizationOnTransitioningRegions(final RegionState.State state) {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    final List<RegionInfo> regionInfos = new LinkedList<>();\n-    final Map<byte[], Integer> regionSizes = new HashMap<>();\n-\n-    final RegionInfo ri1 = RegionInfoBuilder.newBuilder(tableName)\n-      .setStartKey(Bytes.toBytes(\"aaa\"))\n-      .setEndKey(Bytes.toBytes(\"bbb\"))\n-      .build();\n-    regionInfos.add(ri1);\n-    regionSizes.put(ri1.getRegionName(), 10);\n-\n-    final RegionInfo ri2 = RegionInfoBuilder.newBuilder(tableName)\n-      .setStartKey(Bytes.toBytes(\"bbb\"))\n-      .setEndKey(Bytes.toBytes(\"ccc\"))\n-      .build();\n-    regionInfos.add(ri2);\n-    regionSizes.put(ri2.getRegionName(), 1);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 3);\n+    final Map<byte[], Integer> regionSizes = createRegionSizesMap(regionInfos, 10, 1, 100);\n \n     setupMocksForNormalizer(regionSizes, regionInfos);\n     when(masterServices.getAssignmentManager().getRegionStates()\n-      .getRegionState(any(RegionInfo.class))).thenReturn(\n-      RegionState.createForTesting(null, state));\n-    assertNull(\n-      format(\"Unexpected plans for RegionState %s\", state),\n-      normalizer.computePlanForTable(tableName));\n+      .getRegionState(any(RegionInfo.class)))\n+      .thenReturn(RegionState.createForTesting(null, state));\n+    assertThat(normalizer.getMinRegionCount(), greaterThanOrEqualTo(regionInfos.size()));\n+\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(format(\"Unexpected plans for RegionState %s\", state), plans, empty());\n   }\n \n   @Test\n-  public void testNoNormalizationOnMergingNewRegions() throws Exception {\n+  public void testNoNormalizationOnMergingNewRegions() {\n     noNormalizationOnTransitioningRegions(RegionState.State.MERGING_NEW);\n   }\n \n   @Test\n-  public void testNoNormalizationOnMergingRegions() throws Exception {\n+  public void testNoNormalizationOnMergingRegions() {\n     noNormalizationOnTransitioningRegions(RegionState.State.MERGING);\n   }\n \n   @Test\n-  public void testNoNormalizationOnMergedRegions() throws Exception {\n+  public void testNoNormalizationOnMergedRegions() {\n     noNormalizationOnTransitioningRegions(RegionState.State.MERGED);\n   }\n \n   @Test\n-  public void testNoNormalizationOnSplittingNewRegions() throws Exception {\n+  public void testNoNormalizationOnSplittingNewRegions() {\n     noNormalizationOnTransitioningRegions(RegionState.State.SPLITTING_NEW);\n   }\n \n   @Test\n-  public void testNoNormalizationOnSplittingRegions() throws Exception {\n+  public void testNoNormalizationOnSplittingRegions() {\n     noNormalizationOnTransitioningRegions(RegionState.State.SPLITTING);\n   }\n \n   @Test\n-  public void testNoNormalizationOnSplitRegions() throws Exception {\n+  public void testNoNormalizationOnSplitRegions() {\n     noNormalizationOnTransitioningRegions(RegionState.State.SPLIT);\n   }\n \n   @Test\n-  public void testMergeOfSmallRegions() throws HBaseIOException {\n+  public void testMergeOfSmallRegions() {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n-\n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\"))\n-        .build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 15);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\"))\n-        .build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 5);\n-\n-    RegionInfo hri3 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ccc\"))\n-        .setEndKey(Bytes.toBytes(\"ddd\"))\n-        .build();\n-    RegionInfo.add(hri3);\n-    regionSizes.put(hri3.getRegionName(), 5);\n-\n-    RegionInfo hri4 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ddd\"))\n-        .setEndKey(Bytes.toBytes(\"eee\"))\n-        .build();\n-    RegionInfo.add(hri4);\n-    regionSizes.put(hri4.getRegionName(), 15);\n-\n-    RegionInfo hri5 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"eee\"))\n-        .setEndKey(Bytes.toBytes(\"fff\"))\n-        .build();\n-    RegionInfo.add(hri5);\n-    regionSizes.put(hri5.getRegionName(), 16);\n-\n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(tableName);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 5);\n+    final Map<byte[], Integer> regionSizes =\n+      createRegionSizesMap(regionInfos, 15, 5, 5, 15, 16);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n \n-    NormalizationPlan plan = plans.get(0);\n-    assertTrue(plan instanceof MergeNormalizationPlan);\n-    assertEquals(hri2, ((MergeNormalizationPlan) plan).getFirstRegion());\n-    assertEquals(hri3, ((MergeNormalizationPlan) plan).getSecondRegion());\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans.get(0), instanceOf(MergeNormalizationPlan.class));\n+    MergeNormalizationPlan plan = (MergeNormalizationPlan) plans.get(0);\n+    assertEquals(regionInfos.get(1), plan.getFirstRegion());\n+    assertEquals(regionInfos.get(2), plan.getSecondRegion());\n   }\n \n   // Test for situation illustrated in HBASE-14867\n   @Test\n-  public void testMergeOfSecondSmallestRegions() throws HBaseIOException {\n+  public void testMergeOfSecondSmallestRegions() {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n-\n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\"))\n-        .build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 1);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\"))\n-        .build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 10000);\n-\n-    RegionInfo hri3 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ccc\"))\n-        .setEndKey(Bytes.toBytes(\"ddd\"))\n-        .build();\n-    RegionInfo.add(hri3);\n-    regionSizes.put(hri3.getRegionName(), 10000);\n-\n-    RegionInfo hri4 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ddd\"))\n-        .setEndKey(Bytes.toBytes(\"eee\"))\n-        .build();\n-    RegionInfo.add(hri4);\n-    regionSizes.put(hri4.getRegionName(), 10000);\n-\n-    RegionInfo hri5 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"eee\"))\n-        .setEndKey(Bytes.toBytes(\"fff\"))\n-        .build();\n-    RegionInfo.add(hri5);\n-    regionSizes.put(hri5.getRegionName(), 2700);\n-\n-    RegionInfo hri6 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"fff\"))\n-        .setEndKey(Bytes.toBytes(\"ggg\"))\n-        .build();\n-    RegionInfo.add(hri6);\n-    regionSizes.put(hri6.getRegionName(), 2700);\n-\n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(tableName);\n-    NormalizationPlan plan = plans.get(0);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 6);\n+    final Map<byte[], Integer> regionSizes =\n+      createRegionSizesMap(regionInfos, 1, 10000, 10000, 10000, 2700, 2700);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n \n-    assertTrue(plan instanceof MergeNormalizationPlan);\n-    assertEquals(hri5, ((MergeNormalizationPlan) plan).getFirstRegion());\n-    assertEquals(hri6, ((MergeNormalizationPlan) plan).getSecondRegion());\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans.get(0), instanceOf(MergeNormalizationPlan.class));\n+    MergeNormalizationPlan plan = (MergeNormalizationPlan) plans.get(0);\n+    assertEquals(regionInfos.get(4), plan.getFirstRegion());\n+    assertEquals(regionInfos.get(5), plan.getSecondRegion());\n   }\n \n   @Test\n-  public void testMergeOfSmallNonAdjacentRegions() throws HBaseIOException {\n+  public void testMergeOfSmallNonAdjacentRegions() {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n-\n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\"))\n-        .build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 15);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\"))\n-        .build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 5);\n-\n-    RegionInfo hri3 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ccc\"))\n-        .setEndKey(Bytes.toBytes(\"ddd\"))\n-        .build();\n-    RegionInfo.add(hri3);\n-    regionSizes.put(hri3.getRegionName(), 16);\n-\n-    RegionInfo hri4 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ddd\"))\n-        .setEndKey(Bytes.toBytes(\"eee\"))\n-        .build();\n-    RegionInfo.add(hri4);\n-    regionSizes.put(hri4.getRegionName(), 15);\n-\n-    RegionInfo hri5 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ddd\"))\n-        .setEndKey(Bytes.toBytes(\"eee\"))\n-        .build();\n-    RegionInfo.add(hri4);\n-    regionSizes.put(hri5.getRegionName(), 5);\n-\n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(tableName);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 5);\n+    final Map<byte[], Integer> regionSizes =\n+      createRegionSizesMap(regionInfos, 15, 5, 16, 15, 5);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n \n-    assertNull(plans);\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, empty());\n   }\n \n   @Test\n-  public void testSplitOfLargeRegion() throws HBaseIOException {\n+  public void testSplitOfLargeRegion() {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n-\n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\"))\n-        .build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 8);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\"))\n-        .build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 6);\n-\n-    RegionInfo hri3 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ccc\"))\n-        .setEndKey(Bytes.toBytes(\"ddd\"))\n-        .build();\n-    RegionInfo.add(hri3);\n-    regionSizes.put(hri3.getRegionName(), 10);\n-\n-    RegionInfo hri4 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ddd\"))\n-        .setEndKey(Bytes.toBytes(\"eee\"))\n-        .build();\n-    RegionInfo.add(hri4);\n-    regionSizes.put(hri4.getRegionName(), 30);\n-\n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(tableName);\n-    NormalizationPlan plan = plans.get(0);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 4);\n+    final Map<byte[], Integer> regionSizes =\n+      createRegionSizesMap(regionInfos, 8, 6, 10, 30);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n \n-    assertTrue(plan instanceof SplitNormalizationPlan);\n-    assertEquals(hri4, ((SplitNormalizationPlan) plan).getRegionInfo());\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans.get(0), instanceOf(SplitNormalizationPlan.class));\n+    SplitNormalizationPlan plan = (SplitNormalizationPlan) plans.get(0);\n+    assertEquals(regionInfos.get(3), plan.getRegionInfo());\n   }\n \n   @Test\n   public void testSplitWithTargetRegionCount() throws Exception {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n-\n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\")).build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 20);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\")).build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 40);\n-\n-    RegionInfo hri3 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"ccc\"))\n-        .setEndKey(Bytes.toBytes(\"ddd\")).build();\n-    RegionInfo.add(hri3);\n-    regionSizes.put(hri3.getRegionName(), 60);\n-\n-    RegionInfo hri4 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"ddd\"))\n-        .setEndKey(Bytes.toBytes(\"eee\")).build();\n-    RegionInfo.add(hri4);\n-    regionSizes.put(hri4.getRegionName(), 80);\n-\n-    RegionInfo hri5 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"eee\"))\n-        .setEndKey(Bytes.toBytes(\"fff\")).build();\n-    RegionInfo.add(hri5);\n-    regionSizes.put(hri5.getRegionName(), 100);\n-\n-    RegionInfo hri6 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"fff\"))\n-        .setEndKey(Bytes.toBytes(\"ggg\")).build();\n-    RegionInfo.add(hri6);\n-    regionSizes.put(hri6.getRegionName(), 120);\n-\n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 6);\n+    final Map<byte[], Integer> regionSizes =\n+      createRegionSizesMap(regionInfos, 20, 40, 60, 80, 100, 120);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n \n     // test when target region size is 20\n     when(masterServices.getTableDescriptors().get(any()).getNormalizerTargetRegionSize())\n         .thenReturn(20L);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(tableName);\n-    assertEquals(4, plans.size());\n-\n-    for (NormalizationPlan plan : plans) {\n-      assertTrue(plan instanceof SplitNormalizationPlan);\n-    }\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, iterableWithSize(4));\n+    assertThat(plans, everyItem(instanceOf(SplitNormalizationPlan.class)));\n \n     // test when target region size is 200\n     when(masterServices.getTableDescriptors().get(any()).getNormalizerTargetRegionSize())\n         .thenReturn(200L);\n-    plans = normalizer.computePlanForTable(tableName);\n-    assertEquals(2, plans.size());\n-    NormalizationPlan plan = plans.get(0);\n-    assertTrue(plan instanceof MergeNormalizationPlan);\n-    assertEquals(hri1, ((MergeNormalizationPlan) plan).getFirstRegion());\n-    assertEquals(hri2, ((MergeNormalizationPlan) plan).getSecondRegion());\n+    plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, iterableWithSize(2));\n+    assertTrue(plans.get(0) instanceof MergeNormalizationPlan);\n+    MergeNormalizationPlan plan = (MergeNormalizationPlan) plans.get(0);\n+    assertEquals(regionInfos.get(0), plan.getFirstRegion());\n+    assertEquals(regionInfos.get(1), plan.getSecondRegion());\n   }\n \n   @Test\n   public void testSplitWithTargetRegionSize() throws Exception {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n-\n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\")).build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 20);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\")).build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 40);\n-\n-    RegionInfo hri3 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"ccc\"))\n-        .setEndKey(Bytes.toBytes(\"ddd\")).build();\n-    RegionInfo.add(hri3);\n-    regionSizes.put(hri3.getRegionName(), 60);\n-\n-    RegionInfo hri4 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"ddd\"))\n-        .setEndKey(Bytes.toBytes(\"eee\")).build();\n-    RegionInfo.add(hri4);\n-    regionSizes.put(hri4.getRegionName(), 80);\n-\n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 4);\n+    final Map<byte[], Integer> regionSizes = createRegionSizesMap(regionInfos, 20, 40, 60, 80);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n \n     // test when target region count is 8\n     when(masterServices.getTableDescriptors().get(any()).getNormalizerTargetRegionCount())\n         .thenReturn(8);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(tableName);\n-    assertEquals(2, plans.size());\n-\n-    for (NormalizationPlan plan : plans) {\n-      assertTrue(plan instanceof SplitNormalizationPlan);\n-    }\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, iterableWithSize(2));\n+    assertThat(plans, everyItem(instanceOf(SplitNormalizationPlan.class)));\n \n     // test when target region count is 3\n     when(masterServices.getTableDescriptors().get(any()).getNormalizerTargetRegionCount())\n         .thenReturn(3);\n-    plans = normalizer.computePlanForTable(tableName);\n-    assertEquals(1, plans.size());\n-    NormalizationPlan plan = plans.get(0);\n-    assertTrue(plan instanceof MergeNormalizationPlan);\n-    assertEquals(hri1, ((MergeNormalizationPlan) plan).getFirstRegion());\n-    assertEquals(hri2, ((MergeNormalizationPlan) plan).getSecondRegion());\n+    plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, contains(instanceOf(MergeNormalizationPlan.class)));\n+    MergeNormalizationPlan plan = (MergeNormalizationPlan) plans.get(0);\n+    assertEquals(regionInfos.get(0), plan.getFirstRegion());\n+    assertEquals(regionInfos.get(1), plan.getSecondRegion());\n   }\n \n   @Test\n-  public void testSplitIfTooFewRegions() throws HBaseIOException {\n+  public void testHonorsSplitEnabled() {\n+    conf.setBoolean(SPLIT_ENABLED_KEY, true);\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 5);\n+    final Map<byte[], Integer> regionSizes =\n+      createRegionSizesMap(regionInfos, 5, 5, 20, 5, 5);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n+    assertThat(\n+      normalizer.computePlansForTable(tableName),\n+      contains(instanceOf(SplitNormalizationPlan.class)));\n+\n+    conf.setBoolean(SPLIT_ENABLED_KEY, false);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n+    assertThat(normalizer.computePlansForTable(tableName), empty());\n+  }\n+\n+  @Test\n+  public void testHonorsMergeEnabled() {\n+    conf.setBoolean(MERGE_ENABLED_KEY, true);\n+    final TableName tableName = TableName.valueOf(name.getMethodName());\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 5);\n+    final Map<byte[], Integer> regionSizes =\n+      createRegionSizesMap(regionInfos, 20, 5, 5, 20, 20);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n+    assertThat(\n+      normalizer.computePlansForTable(tableName),\n+      contains(instanceOf(MergeNormalizationPlan.class)));\n \n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\"))\n-        .build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 1);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\"))\n-        .build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 1);\n-    // the third region is huge one\n-    RegionInfo hri3 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ccc\"))\n-        .setEndKey(Bytes.toBytes(\"ddd\"))\n-        .build();\n-    RegionInfo.add(hri3);\n-    regionSizes.put(hri3.getRegionName(), 10);\n+    conf.setBoolean(MERGE_ENABLED_KEY, false);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n+    assertThat(normalizer.computePlansForTable(tableName), empty());\n+  }\n \n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n+  @Test\n+  public void testHonorsMinimumRegionCount() {\n+    conf.setInt(MIN_REGION_COUNT_KEY, 1);\n+    final TableName tableName = TableName.valueOf(name.getMethodName());\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 3);\n+    // create a table topology that results in both a merge plan and a split plan. Assert that the\n+    // merge is only created when the when the number of table regions is above the region count\n+    // threshold, and that the split plan is create in both cases.\n+    final Map<byte[], Integer> regionSizes = createRegionSizesMap(regionInfos, 1, 1, 10);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n+\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, contains(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 697}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQzMTkyOQ==", "bodyText": "This assert gates the subsequent casts can be done safely. Without this check, the casts could fail... which would also fail the test, but in a less tasteful way.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431431929", "createdAt": "2020-05-27T20:47:03Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/master/normalizer/TestSimpleRegionNormalizer.java", "diffHunk": "@@ -69,517 +78,347 @@\n   public static final HBaseClassTestRule CLASS_RULE =\n       HBaseClassTestRule.forClass(TestSimpleRegionNormalizer.class);\n \n-  private static final Logger LOG = LoggerFactory.getLogger(TestSimpleRegionNormalizer.class);\n-\n-  private RegionNormalizer normalizer;\n+  private Configuration conf;\n+  private SimpleRegionNormalizer normalizer;\n   private MasterServices masterServices;\n \n   @Rule\n   public TestName name = new TestName();\n \n-  @Test\n-  public void testPlanComparator() {\n-    Comparator<NormalizationPlan> comparator = new SimpleRegionNormalizer.PlanComparator();\n-    NormalizationPlan splitPlan1 = new SplitNormalizationPlan(null, null);\n-    NormalizationPlan splitPlan2 = new SplitNormalizationPlan(null, null);\n-    NormalizationPlan mergePlan1 = new MergeNormalizationPlan(null, null);\n-    NormalizationPlan mergePlan2 = new MergeNormalizationPlan(null, null);\n-\n-    assertEquals(0, comparator.compare(splitPlan1, splitPlan2));\n-    assertEquals(0, comparator.compare(splitPlan2, splitPlan1));\n-    assertEquals(0, comparator.compare(mergePlan1, mergePlan2));\n-    assertEquals(0, comparator.compare(mergePlan2, mergePlan1));\n-    assertTrue(comparator.compare(splitPlan1, mergePlan1) < 0);\n-    assertTrue(comparator.compare(mergePlan1, splitPlan1) > 0);\n+  @Before\n+  public void before() {\n+    conf = HBaseConfiguration.create();\n   }\n \n   @Test\n-  public void testNoNormalizationForMetaTable() throws HBaseIOException {\n+  public void testNoNormalizationForMetaTable() {\n     TableName testTable = TableName.META_TABLE_NAME;\n     List<RegionInfo> RegionInfo = new ArrayList<>();\n     Map<byte[], Integer> regionSizes = new HashMap<>();\n \n     setupMocksForNormalizer(regionSizes, RegionInfo);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(testTable);\n-    assertNull(plans);\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(testTable);\n+    assertThat(plans, empty());\n   }\n \n   @Test\n-  public void testNoNormalizationIfTooFewRegions() throws HBaseIOException {\n+  public void testNoNormalizationIfTooFewRegions() {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\"))\n-        .build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 10);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\"))\n-        .build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 15);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 2);\n+    final Map<byte[], Integer> regionSizes = createRegionSizesMap(regionInfos, 10, 15);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n \n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(tableName);\n-    assertNull(plans);\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, empty());\n   }\n \n   @Test\n-  public void testNoNormalizationOnNormalizedCluster() throws HBaseIOException {\n+  public void testNoNormalizationOnNormalizedCluster() {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n-\n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\"))\n-        .build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 10);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\"))\n-        .build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 15);\n-\n-    RegionInfo hri3 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ccc\"))\n-        .setEndKey(Bytes.toBytes(\"ddd\"))\n-        .build();\n-    RegionInfo.add(hri3);\n-    regionSizes.put(hri3.getRegionName(), 8);\n-\n-    RegionInfo hri4 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ddd\"))\n-        .setEndKey(Bytes.toBytes(\"eee\"))\n-        .build();\n-    regionSizes.put(hri4.getRegionName(), 10);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 4);\n+    final Map<byte[], Integer> regionSizes = createRegionSizesMap(regionInfos, 10, 15, 8, 10);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n \n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(tableName);\n-    assertNull(plans);\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, empty());\n   }\n \n-  private void noNormalizationOnTransitioningRegions(final RegionState.State state)\n-    throws Exception {\n+  private void noNormalizationOnTransitioningRegions(final RegionState.State state) {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    final List<RegionInfo> regionInfos = new LinkedList<>();\n-    final Map<byte[], Integer> regionSizes = new HashMap<>();\n-\n-    final RegionInfo ri1 = RegionInfoBuilder.newBuilder(tableName)\n-      .setStartKey(Bytes.toBytes(\"aaa\"))\n-      .setEndKey(Bytes.toBytes(\"bbb\"))\n-      .build();\n-    regionInfos.add(ri1);\n-    regionSizes.put(ri1.getRegionName(), 10);\n-\n-    final RegionInfo ri2 = RegionInfoBuilder.newBuilder(tableName)\n-      .setStartKey(Bytes.toBytes(\"bbb\"))\n-      .setEndKey(Bytes.toBytes(\"ccc\"))\n-      .build();\n-    regionInfos.add(ri2);\n-    regionSizes.put(ri2.getRegionName(), 1);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 3);\n+    final Map<byte[], Integer> regionSizes = createRegionSizesMap(regionInfos, 10, 1, 100);\n \n     setupMocksForNormalizer(regionSizes, regionInfos);\n     when(masterServices.getAssignmentManager().getRegionStates()\n-      .getRegionState(any(RegionInfo.class))).thenReturn(\n-      RegionState.createForTesting(null, state));\n-    assertNull(\n-      format(\"Unexpected plans for RegionState %s\", state),\n-      normalizer.computePlanForTable(tableName));\n+      .getRegionState(any(RegionInfo.class)))\n+      .thenReturn(RegionState.createForTesting(null, state));\n+    assertThat(normalizer.getMinRegionCount(), greaterThanOrEqualTo(regionInfos.size()));\n+\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(format(\"Unexpected plans for RegionState %s\", state), plans, empty());\n   }\n \n   @Test\n-  public void testNoNormalizationOnMergingNewRegions() throws Exception {\n+  public void testNoNormalizationOnMergingNewRegions() {\n     noNormalizationOnTransitioningRegions(RegionState.State.MERGING_NEW);\n   }\n \n   @Test\n-  public void testNoNormalizationOnMergingRegions() throws Exception {\n+  public void testNoNormalizationOnMergingRegions() {\n     noNormalizationOnTransitioningRegions(RegionState.State.MERGING);\n   }\n \n   @Test\n-  public void testNoNormalizationOnMergedRegions() throws Exception {\n+  public void testNoNormalizationOnMergedRegions() {\n     noNormalizationOnTransitioningRegions(RegionState.State.MERGED);\n   }\n \n   @Test\n-  public void testNoNormalizationOnSplittingNewRegions() throws Exception {\n+  public void testNoNormalizationOnSplittingNewRegions() {\n     noNormalizationOnTransitioningRegions(RegionState.State.SPLITTING_NEW);\n   }\n \n   @Test\n-  public void testNoNormalizationOnSplittingRegions() throws Exception {\n+  public void testNoNormalizationOnSplittingRegions() {\n     noNormalizationOnTransitioningRegions(RegionState.State.SPLITTING);\n   }\n \n   @Test\n-  public void testNoNormalizationOnSplitRegions() throws Exception {\n+  public void testNoNormalizationOnSplitRegions() {\n     noNormalizationOnTransitioningRegions(RegionState.State.SPLIT);\n   }\n \n   @Test\n-  public void testMergeOfSmallRegions() throws HBaseIOException {\n+  public void testMergeOfSmallRegions() {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n-\n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\"))\n-        .build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 15);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\"))\n-        .build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 5);\n-\n-    RegionInfo hri3 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ccc\"))\n-        .setEndKey(Bytes.toBytes(\"ddd\"))\n-        .build();\n-    RegionInfo.add(hri3);\n-    regionSizes.put(hri3.getRegionName(), 5);\n-\n-    RegionInfo hri4 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ddd\"))\n-        .setEndKey(Bytes.toBytes(\"eee\"))\n-        .build();\n-    RegionInfo.add(hri4);\n-    regionSizes.put(hri4.getRegionName(), 15);\n-\n-    RegionInfo hri5 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"eee\"))\n-        .setEndKey(Bytes.toBytes(\"fff\"))\n-        .build();\n-    RegionInfo.add(hri5);\n-    regionSizes.put(hri5.getRegionName(), 16);\n-\n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(tableName);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 5);\n+    final Map<byte[], Integer> regionSizes =\n+      createRegionSizesMap(regionInfos, 15, 5, 5, 15, 16);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n \n-    NormalizationPlan plan = plans.get(0);\n-    assertTrue(plan instanceof MergeNormalizationPlan);\n-    assertEquals(hri2, ((MergeNormalizationPlan) plan).getFirstRegion());\n-    assertEquals(hri3, ((MergeNormalizationPlan) plan).getSecondRegion());\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans.get(0), instanceOf(MergeNormalizationPlan.class));\n+    MergeNormalizationPlan plan = (MergeNormalizationPlan) plans.get(0);\n+    assertEquals(regionInfos.get(1), plan.getFirstRegion());\n+    assertEquals(regionInfos.get(2), plan.getSecondRegion());\n   }\n \n   // Test for situation illustrated in HBASE-14867\n   @Test\n-  public void testMergeOfSecondSmallestRegions() throws HBaseIOException {\n+  public void testMergeOfSecondSmallestRegions() {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n-\n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\"))\n-        .build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 1);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\"))\n-        .build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 10000);\n-\n-    RegionInfo hri3 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ccc\"))\n-        .setEndKey(Bytes.toBytes(\"ddd\"))\n-        .build();\n-    RegionInfo.add(hri3);\n-    regionSizes.put(hri3.getRegionName(), 10000);\n-\n-    RegionInfo hri4 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ddd\"))\n-        .setEndKey(Bytes.toBytes(\"eee\"))\n-        .build();\n-    RegionInfo.add(hri4);\n-    regionSizes.put(hri4.getRegionName(), 10000);\n-\n-    RegionInfo hri5 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"eee\"))\n-        .setEndKey(Bytes.toBytes(\"fff\"))\n-        .build();\n-    RegionInfo.add(hri5);\n-    regionSizes.put(hri5.getRegionName(), 2700);\n-\n-    RegionInfo hri6 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"fff\"))\n-        .setEndKey(Bytes.toBytes(\"ggg\"))\n-        .build();\n-    RegionInfo.add(hri6);\n-    regionSizes.put(hri6.getRegionName(), 2700);\n-\n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(tableName);\n-    NormalizationPlan plan = plans.get(0);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 6);\n+    final Map<byte[], Integer> regionSizes =\n+      createRegionSizesMap(regionInfos, 1, 10000, 10000, 10000, 2700, 2700);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n \n-    assertTrue(plan instanceof MergeNormalizationPlan);\n-    assertEquals(hri5, ((MergeNormalizationPlan) plan).getFirstRegion());\n-    assertEquals(hri6, ((MergeNormalizationPlan) plan).getSecondRegion());\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans.get(0), instanceOf(MergeNormalizationPlan.class));\n+    MergeNormalizationPlan plan = (MergeNormalizationPlan) plans.get(0);\n+    assertEquals(regionInfos.get(4), plan.getFirstRegion());\n+    assertEquals(regionInfos.get(5), plan.getSecondRegion());\n   }\n \n   @Test\n-  public void testMergeOfSmallNonAdjacentRegions() throws HBaseIOException {\n+  public void testMergeOfSmallNonAdjacentRegions() {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n-\n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\"))\n-        .build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 15);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\"))\n-        .build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 5);\n-\n-    RegionInfo hri3 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ccc\"))\n-        .setEndKey(Bytes.toBytes(\"ddd\"))\n-        .build();\n-    RegionInfo.add(hri3);\n-    regionSizes.put(hri3.getRegionName(), 16);\n-\n-    RegionInfo hri4 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ddd\"))\n-        .setEndKey(Bytes.toBytes(\"eee\"))\n-        .build();\n-    RegionInfo.add(hri4);\n-    regionSizes.put(hri4.getRegionName(), 15);\n-\n-    RegionInfo hri5 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ddd\"))\n-        .setEndKey(Bytes.toBytes(\"eee\"))\n-        .build();\n-    RegionInfo.add(hri4);\n-    regionSizes.put(hri5.getRegionName(), 5);\n-\n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(tableName);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 5);\n+    final Map<byte[], Integer> regionSizes =\n+      createRegionSizesMap(regionInfos, 15, 5, 16, 15, 5);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n \n-    assertNull(plans);\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, empty());\n   }\n \n   @Test\n-  public void testSplitOfLargeRegion() throws HBaseIOException {\n+  public void testSplitOfLargeRegion() {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n-\n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\"))\n-        .build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 8);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\"))\n-        .build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 6);\n-\n-    RegionInfo hri3 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ccc\"))\n-        .setEndKey(Bytes.toBytes(\"ddd\"))\n-        .build();\n-    RegionInfo.add(hri3);\n-    regionSizes.put(hri3.getRegionName(), 10);\n-\n-    RegionInfo hri4 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ddd\"))\n-        .setEndKey(Bytes.toBytes(\"eee\"))\n-        .build();\n-    RegionInfo.add(hri4);\n-    regionSizes.put(hri4.getRegionName(), 30);\n-\n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(tableName);\n-    NormalizationPlan plan = plans.get(0);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 4);\n+    final Map<byte[], Integer> regionSizes =\n+      createRegionSizesMap(regionInfos, 8, 6, 10, 30);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n \n-    assertTrue(plan instanceof SplitNormalizationPlan);\n-    assertEquals(hri4, ((SplitNormalizationPlan) plan).getRegionInfo());\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans.get(0), instanceOf(SplitNormalizationPlan.class));\n+    SplitNormalizationPlan plan = (SplitNormalizationPlan) plans.get(0);\n+    assertEquals(regionInfos.get(3), plan.getRegionInfo());\n   }\n \n   @Test\n   public void testSplitWithTargetRegionCount() throws Exception {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n-\n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\")).build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 20);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\")).build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 40);\n-\n-    RegionInfo hri3 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"ccc\"))\n-        .setEndKey(Bytes.toBytes(\"ddd\")).build();\n-    RegionInfo.add(hri3);\n-    regionSizes.put(hri3.getRegionName(), 60);\n-\n-    RegionInfo hri4 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"ddd\"))\n-        .setEndKey(Bytes.toBytes(\"eee\")).build();\n-    RegionInfo.add(hri4);\n-    regionSizes.put(hri4.getRegionName(), 80);\n-\n-    RegionInfo hri5 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"eee\"))\n-        .setEndKey(Bytes.toBytes(\"fff\")).build();\n-    RegionInfo.add(hri5);\n-    regionSizes.put(hri5.getRegionName(), 100);\n-\n-    RegionInfo hri6 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"fff\"))\n-        .setEndKey(Bytes.toBytes(\"ggg\")).build();\n-    RegionInfo.add(hri6);\n-    regionSizes.put(hri6.getRegionName(), 120);\n-\n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 6);\n+    final Map<byte[], Integer> regionSizes =\n+      createRegionSizesMap(regionInfos, 20, 40, 60, 80, 100, 120);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n \n     // test when target region size is 20\n     when(masterServices.getTableDescriptors().get(any()).getNormalizerTargetRegionSize())\n         .thenReturn(20L);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(tableName);\n-    assertEquals(4, plans.size());\n-\n-    for (NormalizationPlan plan : plans) {\n-      assertTrue(plan instanceof SplitNormalizationPlan);\n-    }\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, iterableWithSize(4));\n+    assertThat(plans, everyItem(instanceOf(SplitNormalizationPlan.class)));\n \n     // test when target region size is 200\n     when(masterServices.getTableDescriptors().get(any()).getNormalizerTargetRegionSize())\n         .thenReturn(200L);\n-    plans = normalizer.computePlanForTable(tableName);\n-    assertEquals(2, plans.size());\n-    NormalizationPlan plan = plans.get(0);\n-    assertTrue(plan instanceof MergeNormalizationPlan);\n-    assertEquals(hri1, ((MergeNormalizationPlan) plan).getFirstRegion());\n-    assertEquals(hri2, ((MergeNormalizationPlan) plan).getSecondRegion());\n+    plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, iterableWithSize(2));\n+    assertTrue(plans.get(0) instanceof MergeNormalizationPlan);\n+    MergeNormalizationPlan plan = (MergeNormalizationPlan) plans.get(0);\n+    assertEquals(regionInfos.get(0), plan.getFirstRegion());\n+    assertEquals(regionInfos.get(1), plan.getSecondRegion());\n   }\n \n   @Test\n   public void testSplitWithTargetRegionSize() throws Exception {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n-\n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\")).build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 20);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\")).build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 40);\n-\n-    RegionInfo hri3 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"ccc\"))\n-        .setEndKey(Bytes.toBytes(\"ddd\")).build();\n-    RegionInfo.add(hri3);\n-    regionSizes.put(hri3.getRegionName(), 60);\n-\n-    RegionInfo hri4 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"ddd\"))\n-        .setEndKey(Bytes.toBytes(\"eee\")).build();\n-    RegionInfo.add(hri4);\n-    regionSizes.put(hri4.getRegionName(), 80);\n-\n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 4);\n+    final Map<byte[], Integer> regionSizes = createRegionSizesMap(regionInfos, 20, 40, 60, 80);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n \n     // test when target region count is 8\n     when(masterServices.getTableDescriptors().get(any()).getNormalizerTargetRegionCount())\n         .thenReturn(8);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(tableName);\n-    assertEquals(2, plans.size());\n-\n-    for (NormalizationPlan plan : plans) {\n-      assertTrue(plan instanceof SplitNormalizationPlan);\n-    }\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, iterableWithSize(2));\n+    assertThat(plans, everyItem(instanceOf(SplitNormalizationPlan.class)));\n \n     // test when target region count is 3\n     when(masterServices.getTableDescriptors().get(any()).getNormalizerTargetRegionCount())\n         .thenReturn(3);\n-    plans = normalizer.computePlanForTable(tableName);\n-    assertEquals(1, plans.size());\n-    NormalizationPlan plan = plans.get(0);\n-    assertTrue(plan instanceof MergeNormalizationPlan);\n-    assertEquals(hri1, ((MergeNormalizationPlan) plan).getFirstRegion());\n-    assertEquals(hri2, ((MergeNormalizationPlan) plan).getSecondRegion());\n+    plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, contains(instanceOf(MergeNormalizationPlan.class)));\n+    MergeNormalizationPlan plan = (MergeNormalizationPlan) plans.get(0);\n+    assertEquals(regionInfos.get(0), plan.getFirstRegion());\n+    assertEquals(regionInfos.get(1), plan.getSecondRegion());\n   }\n \n   @Test\n-  public void testSplitIfTooFewRegions() throws HBaseIOException {\n+  public void testHonorsSplitEnabled() {\n+    conf.setBoolean(SPLIT_ENABLED_KEY, true);\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 5);\n+    final Map<byte[], Integer> regionSizes =\n+      createRegionSizesMap(regionInfos, 5, 5, 20, 5, 5);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n+    assertThat(\n+      normalizer.computePlansForTable(tableName),\n+      contains(instanceOf(SplitNormalizationPlan.class)));\n+\n+    conf.setBoolean(SPLIT_ENABLED_KEY, false);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n+    assertThat(normalizer.computePlansForTable(tableName), empty());\n+  }\n+\n+  @Test\n+  public void testHonorsMergeEnabled() {\n+    conf.setBoolean(MERGE_ENABLED_KEY, true);\n+    final TableName tableName = TableName.valueOf(name.getMethodName());\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 5);\n+    final Map<byte[], Integer> regionSizes =\n+      createRegionSizesMap(regionInfos, 20, 5, 5, 20, 20);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n+    assertThat(\n+      normalizer.computePlansForTable(tableName),\n+      contains(instanceOf(MergeNormalizationPlan.class)));\n \n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\"))\n-        .build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 1);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\"))\n-        .build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 1);\n-    // the third region is huge one\n-    RegionInfo hri3 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ccc\"))\n-        .setEndKey(Bytes.toBytes(\"ddd\"))\n-        .build();\n-    RegionInfo.add(hri3);\n-    regionSizes.put(hri3.getRegionName(), 10);\n+    conf.setBoolean(MERGE_ENABLED_KEY, false);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n+    assertThat(normalizer.computePlansForTable(tableName), empty());\n+  }\n \n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n+  @Test\n+  public void testHonorsMinimumRegionCount() {\n+    conf.setInt(MIN_REGION_COUNT_KEY, 1);\n+    final TableName tableName = TableName.valueOf(name.getMethodName());\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 3);\n+    // create a table topology that results in both a merge plan and a split plan. Assert that the\n+    // merge is only created when the when the number of table regions is above the region count\n+    // threshold, and that the split plan is create in both cases.\n+    final Map<byte[], Integer> regionSizes = createRegionSizesMap(regionInfos, 1, 1, 10);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n+\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, contains(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTEyMTQzNQ=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 697}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4NTM0Mjg4OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxMzozMDoyMFrOGbKMlw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QyMjoxNTozOVrOGbfEPg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTEzMTc5OQ==", "bodyText": "This is really great addition to the doc. Should we document all these configs to Region Normalizer section of the book?", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431131799", "createdAt": "2020-05-27T13:30:20Z", "author": {"login": "virajjasani"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,436 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>\n+ *   <li>Otherwise, for the next region in the chain R1, if R0 + R1 is smaller then S, R0 and R1\n+ *     are kindly requested to merge.</li>\n+ * </ol>\n+ * <p>\n+ * The following parameters are configurable:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQwMzc4Mg==", "bodyText": "We should, :)", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431403782", "createdAt": "2020-05-27T19:50:32Z", "author": {"login": "huaxiangsun"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,436 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>\n+ *   <li>Otherwise, for the next region in the chain R1, if R0 + R1 is smaller then S, R0 and R1\n+ *     are kindly requested to merge.</li>\n+ * </ol>\n+ * <p>\n+ * The following parameters are configurable:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTEzMTc5OQ=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQxNDIxOQ==", "bodyText": "Good point. Let me take a pass over those docs as well.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431414219", "createdAt": "2020-05-27T20:11:42Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,436 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>\n+ *   <li>Otherwise, for the next region in the chain R1, if R0 + R1 is smaller then S, R0 and R1\n+ *     are kindly requested to merge.</li>\n+ * </ol>\n+ * <p>\n+ * The following parameters are configurable:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTEzMTc5OQ=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQ3MzcyNg==", "bodyText": "I've done some word-smithing here. However, the bulk of the documentation on this feature appears to have been copy-pasted from a post to Hortonworks forums. Rather than edit this work, I would prefer we start from scratch with our own documentation, so as to not mis-represent the work of that individual.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431473726", "createdAt": "2020-05-27T22:15:39Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,436 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>\n+ *   <li>Otherwise, for the next region in the chain R1, if R0 + R1 is smaller then S, R0 and R1\n+ *     are kindly requested to merge.</li>\n+ * </ol>\n+ * <p>\n+ * The following parameters are configurable:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTEzMTc5OQ=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 59}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4NTM3MzY1OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxMzozNzozN1rOGbKgfw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QyMDoyMTozOFrOGbbvAw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTEzNjg5NQ==", "bodyText": "Both skippedCount and planComparator can be static final.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431136895", "createdAt": "2020-05-27T13:37:37Z", "author": {"login": "virajjasani"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,436 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>\n+ *   <li>Otherwise, for the next region in the chain R1, if R0 + R1 is smaller then S, R0 and R1\n+ *     are kindly requested to merge.</li>\n+ * </ol>\n+ * <p>\n+ * The following parameters are configurable:\n+ * <ol>\n+ *   <li>Whether to split a region as part of normalization. Configuration:\n+ *     {@value SPLIT_ENABLED_KEY}, default: {@value DEFAULT_SPLIT_ENABLED}.</li>\n+ *   <li>Whether to merge a region as part of normalization. Configuration:\n+ *     {@value MERGE_ENABLED_KEY}, default: {@value DEFAULT_MERGE_ENABLED}.</li>\n+ *   <li>The minimum number of regions in a table to consider it for normalization. Configuration:\n+ *     {@value MIN_REGION_COUNT_KEY}, default: {@value DEFAULT_MIN_REGION_COUNT}.</li>\n+ *   <li>The minimum age for a region to be considered for a merge, in days. Configuration:\n+ *     {@value MERGE_MIN_REGION_AGE_DAYS_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_AGE_DAYS}.</li>\n+ *   <li>The minimum size for a region to be considered for a merge, in whole MBs. Configuration:\n+ *     {@value MERGE_MIN_REGION_SIZE_MB_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_SIZE_MB}.</li>\n  * </ol>\n  * <p>\n- * Region sizes are coarse and approximate on the order of megabytes. Additionally, \"empty\" regions\n- * (less than 1MB, with the previous note) are not merged away. This is by design to prevent\n- * normalization from undoing the pre-splitting of a table.\n+ * To see detailed logging of the application of these configuration values, set the log level for\n+ * this class to `TRACE`.\n  */\n-@InterfaceAudience.Private\n-public class SimpleRegionNormalizer extends AbstractRegionNormalizer {\n-\n+@InterfaceAudience.LimitedPrivate(HBaseInterfaceAudience.CONFIG)\n+public class SimpleRegionNormalizer implements RegionNormalizer {\n   private static final Logger LOG = LoggerFactory.getLogger(SimpleRegionNormalizer.class);\n-  private static long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+\n+  static final String SPLIT_ENABLED_KEY = \"hbase.normalizer.split.enabled\";\n+  static final boolean DEFAULT_SPLIT_ENABLED = true;\n+  static final String MERGE_ENABLED_KEY = \"hbase.normalizer.merge.enabled\";\n+  static final boolean DEFAULT_MERGE_ENABLED = true;\n+  // TODO: after HBASE-24416, `min.region.count` only applies to merge plans; should\n+  //  deprecate/rename the configuration key.\n+  static final String MIN_REGION_COUNT_KEY = \"hbase.normalizer.min.region.count\";\n+  static final int DEFAULT_MIN_REGION_COUNT = 3;\n+  static final String MERGE_MIN_REGION_AGE_DAYS_KEY = \"hbase.normalizer.merge.min_region_age.days\";\n+  static final int DEFAULT_MERGE_MIN_REGION_AGE_DAYS = 3;\n+  static final String MERGE_MIN_REGION_SIZE_MB_KEY = \"hbase.normalizer.merge.min_region_size.mb\";\n+  static final int DEFAULT_MERGE_MIN_REGION_SIZE_MB = 1;\n+\n+  private final long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+  private final Comparator<NormalizationPlan> planComparator = new SplitPlanFirstComparator();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQxOTEzOQ==", "bodyText": "Hmm. planComparator, yes.\nskippedCount, no, I disagree. The values in the array are mutable state, which should never be static. Let me make this more clear by moving initialization into the constructor.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431419139", "createdAt": "2020-05-27T20:21:38Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,436 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>\n+ *   <li>Otherwise, for the next region in the chain R1, if R0 + R1 is smaller then S, R0 and R1\n+ *     are kindly requested to merge.</li>\n+ * </ol>\n+ * <p>\n+ * The following parameters are configurable:\n+ * <ol>\n+ *   <li>Whether to split a region as part of normalization. Configuration:\n+ *     {@value SPLIT_ENABLED_KEY}, default: {@value DEFAULT_SPLIT_ENABLED}.</li>\n+ *   <li>Whether to merge a region as part of normalization. Configuration:\n+ *     {@value MERGE_ENABLED_KEY}, default: {@value DEFAULT_MERGE_ENABLED}.</li>\n+ *   <li>The minimum number of regions in a table to consider it for normalization. Configuration:\n+ *     {@value MIN_REGION_COUNT_KEY}, default: {@value DEFAULT_MIN_REGION_COUNT}.</li>\n+ *   <li>The minimum age for a region to be considered for a merge, in days. Configuration:\n+ *     {@value MERGE_MIN_REGION_AGE_DAYS_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_AGE_DAYS}.</li>\n+ *   <li>The minimum size for a region to be considered for a merge, in whole MBs. Configuration:\n+ *     {@value MERGE_MIN_REGION_SIZE_MB_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_SIZE_MB}.</li>\n  * </ol>\n  * <p>\n- * Region sizes are coarse and approximate on the order of megabytes. Additionally, \"empty\" regions\n- * (less than 1MB, with the previous note) are not merged away. This is by design to prevent\n- * normalization from undoing the pre-splitting of a table.\n+ * To see detailed logging of the application of these configuration values, set the log level for\n+ * this class to `TRACE`.\n  */\n-@InterfaceAudience.Private\n-public class SimpleRegionNormalizer extends AbstractRegionNormalizer {\n-\n+@InterfaceAudience.LimitedPrivate(HBaseInterfaceAudience.CONFIG)\n+public class SimpleRegionNormalizer implements RegionNormalizer {\n   private static final Logger LOG = LoggerFactory.getLogger(SimpleRegionNormalizer.class);\n-  private static long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+\n+  static final String SPLIT_ENABLED_KEY = \"hbase.normalizer.split.enabled\";\n+  static final boolean DEFAULT_SPLIT_ENABLED = true;\n+  static final String MERGE_ENABLED_KEY = \"hbase.normalizer.merge.enabled\";\n+  static final boolean DEFAULT_MERGE_ENABLED = true;\n+  // TODO: after HBASE-24416, `min.region.count` only applies to merge plans; should\n+  //  deprecate/rename the configuration key.\n+  static final String MIN_REGION_COUNT_KEY = \"hbase.normalizer.min.region.count\";\n+  static final int DEFAULT_MIN_REGION_COUNT = 3;\n+  static final String MERGE_MIN_REGION_AGE_DAYS_KEY = \"hbase.normalizer.merge.min_region_age.days\";\n+  static final int DEFAULT_MERGE_MIN_REGION_AGE_DAYS = 3;\n+  static final String MERGE_MIN_REGION_SIZE_MB_KEY = \"hbase.normalizer.merge.min_region_size.mb\";\n+  static final int DEFAULT_MERGE_MIN_REGION_SIZE_MB = 1;\n+\n+  private final long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+  private final Comparator<NormalizationPlan> planComparator = new SplitPlanFirstComparator();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTEzNjg5NQ=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 103}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4NTQwNzUwOnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxMzo0NToxN1rOGbK2kg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QyMDozNDozMFrOGbcHXA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTE0MjU0Ng==", "bodyText": "Good to guard with LOG.isDebugEnabled()?", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431142546", "createdAt": "2020-05-27T13:45:17Z", "author": {"login": "virajjasani"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,436 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>\n+ *   <li>Otherwise, for the next region in the chain R1, if R0 + R1 is smaller then S, R0 and R1\n+ *     are kindly requested to merge.</li>\n+ * </ol>\n+ * <p>\n+ * The following parameters are configurable:\n+ * <ol>\n+ *   <li>Whether to split a region as part of normalization. Configuration:\n+ *     {@value SPLIT_ENABLED_KEY}, default: {@value DEFAULT_SPLIT_ENABLED}.</li>\n+ *   <li>Whether to merge a region as part of normalization. Configuration:\n+ *     {@value MERGE_ENABLED_KEY}, default: {@value DEFAULT_MERGE_ENABLED}.</li>\n+ *   <li>The minimum number of regions in a table to consider it for normalization. Configuration:\n+ *     {@value MIN_REGION_COUNT_KEY}, default: {@value DEFAULT_MIN_REGION_COUNT}.</li>\n+ *   <li>The minimum age for a region to be considered for a merge, in days. Configuration:\n+ *     {@value MERGE_MIN_REGION_AGE_DAYS_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_AGE_DAYS}.</li>\n+ *   <li>The minimum size for a region to be considered for a merge, in whole MBs. Configuration:\n+ *     {@value MERGE_MIN_REGION_SIZE_MB_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_SIZE_MB}.</li>\n  * </ol>\n  * <p>\n- * Region sizes are coarse and approximate on the order of megabytes. Additionally, \"empty\" regions\n- * (less than 1MB, with the previous note) are not merged away. This is by design to prevent\n- * normalization from undoing the pre-splitting of a table.\n+ * To see detailed logging of the application of these configuration values, set the log level for\n+ * this class to `TRACE`.\n  */\n-@InterfaceAudience.Private\n-public class SimpleRegionNormalizer extends AbstractRegionNormalizer {\n-\n+@InterfaceAudience.LimitedPrivate(HBaseInterfaceAudience.CONFIG)\n+public class SimpleRegionNormalizer implements RegionNormalizer {\n   private static final Logger LOG = LoggerFactory.getLogger(SimpleRegionNormalizer.class);\n-  private static long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+\n+  static final String SPLIT_ENABLED_KEY = \"hbase.normalizer.split.enabled\";\n+  static final boolean DEFAULT_SPLIT_ENABLED = true;\n+  static final String MERGE_ENABLED_KEY = \"hbase.normalizer.merge.enabled\";\n+  static final boolean DEFAULT_MERGE_ENABLED = true;\n+  // TODO: after HBASE-24416, `min.region.count` only applies to merge plans; should\n+  //  deprecate/rename the configuration key.\n+  static final String MIN_REGION_COUNT_KEY = \"hbase.normalizer.min.region.count\";\n+  static final int DEFAULT_MIN_REGION_COUNT = 3;\n+  static final String MERGE_MIN_REGION_AGE_DAYS_KEY = \"hbase.normalizer.merge.min_region_age.days\";\n+  static final int DEFAULT_MERGE_MIN_REGION_AGE_DAYS = 3;\n+  static final String MERGE_MIN_REGION_SIZE_MB_KEY = \"hbase.normalizer.merge.min_region_size.mb\";\n+  static final int DEFAULT_MERGE_MIN_REGION_SIZE_MB = 1;\n+\n+  private final long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+  private final Comparator<NormalizationPlan> planComparator = new SplitPlanFirstComparator();\n+\n+  private Configuration conf;\n+  private MasterServices masterServices;\n+  private boolean splitEnabled;\n+  private boolean mergeEnabled;\n+  private int minRegionCount;\n+  private Period mergeMinRegionAge;\n+  private int mergeMinRegionSizeMb;\n+\n+  public SimpleRegionNormalizer() {\n+    splitEnabled = DEFAULT_SPLIT_ENABLED;\n+    mergeEnabled = DEFAULT_MERGE_ENABLED;\n+    minRegionCount = DEFAULT_MIN_REGION_COUNT;\n+    mergeMinRegionAge = Period.ofDays(DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    mergeMinRegionSizeMb = DEFAULT_MERGE_MIN_REGION_SIZE_MB;\n+  }\n \n   @Override\n-  public void planSkipped(RegionInfo hri, PlanType type) {\n-    skippedCount[type.ordinal()]++;\n+  public Configuration getConf() {\n+    return conf;\n   }\n \n   @Override\n-  public long getSkippedCount(NormalizationPlan.PlanType type) {\n-    return skippedCount[type.ordinal()];\n+  public void setConf(final Configuration conf) {\n+    if (conf == null) {\n+      return;\n+    }\n+    this.conf = conf;\n+    splitEnabled = conf.getBoolean(SPLIT_ENABLED_KEY, DEFAULT_SPLIT_ENABLED);\n+    mergeEnabled = conf.getBoolean(MERGE_ENABLED_KEY, DEFAULT_MERGE_ENABLED);\n+    minRegionCount = parseMinRegionCount(conf);\n+    mergeMinRegionAge = parseMergeMinRegionAge(conf);\n+    mergeMinRegionSizeMb = parseMergeMinRegionSizeMb(conf);\n+  }\n+\n+  private static int parseMinRegionCount(final Configuration conf) {\n+    final int parsedValue = conf.getInt(MIN_REGION_COUNT_KEY, DEFAULT_MIN_REGION_COUNT);\n+    final int settledValue = Math.max(1, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MIN_REGION_COUNT_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static Period parseMergeMinRegionAge(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_AGE_DAYS_KEY, DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_AGE_DAYS_KEY, parsedValue, settledValue);\n+    }\n+    return Period.ofDays(settledValue);\n+  }\n+\n+  private static int parseMergeMinRegionSizeMb(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_SIZE_MB_KEY, DEFAULT_MERGE_MIN_REGION_SIZE_MB);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_SIZE_MB_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static <T> void warnInvalidValue(final String key, final T parsedValue,\n+    final T settledValue) {\n+    LOG.warn(\"Configured value {}={} is invalid. Setting value to {}.\",\n+      key, parsedValue, settledValue);\n   }\n \n   /**\n-   * Comparator class that gives higher priority to region Split plan.\n+   * Return this instance's configured value for {@value SPLIT_ENABLED_KEY}.\n    */\n-  static class PlanComparator implements Comparator<NormalizationPlan> {\n-    @Override\n-    public int compare(NormalizationPlan plan1, NormalizationPlan plan2) {\n-      boolean plan1IsSplit = plan1 instanceof SplitNormalizationPlan;\n-      boolean plan2IsSplit = plan2 instanceof SplitNormalizationPlan;\n-      if (plan1IsSplit && plan2IsSplit) {\n-        return 0;\n-      } else if (plan1IsSplit) {\n-        return -1;\n-      } else if (plan2IsSplit) {\n-        return 1;\n-      } else {\n-        return 0;\n-      }\n-    }\n+  public boolean isSplitEnabled() {\n+    return splitEnabled;\n   }\n \n-  private Comparator<NormalizationPlan> planComparator = new PlanComparator();\n+  /**\n+   * Return this instance's configured value for {@value MERGE_ENABLED_KEY}.\n+   */\n+  public boolean isMergeEnabled() {\n+    return mergeEnabled;\n+  }\n \n   /**\n-   * Computes next most \"urgent\" normalization action on the table. Action may be either a split, or\n-   * a merge, or no action.\n-   * @param table table to normalize\n-   * @return normalization plan to execute\n+   * Return this instance's configured value for {@value MIN_REGION_COUNT_KEY}.\n+   */\n+  public int getMinRegionCount() {\n+    return minRegionCount;\n+  }\n+\n+  /**\n+   * Return this instance's configured value for {@value MERGE_MIN_REGION_AGE_DAYS_KEY}.\n    */\n+  public Period getMergeMinRegionAge() {\n+    return mergeMinRegionAge;\n+  }\n+\n+  /**\n+   * Return this instance's configured value for {@value MERGE_MIN_REGION_SIZE_MB_KEY}.\n+   */\n+  public int getMergeMinRegionSizeMb() {\n+    return mergeMinRegionSizeMb;\n+  }\n+\n   @Override\n-  public List<NormalizationPlan> computePlanForTable(TableName table) throws HBaseIOException {\n+  public void setMasterServices(final MasterServices masterServices) {\n+    this.masterServices = masterServices;\n+  }\n+\n+  @Override\n+  public void planSkipped(final RegionInfo hri, final PlanType type) {\n+    skippedCount[type.ordinal()]++;\n+  }\n+\n+  @Override\n+  public long getSkippedCount(NormalizationPlan.PlanType type) {\n+    return skippedCount[type.ordinal()];\n+  }\n+\n+  @Override\n+  public List<NormalizationPlan> computePlansForTable(TableName table) {\n     if (table == null || table.isSystemTable()) {\n       LOG.debug(\"Normalization of system table {} isn't allowed\", table);\n-      return null;\n+      return Collections.emptyList();\n     }\n-    boolean splitEnabled = isSplitEnabled();\n-    boolean mergeEnabled = isMergeEnabled();\n+    boolean splitEnabled = isSplitEnabled() && isMasterSwitchEnabled(MasterSwitchType.SPLIT);\n+    boolean mergeEnabled = isMergeEnabled() && isMasterSwitchEnabled(MasterSwitchType.MERGE);\n     if (!mergeEnabled && !splitEnabled) {\n-      LOG.debug(\"Both split and merge are disabled for table: {}\", table);\n-      return null;\n+      LOG.debug(\"Both split and merge are disabled. Skipping normalization of table: {}\", table);\n+      return Collections.emptyList();\n     }\n+\n     List<NormalizationPlan> plans = new ArrayList<>();\n-    List<RegionInfo> tableRegions =\n-        masterServices.getAssignmentManager().getRegionStates().getRegionsOfTable(table);\n+    List<RegionInfo> tableRegions = masterServices.getAssignmentManager()\n+      .getRegionStates()\n+      .getRegionsOfTable(table);\n \n-    if (tableRegions == null) {\n-      return null;\n+    if (CollectionUtils.isEmpty(tableRegions)) {\n+      return Collections.emptyList();\n     }\n \n     LOG.debug(\"Computing normalization plan for table:  {}, number of regions: {}\", table,\n       tableRegions.size());\n \n     if (splitEnabled) {\n-      List<NormalizationPlan> splitPlans = getSplitNormalizationPlan(table);\n-      if (splitPlans != null) {\n-        plans.addAll(splitPlans);\n+      plans.addAll(computeSplitNormalizationPlans(table));\n+    }\n+    if (mergeEnabled) {\n+      plans.addAll(computeMergeNormalizationPlans(table));\n+    }\n+\n+    plans.sort(planComparator);\n+    LOG.debug(\"Computed {} normalization plans for table {}\", plans.size(), table);\n+    return plans;\n+  }\n+\n+  /**\n+   * @return size of region in MB and if region is not found than -1\n+   */\n+  private long getRegionSizeMB(RegionInfo hri) {\n+    ServerName sn =\n+      masterServices.getAssignmentManager().getRegionStates().getRegionServerOfRegion(hri);\n+    RegionMetrics regionLoad =\n+      masterServices.getServerManager().getLoad(sn).getRegionMetrics().get(hri.getRegionName());\n+    if (regionLoad == null) {\n+      LOG.debug(\"{} was not found in RegionsLoad\", hri.getRegionNameAsString());\n+      return -1;\n+    }\n+    return (long) regionLoad.getStoreFileSize().get(Size.Unit.MEGABYTE);\n+  }\n+\n+  private boolean isMasterSwitchEnabled(final MasterSwitchType masterSwitchType) {\n+    return masterServices.isSplitOrMergeEnabled(masterSwitchType);\n+  }\n+\n+  /**\n+   * @param tableRegions regions of table to normalize\n+   * @return average region size depending on\n+   * @see org.apache.hadoop.hbase.client.TableDescriptor#getNormalizerTargetRegionCount()\n+   * Also make sure tableRegions contains regions of the same table\n+   */\n+  private double getAverageRegionSize(List<RegionInfo> tableRegions) {\n+    if (CollectionUtils.isEmpty(tableRegions)) {\n+      throw new IllegalStateException(\n+        \"Cannot calculate average size of a table without any regions.\");\n+    }\n+    final int regionCount = tableRegions.size();\n+    final long totalSizeMb = tableRegions.stream()\n+      .mapToLong(this::getRegionSizeMB)\n+      .sum();\n+    TableName table = tableRegions.get(0).getTable();\n+    int targetRegionCount = -1;\n+    long targetRegionSize = -1;\n+    try {\n+      TableDescriptor tableDescriptor = masterServices.getTableDescriptors().get(table);\n+      if (tableDescriptor != null) {\n+        targetRegionCount = tableDescriptor.getNormalizerTargetRegionCount();\n+        targetRegionSize = tableDescriptor.getNormalizerTargetRegionSize();\n+        LOG.debug(\"Table {} configured with target region count {}, target region size {}\", table,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 341}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQyNTM3Mg==", "bodyText": "I thought these were simple property accessors, but it looks like they're reaching down into a configuration object, so yeah, maybe they should be guarded.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431425372", "createdAt": "2020-05-27T20:34:30Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,436 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>\n+ *   <li>Otherwise, for the next region in the chain R1, if R0 + R1 is smaller then S, R0 and R1\n+ *     are kindly requested to merge.</li>\n+ * </ol>\n+ * <p>\n+ * The following parameters are configurable:\n+ * <ol>\n+ *   <li>Whether to split a region as part of normalization. Configuration:\n+ *     {@value SPLIT_ENABLED_KEY}, default: {@value DEFAULT_SPLIT_ENABLED}.</li>\n+ *   <li>Whether to merge a region as part of normalization. Configuration:\n+ *     {@value MERGE_ENABLED_KEY}, default: {@value DEFAULT_MERGE_ENABLED}.</li>\n+ *   <li>The minimum number of regions in a table to consider it for normalization. Configuration:\n+ *     {@value MIN_REGION_COUNT_KEY}, default: {@value DEFAULT_MIN_REGION_COUNT}.</li>\n+ *   <li>The minimum age for a region to be considered for a merge, in days. Configuration:\n+ *     {@value MERGE_MIN_REGION_AGE_DAYS_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_AGE_DAYS}.</li>\n+ *   <li>The minimum size for a region to be considered for a merge, in whole MBs. Configuration:\n+ *     {@value MERGE_MIN_REGION_SIZE_MB_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_SIZE_MB}.</li>\n  * </ol>\n  * <p>\n- * Region sizes are coarse and approximate on the order of megabytes. Additionally, \"empty\" regions\n- * (less than 1MB, with the previous note) are not merged away. This is by design to prevent\n- * normalization from undoing the pre-splitting of a table.\n+ * To see detailed logging of the application of these configuration values, set the log level for\n+ * this class to `TRACE`.\n  */\n-@InterfaceAudience.Private\n-public class SimpleRegionNormalizer extends AbstractRegionNormalizer {\n-\n+@InterfaceAudience.LimitedPrivate(HBaseInterfaceAudience.CONFIG)\n+public class SimpleRegionNormalizer implements RegionNormalizer {\n   private static final Logger LOG = LoggerFactory.getLogger(SimpleRegionNormalizer.class);\n-  private static long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+\n+  static final String SPLIT_ENABLED_KEY = \"hbase.normalizer.split.enabled\";\n+  static final boolean DEFAULT_SPLIT_ENABLED = true;\n+  static final String MERGE_ENABLED_KEY = \"hbase.normalizer.merge.enabled\";\n+  static final boolean DEFAULT_MERGE_ENABLED = true;\n+  // TODO: after HBASE-24416, `min.region.count` only applies to merge plans; should\n+  //  deprecate/rename the configuration key.\n+  static final String MIN_REGION_COUNT_KEY = \"hbase.normalizer.min.region.count\";\n+  static final int DEFAULT_MIN_REGION_COUNT = 3;\n+  static final String MERGE_MIN_REGION_AGE_DAYS_KEY = \"hbase.normalizer.merge.min_region_age.days\";\n+  static final int DEFAULT_MERGE_MIN_REGION_AGE_DAYS = 3;\n+  static final String MERGE_MIN_REGION_SIZE_MB_KEY = \"hbase.normalizer.merge.min_region_size.mb\";\n+  static final int DEFAULT_MERGE_MIN_REGION_SIZE_MB = 1;\n+\n+  private final long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+  private final Comparator<NormalizationPlan> planComparator = new SplitPlanFirstComparator();\n+\n+  private Configuration conf;\n+  private MasterServices masterServices;\n+  private boolean splitEnabled;\n+  private boolean mergeEnabled;\n+  private int minRegionCount;\n+  private Period mergeMinRegionAge;\n+  private int mergeMinRegionSizeMb;\n+\n+  public SimpleRegionNormalizer() {\n+    splitEnabled = DEFAULT_SPLIT_ENABLED;\n+    mergeEnabled = DEFAULT_MERGE_ENABLED;\n+    minRegionCount = DEFAULT_MIN_REGION_COUNT;\n+    mergeMinRegionAge = Period.ofDays(DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    mergeMinRegionSizeMb = DEFAULT_MERGE_MIN_REGION_SIZE_MB;\n+  }\n \n   @Override\n-  public void planSkipped(RegionInfo hri, PlanType type) {\n-    skippedCount[type.ordinal()]++;\n+  public Configuration getConf() {\n+    return conf;\n   }\n \n   @Override\n-  public long getSkippedCount(NormalizationPlan.PlanType type) {\n-    return skippedCount[type.ordinal()];\n+  public void setConf(final Configuration conf) {\n+    if (conf == null) {\n+      return;\n+    }\n+    this.conf = conf;\n+    splitEnabled = conf.getBoolean(SPLIT_ENABLED_KEY, DEFAULT_SPLIT_ENABLED);\n+    mergeEnabled = conf.getBoolean(MERGE_ENABLED_KEY, DEFAULT_MERGE_ENABLED);\n+    minRegionCount = parseMinRegionCount(conf);\n+    mergeMinRegionAge = parseMergeMinRegionAge(conf);\n+    mergeMinRegionSizeMb = parseMergeMinRegionSizeMb(conf);\n+  }\n+\n+  private static int parseMinRegionCount(final Configuration conf) {\n+    final int parsedValue = conf.getInt(MIN_REGION_COUNT_KEY, DEFAULT_MIN_REGION_COUNT);\n+    final int settledValue = Math.max(1, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MIN_REGION_COUNT_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static Period parseMergeMinRegionAge(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_AGE_DAYS_KEY, DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_AGE_DAYS_KEY, parsedValue, settledValue);\n+    }\n+    return Period.ofDays(settledValue);\n+  }\n+\n+  private static int parseMergeMinRegionSizeMb(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_SIZE_MB_KEY, DEFAULT_MERGE_MIN_REGION_SIZE_MB);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_SIZE_MB_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static <T> void warnInvalidValue(final String key, final T parsedValue,\n+    final T settledValue) {\n+    LOG.warn(\"Configured value {}={} is invalid. Setting value to {}.\",\n+      key, parsedValue, settledValue);\n   }\n \n   /**\n-   * Comparator class that gives higher priority to region Split plan.\n+   * Return this instance's configured value for {@value SPLIT_ENABLED_KEY}.\n    */\n-  static class PlanComparator implements Comparator<NormalizationPlan> {\n-    @Override\n-    public int compare(NormalizationPlan plan1, NormalizationPlan plan2) {\n-      boolean plan1IsSplit = plan1 instanceof SplitNormalizationPlan;\n-      boolean plan2IsSplit = plan2 instanceof SplitNormalizationPlan;\n-      if (plan1IsSplit && plan2IsSplit) {\n-        return 0;\n-      } else if (plan1IsSplit) {\n-        return -1;\n-      } else if (plan2IsSplit) {\n-        return 1;\n-      } else {\n-        return 0;\n-      }\n-    }\n+  public boolean isSplitEnabled() {\n+    return splitEnabled;\n   }\n \n-  private Comparator<NormalizationPlan> planComparator = new PlanComparator();\n+  /**\n+   * Return this instance's configured value for {@value MERGE_ENABLED_KEY}.\n+   */\n+  public boolean isMergeEnabled() {\n+    return mergeEnabled;\n+  }\n \n   /**\n-   * Computes next most \"urgent\" normalization action on the table. Action may be either a split, or\n-   * a merge, or no action.\n-   * @param table table to normalize\n-   * @return normalization plan to execute\n+   * Return this instance's configured value for {@value MIN_REGION_COUNT_KEY}.\n+   */\n+  public int getMinRegionCount() {\n+    return minRegionCount;\n+  }\n+\n+  /**\n+   * Return this instance's configured value for {@value MERGE_MIN_REGION_AGE_DAYS_KEY}.\n    */\n+  public Period getMergeMinRegionAge() {\n+    return mergeMinRegionAge;\n+  }\n+\n+  /**\n+   * Return this instance's configured value for {@value MERGE_MIN_REGION_SIZE_MB_KEY}.\n+   */\n+  public int getMergeMinRegionSizeMb() {\n+    return mergeMinRegionSizeMb;\n+  }\n+\n   @Override\n-  public List<NormalizationPlan> computePlanForTable(TableName table) throws HBaseIOException {\n+  public void setMasterServices(final MasterServices masterServices) {\n+    this.masterServices = masterServices;\n+  }\n+\n+  @Override\n+  public void planSkipped(final RegionInfo hri, final PlanType type) {\n+    skippedCount[type.ordinal()]++;\n+  }\n+\n+  @Override\n+  public long getSkippedCount(NormalizationPlan.PlanType type) {\n+    return skippedCount[type.ordinal()];\n+  }\n+\n+  @Override\n+  public List<NormalizationPlan> computePlansForTable(TableName table) {\n     if (table == null || table.isSystemTable()) {\n       LOG.debug(\"Normalization of system table {} isn't allowed\", table);\n-      return null;\n+      return Collections.emptyList();\n     }\n-    boolean splitEnabled = isSplitEnabled();\n-    boolean mergeEnabled = isMergeEnabled();\n+    boolean splitEnabled = isSplitEnabled() && isMasterSwitchEnabled(MasterSwitchType.SPLIT);\n+    boolean mergeEnabled = isMergeEnabled() && isMasterSwitchEnabled(MasterSwitchType.MERGE);\n     if (!mergeEnabled && !splitEnabled) {\n-      LOG.debug(\"Both split and merge are disabled for table: {}\", table);\n-      return null;\n+      LOG.debug(\"Both split and merge are disabled. Skipping normalization of table: {}\", table);\n+      return Collections.emptyList();\n     }\n+\n     List<NormalizationPlan> plans = new ArrayList<>();\n-    List<RegionInfo> tableRegions =\n-        masterServices.getAssignmentManager().getRegionStates().getRegionsOfTable(table);\n+    List<RegionInfo> tableRegions = masterServices.getAssignmentManager()\n+      .getRegionStates()\n+      .getRegionsOfTable(table);\n \n-    if (tableRegions == null) {\n-      return null;\n+    if (CollectionUtils.isEmpty(tableRegions)) {\n+      return Collections.emptyList();\n     }\n \n     LOG.debug(\"Computing normalization plan for table:  {}, number of regions: {}\", table,\n       tableRegions.size());\n \n     if (splitEnabled) {\n-      List<NormalizationPlan> splitPlans = getSplitNormalizationPlan(table);\n-      if (splitPlans != null) {\n-        plans.addAll(splitPlans);\n+      plans.addAll(computeSplitNormalizationPlans(table));\n+    }\n+    if (mergeEnabled) {\n+      plans.addAll(computeMergeNormalizationPlans(table));\n+    }\n+\n+    plans.sort(planComparator);\n+    LOG.debug(\"Computed {} normalization plans for table {}\", plans.size(), table);\n+    return plans;\n+  }\n+\n+  /**\n+   * @return size of region in MB and if region is not found than -1\n+   */\n+  private long getRegionSizeMB(RegionInfo hri) {\n+    ServerName sn =\n+      masterServices.getAssignmentManager().getRegionStates().getRegionServerOfRegion(hri);\n+    RegionMetrics regionLoad =\n+      masterServices.getServerManager().getLoad(sn).getRegionMetrics().get(hri.getRegionName());\n+    if (regionLoad == null) {\n+      LOG.debug(\"{} was not found in RegionsLoad\", hri.getRegionNameAsString());\n+      return -1;\n+    }\n+    return (long) regionLoad.getStoreFileSize().get(Size.Unit.MEGABYTE);\n+  }\n+\n+  private boolean isMasterSwitchEnabled(final MasterSwitchType masterSwitchType) {\n+    return masterServices.isSplitOrMergeEnabled(masterSwitchType);\n+  }\n+\n+  /**\n+   * @param tableRegions regions of table to normalize\n+   * @return average region size depending on\n+   * @see org.apache.hadoop.hbase.client.TableDescriptor#getNormalizerTargetRegionCount()\n+   * Also make sure tableRegions contains regions of the same table\n+   */\n+  private double getAverageRegionSize(List<RegionInfo> tableRegions) {\n+    if (CollectionUtils.isEmpty(tableRegions)) {\n+      throw new IllegalStateException(\n+        \"Cannot calculate average size of a table without any regions.\");\n+    }\n+    final int regionCount = tableRegions.size();\n+    final long totalSizeMb = tableRegions.stream()\n+      .mapToLong(this::getRegionSizeMB)\n+      .sum();\n+    TableName table = tableRegions.get(0).getTable();\n+    int targetRegionCount = -1;\n+    long targetRegionSize = -1;\n+    try {\n+      TableDescriptor tableDescriptor = masterServices.getTableDescriptors().get(table);\n+      if (tableDescriptor != null) {\n+        targetRegionCount = tableDescriptor.getNormalizerTargetRegionCount();\n+        targetRegionSize = tableDescriptor.getNormalizerTargetRegionSize();\n+        LOG.debug(\"Table {} configured with target region count {}, target region size {}\", table,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTE0MjU0Ng=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 341}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4NTQ5MDc1OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxNDowMjozNVrOGbLrmQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QyMDozNzoxMlrOGbcM9Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTE1NjEyMQ==", "bodyText": "same here, guarding will be better", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431156121", "createdAt": "2020-05-27T14:02:35Z", "author": {"login": "virajjasani"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,436 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>\n+ *   <li>Otherwise, for the next region in the chain R1, if R0 + R1 is smaller then S, R0 and R1\n+ *     are kindly requested to merge.</li>\n+ * </ol>\n+ * <p>\n+ * The following parameters are configurable:\n+ * <ol>\n+ *   <li>Whether to split a region as part of normalization. Configuration:\n+ *     {@value SPLIT_ENABLED_KEY}, default: {@value DEFAULT_SPLIT_ENABLED}.</li>\n+ *   <li>Whether to merge a region as part of normalization. Configuration:\n+ *     {@value MERGE_ENABLED_KEY}, default: {@value DEFAULT_MERGE_ENABLED}.</li>\n+ *   <li>The minimum number of regions in a table to consider it for normalization. Configuration:\n+ *     {@value MIN_REGION_COUNT_KEY}, default: {@value DEFAULT_MIN_REGION_COUNT}.</li>\n+ *   <li>The minimum age for a region to be considered for a merge, in days. Configuration:\n+ *     {@value MERGE_MIN_REGION_AGE_DAYS_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_AGE_DAYS}.</li>\n+ *   <li>The minimum size for a region to be considered for a merge, in whole MBs. Configuration:\n+ *     {@value MERGE_MIN_REGION_SIZE_MB_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_SIZE_MB}.</li>\n  * </ol>\n  * <p>\n- * Region sizes are coarse and approximate on the order of megabytes. Additionally, \"empty\" regions\n- * (less than 1MB, with the previous note) are not merged away. This is by design to prevent\n- * normalization from undoing the pre-splitting of a table.\n+ * To see detailed logging of the application of these configuration values, set the log level for\n+ * this class to `TRACE`.\n  */\n-@InterfaceAudience.Private\n-public class SimpleRegionNormalizer extends AbstractRegionNormalizer {\n-\n+@InterfaceAudience.LimitedPrivate(HBaseInterfaceAudience.CONFIG)\n+public class SimpleRegionNormalizer implements RegionNormalizer {\n   private static final Logger LOG = LoggerFactory.getLogger(SimpleRegionNormalizer.class);\n-  private static long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+\n+  static final String SPLIT_ENABLED_KEY = \"hbase.normalizer.split.enabled\";\n+  static final boolean DEFAULT_SPLIT_ENABLED = true;\n+  static final String MERGE_ENABLED_KEY = \"hbase.normalizer.merge.enabled\";\n+  static final boolean DEFAULT_MERGE_ENABLED = true;\n+  // TODO: after HBASE-24416, `min.region.count` only applies to merge plans; should\n+  //  deprecate/rename the configuration key.\n+  static final String MIN_REGION_COUNT_KEY = \"hbase.normalizer.min.region.count\";\n+  static final int DEFAULT_MIN_REGION_COUNT = 3;\n+  static final String MERGE_MIN_REGION_AGE_DAYS_KEY = \"hbase.normalizer.merge.min_region_age.days\";\n+  static final int DEFAULT_MERGE_MIN_REGION_AGE_DAYS = 3;\n+  static final String MERGE_MIN_REGION_SIZE_MB_KEY = \"hbase.normalizer.merge.min_region_size.mb\";\n+  static final int DEFAULT_MERGE_MIN_REGION_SIZE_MB = 1;\n+\n+  private final long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+  private final Comparator<NormalizationPlan> planComparator = new SplitPlanFirstComparator();\n+\n+  private Configuration conf;\n+  private MasterServices masterServices;\n+  private boolean splitEnabled;\n+  private boolean mergeEnabled;\n+  private int minRegionCount;\n+  private Period mergeMinRegionAge;\n+  private int mergeMinRegionSizeMb;\n+\n+  public SimpleRegionNormalizer() {\n+    splitEnabled = DEFAULT_SPLIT_ENABLED;\n+    mergeEnabled = DEFAULT_MERGE_ENABLED;\n+    minRegionCount = DEFAULT_MIN_REGION_COUNT;\n+    mergeMinRegionAge = Period.ofDays(DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    mergeMinRegionSizeMb = DEFAULT_MERGE_MIN_REGION_SIZE_MB;\n+  }\n \n   @Override\n-  public void planSkipped(RegionInfo hri, PlanType type) {\n-    skippedCount[type.ordinal()]++;\n+  public Configuration getConf() {\n+    return conf;\n   }\n \n   @Override\n-  public long getSkippedCount(NormalizationPlan.PlanType type) {\n-    return skippedCount[type.ordinal()];\n+  public void setConf(final Configuration conf) {\n+    if (conf == null) {\n+      return;\n+    }\n+    this.conf = conf;\n+    splitEnabled = conf.getBoolean(SPLIT_ENABLED_KEY, DEFAULT_SPLIT_ENABLED);\n+    mergeEnabled = conf.getBoolean(MERGE_ENABLED_KEY, DEFAULT_MERGE_ENABLED);\n+    minRegionCount = parseMinRegionCount(conf);\n+    mergeMinRegionAge = parseMergeMinRegionAge(conf);\n+    mergeMinRegionSizeMb = parseMergeMinRegionSizeMb(conf);\n+  }\n+\n+  private static int parseMinRegionCount(final Configuration conf) {\n+    final int parsedValue = conf.getInt(MIN_REGION_COUNT_KEY, DEFAULT_MIN_REGION_COUNT);\n+    final int settledValue = Math.max(1, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MIN_REGION_COUNT_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static Period parseMergeMinRegionAge(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_AGE_DAYS_KEY, DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_AGE_DAYS_KEY, parsedValue, settledValue);\n+    }\n+    return Period.ofDays(settledValue);\n+  }\n+\n+  private static int parseMergeMinRegionSizeMb(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_SIZE_MB_KEY, DEFAULT_MERGE_MIN_REGION_SIZE_MB);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_SIZE_MB_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static <T> void warnInvalidValue(final String key, final T parsedValue,\n+    final T settledValue) {\n+    LOG.warn(\"Configured value {}={} is invalid. Setting value to {}.\",\n+      key, parsedValue, settledValue);\n   }\n \n   /**\n-   * Comparator class that gives higher priority to region Split plan.\n+   * Return this instance's configured value for {@value SPLIT_ENABLED_KEY}.\n    */\n-  static class PlanComparator implements Comparator<NormalizationPlan> {\n-    @Override\n-    public int compare(NormalizationPlan plan1, NormalizationPlan plan2) {\n-      boolean plan1IsSplit = plan1 instanceof SplitNormalizationPlan;\n-      boolean plan2IsSplit = plan2 instanceof SplitNormalizationPlan;\n-      if (plan1IsSplit && plan2IsSplit) {\n-        return 0;\n-      } else if (plan1IsSplit) {\n-        return -1;\n-      } else if (plan2IsSplit) {\n-        return 1;\n-      } else {\n-        return 0;\n-      }\n-    }\n+  public boolean isSplitEnabled() {\n+    return splitEnabled;\n   }\n \n-  private Comparator<NormalizationPlan> planComparator = new PlanComparator();\n+  /**\n+   * Return this instance's configured value for {@value MERGE_ENABLED_KEY}.\n+   */\n+  public boolean isMergeEnabled() {\n+    return mergeEnabled;\n+  }\n \n   /**\n-   * Computes next most \"urgent\" normalization action on the table. Action may be either a split, or\n-   * a merge, or no action.\n-   * @param table table to normalize\n-   * @return normalization plan to execute\n+   * Return this instance's configured value for {@value MIN_REGION_COUNT_KEY}.\n+   */\n+  public int getMinRegionCount() {\n+    return minRegionCount;\n+  }\n+\n+  /**\n+   * Return this instance's configured value for {@value MERGE_MIN_REGION_AGE_DAYS_KEY}.\n    */\n+  public Period getMergeMinRegionAge() {\n+    return mergeMinRegionAge;\n+  }\n+\n+  /**\n+   * Return this instance's configured value for {@value MERGE_MIN_REGION_SIZE_MB_KEY}.\n+   */\n+  public int getMergeMinRegionSizeMb() {\n+    return mergeMinRegionSizeMb;\n+  }\n+\n   @Override\n-  public List<NormalizationPlan> computePlanForTable(TableName table) throws HBaseIOException {\n+  public void setMasterServices(final MasterServices masterServices) {\n+    this.masterServices = masterServices;\n+  }\n+\n+  @Override\n+  public void planSkipped(final RegionInfo hri, final PlanType type) {\n+    skippedCount[type.ordinal()]++;\n+  }\n+\n+  @Override\n+  public long getSkippedCount(NormalizationPlan.PlanType type) {\n+    return skippedCount[type.ordinal()];\n+  }\n+\n+  @Override\n+  public List<NormalizationPlan> computePlansForTable(TableName table) {\n     if (table == null || table.isSystemTable()) {\n       LOG.debug(\"Normalization of system table {} isn't allowed\", table);\n-      return null;\n+      return Collections.emptyList();\n     }\n-    boolean splitEnabled = isSplitEnabled();\n-    boolean mergeEnabled = isMergeEnabled();\n+    boolean splitEnabled = isSplitEnabled() && isMasterSwitchEnabled(MasterSwitchType.SPLIT);\n+    boolean mergeEnabled = isMergeEnabled() && isMasterSwitchEnabled(MasterSwitchType.MERGE);\n     if (!mergeEnabled && !splitEnabled) {\n-      LOG.debug(\"Both split and merge are disabled for table: {}\", table);\n-      return null;\n+      LOG.debug(\"Both split and merge are disabled. Skipping normalization of table: {}\", table);\n+      return Collections.emptyList();\n     }\n+\n     List<NormalizationPlan> plans = new ArrayList<>();\n-    List<RegionInfo> tableRegions =\n-        masterServices.getAssignmentManager().getRegionStates().getRegionsOfTable(table);\n+    List<RegionInfo> tableRegions = masterServices.getAssignmentManager()\n+      .getRegionStates()\n+      .getRegionsOfTable(table);\n \n-    if (tableRegions == null) {\n-      return null;\n+    if (CollectionUtils.isEmpty(tableRegions)) {\n+      return Collections.emptyList();\n     }\n \n     LOG.debug(\"Computing normalization plan for table:  {}, number of regions: {}\", table,\n       tableRegions.size());\n \n     if (splitEnabled) {\n-      List<NormalizationPlan> splitPlans = getSplitNormalizationPlan(table);\n-      if (splitPlans != null) {\n-        plans.addAll(splitPlans);\n+      plans.addAll(computeSplitNormalizationPlans(table));\n+    }\n+    if (mergeEnabled) {\n+      plans.addAll(computeMergeNormalizationPlans(table));\n+    }\n+\n+    plans.sort(planComparator);\n+    LOG.debug(\"Computed {} normalization plans for table {}\", plans.size(), table);\n+    return plans;\n+  }\n+\n+  /**\n+   * @return size of region in MB and if region is not found than -1\n+   */\n+  private long getRegionSizeMB(RegionInfo hri) {\n+    ServerName sn =\n+      masterServices.getAssignmentManager().getRegionStates().getRegionServerOfRegion(hri);\n+    RegionMetrics regionLoad =\n+      masterServices.getServerManager().getLoad(sn).getRegionMetrics().get(hri.getRegionName());\n+    if (regionLoad == null) {\n+      LOG.debug(\"{} was not found in RegionsLoad\", hri.getRegionNameAsString());\n+      return -1;\n+    }\n+    return (long) regionLoad.getStoreFileSize().get(Size.Unit.MEGABYTE);\n+  }\n+\n+  private boolean isMasterSwitchEnabled(final MasterSwitchType masterSwitchType) {\n+    return masterServices.isSplitOrMergeEnabled(masterSwitchType);\n+  }\n+\n+  /**\n+   * @param tableRegions regions of table to normalize\n+   * @return average region size depending on\n+   * @see org.apache.hadoop.hbase.client.TableDescriptor#getNormalizerTargetRegionCount()\n+   * Also make sure tableRegions contains regions of the same table\n+   */\n+  private double getAverageRegionSize(List<RegionInfo> tableRegions) {\n+    if (CollectionUtils.isEmpty(tableRegions)) {\n+      throw new IllegalStateException(\n+        \"Cannot calculate average size of a table without any regions.\");\n+    }\n+    final int regionCount = tableRegions.size();\n+    final long totalSizeMb = tableRegions.stream()\n+      .mapToLong(this::getRegionSizeMB)\n+      .sum();\n+    TableName table = tableRegions.get(0).getTable();\n+    int targetRegionCount = -1;\n+    long targetRegionSize = -1;\n+    try {\n+      TableDescriptor tableDescriptor = masterServices.getTableDescriptors().get(table);\n+      if (tableDescriptor != null) {\n+        targetRegionCount = tableDescriptor.getNormalizerTargetRegionCount();\n+        targetRegionSize = tableDescriptor.getNormalizerTargetRegionSize();\n+        LOG.debug(\"Table {} configured with target region count {}, target region size {}\", table,\n+          targetRegionCount, targetRegionSize);\n       }\n+    } catch (IOException e) {\n+      LOG.warn(\"TableDescriptor for {} unavailable, table-level target region count and size\"\n+        + \" configurations cannot be considered.\", table, e);\n     }\n \n-    if (mergeEnabled) {\n-      if (tableRegions.size() < minRegionCount) {\n-        LOG.debug(\"Table {} has {} regions, required min number of regions for normalizer to run\" +\n-                \" is {}, not running normalizer\",\n-            table, tableRegions.size(), minRegionCount);\n-      } else {\n-        List<NormalizationPlan> mergePlans = getMergeNormalizationPlan(table);\n-        if (mergePlans != null) {\n-          plans.addAll(mergePlans);\n-        }\n+    double avgRegionSize;\n+    if (targetRegionSize > 0) {\n+      avgRegionSize = targetRegionSize;\n+    } else if (targetRegionCount > 0) {\n+      avgRegionSize = totalSizeMb / (double) targetRegionCount;\n+    } else {\n+      avgRegionSize = totalSizeMb / (double) regionCount;\n+    }\n+\n+    LOG.debug(\"Table {}, total aggregated regions size: {} and average region size {}\", table,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 368}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQyNjgwNQ==", "bodyText": "Why? There's no additional calculation being done here; all the format argument values are fully resolved.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431426805", "createdAt": "2020-05-27T20:37:12Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,436 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>\n+ *   <li>Otherwise, for the next region in the chain R1, if R0 + R1 is smaller then S, R0 and R1\n+ *     are kindly requested to merge.</li>\n+ * </ol>\n+ * <p>\n+ * The following parameters are configurable:\n+ * <ol>\n+ *   <li>Whether to split a region as part of normalization. Configuration:\n+ *     {@value SPLIT_ENABLED_KEY}, default: {@value DEFAULT_SPLIT_ENABLED}.</li>\n+ *   <li>Whether to merge a region as part of normalization. Configuration:\n+ *     {@value MERGE_ENABLED_KEY}, default: {@value DEFAULT_MERGE_ENABLED}.</li>\n+ *   <li>The minimum number of regions in a table to consider it for normalization. Configuration:\n+ *     {@value MIN_REGION_COUNT_KEY}, default: {@value DEFAULT_MIN_REGION_COUNT}.</li>\n+ *   <li>The minimum age for a region to be considered for a merge, in days. Configuration:\n+ *     {@value MERGE_MIN_REGION_AGE_DAYS_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_AGE_DAYS}.</li>\n+ *   <li>The minimum size for a region to be considered for a merge, in whole MBs. Configuration:\n+ *     {@value MERGE_MIN_REGION_SIZE_MB_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_SIZE_MB}.</li>\n  * </ol>\n  * <p>\n- * Region sizes are coarse and approximate on the order of megabytes. Additionally, \"empty\" regions\n- * (less than 1MB, with the previous note) are not merged away. This is by design to prevent\n- * normalization from undoing the pre-splitting of a table.\n+ * To see detailed logging of the application of these configuration values, set the log level for\n+ * this class to `TRACE`.\n  */\n-@InterfaceAudience.Private\n-public class SimpleRegionNormalizer extends AbstractRegionNormalizer {\n-\n+@InterfaceAudience.LimitedPrivate(HBaseInterfaceAudience.CONFIG)\n+public class SimpleRegionNormalizer implements RegionNormalizer {\n   private static final Logger LOG = LoggerFactory.getLogger(SimpleRegionNormalizer.class);\n-  private static long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+\n+  static final String SPLIT_ENABLED_KEY = \"hbase.normalizer.split.enabled\";\n+  static final boolean DEFAULT_SPLIT_ENABLED = true;\n+  static final String MERGE_ENABLED_KEY = \"hbase.normalizer.merge.enabled\";\n+  static final boolean DEFAULT_MERGE_ENABLED = true;\n+  // TODO: after HBASE-24416, `min.region.count` only applies to merge plans; should\n+  //  deprecate/rename the configuration key.\n+  static final String MIN_REGION_COUNT_KEY = \"hbase.normalizer.min.region.count\";\n+  static final int DEFAULT_MIN_REGION_COUNT = 3;\n+  static final String MERGE_MIN_REGION_AGE_DAYS_KEY = \"hbase.normalizer.merge.min_region_age.days\";\n+  static final int DEFAULT_MERGE_MIN_REGION_AGE_DAYS = 3;\n+  static final String MERGE_MIN_REGION_SIZE_MB_KEY = \"hbase.normalizer.merge.min_region_size.mb\";\n+  static final int DEFAULT_MERGE_MIN_REGION_SIZE_MB = 1;\n+\n+  private final long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+  private final Comparator<NormalizationPlan> planComparator = new SplitPlanFirstComparator();\n+\n+  private Configuration conf;\n+  private MasterServices masterServices;\n+  private boolean splitEnabled;\n+  private boolean mergeEnabled;\n+  private int minRegionCount;\n+  private Period mergeMinRegionAge;\n+  private int mergeMinRegionSizeMb;\n+\n+  public SimpleRegionNormalizer() {\n+    splitEnabled = DEFAULT_SPLIT_ENABLED;\n+    mergeEnabled = DEFAULT_MERGE_ENABLED;\n+    minRegionCount = DEFAULT_MIN_REGION_COUNT;\n+    mergeMinRegionAge = Period.ofDays(DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    mergeMinRegionSizeMb = DEFAULT_MERGE_MIN_REGION_SIZE_MB;\n+  }\n \n   @Override\n-  public void planSkipped(RegionInfo hri, PlanType type) {\n-    skippedCount[type.ordinal()]++;\n+  public Configuration getConf() {\n+    return conf;\n   }\n \n   @Override\n-  public long getSkippedCount(NormalizationPlan.PlanType type) {\n-    return skippedCount[type.ordinal()];\n+  public void setConf(final Configuration conf) {\n+    if (conf == null) {\n+      return;\n+    }\n+    this.conf = conf;\n+    splitEnabled = conf.getBoolean(SPLIT_ENABLED_KEY, DEFAULT_SPLIT_ENABLED);\n+    mergeEnabled = conf.getBoolean(MERGE_ENABLED_KEY, DEFAULT_MERGE_ENABLED);\n+    minRegionCount = parseMinRegionCount(conf);\n+    mergeMinRegionAge = parseMergeMinRegionAge(conf);\n+    mergeMinRegionSizeMb = parseMergeMinRegionSizeMb(conf);\n+  }\n+\n+  private static int parseMinRegionCount(final Configuration conf) {\n+    final int parsedValue = conf.getInt(MIN_REGION_COUNT_KEY, DEFAULT_MIN_REGION_COUNT);\n+    final int settledValue = Math.max(1, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MIN_REGION_COUNT_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static Period parseMergeMinRegionAge(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_AGE_DAYS_KEY, DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_AGE_DAYS_KEY, parsedValue, settledValue);\n+    }\n+    return Period.ofDays(settledValue);\n+  }\n+\n+  private static int parseMergeMinRegionSizeMb(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_SIZE_MB_KEY, DEFAULT_MERGE_MIN_REGION_SIZE_MB);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_SIZE_MB_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static <T> void warnInvalidValue(final String key, final T parsedValue,\n+    final T settledValue) {\n+    LOG.warn(\"Configured value {}={} is invalid. Setting value to {}.\",\n+      key, parsedValue, settledValue);\n   }\n \n   /**\n-   * Comparator class that gives higher priority to region Split plan.\n+   * Return this instance's configured value for {@value SPLIT_ENABLED_KEY}.\n    */\n-  static class PlanComparator implements Comparator<NormalizationPlan> {\n-    @Override\n-    public int compare(NormalizationPlan plan1, NormalizationPlan plan2) {\n-      boolean plan1IsSplit = plan1 instanceof SplitNormalizationPlan;\n-      boolean plan2IsSplit = plan2 instanceof SplitNormalizationPlan;\n-      if (plan1IsSplit && plan2IsSplit) {\n-        return 0;\n-      } else if (plan1IsSplit) {\n-        return -1;\n-      } else if (plan2IsSplit) {\n-        return 1;\n-      } else {\n-        return 0;\n-      }\n-    }\n+  public boolean isSplitEnabled() {\n+    return splitEnabled;\n   }\n \n-  private Comparator<NormalizationPlan> planComparator = new PlanComparator();\n+  /**\n+   * Return this instance's configured value for {@value MERGE_ENABLED_KEY}.\n+   */\n+  public boolean isMergeEnabled() {\n+    return mergeEnabled;\n+  }\n \n   /**\n-   * Computes next most \"urgent\" normalization action on the table. Action may be either a split, or\n-   * a merge, or no action.\n-   * @param table table to normalize\n-   * @return normalization plan to execute\n+   * Return this instance's configured value for {@value MIN_REGION_COUNT_KEY}.\n+   */\n+  public int getMinRegionCount() {\n+    return minRegionCount;\n+  }\n+\n+  /**\n+   * Return this instance's configured value for {@value MERGE_MIN_REGION_AGE_DAYS_KEY}.\n    */\n+  public Period getMergeMinRegionAge() {\n+    return mergeMinRegionAge;\n+  }\n+\n+  /**\n+   * Return this instance's configured value for {@value MERGE_MIN_REGION_SIZE_MB_KEY}.\n+   */\n+  public int getMergeMinRegionSizeMb() {\n+    return mergeMinRegionSizeMb;\n+  }\n+\n   @Override\n-  public List<NormalizationPlan> computePlanForTable(TableName table) throws HBaseIOException {\n+  public void setMasterServices(final MasterServices masterServices) {\n+    this.masterServices = masterServices;\n+  }\n+\n+  @Override\n+  public void planSkipped(final RegionInfo hri, final PlanType type) {\n+    skippedCount[type.ordinal()]++;\n+  }\n+\n+  @Override\n+  public long getSkippedCount(NormalizationPlan.PlanType type) {\n+    return skippedCount[type.ordinal()];\n+  }\n+\n+  @Override\n+  public List<NormalizationPlan> computePlansForTable(TableName table) {\n     if (table == null || table.isSystemTable()) {\n       LOG.debug(\"Normalization of system table {} isn't allowed\", table);\n-      return null;\n+      return Collections.emptyList();\n     }\n-    boolean splitEnabled = isSplitEnabled();\n-    boolean mergeEnabled = isMergeEnabled();\n+    boolean splitEnabled = isSplitEnabled() && isMasterSwitchEnabled(MasterSwitchType.SPLIT);\n+    boolean mergeEnabled = isMergeEnabled() && isMasterSwitchEnabled(MasterSwitchType.MERGE);\n     if (!mergeEnabled && !splitEnabled) {\n-      LOG.debug(\"Both split and merge are disabled for table: {}\", table);\n-      return null;\n+      LOG.debug(\"Both split and merge are disabled. Skipping normalization of table: {}\", table);\n+      return Collections.emptyList();\n     }\n+\n     List<NormalizationPlan> plans = new ArrayList<>();\n-    List<RegionInfo> tableRegions =\n-        masterServices.getAssignmentManager().getRegionStates().getRegionsOfTable(table);\n+    List<RegionInfo> tableRegions = masterServices.getAssignmentManager()\n+      .getRegionStates()\n+      .getRegionsOfTable(table);\n \n-    if (tableRegions == null) {\n-      return null;\n+    if (CollectionUtils.isEmpty(tableRegions)) {\n+      return Collections.emptyList();\n     }\n \n     LOG.debug(\"Computing normalization plan for table:  {}, number of regions: {}\", table,\n       tableRegions.size());\n \n     if (splitEnabled) {\n-      List<NormalizationPlan> splitPlans = getSplitNormalizationPlan(table);\n-      if (splitPlans != null) {\n-        plans.addAll(splitPlans);\n+      plans.addAll(computeSplitNormalizationPlans(table));\n+    }\n+    if (mergeEnabled) {\n+      plans.addAll(computeMergeNormalizationPlans(table));\n+    }\n+\n+    plans.sort(planComparator);\n+    LOG.debug(\"Computed {} normalization plans for table {}\", plans.size(), table);\n+    return plans;\n+  }\n+\n+  /**\n+   * @return size of region in MB and if region is not found than -1\n+   */\n+  private long getRegionSizeMB(RegionInfo hri) {\n+    ServerName sn =\n+      masterServices.getAssignmentManager().getRegionStates().getRegionServerOfRegion(hri);\n+    RegionMetrics regionLoad =\n+      masterServices.getServerManager().getLoad(sn).getRegionMetrics().get(hri.getRegionName());\n+    if (regionLoad == null) {\n+      LOG.debug(\"{} was not found in RegionsLoad\", hri.getRegionNameAsString());\n+      return -1;\n+    }\n+    return (long) regionLoad.getStoreFileSize().get(Size.Unit.MEGABYTE);\n+  }\n+\n+  private boolean isMasterSwitchEnabled(final MasterSwitchType masterSwitchType) {\n+    return masterServices.isSplitOrMergeEnabled(masterSwitchType);\n+  }\n+\n+  /**\n+   * @param tableRegions regions of table to normalize\n+   * @return average region size depending on\n+   * @see org.apache.hadoop.hbase.client.TableDescriptor#getNormalizerTargetRegionCount()\n+   * Also make sure tableRegions contains regions of the same table\n+   */\n+  private double getAverageRegionSize(List<RegionInfo> tableRegions) {\n+    if (CollectionUtils.isEmpty(tableRegions)) {\n+      throw new IllegalStateException(\n+        \"Cannot calculate average size of a table without any regions.\");\n+    }\n+    final int regionCount = tableRegions.size();\n+    final long totalSizeMb = tableRegions.stream()\n+      .mapToLong(this::getRegionSizeMB)\n+      .sum();\n+    TableName table = tableRegions.get(0).getTable();\n+    int targetRegionCount = -1;\n+    long targetRegionSize = -1;\n+    try {\n+      TableDescriptor tableDescriptor = masterServices.getTableDescriptors().get(table);\n+      if (tableDescriptor != null) {\n+        targetRegionCount = tableDescriptor.getNormalizerTargetRegionCount();\n+        targetRegionSize = tableDescriptor.getNormalizerTargetRegionSize();\n+        LOG.debug(\"Table {} configured with target region count {}, target region size {}\", table,\n+          targetRegionCount, targetRegionSize);\n       }\n+    } catch (IOException e) {\n+      LOG.warn(\"TableDescriptor for {} unavailable, table-level target region count and size\"\n+        + \" configurations cannot be considered.\", table, e);\n     }\n \n-    if (mergeEnabled) {\n-      if (tableRegions.size() < minRegionCount) {\n-        LOG.debug(\"Table {} has {} regions, required min number of regions for normalizer to run\" +\n-                \" is {}, not running normalizer\",\n-            table, tableRegions.size(), minRegionCount);\n-      } else {\n-        List<NormalizationPlan> mergePlans = getMergeNormalizationPlan(table);\n-        if (mergePlans != null) {\n-          plans.addAll(mergePlans);\n-        }\n+    double avgRegionSize;\n+    if (targetRegionSize > 0) {\n+      avgRegionSize = targetRegionSize;\n+    } else if (targetRegionCount > 0) {\n+      avgRegionSize = totalSizeMb / (double) targetRegionCount;\n+    } else {\n+      avgRegionSize = totalSizeMb / (double) regionCount;\n+    }\n+\n+    LOG.debug(\"Table {}, total aggregated regions size: {} and average region size {}\", table,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTE1NjEyMQ=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 368}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4NTYxMjg2OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "isResolved": false, "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxNDoyODo0OFrOGbM7MA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMVQyMjoyOToxOVrOGdcLCA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTE3NjQ5Ng==", "bodyText": "We retrieve List<RegionInfo> tableRegions again in computeSplitNormalizationPlans() and computeMergeNormalizationPlans(). It should be safe to pass this list to both methods and avoid calls to AM?", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431176496", "createdAt": "2020-05-27T14:28:48Z", "author": {"login": "virajjasani"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,436 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>\n+ *   <li>Otherwise, for the next region in the chain R1, if R0 + R1 is smaller then S, R0 and R1\n+ *     are kindly requested to merge.</li>\n+ * </ol>\n+ * <p>\n+ * The following parameters are configurable:\n+ * <ol>\n+ *   <li>Whether to split a region as part of normalization. Configuration:\n+ *     {@value SPLIT_ENABLED_KEY}, default: {@value DEFAULT_SPLIT_ENABLED}.</li>\n+ *   <li>Whether to merge a region as part of normalization. Configuration:\n+ *     {@value MERGE_ENABLED_KEY}, default: {@value DEFAULT_MERGE_ENABLED}.</li>\n+ *   <li>The minimum number of regions in a table to consider it for normalization. Configuration:\n+ *     {@value MIN_REGION_COUNT_KEY}, default: {@value DEFAULT_MIN_REGION_COUNT}.</li>\n+ *   <li>The minimum age for a region to be considered for a merge, in days. Configuration:\n+ *     {@value MERGE_MIN_REGION_AGE_DAYS_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_AGE_DAYS}.</li>\n+ *   <li>The minimum size for a region to be considered for a merge, in whole MBs. Configuration:\n+ *     {@value MERGE_MIN_REGION_SIZE_MB_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_SIZE_MB}.</li>\n  * </ol>\n  * <p>\n- * Region sizes are coarse and approximate on the order of megabytes. Additionally, \"empty\" regions\n- * (less than 1MB, with the previous note) are not merged away. This is by design to prevent\n- * normalization from undoing the pre-splitting of a table.\n+ * To see detailed logging of the application of these configuration values, set the log level for\n+ * this class to `TRACE`.\n  */\n-@InterfaceAudience.Private\n-public class SimpleRegionNormalizer extends AbstractRegionNormalizer {\n-\n+@InterfaceAudience.LimitedPrivate(HBaseInterfaceAudience.CONFIG)\n+public class SimpleRegionNormalizer implements RegionNormalizer {\n   private static final Logger LOG = LoggerFactory.getLogger(SimpleRegionNormalizer.class);\n-  private static long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+\n+  static final String SPLIT_ENABLED_KEY = \"hbase.normalizer.split.enabled\";\n+  static final boolean DEFAULT_SPLIT_ENABLED = true;\n+  static final String MERGE_ENABLED_KEY = \"hbase.normalizer.merge.enabled\";\n+  static final boolean DEFAULT_MERGE_ENABLED = true;\n+  // TODO: after HBASE-24416, `min.region.count` only applies to merge plans; should\n+  //  deprecate/rename the configuration key.\n+  static final String MIN_REGION_COUNT_KEY = \"hbase.normalizer.min.region.count\";\n+  static final int DEFAULT_MIN_REGION_COUNT = 3;\n+  static final String MERGE_MIN_REGION_AGE_DAYS_KEY = \"hbase.normalizer.merge.min_region_age.days\";\n+  static final int DEFAULT_MERGE_MIN_REGION_AGE_DAYS = 3;\n+  static final String MERGE_MIN_REGION_SIZE_MB_KEY = \"hbase.normalizer.merge.min_region_size.mb\";\n+  static final int DEFAULT_MERGE_MIN_REGION_SIZE_MB = 1;\n+\n+  private final long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+  private final Comparator<NormalizationPlan> planComparator = new SplitPlanFirstComparator();\n+\n+  private Configuration conf;\n+  private MasterServices masterServices;\n+  private boolean splitEnabled;\n+  private boolean mergeEnabled;\n+  private int minRegionCount;\n+  private Period mergeMinRegionAge;\n+  private int mergeMinRegionSizeMb;\n+\n+  public SimpleRegionNormalizer() {\n+    splitEnabled = DEFAULT_SPLIT_ENABLED;\n+    mergeEnabled = DEFAULT_MERGE_ENABLED;\n+    minRegionCount = DEFAULT_MIN_REGION_COUNT;\n+    mergeMinRegionAge = Period.ofDays(DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    mergeMinRegionSizeMb = DEFAULT_MERGE_MIN_REGION_SIZE_MB;\n+  }\n \n   @Override\n-  public void planSkipped(RegionInfo hri, PlanType type) {\n-    skippedCount[type.ordinal()]++;\n+  public Configuration getConf() {\n+    return conf;\n   }\n \n   @Override\n-  public long getSkippedCount(NormalizationPlan.PlanType type) {\n-    return skippedCount[type.ordinal()];\n+  public void setConf(final Configuration conf) {\n+    if (conf == null) {\n+      return;\n+    }\n+    this.conf = conf;\n+    splitEnabled = conf.getBoolean(SPLIT_ENABLED_KEY, DEFAULT_SPLIT_ENABLED);\n+    mergeEnabled = conf.getBoolean(MERGE_ENABLED_KEY, DEFAULT_MERGE_ENABLED);\n+    minRegionCount = parseMinRegionCount(conf);\n+    mergeMinRegionAge = parseMergeMinRegionAge(conf);\n+    mergeMinRegionSizeMb = parseMergeMinRegionSizeMb(conf);\n+  }\n+\n+  private static int parseMinRegionCount(final Configuration conf) {\n+    final int parsedValue = conf.getInt(MIN_REGION_COUNT_KEY, DEFAULT_MIN_REGION_COUNT);\n+    final int settledValue = Math.max(1, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MIN_REGION_COUNT_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static Period parseMergeMinRegionAge(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_AGE_DAYS_KEY, DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_AGE_DAYS_KEY, parsedValue, settledValue);\n+    }\n+    return Period.ofDays(settledValue);\n+  }\n+\n+  private static int parseMergeMinRegionSizeMb(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_SIZE_MB_KEY, DEFAULT_MERGE_MIN_REGION_SIZE_MB);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_SIZE_MB_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static <T> void warnInvalidValue(final String key, final T parsedValue,\n+    final T settledValue) {\n+    LOG.warn(\"Configured value {}={} is invalid. Setting value to {}.\",\n+      key, parsedValue, settledValue);\n   }\n \n   /**\n-   * Comparator class that gives higher priority to region Split plan.\n+   * Return this instance's configured value for {@value SPLIT_ENABLED_KEY}.\n    */\n-  static class PlanComparator implements Comparator<NormalizationPlan> {\n-    @Override\n-    public int compare(NormalizationPlan plan1, NormalizationPlan plan2) {\n-      boolean plan1IsSplit = plan1 instanceof SplitNormalizationPlan;\n-      boolean plan2IsSplit = plan2 instanceof SplitNormalizationPlan;\n-      if (plan1IsSplit && plan2IsSplit) {\n-        return 0;\n-      } else if (plan1IsSplit) {\n-        return -1;\n-      } else if (plan2IsSplit) {\n-        return 1;\n-      } else {\n-        return 0;\n-      }\n-    }\n+  public boolean isSplitEnabled() {\n+    return splitEnabled;\n   }\n \n-  private Comparator<NormalizationPlan> planComparator = new PlanComparator();\n+  /**\n+   * Return this instance's configured value for {@value MERGE_ENABLED_KEY}.\n+   */\n+  public boolean isMergeEnabled() {\n+    return mergeEnabled;\n+  }\n \n   /**\n-   * Computes next most \"urgent\" normalization action on the table. Action may be either a split, or\n-   * a merge, or no action.\n-   * @param table table to normalize\n-   * @return normalization plan to execute\n+   * Return this instance's configured value for {@value MIN_REGION_COUNT_KEY}.\n+   */\n+  public int getMinRegionCount() {\n+    return minRegionCount;\n+  }\n+\n+  /**\n+   * Return this instance's configured value for {@value MERGE_MIN_REGION_AGE_DAYS_KEY}.\n    */\n+  public Period getMergeMinRegionAge() {\n+    return mergeMinRegionAge;\n+  }\n+\n+  /**\n+   * Return this instance's configured value for {@value MERGE_MIN_REGION_SIZE_MB_KEY}.\n+   */\n+  public int getMergeMinRegionSizeMb() {\n+    return mergeMinRegionSizeMb;\n+  }\n+\n   @Override\n-  public List<NormalizationPlan> computePlanForTable(TableName table) throws HBaseIOException {\n+  public void setMasterServices(final MasterServices masterServices) {\n+    this.masterServices = masterServices;\n+  }\n+\n+  @Override\n+  public void planSkipped(final RegionInfo hri, final PlanType type) {\n+    skippedCount[type.ordinal()]++;\n+  }\n+\n+  @Override\n+  public long getSkippedCount(NormalizationPlan.PlanType type) {\n+    return skippedCount[type.ordinal()];\n+  }\n+\n+  @Override\n+  public List<NormalizationPlan> computePlansForTable(TableName table) {\n     if (table == null || table.isSystemTable()) {\n       LOG.debug(\"Normalization of system table {} isn't allowed\", table);\n-      return null;\n+      return Collections.emptyList();\n     }\n-    boolean splitEnabled = isSplitEnabled();\n-    boolean mergeEnabled = isMergeEnabled();\n+    boolean splitEnabled = isSplitEnabled() && isMasterSwitchEnabled(MasterSwitchType.SPLIT);\n+    boolean mergeEnabled = isMergeEnabled() && isMasterSwitchEnabled(MasterSwitchType.MERGE);\n     if (!mergeEnabled && !splitEnabled) {\n-      LOG.debug(\"Both split and merge are disabled for table: {}\", table);\n-      return null;\n+      LOG.debug(\"Both split and merge are disabled. Skipping normalization of table: {}\", table);\n+      return Collections.emptyList();\n     }\n+\n     List<NormalizationPlan> plans = new ArrayList<>();\n-    List<RegionInfo> tableRegions =\n-        masterServices.getAssignmentManager().getRegionStates().getRegionsOfTable(table);\n+    List<RegionInfo> tableRegions = masterServices.getAssignmentManager()\n+      .getRegionStates()\n+      .getRegionsOfTable(table);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 273}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI4Mjk5Mg==", "bodyText": "+1 on above", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431282992", "createdAt": "2020-05-27T16:35:48Z", "author": {"login": "saintstack"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,436 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>\n+ *   <li>Otherwise, for the next region in the chain R1, if R0 + R1 is smaller then S, R0 and R1\n+ *     are kindly requested to merge.</li>\n+ * </ol>\n+ * <p>\n+ * The following parameters are configurable:\n+ * <ol>\n+ *   <li>Whether to split a region as part of normalization. Configuration:\n+ *     {@value SPLIT_ENABLED_KEY}, default: {@value DEFAULT_SPLIT_ENABLED}.</li>\n+ *   <li>Whether to merge a region as part of normalization. Configuration:\n+ *     {@value MERGE_ENABLED_KEY}, default: {@value DEFAULT_MERGE_ENABLED}.</li>\n+ *   <li>The minimum number of regions in a table to consider it for normalization. Configuration:\n+ *     {@value MIN_REGION_COUNT_KEY}, default: {@value DEFAULT_MIN_REGION_COUNT}.</li>\n+ *   <li>The minimum age for a region to be considered for a merge, in days. Configuration:\n+ *     {@value MERGE_MIN_REGION_AGE_DAYS_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_AGE_DAYS}.</li>\n+ *   <li>The minimum size for a region to be considered for a merge, in whole MBs. Configuration:\n+ *     {@value MERGE_MIN_REGION_SIZE_MB_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_SIZE_MB}.</li>\n  * </ol>\n  * <p>\n- * Region sizes are coarse and approximate on the order of megabytes. Additionally, \"empty\" regions\n- * (less than 1MB, with the previous note) are not merged away. This is by design to prevent\n- * normalization from undoing the pre-splitting of a table.\n+ * To see detailed logging of the application of these configuration values, set the log level for\n+ * this class to `TRACE`.\n  */\n-@InterfaceAudience.Private\n-public class SimpleRegionNormalizer extends AbstractRegionNormalizer {\n-\n+@InterfaceAudience.LimitedPrivate(HBaseInterfaceAudience.CONFIG)\n+public class SimpleRegionNormalizer implements RegionNormalizer {\n   private static final Logger LOG = LoggerFactory.getLogger(SimpleRegionNormalizer.class);\n-  private static long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+\n+  static final String SPLIT_ENABLED_KEY = \"hbase.normalizer.split.enabled\";\n+  static final boolean DEFAULT_SPLIT_ENABLED = true;\n+  static final String MERGE_ENABLED_KEY = \"hbase.normalizer.merge.enabled\";\n+  static final boolean DEFAULT_MERGE_ENABLED = true;\n+  // TODO: after HBASE-24416, `min.region.count` only applies to merge plans; should\n+  //  deprecate/rename the configuration key.\n+  static final String MIN_REGION_COUNT_KEY = \"hbase.normalizer.min.region.count\";\n+  static final int DEFAULT_MIN_REGION_COUNT = 3;\n+  static final String MERGE_MIN_REGION_AGE_DAYS_KEY = \"hbase.normalizer.merge.min_region_age.days\";\n+  static final int DEFAULT_MERGE_MIN_REGION_AGE_DAYS = 3;\n+  static final String MERGE_MIN_REGION_SIZE_MB_KEY = \"hbase.normalizer.merge.min_region_size.mb\";\n+  static final int DEFAULT_MERGE_MIN_REGION_SIZE_MB = 1;\n+\n+  private final long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+  private final Comparator<NormalizationPlan> planComparator = new SplitPlanFirstComparator();\n+\n+  private Configuration conf;\n+  private MasterServices masterServices;\n+  private boolean splitEnabled;\n+  private boolean mergeEnabled;\n+  private int minRegionCount;\n+  private Period mergeMinRegionAge;\n+  private int mergeMinRegionSizeMb;\n+\n+  public SimpleRegionNormalizer() {\n+    splitEnabled = DEFAULT_SPLIT_ENABLED;\n+    mergeEnabled = DEFAULT_MERGE_ENABLED;\n+    minRegionCount = DEFAULT_MIN_REGION_COUNT;\n+    mergeMinRegionAge = Period.ofDays(DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    mergeMinRegionSizeMb = DEFAULT_MERGE_MIN_REGION_SIZE_MB;\n+  }\n \n   @Override\n-  public void planSkipped(RegionInfo hri, PlanType type) {\n-    skippedCount[type.ordinal()]++;\n+  public Configuration getConf() {\n+    return conf;\n   }\n \n   @Override\n-  public long getSkippedCount(NormalizationPlan.PlanType type) {\n-    return skippedCount[type.ordinal()];\n+  public void setConf(final Configuration conf) {\n+    if (conf == null) {\n+      return;\n+    }\n+    this.conf = conf;\n+    splitEnabled = conf.getBoolean(SPLIT_ENABLED_KEY, DEFAULT_SPLIT_ENABLED);\n+    mergeEnabled = conf.getBoolean(MERGE_ENABLED_KEY, DEFAULT_MERGE_ENABLED);\n+    minRegionCount = parseMinRegionCount(conf);\n+    mergeMinRegionAge = parseMergeMinRegionAge(conf);\n+    mergeMinRegionSizeMb = parseMergeMinRegionSizeMb(conf);\n+  }\n+\n+  private static int parseMinRegionCount(final Configuration conf) {\n+    final int parsedValue = conf.getInt(MIN_REGION_COUNT_KEY, DEFAULT_MIN_REGION_COUNT);\n+    final int settledValue = Math.max(1, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MIN_REGION_COUNT_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static Period parseMergeMinRegionAge(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_AGE_DAYS_KEY, DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_AGE_DAYS_KEY, parsedValue, settledValue);\n+    }\n+    return Period.ofDays(settledValue);\n+  }\n+\n+  private static int parseMergeMinRegionSizeMb(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_SIZE_MB_KEY, DEFAULT_MERGE_MIN_REGION_SIZE_MB);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_SIZE_MB_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static <T> void warnInvalidValue(final String key, final T parsedValue,\n+    final T settledValue) {\n+    LOG.warn(\"Configured value {}={} is invalid. Setting value to {}.\",\n+      key, parsedValue, settledValue);\n   }\n \n   /**\n-   * Comparator class that gives higher priority to region Split plan.\n+   * Return this instance's configured value for {@value SPLIT_ENABLED_KEY}.\n    */\n-  static class PlanComparator implements Comparator<NormalizationPlan> {\n-    @Override\n-    public int compare(NormalizationPlan plan1, NormalizationPlan plan2) {\n-      boolean plan1IsSplit = plan1 instanceof SplitNormalizationPlan;\n-      boolean plan2IsSplit = plan2 instanceof SplitNormalizationPlan;\n-      if (plan1IsSplit && plan2IsSplit) {\n-        return 0;\n-      } else if (plan1IsSplit) {\n-        return -1;\n-      } else if (plan2IsSplit) {\n-        return 1;\n-      } else {\n-        return 0;\n-      }\n-    }\n+  public boolean isSplitEnabled() {\n+    return splitEnabled;\n   }\n \n-  private Comparator<NormalizationPlan> planComparator = new PlanComparator();\n+  /**\n+   * Return this instance's configured value for {@value MERGE_ENABLED_KEY}.\n+   */\n+  public boolean isMergeEnabled() {\n+    return mergeEnabled;\n+  }\n \n   /**\n-   * Computes next most \"urgent\" normalization action on the table. Action may be either a split, or\n-   * a merge, or no action.\n-   * @param table table to normalize\n-   * @return normalization plan to execute\n+   * Return this instance's configured value for {@value MIN_REGION_COUNT_KEY}.\n+   */\n+  public int getMinRegionCount() {\n+    return minRegionCount;\n+  }\n+\n+  /**\n+   * Return this instance's configured value for {@value MERGE_MIN_REGION_AGE_DAYS_KEY}.\n    */\n+  public Period getMergeMinRegionAge() {\n+    return mergeMinRegionAge;\n+  }\n+\n+  /**\n+   * Return this instance's configured value for {@value MERGE_MIN_REGION_SIZE_MB_KEY}.\n+   */\n+  public int getMergeMinRegionSizeMb() {\n+    return mergeMinRegionSizeMb;\n+  }\n+\n   @Override\n-  public List<NormalizationPlan> computePlanForTable(TableName table) throws HBaseIOException {\n+  public void setMasterServices(final MasterServices masterServices) {\n+    this.masterServices = masterServices;\n+  }\n+\n+  @Override\n+  public void planSkipped(final RegionInfo hri, final PlanType type) {\n+    skippedCount[type.ordinal()]++;\n+  }\n+\n+  @Override\n+  public long getSkippedCount(NormalizationPlan.PlanType type) {\n+    return skippedCount[type.ordinal()];\n+  }\n+\n+  @Override\n+  public List<NormalizationPlan> computePlansForTable(TableName table) {\n     if (table == null || table.isSystemTable()) {\n       LOG.debug(\"Normalization of system table {} isn't allowed\", table);\n-      return null;\n+      return Collections.emptyList();\n     }\n-    boolean splitEnabled = isSplitEnabled();\n-    boolean mergeEnabled = isMergeEnabled();\n+    boolean splitEnabled = isSplitEnabled() && isMasterSwitchEnabled(MasterSwitchType.SPLIT);\n+    boolean mergeEnabled = isMergeEnabled() && isMasterSwitchEnabled(MasterSwitchType.MERGE);\n     if (!mergeEnabled && !splitEnabled) {\n-      LOG.debug(\"Both split and merge are disabled for table: {}\", table);\n-      return null;\n+      LOG.debug(\"Both split and merge are disabled. Skipping normalization of table: {}\", table);\n+      return Collections.emptyList();\n     }\n+\n     List<NormalizationPlan> plans = new ArrayList<>();\n-    List<RegionInfo> tableRegions =\n-        masterServices.getAssignmentManager().getRegionStates().getRegionsOfTable(table);\n+    List<RegionInfo> tableRegions = masterServices.getAssignmentManager()\n+      .getRegionStates()\n+      .getRegionsOfTable(table);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTE3NjQ5Ng=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 273}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQyNDA3Mg==", "bodyText": "Yeah, let me see if i can do something better here. I don't like how accessing these collection objects doesn't align with their use here.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431424072", "createdAt": "2020-05-27T20:31:55Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,436 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>\n+ *   <li>Otherwise, for the next region in the chain R1, if R0 + R1 is smaller then S, R0 and R1\n+ *     are kindly requested to merge.</li>\n+ * </ol>\n+ * <p>\n+ * The following parameters are configurable:\n+ * <ol>\n+ *   <li>Whether to split a region as part of normalization. Configuration:\n+ *     {@value SPLIT_ENABLED_KEY}, default: {@value DEFAULT_SPLIT_ENABLED}.</li>\n+ *   <li>Whether to merge a region as part of normalization. Configuration:\n+ *     {@value MERGE_ENABLED_KEY}, default: {@value DEFAULT_MERGE_ENABLED}.</li>\n+ *   <li>The minimum number of regions in a table to consider it for normalization. Configuration:\n+ *     {@value MIN_REGION_COUNT_KEY}, default: {@value DEFAULT_MIN_REGION_COUNT}.</li>\n+ *   <li>The minimum age for a region to be considered for a merge, in days. Configuration:\n+ *     {@value MERGE_MIN_REGION_AGE_DAYS_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_AGE_DAYS}.</li>\n+ *   <li>The minimum size for a region to be considered for a merge, in whole MBs. Configuration:\n+ *     {@value MERGE_MIN_REGION_SIZE_MB_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_SIZE_MB}.</li>\n  * </ol>\n  * <p>\n- * Region sizes are coarse and approximate on the order of megabytes. Additionally, \"empty\" regions\n- * (less than 1MB, with the previous note) are not merged away. This is by design to prevent\n- * normalization from undoing the pre-splitting of a table.\n+ * To see detailed logging of the application of these configuration values, set the log level for\n+ * this class to `TRACE`.\n  */\n-@InterfaceAudience.Private\n-public class SimpleRegionNormalizer extends AbstractRegionNormalizer {\n-\n+@InterfaceAudience.LimitedPrivate(HBaseInterfaceAudience.CONFIG)\n+public class SimpleRegionNormalizer implements RegionNormalizer {\n   private static final Logger LOG = LoggerFactory.getLogger(SimpleRegionNormalizer.class);\n-  private static long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+\n+  static final String SPLIT_ENABLED_KEY = \"hbase.normalizer.split.enabled\";\n+  static final boolean DEFAULT_SPLIT_ENABLED = true;\n+  static final String MERGE_ENABLED_KEY = \"hbase.normalizer.merge.enabled\";\n+  static final boolean DEFAULT_MERGE_ENABLED = true;\n+  // TODO: after HBASE-24416, `min.region.count` only applies to merge plans; should\n+  //  deprecate/rename the configuration key.\n+  static final String MIN_REGION_COUNT_KEY = \"hbase.normalizer.min.region.count\";\n+  static final int DEFAULT_MIN_REGION_COUNT = 3;\n+  static final String MERGE_MIN_REGION_AGE_DAYS_KEY = \"hbase.normalizer.merge.min_region_age.days\";\n+  static final int DEFAULT_MERGE_MIN_REGION_AGE_DAYS = 3;\n+  static final String MERGE_MIN_REGION_SIZE_MB_KEY = \"hbase.normalizer.merge.min_region_size.mb\";\n+  static final int DEFAULT_MERGE_MIN_REGION_SIZE_MB = 1;\n+\n+  private final long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+  private final Comparator<NormalizationPlan> planComparator = new SplitPlanFirstComparator();\n+\n+  private Configuration conf;\n+  private MasterServices masterServices;\n+  private boolean splitEnabled;\n+  private boolean mergeEnabled;\n+  private int minRegionCount;\n+  private Period mergeMinRegionAge;\n+  private int mergeMinRegionSizeMb;\n+\n+  public SimpleRegionNormalizer() {\n+    splitEnabled = DEFAULT_SPLIT_ENABLED;\n+    mergeEnabled = DEFAULT_MERGE_ENABLED;\n+    minRegionCount = DEFAULT_MIN_REGION_COUNT;\n+    mergeMinRegionAge = Period.ofDays(DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    mergeMinRegionSizeMb = DEFAULT_MERGE_MIN_REGION_SIZE_MB;\n+  }\n \n   @Override\n-  public void planSkipped(RegionInfo hri, PlanType type) {\n-    skippedCount[type.ordinal()]++;\n+  public Configuration getConf() {\n+    return conf;\n   }\n \n   @Override\n-  public long getSkippedCount(NormalizationPlan.PlanType type) {\n-    return skippedCount[type.ordinal()];\n+  public void setConf(final Configuration conf) {\n+    if (conf == null) {\n+      return;\n+    }\n+    this.conf = conf;\n+    splitEnabled = conf.getBoolean(SPLIT_ENABLED_KEY, DEFAULT_SPLIT_ENABLED);\n+    mergeEnabled = conf.getBoolean(MERGE_ENABLED_KEY, DEFAULT_MERGE_ENABLED);\n+    minRegionCount = parseMinRegionCount(conf);\n+    mergeMinRegionAge = parseMergeMinRegionAge(conf);\n+    mergeMinRegionSizeMb = parseMergeMinRegionSizeMb(conf);\n+  }\n+\n+  private static int parseMinRegionCount(final Configuration conf) {\n+    final int parsedValue = conf.getInt(MIN_REGION_COUNT_KEY, DEFAULT_MIN_REGION_COUNT);\n+    final int settledValue = Math.max(1, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MIN_REGION_COUNT_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static Period parseMergeMinRegionAge(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_AGE_DAYS_KEY, DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_AGE_DAYS_KEY, parsedValue, settledValue);\n+    }\n+    return Period.ofDays(settledValue);\n+  }\n+\n+  private static int parseMergeMinRegionSizeMb(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_SIZE_MB_KEY, DEFAULT_MERGE_MIN_REGION_SIZE_MB);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_SIZE_MB_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static <T> void warnInvalidValue(final String key, final T parsedValue,\n+    final T settledValue) {\n+    LOG.warn(\"Configured value {}={} is invalid. Setting value to {}.\",\n+      key, parsedValue, settledValue);\n   }\n \n   /**\n-   * Comparator class that gives higher priority to region Split plan.\n+   * Return this instance's configured value for {@value SPLIT_ENABLED_KEY}.\n    */\n-  static class PlanComparator implements Comparator<NormalizationPlan> {\n-    @Override\n-    public int compare(NormalizationPlan plan1, NormalizationPlan plan2) {\n-      boolean plan1IsSplit = plan1 instanceof SplitNormalizationPlan;\n-      boolean plan2IsSplit = plan2 instanceof SplitNormalizationPlan;\n-      if (plan1IsSplit && plan2IsSplit) {\n-        return 0;\n-      } else if (plan1IsSplit) {\n-        return -1;\n-      } else if (plan2IsSplit) {\n-        return 1;\n-      } else {\n-        return 0;\n-      }\n-    }\n+  public boolean isSplitEnabled() {\n+    return splitEnabled;\n   }\n \n-  private Comparator<NormalizationPlan> planComparator = new PlanComparator();\n+  /**\n+   * Return this instance's configured value for {@value MERGE_ENABLED_KEY}.\n+   */\n+  public boolean isMergeEnabled() {\n+    return mergeEnabled;\n+  }\n \n   /**\n-   * Computes next most \"urgent\" normalization action on the table. Action may be either a split, or\n-   * a merge, or no action.\n-   * @param table table to normalize\n-   * @return normalization plan to execute\n+   * Return this instance's configured value for {@value MIN_REGION_COUNT_KEY}.\n+   */\n+  public int getMinRegionCount() {\n+    return minRegionCount;\n+  }\n+\n+  /**\n+   * Return this instance's configured value for {@value MERGE_MIN_REGION_AGE_DAYS_KEY}.\n    */\n+  public Period getMergeMinRegionAge() {\n+    return mergeMinRegionAge;\n+  }\n+\n+  /**\n+   * Return this instance's configured value for {@value MERGE_MIN_REGION_SIZE_MB_KEY}.\n+   */\n+  public int getMergeMinRegionSizeMb() {\n+    return mergeMinRegionSizeMb;\n+  }\n+\n   @Override\n-  public List<NormalizationPlan> computePlanForTable(TableName table) throws HBaseIOException {\n+  public void setMasterServices(final MasterServices masterServices) {\n+    this.masterServices = masterServices;\n+  }\n+\n+  @Override\n+  public void planSkipped(final RegionInfo hri, final PlanType type) {\n+    skippedCount[type.ordinal()]++;\n+  }\n+\n+  @Override\n+  public long getSkippedCount(NormalizationPlan.PlanType type) {\n+    return skippedCount[type.ordinal()];\n+  }\n+\n+  @Override\n+  public List<NormalizationPlan> computePlansForTable(TableName table) {\n     if (table == null || table.isSystemTable()) {\n       LOG.debug(\"Normalization of system table {} isn't allowed\", table);\n-      return null;\n+      return Collections.emptyList();\n     }\n-    boolean splitEnabled = isSplitEnabled();\n-    boolean mergeEnabled = isMergeEnabled();\n+    boolean splitEnabled = isSplitEnabled() && isMasterSwitchEnabled(MasterSwitchType.SPLIT);\n+    boolean mergeEnabled = isMergeEnabled() && isMasterSwitchEnabled(MasterSwitchType.MERGE);\n     if (!mergeEnabled && !splitEnabled) {\n-      LOG.debug(\"Both split and merge are disabled for table: {}\", table);\n-      return null;\n+      LOG.debug(\"Both split and merge are disabled. Skipping normalization of table: {}\", table);\n+      return Collections.emptyList();\n     }\n+\n     List<NormalizationPlan> plans = new ArrayList<>();\n-    List<RegionInfo> tableRegions =\n-        masterServices.getAssignmentManager().getRegionStates().getRegionsOfTable(table);\n+    List<RegionInfo> tableRegions = masterServices.getAssignmentManager()\n+      .getRegionStates()\n+      .getRegionsOfTable(table);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTE3NjQ5Ng=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 273}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjEzNDQ4Nw==", "bodyText": "This is all too messy for my liking. These computeSplitNormalizationPlans and computeMergeNormalizationPlans share a bunch of data in common, and both go rummaging around in the AM independently. TableName, Region list, RegionStates, computed average size, it could all be reused...", "url": "https://github.com/apache/hbase/pull/1786#discussion_r432134487", "createdAt": "2020-05-28T21:28:48Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,436 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>\n+ *   <li>Otherwise, for the next region in the chain R1, if R0 + R1 is smaller then S, R0 and R1\n+ *     are kindly requested to merge.</li>\n+ * </ol>\n+ * <p>\n+ * The following parameters are configurable:\n+ * <ol>\n+ *   <li>Whether to split a region as part of normalization. Configuration:\n+ *     {@value SPLIT_ENABLED_KEY}, default: {@value DEFAULT_SPLIT_ENABLED}.</li>\n+ *   <li>Whether to merge a region as part of normalization. Configuration:\n+ *     {@value MERGE_ENABLED_KEY}, default: {@value DEFAULT_MERGE_ENABLED}.</li>\n+ *   <li>The minimum number of regions in a table to consider it for normalization. Configuration:\n+ *     {@value MIN_REGION_COUNT_KEY}, default: {@value DEFAULT_MIN_REGION_COUNT}.</li>\n+ *   <li>The minimum age for a region to be considered for a merge, in days. Configuration:\n+ *     {@value MERGE_MIN_REGION_AGE_DAYS_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_AGE_DAYS}.</li>\n+ *   <li>The minimum size for a region to be considered for a merge, in whole MBs. Configuration:\n+ *     {@value MERGE_MIN_REGION_SIZE_MB_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_SIZE_MB}.</li>\n  * </ol>\n  * <p>\n- * Region sizes are coarse and approximate on the order of megabytes. Additionally, \"empty\" regions\n- * (less than 1MB, with the previous note) are not merged away. This is by design to prevent\n- * normalization from undoing the pre-splitting of a table.\n+ * To see detailed logging of the application of these configuration values, set the log level for\n+ * this class to `TRACE`.\n  */\n-@InterfaceAudience.Private\n-public class SimpleRegionNormalizer extends AbstractRegionNormalizer {\n-\n+@InterfaceAudience.LimitedPrivate(HBaseInterfaceAudience.CONFIG)\n+public class SimpleRegionNormalizer implements RegionNormalizer {\n   private static final Logger LOG = LoggerFactory.getLogger(SimpleRegionNormalizer.class);\n-  private static long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+\n+  static final String SPLIT_ENABLED_KEY = \"hbase.normalizer.split.enabled\";\n+  static final boolean DEFAULT_SPLIT_ENABLED = true;\n+  static final String MERGE_ENABLED_KEY = \"hbase.normalizer.merge.enabled\";\n+  static final boolean DEFAULT_MERGE_ENABLED = true;\n+  // TODO: after HBASE-24416, `min.region.count` only applies to merge plans; should\n+  //  deprecate/rename the configuration key.\n+  static final String MIN_REGION_COUNT_KEY = \"hbase.normalizer.min.region.count\";\n+  static final int DEFAULT_MIN_REGION_COUNT = 3;\n+  static final String MERGE_MIN_REGION_AGE_DAYS_KEY = \"hbase.normalizer.merge.min_region_age.days\";\n+  static final int DEFAULT_MERGE_MIN_REGION_AGE_DAYS = 3;\n+  static final String MERGE_MIN_REGION_SIZE_MB_KEY = \"hbase.normalizer.merge.min_region_size.mb\";\n+  static final int DEFAULT_MERGE_MIN_REGION_SIZE_MB = 1;\n+\n+  private final long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+  private final Comparator<NormalizationPlan> planComparator = new SplitPlanFirstComparator();\n+\n+  private Configuration conf;\n+  private MasterServices masterServices;\n+  private boolean splitEnabled;\n+  private boolean mergeEnabled;\n+  private int minRegionCount;\n+  private Period mergeMinRegionAge;\n+  private int mergeMinRegionSizeMb;\n+\n+  public SimpleRegionNormalizer() {\n+    splitEnabled = DEFAULT_SPLIT_ENABLED;\n+    mergeEnabled = DEFAULT_MERGE_ENABLED;\n+    minRegionCount = DEFAULT_MIN_REGION_COUNT;\n+    mergeMinRegionAge = Period.ofDays(DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    mergeMinRegionSizeMb = DEFAULT_MERGE_MIN_REGION_SIZE_MB;\n+  }\n \n   @Override\n-  public void planSkipped(RegionInfo hri, PlanType type) {\n-    skippedCount[type.ordinal()]++;\n+  public Configuration getConf() {\n+    return conf;\n   }\n \n   @Override\n-  public long getSkippedCount(NormalizationPlan.PlanType type) {\n-    return skippedCount[type.ordinal()];\n+  public void setConf(final Configuration conf) {\n+    if (conf == null) {\n+      return;\n+    }\n+    this.conf = conf;\n+    splitEnabled = conf.getBoolean(SPLIT_ENABLED_KEY, DEFAULT_SPLIT_ENABLED);\n+    mergeEnabled = conf.getBoolean(MERGE_ENABLED_KEY, DEFAULT_MERGE_ENABLED);\n+    minRegionCount = parseMinRegionCount(conf);\n+    mergeMinRegionAge = parseMergeMinRegionAge(conf);\n+    mergeMinRegionSizeMb = parseMergeMinRegionSizeMb(conf);\n+  }\n+\n+  private static int parseMinRegionCount(final Configuration conf) {\n+    final int parsedValue = conf.getInt(MIN_REGION_COUNT_KEY, DEFAULT_MIN_REGION_COUNT);\n+    final int settledValue = Math.max(1, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MIN_REGION_COUNT_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static Period parseMergeMinRegionAge(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_AGE_DAYS_KEY, DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_AGE_DAYS_KEY, parsedValue, settledValue);\n+    }\n+    return Period.ofDays(settledValue);\n+  }\n+\n+  private static int parseMergeMinRegionSizeMb(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_SIZE_MB_KEY, DEFAULT_MERGE_MIN_REGION_SIZE_MB);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_SIZE_MB_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static <T> void warnInvalidValue(final String key, final T parsedValue,\n+    final T settledValue) {\n+    LOG.warn(\"Configured value {}={} is invalid. Setting value to {}.\",\n+      key, parsedValue, settledValue);\n   }\n \n   /**\n-   * Comparator class that gives higher priority to region Split plan.\n+   * Return this instance's configured value for {@value SPLIT_ENABLED_KEY}.\n    */\n-  static class PlanComparator implements Comparator<NormalizationPlan> {\n-    @Override\n-    public int compare(NormalizationPlan plan1, NormalizationPlan plan2) {\n-      boolean plan1IsSplit = plan1 instanceof SplitNormalizationPlan;\n-      boolean plan2IsSplit = plan2 instanceof SplitNormalizationPlan;\n-      if (plan1IsSplit && plan2IsSplit) {\n-        return 0;\n-      } else if (plan1IsSplit) {\n-        return -1;\n-      } else if (plan2IsSplit) {\n-        return 1;\n-      } else {\n-        return 0;\n-      }\n-    }\n+  public boolean isSplitEnabled() {\n+    return splitEnabled;\n   }\n \n-  private Comparator<NormalizationPlan> planComparator = new PlanComparator();\n+  /**\n+   * Return this instance's configured value for {@value MERGE_ENABLED_KEY}.\n+   */\n+  public boolean isMergeEnabled() {\n+    return mergeEnabled;\n+  }\n \n   /**\n-   * Computes next most \"urgent\" normalization action on the table. Action may be either a split, or\n-   * a merge, or no action.\n-   * @param table table to normalize\n-   * @return normalization plan to execute\n+   * Return this instance's configured value for {@value MIN_REGION_COUNT_KEY}.\n+   */\n+  public int getMinRegionCount() {\n+    return minRegionCount;\n+  }\n+\n+  /**\n+   * Return this instance's configured value for {@value MERGE_MIN_REGION_AGE_DAYS_KEY}.\n    */\n+  public Period getMergeMinRegionAge() {\n+    return mergeMinRegionAge;\n+  }\n+\n+  /**\n+   * Return this instance's configured value for {@value MERGE_MIN_REGION_SIZE_MB_KEY}.\n+   */\n+  public int getMergeMinRegionSizeMb() {\n+    return mergeMinRegionSizeMb;\n+  }\n+\n   @Override\n-  public List<NormalizationPlan> computePlanForTable(TableName table) throws HBaseIOException {\n+  public void setMasterServices(final MasterServices masterServices) {\n+    this.masterServices = masterServices;\n+  }\n+\n+  @Override\n+  public void planSkipped(final RegionInfo hri, final PlanType type) {\n+    skippedCount[type.ordinal()]++;\n+  }\n+\n+  @Override\n+  public long getSkippedCount(NormalizationPlan.PlanType type) {\n+    return skippedCount[type.ordinal()];\n+  }\n+\n+  @Override\n+  public List<NormalizationPlan> computePlansForTable(TableName table) {\n     if (table == null || table.isSystemTable()) {\n       LOG.debug(\"Normalization of system table {} isn't allowed\", table);\n-      return null;\n+      return Collections.emptyList();\n     }\n-    boolean splitEnabled = isSplitEnabled();\n-    boolean mergeEnabled = isMergeEnabled();\n+    boolean splitEnabled = isSplitEnabled() && isMasterSwitchEnabled(MasterSwitchType.SPLIT);\n+    boolean mergeEnabled = isMergeEnabled() && isMasterSwitchEnabled(MasterSwitchType.MERGE);\n     if (!mergeEnabled && !splitEnabled) {\n-      LOG.debug(\"Both split and merge are disabled for table: {}\", table);\n-      return null;\n+      LOG.debug(\"Both split and merge are disabled. Skipping normalization of table: {}\", table);\n+      return Collections.emptyList();\n     }\n+\n     List<NormalizationPlan> plans = new ArrayList<>();\n-    List<RegionInfo> tableRegions =\n-        masterServices.getAssignmentManager().getRegionStates().getRegionsOfTable(table);\n+    List<RegionInfo> tableRegions = masterServices.getAssignmentManager()\n+      .getRegionStates()\n+      .getRegionsOfTable(table);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTE3NjQ5Ng=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 273}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE0ODY0NA==", "bodyText": "How much do you guys care about this? The best solution i have right now is an inner class that does the lookups once, and holds state across methods.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r432148644", "createdAt": "2020-05-28T22:01:07Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,436 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>\n+ *   <li>Otherwise, for the next region in the chain R1, if R0 + R1 is smaller then S, R0 and R1\n+ *     are kindly requested to merge.</li>\n+ * </ol>\n+ * <p>\n+ * The following parameters are configurable:\n+ * <ol>\n+ *   <li>Whether to split a region as part of normalization. Configuration:\n+ *     {@value SPLIT_ENABLED_KEY}, default: {@value DEFAULT_SPLIT_ENABLED}.</li>\n+ *   <li>Whether to merge a region as part of normalization. Configuration:\n+ *     {@value MERGE_ENABLED_KEY}, default: {@value DEFAULT_MERGE_ENABLED}.</li>\n+ *   <li>The minimum number of regions in a table to consider it for normalization. Configuration:\n+ *     {@value MIN_REGION_COUNT_KEY}, default: {@value DEFAULT_MIN_REGION_COUNT}.</li>\n+ *   <li>The minimum age for a region to be considered for a merge, in days. Configuration:\n+ *     {@value MERGE_MIN_REGION_AGE_DAYS_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_AGE_DAYS}.</li>\n+ *   <li>The minimum size for a region to be considered for a merge, in whole MBs. Configuration:\n+ *     {@value MERGE_MIN_REGION_SIZE_MB_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_SIZE_MB}.</li>\n  * </ol>\n  * <p>\n- * Region sizes are coarse and approximate on the order of megabytes. Additionally, \"empty\" regions\n- * (less than 1MB, with the previous note) are not merged away. This is by design to prevent\n- * normalization from undoing the pre-splitting of a table.\n+ * To see detailed logging of the application of these configuration values, set the log level for\n+ * this class to `TRACE`.\n  */\n-@InterfaceAudience.Private\n-public class SimpleRegionNormalizer extends AbstractRegionNormalizer {\n-\n+@InterfaceAudience.LimitedPrivate(HBaseInterfaceAudience.CONFIG)\n+public class SimpleRegionNormalizer implements RegionNormalizer {\n   private static final Logger LOG = LoggerFactory.getLogger(SimpleRegionNormalizer.class);\n-  private static long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+\n+  static final String SPLIT_ENABLED_KEY = \"hbase.normalizer.split.enabled\";\n+  static final boolean DEFAULT_SPLIT_ENABLED = true;\n+  static final String MERGE_ENABLED_KEY = \"hbase.normalizer.merge.enabled\";\n+  static final boolean DEFAULT_MERGE_ENABLED = true;\n+  // TODO: after HBASE-24416, `min.region.count` only applies to merge plans; should\n+  //  deprecate/rename the configuration key.\n+  static final String MIN_REGION_COUNT_KEY = \"hbase.normalizer.min.region.count\";\n+  static final int DEFAULT_MIN_REGION_COUNT = 3;\n+  static final String MERGE_MIN_REGION_AGE_DAYS_KEY = \"hbase.normalizer.merge.min_region_age.days\";\n+  static final int DEFAULT_MERGE_MIN_REGION_AGE_DAYS = 3;\n+  static final String MERGE_MIN_REGION_SIZE_MB_KEY = \"hbase.normalizer.merge.min_region_size.mb\";\n+  static final int DEFAULT_MERGE_MIN_REGION_SIZE_MB = 1;\n+\n+  private final long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+  private final Comparator<NormalizationPlan> planComparator = new SplitPlanFirstComparator();\n+\n+  private Configuration conf;\n+  private MasterServices masterServices;\n+  private boolean splitEnabled;\n+  private boolean mergeEnabled;\n+  private int minRegionCount;\n+  private Period mergeMinRegionAge;\n+  private int mergeMinRegionSizeMb;\n+\n+  public SimpleRegionNormalizer() {\n+    splitEnabled = DEFAULT_SPLIT_ENABLED;\n+    mergeEnabled = DEFAULT_MERGE_ENABLED;\n+    minRegionCount = DEFAULT_MIN_REGION_COUNT;\n+    mergeMinRegionAge = Period.ofDays(DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    mergeMinRegionSizeMb = DEFAULT_MERGE_MIN_REGION_SIZE_MB;\n+  }\n \n   @Override\n-  public void planSkipped(RegionInfo hri, PlanType type) {\n-    skippedCount[type.ordinal()]++;\n+  public Configuration getConf() {\n+    return conf;\n   }\n \n   @Override\n-  public long getSkippedCount(NormalizationPlan.PlanType type) {\n-    return skippedCount[type.ordinal()];\n+  public void setConf(final Configuration conf) {\n+    if (conf == null) {\n+      return;\n+    }\n+    this.conf = conf;\n+    splitEnabled = conf.getBoolean(SPLIT_ENABLED_KEY, DEFAULT_SPLIT_ENABLED);\n+    mergeEnabled = conf.getBoolean(MERGE_ENABLED_KEY, DEFAULT_MERGE_ENABLED);\n+    minRegionCount = parseMinRegionCount(conf);\n+    mergeMinRegionAge = parseMergeMinRegionAge(conf);\n+    mergeMinRegionSizeMb = parseMergeMinRegionSizeMb(conf);\n+  }\n+\n+  private static int parseMinRegionCount(final Configuration conf) {\n+    final int parsedValue = conf.getInt(MIN_REGION_COUNT_KEY, DEFAULT_MIN_REGION_COUNT);\n+    final int settledValue = Math.max(1, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MIN_REGION_COUNT_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static Period parseMergeMinRegionAge(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_AGE_DAYS_KEY, DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_AGE_DAYS_KEY, parsedValue, settledValue);\n+    }\n+    return Period.ofDays(settledValue);\n+  }\n+\n+  private static int parseMergeMinRegionSizeMb(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_SIZE_MB_KEY, DEFAULT_MERGE_MIN_REGION_SIZE_MB);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_SIZE_MB_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static <T> void warnInvalidValue(final String key, final T parsedValue,\n+    final T settledValue) {\n+    LOG.warn(\"Configured value {}={} is invalid. Setting value to {}.\",\n+      key, parsedValue, settledValue);\n   }\n \n   /**\n-   * Comparator class that gives higher priority to region Split plan.\n+   * Return this instance's configured value for {@value SPLIT_ENABLED_KEY}.\n    */\n-  static class PlanComparator implements Comparator<NormalizationPlan> {\n-    @Override\n-    public int compare(NormalizationPlan plan1, NormalizationPlan plan2) {\n-      boolean plan1IsSplit = plan1 instanceof SplitNormalizationPlan;\n-      boolean plan2IsSplit = plan2 instanceof SplitNormalizationPlan;\n-      if (plan1IsSplit && plan2IsSplit) {\n-        return 0;\n-      } else if (plan1IsSplit) {\n-        return -1;\n-      } else if (plan2IsSplit) {\n-        return 1;\n-      } else {\n-        return 0;\n-      }\n-    }\n+  public boolean isSplitEnabled() {\n+    return splitEnabled;\n   }\n \n-  private Comparator<NormalizationPlan> planComparator = new PlanComparator();\n+  /**\n+   * Return this instance's configured value for {@value MERGE_ENABLED_KEY}.\n+   */\n+  public boolean isMergeEnabled() {\n+    return mergeEnabled;\n+  }\n \n   /**\n-   * Computes next most \"urgent\" normalization action on the table. Action may be either a split, or\n-   * a merge, or no action.\n-   * @param table table to normalize\n-   * @return normalization plan to execute\n+   * Return this instance's configured value for {@value MIN_REGION_COUNT_KEY}.\n+   */\n+  public int getMinRegionCount() {\n+    return minRegionCount;\n+  }\n+\n+  /**\n+   * Return this instance's configured value for {@value MERGE_MIN_REGION_AGE_DAYS_KEY}.\n    */\n+  public Period getMergeMinRegionAge() {\n+    return mergeMinRegionAge;\n+  }\n+\n+  /**\n+   * Return this instance's configured value for {@value MERGE_MIN_REGION_SIZE_MB_KEY}.\n+   */\n+  public int getMergeMinRegionSizeMb() {\n+    return mergeMinRegionSizeMb;\n+  }\n+\n   @Override\n-  public List<NormalizationPlan> computePlanForTable(TableName table) throws HBaseIOException {\n+  public void setMasterServices(final MasterServices masterServices) {\n+    this.masterServices = masterServices;\n+  }\n+\n+  @Override\n+  public void planSkipped(final RegionInfo hri, final PlanType type) {\n+    skippedCount[type.ordinal()]++;\n+  }\n+\n+  @Override\n+  public long getSkippedCount(NormalizationPlan.PlanType type) {\n+    return skippedCount[type.ordinal()];\n+  }\n+\n+  @Override\n+  public List<NormalizationPlan> computePlansForTable(TableName table) {\n     if (table == null || table.isSystemTable()) {\n       LOG.debug(\"Normalization of system table {} isn't allowed\", table);\n-      return null;\n+      return Collections.emptyList();\n     }\n-    boolean splitEnabled = isSplitEnabled();\n-    boolean mergeEnabled = isMergeEnabled();\n+    boolean splitEnabled = isSplitEnabled() && isMasterSwitchEnabled(MasterSwitchType.SPLIT);\n+    boolean mergeEnabled = isMergeEnabled() && isMasterSwitchEnabled(MasterSwitchType.MERGE);\n     if (!mergeEnabled && !splitEnabled) {\n-      LOG.debug(\"Both split and merge are disabled for table: {}\", table);\n-      return null;\n+      LOG.debug(\"Both split and merge are disabled. Skipping normalization of table: {}\", table);\n+      return Collections.emptyList();\n     }\n+\n     List<NormalizationPlan> plans = new ArrayList<>();\n-    List<RegionInfo> tableRegions =\n-        masterServices.getAssignmentManager().getRegionStates().getRegionsOfTable(table);\n+    List<RegionInfo> tableRegions = masterServices.getAssignmentManager()\n+      .getRegionStates()\n+      .getRegionsOfTable(table);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTE3NjQ5Ng=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 273}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE2ODUxMw==", "bodyText": "The inner class ends up being awkward too. Let me address the other feedback and return to this one.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r432168513", "createdAt": "2020-05-28T22:56:59Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,436 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>\n+ *   <li>Otherwise, for the next region in the chain R1, if R0 + R1 is smaller then S, R0 and R1\n+ *     are kindly requested to merge.</li>\n+ * </ol>\n+ * <p>\n+ * The following parameters are configurable:\n+ * <ol>\n+ *   <li>Whether to split a region as part of normalization. Configuration:\n+ *     {@value SPLIT_ENABLED_KEY}, default: {@value DEFAULT_SPLIT_ENABLED}.</li>\n+ *   <li>Whether to merge a region as part of normalization. Configuration:\n+ *     {@value MERGE_ENABLED_KEY}, default: {@value DEFAULT_MERGE_ENABLED}.</li>\n+ *   <li>The minimum number of regions in a table to consider it for normalization. Configuration:\n+ *     {@value MIN_REGION_COUNT_KEY}, default: {@value DEFAULT_MIN_REGION_COUNT}.</li>\n+ *   <li>The minimum age for a region to be considered for a merge, in days. Configuration:\n+ *     {@value MERGE_MIN_REGION_AGE_DAYS_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_AGE_DAYS}.</li>\n+ *   <li>The minimum size for a region to be considered for a merge, in whole MBs. Configuration:\n+ *     {@value MERGE_MIN_REGION_SIZE_MB_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_SIZE_MB}.</li>\n  * </ol>\n  * <p>\n- * Region sizes are coarse and approximate on the order of megabytes. Additionally, \"empty\" regions\n- * (less than 1MB, with the previous note) are not merged away. This is by design to prevent\n- * normalization from undoing the pre-splitting of a table.\n+ * To see detailed logging of the application of these configuration values, set the log level for\n+ * this class to `TRACE`.\n  */\n-@InterfaceAudience.Private\n-public class SimpleRegionNormalizer extends AbstractRegionNormalizer {\n-\n+@InterfaceAudience.LimitedPrivate(HBaseInterfaceAudience.CONFIG)\n+public class SimpleRegionNormalizer implements RegionNormalizer {\n   private static final Logger LOG = LoggerFactory.getLogger(SimpleRegionNormalizer.class);\n-  private static long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+\n+  static final String SPLIT_ENABLED_KEY = \"hbase.normalizer.split.enabled\";\n+  static final boolean DEFAULT_SPLIT_ENABLED = true;\n+  static final String MERGE_ENABLED_KEY = \"hbase.normalizer.merge.enabled\";\n+  static final boolean DEFAULT_MERGE_ENABLED = true;\n+  // TODO: after HBASE-24416, `min.region.count` only applies to merge plans; should\n+  //  deprecate/rename the configuration key.\n+  static final String MIN_REGION_COUNT_KEY = \"hbase.normalizer.min.region.count\";\n+  static final int DEFAULT_MIN_REGION_COUNT = 3;\n+  static final String MERGE_MIN_REGION_AGE_DAYS_KEY = \"hbase.normalizer.merge.min_region_age.days\";\n+  static final int DEFAULT_MERGE_MIN_REGION_AGE_DAYS = 3;\n+  static final String MERGE_MIN_REGION_SIZE_MB_KEY = \"hbase.normalizer.merge.min_region_size.mb\";\n+  static final int DEFAULT_MERGE_MIN_REGION_SIZE_MB = 1;\n+\n+  private final long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+  private final Comparator<NormalizationPlan> planComparator = new SplitPlanFirstComparator();\n+\n+  private Configuration conf;\n+  private MasterServices masterServices;\n+  private boolean splitEnabled;\n+  private boolean mergeEnabled;\n+  private int minRegionCount;\n+  private Period mergeMinRegionAge;\n+  private int mergeMinRegionSizeMb;\n+\n+  public SimpleRegionNormalizer() {\n+    splitEnabled = DEFAULT_SPLIT_ENABLED;\n+    mergeEnabled = DEFAULT_MERGE_ENABLED;\n+    minRegionCount = DEFAULT_MIN_REGION_COUNT;\n+    mergeMinRegionAge = Period.ofDays(DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    mergeMinRegionSizeMb = DEFAULT_MERGE_MIN_REGION_SIZE_MB;\n+  }\n \n   @Override\n-  public void planSkipped(RegionInfo hri, PlanType type) {\n-    skippedCount[type.ordinal()]++;\n+  public Configuration getConf() {\n+    return conf;\n   }\n \n   @Override\n-  public long getSkippedCount(NormalizationPlan.PlanType type) {\n-    return skippedCount[type.ordinal()];\n+  public void setConf(final Configuration conf) {\n+    if (conf == null) {\n+      return;\n+    }\n+    this.conf = conf;\n+    splitEnabled = conf.getBoolean(SPLIT_ENABLED_KEY, DEFAULT_SPLIT_ENABLED);\n+    mergeEnabled = conf.getBoolean(MERGE_ENABLED_KEY, DEFAULT_MERGE_ENABLED);\n+    minRegionCount = parseMinRegionCount(conf);\n+    mergeMinRegionAge = parseMergeMinRegionAge(conf);\n+    mergeMinRegionSizeMb = parseMergeMinRegionSizeMb(conf);\n+  }\n+\n+  private static int parseMinRegionCount(final Configuration conf) {\n+    final int parsedValue = conf.getInt(MIN_REGION_COUNT_KEY, DEFAULT_MIN_REGION_COUNT);\n+    final int settledValue = Math.max(1, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MIN_REGION_COUNT_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static Period parseMergeMinRegionAge(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_AGE_DAYS_KEY, DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_AGE_DAYS_KEY, parsedValue, settledValue);\n+    }\n+    return Period.ofDays(settledValue);\n+  }\n+\n+  private static int parseMergeMinRegionSizeMb(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_SIZE_MB_KEY, DEFAULT_MERGE_MIN_REGION_SIZE_MB);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_SIZE_MB_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static <T> void warnInvalidValue(final String key, final T parsedValue,\n+    final T settledValue) {\n+    LOG.warn(\"Configured value {}={} is invalid. Setting value to {}.\",\n+      key, parsedValue, settledValue);\n   }\n \n   /**\n-   * Comparator class that gives higher priority to region Split plan.\n+   * Return this instance's configured value for {@value SPLIT_ENABLED_KEY}.\n    */\n-  static class PlanComparator implements Comparator<NormalizationPlan> {\n-    @Override\n-    public int compare(NormalizationPlan plan1, NormalizationPlan plan2) {\n-      boolean plan1IsSplit = plan1 instanceof SplitNormalizationPlan;\n-      boolean plan2IsSplit = plan2 instanceof SplitNormalizationPlan;\n-      if (plan1IsSplit && plan2IsSplit) {\n-        return 0;\n-      } else if (plan1IsSplit) {\n-        return -1;\n-      } else if (plan2IsSplit) {\n-        return 1;\n-      } else {\n-        return 0;\n-      }\n-    }\n+  public boolean isSplitEnabled() {\n+    return splitEnabled;\n   }\n \n-  private Comparator<NormalizationPlan> planComparator = new PlanComparator();\n+  /**\n+   * Return this instance's configured value for {@value MERGE_ENABLED_KEY}.\n+   */\n+  public boolean isMergeEnabled() {\n+    return mergeEnabled;\n+  }\n \n   /**\n-   * Computes next most \"urgent\" normalization action on the table. Action may be either a split, or\n-   * a merge, or no action.\n-   * @param table table to normalize\n-   * @return normalization plan to execute\n+   * Return this instance's configured value for {@value MIN_REGION_COUNT_KEY}.\n+   */\n+  public int getMinRegionCount() {\n+    return minRegionCount;\n+  }\n+\n+  /**\n+   * Return this instance's configured value for {@value MERGE_MIN_REGION_AGE_DAYS_KEY}.\n    */\n+  public Period getMergeMinRegionAge() {\n+    return mergeMinRegionAge;\n+  }\n+\n+  /**\n+   * Return this instance's configured value for {@value MERGE_MIN_REGION_SIZE_MB_KEY}.\n+   */\n+  public int getMergeMinRegionSizeMb() {\n+    return mergeMinRegionSizeMb;\n+  }\n+\n   @Override\n-  public List<NormalizationPlan> computePlanForTable(TableName table) throws HBaseIOException {\n+  public void setMasterServices(final MasterServices masterServices) {\n+    this.masterServices = masterServices;\n+  }\n+\n+  @Override\n+  public void planSkipped(final RegionInfo hri, final PlanType type) {\n+    skippedCount[type.ordinal()]++;\n+  }\n+\n+  @Override\n+  public long getSkippedCount(NormalizationPlan.PlanType type) {\n+    return skippedCount[type.ordinal()];\n+  }\n+\n+  @Override\n+  public List<NormalizationPlan> computePlansForTable(TableName table) {\n     if (table == null || table.isSystemTable()) {\n       LOG.debug(\"Normalization of system table {} isn't allowed\", table);\n-      return null;\n+      return Collections.emptyList();\n     }\n-    boolean splitEnabled = isSplitEnabled();\n-    boolean mergeEnabled = isMergeEnabled();\n+    boolean splitEnabled = isSplitEnabled() && isMasterSwitchEnabled(MasterSwitchType.SPLIT);\n+    boolean mergeEnabled = isMergeEnabled() && isMasterSwitchEnabled(MasterSwitchType.MERGE);\n     if (!mergeEnabled && !splitEnabled) {\n-      LOG.debug(\"Both split and merge are disabled for table: {}\", table);\n-      return null;\n+      LOG.debug(\"Both split and merge are disabled. Skipping normalization of table: {}\", table);\n+      return Collections.emptyList();\n     }\n+\n     List<NormalizationPlan> plans = new ArrayList<>();\n-    List<RegionInfo> tableRegions =\n-        masterServices.getAssignmentManager().getRegionStates().getRegionsOfTable(table);\n+    List<RegionInfo> tableRegions = masterServices.getAssignmentManager()\n+      .getRegionStates()\n+      .getRegionsOfTable(table);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTE3NjQ5Ng=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 273}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzUyMzQ2NA==", "bodyText": "I've pulled out the common state into an inner class; it's not so bad after all. PTAL.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r433523464", "createdAt": "2020-06-01T22:29:19Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,436 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>\n+ *   <li>Otherwise, for the next region in the chain R1, if R0 + R1 is smaller then S, R0 and R1\n+ *     are kindly requested to merge.</li>\n+ * </ol>\n+ * <p>\n+ * The following parameters are configurable:\n+ * <ol>\n+ *   <li>Whether to split a region as part of normalization. Configuration:\n+ *     {@value SPLIT_ENABLED_KEY}, default: {@value DEFAULT_SPLIT_ENABLED}.</li>\n+ *   <li>Whether to merge a region as part of normalization. Configuration:\n+ *     {@value MERGE_ENABLED_KEY}, default: {@value DEFAULT_MERGE_ENABLED}.</li>\n+ *   <li>The minimum number of regions in a table to consider it for normalization. Configuration:\n+ *     {@value MIN_REGION_COUNT_KEY}, default: {@value DEFAULT_MIN_REGION_COUNT}.</li>\n+ *   <li>The minimum age for a region to be considered for a merge, in days. Configuration:\n+ *     {@value MERGE_MIN_REGION_AGE_DAYS_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_AGE_DAYS}.</li>\n+ *   <li>The minimum size for a region to be considered for a merge, in whole MBs. Configuration:\n+ *     {@value MERGE_MIN_REGION_SIZE_MB_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_SIZE_MB}.</li>\n  * </ol>\n  * <p>\n- * Region sizes are coarse and approximate on the order of megabytes. Additionally, \"empty\" regions\n- * (less than 1MB, with the previous note) are not merged away. This is by design to prevent\n- * normalization from undoing the pre-splitting of a table.\n+ * To see detailed logging of the application of these configuration values, set the log level for\n+ * this class to `TRACE`.\n  */\n-@InterfaceAudience.Private\n-public class SimpleRegionNormalizer extends AbstractRegionNormalizer {\n-\n+@InterfaceAudience.LimitedPrivate(HBaseInterfaceAudience.CONFIG)\n+public class SimpleRegionNormalizer implements RegionNormalizer {\n   private static final Logger LOG = LoggerFactory.getLogger(SimpleRegionNormalizer.class);\n-  private static long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+\n+  static final String SPLIT_ENABLED_KEY = \"hbase.normalizer.split.enabled\";\n+  static final boolean DEFAULT_SPLIT_ENABLED = true;\n+  static final String MERGE_ENABLED_KEY = \"hbase.normalizer.merge.enabled\";\n+  static final boolean DEFAULT_MERGE_ENABLED = true;\n+  // TODO: after HBASE-24416, `min.region.count` only applies to merge plans; should\n+  //  deprecate/rename the configuration key.\n+  static final String MIN_REGION_COUNT_KEY = \"hbase.normalizer.min.region.count\";\n+  static final int DEFAULT_MIN_REGION_COUNT = 3;\n+  static final String MERGE_MIN_REGION_AGE_DAYS_KEY = \"hbase.normalizer.merge.min_region_age.days\";\n+  static final int DEFAULT_MERGE_MIN_REGION_AGE_DAYS = 3;\n+  static final String MERGE_MIN_REGION_SIZE_MB_KEY = \"hbase.normalizer.merge.min_region_size.mb\";\n+  static final int DEFAULT_MERGE_MIN_REGION_SIZE_MB = 1;\n+\n+  private final long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+  private final Comparator<NormalizationPlan> planComparator = new SplitPlanFirstComparator();\n+\n+  private Configuration conf;\n+  private MasterServices masterServices;\n+  private boolean splitEnabled;\n+  private boolean mergeEnabled;\n+  private int minRegionCount;\n+  private Period mergeMinRegionAge;\n+  private int mergeMinRegionSizeMb;\n+\n+  public SimpleRegionNormalizer() {\n+    splitEnabled = DEFAULT_SPLIT_ENABLED;\n+    mergeEnabled = DEFAULT_MERGE_ENABLED;\n+    minRegionCount = DEFAULT_MIN_REGION_COUNT;\n+    mergeMinRegionAge = Period.ofDays(DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    mergeMinRegionSizeMb = DEFAULT_MERGE_MIN_REGION_SIZE_MB;\n+  }\n \n   @Override\n-  public void planSkipped(RegionInfo hri, PlanType type) {\n-    skippedCount[type.ordinal()]++;\n+  public Configuration getConf() {\n+    return conf;\n   }\n \n   @Override\n-  public long getSkippedCount(NormalizationPlan.PlanType type) {\n-    return skippedCount[type.ordinal()];\n+  public void setConf(final Configuration conf) {\n+    if (conf == null) {\n+      return;\n+    }\n+    this.conf = conf;\n+    splitEnabled = conf.getBoolean(SPLIT_ENABLED_KEY, DEFAULT_SPLIT_ENABLED);\n+    mergeEnabled = conf.getBoolean(MERGE_ENABLED_KEY, DEFAULT_MERGE_ENABLED);\n+    minRegionCount = parseMinRegionCount(conf);\n+    mergeMinRegionAge = parseMergeMinRegionAge(conf);\n+    mergeMinRegionSizeMb = parseMergeMinRegionSizeMb(conf);\n+  }\n+\n+  private static int parseMinRegionCount(final Configuration conf) {\n+    final int parsedValue = conf.getInt(MIN_REGION_COUNT_KEY, DEFAULT_MIN_REGION_COUNT);\n+    final int settledValue = Math.max(1, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MIN_REGION_COUNT_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static Period parseMergeMinRegionAge(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_AGE_DAYS_KEY, DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_AGE_DAYS_KEY, parsedValue, settledValue);\n+    }\n+    return Period.ofDays(settledValue);\n+  }\n+\n+  private static int parseMergeMinRegionSizeMb(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_SIZE_MB_KEY, DEFAULT_MERGE_MIN_REGION_SIZE_MB);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_SIZE_MB_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static <T> void warnInvalidValue(final String key, final T parsedValue,\n+    final T settledValue) {\n+    LOG.warn(\"Configured value {}={} is invalid. Setting value to {}.\",\n+      key, parsedValue, settledValue);\n   }\n \n   /**\n-   * Comparator class that gives higher priority to region Split plan.\n+   * Return this instance's configured value for {@value SPLIT_ENABLED_KEY}.\n    */\n-  static class PlanComparator implements Comparator<NormalizationPlan> {\n-    @Override\n-    public int compare(NormalizationPlan plan1, NormalizationPlan plan2) {\n-      boolean plan1IsSplit = plan1 instanceof SplitNormalizationPlan;\n-      boolean plan2IsSplit = plan2 instanceof SplitNormalizationPlan;\n-      if (plan1IsSplit && plan2IsSplit) {\n-        return 0;\n-      } else if (plan1IsSplit) {\n-        return -1;\n-      } else if (plan2IsSplit) {\n-        return 1;\n-      } else {\n-        return 0;\n-      }\n-    }\n+  public boolean isSplitEnabled() {\n+    return splitEnabled;\n   }\n \n-  private Comparator<NormalizationPlan> planComparator = new PlanComparator();\n+  /**\n+   * Return this instance's configured value for {@value MERGE_ENABLED_KEY}.\n+   */\n+  public boolean isMergeEnabled() {\n+    return mergeEnabled;\n+  }\n \n   /**\n-   * Computes next most \"urgent\" normalization action on the table. Action may be either a split, or\n-   * a merge, or no action.\n-   * @param table table to normalize\n-   * @return normalization plan to execute\n+   * Return this instance's configured value for {@value MIN_REGION_COUNT_KEY}.\n+   */\n+  public int getMinRegionCount() {\n+    return minRegionCount;\n+  }\n+\n+  /**\n+   * Return this instance's configured value for {@value MERGE_MIN_REGION_AGE_DAYS_KEY}.\n    */\n+  public Period getMergeMinRegionAge() {\n+    return mergeMinRegionAge;\n+  }\n+\n+  /**\n+   * Return this instance's configured value for {@value MERGE_MIN_REGION_SIZE_MB_KEY}.\n+   */\n+  public int getMergeMinRegionSizeMb() {\n+    return mergeMinRegionSizeMb;\n+  }\n+\n   @Override\n-  public List<NormalizationPlan> computePlanForTable(TableName table) throws HBaseIOException {\n+  public void setMasterServices(final MasterServices masterServices) {\n+    this.masterServices = masterServices;\n+  }\n+\n+  @Override\n+  public void planSkipped(final RegionInfo hri, final PlanType type) {\n+    skippedCount[type.ordinal()]++;\n+  }\n+\n+  @Override\n+  public long getSkippedCount(NormalizationPlan.PlanType type) {\n+    return skippedCount[type.ordinal()];\n+  }\n+\n+  @Override\n+  public List<NormalizationPlan> computePlansForTable(TableName table) {\n     if (table == null || table.isSystemTable()) {\n       LOG.debug(\"Normalization of system table {} isn't allowed\", table);\n-      return null;\n+      return Collections.emptyList();\n     }\n-    boolean splitEnabled = isSplitEnabled();\n-    boolean mergeEnabled = isMergeEnabled();\n+    boolean splitEnabled = isSplitEnabled() && isMasterSwitchEnabled(MasterSwitchType.SPLIT);\n+    boolean mergeEnabled = isMergeEnabled() && isMasterSwitchEnabled(MasterSwitchType.MERGE);\n     if (!mergeEnabled && !splitEnabled) {\n-      LOG.debug(\"Both split and merge are disabled for table: {}\", table);\n-      return null;\n+      LOG.debug(\"Both split and merge are disabled. Skipping normalization of table: {}\", table);\n+      return Collections.emptyList();\n     }\n+\n     List<NormalizationPlan> plans = new ArrayList<>();\n-    List<RegionInfo> tableRegions =\n-        masterServices.getAssignmentManager().getRegionStates().getRegionsOfTable(table);\n+    List<RegionInfo> tableRegions = masterServices.getAssignmentManager()\n+      .getRegionStates()\n+      .getRegionsOfTable(table);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTE3NjQ5Ng=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 273}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4NTY1OTE1OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxNDozNDoxNFrOGbNYcQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QyMDozOTo1M1rOGbcSfA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTE4Mzk4NQ==", "bodyText": "nit: Better var names will be hri and hriNext or hriAdjacent? Same goes for regionSize and regionSize2.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431183985", "createdAt": "2020-05-27T14:34:14Z", "author": {"login": "virajjasani"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,436 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>\n+ *   <li>Otherwise, for the next region in the chain R1, if R0 + R1 is smaller then S, R0 and R1\n+ *     are kindly requested to merge.</li>\n+ * </ol>\n+ * <p>\n+ * The following parameters are configurable:\n+ * <ol>\n+ *   <li>Whether to split a region as part of normalization. Configuration:\n+ *     {@value SPLIT_ENABLED_KEY}, default: {@value DEFAULT_SPLIT_ENABLED}.</li>\n+ *   <li>Whether to merge a region as part of normalization. Configuration:\n+ *     {@value MERGE_ENABLED_KEY}, default: {@value DEFAULT_MERGE_ENABLED}.</li>\n+ *   <li>The minimum number of regions in a table to consider it for normalization. Configuration:\n+ *     {@value MIN_REGION_COUNT_KEY}, default: {@value DEFAULT_MIN_REGION_COUNT}.</li>\n+ *   <li>The minimum age for a region to be considered for a merge, in days. Configuration:\n+ *     {@value MERGE_MIN_REGION_AGE_DAYS_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_AGE_DAYS}.</li>\n+ *   <li>The minimum size for a region to be considered for a merge, in whole MBs. Configuration:\n+ *     {@value MERGE_MIN_REGION_SIZE_MB_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_SIZE_MB}.</li>\n  * </ol>\n  * <p>\n- * Region sizes are coarse and approximate on the order of megabytes. Additionally, \"empty\" regions\n- * (less than 1MB, with the previous note) are not merged away. This is by design to prevent\n- * normalization from undoing the pre-splitting of a table.\n+ * To see detailed logging of the application of these configuration values, set the log level for\n+ * this class to `TRACE`.\n  */\n-@InterfaceAudience.Private\n-public class SimpleRegionNormalizer extends AbstractRegionNormalizer {\n-\n+@InterfaceAudience.LimitedPrivate(HBaseInterfaceAudience.CONFIG)\n+public class SimpleRegionNormalizer implements RegionNormalizer {\n   private static final Logger LOG = LoggerFactory.getLogger(SimpleRegionNormalizer.class);\n-  private static long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+\n+  static final String SPLIT_ENABLED_KEY = \"hbase.normalizer.split.enabled\";\n+  static final boolean DEFAULT_SPLIT_ENABLED = true;\n+  static final String MERGE_ENABLED_KEY = \"hbase.normalizer.merge.enabled\";\n+  static final boolean DEFAULT_MERGE_ENABLED = true;\n+  // TODO: after HBASE-24416, `min.region.count` only applies to merge plans; should\n+  //  deprecate/rename the configuration key.\n+  static final String MIN_REGION_COUNT_KEY = \"hbase.normalizer.min.region.count\";\n+  static final int DEFAULT_MIN_REGION_COUNT = 3;\n+  static final String MERGE_MIN_REGION_AGE_DAYS_KEY = \"hbase.normalizer.merge.min_region_age.days\";\n+  static final int DEFAULT_MERGE_MIN_REGION_AGE_DAYS = 3;\n+  static final String MERGE_MIN_REGION_SIZE_MB_KEY = \"hbase.normalizer.merge.min_region_size.mb\";\n+  static final int DEFAULT_MERGE_MIN_REGION_SIZE_MB = 1;\n+\n+  private final long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+  private final Comparator<NormalizationPlan> planComparator = new SplitPlanFirstComparator();\n+\n+  private Configuration conf;\n+  private MasterServices masterServices;\n+  private boolean splitEnabled;\n+  private boolean mergeEnabled;\n+  private int minRegionCount;\n+  private Period mergeMinRegionAge;\n+  private int mergeMinRegionSizeMb;\n+\n+  public SimpleRegionNormalizer() {\n+    splitEnabled = DEFAULT_SPLIT_ENABLED;\n+    mergeEnabled = DEFAULT_MERGE_ENABLED;\n+    minRegionCount = DEFAULT_MIN_REGION_COUNT;\n+    mergeMinRegionAge = Period.ofDays(DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    mergeMinRegionSizeMb = DEFAULT_MERGE_MIN_REGION_SIZE_MB;\n+  }\n \n   @Override\n-  public void planSkipped(RegionInfo hri, PlanType type) {\n-    skippedCount[type.ordinal()]++;\n+  public Configuration getConf() {\n+    return conf;\n   }\n \n   @Override\n-  public long getSkippedCount(NormalizationPlan.PlanType type) {\n-    return skippedCount[type.ordinal()];\n+  public void setConf(final Configuration conf) {\n+    if (conf == null) {\n+      return;\n+    }\n+    this.conf = conf;\n+    splitEnabled = conf.getBoolean(SPLIT_ENABLED_KEY, DEFAULT_SPLIT_ENABLED);\n+    mergeEnabled = conf.getBoolean(MERGE_ENABLED_KEY, DEFAULT_MERGE_ENABLED);\n+    minRegionCount = parseMinRegionCount(conf);\n+    mergeMinRegionAge = parseMergeMinRegionAge(conf);\n+    mergeMinRegionSizeMb = parseMergeMinRegionSizeMb(conf);\n+  }\n+\n+  private static int parseMinRegionCount(final Configuration conf) {\n+    final int parsedValue = conf.getInt(MIN_REGION_COUNT_KEY, DEFAULT_MIN_REGION_COUNT);\n+    final int settledValue = Math.max(1, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MIN_REGION_COUNT_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static Period parseMergeMinRegionAge(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_AGE_DAYS_KEY, DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_AGE_DAYS_KEY, parsedValue, settledValue);\n+    }\n+    return Period.ofDays(settledValue);\n+  }\n+\n+  private static int parseMergeMinRegionSizeMb(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_SIZE_MB_KEY, DEFAULT_MERGE_MIN_REGION_SIZE_MB);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_SIZE_MB_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static <T> void warnInvalidValue(final String key, final T parsedValue,\n+    final T settledValue) {\n+    LOG.warn(\"Configured value {}={} is invalid. Setting value to {}.\",\n+      key, parsedValue, settledValue);\n   }\n \n   /**\n-   * Comparator class that gives higher priority to region Split plan.\n+   * Return this instance's configured value for {@value SPLIT_ENABLED_KEY}.\n    */\n-  static class PlanComparator implements Comparator<NormalizationPlan> {\n-    @Override\n-    public int compare(NormalizationPlan plan1, NormalizationPlan plan2) {\n-      boolean plan1IsSplit = plan1 instanceof SplitNormalizationPlan;\n-      boolean plan2IsSplit = plan2 instanceof SplitNormalizationPlan;\n-      if (plan1IsSplit && plan2IsSplit) {\n-        return 0;\n-      } else if (plan1IsSplit) {\n-        return -1;\n-      } else if (plan2IsSplit) {\n-        return 1;\n-      } else {\n-        return 0;\n-      }\n-    }\n+  public boolean isSplitEnabled() {\n+    return splitEnabled;\n   }\n \n-  private Comparator<NormalizationPlan> planComparator = new PlanComparator();\n+  /**\n+   * Return this instance's configured value for {@value MERGE_ENABLED_KEY}.\n+   */\n+  public boolean isMergeEnabled() {\n+    return mergeEnabled;\n+  }\n \n   /**\n-   * Computes next most \"urgent\" normalization action on the table. Action may be either a split, or\n-   * a merge, or no action.\n-   * @param table table to normalize\n-   * @return normalization plan to execute\n+   * Return this instance's configured value for {@value MIN_REGION_COUNT_KEY}.\n+   */\n+  public int getMinRegionCount() {\n+    return minRegionCount;\n+  }\n+\n+  /**\n+   * Return this instance's configured value for {@value MERGE_MIN_REGION_AGE_DAYS_KEY}.\n    */\n+  public Period getMergeMinRegionAge() {\n+    return mergeMinRegionAge;\n+  }\n+\n+  /**\n+   * Return this instance's configured value for {@value MERGE_MIN_REGION_SIZE_MB_KEY}.\n+   */\n+  public int getMergeMinRegionSizeMb() {\n+    return mergeMinRegionSizeMb;\n+  }\n+\n   @Override\n-  public List<NormalizationPlan> computePlanForTable(TableName table) throws HBaseIOException {\n+  public void setMasterServices(final MasterServices masterServices) {\n+    this.masterServices = masterServices;\n+  }\n+\n+  @Override\n+  public void planSkipped(final RegionInfo hri, final PlanType type) {\n+    skippedCount[type.ordinal()]++;\n+  }\n+\n+  @Override\n+  public long getSkippedCount(NormalizationPlan.PlanType type) {\n+    return skippedCount[type.ordinal()];\n+  }\n+\n+  @Override\n+  public List<NormalizationPlan> computePlansForTable(TableName table) {\n     if (table == null || table.isSystemTable()) {\n       LOG.debug(\"Normalization of system table {} isn't allowed\", table);\n-      return null;\n+      return Collections.emptyList();\n     }\n-    boolean splitEnabled = isSplitEnabled();\n-    boolean mergeEnabled = isMergeEnabled();\n+    boolean splitEnabled = isSplitEnabled() && isMasterSwitchEnabled(MasterSwitchType.SPLIT);\n+    boolean mergeEnabled = isMergeEnabled() && isMasterSwitchEnabled(MasterSwitchType.MERGE);\n     if (!mergeEnabled && !splitEnabled) {\n-      LOG.debug(\"Both split and merge are disabled for table: {}\", table);\n-      return null;\n+      LOG.debug(\"Both split and merge are disabled. Skipping normalization of table: {}\", table);\n+      return Collections.emptyList();\n     }\n+\n     List<NormalizationPlan> plans = new ArrayList<>();\n-    List<RegionInfo> tableRegions =\n-        masterServices.getAssignmentManager().getRegionStates().getRegionsOfTable(table);\n+    List<RegionInfo> tableRegions = masterServices.getAssignmentManager()\n+      .getRegionStates()\n+      .getRegionsOfTable(table);\n \n-    if (tableRegions == null) {\n-      return null;\n+    if (CollectionUtils.isEmpty(tableRegions)) {\n+      return Collections.emptyList();\n     }\n \n     LOG.debug(\"Computing normalization plan for table:  {}, number of regions: {}\", table,\n       tableRegions.size());\n \n     if (splitEnabled) {\n-      List<NormalizationPlan> splitPlans = getSplitNormalizationPlan(table);\n-      if (splitPlans != null) {\n-        plans.addAll(splitPlans);\n+      plans.addAll(computeSplitNormalizationPlans(table));\n+    }\n+    if (mergeEnabled) {\n+      plans.addAll(computeMergeNormalizationPlans(table));\n+    }\n+\n+    plans.sort(planComparator);\n+    LOG.debug(\"Computed {} normalization plans for table {}\", plans.size(), table);\n+    return plans;\n+  }\n+\n+  /**\n+   * @return size of region in MB and if region is not found than -1\n+   */\n+  private long getRegionSizeMB(RegionInfo hri) {\n+    ServerName sn =\n+      masterServices.getAssignmentManager().getRegionStates().getRegionServerOfRegion(hri);\n+    RegionMetrics regionLoad =\n+      masterServices.getServerManager().getLoad(sn).getRegionMetrics().get(hri.getRegionName());\n+    if (regionLoad == null) {\n+      LOG.debug(\"{} was not found in RegionsLoad\", hri.getRegionNameAsString());\n+      return -1;\n+    }\n+    return (long) regionLoad.getStoreFileSize().get(Size.Unit.MEGABYTE);\n+  }\n+\n+  private boolean isMasterSwitchEnabled(final MasterSwitchType masterSwitchType) {\n+    return masterServices.isSplitOrMergeEnabled(masterSwitchType);\n+  }\n+\n+  /**\n+   * @param tableRegions regions of table to normalize\n+   * @return average region size depending on\n+   * @see org.apache.hadoop.hbase.client.TableDescriptor#getNormalizerTargetRegionCount()\n+   * Also make sure tableRegions contains regions of the same table\n+   */\n+  private double getAverageRegionSize(List<RegionInfo> tableRegions) {\n+    if (CollectionUtils.isEmpty(tableRegions)) {\n+      throw new IllegalStateException(\n+        \"Cannot calculate average size of a table without any regions.\");\n+    }\n+    final int regionCount = tableRegions.size();\n+    final long totalSizeMb = tableRegions.stream()\n+      .mapToLong(this::getRegionSizeMB)\n+      .sum();\n+    TableName table = tableRegions.get(0).getTable();\n+    int targetRegionCount = -1;\n+    long targetRegionSize = -1;\n+    try {\n+      TableDescriptor tableDescriptor = masterServices.getTableDescriptors().get(table);\n+      if (tableDescriptor != null) {\n+        targetRegionCount = tableDescriptor.getNormalizerTargetRegionCount();\n+        targetRegionSize = tableDescriptor.getNormalizerTargetRegionSize();\n+        LOG.debug(\"Table {} configured with target region count {}, target region size {}\", table,\n+          targetRegionCount, targetRegionSize);\n       }\n+    } catch (IOException e) {\n+      LOG.warn(\"TableDescriptor for {} unavailable, table-level target region count and size\"\n+        + \" configurations cannot be considered.\", table, e);\n     }\n \n-    if (mergeEnabled) {\n-      if (tableRegions.size() < minRegionCount) {\n-        LOG.debug(\"Table {} has {} regions, required min number of regions for normalizer to run\" +\n-                \" is {}, not running normalizer\",\n-            table, tableRegions.size(), minRegionCount);\n-      } else {\n-        List<NormalizationPlan> mergePlans = getMergeNormalizationPlan(table);\n-        if (mergePlans != null) {\n-          plans.addAll(mergePlans);\n-        }\n+    double avgRegionSize;\n+    if (targetRegionSize > 0) {\n+      avgRegionSize = targetRegionSize;\n+    } else if (targetRegionCount > 0) {\n+      avgRegionSize = totalSizeMb / (double) targetRegionCount;\n+    } else {\n+      avgRegionSize = totalSizeMb / (double) regionCount;\n+    }\n+\n+    LOG.debug(\"Table {}, total aggregated regions size: {} and average region size {}\", table,\n+      totalSizeMb, avgRegionSize);\n+    return avgRegionSize;\n+  }\n+\n+  /**\n+   * Determine if a {@link RegionInfo} should be considered for a merge operation.\n+   */\n+  private boolean skipForMerge(final RegionStates regionStates, final RegionInfo regionInfo) {\n+    final RegionState state = regionStates.getRegionState(regionInfo);\n+    final String name = regionInfo.getEncodedName();\n+    return\n+      logTraceReason(\n+        () -> state == null,\n+        \"skipping merge of region {} because no state information is available.\", name)\n+        || logTraceReason(\n+          () -> !Objects.equals(state.getState(), RegionState.State.OPEN),\n+          \"skipping merge of region {} because it is not open.\", name)\n+        || logTraceReason(\n+          () -> !isOldEnoughForMerge(regionInfo),\n+          \"skipping merge of region {} because it is not old enough.\", name)\n+        || logTraceReason(\n+          () -> !isLargeEnoughForMerge(regionInfo),\n+          \"skipping merge region {} because it is not large enough.\", name);\n+  }\n+\n+  /**\n+   * Computes the merge plans that should be executed for this table to converge average region\n+   * towards target average or target region count\n+   * @param table table to normalize\n+   * @return list of merge normalization plans\n+   */\n+  private List<NormalizationPlan> computeMergeNormalizationPlans(TableName table) {\n+    final RegionStates regionStates = masterServices.getAssignmentManager().getRegionStates();\n+    final List<RegionInfo> tableRegions = regionStates.getRegionsOfTable(table);\n+\n+    if (tableRegions.size() < minRegionCount) {\n+      LOG.debug(\"Table {} has {} regions, required min number of regions for normalizer to run\"\n+        + \" is {}, not computing merge plans.\", table, tableRegions.size(), minRegionCount);\n+      return Collections.emptyList();\n+    }\n+\n+    final double avgRegionSize = getAverageRegionSize(tableRegions);\n+    LOG.debug(\"Table {}, average region size: {}. Computing normalization plan for table: {}, \"\n+        + \"number of regions: {}.\",\n+      table, avgRegionSize, table, tableRegions.size());\n+\n+    // The list of regionInfo from getRegionsOfTable() is ordered by regionName.\n+    // regionName does not necessary guarantee the order by STARTKEY (let's say 'aa1', 'aa1!',\n+    // in order by regionName, it will be 'aa1!' followed by 'aa1').\n+    // This could result in normalizer merging non-adjacent regions into one and creates overlaps.\n+    // In order to avoid that, sort the list by RegionInfo.COMPARATOR.\n+    tableRegions.sort(RegionInfo.COMPARATOR);\n+    final List<NormalizationPlan> plans = new ArrayList<>();\n+    for (int candidateIdx = 0; candidateIdx < tableRegions.size() - 1; candidateIdx++) {\n+      final RegionInfo hri = tableRegions.get(candidateIdx);\n+      final RegionInfo hri2 = tableRegions.get(candidateIdx + 1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 424}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQyODIyMA==", "bodyText": "Indeed. Let me clean this up too.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431428220", "createdAt": "2020-05-27T20:39:53Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,436 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>\n+ *   <li>Otherwise, for the next region in the chain R1, if R0 + R1 is smaller then S, R0 and R1\n+ *     are kindly requested to merge.</li>\n+ * </ol>\n+ * <p>\n+ * The following parameters are configurable:\n+ * <ol>\n+ *   <li>Whether to split a region as part of normalization. Configuration:\n+ *     {@value SPLIT_ENABLED_KEY}, default: {@value DEFAULT_SPLIT_ENABLED}.</li>\n+ *   <li>Whether to merge a region as part of normalization. Configuration:\n+ *     {@value MERGE_ENABLED_KEY}, default: {@value DEFAULT_MERGE_ENABLED}.</li>\n+ *   <li>The minimum number of regions in a table to consider it for normalization. Configuration:\n+ *     {@value MIN_REGION_COUNT_KEY}, default: {@value DEFAULT_MIN_REGION_COUNT}.</li>\n+ *   <li>The minimum age for a region to be considered for a merge, in days. Configuration:\n+ *     {@value MERGE_MIN_REGION_AGE_DAYS_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_AGE_DAYS}.</li>\n+ *   <li>The minimum size for a region to be considered for a merge, in whole MBs. Configuration:\n+ *     {@value MERGE_MIN_REGION_SIZE_MB_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_SIZE_MB}.</li>\n  * </ol>\n  * <p>\n- * Region sizes are coarse and approximate on the order of megabytes. Additionally, \"empty\" regions\n- * (less than 1MB, with the previous note) are not merged away. This is by design to prevent\n- * normalization from undoing the pre-splitting of a table.\n+ * To see detailed logging of the application of these configuration values, set the log level for\n+ * this class to `TRACE`.\n  */\n-@InterfaceAudience.Private\n-public class SimpleRegionNormalizer extends AbstractRegionNormalizer {\n-\n+@InterfaceAudience.LimitedPrivate(HBaseInterfaceAudience.CONFIG)\n+public class SimpleRegionNormalizer implements RegionNormalizer {\n   private static final Logger LOG = LoggerFactory.getLogger(SimpleRegionNormalizer.class);\n-  private static long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+\n+  static final String SPLIT_ENABLED_KEY = \"hbase.normalizer.split.enabled\";\n+  static final boolean DEFAULT_SPLIT_ENABLED = true;\n+  static final String MERGE_ENABLED_KEY = \"hbase.normalizer.merge.enabled\";\n+  static final boolean DEFAULT_MERGE_ENABLED = true;\n+  // TODO: after HBASE-24416, `min.region.count` only applies to merge plans; should\n+  //  deprecate/rename the configuration key.\n+  static final String MIN_REGION_COUNT_KEY = \"hbase.normalizer.min.region.count\";\n+  static final int DEFAULT_MIN_REGION_COUNT = 3;\n+  static final String MERGE_MIN_REGION_AGE_DAYS_KEY = \"hbase.normalizer.merge.min_region_age.days\";\n+  static final int DEFAULT_MERGE_MIN_REGION_AGE_DAYS = 3;\n+  static final String MERGE_MIN_REGION_SIZE_MB_KEY = \"hbase.normalizer.merge.min_region_size.mb\";\n+  static final int DEFAULT_MERGE_MIN_REGION_SIZE_MB = 1;\n+\n+  private final long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+  private final Comparator<NormalizationPlan> planComparator = new SplitPlanFirstComparator();\n+\n+  private Configuration conf;\n+  private MasterServices masterServices;\n+  private boolean splitEnabled;\n+  private boolean mergeEnabled;\n+  private int minRegionCount;\n+  private Period mergeMinRegionAge;\n+  private int mergeMinRegionSizeMb;\n+\n+  public SimpleRegionNormalizer() {\n+    splitEnabled = DEFAULT_SPLIT_ENABLED;\n+    mergeEnabled = DEFAULT_MERGE_ENABLED;\n+    minRegionCount = DEFAULT_MIN_REGION_COUNT;\n+    mergeMinRegionAge = Period.ofDays(DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    mergeMinRegionSizeMb = DEFAULT_MERGE_MIN_REGION_SIZE_MB;\n+  }\n \n   @Override\n-  public void planSkipped(RegionInfo hri, PlanType type) {\n-    skippedCount[type.ordinal()]++;\n+  public Configuration getConf() {\n+    return conf;\n   }\n \n   @Override\n-  public long getSkippedCount(NormalizationPlan.PlanType type) {\n-    return skippedCount[type.ordinal()];\n+  public void setConf(final Configuration conf) {\n+    if (conf == null) {\n+      return;\n+    }\n+    this.conf = conf;\n+    splitEnabled = conf.getBoolean(SPLIT_ENABLED_KEY, DEFAULT_SPLIT_ENABLED);\n+    mergeEnabled = conf.getBoolean(MERGE_ENABLED_KEY, DEFAULT_MERGE_ENABLED);\n+    minRegionCount = parseMinRegionCount(conf);\n+    mergeMinRegionAge = parseMergeMinRegionAge(conf);\n+    mergeMinRegionSizeMb = parseMergeMinRegionSizeMb(conf);\n+  }\n+\n+  private static int parseMinRegionCount(final Configuration conf) {\n+    final int parsedValue = conf.getInt(MIN_REGION_COUNT_KEY, DEFAULT_MIN_REGION_COUNT);\n+    final int settledValue = Math.max(1, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MIN_REGION_COUNT_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static Period parseMergeMinRegionAge(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_AGE_DAYS_KEY, DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_AGE_DAYS_KEY, parsedValue, settledValue);\n+    }\n+    return Period.ofDays(settledValue);\n+  }\n+\n+  private static int parseMergeMinRegionSizeMb(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_SIZE_MB_KEY, DEFAULT_MERGE_MIN_REGION_SIZE_MB);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_SIZE_MB_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static <T> void warnInvalidValue(final String key, final T parsedValue,\n+    final T settledValue) {\n+    LOG.warn(\"Configured value {}={} is invalid. Setting value to {}.\",\n+      key, parsedValue, settledValue);\n   }\n \n   /**\n-   * Comparator class that gives higher priority to region Split plan.\n+   * Return this instance's configured value for {@value SPLIT_ENABLED_KEY}.\n    */\n-  static class PlanComparator implements Comparator<NormalizationPlan> {\n-    @Override\n-    public int compare(NormalizationPlan plan1, NormalizationPlan plan2) {\n-      boolean plan1IsSplit = plan1 instanceof SplitNormalizationPlan;\n-      boolean plan2IsSplit = plan2 instanceof SplitNormalizationPlan;\n-      if (plan1IsSplit && plan2IsSplit) {\n-        return 0;\n-      } else if (plan1IsSplit) {\n-        return -1;\n-      } else if (plan2IsSplit) {\n-        return 1;\n-      } else {\n-        return 0;\n-      }\n-    }\n+  public boolean isSplitEnabled() {\n+    return splitEnabled;\n   }\n \n-  private Comparator<NormalizationPlan> planComparator = new PlanComparator();\n+  /**\n+   * Return this instance's configured value for {@value MERGE_ENABLED_KEY}.\n+   */\n+  public boolean isMergeEnabled() {\n+    return mergeEnabled;\n+  }\n \n   /**\n-   * Computes next most \"urgent\" normalization action on the table. Action may be either a split, or\n-   * a merge, or no action.\n-   * @param table table to normalize\n-   * @return normalization plan to execute\n+   * Return this instance's configured value for {@value MIN_REGION_COUNT_KEY}.\n+   */\n+  public int getMinRegionCount() {\n+    return minRegionCount;\n+  }\n+\n+  /**\n+   * Return this instance's configured value for {@value MERGE_MIN_REGION_AGE_DAYS_KEY}.\n    */\n+  public Period getMergeMinRegionAge() {\n+    return mergeMinRegionAge;\n+  }\n+\n+  /**\n+   * Return this instance's configured value for {@value MERGE_MIN_REGION_SIZE_MB_KEY}.\n+   */\n+  public int getMergeMinRegionSizeMb() {\n+    return mergeMinRegionSizeMb;\n+  }\n+\n   @Override\n-  public List<NormalizationPlan> computePlanForTable(TableName table) throws HBaseIOException {\n+  public void setMasterServices(final MasterServices masterServices) {\n+    this.masterServices = masterServices;\n+  }\n+\n+  @Override\n+  public void planSkipped(final RegionInfo hri, final PlanType type) {\n+    skippedCount[type.ordinal()]++;\n+  }\n+\n+  @Override\n+  public long getSkippedCount(NormalizationPlan.PlanType type) {\n+    return skippedCount[type.ordinal()];\n+  }\n+\n+  @Override\n+  public List<NormalizationPlan> computePlansForTable(TableName table) {\n     if (table == null || table.isSystemTable()) {\n       LOG.debug(\"Normalization of system table {} isn't allowed\", table);\n-      return null;\n+      return Collections.emptyList();\n     }\n-    boolean splitEnabled = isSplitEnabled();\n-    boolean mergeEnabled = isMergeEnabled();\n+    boolean splitEnabled = isSplitEnabled() && isMasterSwitchEnabled(MasterSwitchType.SPLIT);\n+    boolean mergeEnabled = isMergeEnabled() && isMasterSwitchEnabled(MasterSwitchType.MERGE);\n     if (!mergeEnabled && !splitEnabled) {\n-      LOG.debug(\"Both split and merge are disabled for table: {}\", table);\n-      return null;\n+      LOG.debug(\"Both split and merge are disabled. Skipping normalization of table: {}\", table);\n+      return Collections.emptyList();\n     }\n+\n     List<NormalizationPlan> plans = new ArrayList<>();\n-    List<RegionInfo> tableRegions =\n-        masterServices.getAssignmentManager().getRegionStates().getRegionsOfTable(table);\n+    List<RegionInfo> tableRegions = masterServices.getAssignmentManager()\n+      .getRegionStates()\n+      .getRegionsOfTable(table);\n \n-    if (tableRegions == null) {\n-      return null;\n+    if (CollectionUtils.isEmpty(tableRegions)) {\n+      return Collections.emptyList();\n     }\n \n     LOG.debug(\"Computing normalization plan for table:  {}, number of regions: {}\", table,\n       tableRegions.size());\n \n     if (splitEnabled) {\n-      List<NormalizationPlan> splitPlans = getSplitNormalizationPlan(table);\n-      if (splitPlans != null) {\n-        plans.addAll(splitPlans);\n+      plans.addAll(computeSplitNormalizationPlans(table));\n+    }\n+    if (mergeEnabled) {\n+      plans.addAll(computeMergeNormalizationPlans(table));\n+    }\n+\n+    plans.sort(planComparator);\n+    LOG.debug(\"Computed {} normalization plans for table {}\", plans.size(), table);\n+    return plans;\n+  }\n+\n+  /**\n+   * @return size of region in MB and if region is not found than -1\n+   */\n+  private long getRegionSizeMB(RegionInfo hri) {\n+    ServerName sn =\n+      masterServices.getAssignmentManager().getRegionStates().getRegionServerOfRegion(hri);\n+    RegionMetrics regionLoad =\n+      masterServices.getServerManager().getLoad(sn).getRegionMetrics().get(hri.getRegionName());\n+    if (regionLoad == null) {\n+      LOG.debug(\"{} was not found in RegionsLoad\", hri.getRegionNameAsString());\n+      return -1;\n+    }\n+    return (long) regionLoad.getStoreFileSize().get(Size.Unit.MEGABYTE);\n+  }\n+\n+  private boolean isMasterSwitchEnabled(final MasterSwitchType masterSwitchType) {\n+    return masterServices.isSplitOrMergeEnabled(masterSwitchType);\n+  }\n+\n+  /**\n+   * @param tableRegions regions of table to normalize\n+   * @return average region size depending on\n+   * @see org.apache.hadoop.hbase.client.TableDescriptor#getNormalizerTargetRegionCount()\n+   * Also make sure tableRegions contains regions of the same table\n+   */\n+  private double getAverageRegionSize(List<RegionInfo> tableRegions) {\n+    if (CollectionUtils.isEmpty(tableRegions)) {\n+      throw new IllegalStateException(\n+        \"Cannot calculate average size of a table without any regions.\");\n+    }\n+    final int regionCount = tableRegions.size();\n+    final long totalSizeMb = tableRegions.stream()\n+      .mapToLong(this::getRegionSizeMB)\n+      .sum();\n+    TableName table = tableRegions.get(0).getTable();\n+    int targetRegionCount = -1;\n+    long targetRegionSize = -1;\n+    try {\n+      TableDescriptor tableDescriptor = masterServices.getTableDescriptors().get(table);\n+      if (tableDescriptor != null) {\n+        targetRegionCount = tableDescriptor.getNormalizerTargetRegionCount();\n+        targetRegionSize = tableDescriptor.getNormalizerTargetRegionSize();\n+        LOG.debug(\"Table {} configured with target region count {}, target region size {}\", table,\n+          targetRegionCount, targetRegionSize);\n       }\n+    } catch (IOException e) {\n+      LOG.warn(\"TableDescriptor for {} unavailable, table-level target region count and size\"\n+        + \" configurations cannot be considered.\", table, e);\n     }\n \n-    if (mergeEnabled) {\n-      if (tableRegions.size() < minRegionCount) {\n-        LOG.debug(\"Table {} has {} regions, required min number of regions for normalizer to run\" +\n-                \" is {}, not running normalizer\",\n-            table, tableRegions.size(), minRegionCount);\n-      } else {\n-        List<NormalizationPlan> mergePlans = getMergeNormalizationPlan(table);\n-        if (mergePlans != null) {\n-          plans.addAll(mergePlans);\n-        }\n+    double avgRegionSize;\n+    if (targetRegionSize > 0) {\n+      avgRegionSize = targetRegionSize;\n+    } else if (targetRegionCount > 0) {\n+      avgRegionSize = totalSizeMb / (double) targetRegionCount;\n+    } else {\n+      avgRegionSize = totalSizeMb / (double) regionCount;\n+    }\n+\n+    LOG.debug(\"Table {}, total aggregated regions size: {} and average region size {}\", table,\n+      totalSizeMb, avgRegionSize);\n+    return avgRegionSize;\n+  }\n+\n+  /**\n+   * Determine if a {@link RegionInfo} should be considered for a merge operation.\n+   */\n+  private boolean skipForMerge(final RegionStates regionStates, final RegionInfo regionInfo) {\n+    final RegionState state = regionStates.getRegionState(regionInfo);\n+    final String name = regionInfo.getEncodedName();\n+    return\n+      logTraceReason(\n+        () -> state == null,\n+        \"skipping merge of region {} because no state information is available.\", name)\n+        || logTraceReason(\n+          () -> !Objects.equals(state.getState(), RegionState.State.OPEN),\n+          \"skipping merge of region {} because it is not open.\", name)\n+        || logTraceReason(\n+          () -> !isOldEnoughForMerge(regionInfo),\n+          \"skipping merge of region {} because it is not old enough.\", name)\n+        || logTraceReason(\n+          () -> !isLargeEnoughForMerge(regionInfo),\n+          \"skipping merge region {} because it is not large enough.\", name);\n+  }\n+\n+  /**\n+   * Computes the merge plans that should be executed for this table to converge average region\n+   * towards target average or target region count\n+   * @param table table to normalize\n+   * @return list of merge normalization plans\n+   */\n+  private List<NormalizationPlan> computeMergeNormalizationPlans(TableName table) {\n+    final RegionStates regionStates = masterServices.getAssignmentManager().getRegionStates();\n+    final List<RegionInfo> tableRegions = regionStates.getRegionsOfTable(table);\n+\n+    if (tableRegions.size() < minRegionCount) {\n+      LOG.debug(\"Table {} has {} regions, required min number of regions for normalizer to run\"\n+        + \" is {}, not computing merge plans.\", table, tableRegions.size(), minRegionCount);\n+      return Collections.emptyList();\n+    }\n+\n+    final double avgRegionSize = getAverageRegionSize(tableRegions);\n+    LOG.debug(\"Table {}, average region size: {}. Computing normalization plan for table: {}, \"\n+        + \"number of regions: {}.\",\n+      table, avgRegionSize, table, tableRegions.size());\n+\n+    // The list of regionInfo from getRegionsOfTable() is ordered by regionName.\n+    // regionName does not necessary guarantee the order by STARTKEY (let's say 'aa1', 'aa1!',\n+    // in order by regionName, it will be 'aa1!' followed by 'aa1').\n+    // This could result in normalizer merging non-adjacent regions into one and creates overlaps.\n+    // In order to avoid that, sort the list by RegionInfo.COMPARATOR.\n+    tableRegions.sort(RegionInfo.COMPARATOR);\n+    final List<NormalizationPlan> plans = new ArrayList<>();\n+    for (int candidateIdx = 0; candidateIdx < tableRegions.size() - 1; candidateIdx++) {\n+      final RegionInfo hri = tableRegions.get(candidateIdx);\n+      final RegionInfo hri2 = tableRegions.get(candidateIdx + 1);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTE4Mzk4NQ=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 424}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4NTY4OTExOnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxNDozOTowOVrOGbNrow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QyMDozODozNlrOGbcP8A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTE4ODg5OQ==", "bodyText": "How about !RegionState.State.OPEN.equals(state.getState()) ?", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431188899", "createdAt": "2020-05-27T14:39:09Z", "author": {"login": "virajjasani"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,436 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>\n+ *   <li>Otherwise, for the next region in the chain R1, if R0 + R1 is smaller then S, R0 and R1\n+ *     are kindly requested to merge.</li>\n+ * </ol>\n+ * <p>\n+ * The following parameters are configurable:\n+ * <ol>\n+ *   <li>Whether to split a region as part of normalization. Configuration:\n+ *     {@value SPLIT_ENABLED_KEY}, default: {@value DEFAULT_SPLIT_ENABLED}.</li>\n+ *   <li>Whether to merge a region as part of normalization. Configuration:\n+ *     {@value MERGE_ENABLED_KEY}, default: {@value DEFAULT_MERGE_ENABLED}.</li>\n+ *   <li>The minimum number of regions in a table to consider it for normalization. Configuration:\n+ *     {@value MIN_REGION_COUNT_KEY}, default: {@value DEFAULT_MIN_REGION_COUNT}.</li>\n+ *   <li>The minimum age for a region to be considered for a merge, in days. Configuration:\n+ *     {@value MERGE_MIN_REGION_AGE_DAYS_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_AGE_DAYS}.</li>\n+ *   <li>The minimum size for a region to be considered for a merge, in whole MBs. Configuration:\n+ *     {@value MERGE_MIN_REGION_SIZE_MB_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_SIZE_MB}.</li>\n  * </ol>\n  * <p>\n- * Region sizes are coarse and approximate on the order of megabytes. Additionally, \"empty\" regions\n- * (less than 1MB, with the previous note) are not merged away. This is by design to prevent\n- * normalization from undoing the pre-splitting of a table.\n+ * To see detailed logging of the application of these configuration values, set the log level for\n+ * this class to `TRACE`.\n  */\n-@InterfaceAudience.Private\n-public class SimpleRegionNormalizer extends AbstractRegionNormalizer {\n-\n+@InterfaceAudience.LimitedPrivate(HBaseInterfaceAudience.CONFIG)\n+public class SimpleRegionNormalizer implements RegionNormalizer {\n   private static final Logger LOG = LoggerFactory.getLogger(SimpleRegionNormalizer.class);\n-  private static long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+\n+  static final String SPLIT_ENABLED_KEY = \"hbase.normalizer.split.enabled\";\n+  static final boolean DEFAULT_SPLIT_ENABLED = true;\n+  static final String MERGE_ENABLED_KEY = \"hbase.normalizer.merge.enabled\";\n+  static final boolean DEFAULT_MERGE_ENABLED = true;\n+  // TODO: after HBASE-24416, `min.region.count` only applies to merge plans; should\n+  //  deprecate/rename the configuration key.\n+  static final String MIN_REGION_COUNT_KEY = \"hbase.normalizer.min.region.count\";\n+  static final int DEFAULT_MIN_REGION_COUNT = 3;\n+  static final String MERGE_MIN_REGION_AGE_DAYS_KEY = \"hbase.normalizer.merge.min_region_age.days\";\n+  static final int DEFAULT_MERGE_MIN_REGION_AGE_DAYS = 3;\n+  static final String MERGE_MIN_REGION_SIZE_MB_KEY = \"hbase.normalizer.merge.min_region_size.mb\";\n+  static final int DEFAULT_MERGE_MIN_REGION_SIZE_MB = 1;\n+\n+  private final long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+  private final Comparator<NormalizationPlan> planComparator = new SplitPlanFirstComparator();\n+\n+  private Configuration conf;\n+  private MasterServices masterServices;\n+  private boolean splitEnabled;\n+  private boolean mergeEnabled;\n+  private int minRegionCount;\n+  private Period mergeMinRegionAge;\n+  private int mergeMinRegionSizeMb;\n+\n+  public SimpleRegionNormalizer() {\n+    splitEnabled = DEFAULT_SPLIT_ENABLED;\n+    mergeEnabled = DEFAULT_MERGE_ENABLED;\n+    minRegionCount = DEFAULT_MIN_REGION_COUNT;\n+    mergeMinRegionAge = Period.ofDays(DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    mergeMinRegionSizeMb = DEFAULT_MERGE_MIN_REGION_SIZE_MB;\n+  }\n \n   @Override\n-  public void planSkipped(RegionInfo hri, PlanType type) {\n-    skippedCount[type.ordinal()]++;\n+  public Configuration getConf() {\n+    return conf;\n   }\n \n   @Override\n-  public long getSkippedCount(NormalizationPlan.PlanType type) {\n-    return skippedCount[type.ordinal()];\n+  public void setConf(final Configuration conf) {\n+    if (conf == null) {\n+      return;\n+    }\n+    this.conf = conf;\n+    splitEnabled = conf.getBoolean(SPLIT_ENABLED_KEY, DEFAULT_SPLIT_ENABLED);\n+    mergeEnabled = conf.getBoolean(MERGE_ENABLED_KEY, DEFAULT_MERGE_ENABLED);\n+    minRegionCount = parseMinRegionCount(conf);\n+    mergeMinRegionAge = parseMergeMinRegionAge(conf);\n+    mergeMinRegionSizeMb = parseMergeMinRegionSizeMb(conf);\n+  }\n+\n+  private static int parseMinRegionCount(final Configuration conf) {\n+    final int parsedValue = conf.getInt(MIN_REGION_COUNT_KEY, DEFAULT_MIN_REGION_COUNT);\n+    final int settledValue = Math.max(1, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MIN_REGION_COUNT_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static Period parseMergeMinRegionAge(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_AGE_DAYS_KEY, DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_AGE_DAYS_KEY, parsedValue, settledValue);\n+    }\n+    return Period.ofDays(settledValue);\n+  }\n+\n+  private static int parseMergeMinRegionSizeMb(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_SIZE_MB_KEY, DEFAULT_MERGE_MIN_REGION_SIZE_MB);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_SIZE_MB_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static <T> void warnInvalidValue(final String key, final T parsedValue,\n+    final T settledValue) {\n+    LOG.warn(\"Configured value {}={} is invalid. Setting value to {}.\",\n+      key, parsedValue, settledValue);\n   }\n \n   /**\n-   * Comparator class that gives higher priority to region Split plan.\n+   * Return this instance's configured value for {@value SPLIT_ENABLED_KEY}.\n    */\n-  static class PlanComparator implements Comparator<NormalizationPlan> {\n-    @Override\n-    public int compare(NormalizationPlan plan1, NormalizationPlan plan2) {\n-      boolean plan1IsSplit = plan1 instanceof SplitNormalizationPlan;\n-      boolean plan2IsSplit = plan2 instanceof SplitNormalizationPlan;\n-      if (plan1IsSplit && plan2IsSplit) {\n-        return 0;\n-      } else if (plan1IsSplit) {\n-        return -1;\n-      } else if (plan2IsSplit) {\n-        return 1;\n-      } else {\n-        return 0;\n-      }\n-    }\n+  public boolean isSplitEnabled() {\n+    return splitEnabled;\n   }\n \n-  private Comparator<NormalizationPlan> planComparator = new PlanComparator();\n+  /**\n+   * Return this instance's configured value for {@value MERGE_ENABLED_KEY}.\n+   */\n+  public boolean isMergeEnabled() {\n+    return mergeEnabled;\n+  }\n \n   /**\n-   * Computes next most \"urgent\" normalization action on the table. Action may be either a split, or\n-   * a merge, or no action.\n-   * @param table table to normalize\n-   * @return normalization plan to execute\n+   * Return this instance's configured value for {@value MIN_REGION_COUNT_KEY}.\n+   */\n+  public int getMinRegionCount() {\n+    return minRegionCount;\n+  }\n+\n+  /**\n+   * Return this instance's configured value for {@value MERGE_MIN_REGION_AGE_DAYS_KEY}.\n    */\n+  public Period getMergeMinRegionAge() {\n+    return mergeMinRegionAge;\n+  }\n+\n+  /**\n+   * Return this instance's configured value for {@value MERGE_MIN_REGION_SIZE_MB_KEY}.\n+   */\n+  public int getMergeMinRegionSizeMb() {\n+    return mergeMinRegionSizeMb;\n+  }\n+\n   @Override\n-  public List<NormalizationPlan> computePlanForTable(TableName table) throws HBaseIOException {\n+  public void setMasterServices(final MasterServices masterServices) {\n+    this.masterServices = masterServices;\n+  }\n+\n+  @Override\n+  public void planSkipped(final RegionInfo hri, final PlanType type) {\n+    skippedCount[type.ordinal()]++;\n+  }\n+\n+  @Override\n+  public long getSkippedCount(NormalizationPlan.PlanType type) {\n+    return skippedCount[type.ordinal()];\n+  }\n+\n+  @Override\n+  public List<NormalizationPlan> computePlansForTable(TableName table) {\n     if (table == null || table.isSystemTable()) {\n       LOG.debug(\"Normalization of system table {} isn't allowed\", table);\n-      return null;\n+      return Collections.emptyList();\n     }\n-    boolean splitEnabled = isSplitEnabled();\n-    boolean mergeEnabled = isMergeEnabled();\n+    boolean splitEnabled = isSplitEnabled() && isMasterSwitchEnabled(MasterSwitchType.SPLIT);\n+    boolean mergeEnabled = isMergeEnabled() && isMasterSwitchEnabled(MasterSwitchType.MERGE);\n     if (!mergeEnabled && !splitEnabled) {\n-      LOG.debug(\"Both split and merge are disabled for table: {}\", table);\n-      return null;\n+      LOG.debug(\"Both split and merge are disabled. Skipping normalization of table: {}\", table);\n+      return Collections.emptyList();\n     }\n+\n     List<NormalizationPlan> plans = new ArrayList<>();\n-    List<RegionInfo> tableRegions =\n-        masterServices.getAssignmentManager().getRegionStates().getRegionsOfTable(table);\n+    List<RegionInfo> tableRegions = masterServices.getAssignmentManager()\n+      .getRegionStates()\n+      .getRegionsOfTable(table);\n \n-    if (tableRegions == null) {\n-      return null;\n+    if (CollectionUtils.isEmpty(tableRegions)) {\n+      return Collections.emptyList();\n     }\n \n     LOG.debug(\"Computing normalization plan for table:  {}, number of regions: {}\", table,\n       tableRegions.size());\n \n     if (splitEnabled) {\n-      List<NormalizationPlan> splitPlans = getSplitNormalizationPlan(table);\n-      if (splitPlans != null) {\n-        plans.addAll(splitPlans);\n+      plans.addAll(computeSplitNormalizationPlans(table));\n+    }\n+    if (mergeEnabled) {\n+      plans.addAll(computeMergeNormalizationPlans(table));\n+    }\n+\n+    plans.sort(planComparator);\n+    LOG.debug(\"Computed {} normalization plans for table {}\", plans.size(), table);\n+    return plans;\n+  }\n+\n+  /**\n+   * @return size of region in MB and if region is not found than -1\n+   */\n+  private long getRegionSizeMB(RegionInfo hri) {\n+    ServerName sn =\n+      masterServices.getAssignmentManager().getRegionStates().getRegionServerOfRegion(hri);\n+    RegionMetrics regionLoad =\n+      masterServices.getServerManager().getLoad(sn).getRegionMetrics().get(hri.getRegionName());\n+    if (regionLoad == null) {\n+      LOG.debug(\"{} was not found in RegionsLoad\", hri.getRegionNameAsString());\n+      return -1;\n+    }\n+    return (long) regionLoad.getStoreFileSize().get(Size.Unit.MEGABYTE);\n+  }\n+\n+  private boolean isMasterSwitchEnabled(final MasterSwitchType masterSwitchType) {\n+    return masterServices.isSplitOrMergeEnabled(masterSwitchType);\n+  }\n+\n+  /**\n+   * @param tableRegions regions of table to normalize\n+   * @return average region size depending on\n+   * @see org.apache.hadoop.hbase.client.TableDescriptor#getNormalizerTargetRegionCount()\n+   * Also make sure tableRegions contains regions of the same table\n+   */\n+  private double getAverageRegionSize(List<RegionInfo> tableRegions) {\n+    if (CollectionUtils.isEmpty(tableRegions)) {\n+      throw new IllegalStateException(\n+        \"Cannot calculate average size of a table without any regions.\");\n+    }\n+    final int regionCount = tableRegions.size();\n+    final long totalSizeMb = tableRegions.stream()\n+      .mapToLong(this::getRegionSizeMB)\n+      .sum();\n+    TableName table = tableRegions.get(0).getTable();\n+    int targetRegionCount = -1;\n+    long targetRegionSize = -1;\n+    try {\n+      TableDescriptor tableDescriptor = masterServices.getTableDescriptors().get(table);\n+      if (tableDescriptor != null) {\n+        targetRegionCount = tableDescriptor.getNormalizerTargetRegionCount();\n+        targetRegionSize = tableDescriptor.getNormalizerTargetRegionSize();\n+        LOG.debug(\"Table {} configured with target region count {}, target region size {}\", table,\n+          targetRegionCount, targetRegionSize);\n       }\n+    } catch (IOException e) {\n+      LOG.warn(\"TableDescriptor for {} unavailable, table-level target region count and size\"\n+        + \" configurations cannot be considered.\", table, e);\n     }\n \n-    if (mergeEnabled) {\n-      if (tableRegions.size() < minRegionCount) {\n-        LOG.debug(\"Table {} has {} regions, required min number of regions for normalizer to run\" +\n-                \" is {}, not running normalizer\",\n-            table, tableRegions.size(), minRegionCount);\n-      } else {\n-        List<NormalizationPlan> mergePlans = getMergeNormalizationPlan(table);\n-        if (mergePlans != null) {\n-          plans.addAll(mergePlans);\n-        }\n+    double avgRegionSize;\n+    if (targetRegionSize > 0) {\n+      avgRegionSize = targetRegionSize;\n+    } else if (targetRegionCount > 0) {\n+      avgRegionSize = totalSizeMb / (double) targetRegionCount;\n+    } else {\n+      avgRegionSize = totalSizeMb / (double) regionCount;\n+    }\n+\n+    LOG.debug(\"Table {}, total aggregated regions size: {} and average region size {}\", table,\n+      totalSizeMb, avgRegionSize);\n+    return avgRegionSize;\n+  }\n+\n+  /**\n+   * Determine if a {@link RegionInfo} should be considered for a merge operation.\n+   */\n+  private boolean skipForMerge(final RegionStates regionStates, final RegionInfo regionInfo) {\n+    final RegionState state = regionStates.getRegionState(regionInfo);\n+    final String name = regionInfo.getEncodedName();\n+    return\n+      logTraceReason(\n+        () -> state == null,\n+        \"skipping merge of region {} because no state information is available.\", name)\n+        || logTraceReason(\n+          () -> !Objects.equals(state.getState(), RegionState.State.OPEN),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 384}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQyNzU2OA==", "bodyText": "shrug personal taste. Long ago I made a habit of using the static equals because of its null-safety. This way I never accidentally stumble into an NPE during these checks.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431427568", "createdAt": "2020-05-27T20:38:36Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,436 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>\n+ *   <li>Otherwise, for the next region in the chain R1, if R0 + R1 is smaller then S, R0 and R1\n+ *     are kindly requested to merge.</li>\n+ * </ol>\n+ * <p>\n+ * The following parameters are configurable:\n+ * <ol>\n+ *   <li>Whether to split a region as part of normalization. Configuration:\n+ *     {@value SPLIT_ENABLED_KEY}, default: {@value DEFAULT_SPLIT_ENABLED}.</li>\n+ *   <li>Whether to merge a region as part of normalization. Configuration:\n+ *     {@value MERGE_ENABLED_KEY}, default: {@value DEFAULT_MERGE_ENABLED}.</li>\n+ *   <li>The minimum number of regions in a table to consider it for normalization. Configuration:\n+ *     {@value MIN_REGION_COUNT_KEY}, default: {@value DEFAULT_MIN_REGION_COUNT}.</li>\n+ *   <li>The minimum age for a region to be considered for a merge, in days. Configuration:\n+ *     {@value MERGE_MIN_REGION_AGE_DAYS_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_AGE_DAYS}.</li>\n+ *   <li>The minimum size for a region to be considered for a merge, in whole MBs. Configuration:\n+ *     {@value MERGE_MIN_REGION_SIZE_MB_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_SIZE_MB}.</li>\n  * </ol>\n  * <p>\n- * Region sizes are coarse and approximate on the order of megabytes. Additionally, \"empty\" regions\n- * (less than 1MB, with the previous note) are not merged away. This is by design to prevent\n- * normalization from undoing the pre-splitting of a table.\n+ * To see detailed logging of the application of these configuration values, set the log level for\n+ * this class to `TRACE`.\n  */\n-@InterfaceAudience.Private\n-public class SimpleRegionNormalizer extends AbstractRegionNormalizer {\n-\n+@InterfaceAudience.LimitedPrivate(HBaseInterfaceAudience.CONFIG)\n+public class SimpleRegionNormalizer implements RegionNormalizer {\n   private static final Logger LOG = LoggerFactory.getLogger(SimpleRegionNormalizer.class);\n-  private static long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+\n+  static final String SPLIT_ENABLED_KEY = \"hbase.normalizer.split.enabled\";\n+  static final boolean DEFAULT_SPLIT_ENABLED = true;\n+  static final String MERGE_ENABLED_KEY = \"hbase.normalizer.merge.enabled\";\n+  static final boolean DEFAULT_MERGE_ENABLED = true;\n+  // TODO: after HBASE-24416, `min.region.count` only applies to merge plans; should\n+  //  deprecate/rename the configuration key.\n+  static final String MIN_REGION_COUNT_KEY = \"hbase.normalizer.min.region.count\";\n+  static final int DEFAULT_MIN_REGION_COUNT = 3;\n+  static final String MERGE_MIN_REGION_AGE_DAYS_KEY = \"hbase.normalizer.merge.min_region_age.days\";\n+  static final int DEFAULT_MERGE_MIN_REGION_AGE_DAYS = 3;\n+  static final String MERGE_MIN_REGION_SIZE_MB_KEY = \"hbase.normalizer.merge.min_region_size.mb\";\n+  static final int DEFAULT_MERGE_MIN_REGION_SIZE_MB = 1;\n+\n+  private final long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+  private final Comparator<NormalizationPlan> planComparator = new SplitPlanFirstComparator();\n+\n+  private Configuration conf;\n+  private MasterServices masterServices;\n+  private boolean splitEnabled;\n+  private boolean mergeEnabled;\n+  private int minRegionCount;\n+  private Period mergeMinRegionAge;\n+  private int mergeMinRegionSizeMb;\n+\n+  public SimpleRegionNormalizer() {\n+    splitEnabled = DEFAULT_SPLIT_ENABLED;\n+    mergeEnabled = DEFAULT_MERGE_ENABLED;\n+    minRegionCount = DEFAULT_MIN_REGION_COUNT;\n+    mergeMinRegionAge = Period.ofDays(DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    mergeMinRegionSizeMb = DEFAULT_MERGE_MIN_REGION_SIZE_MB;\n+  }\n \n   @Override\n-  public void planSkipped(RegionInfo hri, PlanType type) {\n-    skippedCount[type.ordinal()]++;\n+  public Configuration getConf() {\n+    return conf;\n   }\n \n   @Override\n-  public long getSkippedCount(NormalizationPlan.PlanType type) {\n-    return skippedCount[type.ordinal()];\n+  public void setConf(final Configuration conf) {\n+    if (conf == null) {\n+      return;\n+    }\n+    this.conf = conf;\n+    splitEnabled = conf.getBoolean(SPLIT_ENABLED_KEY, DEFAULT_SPLIT_ENABLED);\n+    mergeEnabled = conf.getBoolean(MERGE_ENABLED_KEY, DEFAULT_MERGE_ENABLED);\n+    minRegionCount = parseMinRegionCount(conf);\n+    mergeMinRegionAge = parseMergeMinRegionAge(conf);\n+    mergeMinRegionSizeMb = parseMergeMinRegionSizeMb(conf);\n+  }\n+\n+  private static int parseMinRegionCount(final Configuration conf) {\n+    final int parsedValue = conf.getInt(MIN_REGION_COUNT_KEY, DEFAULT_MIN_REGION_COUNT);\n+    final int settledValue = Math.max(1, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MIN_REGION_COUNT_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static Period parseMergeMinRegionAge(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_AGE_DAYS_KEY, DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_AGE_DAYS_KEY, parsedValue, settledValue);\n+    }\n+    return Period.ofDays(settledValue);\n+  }\n+\n+  private static int parseMergeMinRegionSizeMb(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_SIZE_MB_KEY, DEFAULT_MERGE_MIN_REGION_SIZE_MB);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_SIZE_MB_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static <T> void warnInvalidValue(final String key, final T parsedValue,\n+    final T settledValue) {\n+    LOG.warn(\"Configured value {}={} is invalid. Setting value to {}.\",\n+      key, parsedValue, settledValue);\n   }\n \n   /**\n-   * Comparator class that gives higher priority to region Split plan.\n+   * Return this instance's configured value for {@value SPLIT_ENABLED_KEY}.\n    */\n-  static class PlanComparator implements Comparator<NormalizationPlan> {\n-    @Override\n-    public int compare(NormalizationPlan plan1, NormalizationPlan plan2) {\n-      boolean plan1IsSplit = plan1 instanceof SplitNormalizationPlan;\n-      boolean plan2IsSplit = plan2 instanceof SplitNormalizationPlan;\n-      if (plan1IsSplit && plan2IsSplit) {\n-        return 0;\n-      } else if (plan1IsSplit) {\n-        return -1;\n-      } else if (plan2IsSplit) {\n-        return 1;\n-      } else {\n-        return 0;\n-      }\n-    }\n+  public boolean isSplitEnabled() {\n+    return splitEnabled;\n   }\n \n-  private Comparator<NormalizationPlan> planComparator = new PlanComparator();\n+  /**\n+   * Return this instance's configured value for {@value MERGE_ENABLED_KEY}.\n+   */\n+  public boolean isMergeEnabled() {\n+    return mergeEnabled;\n+  }\n \n   /**\n-   * Computes next most \"urgent\" normalization action on the table. Action may be either a split, or\n-   * a merge, or no action.\n-   * @param table table to normalize\n-   * @return normalization plan to execute\n+   * Return this instance's configured value for {@value MIN_REGION_COUNT_KEY}.\n+   */\n+  public int getMinRegionCount() {\n+    return minRegionCount;\n+  }\n+\n+  /**\n+   * Return this instance's configured value for {@value MERGE_MIN_REGION_AGE_DAYS_KEY}.\n    */\n+  public Period getMergeMinRegionAge() {\n+    return mergeMinRegionAge;\n+  }\n+\n+  /**\n+   * Return this instance's configured value for {@value MERGE_MIN_REGION_SIZE_MB_KEY}.\n+   */\n+  public int getMergeMinRegionSizeMb() {\n+    return mergeMinRegionSizeMb;\n+  }\n+\n   @Override\n-  public List<NormalizationPlan> computePlanForTable(TableName table) throws HBaseIOException {\n+  public void setMasterServices(final MasterServices masterServices) {\n+    this.masterServices = masterServices;\n+  }\n+\n+  @Override\n+  public void planSkipped(final RegionInfo hri, final PlanType type) {\n+    skippedCount[type.ordinal()]++;\n+  }\n+\n+  @Override\n+  public long getSkippedCount(NormalizationPlan.PlanType type) {\n+    return skippedCount[type.ordinal()];\n+  }\n+\n+  @Override\n+  public List<NormalizationPlan> computePlansForTable(TableName table) {\n     if (table == null || table.isSystemTable()) {\n       LOG.debug(\"Normalization of system table {} isn't allowed\", table);\n-      return null;\n+      return Collections.emptyList();\n     }\n-    boolean splitEnabled = isSplitEnabled();\n-    boolean mergeEnabled = isMergeEnabled();\n+    boolean splitEnabled = isSplitEnabled() && isMasterSwitchEnabled(MasterSwitchType.SPLIT);\n+    boolean mergeEnabled = isMergeEnabled() && isMasterSwitchEnabled(MasterSwitchType.MERGE);\n     if (!mergeEnabled && !splitEnabled) {\n-      LOG.debug(\"Both split and merge are disabled for table: {}\", table);\n-      return null;\n+      LOG.debug(\"Both split and merge are disabled. Skipping normalization of table: {}\", table);\n+      return Collections.emptyList();\n     }\n+\n     List<NormalizationPlan> plans = new ArrayList<>();\n-    List<RegionInfo> tableRegions =\n-        masterServices.getAssignmentManager().getRegionStates().getRegionsOfTable(table);\n+    List<RegionInfo> tableRegions = masterServices.getAssignmentManager()\n+      .getRegionStates()\n+      .getRegionsOfTable(table);\n \n-    if (tableRegions == null) {\n-      return null;\n+    if (CollectionUtils.isEmpty(tableRegions)) {\n+      return Collections.emptyList();\n     }\n \n     LOG.debug(\"Computing normalization plan for table:  {}, number of regions: {}\", table,\n       tableRegions.size());\n \n     if (splitEnabled) {\n-      List<NormalizationPlan> splitPlans = getSplitNormalizationPlan(table);\n-      if (splitPlans != null) {\n-        plans.addAll(splitPlans);\n+      plans.addAll(computeSplitNormalizationPlans(table));\n+    }\n+    if (mergeEnabled) {\n+      plans.addAll(computeMergeNormalizationPlans(table));\n+    }\n+\n+    plans.sort(planComparator);\n+    LOG.debug(\"Computed {} normalization plans for table {}\", plans.size(), table);\n+    return plans;\n+  }\n+\n+  /**\n+   * @return size of region in MB and if region is not found than -1\n+   */\n+  private long getRegionSizeMB(RegionInfo hri) {\n+    ServerName sn =\n+      masterServices.getAssignmentManager().getRegionStates().getRegionServerOfRegion(hri);\n+    RegionMetrics regionLoad =\n+      masterServices.getServerManager().getLoad(sn).getRegionMetrics().get(hri.getRegionName());\n+    if (regionLoad == null) {\n+      LOG.debug(\"{} was not found in RegionsLoad\", hri.getRegionNameAsString());\n+      return -1;\n+    }\n+    return (long) regionLoad.getStoreFileSize().get(Size.Unit.MEGABYTE);\n+  }\n+\n+  private boolean isMasterSwitchEnabled(final MasterSwitchType masterSwitchType) {\n+    return masterServices.isSplitOrMergeEnabled(masterSwitchType);\n+  }\n+\n+  /**\n+   * @param tableRegions regions of table to normalize\n+   * @return average region size depending on\n+   * @see org.apache.hadoop.hbase.client.TableDescriptor#getNormalizerTargetRegionCount()\n+   * Also make sure tableRegions contains regions of the same table\n+   */\n+  private double getAverageRegionSize(List<RegionInfo> tableRegions) {\n+    if (CollectionUtils.isEmpty(tableRegions)) {\n+      throw new IllegalStateException(\n+        \"Cannot calculate average size of a table without any regions.\");\n+    }\n+    final int regionCount = tableRegions.size();\n+    final long totalSizeMb = tableRegions.stream()\n+      .mapToLong(this::getRegionSizeMB)\n+      .sum();\n+    TableName table = tableRegions.get(0).getTable();\n+    int targetRegionCount = -1;\n+    long targetRegionSize = -1;\n+    try {\n+      TableDescriptor tableDescriptor = masterServices.getTableDescriptors().get(table);\n+      if (tableDescriptor != null) {\n+        targetRegionCount = tableDescriptor.getNormalizerTargetRegionCount();\n+        targetRegionSize = tableDescriptor.getNormalizerTargetRegionSize();\n+        LOG.debug(\"Table {} configured with target region count {}, target region size {}\", table,\n+          targetRegionCount, targetRegionSize);\n       }\n+    } catch (IOException e) {\n+      LOG.warn(\"TableDescriptor for {} unavailable, table-level target region count and size\"\n+        + \" configurations cannot be considered.\", table, e);\n     }\n \n-    if (mergeEnabled) {\n-      if (tableRegions.size() < minRegionCount) {\n-        LOG.debug(\"Table {} has {} regions, required min number of regions for normalizer to run\" +\n-                \" is {}, not running normalizer\",\n-            table, tableRegions.size(), minRegionCount);\n-      } else {\n-        List<NormalizationPlan> mergePlans = getMergeNormalizationPlan(table);\n-        if (mergePlans != null) {\n-          plans.addAll(mergePlans);\n-        }\n+    double avgRegionSize;\n+    if (targetRegionSize > 0) {\n+      avgRegionSize = targetRegionSize;\n+    } else if (targetRegionCount > 0) {\n+      avgRegionSize = totalSizeMb / (double) targetRegionCount;\n+    } else {\n+      avgRegionSize = totalSizeMb / (double) regionCount;\n+    }\n+\n+    LOG.debug(\"Table {}, total aggregated regions size: {} and average region size {}\", table,\n+      totalSizeMb, avgRegionSize);\n+    return avgRegionSize;\n+  }\n+\n+  /**\n+   * Determine if a {@link RegionInfo} should be considered for a merge operation.\n+   */\n+  private boolean skipForMerge(final RegionStates regionStates, final RegionInfo regionInfo) {\n+    final RegionState state = regionStates.getRegionState(regionInfo);\n+    final String name = regionInfo.getEncodedName();\n+    return\n+      logTraceReason(\n+        () -> state == null,\n+        \"skipping merge of region {} because no state information is available.\", name)\n+        || logTraceReason(\n+          () -> !Objects.equals(state.getState(), RegionState.State.OPEN),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTE4ODg5OQ=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 384}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4NTg3MTU3OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxNToxMzoyOVrOGbPhzg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QyMDo1MjowNVrOGbcrug==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTIxOTE1MA==", "bodyText": "Does normalizer run as a chore? If so, chores already have mechanism for ensuring one run at a time.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431219150", "createdAt": "2020-05-27T15:13:29Z", "author": {"login": "saintstack"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "diffHunk": "@@ -400,6 +401,8 @@ public void run() {\n   private final LockManager lockManager = new LockManager(this);\n \n   private RSGroupBasedLoadBalancer balancer;\n+  // a lock to prevent concurrent normalization actions.\n+  private final ReentrantLock normalizationInProgressLock = new ReentrantLock();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM4MzY4OA==", "bodyText": "It can also run from cli.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431383688", "createdAt": "2020-05-27T19:15:21Z", "author": {"login": "huaxiangsun"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "diffHunk": "@@ -400,6 +401,8 @@ public void run() {\n   private final LockManager lockManager = new LockManager(this);\n \n   private RSGroupBasedLoadBalancer balancer;\n+  // a lock to prevent concurrent normalization actions.\n+  private final ReentrantLock normalizationInProgressLock = new ReentrantLock();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTIxOTE1MA=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQzNDY4Mg==", "bodyText": "There is a RegionNormalizerChore, yes. It invokes master.normalizeRegions(). However, the same method can also be called from MasterRpcServices, so this lock (previously a synchronized(normalizer) block) prevents the chore and an operator invocation from colliding.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431434682", "createdAt": "2020-05-27T20:52:05Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "diffHunk": "@@ -400,6 +401,8 @@ public void run() {\n   private final LockManager lockManager = new LockManager(this);\n \n   private RSGroupBasedLoadBalancer balancer;\n+  // a lock to prevent concurrent normalization actions.\n+  private final ReentrantLock normalizationInProgressLock = new ReentrantLock();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTIxOTE1MA=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4NTg4NDYxOnYy", "diffSide": "LEFT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxNToxNjowN1rOGbPqAA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QyMDo1Mjo0N1rOGbctNQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTIyMTI0OA==", "bodyText": "Yeah, this odd... Why do this when it has master passed.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431221248", "createdAt": "2020-05-27T15:16:07Z", "author": {"login": "saintstack"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "diffHunk": "@@ -797,7 +800,6 @@ protected void initializeZKBasedSystemTrackers()\n     this.balancer.setConf(conf);\n     this.normalizer = RegionNormalizerFactory.getRegionNormalizer(conf);\n     this.normalizer.setMasterServices(this);\n-    this.normalizer.setMasterRpcServices((MasterRpcServices)rpcServices);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQzNTA2MQ==", "bodyText": "It was using masterRpcServices to reach out to check the split and merge switches. I've replaced that with direct calls using masterServices.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431435061", "createdAt": "2020-05-27T20:52:47Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "diffHunk": "@@ -797,7 +800,6 @@ protected void initializeZKBasedSystemTrackers()\n     this.balancer.setConf(conf);\n     this.normalizer = RegionNormalizerFactory.getRegionNormalizer(conf);\n     this.normalizer.setMasterServices(this);\n-    this.normalizer.setMasterRpcServices((MasterRpcServices)rpcServices);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTIyMTI0OA=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4NTkwOTg2OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxNToyMTo0NVrOGbP6PQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QyMDo1Nzo1M1rOGbc31g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTIyNTQwNQ==", "bodyText": "Wondering why lock is not internal to the normalizer... why it is out here in Master.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431225405", "createdAt": "2020-05-27T15:21:45Z", "author": {"login": "saintstack"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "diffHunk": "@@ -1911,43 +1912,51 @@ public boolean normalizeRegions() throws IOException {\n       return false;\n     }\n \n-    synchronized (this.normalizer) {\n+    if (!normalizationInProgressLock.tryLock()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQzNzc4Mg==", "bodyText": "It hangs out here on the master because, sadly, a bunch of logic is implemented in HMaster. All the stuff about deciding which tables to normalize and actual execution of the generated plans happens in Master#normalizeRegions (under the same lock we were just discussing). I don't love this design, but I think it does make sense that a normalizer algorithm exist mostly outside of the context of the master context in which it runs. If I were to make the master more of a composition, I would implement a class called something like NormalizationService, which was responsible for instantiating the instance of the Normalizer algorithm, registering the Chore and being the delegation target for invocations coming from RPC. The lock would be internal to this NormalizationService.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431437782", "createdAt": "2020-05-27T20:57:53Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "diffHunk": "@@ -1911,43 +1912,51 @@ public boolean normalizeRegions() throws IOException {\n       return false;\n     }\n \n-    synchronized (this.normalizer) {\n+    if (!normalizationInProgressLock.tryLock()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTIyNTQwNQ=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4NTk2NTg5OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxNTozMToxNlrOGbQdLA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QyMDo1OTowNlrOGbc6Ow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTIzNDM0OA==", "bodyText": "Return true? Don't want to move to the next table?", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431234348", "createdAt": "2020-05-27T15:31:16Z", "author": {"login": "saintstack"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "diffHunk": "@@ -1911,43 +1912,51 @@ public boolean normalizeRegions() throws IOException {\n       return false;\n     }\n \n-    synchronized (this.normalizer) {\n+    if (!normalizationInProgressLock.tryLock()) {\n       // Don't run the normalizer concurrently\n+      LOG.info(\"Normalization already in progress. Skipping request.\");\n+    } else {\n+      try {\n+        List<TableName> allEnabledTables = new ArrayList<>(\n+          tableStateManager.getTablesInStates(TableState.State.ENABLED));\n+        Collections.shuffle(allEnabledTables);\n \n-      List<TableName> allEnabledTables = new ArrayList<>(\n-        this.tableStateManager.getTablesInStates(TableState.State.ENABLED));\n-\n-      Collections.shuffle(allEnabledTables);\n-\n-      for (TableName table : allEnabledTables) {\n-        TableDescriptor tblDesc = getTableDescriptors().get(table);\n-        if (table.isSystemTable() || (tblDesc != null &&\n-            !tblDesc.isNormalizationEnabled())) {\n-          LOG.trace(\"Skipping normalization for {}, as it's either system\"\n-              + \" table or doesn't have auto normalization turned on\", table);\n-          continue;\n-        }\n+        for (TableName table : allEnabledTables) {\n+          if (table.isSystemTable()) {\n+            continue;\n+          }\n+          final TableDescriptor tblDesc = getTableDescriptors().get(table);\n+          if (tblDesc != null && !tblDesc.isNormalizationEnabled()) {\n+            LOG.debug(\n+              \"Skipping {} because normalization is disabled in its table properties.\", table);\n+            continue;\n+          }\n \n-        // make one last check that the cluster isn't shutting down before proceeding.\n-        if (skipRegionManagementAction(\"region normalizer\")) {\n-          return false;\n-        }\n+          // make one last check that the cluster isn't shutting down before proceeding.\n+          if (skipRegionManagementAction(\"region normalizer\")) {\n+            return false;\n+          }\n \n-        final List<NormalizationPlan> plans = this.normalizer.computePlanForTable(table);\n-        if (CollectionUtils.isEmpty(plans)) {\n-          return true;\n-        }\n+          final List<NormalizationPlan> plans = normalizer.computePlansForTable(table);\n+          if (CollectionUtils.isEmpty(plans)) {\n+            return true;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 86}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM5NTMwMw==", "bodyText": "+1, that is the original issue. It should be \"continue\" here.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431395303", "createdAt": "2020-05-27T19:34:07Z", "author": {"login": "huaxiangsun"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "diffHunk": "@@ -1911,43 +1912,51 @@ public boolean normalizeRegions() throws IOException {\n       return false;\n     }\n \n-    synchronized (this.normalizer) {\n+    if (!normalizationInProgressLock.tryLock()) {\n       // Don't run the normalizer concurrently\n+      LOG.info(\"Normalization already in progress. Skipping request.\");\n+    } else {\n+      try {\n+        List<TableName> allEnabledTables = new ArrayList<>(\n+          tableStateManager.getTablesInStates(TableState.State.ENABLED));\n+        Collections.shuffle(allEnabledTables);\n \n-      List<TableName> allEnabledTables = new ArrayList<>(\n-        this.tableStateManager.getTablesInStates(TableState.State.ENABLED));\n-\n-      Collections.shuffle(allEnabledTables);\n-\n-      for (TableName table : allEnabledTables) {\n-        TableDescriptor tblDesc = getTableDescriptors().get(table);\n-        if (table.isSystemTable() || (tblDesc != null &&\n-            !tblDesc.isNormalizationEnabled())) {\n-          LOG.trace(\"Skipping normalization for {}, as it's either system\"\n-              + \" table or doesn't have auto normalization turned on\", table);\n-          continue;\n-        }\n+        for (TableName table : allEnabledTables) {\n+          if (table.isSystemTable()) {\n+            continue;\n+          }\n+          final TableDescriptor tblDesc = getTableDescriptors().get(table);\n+          if (tblDesc != null && !tblDesc.isNormalizationEnabled()) {\n+            LOG.debug(\n+              \"Skipping {} because normalization is disabled in its table properties.\", table);\n+            continue;\n+          }\n \n-        // make one last check that the cluster isn't shutting down before proceeding.\n-        if (skipRegionManagementAction(\"region normalizer\")) {\n-          return false;\n-        }\n+          // make one last check that the cluster isn't shutting down before proceeding.\n+          if (skipRegionManagementAction(\"region normalizer\")) {\n+            return false;\n+          }\n \n-        final List<NormalizationPlan> plans = this.normalizer.computePlanForTable(table);\n-        if (CollectionUtils.isEmpty(plans)) {\n-          return true;\n-        }\n+          final List<NormalizationPlan> plans = normalizer.computePlansForTable(table);\n+          if (CollectionUtils.isEmpty(plans)) {\n+            return true;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTIzNDM0OA=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 86}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQzODM5NQ==", "bodyText": "Yikes! good point.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431438395", "createdAt": "2020-05-27T20:59:06Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "diffHunk": "@@ -1911,43 +1912,51 @@ public boolean normalizeRegions() throws IOException {\n       return false;\n     }\n \n-    synchronized (this.normalizer) {\n+    if (!normalizationInProgressLock.tryLock()) {\n       // Don't run the normalizer concurrently\n+      LOG.info(\"Normalization already in progress. Skipping request.\");\n+    } else {\n+      try {\n+        List<TableName> allEnabledTables = new ArrayList<>(\n+          tableStateManager.getTablesInStates(TableState.State.ENABLED));\n+        Collections.shuffle(allEnabledTables);\n \n-      List<TableName> allEnabledTables = new ArrayList<>(\n-        this.tableStateManager.getTablesInStates(TableState.State.ENABLED));\n-\n-      Collections.shuffle(allEnabledTables);\n-\n-      for (TableName table : allEnabledTables) {\n-        TableDescriptor tblDesc = getTableDescriptors().get(table);\n-        if (table.isSystemTable() || (tblDesc != null &&\n-            !tblDesc.isNormalizationEnabled())) {\n-          LOG.trace(\"Skipping normalization for {}, as it's either system\"\n-              + \" table or doesn't have auto normalization turned on\", table);\n-          continue;\n-        }\n+        for (TableName table : allEnabledTables) {\n+          if (table.isSystemTable()) {\n+            continue;\n+          }\n+          final TableDescriptor tblDesc = getTableDescriptors().get(table);\n+          if (tblDesc != null && !tblDesc.isNormalizationEnabled()) {\n+            LOG.debug(\n+              \"Skipping {} because normalization is disabled in its table properties.\", table);\n+            continue;\n+          }\n \n-        // make one last check that the cluster isn't shutting down before proceeding.\n-        if (skipRegionManagementAction(\"region normalizer\")) {\n-          return false;\n-        }\n+          // make one last check that the cluster isn't shutting down before proceeding.\n+          if (skipRegionManagementAction(\"region normalizer\")) {\n+            return false;\n+          }\n \n-        final List<NormalizationPlan> plans = this.normalizer.computePlanForTable(table);\n-        if (CollectionUtils.isEmpty(plans)) {\n-          return true;\n-        }\n+          final List<NormalizationPlan> plans = normalizer.computePlansForTable(table);\n+          if (CollectionUtils.isEmpty(plans)) {\n+            return true;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTIzNDM0OA=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 86}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4NjAwMzYzOnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "isResolved": true, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxNTozOToyNlrOGbQ0xw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQyMzowNjo0MFrOGcJqig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI0MDM5MQ==", "bodyText": "Should we then limit how much we schedule per invocation?", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431240391", "createdAt": "2020-05-27T15:39:26Z", "author": {"login": "saintstack"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "diffHunk": "@@ -1911,43 +1912,51 @@ public boolean normalizeRegions() throws IOException {\n       return false;\n     }\n \n-    synchronized (this.normalizer) {\n+    if (!normalizationInProgressLock.tryLock()) {\n       // Don't run the normalizer concurrently\n+      LOG.info(\"Normalization already in progress. Skipping request.\");\n+    } else {\n+      try {\n+        List<TableName> allEnabledTables = new ArrayList<>(\n+          tableStateManager.getTablesInStates(TableState.State.ENABLED));\n+        Collections.shuffle(allEnabledTables);\n \n-      List<TableName> allEnabledTables = new ArrayList<>(\n-        this.tableStateManager.getTablesInStates(TableState.State.ENABLED));\n-\n-      Collections.shuffle(allEnabledTables);\n-\n-      for (TableName table : allEnabledTables) {\n-        TableDescriptor tblDesc = getTableDescriptors().get(table);\n-        if (table.isSystemTable() || (tblDesc != null &&\n-            !tblDesc.isNormalizationEnabled())) {\n-          LOG.trace(\"Skipping normalization for {}, as it's either system\"\n-              + \" table or doesn't have auto normalization turned on\", table);\n-          continue;\n-        }\n+        for (TableName table : allEnabledTables) {\n+          if (table.isSystemTable()) {\n+            continue;\n+          }\n+          final TableDescriptor tblDesc = getTableDescriptors().get(table);\n+          if (tblDesc != null && !tblDesc.isNormalizationEnabled()) {\n+            LOG.debug(\n+              \"Skipping {} because normalization is disabled in its table properties.\", table);\n+            continue;\n+          }\n \n-        // make one last check that the cluster isn't shutting down before proceeding.\n-        if (skipRegionManagementAction(\"region normalizer\")) {\n-          return false;\n-        }\n+          // make one last check that the cluster isn't shutting down before proceeding.\n+          if (skipRegionManagementAction(\"region normalizer\")) {\n+            return false;\n+          }\n \n-        final List<NormalizationPlan> plans = this.normalizer.computePlanForTable(table);\n-        if (CollectionUtils.isEmpty(plans)) {\n-          return true;\n-        }\n+          final List<NormalizationPlan> plans = normalizer.computePlansForTable(table);\n+          if (CollectionUtils.isEmpty(plans)) {\n+            return true;\n+          }\n \n-        try (final Admin admin = asyncClusterConnection.toConnection().getAdmin()) {\n-          for (NormalizationPlan plan : plans) {\n-            plan.execute(admin);\n-            if (plan.getType() == PlanType.SPLIT) {\n-              splitPlanCount++;\n-            } else if (plan.getType() == PlanType.MERGE) {\n-              mergePlanCount++;\n+          try (final Admin admin = asyncClusterConnection.toConnection().getAdmin()) {\n+            // as of this writing, `plan.execute()` is non-blocking, so there's no artificial rate-\n+            // limiting of merge requests due to this serial loop.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI0MDU4OQ==", "bodyText": "...so as not to provoke a storm?", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431240589", "createdAt": "2020-05-27T15:39:39Z", "author": {"login": "saintstack"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "diffHunk": "@@ -1911,43 +1912,51 @@ public boolean normalizeRegions() throws IOException {\n       return false;\n     }\n \n-    synchronized (this.normalizer) {\n+    if (!normalizationInProgressLock.tryLock()) {\n       // Don't run the normalizer concurrently\n+      LOG.info(\"Normalization already in progress. Skipping request.\");\n+    } else {\n+      try {\n+        List<TableName> allEnabledTables = new ArrayList<>(\n+          tableStateManager.getTablesInStates(TableState.State.ENABLED));\n+        Collections.shuffle(allEnabledTables);\n \n-      List<TableName> allEnabledTables = new ArrayList<>(\n-        this.tableStateManager.getTablesInStates(TableState.State.ENABLED));\n-\n-      Collections.shuffle(allEnabledTables);\n-\n-      for (TableName table : allEnabledTables) {\n-        TableDescriptor tblDesc = getTableDescriptors().get(table);\n-        if (table.isSystemTable() || (tblDesc != null &&\n-            !tblDesc.isNormalizationEnabled())) {\n-          LOG.trace(\"Skipping normalization for {}, as it's either system\"\n-              + \" table or doesn't have auto normalization turned on\", table);\n-          continue;\n-        }\n+        for (TableName table : allEnabledTables) {\n+          if (table.isSystemTable()) {\n+            continue;\n+          }\n+          final TableDescriptor tblDesc = getTableDescriptors().get(table);\n+          if (tblDesc != null && !tblDesc.isNormalizationEnabled()) {\n+            LOG.debug(\n+              \"Skipping {} because normalization is disabled in its table properties.\", table);\n+            continue;\n+          }\n \n-        // make one last check that the cluster isn't shutting down before proceeding.\n-        if (skipRegionManagementAction(\"region normalizer\")) {\n-          return false;\n-        }\n+          // make one last check that the cluster isn't shutting down before proceeding.\n+          if (skipRegionManagementAction(\"region normalizer\")) {\n+            return false;\n+          }\n \n-        final List<NormalizationPlan> plans = this.normalizer.computePlanForTable(table);\n-        if (CollectionUtils.isEmpty(plans)) {\n-          return true;\n-        }\n+          final List<NormalizationPlan> plans = normalizer.computePlansForTable(table);\n+          if (CollectionUtils.isEmpty(plans)) {\n+            return true;\n+          }\n \n-        try (final Admin admin = asyncClusterConnection.toConnection().getAdmin()) {\n-          for (NormalizationPlan plan : plans) {\n-            plan.execute(admin);\n-            if (plan.getType() == PlanType.SPLIT) {\n-              splitPlanCount++;\n-            } else if (plan.getType() == PlanType.MERGE) {\n-              mergePlanCount++;\n+          try (final Admin admin = asyncClusterConnection.toConnection().getAdmin()) {\n+            // as of this writing, `plan.execute()` is non-blocking, so there's no artificial rate-\n+            // limiting of merge requests due to this serial loop.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI0MDM5MQ=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI0MzM5OQ==", "bodyText": "Oh, I see that you can limit work done with RegionNormalizer configuration", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431243399", "createdAt": "2020-05-27T15:43:26Z", "author": {"login": "saintstack"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "diffHunk": "@@ -1911,43 +1912,51 @@ public boolean normalizeRegions() throws IOException {\n       return false;\n     }\n \n-    synchronized (this.normalizer) {\n+    if (!normalizationInProgressLock.tryLock()) {\n       // Don't run the normalizer concurrently\n+      LOG.info(\"Normalization already in progress. Skipping request.\");\n+    } else {\n+      try {\n+        List<TableName> allEnabledTables = new ArrayList<>(\n+          tableStateManager.getTablesInStates(TableState.State.ENABLED));\n+        Collections.shuffle(allEnabledTables);\n \n-      List<TableName> allEnabledTables = new ArrayList<>(\n-        this.tableStateManager.getTablesInStates(TableState.State.ENABLED));\n-\n-      Collections.shuffle(allEnabledTables);\n-\n-      for (TableName table : allEnabledTables) {\n-        TableDescriptor tblDesc = getTableDescriptors().get(table);\n-        if (table.isSystemTable() || (tblDesc != null &&\n-            !tblDesc.isNormalizationEnabled())) {\n-          LOG.trace(\"Skipping normalization for {}, as it's either system\"\n-              + \" table or doesn't have auto normalization turned on\", table);\n-          continue;\n-        }\n+        for (TableName table : allEnabledTables) {\n+          if (table.isSystemTable()) {\n+            continue;\n+          }\n+          final TableDescriptor tblDesc = getTableDescriptors().get(table);\n+          if (tblDesc != null && !tblDesc.isNormalizationEnabled()) {\n+            LOG.debug(\n+              \"Skipping {} because normalization is disabled in its table properties.\", table);\n+            continue;\n+          }\n \n-        // make one last check that the cluster isn't shutting down before proceeding.\n-        if (skipRegionManagementAction(\"region normalizer\")) {\n-          return false;\n-        }\n+          // make one last check that the cluster isn't shutting down before proceeding.\n+          if (skipRegionManagementAction(\"region normalizer\")) {\n+            return false;\n+          }\n \n-        final List<NormalizationPlan> plans = this.normalizer.computePlanForTable(table);\n-        if (CollectionUtils.isEmpty(plans)) {\n-          return true;\n-        }\n+          final List<NormalizationPlan> plans = normalizer.computePlansForTable(table);\n+          if (CollectionUtils.isEmpty(plans)) {\n+            return true;\n+          }\n \n-        try (final Admin admin = asyncClusterConnection.toConnection().getAdmin()) {\n-          for (NormalizationPlan plan : plans) {\n-            plan.execute(admin);\n-            if (plan.getType() == PlanType.SPLIT) {\n-              splitPlanCount++;\n-            } else if (plan.getType() == PlanType.MERGE) {\n-              mergePlanCount++;\n+          try (final Admin admin = asyncClusterConnection.toConnection().getAdmin()) {\n+            // as of this writing, `plan.execute()` is non-blocking, so there's no artificial rate-\n+            // limiting of merge requests due to this serial loop.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI0MDM5MQ=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQzODk3MA==", "bodyText": "Well, sort of you can limit the work done. There no way to say \"execute at most N actions per table and M actions in a single invocation.\" You think we need something like this?", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431438970", "createdAt": "2020-05-27T21:00:08Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "diffHunk": "@@ -1911,43 +1912,51 @@ public boolean normalizeRegions() throws IOException {\n       return false;\n     }\n \n-    synchronized (this.normalizer) {\n+    if (!normalizationInProgressLock.tryLock()) {\n       // Don't run the normalizer concurrently\n+      LOG.info(\"Normalization already in progress. Skipping request.\");\n+    } else {\n+      try {\n+        List<TableName> allEnabledTables = new ArrayList<>(\n+          tableStateManager.getTablesInStates(TableState.State.ENABLED));\n+        Collections.shuffle(allEnabledTables);\n \n-      List<TableName> allEnabledTables = new ArrayList<>(\n-        this.tableStateManager.getTablesInStates(TableState.State.ENABLED));\n-\n-      Collections.shuffle(allEnabledTables);\n-\n-      for (TableName table : allEnabledTables) {\n-        TableDescriptor tblDesc = getTableDescriptors().get(table);\n-        if (table.isSystemTable() || (tblDesc != null &&\n-            !tblDesc.isNormalizationEnabled())) {\n-          LOG.trace(\"Skipping normalization for {}, as it's either system\"\n-              + \" table or doesn't have auto normalization turned on\", table);\n-          continue;\n-        }\n+        for (TableName table : allEnabledTables) {\n+          if (table.isSystemTable()) {\n+            continue;\n+          }\n+          final TableDescriptor tblDesc = getTableDescriptors().get(table);\n+          if (tblDesc != null && !tblDesc.isNormalizationEnabled()) {\n+            LOG.debug(\n+              \"Skipping {} because normalization is disabled in its table properties.\", table);\n+            continue;\n+          }\n \n-        // make one last check that the cluster isn't shutting down before proceeding.\n-        if (skipRegionManagementAction(\"region normalizer\")) {\n-          return false;\n-        }\n+          // make one last check that the cluster isn't shutting down before proceeding.\n+          if (skipRegionManagementAction(\"region normalizer\")) {\n+            return false;\n+          }\n \n-        final List<NormalizationPlan> plans = this.normalizer.computePlanForTable(table);\n-        if (CollectionUtils.isEmpty(plans)) {\n-          return true;\n-        }\n+          final List<NormalizationPlan> plans = normalizer.computePlansForTable(table);\n+          if (CollectionUtils.isEmpty(plans)) {\n+            return true;\n+          }\n \n-        try (final Admin admin = asyncClusterConnection.toConnection().getAdmin()) {\n-          for (NormalizationPlan plan : plans) {\n-            plan.execute(admin);\n-            if (plan.getType() == PlanType.SPLIT) {\n-              splitPlanCount++;\n-            } else if (plan.getType() == PlanType.MERGE) {\n-              mergePlanCount++;\n+          try (final Admin admin = asyncClusterConnection.toConnection().getAdmin()) {\n+            // as of this writing, `plan.execute()` is non-blocking, so there's no artificial rate-\n+            // limiting of merge requests due to this serial loop.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI0MDM5MQ=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQ1Njk3NA==", "bodyText": "Follow-on or just wait till this an issue. I'd be more concerned about what I think of as too-aggressive behavior.... asking for a split at the S * 2 threshold...", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431456974", "createdAt": "2020-05-27T21:37:09Z", "author": {"login": "saintstack"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "diffHunk": "@@ -1911,43 +1912,51 @@ public boolean normalizeRegions() throws IOException {\n       return false;\n     }\n \n-    synchronized (this.normalizer) {\n+    if (!normalizationInProgressLock.tryLock()) {\n       // Don't run the normalizer concurrently\n+      LOG.info(\"Normalization already in progress. Skipping request.\");\n+    } else {\n+      try {\n+        List<TableName> allEnabledTables = new ArrayList<>(\n+          tableStateManager.getTablesInStates(TableState.State.ENABLED));\n+        Collections.shuffle(allEnabledTables);\n \n-      List<TableName> allEnabledTables = new ArrayList<>(\n-        this.tableStateManager.getTablesInStates(TableState.State.ENABLED));\n-\n-      Collections.shuffle(allEnabledTables);\n-\n-      for (TableName table : allEnabledTables) {\n-        TableDescriptor tblDesc = getTableDescriptors().get(table);\n-        if (table.isSystemTable() || (tblDesc != null &&\n-            !tblDesc.isNormalizationEnabled())) {\n-          LOG.trace(\"Skipping normalization for {}, as it's either system\"\n-              + \" table or doesn't have auto normalization turned on\", table);\n-          continue;\n-        }\n+        for (TableName table : allEnabledTables) {\n+          if (table.isSystemTable()) {\n+            continue;\n+          }\n+          final TableDescriptor tblDesc = getTableDescriptors().get(table);\n+          if (tblDesc != null && !tblDesc.isNormalizationEnabled()) {\n+            LOG.debug(\n+              \"Skipping {} because normalization is disabled in its table properties.\", table);\n+            continue;\n+          }\n \n-        // make one last check that the cluster isn't shutting down before proceeding.\n-        if (skipRegionManagementAction(\"region normalizer\")) {\n-          return false;\n-        }\n+          // make one last check that the cluster isn't shutting down before proceeding.\n+          if (skipRegionManagementAction(\"region normalizer\")) {\n+            return false;\n+          }\n \n-        final List<NormalizationPlan> plans = this.normalizer.computePlanForTable(table);\n-        if (CollectionUtils.isEmpty(plans)) {\n-          return true;\n-        }\n+          final List<NormalizationPlan> plans = normalizer.computePlansForTable(table);\n+          if (CollectionUtils.isEmpty(plans)) {\n+            return true;\n+          }\n \n-        try (final Admin admin = asyncClusterConnection.toConnection().getAdmin()) {\n-          for (NormalizationPlan plan : plans) {\n-            plan.execute(admin);\n-            if (plan.getType() == PlanType.SPLIT) {\n-              splitPlanCount++;\n-            } else if (plan.getType() == PlanType.MERGE) {\n-              mergePlanCount++;\n+          try (final Admin admin = asyncClusterConnection.toConnection().getAdmin()) {\n+            // as of this writing, `plan.execute()` is non-blocking, so there's no artificial rate-\n+            // limiting of merge requests due to this serial loop.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI0MDM5MQ=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE3MTY1OA==", "bodyText": "https://issues.apache.org/jira/browse/HBASE-24463", "url": "https://github.com/apache/hbase/pull/1786#discussion_r432171658", "createdAt": "2020-05-28T23:06:40Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "diffHunk": "@@ -1911,43 +1912,51 @@ public boolean normalizeRegions() throws IOException {\n       return false;\n     }\n \n-    synchronized (this.normalizer) {\n+    if (!normalizationInProgressLock.tryLock()) {\n       // Don't run the normalizer concurrently\n+      LOG.info(\"Normalization already in progress. Skipping request.\");\n+    } else {\n+      try {\n+        List<TableName> allEnabledTables = new ArrayList<>(\n+          tableStateManager.getTablesInStates(TableState.State.ENABLED));\n+        Collections.shuffle(allEnabledTables);\n \n-      List<TableName> allEnabledTables = new ArrayList<>(\n-        this.tableStateManager.getTablesInStates(TableState.State.ENABLED));\n-\n-      Collections.shuffle(allEnabledTables);\n-\n-      for (TableName table : allEnabledTables) {\n-        TableDescriptor tblDesc = getTableDescriptors().get(table);\n-        if (table.isSystemTable() || (tblDesc != null &&\n-            !tblDesc.isNormalizationEnabled())) {\n-          LOG.trace(\"Skipping normalization for {}, as it's either system\"\n-              + \" table or doesn't have auto normalization turned on\", table);\n-          continue;\n-        }\n+        for (TableName table : allEnabledTables) {\n+          if (table.isSystemTable()) {\n+            continue;\n+          }\n+          final TableDescriptor tblDesc = getTableDescriptors().get(table);\n+          if (tblDesc != null && !tblDesc.isNormalizationEnabled()) {\n+            LOG.debug(\n+              \"Skipping {} because normalization is disabled in its table properties.\", table);\n+            continue;\n+          }\n \n-        // make one last check that the cluster isn't shutting down before proceeding.\n-        if (skipRegionManagementAction(\"region normalizer\")) {\n-          return false;\n-        }\n+          // make one last check that the cluster isn't shutting down before proceeding.\n+          if (skipRegionManagementAction(\"region normalizer\")) {\n+            return false;\n+          }\n \n-        final List<NormalizationPlan> plans = this.normalizer.computePlanForTable(table);\n-        if (CollectionUtils.isEmpty(plans)) {\n-          return true;\n-        }\n+          final List<NormalizationPlan> plans = normalizer.computePlansForTable(table);\n+          if (CollectionUtils.isEmpty(plans)) {\n+            return true;\n+          }\n \n-        try (final Admin admin = asyncClusterConnection.toConnection().getAdmin()) {\n-          for (NormalizationPlan plan : plans) {\n-            plan.execute(admin);\n-            if (plan.getType() == PlanType.SPLIT) {\n-              splitPlanCount++;\n-            } else if (plan.getType() == PlanType.MERGE) {\n-              mergePlanCount++;\n+          try (final Admin admin = asyncClusterConnection.toConnection().getAdmin()) {\n+            // as of this writing, `plan.execute()` is non-blocking, so there's no artificial rate-\n+            // limiting of merge requests due to this serial loop.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI0MDM5MQ=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 98}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4NjAyNTk1OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxNTo0NDowOFrOGbRCrQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QyMDowNjozOVrOGbbSNQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI0Mzk0OQ==", "bodyText": "Nice doc", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431243949", "createdAt": "2020-05-27T15:44:08Z", "author": {"login": "saintstack"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,436 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>\n+ *   <li>Otherwise, for the next region in the chain R1, if R0 + R1 is smaller then S, R0 and R1\n+ *     are kindly requested to merge.</li>\n+ * </ol>\n+ * <p>\n+ * The following parameters are configurable:\n+ * <ol>\n+ *   <li>Whether to split a region as part of normalization. Configuration:\n+ *     {@value SPLIT_ENABLED_KEY}, default: {@value DEFAULT_SPLIT_ENABLED}.</li>\n+ *   <li>Whether to merge a region as part of normalization. Configuration:\n+ *     {@value MERGE_ENABLED_KEY}, default: {@value DEFAULT_MERGE_ENABLED}.</li>\n+ *   <li>The minimum number of regions in a table to consider it for normalization. Configuration:\n+ *     {@value MIN_REGION_COUNT_KEY}, default: {@value DEFAULT_MIN_REGION_COUNT}.</li>\n+ *   <li>The minimum age for a region to be considered for a merge, in days. Configuration:\n+ *     {@value MERGE_MIN_REGION_AGE_DAYS_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_AGE_DAYS}.</li>\n+ *   <li>The minimum size for a region to be considered for a merge, in whole MBs. Configuration:\n+ *     {@value MERGE_MIN_REGION_SIZE_MB_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_SIZE_MB}.</li>\n  * </ol>\n  * <p>\n- * Region sizes are coarse and approximate on the order of megabytes. Additionally, \"empty\" regions\n- * (less than 1MB, with the previous note) are not merged away. This is by design to prevent\n- * normalization from undoing the pre-splitting of a table.\n+ * To see detailed logging of the application of these configuration values, set the log level for\n+ * this class to `TRACE`.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQxMTc2NQ==", "bodyText": "+1", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431411765", "createdAt": "2020-05-27T20:06:39Z", "author": {"login": "huaxiangsun"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,436 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>\n+ *   <li>Otherwise, for the next region in the chain R1, if R0 + R1 is smaller then S, R0 and R1\n+ *     are kindly requested to merge.</li>\n+ * </ol>\n+ * <p>\n+ * The following parameters are configurable:\n+ * <ol>\n+ *   <li>Whether to split a region as part of normalization. Configuration:\n+ *     {@value SPLIT_ENABLED_KEY}, default: {@value DEFAULT_SPLIT_ENABLED}.</li>\n+ *   <li>Whether to merge a region as part of normalization. Configuration:\n+ *     {@value MERGE_ENABLED_KEY}, default: {@value DEFAULT_MERGE_ENABLED}.</li>\n+ *   <li>The minimum number of regions in a table to consider it for normalization. Configuration:\n+ *     {@value MIN_REGION_COUNT_KEY}, default: {@value DEFAULT_MIN_REGION_COUNT}.</li>\n+ *   <li>The minimum age for a region to be considered for a merge, in days. Configuration:\n+ *     {@value MERGE_MIN_REGION_AGE_DAYS_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_AGE_DAYS}.</li>\n+ *   <li>The minimum size for a region to be considered for a merge, in whole MBs. Configuration:\n+ *     {@value MERGE_MIN_REGION_SIZE_MB_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_SIZE_MB}.</li>\n  * </ol>\n  * <p>\n- * Region sizes are coarse and approximate on the order of megabytes. Additionally, \"empty\" regions\n- * (less than 1MB, with the previous note) are not merged away. This is by design to prevent\n- * normalization from undoing the pre-splitting of a table.\n+ * To see detailed logging of the application of these configuration values, set the log level for\n+ * this class to `TRACE`.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI0Mzk0OQ=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 79}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4NjAzNTQ2OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxNTo0NTo1MVrOGbRITw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxNTo0NTo1MVrOGbRITw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI0NTM5MQ==", "bodyText": "Good", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431245391", "createdAt": "2020-05-27T15:45:51Z", "author": {"login": "saintstack"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,436 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>\n+ *   <li>Otherwise, for the next region in the chain R1, if R0 + R1 is smaller then S, R0 and R1\n+ *     are kindly requested to merge.</li>\n+ * </ol>\n+ * <p>\n+ * The following parameters are configurable:\n+ * <ol>\n+ *   <li>Whether to split a region as part of normalization. Configuration:\n+ *     {@value SPLIT_ENABLED_KEY}, default: {@value DEFAULT_SPLIT_ENABLED}.</li>\n+ *   <li>Whether to merge a region as part of normalization. Configuration:\n+ *     {@value MERGE_ENABLED_KEY}, default: {@value DEFAULT_MERGE_ENABLED}.</li>\n+ *   <li>The minimum number of regions in a table to consider it for normalization. Configuration:\n+ *     {@value MIN_REGION_COUNT_KEY}, default: {@value DEFAULT_MIN_REGION_COUNT}.</li>\n+ *   <li>The minimum age for a region to be considered for a merge, in days. Configuration:\n+ *     {@value MERGE_MIN_REGION_AGE_DAYS_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_AGE_DAYS}.</li>\n+ *   <li>The minimum size for a region to be considered for a merge, in whole MBs. Configuration:\n+ *     {@value MERGE_MIN_REGION_SIZE_MB_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_SIZE_MB}.</li>\n  * </ol>\n  * <p>\n- * Region sizes are coarse and approximate on the order of megabytes. Additionally, \"empty\" regions\n- * (less than 1MB, with the previous note) are not merged away. This is by design to prevent\n- * normalization from undoing the pre-splitting of a table.\n+ * To see detailed logging of the application of these configuration values, set the log level for\n+ * this class to `TRACE`.\n  */\n-@InterfaceAudience.Private\n-public class SimpleRegionNormalizer extends AbstractRegionNormalizer {\n-\n+@InterfaceAudience.LimitedPrivate(HBaseInterfaceAudience.CONFIG)\n+public class SimpleRegionNormalizer implements RegionNormalizer {\n   private static final Logger LOG = LoggerFactory.getLogger(SimpleRegionNormalizer.class);\n-  private static long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+\n+  static final String SPLIT_ENABLED_KEY = \"hbase.normalizer.split.enabled\";\n+  static final boolean DEFAULT_SPLIT_ENABLED = true;\n+  static final String MERGE_ENABLED_KEY = \"hbase.normalizer.merge.enabled\";\n+  static final boolean DEFAULT_MERGE_ENABLED = true;\n+  // TODO: after HBASE-24416, `min.region.count` only applies to merge plans; should\n+  //  deprecate/rename the configuration key.\n+  static final String MIN_REGION_COUNT_KEY = \"hbase.normalizer.min.region.count\";\n+  static final int DEFAULT_MIN_REGION_COUNT = 3;\n+  static final String MERGE_MIN_REGION_AGE_DAYS_KEY = \"hbase.normalizer.merge.min_region_age.days\";\n+  static final int DEFAULT_MERGE_MIN_REGION_AGE_DAYS = 3;\n+  static final String MERGE_MIN_REGION_SIZE_MB_KEY = \"hbase.normalizer.merge.min_region_size.mb\";\n+  static final int DEFAULT_MERGE_MIN_REGION_SIZE_MB = 1;\n+\n+  private final long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+  private final Comparator<NormalizationPlan> planComparator = new SplitPlanFirstComparator();\n+\n+  private Configuration conf;\n+  private MasterServices masterServices;\n+  private boolean splitEnabled;\n+  private boolean mergeEnabled;\n+  private int minRegionCount;\n+  private Period mergeMinRegionAge;\n+  private int mergeMinRegionSizeMb;\n+\n+  public SimpleRegionNormalizer() {\n+    splitEnabled = DEFAULT_SPLIT_ENABLED;\n+    mergeEnabled = DEFAULT_MERGE_ENABLED;\n+    minRegionCount = DEFAULT_MIN_REGION_COUNT;\n+    mergeMinRegionAge = Period.ofDays(DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    mergeMinRegionSizeMb = DEFAULT_MERGE_MIN_REGION_SIZE_MB;\n+  }\n \n   @Override\n-  public void planSkipped(RegionInfo hri, PlanType type) {\n-    skippedCount[type.ordinal()]++;\n+  public Configuration getConf() {\n+    return conf;\n   }\n \n   @Override\n-  public long getSkippedCount(NormalizationPlan.PlanType type) {\n-    return skippedCount[type.ordinal()];\n+  public void setConf(final Configuration conf) {\n+    if (conf == null) {\n+      return;\n+    }\n+    this.conf = conf;\n+    splitEnabled = conf.getBoolean(SPLIT_ENABLED_KEY, DEFAULT_SPLIT_ENABLED);\n+    mergeEnabled = conf.getBoolean(MERGE_ENABLED_KEY, DEFAULT_MERGE_ENABLED);\n+    minRegionCount = parseMinRegionCount(conf);\n+    mergeMinRegionAge = parseMergeMinRegionAge(conf);\n+    mergeMinRegionSizeMb = parseMergeMinRegionSizeMb(conf);\n+  }\n+\n+  private static int parseMinRegionCount(final Configuration conf) {\n+    final int parsedValue = conf.getInt(MIN_REGION_COUNT_KEY, DEFAULT_MIN_REGION_COUNT);\n+    final int settledValue = Math.max(1, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MIN_REGION_COUNT_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 149}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4NjA5MTg3OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxNTo1NzozNVrOGbRrpQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQyMzoxNjo0MVrOGcJ2zA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI1NDQzNw==", "bodyText": "Why this? We have a process already to check for splittable Regions on the RegionServer  side?  This just doing same thing from master side? Should it be sloppier -- a just-in-case.... maybe S3 or S4?", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431254437", "createdAt": "2020-05-27T15:57:35Z", "author": {"login": "saintstack"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,436 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQxMzIwNQ==", "bodyText": "As I see it, the Normalizer becomes the process that ensure the \"weight\" of regions is event, so that it can be well-balanced by the Balancer. The region server's ability to split a region at a configured point is more of a safety-valve, a way for the region server to protect itself.\nMaybe we want an analogue to hbase.hregion.max.filesize, a way for operators to specify a minimum region size, under this size the Normalizer won't split it.\nI don't know if this subject has been discussed elsewhere.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431413205", "createdAt": "2020-05-27T20:09:45Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,436 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI1NDQzNw=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE3NDc5Ng==", "bodyText": "https://issues.apache.org/jira/browse/HBASE-24464", "url": "https://github.com/apache/hbase/pull/1786#discussion_r432174796", "createdAt": "2020-05-28T23:16:41Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,436 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI1NDQzNw=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 54}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4NjEwMTMxOnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxNTo1OTowNVrOGbRxfA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQyMzoyMTowN1rOGcJ71w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI1NTkzMg==", "bodyText": "Yeah, this seems too aggressive too.... I'd think normalizer would only cut in on an extreme. R0+R1 is smaller than S/2? Else... if close to the edge, could make a Region that is then splittable. Churn.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431255932", "createdAt": "2020-05-27T15:59:05Z", "author": {"login": "saintstack"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,436 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>\n+ *   <li>Otherwise, for the next region in the chain R1, if R0 + R1 is smaller then S, R0 and R1\n+ *     are kindly requested to merge.</li>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQxNTYyNg==", "bodyText": "That's a good point. Maybe a separate ticket? I'm trying very hard to not change any fundamentals in this patch, just consolidate the implementations and features that exist.\nThere's also HBASE-24419, which I think would also make for a more stable operational experience.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431415626", "createdAt": "2020-05-27T20:14:28Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,436 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>\n+ *   <li>Otherwise, for the next region in the chain R1, if R0 + R1 is smaller then S, R0 and R1\n+ *     are kindly requested to merge.</li>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI1NTkzMg=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE3NjA4Nw==", "bodyText": "https://issues.apache.org/jira/browse/HBASE-24465", "url": "https://github.com/apache/hbase/pull/1786#discussion_r432176087", "createdAt": "2020-05-28T23:21:07Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,436 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>\n+ *   <li>Otherwise, for the next region in the chain R1, if R0 + R1 is smaller then S, R0 and R1\n+ *     are kindly requested to merge.</li>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI1NTkzMg=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 56}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4NjEyMTM1OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxNjowMjowNFrOGbR9fg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQxODoyNTowNVrOGd-yKQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI1OTAwNg==", "bodyText": "Hmm... Get rid of the Interface altogether and call this RegionNormalizer. Who is going to write another? Pass in the Master on Construction so you don't have to do the setConfiguration and setMasterServices dance below?", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431259006", "createdAt": "2020-05-27T16:02:04Z", "author": {"login": "saintstack"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,436 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>\n+ *   <li>Otherwise, for the next region in the chain R1, if R0 + R1 is smaller then S, R0 and R1\n+ *     are kindly requested to merge.</li>\n+ * </ol>\n+ * <p>\n+ * The following parameters are configurable:\n+ * <ol>\n+ *   <li>Whether to split a region as part of normalization. Configuration:\n+ *     {@value SPLIT_ENABLED_KEY}, default: {@value DEFAULT_SPLIT_ENABLED}.</li>\n+ *   <li>Whether to merge a region as part of normalization. Configuration:\n+ *     {@value MERGE_ENABLED_KEY}, default: {@value DEFAULT_MERGE_ENABLED}.</li>\n+ *   <li>The minimum number of regions in a table to consider it for normalization. Configuration:\n+ *     {@value MIN_REGION_COUNT_KEY}, default: {@value DEFAULT_MIN_REGION_COUNT}.</li>\n+ *   <li>The minimum age for a region to be considered for a merge, in days. Configuration:\n+ *     {@value MERGE_MIN_REGION_AGE_DAYS_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_AGE_DAYS}.</li>\n+ *   <li>The minimum size for a region to be considered for a merge, in whole MBs. Configuration:\n+ *     {@value MERGE_MIN_REGION_SIZE_MB_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_SIZE_MB}.</li>\n  * </ol>\n  * <p>\n- * Region sizes are coarse and approximate on the order of megabytes. Additionally, \"empty\" regions\n- * (less than 1MB, with the previous note) are not merged away. This is by design to prevent\n- * normalization from undoing the pre-splitting of a table.\n+ * To see detailed logging of the application of these configuration values, set the log level for\n+ * this class to `TRACE`.\n  */\n-@InterfaceAudience.Private\n-public class SimpleRegionNormalizer extends AbstractRegionNormalizer {\n-\n+@InterfaceAudience.LimitedPrivate(HBaseInterfaceAudience.CONFIG)\n+public class SimpleRegionNormalizer implements RegionNormalizer {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQxNzEyNA==", "bodyText": "Constructor interface would be cleaner if it was not driven buy the Configuration and reflection.\nI dunno. How many folks plug in a custom Balancer? Seems like it's not common, but if you need it, you really need it. I don't know that it's easier to plug in a custom implementation in a separate jar, vs. building your own HBase from source.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431417124", "createdAt": "2020-05-27T20:17:29Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,436 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>\n+ *   <li>Otherwise, for the next region in the chain R1, if R0 + R1 is smaller then S, R0 and R1\n+ *     are kindly requested to merge.</li>\n+ * </ol>\n+ * <p>\n+ * The following parameters are configurable:\n+ * <ol>\n+ *   <li>Whether to split a region as part of normalization. Configuration:\n+ *     {@value SPLIT_ENABLED_KEY}, default: {@value DEFAULT_SPLIT_ENABLED}.</li>\n+ *   <li>Whether to merge a region as part of normalization. Configuration:\n+ *     {@value MERGE_ENABLED_KEY}, default: {@value DEFAULT_MERGE_ENABLED}.</li>\n+ *   <li>The minimum number of regions in a table to consider it for normalization. Configuration:\n+ *     {@value MIN_REGION_COUNT_KEY}, default: {@value DEFAULT_MIN_REGION_COUNT}.</li>\n+ *   <li>The minimum age for a region to be considered for a merge, in days. Configuration:\n+ *     {@value MERGE_MIN_REGION_AGE_DAYS_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_AGE_DAYS}.</li>\n+ *   <li>The minimum size for a region to be considered for a merge, in whole MBs. Configuration:\n+ *     {@value MERGE_MIN_REGION_SIZE_MB_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_SIZE_MB}.</li>\n  * </ol>\n  * <p>\n- * Region sizes are coarse and approximate on the order of megabytes. Additionally, \"empty\" regions\n- * (less than 1MB, with the previous note) are not merged away. This is by design to prevent\n- * normalization from undoing the pre-splitting of a table.\n+ * To see detailed logging of the application of these configuration values, set the log level for\n+ * this class to `TRACE`.\n  */\n-@InterfaceAudience.Private\n-public class SimpleRegionNormalizer extends AbstractRegionNormalizer {\n-\n+@InterfaceAudience.LimitedPrivate(HBaseInterfaceAudience.CONFIG)\n+public class SimpleRegionNormalizer implements RegionNormalizer {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI1OTAwNg=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE4MjM4OA==", "bodyText": "Sent a question over on the dev list.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r432182388", "createdAt": "2020-05-28T23:43:00Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,436 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>\n+ *   <li>Otherwise, for the next region in the chain R1, if R0 + R1 is smaller then S, R0 and R1\n+ *     are kindly requested to merge.</li>\n+ * </ol>\n+ * <p>\n+ * The following parameters are configurable:\n+ * <ol>\n+ *   <li>Whether to split a region as part of normalization. Configuration:\n+ *     {@value SPLIT_ENABLED_KEY}, default: {@value DEFAULT_SPLIT_ENABLED}.</li>\n+ *   <li>Whether to merge a region as part of normalization. Configuration:\n+ *     {@value MERGE_ENABLED_KEY}, default: {@value DEFAULT_MERGE_ENABLED}.</li>\n+ *   <li>The minimum number of regions in a table to consider it for normalization. Configuration:\n+ *     {@value MIN_REGION_COUNT_KEY}, default: {@value DEFAULT_MIN_REGION_COUNT}.</li>\n+ *   <li>The minimum age for a region to be considered for a merge, in days. Configuration:\n+ *     {@value MERGE_MIN_REGION_AGE_DAYS_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_AGE_DAYS}.</li>\n+ *   <li>The minimum size for a region to be considered for a merge, in whole MBs. Configuration:\n+ *     {@value MERGE_MIN_REGION_SIZE_MB_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_SIZE_MB}.</li>\n  * </ol>\n  * <p>\n- * Region sizes are coarse and approximate on the order of megabytes. Additionally, \"empty\" regions\n- * (less than 1MB, with the previous note) are not merged away. This is by design to prevent\n- * normalization from undoing the pre-splitting of a table.\n+ * To see detailed logging of the application of these configuration values, set the log level for\n+ * this class to `TRACE`.\n  */\n-@InterfaceAudience.Private\n-public class SimpleRegionNormalizer extends AbstractRegionNormalizer {\n-\n+@InterfaceAudience.LimitedPrivate(HBaseInterfaceAudience.CONFIG)\n+public class SimpleRegionNormalizer implements RegionNormalizer {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI1OTAwNg=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDA2NDU4MQ==", "bodyText": "So we kept the Interface?", "url": "https://github.com/apache/hbase/pull/1786#discussion_r434064581", "createdAt": "2020-06-02T17:54:22Z", "author": {"login": "saintstack"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,436 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>\n+ *   <li>Otherwise, for the next region in the chain R1, if R0 + R1 is smaller then S, R0 and R1\n+ *     are kindly requested to merge.</li>\n+ * </ol>\n+ * <p>\n+ * The following parameters are configurable:\n+ * <ol>\n+ *   <li>Whether to split a region as part of normalization. Configuration:\n+ *     {@value SPLIT_ENABLED_KEY}, default: {@value DEFAULT_SPLIT_ENABLED}.</li>\n+ *   <li>Whether to merge a region as part of normalization. Configuration:\n+ *     {@value MERGE_ENABLED_KEY}, default: {@value DEFAULT_MERGE_ENABLED}.</li>\n+ *   <li>The minimum number of regions in a table to consider it for normalization. Configuration:\n+ *     {@value MIN_REGION_COUNT_KEY}, default: {@value DEFAULT_MIN_REGION_COUNT}.</li>\n+ *   <li>The minimum age for a region to be considered for a merge, in days. Configuration:\n+ *     {@value MERGE_MIN_REGION_AGE_DAYS_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_AGE_DAYS}.</li>\n+ *   <li>The minimum size for a region to be considered for a merge, in whole MBs. Configuration:\n+ *     {@value MERGE_MIN_REGION_SIZE_MB_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_SIZE_MB}.</li>\n  * </ol>\n  * <p>\n- * Region sizes are coarse and approximate on the order of megabytes. Additionally, \"empty\" regions\n- * (less than 1MB, with the previous note) are not merged away. This is by design to prevent\n- * normalization from undoing the pre-splitting of a table.\n+ * To see detailed logging of the application of these configuration values, set the log level for\n+ * this class to `TRACE`.\n  */\n-@InterfaceAudience.Private\n-public class SimpleRegionNormalizer extends AbstractRegionNormalizer {\n-\n+@InterfaceAudience.LimitedPrivate(HBaseInterfaceAudience.CONFIG)\n+public class SimpleRegionNormalizer implements RegionNormalizer {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI1OTAwNg=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDA5MDUzNw==", "bodyText": "Yes, I have kept the interface for now, and posted a question to the dev list. If there's no responses there, I'll file a new issue to deprecate and remove it. I think the soonest we can remove a configuration point is for 3.0 though, so it would merely be deprecated for branch-2 onward.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r434090537", "createdAt": "2020-06-02T18:25:05Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,436 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>\n+ *   <li>Otherwise, for the next region in the chain R1, if R0 + R1 is smaller then S, R0 and R1\n+ *     are kindly requested to merge.</li>\n+ * </ol>\n+ * <p>\n+ * The following parameters are configurable:\n+ * <ol>\n+ *   <li>Whether to split a region as part of normalization. Configuration:\n+ *     {@value SPLIT_ENABLED_KEY}, default: {@value DEFAULT_SPLIT_ENABLED}.</li>\n+ *   <li>Whether to merge a region as part of normalization. Configuration:\n+ *     {@value MERGE_ENABLED_KEY}, default: {@value DEFAULT_MERGE_ENABLED}.</li>\n+ *   <li>The minimum number of regions in a table to consider it for normalization. Configuration:\n+ *     {@value MIN_REGION_COUNT_KEY}, default: {@value DEFAULT_MIN_REGION_COUNT}.</li>\n+ *   <li>The minimum age for a region to be considered for a merge, in days. Configuration:\n+ *     {@value MERGE_MIN_REGION_AGE_DAYS_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_AGE_DAYS}.</li>\n+ *   <li>The minimum size for a region to be considered for a merge, in whole MBs. Configuration:\n+ *     {@value MERGE_MIN_REGION_SIZE_MB_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_SIZE_MB}.</li>\n  * </ol>\n  * <p>\n- * Region sizes are coarse and approximate on the order of megabytes. Additionally, \"empty\" regions\n- * (less than 1MB, with the previous note) are not merged away. This is by design to prevent\n- * normalization from undoing the pre-splitting of a table.\n+ * To see detailed logging of the application of these configuration values, set the log level for\n+ * this class to `TRACE`.\n  */\n-@InterfaceAudience.Private\n-public class SimpleRegionNormalizer extends AbstractRegionNormalizer {\n-\n+@InterfaceAudience.LimitedPrivate(HBaseInterfaceAudience.CONFIG)\n+public class SimpleRegionNormalizer implements RegionNormalizer {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI1OTAwNg=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 85}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4NjEyMzgwOnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxNjowMjoyOVrOGbR_Fw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxNjowMjoyOVrOGbR_Fw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI1OTQxNQ==", "bodyText": "This is good stuff. Clean", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431259415", "createdAt": "2020-05-27T16:02:29Z", "author": {"login": "saintstack"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,436 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>\n+ *   <li>Otherwise, for the next region in the chain R1, if R0 + R1 is smaller then S, R0 and R1\n+ *     are kindly requested to merge.</li>\n+ * </ol>\n+ * <p>\n+ * The following parameters are configurable:\n+ * <ol>\n+ *   <li>Whether to split a region as part of normalization. Configuration:\n+ *     {@value SPLIT_ENABLED_KEY}, default: {@value DEFAULT_SPLIT_ENABLED}.</li>\n+ *   <li>Whether to merge a region as part of normalization. Configuration:\n+ *     {@value MERGE_ENABLED_KEY}, default: {@value DEFAULT_MERGE_ENABLED}.</li>\n+ *   <li>The minimum number of regions in a table to consider it for normalization. Configuration:\n+ *     {@value MIN_REGION_COUNT_KEY}, default: {@value DEFAULT_MIN_REGION_COUNT}.</li>\n+ *   <li>The minimum age for a region to be considered for a merge, in days. Configuration:\n+ *     {@value MERGE_MIN_REGION_AGE_DAYS_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_AGE_DAYS}.</li>\n+ *   <li>The minimum size for a region to be considered for a merge, in whole MBs. Configuration:\n+ *     {@value MERGE_MIN_REGION_SIZE_MB_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_SIZE_MB}.</li>\n  * </ol>\n  * <p>\n- * Region sizes are coarse and approximate on the order of megabytes. Additionally, \"empty\" regions\n- * (less than 1MB, with the previous note) are not merged away. This is by design to prevent\n- * normalization from undoing the pre-splitting of a table.\n+ * To see detailed logging of the application of these configuration values, set the log level for\n+ * this class to `TRACE`.\n  */\n-@InterfaceAudience.Private\n-public class SimpleRegionNormalizer extends AbstractRegionNormalizer {\n-\n+@InterfaceAudience.LimitedPrivate(HBaseInterfaceAudience.CONFIG)\n+public class SimpleRegionNormalizer implements RegionNormalizer {\n   private static final Logger LOG = LoggerFactory.getLogger(SimpleRegionNormalizer.class);\n-  private static long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+\n+  static final String SPLIT_ENABLED_KEY = \"hbase.normalizer.split.enabled\";\n+  static final boolean DEFAULT_SPLIT_ENABLED = true;\n+  static final String MERGE_ENABLED_KEY = \"hbase.normalizer.merge.enabled\";\n+  static final boolean DEFAULT_MERGE_ENABLED = true;\n+  // TODO: after HBASE-24416, `min.region.count` only applies to merge plans; should\n+  //  deprecate/rename the configuration key.\n+  static final String MIN_REGION_COUNT_KEY = \"hbase.normalizer.min.region.count\";\n+  static final int DEFAULT_MIN_REGION_COUNT = 3;\n+  static final String MERGE_MIN_REGION_AGE_DAYS_KEY = \"hbase.normalizer.merge.min_region_age.days\";\n+  static final int DEFAULT_MERGE_MIN_REGION_AGE_DAYS = 3;\n+  static final String MERGE_MIN_REGION_SIZE_MB_KEY = \"hbase.normalizer.merge.min_region_size.mb\";\n+  static final int DEFAULT_MERGE_MIN_REGION_SIZE_MB = 1;\n+\n+  private final long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+  private final Comparator<NormalizationPlan> planComparator = new SplitPlanFirstComparator();\n+\n+  private Configuration conf;\n+  private MasterServices masterServices;\n+  private boolean splitEnabled;\n+  private boolean mergeEnabled;\n+  private int minRegionCount;\n+  private Period mergeMinRegionAge;\n+  private int mergeMinRegionSizeMb;\n+\n+  public SimpleRegionNormalizer() {\n+    splitEnabled = DEFAULT_SPLIT_ENABLED;\n+    mergeEnabled = DEFAULT_MERGE_ENABLED;\n+    minRegionCount = DEFAULT_MIN_REGION_COUNT;\n+    mergeMinRegionAge = Period.ofDays(DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    mergeMinRegionSizeMb = DEFAULT_MERGE_MIN_REGION_SIZE_MB;\n+  }\n \n   @Override\n-  public void planSkipped(RegionInfo hri, PlanType type) {\n-    skippedCount[type.ordinal()]++;\n+  public Configuration getConf() {\n+    return conf;\n   }\n \n   @Override\n-  public long getSkippedCount(NormalizationPlan.PlanType type) {\n-    return skippedCount[type.ordinal()];\n+  public void setConf(final Configuration conf) {\n+    if (conf == null) {\n+      return;\n+    }\n+    this.conf = conf;\n+    splitEnabled = conf.getBoolean(SPLIT_ENABLED_KEY, DEFAULT_SPLIT_ENABLED);\n+    mergeEnabled = conf.getBoolean(MERGE_ENABLED_KEY, DEFAULT_MERGE_ENABLED);\n+    minRegionCount = parseMinRegionCount(conf);\n+    mergeMinRegionAge = parseMergeMinRegionAge(conf);\n+    mergeMinRegionSizeMb = parseMergeMinRegionSizeMb(conf);\n+  }\n+\n+  private static int parseMinRegionCount(final Configuration conf) {\n+    final int parsedValue = conf.getInt(MIN_REGION_COUNT_KEY, DEFAULT_MIN_REGION_COUNT);\n+    final int settledValue = Math.max(1, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MIN_REGION_COUNT_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static Period parseMergeMinRegionAge(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_AGE_DAYS_KEY, DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_AGE_DAYS_KEY, parsedValue, settledValue);\n+    }\n+    return Period.ofDays(settledValue);\n+  }\n+\n+  private static int parseMergeMinRegionSizeMb(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_SIZE_MB_KEY, DEFAULT_MERGE_MIN_REGION_SIZE_MB);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_SIZE_MB_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 169}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4NjI2MjAxOnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxNjozNToyMlrOGbTZgg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QyMDozMDozNlrOGbb_uQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI4MjU2Mg==", "bodyText": "Should the master switch check be inside the isSplitEnabled?", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431282562", "createdAt": "2020-05-27T16:35:22Z", "author": {"login": "saintstack"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,436 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>\n+ *   <li>Otherwise, for the next region in the chain R1, if R0 + R1 is smaller then S, R0 and R1\n+ *     are kindly requested to merge.</li>\n+ * </ol>\n+ * <p>\n+ * The following parameters are configurable:\n+ * <ol>\n+ *   <li>Whether to split a region as part of normalization. Configuration:\n+ *     {@value SPLIT_ENABLED_KEY}, default: {@value DEFAULT_SPLIT_ENABLED}.</li>\n+ *   <li>Whether to merge a region as part of normalization. Configuration:\n+ *     {@value MERGE_ENABLED_KEY}, default: {@value DEFAULT_MERGE_ENABLED}.</li>\n+ *   <li>The minimum number of regions in a table to consider it for normalization. Configuration:\n+ *     {@value MIN_REGION_COUNT_KEY}, default: {@value DEFAULT_MIN_REGION_COUNT}.</li>\n+ *   <li>The minimum age for a region to be considered for a merge, in days. Configuration:\n+ *     {@value MERGE_MIN_REGION_AGE_DAYS_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_AGE_DAYS}.</li>\n+ *   <li>The minimum size for a region to be considered for a merge, in whole MBs. Configuration:\n+ *     {@value MERGE_MIN_REGION_SIZE_MB_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_SIZE_MB}.</li>\n  * </ol>\n  * <p>\n- * Region sizes are coarse and approximate on the order of megabytes. Additionally, \"empty\" regions\n- * (less than 1MB, with the previous note) are not merged away. This is by design to prevent\n- * normalization from undoing the pre-splitting of a table.\n+ * To see detailed logging of the application of these configuration values, set the log level for\n+ * this class to `TRACE`.\n  */\n-@InterfaceAudience.Private\n-public class SimpleRegionNormalizer extends AbstractRegionNormalizer {\n-\n+@InterfaceAudience.LimitedPrivate(HBaseInterfaceAudience.CONFIG)\n+public class SimpleRegionNormalizer implements RegionNormalizer {\n   private static final Logger LOG = LoggerFactory.getLogger(SimpleRegionNormalizer.class);\n-  private static long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+\n+  static final String SPLIT_ENABLED_KEY = \"hbase.normalizer.split.enabled\";\n+  static final boolean DEFAULT_SPLIT_ENABLED = true;\n+  static final String MERGE_ENABLED_KEY = \"hbase.normalizer.merge.enabled\";\n+  static final boolean DEFAULT_MERGE_ENABLED = true;\n+  // TODO: after HBASE-24416, `min.region.count` only applies to merge plans; should\n+  //  deprecate/rename the configuration key.\n+  static final String MIN_REGION_COUNT_KEY = \"hbase.normalizer.min.region.count\";\n+  static final int DEFAULT_MIN_REGION_COUNT = 3;\n+  static final String MERGE_MIN_REGION_AGE_DAYS_KEY = \"hbase.normalizer.merge.min_region_age.days\";\n+  static final int DEFAULT_MERGE_MIN_REGION_AGE_DAYS = 3;\n+  static final String MERGE_MIN_REGION_SIZE_MB_KEY = \"hbase.normalizer.merge.min_region_size.mb\";\n+  static final int DEFAULT_MERGE_MIN_REGION_SIZE_MB = 1;\n+\n+  private final long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+  private final Comparator<NormalizationPlan> planComparator = new SplitPlanFirstComparator();\n+\n+  private Configuration conf;\n+  private MasterServices masterServices;\n+  private boolean splitEnabled;\n+  private boolean mergeEnabled;\n+  private int minRegionCount;\n+  private Period mergeMinRegionAge;\n+  private int mergeMinRegionSizeMb;\n+\n+  public SimpleRegionNormalizer() {\n+    splitEnabled = DEFAULT_SPLIT_ENABLED;\n+    mergeEnabled = DEFAULT_MERGE_ENABLED;\n+    minRegionCount = DEFAULT_MIN_REGION_COUNT;\n+    mergeMinRegionAge = Period.ofDays(DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    mergeMinRegionSizeMb = DEFAULT_MERGE_MIN_REGION_SIZE_MB;\n+  }\n \n   @Override\n-  public void planSkipped(RegionInfo hri, PlanType type) {\n-    skippedCount[type.ordinal()]++;\n+  public Configuration getConf() {\n+    return conf;\n   }\n \n   @Override\n-  public long getSkippedCount(NormalizationPlan.PlanType type) {\n-    return skippedCount[type.ordinal()];\n+  public void setConf(final Configuration conf) {\n+    if (conf == null) {\n+      return;\n+    }\n+    this.conf = conf;\n+    splitEnabled = conf.getBoolean(SPLIT_ENABLED_KEY, DEFAULT_SPLIT_ENABLED);\n+    mergeEnabled = conf.getBoolean(MERGE_ENABLED_KEY, DEFAULT_MERGE_ENABLED);\n+    minRegionCount = parseMinRegionCount(conf);\n+    mergeMinRegionAge = parseMergeMinRegionAge(conf);\n+    mergeMinRegionSizeMb = parseMergeMinRegionSizeMb(conf);\n+  }\n+\n+  private static int parseMinRegionCount(final Configuration conf) {\n+    final int parsedValue = conf.getInt(MIN_REGION_COUNT_KEY, DEFAULT_MIN_REGION_COUNT);\n+    final int settledValue = Math.max(1, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MIN_REGION_COUNT_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static Period parseMergeMinRegionAge(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_AGE_DAYS_KEY, DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_AGE_DAYS_KEY, parsedValue, settledValue);\n+    }\n+    return Period.ofDays(settledValue);\n+  }\n+\n+  private static int parseMergeMinRegionSizeMb(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_SIZE_MB_KEY, DEFAULT_MERGE_MIN_REGION_SIZE_MB);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_SIZE_MB_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static <T> void warnInvalidValue(final String key, final T parsedValue,\n+    final T settledValue) {\n+    LOG.warn(\"Configured value {}={} is invalid. Setting value to {}.\",\n+      key, parsedValue, settledValue);\n   }\n \n   /**\n-   * Comparator class that gives higher priority to region Split plan.\n+   * Return this instance's configured value for {@value SPLIT_ENABLED_KEY}.\n    */\n-  static class PlanComparator implements Comparator<NormalizationPlan> {\n-    @Override\n-    public int compare(NormalizationPlan plan1, NormalizationPlan plan2) {\n-      boolean plan1IsSplit = plan1 instanceof SplitNormalizationPlan;\n-      boolean plan2IsSplit = plan2 instanceof SplitNormalizationPlan;\n-      if (plan1IsSplit && plan2IsSplit) {\n-        return 0;\n-      } else if (plan1IsSplit) {\n-        return -1;\n-      } else if (plan2IsSplit) {\n-        return 1;\n-      } else {\n-        return 0;\n-      }\n-    }\n+  public boolean isSplitEnabled() {\n+    return splitEnabled;\n   }\n \n-  private Comparator<NormalizationPlan> planComparator = new PlanComparator();\n+  /**\n+   * Return this instance's configured value for {@value MERGE_ENABLED_KEY}.\n+   */\n+  public boolean isMergeEnabled() {\n+    return mergeEnabled;\n+  }\n \n   /**\n-   * Computes next most \"urgent\" normalization action on the table. Action may be either a split, or\n-   * a merge, or no action.\n-   * @param table table to normalize\n-   * @return normalization plan to execute\n+   * Return this instance's configured value for {@value MIN_REGION_COUNT_KEY}.\n+   */\n+  public int getMinRegionCount() {\n+    return minRegionCount;\n+  }\n+\n+  /**\n+   * Return this instance's configured value for {@value MERGE_MIN_REGION_AGE_DAYS_KEY}.\n    */\n+  public Period getMergeMinRegionAge() {\n+    return mergeMinRegionAge;\n+  }\n+\n+  /**\n+   * Return this instance's configured value for {@value MERGE_MIN_REGION_SIZE_MB_KEY}.\n+   */\n+  public int getMergeMinRegionSizeMb() {\n+    return mergeMinRegionSizeMb;\n+  }\n+\n   @Override\n-  public List<NormalizationPlan> computePlanForTable(TableName table) throws HBaseIOException {\n+  public void setMasterServices(final MasterServices masterServices) {\n+    this.masterServices = masterServices;\n+  }\n+\n+  @Override\n+  public void planSkipped(final RegionInfo hri, final PlanType type) {\n+    skippedCount[type.ordinal()]++;\n+  }\n+\n+  @Override\n+  public long getSkippedCount(NormalizationPlan.PlanType type) {\n+    return skippedCount[type.ordinal()];\n+  }\n+\n+  @Override\n+  public List<NormalizationPlan> computePlansForTable(TableName table) {\n     if (table == null || table.isSystemTable()) {\n       LOG.debug(\"Normalization of system table {} isn't allowed\", table);\n-      return null;\n+      return Collections.emptyList();\n     }\n-    boolean splitEnabled = isSplitEnabled();\n-    boolean mergeEnabled = isMergeEnabled();\n+    boolean splitEnabled = isSplitEnabled() && isMasterSwitchEnabled(MasterSwitchType.SPLIT);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 259}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQyMzQxNw==", "bodyText": "Well, not quite. isSplitEnabled is a simple property accessor. You're proposing a consolidation of logic. I don't want to conflate the two.\nI could combine these checks behind a single method. How about boolean proceedWithSplit() ?", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431423417", "createdAt": "2020-05-27T20:30:36Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,436 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>\n+ *   <li>Otherwise, for the next region in the chain R1, if R0 + R1 is smaller then S, R0 and R1\n+ *     are kindly requested to merge.</li>\n+ * </ol>\n+ * <p>\n+ * The following parameters are configurable:\n+ * <ol>\n+ *   <li>Whether to split a region as part of normalization. Configuration:\n+ *     {@value SPLIT_ENABLED_KEY}, default: {@value DEFAULT_SPLIT_ENABLED}.</li>\n+ *   <li>Whether to merge a region as part of normalization. Configuration:\n+ *     {@value MERGE_ENABLED_KEY}, default: {@value DEFAULT_MERGE_ENABLED}.</li>\n+ *   <li>The minimum number of regions in a table to consider it for normalization. Configuration:\n+ *     {@value MIN_REGION_COUNT_KEY}, default: {@value DEFAULT_MIN_REGION_COUNT}.</li>\n+ *   <li>The minimum age for a region to be considered for a merge, in days. Configuration:\n+ *     {@value MERGE_MIN_REGION_AGE_DAYS_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_AGE_DAYS}.</li>\n+ *   <li>The minimum size for a region to be considered for a merge, in whole MBs. Configuration:\n+ *     {@value MERGE_MIN_REGION_SIZE_MB_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_SIZE_MB}.</li>\n  * </ol>\n  * <p>\n- * Region sizes are coarse and approximate on the order of megabytes. Additionally, \"empty\" regions\n- * (less than 1MB, with the previous note) are not merged away. This is by design to prevent\n- * normalization from undoing the pre-splitting of a table.\n+ * To see detailed logging of the application of these configuration values, set the log level for\n+ * this class to `TRACE`.\n  */\n-@InterfaceAudience.Private\n-public class SimpleRegionNormalizer extends AbstractRegionNormalizer {\n-\n+@InterfaceAudience.LimitedPrivate(HBaseInterfaceAudience.CONFIG)\n+public class SimpleRegionNormalizer implements RegionNormalizer {\n   private static final Logger LOG = LoggerFactory.getLogger(SimpleRegionNormalizer.class);\n-  private static long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+\n+  static final String SPLIT_ENABLED_KEY = \"hbase.normalizer.split.enabled\";\n+  static final boolean DEFAULT_SPLIT_ENABLED = true;\n+  static final String MERGE_ENABLED_KEY = \"hbase.normalizer.merge.enabled\";\n+  static final boolean DEFAULT_MERGE_ENABLED = true;\n+  // TODO: after HBASE-24416, `min.region.count` only applies to merge plans; should\n+  //  deprecate/rename the configuration key.\n+  static final String MIN_REGION_COUNT_KEY = \"hbase.normalizer.min.region.count\";\n+  static final int DEFAULT_MIN_REGION_COUNT = 3;\n+  static final String MERGE_MIN_REGION_AGE_DAYS_KEY = \"hbase.normalizer.merge.min_region_age.days\";\n+  static final int DEFAULT_MERGE_MIN_REGION_AGE_DAYS = 3;\n+  static final String MERGE_MIN_REGION_SIZE_MB_KEY = \"hbase.normalizer.merge.min_region_size.mb\";\n+  static final int DEFAULT_MERGE_MIN_REGION_SIZE_MB = 1;\n+\n+  private final long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+  private final Comparator<NormalizationPlan> planComparator = new SplitPlanFirstComparator();\n+\n+  private Configuration conf;\n+  private MasterServices masterServices;\n+  private boolean splitEnabled;\n+  private boolean mergeEnabled;\n+  private int minRegionCount;\n+  private Period mergeMinRegionAge;\n+  private int mergeMinRegionSizeMb;\n+\n+  public SimpleRegionNormalizer() {\n+    splitEnabled = DEFAULT_SPLIT_ENABLED;\n+    mergeEnabled = DEFAULT_MERGE_ENABLED;\n+    minRegionCount = DEFAULT_MIN_REGION_COUNT;\n+    mergeMinRegionAge = Period.ofDays(DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    mergeMinRegionSizeMb = DEFAULT_MERGE_MIN_REGION_SIZE_MB;\n+  }\n \n   @Override\n-  public void planSkipped(RegionInfo hri, PlanType type) {\n-    skippedCount[type.ordinal()]++;\n+  public Configuration getConf() {\n+    return conf;\n   }\n \n   @Override\n-  public long getSkippedCount(NormalizationPlan.PlanType type) {\n-    return skippedCount[type.ordinal()];\n+  public void setConf(final Configuration conf) {\n+    if (conf == null) {\n+      return;\n+    }\n+    this.conf = conf;\n+    splitEnabled = conf.getBoolean(SPLIT_ENABLED_KEY, DEFAULT_SPLIT_ENABLED);\n+    mergeEnabled = conf.getBoolean(MERGE_ENABLED_KEY, DEFAULT_MERGE_ENABLED);\n+    minRegionCount = parseMinRegionCount(conf);\n+    mergeMinRegionAge = parseMergeMinRegionAge(conf);\n+    mergeMinRegionSizeMb = parseMergeMinRegionSizeMb(conf);\n+  }\n+\n+  private static int parseMinRegionCount(final Configuration conf) {\n+    final int parsedValue = conf.getInt(MIN_REGION_COUNT_KEY, DEFAULT_MIN_REGION_COUNT);\n+    final int settledValue = Math.max(1, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MIN_REGION_COUNT_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static Period parseMergeMinRegionAge(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_AGE_DAYS_KEY, DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_AGE_DAYS_KEY, parsedValue, settledValue);\n+    }\n+    return Period.ofDays(settledValue);\n+  }\n+\n+  private static int parseMergeMinRegionSizeMb(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_SIZE_MB_KEY, DEFAULT_MERGE_MIN_REGION_SIZE_MB);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_SIZE_MB_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static <T> void warnInvalidValue(final String key, final T parsedValue,\n+    final T settledValue) {\n+    LOG.warn(\"Configured value {}={} is invalid. Setting value to {}.\",\n+      key, parsedValue, settledValue);\n   }\n \n   /**\n-   * Comparator class that gives higher priority to region Split plan.\n+   * Return this instance's configured value for {@value SPLIT_ENABLED_KEY}.\n    */\n-  static class PlanComparator implements Comparator<NormalizationPlan> {\n-    @Override\n-    public int compare(NormalizationPlan plan1, NormalizationPlan plan2) {\n-      boolean plan1IsSplit = plan1 instanceof SplitNormalizationPlan;\n-      boolean plan2IsSplit = plan2 instanceof SplitNormalizationPlan;\n-      if (plan1IsSplit && plan2IsSplit) {\n-        return 0;\n-      } else if (plan1IsSplit) {\n-        return -1;\n-      } else if (plan2IsSplit) {\n-        return 1;\n-      } else {\n-        return 0;\n-      }\n-    }\n+  public boolean isSplitEnabled() {\n+    return splitEnabled;\n   }\n \n-  private Comparator<NormalizationPlan> planComparator = new PlanComparator();\n+  /**\n+   * Return this instance's configured value for {@value MERGE_ENABLED_KEY}.\n+   */\n+  public boolean isMergeEnabled() {\n+    return mergeEnabled;\n+  }\n \n   /**\n-   * Computes next most \"urgent\" normalization action on the table. Action may be either a split, or\n-   * a merge, or no action.\n-   * @param table table to normalize\n-   * @return normalization plan to execute\n+   * Return this instance's configured value for {@value MIN_REGION_COUNT_KEY}.\n+   */\n+  public int getMinRegionCount() {\n+    return minRegionCount;\n+  }\n+\n+  /**\n+   * Return this instance's configured value for {@value MERGE_MIN_REGION_AGE_DAYS_KEY}.\n    */\n+  public Period getMergeMinRegionAge() {\n+    return mergeMinRegionAge;\n+  }\n+\n+  /**\n+   * Return this instance's configured value for {@value MERGE_MIN_REGION_SIZE_MB_KEY}.\n+   */\n+  public int getMergeMinRegionSizeMb() {\n+    return mergeMinRegionSizeMb;\n+  }\n+\n   @Override\n-  public List<NormalizationPlan> computePlanForTable(TableName table) throws HBaseIOException {\n+  public void setMasterServices(final MasterServices masterServices) {\n+    this.masterServices = masterServices;\n+  }\n+\n+  @Override\n+  public void planSkipped(final RegionInfo hri, final PlanType type) {\n+    skippedCount[type.ordinal()]++;\n+  }\n+\n+  @Override\n+  public long getSkippedCount(NormalizationPlan.PlanType type) {\n+    return skippedCount[type.ordinal()];\n+  }\n+\n+  @Override\n+  public List<NormalizationPlan> computePlansForTable(TableName table) {\n     if (table == null || table.isSystemTable()) {\n       LOG.debug(\"Normalization of system table {} isn't allowed\", table);\n-      return null;\n+      return Collections.emptyList();\n     }\n-    boolean splitEnabled = isSplitEnabled();\n-    boolean mergeEnabled = isMergeEnabled();\n+    boolean splitEnabled = isSplitEnabled() && isMasterSwitchEnabled(MasterSwitchType.SPLIT);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI4MjU2Mg=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 259}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4NjI3OTI2OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SplitPlanFirstComparator.java", "isResolved": true, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxNjozODoxMFrOGbTkuA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQwMDoyMjo0MlrOGcK-tw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI4NTQzMg==", "bodyText": "Why. And should we sort by table order too?", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431285432", "createdAt": "2020-05-27T16:38:10Z", "author": {"login": "saintstack"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SplitPlanFirstComparator.java", "diffHunk": "@@ -0,0 +1,40 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.master.normalizer;\n+\n+import java.util.Comparator;\n+\n+/**\n+ * Comparator class that gives higher priority to {@link SplitNormalizationPlan}.\n+ */\n+class SplitPlanFirstComparator implements Comparator<NormalizationPlan> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQyNjEzNQ==", "bodyText": "This is for sorting plans within one table, does not seem it is necessary though.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431426135", "createdAt": "2020-05-27T20:35:55Z", "author": {"login": "huaxiangsun"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SplitPlanFirstComparator.java", "diffHunk": "@@ -0,0 +1,40 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.master.normalizer;\n+\n+import java.util.Comparator;\n+\n+/**\n+ * Comparator class that gives higher priority to {@link SplitNormalizationPlan}.\n+ */\n+class SplitPlanFirstComparator implements Comparator<NormalizationPlan> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI4NTQzMg=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQzMDkyMA==", "bodyText": "Good question. I don't know the history of this class.\nMy original theory is something to do with splits vs. merges. If somehow a region is involved in both a split and a merge plan, the split would happen first and the merge would fail. This gives priority to splits (which I think is intentional), but is a bit ugly. I think a final validation and optimization pass should be taken over the resulting plan list, which is a superset of what's proposed in HBASE-24418.\nAs for table ordering, the normalizer is invoked once per table, so there's no case where plans for multiple tables would be in the same collection. At least, not in current implementation.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431430920", "createdAt": "2020-05-27T20:45:07Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SplitPlanFirstComparator.java", "diffHunk": "@@ -0,0 +1,40 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.master.normalizer;\n+\n+import java.util.Comparator;\n+\n+/**\n+ * Comparator class that gives higher priority to {@link SplitNormalizationPlan}.\n+ */\n+class SplitPlanFirstComparator implements Comparator<NormalizationPlan> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI4NTQzMg=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQ1NzY0OQ==", "bodyText": "I meant regions in the table order... i.e. do the plan for early table REgions first..... But yeah, can be punted to later.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431457649", "createdAt": "2020-05-27T21:38:42Z", "author": {"login": "saintstack"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SplitPlanFirstComparator.java", "diffHunk": "@@ -0,0 +1,40 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.master.normalizer;\n+\n+import java.util.Comparator;\n+\n+/**\n+ * Comparator class that gives higher priority to {@link SplitNormalizationPlan}.\n+ */\n+class SplitPlanFirstComparator implements Comparator<NormalizationPlan> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI4NTQzMg=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTU4MDU2Nw==", "bodyText": "The PlanComparator compares plans based on if it is a split or merge. It puts all split plan at the head of the list and merge plans put to the end of the list.\nBased on the addToList order, split plans are already added first, followed by merge plans, so my understanding is that this sort does nothing.\nplans.sort(planComparator);\nWe can get rid of this comparator totally and simplify the code. Something missing in my understanding?", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431580567", "createdAt": "2020-05-28T04:53:58Z", "author": {"login": "huaxiangsun"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SplitPlanFirstComparator.java", "diffHunk": "@@ -0,0 +1,40 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.master.normalizer;\n+\n+import java.util.Comparator;\n+\n+/**\n+ * Comparator class that gives higher priority to {@link SplitNormalizationPlan}.\n+ */\n+class SplitPlanFirstComparator implements Comparator<NormalizationPlan> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI4NTQzMg=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE5MzIwNw==", "bodyText": "Reading through the old patches, i think this is an appendix we can safely discard.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r432193207", "createdAt": "2020-05-29T00:22:42Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SplitPlanFirstComparator.java", "diffHunk": "@@ -0,0 +1,40 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.master.normalizer;\n+\n+import java.util.Comparator;\n+\n+/**\n+ * Comparator class that gives higher priority to {@link SplitNormalizationPlan}.\n+ */\n+class SplitPlanFirstComparator implements Comparator<NormalizationPlan> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI4NTQzMg=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4NjI4NTMwOnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxNjozOTo1NFrOGbTouQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QyMDozNjowOFrOGbcKvQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI4NjQ1Nw==", "bodyText": "regionCount can't be zero here?", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431286457", "createdAt": "2020-05-27T16:39:54Z", "author": {"login": "saintstack"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,436 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>\n+ *   <li>Otherwise, for the next region in the chain R1, if R0 + R1 is smaller then S, R0 and R1\n+ *     are kindly requested to merge.</li>\n+ * </ol>\n+ * <p>\n+ * The following parameters are configurable:\n+ * <ol>\n+ *   <li>Whether to split a region as part of normalization. Configuration:\n+ *     {@value SPLIT_ENABLED_KEY}, default: {@value DEFAULT_SPLIT_ENABLED}.</li>\n+ *   <li>Whether to merge a region as part of normalization. Configuration:\n+ *     {@value MERGE_ENABLED_KEY}, default: {@value DEFAULT_MERGE_ENABLED}.</li>\n+ *   <li>The minimum number of regions in a table to consider it for normalization. Configuration:\n+ *     {@value MIN_REGION_COUNT_KEY}, default: {@value DEFAULT_MIN_REGION_COUNT}.</li>\n+ *   <li>The minimum age for a region to be considered for a merge, in days. Configuration:\n+ *     {@value MERGE_MIN_REGION_AGE_DAYS_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_AGE_DAYS}.</li>\n+ *   <li>The minimum size for a region to be considered for a merge, in whole MBs. Configuration:\n+ *     {@value MERGE_MIN_REGION_SIZE_MB_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_SIZE_MB}.</li>\n  * </ol>\n  * <p>\n- * Region sizes are coarse and approximate on the order of megabytes. Additionally, \"empty\" regions\n- * (less than 1MB, with the previous note) are not merged away. This is by design to prevent\n- * normalization from undoing the pre-splitting of a table.\n+ * To see detailed logging of the application of these configuration values, set the log level for\n+ * this class to `TRACE`.\n  */\n-@InterfaceAudience.Private\n-public class SimpleRegionNormalizer extends AbstractRegionNormalizer {\n-\n+@InterfaceAudience.LimitedPrivate(HBaseInterfaceAudience.CONFIG)\n+public class SimpleRegionNormalizer implements RegionNormalizer {\n   private static final Logger LOG = LoggerFactory.getLogger(SimpleRegionNormalizer.class);\n-  private static long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+\n+  static final String SPLIT_ENABLED_KEY = \"hbase.normalizer.split.enabled\";\n+  static final boolean DEFAULT_SPLIT_ENABLED = true;\n+  static final String MERGE_ENABLED_KEY = \"hbase.normalizer.merge.enabled\";\n+  static final boolean DEFAULT_MERGE_ENABLED = true;\n+  // TODO: after HBASE-24416, `min.region.count` only applies to merge plans; should\n+  //  deprecate/rename the configuration key.\n+  static final String MIN_REGION_COUNT_KEY = \"hbase.normalizer.min.region.count\";\n+  static final int DEFAULT_MIN_REGION_COUNT = 3;\n+  static final String MERGE_MIN_REGION_AGE_DAYS_KEY = \"hbase.normalizer.merge.min_region_age.days\";\n+  static final int DEFAULT_MERGE_MIN_REGION_AGE_DAYS = 3;\n+  static final String MERGE_MIN_REGION_SIZE_MB_KEY = \"hbase.normalizer.merge.min_region_size.mb\";\n+  static final int DEFAULT_MERGE_MIN_REGION_SIZE_MB = 1;\n+\n+  private final long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+  private final Comparator<NormalizationPlan> planComparator = new SplitPlanFirstComparator();\n+\n+  private Configuration conf;\n+  private MasterServices masterServices;\n+  private boolean splitEnabled;\n+  private boolean mergeEnabled;\n+  private int minRegionCount;\n+  private Period mergeMinRegionAge;\n+  private int mergeMinRegionSizeMb;\n+\n+  public SimpleRegionNormalizer() {\n+    splitEnabled = DEFAULT_SPLIT_ENABLED;\n+    mergeEnabled = DEFAULT_MERGE_ENABLED;\n+    minRegionCount = DEFAULT_MIN_REGION_COUNT;\n+    mergeMinRegionAge = Period.ofDays(DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    mergeMinRegionSizeMb = DEFAULT_MERGE_MIN_REGION_SIZE_MB;\n+  }\n \n   @Override\n-  public void planSkipped(RegionInfo hri, PlanType type) {\n-    skippedCount[type.ordinal()]++;\n+  public Configuration getConf() {\n+    return conf;\n   }\n \n   @Override\n-  public long getSkippedCount(NormalizationPlan.PlanType type) {\n-    return skippedCount[type.ordinal()];\n+  public void setConf(final Configuration conf) {\n+    if (conf == null) {\n+      return;\n+    }\n+    this.conf = conf;\n+    splitEnabled = conf.getBoolean(SPLIT_ENABLED_KEY, DEFAULT_SPLIT_ENABLED);\n+    mergeEnabled = conf.getBoolean(MERGE_ENABLED_KEY, DEFAULT_MERGE_ENABLED);\n+    minRegionCount = parseMinRegionCount(conf);\n+    mergeMinRegionAge = parseMergeMinRegionAge(conf);\n+    mergeMinRegionSizeMb = parseMergeMinRegionSizeMb(conf);\n+  }\n+\n+  private static int parseMinRegionCount(final Configuration conf) {\n+    final int parsedValue = conf.getInt(MIN_REGION_COUNT_KEY, DEFAULT_MIN_REGION_COUNT);\n+    final int settledValue = Math.max(1, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MIN_REGION_COUNT_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static Period parseMergeMinRegionAge(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_AGE_DAYS_KEY, DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_AGE_DAYS_KEY, parsedValue, settledValue);\n+    }\n+    return Period.ofDays(settledValue);\n+  }\n+\n+  private static int parseMergeMinRegionSizeMb(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_SIZE_MB_KEY, DEFAULT_MERGE_MIN_REGION_SIZE_MB);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_SIZE_MB_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static <T> void warnInvalidValue(final String key, final T parsedValue,\n+    final T settledValue) {\n+    LOG.warn(\"Configured value {}={} is invalid. Setting value to {}.\",\n+      key, parsedValue, settledValue);\n   }\n \n   /**\n-   * Comparator class that gives higher priority to region Split plan.\n+   * Return this instance's configured value for {@value SPLIT_ENABLED_KEY}.\n    */\n-  static class PlanComparator implements Comparator<NormalizationPlan> {\n-    @Override\n-    public int compare(NormalizationPlan plan1, NormalizationPlan plan2) {\n-      boolean plan1IsSplit = plan1 instanceof SplitNormalizationPlan;\n-      boolean plan2IsSplit = plan2 instanceof SplitNormalizationPlan;\n-      if (plan1IsSplit && plan2IsSplit) {\n-        return 0;\n-      } else if (plan1IsSplit) {\n-        return -1;\n-      } else if (plan2IsSplit) {\n-        return 1;\n-      } else {\n-        return 0;\n-      }\n-    }\n+  public boolean isSplitEnabled() {\n+    return splitEnabled;\n   }\n \n-  private Comparator<NormalizationPlan> planComparator = new PlanComparator();\n+  /**\n+   * Return this instance's configured value for {@value MERGE_ENABLED_KEY}.\n+   */\n+  public boolean isMergeEnabled() {\n+    return mergeEnabled;\n+  }\n \n   /**\n-   * Computes next most \"urgent\" normalization action on the table. Action may be either a split, or\n-   * a merge, or no action.\n-   * @param table table to normalize\n-   * @return normalization plan to execute\n+   * Return this instance's configured value for {@value MIN_REGION_COUNT_KEY}.\n+   */\n+  public int getMinRegionCount() {\n+    return minRegionCount;\n+  }\n+\n+  /**\n+   * Return this instance's configured value for {@value MERGE_MIN_REGION_AGE_DAYS_KEY}.\n    */\n+  public Period getMergeMinRegionAge() {\n+    return mergeMinRegionAge;\n+  }\n+\n+  /**\n+   * Return this instance's configured value for {@value MERGE_MIN_REGION_SIZE_MB_KEY}.\n+   */\n+  public int getMergeMinRegionSizeMb() {\n+    return mergeMinRegionSizeMb;\n+  }\n+\n   @Override\n-  public List<NormalizationPlan> computePlanForTable(TableName table) throws HBaseIOException {\n+  public void setMasterServices(final MasterServices masterServices) {\n+    this.masterServices = masterServices;\n+  }\n+\n+  @Override\n+  public void planSkipped(final RegionInfo hri, final PlanType type) {\n+    skippedCount[type.ordinal()]++;\n+  }\n+\n+  @Override\n+  public long getSkippedCount(NormalizationPlan.PlanType type) {\n+    return skippedCount[type.ordinal()];\n+  }\n+\n+  @Override\n+  public List<NormalizationPlan> computePlansForTable(TableName table) {\n     if (table == null || table.isSystemTable()) {\n       LOG.debug(\"Normalization of system table {} isn't allowed\", table);\n-      return null;\n+      return Collections.emptyList();\n     }\n-    boolean splitEnabled = isSplitEnabled();\n-    boolean mergeEnabled = isMergeEnabled();\n+    boolean splitEnabled = isSplitEnabled() && isMasterSwitchEnabled(MasterSwitchType.SPLIT);\n+    boolean mergeEnabled = isMergeEnabled() && isMasterSwitchEnabled(MasterSwitchType.MERGE);\n     if (!mergeEnabled && !splitEnabled) {\n-      LOG.debug(\"Both split and merge are disabled for table: {}\", table);\n-      return null;\n+      LOG.debug(\"Both split and merge are disabled. Skipping normalization of table: {}\", table);\n+      return Collections.emptyList();\n     }\n+\n     List<NormalizationPlan> plans = new ArrayList<>();\n-    List<RegionInfo> tableRegions =\n-        masterServices.getAssignmentManager().getRegionStates().getRegionsOfTable(table);\n+    List<RegionInfo> tableRegions = masterServices.getAssignmentManager()\n+      .getRegionStates()\n+      .getRegionsOfTable(table);\n \n-    if (tableRegions == null) {\n-      return null;\n+    if (CollectionUtils.isEmpty(tableRegions)) {\n+      return Collections.emptyList();\n     }\n \n     LOG.debug(\"Computing normalization plan for table:  {}, number of regions: {}\", table,\n       tableRegions.size());\n \n     if (splitEnabled) {\n-      List<NormalizationPlan> splitPlans = getSplitNormalizationPlan(table);\n-      if (splitPlans != null) {\n-        plans.addAll(splitPlans);\n+      plans.addAll(computeSplitNormalizationPlans(table));\n+    }\n+    if (mergeEnabled) {\n+      plans.addAll(computeMergeNormalizationPlans(table));\n+    }\n+\n+    plans.sort(planComparator);\n+    LOG.debug(\"Computed {} normalization plans for table {}\", plans.size(), table);\n+    return plans;\n+  }\n+\n+  /**\n+   * @return size of region in MB and if region is not found than -1\n+   */\n+  private long getRegionSizeMB(RegionInfo hri) {\n+    ServerName sn =\n+      masterServices.getAssignmentManager().getRegionStates().getRegionServerOfRegion(hri);\n+    RegionMetrics regionLoad =\n+      masterServices.getServerManager().getLoad(sn).getRegionMetrics().get(hri.getRegionName());\n+    if (regionLoad == null) {\n+      LOG.debug(\"{} was not found in RegionsLoad\", hri.getRegionNameAsString());\n+      return -1;\n+    }\n+    return (long) regionLoad.getStoreFileSize().get(Size.Unit.MEGABYTE);\n+  }\n+\n+  private boolean isMasterSwitchEnabled(final MasterSwitchType masterSwitchType) {\n+    return masterServices.isSplitOrMergeEnabled(masterSwitchType);\n+  }\n+\n+  /**\n+   * @param tableRegions regions of table to normalize\n+   * @return average region size depending on\n+   * @see org.apache.hadoop.hbase.client.TableDescriptor#getNormalizerTargetRegionCount()\n+   * Also make sure tableRegions contains regions of the same table\n+   */\n+  private double getAverageRegionSize(List<RegionInfo> tableRegions) {\n+    if (CollectionUtils.isEmpty(tableRegions)) {\n+      throw new IllegalStateException(\n+        \"Cannot calculate average size of a table without any regions.\");\n+    }\n+    final int regionCount = tableRegions.size();\n+    final long totalSizeMb = tableRegions.stream()\n+      .mapToLong(this::getRegionSizeMB)\n+      .sum();\n+    TableName table = tableRegions.get(0).getTable();\n+    int targetRegionCount = -1;\n+    long targetRegionSize = -1;\n+    try {\n+      TableDescriptor tableDescriptor = masterServices.getTableDescriptors().get(table);\n+      if (tableDescriptor != null) {\n+        targetRegionCount = tableDescriptor.getNormalizerTargetRegionCount();\n+        targetRegionSize = tableDescriptor.getNormalizerTargetRegionSize();\n+        LOG.debug(\"Table {} configured with target region count {}, target region size {}\", table,\n+          targetRegionCount, targetRegionSize);\n       }\n+    } catch (IOException e) {\n+      LOG.warn(\"TableDescriptor for {} unavailable, table-level target region count and size\"\n+        + \" configurations cannot be considered.\", table, e);\n     }\n \n-    if (mergeEnabled) {\n-      if (tableRegions.size() < minRegionCount) {\n-        LOG.debug(\"Table {} has {} regions, required min number of regions for normalizer to run\" +\n-                \" is {}, not running normalizer\",\n-            table, tableRegions.size(), minRegionCount);\n-      } else {\n-        List<NormalizationPlan> mergePlans = getMergeNormalizationPlan(table);\n-        if (mergePlans != null) {\n-          plans.addAll(mergePlans);\n-        }\n+    double avgRegionSize;\n+    if (targetRegionSize > 0) {\n+      avgRegionSize = targetRegionSize;\n+    } else if (targetRegionCount > 0) {\n+      avgRegionSize = totalSizeMb / (double) targetRegionCount;\n+    } else {\n+      avgRegionSize = totalSizeMb / (double) regionCount;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 365}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQyNjIzNw==", "bodyText": "Nope, it can't. The first line of the method checks that the argument is non-null and non-empty.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431426237", "createdAt": "2020-05-27T20:36:08Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,436 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>\n+ *   <li>Otherwise, for the next region in the chain R1, if R0 + R1 is smaller then S, R0 and R1\n+ *     are kindly requested to merge.</li>\n+ * </ol>\n+ * <p>\n+ * The following parameters are configurable:\n+ * <ol>\n+ *   <li>Whether to split a region as part of normalization. Configuration:\n+ *     {@value SPLIT_ENABLED_KEY}, default: {@value DEFAULT_SPLIT_ENABLED}.</li>\n+ *   <li>Whether to merge a region as part of normalization. Configuration:\n+ *     {@value MERGE_ENABLED_KEY}, default: {@value DEFAULT_MERGE_ENABLED}.</li>\n+ *   <li>The minimum number of regions in a table to consider it for normalization. Configuration:\n+ *     {@value MIN_REGION_COUNT_KEY}, default: {@value DEFAULT_MIN_REGION_COUNT}.</li>\n+ *   <li>The minimum age for a region to be considered for a merge, in days. Configuration:\n+ *     {@value MERGE_MIN_REGION_AGE_DAYS_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_AGE_DAYS}.</li>\n+ *   <li>The minimum size for a region to be considered for a merge, in whole MBs. Configuration:\n+ *     {@value MERGE_MIN_REGION_SIZE_MB_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_SIZE_MB}.</li>\n  * </ol>\n  * <p>\n- * Region sizes are coarse and approximate on the order of megabytes. Additionally, \"empty\" regions\n- * (less than 1MB, with the previous note) are not merged away. This is by design to prevent\n- * normalization from undoing the pre-splitting of a table.\n+ * To see detailed logging of the application of these configuration values, set the log level for\n+ * this class to `TRACE`.\n  */\n-@InterfaceAudience.Private\n-public class SimpleRegionNormalizer extends AbstractRegionNormalizer {\n-\n+@InterfaceAudience.LimitedPrivate(HBaseInterfaceAudience.CONFIG)\n+public class SimpleRegionNormalizer implements RegionNormalizer {\n   private static final Logger LOG = LoggerFactory.getLogger(SimpleRegionNormalizer.class);\n-  private static long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+\n+  static final String SPLIT_ENABLED_KEY = \"hbase.normalizer.split.enabled\";\n+  static final boolean DEFAULT_SPLIT_ENABLED = true;\n+  static final String MERGE_ENABLED_KEY = \"hbase.normalizer.merge.enabled\";\n+  static final boolean DEFAULT_MERGE_ENABLED = true;\n+  // TODO: after HBASE-24416, `min.region.count` only applies to merge plans; should\n+  //  deprecate/rename the configuration key.\n+  static final String MIN_REGION_COUNT_KEY = \"hbase.normalizer.min.region.count\";\n+  static final int DEFAULT_MIN_REGION_COUNT = 3;\n+  static final String MERGE_MIN_REGION_AGE_DAYS_KEY = \"hbase.normalizer.merge.min_region_age.days\";\n+  static final int DEFAULT_MERGE_MIN_REGION_AGE_DAYS = 3;\n+  static final String MERGE_MIN_REGION_SIZE_MB_KEY = \"hbase.normalizer.merge.min_region_size.mb\";\n+  static final int DEFAULT_MERGE_MIN_REGION_SIZE_MB = 1;\n+\n+  private final long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+  private final Comparator<NormalizationPlan> planComparator = new SplitPlanFirstComparator();\n+\n+  private Configuration conf;\n+  private MasterServices masterServices;\n+  private boolean splitEnabled;\n+  private boolean mergeEnabled;\n+  private int minRegionCount;\n+  private Period mergeMinRegionAge;\n+  private int mergeMinRegionSizeMb;\n+\n+  public SimpleRegionNormalizer() {\n+    splitEnabled = DEFAULT_SPLIT_ENABLED;\n+    mergeEnabled = DEFAULT_MERGE_ENABLED;\n+    minRegionCount = DEFAULT_MIN_REGION_COUNT;\n+    mergeMinRegionAge = Period.ofDays(DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    mergeMinRegionSizeMb = DEFAULT_MERGE_MIN_REGION_SIZE_MB;\n+  }\n \n   @Override\n-  public void planSkipped(RegionInfo hri, PlanType type) {\n-    skippedCount[type.ordinal()]++;\n+  public Configuration getConf() {\n+    return conf;\n   }\n \n   @Override\n-  public long getSkippedCount(NormalizationPlan.PlanType type) {\n-    return skippedCount[type.ordinal()];\n+  public void setConf(final Configuration conf) {\n+    if (conf == null) {\n+      return;\n+    }\n+    this.conf = conf;\n+    splitEnabled = conf.getBoolean(SPLIT_ENABLED_KEY, DEFAULT_SPLIT_ENABLED);\n+    mergeEnabled = conf.getBoolean(MERGE_ENABLED_KEY, DEFAULT_MERGE_ENABLED);\n+    minRegionCount = parseMinRegionCount(conf);\n+    mergeMinRegionAge = parseMergeMinRegionAge(conf);\n+    mergeMinRegionSizeMb = parseMergeMinRegionSizeMb(conf);\n+  }\n+\n+  private static int parseMinRegionCount(final Configuration conf) {\n+    final int parsedValue = conf.getInt(MIN_REGION_COUNT_KEY, DEFAULT_MIN_REGION_COUNT);\n+    final int settledValue = Math.max(1, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MIN_REGION_COUNT_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static Period parseMergeMinRegionAge(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_AGE_DAYS_KEY, DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_AGE_DAYS_KEY, parsedValue, settledValue);\n+    }\n+    return Period.ofDays(settledValue);\n+  }\n+\n+  private static int parseMergeMinRegionSizeMb(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_SIZE_MB_KEY, DEFAULT_MERGE_MIN_REGION_SIZE_MB);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_SIZE_MB_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static <T> void warnInvalidValue(final String key, final T parsedValue,\n+    final T settledValue) {\n+    LOG.warn(\"Configured value {}={} is invalid. Setting value to {}.\",\n+      key, parsedValue, settledValue);\n   }\n \n   /**\n-   * Comparator class that gives higher priority to region Split plan.\n+   * Return this instance's configured value for {@value SPLIT_ENABLED_KEY}.\n    */\n-  static class PlanComparator implements Comparator<NormalizationPlan> {\n-    @Override\n-    public int compare(NormalizationPlan plan1, NormalizationPlan plan2) {\n-      boolean plan1IsSplit = plan1 instanceof SplitNormalizationPlan;\n-      boolean plan2IsSplit = plan2 instanceof SplitNormalizationPlan;\n-      if (plan1IsSplit && plan2IsSplit) {\n-        return 0;\n-      } else if (plan1IsSplit) {\n-        return -1;\n-      } else if (plan2IsSplit) {\n-        return 1;\n-      } else {\n-        return 0;\n-      }\n-    }\n+  public boolean isSplitEnabled() {\n+    return splitEnabled;\n   }\n \n-  private Comparator<NormalizationPlan> planComparator = new PlanComparator();\n+  /**\n+   * Return this instance's configured value for {@value MERGE_ENABLED_KEY}.\n+   */\n+  public boolean isMergeEnabled() {\n+    return mergeEnabled;\n+  }\n \n   /**\n-   * Computes next most \"urgent\" normalization action on the table. Action may be either a split, or\n-   * a merge, or no action.\n-   * @param table table to normalize\n-   * @return normalization plan to execute\n+   * Return this instance's configured value for {@value MIN_REGION_COUNT_KEY}.\n+   */\n+  public int getMinRegionCount() {\n+    return minRegionCount;\n+  }\n+\n+  /**\n+   * Return this instance's configured value for {@value MERGE_MIN_REGION_AGE_DAYS_KEY}.\n    */\n+  public Period getMergeMinRegionAge() {\n+    return mergeMinRegionAge;\n+  }\n+\n+  /**\n+   * Return this instance's configured value for {@value MERGE_MIN_REGION_SIZE_MB_KEY}.\n+   */\n+  public int getMergeMinRegionSizeMb() {\n+    return mergeMinRegionSizeMb;\n+  }\n+\n   @Override\n-  public List<NormalizationPlan> computePlanForTable(TableName table) throws HBaseIOException {\n+  public void setMasterServices(final MasterServices masterServices) {\n+    this.masterServices = masterServices;\n+  }\n+\n+  @Override\n+  public void planSkipped(final RegionInfo hri, final PlanType type) {\n+    skippedCount[type.ordinal()]++;\n+  }\n+\n+  @Override\n+  public long getSkippedCount(NormalizationPlan.PlanType type) {\n+    return skippedCount[type.ordinal()];\n+  }\n+\n+  @Override\n+  public List<NormalizationPlan> computePlansForTable(TableName table) {\n     if (table == null || table.isSystemTable()) {\n       LOG.debug(\"Normalization of system table {} isn't allowed\", table);\n-      return null;\n+      return Collections.emptyList();\n     }\n-    boolean splitEnabled = isSplitEnabled();\n-    boolean mergeEnabled = isMergeEnabled();\n+    boolean splitEnabled = isSplitEnabled() && isMasterSwitchEnabled(MasterSwitchType.SPLIT);\n+    boolean mergeEnabled = isMergeEnabled() && isMasterSwitchEnabled(MasterSwitchType.MERGE);\n     if (!mergeEnabled && !splitEnabled) {\n-      LOG.debug(\"Both split and merge are disabled for table: {}\", table);\n-      return null;\n+      LOG.debug(\"Both split and merge are disabled. Skipping normalization of table: {}\", table);\n+      return Collections.emptyList();\n     }\n+\n     List<NormalizationPlan> plans = new ArrayList<>();\n-    List<RegionInfo> tableRegions =\n-        masterServices.getAssignmentManager().getRegionStates().getRegionsOfTable(table);\n+    List<RegionInfo> tableRegions = masterServices.getAssignmentManager()\n+      .getRegionStates()\n+      .getRegionsOfTable(table);\n \n-    if (tableRegions == null) {\n-      return null;\n+    if (CollectionUtils.isEmpty(tableRegions)) {\n+      return Collections.emptyList();\n     }\n \n     LOG.debug(\"Computing normalization plan for table:  {}, number of regions: {}\", table,\n       tableRegions.size());\n \n     if (splitEnabled) {\n-      List<NormalizationPlan> splitPlans = getSplitNormalizationPlan(table);\n-      if (splitPlans != null) {\n-        plans.addAll(splitPlans);\n+      plans.addAll(computeSplitNormalizationPlans(table));\n+    }\n+    if (mergeEnabled) {\n+      plans.addAll(computeMergeNormalizationPlans(table));\n+    }\n+\n+    plans.sort(planComparator);\n+    LOG.debug(\"Computed {} normalization plans for table {}\", plans.size(), table);\n+    return plans;\n+  }\n+\n+  /**\n+   * @return size of region in MB and if region is not found than -1\n+   */\n+  private long getRegionSizeMB(RegionInfo hri) {\n+    ServerName sn =\n+      masterServices.getAssignmentManager().getRegionStates().getRegionServerOfRegion(hri);\n+    RegionMetrics regionLoad =\n+      masterServices.getServerManager().getLoad(sn).getRegionMetrics().get(hri.getRegionName());\n+    if (regionLoad == null) {\n+      LOG.debug(\"{} was not found in RegionsLoad\", hri.getRegionNameAsString());\n+      return -1;\n+    }\n+    return (long) regionLoad.getStoreFileSize().get(Size.Unit.MEGABYTE);\n+  }\n+\n+  private boolean isMasterSwitchEnabled(final MasterSwitchType masterSwitchType) {\n+    return masterServices.isSplitOrMergeEnabled(masterSwitchType);\n+  }\n+\n+  /**\n+   * @param tableRegions regions of table to normalize\n+   * @return average region size depending on\n+   * @see org.apache.hadoop.hbase.client.TableDescriptor#getNormalizerTargetRegionCount()\n+   * Also make sure tableRegions contains regions of the same table\n+   */\n+  private double getAverageRegionSize(List<RegionInfo> tableRegions) {\n+    if (CollectionUtils.isEmpty(tableRegions)) {\n+      throw new IllegalStateException(\n+        \"Cannot calculate average size of a table without any regions.\");\n+    }\n+    final int regionCount = tableRegions.size();\n+    final long totalSizeMb = tableRegions.stream()\n+      .mapToLong(this::getRegionSizeMB)\n+      .sum();\n+    TableName table = tableRegions.get(0).getTable();\n+    int targetRegionCount = -1;\n+    long targetRegionSize = -1;\n+    try {\n+      TableDescriptor tableDescriptor = masterServices.getTableDescriptors().get(table);\n+      if (tableDescriptor != null) {\n+        targetRegionCount = tableDescriptor.getNormalizerTargetRegionCount();\n+        targetRegionSize = tableDescriptor.getNormalizerTargetRegionSize();\n+        LOG.debug(\"Table {} configured with target region count {}, target region size {}\", table,\n+          targetRegionCount, targetRegionSize);\n       }\n+    } catch (IOException e) {\n+      LOG.warn(\"TableDescriptor for {} unavailable, table-level target region count and size\"\n+        + \" configurations cannot be considered.\", table, e);\n     }\n \n-    if (mergeEnabled) {\n-      if (tableRegions.size() < minRegionCount) {\n-        LOG.debug(\"Table {} has {} regions, required min number of regions for normalizer to run\" +\n-                \" is {}, not running normalizer\",\n-            table, tableRegions.size(), minRegionCount);\n-      } else {\n-        List<NormalizationPlan> mergePlans = getMergeNormalizationPlan(table);\n-        if (mergePlans != null) {\n-          plans.addAll(mergePlans);\n-        }\n+    double avgRegionSize;\n+    if (targetRegionSize > 0) {\n+      avgRegionSize = targetRegionSize;\n+    } else if (targetRegionCount > 0) {\n+      avgRegionSize = totalSizeMb / (double) targetRegionCount;\n+    } else {\n+      avgRegionSize = totalSizeMb / (double) regionCount;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI4NjQ1Nw=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 365}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4Njk3MDgxOnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxOTozOTozMVrOGbacyA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxOTozOTozMVrOGbacyA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM5ODA4OA==", "bodyText": "Sorry, this is an enhancement, can\nfinal Admin admin = asyncClusterConnection.toConnection().getAdmin() be moved to before\nfor (TableName table : allEnabledTables) {\nso it wont create a admin instance for each table?", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431398088", "createdAt": "2020-05-27T19:39:31Z", "author": {"login": "huaxiangsun"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "diffHunk": "@@ -1911,43 +1912,51 @@ public boolean normalizeRegions() throws IOException {\n       return false;\n     }\n \n-    synchronized (this.normalizer) {\n+    if (!normalizationInProgressLock.tryLock()) {\n       // Don't run the normalizer concurrently\n+      LOG.info(\"Normalization already in progress. Skipping request.\");\n+    } else {\n+      try {\n+        List<TableName> allEnabledTables = new ArrayList<>(\n+          tableStateManager.getTablesInStates(TableState.State.ENABLED));\n+        Collections.shuffle(allEnabledTables);\n \n-      List<TableName> allEnabledTables = new ArrayList<>(\n-        this.tableStateManager.getTablesInStates(TableState.State.ENABLED));\n-\n-      Collections.shuffle(allEnabledTables);\n-\n-      for (TableName table : allEnabledTables) {\n-        TableDescriptor tblDesc = getTableDescriptors().get(table);\n-        if (table.isSystemTable() || (tblDesc != null &&\n-            !tblDesc.isNormalizationEnabled())) {\n-          LOG.trace(\"Skipping normalization for {}, as it's either system\"\n-              + \" table or doesn't have auto normalization turned on\", table);\n-          continue;\n-        }\n+        for (TableName table : allEnabledTables) {\n+          if (table.isSystemTable()) {\n+            continue;\n+          }\n+          final TableDescriptor tblDesc = getTableDescriptors().get(table);\n+          if (tblDesc != null && !tblDesc.isNormalizationEnabled()) {\n+            LOG.debug(\n+              \"Skipping {} because normalization is disabled in its table properties.\", table);\n+            continue;\n+          }\n \n-        // make one last check that the cluster isn't shutting down before proceeding.\n-        if (skipRegionManagementAction(\"region normalizer\")) {\n-          return false;\n-        }\n+          // make one last check that the cluster isn't shutting down before proceeding.\n+          if (skipRegionManagementAction(\"region normalizer\")) {\n+            return false;\n+          }\n \n-        final List<NormalizationPlan> plans = this.normalizer.computePlanForTable(table);\n-        if (CollectionUtils.isEmpty(plans)) {\n-          return true;\n-        }\n+          final List<NormalizationPlan> plans = normalizer.computePlansForTable(table);\n+          if (CollectionUtils.isEmpty(plans)) {\n+            return true;\n+          }\n \n-        try (final Admin admin = asyncClusterConnection.toConnection().getAdmin()) {\n-          for (NormalizationPlan plan : plans) {\n-            plan.execute(admin);\n-            if (plan.getType() == PlanType.SPLIT) {\n-              splitPlanCount++;\n-            } else if (plan.getType() == PlanType.MERGE) {\n-              mergePlanCount++;\n+          try (final Admin admin = asyncClusterConnection.toConnection().getAdmin()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 96}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4NzA1NjAyOnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QyMDowNzo0MlrOGbbUAg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QyMDozMzoyMFrOGbcFIQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQxMjIyNg==", "bodyText": "Seems this sort is unnecessary? All split plans are added to the head of the list, followed by merge plans. Sorry, this is the original code.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431412226", "createdAt": "2020-05-27T20:07:42Z", "author": {"login": "huaxiangsun"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,436 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>\n+ *   <li>Otherwise, for the next region in the chain R1, if R0 + R1 is smaller then S, R0 and R1\n+ *     are kindly requested to merge.</li>\n+ * </ol>\n+ * <p>\n+ * The following parameters are configurable:\n+ * <ol>\n+ *   <li>Whether to split a region as part of normalization. Configuration:\n+ *     {@value SPLIT_ENABLED_KEY}, default: {@value DEFAULT_SPLIT_ENABLED}.</li>\n+ *   <li>Whether to merge a region as part of normalization. Configuration:\n+ *     {@value MERGE_ENABLED_KEY}, default: {@value DEFAULT_MERGE_ENABLED}.</li>\n+ *   <li>The minimum number of regions in a table to consider it for normalization. Configuration:\n+ *     {@value MIN_REGION_COUNT_KEY}, default: {@value DEFAULT_MIN_REGION_COUNT}.</li>\n+ *   <li>The minimum age for a region to be considered for a merge, in days. Configuration:\n+ *     {@value MERGE_MIN_REGION_AGE_DAYS_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_AGE_DAYS}.</li>\n+ *   <li>The minimum size for a region to be considered for a merge, in whole MBs. Configuration:\n+ *     {@value MERGE_MIN_REGION_SIZE_MB_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_SIZE_MB}.</li>\n  * </ol>\n  * <p>\n- * Region sizes are coarse and approximate on the order of megabytes. Additionally, \"empty\" regions\n- * (less than 1MB, with the previous note) are not merged away. This is by design to prevent\n- * normalization from undoing the pre-splitting of a table.\n+ * To see detailed logging of the application of these configuration values, set the log level for\n+ * this class to `TRACE`.\n  */\n-@InterfaceAudience.Private\n-public class SimpleRegionNormalizer extends AbstractRegionNormalizer {\n-\n+@InterfaceAudience.LimitedPrivate(HBaseInterfaceAudience.CONFIG)\n+public class SimpleRegionNormalizer implements RegionNormalizer {\n   private static final Logger LOG = LoggerFactory.getLogger(SimpleRegionNormalizer.class);\n-  private static long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+\n+  static final String SPLIT_ENABLED_KEY = \"hbase.normalizer.split.enabled\";\n+  static final boolean DEFAULT_SPLIT_ENABLED = true;\n+  static final String MERGE_ENABLED_KEY = \"hbase.normalizer.merge.enabled\";\n+  static final boolean DEFAULT_MERGE_ENABLED = true;\n+  // TODO: after HBASE-24416, `min.region.count` only applies to merge plans; should\n+  //  deprecate/rename the configuration key.\n+  static final String MIN_REGION_COUNT_KEY = \"hbase.normalizer.min.region.count\";\n+  static final int DEFAULT_MIN_REGION_COUNT = 3;\n+  static final String MERGE_MIN_REGION_AGE_DAYS_KEY = \"hbase.normalizer.merge.min_region_age.days\";\n+  static final int DEFAULT_MERGE_MIN_REGION_AGE_DAYS = 3;\n+  static final String MERGE_MIN_REGION_SIZE_MB_KEY = \"hbase.normalizer.merge.min_region_size.mb\";\n+  static final int DEFAULT_MERGE_MIN_REGION_SIZE_MB = 1;\n+\n+  private final long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+  private final Comparator<NormalizationPlan> planComparator = new SplitPlanFirstComparator();\n+\n+  private Configuration conf;\n+  private MasterServices masterServices;\n+  private boolean splitEnabled;\n+  private boolean mergeEnabled;\n+  private int minRegionCount;\n+  private Period mergeMinRegionAge;\n+  private int mergeMinRegionSizeMb;\n+\n+  public SimpleRegionNormalizer() {\n+    splitEnabled = DEFAULT_SPLIT_ENABLED;\n+    mergeEnabled = DEFAULT_MERGE_ENABLED;\n+    minRegionCount = DEFAULT_MIN_REGION_COUNT;\n+    mergeMinRegionAge = Period.ofDays(DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    mergeMinRegionSizeMb = DEFAULT_MERGE_MIN_REGION_SIZE_MB;\n+  }\n \n   @Override\n-  public void planSkipped(RegionInfo hri, PlanType type) {\n-    skippedCount[type.ordinal()]++;\n+  public Configuration getConf() {\n+    return conf;\n   }\n \n   @Override\n-  public long getSkippedCount(NormalizationPlan.PlanType type) {\n-    return skippedCount[type.ordinal()];\n+  public void setConf(final Configuration conf) {\n+    if (conf == null) {\n+      return;\n+    }\n+    this.conf = conf;\n+    splitEnabled = conf.getBoolean(SPLIT_ENABLED_KEY, DEFAULT_SPLIT_ENABLED);\n+    mergeEnabled = conf.getBoolean(MERGE_ENABLED_KEY, DEFAULT_MERGE_ENABLED);\n+    minRegionCount = parseMinRegionCount(conf);\n+    mergeMinRegionAge = parseMergeMinRegionAge(conf);\n+    mergeMinRegionSizeMb = parseMergeMinRegionSizeMb(conf);\n+  }\n+\n+  private static int parseMinRegionCount(final Configuration conf) {\n+    final int parsedValue = conf.getInt(MIN_REGION_COUNT_KEY, DEFAULT_MIN_REGION_COUNT);\n+    final int settledValue = Math.max(1, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MIN_REGION_COUNT_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static Period parseMergeMinRegionAge(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_AGE_DAYS_KEY, DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_AGE_DAYS_KEY, parsedValue, settledValue);\n+    }\n+    return Period.ofDays(settledValue);\n+  }\n+\n+  private static int parseMergeMinRegionSizeMb(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_SIZE_MB_KEY, DEFAULT_MERGE_MIN_REGION_SIZE_MB);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_SIZE_MB_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static <T> void warnInvalidValue(final String key, final T parsedValue,\n+    final T settledValue) {\n+    LOG.warn(\"Configured value {}={} is invalid. Setting value to {}.\",\n+      key, parsedValue, settledValue);\n   }\n \n   /**\n-   * Comparator class that gives higher priority to region Split plan.\n+   * Return this instance's configured value for {@value SPLIT_ENABLED_KEY}.\n    */\n-  static class PlanComparator implements Comparator<NormalizationPlan> {\n-    @Override\n-    public int compare(NormalizationPlan plan1, NormalizationPlan plan2) {\n-      boolean plan1IsSplit = plan1 instanceof SplitNormalizationPlan;\n-      boolean plan2IsSplit = plan2 instanceof SplitNormalizationPlan;\n-      if (plan1IsSplit && plan2IsSplit) {\n-        return 0;\n-      } else if (plan1IsSplit) {\n-        return -1;\n-      } else if (plan2IsSplit) {\n-        return 1;\n-      } else {\n-        return 0;\n-      }\n-    }\n+  public boolean isSplitEnabled() {\n+    return splitEnabled;\n   }\n \n-  private Comparator<NormalizationPlan> planComparator = new PlanComparator();\n+  /**\n+   * Return this instance's configured value for {@value MERGE_ENABLED_KEY}.\n+   */\n+  public boolean isMergeEnabled() {\n+    return mergeEnabled;\n+  }\n \n   /**\n-   * Computes next most \"urgent\" normalization action on the table. Action may be either a split, or\n-   * a merge, or no action.\n-   * @param table table to normalize\n-   * @return normalization plan to execute\n+   * Return this instance's configured value for {@value MIN_REGION_COUNT_KEY}.\n+   */\n+  public int getMinRegionCount() {\n+    return minRegionCount;\n+  }\n+\n+  /**\n+   * Return this instance's configured value for {@value MERGE_MIN_REGION_AGE_DAYS_KEY}.\n    */\n+  public Period getMergeMinRegionAge() {\n+    return mergeMinRegionAge;\n+  }\n+\n+  /**\n+   * Return this instance's configured value for {@value MERGE_MIN_REGION_SIZE_MB_KEY}.\n+   */\n+  public int getMergeMinRegionSizeMb() {\n+    return mergeMinRegionSizeMb;\n+  }\n+\n   @Override\n-  public List<NormalizationPlan> computePlanForTable(TableName table) throws HBaseIOException {\n+  public void setMasterServices(final MasterServices masterServices) {\n+    this.masterServices = masterServices;\n+  }\n+\n+  @Override\n+  public void planSkipped(final RegionInfo hri, final PlanType type) {\n+    skippedCount[type.ordinal()]++;\n+  }\n+\n+  @Override\n+  public long getSkippedCount(NormalizationPlan.PlanType type) {\n+    return skippedCount[type.ordinal()];\n+  }\n+\n+  @Override\n+  public List<NormalizationPlan> computePlansForTable(TableName table) {\n     if (table == null || table.isSystemTable()) {\n       LOG.debug(\"Normalization of system table {} isn't allowed\", table);\n-      return null;\n+      return Collections.emptyList();\n     }\n-    boolean splitEnabled = isSplitEnabled();\n-    boolean mergeEnabled = isMergeEnabled();\n+    boolean splitEnabled = isSplitEnabled() && isMasterSwitchEnabled(MasterSwitchType.SPLIT);\n+    boolean mergeEnabled = isMergeEnabled() && isMasterSwitchEnabled(MasterSwitchType.MERGE);\n     if (!mergeEnabled && !splitEnabled) {\n-      LOG.debug(\"Both split and merge are disabled for table: {}\", table);\n-      return null;\n+      LOG.debug(\"Both split and merge are disabled. Skipping normalization of table: {}\", table);\n+      return Collections.emptyList();\n     }\n+\n     List<NormalizationPlan> plans = new ArrayList<>();\n-    List<RegionInfo> tableRegions =\n-        masterServices.getAssignmentManager().getRegionStates().getRegionsOfTable(table);\n+    List<RegionInfo> tableRegions = masterServices.getAssignmentManager()\n+      .getRegionStates()\n+      .getRegionsOfTable(table);\n \n-    if (tableRegions == null) {\n-      return null;\n+    if (CollectionUtils.isEmpty(tableRegions)) {\n+      return Collections.emptyList();\n     }\n \n     LOG.debug(\"Computing normalization plan for table:  {}, number of regions: {}\", table,\n       tableRegions.size());\n \n     if (splitEnabled) {\n-      List<NormalizationPlan> splitPlans = getSplitNormalizationPlan(table);\n-      if (splitPlans != null) {\n-        plans.addAll(splitPlans);\n+      plans.addAll(computeSplitNormalizationPlans(table));\n+    }\n+    if (mergeEnabled) {\n+      plans.addAll(computeMergeNormalizationPlans(table));\n+    }\n+\n+    plans.sort(planComparator);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 294}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQyNDgwMQ==", "bodyText": "It can be addressed in a new jira, not necessary in this jira.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431424801", "createdAt": "2020-05-27T20:33:20Z", "author": {"login": "huaxiangsun"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,436 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>\n+ *   <li>Otherwise, for the next region in the chain R1, if R0 + R1 is smaller then S, R0 and R1\n+ *     are kindly requested to merge.</li>\n+ * </ol>\n+ * <p>\n+ * The following parameters are configurable:\n+ * <ol>\n+ *   <li>Whether to split a region as part of normalization. Configuration:\n+ *     {@value SPLIT_ENABLED_KEY}, default: {@value DEFAULT_SPLIT_ENABLED}.</li>\n+ *   <li>Whether to merge a region as part of normalization. Configuration:\n+ *     {@value MERGE_ENABLED_KEY}, default: {@value DEFAULT_MERGE_ENABLED}.</li>\n+ *   <li>The minimum number of regions in a table to consider it for normalization. Configuration:\n+ *     {@value MIN_REGION_COUNT_KEY}, default: {@value DEFAULT_MIN_REGION_COUNT}.</li>\n+ *   <li>The minimum age for a region to be considered for a merge, in days. Configuration:\n+ *     {@value MERGE_MIN_REGION_AGE_DAYS_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_AGE_DAYS}.</li>\n+ *   <li>The minimum size for a region to be considered for a merge, in whole MBs. Configuration:\n+ *     {@value MERGE_MIN_REGION_SIZE_MB_KEY}, default:\n+ *     {@value DEFAULT_MERGE_MIN_REGION_SIZE_MB}.</li>\n  * </ol>\n  * <p>\n- * Region sizes are coarse and approximate on the order of megabytes. Additionally, \"empty\" regions\n- * (less than 1MB, with the previous note) are not merged away. This is by design to prevent\n- * normalization from undoing the pre-splitting of a table.\n+ * To see detailed logging of the application of these configuration values, set the log level for\n+ * this class to `TRACE`.\n  */\n-@InterfaceAudience.Private\n-public class SimpleRegionNormalizer extends AbstractRegionNormalizer {\n-\n+@InterfaceAudience.LimitedPrivate(HBaseInterfaceAudience.CONFIG)\n+public class SimpleRegionNormalizer implements RegionNormalizer {\n   private static final Logger LOG = LoggerFactory.getLogger(SimpleRegionNormalizer.class);\n-  private static long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+\n+  static final String SPLIT_ENABLED_KEY = \"hbase.normalizer.split.enabled\";\n+  static final boolean DEFAULT_SPLIT_ENABLED = true;\n+  static final String MERGE_ENABLED_KEY = \"hbase.normalizer.merge.enabled\";\n+  static final boolean DEFAULT_MERGE_ENABLED = true;\n+  // TODO: after HBASE-24416, `min.region.count` only applies to merge plans; should\n+  //  deprecate/rename the configuration key.\n+  static final String MIN_REGION_COUNT_KEY = \"hbase.normalizer.min.region.count\";\n+  static final int DEFAULT_MIN_REGION_COUNT = 3;\n+  static final String MERGE_MIN_REGION_AGE_DAYS_KEY = \"hbase.normalizer.merge.min_region_age.days\";\n+  static final int DEFAULT_MERGE_MIN_REGION_AGE_DAYS = 3;\n+  static final String MERGE_MIN_REGION_SIZE_MB_KEY = \"hbase.normalizer.merge.min_region_size.mb\";\n+  static final int DEFAULT_MERGE_MIN_REGION_SIZE_MB = 1;\n+\n+  private final long[] skippedCount = new long[NormalizationPlan.PlanType.values().length];\n+  private final Comparator<NormalizationPlan> planComparator = new SplitPlanFirstComparator();\n+\n+  private Configuration conf;\n+  private MasterServices masterServices;\n+  private boolean splitEnabled;\n+  private boolean mergeEnabled;\n+  private int minRegionCount;\n+  private Period mergeMinRegionAge;\n+  private int mergeMinRegionSizeMb;\n+\n+  public SimpleRegionNormalizer() {\n+    splitEnabled = DEFAULT_SPLIT_ENABLED;\n+    mergeEnabled = DEFAULT_MERGE_ENABLED;\n+    minRegionCount = DEFAULT_MIN_REGION_COUNT;\n+    mergeMinRegionAge = Period.ofDays(DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    mergeMinRegionSizeMb = DEFAULT_MERGE_MIN_REGION_SIZE_MB;\n+  }\n \n   @Override\n-  public void planSkipped(RegionInfo hri, PlanType type) {\n-    skippedCount[type.ordinal()]++;\n+  public Configuration getConf() {\n+    return conf;\n   }\n \n   @Override\n-  public long getSkippedCount(NormalizationPlan.PlanType type) {\n-    return skippedCount[type.ordinal()];\n+  public void setConf(final Configuration conf) {\n+    if (conf == null) {\n+      return;\n+    }\n+    this.conf = conf;\n+    splitEnabled = conf.getBoolean(SPLIT_ENABLED_KEY, DEFAULT_SPLIT_ENABLED);\n+    mergeEnabled = conf.getBoolean(MERGE_ENABLED_KEY, DEFAULT_MERGE_ENABLED);\n+    minRegionCount = parseMinRegionCount(conf);\n+    mergeMinRegionAge = parseMergeMinRegionAge(conf);\n+    mergeMinRegionSizeMb = parseMergeMinRegionSizeMb(conf);\n+  }\n+\n+  private static int parseMinRegionCount(final Configuration conf) {\n+    final int parsedValue = conf.getInt(MIN_REGION_COUNT_KEY, DEFAULT_MIN_REGION_COUNT);\n+    final int settledValue = Math.max(1, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MIN_REGION_COUNT_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static Period parseMergeMinRegionAge(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_AGE_DAYS_KEY, DEFAULT_MERGE_MIN_REGION_AGE_DAYS);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_AGE_DAYS_KEY, parsedValue, settledValue);\n+    }\n+    return Period.ofDays(settledValue);\n+  }\n+\n+  private static int parseMergeMinRegionSizeMb(final Configuration conf) {\n+    final int parsedValue =\n+      conf.getInt(MERGE_MIN_REGION_SIZE_MB_KEY, DEFAULT_MERGE_MIN_REGION_SIZE_MB);\n+    final int settledValue = Math.max(0, parsedValue);\n+    if (parsedValue != settledValue) {\n+      warnInvalidValue(MERGE_MIN_REGION_SIZE_MB_KEY, parsedValue, settledValue);\n+    }\n+    return settledValue;\n+  }\n+\n+  private static <T> void warnInvalidValue(final String key, final T parsedValue,\n+    final T settledValue) {\n+    LOG.warn(\"Configured value {}={} is invalid. Setting value to {}.\",\n+      key, parsedValue, settledValue);\n   }\n \n   /**\n-   * Comparator class that gives higher priority to region Split plan.\n+   * Return this instance's configured value for {@value SPLIT_ENABLED_KEY}.\n    */\n-  static class PlanComparator implements Comparator<NormalizationPlan> {\n-    @Override\n-    public int compare(NormalizationPlan plan1, NormalizationPlan plan2) {\n-      boolean plan1IsSplit = plan1 instanceof SplitNormalizationPlan;\n-      boolean plan2IsSplit = plan2 instanceof SplitNormalizationPlan;\n-      if (plan1IsSplit && plan2IsSplit) {\n-        return 0;\n-      } else if (plan1IsSplit) {\n-        return -1;\n-      } else if (plan2IsSplit) {\n-        return 1;\n-      } else {\n-        return 0;\n-      }\n-    }\n+  public boolean isSplitEnabled() {\n+    return splitEnabled;\n   }\n \n-  private Comparator<NormalizationPlan> planComparator = new PlanComparator();\n+  /**\n+   * Return this instance's configured value for {@value MERGE_ENABLED_KEY}.\n+   */\n+  public boolean isMergeEnabled() {\n+    return mergeEnabled;\n+  }\n \n   /**\n-   * Computes next most \"urgent\" normalization action on the table. Action may be either a split, or\n-   * a merge, or no action.\n-   * @param table table to normalize\n-   * @return normalization plan to execute\n+   * Return this instance's configured value for {@value MIN_REGION_COUNT_KEY}.\n+   */\n+  public int getMinRegionCount() {\n+    return minRegionCount;\n+  }\n+\n+  /**\n+   * Return this instance's configured value for {@value MERGE_MIN_REGION_AGE_DAYS_KEY}.\n    */\n+  public Period getMergeMinRegionAge() {\n+    return mergeMinRegionAge;\n+  }\n+\n+  /**\n+   * Return this instance's configured value for {@value MERGE_MIN_REGION_SIZE_MB_KEY}.\n+   */\n+  public int getMergeMinRegionSizeMb() {\n+    return mergeMinRegionSizeMb;\n+  }\n+\n   @Override\n-  public List<NormalizationPlan> computePlanForTable(TableName table) throws HBaseIOException {\n+  public void setMasterServices(final MasterServices masterServices) {\n+    this.masterServices = masterServices;\n+  }\n+\n+  @Override\n+  public void planSkipped(final RegionInfo hri, final PlanType type) {\n+    skippedCount[type.ordinal()]++;\n+  }\n+\n+  @Override\n+  public long getSkippedCount(NormalizationPlan.PlanType type) {\n+    return skippedCount[type.ordinal()];\n+  }\n+\n+  @Override\n+  public List<NormalizationPlan> computePlansForTable(TableName table) {\n     if (table == null || table.isSystemTable()) {\n       LOG.debug(\"Normalization of system table {} isn't allowed\", table);\n-      return null;\n+      return Collections.emptyList();\n     }\n-    boolean splitEnabled = isSplitEnabled();\n-    boolean mergeEnabled = isMergeEnabled();\n+    boolean splitEnabled = isSplitEnabled() && isMasterSwitchEnabled(MasterSwitchType.SPLIT);\n+    boolean mergeEnabled = isMergeEnabled() && isMasterSwitchEnabled(MasterSwitchType.MERGE);\n     if (!mergeEnabled && !splitEnabled) {\n-      LOG.debug(\"Both split and merge are disabled for table: {}\", table);\n-      return null;\n+      LOG.debug(\"Both split and merge are disabled. Skipping normalization of table: {}\", table);\n+      return Collections.emptyList();\n     }\n+\n     List<NormalizationPlan> plans = new ArrayList<>();\n-    List<RegionInfo> tableRegions =\n-        masterServices.getAssignmentManager().getRegionStates().getRegionsOfTable(table);\n+    List<RegionInfo> tableRegions = masterServices.getAssignmentManager()\n+      .getRegionStates()\n+      .getRegionsOfTable(table);\n \n-    if (tableRegions == null) {\n-      return null;\n+    if (CollectionUtils.isEmpty(tableRegions)) {\n+      return Collections.emptyList();\n     }\n \n     LOG.debug(\"Computing normalization plan for table:  {}, number of regions: {}\", table,\n       tableRegions.size());\n \n     if (splitEnabled) {\n-      List<NormalizationPlan> splitPlans = getSplitNormalizationPlan(table);\n-      if (splitPlans != null) {\n-        plans.addAll(splitPlans);\n+      plans.addAll(computeSplitNormalizationPlans(table));\n+    }\n+    if (mergeEnabled) {\n+      plans.addAll(computeMergeNormalizationPlans(table));\n+    }\n+\n+    plans.sort(planComparator);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQxMjIyNg=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 294}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4NzIyMTUwOnYy", "diffSide": "RIGHT", "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/master/normalizer/TestSimpleRegionNormalizer.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QyMTowMDozOVrOGbc9iw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QyMToyNjozNFrOGbdvtQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQzOTI0Mw==", "bodyText": "That is a nice move, thank you! I tested without the patch(sort based regioninfo in getMergePlan()), it also passed for me. Debugged a bit, regionInfos() here is already sorted based on STARTKEY. We need to simulate what is the order in master, so changing the keys to\n    final byte[][] keys = { null, Bytes.toBytes(\"aa\"), Bytes.toBytes(\"aa1!\"), Bytes.toBytes(\"aa1\"), Bytes.toBytes(\"aa2\"), null, };\nwill fix it. The regionInfo is already key based, the order does not matter.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431439243", "createdAt": "2020-05-27T21:00:39Z", "author": {"login": "huaxiangsun"}, "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/master/normalizer/TestSimpleRegionNormalizer.java", "diffHunk": "@@ -69,517 +78,347 @@\n   public static final HBaseClassTestRule CLASS_RULE =\n       HBaseClassTestRule.forClass(TestSimpleRegionNormalizer.class);\n \n-  private static final Logger LOG = LoggerFactory.getLogger(TestSimpleRegionNormalizer.class);\n-\n-  private RegionNormalizer normalizer;\n+  private Configuration conf;\n+  private SimpleRegionNormalizer normalizer;\n   private MasterServices masterServices;\n \n   @Rule\n   public TestName name = new TestName();\n \n-  @Test\n-  public void testPlanComparator() {\n-    Comparator<NormalizationPlan> comparator = new SimpleRegionNormalizer.PlanComparator();\n-    NormalizationPlan splitPlan1 = new SplitNormalizationPlan(null, null);\n-    NormalizationPlan splitPlan2 = new SplitNormalizationPlan(null, null);\n-    NormalizationPlan mergePlan1 = new MergeNormalizationPlan(null, null);\n-    NormalizationPlan mergePlan2 = new MergeNormalizationPlan(null, null);\n-\n-    assertEquals(0, comparator.compare(splitPlan1, splitPlan2));\n-    assertEquals(0, comparator.compare(splitPlan2, splitPlan1));\n-    assertEquals(0, comparator.compare(mergePlan1, mergePlan2));\n-    assertEquals(0, comparator.compare(mergePlan2, mergePlan1));\n-    assertTrue(comparator.compare(splitPlan1, mergePlan1) < 0);\n-    assertTrue(comparator.compare(mergePlan1, splitPlan1) > 0);\n+  @Before\n+  public void before() {\n+    conf = HBaseConfiguration.create();\n   }\n \n   @Test\n-  public void testNoNormalizationForMetaTable() throws HBaseIOException {\n+  public void testNoNormalizationForMetaTable() {\n     TableName testTable = TableName.META_TABLE_NAME;\n     List<RegionInfo> RegionInfo = new ArrayList<>();\n     Map<byte[], Integer> regionSizes = new HashMap<>();\n \n     setupMocksForNormalizer(regionSizes, RegionInfo);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(testTable);\n-    assertNull(plans);\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(testTable);\n+    assertThat(plans, empty());\n   }\n \n   @Test\n-  public void testNoNormalizationIfTooFewRegions() throws HBaseIOException {\n+  public void testNoNormalizationIfTooFewRegions() {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\"))\n-        .build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 10);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\"))\n-        .build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 15);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 2);\n+    final Map<byte[], Integer> regionSizes = createRegionSizesMap(regionInfos, 10, 15);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n \n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(tableName);\n-    assertNull(plans);\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, empty());\n   }\n \n   @Test\n-  public void testNoNormalizationOnNormalizedCluster() throws HBaseIOException {\n+  public void testNoNormalizationOnNormalizedCluster() {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n-\n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\"))\n-        .build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 10);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\"))\n-        .build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 15);\n-\n-    RegionInfo hri3 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ccc\"))\n-        .setEndKey(Bytes.toBytes(\"ddd\"))\n-        .build();\n-    RegionInfo.add(hri3);\n-    regionSizes.put(hri3.getRegionName(), 8);\n-\n-    RegionInfo hri4 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ddd\"))\n-        .setEndKey(Bytes.toBytes(\"eee\"))\n-        .build();\n-    regionSizes.put(hri4.getRegionName(), 10);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 4);\n+    final Map<byte[], Integer> regionSizes = createRegionSizesMap(regionInfos, 10, 15, 8, 10);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n \n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(tableName);\n-    assertNull(plans);\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, empty());\n   }\n \n-  private void noNormalizationOnTransitioningRegions(final RegionState.State state)\n-    throws Exception {\n+  private void noNormalizationOnTransitioningRegions(final RegionState.State state) {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    final List<RegionInfo> regionInfos = new LinkedList<>();\n-    final Map<byte[], Integer> regionSizes = new HashMap<>();\n-\n-    final RegionInfo ri1 = RegionInfoBuilder.newBuilder(tableName)\n-      .setStartKey(Bytes.toBytes(\"aaa\"))\n-      .setEndKey(Bytes.toBytes(\"bbb\"))\n-      .build();\n-    regionInfos.add(ri1);\n-    regionSizes.put(ri1.getRegionName(), 10);\n-\n-    final RegionInfo ri2 = RegionInfoBuilder.newBuilder(tableName)\n-      .setStartKey(Bytes.toBytes(\"bbb\"))\n-      .setEndKey(Bytes.toBytes(\"ccc\"))\n-      .build();\n-    regionInfos.add(ri2);\n-    regionSizes.put(ri2.getRegionName(), 1);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 3);\n+    final Map<byte[], Integer> regionSizes = createRegionSizesMap(regionInfos, 10, 1, 100);\n \n     setupMocksForNormalizer(regionSizes, regionInfos);\n     when(masterServices.getAssignmentManager().getRegionStates()\n-      .getRegionState(any(RegionInfo.class))).thenReturn(\n-      RegionState.createForTesting(null, state));\n-    assertNull(\n-      format(\"Unexpected plans for RegionState %s\", state),\n-      normalizer.computePlanForTable(tableName));\n+      .getRegionState(any(RegionInfo.class)))\n+      .thenReturn(RegionState.createForTesting(null, state));\n+    assertThat(normalizer.getMinRegionCount(), greaterThanOrEqualTo(regionInfos.size()));\n+\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(format(\"Unexpected plans for RegionState %s\", state), plans, empty());\n   }\n \n   @Test\n-  public void testNoNormalizationOnMergingNewRegions() throws Exception {\n+  public void testNoNormalizationOnMergingNewRegions() {\n     noNormalizationOnTransitioningRegions(RegionState.State.MERGING_NEW);\n   }\n \n   @Test\n-  public void testNoNormalizationOnMergingRegions() throws Exception {\n+  public void testNoNormalizationOnMergingRegions() {\n     noNormalizationOnTransitioningRegions(RegionState.State.MERGING);\n   }\n \n   @Test\n-  public void testNoNormalizationOnMergedRegions() throws Exception {\n+  public void testNoNormalizationOnMergedRegions() {\n     noNormalizationOnTransitioningRegions(RegionState.State.MERGED);\n   }\n \n   @Test\n-  public void testNoNormalizationOnSplittingNewRegions() throws Exception {\n+  public void testNoNormalizationOnSplittingNewRegions() {\n     noNormalizationOnTransitioningRegions(RegionState.State.SPLITTING_NEW);\n   }\n \n   @Test\n-  public void testNoNormalizationOnSplittingRegions() throws Exception {\n+  public void testNoNormalizationOnSplittingRegions() {\n     noNormalizationOnTransitioningRegions(RegionState.State.SPLITTING);\n   }\n \n   @Test\n-  public void testNoNormalizationOnSplitRegions() throws Exception {\n+  public void testNoNormalizationOnSplitRegions() {\n     noNormalizationOnTransitioningRegions(RegionState.State.SPLIT);\n   }\n \n   @Test\n-  public void testMergeOfSmallRegions() throws HBaseIOException {\n+  public void testMergeOfSmallRegions() {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n-\n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\"))\n-        .build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 15);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\"))\n-        .build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 5);\n-\n-    RegionInfo hri3 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ccc\"))\n-        .setEndKey(Bytes.toBytes(\"ddd\"))\n-        .build();\n-    RegionInfo.add(hri3);\n-    regionSizes.put(hri3.getRegionName(), 5);\n-\n-    RegionInfo hri4 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ddd\"))\n-        .setEndKey(Bytes.toBytes(\"eee\"))\n-        .build();\n-    RegionInfo.add(hri4);\n-    regionSizes.put(hri4.getRegionName(), 15);\n-\n-    RegionInfo hri5 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"eee\"))\n-        .setEndKey(Bytes.toBytes(\"fff\"))\n-        .build();\n-    RegionInfo.add(hri5);\n-    regionSizes.put(hri5.getRegionName(), 16);\n-\n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(tableName);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 5);\n+    final Map<byte[], Integer> regionSizes =\n+      createRegionSizesMap(regionInfos, 15, 5, 5, 15, 16);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n \n-    NormalizationPlan plan = plans.get(0);\n-    assertTrue(plan instanceof MergeNormalizationPlan);\n-    assertEquals(hri2, ((MergeNormalizationPlan) plan).getFirstRegion());\n-    assertEquals(hri3, ((MergeNormalizationPlan) plan).getSecondRegion());\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans.get(0), instanceOf(MergeNormalizationPlan.class));\n+    MergeNormalizationPlan plan = (MergeNormalizationPlan) plans.get(0);\n+    assertEquals(regionInfos.get(1), plan.getFirstRegion());\n+    assertEquals(regionInfos.get(2), plan.getSecondRegion());\n   }\n \n   // Test for situation illustrated in HBASE-14867\n   @Test\n-  public void testMergeOfSecondSmallestRegions() throws HBaseIOException {\n+  public void testMergeOfSecondSmallestRegions() {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n-\n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\"))\n-        .build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 1);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\"))\n-        .build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 10000);\n-\n-    RegionInfo hri3 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ccc\"))\n-        .setEndKey(Bytes.toBytes(\"ddd\"))\n-        .build();\n-    RegionInfo.add(hri3);\n-    regionSizes.put(hri3.getRegionName(), 10000);\n-\n-    RegionInfo hri4 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ddd\"))\n-        .setEndKey(Bytes.toBytes(\"eee\"))\n-        .build();\n-    RegionInfo.add(hri4);\n-    regionSizes.put(hri4.getRegionName(), 10000);\n-\n-    RegionInfo hri5 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"eee\"))\n-        .setEndKey(Bytes.toBytes(\"fff\"))\n-        .build();\n-    RegionInfo.add(hri5);\n-    regionSizes.put(hri5.getRegionName(), 2700);\n-\n-    RegionInfo hri6 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"fff\"))\n-        .setEndKey(Bytes.toBytes(\"ggg\"))\n-        .build();\n-    RegionInfo.add(hri6);\n-    regionSizes.put(hri6.getRegionName(), 2700);\n-\n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(tableName);\n-    NormalizationPlan plan = plans.get(0);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 6);\n+    final Map<byte[], Integer> regionSizes =\n+      createRegionSizesMap(regionInfos, 1, 10000, 10000, 10000, 2700, 2700);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n \n-    assertTrue(plan instanceof MergeNormalizationPlan);\n-    assertEquals(hri5, ((MergeNormalizationPlan) plan).getFirstRegion());\n-    assertEquals(hri6, ((MergeNormalizationPlan) plan).getSecondRegion());\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans.get(0), instanceOf(MergeNormalizationPlan.class));\n+    MergeNormalizationPlan plan = (MergeNormalizationPlan) plans.get(0);\n+    assertEquals(regionInfos.get(4), plan.getFirstRegion());\n+    assertEquals(regionInfos.get(5), plan.getSecondRegion());\n   }\n \n   @Test\n-  public void testMergeOfSmallNonAdjacentRegions() throws HBaseIOException {\n+  public void testMergeOfSmallNonAdjacentRegions() {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n-\n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\"))\n-        .build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 15);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\"))\n-        .build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 5);\n-\n-    RegionInfo hri3 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ccc\"))\n-        .setEndKey(Bytes.toBytes(\"ddd\"))\n-        .build();\n-    RegionInfo.add(hri3);\n-    regionSizes.put(hri3.getRegionName(), 16);\n-\n-    RegionInfo hri4 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ddd\"))\n-        .setEndKey(Bytes.toBytes(\"eee\"))\n-        .build();\n-    RegionInfo.add(hri4);\n-    regionSizes.put(hri4.getRegionName(), 15);\n-\n-    RegionInfo hri5 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ddd\"))\n-        .setEndKey(Bytes.toBytes(\"eee\"))\n-        .build();\n-    RegionInfo.add(hri4);\n-    regionSizes.put(hri5.getRegionName(), 5);\n-\n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(tableName);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 5);\n+    final Map<byte[], Integer> regionSizes =\n+      createRegionSizesMap(regionInfos, 15, 5, 16, 15, 5);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n \n-    assertNull(plans);\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, empty());\n   }\n \n   @Test\n-  public void testSplitOfLargeRegion() throws HBaseIOException {\n+  public void testSplitOfLargeRegion() {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n-\n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\"))\n-        .build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 8);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\"))\n-        .build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 6);\n-\n-    RegionInfo hri3 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ccc\"))\n-        .setEndKey(Bytes.toBytes(\"ddd\"))\n-        .build();\n-    RegionInfo.add(hri3);\n-    regionSizes.put(hri3.getRegionName(), 10);\n-\n-    RegionInfo hri4 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ddd\"))\n-        .setEndKey(Bytes.toBytes(\"eee\"))\n-        .build();\n-    RegionInfo.add(hri4);\n-    regionSizes.put(hri4.getRegionName(), 30);\n-\n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(tableName);\n-    NormalizationPlan plan = plans.get(0);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 4);\n+    final Map<byte[], Integer> regionSizes =\n+      createRegionSizesMap(regionInfos, 8, 6, 10, 30);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n \n-    assertTrue(plan instanceof SplitNormalizationPlan);\n-    assertEquals(hri4, ((SplitNormalizationPlan) plan).getRegionInfo());\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans.get(0), instanceOf(SplitNormalizationPlan.class));\n+    SplitNormalizationPlan plan = (SplitNormalizationPlan) plans.get(0);\n+    assertEquals(regionInfos.get(3), plan.getRegionInfo());\n   }\n \n   @Test\n   public void testSplitWithTargetRegionCount() throws Exception {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n-\n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\")).build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 20);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\")).build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 40);\n-\n-    RegionInfo hri3 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"ccc\"))\n-        .setEndKey(Bytes.toBytes(\"ddd\")).build();\n-    RegionInfo.add(hri3);\n-    regionSizes.put(hri3.getRegionName(), 60);\n-\n-    RegionInfo hri4 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"ddd\"))\n-        .setEndKey(Bytes.toBytes(\"eee\")).build();\n-    RegionInfo.add(hri4);\n-    regionSizes.put(hri4.getRegionName(), 80);\n-\n-    RegionInfo hri5 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"eee\"))\n-        .setEndKey(Bytes.toBytes(\"fff\")).build();\n-    RegionInfo.add(hri5);\n-    regionSizes.put(hri5.getRegionName(), 100);\n-\n-    RegionInfo hri6 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"fff\"))\n-        .setEndKey(Bytes.toBytes(\"ggg\")).build();\n-    RegionInfo.add(hri6);\n-    regionSizes.put(hri6.getRegionName(), 120);\n-\n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 6);\n+    final Map<byte[], Integer> regionSizes =\n+      createRegionSizesMap(regionInfos, 20, 40, 60, 80, 100, 120);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n \n     // test when target region size is 20\n     when(masterServices.getTableDescriptors().get(any()).getNormalizerTargetRegionSize())\n         .thenReturn(20L);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(tableName);\n-    assertEquals(4, plans.size());\n-\n-    for (NormalizationPlan plan : plans) {\n-      assertTrue(plan instanceof SplitNormalizationPlan);\n-    }\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, iterableWithSize(4));\n+    assertThat(plans, everyItem(instanceOf(SplitNormalizationPlan.class)));\n \n     // test when target region size is 200\n     when(masterServices.getTableDescriptors().get(any()).getNormalizerTargetRegionSize())\n         .thenReturn(200L);\n-    plans = normalizer.computePlanForTable(tableName);\n-    assertEquals(2, plans.size());\n-    NormalizationPlan plan = plans.get(0);\n-    assertTrue(plan instanceof MergeNormalizationPlan);\n-    assertEquals(hri1, ((MergeNormalizationPlan) plan).getFirstRegion());\n-    assertEquals(hri2, ((MergeNormalizationPlan) plan).getSecondRegion());\n+    plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, iterableWithSize(2));\n+    assertTrue(plans.get(0) instanceof MergeNormalizationPlan);\n+    MergeNormalizationPlan plan = (MergeNormalizationPlan) plans.get(0);\n+    assertEquals(regionInfos.get(0), plan.getFirstRegion());\n+    assertEquals(regionInfos.get(1), plan.getSecondRegion());\n   }\n \n   @Test\n   public void testSplitWithTargetRegionSize() throws Exception {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n-\n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\")).build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 20);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\")).build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 40);\n-\n-    RegionInfo hri3 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"ccc\"))\n-        .setEndKey(Bytes.toBytes(\"ddd\")).build();\n-    RegionInfo.add(hri3);\n-    regionSizes.put(hri3.getRegionName(), 60);\n-\n-    RegionInfo hri4 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"ddd\"))\n-        .setEndKey(Bytes.toBytes(\"eee\")).build();\n-    RegionInfo.add(hri4);\n-    regionSizes.put(hri4.getRegionName(), 80);\n-\n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 4);\n+    final Map<byte[], Integer> regionSizes = createRegionSizesMap(regionInfos, 20, 40, 60, 80);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n \n     // test when target region count is 8\n     when(masterServices.getTableDescriptors().get(any()).getNormalizerTargetRegionCount())\n         .thenReturn(8);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(tableName);\n-    assertEquals(2, plans.size());\n-\n-    for (NormalizationPlan plan : plans) {\n-      assertTrue(plan instanceof SplitNormalizationPlan);\n-    }\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, iterableWithSize(2));\n+    assertThat(plans, everyItem(instanceOf(SplitNormalizationPlan.class)));\n \n     // test when target region count is 3\n     when(masterServices.getTableDescriptors().get(any()).getNormalizerTargetRegionCount())\n         .thenReturn(3);\n-    plans = normalizer.computePlanForTable(tableName);\n-    assertEquals(1, plans.size());\n-    NormalizationPlan plan = plans.get(0);\n-    assertTrue(plan instanceof MergeNormalizationPlan);\n-    assertEquals(hri1, ((MergeNormalizationPlan) plan).getFirstRegion());\n-    assertEquals(hri2, ((MergeNormalizationPlan) plan).getSecondRegion());\n+    plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, contains(instanceOf(MergeNormalizationPlan.class)));\n+    MergeNormalizationPlan plan = (MergeNormalizationPlan) plans.get(0);\n+    assertEquals(regionInfos.get(0), plan.getFirstRegion());\n+    assertEquals(regionInfos.get(1), plan.getSecondRegion());\n   }\n \n   @Test\n-  public void testSplitIfTooFewRegions() throws HBaseIOException {\n+  public void testHonorsSplitEnabled() {\n+    conf.setBoolean(SPLIT_ENABLED_KEY, true);\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 5);\n+    final Map<byte[], Integer> regionSizes =\n+      createRegionSizesMap(regionInfos, 5, 5, 20, 5, 5);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n+    assertThat(\n+      normalizer.computePlansForTable(tableName),\n+      contains(instanceOf(SplitNormalizationPlan.class)));\n+\n+    conf.setBoolean(SPLIT_ENABLED_KEY, false);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n+    assertThat(normalizer.computePlansForTable(tableName), empty());\n+  }\n+\n+  @Test\n+  public void testHonorsMergeEnabled() {\n+    conf.setBoolean(MERGE_ENABLED_KEY, true);\n+    final TableName tableName = TableName.valueOf(name.getMethodName());\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 5);\n+    final Map<byte[], Integer> regionSizes =\n+      createRegionSizesMap(regionInfos, 20, 5, 5, 20, 20);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n+    assertThat(\n+      normalizer.computePlansForTable(tableName),\n+      contains(instanceOf(MergeNormalizationPlan.class)));\n \n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\"))\n-        .build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 1);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\"))\n-        .build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 1);\n-    // the third region is huge one\n-    RegionInfo hri3 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ccc\"))\n-        .setEndKey(Bytes.toBytes(\"ddd\"))\n-        .build();\n-    RegionInfo.add(hri3);\n-    regionSizes.put(hri3.getRegionName(), 10);\n+    conf.setBoolean(MERGE_ENABLED_KEY, false);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n+    assertThat(normalizer.computePlansForTable(tableName), empty());\n+  }\n \n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n+  @Test\n+  public void testHonorsMinimumRegionCount() {\n+    conf.setInt(MIN_REGION_COUNT_KEY, 1);\n+    final TableName tableName = TableName.valueOf(name.getMethodName());\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 3);\n+    // create a table topology that results in both a merge plan and a split plan. Assert that the\n+    // merge is only created when the when the number of table regions is above the region count\n+    // threshold, and that the split plan is create in both cases.\n+    final Map<byte[], Integer> regionSizes = createRegionSizesMap(regionInfos, 1, 1, 10);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n+\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, contains(\n+      instanceOf(SplitNormalizationPlan.class),\n+      instanceOf(MergeNormalizationPlan.class)));\n+    SplitNormalizationPlan splitPlan = (SplitNormalizationPlan) plans.get(0);\n+    assertEquals(regionInfos.get(2), splitPlan.getRegionInfo());\n+    MergeNormalizationPlan mergePlan = (MergeNormalizationPlan) plans.get(1);\n+    assertEquals(regionInfos.get(0), mergePlan.getFirstRegion());\n+    assertEquals(regionInfos.get(1), mergePlan.getSecondRegion());\n+\n+    // have to call setupMocks again because we don't have dynamic config update on normalizer.\n+    conf.setInt(MIN_REGION_COUNT_KEY, 4);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n+    plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, contains(instanceOf(SplitNormalizationPlan.class)));\n+    splitPlan = (SplitNormalizationPlan) plans.get(0);\n+    assertEquals(regionInfos.get(2), splitPlan.getRegionInfo());\n+  }\n+\n+  @Test\n+  public void testHonorsMergeMinRegionAge() {\n+    conf.setInt(MERGE_MIN_REGION_AGE_DAYS_KEY, 7);\n+    final TableName tableName = TableName.valueOf(name.getMethodName());\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 4);\n+    final Map<byte[], Integer> regionSizes =\n+      createRegionSizesMap(regionInfos, 1, 1, 10, 10);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n+    assertEquals(Period.ofDays(7), normalizer.getMergeMinRegionAge());\n+    assertThat(\n+      normalizer.computePlansForTable(tableName),\n+      everyItem(not(instanceOf(MergeNormalizationPlan.class))));\n+\n+    // have to call setupMocks again because we don't have dynamic config update on normalizer.\n+    conf.unset(MERGE_MIN_REGION_AGE_DAYS_KEY);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n+    assertEquals(\n+      Period.ofDays(DEFAULT_MERGE_MIN_REGION_AGE_DAYS), normalizer.getMergeMinRegionAge());\n+    final List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, not(empty()));\n+    assertThat(plans, everyItem(instanceOf(MergeNormalizationPlan.class)));\n+  }\n+\n+  @Test\n+  public void testHonorsMergeMinRegionSize() {\n+    conf.setBoolean(SPLIT_ENABLED_KEY, false);\n+    final TableName tableName = TableName.valueOf(name.getMethodName());\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 5);\n+    final Map<byte[], Integer> regionSizes = createRegionSizesMap(regionInfos, 1, 2, 0, 10, 10);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n+\n+    assertFalse(normalizer.isSplitEnabled());\n+    assertEquals(1, normalizer.getMergeMinRegionSizeMb());\n+    final List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, everyItem(instanceOf(MergeNormalizationPlan.class)));\n+    assertThat(plans, iterableWithSize(1));\n+    final MergeNormalizationPlan plan = (MergeNormalizationPlan) plans.get(0);\n+    assertEquals(regionInfos.get(0), plan.getFirstRegion());\n+    assertEquals(regionInfos.get(1), plan.getSecondRegion());\n+\n+    conf.setInt(MERGE_MIN_REGION_SIZE_MB_KEY, 3);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n+    assertEquals(3, normalizer.getMergeMinRegionSizeMb());\n+    assertThat(normalizer.computePlansForTable(tableName), empty());\n+  }\n \n-    Configuration configuration = HBaseConfiguration.create();\n-    configuration.setInt(AbstractRegionNormalizer.HBASE_REGION_NORMALIZER_MIN_REGION_COUNT_KEY, 4);\n-    when(masterServices.getConfiguration()).thenReturn(configuration);\n+  // This test is to make sure that normalizer is only going to merge adjacent regions.\n+  @Test\n+  public void testNormalizerCannotMergeNonAdjacentRegions() {\n+    final TableName tableName = TableName.valueOf(name.getMethodName());\n+    // create 5 regions with sizes to trigger merge of small regions. region ranges are:\n+    // [, \"aa\"), [\"aa\", \"aa1\"), [\"aa1\", \"aa1!\"), [\"aa1!\", \"aa2\"), [\"aa2\", )\n+    // Region [\"aa\", \"aa1\") and [\"aa1!\", \"aa2\") are not adjacent, they are not supposed to\n+    // merged.\n+    final byte[][] keys = {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 772}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQ0MjQ0OQ==", "bodyText": "Oh, got it. Makes sense, thanks.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431442449", "createdAt": "2020-05-27T21:07:01Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/master/normalizer/TestSimpleRegionNormalizer.java", "diffHunk": "@@ -69,517 +78,347 @@\n   public static final HBaseClassTestRule CLASS_RULE =\n       HBaseClassTestRule.forClass(TestSimpleRegionNormalizer.class);\n \n-  private static final Logger LOG = LoggerFactory.getLogger(TestSimpleRegionNormalizer.class);\n-\n-  private RegionNormalizer normalizer;\n+  private Configuration conf;\n+  private SimpleRegionNormalizer normalizer;\n   private MasterServices masterServices;\n \n   @Rule\n   public TestName name = new TestName();\n \n-  @Test\n-  public void testPlanComparator() {\n-    Comparator<NormalizationPlan> comparator = new SimpleRegionNormalizer.PlanComparator();\n-    NormalizationPlan splitPlan1 = new SplitNormalizationPlan(null, null);\n-    NormalizationPlan splitPlan2 = new SplitNormalizationPlan(null, null);\n-    NormalizationPlan mergePlan1 = new MergeNormalizationPlan(null, null);\n-    NormalizationPlan mergePlan2 = new MergeNormalizationPlan(null, null);\n-\n-    assertEquals(0, comparator.compare(splitPlan1, splitPlan2));\n-    assertEquals(0, comparator.compare(splitPlan2, splitPlan1));\n-    assertEquals(0, comparator.compare(mergePlan1, mergePlan2));\n-    assertEquals(0, comparator.compare(mergePlan2, mergePlan1));\n-    assertTrue(comparator.compare(splitPlan1, mergePlan1) < 0);\n-    assertTrue(comparator.compare(mergePlan1, splitPlan1) > 0);\n+  @Before\n+  public void before() {\n+    conf = HBaseConfiguration.create();\n   }\n \n   @Test\n-  public void testNoNormalizationForMetaTable() throws HBaseIOException {\n+  public void testNoNormalizationForMetaTable() {\n     TableName testTable = TableName.META_TABLE_NAME;\n     List<RegionInfo> RegionInfo = new ArrayList<>();\n     Map<byte[], Integer> regionSizes = new HashMap<>();\n \n     setupMocksForNormalizer(regionSizes, RegionInfo);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(testTable);\n-    assertNull(plans);\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(testTable);\n+    assertThat(plans, empty());\n   }\n \n   @Test\n-  public void testNoNormalizationIfTooFewRegions() throws HBaseIOException {\n+  public void testNoNormalizationIfTooFewRegions() {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\"))\n-        .build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 10);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\"))\n-        .build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 15);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 2);\n+    final Map<byte[], Integer> regionSizes = createRegionSizesMap(regionInfos, 10, 15);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n \n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(tableName);\n-    assertNull(plans);\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, empty());\n   }\n \n   @Test\n-  public void testNoNormalizationOnNormalizedCluster() throws HBaseIOException {\n+  public void testNoNormalizationOnNormalizedCluster() {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n-\n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\"))\n-        .build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 10);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\"))\n-        .build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 15);\n-\n-    RegionInfo hri3 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ccc\"))\n-        .setEndKey(Bytes.toBytes(\"ddd\"))\n-        .build();\n-    RegionInfo.add(hri3);\n-    regionSizes.put(hri3.getRegionName(), 8);\n-\n-    RegionInfo hri4 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ddd\"))\n-        .setEndKey(Bytes.toBytes(\"eee\"))\n-        .build();\n-    regionSizes.put(hri4.getRegionName(), 10);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 4);\n+    final Map<byte[], Integer> regionSizes = createRegionSizesMap(regionInfos, 10, 15, 8, 10);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n \n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(tableName);\n-    assertNull(plans);\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, empty());\n   }\n \n-  private void noNormalizationOnTransitioningRegions(final RegionState.State state)\n-    throws Exception {\n+  private void noNormalizationOnTransitioningRegions(final RegionState.State state) {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    final List<RegionInfo> regionInfos = new LinkedList<>();\n-    final Map<byte[], Integer> regionSizes = new HashMap<>();\n-\n-    final RegionInfo ri1 = RegionInfoBuilder.newBuilder(tableName)\n-      .setStartKey(Bytes.toBytes(\"aaa\"))\n-      .setEndKey(Bytes.toBytes(\"bbb\"))\n-      .build();\n-    regionInfos.add(ri1);\n-    regionSizes.put(ri1.getRegionName(), 10);\n-\n-    final RegionInfo ri2 = RegionInfoBuilder.newBuilder(tableName)\n-      .setStartKey(Bytes.toBytes(\"bbb\"))\n-      .setEndKey(Bytes.toBytes(\"ccc\"))\n-      .build();\n-    regionInfos.add(ri2);\n-    regionSizes.put(ri2.getRegionName(), 1);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 3);\n+    final Map<byte[], Integer> regionSizes = createRegionSizesMap(regionInfos, 10, 1, 100);\n \n     setupMocksForNormalizer(regionSizes, regionInfos);\n     when(masterServices.getAssignmentManager().getRegionStates()\n-      .getRegionState(any(RegionInfo.class))).thenReturn(\n-      RegionState.createForTesting(null, state));\n-    assertNull(\n-      format(\"Unexpected plans for RegionState %s\", state),\n-      normalizer.computePlanForTable(tableName));\n+      .getRegionState(any(RegionInfo.class)))\n+      .thenReturn(RegionState.createForTesting(null, state));\n+    assertThat(normalizer.getMinRegionCount(), greaterThanOrEqualTo(regionInfos.size()));\n+\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(format(\"Unexpected plans for RegionState %s\", state), plans, empty());\n   }\n \n   @Test\n-  public void testNoNormalizationOnMergingNewRegions() throws Exception {\n+  public void testNoNormalizationOnMergingNewRegions() {\n     noNormalizationOnTransitioningRegions(RegionState.State.MERGING_NEW);\n   }\n \n   @Test\n-  public void testNoNormalizationOnMergingRegions() throws Exception {\n+  public void testNoNormalizationOnMergingRegions() {\n     noNormalizationOnTransitioningRegions(RegionState.State.MERGING);\n   }\n \n   @Test\n-  public void testNoNormalizationOnMergedRegions() throws Exception {\n+  public void testNoNormalizationOnMergedRegions() {\n     noNormalizationOnTransitioningRegions(RegionState.State.MERGED);\n   }\n \n   @Test\n-  public void testNoNormalizationOnSplittingNewRegions() throws Exception {\n+  public void testNoNormalizationOnSplittingNewRegions() {\n     noNormalizationOnTransitioningRegions(RegionState.State.SPLITTING_NEW);\n   }\n \n   @Test\n-  public void testNoNormalizationOnSplittingRegions() throws Exception {\n+  public void testNoNormalizationOnSplittingRegions() {\n     noNormalizationOnTransitioningRegions(RegionState.State.SPLITTING);\n   }\n \n   @Test\n-  public void testNoNormalizationOnSplitRegions() throws Exception {\n+  public void testNoNormalizationOnSplitRegions() {\n     noNormalizationOnTransitioningRegions(RegionState.State.SPLIT);\n   }\n \n   @Test\n-  public void testMergeOfSmallRegions() throws HBaseIOException {\n+  public void testMergeOfSmallRegions() {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n-\n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\"))\n-        .build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 15);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\"))\n-        .build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 5);\n-\n-    RegionInfo hri3 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ccc\"))\n-        .setEndKey(Bytes.toBytes(\"ddd\"))\n-        .build();\n-    RegionInfo.add(hri3);\n-    regionSizes.put(hri3.getRegionName(), 5);\n-\n-    RegionInfo hri4 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ddd\"))\n-        .setEndKey(Bytes.toBytes(\"eee\"))\n-        .build();\n-    RegionInfo.add(hri4);\n-    regionSizes.put(hri4.getRegionName(), 15);\n-\n-    RegionInfo hri5 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"eee\"))\n-        .setEndKey(Bytes.toBytes(\"fff\"))\n-        .build();\n-    RegionInfo.add(hri5);\n-    regionSizes.put(hri5.getRegionName(), 16);\n-\n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(tableName);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 5);\n+    final Map<byte[], Integer> regionSizes =\n+      createRegionSizesMap(regionInfos, 15, 5, 5, 15, 16);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n \n-    NormalizationPlan plan = plans.get(0);\n-    assertTrue(plan instanceof MergeNormalizationPlan);\n-    assertEquals(hri2, ((MergeNormalizationPlan) plan).getFirstRegion());\n-    assertEquals(hri3, ((MergeNormalizationPlan) plan).getSecondRegion());\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans.get(0), instanceOf(MergeNormalizationPlan.class));\n+    MergeNormalizationPlan plan = (MergeNormalizationPlan) plans.get(0);\n+    assertEquals(regionInfos.get(1), plan.getFirstRegion());\n+    assertEquals(regionInfos.get(2), plan.getSecondRegion());\n   }\n \n   // Test for situation illustrated in HBASE-14867\n   @Test\n-  public void testMergeOfSecondSmallestRegions() throws HBaseIOException {\n+  public void testMergeOfSecondSmallestRegions() {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n-\n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\"))\n-        .build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 1);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\"))\n-        .build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 10000);\n-\n-    RegionInfo hri3 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ccc\"))\n-        .setEndKey(Bytes.toBytes(\"ddd\"))\n-        .build();\n-    RegionInfo.add(hri3);\n-    regionSizes.put(hri3.getRegionName(), 10000);\n-\n-    RegionInfo hri4 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ddd\"))\n-        .setEndKey(Bytes.toBytes(\"eee\"))\n-        .build();\n-    RegionInfo.add(hri4);\n-    regionSizes.put(hri4.getRegionName(), 10000);\n-\n-    RegionInfo hri5 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"eee\"))\n-        .setEndKey(Bytes.toBytes(\"fff\"))\n-        .build();\n-    RegionInfo.add(hri5);\n-    regionSizes.put(hri5.getRegionName(), 2700);\n-\n-    RegionInfo hri6 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"fff\"))\n-        .setEndKey(Bytes.toBytes(\"ggg\"))\n-        .build();\n-    RegionInfo.add(hri6);\n-    regionSizes.put(hri6.getRegionName(), 2700);\n-\n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(tableName);\n-    NormalizationPlan plan = plans.get(0);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 6);\n+    final Map<byte[], Integer> regionSizes =\n+      createRegionSizesMap(regionInfos, 1, 10000, 10000, 10000, 2700, 2700);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n \n-    assertTrue(plan instanceof MergeNormalizationPlan);\n-    assertEquals(hri5, ((MergeNormalizationPlan) plan).getFirstRegion());\n-    assertEquals(hri6, ((MergeNormalizationPlan) plan).getSecondRegion());\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans.get(0), instanceOf(MergeNormalizationPlan.class));\n+    MergeNormalizationPlan plan = (MergeNormalizationPlan) plans.get(0);\n+    assertEquals(regionInfos.get(4), plan.getFirstRegion());\n+    assertEquals(regionInfos.get(5), plan.getSecondRegion());\n   }\n \n   @Test\n-  public void testMergeOfSmallNonAdjacentRegions() throws HBaseIOException {\n+  public void testMergeOfSmallNonAdjacentRegions() {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n-\n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\"))\n-        .build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 15);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\"))\n-        .build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 5);\n-\n-    RegionInfo hri3 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ccc\"))\n-        .setEndKey(Bytes.toBytes(\"ddd\"))\n-        .build();\n-    RegionInfo.add(hri3);\n-    regionSizes.put(hri3.getRegionName(), 16);\n-\n-    RegionInfo hri4 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ddd\"))\n-        .setEndKey(Bytes.toBytes(\"eee\"))\n-        .build();\n-    RegionInfo.add(hri4);\n-    regionSizes.put(hri4.getRegionName(), 15);\n-\n-    RegionInfo hri5 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ddd\"))\n-        .setEndKey(Bytes.toBytes(\"eee\"))\n-        .build();\n-    RegionInfo.add(hri4);\n-    regionSizes.put(hri5.getRegionName(), 5);\n-\n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(tableName);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 5);\n+    final Map<byte[], Integer> regionSizes =\n+      createRegionSizesMap(regionInfos, 15, 5, 16, 15, 5);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n \n-    assertNull(plans);\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, empty());\n   }\n \n   @Test\n-  public void testSplitOfLargeRegion() throws HBaseIOException {\n+  public void testSplitOfLargeRegion() {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n-\n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\"))\n-        .build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 8);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\"))\n-        .build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 6);\n-\n-    RegionInfo hri3 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ccc\"))\n-        .setEndKey(Bytes.toBytes(\"ddd\"))\n-        .build();\n-    RegionInfo.add(hri3);\n-    regionSizes.put(hri3.getRegionName(), 10);\n-\n-    RegionInfo hri4 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ddd\"))\n-        .setEndKey(Bytes.toBytes(\"eee\"))\n-        .build();\n-    RegionInfo.add(hri4);\n-    regionSizes.put(hri4.getRegionName(), 30);\n-\n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(tableName);\n-    NormalizationPlan plan = plans.get(0);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 4);\n+    final Map<byte[], Integer> regionSizes =\n+      createRegionSizesMap(regionInfos, 8, 6, 10, 30);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n \n-    assertTrue(plan instanceof SplitNormalizationPlan);\n-    assertEquals(hri4, ((SplitNormalizationPlan) plan).getRegionInfo());\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans.get(0), instanceOf(SplitNormalizationPlan.class));\n+    SplitNormalizationPlan plan = (SplitNormalizationPlan) plans.get(0);\n+    assertEquals(regionInfos.get(3), plan.getRegionInfo());\n   }\n \n   @Test\n   public void testSplitWithTargetRegionCount() throws Exception {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n-\n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\")).build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 20);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\")).build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 40);\n-\n-    RegionInfo hri3 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"ccc\"))\n-        .setEndKey(Bytes.toBytes(\"ddd\")).build();\n-    RegionInfo.add(hri3);\n-    regionSizes.put(hri3.getRegionName(), 60);\n-\n-    RegionInfo hri4 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"ddd\"))\n-        .setEndKey(Bytes.toBytes(\"eee\")).build();\n-    RegionInfo.add(hri4);\n-    regionSizes.put(hri4.getRegionName(), 80);\n-\n-    RegionInfo hri5 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"eee\"))\n-        .setEndKey(Bytes.toBytes(\"fff\")).build();\n-    RegionInfo.add(hri5);\n-    regionSizes.put(hri5.getRegionName(), 100);\n-\n-    RegionInfo hri6 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"fff\"))\n-        .setEndKey(Bytes.toBytes(\"ggg\")).build();\n-    RegionInfo.add(hri6);\n-    regionSizes.put(hri6.getRegionName(), 120);\n-\n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 6);\n+    final Map<byte[], Integer> regionSizes =\n+      createRegionSizesMap(regionInfos, 20, 40, 60, 80, 100, 120);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n \n     // test when target region size is 20\n     when(masterServices.getTableDescriptors().get(any()).getNormalizerTargetRegionSize())\n         .thenReturn(20L);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(tableName);\n-    assertEquals(4, plans.size());\n-\n-    for (NormalizationPlan plan : plans) {\n-      assertTrue(plan instanceof SplitNormalizationPlan);\n-    }\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, iterableWithSize(4));\n+    assertThat(plans, everyItem(instanceOf(SplitNormalizationPlan.class)));\n \n     // test when target region size is 200\n     when(masterServices.getTableDescriptors().get(any()).getNormalizerTargetRegionSize())\n         .thenReturn(200L);\n-    plans = normalizer.computePlanForTable(tableName);\n-    assertEquals(2, plans.size());\n-    NormalizationPlan plan = plans.get(0);\n-    assertTrue(plan instanceof MergeNormalizationPlan);\n-    assertEquals(hri1, ((MergeNormalizationPlan) plan).getFirstRegion());\n-    assertEquals(hri2, ((MergeNormalizationPlan) plan).getSecondRegion());\n+    plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, iterableWithSize(2));\n+    assertTrue(plans.get(0) instanceof MergeNormalizationPlan);\n+    MergeNormalizationPlan plan = (MergeNormalizationPlan) plans.get(0);\n+    assertEquals(regionInfos.get(0), plan.getFirstRegion());\n+    assertEquals(regionInfos.get(1), plan.getSecondRegion());\n   }\n \n   @Test\n   public void testSplitWithTargetRegionSize() throws Exception {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n-\n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\")).build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 20);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\")).build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 40);\n-\n-    RegionInfo hri3 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"ccc\"))\n-        .setEndKey(Bytes.toBytes(\"ddd\")).build();\n-    RegionInfo.add(hri3);\n-    regionSizes.put(hri3.getRegionName(), 60);\n-\n-    RegionInfo hri4 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"ddd\"))\n-        .setEndKey(Bytes.toBytes(\"eee\")).build();\n-    RegionInfo.add(hri4);\n-    regionSizes.put(hri4.getRegionName(), 80);\n-\n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 4);\n+    final Map<byte[], Integer> regionSizes = createRegionSizesMap(regionInfos, 20, 40, 60, 80);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n \n     // test when target region count is 8\n     when(masterServices.getTableDescriptors().get(any()).getNormalizerTargetRegionCount())\n         .thenReturn(8);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(tableName);\n-    assertEquals(2, plans.size());\n-\n-    for (NormalizationPlan plan : plans) {\n-      assertTrue(plan instanceof SplitNormalizationPlan);\n-    }\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, iterableWithSize(2));\n+    assertThat(plans, everyItem(instanceOf(SplitNormalizationPlan.class)));\n \n     // test when target region count is 3\n     when(masterServices.getTableDescriptors().get(any()).getNormalizerTargetRegionCount())\n         .thenReturn(3);\n-    plans = normalizer.computePlanForTable(tableName);\n-    assertEquals(1, plans.size());\n-    NormalizationPlan plan = plans.get(0);\n-    assertTrue(plan instanceof MergeNormalizationPlan);\n-    assertEquals(hri1, ((MergeNormalizationPlan) plan).getFirstRegion());\n-    assertEquals(hri2, ((MergeNormalizationPlan) plan).getSecondRegion());\n+    plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, contains(instanceOf(MergeNormalizationPlan.class)));\n+    MergeNormalizationPlan plan = (MergeNormalizationPlan) plans.get(0);\n+    assertEquals(regionInfos.get(0), plan.getFirstRegion());\n+    assertEquals(regionInfos.get(1), plan.getSecondRegion());\n   }\n \n   @Test\n-  public void testSplitIfTooFewRegions() throws HBaseIOException {\n+  public void testHonorsSplitEnabled() {\n+    conf.setBoolean(SPLIT_ENABLED_KEY, true);\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 5);\n+    final Map<byte[], Integer> regionSizes =\n+      createRegionSizesMap(regionInfos, 5, 5, 20, 5, 5);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n+    assertThat(\n+      normalizer.computePlansForTable(tableName),\n+      contains(instanceOf(SplitNormalizationPlan.class)));\n+\n+    conf.setBoolean(SPLIT_ENABLED_KEY, false);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n+    assertThat(normalizer.computePlansForTable(tableName), empty());\n+  }\n+\n+  @Test\n+  public void testHonorsMergeEnabled() {\n+    conf.setBoolean(MERGE_ENABLED_KEY, true);\n+    final TableName tableName = TableName.valueOf(name.getMethodName());\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 5);\n+    final Map<byte[], Integer> regionSizes =\n+      createRegionSizesMap(regionInfos, 20, 5, 5, 20, 20);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n+    assertThat(\n+      normalizer.computePlansForTable(tableName),\n+      contains(instanceOf(MergeNormalizationPlan.class)));\n \n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\"))\n-        .build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 1);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\"))\n-        .build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 1);\n-    // the third region is huge one\n-    RegionInfo hri3 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ccc\"))\n-        .setEndKey(Bytes.toBytes(\"ddd\"))\n-        .build();\n-    RegionInfo.add(hri3);\n-    regionSizes.put(hri3.getRegionName(), 10);\n+    conf.setBoolean(MERGE_ENABLED_KEY, false);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n+    assertThat(normalizer.computePlansForTable(tableName), empty());\n+  }\n \n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n+  @Test\n+  public void testHonorsMinimumRegionCount() {\n+    conf.setInt(MIN_REGION_COUNT_KEY, 1);\n+    final TableName tableName = TableName.valueOf(name.getMethodName());\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 3);\n+    // create a table topology that results in both a merge plan and a split plan. Assert that the\n+    // merge is only created when the when the number of table regions is above the region count\n+    // threshold, and that the split plan is create in both cases.\n+    final Map<byte[], Integer> regionSizes = createRegionSizesMap(regionInfos, 1, 1, 10);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n+\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, contains(\n+      instanceOf(SplitNormalizationPlan.class),\n+      instanceOf(MergeNormalizationPlan.class)));\n+    SplitNormalizationPlan splitPlan = (SplitNormalizationPlan) plans.get(0);\n+    assertEquals(regionInfos.get(2), splitPlan.getRegionInfo());\n+    MergeNormalizationPlan mergePlan = (MergeNormalizationPlan) plans.get(1);\n+    assertEquals(regionInfos.get(0), mergePlan.getFirstRegion());\n+    assertEquals(regionInfos.get(1), mergePlan.getSecondRegion());\n+\n+    // have to call setupMocks again because we don't have dynamic config update on normalizer.\n+    conf.setInt(MIN_REGION_COUNT_KEY, 4);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n+    plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, contains(instanceOf(SplitNormalizationPlan.class)));\n+    splitPlan = (SplitNormalizationPlan) plans.get(0);\n+    assertEquals(regionInfos.get(2), splitPlan.getRegionInfo());\n+  }\n+\n+  @Test\n+  public void testHonorsMergeMinRegionAge() {\n+    conf.setInt(MERGE_MIN_REGION_AGE_DAYS_KEY, 7);\n+    final TableName tableName = TableName.valueOf(name.getMethodName());\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 4);\n+    final Map<byte[], Integer> regionSizes =\n+      createRegionSizesMap(regionInfos, 1, 1, 10, 10);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n+    assertEquals(Period.ofDays(7), normalizer.getMergeMinRegionAge());\n+    assertThat(\n+      normalizer.computePlansForTable(tableName),\n+      everyItem(not(instanceOf(MergeNormalizationPlan.class))));\n+\n+    // have to call setupMocks again because we don't have dynamic config update on normalizer.\n+    conf.unset(MERGE_MIN_REGION_AGE_DAYS_KEY);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n+    assertEquals(\n+      Period.ofDays(DEFAULT_MERGE_MIN_REGION_AGE_DAYS), normalizer.getMergeMinRegionAge());\n+    final List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, not(empty()));\n+    assertThat(plans, everyItem(instanceOf(MergeNormalizationPlan.class)));\n+  }\n+\n+  @Test\n+  public void testHonorsMergeMinRegionSize() {\n+    conf.setBoolean(SPLIT_ENABLED_KEY, false);\n+    final TableName tableName = TableName.valueOf(name.getMethodName());\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 5);\n+    final Map<byte[], Integer> regionSizes = createRegionSizesMap(regionInfos, 1, 2, 0, 10, 10);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n+\n+    assertFalse(normalizer.isSplitEnabled());\n+    assertEquals(1, normalizer.getMergeMinRegionSizeMb());\n+    final List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, everyItem(instanceOf(MergeNormalizationPlan.class)));\n+    assertThat(plans, iterableWithSize(1));\n+    final MergeNormalizationPlan plan = (MergeNormalizationPlan) plans.get(0);\n+    assertEquals(regionInfos.get(0), plan.getFirstRegion());\n+    assertEquals(regionInfos.get(1), plan.getSecondRegion());\n+\n+    conf.setInt(MERGE_MIN_REGION_SIZE_MB_KEY, 3);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n+    assertEquals(3, normalizer.getMergeMinRegionSizeMb());\n+    assertThat(normalizer.computePlansForTable(tableName), empty());\n+  }\n \n-    Configuration configuration = HBaseConfiguration.create();\n-    configuration.setInt(AbstractRegionNormalizer.HBASE_REGION_NORMALIZER_MIN_REGION_COUNT_KEY, 4);\n-    when(masterServices.getConfiguration()).thenReturn(configuration);\n+  // This test is to make sure that normalizer is only going to merge adjacent regions.\n+  @Test\n+  public void testNormalizerCannotMergeNonAdjacentRegions() {\n+    final TableName tableName = TableName.valueOf(name.getMethodName());\n+    // create 5 regions with sizes to trigger merge of small regions. region ranges are:\n+    // [, \"aa\"), [\"aa\", \"aa1\"), [\"aa1\", \"aa1!\"), [\"aa1!\", \"aa2\"), [\"aa2\", )\n+    // Region [\"aa\", \"aa1\") and [\"aa1!\", \"aa2\") are not adjacent, they are not supposed to\n+    // merged.\n+    final byte[][] keys = {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQzOTI0Mw=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 772}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQ1MjA4NQ==", "bodyText": "Or, sorry, there is another change needed.\nfinal Map<byte[], Integer> regionSizes = createRegionSizesMap(regionInfos, 3, 1, 1, 3, 5);\nSince the order of regions are changed, the regionSizes order also needs to change.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r431452085", "createdAt": "2020-05-27T21:26:34Z", "author": {"login": "huaxiangsun"}, "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/master/normalizer/TestSimpleRegionNormalizer.java", "diffHunk": "@@ -69,517 +78,347 @@\n   public static final HBaseClassTestRule CLASS_RULE =\n       HBaseClassTestRule.forClass(TestSimpleRegionNormalizer.class);\n \n-  private static final Logger LOG = LoggerFactory.getLogger(TestSimpleRegionNormalizer.class);\n-\n-  private RegionNormalizer normalizer;\n+  private Configuration conf;\n+  private SimpleRegionNormalizer normalizer;\n   private MasterServices masterServices;\n \n   @Rule\n   public TestName name = new TestName();\n \n-  @Test\n-  public void testPlanComparator() {\n-    Comparator<NormalizationPlan> comparator = new SimpleRegionNormalizer.PlanComparator();\n-    NormalizationPlan splitPlan1 = new SplitNormalizationPlan(null, null);\n-    NormalizationPlan splitPlan2 = new SplitNormalizationPlan(null, null);\n-    NormalizationPlan mergePlan1 = new MergeNormalizationPlan(null, null);\n-    NormalizationPlan mergePlan2 = new MergeNormalizationPlan(null, null);\n-\n-    assertEquals(0, comparator.compare(splitPlan1, splitPlan2));\n-    assertEquals(0, comparator.compare(splitPlan2, splitPlan1));\n-    assertEquals(0, comparator.compare(mergePlan1, mergePlan2));\n-    assertEquals(0, comparator.compare(mergePlan2, mergePlan1));\n-    assertTrue(comparator.compare(splitPlan1, mergePlan1) < 0);\n-    assertTrue(comparator.compare(mergePlan1, splitPlan1) > 0);\n+  @Before\n+  public void before() {\n+    conf = HBaseConfiguration.create();\n   }\n \n   @Test\n-  public void testNoNormalizationForMetaTable() throws HBaseIOException {\n+  public void testNoNormalizationForMetaTable() {\n     TableName testTable = TableName.META_TABLE_NAME;\n     List<RegionInfo> RegionInfo = new ArrayList<>();\n     Map<byte[], Integer> regionSizes = new HashMap<>();\n \n     setupMocksForNormalizer(regionSizes, RegionInfo);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(testTable);\n-    assertNull(plans);\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(testTable);\n+    assertThat(plans, empty());\n   }\n \n   @Test\n-  public void testNoNormalizationIfTooFewRegions() throws HBaseIOException {\n+  public void testNoNormalizationIfTooFewRegions() {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\"))\n-        .build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 10);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\"))\n-        .build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 15);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 2);\n+    final Map<byte[], Integer> regionSizes = createRegionSizesMap(regionInfos, 10, 15);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n \n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(tableName);\n-    assertNull(plans);\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, empty());\n   }\n \n   @Test\n-  public void testNoNormalizationOnNormalizedCluster() throws HBaseIOException {\n+  public void testNoNormalizationOnNormalizedCluster() {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n-\n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\"))\n-        .build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 10);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\"))\n-        .build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 15);\n-\n-    RegionInfo hri3 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ccc\"))\n-        .setEndKey(Bytes.toBytes(\"ddd\"))\n-        .build();\n-    RegionInfo.add(hri3);\n-    regionSizes.put(hri3.getRegionName(), 8);\n-\n-    RegionInfo hri4 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ddd\"))\n-        .setEndKey(Bytes.toBytes(\"eee\"))\n-        .build();\n-    regionSizes.put(hri4.getRegionName(), 10);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 4);\n+    final Map<byte[], Integer> regionSizes = createRegionSizesMap(regionInfos, 10, 15, 8, 10);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n \n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(tableName);\n-    assertNull(plans);\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, empty());\n   }\n \n-  private void noNormalizationOnTransitioningRegions(final RegionState.State state)\n-    throws Exception {\n+  private void noNormalizationOnTransitioningRegions(final RegionState.State state) {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    final List<RegionInfo> regionInfos = new LinkedList<>();\n-    final Map<byte[], Integer> regionSizes = new HashMap<>();\n-\n-    final RegionInfo ri1 = RegionInfoBuilder.newBuilder(tableName)\n-      .setStartKey(Bytes.toBytes(\"aaa\"))\n-      .setEndKey(Bytes.toBytes(\"bbb\"))\n-      .build();\n-    regionInfos.add(ri1);\n-    regionSizes.put(ri1.getRegionName(), 10);\n-\n-    final RegionInfo ri2 = RegionInfoBuilder.newBuilder(tableName)\n-      .setStartKey(Bytes.toBytes(\"bbb\"))\n-      .setEndKey(Bytes.toBytes(\"ccc\"))\n-      .build();\n-    regionInfos.add(ri2);\n-    regionSizes.put(ri2.getRegionName(), 1);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 3);\n+    final Map<byte[], Integer> regionSizes = createRegionSizesMap(regionInfos, 10, 1, 100);\n \n     setupMocksForNormalizer(regionSizes, regionInfos);\n     when(masterServices.getAssignmentManager().getRegionStates()\n-      .getRegionState(any(RegionInfo.class))).thenReturn(\n-      RegionState.createForTesting(null, state));\n-    assertNull(\n-      format(\"Unexpected plans for RegionState %s\", state),\n-      normalizer.computePlanForTable(tableName));\n+      .getRegionState(any(RegionInfo.class)))\n+      .thenReturn(RegionState.createForTesting(null, state));\n+    assertThat(normalizer.getMinRegionCount(), greaterThanOrEqualTo(regionInfos.size()));\n+\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(format(\"Unexpected plans for RegionState %s\", state), plans, empty());\n   }\n \n   @Test\n-  public void testNoNormalizationOnMergingNewRegions() throws Exception {\n+  public void testNoNormalizationOnMergingNewRegions() {\n     noNormalizationOnTransitioningRegions(RegionState.State.MERGING_NEW);\n   }\n \n   @Test\n-  public void testNoNormalizationOnMergingRegions() throws Exception {\n+  public void testNoNormalizationOnMergingRegions() {\n     noNormalizationOnTransitioningRegions(RegionState.State.MERGING);\n   }\n \n   @Test\n-  public void testNoNormalizationOnMergedRegions() throws Exception {\n+  public void testNoNormalizationOnMergedRegions() {\n     noNormalizationOnTransitioningRegions(RegionState.State.MERGED);\n   }\n \n   @Test\n-  public void testNoNormalizationOnSplittingNewRegions() throws Exception {\n+  public void testNoNormalizationOnSplittingNewRegions() {\n     noNormalizationOnTransitioningRegions(RegionState.State.SPLITTING_NEW);\n   }\n \n   @Test\n-  public void testNoNormalizationOnSplittingRegions() throws Exception {\n+  public void testNoNormalizationOnSplittingRegions() {\n     noNormalizationOnTransitioningRegions(RegionState.State.SPLITTING);\n   }\n \n   @Test\n-  public void testNoNormalizationOnSplitRegions() throws Exception {\n+  public void testNoNormalizationOnSplitRegions() {\n     noNormalizationOnTransitioningRegions(RegionState.State.SPLIT);\n   }\n \n   @Test\n-  public void testMergeOfSmallRegions() throws HBaseIOException {\n+  public void testMergeOfSmallRegions() {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n-\n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\"))\n-        .build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 15);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\"))\n-        .build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 5);\n-\n-    RegionInfo hri3 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ccc\"))\n-        .setEndKey(Bytes.toBytes(\"ddd\"))\n-        .build();\n-    RegionInfo.add(hri3);\n-    regionSizes.put(hri3.getRegionName(), 5);\n-\n-    RegionInfo hri4 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ddd\"))\n-        .setEndKey(Bytes.toBytes(\"eee\"))\n-        .build();\n-    RegionInfo.add(hri4);\n-    regionSizes.put(hri4.getRegionName(), 15);\n-\n-    RegionInfo hri5 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"eee\"))\n-        .setEndKey(Bytes.toBytes(\"fff\"))\n-        .build();\n-    RegionInfo.add(hri5);\n-    regionSizes.put(hri5.getRegionName(), 16);\n-\n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(tableName);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 5);\n+    final Map<byte[], Integer> regionSizes =\n+      createRegionSizesMap(regionInfos, 15, 5, 5, 15, 16);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n \n-    NormalizationPlan plan = plans.get(0);\n-    assertTrue(plan instanceof MergeNormalizationPlan);\n-    assertEquals(hri2, ((MergeNormalizationPlan) plan).getFirstRegion());\n-    assertEquals(hri3, ((MergeNormalizationPlan) plan).getSecondRegion());\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans.get(0), instanceOf(MergeNormalizationPlan.class));\n+    MergeNormalizationPlan plan = (MergeNormalizationPlan) plans.get(0);\n+    assertEquals(regionInfos.get(1), plan.getFirstRegion());\n+    assertEquals(regionInfos.get(2), plan.getSecondRegion());\n   }\n \n   // Test for situation illustrated in HBASE-14867\n   @Test\n-  public void testMergeOfSecondSmallestRegions() throws HBaseIOException {\n+  public void testMergeOfSecondSmallestRegions() {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n-\n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\"))\n-        .build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 1);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\"))\n-        .build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 10000);\n-\n-    RegionInfo hri3 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ccc\"))\n-        .setEndKey(Bytes.toBytes(\"ddd\"))\n-        .build();\n-    RegionInfo.add(hri3);\n-    regionSizes.put(hri3.getRegionName(), 10000);\n-\n-    RegionInfo hri4 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ddd\"))\n-        .setEndKey(Bytes.toBytes(\"eee\"))\n-        .build();\n-    RegionInfo.add(hri4);\n-    regionSizes.put(hri4.getRegionName(), 10000);\n-\n-    RegionInfo hri5 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"eee\"))\n-        .setEndKey(Bytes.toBytes(\"fff\"))\n-        .build();\n-    RegionInfo.add(hri5);\n-    regionSizes.put(hri5.getRegionName(), 2700);\n-\n-    RegionInfo hri6 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"fff\"))\n-        .setEndKey(Bytes.toBytes(\"ggg\"))\n-        .build();\n-    RegionInfo.add(hri6);\n-    regionSizes.put(hri6.getRegionName(), 2700);\n-\n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(tableName);\n-    NormalizationPlan plan = plans.get(0);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 6);\n+    final Map<byte[], Integer> regionSizes =\n+      createRegionSizesMap(regionInfos, 1, 10000, 10000, 10000, 2700, 2700);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n \n-    assertTrue(plan instanceof MergeNormalizationPlan);\n-    assertEquals(hri5, ((MergeNormalizationPlan) plan).getFirstRegion());\n-    assertEquals(hri6, ((MergeNormalizationPlan) plan).getSecondRegion());\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans.get(0), instanceOf(MergeNormalizationPlan.class));\n+    MergeNormalizationPlan plan = (MergeNormalizationPlan) plans.get(0);\n+    assertEquals(regionInfos.get(4), plan.getFirstRegion());\n+    assertEquals(regionInfos.get(5), plan.getSecondRegion());\n   }\n \n   @Test\n-  public void testMergeOfSmallNonAdjacentRegions() throws HBaseIOException {\n+  public void testMergeOfSmallNonAdjacentRegions() {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n-\n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\"))\n-        .build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 15);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\"))\n-        .build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 5);\n-\n-    RegionInfo hri3 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ccc\"))\n-        .setEndKey(Bytes.toBytes(\"ddd\"))\n-        .build();\n-    RegionInfo.add(hri3);\n-    regionSizes.put(hri3.getRegionName(), 16);\n-\n-    RegionInfo hri4 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ddd\"))\n-        .setEndKey(Bytes.toBytes(\"eee\"))\n-        .build();\n-    RegionInfo.add(hri4);\n-    regionSizes.put(hri4.getRegionName(), 15);\n-\n-    RegionInfo hri5 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ddd\"))\n-        .setEndKey(Bytes.toBytes(\"eee\"))\n-        .build();\n-    RegionInfo.add(hri4);\n-    regionSizes.put(hri5.getRegionName(), 5);\n-\n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(tableName);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 5);\n+    final Map<byte[], Integer> regionSizes =\n+      createRegionSizesMap(regionInfos, 15, 5, 16, 15, 5);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n \n-    assertNull(plans);\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, empty());\n   }\n \n   @Test\n-  public void testSplitOfLargeRegion() throws HBaseIOException {\n+  public void testSplitOfLargeRegion() {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n-\n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\"))\n-        .build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 8);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\"))\n-        .build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 6);\n-\n-    RegionInfo hri3 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ccc\"))\n-        .setEndKey(Bytes.toBytes(\"ddd\"))\n-        .build();\n-    RegionInfo.add(hri3);\n-    regionSizes.put(hri3.getRegionName(), 10);\n-\n-    RegionInfo hri4 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ddd\"))\n-        .setEndKey(Bytes.toBytes(\"eee\"))\n-        .build();\n-    RegionInfo.add(hri4);\n-    regionSizes.put(hri4.getRegionName(), 30);\n-\n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(tableName);\n-    NormalizationPlan plan = plans.get(0);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 4);\n+    final Map<byte[], Integer> regionSizes =\n+      createRegionSizesMap(regionInfos, 8, 6, 10, 30);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n \n-    assertTrue(plan instanceof SplitNormalizationPlan);\n-    assertEquals(hri4, ((SplitNormalizationPlan) plan).getRegionInfo());\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans.get(0), instanceOf(SplitNormalizationPlan.class));\n+    SplitNormalizationPlan plan = (SplitNormalizationPlan) plans.get(0);\n+    assertEquals(regionInfos.get(3), plan.getRegionInfo());\n   }\n \n   @Test\n   public void testSplitWithTargetRegionCount() throws Exception {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n-\n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\")).build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 20);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\")).build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 40);\n-\n-    RegionInfo hri3 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"ccc\"))\n-        .setEndKey(Bytes.toBytes(\"ddd\")).build();\n-    RegionInfo.add(hri3);\n-    regionSizes.put(hri3.getRegionName(), 60);\n-\n-    RegionInfo hri4 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"ddd\"))\n-        .setEndKey(Bytes.toBytes(\"eee\")).build();\n-    RegionInfo.add(hri4);\n-    regionSizes.put(hri4.getRegionName(), 80);\n-\n-    RegionInfo hri5 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"eee\"))\n-        .setEndKey(Bytes.toBytes(\"fff\")).build();\n-    RegionInfo.add(hri5);\n-    regionSizes.put(hri5.getRegionName(), 100);\n-\n-    RegionInfo hri6 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"fff\"))\n-        .setEndKey(Bytes.toBytes(\"ggg\")).build();\n-    RegionInfo.add(hri6);\n-    regionSizes.put(hri6.getRegionName(), 120);\n-\n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 6);\n+    final Map<byte[], Integer> regionSizes =\n+      createRegionSizesMap(regionInfos, 20, 40, 60, 80, 100, 120);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n \n     // test when target region size is 20\n     when(masterServices.getTableDescriptors().get(any()).getNormalizerTargetRegionSize())\n         .thenReturn(20L);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(tableName);\n-    assertEquals(4, plans.size());\n-\n-    for (NormalizationPlan plan : plans) {\n-      assertTrue(plan instanceof SplitNormalizationPlan);\n-    }\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, iterableWithSize(4));\n+    assertThat(plans, everyItem(instanceOf(SplitNormalizationPlan.class)));\n \n     // test when target region size is 200\n     when(masterServices.getTableDescriptors().get(any()).getNormalizerTargetRegionSize())\n         .thenReturn(200L);\n-    plans = normalizer.computePlanForTable(tableName);\n-    assertEquals(2, plans.size());\n-    NormalizationPlan plan = plans.get(0);\n-    assertTrue(plan instanceof MergeNormalizationPlan);\n-    assertEquals(hri1, ((MergeNormalizationPlan) plan).getFirstRegion());\n-    assertEquals(hri2, ((MergeNormalizationPlan) plan).getSecondRegion());\n+    plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, iterableWithSize(2));\n+    assertTrue(plans.get(0) instanceof MergeNormalizationPlan);\n+    MergeNormalizationPlan plan = (MergeNormalizationPlan) plans.get(0);\n+    assertEquals(regionInfos.get(0), plan.getFirstRegion());\n+    assertEquals(regionInfos.get(1), plan.getSecondRegion());\n   }\n \n   @Test\n   public void testSplitWithTargetRegionSize() throws Exception {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n-\n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\")).build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 20);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\")).build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 40);\n-\n-    RegionInfo hri3 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"ccc\"))\n-        .setEndKey(Bytes.toBytes(\"ddd\")).build();\n-    RegionInfo.add(hri3);\n-    regionSizes.put(hri3.getRegionName(), 60);\n-\n-    RegionInfo hri4 = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes(\"ddd\"))\n-        .setEndKey(Bytes.toBytes(\"eee\")).build();\n-    RegionInfo.add(hri4);\n-    regionSizes.put(hri4.getRegionName(), 80);\n-\n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 4);\n+    final Map<byte[], Integer> regionSizes = createRegionSizesMap(regionInfos, 20, 40, 60, 80);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n \n     // test when target region count is 8\n     when(masterServices.getTableDescriptors().get(any()).getNormalizerTargetRegionCount())\n         .thenReturn(8);\n-    List<NormalizationPlan> plans = normalizer.computePlanForTable(tableName);\n-    assertEquals(2, plans.size());\n-\n-    for (NormalizationPlan plan : plans) {\n-      assertTrue(plan instanceof SplitNormalizationPlan);\n-    }\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, iterableWithSize(2));\n+    assertThat(plans, everyItem(instanceOf(SplitNormalizationPlan.class)));\n \n     // test when target region count is 3\n     when(masterServices.getTableDescriptors().get(any()).getNormalizerTargetRegionCount())\n         .thenReturn(3);\n-    plans = normalizer.computePlanForTable(tableName);\n-    assertEquals(1, plans.size());\n-    NormalizationPlan plan = plans.get(0);\n-    assertTrue(plan instanceof MergeNormalizationPlan);\n-    assertEquals(hri1, ((MergeNormalizationPlan) plan).getFirstRegion());\n-    assertEquals(hri2, ((MergeNormalizationPlan) plan).getSecondRegion());\n+    plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, contains(instanceOf(MergeNormalizationPlan.class)));\n+    MergeNormalizationPlan plan = (MergeNormalizationPlan) plans.get(0);\n+    assertEquals(regionInfos.get(0), plan.getFirstRegion());\n+    assertEquals(regionInfos.get(1), plan.getSecondRegion());\n   }\n \n   @Test\n-  public void testSplitIfTooFewRegions() throws HBaseIOException {\n+  public void testHonorsSplitEnabled() {\n+    conf.setBoolean(SPLIT_ENABLED_KEY, true);\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n-    List<RegionInfo> RegionInfo = new ArrayList<>();\n-    Map<byte[], Integer> regionSizes = new HashMap<>();\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 5);\n+    final Map<byte[], Integer> regionSizes =\n+      createRegionSizesMap(regionInfos, 5, 5, 20, 5, 5);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n+    assertThat(\n+      normalizer.computePlansForTable(tableName),\n+      contains(instanceOf(SplitNormalizationPlan.class)));\n+\n+    conf.setBoolean(SPLIT_ENABLED_KEY, false);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n+    assertThat(normalizer.computePlansForTable(tableName), empty());\n+  }\n+\n+  @Test\n+  public void testHonorsMergeEnabled() {\n+    conf.setBoolean(MERGE_ENABLED_KEY, true);\n+    final TableName tableName = TableName.valueOf(name.getMethodName());\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 5);\n+    final Map<byte[], Integer> regionSizes =\n+      createRegionSizesMap(regionInfos, 20, 5, 5, 20, 20);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n+    assertThat(\n+      normalizer.computePlansForTable(tableName),\n+      contains(instanceOf(MergeNormalizationPlan.class)));\n \n-    RegionInfo hri1 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"aaa\"))\n-        .setEndKey(Bytes.toBytes(\"bbb\"))\n-        .build();\n-    RegionInfo.add(hri1);\n-    regionSizes.put(hri1.getRegionName(), 1);\n-\n-    RegionInfo hri2 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"bbb\"))\n-        .setEndKey(Bytes.toBytes(\"ccc\"))\n-        .build();\n-    RegionInfo.add(hri2);\n-    regionSizes.put(hri2.getRegionName(), 1);\n-    // the third region is huge one\n-    RegionInfo hri3 = RegionInfoBuilder.newBuilder(tableName)\n-        .setStartKey(Bytes.toBytes(\"ccc\"))\n-        .setEndKey(Bytes.toBytes(\"ddd\"))\n-        .build();\n-    RegionInfo.add(hri3);\n-    regionSizes.put(hri3.getRegionName(), 10);\n+    conf.setBoolean(MERGE_ENABLED_KEY, false);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n+    assertThat(normalizer.computePlansForTable(tableName), empty());\n+  }\n \n-    setupMocksForNormalizer(regionSizes, RegionInfo);\n+  @Test\n+  public void testHonorsMinimumRegionCount() {\n+    conf.setInt(MIN_REGION_COUNT_KEY, 1);\n+    final TableName tableName = TableName.valueOf(name.getMethodName());\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 3);\n+    // create a table topology that results in both a merge plan and a split plan. Assert that the\n+    // merge is only created when the when the number of table regions is above the region count\n+    // threshold, and that the split plan is create in both cases.\n+    final Map<byte[], Integer> regionSizes = createRegionSizesMap(regionInfos, 1, 1, 10);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n+\n+    List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, contains(\n+      instanceOf(SplitNormalizationPlan.class),\n+      instanceOf(MergeNormalizationPlan.class)));\n+    SplitNormalizationPlan splitPlan = (SplitNormalizationPlan) plans.get(0);\n+    assertEquals(regionInfos.get(2), splitPlan.getRegionInfo());\n+    MergeNormalizationPlan mergePlan = (MergeNormalizationPlan) plans.get(1);\n+    assertEquals(regionInfos.get(0), mergePlan.getFirstRegion());\n+    assertEquals(regionInfos.get(1), mergePlan.getSecondRegion());\n+\n+    // have to call setupMocks again because we don't have dynamic config update on normalizer.\n+    conf.setInt(MIN_REGION_COUNT_KEY, 4);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n+    plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, contains(instanceOf(SplitNormalizationPlan.class)));\n+    splitPlan = (SplitNormalizationPlan) plans.get(0);\n+    assertEquals(regionInfos.get(2), splitPlan.getRegionInfo());\n+  }\n+\n+  @Test\n+  public void testHonorsMergeMinRegionAge() {\n+    conf.setInt(MERGE_MIN_REGION_AGE_DAYS_KEY, 7);\n+    final TableName tableName = TableName.valueOf(name.getMethodName());\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 4);\n+    final Map<byte[], Integer> regionSizes =\n+      createRegionSizesMap(regionInfos, 1, 1, 10, 10);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n+    assertEquals(Period.ofDays(7), normalizer.getMergeMinRegionAge());\n+    assertThat(\n+      normalizer.computePlansForTable(tableName),\n+      everyItem(not(instanceOf(MergeNormalizationPlan.class))));\n+\n+    // have to call setupMocks again because we don't have dynamic config update on normalizer.\n+    conf.unset(MERGE_MIN_REGION_AGE_DAYS_KEY);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n+    assertEquals(\n+      Period.ofDays(DEFAULT_MERGE_MIN_REGION_AGE_DAYS), normalizer.getMergeMinRegionAge());\n+    final List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, not(empty()));\n+    assertThat(plans, everyItem(instanceOf(MergeNormalizationPlan.class)));\n+  }\n+\n+  @Test\n+  public void testHonorsMergeMinRegionSize() {\n+    conf.setBoolean(SPLIT_ENABLED_KEY, false);\n+    final TableName tableName = TableName.valueOf(name.getMethodName());\n+    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 5);\n+    final Map<byte[], Integer> regionSizes = createRegionSizesMap(regionInfos, 1, 2, 0, 10, 10);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n+\n+    assertFalse(normalizer.isSplitEnabled());\n+    assertEquals(1, normalizer.getMergeMinRegionSizeMb());\n+    final List<NormalizationPlan> plans = normalizer.computePlansForTable(tableName);\n+    assertThat(plans, everyItem(instanceOf(MergeNormalizationPlan.class)));\n+    assertThat(plans, iterableWithSize(1));\n+    final MergeNormalizationPlan plan = (MergeNormalizationPlan) plans.get(0);\n+    assertEquals(regionInfos.get(0), plan.getFirstRegion());\n+    assertEquals(regionInfos.get(1), plan.getSecondRegion());\n+\n+    conf.setInt(MERGE_MIN_REGION_SIZE_MB_KEY, 3);\n+    setupMocksForNormalizer(regionSizes, regionInfos);\n+    assertEquals(3, normalizer.getMergeMinRegionSizeMb());\n+    assertThat(normalizer.computePlansForTable(tableName), empty());\n+  }\n \n-    Configuration configuration = HBaseConfiguration.create();\n-    configuration.setInt(AbstractRegionNormalizer.HBASE_REGION_NORMALIZER_MIN_REGION_COUNT_KEY, 4);\n-    when(masterServices.getConfiguration()).thenReturn(configuration);\n+  // This test is to make sure that normalizer is only going to merge adjacent regions.\n+  @Test\n+  public void testNormalizerCannotMergeNonAdjacentRegions() {\n+    final TableName tableName = TableName.valueOf(name.getMethodName());\n+    // create 5 regions with sizes to trigger merge of small regions. region ranges are:\n+    // [, \"aa\"), [\"aa\", \"aa1\"), [\"aa1\", \"aa1!\"), [\"aa1!\", \"aa2\"), [\"aa2\", )\n+    // Region [\"aa\", \"aa1\") and [\"aa1!\", \"aa2\") are not adjacent, they are not supposed to\n+    // merged.\n+    final byte[][] keys = {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQzOTI0Mw=="}, "originalCommit": {"oid": "171d1fcb91259af0abee3106a597d3bfa087eafb"}, "originalPosition": 772}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcwMzgwMjQwOnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQxNzo1Mzo1MVrOGd9Lhg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQxODoyMjo1M1rOGd-qcA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDA2NDI2Mg==", "bodyText": "I said it already that this strikes me as too aggressive. In a follow-up we should make this sloppier?  S * (2*) + (2*slop)?", "url": "https://github.com/apache/hbase/pull/1786#discussion_r434064262", "createdAt": "2020-06-02T17:53:51Z", "author": {"login": "saintstack"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,474 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n-import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>\n+ *   <li>Otherwise, for the next region in the chain R1, if R0 + R1 is smaller then S, R0 and R1\n+ *     are kindly requested to merge.</li>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c21c8a7b3c0ea4298e30b4ecad6f1aa743211aec"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDA4ODU2MA==", "bodyText": "Rather than slop, my recommendation is that we add the concept of a \"minimum region size\" for deciding when to split. I filed HBASE-24464 for that discussion.", "url": "https://github.com/apache/hbase/pull/1786#discussion_r434088560", "createdAt": "2020-06-02T18:22:53Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -18,126 +17,474 @@\n  */\n package org.apache.hadoop.hbase.master.normalizer;\n \n+import java.io.IOException;\n+import java.time.Instant;\n+import java.time.Period;\n import java.util.ArrayList;\n import java.util.Collections;\n-import java.util.Comparator;\n import java.util.List;\n-\n-import org.apache.hadoop.hbase.HBaseIOException;\n+import java.util.Objects;\n+import java.util.function.BooleanSupplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseInterfaceAudience;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.MasterSwitchType;\n import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.master.MasterServices;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.assignment.RegionStates;\n import org.apache.hadoop.hbase.master.normalizer.NormalizationPlan.PlanType;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n import org.apache.yetus.audience.InterfaceAudience;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n \n /**\n  * Simple implementation of region normalizer. Logic in use:\n  * <ol>\n- * <li>Get all regions of a given table\n- * <li>Get avg size S of each region (by total size of store files reported in RegionMetrics)\n- * <li>Seek every single region one by one. If a region R0 is bigger than S * 2, it is kindly\n- * requested to split. Thereon evaluate the next region R1\n- * <li>Otherwise, if R0 + R1 is smaller than S, R0 and R1 are kindly requested to merge. Thereon\n- * evaluate the next region R2\n- * <li>Otherwise, R1 is evaluated\n+ *   <li>Get all regions of a given table</li>\n+ *   <li>Get avg size S of the regions in the table (by total size of store files reported in\n+ *     RegionMetrics)</li>\n+ *   <li>For each region R0, if R0 is bigger than S * 2, it is kindly requested to split.</li>\n+ *   <li>Otherwise, for the next region in the chain R1, if R0 + R1 is smaller then S, R0 and R1\n+ *     are kindly requested to merge.</li>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDA2NDI2Mg=="}, "originalCommit": {"oid": "c21c8a7b3c0ea4298e30b4ecad6f1aa743211aec"}, "originalPosition": 56}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3059, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}