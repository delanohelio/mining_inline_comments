{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDY2NTc0Mzg0", "number": 2249, "title": "HBASE-24871 Replication may loss data when refresh recovered replicat\u2026", "bodyText": "\u2026ion sources", "createdAt": "2020-08-12T07:21:58Z", "url": "https://github.com/apache/hbase/pull/2249", "merged": true, "mergeCommit": {"oid": "e0c9f911adad331ff1ab8db1dffa2f6799741ff3"}, "closed": true, "closedAt": "2020-08-24T13:43:16Z", "author": {"login": "ddupg"}, "timelineItems": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc-TXg6AFqTQ2NjMyNjIxNw==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdB6KgqABqjM2ODM1NDUxNTM=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY2MzI2MjE3", "url": "https://github.com/apache/hbase/pull/2249#pullrequestreview-466326217", "createdAt": "2020-08-12T22:43:16Z", "commit": {"oid": "a1acbb8ab647267248a599b7d642bcd00e4df116"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY2NjE4NjM0", "url": "https://github.com/apache/hbase/pull/2249#pullrequestreview-466618634", "createdAt": "2020-08-13T10:00:56Z", "commit": {"oid": "a1acbb8ab647267248a599b7d642bcd00e4df116"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xM1QxMDowMDo1NlrOHAEvcA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xM1QxMDowMDo1NlrOHAEvcA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTgzOTcyOA==", "bodyText": "So the problem is that logs from recovered queues were getting added to the new \"normal\" queue? And these logs are never read, then?\nNit: maybe worth rename the variable from line #516 from replicationSource to recoveredReplicationSource, for further clarity?\nI endorse the call for an additional UT, here.", "url": "https://github.com/apache/hbase/pull/2249#discussion_r469839728", "createdAt": "2020-08-13T10:00:56Z", "author": {"login": "wchevreuil"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java", "diffHunk": "@@ -516,7 +516,7 @@ public void refreshSources(String peerId) throws IOException {\n         ReplicationSourceInterface replicationSource = createSource(queueId, peer);\n         this.oldsources.add(replicationSource);\n         for (SortedSet<String> walsByGroup : walsByIdRecoveredQueues.get(queueId).values()) {\n-          walsByGroup.forEach(wal -> src.enqueueLog(new Path(wal)));\n+          walsByGroup.forEach(wal -> replicationSource.enqueueLog(new Path(wal)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a1acbb8ab647267248a599b7d642bcd00e4df116"}, "originalPosition": 5}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a1acbb8ab647267248a599b7d642bcd00e4df116", "author": {"user": {"login": "ddupg", "name": "XinSun"}}, "url": "https://github.com/apache/hbase/commit/a1acbb8ab647267248a599b7d642bcd00e4df116", "committedDate": "2020-08-12T07:20:41Z", "message": "HBASE-24871 Replication may loss data when refresh recovered replication sources"}, "afterCommit": {"oid": "8a238a0fc7452845fccbcaf2a85fa88c8e3b7173", "author": {"user": {"login": "ddupg", "name": "XinSun"}}, "url": "https://github.com/apache/hbase/commit/8a238a0fc7452845fccbcaf2a85fa88c8e3b7173", "committedDate": "2020-08-19T03:47:41Z", "message": "HBASE-24871 Replication may loss data when refresh recovered replication sources"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8a238a0fc7452845fccbcaf2a85fa88c8e3b7173", "author": {"user": {"login": "ddupg", "name": "XinSun"}}, "url": "https://github.com/apache/hbase/commit/8a238a0fc7452845fccbcaf2a85fa88c8e3b7173", "committedDate": "2020-08-19T03:47:41Z", "message": "HBASE-24871 Replication may loss data when refresh recovered replication sources"}, "afterCommit": {"oid": "fd5bad91bc2c30af81eca50702bd4615fff10143", "author": {"user": {"login": "ddupg", "name": "XinSun"}}, "url": "https://github.com/apache/hbase/commit/fd5bad91bc2c30af81eca50702bd4615fff10143", "committedDate": "2020-08-19T13:22:34Z", "message": "HBASE-24871 Replication may loss data when refresh recovered replication sources"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "fd5bad91bc2c30af81eca50702bd4615fff10143", "author": {"user": {"login": "ddupg", "name": "XinSun"}}, "url": "https://github.com/apache/hbase/commit/fd5bad91bc2c30af81eca50702bd4615fff10143", "committedDate": "2020-08-19T13:22:34Z", "message": "HBASE-24871 Replication may loss data when refresh recovered replication sources"}, "afterCommit": {"oid": "c8e1785fc324417637ac6de111f25f3cce5d8cc1", "author": {"user": {"login": "ddupg", "name": "XinSun"}}, "url": "https://github.com/apache/hbase/commit/c8e1785fc324417637ac6de111f25f3cce5d8cc1", "committedDate": "2020-08-20T02:02:13Z", "message": "HBASE-24871 Replication may loss data when refresh recovered replication sources"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcxNzY4NDc4", "url": "https://github.com/apache/hbase/pull/2249#pullrequestreview-471768478", "createdAt": "2020-08-20T16:06:49Z", "commit": {"oid": "c8e1785fc324417637ac6de111f25f3cce5d8cc1"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcyODkyMzI2", "url": "https://github.com/apache/hbase/pull/2249#pullrequestreview-472892326", "createdAt": "2020-08-22T03:03:53Z", "commit": {"oid": "c8e1785fc324417637ac6de111f25f3cce5d8cc1"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQwMzowMzo1M1rOHFCBrA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQwMzowMzo1M1rOHFCBrA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTAzODEyNA==", "bodyText": "Which assert will failed if no this fix?", "url": "https://github.com/apache/hbase/pull/2249#discussion_r475038124", "createdAt": "2020-08-22T03:03:53Z", "author": {"login": "infraio"}, "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/replication/regionserver/TestRefreshRecoveredReplication.java", "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.replication.regionserver;\n+\n+import java.io.IOException;\n+import java.util.Optional;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HBaseClassTestRule;\n+import org.apache.hadoop.hbase.HConstants;\n+import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.ColumnFamilyDescriptorBuilder;\n+import org.apache.hadoop.hbase.client.Put;\n+import org.apache.hadoop.hbase.client.Result;\n+import org.apache.hadoop.hbase.client.ResultScanner;\n+import org.apache.hadoop.hbase.client.Scan;\n+import org.apache.hadoop.hbase.client.Table;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.client.TableDescriptorBuilder;\n+import org.apache.hadoop.hbase.replication.TestReplicationBase;\n+import org.apache.hadoop.hbase.testclassification.MediumTests;\n+import org.apache.hadoop.hbase.testclassification.ReplicationTests;\n+import org.apache.hadoop.hbase.util.Bytes;\n+import org.apache.hadoop.hbase.util.JVMClusterUtil.RegionServerThread;\n+import org.junit.After;\n+import org.junit.AfterClass;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.TestName;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hbase.thirdparty.org.apache.commons.collections4.CollectionUtils;\n+\n+/**\n+ * Testcase for HBASE-24871.\n+ */\n+@Category({ ReplicationTests.class, MediumTests.class })\n+public class TestRefreshRecoveredReplication extends TestReplicationBase {\n+\n+  @ClassRule\n+  public static final HBaseClassTestRule CLASS_RULE =\n+      HBaseClassTestRule.forClass(TestRefreshRecoveredReplication.class);\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(TestRefreshRecoveredReplication.class);\n+\n+  private static final int BATCH = 50;\n+\n+  @Rule\n+  public TestName name = new TestName();\n+\n+  private TableName tablename;\n+  private Table table1;\n+  private Table table2;\n+\n+  @BeforeClass\n+  public static void setUpBeforeClass() throws Exception {\n+    NUM_SLAVES1 = 2;\n+    // replicate slowly\n+    Configuration conf1 = UTIL1.getConfiguration();\n+    conf1.setInt(HConstants.REPLICATION_SOURCE_TOTAL_BUFFER_KEY, 100);\n+    TestReplicationBase.setUpBeforeClass();\n+  }\n+\n+  @AfterClass\n+  public static void tearDownAfterClass() throws Exception {\n+    TestReplicationBase.tearDownAfterClass();\n+  }\n+\n+  @Before\n+  public void setup() throws Exception {\n+    setUpBase();\n+\n+    tablename = TableName.valueOf(name.getMethodName());\n+    TableDescriptor table = TableDescriptorBuilder.newBuilder(tablename)\n+        .setColumnFamily(ColumnFamilyDescriptorBuilder.newBuilder(famName)\n+            .setScope(HConstants.REPLICATION_SCOPE_GLOBAL).build())\n+        .build();\n+\n+    UTIL1.getAdmin().createTable(table);\n+    UTIL2.getAdmin().createTable(table);\n+    UTIL1.waitTableAvailable(tablename);\n+    UTIL2.waitTableAvailable(tablename);\n+    table1 = UTIL1.getConnection().getTable(tablename);\n+    table2 = UTIL2.getConnection().getTable(tablename);\n+  }\n+\n+  @After\n+  public void teardown() throws Exception {\n+    tearDownBase();\n+\n+    UTIL1.deleteTableIfAny(tablename);\n+    UTIL2.deleteTableIfAny(tablename);\n+  }\n+\n+  @Test\n+  public void testReplicationRefreshSource() throws Exception {\n+    // put some data\n+    for (int i = 0; i < BATCH; i++) {\n+      byte[] r = Bytes.toBytes(i);\n+      table1.put(new Put(r).addColumn(famName, famName, r));\n+    }\n+\n+    // kill rs holding table region\n+    Optional<RegionServerThread> server = UTIL1.getMiniHBaseCluster().getLiveRegionServerThreads()\n+        .stream()\n+        .filter(rst -> CollectionUtils.isNotEmpty(rst.getRegionServer().getRegions(tablename)))\n+        .findAny();\n+    Assert.assertTrue(server.isPresent());\n+    server.get().getRegionServer().abort(\"stopping for test\");\n+    UTIL1.waitFor(60000, () ->\n+        UTIL1.getMiniHBaseCluster().getLiveRegionServerThreads().size() == NUM_SLAVES1 - 1);\n+    UTIL1.waitTableAvailable(tablename);\n+\n+    // waiting for recovered peer to start\n+    Replication replication = (Replication) UTIL1.getMiniHBaseCluster()\n+        .getLiveRegionServerThreads().get(0).getRegionServer().getReplicationSourceService();\n+    UTIL1.waitFor(60000, () ->\n+        !replication.getReplicationManager().getOldSources().isEmpty());\n+\n+    // disable peer to trigger refreshSources\n+    hbaseAdmin.disableReplicationPeer(PEER_ID2);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c8e1785fc324417637ac6de111f25f3cce5d8cc1"}, "originalPosition": 142}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDczMDk2ODI0", "url": "https://github.com/apache/hbase/pull/2249#pullrequestreview-473096824", "createdAt": "2020-08-24T03:24:05Z", "commit": {"oid": "c8e1785fc324417637ac6de111f25f3cce5d8cc1"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5eb40848bcba7dc38259f69330fb9c82d8a1f2d0", "author": {"user": {"login": "ddupg", "name": "XinSun"}}, "url": "https://github.com/apache/hbase/commit/5eb40848bcba7dc38259f69330fb9c82d8a1f2d0", "committedDate": "2020-08-24T03:36:22Z", "message": "HBASE-24871 Replication may loss data when refresh recovered replication sources"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c8e1785fc324417637ac6de111f25f3cce5d8cc1", "author": {"user": {"login": "ddupg", "name": "XinSun"}}, "url": "https://github.com/apache/hbase/commit/c8e1785fc324417637ac6de111f25f3cce5d8cc1", "committedDate": "2020-08-20T02:02:13Z", "message": "HBASE-24871 Replication may loss data when refresh recovered replication sources"}, "afterCommit": {"oid": "5eb40848bcba7dc38259f69330fb9c82d8a1f2d0", "author": {"user": {"login": "ddupg", "name": "XinSun"}}, "url": "https://github.com/apache/hbase/commit/5eb40848bcba7dc38259f69330fb9c82d8a1f2d0", "committedDate": "2020-08-24T03:36:22Z", "message": "HBASE-24871 Replication may loss data when refresh recovered replication sources"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4862, "cost": 1, "resetAt": "2021-10-28T16:48:13Z"}}}