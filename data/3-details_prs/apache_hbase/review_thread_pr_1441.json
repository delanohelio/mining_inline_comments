{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzk5ODg5MDUy", "number": 1441, "reviewThreads": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQyMjowOTowMlrODvUsZA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwMToxMzo1NVrODvzBTA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwOTQ4NzA4OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQyMjowOTowMlrOGBrvnw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQyMzo0NDoyNVrOGBt5Ag==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQxODQ2Mw==", "bodyText": "You sure you don't want to propagate the InterruptedException? Looks like run loop in ReplicationSourceShipper is designed to handle that exception. return here would continue the thread executing, which I think is not what we want.", "url": "https://github.com/apache/hbase/pull/1441#discussion_r404418463", "createdAt": "2020-04-06T22:09:02Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java", "diffHunk": "@@ -579,8 +579,8 @@ private void interruptOrAbortWhenFail(ReplicationQueueOperation op) {\n       if (e.getCause() != null && e.getCause() instanceof KeeperException.SystemErrorException\n           && e.getCause().getCause() != null && e.getCause()\n           .getCause() instanceof InterruptedException) {\n-        throw new RuntimeException(\n-            \"Thread is interrupted, the replication source may be terminated\");\n+        LOG.info(\"Thread is interrupted, the replication source may be terminated\");\n+        return;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1c89328b2fa7128663877ce71ea34cf3aa690165"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQ0OTA5Nw==", "bodyText": "the interrupt flap has been set up in the zkwatcher layer and upper layer handles this flag nicely.\n  zkw.interruptedException(ie);\n\nhttps://github.com/apache/hbase/blob/master/hbase-zookeeper/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKWatcher.java#L637, in the outside loop, it will handle this interrupt flag and terminate the thread.\nInside  isActive() of the following loop, it will return false if isInterrupted flag is true.\nhttps://github.com/apache/hbase/blob/master/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceShipper.java#L101", "url": "https://github.com/apache/hbase/pull/1441#discussion_r404449097", "createdAt": "2020-04-06T23:30:16Z", "author": {"login": "huaxiangsun"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java", "diffHunk": "@@ -579,8 +579,8 @@ private void interruptOrAbortWhenFail(ReplicationQueueOperation op) {\n       if (e.getCause() != null && e.getCause() instanceof KeeperException.SystemErrorException\n           && e.getCause().getCause() != null && e.getCause()\n           .getCause() instanceof InterruptedException) {\n-        throw new RuntimeException(\n-            \"Thread is interrupted, the replication source may be terminated\");\n+        LOG.info(\"Thread is interrupted, the replication source may be terminated\");\n+        return;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQxODQ2Mw=="}, "originalCommit": {"oid": "1c89328b2fa7128663877ce71ea34cf3aa690165"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQ1MDA5NA==", "bodyText": "I have manually tested the code path by injecting an InterruptException at zkwatcher and made sure thread exits and  no region server abort.", "url": "https://github.com/apache/hbase/pull/1441#discussion_r404450094", "createdAt": "2020-04-06T23:33:28Z", "author": {"login": "huaxiangsun"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java", "diffHunk": "@@ -579,8 +579,8 @@ private void interruptOrAbortWhenFail(ReplicationQueueOperation op) {\n       if (e.getCause() != null && e.getCause() instanceof KeeperException.SystemErrorException\n           && e.getCause().getCause() != null && e.getCause()\n           .getCause() instanceof InterruptedException) {\n-        throw new RuntimeException(\n-            \"Thread is interrupted, the replication source may be terminated\");\n+        LOG.info(\"Thread is interrupted, the replication source may be terminated\");\n+        return;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQxODQ2Mw=="}, "originalCommit": {"oid": "1c89328b2fa7128663877ce71ea34cf3aa690165"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQ1MzYzNA==", "bodyText": "Thanks for checking.", "url": "https://github.com/apache/hbase/pull/1441#discussion_r404453634", "createdAt": "2020-04-06T23:44:25Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java", "diffHunk": "@@ -579,8 +579,8 @@ private void interruptOrAbortWhenFail(ReplicationQueueOperation op) {\n       if (e.getCause() != null && e.getCause() instanceof KeeperException.SystemErrorException\n           && e.getCause().getCause() != null && e.getCause()\n           .getCause() instanceof InterruptedException) {\n-        throw new RuntimeException(\n-            \"Thread is interrupted, the replication source may be terminated\");\n+        LOG.info(\"Thread is interrupted, the replication source may be terminated\");\n+        return;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQxODQ2Mw=="}, "originalCommit": {"oid": "1c89328b2fa7128663877ce71ea34cf3aa690165"}, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwOTQ4OTcxOnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQyMjoxMDowN1rOGBrxQQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwMDo0NjoyMlrOGCbKew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQxODg4MQ==", "bodyText": "I tried rewriting this big nasty if-expression using an Optional. Tell me what you think\n      if (Optional.of(e.getCause())\n        .filter(c -> c instanceof KeeperException.SystemErrorException)\n        .map(c -> (KeeperException.SystemErrorException) c)\n        .map(Exception::getCause)\n        .filter(c -> c instanceof InterruptedException)\n        .isPresent()) {", "url": "https://github.com/apache/hbase/pull/1441#discussion_r404418881", "createdAt": "2020-04-06T22:10:07Z", "author": {"login": "ndimiduk"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java", "diffHunk": "@@ -579,8 +579,8 @@ private void interruptOrAbortWhenFail(ReplicationQueueOperation op) {\n       if (e.getCause() != null && e.getCause() instanceof KeeperException.SystemErrorException", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1c89328b2fa7128663877ce71ea34cf3aa690165"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTE5NTM4Nw==", "bodyText": "missed this comment, will get back.", "url": "https://github.com/apache/hbase/pull/1441#discussion_r405195387", "createdAt": "2020-04-08T00:46:22Z", "author": {"login": "huaxiangsun"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java", "diffHunk": "@@ -579,8 +579,8 @@ private void interruptOrAbortWhenFail(ReplicationQueueOperation op) {\n       if (e.getCause() != null && e.getCause() instanceof KeeperException.SystemErrorException", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQxODg4MQ=="}, "originalCommit": {"oid": "1c89328b2fa7128663877ce71ea34cf3aa690165"}, "originalPosition": 1}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxNDQ1MjA4OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/ProtobufLogReader.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwMToxMTo1M1rOGCbkxg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwMToxMTo1M1rOGCbkxg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTIwMjExOA==", "bodyText": "Added this check because the flakey test run into the following Nullpointer exception.\n2020-04-07 03:30:03,677 WARN  [RS_REFRESH_PEER-regionserver/asf905:0-0.replicationSource,2.replicationSource.wal-reader.asf905.gq1.ygridcore.net%2C41391%2C1586230117579,2] impl.BlockReaderFactory(768): I/O error constructing remote block reader. java.nio.channels.ClosedByInterruptException at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202) at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:659) at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192) at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531) at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2881) at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:825) at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:750) at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:387) at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:717) at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:665) at org.apache.hadoop.hdfs.DFSInputStream.seekToBlockSource(DFSInputStream.java:1697) at org.apache.hadoop.hdfs.DFSInputStream.readBuffer(DFSInputStream.java:915) at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:950) at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:996) at java.io.DataInputStream.read(DataInputStream.java:149) at java.io.FilterInputStream.read(FilterInputStream.java:133) at java.io.PushbackInputStream.read(PushbackInputStream.java:186) at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:209) at org.apache.hadoop.hbase.KeyValueUtil.createKeyValueFromInputStream(KeyValueUtil.java:716) at org.apache.hadoop.hbase.codec.KeyValueCodecWithTags$KeyValueDecoder.parseCell(KeyValueCodecWithTags.java:81) at org.apache.hadoop.hbase.codec.BaseDecoder.advance(BaseDecoder.java:68) at org.apache.hadoop.hbase.wal.WALEdit.readFromCells(WALEdit.java:276) at org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader.readNext(ProtobufLogReader.java:382) at org.apache.hadoop.hbase.regionserver.wal.ReaderBase.next(ReaderBase.java:98) at org.apache.hadoop.hbase.regionserver.wal.ReaderBase.next(ReaderBase.java:86) at org.apache.hadoop.hbase.replication.regionserver.WALEntryStream.readNextEntryAndRecordReaderPosition(WALEntryStream.java:263) at org.apache.hadoop.hbase.replication.regionserver.WALEntryStream.tryAdvanceEntry(WALEntryStream.java:176) at org.apache.hadoop.hbase.replication.regionserver.WALEntryStream.hasNext(WALEntryStream.java:101) at org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceWALReader.readWALEntries(ReplicationSourceWALReader.java:221) at org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceWALReader.run(ReplicationSourceWALReader.java:138) 2020-04-07 03:30:03,678 ERROR [RS_REFRESH_PEER-regionserver/asf905:0-0.replicationSource,2.replicationSource.wal-reader.asf905.gq1.ygridcore.net%2C41391%2C1586230117579,2] regionserver.ReplicationSource(397): Unexpected exception in RS_REFRESH_PEER-regionserver/asf905:0-0.replicationSource,2.replicationSource.wal-reader.asf905.gq1.ygridcore.net%2C41391%2C1586230117579,2 currentPath=hdfs://localhost:37359/user/jenkins/test-data/260e1f0f-a3fd-6192-b1d7-6568614aef58/WALs/asf905.gq1.ygridcore.net,41391,1586230117579/asf905.gq1.ygridcore.net%2C41391%2C1586230117579.1586230122806 java.lang.NullPointerException at org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader.extractHiddenEof(ProtobufLogReader.java:449) at org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader.readNext(ProtobufLogReader.java:396) at org.apache.hadoop.hbase.regionserver.wal.ReaderBase.next(ReaderBase.java:98) at org.apache.hadoop.hbase.regionserver.wal.ReaderBase.next(ReaderBase.java:86) at org.apache.hadoop.hbase.replication.regionserver.WALEntryStream.readNextEntryAndRecordReaderPosition(WALEntryStream.java:263) at org.apache.hadoop.hbase.replication.regionserver.WALEntryStream.tryAdvanceEntry(WALEntryStream.java:176) at org.apache.hadoop.hbase.replication.regionserver.WALEntryStream.hasNext(WALEntryStream.java:101) at org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceWALReader.readWALEntries(ReplicationSourceWALReader.java:221) at org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceWALReader.run(ReplicationSourceWALReader.java:138)", "url": "https://github.com/apache/hbase/pull/1441#discussion_r405202118", "createdAt": "2020-04-08T01:11:53Z", "author": {"login": "huaxiangsun"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/ProtobufLogReader.java", "diffHunk": "@@ -445,7 +445,7 @@ private IOException extractHiddenEof(Exception ex) {\n         && ex.getCause() != null && ex.getCause() instanceof IOException) {\n       ioEx = (IOException)ex.getCause();\n     }\n-    if (ioEx != null) {\n+    if ((ioEx != null) && (ioEx.getMessage() != null)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "328b048ee94b4a7275133c6fc6bb9532300a260a"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxNDQ1MzU4OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceShipper.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwMToxMjo0N1rOGCblsQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwMToxNjowMVrOGCbo_g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTIwMjM1Mw==", "bodyText": "I think we could do this\ncatch (InterruptedException | ReplicationRuntimeException e) {\n  blabla\n}", "url": "https://github.com/apache/hbase/pull/1441#discussion_r405202353", "createdAt": "2020-04-08T01:12:47Z", "author": {"login": "Apache9"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceShipper.java", "diffHunk": "@@ -122,6 +122,10 @@ public final void run() {\n       } catch (InterruptedException e) {\n         LOG.trace(\"Interrupted while waiting for next replication entry batch\", e);\n         Thread.currentThread().interrupt();\n+      } catch (ReplicationRuntimeException rre) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "328b048ee94b4a7275133c6fc6bb9532300a260a"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTIwMzE5OA==", "bodyText": "Will do, and updated the patch to fix the NullPointerException as well, thanks.", "url": "https://github.com/apache/hbase/pull/1441#discussion_r405203198", "createdAt": "2020-04-08T01:16:01Z", "author": {"login": "huaxiangsun"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceShipper.java", "diffHunk": "@@ -122,6 +122,10 @@ public final void run() {\n       } catch (InterruptedException e) {\n         LOG.trace(\"Interrupted while waiting for next replication entry batch\", e);\n         Thread.currentThread().interrupt();\n+      } catch (ReplicationRuntimeException rre) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTIwMjM1Mw=="}, "originalCommit": {"oid": "328b048ee94b4a7275133c6fc6bb9532300a260a"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxNDQ1NDYyOnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationRuntimeException.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwMToxMzoyM1rOGCbmSg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwMToxMzoyM1rOGCbmSg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTIwMjUwNg==", "bodyText": "Add a  so it will not be reformated by IDE.", "url": "https://github.com/apache/hbase/pull/1441#discussion_r405202506", "createdAt": "2020-04-08T01:13:23Z", "author": {"login": "Apache9"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationRuntimeException.java", "diffHunk": "@@ -0,0 +1,40 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.replication.regionserver;\n+\n+import org.apache.yetus.audience.InterfaceAudience;\n+\n+/**\n+ * This exception is thrown when replication source is terminated and source threads got\n+ * interrupted.\n+ *", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "328b048ee94b4a7275133c6fc6bb9532300a260a"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxNDQ1NTgwOnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/ProtobufLogReader.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwMToxMzo1NVrOGCbm9A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwMToxMzo1NVrOGCbm9A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTIwMjY3Ng==", "bodyText": "Good.", "url": "https://github.com/apache/hbase/pull/1441#discussion_r405202676", "createdAt": "2020-04-08T01:13:55Z", "author": {"login": "Apache9"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/ProtobufLogReader.java", "diffHunk": "@@ -445,7 +445,7 @@ private IOException extractHiddenEof(Exception ex) {\n         && ex.getCause() != null && ex.getCause() instanceof IOException) {\n       ioEx = (IOException)ex.getCause();\n     }\n-    if (ioEx != null) {\n+    if ((ioEx != null) && (ioEx.getMessage() != null)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "328b048ee94b4a7275133c6fc6bb9532300a260a"}, "originalPosition": 5}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1872, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}