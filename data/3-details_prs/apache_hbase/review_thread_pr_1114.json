{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzY5OTkwNTI3", "number": 1114, "reviewThreads": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QwMTozNDowNlrODcgI3A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQwODo1MjoxM1rODinN-w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxMjEzMjc2OnYy", "diffSide": "RIGHT", "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncTable.java", "isResolved": true, "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QwMTozNDowNlrOFkkvAg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xN1QwNDowMTo1NlrOFqX-Iw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg5NDkxNA==", "bodyText": "The API here is a bit strange. We introduce the above family & row method is because that family and row both can not be null, but here since we allow matching multiple qualifiers acrossing different families, we can accept null families as we can pass it through the filter implementation? So here, either we deprecated the old checkAndMutate(family, row) method and introduce a new family method, or we introduce a new checkAndMutate(row, filter)?", "url": "https://github.com/apache/hbase/pull/1114#discussion_r373894914", "createdAt": "2020-02-03T01:34:06Z", "author": {"login": "Apache9"}, "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncTable.java", "diffHunk": "@@ -233,6 +234,28 @@\n    */\n   CheckAndMutateBuilder checkAndMutate(byte[] row, byte[] family);\n \n+  /**\n+   * Atomically checks if a row matches the specified filter. If it does, it adds the\n+   * Put/Delete/RowMutations.\n+   * <p>\n+   * Use the returned {@link CheckAndMutateBuilder} to construct your request and then execute it.\n+   * This is a fluent style API, the code is like:\n+   *\n+   * <pre>\n+   * <code>\n+   * table.checkAndMutate(row).ifMatches(filter).thenPut(put)\n+   *     .thenAccept(succ -> {\n+   *       if (succ) {\n+   *         System.out.println(\"Check and put succeeded\");\n+   *       } else {\n+   *         System.out.println(\"Check and put failed\");\n+   *       }\n+   *     });\n+   * </code>\n+   * </pre>\n+   */\n+  CheckAndMutateBuilder checkAndMutate(byte[] row);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "34e71d99233b34df974109dbccd4484f141b43ce"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkwMjY3MA==", "bodyText": "@Apache9 Thank you for reviewing this!\n\nbut here since we allow matching multiple qualifiers acrossing different families, we can accept null families as we can pass it through the filter implementation?\n\nYes. With this new feature, we can specify multiple conditions across different families by setting a filter. So the family can be null.\nMy intention was if we want to specify a filter by ifMatches(filter), we can use checkAndMutate(row). And if we want to specify a qualifier and a condition by qualifier()/ifNotExists()/ifEquals()/ifMatches(op, value), we can use checkAndMutate(row, family) in the existing way.\nAnd, if we call ifMatches(filter) after calling checkAndMutate(row, family) wrongly, it will throw UnsupportedOperationException with the message \"Please use checkAndMutate(row)\":\ntable.checkAndMutate(row, family).ifMatches(filter).thenPut(put); // UnsupportedOperationException: Please use checkAndMutate(row)\n\nAnd vice versa:\ntable.checkAndMutate(row).qualifier(qualifier).ifMatches(op, value).thenPut(put); // UnsupportedOperationException: Please use checkAndMutate(row, family)\n\nPlease see the following test for this:\nhttps://github.com/brfrn169/hbase/blob/HBASE-23146/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestCheckAndMutate.java#L380-L416\nI think, you are right, it might be a little bit confusing but I'm still feeling it's okay. What do you think?", "url": "https://github.com/apache/hbase/pull/1114#discussion_r373902670", "createdAt": "2020-02-03T02:38:23Z", "author": {"login": "brfrn169"}, "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncTable.java", "diffHunk": "@@ -233,6 +234,28 @@\n    */\n   CheckAndMutateBuilder checkAndMutate(byte[] row, byte[] family);\n \n+  /**\n+   * Atomically checks if a row matches the specified filter. If it does, it adds the\n+   * Put/Delete/RowMutations.\n+   * <p>\n+   * Use the returned {@link CheckAndMutateBuilder} to construct your request and then execute it.\n+   * This is a fluent style API, the code is like:\n+   *\n+   * <pre>\n+   * <code>\n+   * table.checkAndMutate(row).ifMatches(filter).thenPut(put)\n+   *     .thenAccept(succ -> {\n+   *       if (succ) {\n+   *         System.out.println(\"Check and put succeeded\");\n+   *       } else {\n+   *         System.out.println(\"Check and put failed\");\n+   *       }\n+   *     });\n+   * </code>\n+   * </pre>\n+   */\n+  CheckAndMutateBuilder checkAndMutate(byte[] row);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg5NDkxNA=="}, "originalCommit": {"oid": "34e71d99233b34df974109dbccd4484f141b43ce"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjA3MjM4OA==", "bodyText": "Ping @Apache9", "url": "https://github.com/apache/hbase/pull/1114#discussion_r376072388", "createdAt": "2020-02-06T20:45:48Z", "author": {"login": "brfrn169"}, "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncTable.java", "diffHunk": "@@ -233,6 +234,28 @@\n    */\n   CheckAndMutateBuilder checkAndMutate(byte[] row, byte[] family);\n \n+  /**\n+   * Atomically checks if a row matches the specified filter. If it does, it adds the\n+   * Put/Delete/RowMutations.\n+   * <p>\n+   * Use the returned {@link CheckAndMutateBuilder} to construct your request and then execute it.\n+   * This is a fluent style API, the code is like:\n+   *\n+   * <pre>\n+   * <code>\n+   * table.checkAndMutate(row).ifMatches(filter).thenPut(put)\n+   *     .thenAccept(succ -> {\n+   *       if (succ) {\n+   *         System.out.println(\"Check and put succeeded\");\n+   *       } else {\n+   *         System.out.println(\"Check and put failed\");\n+   *       }\n+   *     });\n+   * </code>\n+   * </pre>\n+   */\n+  CheckAndMutateBuilder checkAndMutate(byte[] row);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg5NDkxNA=="}, "originalCommit": {"oid": "34e71d99233b34df974109dbccd4484f141b43ce"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjY0OTUyMw==", "bodyText": "@Apache9\nOne of the reasons why I decided the design of the new API here is that I wanted to keep the compatibility of the existing API. This patch also involves coprocessor changes, and I didn't want to change the existing methods and I just wanted to add new methods.\nIf you still think the API is strange, I can change it.\nThanks.", "url": "https://github.com/apache/hbase/pull/1114#discussion_r376649523", "createdAt": "2020-02-07T23:08:20Z", "author": {"login": "brfrn169"}, "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncTable.java", "diffHunk": "@@ -233,6 +234,28 @@\n    */\n   CheckAndMutateBuilder checkAndMutate(byte[] row, byte[] family);\n \n+  /**\n+   * Atomically checks if a row matches the specified filter. If it does, it adds the\n+   * Put/Delete/RowMutations.\n+   * <p>\n+   * Use the returned {@link CheckAndMutateBuilder} to construct your request and then execute it.\n+   * This is a fluent style API, the code is like:\n+   *\n+   * <pre>\n+   * <code>\n+   * table.checkAndMutate(row).ifMatches(filter).thenPut(put)\n+   *     .thenAccept(succ -> {\n+   *       if (succ) {\n+   *         System.out.println(\"Check and put succeeded\");\n+   *       } else {\n+   *         System.out.println(\"Check and put failed\");\n+   *       }\n+   *     });\n+   * </code>\n+   * </pre>\n+   */\n+  CheckAndMutateBuilder checkAndMutate(byte[] row);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg5NDkxNA=="}, "originalCommit": {"oid": "34e71d99233b34df974109dbccd4484f141b43ce"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTk1MTc3OQ==", "bodyText": "@Apache9 Could you please reply this when you get a chance?", "url": "https://github.com/apache/hbase/pull/1114#discussion_r379951779", "createdAt": "2020-02-17T01:05:28Z", "author": {"login": "brfrn169"}, "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncTable.java", "diffHunk": "@@ -233,6 +234,28 @@\n    */\n   CheckAndMutateBuilder checkAndMutate(byte[] row, byte[] family);\n \n+  /**\n+   * Atomically checks if a row matches the specified filter. If it does, it adds the\n+   * Put/Delete/RowMutations.\n+   * <p>\n+   * Use the returned {@link CheckAndMutateBuilder} to construct your request and then execute it.\n+   * This is a fluent style API, the code is like:\n+   *\n+   * <pre>\n+   * <code>\n+   * table.checkAndMutate(row).ifMatches(filter).thenPut(put)\n+   *     .thenAccept(succ -> {\n+   *       if (succ) {\n+   *         System.out.println(\"Check and put succeeded\");\n+   *       } else {\n+   *         System.out.println(\"Check and put failed\");\n+   *       }\n+   *     });\n+   * </code>\n+   * </pre>\n+   */\n+  CheckAndMutateBuilder checkAndMutate(byte[] row);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg5NDkxNA=="}, "originalCommit": {"oid": "34e71d99233b34df974109dbccd4484f141b43ce"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTk1MjE4Mw==", "bodyText": "Actually, this feature is needed for our use case. If we can, I want to include it in hbase-2.3.", "url": "https://github.com/apache/hbase/pull/1114#discussion_r379952183", "createdAt": "2020-02-17T01:08:37Z", "author": {"login": "brfrn169"}, "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncTable.java", "diffHunk": "@@ -233,6 +234,28 @@\n    */\n   CheckAndMutateBuilder checkAndMutate(byte[] row, byte[] family);\n \n+  /**\n+   * Atomically checks if a row matches the specified filter. If it does, it adds the\n+   * Put/Delete/RowMutations.\n+   * <p>\n+   * Use the returned {@link CheckAndMutateBuilder} to construct your request and then execute it.\n+   * This is a fluent style API, the code is like:\n+   *\n+   * <pre>\n+   * <code>\n+   * table.checkAndMutate(row).ifMatches(filter).thenPut(put)\n+   *     .thenAccept(succ -> {\n+   *       if (succ) {\n+   *         System.out.println(\"Check and put succeeded\");\n+   *       } else {\n+   *         System.out.println(\"Check and put failed\");\n+   *       }\n+   *     });\n+   * </code>\n+   * </pre>\n+   */\n+  CheckAndMutateBuilder checkAndMutate(byte[] row);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg5NDkxNA=="}, "originalCommit": {"oid": "34e71d99233b34df974109dbccd4484f141b43ce"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTk1NjQxNw==", "bodyText": "Sorry, we are still fighting with 2019-nCov so... Hope Japan will be safe...\nI still prefer that we introduce a new method which accepts a row and filter as parameters to construct a Builder, this is more natural. Enforcing usage by method signature is better than javadoc.", "url": "https://github.com/apache/hbase/pull/1114#discussion_r379956417", "createdAt": "2020-02-17T01:43:02Z", "author": {"login": "Apache9"}, "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncTable.java", "diffHunk": "@@ -233,6 +234,28 @@\n    */\n   CheckAndMutateBuilder checkAndMutate(byte[] row, byte[] family);\n \n+  /**\n+   * Atomically checks if a row matches the specified filter. If it does, it adds the\n+   * Put/Delete/RowMutations.\n+   * <p>\n+   * Use the returned {@link CheckAndMutateBuilder} to construct your request and then execute it.\n+   * This is a fluent style API, the code is like:\n+   *\n+   * <pre>\n+   * <code>\n+   * table.checkAndMutate(row).ifMatches(filter).thenPut(put)\n+   *     .thenAccept(succ -> {\n+   *       if (succ) {\n+   *         System.out.println(\"Check and put succeeded\");\n+   *       } else {\n+   *         System.out.println(\"Check and put failed\");\n+   *       }\n+   *     });\n+   * </code>\n+   * </pre>\n+   */\n+  CheckAndMutateBuilder checkAndMutate(byte[] row);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg5NDkxNA=="}, "originalCommit": {"oid": "34e71d99233b34df974109dbccd4484f141b43ce"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTk3NzI1MQ==", "bodyText": "@Apache9 Thank you very much for the reply.\n\nwe are still fighting with 2019-nCov so... Hope Japan will be safe...\n\nOh okay.. I hope you are well... I'm okay now, but 2019-nCov is spreading little by little in Japan actually.\n\nI still prefer that we introduce a new method which accepts a row and filter as parameters to construct a Builder, this is more natural. Enforcing usage by method signature is better than javadoc.\n\nThank you for commenting on this. I will change the API as you mentioned.", "url": "https://github.com/apache/hbase/pull/1114#discussion_r379977251", "createdAt": "2020-02-17T04:01:56Z", "author": {"login": "brfrn169"}, "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncTable.java", "diffHunk": "@@ -233,6 +234,28 @@\n    */\n   CheckAndMutateBuilder checkAndMutate(byte[] row, byte[] family);\n \n+  /**\n+   * Atomically checks if a row matches the specified filter. If it does, it adds the\n+   * Put/Delete/RowMutations.\n+   * <p>\n+   * Use the returned {@link CheckAndMutateBuilder} to construct your request and then execute it.\n+   * This is a fluent style API, the code is like:\n+   *\n+   * <pre>\n+   * <code>\n+   * table.checkAndMutate(row).ifMatches(filter).thenPut(put)\n+   *     .thenAccept(succ -> {\n+   *       if (succ) {\n+   *         System.out.println(\"Check and put succeeded\");\n+   *       } else {\n+   *         System.out.println(\"Check and put failed\");\n+   *       }\n+   *     });\n+   * </code>\n+   * </pre>\n+   */\n+  CheckAndMutateBuilder checkAndMutate(byte[] row);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg5NDkxNA=="}, "originalCommit": {"oid": "34e71d99233b34df974109dbccd4484f141b43ce"}, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxMjEzMzA3OnYy", "diffSide": "RIGHT", "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/shaded/protobuf/RequestConverter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QwMTozNDo0MlrOFkkvLw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QwMTozNDo0MlrOFkkvLw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg5NDk1OQ==", "bodyText": "Just remove all the empty param javadoc?", "url": "https://github.com/apache/hbase/pull/1114#discussion_r373894959", "createdAt": "2020-02-03T01:34:42Z", "author": {"login": "Apache9"}, "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/shaded/protobuf/RequestConverter.java", "diffHunk": "@@ -191,18 +193,18 @@ public static GetRequest buildGetRequest(final byte[] regionName,\n    * @param row\n    * @param family\n    * @param qualifier\n-   * @param comparator\n-   * @param compareType\n+   * @param op", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "34e71d99233b34df974109dbccd4484f141b43ce"}, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxMjEzMzMzOnYy", "diffSide": "RIGHT", "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/shaded/protobuf/RequestConverter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QwMTozNToxMFrOFkkvVw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QwMTozNToxMFrOFkkvVw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg5NDk5OQ==", "bodyText": "Ditto.", "url": "https://github.com/apache/hbase/pull/1114#discussion_r373894999", "createdAt": "2020-02-03T01:35:10Z", "author": {"login": "Apache9"}, "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/shaded/protobuf/RequestConverter.java", "diffHunk": "@@ -212,54 +214,55 @@ public static MutateRequest buildMutateRequest(\n    * @param row\n    * @param family\n    * @param qualifier\n-   * @param comparator\n-   * @param compareType\n+   * @param op\n+   * @param value\n    * @param delete\n    * @return a mutate request\n    * @throws IOException\n    */\n   public static MutateRequest buildMutateRequest(\n-      final byte[] regionName, final byte[] row, final byte[] family,\n-      final byte [] qualifier, final ByteArrayComparable comparator,\n-      final CompareType compareType, TimeRange timeRange, final Delete delete) throws IOException {\n-    return buildMutateRequest(regionName, row, family, qualifier, comparator, compareType, timeRange\n-      , delete, MutationType.DELETE);\n+    final byte[] regionName, final byte[] row, final byte[] family,\n+    final byte [] qualifier, final CompareOperator op, final byte[] value, final Filter filter,\n+    final TimeRange timeRange, final Delete delete) throws IOException {\n+    return buildMutateRequest(regionName, row, family, qualifier, op, value, filter, timeRange,\n+      delete, MutationType.DELETE);\n   }\n \n   public static MutateRequest buildMutateRequest(final byte[] regionName, final byte[] row,\n-    final byte[] family, final byte[] qualifier, final ByteArrayComparable comparator,\n-    final CompareType compareType, TimeRange timeRange, final Mutation mutation,\n+    final byte[] family, final byte[] qualifier, final CompareOperator op, final byte[] value,\n+    final Filter filter, final TimeRange timeRange, final Mutation mutation,\n     final MutationType type) throws IOException {\n     return MutateRequest.newBuilder()\n       .setRegion(buildRegionSpecifier(RegionSpecifierType.REGION_NAME, regionName))\n       .setMutation(ProtobufUtil.toMutation(type, mutation))\n-      .setCondition(buildCondition(row, family, qualifier, comparator, compareType, timeRange))\n+      .setCondition(buildCondition(row, family, qualifier, op, value, filter, timeRange))\n       .build();\n   }\n+\n   /**\n    * Create a protocol buffer MutateRequest for conditioned row mutations\n    *\n    * @param regionName\n    * @param row\n    * @param family\n    * @param qualifier\n-   * @param comparator\n-   * @param compareType\n+   * @param op", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "34e71d99233b34df974109dbccd4484f141b43ce"}, "originalPosition": 92}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxMjEzMzQ0OnYy", "diffSide": "RIGHT", "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/shaded/protobuf/RequestConverter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QwMTozNToxOVrOFkkvag==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QwMTozNToxOVrOFkkvag==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg5NTAxOA==", "bodyText": "Ditto.", "url": "https://github.com/apache/hbase/pull/1114#discussion_r373895018", "createdAt": "2020-02-03T01:35:19Z", "author": {"login": "Apache9"}, "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/shaded/protobuf/RequestConverter.java", "diffHunk": "@@ -921,22 +924,28 @@ public static RegionSpecifier buildRegionSpecifier(\n    * @param row\n    * @param family\n    * @param qualifier\n-   * @param comparator\n-   * @param compareType\n+   * @param op", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "34e71d99233b34df974109dbccd4484f141b43ce"}, "originalPosition": 129}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3NjIwNzMxOnYy", "diffSide": "RIGHT", "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncTable.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQwODo1MjoxM1rOFt9R1w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQyMzowNTozNlrOFuYjGg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzczNDIzMQ==", "bodyText": "I think these 4 methods are also in the CheckAndMutateBuilder? Maybe we could have a CheckAndMutateBuilderBase to palce these methods. Anyway, can be a follow issue as I do not think the change will break compatibility.", "url": "https://github.com/apache/hbase/pull/1114#discussion_r383734231", "createdAt": "2020-02-25T08:52:13Z", "author": {"login": "Apache9"}, "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncTable.java", "diffHunk": "@@ -289,6 +290,60 @@ default CheckAndMutateBuilder ifEquals(byte[] value) {\n     CompletableFuture<Boolean> thenMutate(RowMutations mutation);\n   }\n \n+  /**\n+   * Atomically checks if a row matches the specified filter. If it does, it adds the\n+   * Put/Delete/RowMutations.\n+   * <p>\n+   * Use the returned {@link CheckAndMutateWithFilterBuilder} to construct your request and then\n+   * execute it. This is a fluent style API, the code is like:\n+   *\n+   * <pre>\n+   * <code>\n+   * table.checkAndMutate(row, filter).thenPut(put)\n+   *     .thenAccept(succ -> {\n+   *       if (succ) {\n+   *         System.out.println(\"Check and put succeeded\");\n+   *       } else {\n+   *         System.out.println(\"Check and put failed\");\n+   *       }\n+   *     });\n+   * </code>\n+   * </pre>\n+   */\n+  CheckAndMutateWithFilterBuilder checkAndMutate(byte[] row, Filter filter);\n+\n+  /**\n+   * A helper class for sending checkAndMutate request with a filter.\n+   */\n+  interface CheckAndMutateWithFilterBuilder {\n+\n+    /**\n+     * @param timeRange time range to check.\n+     */\n+    CheckAndMutateWithFilterBuilder timeRange(TimeRange timeRange);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "927d5e093c33d06ec3b640e40519717725d81e87"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDE4MTAxOA==", "bodyText": "Thank you very much for your review and approval!\n\nMaybe we could have a CheckAndMutateBuilderBase to palce these methods.\n\nYes, we can have CheckAndMutateBuilderBase to place the methods.\n\nAnyway, can be a follow issue as I do not think the change will break compatibility.\n\nSure. Maybe we can do it at a next time when we add another type of checkAndMutate.\nWill commit this. Thank you very much again!", "url": "https://github.com/apache/hbase/pull/1114#discussion_r384181018", "createdAt": "2020-02-25T23:05:36Z", "author": {"login": "brfrn169"}, "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncTable.java", "diffHunk": "@@ -289,6 +290,60 @@ default CheckAndMutateBuilder ifEquals(byte[] value) {\n     CompletableFuture<Boolean> thenMutate(RowMutations mutation);\n   }\n \n+  /**\n+   * Atomically checks if a row matches the specified filter. If it does, it adds the\n+   * Put/Delete/RowMutations.\n+   * <p>\n+   * Use the returned {@link CheckAndMutateWithFilterBuilder} to construct your request and then\n+   * execute it. This is a fluent style API, the code is like:\n+   *\n+   * <pre>\n+   * <code>\n+   * table.checkAndMutate(row, filter).thenPut(put)\n+   *     .thenAccept(succ -> {\n+   *       if (succ) {\n+   *         System.out.println(\"Check and put succeeded\");\n+   *       } else {\n+   *         System.out.println(\"Check and put failed\");\n+   *       }\n+   *     });\n+   * </code>\n+   * </pre>\n+   */\n+  CheckAndMutateWithFilterBuilder checkAndMutate(byte[] row, Filter filter);\n+\n+  /**\n+   * A helper class for sending checkAndMutate request with a filter.\n+   */\n+  interface CheckAndMutateWithFilterBuilder {\n+\n+    /**\n+     * @param timeRange time range to check.\n+     */\n+    CheckAndMutateWithFilterBuilder timeRange(TimeRange timeRange);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzczNDIzMQ=="}, "originalCommit": {"oid": "927d5e093c33d06ec3b640e40519717725d81e87"}, "originalPosition": 42}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2193, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}