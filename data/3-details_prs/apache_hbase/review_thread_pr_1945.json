{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDM3NjE2MzAz", "number": 1945, "reviewThreads": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQwNzozNTo0NlrOEHdYEA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNVQxNzo1NDowM1rOEI3VzQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2MjU2Nzg0OnYy", "diffSide": "RIGHT", "path": "hbase-zookeeper/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKWatcher.java", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQwNzozNTo0NlrOGm1FFw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNVQwMjo0MDoxOVrOGopfNA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzM2ODcyNw==", "bodyText": "IMHO error is fine but better to keep it warn. We anyways have warn for InterruptedException also.", "url": "https://github.com/apache/hbase/pull/1945#discussion_r443368727", "createdAt": "2020-06-22T07:35:46Z", "author": {"login": "virajjasani"}, "path": "hbase-zookeeper/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKWatcher.java", "diffHunk": "@@ -595,9 +604,28 @@ private void connectionEvent(WatchedEvent event) {\n    * data of an existing node and delete or transition that node, utilizing the\n    * previously read version and data.  We want to ensure that the version read\n    * is up-to-date from when we begin the operation.\n+   * <p>\n    */\n-  public void sync(String path) throws KeeperException {\n-    this.recoverableZooKeeper.sync(path, null, null);\n+  public void syncOrTimeout(String path) throws KeeperException {\n+    final CountDownLatch latch = new CountDownLatch(1);\n+    long startTime = EnvironmentEdgeManager.currentTime();\n+    this.recoverableZooKeeper.sync(path, (i, s, o) -> latch.countDown(), null);\n+    try {\n+      if (!latch.await(zkSyncTimeout, TimeUnit.MILLISECONDS)) {\n+        LOG.error(\"sync() operation to ZK timed out. Configured timeout: {}ms. This usually points \"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9bde262b066b94877f53066c01b024f14ded5107"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzcxODE2Mg==", "bodyText": "This should be WARN.", "url": "https://github.com/apache/hbase/pull/1945#discussion_r443718162", "createdAt": "2020-06-22T17:30:59Z", "author": {"login": "apurtell"}, "path": "hbase-zookeeper/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKWatcher.java", "diffHunk": "@@ -595,9 +604,28 @@ private void connectionEvent(WatchedEvent event) {\n    * data of an existing node and delete or transition that node, utilizing the\n    * previously read version and data.  We want to ensure that the version read\n    * is up-to-date from when we begin the operation.\n+   * <p>\n    */\n-  public void sync(String path) throws KeeperException {\n-    this.recoverableZooKeeper.sync(path, null, null);\n+  public void syncOrTimeout(String path) throws KeeperException {\n+    final CountDownLatch latch = new CountDownLatch(1);\n+    long startTime = EnvironmentEdgeManager.currentTime();\n+    this.recoverableZooKeeper.sync(path, (i, s, o) -> latch.countDown(), null);\n+    try {\n+      if (!latch.await(zkSyncTimeout, TimeUnit.MILLISECONDS)) {\n+        LOG.error(\"sync() operation to ZK timed out. Configured timeout: {}ms. This usually points \"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzM2ODcyNw=="}, "originalCommit": {"oid": "9bde262b066b94877f53066c01b024f14ded5107"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzczMTg1Mw==", "bodyText": "Any particular reason this has to be WARN? This can potentially be a correctness issue at this point and hence I chose the higher log level.", "url": "https://github.com/apache/hbase/pull/1945#discussion_r443731853", "createdAt": "2020-06-22T17:56:32Z", "author": {"login": "bharathv"}, "path": "hbase-zookeeper/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKWatcher.java", "diffHunk": "@@ -595,9 +604,28 @@ private void connectionEvent(WatchedEvent event) {\n    * data of an existing node and delete or transition that node, utilizing the\n    * previously read version and data.  We want to ensure that the version read\n    * is up-to-date from when we begin the operation.\n+   * <p>\n    */\n-  public void sync(String path) throws KeeperException {\n-    this.recoverableZooKeeper.sync(path, null, null);\n+  public void syncOrTimeout(String path) throws KeeperException {\n+    final CountDownLatch latch = new CountDownLatch(1);\n+    long startTime = EnvironmentEdgeManager.currentTime();\n+    this.recoverableZooKeeper.sync(path, (i, s, o) -> latch.countDown(), null);\n+    try {\n+      if (!latch.await(zkSyncTimeout, TimeUnit.MILLISECONDS)) {\n+        LOG.error(\"sync() operation to ZK timed out. Configured timeout: {}ms. This usually points \"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzM2ODcyNw=="}, "originalCommit": {"oid": "9bde262b066b94877f53066c01b024f14ded5107"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQxNDY1NA==", "bodyText": "WARN implies to me as an operator that something bad happened that is noteworthy but not an emergency. ERROR implies a serious problem that probably should cause someone to be paged.\nsync is going to occasionally time out. We should be handling such without correctness problems. ERROR logging doesn't substitute for handling the timeout properly. So, assuming we are handling timeouts correctly, WARN level logging is most appropriate.", "url": "https://github.com/apache/hbase/pull/1945#discussion_r444414654", "createdAt": "2020-06-23T18:11:05Z", "author": {"login": "apurtell"}, "path": "hbase-zookeeper/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKWatcher.java", "diffHunk": "@@ -595,9 +604,28 @@ private void connectionEvent(WatchedEvent event) {\n    * data of an existing node and delete or transition that node, utilizing the\n    * previously read version and data.  We want to ensure that the version read\n    * is up-to-date from when we begin the operation.\n+   * <p>\n    */\n-  public void sync(String path) throws KeeperException {\n-    this.recoverableZooKeeper.sync(path, null, null);\n+  public void syncOrTimeout(String path) throws KeeperException {\n+    final CountDownLatch latch = new CountDownLatch(1);\n+    long startTime = EnvironmentEdgeManager.currentTime();\n+    this.recoverableZooKeeper.sync(path, (i, s, o) -> latch.countDown(), null);\n+    try {\n+      if (!latch.await(zkSyncTimeout, TimeUnit.MILLISECONDS)) {\n+        LOG.error(\"sync() operation to ZK timed out. Configured timeout: {}ms. This usually points \"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzM2ODcyNw=="}, "originalCommit": {"oid": "9bde262b066b94877f53066c01b024f14ded5107"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTI3NTk1Ng==", "bodyText": "Fair point. Changed.", "url": "https://github.com/apache/hbase/pull/1945#discussion_r445275956", "createdAt": "2020-06-25T02:40:19Z", "author": {"login": "bharathv"}, "path": "hbase-zookeeper/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKWatcher.java", "diffHunk": "@@ -595,9 +604,28 @@ private void connectionEvent(WatchedEvent event) {\n    * data of an existing node and delete or transition that node, utilizing the\n    * previously read version and data.  We want to ensure that the version read\n    * is up-to-date from when we begin the operation.\n+   * <p>\n    */\n-  public void sync(String path) throws KeeperException {\n-    this.recoverableZooKeeper.sync(path, null, null);\n+  public void syncOrTimeout(String path) throws KeeperException {\n+    final CountDownLatch latch = new CountDownLatch(1);\n+    long startTime = EnvironmentEdgeManager.currentTime();\n+    this.recoverableZooKeeper.sync(path, (i, s, o) -> latch.countDown(), null);\n+    try {\n+      if (!latch.await(zkSyncTimeout, TimeUnit.MILLISECONDS)) {\n+        LOG.error(\"sync() operation to ZK timed out. Configured timeout: {}ms. This usually points \"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzM2ODcyNw=="}, "originalCommit": {"oid": "9bde262b066b94877f53066c01b024f14ded5107"}, "originalPosition": 60}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2MjU3NTA5OnYy", "diffSide": "RIGHT", "path": "hbase-zookeeper/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKWatcher.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQwNzozODoxMlrOGm1Jug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNVQwMjo0MToxN1rOGopgDA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzM2OTkxNA==", "bodyText": "RecoverableZooKeeper is IA.Private. Can we remove last argument Object ctx as part of this PR? Anyways we pass null context to actual API.", "url": "https://github.com/apache/hbase/pull/1945#discussion_r443369914", "createdAt": "2020-06-22T07:38:12Z", "author": {"login": "virajjasani"}, "path": "hbase-zookeeper/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKWatcher.java", "diffHunk": "@@ -595,9 +604,28 @@ private void connectionEvent(WatchedEvent event) {\n    * data of an existing node and delete or transition that node, utilizing the\n    * previously read version and data.  We want to ensure that the version read\n    * is up-to-date from when we begin the operation.\n+   * <p>\n    */\n-  public void sync(String path) throws KeeperException {\n-    this.recoverableZooKeeper.sync(path, null, null);\n+  public void syncOrTimeout(String path) throws KeeperException {\n+    final CountDownLatch latch = new CountDownLatch(1);\n+    long startTime = EnvironmentEdgeManager.currentTime();\n+    this.recoverableZooKeeper.sync(path, (i, s, o) -> latch.countDown(), null);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9bde262b066b94877f53066c01b024f14ded5107"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzczNjM3Ng==", "bodyText": "ok will do.", "url": "https://github.com/apache/hbase/pull/1945#discussion_r443736376", "createdAt": "2020-06-22T18:04:47Z", "author": {"login": "bharathv"}, "path": "hbase-zookeeper/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKWatcher.java", "diffHunk": "@@ -595,9 +604,28 @@ private void connectionEvent(WatchedEvent event) {\n    * data of an existing node and delete or transition that node, utilizing the\n    * previously read version and data.  We want to ensure that the version read\n    * is up-to-date from when we begin the operation.\n+   * <p>\n    */\n-  public void sync(String path) throws KeeperException {\n-    this.recoverableZooKeeper.sync(path, null, null);\n+  public void syncOrTimeout(String path) throws KeeperException {\n+    final CountDownLatch latch = new CountDownLatch(1);\n+    long startTime = EnvironmentEdgeManager.currentTime();\n+    this.recoverableZooKeeper.sync(path, (i, s, o) -> latch.countDown(), null);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzM2OTkxNA=="}, "originalCommit": {"oid": "9bde262b066b94877f53066c01b024f14ded5107"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mzc3NTc5NA==", "bodyText": "Why can't we instead pass ctx as the last argument instead of NULL during the actual API call ? Just in case we want to use this field somewhere else in future to get the context in callback.", "url": "https://github.com/apache/hbase/pull/1945#discussion_r443775794", "createdAt": "2020-06-22T19:23:37Z", "author": {"login": "sguggilam"}, "path": "hbase-zookeeper/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKWatcher.java", "diffHunk": "@@ -595,9 +604,28 @@ private void connectionEvent(WatchedEvent event) {\n    * data of an existing node and delete or transition that node, utilizing the\n    * previously read version and data.  We want to ensure that the version read\n    * is up-to-date from when we begin the operation.\n+   * <p>\n    */\n-  public void sync(String path) throws KeeperException {\n-    this.recoverableZooKeeper.sync(path, null, null);\n+  public void syncOrTimeout(String path) throws KeeperException {\n+    final CountDownLatch latch = new CountDownLatch(1);\n+    long startTime = EnvironmentEdgeManager.currentTime();\n+    this.recoverableZooKeeper.sync(path, (i, s, o) -> latch.countDown(), null);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzM2OTkxNA=="}, "originalCommit": {"oid": "9bde262b066b94877f53066c01b024f14ded5107"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTI3NjE3Mg==", "bodyText": "That sounds better Sandeep. Fixed it. (I don't have a strong preference either way)", "url": "https://github.com/apache/hbase/pull/1945#discussion_r445276172", "createdAt": "2020-06-25T02:41:17Z", "author": {"login": "bharathv"}, "path": "hbase-zookeeper/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKWatcher.java", "diffHunk": "@@ -595,9 +604,28 @@ private void connectionEvent(WatchedEvent event) {\n    * data of an existing node and delete or transition that node, utilizing the\n    * previously read version and data.  We want to ensure that the version read\n    * is up-to-date from when we begin the operation.\n+   * <p>\n    */\n-  public void sync(String path) throws KeeperException {\n-    this.recoverableZooKeeper.sync(path, null, null);\n+  public void syncOrTimeout(String path) throws KeeperException {\n+    final CountDownLatch latch = new CountDownLatch(1);\n+    long startTime = EnvironmentEdgeManager.currentTime();\n+    this.recoverableZooKeeper.sync(path, (i, s, o) -> latch.countDown(), null);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzM2OTkxNA=="}, "originalCommit": {"oid": "9bde262b066b94877f53066c01b024f14ded5107"}, "originalPosition": 57}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2NDc0MDU4OnYy", "diffSide": "RIGHT", "path": "hbase-zookeeper/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKWatcher.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQxNzozMDozM1rOGnKZRA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNVQwMjo0MjowNFrOGophBQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzcxNzk1Ng==", "bodyText": "This has to be backported to branch-1, which requires Java 7 compatible code, and there's no real need for a lambda here. We have guaranteed code divergence between the branches in exchange for perhaps some improved readability. Is it worth it?", "url": "https://github.com/apache/hbase/pull/1945#discussion_r443717956", "createdAt": "2020-06-22T17:30:33Z", "author": {"login": "apurtell"}, "path": "hbase-zookeeper/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKWatcher.java", "diffHunk": "@@ -595,9 +604,28 @@ private void connectionEvent(WatchedEvent event) {\n    * data of an existing node and delete or transition that node, utilizing the\n    * previously read version and data.  We want to ensure that the version read\n    * is up-to-date from when we begin the operation.\n+   * <p>\n    */\n-  public void sync(String path) throws KeeperException {\n-    this.recoverableZooKeeper.sync(path, null, null);\n+  public void syncOrTimeout(String path) throws KeeperException {\n+    final CountDownLatch latch = new CountDownLatch(1);\n+    long startTime = EnvironmentEdgeManager.currentTime();\n+    this.recoverableZooKeeper.sync(path, (i, s, o) -> latch.countDown(), null);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9bde262b066b94877f53066c01b024f14ded5107"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzczNzg3NQ==", "bodyText": "I kind of like the fact that the code is a bit concise (since there is no real logic in this lambda in this case) but I get the concern about readability. I don't have a strong preference though, I can switch it to an inline class.", "url": "https://github.com/apache/hbase/pull/1945#discussion_r443737875", "createdAt": "2020-06-22T18:07:29Z", "author": {"login": "bharathv"}, "path": "hbase-zookeeper/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKWatcher.java", "diffHunk": "@@ -595,9 +604,28 @@ private void connectionEvent(WatchedEvent event) {\n    * data of an existing node and delete or transition that node, utilizing the\n    * previously read version and data.  We want to ensure that the version read\n    * is up-to-date from when we begin the operation.\n+   * <p>\n    */\n-  public void sync(String path) throws KeeperException {\n-    this.recoverableZooKeeper.sync(path, null, null);\n+  public void syncOrTimeout(String path) throws KeeperException {\n+    final CountDownLatch latch = new CountDownLatch(1);\n+    long startTime = EnvironmentEdgeManager.currentTime();\n+    this.recoverableZooKeeper.sync(path, (i, s, o) -> latch.countDown(), null);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzcxNzk1Ng=="}, "originalCommit": {"oid": "9bde262b066b94877f53066c01b024f14ded5107"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQxNTMwMw==", "bodyText": "Every Java 8 ism makes a backport to branch-1 that more painful. If you don't need to do it, please don't. Unless the change is not intended for branch-1 then who cares.", "url": "https://github.com/apache/hbase/pull/1945#discussion_r444415303", "createdAt": "2020-06-23T18:12:15Z", "author": {"login": "apurtell"}, "path": "hbase-zookeeper/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKWatcher.java", "diffHunk": "@@ -595,9 +604,28 @@ private void connectionEvent(WatchedEvent event) {\n    * data of an existing node and delete or transition that node, utilizing the\n    * previously read version and data.  We want to ensure that the version read\n    * is up-to-date from when we begin the operation.\n+   * <p>\n    */\n-  public void sync(String path) throws KeeperException {\n-    this.recoverableZooKeeper.sync(path, null, null);\n+  public void syncOrTimeout(String path) throws KeeperException {\n+    final CountDownLatch latch = new CountDownLatch(1);\n+    long startTime = EnvironmentEdgeManager.currentTime();\n+    this.recoverableZooKeeper.sync(path, (i, s, o) -> latch.countDown(), null);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzcxNzk1Ng=="}, "originalCommit": {"oid": "9bde262b066b94877f53066c01b024f14ded5107"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTI3NjQyMQ==", "bodyText": "Ya, this is meant to be back ported to branch-1, but I'll take care of it with a small rewrite, hope thats okay.", "url": "https://github.com/apache/hbase/pull/1945#discussion_r445276421", "createdAt": "2020-06-25T02:42:04Z", "author": {"login": "bharathv"}, "path": "hbase-zookeeper/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKWatcher.java", "diffHunk": "@@ -595,9 +604,28 @@ private void connectionEvent(WatchedEvent event) {\n    * data of an existing node and delete or transition that node, utilizing the\n    * previously read version and data.  We want to ensure that the version read\n    * is up-to-date from when we begin the operation.\n+   * <p>\n    */\n-  public void sync(String path) throws KeeperException {\n-    this.recoverableZooKeeper.sync(path, null, null);\n+  public void syncOrTimeout(String path) throws KeeperException {\n+    final CountDownLatch latch = new CountDownLatch(1);\n+    long startTime = EnvironmentEdgeManager.currentTime();\n+    this.recoverableZooKeeper.sync(path, (i, s, o) -> latch.countDown(), null);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzcxNzk1Ng=="}, "originalCommit": {"oid": "9bde262b066b94877f53066c01b024f14ded5107"}, "originalPosition": 57}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3NzAyNDIyOnYy", "diffSide": "RIGHT", "path": "hbase-zookeeper/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKWatcher.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNVQxNjozNDo1NlrOGpCwSw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNVQxNjozNDo1NlrOGpCwSw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTY4OTkzMQ==", "bodyText": "Yeah, this looks better.", "url": "https://github.com/apache/hbase/pull/1945#discussion_r445689931", "createdAt": "2020-06-25T16:34:56Z", "author": {"login": "virajjasani"}, "path": "hbase-zookeeper/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKWatcher.java", "diffHunk": "@@ -530,10 +539,26 @@ public void process(WatchedEvent event) {\n         break;\n       }\n       default:\n-        throw new IllegalStateException(\"Received event is not valid: \" + event.getState());\n+        LOG.error(\"Invalid event of type {} received for path {}. Ignoring.\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "75846a7e6a11f9a7befe88370efc81f0e1cb7b3b"}, "originalPosition": 89}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3NzA1NzQ3OnYy", "diffSide": "RIGHT", "path": "hbase-zookeeper/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKWatcher.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNVQxNjo0Mzo1NlrOGpDFZg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNVQxNzozMToxNVrOGpExew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTY5NTMzNA==", "bodyText": "keep it private?", "url": "https://github.com/apache/hbase/pull/1945#discussion_r445695334", "createdAt": "2020-06-25T16:43:56Z", "author": {"login": "virajjasani"}, "path": "hbase-zookeeper/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKWatcher.java", "diffHunk": "@@ -479,29 +502,15 @@ public ZNodePaths getZNodePaths() {\n     return znodePaths;\n   }\n \n-  /**\n-   * Method called from ZooKeeper for events and connection status.\n-   * <p>\n-   * Valid events are passed along to listeners.  Connection status changes\n-   * are dealt with locally.\n-   */\n-  @Override\n-  public void process(WatchedEvent event) {\n-    LOG.debug(prefix(\"Received ZooKeeper Event, \" +\n-        \"type=\" + event.getType() + \", \" +\n-        \"state=\" + event.getState() + \", \" +\n-        \"path=\" + event.getPath()));\n-\n+  void processEvent(WatchedEvent event) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "75846a7e6a11f9a7befe88370efc81f0e1cb7b3b"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTcyMzAwMw==", "bodyText": "Done.", "url": "https://github.com/apache/hbase/pull/1945#discussion_r445723003", "createdAt": "2020-06-25T17:31:15Z", "author": {"login": "bharathv"}, "path": "hbase-zookeeper/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKWatcher.java", "diffHunk": "@@ -479,29 +502,15 @@ public ZNodePaths getZNodePaths() {\n     return znodePaths;\n   }\n \n-  /**\n-   * Method called from ZooKeeper for events and connection status.\n-   * <p>\n-   * Valid events are passed along to listeners.  Connection status changes\n-   * are dealt with locally.\n-   */\n-  @Override\n-  public void process(WatchedEvent event) {\n-    LOG.debug(prefix(\"Received ZooKeeper Event, \" +\n-        \"type=\" + event.getType() + \", \" +\n-        \"state=\" + event.getState() + \", \" +\n-        \"path=\" + event.getPath()));\n-\n+  void processEvent(WatchedEvent event) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTY5NTMzNA=="}, "originalCommit": {"oid": "75846a7e6a11f9a7befe88370efc81f0e1cb7b3b"}, "originalPosition": 70}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3NzA3NjEzOnYy", "diffSide": "RIGHT", "path": "hbase-zookeeper/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKWatcher.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNVQxNjo0ODo0M1rOGpDRSw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNVQxODowNTo1M1rOGpF-yg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTY5ODM3OQ==", "bodyText": "Why not use new ThreadFactoryBuilder() and set name format?", "url": "https://github.com/apache/hbase/pull/1945#discussion_r445698379", "createdAt": "2020-06-25T16:48:43Z", "author": {"login": "virajjasani"}, "path": "hbase-zookeeper/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKWatcher.java", "diffHunk": "@@ -79,8 +86,22 @@\n   // listeners to be notified\n   private final List<ZKListener> listeners = new CopyOnWriteArrayList<>();\n \n+  // Single threaded executor pool that processes event notifications from Zookeeper. Events are\n+  // processed in the order in which they arrive (pool backed by an unbounded fifo queue). We do\n+  // this to decouple the event processing from Zookeeper's ClientCnxn's EventThread context.\n+  // EventThread internally runs a single while loop to serially process all the events. When events\n+  // are processed by the listeners in the same thread, that blocks the EventThread from processing\n+  // subsequent events. Processing events in a separate thread frees up the event thread to continue\n+  // and further prevents deadlocks if the process method itself makes other zookeeper calls.\n+  // It is ok to do it in a single thread because the Zookeeper ClientCnxn already serializes the\n+  // requests using a single while loop and hence there is no performance degradation.\n+  private final ExecutorService zkEventProcessor =\n+      Executors.newSingleThreadExecutor(Threads.getNamedThreadFactory(\"zk-event-processor\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "75846a7e6a11f9a7befe88370efc81f0e1cb7b3b"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTcxNTUyMg==", "bodyText": "And also we can keep Threads.getNamedThreadFactory() private(unmodified) with this change", "url": "https://github.com/apache/hbase/pull/1945#discussion_r445715522", "createdAt": "2020-06-25T17:18:09Z", "author": {"login": "virajjasani"}, "path": "hbase-zookeeper/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKWatcher.java", "diffHunk": "@@ -79,8 +86,22 @@\n   // listeners to be notified\n   private final List<ZKListener> listeners = new CopyOnWriteArrayList<>();\n \n+  // Single threaded executor pool that processes event notifications from Zookeeper. Events are\n+  // processed in the order in which they arrive (pool backed by an unbounded fifo queue). We do\n+  // this to decouple the event processing from Zookeeper's ClientCnxn's EventThread context.\n+  // EventThread internally runs a single while loop to serially process all the events. When events\n+  // are processed by the listeners in the same thread, that blocks the EventThread from processing\n+  // subsequent events. Processing events in a separate thread frees up the event thread to continue\n+  // and further prevents deadlocks if the process method itself makes other zookeeper calls.\n+  // It is ok to do it in a single thread because the Zookeeper ClientCnxn already serializes the\n+  // requests using a single while loop and hence there is no performance degradation.\n+  private final ExecutorService zkEventProcessor =\n+      Executors.newSingleThreadExecutor(Threads.getNamedThreadFactory(\"zk-event-processor\"));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTY5ODM3OQ=="}, "originalCommit": {"oid": "75846a7e6a11f9a7befe88370efc81f0e1cb7b3b"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTcyNDM2Ng==", "bodyText": "The reason is ThreadFactoryBuilder is from a third party library (guava). Usually I prefer to reuse the code we already have rather than pulling it from elsewhere. Also, making that util public doesn't matter much I guess, its a static utility anyway.", "url": "https://github.com/apache/hbase/pull/1945#discussion_r445724366", "createdAt": "2020-06-25T17:33:45Z", "author": {"login": "bharathv"}, "path": "hbase-zookeeper/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKWatcher.java", "diffHunk": "@@ -79,8 +86,22 @@\n   // listeners to be notified\n   private final List<ZKListener> listeners = new CopyOnWriteArrayList<>();\n \n+  // Single threaded executor pool that processes event notifications from Zookeeper. Events are\n+  // processed in the order in which they arrive (pool backed by an unbounded fifo queue). We do\n+  // this to decouple the event processing from Zookeeper's ClientCnxn's EventThread context.\n+  // EventThread internally runs a single while loop to serially process all the events. When events\n+  // are processed by the listeners in the same thread, that blocks the EventThread from processing\n+  // subsequent events. Processing events in a separate thread frees up the event thread to continue\n+  // and further prevents deadlocks if the process method itself makes other zookeeper calls.\n+  // It is ok to do it in a single thread because the Zookeeper ClientCnxn already serializes the\n+  // requests using a single while loop and hence there is no performance degradation.\n+  private final ExecutorService zkEventProcessor =\n+      Executors.newSingleThreadExecutor(Threads.getNamedThreadFactory(\"zk-event-processor\"));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTY5ODM3OQ=="}, "originalCommit": {"oid": "75846a7e6a11f9a7befe88370efc81f0e1cb7b3b"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTczNDUwNQ==", "bodyText": "We should definitely avoid dependencies on Guava. Hadoop, HBase, and Phoenix do not stay in sync (Hadoop 3 is up on 21 and that will be painful for the rest!) and Google regularly breaks compatibility among Guava major versions.", "url": "https://github.com/apache/hbase/pull/1945#discussion_r445734505", "createdAt": "2020-06-25T17:51:19Z", "author": {"login": "apurtell"}, "path": "hbase-zookeeper/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKWatcher.java", "diffHunk": "@@ -79,8 +86,22 @@\n   // listeners to be notified\n   private final List<ZKListener> listeners = new CopyOnWriteArrayList<>();\n \n+  // Single threaded executor pool that processes event notifications from Zookeeper. Events are\n+  // processed in the order in which they arrive (pool backed by an unbounded fifo queue). We do\n+  // this to decouple the event processing from Zookeeper's ClientCnxn's EventThread context.\n+  // EventThread internally runs a single while loop to serially process all the events. When events\n+  // are processed by the listeners in the same thread, that blocks the EventThread from processing\n+  // subsequent events. Processing events in a separate thread frees up the event thread to continue\n+  // and further prevents deadlocks if the process method itself makes other zookeeper calls.\n+  // It is ok to do it in a single thread because the Zookeeper ClientCnxn already serializes the\n+  // requests using a single while loop and hence there is no performance degradation.\n+  private final ExecutorService zkEventProcessor =\n+      Executors.newSingleThreadExecutor(Threads.getNamedThreadFactory(\"zk-event-processor\"));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTY5ODM3OQ=="}, "originalCommit": {"oid": "75846a7e6a11f9a7befe88370efc81f0e1cb7b3b"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTc0Mjc5NA==", "bodyText": "Okk that makes sense", "url": "https://github.com/apache/hbase/pull/1945#discussion_r445742794", "createdAt": "2020-06-25T18:05:53Z", "author": {"login": "virajjasani"}, "path": "hbase-zookeeper/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKWatcher.java", "diffHunk": "@@ -79,8 +86,22 @@\n   // listeners to be notified\n   private final List<ZKListener> listeners = new CopyOnWriteArrayList<>();\n \n+  // Single threaded executor pool that processes event notifications from Zookeeper. Events are\n+  // processed in the order in which they arrive (pool backed by an unbounded fifo queue). We do\n+  // this to decouple the event processing from Zookeeper's ClientCnxn's EventThread context.\n+  // EventThread internally runs a single while loop to serially process all the events. When events\n+  // are processed by the listeners in the same thread, that blocks the EventThread from processing\n+  // subsequent events. Processing events in a separate thread frees up the event thread to continue\n+  // and further prevents deadlocks if the process method itself makes other zookeeper calls.\n+  // It is ok to do it in a single thread because the Zookeeper ClientCnxn already serializes the\n+  // requests using a single while loop and hence there is no performance degradation.\n+  private final ExecutorService zkEventProcessor =\n+      Executors.newSingleThreadExecutor(Threads.getNamedThreadFactory(\"zk-event-processor\"));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTY5ODM3OQ=="}, "originalCommit": {"oid": "75846a7e6a11f9a7befe88370efc81f0e1cb7b3b"}, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3NzMwMzYzOnYy", "diffSide": "RIGHT", "path": "hbase-zookeeper/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKWatcher.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNVQxNzo1Mjo1N1rOGpFiEg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNVQxNzo1Mjo1N1rOGpFiEg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTczNTQ0Mg==", "bodyText": "I see, this was at the root of the test failures.", "url": "https://github.com/apache/hbase/pull/1945#discussion_r445735442", "createdAt": "2020-06-25T17:52:57Z", "author": {"login": "apurtell"}, "path": "hbase-zookeeper/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKWatcher.java", "diffHunk": "@@ -79,8 +86,22 @@\n   // listeners to be notified\n   private final List<ZKListener> listeners = new CopyOnWriteArrayList<>();\n \n+  // Single threaded executor pool that processes event notifications from Zookeeper. Events are\n+  // processed in the order in which they arrive (pool backed by an unbounded fifo queue). We do\n+  // this to decouple the event processing from Zookeeper's ClientCnxn's EventThread context.\n+  // EventThread internally runs a single while loop to serially process all the events. When events\n+  // are processed by the listeners in the same thread, that blocks the EventThread from processing\n+  // subsequent events. Processing events in a separate thread frees up the event thread to continue", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "93f268d3c405715a1513154dc0a3da0bd4463540"}, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3NzMwNzY1OnYy", "diffSide": "RIGHT", "path": "hbase-zookeeper/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKWatcher.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNVQxNzo1NDowM1rOGpFkug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNVQxNzo1NDo1MVrOGpFmbQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTczNjEyMg==", "bodyText": "Do we need the lambda here? branch-1....", "url": "https://github.com/apache/hbase/pull/1945#discussion_r445736122", "createdAt": "2020-06-25T17:54:03Z", "author": {"login": "apurtell"}, "path": "hbase-zookeeper/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKWatcher.java", "diffHunk": "@@ -530,10 +539,26 @@ public void process(WatchedEvent event) {\n         break;\n       }\n       default:\n-        throw new IllegalStateException(\"Received event is not valid: \" + event.getState());\n+        LOG.error(\"Invalid event of type {} received for path {}. Ignoring.\",\n+            event.getState(), event.getPath());\n     }\n   }\n \n+  /**\n+   * Method called from ZooKeeper for events and connection status.\n+   * <p>\n+   * Valid events are passed along to listeners.  Connection status changes\n+   * are dealt with locally.\n+   */\n+  @Override\n+  public void process(WatchedEvent event) {\n+    LOG.debug(prefix(\"Received ZooKeeper Event, \" +\n+        \"type=\" + event.getType() + \", \" +\n+        \"state=\" + event.getState() + \", \" +\n+        \"path=\" + event.getPath()));\n+    zkEventProcessor.submit(() -> processEvent(event));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "93f268d3c405715a1513154dc0a3da0bd4463540"}, "originalPosition": 106}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTczNjU1Nw==", "bodyText": "Never mind, as long as it's understood this is a minor pain for backporting.", "url": "https://github.com/apache/hbase/pull/1945#discussion_r445736557", "createdAt": "2020-06-25T17:54:51Z", "author": {"login": "apurtell"}, "path": "hbase-zookeeper/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKWatcher.java", "diffHunk": "@@ -530,10 +539,26 @@ public void process(WatchedEvent event) {\n         break;\n       }\n       default:\n-        throw new IllegalStateException(\"Received event is not valid: \" + event.getState());\n+        LOG.error(\"Invalid event of type {} received for path {}. Ignoring.\",\n+            event.getState(), event.getPath());\n     }\n   }\n \n+  /**\n+   * Method called from ZooKeeper for events and connection status.\n+   * <p>\n+   * Valid events are passed along to listeners.  Connection status changes\n+   * are dealt with locally.\n+   */\n+  @Override\n+  public void process(WatchedEvent event) {\n+    LOG.debug(prefix(\"Received ZooKeeper Event, \" +\n+        \"type=\" + event.getType() + \", \" +\n+        \"state=\" + event.getState() + \", \" +\n+        \"path=\" + event.getPath()));\n+    zkEventProcessor.submit(() -> processEvent(event));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTczNjEyMg=="}, "originalCommit": {"oid": "93f268d3c405715a1513154dc0a3da0bd4463540"}, "originalPosition": 106}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2852, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}