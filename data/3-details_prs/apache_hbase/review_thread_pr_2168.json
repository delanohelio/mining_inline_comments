{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDU4MjQ5MDg5", "number": 2168, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxMDoxMzoxM1rOETMDUQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxMDoxNTowMVrOETMFqg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NTU1ODU3OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxMDoxMzoxM1rOG4x52g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxMTozMzoyN1rOG40XjQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjE5MTA2Ng==", "bodyText": "May be we can replace with that {} method of logging where we have the placeholders?", "url": "https://github.com/apache/hbase/pull/2168#discussion_r462191066", "createdAt": "2020-07-29T10:13:13Z", "author": {"login": "ramkrish86"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java", "diffHunk": "@@ -436,6 +464,19 @@ protected void doShutdown() throws IOException {\n       this.writer.close();\n       this.writer = null;\n     }\n+    closeExecutor.shutdown();\n+    try {\n+      if (!closeExecutor.awaitTermination(waitOnShutdownInSeconds, TimeUnit.SECONDS)) {\n+        LOG.error(\"We have waited \" + waitOnShutdownInSeconds + \" seconds but\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5b6517641c048dfc93fbf6de6b86a34981aed1a6"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjIzMTQzNw==", "bodyText": "done", "url": "https://github.com/apache/hbase/pull/2168#discussion_r462231437", "createdAt": "2020-07-29T11:33:27Z", "author": {"login": "anoopsjohn"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java", "diffHunk": "@@ -436,6 +464,19 @@ protected void doShutdown() throws IOException {\n       this.writer.close();\n       this.writer = null;\n     }\n+    closeExecutor.shutdown();\n+    try {\n+      if (!closeExecutor.awaitTermination(waitOnShutdownInSeconds, TimeUnit.SECONDS)) {\n+        LOG.error(\"We have waited \" + waitOnShutdownInSeconds + \" seconds but\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjE5MTA2Ng=="}, "originalCommit": {"oid": "5b6517641c048dfc93fbf6de6b86a34981aed1a6"}, "originalPosition": 116}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NTU2NDU4OnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxMDoxNTowMVrOG4x9ig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQwNDowMTowOFrOG5SO4Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjE5MjAxMA==", "bodyText": "confirming once again with hasFlushedEntries when syncCloseCall is it mandatory or just to be on the safe side? Because even if hasUnFlushedEntries is false here i think errors would have crossed the limit anyway because we increment and then check it.\nRest LGTM. Can check the QA once. May be you may have to change some cluster based test to run with FSHLog as the default may be AsyncWAL.", "url": "https://github.com/apache/hbase/pull/2168#discussion_r462192010", "createdAt": "2020-07-29T10:15:01Z", "author": {"login": "ramkrish86"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java", "diffHunk": "@@ -412,6 +422,24 @@ protected void doReplaceWriter(Path oldPath, Path newPath, Writer nextWriter) th\n     }\n   }\n \n+  private void closeWriter(Path path, boolean syncCloseCall) throws IOException {\n+    try {\n+      TraceUtil.addTimelineAnnotation(\"closing writer\");\n+      writer.close();\n+      TraceUtil.addTimelineAnnotation(\"writer closed\");\n+    } catch (IOException ioe) {\n+      int errors = closeErrorCount.incrementAndGet();\n+      boolean hasUnflushedEntries = isUnflushedEntries();\n+      if (syncCloseCall && (hasUnflushedEntries || (errors > this.closeErrorsTolerated))) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5b6517641c048dfc93fbf6de6b86a34981aed1a6"}, "originalPosition": 96}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjIxNTI1Mg==", "bodyText": "Ideally when we writer close, there wont be any unflushed entries. We have synced all writes happend to this wal writer.  But as the code was having it and to be on safe side, continue to use that.  Ya in that case will go with sync way of call so that we can act against and IOE in close call.  Same with that errors count. If consecutively those many failures, we will have to throw IOE and RS will abort.  But here one catch is there.  This #errors based abort wont be that strict from now on.  Say if the errors tolerated is 1, we need to throw back IOE if errors count is 2.  But it is possible that one close req came and given to a thread and before that is done another close req and given to another thread and then a 3rd close req came by then 1st thread is done and it was failed. So the 3rd req will be tried in sync way of close. By the time it finishes, the 2nd close thread also failed to close. So the errors already became 2 and 3d  (sync way call) also failed which makes the count to 3.  So instead of throw back IOE at errors=2, it will do now on errors=3.  But we are sure all edits are synced and no data loss. So I believe this is ok.. Asycn wal is not having any such logic at all.", "url": "https://github.com/apache/hbase/pull/2168#discussion_r462215252", "createdAt": "2020-07-29T11:00:25Z", "author": {"login": "anoopsjohn"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java", "diffHunk": "@@ -412,6 +422,24 @@ protected void doReplaceWriter(Path oldPath, Path newPath, Writer nextWriter) th\n     }\n   }\n \n+  private void closeWriter(Path path, boolean syncCloseCall) throws IOException {\n+    try {\n+      TraceUtil.addTimelineAnnotation(\"closing writer\");\n+      writer.close();\n+      TraceUtil.addTimelineAnnotation(\"writer closed\");\n+    } catch (IOException ioe) {\n+      int errors = closeErrorCount.incrementAndGet();\n+      boolean hasUnflushedEntries = isUnflushedEntries();\n+      if (syncCloseCall && (hasUnflushedEntries || (errors > this.closeErrorsTolerated))) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjE5MjAxMA=="}, "originalCommit": {"oid": "5b6517641c048dfc93fbf6de6b86a34981aed1a6"}, "originalPosition": 96}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjcyMDczNw==", "bodyText": "That is right. It is not a harm to check again. Am just saying that since the first sync based close was checking for >= it means either it has already reached the max count or already greater. And next time when we do throw the IOE we check it  after increment. Reg AsyncWAL i just said if tests are running with AsyncWAL this code path may never get executed. So should you go and change the WAL type for test cases to execute this flow?", "url": "https://github.com/apache/hbase/pull/2168#discussion_r462720737", "createdAt": "2020-07-30T04:01:08Z", "author": {"login": "ramkrish86"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java", "diffHunk": "@@ -412,6 +422,24 @@ protected void doReplaceWriter(Path oldPath, Path newPath, Writer nextWriter) th\n     }\n   }\n \n+  private void closeWriter(Path path, boolean syncCloseCall) throws IOException {\n+    try {\n+      TraceUtil.addTimelineAnnotation(\"closing writer\");\n+      writer.close();\n+      TraceUtil.addTimelineAnnotation(\"writer closed\");\n+    } catch (IOException ioe) {\n+      int errors = closeErrorCount.incrementAndGet();\n+      boolean hasUnflushedEntries = isUnflushedEntries();\n+      if (syncCloseCall && (hasUnflushedEntries || (errors > this.closeErrorsTolerated))) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjE5MjAxMA=="}, "originalCommit": {"oid": "5b6517641c048dfc93fbf6de6b86a34981aed1a6"}, "originalPosition": 96}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2722, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}