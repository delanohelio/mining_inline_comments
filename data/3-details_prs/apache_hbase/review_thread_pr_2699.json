{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTI2MjA0NzE2", "number": 2699, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yOFQxMjo1NjozMVrOE-Q6jA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yOFQxMjo1NjozMVrOE-Q6jA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMzNzI0MzAwOnYy", "diffSide": "RIGHT", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileInfo.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yOFQxMjo1NjozMVrOH7Y-3g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwNToxMDozNFrOH8YbGA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjAzNzM0Mg==", "bodyText": "Is it safe to unbuffer the input stream after it is closed?", "url": "https://github.com/apache/hbase/pull/2699#discussion_r532037342", "createdAt": "2020-11-28T12:56:31Z", "author": {"login": "Apache9"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileInfo.java", "diffHunk": "@@ -359,24 +360,32 @@ public void initMetaAndIndex(HFile.Reader reader) throws IOException {\n     // Initialize an block iterator, and parse load-on-open blocks in the following.\n     blockIter = blockReader.blockRange(trailer.getLoadOnOpenDataOffset(),\n         context.getFileSize() - trailer.getTrailerSize());\n-    // Data index. We also read statistics about the block index written after\n-    // the root level.\n-    this.dataIndexReader = new HFileBlockIndex\n-        .CellBasedKeyBlockIndexReader(trailer.createComparator(), trailer.getNumDataIndexLevels());\n-    dataIndexReader.readMultiLevelIndexRoot(blockIter.nextBlockWithBlockType(BlockType.ROOT_INDEX),\n-        trailer.getDataIndexCount());\n-    reader.setDataBlockIndexReader(dataIndexReader);\n-    // Meta index.\n-    this.metaIndexReader = new HFileBlockIndex.ByteArrayKeyBlockIndexReader(1);\n-    metaIndexReader.readRootIndex(blockIter.nextBlockWithBlockType(BlockType.ROOT_INDEX),\n+    try {\n+      // Data index. We also read statistics about the block index written after\n+      // the root level.\n+      this.dataIndexReader =\n+        new HFileBlockIndex.CellBasedKeyBlockIndexReader(trailer.createComparator(), trailer.getNumDataIndexLevels());\n+      dataIndexReader\n+        .readMultiLevelIndexRoot(blockIter.nextBlockWithBlockType(BlockType.ROOT_INDEX), trailer.getDataIndexCount());\n+      reader.setDataBlockIndexReader(dataIndexReader);\n+      // Meta index.\n+      this.metaIndexReader = new HFileBlockIndex.ByteArrayKeyBlockIndexReader(1);\n+      metaIndexReader.readRootIndex(blockIter.nextBlockWithBlockType(BlockType.ROOT_INDEX),\n         trailer.getMetaIndexCount());\n-    reader.setMetaBlockIndexReader(metaIndexReader);\n-    loadMetaInfo(blockIter, hfileContext);\n-    reader.setDataBlockEncoder(HFileDataBlockEncoderImpl.createFromFileInfo(this));\n-    // Load-On-Open info\n-    HFileBlock b;\n-    while ((b = blockIter.nextBlock()) != null) {\n-      loadOnOpenBlocks.add(b);\n+      reader.setMetaBlockIndexReader(metaIndexReader);\n+      loadMetaInfo(blockIter, hfileContext);\n+      reader.setDataBlockEncoder(HFileDataBlockEncoderImpl.createFromFileInfo(this));\n+      // Load-On-Open info\n+      HFileBlock b;\n+      while ((b = blockIter.nextBlock()) != null) {\n+        loadOnOpenBlocks.add(b);\n+      }\n+    } catch (Throwable t) {\n+      IOUtils.closeQuietly(context.getInputStreamWrapper());\n+      throw new CorruptHFileException(\"Problem reading data index and meta index from file \"\n+        + context.getFilePath(), t);\n+    } finally {\n+      context.getInputStreamWrapper().unbuffer();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f3d8072a4326aa34751f362e2e5a650f7edf673a"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjE4MDg2Mw==", "bodyText": "Thanks for reviewing, @Apache9 .\nIOUtils.closeQuietly just calls stream.close(), and does not set stream be null. stream=null is always explicitly called when needed. So I think context.getInputStreamWrapper.unbuffer will not throw NPE here. In unbuffer() method, it closes the bockReader when it is not null. As a result, unbuffer will not throws NPE eighter.\nI have made a UT to create a context and called IOUtils.closeQuietly followed bycontext.getInputStreamWrapper().unbuffer(), no exceptions occurred.\nThe try...cache..finally codes here is the same as those in HFile.createReader.\nIf it seems a little bit not graceful and ugly, adding a check of context.getInputStreamWrapper()!=null may be helpful?", "url": "https://github.com/apache/hbase/pull/2699#discussion_r532180863", "createdAt": "2020-11-29T09:23:27Z", "author": {"login": "sunhelly"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileInfo.java", "diffHunk": "@@ -359,24 +360,32 @@ public void initMetaAndIndex(HFile.Reader reader) throws IOException {\n     // Initialize an block iterator, and parse load-on-open blocks in the following.\n     blockIter = blockReader.blockRange(trailer.getLoadOnOpenDataOffset(),\n         context.getFileSize() - trailer.getTrailerSize());\n-    // Data index. We also read statistics about the block index written after\n-    // the root level.\n-    this.dataIndexReader = new HFileBlockIndex\n-        .CellBasedKeyBlockIndexReader(trailer.createComparator(), trailer.getNumDataIndexLevels());\n-    dataIndexReader.readMultiLevelIndexRoot(blockIter.nextBlockWithBlockType(BlockType.ROOT_INDEX),\n-        trailer.getDataIndexCount());\n-    reader.setDataBlockIndexReader(dataIndexReader);\n-    // Meta index.\n-    this.metaIndexReader = new HFileBlockIndex.ByteArrayKeyBlockIndexReader(1);\n-    metaIndexReader.readRootIndex(blockIter.nextBlockWithBlockType(BlockType.ROOT_INDEX),\n+    try {\n+      // Data index. We also read statistics about the block index written after\n+      // the root level.\n+      this.dataIndexReader =\n+        new HFileBlockIndex.CellBasedKeyBlockIndexReader(trailer.createComparator(), trailer.getNumDataIndexLevels());\n+      dataIndexReader\n+        .readMultiLevelIndexRoot(blockIter.nextBlockWithBlockType(BlockType.ROOT_INDEX), trailer.getDataIndexCount());\n+      reader.setDataBlockIndexReader(dataIndexReader);\n+      // Meta index.\n+      this.metaIndexReader = new HFileBlockIndex.ByteArrayKeyBlockIndexReader(1);\n+      metaIndexReader.readRootIndex(blockIter.nextBlockWithBlockType(BlockType.ROOT_INDEX),\n         trailer.getMetaIndexCount());\n-    reader.setMetaBlockIndexReader(metaIndexReader);\n-    loadMetaInfo(blockIter, hfileContext);\n-    reader.setDataBlockEncoder(HFileDataBlockEncoderImpl.createFromFileInfo(this));\n-    // Load-On-Open info\n-    HFileBlock b;\n-    while ((b = blockIter.nextBlock()) != null) {\n-      loadOnOpenBlocks.add(b);\n+      reader.setMetaBlockIndexReader(metaIndexReader);\n+      loadMetaInfo(blockIter, hfileContext);\n+      reader.setDataBlockEncoder(HFileDataBlockEncoderImpl.createFromFileInfo(this));\n+      // Load-On-Open info\n+      HFileBlock b;\n+      while ((b = blockIter.nextBlock()) != null) {\n+        loadOnOpenBlocks.add(b);\n+      }\n+    } catch (Throwable t) {\n+      IOUtils.closeQuietly(context.getInputStreamWrapper());\n+      throw new CorruptHFileException(\"Problem reading data index and meta index from file \"\n+        + context.getFilePath(), t);\n+    } finally {\n+      context.getInputStreamWrapper().unbuffer();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjAzNzM0Mg=="}, "originalCommit": {"oid": "f3d8072a4326aa34751f362e2e5a650f7edf673a"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzA3Njc2MA==", "bodyText": "I think it might be better to call context.getInputStreamWrapper().unbuffer() before catch sentences.\nAnd because DFSInputStream.close() uses the same logic as unbuffer() to close the blockReader by closeCurrentBlockReaders(), so it need not to call unbuffer() before IOUtils.closeQuietly(). PR has been updated.", "url": "https://github.com/apache/hbase/pull/2699#discussion_r533076760", "createdAt": "2020-12-01T05:10:34Z", "author": {"login": "sunhelly"}, "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileInfo.java", "diffHunk": "@@ -359,24 +360,32 @@ public void initMetaAndIndex(HFile.Reader reader) throws IOException {\n     // Initialize an block iterator, and parse load-on-open blocks in the following.\n     blockIter = blockReader.blockRange(trailer.getLoadOnOpenDataOffset(),\n         context.getFileSize() - trailer.getTrailerSize());\n-    // Data index. We also read statistics about the block index written after\n-    // the root level.\n-    this.dataIndexReader = new HFileBlockIndex\n-        .CellBasedKeyBlockIndexReader(trailer.createComparator(), trailer.getNumDataIndexLevels());\n-    dataIndexReader.readMultiLevelIndexRoot(blockIter.nextBlockWithBlockType(BlockType.ROOT_INDEX),\n-        trailer.getDataIndexCount());\n-    reader.setDataBlockIndexReader(dataIndexReader);\n-    // Meta index.\n-    this.metaIndexReader = new HFileBlockIndex.ByteArrayKeyBlockIndexReader(1);\n-    metaIndexReader.readRootIndex(blockIter.nextBlockWithBlockType(BlockType.ROOT_INDEX),\n+    try {\n+      // Data index. We also read statistics about the block index written after\n+      // the root level.\n+      this.dataIndexReader =\n+        new HFileBlockIndex.CellBasedKeyBlockIndexReader(trailer.createComparator(), trailer.getNumDataIndexLevels());\n+      dataIndexReader\n+        .readMultiLevelIndexRoot(blockIter.nextBlockWithBlockType(BlockType.ROOT_INDEX), trailer.getDataIndexCount());\n+      reader.setDataBlockIndexReader(dataIndexReader);\n+      // Meta index.\n+      this.metaIndexReader = new HFileBlockIndex.ByteArrayKeyBlockIndexReader(1);\n+      metaIndexReader.readRootIndex(blockIter.nextBlockWithBlockType(BlockType.ROOT_INDEX),\n         trailer.getMetaIndexCount());\n-    reader.setMetaBlockIndexReader(metaIndexReader);\n-    loadMetaInfo(blockIter, hfileContext);\n-    reader.setDataBlockEncoder(HFileDataBlockEncoderImpl.createFromFileInfo(this));\n-    // Load-On-Open info\n-    HFileBlock b;\n-    while ((b = blockIter.nextBlock()) != null) {\n-      loadOnOpenBlocks.add(b);\n+      reader.setMetaBlockIndexReader(metaIndexReader);\n+      loadMetaInfo(blockIter, hfileContext);\n+      reader.setDataBlockEncoder(HFileDataBlockEncoderImpl.createFromFileInfo(this));\n+      // Load-On-Open info\n+      HFileBlock b;\n+      while ((b = blockIter.nextBlock()) != null) {\n+        loadOnOpenBlocks.add(b);\n+      }\n+    } catch (Throwable t) {\n+      IOUtils.closeQuietly(context.getInputStreamWrapper());\n+      throw new CorruptHFileException(\"Problem reading data index and meta index from file \"\n+        + context.getFilePath(), t);\n+    } finally {\n+      context.getInputStreamWrapper().unbuffer();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjAzNzM0Mg=="}, "originalCommit": {"oid": "f3d8072a4326aa34751f362e2e5a650f7edf673a"}, "originalPosition": 59}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2298, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}