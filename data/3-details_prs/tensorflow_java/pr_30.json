{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg0NjI3MTUx", "number": 30, "title": "TF Data API for Java", "bodyText": "Here's an implementation of the proposed Tensorflow Data API for TF Java described in this RFC. As the RFC discussion continues I'll update this PR to match! Would love to hear comments / suggestions!", "createdAt": "2020-03-06T04:24:20Z", "url": "https://github.com/tensorflow/java/pull/30", "merged": true, "mergeCommit": {"oid": "0f0ff7d10fafe2c42ea4768ec13ab5a169da1ce5"}, "closed": true, "closedAt": "2020-04-30T22:05:41Z", "author": {"login": "dhruvrajan"}, "timelineItems": {"totalCount": 121, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABccaf9UAH2gAyMzg0NjI3MTUxOmZjYTczZmYxMjljYTY3YTlmOTIwYmFjNjRiNWU5ZTM0MzAxYzRlMDg=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcc0eCXAFqTQwMzkwOTA2Ng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "fca73ff129ca67a9f920bac64b5e9e34301c4e08", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/fca73ff129ca67a9f920bac64b5e9e34301c4e08", "committedDate": "2020-04-29T15:48:24Z", "message": "TensorFlow Data examples with batching working in graph / eager mode"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bb6cec22afd48c8ab7f84175d26b7b3f6d424fcc", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/bb6cec22afd48c8ab7f84175d26b7b3f6d424fcc", "committedDate": "2020-04-29T15:49:02Z", "message": "Add repeat() method to Session"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4ebbaf2a6ac28636e82b1253d564bd4b9af7184d", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/4ebbaf2a6ac28636e82b1253d564bd4b9af7184d", "committedDate": "2020-04-29T15:49:02Z", "message": "update readme with stream dataset iteration"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "23f6ba3b4d95e1aca7e32a08d93b20a89d2711a9", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/23f6ba3b4d95e1aca7e32a08d93b20a89d2711a9", "committedDate": "2020-04-29T15:49:02Z", "message": "Merge optimizers and datasets into tensorflow-framework"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d3d8d482325f8a0af17ece4722c4564caf74ba06", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/d3d8d482325f8a0af17ece4722c4564caf74ba06", "committedDate": "2020-04-29T15:49:03Z", "message": "Add TensorFlow Exceptions, map to these from TF Statuses in tensorflow-core"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b9683c63d3afd6ce8aefc545fb09ff0242190953", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/b9683c63d3afd6ce8aefc545fb09ff0242190953", "committedDate": "2020-04-29T15:49:03Z", "message": "Fix tests to use new exceptions from tensorflow-core"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e4afc6868f8afd3c03a2dd641206290c33f79ba3", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/e4afc6868f8afd3c03a2dd641206290c33f79ba3", "committedDate": "2020-04-29T15:49:03Z", "message": "revert tensorflow-data readme"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "70af76874119ffa5560aedd234d4a267b657d226", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/70af76874119ffa5560aedd234d4a267b657d226", "committedDate": "2020-04-29T15:49:03Z", "message": "Update tensorflow-data.md"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "104b81b1e9503c80199510df8dfe6c52b2d8aa51", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/104b81b1e9503c80199510df8dfe6c52b2d8aa51", "committedDate": "2020-04-29T15:49:03Z", "message": "Update tensorflow-data.md"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "14288add601db18f2f99b65eba5f004fffc99c3b", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/14288add601db18f2f99b65eba5f004fffc99c3b", "committedDate": "2020-04-29T15:49:20Z", "message": ":wqremove unnecessary files, add copyrights, format with google java style, update documentation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "17cfcf46649ba1826205933bf27b6c6f82c5ab38", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/17cfcf46649ba1826205933bf27b6c6f82c5ab38", "committedDate": "2020-04-29T15:49:20Z", "message": "Convert batches from List<Output<?>> to List<Operand<?>>"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a7d4d0e992c6ff0525f2cada08d34cd4b20d3cdc", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/a7d4d0e992c6ff0525f2cada08d34cd4b20d3cdc", "committedDate": "2020-04-27T15:23:48Z", "message": "Convert batches from List<Output<?>> to List<Operand<?>>"}, "afterCommit": {"oid": "8f6cfeff5f522465dbb9e23a63e242850737000a", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/8f6cfeff5f522465dbb9e23a63e242850737000a", "committedDate": "2020-04-29T16:12:12Z", "message": "Fix copyright authors, add Shape.prepend(), fix pom.xml, revert Session"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "69f921d6c90b128a7790dc3860ec95551dbfeb51", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/69f921d6c90b128a7790dc3860ec95551dbfeb51", "committedDate": "2020-04-29T17:16:24Z", "message": "Fix copyright authors, add Shape.prepend(), fix pom.xml, revert Session"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8f6cfeff5f522465dbb9e23a63e242850737000a", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/8f6cfeff5f522465dbb9e23a63e242850737000a", "committedDate": "2020-04-29T16:12:12Z", "message": "Fix copyright authors, add Shape.prepend(), fix pom.xml, revert Session"}, "afterCommit": {"oid": "69f921d6c90b128a7790dc3860ec95551dbfeb51", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/69f921d6c90b128a7790dc3860ec95551dbfeb51", "committedDate": "2020-04-29T17:16:24Z", "message": "Fix copyright authors, add Shape.prepend(), fix pom.xml, revert Session"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "eb61e2fcb3fb2d8f282d7f00885bed2db8fac6e0", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/eb61e2fcb3fb2d8f282d7f00885bed2db8fac6e0", "committedDate": "2020-04-29T17:33:27Z", "message": "remove * imports from session"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "28add779d43b5bf641bc6b7a87bcdc544dcddd4f", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/28add779d43b5bf641bc6b7a87bcdc544dcddd4f", "committedDate": "2020-04-30T21:36:22Z", "message": "extend from java.lang exceptions"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAzOTA5MDY2", "url": "https://github.com/tensorflow/java/pull/30#pullrequestreview-403909066", "createdAt": "2020-04-30T22:03:50Z", "commit": {"oid": "28add779d43b5bf641bc6b7a87bcdc544dcddd4f"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcyNDE4MjMz", "url": "https://github.com/tensorflow/java/pull/30#pullrequestreview-372418233", "createdAt": "2020-03-11T01:08:50Z", "commit": {"oid": "a69cfd9d8117fe6158a25e23133364b3b59b29ce"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 29, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQwMTowODo1MVrOF0mJ4w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQwMjo0MjowOFrOF0nfag==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDY5NTM5NQ==", "bodyText": "Maybe \"... cast from output of .... to output of.... \"?", "url": "https://github.com/tensorflow/java/pull/30#discussion_r390695395", "createdAt": "2020-03-11T01:08:51Z", "author": {"login": "karllessard"}, "path": "tensorflow-core/tensorflow-core-api/src/main/java/org/tensorflow/Output.java", "diffHunk": "@@ -52,6 +52,24 @@ public Shape shape() {\n     return (DataType<T>)operation.dtype(index);\n   }\n \n+    /**\n+   * Returns this Output object with the type {@code Output<U>}. This method is useful when given a\n+   * value of type {@code Output<?>}.\n+   *\n+   * @param dt any supported tensor data type\n+   * @throws IllegalArgumentException if the actual data type of this object does not match the type\n+   *     {@code U}.\n+   */\n+  @SuppressWarnings(\"unchecked\")\n+  public <U extends TType> Output<U> expect(DataType<U> dt) {\n+    if (!dt.equals(this.dataType())) {\n+      throw new IllegalArgumentException(\n+          \"Cannot cast from tensor of \" + this.dataType() + \" to tensor of \" + dt);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a69cfd9d8117fe6158a25e23133364b3b59b29ce"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDY5NTk1Ng==", "bodyText": "I think datasets are mostly used for training, aren't they? If so, then they might fit well as part of the tensorflow-training artifact, aside with the new optimizers?", "url": "https://github.com/tensorflow/java/pull/30#discussion_r390695956", "createdAt": "2020-03-11T01:11:22Z", "author": {"login": "karllessard"}, "path": "pom.xml", "diffHunk": "@@ -32,6 +32,7 @@\n     <module>tensorflow-tools</module>\n     <module>tensorflow-core</module>\n     <module>tensorflow-training</module>\n+    <module>tensorflow-frameworks</module>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a69cfd9d8117fe6158a25e23133364b3b59b29ce"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDY5NzE2Mw==", "bodyText": "Recommended usage would be to use NdArrays here, as using standard arrays requires an extra copy. It's ok for small constants like this but since tensors used in training in a real scenario can be significantly larger, maybe the example here should show how to handle these correctly.", "url": "https://github.com/tensorflow/java/pull/30#discussion_r390697163", "createdAt": "2020-03-11T01:16:30Z", "author": {"login": "karllessard"}, "path": "tensorflow-frameworks/tensorflow-data/README.md", "diffHunk": "@@ -0,0 +1,93 @@\n+Tensorflow-Data (Java)\n+==\n+\n+TensorFlow Data provides simple APIs for loading data of various formats, and preparing\n+datasets for use in training and using deep learning models.\n+\n+TensorFlow Java's implementation simplifies the use of the C++ `data` ops, and provides\n+a simple API for configuring and iterating over datasets in both \"graph\" and \"eager\" mode.\n+\n+Usage\n+--\n+\n+The `Dataset` abstraction represents a sequence of elements, where each element in the sequence is a collection (`List`) of tensors (or, \"components\").\n+\n+\n+Creation\n+-\n+A dataset can be constructed from a list of constant tensors\n+using `Dataset.fromTensorSlices( ... )` as follows:\n+\n+```java\n+// Declare dataset components as arrays.\n+// NOTE: All components in a dataset must share the first \"batch\" dimension.\n+\n+int[][] m1 = new int[][]{\n+        {1, 2, 3, 4, 5},\n+        {2, 4, 6, 8, 10},\n+        {3, 6, 8, 12, 15},\n+        {4, 8, 12, 16, 20}\n+    };\n+\n+int[][] m2 = new int[][]{\n+    {1}, {0}, {1}, {1}\n+};", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a69cfd9d8117fe6158a25e23133364b3b59b29ce"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDY5ODI3NQ==", "bodyText": "I guess this makeIterator op can be added to the list of graph initializers?", "url": "https://github.com/tensorflow/java/pull/30#discussion_r390698275", "createdAt": "2020-03-11T01:21:19Z", "author": {"login": "karllessard"}, "path": "tensorflow-frameworks/tensorflow-data/README.md", "diffHunk": "@@ -0,0 +1,93 @@\n+Tensorflow-Data (Java)\n+==\n+\n+TensorFlow Data provides simple APIs for loading data of various formats, and preparing\n+datasets for use in training and using deep learning models.\n+\n+TensorFlow Java's implementation simplifies the use of the C++ `data` ops, and provides\n+a simple API for configuring and iterating over datasets in both \"graph\" and \"eager\" mode.\n+\n+Usage\n+--\n+\n+The `Dataset` abstraction represents a sequence of elements, where each element in the sequence is a collection (`List`) of tensors (or, \"components\").\n+\n+\n+Creation\n+-\n+A dataset can be constructed from a list of constant tensors\n+using `Dataset.fromTensorSlices( ... )` as follows:\n+\n+```java\n+// Declare dataset components as arrays.\n+// NOTE: All components in a dataset must share the first \"batch\" dimension.\n+\n+int[][] m1 = new int[][]{\n+        {1, 2, 3, 4, 5},\n+        {2, 4, 6, 8, 10},\n+        {3, 6, 8, 12, 15},\n+        {4, 8, 12, 16, 20}\n+    };\n+\n+int[][] m2 = new int[][]{\n+    {1}, {0}, {1}, {1}\n+};\n+\n+\n+Ops tf = // ... TensorFlow Ops Accessor (either graph or eager).\n+\n+// Construct dataset with two components, batchSize=2.\n+Dataset dataset = Dataset.fromTensorSlices(tf,\n+    // List of array components\n+    Arrays.asList(tf.constant(m1), tf.constant(m2)),\n+    // List of each component's dtype\n+    Arrays.asList(TInt32.DTYPE, TInt32.DTYPE)\n+)\n+```\n+\n+Iteration\n+--\n+\n+In eager mode, the dataset can be iterated through using a standard \n+\"for-each\" loop, to receive the tensor values of each component:\n+\n+```java\n+int BATCH_SIZE = 2;\n+for (List<Output<?>> components : dataset.batch(BATCH_SIZE)) {\n+      Tensor<TInt32> XBatch = components.get(0).tensor().expect(TInt32.DTYPE);\n+      Tensor<TInt32> yBatch = components.get(1).tensor().expect(TInt32.DTYPE);\n+      \n+      // ... use batch tensors\n+}\n+```\n+\n+In graph mode, the dataset can be iterated through using the `OneShotIterator` abstraction, and a while loop, as follows:\n+\n+```java\n+OneShotIterator oneShotIterator = dataset.makeOneShotIterator();\n+Operation makeIterator = oneShotIterator.getMakeIteratorOp();\n+List<Output<?>> components = oneShotIterator.getComponents();\n+\n+try (Session session = new Session(graph)) {\n+    // Run MakeIterator Op to set iterator position\n+    session.runner()\n+        .addTarget(makeIterator)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a69cfd9d8117fe6158a25e23133364b3b59b29ce"}, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDY5ODc2MA==", "bodyText": "These tensors need to be closed as well", "url": "https://github.com/tensorflow/java/pull/30#discussion_r390698760", "createdAt": "2020-03-11T01:23:20Z", "author": {"login": "karllessard"}, "path": "tensorflow-frameworks/tensorflow-data/README.md", "diffHunk": "@@ -0,0 +1,93 @@\n+Tensorflow-Data (Java)\n+==\n+\n+TensorFlow Data provides simple APIs for loading data of various formats, and preparing\n+datasets for use in training and using deep learning models.\n+\n+TensorFlow Java's implementation simplifies the use of the C++ `data` ops, and provides\n+a simple API for configuring and iterating over datasets in both \"graph\" and \"eager\" mode.\n+\n+Usage\n+--\n+\n+The `Dataset` abstraction represents a sequence of elements, where each element in the sequence is a collection (`List`) of tensors (or, \"components\").\n+\n+\n+Creation\n+-\n+A dataset can be constructed from a list of constant tensors\n+using `Dataset.fromTensorSlices( ... )` as follows:\n+\n+```java\n+// Declare dataset components as arrays.\n+// NOTE: All components in a dataset must share the first \"batch\" dimension.\n+\n+int[][] m1 = new int[][]{\n+        {1, 2, 3, 4, 5},\n+        {2, 4, 6, 8, 10},\n+        {3, 6, 8, 12, 15},\n+        {4, 8, 12, 16, 20}\n+    };\n+\n+int[][] m2 = new int[][]{\n+    {1}, {0}, {1}, {1}\n+};\n+\n+\n+Ops tf = // ... TensorFlow Ops Accessor (either graph or eager).\n+\n+// Construct dataset with two components, batchSize=2.\n+Dataset dataset = Dataset.fromTensorSlices(tf,\n+    // List of array components\n+    Arrays.asList(tf.constant(m1), tf.constant(m2)),\n+    // List of each component's dtype\n+    Arrays.asList(TInt32.DTYPE, TInt32.DTYPE)\n+)\n+```\n+\n+Iteration\n+--\n+\n+In eager mode, the dataset can be iterated through using a standard \n+\"for-each\" loop, to receive the tensor values of each component:\n+\n+```java\n+int BATCH_SIZE = 2;\n+for (List<Output<?>> components : dataset.batch(BATCH_SIZE)) {\n+      Tensor<TInt32> XBatch = components.get(0).tensor().expect(TInt32.DTYPE);\n+      Tensor<TInt32> yBatch = components.get(1).tensor().expect(TInt32.DTYPE);\n+      \n+      // ... use batch tensors\n+}\n+```\n+\n+In graph mode, the dataset can be iterated through using the `OneShotIterator` abstraction, and a while loop, as follows:\n+\n+```java\n+OneShotIterator oneShotIterator = dataset.makeOneShotIterator();\n+Operation makeIterator = oneShotIterator.getMakeIteratorOp();\n+List<Output<?>> components = oneShotIterator.getComponents();\n+\n+try (Session session = new Session(graph)) {\n+    // Run MakeIterator Op to set iterator position\n+    session.runner()\n+        .addTarget(makeIterator)\n+        .run();\n+    \n+    while (true) {\n+        try {\n+            List<Tensor<?>> outputs = session.runner()\n+                .fetch(components.get(0))\n+                .fetch(components.get(1))\n+                .run();\n+\n+            Tensor<TInt32> matrix1 = outputs.get(0).expect(TInt32.DTYPE);\n+            Tensor<TInt32> matrix2 = outputs.get(1).expect(TInt32.DTYPE);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a69cfd9d8117fe6158a25e23133364b3b59b29ce"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDY5OTEzMQ==", "bodyText": "It is preferable to close tensors returned by Output.tensor() to avoid potential memory leaks.", "url": "https://github.com/tensorflow/java/pull/30#discussion_r390699131", "createdAt": "2020-03-11T01:24:59Z", "author": {"login": "karllessard"}, "path": "tensorflow-frameworks/tensorflow-data/README.md", "diffHunk": "@@ -0,0 +1,93 @@\n+Tensorflow-Data (Java)\n+==\n+\n+TensorFlow Data provides simple APIs for loading data of various formats, and preparing\n+datasets for use in training and using deep learning models.\n+\n+TensorFlow Java's implementation simplifies the use of the C++ `data` ops, and provides\n+a simple API for configuring and iterating over datasets in both \"graph\" and \"eager\" mode.\n+\n+Usage\n+--\n+\n+The `Dataset` abstraction represents a sequence of elements, where each element in the sequence is a collection (`List`) of tensors (or, \"components\").\n+\n+\n+Creation\n+-\n+A dataset can be constructed from a list of constant tensors\n+using `Dataset.fromTensorSlices( ... )` as follows:\n+\n+```java\n+// Declare dataset components as arrays.\n+// NOTE: All components in a dataset must share the first \"batch\" dimension.\n+\n+int[][] m1 = new int[][]{\n+        {1, 2, 3, 4, 5},\n+        {2, 4, 6, 8, 10},\n+        {3, 6, 8, 12, 15},\n+        {4, 8, 12, 16, 20}\n+    };\n+\n+int[][] m2 = new int[][]{\n+    {1}, {0}, {1}, {1}\n+};\n+\n+\n+Ops tf = // ... TensorFlow Ops Accessor (either graph or eager).\n+\n+// Construct dataset with two components, batchSize=2.\n+Dataset dataset = Dataset.fromTensorSlices(tf,\n+    // List of array components\n+    Arrays.asList(tf.constant(m1), tf.constant(m2)),\n+    // List of each component's dtype\n+    Arrays.asList(TInt32.DTYPE, TInt32.DTYPE)\n+)\n+```\n+\n+Iteration\n+--\n+\n+In eager mode, the dataset can be iterated through using a standard \n+\"for-each\" loop, to receive the tensor values of each component:\n+\n+```java\n+int BATCH_SIZE = 2;\n+for (List<Output<?>> components : dataset.batch(BATCH_SIZE)) {\n+      Tensor<TInt32> XBatch = components.get(0).tensor().expect(TInt32.DTYPE);\n+      Tensor<TInt32> yBatch = components.get(1).tensor().expect(TInt32.DTYPE);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a69cfd9d8117fe6158a25e23133364b3b59b29ce"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDY5OTI5Ng==", "bodyText": "So the exception is part of the normal logic flow? Any way to avoid this?", "url": "https://github.com/tensorflow/java/pull/30#discussion_r390699296", "createdAt": "2020-03-11T01:25:48Z", "author": {"login": "karllessard"}, "path": "tensorflow-frameworks/tensorflow-data/README.md", "diffHunk": "@@ -0,0 +1,93 @@\n+Tensorflow-Data (Java)\n+==\n+\n+TensorFlow Data provides simple APIs for loading data of various formats, and preparing\n+datasets for use in training and using deep learning models.\n+\n+TensorFlow Java's implementation simplifies the use of the C++ `data` ops, and provides\n+a simple API for configuring and iterating over datasets in both \"graph\" and \"eager\" mode.\n+\n+Usage\n+--\n+\n+The `Dataset` abstraction represents a sequence of elements, where each element in the sequence is a collection (`List`) of tensors (or, \"components\").\n+\n+\n+Creation\n+-\n+A dataset can be constructed from a list of constant tensors\n+using `Dataset.fromTensorSlices( ... )` as follows:\n+\n+```java\n+// Declare dataset components as arrays.\n+// NOTE: All components in a dataset must share the first \"batch\" dimension.\n+\n+int[][] m1 = new int[][]{\n+        {1, 2, 3, 4, 5},\n+        {2, 4, 6, 8, 10},\n+        {3, 6, 8, 12, 15},\n+        {4, 8, 12, 16, 20}\n+    };\n+\n+int[][] m2 = new int[][]{\n+    {1}, {0}, {1}, {1}\n+};\n+\n+\n+Ops tf = // ... TensorFlow Ops Accessor (either graph or eager).\n+\n+// Construct dataset with two components, batchSize=2.\n+Dataset dataset = Dataset.fromTensorSlices(tf,\n+    // List of array components\n+    Arrays.asList(tf.constant(m1), tf.constant(m2)),\n+    // List of each component's dtype\n+    Arrays.asList(TInt32.DTYPE, TInt32.DTYPE)\n+)\n+```\n+\n+Iteration\n+--\n+\n+In eager mode, the dataset can be iterated through using a standard \n+\"for-each\" loop, to receive the tensor values of each component:\n+\n+```java\n+int BATCH_SIZE = 2;\n+for (List<Output<?>> components : dataset.batch(BATCH_SIZE)) {\n+      Tensor<TInt32> XBatch = components.get(0).tensor().expect(TInt32.DTYPE);\n+      Tensor<TInt32> yBatch = components.get(1).tensor().expect(TInt32.DTYPE);\n+      \n+      // ... use batch tensors\n+}\n+```\n+\n+In graph mode, the dataset can be iterated through using the `OneShotIterator` abstraction, and a while loop, as follows:\n+\n+```java\n+OneShotIterator oneShotIterator = dataset.makeOneShotIterator();\n+Operation makeIterator = oneShotIterator.getMakeIteratorOp();\n+List<Output<?>> components = oneShotIterator.getComponents();\n+\n+try (Session session = new Session(graph)) {\n+    // Run MakeIterator Op to set iterator position\n+    session.runner()\n+        .addTarget(makeIterator)\n+        .run();\n+    \n+    while (true) {\n+        try {\n+            List<Tensor<?>> outputs = session.runner()\n+                .fetch(components.get(0))\n+                .fetch(components.get(1))\n+                .run();\n+\n+            Tensor<TInt32> matrix1 = outputs.get(0).expect(TInt32.DTYPE);\n+            Tensor<TInt32> matrix2 = outputs.get(1).expect(TInt32.DTYPE);\n+\n+        } catch (IndexOutOfBoundsException e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a69cfd9d8117fe6158a25e23133364b3b59b29ce"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDcwMDk5OA==", "bodyText": "Google Java Style Guide doesn't recommend the usage of wildcard imports (I personally think it is fine for static imports though)", "url": "https://github.com/tensorflow/java/pull/30#discussion_r390700998", "createdAt": "2020-03-11T01:33:11Z", "author": {"login": "karllessard"}, "path": "tensorflow-frameworks/tensorflow-data/src/main/java/org/tensorflow/data/Dataset.java", "diffHunk": "@@ -0,0 +1,180 @@\n+package org.tensorflow.data;\r\n+\r\n+import org.tensorflow.*;\r\n+import org.tensorflow.data.impl.*;\r", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a69cfd9d8117fe6158a25e23133364b3b59b29ce"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDcwMTE5OA==", "bodyText": "no need of else if you throw in the previous block", "url": "https://github.com/tensorflow/java/pull/30#discussion_r390701198", "createdAt": "2020-03-11T01:34:05Z", "author": {"login": "karllessard"}, "path": "tensorflow-frameworks/tensorflow-data/src/main/java/org/tensorflow/data/Dataset.java", "diffHunk": "@@ -0,0 +1,180 @@\n+package org.tensorflow.data;\r\n+\r\n+import org.tensorflow.*;\r\n+import org.tensorflow.data.impl.*;\r\n+import org.tensorflow.op.Ops;\r\n+import org.tensorflow.op.data.AnonymousIterator;\r\n+import org.tensorflow.op.data.MakeIterator;\r\n+import org.tensorflow.tools.Shape;\r\n+import org.tensorflow.utils.Tuple2;\r\n+\r\n+import java.util.Iterator;\r\n+import java.util.List;\r\n+import java.util.Objects;\r\n+import java.util.stream.Collectors;\r\n+\r\n+/**\r\n+ * Represents a potentially large list of independent elements (samples), and\r\n+ * allows iteration and transformations to be performed across these elements.\r\n+ */\r\n+public abstract class Dataset implements Iterable<List<Output<?>>> {\r\n+  protected Ops tf;\r\n+  private List<DataType<?>> outputTypes;\r\n+  private List<Shape> outputShapes;\r\n+\r\n+  public Dataset(Ops tf, List<DataType<?>> outputTypes, List<Shape> outputShapes) {\r\n+    if (Objects.isNull(tf)) {\r\n+      throw new IllegalArgumentException(\"Ops accessor cannot be null.\");\r\n+    } else if (outputTypes.size() != outputShapes.size()) {\r", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a69cfd9d8117fe6158a25e23133364b3b59b29ce"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDcwMTQ4MA==", "bodyText": "Are there benefits to use Objects.isNull if it is not as a filter predicate, instead of just tf == null?", "url": "https://github.com/tensorflow/java/pull/30#discussion_r390701480", "createdAt": "2020-03-11T01:35:34Z", "author": {"login": "karllessard"}, "path": "tensorflow-frameworks/tensorflow-data/src/main/java/org/tensorflow/data/Dataset.java", "diffHunk": "@@ -0,0 +1,180 @@\n+package org.tensorflow.data;\r\n+\r\n+import org.tensorflow.*;\r\n+import org.tensorflow.data.impl.*;\r\n+import org.tensorflow.op.Ops;\r\n+import org.tensorflow.op.data.AnonymousIterator;\r\n+import org.tensorflow.op.data.MakeIterator;\r\n+import org.tensorflow.tools.Shape;\r\n+import org.tensorflow.utils.Tuple2;\r\n+\r\n+import java.util.Iterator;\r\n+import java.util.List;\r\n+import java.util.Objects;\r\n+import java.util.stream.Collectors;\r\n+\r\n+/**\r\n+ * Represents a potentially large list of independent elements (samples), and\r\n+ * allows iteration and transformations to be performed across these elements.\r\n+ */\r\n+public abstract class Dataset implements Iterable<List<Output<?>>> {\r\n+  protected Ops tf;\r\n+  private List<DataType<?>> outputTypes;\r\n+  private List<Shape> outputShapes;\r\n+\r\n+  public Dataset(Ops tf, List<DataType<?>> outputTypes, List<Shape> outputShapes) {\r\n+    if (Objects.isNull(tf)) {\r", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a69cfd9d8117fe6158a25e23133364b3b59b29ce"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDcwNTUxMw==", "bodyText": "Maybe we could add a isEager() method in ExecutionEnvironment to avoid these instanceof", "url": "https://github.com/tensorflow/java/pull/30#discussion_r390705513", "createdAt": "2020-03-11T01:53:03Z", "author": {"login": "karllessard"}, "path": "tensorflow-frameworks/tensorflow-data/src/main/java/org/tensorflow/data/Dataset.java", "diffHunk": "@@ -0,0 +1,180 @@\n+package org.tensorflow.data;\r\n+\r\n+import org.tensorflow.*;\r\n+import org.tensorflow.data.impl.*;\r\n+import org.tensorflow.op.Ops;\r\n+import org.tensorflow.op.data.AnonymousIterator;\r\n+import org.tensorflow.op.data.MakeIterator;\r\n+import org.tensorflow.tools.Shape;\r\n+import org.tensorflow.utils.Tuple2;\r\n+\r\n+import java.util.Iterator;\r\n+import java.util.List;\r\n+import java.util.Objects;\r\n+import java.util.stream.Collectors;\r\n+\r\n+/**\r\n+ * Represents a potentially large list of independent elements (samples), and\r\n+ * allows iteration and transformations to be performed across these elements.\r\n+ */\r\n+public abstract class Dataset implements Iterable<List<Output<?>>> {\r\n+  protected Ops tf;\r\n+  private List<DataType<?>> outputTypes;\r\n+  private List<Shape> outputShapes;\r\n+\r\n+  public Dataset(Ops tf, List<DataType<?>> outputTypes, List<Shape> outputShapes) {\r\n+    if (Objects.isNull(tf)) {\r\n+      throw new IllegalArgumentException(\"Ops accessor cannot be null.\");\r\n+    } else if (outputTypes.size() != outputShapes.size()) {\r\n+      throw new IllegalArgumentException(\"`outputTypes` and `outputShapes` must have the same size.\");\r\n+    }\r\n+\r\n+    this.tf = tf;\r\n+    this.outputTypes = outputTypes;\r\n+    this.outputShapes = outputShapes;\r\n+  }\r\n+\r\n+  /**\r\n+   * Groups elements of this dataset into batches.\r\n+   *\r\n+   * @param batchSize     The number of desired elements per batch\r\n+   * @param dropLastBatch Whether to leave out the final batch if it has fewer\r\n+   *                      than `batchSize` elements.\r\n+   * @return A batched Dataset\r\n+   */\r\n+  public final Dataset batch(long batchSize, boolean dropLastBatch) {\r\n+    List<Shape> batchOutputShapes = getOutputShapes().stream()\r\n+        .map(s -> Shape.of(Utils.array(batchSize, s.asArray())))\r\n+        .collect(Collectors.toList());\r\n+    return new BatchDataset(tf, this.getVariant(), tf.val(batchSize),\r\n+        tf.val(dropLastBatch), this.getOutputTypes(), batchOutputShapes);\r\n+  }\r\n+\r\n+  /**\r\n+   * Groups elements of this dataset into batches.\r\n+   * Leaves out the last batch if it has fewer than `batchSize` elements.\r\n+   *\r\n+   * @param batchSize The number of desired elements per batch\r\n+   * @return A batched Dataset\r\n+   */\r\n+  public final Dataset batch(long batchSize) {\r\n+    return batch(batchSize, true);\r\n+  }\r\n+\r\n+  /**\r\n+   * Creates new `Dataset` skips `count` initial elements from this dataset\r\n+   *\r\n+   * @param count The number of elements to `skip` to form the new dataset.\r\n+   * @return A new Dataset with `count` elements removed.\r\n+   */\r\n+  public final Dataset skip(long count) {\r\n+    return new SkipDataset(tf, this.getVariant(), tf.val(count), this.getOutputTypes(), this.getOutputShapes());\r\n+  }\r\n+\r\n+  /**\r\n+   * Creates new `Dataset` with the first `count` elements from this dataset.\r\n+   *\r\n+   * @param count The number of elements to \"take\" from this dataset.\r\n+   * @return A new Dataset containing the first `count` elements from this dataset.\r\n+   */\r\n+  public final Dataset take(long count) {\r\n+    return new TakeDataset(tf, this.getVariant(), tf.val(count), this.getOutputTypes(), this.getOutputShapes());\r\n+  }\r\n+\r\n+  /**\r\n+   * Creates an iterator which iterates through all batches of this Dataset in an eager fashion.\r\n+   * Each batch is a list of components, returned as `Output` objects.\r\n+   * <p>\r\n+   * This method enables for-each iteration through batches when running\r\n+   * in eager mode. For Graph mode batch iteration, see `makeOneShotIterator`.\r\n+   *\r\n+   * @return an Iterator through batches of this dataset.\r\n+   */\r\n+  @Override\r\n+  public Iterator<List<Output<?>>> iterator() {\r\n+\r\n+    if (!(tf.scope().env() instanceof EagerSession)) {\r", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a69cfd9d8117fe6158a25e23133364b3b59b29ce"}, "originalPosition": 96}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDcwNjE3Mg==", "bodyText": "Method return type as Dataset instead, to preserve the abstraction?", "url": "https://github.com/tensorflow/java/pull/30#discussion_r390706172", "createdAt": "2020-03-11T01:55:49Z", "author": {"login": "karllessard"}, "path": "tensorflow-frameworks/tensorflow-data/src/main/java/org/tensorflow/data/Dataset.java", "diffHunk": "@@ -0,0 +1,180 @@\n+package org.tensorflow.data;\r\n+\r\n+import org.tensorflow.*;\r\n+import org.tensorflow.data.impl.*;\r\n+import org.tensorflow.op.Ops;\r\n+import org.tensorflow.op.data.AnonymousIterator;\r\n+import org.tensorflow.op.data.MakeIterator;\r\n+import org.tensorflow.tools.Shape;\r\n+import org.tensorflow.utils.Tuple2;\r\n+\r\n+import java.util.Iterator;\r\n+import java.util.List;\r\n+import java.util.Objects;\r\n+import java.util.stream.Collectors;\r\n+\r\n+/**\r\n+ * Represents a potentially large list of independent elements (samples), and\r\n+ * allows iteration and transformations to be performed across these elements.\r\n+ */\r\n+public abstract class Dataset implements Iterable<List<Output<?>>> {\r\n+  protected Ops tf;\r\n+  private List<DataType<?>> outputTypes;\r\n+  private List<Shape> outputShapes;\r\n+\r\n+  public Dataset(Ops tf, List<DataType<?>> outputTypes, List<Shape> outputShapes) {\r\n+    if (Objects.isNull(tf)) {\r\n+      throw new IllegalArgumentException(\"Ops accessor cannot be null.\");\r\n+    } else if (outputTypes.size() != outputShapes.size()) {\r\n+      throw new IllegalArgumentException(\"`outputTypes` and `outputShapes` must have the same size.\");\r\n+    }\r\n+\r\n+    this.tf = tf;\r\n+    this.outputTypes = outputTypes;\r\n+    this.outputShapes = outputShapes;\r\n+  }\r\n+\r\n+  /**\r\n+   * Groups elements of this dataset into batches.\r\n+   *\r\n+   * @param batchSize     The number of desired elements per batch\r\n+   * @param dropLastBatch Whether to leave out the final batch if it has fewer\r\n+   *                      than `batchSize` elements.\r\n+   * @return A batched Dataset\r\n+   */\r\n+  public final Dataset batch(long batchSize, boolean dropLastBatch) {\r\n+    List<Shape> batchOutputShapes = getOutputShapes().stream()\r\n+        .map(s -> Shape.of(Utils.array(batchSize, s.asArray())))\r\n+        .collect(Collectors.toList());\r\n+    return new BatchDataset(tf, this.getVariant(), tf.val(batchSize),\r\n+        tf.val(dropLastBatch), this.getOutputTypes(), batchOutputShapes);\r\n+  }\r\n+\r\n+  /**\r\n+   * Groups elements of this dataset into batches.\r\n+   * Leaves out the last batch if it has fewer than `batchSize` elements.\r\n+   *\r\n+   * @param batchSize The number of desired elements per batch\r\n+   * @return A batched Dataset\r\n+   */\r\n+  public final Dataset batch(long batchSize) {\r\n+    return batch(batchSize, true);\r\n+  }\r\n+\r\n+  /**\r\n+   * Creates new `Dataset` skips `count` initial elements from this dataset\r\n+   *\r\n+   * @param count The number of elements to `skip` to form the new dataset.\r\n+   * @return A new Dataset with `count` elements removed.\r\n+   */\r\n+  public final Dataset skip(long count) {\r\n+    return new SkipDataset(tf, this.getVariant(), tf.val(count), this.getOutputTypes(), this.getOutputShapes());\r\n+  }\r\n+\r\n+  /**\r\n+   * Creates new `Dataset` with the first `count` elements from this dataset.\r\n+   *\r\n+   * @param count The number of elements to \"take\" from this dataset.\r\n+   * @return A new Dataset containing the first `count` elements from this dataset.\r\n+   */\r\n+  public final Dataset take(long count) {\r\n+    return new TakeDataset(tf, this.getVariant(), tf.val(count), this.getOutputTypes(), this.getOutputShapes());\r\n+  }\r\n+\r\n+  /**\r\n+   * Creates an iterator which iterates through all batches of this Dataset in an eager fashion.\r\n+   * Each batch is a list of components, returned as `Output` objects.\r\n+   * <p>\r\n+   * This method enables for-each iteration through batches when running\r\n+   * in eager mode. For Graph mode batch iteration, see `makeOneShotIterator`.\r\n+   *\r\n+   * @return an Iterator through batches of this dataset.\r\n+   */\r\n+  @Override\r\n+  public Iterator<List<Output<?>>> iterator() {\r\n+\r\n+    if (!(tf.scope().env() instanceof EagerSession)) {\r\n+      throw new UnsupportedOperationException(\"Cannot iterate through a dataset in graph mode.\");\r\n+    }\r\n+\r\n+    Operand<?> dataset = getVariant();\r\n+    AnonymousIterator anonymousIterator = tf.data.anonymousIterator(getOutputTypes(), getOutputShapes());\r\n+\r\n+    tf.data.makeIterator(dataset, anonymousIterator.handle());\r\n+\r\n+    return new Iterator<List<Output<?>>>() {\r\n+      private List<Output<?>> tryNext = getNext();\r\n+\r\n+      private List<Output<?>> getNext() {\r\n+        try {\r\n+          return tf.data.iteratorGetNext(anonymousIterator.handle(), getOutputTypes(), getOutputShapes()).components();\r\n+        } catch (IndexOutOfBoundsException e) {\r\n+          return null;\r\n+        }\r\n+      }\r\n+\r\n+      @Override\r\n+      public boolean hasNext() {\r\n+        return tryNext != null;\r\n+      }\r\n+\r\n+      @Override\r\n+      public List<Output<?>> next() {\r\n+        List<Output<?>> result = tryNext;\r\n+        tryNext = getNext();\r\n+        return result;\r\n+      }\r\n+    };\r\n+  }\r\n+\r\n+  /**\r\n+   * Return the necessary components to iterate through batches of this\r\n+   * dataset in Graph mode.\r\n+   * <p>\r\n+   * This method returns a Pair whose first element is a MakeIterator operation\r\n+   * that must be run first in its own session to create the iterator internally.\r\n+   * <p>\r\n+   * The second element in the pair is a list of Output objects. In sequential\r\n+   * calls to session.run() in which these (or child) nodes are fetched, the batches\r\n+   * are already loaded into these objects.\r\n+   *\r\n+   * @return A Pair whose first element is a MakeIterator Operation, and whose\r\n+   * second element is a list batch components.\r\n+   */\r\n+  public OneShotIterator makeOneShotIterator() {\r\n+    if (!(tf.scope().env() instanceof Graph)) {\r\n+      throw new UnsupportedOperationException(\"OneShotIterator should only be used in Graph mode.\");\r\n+    }\r\n+    List<DataType<?>> outputTypes = getOutputTypes();\r\n+    List<Shape> outputShapes = getOutputShapes();\r\n+    Operand<?> iterator = tf.data.iterator(\"null\", \"null\", outputTypes, outputShapes);\r\n+\r\n+    MakeIterator makeIterator = tf.data.makeIterator(getVariant(), iterator);\r\n+    List<Output<?>> components = tf.data.iteratorGetNext(iterator, outputTypes, outputShapes).components();\r\n+\r\n+    return new OneShotIterator(makeIterator, components);\r\n+  }\r\n+\r\n+  public static TensorSliceDataset fromTensorSlices(Ops tf, List<Operand<?>> slices, List<DataType<?>> outputTypes) {\r", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a69cfd9d8117fe6158a25e23133364b3b59b29ce"}, "originalPosition": 158}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDcwNzMwMg==", "bodyText": "Maybe we can move this class as a @Operator available in Ops? e.g. tf.data.oneShotIterator(makeIterator, components)? I understand we don't have access to this op because  it uses a func attribute but that could replace it?", "url": "https://github.com/tensorflow/java/pull/30#discussion_r390707302", "createdAt": "2020-03-11T02:00:03Z", "author": {"login": "karllessard"}, "path": "tensorflow-frameworks/tensorflow-data/src/main/java/org/tensorflow/data/OneShotIterator.java", "diffHunk": "@@ -0,0 +1,25 @@\n+package org.tensorflow.data;\n+\n+import org.tensorflow.Operation;\n+import org.tensorflow.Output;\n+import org.tensorflow.op.data.MakeIterator;\n+\n+import java.util.List;\n+\n+public class OneShotIterator {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a69cfd9d8117fe6158a25e23133364b3b59b29ce"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDcwNzgxNg==", "bodyText": "It would be worth it to check which of the following utilities could be added directly to the Shape class instead.\nFor example, array(...) could be replaced by something like shape.extend(batchSize, 0), where 0 is the dimension index", "url": "https://github.com/tensorflow/java/pull/30#discussion_r390707816", "createdAt": "2020-03-11T02:02:16Z", "author": {"login": "karllessard"}, "path": "tensorflow-frameworks/tensorflow-data/src/main/java/org/tensorflow/data/Utils.java", "diffHunk": "@@ -0,0 +1,34 @@\n+package org.tensorflow.data;\r\n+\r\n+import org.tensorflow.tools.Shape;\r\n+\r\n+public class Utils {\r", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a69cfd9d8117fe6158a25e23133364b3b59b29ce"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDcwODQ2Nw==", "bodyText": "That could be replaced by Arrays.copyOfRange(shape.asArray(), 1, shape.numDimensions)", "url": "https://github.com/tensorflow/java/pull/30#discussion_r390708467", "createdAt": "2020-03-11T02:05:13Z", "author": {"login": "karllessard"}, "path": "tensorflow-frameworks/tensorflow-data/src/main/java/org/tensorflow/data/Utils.java", "diffHunk": "@@ -0,0 +1,34 @@\n+package org.tensorflow.data;\r\n+\r\n+import org.tensorflow.tools.Shape;\r\n+\r\n+public class Utils {\r\n+\r\n+    private static Shape head(Shape shape) {\r\n+        return Shape.of(shape.size(0));\r\n+    }\r\n+\r\n+    public static Shape tail(Shape shape) {\r\n+        long[] tail = new long[shape.numDimensions() - 1];\r\n+        for (int i = 1; i < shape.numDimensions(); i++) {\r\n+            tail[i - 1] = shape.size(i);\r\n+        }\r", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a69cfd9d8117fe6158a25e23133364b3b59b29ce"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDcwODUyMQ==", "bodyText": "that could be replaced simply by shape.asArray(), unless you need a copy, which Arrays.copyOf can provide you", "url": "https://github.com/tensorflow/java/pull/30#discussion_r390708521", "createdAt": "2020-03-11T02:05:29Z", "author": {"login": "karllessard"}, "path": "tensorflow-frameworks/tensorflow-data/src/main/java/org/tensorflow/data/Utils.java", "diffHunk": "@@ -0,0 +1,34 @@\n+package org.tensorflow.data;\r\n+\r\n+import org.tensorflow.tools.Shape;\r\n+\r\n+public class Utils {\r\n+\r\n+    private static Shape head(Shape shape) {\r\n+        return Shape.of(shape.size(0));\r\n+    }\r\n+\r\n+    public static Shape tail(Shape shape) {\r\n+        long[] tail = new long[shape.numDimensions() - 1];\r\n+        for (int i = 1; i < shape.numDimensions(); i++) {\r\n+            tail[i - 1] = shape.size(i);\r\n+        }\r\n+\r\n+        return Shape.of(tail);\r\n+    }\r\n+\r\n+    public static long[] shapeArray(Shape shape) {\r\n+        long[] arr = new long[shape.numDimensions()];\r\n+        for (int i = 0; i < arr.length; i++) {\r\n+            arr[i] = shape.size(i);\r\n+        }\r\n+        return arr;\r", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a69cfd9d8117fe6158a25e23133364b3b59b29ce"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDcwOTcwNQ==", "bodyText": "I don't know how tf.data.batchDataset works but I find it strange that we need to add the batchSize as a new dimension for all individual shapes. Just saying in case this is a mistake", "url": "https://github.com/tensorflow/java/pull/30#discussion_r390709705", "createdAt": "2020-03-11T02:10:23Z", "author": {"login": "karllessard"}, "path": "tensorflow-frameworks/tensorflow-data/src/main/java/org/tensorflow/data/Dataset.java", "diffHunk": "@@ -0,0 +1,180 @@\n+package org.tensorflow.data;\r\n+\r\n+import org.tensorflow.*;\r\n+import org.tensorflow.data.impl.*;\r\n+import org.tensorflow.op.Ops;\r\n+import org.tensorflow.op.data.AnonymousIterator;\r\n+import org.tensorflow.op.data.MakeIterator;\r\n+import org.tensorflow.tools.Shape;\r\n+import org.tensorflow.utils.Tuple2;\r\n+\r\n+import java.util.Iterator;\r\n+import java.util.List;\r\n+import java.util.Objects;\r\n+import java.util.stream.Collectors;\r\n+\r\n+/**\r\n+ * Represents a potentially large list of independent elements (samples), and\r\n+ * allows iteration and transformations to be performed across these elements.\r\n+ */\r\n+public abstract class Dataset implements Iterable<List<Output<?>>> {\r\n+  protected Ops tf;\r\n+  private List<DataType<?>> outputTypes;\r\n+  private List<Shape> outputShapes;\r\n+\r\n+  public Dataset(Ops tf, List<DataType<?>> outputTypes, List<Shape> outputShapes) {\r\n+    if (Objects.isNull(tf)) {\r\n+      throw new IllegalArgumentException(\"Ops accessor cannot be null.\");\r\n+    } else if (outputTypes.size() != outputShapes.size()) {\r\n+      throw new IllegalArgumentException(\"`outputTypes` and `outputShapes` must have the same size.\");\r\n+    }\r\n+\r\n+    this.tf = tf;\r\n+    this.outputTypes = outputTypes;\r\n+    this.outputShapes = outputShapes;\r\n+  }\r\n+\r\n+  /**\r\n+   * Groups elements of this dataset into batches.\r\n+   *\r\n+   * @param batchSize     The number of desired elements per batch\r\n+   * @param dropLastBatch Whether to leave out the final batch if it has fewer\r\n+   *                      than `batchSize` elements.\r\n+   * @return A batched Dataset\r\n+   */\r\n+  public final Dataset batch(long batchSize, boolean dropLastBatch) {\r\n+    List<Shape> batchOutputShapes = getOutputShapes().stream()\r\n+        .map(s -> Shape.of(Utils.array(batchSize, s.asArray())))\r\n+        .collect(Collectors.toList());\r", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a69cfd9d8117fe6158a25e23133364b3b59b29ce"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDcxMTkxNg==", "bodyText": "Why do we need to remove the first dimension of each tensor shapes?", "url": "https://github.com/tensorflow/java/pull/30#discussion_r390711916", "createdAt": "2020-03-11T02:19:24Z", "author": {"login": "karllessard"}, "path": "tensorflow-frameworks/tensorflow-data/src/main/java/org/tensorflow/data/impl/TensorSliceDataset.java", "diffHunk": "@@ -0,0 +1,32 @@\n+package org.tensorflow.data.impl;\n+\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import org.tensorflow.DataType;\n+import org.tensorflow.Operand;\n+import org.tensorflow.data.Dataset;\n+import org.tensorflow.data.Utils;\n+import org.tensorflow.op.Ops;\n+\n+public class TensorSliceDataset extends Dataset {\n+  private org.tensorflow.op.data.TensorSliceDataset dataset;\n+\n+  public TensorSliceDataset(Ops tf, List<Operand<?>> components, List<DataType<?>> outputTypes) {\n+    super(tf, outputTypes,\n+        components.stream()\n+            .map(c -> Utils.tail(c.asOutput().shape()))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a69cfd9d8117fe6158a25e23133364b3b59b29ce"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDcxMjY5MQ==", "bodyText": "testMatrix1 and testMatrix2 can be of the type IntNdArray that you initialize with: StdArrays.copyOf(new int[][]{ ... })", "url": "https://github.com/tensorflow/java/pull/30#discussion_r390712691", "createdAt": "2020-03-11T02:22:44Z", "author": {"login": "karllessard"}, "path": "tensorflow-frameworks/tensorflow-data/src/test/java/org/tensorflow/data/DatasetTestBase.java", "diffHunk": "@@ -0,0 +1,39 @@\n+package org.tensorflow.data;\n+import org.junit.Before;\n+import org.tensorflow.Tensor;\n+import org.tensorflow.types.TInt32;\n+\n+import java.nio.IntBuffer;\n+\n+public class DatasetTestBase {\n+  int[][] testMatrix1;\n+  int[][] testMatrix2;\n+\n+\n+  @Before\n+  public void setUp() {\n+    testMatrix1 = new int[][]{\n+        {1, 2, 3, 4, 5},\n+        {2, 4, 6, 8, 10},\n+        {3, 6, 8, 12, 15},\n+        {4, 8, 12, 16, 20}\n+    };\n+\n+    testMatrix2 = new int[][]{\n+        {1}, {0}, {1}, {1}\n+    };", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a69cfd9d8117fe6158a25e23133364b3b59b29ce"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDcxMzI0MQ==", "bodyText": "Use intTensor.data() here to return the tensor as a TInt32/IntNdArray directly", "url": "https://github.com/tensorflow/java/pull/30#discussion_r390713241", "createdAt": "2020-03-11T02:25:00Z", "author": {"login": "karllessard"}, "path": "tensorflow-frameworks/tensorflow-data/src/test/java/org/tensorflow/data/DatasetTestBase.java", "diffHunk": "@@ -0,0 +1,39 @@\n+package org.tensorflow.data;\n+import org.junit.Before;\n+import org.tensorflow.Tensor;\n+import org.tensorflow.types.TInt32;\n+\n+import java.nio.IntBuffer;\n+\n+public class DatasetTestBase {\n+  int[][] testMatrix1;\n+  int[][] testMatrix2;\n+\n+\n+  @Before\n+  public void setUp() {\n+    testMatrix1 = new int[][]{\n+        {1, 2, 3, 4, 5},\n+        {2, 4, 6, 8, 10},\n+        {3, 6, 8, 12, 15},\n+        {4, 8, 12, 16, 20}\n+    };\n+\n+    testMatrix2 = new int[][]{\n+        {1}, {0}, {1}, {1}\n+    };\n+  }\n+\n+  static int[] concat(int[] first, int[] second) {\n+    int[] concatenated = new int[first.length + second.length];\n+    System.arraycopy(first, 0, concatenated, 0, first.length);\n+    System.arraycopy(second, 0, concatenated, first.length, second.length);\n+    return concatenated;\n+  }\n+\n+  static int[] getIntTensorAsArray(Tensor<TInt32> intTensor) {\n+    IntBuffer buffer = IntBuffer.allocate((int) intTensor.shape().size());\n+    intTensor.writeTo(buffer);\n+    return buffer.array();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a69cfd9d8117fe6158a25e23133364b3b59b29ce"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDcxMzQ5Mg==", "bodyText": "As said before, tensors must be released with try-with-resources blocks", "url": "https://github.com/tensorflow/java/pull/30#discussion_r390713492", "createdAt": "2020-03-11T02:25:52Z", "author": {"login": "karllessard"}, "path": "tensorflow-frameworks/tensorflow-data/src/test/java/org/tensorflow/data/BatchDatasetTest.java", "diffHunk": "@@ -0,0 +1,96 @@\n+package org.tensorflow.data;\n+\n+import org.junit.Test;\n+import org.tensorflow.Output;\n+import org.tensorflow.Tensor;\n+import org.tensorflow.op.Ops;\n+import org.tensorflow.types.TInt32;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import static org.junit.Assert.assertArrayEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+public class BatchDatasetTest extends DatasetTestBase {\n+\n+  @Test\n+  public void testEagerBatchDataset() {\n+    Ops tf = Ops.create();\n+\n+    // EVEN BATCH SIZES\n+    Dataset dataset = Dataset\n+        .fromTensorSlices(tf,\n+            Arrays.asList(\n+                tf.val(testMatrix1),\n+                tf.val(testMatrix2)),\n+            Arrays.asList(TInt32.DTYPE, TInt32.DTYPE))\n+        .batch(2);\n+\n+    int count = 0;\n+\n+    for (List<Output<?>> components : dataset) {\n+      Tensor<TInt32> batch1 = components.get(0).tensor().expect(TInt32.DTYPE);\n+      Tensor<TInt32> batch2 = components.get(1).tensor().expect(TInt32.DTYPE);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a69cfd9d8117fe6158a25e23133364b3b59b29ce"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDcxNDAwMA==", "bodyText": "This PR will allow you to test equality of NdArray instances, if you make that change (see other comments)", "url": "https://github.com/tensorflow/java/pull/30#discussion_r390714000", "createdAt": "2020-03-11T02:27:53Z", "author": {"login": "karllessard"}, "path": "tensorflow-frameworks/tensorflow-data/src/test/java/org/tensorflow/data/BatchDatasetTest.java", "diffHunk": "@@ -0,0 +1,96 @@\n+package org.tensorflow.data;\n+\n+import org.junit.Test;\n+import org.tensorflow.Output;\n+import org.tensorflow.Tensor;\n+import org.tensorflow.op.Ops;\n+import org.tensorflow.types.TInt32;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import static org.junit.Assert.assertArrayEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+public class BatchDatasetTest extends DatasetTestBase {\n+\n+  @Test\n+  public void testEagerBatchDataset() {\n+    Ops tf = Ops.create();\n+\n+    // EVEN BATCH SIZES\n+    Dataset dataset = Dataset\n+        .fromTensorSlices(tf,\n+            Arrays.asList(\n+                tf.val(testMatrix1),\n+                tf.val(testMatrix2)),\n+            Arrays.asList(TInt32.DTYPE, TInt32.DTYPE))\n+        .batch(2);\n+\n+    int count = 0;\n+\n+    for (List<Output<?>> components : dataset) {\n+      Tensor<TInt32> batch1 = components.get(0).tensor().expect(TInt32.DTYPE);\n+      Tensor<TInt32> batch2 = components.get(1).tensor().expect(TInt32.DTYPE);\n+\n+      assertArrayEquals(concat(testMatrix1[count], testMatrix1[count + 1]), getIntTensorAsArray(batch1));\n+      assertArrayEquals(concat(testMatrix2[count], testMatrix2[count + 1]), getIntTensorAsArray(batch2));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a69cfd9d8117fe6158a25e23133364b3b59b29ce"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDcxNDQ1NA==", "bodyText": "In this PR again, I dropped the StaticApi class, so better not using it :) Meaning that would be NdArrays.ofInts(Shape.of(3, 4))\nBut everything in this class seems to test more tensorflow-tools functionalities than tensorflow-data, could we simply remove it? Or move it directly to tensorflow-tools if you think they are worth it.", "url": "https://github.com/tensorflow/java/pull/30#discussion_r390714454", "createdAt": "2020-03-11T02:29:49Z", "author": {"login": "karllessard"}, "path": "tensorflow-frameworks/tensorflow-data/src/test/java/org/tensorflow/data/DataInterfaceTester.java", "diffHunk": "@@ -0,0 +1,31 @@\n+package org.tensorflow.data;\n+\n+import org.junit.Test;\n+import org.tensorflow.tools.ndarray.IntNdArray;\n+\n+import java.util.Arrays;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.tensorflow.tools.StaticApi.*;\n+\n+public class DataInterfaceTester {\n+  @Test\n+  public void testSomething() {\n+    IntNdArray matrix2d = ndArrayOfInts(shapeOf(3, 4));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a69cfd9d8117fe6158a25e23133364b3b59b29ce"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDcxNTE1OA==", "bodyText": "Are TensorSliceDataset, BatchDataset, etc. meant to be accessed directly or this is only for testing purposes?\nIf they are, then you'll probably want to move these out of the impl package", "url": "https://github.com/tensorflow/java/pull/30#discussion_r390715158", "createdAt": "2020-03-11T02:32:53Z", "author": {"login": "karllessard"}, "path": "tensorflow-frameworks/tensorflow-data/src/test/java/org/tensorflow/data/DatasetOpTester.java", "diffHunk": "@@ -0,0 +1,283 @@\n+package org.tensorflow.data;\n+\n+import org.junit.Test;\n+import org.tensorflow.*;\n+import org.tensorflow.op.Ops;\n+import org.tensorflow.op.core.Constant;\n+import org.tensorflow.op.data.*;\n+import org.tensorflow.tools.Shape;\n+import org.tensorflow.types.TInt32;\n+import org.tensorflow.utils.Tuple2;\n+\n+import java.nio.IntBuffer;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+public class DatasetOpTester {\n+\n+  @Test\n+  public void testEagerBatching() {\n+    try (EagerSession session = EagerSession.create()) {\n+      Ops tf = Ops.create(session);\n+\n+      Constant<TInt32> X = tf.val(\n+          new int[][]{\n+              {1, 2, 3},\n+              {4, 5, 6},\n+              {7, 8, 9},\n+              {10, 11, 12}\n+          }\n+      );\n+\n+      Constant<TInt32> y = tf.val(\n+          new int[][]{\n+              {1},\n+              {4},\n+              {7},\n+              {10}\n+          }\n+      );\n+\n+\n+      List<Operand<?>> tensors = Arrays.asList(X, y);\n+\n+      // // Try running TensorDataset\n+      List<DataType<?>> outputTypes = Arrays.asList(TInt32.DTYPE, TInt32.DTYPE);\n+      List<Shape> outputShapes = Arrays.asList(\n+          Shape.of(3),\n+          Shape.of(1));\n+\n+      TensorSliceDataset tensorDataset = TensorSliceDataset.create(tf.scope(), tensors, outputShapes);\n+\n+      BatchDataset batchDataset = BatchDataset.create(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a69cfd9d8117fe6158a25e23133364b3b59b29ce"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDcxNTMzMQ==", "bodyText": "handle tensor close", "url": "https://github.com/tensorflow/java/pull/30#discussion_r390715331", "createdAt": "2020-03-11T02:33:34Z", "author": {"login": "karllessard"}, "path": "tensorflow-frameworks/tensorflow-data/src/test/java/org/tensorflow/data/DatasetOpTester.java", "diffHunk": "@@ -0,0 +1,283 @@\n+package org.tensorflow.data;\n+\n+import org.junit.Test;\n+import org.tensorflow.*;\n+import org.tensorflow.op.Ops;\n+import org.tensorflow.op.core.Constant;\n+import org.tensorflow.op.data.*;\n+import org.tensorflow.tools.Shape;\n+import org.tensorflow.types.TInt32;\n+import org.tensorflow.utils.Tuple2;\n+\n+import java.nio.IntBuffer;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+public class DatasetOpTester {\n+\n+  @Test\n+  public void testEagerBatching() {\n+    try (EagerSession session = EagerSession.create()) {\n+      Ops tf = Ops.create(session);\n+\n+      Constant<TInt32> X = tf.val(\n+          new int[][]{\n+              {1, 2, 3},\n+              {4, 5, 6},\n+              {7, 8, 9},\n+              {10, 11, 12}\n+          }\n+      );\n+\n+      Constant<TInt32> y = tf.val(\n+          new int[][]{\n+              {1},\n+              {4},\n+              {7},\n+              {10}\n+          }\n+      );\n+\n+\n+      List<Operand<?>> tensors = Arrays.asList(X, y);\n+\n+      // // Try running TensorDataset\n+      List<DataType<?>> outputTypes = Arrays.asList(TInt32.DTYPE, TInt32.DTYPE);\n+      List<Shape> outputShapes = Arrays.asList(\n+          Shape.of(3),\n+          Shape.of(1));\n+\n+      TensorSliceDataset tensorDataset = TensorSliceDataset.create(tf.scope(), tensors, outputShapes);\n+\n+      BatchDataset batchDataset = BatchDataset.create(\n+          tf.scope(),\n+          tensorDataset,\n+          tf.val(2L),\n+          tf.val(true),\n+          outputTypes,\n+          Arrays.asList(\n+              Shape.of(2, 3),\n+              Shape.of(2, 1))\n+      );\n+\n+\n+      AnonymousIterator anonymousIter = AnonymousIterator.create(tf.scope(), outputTypes, Arrays.asList(\n+          Shape.of(2, 3),\n+          Shape.of(2, 1)));\n+\n+      MakeIterator makeIterator = tf.data.makeIterator(batchDataset, anonymousIter.handle());\n+\n+      while (true) {\n+        try {\n+          IteratorGetNext getNext = tf.data.iteratorGetNext(anonymousIter.handle(), outputTypes, outputShapes);\n+          List<Output<?>> outputs = getNext.components();\n+          System.out.println(\"BATCH: \");\n+          printIntTensor(outputs.get(0).tensor());\n+          printIntTensor(outputs.get(1).tensor());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a69cfd9d8117fe6158a25e23133364b3b59b29ce"}, "originalPosition": 76}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDcxNTUzNQ==", "bodyText": "again, any way to avoid catching an exception as part of the normal process? I think I already asked you this question before and you told me that is how Python is doing it... but still, can we do better? :)", "url": "https://github.com/tensorflow/java/pull/30#discussion_r390715535", "createdAt": "2020-03-11T02:34:25Z", "author": {"login": "karllessard"}, "path": "tensorflow-frameworks/tensorflow-data/src/test/java/org/tensorflow/data/DatasetOpTester.java", "diffHunk": "@@ -0,0 +1,283 @@\n+package org.tensorflow.data;\n+\n+import org.junit.Test;\n+import org.tensorflow.*;\n+import org.tensorflow.op.Ops;\n+import org.tensorflow.op.core.Constant;\n+import org.tensorflow.op.data.*;\n+import org.tensorflow.tools.Shape;\n+import org.tensorflow.types.TInt32;\n+import org.tensorflow.utils.Tuple2;\n+\n+import java.nio.IntBuffer;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+public class DatasetOpTester {\n+\n+  @Test\n+  public void testEagerBatching() {\n+    try (EagerSession session = EagerSession.create()) {\n+      Ops tf = Ops.create(session);\n+\n+      Constant<TInt32> X = tf.val(\n+          new int[][]{\n+              {1, 2, 3},\n+              {4, 5, 6},\n+              {7, 8, 9},\n+              {10, 11, 12}\n+          }\n+      );\n+\n+      Constant<TInt32> y = tf.val(\n+          new int[][]{\n+              {1},\n+              {4},\n+              {7},\n+              {10}\n+          }\n+      );\n+\n+\n+      List<Operand<?>> tensors = Arrays.asList(X, y);\n+\n+      // // Try running TensorDataset\n+      List<DataType<?>> outputTypes = Arrays.asList(TInt32.DTYPE, TInt32.DTYPE);\n+      List<Shape> outputShapes = Arrays.asList(\n+          Shape.of(3),\n+          Shape.of(1));\n+\n+      TensorSliceDataset tensorDataset = TensorSliceDataset.create(tf.scope(), tensors, outputShapes);\n+\n+      BatchDataset batchDataset = BatchDataset.create(\n+          tf.scope(),\n+          tensorDataset,\n+          tf.val(2L),\n+          tf.val(true),\n+          outputTypes,\n+          Arrays.asList(\n+              Shape.of(2, 3),\n+              Shape.of(2, 1))\n+      );\n+\n+\n+      AnonymousIterator anonymousIter = AnonymousIterator.create(tf.scope(), outputTypes, Arrays.asList(\n+          Shape.of(2, 3),\n+          Shape.of(2, 1)));\n+\n+      MakeIterator makeIterator = tf.data.makeIterator(batchDataset, anonymousIter.handle());\n+\n+      while (true) {\n+        try {\n+          IteratorGetNext getNext = tf.data.iteratorGetNext(anonymousIter.handle(), outputTypes, outputShapes);\n+          List<Output<?>> outputs = getNext.components();\n+          System.out.println(\"BATCH: \");\n+          printIntTensor(outputs.get(0).tensor());\n+          printIntTensor(outputs.get(1).tensor());\n+          System.out.println();\n+        } catch (IndexOutOfBoundsException e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a69cfd9d8117fe6158a25e23133364b3b59b29ce"}, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDcxNTk4OQ==", "bodyText": "tensor.writeTo might be remove soon, you might want to use tensor.data() instead and maybe enhanced NdArray with what is missing (like ndArray.print()?)", "url": "https://github.com/tensorflow/java/pull/30#discussion_r390715989", "createdAt": "2020-03-11T02:36:38Z", "author": {"login": "karllessard"}, "path": "tensorflow-frameworks/tensorflow-data/src/test/java/org/tensorflow/data/DatasetOpTester.java", "diffHunk": "@@ -0,0 +1,283 @@\n+package org.tensorflow.data;\n+\n+import org.junit.Test;\n+import org.tensorflow.*;\n+import org.tensorflow.op.Ops;\n+import org.tensorflow.op.core.Constant;\n+import org.tensorflow.op.data.*;\n+import org.tensorflow.tools.Shape;\n+import org.tensorflow.types.TInt32;\n+import org.tensorflow.utils.Tuple2;\n+\n+import java.nio.IntBuffer;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+public class DatasetOpTester {\n+\n+  @Test\n+  public void testEagerBatching() {\n+    try (EagerSession session = EagerSession.create()) {\n+      Ops tf = Ops.create(session);\n+\n+      Constant<TInt32> X = tf.val(\n+          new int[][]{\n+              {1, 2, 3},\n+              {4, 5, 6},\n+              {7, 8, 9},\n+              {10, 11, 12}\n+          }\n+      );\n+\n+      Constant<TInt32> y = tf.val(\n+          new int[][]{\n+              {1},\n+              {4},\n+              {7},\n+              {10}\n+          }\n+      );\n+\n+\n+      List<Operand<?>> tensors = Arrays.asList(X, y);\n+\n+      // // Try running TensorDataset\n+      List<DataType<?>> outputTypes = Arrays.asList(TInt32.DTYPE, TInt32.DTYPE);\n+      List<Shape> outputShapes = Arrays.asList(\n+          Shape.of(3),\n+          Shape.of(1));\n+\n+      TensorSliceDataset tensorDataset = TensorSliceDataset.create(tf.scope(), tensors, outputShapes);\n+\n+      BatchDataset batchDataset = BatchDataset.create(\n+          tf.scope(),\n+          tensorDataset,\n+          tf.val(2L),\n+          tf.val(true),\n+          outputTypes,\n+          Arrays.asList(\n+              Shape.of(2, 3),\n+              Shape.of(2, 1))\n+      );\n+\n+\n+      AnonymousIterator anonymousIter = AnonymousIterator.create(tf.scope(), outputTypes, Arrays.asList(\n+          Shape.of(2, 3),\n+          Shape.of(2, 1)));\n+\n+      MakeIterator makeIterator = tf.data.makeIterator(batchDataset, anonymousIter.handle());\n+\n+      while (true) {\n+        try {\n+          IteratorGetNext getNext = tf.data.iteratorGetNext(anonymousIter.handle(), outputTypes, outputShapes);\n+          List<Output<?>> outputs = getNext.components();\n+          System.out.println(\"BATCH: \");\n+          printIntTensor(outputs.get(0).tensor());\n+          printIntTensor(outputs.get(1).tensor());\n+          System.out.println();\n+        } catch (IndexOutOfBoundsException e) {\n+          System.out.println(\"finished iterating.\");\n+          break;\n+        }\n+      }\n+    }\n+  }\n+\n+  @Test\n+  public void testCleanEagerBatching() {\n+    try (EagerSession session = EagerSession.create()) {\n+      Ops tf = Ops.create(session);\n+\n+      Constant<TInt32> X = tf.val(\n+          new int[][]{\n+              {1, 2, 3},\n+              {4, 5, 6},\n+              {7, 8, 9},\n+              {10, 11, 12}\n+          }\n+      );\n+\n+      Constant<TInt32> y = tf.val(\n+          new int[][]{\n+              {1},\n+              {4},\n+              {7},\n+              {10}\n+          }\n+      );\n+\n+\n+      // // Try running TensorDataset\n+      List<Operand<?>> tensors = Arrays.asList(X, y);\n+      List<DataType<?>> outputTypes = Arrays.asList(TInt32.DTYPE, TInt32.DTYPE);\n+\n+      Dataset dataset = Dataset\n+          .fromTensorSlices(tf, tensors, outputTypes)\n+          .batch(50)\n+          .take(3)\n+          .skip(1);\n+      for (List<Output<?>> output : dataset) {\n+        Tensor<?> XBatch = output.get(0).tensor();\n+        Tensor<?> yBatch = output.get(1).tensor();\n+\n+        System.out.println(\"New Batch: \");\n+        System.out.print(\"   X is\");\n+        printIntTensor(XBatch);\n+        System.out.print(\"   y is\");\n+        printIntTensor(yBatch);\n+      }\n+    }\n+  }\n+\n+\n+  @Test\n+  public  void testGraphBatching() {\n+    try (Graph graph = new Graph()) {\n+\n+      Ops tf = Ops.create(graph);\n+      try (Session session = new Session(graph)) {\n+        long BATCH_SIZE = 2L;\n+\n+        Constant<TInt32> X = tf.val(\n+            new int[][]{\n+                {1, 2, 3},\n+                {4, 5, 6},\n+                {7, 8, 9},\n+                {10, 11, 12}\n+            }\n+        );\n+\n+        Constant<TInt32> y = tf.val(\n+            new int[][]{\n+                {1},\n+                {4},\n+                {7},\n+                {10}\n+            }\n+        );\n+\n+        // // Try running TensorDataset\n+        List<DataType<?>> outputTypes = Arrays.asList(TInt32.DTYPE, TInt32.DTYPE);\n+        List<Shape> outputShapes = Arrays.asList(\n+            Shape.of(3),\n+            Shape.of(1));\n+\n+        TensorSliceDataset tensorDataset = TensorSliceDataset.create(tf.scope(),\n+            Arrays.asList(X, y),\n+            outputShapes);\n+\n+        BatchDataset batchDataset = BatchDataset.create(\n+            tf.scope(),\n+            tensorDataset,\n+            tf.val(BATCH_SIZE),\n+            tf.val(true),\n+            outputTypes,\n+            Arrays.asList(\n+                Shape.of(BATCH_SIZE, 3),\n+                Shape.of(BATCH_SIZE, 1))\n+        );\n+\n+        Iterator anonymousIter = Iterator.create(tf.scope(), null, null, outputTypes, Arrays.asList(\n+            Shape.of(BATCH_SIZE, 3),\n+            Shape.of(BATCH_SIZE, 1)));\n+\n+        MakeIterator makeIterator = tf.data.makeIterator(batchDataset, anonymousIter);\n+\n+        session.runner()\n+            .addTarget(makeIterator.op())\n+            .run();\n+\n+        IteratorGetNext getNext = tf.data.iteratorGetNext(anonymousIter, outputTypes, outputShapes);\n+        Operand<?> XOp = getNext.components().get(0);\n+        Operand<?> yOp = getNext.components().get(1);\n+        while (true) {\n+          try {\n+            List<Tensor<?>> outputs = session.runner()\n+                .addTarget(getNext.op())\n+                .fetch(XOp)\n+                .fetch(yOp)\n+                .run();\n+            System.out.println(\"BATCH: \");\n+            printIntTensor(outputs.get(0));\n+            printIntTensor(outputs.get(1));\n+            System.out.println();\n+          } catch (IndexOutOfBoundsException e) {\n+            System.out.println(\"finished iterating.\");\n+            break;\n+          }\n+        }\n+      }\n+    }\n+\n+  }\n+\n+  @Test\n+  public void testCleanGraphBatching() {\n+    try (Graph graph = new Graph()) {\n+\n+      Ops tf = Ops.create(graph);\n+      try (Session session = new Session(graph)) {\n+        long BATCH_SIZE = 2L;\n+\n+        Constant<TInt32> X = tf.val(\n+            new int[][]{\n+                {1, 2, 3},\n+                {4, 5, 6},\n+                {7, 8, 9},\n+                {10, 11, 12}\n+            }\n+        );\n+\n+        Constant<TInt32> y = tf.val(\n+            new int[][]{\n+                {1},\n+                {4},\n+                {7},\n+                {10}\n+            }\n+        );\n+\n+        // // Try running TensorDataset\n+        List<Operand<?>> tensors = Arrays.asList(X, y);\n+        List<DataType<?>> outputTypes = Arrays.asList(TInt32.DTYPE, TInt32.DTYPE);\n+\n+        Dataset dataset = Dataset\n+            .fromTensorSlices(tf, tensors, outputTypes)\n+            .batch(2);\n+\n+        OneShotIterator oneShotIterator = dataset.makeOneShotIterator();\n+        List<Output<?>> components = oneShotIterator.getComponents();\n+        Operand<?> XOp = components.get(0);\n+        Operand<?> yOp = components.get(1);\n+\n+        // Run MakeIterator Op\n+        session.runner()\n+            .addTarget(oneShotIterator.getMakeIteratorOp())\n+            .run();\n+\n+        while (true) {\n+          try {\n+            List<Tensor<?>> outputs = session.runner()\n+                .fetch(XOp)\n+                .fetch(yOp)\n+                .run();\n+\n+            System.out.println(\"BATCH: \");\n+            printIntTensor(outputs.get(0));\n+            printIntTensor(outputs.get(1));\n+            System.out.println();\n+          } catch (IndexOutOfBoundsException e) {\n+            System.out.println(\"finished iterating.\");\n+            break;\n+          }\n+        }\n+      }\n+    }\n+  }\n+\n+  public static void printIntTensor(Tensor<?> tensor) {\n+    IntBuffer buffer = IntBuffer.allocate((int) tensor.shape().size());\n+    tensor.writeTo(buffer);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a69cfd9d8117fe6158a25e23133364b3b59b29ce"}, "originalPosition": 280}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDcxNjQ0Ng==", "bodyText": "You can move classes in this artifact directly in tensorflow-tools, its main purpose is to provide such generic utilities.\nBut looking again at your PR, it seems that those classes (Pair and Tuple2) are not being used anywhere, so I suggest we simple drop them.", "url": "https://github.com/tensorflow/java/pull/30#discussion_r390716446", "createdAt": "2020-03-11T02:38:32Z", "author": {"login": "karllessard"}, "path": "tensorflow-frameworks/tensorflow-utils/pom.xml", "diffHunk": "@@ -0,0 +1,62 @@\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n+         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n+         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+    <modelVersion>4.0.0</modelVersion>\n+\n+    <parent>\n+        <groupId>org.tensorflow</groupId>\n+        <artifactId>tensorflow-frameworks</artifactId>\n+        <version>0.1.0-SNAPSHOT</version>\n+    </parent>\n+    <artifactId>tensorflow-utils</artifactId>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a69cfd9d8117fe6158a25e23133364b3b59b29ce"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDcxNzI5MA==", "bodyText": "It seems that it does not return a Pair anymore?", "url": "https://github.com/tensorflow/java/pull/30#discussion_r390717290", "createdAt": "2020-03-11T02:42:08Z", "author": {"login": "karllessard"}, "path": "tensorflow-frameworks/tensorflow-data/src/main/java/org/tensorflow/data/Dataset.java", "diffHunk": "@@ -0,0 +1,180 @@\n+package org.tensorflow.data;\r\n+\r\n+import org.tensorflow.*;\r\n+import org.tensorflow.data.impl.*;\r\n+import org.tensorflow.op.Ops;\r\n+import org.tensorflow.op.data.AnonymousIterator;\r\n+import org.tensorflow.op.data.MakeIterator;\r\n+import org.tensorflow.tools.Shape;\r\n+import org.tensorflow.utils.Tuple2;\r\n+\r\n+import java.util.Iterator;\r\n+import java.util.List;\r\n+import java.util.Objects;\r\n+import java.util.stream.Collectors;\r\n+\r\n+/**\r\n+ * Represents a potentially large list of independent elements (samples), and\r\n+ * allows iteration and transformations to be performed across these elements.\r\n+ */\r\n+public abstract class Dataset implements Iterable<List<Output<?>>> {\r\n+  protected Ops tf;\r\n+  private List<DataType<?>> outputTypes;\r\n+  private List<Shape> outputShapes;\r\n+\r\n+  public Dataset(Ops tf, List<DataType<?>> outputTypes, List<Shape> outputShapes) {\r\n+    if (Objects.isNull(tf)) {\r\n+      throw new IllegalArgumentException(\"Ops accessor cannot be null.\");\r\n+    } else if (outputTypes.size() != outputShapes.size()) {\r\n+      throw new IllegalArgumentException(\"`outputTypes` and `outputShapes` must have the same size.\");\r\n+    }\r\n+\r\n+    this.tf = tf;\r\n+    this.outputTypes = outputTypes;\r\n+    this.outputShapes = outputShapes;\r\n+  }\r\n+\r\n+  /**\r\n+   * Groups elements of this dataset into batches.\r\n+   *\r\n+   * @param batchSize     The number of desired elements per batch\r\n+   * @param dropLastBatch Whether to leave out the final batch if it has fewer\r\n+   *                      than `batchSize` elements.\r\n+   * @return A batched Dataset\r\n+   */\r\n+  public final Dataset batch(long batchSize, boolean dropLastBatch) {\r\n+    List<Shape> batchOutputShapes = getOutputShapes().stream()\r\n+        .map(s -> Shape.of(Utils.array(batchSize, s.asArray())))\r\n+        .collect(Collectors.toList());\r\n+    return new BatchDataset(tf, this.getVariant(), tf.val(batchSize),\r\n+        tf.val(dropLastBatch), this.getOutputTypes(), batchOutputShapes);\r\n+  }\r\n+\r\n+  /**\r\n+   * Groups elements of this dataset into batches.\r\n+   * Leaves out the last batch if it has fewer than `batchSize` elements.\r\n+   *\r\n+   * @param batchSize The number of desired elements per batch\r\n+   * @return A batched Dataset\r\n+   */\r\n+  public final Dataset batch(long batchSize) {\r\n+    return batch(batchSize, true);\r\n+  }\r\n+\r\n+  /**\r\n+   * Creates new `Dataset` skips `count` initial elements from this dataset\r\n+   *\r\n+   * @param count The number of elements to `skip` to form the new dataset.\r\n+   * @return A new Dataset with `count` elements removed.\r\n+   */\r\n+  public final Dataset skip(long count) {\r\n+    return new SkipDataset(tf, this.getVariant(), tf.val(count), this.getOutputTypes(), this.getOutputShapes());\r\n+  }\r\n+\r\n+  /**\r\n+   * Creates new `Dataset` with the first `count` elements from this dataset.\r\n+   *\r\n+   * @param count The number of elements to \"take\" from this dataset.\r\n+   * @return A new Dataset containing the first `count` elements from this dataset.\r\n+   */\r\n+  public final Dataset take(long count) {\r\n+    return new TakeDataset(tf, this.getVariant(), tf.val(count), this.getOutputTypes(), this.getOutputShapes());\r\n+  }\r\n+\r\n+  /**\r\n+   * Creates an iterator which iterates through all batches of this Dataset in an eager fashion.\r\n+   * Each batch is a list of components, returned as `Output` objects.\r\n+   * <p>\r\n+   * This method enables for-each iteration through batches when running\r\n+   * in eager mode. For Graph mode batch iteration, see `makeOneShotIterator`.\r\n+   *\r\n+   * @return an Iterator through batches of this dataset.\r\n+   */\r\n+  @Override\r\n+  public Iterator<List<Output<?>>> iterator() {\r\n+\r\n+    if (!(tf.scope().env() instanceof EagerSession)) {\r\n+      throw new UnsupportedOperationException(\"Cannot iterate through a dataset in graph mode.\");\r\n+    }\r\n+\r\n+    Operand<?> dataset = getVariant();\r\n+    AnonymousIterator anonymousIterator = tf.data.anonymousIterator(getOutputTypes(), getOutputShapes());\r\n+\r\n+    tf.data.makeIterator(dataset, anonymousIterator.handle());\r\n+\r\n+    return new Iterator<List<Output<?>>>() {\r\n+      private List<Output<?>> tryNext = getNext();\r\n+\r\n+      private List<Output<?>> getNext() {\r\n+        try {\r\n+          return tf.data.iteratorGetNext(anonymousIterator.handle(), getOutputTypes(), getOutputShapes()).components();\r\n+        } catch (IndexOutOfBoundsException e) {\r\n+          return null;\r\n+        }\r\n+      }\r\n+\r\n+      @Override\r\n+      public boolean hasNext() {\r\n+        return tryNext != null;\r\n+      }\r\n+\r\n+      @Override\r\n+      public List<Output<?>> next() {\r\n+        List<Output<?>> result = tryNext;\r\n+        tryNext = getNext();\r\n+        return result;\r\n+      }\r\n+    };\r\n+  }\r\n+\r\n+  /**\r\n+   * Return the necessary components to iterate through batches of this\r\n+   * dataset in Graph mode.\r\n+   * <p>\r\n+   * This method returns a Pair whose first element is a MakeIterator operation\r\n+   * that must be run first in its own session to create the iterator internally.\r\n+   * <p>\r\n+   * The second element in the pair is a list of Output objects. In sequential\r\n+   * calls to session.run() in which these (or child) nodes are fetched, the batches\r\n+   * are already loaded into these objects.\r\n+   *\r\n+   * @return A Pair whose first element is a MakeIterator Operation, and whose\r", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a69cfd9d8117fe6158a25e23133364b3b59b29ce"}, "originalPosition": 141}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc1MjI4NDM0", "url": "https://github.com/tensorflow/java/pull/30#pullrequestreview-375228434", "createdAt": "2020-03-16T13:49:18Z", "commit": {"oid": "a69cfd9d8117fe6158a25e23133364b3b59b29ce"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQxMzo0OToxOFrOF208mw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQxNDoxNDo1MVrOF22CHg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzAzNDkwNw==", "bodyText": "Does the bit about C++ need to be at the top of the readme? It's not relevant to most users who come across this library. The rest of it is fine, I just don't want to put off people who might think they need to know anything about TF's C++ API before using this.", "url": "https://github.com/tensorflow/java/pull/30#discussion_r393034907", "createdAt": "2020-03-16T13:49:18Z", "author": {"login": "Craigacp"}, "path": "tensorflow-frameworks/tensorflow-data/README.md", "diffHunk": "@@ -0,0 +1,93 @@\n+Tensorflow-Data (Java)\n+==\n+\n+TensorFlow Data provides simple APIs for loading data of various formats, and preparing\n+datasets for use in training and using deep learning models.\n+\n+TensorFlow Java's implementation simplifies the use of the C++ `data` ops, and provides", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a69cfd9d8117fe6158a25e23133364b3b59b29ce"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzAzOTE1Mw==", "bodyText": "I agree with Karl, but moreso, I don't think that we should expose any API where catching a RuntimeException is the expected way to use it.", "url": "https://github.com/tensorflow/java/pull/30#discussion_r393039153", "createdAt": "2020-03-16T13:55:35Z", "author": {"login": "Craigacp"}, "path": "tensorflow-frameworks/tensorflow-data/README.md", "diffHunk": "@@ -0,0 +1,93 @@\n+Tensorflow-Data (Java)\n+==\n+\n+TensorFlow Data provides simple APIs for loading data of various formats, and preparing\n+datasets for use in training and using deep learning models.\n+\n+TensorFlow Java's implementation simplifies the use of the C++ `data` ops, and provides\n+a simple API for configuring and iterating over datasets in both \"graph\" and \"eager\" mode.\n+\n+Usage\n+--\n+\n+The `Dataset` abstraction represents a sequence of elements, where each element in the sequence is a collection (`List`) of tensors (or, \"components\").\n+\n+\n+Creation\n+-\n+A dataset can be constructed from a list of constant tensors\n+using `Dataset.fromTensorSlices( ... )` as follows:\n+\n+```java\n+// Declare dataset components as arrays.\n+// NOTE: All components in a dataset must share the first \"batch\" dimension.\n+\n+int[][] m1 = new int[][]{\n+        {1, 2, 3, 4, 5},\n+        {2, 4, 6, 8, 10},\n+        {3, 6, 8, 12, 15},\n+        {4, 8, 12, 16, 20}\n+    };\n+\n+int[][] m2 = new int[][]{\n+    {1}, {0}, {1}, {1}\n+};\n+\n+\n+Ops tf = // ... TensorFlow Ops Accessor (either graph or eager).\n+\n+// Construct dataset with two components, batchSize=2.\n+Dataset dataset = Dataset.fromTensorSlices(tf,\n+    // List of array components\n+    Arrays.asList(tf.constant(m1), tf.constant(m2)),\n+    // List of each component's dtype\n+    Arrays.asList(TInt32.DTYPE, TInt32.DTYPE)\n+)\n+```\n+\n+Iteration\n+--\n+\n+In eager mode, the dataset can be iterated through using a standard \n+\"for-each\" loop, to receive the tensor values of each component:\n+\n+```java\n+int BATCH_SIZE = 2;\n+for (List<Output<?>> components : dataset.batch(BATCH_SIZE)) {\n+      Tensor<TInt32> XBatch = components.get(0).tensor().expect(TInt32.DTYPE);\n+      Tensor<TInt32> yBatch = components.get(1).tensor().expect(TInt32.DTYPE);\n+      \n+      // ... use batch tensors\n+}\n+```\n+\n+In graph mode, the dataset can be iterated through using the `OneShotIterator` abstraction, and a while loop, as follows:\n+\n+```java\n+OneShotIterator oneShotIterator = dataset.makeOneShotIterator();\n+Operation makeIterator = oneShotIterator.getMakeIteratorOp();\n+List<Output<?>> components = oneShotIterator.getComponents();\n+\n+try (Session session = new Session(graph)) {\n+    // Run MakeIterator Op to set iterator position\n+    session.runner()\n+        .addTarget(makeIterator)\n+        .run();\n+    \n+    while (true) {\n+        try {\n+            List<Tensor<?>> outputs = session.runner()\n+                .fetch(components.get(0))\n+                .fetch(components.get(1))\n+                .run();\n+\n+            Tensor<TInt32> matrix1 = outputs.get(0).expect(TInt32.DTYPE);\n+            Tensor<TInt32> matrix2 = outputs.get(1).expect(TInt32.DTYPE);\n+\n+        } catch (IndexOutOfBoundsException e) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDY5OTI5Ng=="}, "originalCommit": {"oid": "a69cfd9d8117fe6158a25e23133364b3b59b29ce"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzA0MDQ4Mg==", "bodyText": "I think it was added to the JDK to exist as a method reference for a null check (so people didn't have to make a lambda), not sure if it has any optimization benefits (probably not as if it's not inlined then it will be more expensive).", "url": "https://github.com/tensorflow/java/pull/30#discussion_r393040482", "createdAt": "2020-03-16T13:57:37Z", "author": {"login": "Craigacp"}, "path": "tensorflow-frameworks/tensorflow-data/src/main/java/org/tensorflow/data/Dataset.java", "diffHunk": "@@ -0,0 +1,180 @@\n+package org.tensorflow.data;\r\n+\r\n+import org.tensorflow.*;\r\n+import org.tensorflow.data.impl.*;\r\n+import org.tensorflow.op.Ops;\r\n+import org.tensorflow.op.data.AnonymousIterator;\r\n+import org.tensorflow.op.data.MakeIterator;\r\n+import org.tensorflow.tools.Shape;\r\n+import org.tensorflow.utils.Tuple2;\r\n+\r\n+import java.util.Iterator;\r\n+import java.util.List;\r\n+import java.util.Objects;\r\n+import java.util.stream.Collectors;\r\n+\r\n+/**\r\n+ * Represents a potentially large list of independent elements (samples), and\r\n+ * allows iteration and transformations to be performed across these elements.\r\n+ */\r\n+public abstract class Dataset implements Iterable<List<Output<?>>> {\r\n+  protected Ops tf;\r\n+  private List<DataType<?>> outputTypes;\r\n+  private List<Shape> outputShapes;\r\n+\r\n+  public Dataset(Ops tf, List<DataType<?>> outputTypes, List<Shape> outputShapes) {\r\n+    if (Objects.isNull(tf)) {\r", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDcwMTQ4MA=="}, "originalCommit": {"oid": "a69cfd9d8117fe6158a25e23133364b3b59b29ce"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzA0Mjk4NQ==", "bodyText": "Why do we want the default behaviour to drop the last batch? Most code should be agnostic to the batch size right?", "url": "https://github.com/tensorflow/java/pull/30#discussion_r393042985", "createdAt": "2020-03-16T14:01:18Z", "author": {"login": "Craigacp"}, "path": "tensorflow-frameworks/tensorflow-data/src/main/java/org/tensorflow/data/Dataset.java", "diffHunk": "@@ -0,0 +1,180 @@\n+package org.tensorflow.data;\r\n+\r\n+import org.tensorflow.*;\r\n+import org.tensorflow.data.impl.*;\r\n+import org.tensorflow.op.Ops;\r\n+import org.tensorflow.op.data.AnonymousIterator;\r\n+import org.tensorflow.op.data.MakeIterator;\r\n+import org.tensorflow.tools.Shape;\r\n+import org.tensorflow.utils.Tuple2;\r\n+\r\n+import java.util.Iterator;\r\n+import java.util.List;\r\n+import java.util.Objects;\r\n+import java.util.stream.Collectors;\r\n+\r\n+/**\r\n+ * Represents a potentially large list of independent elements (samples), and\r\n+ * allows iteration and transformations to be performed across these elements.\r\n+ */\r\n+public abstract class Dataset implements Iterable<List<Output<?>>> {\r\n+  protected Ops tf;\r\n+  private List<DataType<?>> outputTypes;\r\n+  private List<Shape> outputShapes;\r\n+\r\n+  public Dataset(Ops tf, List<DataType<?>> outputTypes, List<Shape> outputShapes) {\r\n+    if (Objects.isNull(tf)) {\r\n+      throw new IllegalArgumentException(\"Ops accessor cannot be null.\");\r\n+    } else if (outputTypes.size() != outputShapes.size()) {\r\n+      throw new IllegalArgumentException(\"`outputTypes` and `outputShapes` must have the same size.\");\r\n+    }\r\n+\r\n+    this.tf = tf;\r\n+    this.outputTypes = outputTypes;\r\n+    this.outputShapes = outputShapes;\r\n+  }\r\n+\r\n+  /**\r\n+   * Groups elements of this dataset into batches.\r\n+   *\r\n+   * @param batchSize     The number of desired elements per batch\r\n+   * @param dropLastBatch Whether to leave out the final batch if it has fewer\r\n+   *                      than `batchSize` elements.\r\n+   * @return A batched Dataset\r\n+   */\r\n+  public final Dataset batch(long batchSize, boolean dropLastBatch) {\r\n+    List<Shape> batchOutputShapes = getOutputShapes().stream()\r\n+        .map(s -> Shape.of(Utils.array(batchSize, s.asArray())))\r\n+        .collect(Collectors.toList());\r\n+    return new BatchDataset(tf, this.getVariant(), tf.val(batchSize),\r\n+        tf.val(dropLastBatch), this.getOutputTypes(), batchOutputShapes);\r\n+  }\r\n+\r\n+  /**\r\n+   * Groups elements of this dataset into batches.\r\n+   * Leaves out the last batch if it has fewer than `batchSize` elements.\r\n+   *\r\n+   * @param batchSize The number of desired elements per batch\r\n+   * @return A batched Dataset\r\n+   */\r\n+  public final Dataset batch(long batchSize) {\r", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a69cfd9d8117fe6158a25e23133364b3b59b29ce"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzA1MjcwMg==", "bodyText": "Do we need both Pair and Tuple2? Or indeed either of them?", "url": "https://github.com/tensorflow/java/pull/30#discussion_r393052702", "createdAt": "2020-03-16T14:14:51Z", "author": {"login": "Craigacp"}, "path": "tensorflow-frameworks/tensorflow-utils/src/main/java/org/tensorflow/utils/Pair.java", "diffHunk": "@@ -0,0 +1,33 @@\n+package org.tensorflow.utils;\r\n+\r\n+public class Pair<T> extends Tuple2<T, T> {\r", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a69cfd9d8117fe6158a25e23133364b3b59b29ce"}, "originalPosition": 3}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a69cfd9d8117fe6158a25e23133364b3b59b29ce", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/a69cfd9d8117fe6158a25e23133364b3b59b29ce", "committedDate": "2020-03-07T23:57:38Z", "message": "merge"}, "afterCommit": {"oid": "50bbd47093e8dbab28473267995e764904d3252d", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/50bbd47093e8dbab28473267995e764904d3252d", "committedDate": "2020-04-05T18:52:49Z", "message": "add javadoc for tf.data"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkwMzA1NTYx", "url": "https://github.com/tensorflow/java/pull/30#pullrequestreview-390305561", "createdAt": "2020-04-08T20:26:08Z", "commit": {"oid": "3b193cddfe94d332d29e4962ac3b40c2776d9cb1"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQyMDoyNjowOFrOGC_psw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQyMDozMjoxMVrOGC_1_g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc5MzIwMw==", "bodyText": "This class is package private, yet returned by a public method on Dataset. Should it be public?", "url": "https://github.com/tensorflow/java/pull/30#discussion_r405793203", "createdAt": "2020-04-08T20:26:08Z", "author": {"login": "Craigacp"}, "path": "tensorflow-frameworks/tensorflow-data/src/main/java/org/tensorflow/data/DatasetIterator.java", "diffHunk": "@@ -0,0 +1,214 @@\n+package org.tensorflow.data;\n+\n+import org.tensorflow.DataType;\n+import org.tensorflow.Graph;\n+import org.tensorflow.Operand;\n+import org.tensorflow.Output;\n+import org.tensorflow.op.Op;\n+import org.tensorflow.op.Ops;\n+import org.tensorflow.tools.Shape;\n+\n+import java.util.List;\n+\n+/**\n+ * Represents the state of an iteration through\n+ * a tf.data Datset.\n+ * <p>\n+ * Example: Iteration in graph mode.\n+ *\n+ * <pre>{@code\n+ *  // Create input tensors\n+ *  Operand<?> XTensor = tf.constant( ... );\n+ *  Operand<?> yTensor = tf.constant( ... );\n+ *\n+ *\n+ *  Dataset dataset = Dataset\n+ *          .fromTensorSlices(XTensor, yTensor);\n+ *          .batch(BATCH_SIZE);\n+ *\n+ *  DatasetIterator iterator = dataset.makeIterator();\n+ *  List<Output<?>> components = iterator.getNext();\n+ *  Operand<?> XBatch = components.get(0);\n+ *  Operand<?> yBatch = components.get(1);\n+ *\n+ *  // Build a TensorFlow graph that does something on each element.\n+ *  loss = computeModelLoss(X, y);\n+ *\n+ *  optimizer = ... // create an optimizer\n+ *  trainOp = optimizer.minimize(loss);\n+ *\n+ *  try (Session session = new Session(graph) {\n+ *      try {\n+ *          session.run(trainOp);\n+ *          ...\n+ *      } catch (IndexOutOfBoundsException e) {\n+ *          System.out.println(\"finished iterating.\");\n+ *          break;\n+ *      }\n+ *  }\n+ *\n+ * }</pre>\n+ * <p>\n+ * Example: Iteration in eager mode.\n+ *\n+ * <pre>{@code\n+ *  // Create input tensors\n+ *  Operand<?> XTensor = tf.constant( ... );\n+ *  Operand<?> yTensor = tf.constant( ... );\n+ *\n+ *  int BATCH_SIZE = ...\n+ *\n+ *  Dataset dataset = Dataset\n+ *          .fromTensorSlices(XTensor, yTensor)\n+ *          .batch(BATCH_SIZE);\n+ *  DatasetIterator iterator = dataset.makeIterator();\n+ *\n+ *  Optimizer optimizer = ... // create an optimizer\n+ *\n+ *  for (List<Output<?>> components : dataset) {\n+ *      Operand<?> XBatch = components.get(0);\n+ *      Operand<?> yBatch = components.get(1);\n+ *\n+ *      loss = computeModelLoss(X, y);\n+ *      trainOp = optimizer.minimize(loss);\n+ *  }\n+ * }</pre>\n+ */\n+class DatasetIterator {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3b193cddfe94d332d29e4962ac3b40c2776d9cb1"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc5MzQyNQ==", "bodyText": "There should be an explicit notice in this javadoc that DatasetIterator is not a java.util.Iterator. It's unfortunate that we can't really change the name entirely, but I guess it's best to go with what the TF Python functions are called when they mirror the functionality.", "url": "https://github.com/tensorflow/java/pull/30#discussion_r405793425", "createdAt": "2020-04-08T20:26:34Z", "author": {"login": "Craigacp"}, "path": "tensorflow-frameworks/tensorflow-data/src/main/java/org/tensorflow/data/DatasetIterator.java", "diffHunk": "@@ -0,0 +1,214 @@\n+package org.tensorflow.data;\n+\n+import org.tensorflow.DataType;\n+import org.tensorflow.Graph;\n+import org.tensorflow.Operand;\n+import org.tensorflow.Output;\n+import org.tensorflow.op.Op;\n+import org.tensorflow.op.Ops;\n+import org.tensorflow.tools.Shape;\n+\n+import java.util.List;\n+\n+/**\n+ * Represents the state of an iteration through\n+ * a tf.data Datset.\n+ * <p>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3b193cddfe94d332d29e4962ac3b40c2776d9cb1"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc5NjM1MA==", "bodyText": "Should these constructors be public? They don't validate that the iteratorResource is actually an iterator.", "url": "https://github.com/tensorflow/java/pull/30#discussion_r405796350", "createdAt": "2020-04-08T20:32:11Z", "author": {"login": "Craigacp"}, "path": "tensorflow-frameworks/tensorflow-data/src/main/java/org/tensorflow/data/DatasetIterator.java", "diffHunk": "@@ -0,0 +1,214 @@\n+package org.tensorflow.data;\n+\n+import org.tensorflow.DataType;\n+import org.tensorflow.Graph;\n+import org.tensorflow.Operand;\n+import org.tensorflow.Output;\n+import org.tensorflow.op.Op;\n+import org.tensorflow.op.Ops;\n+import org.tensorflow.tools.Shape;\n+\n+import java.util.List;\n+\n+/**\n+ * Represents the state of an iteration through\n+ * a tf.data Datset.\n+ * <p>\n+ * Example: Iteration in graph mode.\n+ *\n+ * <pre>{@code\n+ *  // Create input tensors\n+ *  Operand<?> XTensor = tf.constant( ... );\n+ *  Operand<?> yTensor = tf.constant( ... );\n+ *\n+ *\n+ *  Dataset dataset = Dataset\n+ *          .fromTensorSlices(XTensor, yTensor);\n+ *          .batch(BATCH_SIZE);\n+ *\n+ *  DatasetIterator iterator = dataset.makeIterator();\n+ *  List<Output<?>> components = iterator.getNext();\n+ *  Operand<?> XBatch = components.get(0);\n+ *  Operand<?> yBatch = components.get(1);\n+ *\n+ *  // Build a TensorFlow graph that does something on each element.\n+ *  loss = computeModelLoss(X, y);\n+ *\n+ *  optimizer = ... // create an optimizer\n+ *  trainOp = optimizer.minimize(loss);\n+ *\n+ *  try (Session session = new Session(graph) {\n+ *      try {\n+ *          session.run(trainOp);\n+ *          ...\n+ *      } catch (IndexOutOfBoundsException e) {\n+ *          System.out.println(\"finished iterating.\");\n+ *          break;\n+ *      }\n+ *  }\n+ *\n+ * }</pre>\n+ * <p>\n+ * Example: Iteration in eager mode.\n+ *\n+ * <pre>{@code\n+ *  // Create input tensors\n+ *  Operand<?> XTensor = tf.constant( ... );\n+ *  Operand<?> yTensor = tf.constant( ... );\n+ *\n+ *  int BATCH_SIZE = ...\n+ *\n+ *  Dataset dataset = Dataset\n+ *          .fromTensorSlices(XTensor, yTensor)\n+ *          .batch(BATCH_SIZE);\n+ *  DatasetIterator iterator = dataset.makeIterator();\n+ *\n+ *  Optimizer optimizer = ... // create an optimizer\n+ *\n+ *  for (List<Output<?>> components : dataset) {\n+ *      Operand<?> XBatch = components.get(0);\n+ *      Operand<?> yBatch = components.get(1);\n+ *\n+ *      loss = computeModelLoss(X, y);\n+ *      trainOp = optimizer.minimize(loss);\n+ *  }\n+ * }</pre>\n+ */\n+class DatasetIterator {\n+    public static final String EMPTY_SHARED_NAME = \"\";\n+\n+    private Ops tf;\n+\n+    private Operand<?> iteratorResource;\n+    private Op initializer;\n+\n+    private List<DataType<?>> outputTypes;\n+    private List<Shape> outputShapes;\n+\n+    /**\n+     * @param tf               Ops accessor corresponding to the same `ExecutionEnvironment`\n+     *                         as the `iteratorResource`.\n+     * @param iteratorResource An Operand representing the iterator\n+     *                         (e.g. constructed from `tf.data.iterator` or\n+     *                         `tf.data.anonymousIterator`)\n+     * @param initializer      An `Op` that should be run to initialize this iterator\n+     * @param outputTypes      A list of `DataType` objects corresponding to the\n+     *                         types of each component of a dataset element.\n+     * @param outputShapes     A list of `Shape` objects corresponding to the\n+     *                         shapes of each componenet of a dataset element.\n+     */\n+    public DatasetIterator(Ops tf, Operand<?> iteratorResource,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3b193cddfe94d332d29e4962ac3b40c2776d9cb1"}, "originalPosition": 100}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b912864f06686fff390aeb109bef6b0774d251d1", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/b912864f06686fff390aeb109bef6b0774d251d1", "committedDate": "2020-04-10T19:03:50Z", "message": "refactoring"}, "afterCommit": {"oid": "c3ffe8c61705e8d36d4a1c6f5a56085fd3beff38", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/c3ffe8c61705e8d36d4a1c6f5a56085fd3beff38", "committedDate": "2020-04-10T19:23:09Z", "message": "refactoring"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c3ffe8c61705e8d36d4a1c6f5a56085fd3beff38", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/c3ffe8c61705e8d36d4a1c6f5a56085fd3beff38", "committedDate": "2020-04-10T19:23:09Z", "message": "refactoring"}, "afterCommit": {"oid": "c8c50b8c61b52a4431a32488908d6d66563abd6f", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/c8c50b8c61b52a4431a32488908d6d66563abd6f", "committedDate": "2020-04-10T19:30:36Z", "message": "refactoring"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkxNzY4MzIz", "url": "https://github.com/tensorflow/java/pull/30#pullrequestreview-391768323", "createdAt": "2020-04-11T13:54:10Z", "commit": {"oid": "c8c50b8c61b52a4431a32488908d6d66563abd6f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMVQxMzo1NDoxMFrOGENYmA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMVQxMzo1NDoxMFrOGENYmA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzA2Njc3Ng==", "bodyText": "The starting comment tag is offset of one character (at least in GitHub review)", "url": "https://github.com/tensorflow/java/pull/30#discussion_r407066776", "createdAt": "2020-04-11T13:54:10Z", "author": {"login": "karllessard"}, "path": "tensorflow-core/tensorflow-core-api/src/main/java/org/tensorflow/Output.java", "diffHunk": "@@ -47,6 +47,24 @@ public Shape shape() {\n     return (DataType<T>)operation.dtype(index);\n   }\n \n+    /**", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c8c50b8c61b52a4431a32488908d6d66563abd6f"}, "originalPosition": 4}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkxNzY4NTgy", "url": "https://github.com/tensorflow/java/pull/30#pullrequestreview-391768582", "createdAt": "2020-04-11T13:57:02Z", "commit": {"oid": "c8c50b8c61b52a4431a32488908d6d66563abd6f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMVQxMzo1NzowM1rOGENZyA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMVQxMzo1NzowM1rOGENZyA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzA2NzA4MA==", "bodyText": "@dhruvrajan , there is a few typos in that README but before going through them, is this PR ready to be merged or it is still work in progress?", "url": "https://github.com/tensorflow/java/pull/30#discussion_r407067080", "createdAt": "2020-04-11T13:57:03Z", "author": {"login": "karllessard"}, "path": "tensorflow-frameworks/tensorflow-data/README.md", "diffHunk": "@@ -0,0 +1,220 @@\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c8c50b8c61b52a4431a32488908d6d66563abd6f"}, "originalPosition": 1}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkxNzY4Njcw", "url": "https://github.com/tensorflow/java/pull/30#pullrequestreview-391768670", "createdAt": "2020-04-11T13:57:53Z", "commit": {"oid": "c8c50b8c61b52a4431a32488908d6d66563abd6f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMVQxMzo1Nzo1M1rOGENaNQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMVQxMzo1Nzo1M1rOGENaNQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzA2NzE4OQ==", "bodyText": "In case of simple vectors, you probably want to go with NdArrays.vectorOf(0.0f, 1.0f, 1.0f, 0.0f);", "url": "https://github.com/tensorflow/java/pull/30#discussion_r407067189", "createdAt": "2020-04-11T13:57:53Z", "author": {"login": "karllessard"}, "path": "tensorflow-frameworks/tensorflow-data/README.md", "diffHunk": "@@ -0,0 +1,220 @@\n+\n+NOTE: This readme follows the discussion of this [RFC]()\n+\n+\n+Tensorflow-Data (Java)\n+==\n+\n+TensorFlow Data provides utilities and APIsfor loading data of various formats\n+, and preparing datasets for use in training and using deep learning models\n+. This package\n+ provides a\n+ simple API for configuring and iterating over\n+ datasets in both \"graph\" and \"eager\" mode.\n+\n+Usage\n+--\n+\n+The `Dataset` abstraction represents a sequence of elements, where each element in the sequence is a collection (`List`) of tensors (or, \"components\").\n+\n+\n+\n+The `Dataset` class represents a sequence of elements which can be iterated over and\n+transformed. Each element is a list of \"output\" operands, represented by the type `List<Output<?>>`. \n+\n+Note: An `Output` is a symbolic handle to a tensor produced by a TensorFlow op. In graph\n+mode, `Output` objects will not have a concrete `Tensor` value unless all dependent operations\n+are run in a `Session` (this is done \"in-real-time\" in eager mode).\n+\n+### Construction\n+\n+Datasets can be constructed either directly from a data source (e.g. a list of tensors representing the components of the dataset), or as a transformation on an existing dataset.\n+\n+#### From Data Source\n+\n+To construct a dataset from a list of tensor components, use \n+`Dataset.fromTensorSlices( ... )`. For example, say we are working\n+with a standard feature/label dataset which has 4 elements.\n+\n+```java\n+FloatNdArray features = StdArrays.ndCopyOf(\n+        new float[][] {\n+        {1, 2, 3},\n+        {4, 5, 6},\n+        {7, 8, 9},\n+        {10, 11, 12}\n+});\n+\n+FloatNdArray labels = StdArrays.ndCopyOf(\n+    new float[] {\n+        0,\n+        1,\n+        1,\n+        0\n+});", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c8c50b8c61b52a4431a32488908d6d66563abd6f"}, "originalPosition": 54}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkxNzcwODM0", "url": "https://github.com/tensorflow/java/pull/30#pullrequestreview-391770834", "createdAt": "2020-04-11T14:28:26Z", "commit": {"oid": "c8c50b8c61b52a4431a32488908d6d66563abd6f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMVQxNDoyODoyNlrOGENmaQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMVQxNDoyODoyNlrOGENmaQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzA3MDMxMw==", "bodyText": "I think we talked previously to add a method in the Ops or Scope class telling if we are in graph mode or not without the need of instanceof (returning either a boolean or an enum to support future execution environments). Should we do it in this PR as well?", "url": "https://github.com/tensorflow/java/pull/30#discussion_r407070313", "createdAt": "2020-04-11T14:28:26Z", "author": {"login": "karllessard"}, "path": "tensorflow-frameworks/tensorflow-data/src/main/java/org/tensorflow/data/Dataset.java", "diffHunk": "@@ -0,0 +1,210 @@\n+package org.tensorflow.data;\r\n+\r\n+import org.tensorflow.*;\r\n+import org.tensorflow.data.impl.BatchDataset;\r\n+import org.tensorflow.data.impl.SkipDataset;\r\n+import org.tensorflow.data.impl.TakeDataset;\r\n+import org.tensorflow.data.impl.TensorSliceDataset;\r\n+import org.tensorflow.op.Op;\r\n+import org.tensorflow.op.Ops;\r\n+import org.tensorflow.tools.Shape;\r\n+\r\n+import java.util.Iterator;\r\n+import java.util.List;\r\n+import java.util.Objects;\r\n+import java.util.stream.Collectors;\r\n+\r\n+/**\r\n+ * Represents a potentially large list of independent elements (samples), and\r\n+ * allows iteration and transformations to be performed across these elements.\r\n+ */\r\n+public abstract class Dataset implements Iterable<List<Output<?>>> {\r\n+    protected Ops tf;\r\n+    private List<DataType<?>> outputTypes;\r\n+    private List<Shape> outputShapes;\r\n+\r\n+    public Dataset(Ops tf, List<DataType<?>> outputTypes, List<Shape> outputShapes) {\r\n+        if (Objects.isNull(tf)) {\r\n+            throw new IllegalArgumentException(\"Ops accessor cannot be null.\");\r\n+        } else if (outputTypes.size() != outputShapes.size()) {\r\n+            throw new IllegalArgumentException(\"`outputTypes` and `outputShapes` must have the same size.\");\r\n+        }\r\n+\r\n+        this.tf = tf;\r\n+        this.outputTypes = outputTypes;\r\n+        this.outputShapes = outputShapes;\r\n+    }\r\n+\r\n+    /**\r\n+     * Groups elements of this dataset into batches.\r\n+     *\r\n+     * @param batchSize     The number of desired elements per batch\r\n+     * @param dropLastBatch Whether to leave out the final batch if it has fewer\r\n+     *                      than `batchSize` elements.\r\n+     * @return A batched Dataset\r\n+     */\r\n+    public final Dataset batch(long batchSize, boolean dropLastBatch) {\r\n+        List<Shape> batchOutputShapes = getOutputShapes().stream()\r\n+                .map(s -> Shape.of(batchSize, s.asArray()))\r\n+                .collect(Collectors.toList());\r\n+\r\n+\r\n+        return new BatchDataset(tf, this.getVariant(), tf.constant(batchSize),\r\n+                tf.constant(dropLastBatch), this.getOutputTypes(), batchOutputShapes);\r\n+    }\r\n+\r\n+    /**\r\n+     * Groups elements of this dataset into batches.\r\n+     * Includes the last batch, even if it has fewer than `batchSize` elements.\r\n+     *\r\n+     * @param batchSize The number of desired elements per batch\r\n+     * @return A batched Dataset\r\n+     */\r\n+    public final Dataset batch(long batchSize) {\r\n+        return batch(batchSize, false);\r\n+    }\r\n+\r\n+    /**\r\n+     * Returns a new `Dataset` which skips `count` initial elements from this\r\n+     * dataset\r\n+     *\r\n+     * @param count The number of elements to `skip` to form the new dataset.\r\n+     * @return A new Dataset with `count` elements removed.\r\n+     */\r\n+    public final Dataset skip(long count) {\r\n+        return new SkipDataset(tf, this.getVariant(), tf.constant(count), this.getOutputTypes(), this.getOutputShapes());\r\n+    }\r\n+\r\n+    /**\r\n+     * Returns a new `Dataset` with only the first `count` elements from this\r\n+     * dataset.\r\n+     *\r\n+     * @param count The number of elements to \"take\" from this dataset.\r\n+     * @return A new Dataset containing the first `count` elements from this dataset.\r\n+     */\r\n+    public final Dataset take(long count) {\r\n+        return new TakeDataset(tf, this.getVariant(), tf.constant(count), this.getOutputTypes(), this.getOutputShapes());\r\n+    }\r\n+\r\n+    /**\r\n+     * Creates an iterator which iterates through all batches of this Dataset in an eager fashion.\r\n+     * Each batch is a list of components, returned as `Output` objects.\r\n+     * <p>\r\n+     * This method enables for-each iteration through batches when running\r\n+     * in eager mode. For Graph mode batch iteration, see `makeOneShotIterator`.\r\n+     *\r\n+     * @return an Iterator through batches of this dataset.\r\n+     */\r\n+    @Override\r\n+    public Iterator<List<Output<?>>> iterator() {\r\n+\r\n+        if (!(tf.scope().env() instanceof EagerSession)) {\r\n+            throw new UnsupportedOperationException(\"Cannot iterate through a dataset in graph mode.\");\r\n+        }\r\n+\r\n+        DatasetIterator iterator = makeOneShotIterator();\r\n+\r\n+        return new Iterator<List<Output<?>>>() {\r\n+            private List<Output<?>> tryNext = getNext();\r\n+\r\n+            private List<Output<?>> getNext() {\r\n+                try {\r\n+                    return iterator.getNext();\r\n+                } catch (IndexOutOfBoundsException e) {\r\n+                    return null;\r\n+                }\r\n+            }\r\n+\r\n+            @Override\r\n+            public boolean hasNext() {\r\n+                return tryNext != null;\r\n+            }\r\n+\r\n+            @Override\r\n+            public List<Output<?>> next() {\r\n+                List<Output<?>> result = tryNext;\r\n+                tryNext = getNext();\r\n+                return result;\r\n+            }\r\n+        };\r\n+    }\r\n+\r\n+    /**\r\n+     * Creates a `DatasetIterator` that can be used to iterate\r\n+     * over elements of this dataset.\r\n+     *\r\n+     * This iterator will have to be initialized with a call\r\n+     * to `iterator.makeInitializer(Dataset)` before elements\r\n+     * can be retreived in a loop.\r\n+     *\r\n+     * @return A new `DatasetIterator` based on this dataset's structure.\r\n+     */\r\n+    public DatasetIterator makeInitializeableIterator() {\r\n+        return DatasetIterator\r\n+                .fromStructure(tf, outputTypes, outputShapes);\r\n+    }\r\n+\r\n+    /**\r\n+     * Creates a `DatasetIterator` that can be used to iterate over\r\n+     * elements of this dataset. Using `makeOneShotIterator` ensures\r\n+     * that the iterator is\r\n+     * automatically initialized on this dataset.\r\n+     *skips\r\n+     * In graph mode, the initializer op will be added to the Graph's\r\n+     * intitializer list, which must be run via `tf.init()`:\r\n+     *\r\n+     * Ex:\r\n+     * <pre>\r\n+     *     try (Session session = new Session(graph) {\r\n+     *         // Immediately run initializers\r\n+     *         session.run(tf.init());\r\n+     *     }\r\n+     * </pre>\r\n+     *\r\n+     * In eager mode, the initializer will be run automatically as a result\r\n+     * of this call.\r\n+     *\r\n+     * @return A new `DatasetIterator` based on this dataset's structure.\r\n+     */\r\n+    public DatasetIterator makeOneShotIterator() {\r\n+        DatasetIterator iterator = makeInitializeableIterator();\r\n+        Op initializer = iterator.makeInitializer(this);\r\n+        if (tf.scope().env() instanceof Graph) tf.initAdd(initializer);\r", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c8c50b8c61b52a4431a32488908d6d66563abd6f"}, "originalPosition": 172}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkxNzcxMjI2", "url": "https://github.com/tensorflow/java/pull/30#pullrequestreview-391771226", "createdAt": "2020-04-11T14:33:15Z", "commit": {"oid": "c8c50b8c61b52a4431a32488908d6d66563abd6f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMVQxNDozMzoxNVrOGENocA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMVQxNDozMzoxNVrOGENocA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzA3MDgzMg==", "bodyText": "Oops, I don't think this reformatting was meant to be part of the PR", "url": "https://github.com/tensorflow/java/pull/30#discussion_r407070832", "createdAt": "2020-04-11T14:33:15Z", "author": {"login": "karllessard"}, "path": "tensorflow-tools/src/main/java/org/tensorflow/tools/Shape.java", "diffHunk": "@@ -21,122 +21,159 @@\n ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c8c50b8c61b52a4431a32488908d6d66563abd6f"}, "originalPosition": 1}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkxNzc3MjU2", "url": "https://github.com/tensorflow/java/pull/30#pullrequestreview-391777256", "createdAt": "2020-04-11T15:47:44Z", "commit": {"oid": "c8c50b8c61b52a4431a32488908d6d66563abd6f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMVQxNTo0Nzo0NVrOGEOHXw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMVQxNTo0Nzo0NVrOGEOHXw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzA3ODc1MQ==", "bodyText": "I think we can get avoid having this exception as part of the normal workflow if we use tf.data.iteratorGetNextAsOptional instead of tf.data.iteratorGetNext, but that might require other changes as well in the graph so it is handle properly.\nMaybe the framework can automatically add what is required to do it? I did not went very far in my analysis, I just dropped the idea here so you can check if it make sense or not.", "url": "https://github.com/tensorflow/java/pull/30#discussion_r407078751", "createdAt": "2020-04-11T15:47:45Z", "author": {"login": "karllessard"}, "path": "tensorflow-frameworks/tensorflow-data/README.md", "diffHunk": "@@ -0,0 +1,220 @@\n+\n+NOTE: This readme follows the discussion of this [RFC]()\n+\n+\n+Tensorflow-Data (Java)\n+==\n+\n+TensorFlow Data provides utilities and APIsfor loading data of various formats\n+, and preparing datasets for use in training and using deep learning models\n+. This package\n+ provides a\n+ simple API for configuring and iterating over\n+ datasets in both \"graph\" and \"eager\" mode.\n+\n+Usage\n+--\n+\n+The `Dataset` abstraction represents a sequence of elements, where each element in the sequence is a collection (`List`) of tensors (or, \"components\").\n+\n+\n+\n+The `Dataset` class represents a sequence of elements which can be iterated over and\n+transformed. Each element is a list of \"output\" operands, represented by the type `List<Output<?>>`. \n+\n+Note: An `Output` is a symbolic handle to a tensor produced by a TensorFlow op. In graph\n+mode, `Output` objects will not have a concrete `Tensor` value unless all dependent operations\n+are run in a `Session` (this is done \"in-real-time\" in eager mode).\n+\n+### Construction\n+\n+Datasets can be constructed either directly from a data source (e.g. a list of tensors representing the components of the dataset), or as a transformation on an existing dataset.\n+\n+#### From Data Source\n+\n+To construct a dataset from a list of tensor components, use \n+`Dataset.fromTensorSlices( ... )`. For example, say we are working\n+with a standard feature/label dataset which has 4 elements.\n+\n+```java\n+FloatNdArray features = StdArrays.ndCopyOf(\n+        new float[][] {\n+        {1, 2, 3},\n+        {4, 5, 6},\n+        {7, 8, 9},\n+        {10, 11, 12}\n+});\n+\n+FloatNdArray labels = StdArrays.ndCopyOf(\n+    new float[] {\n+        0,\n+        1,\n+        1,\n+        0\n+});\n+```\n+\n+A dataset can be constructed from a list of the constant `Operand`s generated\n+from this dataset, and a list of `DataType` objects corresponding\n+to the type of each component:\n+\n+Note: Each of the input components must share the same first \"batch\" dimension.\n+\n+```java\n+Ops tf = // ... TensorFlow Ops accessor (either graph or eager)\n+Dataset dataset = Dataset.fromTensorSlices(\n+    Arrays.asList(tf.constant(features), tf.constant(labels)),\n+    Arrays.asList(TInt32.DTYPE, TInt32.DTYPE)\n+);\n+```\n+\n+\n+Other data sources are also possible, using `tf.data` ops; these include TFRecord files, CSV files, and more.\n+\n+#### Transformations on Existing Datasets\n+\n+Once a dataset has been created from a data source it can be transformed by calling\n+methods on the `Dataset` object. For example, to group elements in the above dataset into batches of size `2`, use `Dataset.batch(int batchSize)`:\n+\n+```java\n+dataset = dataset.batch(2)\n+```\n+\n+Dataset transformations alter both the values and shapes of the original elements, and\n+return a *new* `Dataset` object.\n+\n+In this case, the original dataset had 4 elements of shape `[features: (3,) labels: (1,)]`.\n+Once the `.batch` transformation is applied, the new dataset has 2 elements (batches) of shape `[features: (2, 3), labels: (2, 1)]`.\n+\n+Similar transformations include `.skip`, `.take`, `.map`, `.filter`, etc.\n+\n+\n+### Iterating over Dataset Elements\n+\n+The primary use of a dataset is for iteration over its elements.\n+Each row (or batch) element is represented as a list of tensor components, with\n+type `List<Output<?>>`. The tensor components of this elements can be accessed using `List.get(int index)`.\n+\n+It is recommended to use `Tensor.expect(DataType<?> dtype)` to restore types\n+to the retrieved tensors.\n+\n+#### Using DatastetIterator\n+The `DatasetIterator` class provides abstractions for creating and using\n+iterators in graph and eager mode. These will be explained here; however\n+end-users should only interact with `Iterator` objects through the methods\n+provided in the `Dataset` class (examples to follow).\n+\n+To construct an iterator for a dataset of a specific structure, use\n+the static method `Iterator.fromStructure(Ops tf, List<DataType<?>> outputTypes, List<Shape> outputShapes)`. This creates a `DatasetIterator` object\n+which can be used with any dataset of a matching structure.\n+\n+Once a `DatasetIterator` is created, it can be initialized on a `Dataset` intsance using `Iterator.makeInitializer(Dataset dataset)`. This will initialize (or re-initialize) the iterator to start at the beginning\n+of this dataset.\n+\n+The `Iterator.getNext()` method can be used to retrieve dataset elements.\n+In eager mode, each call to `getNext()` will return the next dataset element as\n+as `List<Output<?>>`. In graph mode, this method should be called just once\n+to retrieve the components. These can be fed into additional operations as\n+a computation Graph is built. On successive `session.run` operations, the\n+successive dataset elements will be automatically passed through the graph.\n+\n+\n+#### Eager Mode: Iterable\n+The `Dataset` class implements the `Iterable` interface, so in\n+eager mode, iteration over dataset elements is possible using a standard for-each loop (this is a wrapper around `DatasetIterator` constructs).\n+\n+Using the same example dataset from above, dataset elements can be extracted and\n+used as follows:\n+```java\n+// Use default EagerSession\n+Ops tf = Ops.create()\n+\n+// Dataset of (features, labels) from above\n+Dataset dataset = Dataset.fromTensorSlices(tf, ... );\n+\n+// batch dataset elements into batches of size 2\n+dataset = dataset.batch(2);\n+\n+Optmizer optimizer = ... // TF Optimizer\n+\n+for (List<Output<?>> batch : dataset) {\n+    Operand<?> featureBatch = element.get(0);\n+    Operand<?> labelBatch = element.get(1);\n+\n+    // Perform batch-wise computations on featureBatch and labelBatch\n+    // e.g. computing model losses, running optimizers.\n+\n+    Operand<TFloat32> loss = myModelLoss(featureBatch, labelBatch);\n+\n+    optimizer.minimize(loss);\n+    \n+    ...\n+}   \n+\n+```\n+\n+#### Graph Mode: OneShotIterator\n+\n+The above code will not work in graph mode, which requires the use of `Session`s\n+to run the computations. In graph mode, datasets can be iterated over using the `DatasetIterator` abstraction, and a while loop.\n+\n+Once the iterator is initialized, repeated calls to `Session.run` will populate the components with new values, until all elements have\n+been retrieved. After this, `Session.run` will result in an `IndexOutOfBounds` exception.\n+\n+Note that the make-iterator operation can be re-run to re-initialize\n+the iterator, to iterate over the dataset a second time.\n+\n+```java\n+try (Graph graph = new Graph()) {\n+    // Graph mode Ops accessor\n+    Ops tf = Ops.create(graph)\n+\n+    // Dataset of (features, labels) from above\n+    Dataset dataset = Dataset.fromTensorSlices(tf, ... );\n+\n+    // batch dataset elements into batches of size 2\n+    dataset = dataset.batch(2); \n+\n+    // makeOneShotIterator() automatically adds the \n+    // iterator initializer (MakeIterator) Op to the Graph\n+    // initializers list. Make sure to run `session.run(tf.init())`\n+    // first!\n+    DatasetIterator iterator = dataset.makeOneShotIterator();\n+    List<Output<?>> batch = iterator.getNext();\n+\n+    Operand<?> features = batch.get(0);\n+    Operand<?> labels = batch.get(1);\n+\n+    // Run additional computations on `features` and `labels`,\n+    // e.g. computing model losses, instantiating Optimizers\n+\n+    Optimizer optimizer = ... // TF Optimizer \n+    Operand<TFloat32> loss = myModelLoss(features, labels);\n+    \n+    Op trainOp = optimizer.minimize(loss)\n+\n+    // instantiate graph-mode session\n+    try (Session session = new Session(graph)) {\n+        // Run graph initializers (and the iterator initializer)\n+        session.run(tf.init());\n+\n+        // Iterate over dataset elements\n+        while (true) {\n+            try {\n+                // Run training ops / fetch loss\n+                List<Tensor<?>> outputs = session.runner()\n+                    .addTarget(trainOp)\n+                    .fetch(loss)\n+                    .run();\n+\n+                ...\n+\n+            } catch (IndexOutOfBoundsException e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c8c50b8c61b52a4431a32488908d6d66563abd6f"}, "originalPosition": 212}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f61c5938f463611314e3d1bdd98f93feaccdf6fd", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/f61c5938f463611314e3d1bdd98f93feaccdf6fd", "committedDate": "2020-04-11T21:47:48Z", "message": "update README"}, "afterCommit": {"oid": "692ffd60e26794ebbbd9c7eeedcf4ded37e04789", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/692ffd60e26794ebbbd9c7eeedcf4ded37e04789", "committedDate": "2020-04-11T22:05:44Z", "message": "use 2-space indentation"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "464a8d5967d4f982c8f3e262485d593e68561afe", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/464a8d5967d4f982c8f3e262485d593e68561afe", "committedDate": "2020-04-11T22:12:04Z", "message": "remove wildcard imports from Dataset"}, "afterCommit": {"oid": "4546d4d010622cfba5312dd401690a73a9a9cee7", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/4546d4d010622cfba5312dd401690a73a9a9cee7", "committedDate": "2020-04-14T02:28:08Z", "message": "simple refactor"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkzNzk3MTkw", "url": "https://github.com/tensorflow/java/pull/30#pullrequestreview-393797190", "createdAt": "2020-04-15T13:55:28Z", "commit": {"oid": "88f3ae9f00eef133a3bf24fa95b82f8296f5c150"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQxMzo1NToyOFrOGF65Sw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQxMzo1NToyOFrOGF65Sw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODg2MTAwMw==", "bodyText": "Mmh, I was expecting those changes to come in, from our conversation with @Craigacp , I thought we were more heading on just finding a way to prevent to user to catch an exception as part of the control flow.\nI don't discard this idea of \"popping\" the tensors out of the Run object but there might be more thinking to do around this and it is not required for supporting the Data API.", "url": "https://github.com/tensorflow/java/pull/30#discussion_r408861003", "createdAt": "2020-04-15T13:55:28Z", "author": {"login": "karllessard"}, "path": "tensorflow-core/tensorflow-core-api/src/main/java/org/tensorflow/Session.java", "diffHunk": "@@ -485,6 +484,51 @@ public void run(Op op) {\n      * this field may be replaced by more type-safe equivalents at any time.\n      */\n     public RunMetadata metadata;\n+\n+    /**\n+     * Current `pop` index in the `outputs` list.\n+     */\n+    private int index = 0;\n+\n+    Run(List<Tensor<?>> outputs, RunMetadata metadata) {\n+      this.outputs = outputs;\n+      this.metadata = metadata;\n+    }\n+\n+    Run(List<Tensor<?>> outputs) {\n+      this.outputs = outputs;\n+    }\n+\n+    public <T extends TType> Tensor<T> pop(DataType<T> dtype) {\n+      return outputs.get(index++).expect(dtype);\n+    }\n+\n+    public int popInt(long... coordinates) {\n+      return pop(TInt32.DTYPE).data().getInt(coordinates);\n+    }\n+\n+    public long popLong(long... coordinates) {\n+      return pop(TInt64.DTYPE).data().getLong(coordinates);\n+    }\n+\n+    public float popFloat16(long... coordinates) {\n+      return pop(TFloat16.DTYPE).data().getFloat(coordinates);\n+    }\n+\n+    public float popFloat(long... coordinates) {\n+      return pop(TFloat32.DTYPE).data().getFloat(coordinates);\n+    }\n+\n+    public double popDouble(long... coordinates) {\n+      return pop(TFloat64.DTYPE).data().getDouble(coordinates);\n+    }\n+\n+    @Override\n+    public void close() {\n+      for (Tensor<?> tensor : this.outputs) {\n+        tensor.close();\n+      }\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "88f3ae9f00eef133a3bf24fa95b82f8296f5c150"}, "originalPosition": 89}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "88f3ae9f00eef133a3bf24fa95b82f8296f5c150", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/88f3ae9f00eef133a3bf24fa95b82f8296f5c150", "committedDate": "2020-04-15T06:40:19Z", "message": "add Session.Run with pop() methods"}, "afterCommit": {"oid": "b12686398b1a860549ea39955ece8aee266ab7f4", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/b12686398b1a860549ea39955ece8aee266ab7f4", "committedDate": "2020-04-19T16:18:15Z", "message": "Add repeat() method to Session"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b12686398b1a860549ea39955ece8aee266ab7f4", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/b12686398b1a860549ea39955ece8aee266ab7f4", "committedDate": "2020-04-19T16:18:15Z", "message": "Add repeat() method to Session"}, "afterCommit": {"oid": "baaf84c65adf8a11170d7b6585dd4831014e74fd", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/baaf84c65adf8a11170d7b6585dd4831014e74fd", "committedDate": "2020-04-19T16:39:27Z", "message": "Add repeat() method to Session"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0da237928996ea702d0c1f6cabd38e09b22353d0", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/0da237928996ea702d0c1f6cabd38e09b22353d0", "committedDate": "2020-04-19T21:46:23Z", "message": "Merge optimizers and datasets into tensorflow-framework"}, "afterCommit": {"oid": "ce003dd7e16059dd59371e1459238f861464c3f3", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/ce003dd7e16059dd59371e1459238f861464c3f3", "committedDate": "2020-04-19T21:48:45Z", "message": "Merge optimizers and datasets into tensorflow-framework"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ce003dd7e16059dd59371e1459238f861464c3f3", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/ce003dd7e16059dd59371e1459238f861464c3f3", "committedDate": "2020-04-19T21:48:45Z", "message": "Merge optimizers and datasets into tensorflow-framework"}, "afterCommit": {"oid": "d6a47e29d044de336c9e621724e8367c45c0d263", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/d6a47e29d044de336c9e621724e8367c45c0d263", "committedDate": "2020-04-19T21:51:03Z", "message": "Merge optimizers and datasets into tensorflow-framework"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "49f16290a5d0f919ca2e4c67cb2aeddefbba9b04", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/49f16290a5d0f919ca2e4c67cb2aeddefbba9b04", "committedDate": "2020-04-23T15:23:34Z", "message": "Fix tests to use new exceptions from tensorflow-core"}, "afterCommit": {"oid": "579ebc2021672de4063c58de608b910106b913c4", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/579ebc2021672de4063c58de608b910106b913c4", "committedDate": "2020-04-23T15:33:55Z", "message": "Fix tests to use new exceptions from tensorflow-core"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAwNTQ0NzE3", "url": "https://github.com/tensorflow/java/pull/30#pullrequestreview-400544717", "createdAt": "2020-04-26T20:16:16Z", "commit": {"oid": "41d1b563c857107b549c80bc16a3c2cdf52a275f"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 25, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNlQyMDoxNjoxNlrOGMJfXw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNlQyMTowNDoxMVrOGMKChQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTM5MTU4Mw==", "bodyText": "Maybe rename this enum to Type? (so it is referenced as ExecutionEnvironment.Type instead of ExecutionEnvironment.Environments)", "url": "https://github.com/tensorflow/java/pull/30#discussion_r415391583", "createdAt": "2020-04-26T20:16:16Z", "author": {"login": "karllessard"}, "path": "tensorflow-core/tensorflow-core-api/src/main/java/org/tensorflow/ExecutionEnvironment.java", "diffHunk": "@@ -18,6 +18,11 @@\n /** Defines an environment for creating and executing TensorFlow {@link Operation}s. */\n public interface ExecutionEnvironment {\n \n+  enum Environments {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "41d1b563c857107b549c80bc16a3c2cdf52a275f"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTM5MjM2MA==", "bodyText": "We shouldn't use wildcards in non-static imports, but looking again it seems that these new imports are not required anymore (probably a left over from the pop* methods you added before), can you please cleanup your list of imports?", "url": "https://github.com/tensorflow/java/pull/30#discussion_r415392360", "createdAt": "2020-04-26T20:20:22Z", "author": {"login": "karllessard"}, "path": "tensorflow-core/tensorflow-core-api/src/main/java/org/tensorflow/Session.java", "diffHunk": "@@ -41,6 +48,8 @@\n import org.tensorflow.proto.framework.ConfigProto;\n import org.tensorflow.proto.framework.RunMetadata;\n import org.tensorflow.proto.framework.RunOptions;\n+import org.tensorflow.types.*;\n+import org.tensorflow.types.family.TType;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "41d1b563c857107b549c80bc16a3c2cdf52a275f"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTM5MjkzOA==", "bodyText": "Just to double check, all those reformatting commits, are they the result of applying the Google Java Style formatting settings over the code or just personal settings?", "url": "https://github.com/tensorflow/java/pull/30#discussion_r415392938", "createdAt": "2020-04-26T20:23:03Z", "author": {"login": "karllessard"}, "path": "tensorflow-core/tensorflow-core-api/src/main/java/org/tensorflow/Session.java", "diffHunk": "@@ -135,21 +148,21 @@ public void close() {\n    * Run {@link Operation}s and evaluate {@link Tensor Tensors}.\n    *\n    * <p>A Runner runs the necessary graph fragments to execute every {@link Operation} required to\n-   * evaluate the {@link Tensor Tensors} to fetch. The {@link #feed(String,int,Tensor)} call allows\n+   * evaluate the {@link Tensor Tensors} to fetch. The {@link #feed(String, int, Tensor)} call allows\n    * callers to override the value of {@link Tensor Tensors} in the graph by substituting the\n    * provided {@link Tensor Tensors} for the outputs of the operations provided to {@link\n-   * #feed(String,int,Tensor)}.\n+   * #feed(String, int, Tensor)}.\n    */\n   public final class Runner {\n     /**\n      * Avoid evaluating {@code operation} and substitute {@code t} for the value it produces.\n      *\n      * @param operation Is either the string name of the operation, in which case this method is a\n-     *     shorthand for {@code feed(operation, 0)}, or it is a string of the form\n-     *     <tt>operation_name:output_index</tt> , in which case this method acts like {@code\n-     *     feed(operation_name, output_index)}. These colon-separated names are commonly used in the\n-     *     {@code SignatureDef} protocol buffer messages that are included in {@link\n-     *     SavedModelBundle#metaGraphDef()}.\n+     *                  shorthand for {@code feed(operation, 0)}, or it is a string of the form\n+     *                  <tt>operation_name:output_index</tt> , in which case this method acts like {@code\n+     *                  feed(operation_name, output_index)}. These colon-separated names are commonly used in the\n+     *                  {@code SignatureDef} protocol buffer messages that are included in {@link\n+     *                  SavedModelBundle#metaGraphDef()}.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "41d1b563c857107b549c80bc16a3c2cdf52a275f"}, "originalPosition": 90}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTM5MzA5NA==", "bodyText": "This is not used anymore.", "url": "https://github.com/tensorflow/java/pull/30#discussion_r415393094", "createdAt": "2020-04-26T20:23:59Z", "author": {"login": "karllessard"}, "path": "tensorflow-core/tensorflow-core-api/src/main/java/org/tensorflow/Session.java", "diffHunk": "@@ -485,6 +499,31 @@ public void run(Op op) {\n      * this field may be replaced by more type-safe equivalents at any time.\n      */\n     public RunMetadata metadata;\n+\n+    /**\n+     * Current `pop` index in the `outputs` list.\n+     */\n+    private int index = 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "41d1b563c857107b549c80bc16a3c2cdf52a275f"}, "originalPosition": 192}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTM5MzQyMA==", "bodyText": "while we are at it, should we move this guy to the exceptions package as well?", "url": "https://github.com/tensorflow/java/pull/30#discussion_r415393420", "createdAt": "2020-04-26T20:25:55Z", "author": {"login": "karllessard"}, "path": "tensorflow-core/tensorflow-core-api/src/main/java/org/tensorflow/TensorFlowException.java", "diffHunk": "@@ -15,11 +15,14 @@\n \n package org.tensorflow;\n \n-/** Unchecked exception thrown by TensorFlow core classes */\n-public final class TensorFlowException extends RuntimeException {\n+/**\n+ * Unchecked exception thrown by TensorFlow core classes\n+ */\n+public class TensorFlowException extends RuntimeException {\n   public TensorFlowException(String message) {\n     super(message);\n   }\n+\n   public TensorFlowException(String message, Throwable cause) {\n     super(message, cause);\n   }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "41d1b563c857107b549c80bc16a3c2cdf52a275f"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTM5NTM4OA==", "bodyText": "Oh I didn't know we were changing all exceptions here, I thought we were only doing it for OutOfRangeException, @Craigacp  was it what you had in mind as well?\nChanging all of them might be tougher for our clients migrating for 1.* to 2.* as they are all thrown as runtime exception... another idea would have been then to extends each of these TF errors to known runtime exceptions (i.e. TFOutOfRangeException would extends from IndexOutOfBoundsException instead of TensorFlowException).\nIf we are keeping this new mapping, then I suggest that we have all distinct exceptions for each possible error (i.e. there should be  a TFResourceExhaustedException and a TFUnauthenticatedException as well)", "url": "https://github.com/tensorflow/java/pull/30#discussion_r415395388", "createdAt": "2020-04-26T20:36:14Z", "author": {"login": "karllessard"}, "path": "tensorflow-core/tensorflow-core-api/src/main/java/org/tensorflow/internal/c_api/AbstractTF_Status.java", "diffHunk": "@@ -69,17 +75,17 @@ public void throwExceptionIfNotOK() {\n         case TF_OK:\n           break;\n         case TF_INVALID_ARGUMENT:\n-          throw new IllegalArgumentException(TF_Message(s).getString());\n+          throw new TFInvalidArgumentException(TF_Message(s).getString());\n         case TF_UNAUTHENTICATED:\n         case TF_PERMISSION_DENIED:\n-          throw new SecurityException(TF_Message(s).getString());\n+          throw new TFPermissionDeniedException(TF_Message(s).getString());\n         case TF_RESOURCE_EXHAUSTED:\n         case TF_FAILED_PRECONDITION:\n-          throw new IllegalStateException(TF_Message(s).getString());\n+          throw new TFFailedPreconditionException(TF_Message(s).getString());\n         case TF_OUT_OF_RANGE:\n-          throw new IndexOutOfBoundsException(TF_Message(s).getString());\n+          throw new TFOutOfRangeException(TF_Message(s).getString());\n         case TF_UNIMPLEMENTED:\n-          throw new UnsupportedOperationException(TF_Message(s).getString());\n+          throw new TFUnimplementedException(TF_Message(s).getString());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "41d1b563c857107b549c80bc16a3c2cdf52a275f"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTM5NTc2OA==", "bodyText": "This is no more only for training. So maybe more something like High-level abstractions for training and serving TensorFlow models?", "url": "https://github.com/tensorflow/java/pull/30#discussion_r415395768", "createdAt": "2020-04-26T20:38:25Z", "author": {"login": "karllessard"}, "path": "tensorflow-framework/pom.xml", "diffHunk": "@@ -24,12 +24,13 @@\n     <artifactId>tensorflow-java</artifactId>\n     <version>0.1.0-SNAPSHOT</version>\n   </parent>\n-  <artifactId>tensorflow-training</artifactId>\n+  <artifactId>tensorflow-framework</artifactId>\n   <packaging>jar</packaging>\n \n-  <name>TensorFlow Training Library</name>\n+  <name>TensorFlow Framework Library</name>\n   <description>\n-    Operations for training Tensorflow models.\n+    Abstractions to help train deep learning\n+    models using TensorFlow Java", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "41d1b563c857107b549c80bc16a3c2cdf52a275f"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTM5NTg4Mg==", "bodyText": "version is inherited from parent and scope should remain test", "url": "https://github.com/tensorflow/java/pull/30#discussion_r415395882", "createdAt": "2020-04-26T20:39:01Z", "author": {"login": "karllessard"}, "path": "tensorflow-framework/pom.xml", "diffHunk": "@@ -41,7 +42,7 @@\n     <dependency>\n       <groupId>junit</groupId>\n       <artifactId>junit</artifactId>\n-      <scope>test</scope>\n+      <version>${junit.version}</version>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "41d1b563c857107b549c80bc16a3c2cdf52a275f"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTM5NTkwOA==", "bodyText": "oops :)", "url": "https://github.com/tensorflow/java/pull/30#discussion_r415395908", "createdAt": "2020-04-26T20:39:11Z", "author": {"login": "karllessard"}, "path": "tensorflow-framework/pom.xml", "diffHunk": "@@ -64,7 +65,7 @@\n         <configuration>\n           <forkCount>1</forkCount>\n           <reuseForks>false</reuseForks>\n-          <argLine>-Xmx2G -XX:MaxPermSize=256m</argLine>\n+          <argLine>-Xmx2G -XX:MaxPermSize=256m -Djava.library.path=/home/dhruv/git/tensorflow-java/tensorflow-core/tensorflow-core-api/target/native/org/tensorflow/internal/c_api/linux-x86_64/</argLine>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "41d1b563c857107b549c80bc16a3c2cdf52a275f"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTM5NjM2OQ==", "bodyText": "It looks to me that your line wrapping is less that 100 characters.", "url": "https://github.com/tensorflow/java/pull/30#discussion_r415396369", "createdAt": "2020-04-26T20:41:35Z", "author": {"login": "karllessard"}, "path": "tensorflow-framework/src/main/java/org/tensorflow/framework/data/DatasetIterator.java", "diffHunk": "@@ -0,0 +1,242 @@\n+package org.tensorflow.framework.data;\n+\n+import org.tensorflow.DataType;\n+import org.tensorflow.Graph;\n+import org.tensorflow.Operand;\n+import org.tensorflow.Output;\n+import org.tensorflow.op.Op;\n+import org.tensorflow.op.Ops;\n+import org.tensorflow.tools.Shape;\n+\n+import java.util.List;\n+\n+/**\n+ * Represents the state of an iteration through\n+ * a tf.data Datset. DatasetIterator is not\n+ * a java.util.Iterator. In eager mode, `Dataset`\n+ * can be used as an Iterable, returning dataset\n+ * elements each iteration.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "41d1b563c857107b549c80bc16a3c2cdf52a275f"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTM5NjQ3Nw==", "bodyText": "should be TFOutOfRangeException now. Also, where is the loop?", "url": "https://github.com/tensorflow/java/pull/30#discussion_r415396477", "createdAt": "2020-04-26T20:42:12Z", "author": {"login": "karllessard"}, "path": "tensorflow-framework/src/main/java/org/tensorflow/framework/data/DatasetIterator.java", "diffHunk": "@@ -0,0 +1,242 @@\n+package org.tensorflow.framework.data;\n+\n+import org.tensorflow.DataType;\n+import org.tensorflow.Graph;\n+import org.tensorflow.Operand;\n+import org.tensorflow.Output;\n+import org.tensorflow.op.Op;\n+import org.tensorflow.op.Ops;\n+import org.tensorflow.tools.Shape;\n+\n+import java.util.List;\n+\n+/**\n+ * Represents the state of an iteration through\n+ * a tf.data Datset. DatasetIterator is not\n+ * a java.util.Iterator. In eager mode, `Dataset`\n+ * can be used as an Iterable, returning dataset\n+ * elements each iteration.\n+ *\n+ * <p>\n+ * Example: Iteration in graph mode.\n+ *\n+ * <pre>{@code\n+ *  // Create input tensors\n+ *  Operand<?> XTensor = tf.constant( ... );\n+ *  Operand<?> yTensor = tf.constant( ... );\n+ *\n+ *\n+ *  Dataset dataset = Dataset\n+ *          .fromTensorSlices(XTensor, yTensor);\n+ *          .batch(BATCH_SIZE);\n+ *\n+ *  DatasetIterator iterator = dataset.makeIterator();\n+ *  List<Output<?>> components = iterator.getNext();\n+ *  Operand<?> XBatch = components.get(0);\n+ *  Operand<?> yBatch = components.get(1);\n+ *\n+ *  // Build a TensorFlow graph that does something on each element.\n+ *  loss = computeModelLoss(X, y);\n+ *\n+ *  optimizer = ... // create an optimizer\n+ *  trainOp = optimizer.minimize(loss);\n+ *\n+ *  try (Session session = new Session(graph) {\n+ *      try {\n+ *          session.run(trainOp);\n+ *          ...\n+ *      } catch (IndexOutOfBoundsException e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "41d1b563c857107b549c80bc16a3c2cdf52a275f"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTM5NjczOQ==", "bodyText": "where are defined X and y? Also, variables should start with lowercase, so xTensor & cie are a better pick", "url": "https://github.com/tensorflow/java/pull/30#discussion_r415396739", "createdAt": "2020-04-26T20:44:00Z", "author": {"login": "karllessard"}, "path": "tensorflow-framework/src/main/java/org/tensorflow/framework/data/DatasetIterator.java", "diffHunk": "@@ -0,0 +1,242 @@\n+package org.tensorflow.framework.data;\n+\n+import org.tensorflow.DataType;\n+import org.tensorflow.Graph;\n+import org.tensorflow.Operand;\n+import org.tensorflow.Output;\n+import org.tensorflow.op.Op;\n+import org.tensorflow.op.Ops;\n+import org.tensorflow.tools.Shape;\n+\n+import java.util.List;\n+\n+/**\n+ * Represents the state of an iteration through\n+ * a tf.data Datset. DatasetIterator is not\n+ * a java.util.Iterator. In eager mode, `Dataset`\n+ * can be used as an Iterable, returning dataset\n+ * elements each iteration.\n+ *\n+ * <p>\n+ * Example: Iteration in graph mode.\n+ *\n+ * <pre>{@code\n+ *  // Create input tensors\n+ *  Operand<?> XTensor = tf.constant( ... );\n+ *  Operand<?> yTensor = tf.constant( ... );\n+ *\n+ *\n+ *  Dataset dataset = Dataset\n+ *          .fromTensorSlices(XTensor, yTensor);\n+ *          .batch(BATCH_SIZE);\n+ *\n+ *  DatasetIterator iterator = dataset.makeIterator();\n+ *  List<Output<?>> components = iterator.getNext();\n+ *  Operand<?> XBatch = components.get(0);\n+ *  Operand<?> yBatch = components.get(1);\n+ *\n+ *  // Build a TensorFlow graph that does something on each element.\n+ *  loss = computeModelLoss(X, y);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "41d1b563c857107b549c80bc16a3c2cdf52a275f"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTM5NzIxMA==", "bodyText": "should be List<Operand<?>> according to the documentation", "url": "https://github.com/tensorflow/java/pull/30#discussion_r415397210", "createdAt": "2020-04-26T20:46:30Z", "author": {"login": "karllessard"}, "path": "tensorflow-framework/src/main/java/org/tensorflow/framework/data/DatasetIterator.java", "diffHunk": "@@ -0,0 +1,242 @@\n+package org.tensorflow.framework.data;\n+\n+import org.tensorflow.DataType;\n+import org.tensorflow.Graph;\n+import org.tensorflow.Operand;\n+import org.tensorflow.Output;\n+import org.tensorflow.op.Op;\n+import org.tensorflow.op.Ops;\n+import org.tensorflow.tools.Shape;\n+\n+import java.util.List;\n+\n+/**\n+ * Represents the state of an iteration through\n+ * a tf.data Datset. DatasetIterator is not\n+ * a java.util.Iterator. In eager mode, `Dataset`\n+ * can be used as an Iterable, returning dataset\n+ * elements each iteration.\n+ *\n+ * <p>\n+ * Example: Iteration in graph mode.\n+ *\n+ * <pre>{@code\n+ *  // Create input tensors\n+ *  Operand<?> XTensor = tf.constant( ... );\n+ *  Operand<?> yTensor = tf.constant( ... );\n+ *\n+ *\n+ *  Dataset dataset = Dataset\n+ *          .fromTensorSlices(XTensor, yTensor);\n+ *          .batch(BATCH_SIZE);\n+ *\n+ *  DatasetIterator iterator = dataset.makeIterator();\n+ *  List<Output<?>> components = iterator.getNext();\n+ *  Operand<?> XBatch = components.get(0);\n+ *  Operand<?> yBatch = components.get(1);\n+ *\n+ *  // Build a TensorFlow graph that does something on each element.\n+ *  loss = computeModelLoss(X, y);\n+ *\n+ *  optimizer = ... // create an optimizer\n+ *  trainOp = optimizer.minimize(loss);\n+ *\n+ *  try (Session session = new Session(graph) {\n+ *      try {\n+ *          session.run(trainOp);\n+ *          ...\n+ *      } catch (IndexOutOfBoundsException e) {\n+ *          System.out.println(\"finished iterating.\");\n+ *          break;\n+ *      }\n+ *  }\n+ *\n+ * }</pre>\n+ * <p>\n+ * Example: Iteration in eager mode.\n+ *\n+ * <pre>{@code\n+ *  // Create input tensors\n+ *  Operand<?> XTensor = tf.constant( ... );\n+ *  Operand<?> yTensor = tf.constant( ... );\n+ *\n+ *  int BATCH_SIZE = ...\n+ *\n+ *  Dataset dataset = Dataset\n+ *          .fromTensorSlices(XTensor, yTensor)\n+ *          .batch(BATCH_SIZE);\n+ *  DatasetIterator iterator = dataset.makeIterator();\n+ *\n+ *  Optimizer optimizer = ... // create an optimizer\n+ *\n+ *  for (List<Output<?>> components : dataset) {\n+ *      Operand<?> XBatch = components.get(0);\n+ *      Operand<?> yBatch = components.get(1);\n+ *\n+ *      loss = computeModelLoss(X, y);\n+ *      trainOp = optimizer.minimize(loss);\n+ *  }\n+ * }</pre>\n+ */\n+public class DatasetIterator {\n+  public static final String EMPTY_SHARED_NAME = \"\";\n+\n+  private Ops tf;\n+\n+  private Operand<?> iteratorResource;\n+  private Op initializer;\n+\n+  private List<DataType<?>> outputTypes;\n+  private List<Shape> outputShapes;\n+\n+  /**\n+   * @param tf               Ops accessor corresponding to the same `ExecutionEnvironment`\n+   *                         as the `iteratorResource`.\n+   * @param iteratorResource An Operand representing the iterator\n+   *                         (e.g. constructed from `tf.data.iterator` or\n+   *                         `tf.data.anonymousIterator`)\n+   * @param initializer      An `Op` that should be run to initialize this iterator\n+   * @param outputTypes      A list of `DataType` objects corresponding to the\n+   *                         types of each component of a dataset element.\n+   * @param outputShapes     A list of `Shape` objects corresponding to the\n+   *                         shapes of each componenet of a dataset element.\n+   */\n+  private DatasetIterator(Ops tf, Operand<?> iteratorResource,\n+                          Op initializer,\n+                          List<DataType<?>> outputTypes,\n+                          List<Shape> outputShapes) {\n+\n+    this.tf = tf;\n+    this.iteratorResource = iteratorResource;\n+    this.initializer = initializer;\n+    this.outputTypes = outputTypes;\n+    this.outputShapes = outputShapes;\n+  }\n+\n+  private DatasetIterator(Ops tf, Operand<?> iteratorResource,\n+                          List<DataType<?>> outputTypes,\n+                          List<Shape> outputShapes) {\n+    this.tf = tf;\n+    this.iteratorResource = iteratorResource;\n+    this.outputTypes = outputTypes;\n+    this.outputShapes = outputShapes;\n+  }\n+\n+  /**\n+   * Returns a list of `Operand<?>` representing the components of the\n+   * next dataset element.\n+   * <p>\n+   * In graph mode, call this method once, and use its result as input\n+   * to another computation. Then in the training loop, on successive calls\n+   * to session.run(), successive dataset elements will be retrieved through\n+   * these components.\n+   * <p>\n+   * In eager mode, each time this method is called, the next dataset\n+   * element will be returned. (This is done automatically by iterating\n+   * through `Dataset` as a Java `Iterable`).\n+   *\n+   * @return A `List<Operand<?>>` representing dataset element components.\n+   */\n+  public List<Output<?>> getNext() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "41d1b563c857107b549c80bc16a3c2cdf52a275f"}, "originalPosition": 140}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTM5NzQwNg==", "bodyText": "Wrong doc, this is a copy of getNext()", "url": "https://github.com/tensorflow/java/pull/30#discussion_r415397406", "createdAt": "2020-04-26T20:47:37Z", "author": {"login": "karllessard"}, "path": "tensorflow-framework/src/main/java/org/tensorflow/framework/data/DatasetIterator.java", "diffHunk": "@@ -0,0 +1,242 @@\n+package org.tensorflow.framework.data;\n+\n+import org.tensorflow.DataType;\n+import org.tensorflow.Graph;\n+import org.tensorflow.Operand;\n+import org.tensorflow.Output;\n+import org.tensorflow.op.Op;\n+import org.tensorflow.op.Ops;\n+import org.tensorflow.tools.Shape;\n+\n+import java.util.List;\n+\n+/**\n+ * Represents the state of an iteration through\n+ * a tf.data Datset. DatasetIterator is not\n+ * a java.util.Iterator. In eager mode, `Dataset`\n+ * can be used as an Iterable, returning dataset\n+ * elements each iteration.\n+ *\n+ * <p>\n+ * Example: Iteration in graph mode.\n+ *\n+ * <pre>{@code\n+ *  // Create input tensors\n+ *  Operand<?> XTensor = tf.constant( ... );\n+ *  Operand<?> yTensor = tf.constant( ... );\n+ *\n+ *\n+ *  Dataset dataset = Dataset\n+ *          .fromTensorSlices(XTensor, yTensor);\n+ *          .batch(BATCH_SIZE);\n+ *\n+ *  DatasetIterator iterator = dataset.makeIterator();\n+ *  List<Output<?>> components = iterator.getNext();\n+ *  Operand<?> XBatch = components.get(0);\n+ *  Operand<?> yBatch = components.get(1);\n+ *\n+ *  // Build a TensorFlow graph that does something on each element.\n+ *  loss = computeModelLoss(X, y);\n+ *\n+ *  optimizer = ... // create an optimizer\n+ *  trainOp = optimizer.minimize(loss);\n+ *\n+ *  try (Session session = new Session(graph) {\n+ *      try {\n+ *          session.run(trainOp);\n+ *          ...\n+ *      } catch (IndexOutOfBoundsException e) {\n+ *          System.out.println(\"finished iterating.\");\n+ *          break;\n+ *      }\n+ *  }\n+ *\n+ * }</pre>\n+ * <p>\n+ * Example: Iteration in eager mode.\n+ *\n+ * <pre>{@code\n+ *  // Create input tensors\n+ *  Operand<?> XTensor = tf.constant( ... );\n+ *  Operand<?> yTensor = tf.constant( ... );\n+ *\n+ *  int BATCH_SIZE = ...\n+ *\n+ *  Dataset dataset = Dataset\n+ *          .fromTensorSlices(XTensor, yTensor)\n+ *          .batch(BATCH_SIZE);\n+ *  DatasetIterator iterator = dataset.makeIterator();\n+ *\n+ *  Optimizer optimizer = ... // create an optimizer\n+ *\n+ *  for (List<Output<?>> components : dataset) {\n+ *      Operand<?> XBatch = components.get(0);\n+ *      Operand<?> yBatch = components.get(1);\n+ *\n+ *      loss = computeModelLoss(X, y);\n+ *      trainOp = optimizer.minimize(loss);\n+ *  }\n+ * }</pre>\n+ */\n+public class DatasetIterator {\n+  public static final String EMPTY_SHARED_NAME = \"\";\n+\n+  private Ops tf;\n+\n+  private Operand<?> iteratorResource;\n+  private Op initializer;\n+\n+  private List<DataType<?>> outputTypes;\n+  private List<Shape> outputShapes;\n+\n+  /**\n+   * @param tf               Ops accessor corresponding to the same `ExecutionEnvironment`\n+   *                         as the `iteratorResource`.\n+   * @param iteratorResource An Operand representing the iterator\n+   *                         (e.g. constructed from `tf.data.iterator` or\n+   *                         `tf.data.anonymousIterator`)\n+   * @param initializer      An `Op` that should be run to initialize this iterator\n+   * @param outputTypes      A list of `DataType` objects corresponding to the\n+   *                         types of each component of a dataset element.\n+   * @param outputShapes     A list of `Shape` objects corresponding to the\n+   *                         shapes of each componenet of a dataset element.\n+   */\n+  private DatasetIterator(Ops tf, Operand<?> iteratorResource,\n+                          Op initializer,\n+                          List<DataType<?>> outputTypes,\n+                          List<Shape> outputShapes) {\n+\n+    this.tf = tf;\n+    this.iteratorResource = iteratorResource;\n+    this.initializer = initializer;\n+    this.outputTypes = outputTypes;\n+    this.outputShapes = outputShapes;\n+  }\n+\n+  private DatasetIterator(Ops tf, Operand<?> iteratorResource,\n+                          List<DataType<?>> outputTypes,\n+                          List<Shape> outputShapes) {\n+    this.tf = tf;\n+    this.iteratorResource = iteratorResource;\n+    this.outputTypes = outputTypes;\n+    this.outputShapes = outputShapes;\n+  }\n+\n+  /**\n+   * Returns a list of `Operand<?>` representing the components of the\n+   * next dataset element.\n+   * <p>\n+   * In graph mode, call this method once, and use its result as input\n+   * to another computation. Then in the training loop, on successive calls\n+   * to session.run(), successive dataset elements will be retrieved through\n+   * these components.\n+   * <p>\n+   * In eager mode, each time this method is called, the next dataset\n+   * element will be returned. (This is done automatically by iterating\n+   * through `Dataset` as a Java `Iterable`).\n+   *\n+   * @return A `List<Operand<?>>` representing dataset element components.\n+   */\n+  public List<Output<?>> getNext() {\n+    return tf.data.iteratorGetNext(getIteratorResource(),\n+        getOutputTypes(), getOutputShapes()).components();\n+  }\n+\n+  /**\n+   * Returns a list of `Operand<?>` representing the components of the\n+   * next dataset element.\n+   * <p>\n+   * In graph mode, call this method once, and use its result as input\n+   * to another computation. Then in the training loop, on successive calls\n+   * to session.run(), successive dataset elements will be retrieved through\n+   * these components.\n+   * <p>\n+   * In eager mode, each time this method is called, the next dataset\n+   * element will be returned. (This is done automatically by iterating\n+   * through `Dataset` as a Java `Iterable`).\n+   *\n+   * @return A `List<Operand<?>>` representing dataset element components.\n+   */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "41d1b563c857107b549c80bc16a3c2cdf52a275f"}, "originalPosition": 159}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTM5NzUxMQ==", "bodyText": "extra line", "url": "https://github.com/tensorflow/java/pull/30#discussion_r415397511", "createdAt": "2020-04-26T20:48:32Z", "author": {"login": "karllessard"}, "path": "tensorflow-framework/src/main/java/org/tensorflow/framework/data/DatasetIterator.java", "diffHunk": "@@ -0,0 +1,242 @@\n+package org.tensorflow.framework.data;\n+\n+import org.tensorflow.DataType;\n+import org.tensorflow.Graph;\n+import org.tensorflow.Operand;\n+import org.tensorflow.Output;\n+import org.tensorflow.op.Op;\n+import org.tensorflow.op.Ops;\n+import org.tensorflow.tools.Shape;\n+\n+import java.util.List;\n+\n+/**\n+ * Represents the state of an iteration through\n+ * a tf.data Datset. DatasetIterator is not\n+ * a java.util.Iterator. In eager mode, `Dataset`\n+ * can be used as an Iterable, returning dataset\n+ * elements each iteration.\n+ *\n+ * <p>\n+ * Example: Iteration in graph mode.\n+ *\n+ * <pre>{@code\n+ *  // Create input tensors\n+ *  Operand<?> XTensor = tf.constant( ... );\n+ *  Operand<?> yTensor = tf.constant( ... );\n+ *\n+ *\n+ *  Dataset dataset = Dataset\n+ *          .fromTensorSlices(XTensor, yTensor);\n+ *          .batch(BATCH_SIZE);\n+ *\n+ *  DatasetIterator iterator = dataset.makeIterator();\n+ *  List<Output<?>> components = iterator.getNext();\n+ *  Operand<?> XBatch = components.get(0);\n+ *  Operand<?> yBatch = components.get(1);\n+ *\n+ *  // Build a TensorFlow graph that does something on each element.\n+ *  loss = computeModelLoss(X, y);\n+ *\n+ *  optimizer = ... // create an optimizer\n+ *  trainOp = optimizer.minimize(loss);\n+ *\n+ *  try (Session session = new Session(graph) {\n+ *      try {\n+ *          session.run(trainOp);\n+ *          ...\n+ *      } catch (IndexOutOfBoundsException e) {\n+ *          System.out.println(\"finished iterating.\");\n+ *          break;\n+ *      }\n+ *  }\n+ *\n+ * }</pre>\n+ * <p>\n+ * Example: Iteration in eager mode.\n+ *\n+ * <pre>{@code\n+ *  // Create input tensors\n+ *  Operand<?> XTensor = tf.constant( ... );\n+ *  Operand<?> yTensor = tf.constant( ... );\n+ *\n+ *  int BATCH_SIZE = ...\n+ *\n+ *  Dataset dataset = Dataset\n+ *          .fromTensorSlices(XTensor, yTensor)\n+ *          .batch(BATCH_SIZE);\n+ *  DatasetIterator iterator = dataset.makeIterator();\n+ *\n+ *  Optimizer optimizer = ... // create an optimizer\n+ *\n+ *  for (List<Output<?>> components : dataset) {\n+ *      Operand<?> XBatch = components.get(0);\n+ *      Operand<?> yBatch = components.get(1);\n+ *\n+ *      loss = computeModelLoss(X, y);\n+ *      trainOp = optimizer.minimize(loss);\n+ *  }\n+ * }</pre>\n+ */\n+public class DatasetIterator {\n+  public static final String EMPTY_SHARED_NAME = \"\";\n+\n+  private Ops tf;\n+\n+  private Operand<?> iteratorResource;\n+  private Op initializer;\n+\n+  private List<DataType<?>> outputTypes;\n+  private List<Shape> outputShapes;\n+\n+  /**\n+   * @param tf               Ops accessor corresponding to the same `ExecutionEnvironment`\n+   *                         as the `iteratorResource`.\n+   * @param iteratorResource An Operand representing the iterator\n+   *                         (e.g. constructed from `tf.data.iterator` or\n+   *                         `tf.data.anonymousIterator`)\n+   * @param initializer      An `Op` that should be run to initialize this iterator\n+   * @param outputTypes      A list of `DataType` objects corresponding to the\n+   *                         types of each component of a dataset element.\n+   * @param outputShapes     A list of `Shape` objects corresponding to the\n+   *                         shapes of each componenet of a dataset element.\n+   */\n+  private DatasetIterator(Ops tf, Operand<?> iteratorResource,\n+                          Op initializer,\n+                          List<DataType<?>> outputTypes,\n+                          List<Shape> outputShapes) {\n+\n+    this.tf = tf;\n+    this.iteratorResource = iteratorResource;\n+    this.initializer = initializer;\n+    this.outputTypes = outputTypes;\n+    this.outputShapes = outputShapes;\n+  }\n+\n+  private DatasetIterator(Ops tf, Operand<?> iteratorResource,\n+                          List<DataType<?>> outputTypes,\n+                          List<Shape> outputShapes) {\n+    this.tf = tf;\n+    this.iteratorResource = iteratorResource;\n+    this.outputTypes = outputTypes;\n+    this.outputShapes = outputShapes;\n+  }\n+\n+  /**\n+   * Returns a list of `Operand<?>` representing the components of the\n+   * next dataset element.\n+   * <p>\n+   * In graph mode, call this method once, and use its result as input\n+   * to another computation. Then in the training loop, on successive calls\n+   * to session.run(), successive dataset elements will be retrieved through\n+   * these components.\n+   * <p>\n+   * In eager mode, each time this method is called, the next dataset\n+   * element will be returned. (This is done automatically by iterating\n+   * through `Dataset` as a Java `Iterable`).\n+   *\n+   * @return A `List<Operand<?>>` representing dataset element components.\n+   */\n+  public List<Output<?>> getNext() {\n+    return tf.data.iteratorGetNext(getIteratorResource(),\n+        getOutputTypes(), getOutputShapes()).components();\n+  }\n+\n+  /**\n+   * Returns a list of `Operand<?>` representing the components of the\n+   * next dataset element.\n+   * <p>\n+   * In graph mode, call this method once, and use its result as input\n+   * to another computation. Then in the training loop, on successive calls\n+   * to session.run(), successive dataset elements will be retrieved through\n+   * these components.\n+   * <p>\n+   * In eager mode, each time this method is called, the next dataset\n+   * element will be returned. (This is done automatically by iterating\n+   * through `Dataset` as a Java `Iterable`).\n+   *\n+   * @return A `List<Operand<?>>` representing dataset element components.\n+   */\n+  public DatasetOptional getNextAsOptional() {\n+    Operand<?> optionalVariant = tf.data.iteratorGetNextAsOptional(\n+        getIteratorResource(),\n+        getOutputTypes(),\n+        getOutputShapes()).optional();\n+    return new DatasetOptional(tf, optionalVariant, outputTypes,\n+        outputShapes);\n+  }\n+\n+  /**\n+   * Creates and returns a TF `Op` that can be run to initialize\n+   * this iterator on a dataset. The dataset must have a structure\n+   * (outputTypes, outputShapes) that match this iterator, and\n+   * share the same ExecutionEnvironment as this iterator.\n+   * <p>\n+   * When this `Op` is run, this iterator will be \"re-initialized\" at\n+   * the first element of the input dataset.\n+   * <p>\n+   * In eager mode, the op will be run automatically as part of\n+   * a call to `makeIterator`.\n+   *\n+   * @param dataset An `org.tensorflow.data.Dataset` to initialize this\n+   *                iterator on.\n+   * @return A TF `Op` that can be used to initialize this iterator on the\n+   * dataset.\n+   * @throws IllegalArgumentException if the dataset's ExecutionEnvironment or\n+   *                                  structure doesn't match this iterator.\n+   */\n+  public Op makeInitializer(Dataset dataset) {\n+    if (tf.scope().env() != dataset.tf.scope().env()) {\n+      throw new IllegalArgumentException(\"Dataset must share the same\" +\n+          \"ExecutionEnvironment as this iterator.\");\n+    }\n+\n+    if (!dataset.getOutputShapes().equals(getOutputShapes())\n+        || !dataset.getOutputTypes().equals(getOutputTypes())) {\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "41d1b563c857107b549c80bc16a3c2cdf52a275f"}, "originalPosition": 196}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTM5NzczNA==", "bodyText": "Missing copyrights (and for all new files in this PR)", "url": "https://github.com/tensorflow/java/pull/30#discussion_r415397734", "createdAt": "2020-04-26T20:49:32Z", "author": {"login": "karllessard"}, "path": "tensorflow-framework/src/main/java/org/tensorflow/framework/data/DatasetIterator.java", "diffHunk": "@@ -0,0 +1,242 @@\n+package org.tensorflow.framework.data;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "41d1b563c857107b549c80bc16a3c2cdf52a275f"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTM5ODUyNg==", "bodyText": "There is no reference to the RFC, but I think you can simply remove this line", "url": "https://github.com/tensorflow/java/pull/30#discussion_r415398526", "createdAt": "2020-04-26T20:53:35Z", "author": {"login": "karllessard"}, "path": "tensorflow-framework/tensorflow-data.md", "diffHunk": "@@ -0,0 +1,209 @@\n+\n+NOTE: This readme follows the discussion of this [RFC]()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "41d1b563c857107b549c80bc16a3c2cdf52a275f"}, "originalPosition": 2}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTM5ODczMQ==", "bodyText": "tensorflow-frameworks should not be present anymore", "url": "https://github.com/tensorflow/java/pull/30#discussion_r415398731", "createdAt": "2020-04-26T20:54:33Z", "author": {"login": "karllessard"}, "path": "tensorflow-frameworks/tensorflow-data/README.md", "diffHunk": "@@ -0,0 +1,209 @@\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "41d1b563c857107b549c80bc16a3c2cdf52a275f"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTM5ODg0OA==", "bodyText": "or is it TFOutOfRangeException?", "url": "https://github.com/tensorflow/java/pull/30#discussion_r415398848", "createdAt": "2020-04-26T20:55:05Z", "author": {"login": "karllessard"}, "path": "tensorflow-framework/tensorflow-data.md", "diffHunk": "@@ -0,0 +1,209 @@\n+\n+NOTE: This readme follows the discussion of this [RFC]()\n+\n+\n+Tensorflow-Data (Java)\n+==\n+\n+TensorFlow Data provides utilities and APIs for loading data of various formats, and preparing datasets for use in training and using deep learning models\n+. This package\n+ provides a\n+ simple API for configuring and iterating over\n+ datasets in both \"graph\" and \"eager\" mode.\n+\n+Usage\n+--\n+\n+The `Dataset` class represents a sequence of elements which can be iterated over and\n+transformed. Each element is a list of \"output\" operands, represented by the type `List<Output<?>>`. \n+\n+Note: An `Output` is a symbolic handle to a tensor produced by a TensorFlow op. In graph\n+mode, `Output` objects will not have a concrete `Tensor` value unless all dependent operations\n+are run in a `Session` (this is done \"in-real-time\" in eager mode).\n+\n+### Construction\n+\n+Datasets can be constructed either directly from a data source (e.g. a list of tensors representing the components of the dataset), or as a transformation on an existing dataset.\n+\n+#### From Data Source\n+\n+To construct a dataset from a list of tensor components, use \n+`Dataset.fromTensorSlices( ... )`. For example, say we are working\n+with a standard feature/label dataset which has 4 elements.\n+\n+```java\n+FloatNdArray features = StdArrays.ndCopyOf(\n+        new float[][] {\n+        {1, 2, 3},\n+        {4, 5, 6},\n+        {7, 8, 9},\n+        {10, 11, 12}\n+});\n+\n+FloatNdArray labels = NdArrays.vectorOf(0, 1, 1, 0);\n+```\n+\n+A dataset can be constructed from a list of the constant `Operand`s generated\n+from this dataset, and a list of `DataType` objects corresponding\n+to the type of each component:\n+\n+Note: Each of the input components must share the same first \"batch\" dimension.\n+\n+```java\n+Ops tf = // ... TensorFlow Ops accessor (either graph or eager)\n+Dataset dataset = Dataset.fromTensorSlices(\n+    Arrays.asList(tf.constant(features), tf.constant(labels)),\n+    Arrays.asList(TInt32.DTYPE, TInt32.DTYPE)\n+);\n+```\n+\n+\n+Other data sources are also possible, using `tf.data` ops; these include TFRecord files, CSV files, and more.\n+\n+#### Transformations on Existing Datasets\n+\n+Once a dataset has been created from a data source it can be transformed by calling\n+methods on the `Dataset` object. For example, to group elements in the above dataset into batches of size `2`, use `Dataset.batch(int batchSize)`:\n+\n+```java\n+dataset = dataset.batch(2)\n+```\n+\n+Each dataset transformation alters both the values and shapes of the original\n+ elements, and returns a *new* `Dataset` object.\n+\n+In this case, the original dataset had 4 elements of shape `[features: (3,) labels: (1,)]`.\n+Once the `.batch` transformation is applied, the new dataset has 2 elements (batches) of shape `[features: (2, 3), labels: (2, 1)]`.\n+\n+Similar transformations include `.skip`, `.take`, `.map`, `.filter`, etc.\n+\n+\n+### Iterating over Dataset Elements\n+\n+The primary use of a dataset is for iteration over its elements.\n+Each row (or batch) element is represented as a list of tensor components, with\n+type `List<Output<?>>`. The tensor components of this element can be accessed using `List.get(int index)`.\n+\n+It is recommended to use `Tensor.expect(DataType<?> dtype)` to restore types\n+to the retrieved tensors.\n+\n+#### Using DatastetIterator\n+The `DatasetIterator` class provides abstractions for creating and using\n+iterators in graph and eager mode. These will be explained here; however\n+end-users should only interact with `Iterator` objects through the methods\n+provided in the `Dataset` class (examples to follow).\n+\n+To construct an iterator for a dataset of a specific structure, use\n+the static method `Iterator.fromStructure(Ops tf, List<DataType<?>> outputTypes, List<Shape> outputShapes)`. This creates a `DatasetIterator` object\n+which can be used with any dataset of a matching structure.\n+\n+Once a `DatasetIterator` is created, it can be initialized on a `Dataset` intsance using `Iterator.makeInitializer(Dataset dataset)`. This will initialize (or re-initialize) the iterator to start at the beginning\n+of this dataset.\n+\n+The `Iterator.getNext()` method can be used to retrieve dataset elements.\n+In eager mode, each call to `getNext()` will return the next dataset element as\n+as `List<Output<?>>`. In graph mode, this method should be called just once\n+to retrieve the components. These can be fed into additional operations as\n+a computation Graph is built. On successive `session.run` operations, the\n+successive dataset elements will be automatically passed through the graph.\n+\n+\n+#### Eager Mode: Iterable\n+The `Dataset` class implements the `Iterable` interface, so in\n+eager mode, iteration over dataset elements is possible using a standard for-each loop (this is a wrapper around `DatasetIterator` constructs).\n+\n+Using the same example dataset from above, dataset elements can be extracted and\n+used as follows:\n+```java\n+// Use default EagerSession\n+Ops tf = Ops.create()\n+\n+// Dataset of (features, labels) from above\n+Dataset dataset = Dataset.fromTensorSlices(tf, ... );\n+\n+// batch dataset elements into batches of size 2\n+dataset = dataset.batch(2);\n+\n+Optmizer optimizer = ... // TF Optimizer\n+\n+for (List<Output<?>> batch : dataset) {\n+    Operand<?> featureBatch = element.get(0);\n+    Operand<?> labelBatch = element.get(1);\n+\n+    // Perform batch-wise computations on featureBatch and labelBatch\n+    // e.g. computing model losses, running optimizers.\n+\n+    Operand<TFloat32> loss = myModelLoss(featureBatch, labelBatch);\n+\n+    optimizer.minimize(loss);\n+    \n+    ...\n+}   \n+\n+```\n+\n+#### Graph Mode: OneShotIterator\n+\n+The above code will not work in graph mode, which requires the use of\n+ `Session` instances\n+to run the computations. In graph mode, datasets can be iterated over using the `DatasetIterator` abstraction, and a while loop.\n+\n+Once the iterator is initialized, repeated calls to `Session.run` will populate the components with new values, until all elements have\n+been retrieved. After this, `Session.run` will result in a `TFOutOfRangeException`.\n+\n+Note that the make-iterator operation can be re-run to re-initialize\n+the iterator, to iterate over the dataset a second time.\n+\n+```java\n+try (Graph graph = new Graph()) {\n+    // Graph mode Ops accessor\n+    Ops tf = Ops.create(graph)\n+\n+    // Dataset of (features, labels) from above\n+    Dataset dataset = Dataset.fromTensorSlices(tf, ... );\n+\n+    // batch dataset elements into batches of size 2\n+    dataset = dataset.batch(2); \n+\n+    // makeOneShotIterator() automatically adds the \n+    // iterator initializer (MakeIterator) Op to the Graph\n+    // initializers list. Make sure to run `session.run(tf.init())`\n+    // first!\n+    DatasetIterator iterator = dataset.makeOneShotIterator();\n+    List<Output<?>> batch = iterator.getNext();\n+\n+    Operand<?> features = batch.get(0);\n+    Operand<?> labels = batch.get(1);\n+\n+    // Run additional computations on `features` and `labels`,\n+    // e.g. computing model losses, instantiating Optimizers\n+\n+    Optimizer optimizer = ... // TF Optimizer \n+    Operand<TFloat32> loss = myModelLoss(features, labels);\n+    \n+    Op trainOp = optimizer.minimize(loss)\n+\n+    // instantiate graph-mode session\n+    try (Session session = new Session(graph)) {\n+        // Run graph initializers (and the iterator initializer)\n+        session.run(tf.init());\n+\n+        // Iterate over dataset elements\n+        while (true) {\n+            try {\n+                // Run training ops / fetch loss\n+                List<Tensor<?>> outputs = session.runner()\n+                    .addTarget(trainOp)\n+                    .fetch(loss)\n+                    .run();\n+\n+                ...\n+\n+            } catch (TFOutOfRangeError e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "41d1b563c857107b549c80bc16a3c2cdf52a275f"}, "originalPosition": 202}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTM5OTAwNw==", "bodyText": "We need to save that epic thread somewhere before closing it :)", "url": "https://github.com/tensorflow/java/pull/30#discussion_r415399007", "createdAt": "2020-04-26T20:56:04Z", "author": {"login": "karllessard"}, "path": "tensorflow-frameworks/tensorflow-data/README.md", "diffHunk": "@@ -0,0 +1,220 @@\n+\n+NOTE: This readme follows the discussion of this [RFC]()\n+\n+\n+Tensorflow-Data (Java)\n+==\n+\n+TensorFlow Data provides utilities and APIsfor loading data of various formats\n+, and preparing datasets for use in training and using deep learning models\n+. This package\n+ provides a\n+ simple API for configuring and iterating over\n+ datasets in both \"graph\" and \"eager\" mode.\n+\n+Usage\n+--\n+\n+The `Dataset` abstraction represents a sequence of elements, where each element in the sequence is a collection (`List`) of tensors (or, \"components\").\n+\n+\n+\n+The `Dataset` class represents a sequence of elements which can be iterated over and\n+transformed. Each element is a list of \"output\" operands, represented by the type `List<Output<?>>`. \n+\n+Note: An `Output` is a symbolic handle to a tensor produced by a TensorFlow op. In graph\n+mode, `Output` objects will not have a concrete `Tensor` value unless all dependent operations\n+are run in a `Session` (this is done \"in-real-time\" in eager mode).\n+\n+### Construction\n+\n+Datasets can be constructed either directly from a data source (e.g. a list of tensors representing the components of the dataset), or as a transformation on an existing dataset.\n+\n+#### From Data Source\n+\n+To construct a dataset from a list of tensor components, use \n+`Dataset.fromTensorSlices( ... )`. For example, say we are working\n+with a standard feature/label dataset which has 4 elements.\n+\n+```java\n+FloatNdArray features = StdArrays.ndCopyOf(\n+        new float[][] {\n+        {1, 2, 3},\n+        {4, 5, 6},\n+        {7, 8, 9},\n+        {10, 11, 12}\n+});\n+\n+FloatNdArray labels = StdArrays.ndCopyOf(\n+    new float[] {\n+        0,\n+        1,\n+        1,\n+        0\n+});\n+```\n+\n+A dataset can be constructed from a list of the constant `Operand`s generated\n+from this dataset, and a list of `DataType` objects corresponding\n+to the type of each component:\n+\n+Note: Each of the input components must share the same first \"batch\" dimension.\n+\n+```java\n+Ops tf = // ... TensorFlow Ops accessor (either graph or eager)\n+Dataset dataset = Dataset.fromTensorSlices(\n+    Arrays.asList(tf.constant(features), tf.constant(labels)),\n+    Arrays.asList(TInt32.DTYPE, TInt32.DTYPE)\n+);\n+```\n+\n+\n+Other data sources are also possible, using `tf.data` ops; these include TFRecord files, CSV files, and more.\n+\n+#### Transformations on Existing Datasets\n+\n+Once a dataset has been created from a data source it can be transformed by calling\n+methods on the `Dataset` object. For example, to group elements in the above dataset into batches of size `2`, use `Dataset.batch(int batchSize)`:\n+\n+```java\n+dataset = dataset.batch(2)\n+```\n+\n+Dataset transformations alter both the values and shapes of the original elements, and\n+return a *new* `Dataset` object.\n+\n+In this case, the original dataset had 4 elements of shape `[features: (3,) labels: (1,)]`.\n+Once the `.batch` transformation is applied, the new dataset has 2 elements (batches) of shape `[features: (2, 3), labels: (2, 1)]`.\n+\n+Similar transformations include `.skip`, `.take`, `.map`, `.filter`, etc.\n+\n+\n+### Iterating over Dataset Elements\n+\n+The primary use of a dataset is for iteration over its elements.\n+Each row (or batch) element is represented as a list of tensor components, with\n+type `List<Output<?>>`. The tensor components of this elements can be accessed using `List.get(int index)`.\n+\n+It is recommended to use `Tensor.expect(DataType<?> dtype)` to restore types\n+to the retrieved tensors.\n+\n+#### Using DatastetIterator\n+The `DatasetIterator` class provides abstractions for creating and using\n+iterators in graph and eager mode. These will be explained here; however\n+end-users should only interact with `Iterator` objects through the methods\n+provided in the `Dataset` class (examples to follow).\n+\n+To construct an iterator for a dataset of a specific structure, use\n+the static method `Iterator.fromStructure(Ops tf, List<DataType<?>> outputTypes, List<Shape> outputShapes)`. This creates a `DatasetIterator` object\n+which can be used with any dataset of a matching structure.\n+\n+Once a `DatasetIterator` is created, it can be initialized on a `Dataset` intsance using `Iterator.makeInitializer(Dataset dataset)`. This will initialize (or re-initialize) the iterator to start at the beginning\n+of this dataset.\n+\n+The `Iterator.getNext()` method can be used to retrieve dataset elements.\n+In eager mode, each call to `getNext()` will return the next dataset element as\n+as `List<Output<?>>`. In graph mode, this method should be called just once\n+to retrieve the components. These can be fed into additional operations as\n+a computation Graph is built. On successive `session.run` operations, the\n+successive dataset elements will be automatically passed through the graph.\n+\n+\n+#### Eager Mode: Iterable\n+The `Dataset` class implements the `Iterable` interface, so in\n+eager mode, iteration over dataset elements is possible using a standard for-each loop (this is a wrapper around `DatasetIterator` constructs).\n+\n+Using the same example dataset from above, dataset elements can be extracted and\n+used as follows:\n+```java\n+// Use default EagerSession\n+Ops tf = Ops.create()\n+\n+// Dataset of (features, labels) from above\n+Dataset dataset = Dataset.fromTensorSlices(tf, ... );\n+\n+// batch dataset elements into batches of size 2\n+dataset = dataset.batch(2);\n+\n+Optmizer optimizer = ... // TF Optimizer\n+\n+for (List<Output<?>> batch : dataset) {\n+    Operand<?> featureBatch = element.get(0);\n+    Operand<?> labelBatch = element.get(1);\n+\n+    // Perform batch-wise computations on featureBatch and labelBatch\n+    // e.g. computing model losses, running optimizers.\n+\n+    Operand<TFloat32> loss = myModelLoss(featureBatch, labelBatch);\n+\n+    optimizer.minimize(loss);\n+    \n+    ...\n+}   \n+\n+```\n+\n+#### Graph Mode: OneShotIterator\n+\n+The above code will not work in graph mode, which requires the use of `Session`s\n+to run the computations. In graph mode, datasets can be iterated over using the `DatasetIterator` abstraction, and a while loop.\n+\n+Once the iterator is initialized, repeated calls to `Session.run` will populate the components with new values, until all elements have\n+been retrieved. After this, `Session.run` will result in an `IndexOutOfBounds` exception.\n+\n+Note that the make-iterator operation can be re-run to re-initialize\n+the iterator, to iterate over the dataset a second time.\n+\n+```java\n+try (Graph graph = new Graph()) {\n+    // Graph mode Ops accessor\n+    Ops tf = Ops.create(graph)\n+\n+    // Dataset of (features, labels) from above\n+    Dataset dataset = Dataset.fromTensorSlices(tf, ... );\n+\n+    // batch dataset elements into batches of size 2\n+    dataset = dataset.batch(2); \n+\n+    // makeOneShotIterator() automatically adds the \n+    // iterator initializer (MakeIterator) Op to the Graph\n+    // initializers list. Make sure to run `session.run(tf.init())`\n+    // first!\n+    DatasetIterator iterator = dataset.makeOneShotIterator();\n+    List<Output<?>> batch = iterator.getNext();\n+\n+    Operand<?> features = batch.get(0);\n+    Operand<?> labels = batch.get(1);\n+\n+    // Run additional computations on `features` and `labels`,\n+    // e.g. computing model losses, instantiating Optimizers\n+\n+    Optimizer optimizer = ... // TF Optimizer \n+    Operand<TFloat32> loss = myModelLoss(features, labels);\n+    \n+    Op trainOp = optimizer.minimize(loss)\n+\n+    // instantiate graph-mode session\n+    try (Session session = new Session(graph)) {\n+        // Run graph initializers (and the iterator initializer)\n+        session.run(tf.init());\n+\n+        // Iterate over dataset elements\n+        while (true) {\n+            try {\n+                // Run training ops / fetch loss\n+                List<Tensor<?>> outputs = session.runner()\n+                    .addTarget(trainOp)\n+                    .fetch(loss)\n+                    .run();\n+\n+                ...\n+\n+            } catch (IndexOutOfBoundsException e) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzA3ODc1MQ=="}, "originalCommit": {"oid": "c8c50b8c61b52a4431a32488908d6d66563abd6f"}, "originalPosition": 212}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTM5OTI4OQ==", "bodyText": "Where in the code do you use this new constructor? is it really required?", "url": "https://github.com/tensorflow/java/pull/30#discussion_r415399289", "createdAt": "2020-04-26T20:57:17Z", "author": {"login": "karllessard"}, "path": "tensorflow-tools/src/main/java/org/tensorflow/tools/Shape.java", "diffHunk": "@@ -61,6 +65,15 @@ public static Shape of(long... dimensionSizes) {\n     return new Shape(dimensionSizes);\n   }\n \n+  public static Shape of(long firstDimensionSize, long[] otherDimensionSizes) {\n+    long[] dimensionSizes = new long[otherDimensionSizes.length + 1];\n+    dimensionSizes[0] = firstDimensionSize;\n+    System.arraycopy(\n+        otherDimensionSizes, 0, dimensionSizes, 1, otherDimensionSizes.length);\n+\n+    return Shape.of(dimensionSizes);\n+  }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "41d1b563c857107b549c80bc16a3c2cdf52a275f"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTM5OTQ5OQ==", "bodyText": "With dash - or without is fine, but let's be consistent :) Since this API is now part of the framework, maybe we don't need to refer to it as a distinct framework. What about simply call this document \"Datasets\"?", "url": "https://github.com/tensorflow/java/pull/30#discussion_r415399499", "createdAt": "2020-04-26T20:58:29Z", "author": {"login": "karllessard"}, "path": "tensorflow-framework/tensorflow-data.md", "diffHunk": "@@ -0,0 +1,209 @@\n+\n+NOTE: This readme follows the discussion of this [RFC]()\n+\n+\n+Tensorflow-Data (Java)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "41d1b563c857107b549c80bc16a3c2cdf52a275f"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTQwMDA2OA==", "bodyText": "My English is not great but I think something is off in this sentence... maybe:\n\"The Datasets provides an abstraction for loading data of various formats and preparing it for training of deep learning models\"?", "url": "https://github.com/tensorflow/java/pull/30#discussion_r415400068", "createdAt": "2020-04-26T21:01:29Z", "author": {"login": "karllessard"}, "path": "tensorflow-framework/tensorflow-data.md", "diffHunk": "@@ -0,0 +1,209 @@\n+\n+NOTE: This readme follows the discussion of this [RFC]()\n+\n+\n+Tensorflow-Data (Java)\n+==\n+\n+TensorFlow Data provides utilities and APIs for loading data of various formats, and preparing datasets for use in training and using deep learning models", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "41d1b563c857107b549c80bc16a3c2cdf52a275f"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTQwMDE3Ng==", "bodyText": "again, is it List<Output<?>> or List<Operand<?>>?", "url": "https://github.com/tensorflow/java/pull/30#discussion_r415400176", "createdAt": "2020-04-26T21:02:01Z", "author": {"login": "karllessard"}, "path": "tensorflow-framework/tensorflow-data.md", "diffHunk": "@@ -0,0 +1,209 @@\n+\n+NOTE: This readme follows the discussion of this [RFC]()\n+\n+\n+Tensorflow-Data (Java)\n+==\n+\n+TensorFlow Data provides utilities and APIs for loading data of various formats, and preparing datasets for use in training and using deep learning models\n+. This package\n+ provides a\n+ simple API for configuring and iterating over\n+ datasets in both \"graph\" and \"eager\" mode.\n+\n+Usage\n+--\n+\n+The `Dataset` class represents a sequence of elements which can be iterated over and\n+transformed. Each element is a list of \"output\" operands, represented by the type `List<Output<?>>`. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "41d1b563c857107b549c80bc16a3c2cdf52a275f"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTQwMDU4MQ==", "bodyText": "I think many reference to Iterator should be replaced by DatasetIterator here.", "url": "https://github.com/tensorflow/java/pull/30#discussion_r415400581", "createdAt": "2020-04-26T21:04:11Z", "author": {"login": "karllessard"}, "path": "tensorflow-framework/tensorflow-data.md", "diffHunk": "@@ -0,0 +1,209 @@\n+\n+NOTE: This readme follows the discussion of this [RFC]()\n+\n+\n+Tensorflow-Data (Java)\n+==\n+\n+TensorFlow Data provides utilities and APIs for loading data of various formats, and preparing datasets for use in training and using deep learning models\n+. This package\n+ provides a\n+ simple API for configuring and iterating over\n+ datasets in both \"graph\" and \"eager\" mode.\n+\n+Usage\n+--\n+\n+The `Dataset` class represents a sequence of elements which can be iterated over and\n+transformed. Each element is a list of \"output\" operands, represented by the type `List<Output<?>>`. \n+\n+Note: An `Output` is a symbolic handle to a tensor produced by a TensorFlow op. In graph\n+mode, `Output` objects will not have a concrete `Tensor` value unless all dependent operations\n+are run in a `Session` (this is done \"in-real-time\" in eager mode).\n+\n+### Construction\n+\n+Datasets can be constructed either directly from a data source (e.g. a list of tensors representing the components of the dataset), or as a transformation on an existing dataset.\n+\n+#### From Data Source\n+\n+To construct a dataset from a list of tensor components, use \n+`Dataset.fromTensorSlices( ... )`. For example, say we are working\n+with a standard feature/label dataset which has 4 elements.\n+\n+```java\n+FloatNdArray features = StdArrays.ndCopyOf(\n+        new float[][] {\n+        {1, 2, 3},\n+        {4, 5, 6},\n+        {7, 8, 9},\n+        {10, 11, 12}\n+});\n+\n+FloatNdArray labels = NdArrays.vectorOf(0, 1, 1, 0);\n+```\n+\n+A dataset can be constructed from a list of the constant `Operand`s generated\n+from this dataset, and a list of `DataType` objects corresponding\n+to the type of each component:\n+\n+Note: Each of the input components must share the same first \"batch\" dimension.\n+\n+```java\n+Ops tf = // ... TensorFlow Ops accessor (either graph or eager)\n+Dataset dataset = Dataset.fromTensorSlices(\n+    Arrays.asList(tf.constant(features), tf.constant(labels)),\n+    Arrays.asList(TInt32.DTYPE, TInt32.DTYPE)\n+);\n+```\n+\n+\n+Other data sources are also possible, using `tf.data` ops; these include TFRecord files, CSV files, and more.\n+\n+#### Transformations on Existing Datasets\n+\n+Once a dataset has been created from a data source it can be transformed by calling\n+methods on the `Dataset` object. For example, to group elements in the above dataset into batches of size `2`, use `Dataset.batch(int batchSize)`:\n+\n+```java\n+dataset = dataset.batch(2)\n+```\n+\n+Each dataset transformation alters both the values and shapes of the original\n+ elements, and returns a *new* `Dataset` object.\n+\n+In this case, the original dataset had 4 elements of shape `[features: (3,) labels: (1,)]`.\n+Once the `.batch` transformation is applied, the new dataset has 2 elements (batches) of shape `[features: (2, 3), labels: (2, 1)]`.\n+\n+Similar transformations include `.skip`, `.take`, `.map`, `.filter`, etc.\n+\n+\n+### Iterating over Dataset Elements\n+\n+The primary use of a dataset is for iteration over its elements.\n+Each row (or batch) element is represented as a list of tensor components, with\n+type `List<Output<?>>`. The tensor components of this element can be accessed using `List.get(int index)`.\n+\n+It is recommended to use `Tensor.expect(DataType<?> dtype)` to restore types\n+to the retrieved tensors.\n+\n+#### Using DatastetIterator\n+The `DatasetIterator` class provides abstractions for creating and using\n+iterators in graph and eager mode. These will be explained here; however\n+end-users should only interact with `Iterator` objects through the methods", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "41d1b563c857107b549c80bc16a3c2cdf52a275f"}, "originalPosition": 93}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ebffd1ebd015778b55140c8840112e5fb922a6c4", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/ebffd1ebd015778b55140c8840112e5fb922a6c4", "committedDate": "2020-04-26T23:26:15Z", "message": "remove unnecessary files, add copyrights, format with google java style, update documentation"}, "afterCommit": {"oid": "27531333ac3d3664b02b73fe904d0bb96e74de46", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/27531333ac3d3664b02b73fe904d0bb96e74de46", "committedDate": "2020-04-26T23:31:03Z", "message": ":wqremove unnecessary files, add copyrights, format with google java style, update documentation"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "27531333ac3d3664b02b73fe904d0bb96e74de46", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/27531333ac3d3664b02b73fe904d0bb96e74de46", "committedDate": "2020-04-26T23:31:03Z", "message": ":wqremove unnecessary files, add copyrights, format with google java style, update documentation"}, "afterCommit": {"oid": "3fd9b3f555b9ffa32362feb0d8ddc5bc0839a909", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/3fd9b3f555b9ffa32362feb0d8ddc5bc0839a909", "committedDate": "2020-04-27T00:32:00Z", "message": ":wqremove unnecessary files, add copyrights, format with google java style, update documentation"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "3fd9b3f555b9ffa32362feb0d8ddc5bc0839a909", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/3fd9b3f555b9ffa32362feb0d8ddc5bc0839a909", "committedDate": "2020-04-27T00:32:00Z", "message": ":wqremove unnecessary files, add copyrights, format with google java style, update documentation"}, "afterCommit": {"oid": "48fd49ea88f354386efdce776560dda8f5b1f677", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/48fd49ea88f354386efdce776560dda8f5b1f677", "committedDate": "2020-04-27T00:33:13Z", "message": ":wqremove unnecessary files, add copyrights, format with google java style, update documentation"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "48fd49ea88f354386efdce776560dda8f5b1f677", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/48fd49ea88f354386efdce776560dda8f5b1f677", "committedDate": "2020-04-27T00:33:13Z", "message": ":wqremove unnecessary files, add copyrights, format with google java style, update documentation"}, "afterCommit": {"oid": "43f6be7a74403c3c4cb9d42beed089b325b0bb46", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/43f6be7a74403c3c4cb9d42beed089b325b0bb46", "committedDate": "2020-04-27T00:35:05Z", "message": ":wqremove unnecessary files, add copyrights, format with google java style, update documentation"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a1263ceab08e313a5f937015becfa672d0a4e039", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/a1263ceab08e313a5f937015becfa672d0a4e039", "committedDate": "2020-04-27T00:54:02Z", "message": "Convert batches from List<Output<?>> to List<Operand<?>>"}, "afterCommit": {"oid": "a5fdab794291a33048fad1ddea3c0113209b0dad", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/a5fdab794291a33048fad1ddea3c0113209b0dad", "committedDate": "2020-04-27T00:56:59Z", "message": "Convert batches from List<Output<?>> to List<Operand<?>>"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a5fdab794291a33048fad1ddea3c0113209b0dad", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/a5fdab794291a33048fad1ddea3c0113209b0dad", "committedDate": "2020-04-27T00:56:59Z", "message": "Convert batches from List<Output<?>> to List<Operand<?>>"}, "afterCommit": {"oid": "dc662469d9eb52a8cc835bf15f98ff24b0a5dd50", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/dc662469d9eb52a8cc835bf15f98ff24b0a5dd50", "committedDate": "2020-04-27T15:22:29Z", "message": "Convert batches from List<Output<?>> to List<Operand<?>>"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "dc662469d9eb52a8cc835bf15f98ff24b0a5dd50", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/dc662469d9eb52a8cc835bf15f98ff24b0a5dd50", "committedDate": "2020-04-27T15:22:29Z", "message": "Convert batches from List<Output<?>> to List<Operand<?>>"}, "afterCommit": {"oid": "a7d4d0e992c6ff0525f2cada08d34cd4b20d3cdc", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/a7d4d0e992c6ff0525f2cada08d34cd4b20d3cdc", "committedDate": "2020-04-27T15:23:48Z", "message": "Convert batches from List<Output<?>> to List<Operand<?>>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAyMzE2MzY4", "url": "https://github.com/tensorflow/java/pull/30#pullrequestreview-402316368", "createdAt": "2020-04-29T01:24:48Z", "commit": {"oid": "a7d4d0e992c6ff0525f2cada08d34cd4b20d3cdc"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQwMToyNDo0OFrOGNszLw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQwMTozNTo1MVrOGNs8_g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzAxODY3MQ==", "bodyText": "Just noticed this, if we auto-close tensors resulting from a run, we should allow the user to retain a reference to one or more of them so the tensor will survive beyond the life of Run if needed.\nThis could be done by adding a utility method like Tensor.retain() which will call tensorHandle.retainReference() internally... or we remove this change from this actual PR and do it later, your choice.", "url": "https://github.com/tensorflow/java/pull/30#discussion_r417018671", "createdAt": "2020-04-29T01:24:48Z", "author": {"login": "karllessard"}, "path": "tensorflow-core/tensorflow-core-api/src/main/java/org/tensorflow/Session.java", "diffHunk": "@@ -485,6 +475,26 @@ public void run(Op op) {\n      * this field may be replaced by more type-safe equivalents at any time.\n      */\n     public RunMetadata metadata;\n+\n+    Run(List<Tensor<?>> outputs, RunMetadata metadata) {\n+      this.outputs = outputs;\n+      this.metadata = metadata;\n+    }\n+\n+    Run(List<Tensor<?>> outputs) {\n+      this.outputs = outputs;\n+    }\n+\n+    public Tensor<?> get(int index) {\n+      return this.outputs.get(index);\n+    }\n+\n+    @Override\n+    public void close() {\n+      for (Tensor<?> tensor : this.outputs) {\n+        tensor.close();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a7d4d0e992c6ff0525f2cada08d34cd4b20d3cdc"}, "originalPosition": 176}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzAxODk4Mw==", "bodyText": "This shouldn't be there as well.", "url": "https://github.com/tensorflow/java/pull/30#discussion_r417018983", "createdAt": "2020-04-29T01:26:08Z", "author": {"login": "karllessard"}, "path": "tensorflow-framework/pom.xml", "diffHunk": "@@ -64,7 +65,7 @@\n         <configuration>\n           <forkCount>1</forkCount>\n           <reuseForks>false</reuseForks>\n-          <argLine>-Xmx2G -XX:MaxPermSize=256m</argLine>\n+          <argLine>-Xmx2G -XX:MaxPermSize=256m -Djava.library.path=${basedir}/../tensorflow-core/tensorflow-core-api/target/native/org/tensorflow/internal/c_api/linux-x86_64/</argLine>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a7d4d0e992c6ff0525f2cada08d34cd4b20d3cdc"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzAxOTMxMw==", "bodyText": "AFAIK, you don't work at Oracle :)\nI suggest you change all copyrights to Copyright 2020 The TensorFlow Authors. All Rights Reserved., like most of the files in the core module, that is what I'm using too.", "url": "https://github.com/tensorflow/java/pull/30#discussion_r417019313", "createdAt": "2020-04-29T01:27:30Z", "author": {"login": "karllessard"}, "path": "tensorflow-framework/src/main/java/org/tensorflow/framework/data/Dataset.java", "diffHunk": "@@ -0,0 +1,213 @@\n+/*\r\n+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.\r", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a7d4d0e992c6ff0525f2cada08d34cd4b20d3cdc"}, "originalPosition": 2}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzAxOTY3OQ==", "bodyText": "extra-line is still there but whatever, not important  :)", "url": "https://github.com/tensorflow/java/pull/30#discussion_r417019679", "createdAt": "2020-04-29T01:29:00Z", "author": {"login": "karllessard"}, "path": "tensorflow-framework/src/main/java/org/tensorflow/framework/data/DatasetIterator.java", "diffHunk": "@@ -0,0 +1,242 @@\n+package org.tensorflow.framework.data;\n+\n+import org.tensorflow.DataType;\n+import org.tensorflow.Graph;\n+import org.tensorflow.Operand;\n+import org.tensorflow.Output;\n+import org.tensorflow.op.Op;\n+import org.tensorflow.op.Ops;\n+import org.tensorflow.tools.Shape;\n+\n+import java.util.List;\n+\n+/**\n+ * Represents the state of an iteration through\n+ * a tf.data Datset. DatasetIterator is not\n+ * a java.util.Iterator. In eager mode, `Dataset`\n+ * can be used as an Iterable, returning dataset\n+ * elements each iteration.\n+ *\n+ * <p>\n+ * Example: Iteration in graph mode.\n+ *\n+ * <pre>{@code\n+ *  // Create input tensors\n+ *  Operand<?> XTensor = tf.constant( ... );\n+ *  Operand<?> yTensor = tf.constant( ... );\n+ *\n+ *\n+ *  Dataset dataset = Dataset\n+ *          .fromTensorSlices(XTensor, yTensor);\n+ *          .batch(BATCH_SIZE);\n+ *\n+ *  DatasetIterator iterator = dataset.makeIterator();\n+ *  List<Output<?>> components = iterator.getNext();\n+ *  Operand<?> XBatch = components.get(0);\n+ *  Operand<?> yBatch = components.get(1);\n+ *\n+ *  // Build a TensorFlow graph that does something on each element.\n+ *  loss = computeModelLoss(X, y);\n+ *\n+ *  optimizer = ... // create an optimizer\n+ *  trainOp = optimizer.minimize(loss);\n+ *\n+ *  try (Session session = new Session(graph) {\n+ *      try {\n+ *          session.run(trainOp);\n+ *          ...\n+ *      } catch (IndexOutOfBoundsException e) {\n+ *          System.out.println(\"finished iterating.\");\n+ *          break;\n+ *      }\n+ *  }\n+ *\n+ * }</pre>\n+ * <p>\n+ * Example: Iteration in eager mode.\n+ *\n+ * <pre>{@code\n+ *  // Create input tensors\n+ *  Operand<?> XTensor = tf.constant( ... );\n+ *  Operand<?> yTensor = tf.constant( ... );\n+ *\n+ *  int BATCH_SIZE = ...\n+ *\n+ *  Dataset dataset = Dataset\n+ *          .fromTensorSlices(XTensor, yTensor)\n+ *          .batch(BATCH_SIZE);\n+ *  DatasetIterator iterator = dataset.makeIterator();\n+ *\n+ *  Optimizer optimizer = ... // create an optimizer\n+ *\n+ *  for (List<Output<?>> components : dataset) {\n+ *      Operand<?> XBatch = components.get(0);\n+ *      Operand<?> yBatch = components.get(1);\n+ *\n+ *      loss = computeModelLoss(X, y);\n+ *      trainOp = optimizer.minimize(loss);\n+ *  }\n+ * }</pre>\n+ */\n+public class DatasetIterator {\n+  public static final String EMPTY_SHARED_NAME = \"\";\n+\n+  private Ops tf;\n+\n+  private Operand<?> iteratorResource;\n+  private Op initializer;\n+\n+  private List<DataType<?>> outputTypes;\n+  private List<Shape> outputShapes;\n+\n+  /**\n+   * @param tf               Ops accessor corresponding to the same `ExecutionEnvironment`\n+   *                         as the `iteratorResource`.\n+   * @param iteratorResource An Operand representing the iterator\n+   *                         (e.g. constructed from `tf.data.iterator` or\n+   *                         `tf.data.anonymousIterator`)\n+   * @param initializer      An `Op` that should be run to initialize this iterator\n+   * @param outputTypes      A list of `DataType` objects corresponding to the\n+   *                         types of each component of a dataset element.\n+   * @param outputShapes     A list of `Shape` objects corresponding to the\n+   *                         shapes of each componenet of a dataset element.\n+   */\n+  private DatasetIterator(Ops tf, Operand<?> iteratorResource,\n+                          Op initializer,\n+                          List<DataType<?>> outputTypes,\n+                          List<Shape> outputShapes) {\n+\n+    this.tf = tf;\n+    this.iteratorResource = iteratorResource;\n+    this.initializer = initializer;\n+    this.outputTypes = outputTypes;\n+    this.outputShapes = outputShapes;\n+  }\n+\n+  private DatasetIterator(Ops tf, Operand<?> iteratorResource,\n+                          List<DataType<?>> outputTypes,\n+                          List<Shape> outputShapes) {\n+    this.tf = tf;\n+    this.iteratorResource = iteratorResource;\n+    this.outputTypes = outputTypes;\n+    this.outputShapes = outputShapes;\n+  }\n+\n+  /**\n+   * Returns a list of `Operand<?>` representing the components of the\n+   * next dataset element.\n+   * <p>\n+   * In graph mode, call this method once, and use its result as input\n+   * to another computation. Then in the training loop, on successive calls\n+   * to session.run(), successive dataset elements will be retrieved through\n+   * these components.\n+   * <p>\n+   * In eager mode, each time this method is called, the next dataset\n+   * element will be returned. (This is done automatically by iterating\n+   * through `Dataset` as a Java `Iterable`).\n+   *\n+   * @return A `List<Operand<?>>` representing dataset element components.\n+   */\n+  public List<Output<?>> getNext() {\n+    return tf.data.iteratorGetNext(getIteratorResource(),\n+        getOutputTypes(), getOutputShapes()).components();\n+  }\n+\n+  /**\n+   * Returns a list of `Operand<?>` representing the components of the\n+   * next dataset element.\n+   * <p>\n+   * In graph mode, call this method once, and use its result as input\n+   * to another computation. Then in the training loop, on successive calls\n+   * to session.run(), successive dataset elements will be retrieved through\n+   * these components.\n+   * <p>\n+   * In eager mode, each time this method is called, the next dataset\n+   * element will be returned. (This is done automatically by iterating\n+   * through `Dataset` as a Java `Iterable`).\n+   *\n+   * @return A `List<Operand<?>>` representing dataset element components.\n+   */\n+  public DatasetOptional getNextAsOptional() {\n+    Operand<?> optionalVariant = tf.data.iteratorGetNextAsOptional(\n+        getIteratorResource(),\n+        getOutputTypes(),\n+        getOutputShapes()).optional();\n+    return new DatasetOptional(tf, optionalVariant, outputTypes,\n+        outputShapes);\n+  }\n+\n+  /**\n+   * Creates and returns a TF `Op` that can be run to initialize\n+   * this iterator on a dataset. The dataset must have a structure\n+   * (outputTypes, outputShapes) that match this iterator, and\n+   * share the same ExecutionEnvironment as this iterator.\n+   * <p>\n+   * When this `Op` is run, this iterator will be \"re-initialized\" at\n+   * the first element of the input dataset.\n+   * <p>\n+   * In eager mode, the op will be run automatically as part of\n+   * a call to `makeIterator`.\n+   *\n+   * @param dataset An `org.tensorflow.data.Dataset` to initialize this\n+   *                iterator on.\n+   * @return A TF `Op` that can be used to initialize this iterator on the\n+   * dataset.\n+   * @throws IllegalArgumentException if the dataset's ExecutionEnvironment or\n+   *                                  structure doesn't match this iterator.\n+   */\n+  public Op makeInitializer(Dataset dataset) {\n+    if (tf.scope().env() != dataset.tf.scope().env()) {\n+      throw new IllegalArgumentException(\"Dataset must share the same\" +\n+          \"ExecutionEnvironment as this iterator.\");\n+    }\n+\n+    if (!dataset.getOutputShapes().equals(getOutputShapes())\n+        || !dataset.getOutputTypes().equals(getOutputTypes())) {\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTM5NzUxMQ=="}, "originalCommit": {"oid": "41d1b563c857107b549c80bc16a3c2cdf52a275f"}, "originalPosition": 196}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzAyMDM2NQ==", "bodyText": "I'm still not sure if we should have individual .md files per package or just one big README.md that is correctly split into sections... but I think that's fine for now.", "url": "https://github.com/tensorflow/java/pull/30#discussion_r417020365", "createdAt": "2020-04-29T01:31:48Z", "author": {"login": "karllessard"}, "path": "tensorflow-framework/tensorflow-data.md", "diffHunk": "@@ -0,0 +1,201 @@\n+Tensorflow Data (Java)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a7d4d0e992c6ff0525f2cada08d34cd4b20d3cdc"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzAyMTE4Mg==", "bodyText": "But if the main reason is to add an extra dimension to an existing shape, I would prefer having a method called Shape prepend(dimensionSizes) or something like that than a new constructor.\nWe should be able also to \"reshape\" a shape ultimately (i.e. changing [2, 3, 2] to [2, 1, 2, 3]) with a utility called Shape reshape(dimensionsSizes)... but it sounds that in your case, prepend would be a better pick? Like you did with head and tail?", "url": "https://github.com/tensorflow/java/pull/30#discussion_r417021182", "createdAt": "2020-04-29T01:35:51Z", "author": {"login": "karllessard"}, "path": "tensorflow-tools/src/main/java/org/tensorflow/tools/Shape.java", "diffHunk": "@@ -61,6 +65,15 @@ public static Shape of(long... dimensionSizes) {\n     return new Shape(dimensionSizes);\n   }\n \n+  public static Shape of(long firstDimensionSize, long[] otherDimensionSizes) {\n+    long[] dimensionSizes = new long[otherDimensionSizes.length + 1];\n+    dimensionSizes[0] = firstDimensionSize;\n+    System.arraycopy(\n+        otherDimensionSizes, 0, dimensionSizes, 1, otherDimensionSizes.length);\n+\n+    return Shape.of(dimensionSizes);\n+  }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTM5OTI4OQ=="}, "originalCommit": {"oid": "41d1b563c857107b549c80bc16a3c2cdf52a275f"}, "originalPosition": 30}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b806fcb067d2bf42e03a16ae81fd00f13ebd36e0", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/b806fcb067d2bf42e03a16ae81fd00f13ebd36e0", "committedDate": "2020-04-29T15:48:23Z", "message": "initial tf.data mvn project"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ab1d31fc14beee53eaa9c8aab2677d7ed6ed25fc", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/ab1d31fc14beee53eaa9c8aab2677d7ed6ed25fc", "committedDate": "2020-04-29T15:48:23Z", "message": "make relevant data ops visible"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "89bd94fd6e2bb1e9cb7c3c6398581975339b3db5", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/89bd94fd6e2bb1e9cb7c3c6398581975339b3db5", "committedDate": "2020-04-29T15:48:23Z", "message": "TensorFlow Data examples with batching working in graph / eager mode"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2bb5e528669bc7fc8cdd298052e02e25f553ea60", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/2bb5e528669bc7fc8cdd298052e02e25f553ea60", "committedDate": "2020-04-29T15:48:23Z", "message": "adding take and skip dataset"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "27bb08152a254e657b5552458be980053c8c86b0", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/27bb08152a254e657b5552458be980053c8c86b0", "committedDate": "2020-04-29T15:48:23Z", "message": "added tests for tf dataset iteration"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f51b52ec3a9df57f3aa9a2ea5ee1cda5c9c1f3db", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/f51b52ec3a9df57f3aa9a2ea5ee1cda5c9c1f3db", "committedDate": "2020-04-29T15:48:23Z", "message": "added tests for all dataset types (skip, take, batch)"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a5054cf6fbc44a2d4ddff9b227f8f3fe2abb5e5e", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/a5054cf6fbc44a2d4ddff9b227f8f3fe2abb5e5e", "committedDate": "2020-04-29T15:48:23Z", "message": "adding readme for tf data"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bc11142e55a3aed127db4e819299f68707cf7c45", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/bc11142e55a3aed127db4e819299f68707cf7c45", "committedDate": "2020-04-29T15:48:23Z", "message": "adding readme for tf data"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a94ff974ec291ec2e7c2a8043de38accdd557496", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/a94ff974ec291ec2e7c2a8043de38accdd557496", "committedDate": "2020-04-29T15:48:23Z", "message": "oneshotiterator class"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "107e2b45f51657294b446d15bea50ee03f3924e3", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/107e2b45f51657294b446d15bea50ee03f3924e3", "committedDate": "2020-04-29T15:48:23Z", "message": "updated .gitignore for vs code"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7e727b7c5cdbe5914e8e3740853d5a5e93852344", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/7e727b7c5cdbe5914e8e3740853d5a5e93852344", "committedDate": "2020-04-29T15:48:23Z", "message": "revert pom.xml files to master version"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2a8a2c1dd7085fdb0d865afcd84dba0a76574cc0", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/2a8a2c1dd7085fdb0d865afcd84dba0a76574cc0", "committedDate": "2020-04-29T15:48:23Z", "message": "committing pom"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "83e1f893b3ffceb2777c2d616a00d26b62320b7e", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/83e1f893b3ffceb2777c2d616a00d26b62320b7e", "committedDate": "2020-04-29T15:48:23Z", "message": "remove target from .gitignore"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2b74d96cfbf223b7b2a94c9347a15f1d268fac87", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/2b74d96cfbf223b7b2a94c9347a15f1d268fac87", "committedDate": "2020-04-29T15:48:23Z", "message": "tf data finds jni resource"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "17c56426601258b4b6dd3e21883d6b8e553b9fd5", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/17c56426601258b4b6dd3e21883d6b8e553b9fd5", "committedDate": "2020-04-29T15:48:23Z", "message": "make dataset ops visible"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0dfa0ae7a092e5ea45f4ba072c6ec30ad4fc7b00", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/0dfa0ae7a092e5ea45f4ba072c6ec30ad4fc7b00", "committedDate": "2020-04-29T15:48:23Z", "message": "fix dataset issues; comment keras files"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c357b2178b56427e68913ad4fdd2529f82304c67", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/c357b2178b56427e68913ad4fdd2529f82304c67", "committedDate": "2020-04-29T15:48:23Z", "message": "tf data tests pass"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "37c82617e778c84a88b48553ef031dc327ecc298", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/37c82617e778c84a88b48553ef031dc327ecc298", "committedDate": "2020-04-29T15:48:23Z", "message": "working tests in vscode"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "39e53c2a66ecbc53a6fa84a419d629fe9924d4c5", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/39e53c2a66ecbc53a6fa84a419d629fe9924d4c5", "committedDate": "2020-04-29T15:48:23Z", "message": "add range dataset"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0773496a0eb5d5563d595f6bca6daad6a6a05f5c", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/0773496a0eb5d5563d595f6bca6daad6a6a05f5c", "committedDate": "2020-04-29T15:48:23Z", "message": "refactor mnist data loader"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ef8419aa4a73a14bb301175c8b9682cd6aa881e3", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/ef8419aa4a73a14bb301175c8b9682cd6aa881e3", "committedDate": "2020-04-29T15:48:23Z", "message": "add 'expect' method to Output object"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8ee7759665640efbc8b711eaa8f7c817d58f3b44", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/8ee7759665640efbc8b711eaa8f7c817d58f3b44", "committedDate": "2020-04-29T15:48:23Z", "message": "refactor"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "64df39b650b0a08771b70092c34de79c19cf5dc0", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/64df39b650b0a08771b70092c34de79c19cf5dc0", "committedDate": "2020-04-29T15:48:23Z", "message": "revert change to base tensorfow file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "919a31c63b527f5bd378fdd0f5a857f5d004b280", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/919a31c63b527f5bd378fdd0f5a857f5d004b280", "committedDate": "2020-04-29T15:48:23Z", "message": "working on data readme"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e6dc8eaa9e311a5b974c21e96f989723155c56ec", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/e6dc8eaa9e311a5b974c21e96f989723155c56ec", "committedDate": "2020-04-29T15:48:23Z", "message": "updated tf.data README"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "62b5050af817a9a2fe5752ef7433814901bc5087", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/62b5050af817a9a2fe5752ef7433814901bc5087", "committedDate": "2020-04-29T15:48:23Z", "message": "move pair and tuple2 to utils"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "41f3c294bb986da1c55e7060c75d12a28b3bf7db", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/41f3c294bb986da1c55e7060c75d12a28b3bf7db", "committedDate": "2020-04-29T15:48:23Z", "message": "utils pom files"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0920e56fa6721d85d781817c87f4fb7ed3c61f63", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/0920e56fa6721d85d781817c87f4fb7ed3c61f63", "committedDate": "2020-04-29T15:48:23Z", "message": "Fix pom structure, add back oneshotiterator"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f03419b54f71a7732fad4a19bd2595ad2215026a", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/f03419b54f71a7732fad4a19bd2595ad2215026a", "committedDate": "2020-04-29T15:48:23Z", "message": "updated README"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2811294fa7652ead1ce1ac441af925811db39c11", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/2811294fa7652ead1ce1ac441af925811db39c11", "committedDate": "2020-04-29T15:48:23Z", "message": "remove shuffle and range dataset"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "844b223989bda6670279917616aeb9c02aa0f5a9", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/844b223989bda6670279917616aeb9c02aa0f5a9", "committedDate": "2020-04-29T15:48:23Z", "message": "rebase on new tensorflow commit"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6e6e763717a5fed3fd762735e0cc1a331541bf8e", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/6e6e763717a5fed3fd762735e0cc1a331541bf8e", "committedDate": "2020-04-29T15:48:24Z", "message": "fixed mvn compile"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ed9b405a921a8d9d142aaa9b45c8bda4287ef80f", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/ed9b405a921a8d9d142aaa9b45c8bda4287ef80f", "committedDate": "2020-04-29T15:48:24Z", "message": "make relevant data ops visible"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fca73ff129ca67a9f920bac64b5e9e34301c4e08", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/fca73ff129ca67a9f920bac64b5e9e34301c4e08", "committedDate": "2020-04-29T15:48:24Z", "message": "TensorFlow Data examples with batching working in graph / eager mode"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "47fd5c43c4832b4129f06b8f317d2f95a68c5f65", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/47fd5c43c4832b4129f06b8f317d2f95a68c5f65", "committedDate": "2020-04-29T15:48:24Z", "message": "adding take and skip dataset"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "16c75dd1a825bf47dc72ae4a226b4ea0b94c1a3e", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/16c75dd1a825bf47dc72ae4a226b4ea0b94c1a3e", "committedDate": "2020-04-29T15:48:24Z", "message": "added tests for tf dataset iteration"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "219bb69cf4eacc7937f76576caf39322e81be694", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/219bb69cf4eacc7937f76576caf39322e81be694", "committedDate": "2020-04-29T15:48:24Z", "message": "added tests for all dataset types (skip, take, batch)"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "62a96ac19f766652ee7a16981312895519312abc", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/62a96ac19f766652ee7a16981312895519312abc", "committedDate": "2020-04-29T15:48:24Z", "message": "oneshotiterator class"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "94362d9a08f5ef8ac3fdf4c723e90999204c7a37", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/94362d9a08f5ef8ac3fdf4c723e90999204c7a37", "committedDate": "2020-04-29T15:48:24Z", "message": "tf data finds jni resource"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "77de569c20b7565df12dc63e2c63d736b8575b95", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/77de569c20b7565df12dc63e2c63d736b8575b95", "committedDate": "2020-04-29T15:48:24Z", "message": "fix dataset issues; comment keras files"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "26c51706a8dd418d4f4de141fe9a0738c8e12202", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/26c51706a8dd418d4f4de141fe9a0738c8e12202", "committedDate": "2020-04-29T15:48:24Z", "message": "tf data tests pass"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2baf8ca4bcd5eecac8eb88f4bdc02c4dce2d401e", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/2baf8ca4bcd5eecac8eb88f4bdc02c4dce2d401e", "committedDate": "2020-04-29T15:48:24Z", "message": "working tests in vscode"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0a19df75032c9960f8ae6a2643eb31a579dfdc58", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/0a19df75032c9960f8ae6a2643eb31a579dfdc58", "committedDate": "2020-04-29T15:48:24Z", "message": "add range dataset"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d9a1e47a731127061364620bea099b900598657d", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/d9a1e47a731127061364620bea099b900598657d", "committedDate": "2020-04-29T15:48:24Z", "message": "refactor mnist data loader"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1959618bad4d3c02ca39da4dd9fb8025900668f4", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/1959618bad4d3c02ca39da4dd9fb8025900668f4", "committedDate": "2020-04-29T15:48:24Z", "message": "refactor"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5c02d03b8ace2b3628ad0ea54bd8f48c98c7bdd4", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/5c02d03b8ace2b3628ad0ea54bd8f48c98c7bdd4", "committedDate": "2020-04-29T15:48:24Z", "message": "revert change to base tensorfow file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "20e637390a22beb606b3756a5d4b269d3a268e5a", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/20e637390a22beb606b3756a5d4b269d3a268e5a", "committedDate": "2020-04-29T15:48:24Z", "message": "working on data readme"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "db2cbf8116e1e140ed41cd43bad298054d76087e", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/db2cbf8116e1e140ed41cd43bad298054d76087e", "committedDate": "2020-04-29T15:48:24Z", "message": "updated tf.data README"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9637b9655b7e895bd903a455ffcb283e801a8e75", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/9637b9655b7e895bd903a455ffcb283e801a8e75", "committedDate": "2020-04-29T15:48:24Z", "message": "move pair and tuple2 to utils"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "593810f6e4ea19a260a879fcfd2551c6ec1226e9", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/593810f6e4ea19a260a879fcfd2551c6ec1226e9", "committedDate": "2020-04-29T15:48:24Z", "message": "utils pom files"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "db82c3375202faa9f181be10f9f9d731bb3a42a9", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/db82c3375202faa9f181be10f9f9d731bb3a42a9", "committedDate": "2020-04-29T15:48:24Z", "message": "Fix pom structure, add back oneshotiterator"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9c270b45da3212cf6f6e45902b818fb7bbf0a0e8", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/9c270b45da3212cf6f6e45902b818fb7bbf0a0e8", "committedDate": "2020-04-29T15:48:24Z", "message": "remove shuffle and range dataset"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "439af82f902003610d279d8066deda57d2b8794d", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/439af82f902003610d279d8066deda57d2b8794d", "committedDate": "2020-04-29T15:48:24Z", "message": "rebase on new tensorflow commit"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "950d258f5d2563dbed78e665a6811ee47b219e9d", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/950d258f5d2563dbed78e665a6811ee47b219e9d", "committedDate": "2020-04-29T15:48:24Z", "message": "ensure tests pass, rebase on newest changes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "782601ccccae1ad6711ec2320d0aa9bbbae738e4", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/782601ccccae1ad6711ec2320d0aa9bbbae738e4", "committedDate": "2020-04-29T15:48:24Z", "message": "refactor"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5ddba23ef65d94963214e6bdef643f073f28d1a0", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/5ddba23ef65d94963214e6bdef643f073f28d1a0", "committedDate": "2020-04-29T15:48:24Z", "message": "remove tensorflow utils"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "23d87dbfe038de8f3256ba1566477fd5f1bd4bd5", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/23d87dbfe038de8f3256ba1566477fd5f1bd4bd5", "committedDate": "2020-04-29T15:48:24Z", "message": "fix compilation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9f64c2e37d178c78f3d516431b425878bd8506f8", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/9f64c2e37d178c78f3d516431b425878bd8506f8", "committedDate": "2020-04-29T15:48:24Z", "message": "fix compilation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8e70d331f93192d2789d1a9072b9d6771fd9d354", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/8e70d331f93192d2789d1a9072b9d6771fd9d354", "committedDate": "2020-04-29T15:48:24Z", "message": "add Iterator class for iterating over datasets in eager and graph  mode."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9b79be345591f4cb71b37a73abf22de68ead468d", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/9b79be345591f4cb71b37a73abf22de68ead468d", "committedDate": "2020-04-29T15:48:24Z", "message": "add javadoc for tf.data"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2b91aa31531b7f38b308a7dbf7f5ffbbd3a157db", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/2b91aa31531b7f38b308a7dbf7f5ffbbd3a157db", "committedDate": "2020-04-29T15:48:24Z", "message": "Using NdArray in tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "84d9b7e47e58ab7a7a3b1b5a55df96b3d7c04efd", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/84d9b7e47e58ab7a7a3b1b5a55df96b3d7c04efd", "committedDate": "2020-04-29T15:48:24Z", "message": "use try-with-resources for test tensors"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f33f02bbbe32043b59bd875a34bbd8fe597511ac", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/f33f02bbbe32043b59bd875a34bbd8fe597511ac", "committedDate": "2020-04-29T15:48:24Z", "message": "update readme to match RFC"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7e7c1bfaba7c725cd981f74e981ae365a3b787d7", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/7e7c1bfaba7c725cd981f74e981ae365a3b787d7", "committedDate": "2020-04-29T15:48:24Z", "message": "update readme"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b08f8d89e3a2921b1f0013e0f650c02fbb2f91ba", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/b08f8d89e3a2921b1f0013e0f650c02fbb2f91ba", "committedDate": "2020-04-29T15:48:24Z", "message": "Dataset return type from fromTensorSlices"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "048e1221f8fb65f0ea9474b279c72a3a577aefde", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/048e1221f8fb65f0ea9474b279c72a3a577aefde", "committedDate": "2020-04-29T15:48:24Z", "message": "update readme"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b0059362d74b61e2d809d61038cbb13d1f3a468f", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/b0059362d74b61e2d809d61038cbb13d1f3a468f", "committedDate": "2020-04-29T15:48:24Z", "message": "add head() and tail() to Shape class"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e4a2431f06b5f4c63f7c0238650371dd60c89721", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/e4a2431f06b5f4c63f7c0238650371dd60c89721", "committedDate": "2020-04-29T15:48:24Z", "message": "refactoring"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "08041de037c8477a90debd512c32f1fc4ff5b77e", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/08041de037c8477a90debd512c32f1fc4ff5b77e", "committedDate": "2020-04-29T15:48:24Z", "message": "add dataset optional to improve eager iteration"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "abaa1f7a7bb5b4635cecaf8904ee174d33d9250c", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/abaa1f7a7bb5b4635cecaf8904ee174d33d9250c", "committedDate": "2020-04-29T15:48:24Z", "message": "update README"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fa8f5d593423ea7beb6b18c83f73e87baffefb18", "author": {"user": {"login": "dhruvrajan", "name": "Dhruv Rajan"}}, "url": "https://github.com/tensorflow/java/commit/fa8f5d593423ea7beb6b18c83f73e87baffefb18", "committedDate": "2020-04-29T15:48:24Z", "message": "use 2-space indentation"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3435, "cost": 1, "resetAt": "2021-11-02T12:20:56Z"}}}