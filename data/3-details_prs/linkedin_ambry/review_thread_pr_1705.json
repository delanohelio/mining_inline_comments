{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTI2ODQ2NTc4", "number": 1705, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QyMDowNTo1NlrOFAcUjQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QyMTo1MDo1MVrOFAgnnA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM2MDA4MzMzOnYy", "diffSide": "RIGHT", "path": "ambry-clustermap/src/test/java/com/github/ambry/clustermap/MockHelixAdmin.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QyMDowNTo1NlrOH-vUCw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QyMDowNTo1NlrOH-vUCw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTU0ODkzOQ==", "bodyText": "nit: it looks like this comment should still go above getResourcesInClusterWithTag?", "url": "https://github.com/linkedin/ambry/pull/1705#discussion_r535548939", "createdAt": "2020-12-03T20:05:56Z", "author": {"login": "cgtz"}, "path": "ambry-clustermap/src/test/java/com/github/ambry/clustermap/MockHelixAdmin.java", "diffHunk": "@@ -407,36 +446,15 @@ int getSetInstanceConfigCallCount() {\n     return setInstanceConfigCallCount;\n   }\n \n-  /**\n-   * Private class that holds partition state infos from one data node.\n-   */\n-  class ReplicaStateInfos {\n-    Map<String, Map<String, String>> replicaStateMap;\n-\n-    ReplicaStateInfos() {\n-      replicaStateMap = new HashMap<>();\n-    }\n-\n-    void setReplicaState(String partition, String state) {\n-      Map<String, String> stateMap = new HashMap<>();\n-      stateMap.put(CurrentState.CurrentStateProperty.CURRENT_STATE.name(), state);\n-      replicaStateMap.put(partition, stateMap);\n-    }\n-\n-    Map<String, Map<String, String>> getReplicaStateMap() {\n-      return replicaStateMap;\n-    }\n+  @Override\n+  public List<String> getResourcesInClusterWithTag(String clusterName, String tag) {\n+    throw new IllegalStateException(\"Not implemented\");\n   }\n \n   // ***************************************", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "47d0793fcbec5876b483d5f31bbe6661b7b40497"}, "originalPosition": 99}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM2MDI2MTIwOnYy", "diffSide": "RIGHT", "path": "ambry-router/src/main/java/com/github/ambry/router/SimpleOperationTracker.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QyMDozMzo0MVrOH-xCgg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QyMjo0NTo1MVrOH-4flw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTU3NzIxOA==", "bodyText": "So we have removed the option to exclude cross colo replicas that aren't in the originating DC? I thought that we used this option in production to improve latency in the not found case?", "url": "https://github.com/linkedin/ambry/pull/1705#discussion_r535577218", "createdAt": "2020-12-03T20:33:41Z", "author": {"login": "cgtz"}, "path": "ambry-router/src/main/java/com/github/ambry/router/SimpleOperationTracker.java", "diffHunk": "@@ -265,19 +258,29 @@\n     }\n     List<ReplicaId> backupReplicasToCheck = new ArrayList<>(backupReplicas);\n     List<ReplicaId> downReplicasToCheck = new ArrayList<>(downReplicas);\n-    if (includeNonOriginatingDcReplicas || this.originatingDcName == null) {\n-      backupReplicas.forEach(this::addToEndOfPool);\n+\n+    // Add replicas that are neither in local dc nor in originating dc.\n+    backupReplicas.forEach(this::addToEndOfPool);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "47d0793fcbec5876b483d5f31bbe6661b7b40497"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTY4MDM4NQ==", "bodyText": "Right, with this change, we always allows GET request to also try on non-originating replicas. Since these replicas will be tried with lower priority and we have failOnNotFound logic to terminate operation before exhausting all replicas, I think we don't really sacrifice the latency in \"NotFound\" case.", "url": "https://github.com/linkedin/ambry/pull/1705#discussion_r535680385", "createdAt": "2020-12-03T22:10:12Z", "author": {"login": "jsjtzyy"}, "path": "ambry-router/src/main/java/com/github/ambry/router/SimpleOperationTracker.java", "diffHunk": "@@ -265,19 +258,29 @@\n     }\n     List<ReplicaId> backupReplicasToCheck = new ArrayList<>(backupReplicas);\n     List<ReplicaId> downReplicasToCheck = new ArrayList<>(downReplicas);\n-    if (includeNonOriginatingDcReplicas || this.originatingDcName == null) {\n-      backupReplicas.forEach(this::addToEndOfPool);\n+\n+    // Add replicas that are neither in local dc nor in originating dc.\n+    backupReplicas.forEach(this::addToEndOfPool);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTU3NzIxOA=="}, "originalCommit": {"oid": "47d0793fcbec5876b483d5f31bbe6661b7b40497"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTY5NTMwOQ==", "bodyText": "(The intention of this change is to simplify some logic in operation tracker. We already have many configs to control its behavior and some of them may not be needed anymore. )", "url": "https://github.com/linkedin/ambry/pull/1705#discussion_r535695309", "createdAt": "2020-12-03T22:38:58Z", "author": {"login": "jsjtzyy"}, "path": "ambry-router/src/main/java/com/github/ambry/router/SimpleOperationTracker.java", "diffHunk": "@@ -265,19 +258,29 @@\n     }\n     List<ReplicaId> backupReplicasToCheck = new ArrayList<>(backupReplicas);\n     List<ReplicaId> downReplicasToCheck = new ArrayList<>(downReplicas);\n-    if (includeNonOriginatingDcReplicas || this.originatingDcName == null) {\n-      backupReplicas.forEach(this::addToEndOfPool);\n+\n+    // Add replicas that are neither in local dc nor in originating dc.\n+    backupReplicas.forEach(this::addToEndOfPool);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTU3NzIxOA=="}, "originalCommit": {"oid": "47d0793fcbec5876b483d5f31bbe6661b7b40497"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTY5OTM1MQ==", "bodyText": "Ah that makes sense that hasFailedOnNotFound() will catch this first. I forgot about that. It is good to simplify the configuration as much as possible.", "url": "https://github.com/linkedin/ambry/pull/1705#discussion_r535699351", "createdAt": "2020-12-03T22:45:51Z", "author": {"login": "cgtz"}, "path": "ambry-router/src/main/java/com/github/ambry/router/SimpleOperationTracker.java", "diffHunk": "@@ -265,19 +258,29 @@\n     }\n     List<ReplicaId> backupReplicasToCheck = new ArrayList<>(backupReplicas);\n     List<ReplicaId> downReplicasToCheck = new ArrayList<>(downReplicas);\n-    if (includeNonOriginatingDcReplicas || this.originatingDcName == null) {\n-      backupReplicas.forEach(this::addToEndOfPool);\n+\n+    // Add replicas that are neither in local dc nor in originating dc.\n+    backupReplicas.forEach(this::addToEndOfPool);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTU3NzIxOA=="}, "originalCommit": {"oid": "47d0793fcbec5876b483d5f31bbe6661b7b40497"}, "originalPosition": 65}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM2MDc4NzQ4OnYy", "diffSide": "RIGHT", "path": "ambry-router/src/main/java/com/github/ambry/router/SimpleOperationTracker.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QyMTo1MDo1MVrOH-2UBw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QyMjozNjozN1rOH-4LPg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTY2MzYyMw==", "bodyText": "It may be better to do a loop here. Mutating the offlineReplicas list was a little confusing to me and a loop can save a couple list iterations:\nSet remoteOfflineReplicas\nfor (replica in offlineReplicas) {\n  if (replica in originating DC) {\n    numReplicasInOriginatingDc++;\n  }\n  if (replica in local DC) {\n    addToEndOfPool\n  } else {\n    remoteOfflineReplicas.add(replica)\n  }\n}\nremoteOfflineReplicas.forEach(addToEndOfPool);", "url": "https://github.com/linkedin/ambry/pull/1705#discussion_r535663623", "createdAt": "2020-12-03T21:50:51Z", "author": {"login": "cgtz"}, "path": "ambry-router/src/main/java/com/github/ambry/router/SimpleOperationTracker.java", "diffHunk": "@@ -265,19 +258,29 @@\n     }\n     List<ReplicaId> backupReplicasToCheck = new ArrayList<>(backupReplicas);\n     List<ReplicaId> downReplicasToCheck = new ArrayList<>(downReplicas);\n-    if (includeNonOriginatingDcReplicas || this.originatingDcName == null) {\n-      backupReplicas.forEach(this::addToEndOfPool);\n+\n+    // Add replicas that are neither in local dc nor in originating dc.\n+    backupReplicas.forEach(this::addToEndOfPool);\n+\n+    if (routerConfig.routerOperationTrackerIncludeDownReplicas) {\n+      // Add those replicas deemed by native failure detector to be down\n       downReplicas.forEach(this::addToEndOfPool);\n-    } else {\n-      // This is for get request only. Take replicasRequired copy of replicas to do the request\n-      // Please note replicasRequired is 6 because total number of local and originating replicas is always <= 6.\n-      // This may no longer be true with partition classes and flexible replication.\n-      // Don't do this if originatingDcName is unknown.\n-      while (replicaPool.size() < numOfReplicasRequired && backupReplicas.size() > 0) {\n-        addToEndOfPool(backupReplicas.pollFirst());\n-      }\n-      while (replicaPool.size() < numOfReplicasRequired && downReplicas.size() > 0) {\n-        addToEndOfPool(downReplicas.pollFirst());\n+      // Add those replicas deemed by Helix to be down (offline). This only applies to GET operation.\n+      // Adding this logic to mitigate situation where one or more Zookeeper clusters are suddenly unavailable while\n+      // ambry servers are still up.\n+      if (routerOperation == RouterOperation.GetBlobOperation\n+          || routerOperation == RouterOperation.GetBlobInfoOperation) {\n+        Set<ReplicaId> offlineReplicas =\n+            new HashSet<>(getEligibleReplicas(partitionId, null, EnumSet.of(ReplicaState.OFFLINE)));\n+        Set<ReplicaId> originatingReplicas = offlineReplicas.stream().filter(r -> r.getDataNodeId().getDatacenterName().equals(this.originatingDcName)).collect(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "47d0793fcbec5876b483d5f31bbe6661b7b40497"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTY5NDE0Mg==", "bodyText": "Sure, this looks more straightforward.", "url": "https://github.com/linkedin/ambry/pull/1705#discussion_r535694142", "createdAt": "2020-12-03T22:36:37Z", "author": {"login": "jsjtzyy"}, "path": "ambry-router/src/main/java/com/github/ambry/router/SimpleOperationTracker.java", "diffHunk": "@@ -265,19 +258,29 @@\n     }\n     List<ReplicaId> backupReplicasToCheck = new ArrayList<>(backupReplicas);\n     List<ReplicaId> downReplicasToCheck = new ArrayList<>(downReplicas);\n-    if (includeNonOriginatingDcReplicas || this.originatingDcName == null) {\n-      backupReplicas.forEach(this::addToEndOfPool);\n+\n+    // Add replicas that are neither in local dc nor in originating dc.\n+    backupReplicas.forEach(this::addToEndOfPool);\n+\n+    if (routerConfig.routerOperationTrackerIncludeDownReplicas) {\n+      // Add those replicas deemed by native failure detector to be down\n       downReplicas.forEach(this::addToEndOfPool);\n-    } else {\n-      // This is for get request only. Take replicasRequired copy of replicas to do the request\n-      // Please note replicasRequired is 6 because total number of local and originating replicas is always <= 6.\n-      // This may no longer be true with partition classes and flexible replication.\n-      // Don't do this if originatingDcName is unknown.\n-      while (replicaPool.size() < numOfReplicasRequired && backupReplicas.size() > 0) {\n-        addToEndOfPool(backupReplicas.pollFirst());\n-      }\n-      while (replicaPool.size() < numOfReplicasRequired && downReplicas.size() > 0) {\n-        addToEndOfPool(downReplicas.pollFirst());\n+      // Add those replicas deemed by Helix to be down (offline). This only applies to GET operation.\n+      // Adding this logic to mitigate situation where one or more Zookeeper clusters are suddenly unavailable while\n+      // ambry servers are still up.\n+      if (routerOperation == RouterOperation.GetBlobOperation\n+          || routerOperation == RouterOperation.GetBlobInfoOperation) {\n+        Set<ReplicaId> offlineReplicas =\n+            new HashSet<>(getEligibleReplicas(partitionId, null, EnumSet.of(ReplicaState.OFFLINE)));\n+        Set<ReplicaId> originatingReplicas = offlineReplicas.stream().filter(r -> r.getDataNodeId().getDatacenterName().equals(this.originatingDcName)).collect(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTY2MzYyMw=="}, "originalCommit": {"oid": "47d0793fcbec5876b483d5f31bbe6661b7b40497"}, "originalPosition": 87}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1148, "cost": 1, "resetAt": "2021-11-12T20:44:06Z"}}}