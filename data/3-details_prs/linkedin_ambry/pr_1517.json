{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE2MzE2MjE4", "number": 1517, "title": "Cloud blob store changes for serving data", "bodyText": "This PR makes CloudBlobStore compatible with BlobStore.\nAlso makes changes in CloudBlobStore with respect to validations and functionality required for serving data.", "createdAt": "2020-05-11T20:05:33Z", "url": "https://github.com/linkedin/ambry/pull/1517", "merged": true, "mergeCommit": {"oid": "8377454fbbd49b61837a1dbfc14266669c4d5f11"}, "closed": true, "closedAt": "2020-06-07T05:22:17Z", "author": {"login": "ankagrawal"}, "timelineItems": {"totalCount": 31, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABchk-RbgFqTQxMjc4OTc0MQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcoa6XSAH2gAyNDE2MzE2MjE4OjljZDBjOGVkY2Q3NWFjM2IwMGJlYmQ4ODZiNTAwMGE1NjJlM2ViNjE=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDEyNzg5NzQx", "url": "https://github.com/linkedin/ambry/pull/1517#pullrequestreview-412789741", "createdAt": "2020-05-15T16:20:55Z", "commit": {"oid": "8209a5c500dc7c8c5a0b47c4528c3e4ad5379519"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxNjoyMDo1NVrOGWLe_A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxNjo0OToyNVrOGWMeGA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxMDAxMg==", "bodyText": "This misses the expired blobs.", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r425910012", "createdAt": "2020-05-15T16:20:55Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudBlobMetadata.java", "diffHunk": "@@ -435,8 +435,36 @@ public void setLifeVersion(short lifeVersion) {\n    * @return true if this blob is deleted or expired, otherwise false.\n    */\n   public boolean isDeletedOrExpired() {\n-    return (expirationTime != Utils.Infinite_Time && expirationTime < System.currentTimeMillis())\n-        || deletionTime != Utils.Infinite_Time;\n+    return isExpired() || isDeleted();\n+  }\n+\n+  /**\n+   * @return true if this blob is marked as deleted, false otherwise.\n+   */\n+  public boolean isDeleted() {\n+    return (deletionTime != Utils.Infinite_Time);\n+  }\n+\n+  /**\n+   * @return true if this blob has expired, false otherwise.\n+   */\n+  public boolean isExpired() {\n+    return expirationTime != Utils.Infinite_Time && expirationTime < System.currentTimeMillis();\n+  }\n+\n+  /**\n+   * @return true if this blob is undeleted.\n+   */\n+  public boolean isUndeleted() {\n+    return !isDeleted() && lifeVersion > 0;\n+  }\n+\n+  /**\n+   * @param retentionPeriod period for which blobs marked a deleted aren't compacted away.\n+   * @return true if deletion time is outside retention window. false otherwise.\n+   */\n+  public boolean isCompactionCandidate(long retentionPeriod) {\n+    return isDeleted() && deletionTime <= (System.currentTimeMillis() - retentionPeriod);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8209a5c500dc7c8c5a0b47c4528c3e4ad5379519"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxMDI3MA==", "bodyText": "caller", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r425910270", "createdAt": "2020-05-15T16:21:23Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudDestination.java", "diffHunk": "@@ -53,28 +53,34 @@ boolean uploadBlob(BlobId blobId, long inputLength, CloudBlobMetadata cloudBlobM\n    * @param blobId id of the Ambry blob\n    * @param deletionTime time of blob deletion\n    * @param lifeVersion life version of the blob to be deleted.\n+   * @param cloudUpdateValidator {@link CloudUpdateValidator} object passed by called to validate the update.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8209a5c500dc7c8c5a0b47c4528c3e4ad5379519"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxMDQ2Nw==", "bodyText": "And validate the delete.", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r425910467", "createdAt": "2020-05-15T16:21:45Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudDestination.java", "diffHunk": "@@ -53,28 +53,34 @@ boolean uploadBlob(BlobId blobId, long inputLength, CloudBlobMetadata cloudBlobM\n    * @param blobId id of the Ambry blob\n    * @param deletionTime time of blob deletion\n    * @param lifeVersion life version of the blob to be deleted.\n+   * @param cloudUpdateValidator {@link CloudUpdateValidator} object passed by called to validate the update.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxMDI3MA=="}, "originalCommit": {"oid": "8209a5c500dc7c8c5a0b47c4528c3e4ad5379519"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxMDcwMQ==", "bodyText": "caller to validate the undelete", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r425910701", "createdAt": "2020-05-15T16:22:08Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudDestination.java", "diffHunk": "@@ -53,28 +53,34 @@ boolean uploadBlob(BlobId blobId, long inputLength, CloudBlobMetadata cloudBlobM\n    * @param blobId id of the Ambry blob\n    * @param deletionTime time of blob deletion\n    * @param lifeVersion life version of the blob to be deleted.\n+   * @param cloudUpdateValidator {@link CloudUpdateValidator} object passed by called to validate the update.\n    * @return flag indicating whether the blob was deleted\n    * @throws CloudStorageException if the deletion encounters an error.\n    */\n-  boolean deleteBlob(BlobId blobId, long deletionTime, short lifeVersion) throws CloudStorageException;\n+  boolean deleteBlob(BlobId blobId, long deletionTime, short lifeVersion, CloudUpdateValidator cloudUpdateValidator)\n+      throws CloudStorageException;\n \n   /**\n    * Undelete the blob from cloud destination, and update the new life version.\n    * @param blobId id of the Ambry blob.\n    * @param lifeVersion new life version to update.\n+   * @param cloudUpdateValidator {@link CloudUpdateValidator} object passed by called to validate the update.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8209a5c500dc7c8c5a0b47c4528c3e4ad5379519"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxMDg2OQ==", "bodyText": "caller", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r425910869", "createdAt": "2020-05-15T16:22:26Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudDestination.java", "diffHunk": "@@ -53,28 +53,34 @@ boolean uploadBlob(BlobId blobId, long inputLength, CloudBlobMetadata cloudBlobM\n    * @param blobId id of the Ambry blob\n    * @param deletionTime time of blob deletion\n    * @param lifeVersion life version of the blob to be deleted.\n+   * @param cloudUpdateValidator {@link CloudUpdateValidator} object passed by called to validate the update.\n    * @return flag indicating whether the blob was deleted\n    * @throws CloudStorageException if the deletion encounters an error.\n    */\n-  boolean deleteBlob(BlobId blobId, long deletionTime, short lifeVersion) throws CloudStorageException;\n+  boolean deleteBlob(BlobId blobId, long deletionTime, short lifeVersion, CloudUpdateValidator cloudUpdateValidator)\n+      throws CloudStorageException;\n \n   /**\n    * Undelete the blob from cloud destination, and update the new life version.\n    * @param blobId id of the Ambry blob.\n    * @param lifeVersion new life version to update.\n+   * @param cloudUpdateValidator {@link CloudUpdateValidator} object passed by called to validate the update.\n    * @return final live version of the undeleted blob.\n    * @throws CloudStorageException if the undelete encounters an error.\n    */\n-  short undeleteBlob(BlobId blobId, short lifeVersion) throws CloudStorageException;\n+  short undeleteBlob(BlobId blobId, short lifeVersion, CloudUpdateValidator cloudUpdateValidator)\n+      throws CloudStorageException;\n \n   /**\n    * Update expiration time of blob in the cloud destination.\n    * @param blobId id of the Ambry blob\n    * @param expirationTime the new expiration time\n-   * @return flag indicating whether the blob was updated\n+   * @param cloudUpdateValidator {@link CloudUpdateValidator} object passed by called to validate the update.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8209a5c500dc7c8c5a0b47c4528c3e4ad5379519"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxMTgyMg==", "bodyText": "new requested life version doesn't appear to be an argument.", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r425911822", "createdAt": "2020-05-15T16:24:06Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudUpdateValidator.java", "diffHunk": "@@ -0,0 +1,34 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.cloud;\n+\n+import com.github.ambry.store.StoreException;\n+import com.github.ambry.store.StoreKey;\n+import java.util.Map;\n+\n+\n+/**\n+ * Interface for Ambry validation logic for updates requested from cloud destination.\n+ */\n+public interface CloudUpdateValidator {\n+  /**\n+   * Validate operation on {@link CloudBlobMetadata} in cloud destination for the operation on blob with\n+   * given {@link StoreKey} and new requested life version.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8209a5c500dc7c8c5a0b47c4528c3e4ad5379519"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxMzQ1NA==", "bodyText": "It seems strange that a class in cloud package is throwing StoreException.", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r425913454", "createdAt": "2020-05-15T16:27:09Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudUpdateValidator.java", "diffHunk": "@@ -0,0 +1,34 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.cloud;\n+\n+import com.github.ambry.store.StoreException;\n+import com.github.ambry.store.StoreKey;\n+import java.util.Map;\n+\n+\n+/**\n+ * Interface for Ambry validation logic for updates requested from cloud destination.\n+ */\n+public interface CloudUpdateValidator {\n+  /**\n+   * Validate operation on {@link CloudBlobMetadata} in cloud destination for the operation on blob with\n+   * given {@link StoreKey} and new requested life version.\n+   * @param metadata {@link CloudBlobMetadata} object obtained from cloud destination.\n+   * @param key {@link StoreKey} of the blob being updated.\n+   * @param updateFields {@link Map} of fields and new values requested for update.\n+   * @throws StoreException if validation fails.\n+   */\n+  void validateUpdate(CloudBlobMetadata metadata, StoreKey key, Map<String, Object> updateFields) throws StoreException;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8209a5c500dc7c8c5a0b47c4528c3e4ad5379519"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkyNjE2OA==", "bodyText": "I'd like to see clearer description of what is validated, or what would cause validation to fail.  And specifically that you are validating application of update fields to existing metadata.", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r425926168", "createdAt": "2020-05-15T16:49:25Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudUpdateValidator.java", "diffHunk": "@@ -0,0 +1,34 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.cloud;\n+\n+import com.github.ambry.store.StoreException;\n+import com.github.ambry.store.StoreKey;\n+import java.util.Map;\n+\n+\n+/**\n+ * Interface for Ambry validation logic for updates requested from cloud destination.\n+ */\n+public interface CloudUpdateValidator {\n+  /**\n+   * Validate operation on {@link CloudBlobMetadata} in cloud destination for the operation on blob with\n+   * given {@link StoreKey} and new requested life version.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxMTgyMg=="}, "originalCommit": {"oid": "8209a5c500dc7c8c5a0b47c4528c3e4ad5379519"}, "originalPosition": 27}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE0MDczMTM1", "url": "https://github.com/linkedin/ambry/pull/1517#pullrequestreview-414073135", "createdAt": "2020-05-19T03:16:33Z", "commit": {"oid": "8209a5c500dc7c8c5a0b47c4528c3e4ad5379519"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQwMzoxNjozNFrOGXOYgA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQwMzoxODoyNlrOGXOaPA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzAwNjA4MA==", "bodyText": "We might need to distinguish between vcr and live traffic.  For VCR, shouldUpload() can return false if the TTL is low.", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r427006080", "createdAt": "2020-05-19T03:16:34Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudBlobStore.java", "diffHunk": "@@ -391,11 +377,15 @@ private boolean deleteIfNeeded(BlobId blobId, long deletionTime, short lifeVersi\n     // Note: always check cache before operation attempt, since this could be a retry after a CONFLICT error,\n     // in which case the cache may have been updated by another thread.\n     if (!checkCacheState(blobKey, lifeVersion, BlobState.DELETED)) {\n-      boolean deleted = cloudDestination.deleteBlob(blobId, deletionTime, lifeVersion);\n+      boolean deleted = cloudDestination.deleteBlob(blobId, deletionTime, lifeVersion,\n+          (metadata, key, updateFields) -> preDeleteValidation(metadata, key, updateFields));\n       addToCache(blobKey, lifeVersion, BlobState.DELETED);\n       return deleted;\n+    } else {\n+      throw new CloudStorageException(\"Error updating blob metadata\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8209a5c500dc7c8c5a0b47c4528c3e4ad5379519"}, "originalPosition": 149}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzAwNjUyNA==", "bodyText": "Why not just throw a StoreException here?\nAlso, for VCR case it may not be an error (that's why we mark it skipped).", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r427006524", "createdAt": "2020-05-19T03:18:26Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudBlobStore.java", "diffHunk": "@@ -314,13 +290,20 @@ private void putBlob(MessageInfo messageInfo, ByteBuffer messageBuf, long size)\n             new CloudBlobMetadata(blobId, messageInfo.getOperationTimeMs(), messageInfo.getExpirationTimeInMs(),\n                 messageInfo.getSize(), encryptionOrigin);\n         InputStream uploadInputStream = new ByteBufferInputStream(messageBuf);\n-        requestAgent.doWithRetries(() -> cloudDestination.uploadBlob(blobId, size, blobMetadata, uploadInputStream),\n-            \"Upload\", partitionId.toPathString());\n+        uploaded =\n+            requestAgent.doWithRetries(() -> cloudDestination.uploadBlob(blobId, size, blobMetadata, uploadInputStream),\n+                \"Upload\", partitionId.toPathString());\n       }\n       addToCache(blobId.getID(), (short) 0, BlobState.CREATED);\n+      if (!uploaded) {\n+        throw new StoreException(String.format(\"Another blob with same key %s exists in store\", blobId.getID()),\n+            StoreErrorCodes.Already_Exist);\n+      }\n     } else {\n-      logger.trace(\"Blob is skipped: {}\", messageInfo);\n       vcrMetrics.blobUploadSkippedCount.inc();\n+      throw new CloudStorageException(\"Error updating blob metadata\", new StoreException(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8209a5c500dc7c8c5a0b47c4528c3e4ad5379519"}, "originalPosition": 123}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE3MzE0MzI0", "url": "https://github.com/linkedin/ambry/pull/1517#pullrequestreview-417314324", "createdAt": "2020-05-23T22:56:12Z", "commit": {"oid": "8209a5c500dc7c8c5a0b47c4528c3e4ad5379519"}, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yM1QyMjo1NjoxM1rOGZrwDA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yM1QyMzoxMDowOVrOGZryYw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTU4NDM5Ng==", "bodyText": "fixed.", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r429584396", "createdAt": "2020-05-23T22:56:13Z", "author": {"login": "ankagrawal"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudBlobMetadata.java", "diffHunk": "@@ -435,8 +435,36 @@ public void setLifeVersion(short lifeVersion) {\n    * @return true if this blob is deleted or expired, otherwise false.\n    */\n   public boolean isDeletedOrExpired() {\n-    return (expirationTime != Utils.Infinite_Time && expirationTime < System.currentTimeMillis())\n-        || deletionTime != Utils.Infinite_Time;\n+    return isExpired() || isDeleted();\n+  }\n+\n+  /**\n+   * @return true if this blob is marked as deleted, false otherwise.\n+   */\n+  public boolean isDeleted() {\n+    return (deletionTime != Utils.Infinite_Time);\n+  }\n+\n+  /**\n+   * @return true if this blob has expired, false otherwise.\n+   */\n+  public boolean isExpired() {\n+    return expirationTime != Utils.Infinite_Time && expirationTime < System.currentTimeMillis();\n+  }\n+\n+  /**\n+   * @return true if this blob is undeleted.\n+   */\n+  public boolean isUndeleted() {\n+    return !isDeleted() && lifeVersion > 0;\n+  }\n+\n+  /**\n+   * @param retentionPeriod period for which blobs marked a deleted aren't compacted away.\n+   * @return true if deletion time is outside retention window. false otherwise.\n+   */\n+  public boolean isCompactionCandidate(long retentionPeriod) {\n+    return isDeleted() && deletionTime <= (System.currentTimeMillis() - retentionPeriod);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxMDAxMg=="}, "originalCommit": {"oid": "8209a5c500dc7c8c5a0b47c4528c3e4ad5379519"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTU4NDQxOA==", "bodyText": "fixed.", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r429584418", "createdAt": "2020-05-23T22:56:29Z", "author": {"login": "ankagrawal"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudBlobStore.java", "diffHunk": "@@ -314,13 +290,20 @@ private void putBlob(MessageInfo messageInfo, ByteBuffer messageBuf, long size)\n             new CloudBlobMetadata(blobId, messageInfo.getOperationTimeMs(), messageInfo.getExpirationTimeInMs(),\n                 messageInfo.getSize(), encryptionOrigin);\n         InputStream uploadInputStream = new ByteBufferInputStream(messageBuf);\n-        requestAgent.doWithRetries(() -> cloudDestination.uploadBlob(blobId, size, blobMetadata, uploadInputStream),\n-            \"Upload\", partitionId.toPathString());\n+        uploaded =\n+            requestAgent.doWithRetries(() -> cloudDestination.uploadBlob(blobId, size, blobMetadata, uploadInputStream),\n+                \"Upload\", partitionId.toPathString());\n       }\n       addToCache(blobId.getID(), (short) 0, BlobState.CREATED);\n+      if (!uploaded) {\n+        throw new StoreException(String.format(\"Another blob with same key %s exists in store\", blobId.getID()),\n+            StoreErrorCodes.Already_Exist);\n+      }\n     } else {\n-      logger.trace(\"Blob is skipped: {}\", messageInfo);\n       vcrMetrics.blobUploadSkippedCount.inc();\n+      throw new CloudStorageException(\"Error updating blob metadata\", new StoreException(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzAwNjUyNA=="}, "originalCommit": {"oid": "8209a5c500dc7c8c5a0b47c4528c3e4ad5379519"}, "originalPosition": 123}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTU4NDQ4Mw==", "bodyText": "shouldUpload() gets called only for PUT request.\nIn this case, delete() can be called either by ReplicaThread or by AmbryRequests. Delete coming from AmbryRequests, for a lifeVersion that we have already seen, should throw an error. In case it comes from ReplicaThread, its ok for it to throw error. ReplicaThread::applyDelete handles StoreErrorCodes::ID_Deleted gracefully. Also such a behavior from CloudBlobStore seems to be in sync with BlobStore.", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r429584483", "createdAt": "2020-05-23T22:58:10Z", "author": {"login": "ankagrawal"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudBlobStore.java", "diffHunk": "@@ -391,11 +377,15 @@ private boolean deleteIfNeeded(BlobId blobId, long deletionTime, short lifeVersi\n     // Note: always check cache before operation attempt, since this could be a retry after a CONFLICT error,\n     // in which case the cache may have been updated by another thread.\n     if (!checkCacheState(blobKey, lifeVersion, BlobState.DELETED)) {\n-      boolean deleted = cloudDestination.deleteBlob(blobId, deletionTime, lifeVersion);\n+      boolean deleted = cloudDestination.deleteBlob(blobId, deletionTime, lifeVersion,\n+          (metadata, key, updateFields) -> preDeleteValidation(metadata, key, updateFields));\n       addToCache(blobKey, lifeVersion, BlobState.DELETED);\n       return deleted;\n+    } else {\n+      throw new CloudStorageException(\"Error updating blob metadata\",", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzAwNjA4MA=="}, "originalCommit": {"oid": "8209a5c500dc7c8c5a0b47c4528c3e4ad5379519"}, "originalPosition": 149}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTU4NDk0OQ==", "bodyText": "fixed.", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r429584949", "createdAt": "2020-05-23T23:09:06Z", "author": {"login": "ankagrawal"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudDestination.java", "diffHunk": "@@ -53,28 +53,34 @@ boolean uploadBlob(BlobId blobId, long inputLength, CloudBlobMetadata cloudBlobM\n    * @param blobId id of the Ambry blob\n    * @param deletionTime time of blob deletion\n    * @param lifeVersion life version of the blob to be deleted.\n+   * @param cloudUpdateValidator {@link CloudUpdateValidator} object passed by called to validate the update.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxMDI3MA=="}, "originalCommit": {"oid": "8209a5c500dc7c8c5a0b47c4528c3e4ad5379519"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTU4NDk1Mg==", "bodyText": "fixed.", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r429584952", "createdAt": "2020-05-23T23:09:12Z", "author": {"login": "ankagrawal"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudDestination.java", "diffHunk": "@@ -53,28 +53,34 @@ boolean uploadBlob(BlobId blobId, long inputLength, CloudBlobMetadata cloudBlobM\n    * @param blobId id of the Ambry blob\n    * @param deletionTime time of blob deletion\n    * @param lifeVersion life version of the blob to be deleted.\n+   * @param cloudUpdateValidator {@link CloudUpdateValidator} object passed by called to validate the update.\n    * @return flag indicating whether the blob was deleted\n    * @throws CloudStorageException if the deletion encounters an error.\n    */\n-  boolean deleteBlob(BlobId blobId, long deletionTime, short lifeVersion) throws CloudStorageException;\n+  boolean deleteBlob(BlobId blobId, long deletionTime, short lifeVersion, CloudUpdateValidator cloudUpdateValidator)\n+      throws CloudStorageException;\n \n   /**\n    * Undelete the blob from cloud destination, and update the new life version.\n    * @param blobId id of the Ambry blob.\n    * @param lifeVersion new life version to update.\n+   * @param cloudUpdateValidator {@link CloudUpdateValidator} object passed by called to validate the update.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxMDcwMQ=="}, "originalCommit": {"oid": "8209a5c500dc7c8c5a0b47c4528c3e4ad5379519"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTU4NDk1Ng==", "bodyText": "fixed.", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r429584956", "createdAt": "2020-05-23T23:09:20Z", "author": {"login": "ankagrawal"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudDestination.java", "diffHunk": "@@ -53,28 +53,34 @@ boolean uploadBlob(BlobId blobId, long inputLength, CloudBlobMetadata cloudBlobM\n    * @param blobId id of the Ambry blob\n    * @param deletionTime time of blob deletion\n    * @param lifeVersion life version of the blob to be deleted.\n+   * @param cloudUpdateValidator {@link CloudUpdateValidator} object passed by called to validate the update.\n    * @return flag indicating whether the blob was deleted\n    * @throws CloudStorageException if the deletion encounters an error.\n    */\n-  boolean deleteBlob(BlobId blobId, long deletionTime, short lifeVersion) throws CloudStorageException;\n+  boolean deleteBlob(BlobId blobId, long deletionTime, short lifeVersion, CloudUpdateValidator cloudUpdateValidator)\n+      throws CloudStorageException;\n \n   /**\n    * Undelete the blob from cloud destination, and update the new life version.\n    * @param blobId id of the Ambry blob.\n    * @param lifeVersion new life version to update.\n+   * @param cloudUpdateValidator {@link CloudUpdateValidator} object passed by called to validate the update.\n    * @return final live version of the undeleted blob.\n    * @throws CloudStorageException if the undelete encounters an error.\n    */\n-  short undeleteBlob(BlobId blobId, short lifeVersion) throws CloudStorageException;\n+  short undeleteBlob(BlobId blobId, short lifeVersion, CloudUpdateValidator cloudUpdateValidator)\n+      throws CloudStorageException;\n \n   /**\n    * Update expiration time of blob in the cloud destination.\n    * @param blobId id of the Ambry blob\n    * @param expirationTime the new expiration time\n-   * @return flag indicating whether the blob was updated\n+   * @param cloudUpdateValidator {@link CloudUpdateValidator} object passed by called to validate the update.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxMDg2OQ=="}, "originalCommit": {"oid": "8209a5c500dc7c8c5a0b47c4528c3e4ad5379519"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTU4NDk5NQ==", "bodyText": "Added comments to capture the description, while keeping it relatively generic so that it can potentially be applied to future CloudDestination extensions. Let me know if it looks good.", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r429584995", "createdAt": "2020-05-23T23:10:09Z", "author": {"login": "ankagrawal"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudUpdateValidator.java", "diffHunk": "@@ -0,0 +1,34 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.cloud;\n+\n+import com.github.ambry.store.StoreException;\n+import com.github.ambry.store.StoreKey;\n+import java.util.Map;\n+\n+\n+/**\n+ * Interface for Ambry validation logic for updates requested from cloud destination.\n+ */\n+public interface CloudUpdateValidator {\n+  /**\n+   * Validate operation on {@link CloudBlobMetadata} in cloud destination for the operation on blob with\n+   * given {@link StoreKey} and new requested life version.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxMTgyMg=="}, "originalCommit": {"oid": "8209a5c500dc7c8c5a0b47c4528c3e4ad5379519"}, "originalPosition": 27}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4ODM3MTA4", "url": "https://github.com/linkedin/ambry/pull/1517#pullrequestreview-418837108", "createdAt": "2020-05-27T03:45:15Z", "commit": {"oid": "fb47a16339867695075be0f6b421a59bba8c95df"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwMzo0NToxNVrOGa4cPg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwNTowNToyMVrOGa5irA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg0MDg5NA==", "bodyText": "Expiration needs the same retention check.", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r430840894", "createdAt": "2020-05-27T03:45:15Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudBlobMetadata.java", "diffHunk": "@@ -432,11 +432,32 @@ public void setLifeVersion(short lifeVersion) {\n   }\n \n   /**\n-   * @return true if this blob is deleted or expired, otherwise false.\n+   * @return true if this blob is marked as deleted, false otherwise.\n    */\n-  public boolean isDeletedOrExpired() {\n-    return (expirationTime != Utils.Infinite_Time && expirationTime < System.currentTimeMillis())\n-        || deletionTime != Utils.Infinite_Time;\n+  public boolean isDeleted() {\n+    return (deletionTime != Utils.Infinite_Time);\n+  }\n+\n+  /**\n+   * @return true if this blob has expired, false otherwise.\n+   */\n+  public boolean isExpired() {\n+    return expirationTime != Utils.Infinite_Time && expirationTime < System.currentTimeMillis();\n+  }\n+\n+  /**\n+   * @return true if this blob is undeleted.\n+   */\n+  public boolean isUndeleted() {\n+    return !isDeleted() && lifeVersion > 0;\n+  }\n+\n+  /**\n+   * @param retentionPeriod period for which blobs marked a deleted aren't compacted away.\n+   * @return true if deletion time is outside retention window or blob is expired. false otherwise.\n+   */\n+  public boolean isCompactionCandidate(long retentionPeriod) {\n+    return (isDeleted() && deletionTime <= (System.currentTimeMillis() - retentionPeriod)) || isExpired();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fb47a16339867695075be0f6b421a59bba8c95df"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg1MjgyMw==", "bodyText": "We can get to this else clause if isVcr and uploaded are both true, in which case nothing was skipped.", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r430852823", "createdAt": "2020-05-27T04:39:43Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudBlobStore.java", "diffHunk": "@@ -295,15 +295,23 @@ private void putBlob(MessageInfo messageInfo, ByteBuffer messageBuf, long size)\n                 \"Upload\", partitionId.toPathString());\n       }\n       addToCache(blobId.getID(), (short) 0, BlobState.CREATED);\n-      if (!uploaded) {\n+      if (!uploaded && !isVcr) {\n+        // If put is coming from frontend, then uploadBlob must be true. Its not acceptable that a blob already exists.\n+        // If put is coming from vcr, then findMissingKeys might have reported a key to be missing even though the blob\n+        // was uploaded to ABS. This can happen, if previously, the upload to ABS succeeded but the upload couldn't make\n+        // it to cosmos.\n         throw new StoreException(String.format(\"Another blob with same key %s exists in store\", blobId.getID()),\n             StoreErrorCodes.Already_Exist);\n       }\n     } else {\n       vcrMetrics.blobUploadSkippedCount.inc();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fb47a16339867695075be0f6b421a59bba8c95df"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg1NDYxOQ==", "bodyText": "Let's avoid mentioning Azure stuff in this class.  The logic should be independent anyway.", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r430854619", "createdAt": "2020-05-27T04:47:17Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudBlobStore.java", "diffHunk": "@@ -522,12 +530,20 @@ private void validateAccountAndContainer(Map<String, CloudBlobMetadata> cloudBlo\n    * @param metadata existing {@link CloudBlobMetadata} in cloud.\n    * @param key {@link StoreKey} being deleted.\n    * @param updateFields {@link Map} of fields and values being updated.\n+   * @return false only for vcr if local cloud destination life version is more recent. true if validation successful.\n    * @throws StoreException if validation fails.\n    */\n-  private void preDeleteValidation(CloudBlobMetadata metadata, StoreKey key, Map<String, Object> updateFields)\n+  private boolean preDeleteValidation(CloudBlobMetadata metadata, StoreKey key, Map<String, Object> updateFields)\n       throws StoreException {\n     validateAccountAndContainer(Collections.singletonMap(metadata.getId(), metadata), Collections.singletonList(key));\n     short requestedLifeVersion = (short) updateFields.get(FIELD_LIFE_VERSION);\n+    if (isVcr) {\n+      // This is a delete request from vcr. Apply delete only if incoming life version is more recent. Don't throw any\n+      // exception because replication relies on findMissingKeys which in turn relies on cosmos state for CloudBlobStore.\n+      // Cosmos could be missing some updates that were applied to ABS.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fb47a16339867695075be0f6b421a59bba8c95df"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg1NTEzOA==", "bodyText": "Remove Cosmos/ABS mentions", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r430855138", "createdAt": "2020-05-27T04:49:34Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudBlobStore.java", "diffHunk": "@@ -554,12 +563,19 @@ private void preDeleteValidation(CloudBlobMetadata metadata, StoreKey key, Map<S\n    * @param metadata existing {@link CloudBlobMetadata} in cloud.\n    * @param key {@link StoreKey} being updated.\n    * @param updateFields {@link Map} of fields and values being updated.\n+   * @return false only for vcr if ttl is already applied on blob. true in all other cases if validation is successful.\n    * @throws StoreException if validation fails.\n    */\n-  private void preTtlUpdateValidation(CloudBlobMetadata metadata, StoreKey key, Map<String, Object> updateFields)\n+  private boolean preTtlUpdateValidation(CloudBlobMetadata metadata, StoreKey key, Map<String, Object> updateFields)\n       throws StoreException {\n     validateAccountAndContainer(Collections.singletonMap(metadata.getId(), metadata), Collections.singletonList(key));\n     long now = System.currentTimeMillis();\n+    if (isVcr) {\n+      // For vcr don't update ttl if already updated. Don't throw any exception because replication relies on\n+      // findMissingKeys which in turn relies on cosmos state for CloudBlobStore. Cosmos could be missing some updates", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fb47a16339867695075be0f6b421a59bba8c95df"}, "originalPosition": 99}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg1NTYyOQ==", "bodyText": "Same here.", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r430855629", "createdAt": "2020-05-27T04:51:42Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudBlobStore.java", "diffHunk": "@@ -579,10 +596,16 @@ private void preTtlUpdateValidation(CloudBlobMetadata metadata, StoreKey key, Ma\n    * @param updateFields {@link Map} of fields and values being updated.\n    * @throws StoreException if validation fails.\n    */\n-  private void preUndeleteValidation(CloudBlobMetadata metadata, StoreKey key, Map<String, Object> updateFields)\n+  private boolean preUndeleteValidation(CloudBlobMetadata metadata, StoreKey key, Map<String, Object> updateFields)\n       throws StoreException {\n     validateAccountAndContainer(Collections.singletonMap(metadata.getId(), metadata), Collections.singletonList(key));\n     short requestedLifeVersion = (short) updateFields.get(FIELD_LIFE_VERSION);\n+    if (isVcr) {\n+      // This is an undelete request from vcr. Apply undelete only if incoming life version is more recent. Don't throw\n+      // any exception because replication relies on findMissingKeys which in turn relies on cosmos state for CloudBlobStore.\n+      // Cosmos could be missing some updates that were applied to ABS.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fb47a16339867695075be0f6b421a59bba8c95df"}, "originalPosition": 126}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg1NjA4OA==", "bodyText": "Add @return javadoc", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r430856088", "createdAt": "2020-05-27T04:53:31Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudBlobStore.java", "diffHunk": "@@ -579,10 +596,16 @@ private void preTtlUpdateValidation(CloudBlobMetadata metadata, StoreKey key, Ma\n    * @param updateFields {@link Map} of fields and values being updated.\n    * @throws StoreException if validation fails.\n    */\n-  private void preUndeleteValidation(CloudBlobMetadata metadata, StoreKey key, Map<String, Object> updateFields)\n+  private boolean preUndeleteValidation(CloudBlobMetadata metadata, StoreKey key, Map<String, Object> updateFields)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fb47a16339867695075be0f6b421a59bba8c95df"}, "originalPosition": 119}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg1NzYyOQ==", "bodyText": "I don't understand this logic.  What about the case where we have reset the replica tokens but not deleted the blob store?  The put needs to be idempotent for VCR.", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r430857629", "createdAt": "2020-05-27T05:00:07Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudBlobStore.java", "diffHunk": "@@ -295,15 +295,23 @@ private void putBlob(MessageInfo messageInfo, ByteBuffer messageBuf, long size)\n                 \"Upload\", partitionId.toPathString());\n       }\n       addToCache(blobId.getID(), (short) 0, BlobState.CREATED);\n-      if (!uploaded) {\n+      if (!uploaded && !isVcr) {\n+        // If put is coming from frontend, then uploadBlob must be true. Its not acceptable that a blob already exists.\n+        // If put is coming from vcr, then findMissingKeys might have reported a key to be missing even though the blob\n+        // was uploaded to ABS. This can happen, if previously, the upload to ABS succeeded but the upload couldn't make\n+        // it to cosmos.\n         throw new StoreException(String.format(\"Another blob with same key %s exists in store\", blobId.getID()),\n             StoreErrorCodes.Already_Exist);\n       }\n     } else {\n       vcrMetrics.blobUploadSkippedCount.inc();\n-      throw new CloudStorageException(\"Error updating blob metadata\", new StoreException(\n-          String.format(\"Another blob with same key %s exists in store\", messageInfo.getStoreKey().getID()),\n-          StoreErrorCodes.Already_Exist));\n+      // The only case where its ok to see a put request for a already seen blob is, during replication if the blob is\n+      // expiring within {@link CloudConfig#vcrMinTtlDays} for vcr to upload.\n+      if (isVcr && !isExpiringSoon(messageInfo)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fb47a16339867695075be0f6b421a59bba8c95df"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg1ODkyNA==", "bodyText": "Rephrase as:\n@return true if the operation can proceed, or false if it is not needed (e.g. cloud state is more recent).\nThe exception part is implicit.", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r430858924", "createdAt": "2020-05-27T05:05:21Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudUpdateValidator.java", "diffHunk": "@@ -23,12 +23,15 @@\n  */\n public interface CloudUpdateValidator {\n   /**\n-   * Validate operation on {@link CloudBlobMetadata} in cloud destination for the operation on blob with\n-   * given {@link StoreKey} and new requested life version.\n+   * Validate the sanity of update operation on given {@code updateFields} against existing {@link CloudBlobMetadata} in\n+   * cloud destination for the blob with key {@code key}. This can be used to hook Ambry store related validation logic\n+   * during {@link CloudDestination} specific get-check-update flow.\n    * @param metadata {@link CloudBlobMetadata} object obtained from cloud destination.\n    * @param key {@link StoreKey} of the blob being updated.\n    * @param updateFields {@link Map} of fields and new values requested for update.\n+   * @return if no exception needs to thrown, return false if the operation is not needed (maybe cloud state is more\n+   * recent). true otherwise.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fb47a16339867695075be0f6b421a59bba8c95df"}, "originalPosition": 13}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE5ODExMDY3", "url": "https://github.com/linkedin/ambry/pull/1517#pullrequestreview-419811067", "createdAt": "2020-05-28T06:29:37Z", "commit": {"oid": "fb47a16339867695075be0f6b421a59bba8c95df"}, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQwNjoyOTozN1rOGbnTvw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQwNjo1ODozNVrOGboCaA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTYwODc2Nw==", "bodyText": "could you simplify the lambda to this::preUndeleteValidation? Same in other places where this method is used.", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r431608767", "createdAt": "2020-05-28T06:29:37Z", "author": {"login": "cgtz"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudBlobStore.java", "diffHunk": "@@ -419,32 +417,34 @@ public short undelete(MessageInfo info) throws StoreException {\n    * @throws CloudStorageException in case any exception happens during undelete.\n    */\n   private short undeleteIfNeeded(BlobId blobId, short lifeVersion) throws CloudStorageException {\n-    // TODO: Currently this is implemented for undeletes via replication only for DR.\n     // See note in deleteIfNeeded.\n     if (!checkCacheState(blobId.getID(), lifeVersion, BlobState.CREATED)) {\n-      short newLifeVersion = cloudDestination.undeleteBlob(blobId, lifeVersion);\n+      short newLifeVersion = cloudDestination.undeleteBlob(blobId, lifeVersion,\n+          (metadata, key, updateFields) -> preUndeleteValidation(metadata, key, updateFields));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fb47a16339867695075be0f6b421a59bba8c95df"}, "originalPosition": 185}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTYxMjIxNA==", "bodyText": "does undelete change the operation time?", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r431612214", "createdAt": "2020-05-28T06:38:30Z", "author": {"login": "cgtz"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudBlobStore.java", "diffHunk": "@@ -469,17 +469,171 @@ public void updateTtl(List<MessageInfo> infos) throws StoreException {\n   private boolean updateTtlIfNeeded(BlobId blobId) throws CloudStorageException {\n     String blobKey = blobId.getID();\n     // See note in deleteIfNeeded.\n-    if (!checkCacheState(blobKey, BlobState.TTL_UPDATED, BlobState.DELETED)) {\n-      boolean updated = cloudDestination.updateBlobExpiration(blobId, Utils.Infinite_Time);\n-      // We do not have the definitive value of life version here. So we add to cache with minimum valid value.\n-      // If the key is present in cache, then correct life version will be updated. (see method {@link addToCache}).\n-      // If not then in worst case, the cache might let some operations with higher life version go through again.\n-      addToCache(blobKey, (short) 0, BlobState.TTL_UPDATED);\n-      return updated;\n+    if (!checkCacheState(blobKey, BlobState.TTL_UPDATED)) {\n+      short lifeVersion = cloudDestination.updateBlobExpiration(blobId, Utils.Infinite_Time,\n+          (metadata, key, updateFields) -> preTtlUpdateValidation(metadata, key, updateFields));\n+      addToCache(blobKey, lifeVersion, BlobState.TTL_UPDATED);\n+      return (lifeVersion != -1);\n     }\n     return false;\n   }\n \n+  /**\n+   * Validate {@link CloudBlobMetadata} map to make sure it has metadata for all keys, and they meet the {@code storeGetOptions} requirements.\n+   * @param cloudBlobMetadataMap {@link CloudBlobMetadata} map.\n+   * @param storeGetOptions {@link StoreGetOptions} requirements.\n+   * @param currentTimestamp current time stamp.\n+   * @throws StoreException if the {@code CloudBlobMetadata} isnt valid\n+   */\n+  private void validateCloudMetadata(Map<String, CloudBlobMetadata> cloudBlobMetadataMap,\n+      EnumSet<StoreGetOptions> storeGetOptions, long currentTimestamp, List<? extends StoreKey> ids)\n+      throws StoreException {\n+    for (String key : cloudBlobMetadataMap.keySet()) {\n+      if (isBlobDeleted(cloudBlobMetadataMap.get(key)) && !storeGetOptions.contains(\n+          StoreGetOptions.Store_Include_Deleted)) {\n+        throw new StoreException(\"Id \" + key + \" has been deleted on the cloud\", StoreErrorCodes.ID_Deleted);\n+      }\n+      if (isBlobExpired(cloudBlobMetadataMap.get(key), currentTimestamp) && !storeGetOptions.contains(\n+          StoreGetOptions.Store_Include_Expired)) {\n+        throw new StoreException(\"Id \" + key + \" has expired on the cloud\", StoreErrorCodes.TTL_Expired);\n+      }\n+    }\n+    validateAccountAndContainer(cloudBlobMetadataMap, ids);\n+  }\n+\n+  /**\n+   * Validate account id and container id for blobs in {@link CloudBlobMetadata} map match those in {@link StoreKey} list.\n+   * @param cloudBlobMetadataMap {@link Map} of {@link CloudBlobMetadata}.\n+   * @param storeKeys {@link List} of {@link StoreKey}s.\n+   */\n+  private void validateAccountAndContainer(Map<String, CloudBlobMetadata> cloudBlobMetadataMap,\n+      List<? extends StoreKey> storeKeys) throws StoreException {\n+    for (StoreKey key : storeKeys) {\n+      CloudBlobMetadata cloudBlobMetadata = cloudBlobMetadataMap.get(key.getID());\n+      // validate accountId and containerId\n+      if (!key.isAccountContainerMatch((short) cloudBlobMetadata.getAccountId(),\n+          (short) cloudBlobMetadata.getContainerId())) {\n+        if (storeConfig.storeValidateAuthorization) {\n+          throw new StoreException(\"GET authorization failure. Key: \" + key.getID() + \" Actual accountId: \"\n+              + cloudBlobMetadata.getAccountId() + \" Actual containerId: \" + cloudBlobMetadata.getAccountId(),\n+              StoreErrorCodes.Authorization_Failure);\n+        } else {\n+          logger.warn(\"GET authorization failure. Key: {} Actually accountId: {} Actually containerId: {}\", key.getID(),\n+              cloudBlobMetadata.getAccountId(), cloudBlobMetadata.getContainerId());\n+        }\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Validates existing metadata in cloud destination against requested update for delete.\n+   * @param metadata existing {@link CloudBlobMetadata} in cloud.\n+   * @param key {@link StoreKey} being deleted.\n+   * @param updateFields {@link Map} of fields and values being updated.\n+   * @return false only for vcr if local cloud destination life version is more recent. true if validation successful.\n+   * @throws StoreException if validation fails.\n+   */\n+  private boolean preDeleteValidation(CloudBlobMetadata metadata, StoreKey key, Map<String, Object> updateFields)\n+      throws StoreException {\n+    validateAccountAndContainer(Collections.singletonMap(metadata.getId(), metadata), Collections.singletonList(key));\n+    short requestedLifeVersion = (short) updateFields.get(FIELD_LIFE_VERSION);\n+    if (isVcr) {\n+      // This is a delete request from vcr. Apply delete only if incoming life version is more recent. Don't throw any\n+      // exception because replication relies on findMissingKeys which in turn relies on cosmos state for CloudBlobStore.\n+      // Cosmos could be missing some updates that were applied to ABS.\n+      return (!metadata.isDeleted() || metadata.getLifeVersion() < requestedLifeVersion) && (metadata.getLifeVersion()\n+          <= requestedLifeVersion);\n+    }\n+    if (requestedLifeVersion == MessageInfo.LIFE_VERSION_FROM_FRONTEND) {\n+      // This is a delete request from frontend\n+      if (metadata.isDeleted()) {\n+        throw new StoreException(\n+            \"Cannot delete id \" + metadata.getId() + \" since it is already marked as deleted in cloud.\",\n+            StoreErrorCodes.ID_Deleted);\n+      }\n+      // this is delete request from frontend, we use life version only for validation.\n+      updateFields.remove(FIELD_LIFE_VERSION);\n+    }\n+    return true;\n+  }\n+\n+  /**\n+   * Validates existing metadata in cloud destination against requested update for ttl.\n+   * Note that this method also has an unclean side effect of updating the {@code updateFields}.\n+   * @param metadata existing {@link CloudBlobMetadata} in cloud.\n+   * @param key {@link StoreKey} being updated.\n+   * @param updateFields {@link Map} of fields and values being updated.\n+   * @return false only for vcr if ttl is already applied on blob. true in all other cases if validation is successful.\n+   * @throws StoreException if validation fails.\n+   */\n+  private boolean preTtlUpdateValidation(CloudBlobMetadata metadata, StoreKey key, Map<String, Object> updateFields)\n+      throws StoreException {\n+    validateAccountAndContainer(Collections.singletonMap(metadata.getId(), metadata), Collections.singletonList(key));\n+    long now = System.currentTimeMillis();\n+    if (isVcr) {\n+      // For vcr don't update ttl if already updated. Don't throw any exception because replication relies on\n+      // findMissingKeys which in turn relies on cosmos state for CloudBlobStore. Cosmos could be missing some updates\n+      // that were applied to ABS.\n+      return metadata.getExpirationTime() != Utils.Infinite_Time;\n+    }\n+    if (metadata.isDeleted()) {\n+      throw new StoreException(\"Cannot update TTL of \" + key.getID() + \" since it is already deleted in the index.\",\n+          StoreErrorCodes.ID_Deleted);\n+    } else if (metadata.getExpirationTime() != Utils.Infinite_Time\n+        && metadata.getExpirationTime() < now + ttlUpdateBufferTimeMs) {\n+      throw new StoreException(\n+          \"TTL of \" + key.getID() + \" cannot be updated because it is too close to expiry. Minimum Op time (ms): \" + now\n+              + \". ExpiresAtMs: \" + metadata.getExpirationTime(), StoreErrorCodes.Update_Not_Allowed);\n+    }\n+    return true;\n+  }\n+\n+  /**\n+   * Validates existing metadata in cloud destination against requested undelete.\n+   * Note that this method also has an unclean side effect of updating the {@code updateFields}.\n+   * @param metadata existing {@link CloudBlobMetadata} in cloud.\n+   * @param key {@link StoreKey} being updated.\n+   * @param updateFields {@link Map} of fields and values being updated.\n+   * @throws StoreException if validation fails.\n+   */\n+  private boolean preUndeleteValidation(CloudBlobMetadata metadata, StoreKey key, Map<String, Object> updateFields)\n+      throws StoreException {\n+    validateAccountAndContainer(Collections.singletonMap(metadata.getId(), metadata), Collections.singletonList(key));\n+    short requestedLifeVersion = (short) updateFields.get(FIELD_LIFE_VERSION);\n+    if (isVcr) {\n+      // This is an undelete request from vcr. Apply undelete only if incoming life version is more recent. Don't throw\n+      // any exception because replication relies on findMissingKeys which in turn relies on cosmos state for CloudBlobStore.\n+      // Cosmos could be missing some updates that were applied to ABS.\n+      return metadata.getLifeVersion() < requestedLifeVersion;\n+    }\n+    if (metadata.isExpired()) {\n+      throw new StoreException(\"Id \" + key + \" already expired in cloud \", StoreErrorCodes.TTL_Expired);\n+    } else if (metadata.isUndeleted()) {\n+      throw new StoreException(\"Id \" + key + \" is already undeleted in cloud\", StoreErrorCodes.ID_Undeleted);\n+    } else if (!metadata.isDeleted()) {\n+      throw new StoreException(\"Id \" + key + \" is not deleted yet in cloud \", StoreErrorCodes.ID_Not_Deleted);\n+    } else if (metadata.getDeletionTime() + TimeUnit.DAYS.toMillis(storeConfig.storeDeletedMessageRetentionDays)\n+        < System.currentTimeMillis()) {\n+      throw new StoreException(\"Id \" + key + \" already permanently deleted in cloud \",\n+          StoreErrorCodes.ID_Deleted_Permanently);\n+    }\n+    // Update life version to appropriate value for frontend requests.\n+    updateFields.put(FIELD_LIFE_VERSION, metadata.getLifeVersion() + 1);\n+    return true;\n+  }\n+\n+  /**\n+   * Gets the operation time for a blob from blob metadata based on the blob's current state and timestamp recorded for that state.\n+   * @param metadata blob metadata from which to derive operation time.\n+   * @return operation time.\n+   */\n+  private long getOperationTime(CloudBlobMetadata metadata) {\n+    if (isBlobDeleted(metadata)) {\n+      return metadata.getDeletionTime();\n+    }\n+    return (metadata.getCreationTime() == Utils.Infinite_Time) ? metadata.getUploadTime() : metadata.getCreationTime();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fb47a16339867695075be0f6b421a59bba8c95df"}, "originalPosition": 393}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTYxNDI3NQ==", "bodyText": "why is this clause added? seems like it is immediately rethrowing the same exc.", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r431614275", "createdAt": "2020-05-28T06:43:48Z", "author": {"login": "cgtz"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudBlobStore.java", "diffHunk": "@@ -811,6 +990,8 @@ public void appendFrom(ReadableByteChannel channel, long size) throws StoreExcep\n         messageBuf.flip();\n         cloudBlobStore.putBlob(messageInfo, messageBuf, size);\n         messageIndex++;\n+      } catch (StoreException se) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fb47a16339867695075be0f6b421a59bba8c95df"}, "originalPosition": 525}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTYxNDU5OA==", "bodyText": "note that  the validator may change fields within this map.", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r431614598", "createdAt": "2020-05-28T06:44:33Z", "author": {"login": "cgtz"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudUpdateValidator.java", "diffHunk": "@@ -0,0 +1,37 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.cloud;\n+\n+import com.github.ambry.store.StoreException;\n+import com.github.ambry.store.StoreKey;\n+import java.util.Map;\n+\n+\n+/**\n+ * Interface for Ambry validation logic for updates requested from cloud destination.\n+ */\n+public interface CloudUpdateValidator {\n+  /**\n+   * Validate the sanity of update operation on given {@code updateFields} against existing {@link CloudBlobMetadata} in\n+   * cloud destination for the blob with key {@code key}. This can be used to hook Ambry store related validation logic\n+   * during {@link CloudDestination} specific get-check-update flow.\n+   * @param metadata {@link CloudBlobMetadata} object obtained from cloud destination.\n+   * @param key {@link StoreKey} of the blob being updated.\n+   * @param updateFields {@link Map} of fields and new values requested for update.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fb47a16339867695075be0f6b421a59bba8c95df"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTYxNzE0Ng==", "bodyText": "What is the case where a StoreException gets here? Is this when the CloudUpdateValidator throws?", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r431617146", "createdAt": "2020-05-28T06:50:52Z", "author": {"login": "cgtz"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/azure/AzureCloudDestination.java", "diffHunk": "@@ -473,7 +483,7 @@ private CloudStorageException toCloudStorageException(String message, Exception\n       statusCode = StatusCodes.INTERNAL_SERVER_ERROR;\n     }\n     // Everything is retryable except NOT_FOUND\n-    boolean isRetryable = (statusCode != StatusCodes.NOTFOUND);\n+    boolean isRetryable = (statusCode != StatusCodes.NOTFOUND && !(e instanceof StoreException));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fb47a16339867695075be0f6b421a59bba8c95df"}, "originalPosition": 164}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTYyMDM1OQ==", "bodyText": "It seems like the code will now throw in this case. Is there a reason for the change?", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r431620359", "createdAt": "2020-05-28T06:57:52Z", "author": {"login": "cgtz"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/azure/AzureCloudDestination.java", "diffHunk": "@@ -293,21 +306,18 @@ private boolean updateBlobMetadata(BlobId blobId, Map<String, Object> updateFiel\n           // attempt fails.  So we check for that case here.\n           CloudBlobMetadata cosmosMetadata = cosmosDataAccessor.getMetadataOrNull(blobId);\n           if (cosmosMetadata != null) {\n-            if (cosmosMetadata.isDeletedOrExpired()) {\n+            if (cosmosMetadata.isCompactionCandidate(\n+                TimeUnit.HOURS.toMillis(cloudConfig.cloudBlobCompactionIntervalHours))) {\n               logger.warn(\"Inconsistency: Cosmos contains record for inactive blob {}, removing it.\", blobId.getID());\n               cosmosDataAccessor.deleteMetadata(cosmosMetadata);\n               azureMetrics.blobUpdateRecoverCount.inc();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fb47a16339867695075be0f6b421a59bba8c95df"}, "originalPosition": 129}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTYyMDcxMg==", "bodyText": "unused import?", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r431620712", "createdAt": "2020-05-28T06:58:35Z", "author": {"login": "cgtz"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudStorageManager.java", "diffHunk": "@@ -16,6 +16,7 @@\n import com.github.ambry.clustermap.ClusterMap;\n import com.github.ambry.clustermap.PartitionId;\n import com.github.ambry.clustermap.ReplicaId;\n+import com.github.ambry.config.StoreConfig;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fb47a16339867695075be0f6b421a59bba8c95df"}, "originalPosition": 4}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "5a1dd2d49c45f134b221b1e335542e84abe5ab2a", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/5a1dd2d49c45f134b221b1e335542e84abe5ab2a", "committedDate": "2020-06-01T19:36:58Z", "message": "Fix review comments."}, "afterCommit": {"oid": "e9e7105d292e1d7de29ec52220f044f8fad837f0", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/e9e7105d292e1d7de29ec52220f044f8fad837f0", "committedDate": "2020-06-02T19:39:02Z", "message": "Fix cloudblobstore tests."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIzMTA2MDUy", "url": "https://github.com/linkedin/ambry/pull/1517#pullrequestreview-423106052", "createdAt": "2020-06-02T22:42:55Z", "commit": {"oid": "5c9b48fb637be27cd3f241880235bddc9664835a"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIzMTE3MTQy", "url": "https://github.com/linkedin/ambry/pull/1517#pullrequestreview-423117142", "createdAt": "2020-06-02T23:12:12Z", "commit": {"oid": "5c9b48fb637be27cd3f241880235bddc9664835a"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d28f668503e739abb7588b21f8bb1b38990249d3", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/d28f668503e739abb7588b21f8bb1b38990249d3", "committedDate": "2020-06-05T03:23:37Z", "message": "Change the CloudBlobStore to make it compatible with BlobStore and make it ready for serving reqeusts."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b827babba0d3470b3e22a5195750510058c5868d", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/b827babba0d3470b3e22a5195750510058c5868d", "committedDate": "2020-06-05T03:23:46Z", "message": "Update license"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "976566752a52ec49009092e8499456c7e80e3a9e", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/976566752a52ec49009092e8499456c7e80e3a9e", "committedDate": "2020-06-05T03:23:47Z", "message": "Fix tests."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "44ffacf4349cfe6f61aa3351b1b04b82033050bf", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/44ffacf4349cfe6f61aa3351b1b04b82033050bf", "committedDate": "2020-06-05T03:23:47Z", "message": "Address review comments."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4eefe8263c0ec609c5cc20143a1568a1482f0657", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/4eefe8263c0ec609c5cc20143a1568a1482f0657", "committedDate": "2020-06-05T03:23:47Z", "message": "Fix review comments."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "873d2ab09a2ed79f140f33f13da9680cb8cf960e", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/873d2ab09a2ed79f140f33f13da9680cb8cf960e", "committedDate": "2020-06-05T03:23:47Z", "message": "Update test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "13f48449ead375865376458a29f6f6e2bb68c862", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/13f48449ead375865376458a29f6f6e2bb68c862", "committedDate": "2020-06-05T03:23:47Z", "message": "Fix tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bde000b7feaabb1892c878f9944ce2c14c0f1358", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/bde000b7feaabb1892c878f9944ce2c14c0f1358", "committedDate": "2020-06-05T03:23:47Z", "message": "Fix cloudblobstore tests."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "da55bac18bcdd1b274e37e03e8631834fa375962", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/da55bac18bcdd1b274e37e03e8631834fa375962", "committedDate": "2020-06-05T03:23:47Z", "message": "cleanup"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "43ddd899be3828bc01b2c6e5635e5991f51951bb", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/43ddd899be3828bc01b2c6e5635e5991f51951bb", "committedDate": "2020-06-05T03:23:47Z", "message": "Add integration test for cloudblob store. Also add more test cases and fix minor bugs."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "bea3f774211dfdca3850ab2edee8006bc5dc3705", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/bea3f774211dfdca3850ab2edee8006bc5dc3705", "committedDate": "2020-06-05T00:21:02Z", "message": "Add integration test for cloudblob store. Also add more test cases and fix minor bugs."}, "afterCommit": {"oid": "43ddd899be3828bc01b2c6e5635e5991f51951bb", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/43ddd899be3828bc01b2c6e5635e5991f51951bb", "committedDate": "2020-06-05T03:23:47Z", "message": "Add integration test for cloudblob store. Also add more test cases and fix minor bugs."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "89a230c8e53fdb485db7a7cc3745f14855828058", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/89a230c8e53fdb485db7a7cc3745f14855828058", "committedDate": "2020-06-05T03:31:22Z", "message": "Ignore AzureIntegrationTest"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1MDQwNjI3", "url": "https://github.com/linkedin/ambry/pull/1517#pullrequestreview-425040627", "createdAt": "2020-06-05T06:58:16Z", "commit": {"oid": "43ddd899be3828bc01b2c6e5635e5991f51951bb"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQwNjo1ODoxNlrOGfijnw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQwNjo1ODoxNlrOGfijnw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTcyNTIxNQ==", "bodyText": "This doesn't make sense, you can't expect the method to return false and throw an exception.", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r435725215", "createdAt": "2020-06-05T06:58:16Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/test/java/com/github/ambry/cloud/azure/AzureIntegrationTest.java", "diffHunk": "@@ -502,8 +502,12 @@ public void testRepairAfterIncompleteCompaction() throws Exception {\n     azureDest.getAzureBlobDataAccessor().purgeBlobs(Collections.singletonList(cloudBlobMetadata));\n \n     // Try to delete again (to trigger recovery), verify removed from Cosmos\n-    assertFalse(\"Expected delete to return false\",\n-        azureDest.deleteBlob(blobId, deletionTime, (short) 0, dummyCloudUpdateValidator));\n+    try {\n+      assertFalse(\"Expected delete to return false\",\n+          azureDest.deleteBlob(blobId, deletionTime, (short) 0, dummyCloudUpdateValidator));\n+    } catch (CloudStorageException cex) {\n+      assertEquals(\"Unexpected error code\", HttpConstants.StatusCodes.NOTFOUND, cex.getStatusCode());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "43ddd899be3828bc01b2c6e5635e5991f51951bb"}, "originalPosition": 19}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1MDQxNDUx", "url": "https://github.com/linkedin/ambry/pull/1517#pullrequestreview-425041451", "createdAt": "2020-06-05T06:59:52Z", "commit": {"oid": "43ddd899be3828bc01b2c6e5635e5991f51951bb"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQwNjo1OTo1MlrOGfil3A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQwNjo1OTo1MlrOGfil3A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTcyNTc4OA==", "bodyText": "The methods in this class seem unrelated to anything cloud.", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r435725788", "createdAt": "2020-06-05T06:59:52Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/test/java/com/github/ambry/cloud/CloudTestUtil.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/**\n+ * Copyright 2019 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.cloud;\n+\n+import com.github.ambry.clustermap.PartitionId;\n+import com.github.ambry.commons.BlobId;\n+import com.github.ambry.store.MessageInfo;\n+import com.github.ambry.store.MockMessageWriteSet;\n+import com.github.ambry.utils.TestUtils;\n+import java.nio.ByteBuffer;\n+import java.util.Random;\n+\n+import static com.github.ambry.commons.BlobId.*;\n+\n+\n+public class CloudTestUtil {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "43ddd899be3828bc01b2c6e5635e5991f51951bb"}, "originalPosition": 27}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1MDQyNjc5", "url": "https://github.com/linkedin/ambry/pull/1517#pullrequestreview-425042679", "createdAt": "2020-06-05T07:02:15Z", "commit": {"oid": "43ddd899be3828bc01b2c6e5635e5991f51951bb"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQwNzowMjoxNVrOGfipfA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQwNzowMjoxNVrOGfipfA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTcyNjcxNg==", "bodyText": "Cool, thanks for adding this.", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r435726716", "createdAt": "2020-06-05T07:02:15Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/test/java/com/github/ambry/cloud/CloudBlobStoreIntegrationTest.java", "diffHunk": "@@ -0,0 +1,515 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.cloud;\n+\n+import com.codahale.metrics.MetricRegistry;\n+import com.github.ambry.cloud.azure.AzureCloudConfig;\n+import com.github.ambry.cloud.azure.AzureMetrics;\n+import com.github.ambry.clustermap.ClusterMap;\n+import com.github.ambry.clustermap.MockClusterMap;\n+import com.github.ambry.clustermap.MockDataNodeId;\n+import com.github.ambry.clustermap.Partition;\n+import com.github.ambry.clustermap.PartitionId;\n+import com.github.ambry.clustermap.PartitionState;\n+import com.github.ambry.config.CloudConfig;\n+import com.github.ambry.config.ClusterMapConfig;\n+import com.github.ambry.config.StoreConfig;\n+import com.github.ambry.config.VerifiableProperties;\n+import com.github.ambry.network.Port;\n+import com.github.ambry.network.PortType;\n+import com.github.ambry.store.MessageInfo;\n+import com.github.ambry.store.MockMessageWriteSet;\n+import com.github.ambry.store.StoreErrorCodes;\n+import com.github.ambry.store.StoreException;\n+import com.github.ambry.store.StoreGetOptions;\n+import com.github.ambry.store.StoreInfo;\n+import com.github.ambry.utils.Utils;\n+import com.microsoft.azure.cosmosdb.ConnectionPolicy;\n+import com.microsoft.azure.cosmosdb.ConsistencyLevel;\n+import com.microsoft.azure.cosmosdb.Document;\n+import com.microsoft.azure.cosmosdb.FeedOptions;\n+import com.microsoft.azure.cosmosdb.FeedResponse;\n+import com.microsoft.azure.cosmosdb.PartitionKey;\n+import com.microsoft.azure.cosmosdb.RequestOptions;\n+import com.microsoft.azure.cosmosdb.SqlQuerySpec;\n+import com.microsoft.azure.cosmosdb.rx.AsyncDocumentClient;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.EnumSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Properties;\n+import java.util.Random;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import static com.github.ambry.cloud.CloudTestUtil.*;\n+import static org.junit.Assert.*;\n+\n+\n+/**\n+ * Integration Test cases for {@link CloudBlobStore}\n+ * Must supply file azure-test.properties in classpath with valid config property values.\n+ */\n+//@Ignore\n+@RunWith(Parameterized.class)\n+public class CloudBlobStoreIntegrationTest {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "43ddd899be3828bc01b2c6e5635e5991f51951bb"}, "originalPosition": 74}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1NDg2NDgw", "url": "https://github.com/linkedin/ambry/pull/1517#pullrequestreview-425486480", "createdAt": "2020-06-05T17:24:39Z", "commit": {"oid": "43ddd899be3828bc01b2c6e5635e5991f51951bb"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNzoyNDozOVrOGf289g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNzoyNDozOVrOGf289g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA1OTM4Mg==", "bodyText": "Is it possible that is has been deleted in the cloud but didn't go through this vcr so the cache entry is stale?", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r436059382", "createdAt": "2020-06-05T17:24:39Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudBlobStore.java", "diffHunk": "@@ -416,16 +416,21 @@ public short undelete(MessageInfo info) throws StoreException {\n    * @param lifeVersion life version of the deleted blob.\n    * @return final updated life version of the blob.\n    * @throws CloudStorageException in case any exception happens during undelete.\n+   * @throws StoreException in case any {@link StoreException} is thrown.\n    */\n-  private short undeleteIfNeeded(BlobId blobId, short lifeVersion) throws CloudStorageException {\n+  private short undeleteIfNeeded(BlobId blobId, short lifeVersion) throws CloudStorageException, StoreException {\n     // See note in deleteIfNeeded.\n     if (!checkCacheState(blobId.getID(), lifeVersion, BlobState.CREATED)) {\n       short newLifeVersion = cloudDestination.undeleteBlob(blobId, lifeVersion, this::preUndeleteValidation);\n       addToCache(blobId.getID(), newLifeVersion, BlobState.CREATED);\n       return newLifeVersion;\n     } else {\n-      throw new CloudStorageException(\"Error updating blob metadata\",\n-          new StoreException(\"Id \" + blobId.getID() + \" is already undeleted in cloud\", StoreErrorCodes.ID_Undeleted));\n+      if (lifeVersion > 0) {\n+        throw new StoreException(\"Id \" + blobId.getID() + \" is already undeleted in cloud\",\n+            StoreErrorCodes.ID_Undeleted);\n+      } else {\n+        throw new StoreException(\"Id \" + blobId.getID() + \" not deleted yet in cloud\", StoreErrorCodes.ID_Not_Deleted);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "43ddd899be3828bc01b2c6e5635e5991f51951bb"}, "originalPosition": 60}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1NDg3ODU1", "url": "https://github.com/linkedin/ambry/pull/1517#pullrequestreview-425487855", "createdAt": "2020-06-05T17:26:47Z", "commit": {"oid": "43ddd899be3828bc01b2c6e5635e5991f51951bb"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNzoyNjo0N1rOGf3BOQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNzoyNjo0N1rOGf3BOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA2MDQ3Mw==", "bodyText": "I think you can use Map.getOrDefault() here.", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r436060473", "createdAt": "2020-06-05T17:26:47Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/azure/AzureCloudDestination.java", "diffHunk": "@@ -195,8 +195,8 @@ public short undeleteBlob(BlobId blobId, short lifeVersion, CloudUpdateValidator\n     updateFields.put(CloudBlobMetadata.FIELD_LIFE_VERSION, lifeVersion);\n     updateFields.put(CloudBlobMetadata.FIELD_DELETION_TIME, Utils.Infinite_Time);\n     UpdateResponse updateResponse = updateBlobMetadata(blobId, updateFields, cloudUpdateValidator);\n-    return updateResponse.metadata.containsKey(CloudBlobMetadata.FIELD_LIFE_VERSION) ? 0\n-        : Short.parseShort(updateResponse.metadata.get(CloudBlobMetadata.FIELD_LIFE_VERSION));\n+    return updateResponse.metadata.containsKey(CloudBlobMetadata.FIELD_LIFE_VERSION) ? Short.parseShort(\n+        updateResponse.metadata.get(CloudBlobMetadata.FIELD_LIFE_VERSION)) : 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "43ddd899be3828bc01b2c6e5635e5991f51951bb"}, "originalPosition": 7}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1NDg5NTc1", "url": "https://github.com/linkedin/ambry/pull/1517#pullrequestreview-425489575", "createdAt": "2020-06-05T17:29:21Z", "commit": {"oid": "43ddd899be3828bc01b2c6e5635e5991f51951bb"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNzoyOToyMVrOGf3GaA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNzoyOToyMVrOGf3GaA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA2MTgwMA==", "bodyText": "Comment doesn't seem to match code.", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r436061800", "createdAt": "2020-06-05T17:29:21Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/test/java/com/github/ambry/cloud/CloudBlobStoreIntegrationTest.java", "diffHunk": "@@ -0,0 +1,515 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.cloud;\n+\n+import com.codahale.metrics.MetricRegistry;\n+import com.github.ambry.cloud.azure.AzureCloudConfig;\n+import com.github.ambry.cloud.azure.AzureMetrics;\n+import com.github.ambry.clustermap.ClusterMap;\n+import com.github.ambry.clustermap.MockClusterMap;\n+import com.github.ambry.clustermap.MockDataNodeId;\n+import com.github.ambry.clustermap.Partition;\n+import com.github.ambry.clustermap.PartitionId;\n+import com.github.ambry.clustermap.PartitionState;\n+import com.github.ambry.config.CloudConfig;\n+import com.github.ambry.config.ClusterMapConfig;\n+import com.github.ambry.config.StoreConfig;\n+import com.github.ambry.config.VerifiableProperties;\n+import com.github.ambry.network.Port;\n+import com.github.ambry.network.PortType;\n+import com.github.ambry.store.MessageInfo;\n+import com.github.ambry.store.MockMessageWriteSet;\n+import com.github.ambry.store.StoreErrorCodes;\n+import com.github.ambry.store.StoreException;\n+import com.github.ambry.store.StoreGetOptions;\n+import com.github.ambry.store.StoreInfo;\n+import com.github.ambry.utils.Utils;\n+import com.microsoft.azure.cosmosdb.ConnectionPolicy;\n+import com.microsoft.azure.cosmosdb.ConsistencyLevel;\n+import com.microsoft.azure.cosmosdb.Document;\n+import com.microsoft.azure.cosmosdb.FeedOptions;\n+import com.microsoft.azure.cosmosdb.FeedResponse;\n+import com.microsoft.azure.cosmosdb.PartitionKey;\n+import com.microsoft.azure.cosmosdb.RequestOptions;\n+import com.microsoft.azure.cosmosdb.SqlQuerySpec;\n+import com.microsoft.azure.cosmosdb.rx.AsyncDocumentClient;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.EnumSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Properties;\n+import java.util.Random;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import static com.github.ambry.cloud.CloudTestUtil.*;\n+import static org.junit.Assert.*;\n+\n+\n+/**\n+ * Integration Test cases for {@link CloudBlobStore}\n+ * Must supply file azure-test.properties in classpath with valid config property values.\n+ */\n+//@Ignore\n+@RunWith(Parameterized.class)\n+public class CloudBlobStoreIntegrationTest {\n+\n+  private VerifiableProperties verifiableProperties;\n+  private CloudBlobStore cloudBlobStore;\n+  private CloudDestination cloudDestination;\n+  private Random random = new Random();\n+  private short accountId = 101;\n+  private short containerId = 5;\n+  private long operationTime = System.currentTimeMillis();\n+  private boolean isVcr;\n+  private PartitionId partitionId;\n+  // one day retention", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "43ddd899be3828bc01b2c6e5635e5991f51951bb"}, "originalPosition": 85}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1NDkzMjM0", "url": "https://github.com/linkedin/ambry/pull/1517#pullrequestreview-425493234", "createdAt": "2020-06-05T17:34:06Z", "commit": {"oid": "43ddd899be3828bc01b2c6e5635e5991f51951bb"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNzozNDowN1rOGf3SOg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNzozNDowN1rOGf3SOg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA2NDgyNg==", "bodyText": "Can this be a common utility used by both (and future) integration tests, like CloudTestUtil?", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r436064826", "createdAt": "2020-06-05T17:34:07Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/test/java/com/github/ambry/cloud/CloudBlobStoreIntegrationTest.java", "diffHunk": "@@ -0,0 +1,515 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.cloud;\n+\n+import com.codahale.metrics.MetricRegistry;\n+import com.github.ambry.cloud.azure.AzureCloudConfig;\n+import com.github.ambry.cloud.azure.AzureMetrics;\n+import com.github.ambry.clustermap.ClusterMap;\n+import com.github.ambry.clustermap.MockClusterMap;\n+import com.github.ambry.clustermap.MockDataNodeId;\n+import com.github.ambry.clustermap.Partition;\n+import com.github.ambry.clustermap.PartitionId;\n+import com.github.ambry.clustermap.PartitionState;\n+import com.github.ambry.config.CloudConfig;\n+import com.github.ambry.config.ClusterMapConfig;\n+import com.github.ambry.config.StoreConfig;\n+import com.github.ambry.config.VerifiableProperties;\n+import com.github.ambry.network.Port;\n+import com.github.ambry.network.PortType;\n+import com.github.ambry.store.MessageInfo;\n+import com.github.ambry.store.MockMessageWriteSet;\n+import com.github.ambry.store.StoreErrorCodes;\n+import com.github.ambry.store.StoreException;\n+import com.github.ambry.store.StoreGetOptions;\n+import com.github.ambry.store.StoreInfo;\n+import com.github.ambry.utils.Utils;\n+import com.microsoft.azure.cosmosdb.ConnectionPolicy;\n+import com.microsoft.azure.cosmosdb.ConsistencyLevel;\n+import com.microsoft.azure.cosmosdb.Document;\n+import com.microsoft.azure.cosmosdb.FeedOptions;\n+import com.microsoft.azure.cosmosdb.FeedResponse;\n+import com.microsoft.azure.cosmosdb.PartitionKey;\n+import com.microsoft.azure.cosmosdb.RequestOptions;\n+import com.microsoft.azure.cosmosdb.SqlQuerySpec;\n+import com.microsoft.azure.cosmosdb.rx.AsyncDocumentClient;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.EnumSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Properties;\n+import java.util.Random;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import static com.github.ambry.cloud.CloudTestUtil.*;\n+import static org.junit.Assert.*;\n+\n+\n+/**\n+ * Integration Test cases for {@link CloudBlobStore}\n+ * Must supply file azure-test.properties in classpath with valid config property values.\n+ */\n+//@Ignore\n+@RunWith(Parameterized.class)\n+public class CloudBlobStoreIntegrationTest {\n+\n+  private VerifiableProperties verifiableProperties;\n+  private CloudBlobStore cloudBlobStore;\n+  private CloudDestination cloudDestination;\n+  private Random random = new Random();\n+  private short accountId = 101;\n+  private short containerId = 5;\n+  private long operationTime = System.currentTimeMillis();\n+  private boolean isVcr;\n+  private PartitionId partitionId;\n+  // one day retention\n+  private final String PROPS_FILE_NAME = \"azure-test.properties\";\n+  private VcrMetrics vcrMetrics;\n+  private AzureMetrics azureMetrics;\n+\n+  /**\n+   * Run in both VCR and live serving mode.\n+   * @return an array with both {@code false} and {@code true}.\n+   */\n+  @Parameterized.Parameters\n+  public static List<Object[]> data() {\n+    return Arrays.asList(new Object[][]{{false}, {true}});\n+  }\n+\n+  /**\n+   * Constructor for {@link CloudBlobStoreIntegrationTest}.\n+   * @param isVcr true if testing for vcr. false otherwise.\n+   */\n+  public CloudBlobStoreIntegrationTest(boolean isVcr) {\n+    this.isVcr = isVcr;\n+  }\n+\n+  @Before\n+  public void setup() throws ReflectiveOperationException {\n+    Properties testProperties = new Properties();\n+    try (InputStream input = this.getClass().getClassLoader().getResourceAsStream(PROPS_FILE_NAME)) {\n+      if (input == null) {\n+        throw new IllegalStateException(\"Could not find resource: \" + PROPS_FILE_NAME);\n+      }\n+      testProperties.load(input);\n+    } catch (IOException ex) {\n+      throw new IllegalStateException(\"Could not load properties from resource: \" + PROPS_FILE_NAME);\n+    }\n+    testProperties.setProperty(\"clustermap.cluster.name\", \"Integration-Test\");\n+    testProperties.setProperty(\"clustermap.datacenter.name\", \"uswest\");\n+    testProperties.setProperty(\"clustermap.host.name\", \"localhost\");\n+    testProperties.setProperty(\"kms.default.container.key\",\n+        \"B374A26A71490437AA024E4FADD5B497FDFF1A8EA6FF12F6FB65AF2720B59CCF\");\n+\n+    testProperties.setProperty(CloudConfig.CLOUD_DELETED_BLOB_RETENTION_DAYS, String.valueOf(1));\n+    testProperties.setProperty(AzureCloudConfig.AZURE_PURGE_BATCH_SIZE, \"10\");\n+    testProperties.setProperty(CloudConfig.CLOUD_IS_VCR, \"\" + isVcr);\n+    verifiableProperties = new VerifiableProperties(testProperties);\n+    ClusterMapConfig clusterMapConfig = new ClusterMapConfig(verifiableProperties);\n+    CloudConfig cloudConfig = new CloudConfig(verifiableProperties);\n+    partitionId = new Partition(666, clusterMapConfig.clusterMapDefaultPartitionClass, PartitionState.READ_WRITE,\n+        100 * 1024 * 1024 * 1024L);\n+    ClusterMap clusterMap = new MockClusterMap(false, Collections.singletonList(\n+        new MockDataNodeId(Collections.singletonList(new Port(6666, PortType.PLAINTEXT)),\n+            Collections.singletonList(\"test\"), \"AzureTest\")), 1, Collections.singletonList(partitionId), \"AzureTest\");\n+    MetricRegistry registry = new MetricRegistry();\n+    vcrMetrics = new VcrMetrics(registry);\n+    azureMetrics = new AzureMetrics(registry);\n+    CloudDestinationFactory cloudDestinationFactory =\n+        Utils.getObj(cloudConfig.cloudDestinationFactoryClass, verifiableProperties, registry);\n+    cloudDestination = cloudDestinationFactory.getCloudDestination();\n+    cloudBlobStore = new CloudBlobStore(verifiableProperties, partitionId, cloudDestination, clusterMap, vcrMetrics);\n+    cloudBlobStore.start();\n+  }\n+\n+  @After\n+  public void destroy() throws IOException {\n+    cleanup();\n+    if (cloudBlobStore != null) {\n+      cloudBlobStore.shutdown();\n+    }\n+    if (cloudDestination != null) {\n+      cloudDestination.close();\n+    }\n+  }\n+\n+  /** Test {@link CloudBlobStore#put} method. */\n+  @Test\n+  public void testPut() throws StoreException {\n+    // Put blobs with and without expiration and encryption\n+    MockMessageWriteSet messageWriteSet = new MockMessageWriteSet();\n+    int count = 5;\n+    int expectedUploads = 0;\n+    int expectedEncryptions = 0;\n+    for (int j = 0; j < count; j++) {\n+      long size = Math.abs(random.nextLong()) % 10000;\n+      // Permanent and encrypted, should be uploaded and not reencrypted\n+      addBlobToMessageSet(messageWriteSet, size, Utils.Infinite_Time, accountId, containerId, true, false, partitionId,\n+          operationTime, isVcr);\n+      expectedUploads++;\n+      // Permanent and unencrypted\n+      addBlobToMessageSet(messageWriteSet, size, Utils.Infinite_Time, accountId, containerId, false, false, partitionId,\n+          operationTime, isVcr);\n+      expectedUploads++;\n+    }\n+    cloudBlobStore.put(messageWriteSet);\n+    assertEquals(\"Unexpected blobs count\", expectedUploads, azureMetrics.blobUploadSuccessCount.getCount());\n+    assertEquals(\"Unexpected encryption count\", expectedEncryptions, vcrMetrics.blobEncryptionCount.getCount());\n+  }\n+\n+  /** Test {@link CloudBlobStore#get} method. */\n+  @Test\n+  public void testGet() throws StoreException {\n+    MockMessageWriteSet messageWriteSet = new MockMessageWriteSet();\n+    addBlobToMessageSet(messageWriteSet, Utils.Infinite_Time, accountId, containerId, partitionId,\n+        operationTime, (short) 2);\n+    cloudBlobStore.put(messageWriteSet);\n+\n+    // verify that the blob was uploaded with expected metadata.\n+    StoreInfo storeInfo = cloudBlobStore.get(\n+        messageWriteSet.getMessageSetInfo().stream().map(MessageInfo::getStoreKey).collect(Collectors.toList()),\n+        EnumSet.allOf(StoreGetOptions.class));\n+    assertEquals(\"Unexpected blob id\", messageWriteSet.getMessageSetInfo().get(0).getStoreKey(),\n+        storeInfo.getMessageReadSetInfo().get(0).getStoreKey());\n+    assertEquals(\"Unexpected live version\", messageWriteSet.getMessageSetInfo().get(0).getLifeVersion(),\n+        storeInfo.getMessageReadSetInfo().get(0).getLifeVersion());\n+    assertEquals(\"Unexpected delete status\", messageWriteSet.getMessageSetInfo().get(0).isDeleted(),\n+        storeInfo.getMessageReadSetInfo().get(0).isDeleted());\n+    assertEquals(\"Unexpected blob size\", messageWriteSet.getMessageSetInfo().get(0).getSize(),\n+        storeInfo.getMessageReadSetInfo().get(0).getSize());\n+    assertEquals(\"Unexpected ttl update status\", messageWriteSet.getMessageSetInfo().get(0).isTtlUpdated(),\n+        storeInfo.getMessageReadSetInfo().get(0).isTtlUpdated());\n+    assertEquals(\"Unexpected account id\", messageWriteSet.getMessageSetInfo().get(0).getAccountId(),\n+        storeInfo.getMessageReadSetInfo().get(0).getAccountId());\n+    assertEquals(\"Unexpected container id\", messageWriteSet.getMessageSetInfo().get(0).getContainerId(),\n+        storeInfo.getMessageReadSetInfo().get(0).getContainerId());\n+    assertEquals(\"Unexpected operation time\", messageWriteSet.getMessageSetInfo().get(0).getOperationTimeMs(),\n+        storeInfo.getMessageReadSetInfo().get(0).getOperationTimeMs());\n+  }\n+\n+  /** Test {@link CloudBlobStore#delete} method. */\n+  @Test\n+  public void testDelete() throws StoreException {\n+    cleanup();\n+    if (isVcr) {\n+      testDeleteFromVcr();\n+    } else {\n+      testDeleteFromFrontend();\n+    }\n+  }\n+\n+  /** Test {@link CloudBlobStore#delete} method for vcr. */\n+  public void testDeleteFromVcr() throws StoreException {\n+    // First upload a blob with a life version 2\n+    MockMessageWriteSet messageWriteSet = new MockMessageWriteSet();\n+    addBlobToMessageSet(messageWriteSet, Utils.Infinite_Time, accountId, containerId, partitionId,\n+        operationTime, (short) 2);\n+    cloudBlobStore.put(messageWriteSet);\n+\n+    // verify that the blob was uploaded with expected metadata.\n+    StoreInfo storeInfo = cloudBlobStore.get(\n+        messageWriteSet.getMessageSetInfo().stream().map(MessageInfo::getStoreKey).collect(Collectors.toList()),\n+        EnumSet.allOf(StoreGetOptions.class));\n+    assertEquals(\"Unexpected live version\", messageWriteSet.getMessageSetInfo().get(0).getLifeVersion(),\n+        storeInfo.getMessageReadSetInfo().get(0).getLifeVersion());\n+    assertEquals(\"Unexpected delete status\", messageWriteSet.getMessageSetInfo().get(0).isDeleted(),\n+        storeInfo.getMessageReadSetInfo().get(0).isDeleted());\n+\n+    // Now delete with a smaller life version should fail silently without updating the life version.\n+    MessageInfo messageInfo = messageWriteSet.getMessageSetInfo().get(0);\n+    MessageInfo deleteMessageInfo =\n+        new MessageInfo(messageInfo.getStoreKey(), messageInfo.getSize(), messageInfo.isDeleted(),\n+            messageInfo.isTtlUpdated(), messageInfo.isUndeleted(), messageInfo.getExpirationTimeInMs(),\n+            messageInfo.getCrc(), messageInfo.getAccountId(), messageInfo.getContainerId(),\n+            messageInfo.getOperationTimeMs(), (short) 1);\n+    cloudBlobStore.delete(Collections.singletonList(deleteMessageInfo));\n+    storeInfo = cloudBlobStore.get(\n+        messageWriteSet.getMessageSetInfo().stream().map(MessageInfo::getStoreKey).collect(Collectors.toList()),\n+        EnumSet.allOf(StoreGetOptions.class));\n+    assertEquals(\"Unexpected live version\", messageWriteSet.getMessageSetInfo().get(0).getLifeVersion(),\n+        storeInfo.getMessageReadSetInfo().get(0).getLifeVersion());\n+    assertEquals(\"Unexpected delete status\", messageWriteSet.getMessageSetInfo().get(0).isDeleted(),\n+        storeInfo.getMessageReadSetInfo().get(0).isDeleted());\n+\n+    // Delete with same life version should pass without changing life version.\n+    deleteMessageInfo = new MessageInfo(messageInfo.getStoreKey(), messageInfo.getSize(), messageInfo.isDeleted(),\n+        messageInfo.isTtlUpdated(), messageInfo.isUndeleted(), messageInfo.getExpirationTimeInMs(),\n+        messageInfo.getCrc(), messageInfo.getAccountId(), messageInfo.getContainerId(),\n+        messageInfo.getOperationTimeMs(), messageInfo.getLifeVersion());\n+    cloudBlobStore.delete(Collections.singletonList(deleteMessageInfo));\n+    storeInfo = cloudBlobStore.get(\n+        messageWriteSet.getMessageSetInfo().stream().map(MessageInfo::getStoreKey).collect(Collectors.toList()),\n+        EnumSet.allOf(StoreGetOptions.class));\n+    assertEquals(\"Unexpected live version\", messageWriteSet.getMessageSetInfo().get(0).getLifeVersion(),\n+        storeInfo.getMessageReadSetInfo().get(0).getLifeVersion());\n+    assertTrue(\"Unexpected delete status\", storeInfo.getMessageReadSetInfo().get(0).isDeleted());\n+\n+    // Deleting a deleted blob with higher life version should update life version.\n+    deleteMessageInfo = new MessageInfo(messageInfo.getStoreKey(), messageInfo.getSize(), messageInfo.isDeleted(),\n+        messageInfo.isTtlUpdated(), messageInfo.isUndeleted(), messageInfo.getExpirationTimeInMs(),\n+        messageInfo.getCrc(), messageInfo.getAccountId(), messageInfo.getContainerId(),\n+        messageInfo.getOperationTimeMs(), (short) 3);\n+    cloudBlobStore.delete(Collections.singletonList(deleteMessageInfo));\n+    storeInfo = cloudBlobStore.get(\n+        messageWriteSet.getMessageSetInfo().stream().map(MessageInfo::getStoreKey).collect(Collectors.toList()),\n+        EnumSet.allOf(StoreGetOptions.class));\n+    assertEquals(\"Unexpected live version\", 3, storeInfo.getMessageReadSetInfo().get(0).getLifeVersion());\n+    assertTrue(\"Unexpected delete status\", storeInfo.getMessageReadSetInfo().get(0).isDeleted());\n+\n+    // Deleting again with smaller life version should fail with exception.\n+    deleteMessageInfo = new MessageInfo(messageInfo.getStoreKey(), messageInfo.getSize(), messageInfo.isDeleted(),\n+        messageInfo.isTtlUpdated(), messageInfo.isUndeleted(), messageInfo.getExpirationTimeInMs(),\n+        messageInfo.getCrc(), messageInfo.getAccountId(), messageInfo.getContainerId(),\n+        messageInfo.getOperationTimeMs(), (short) 1);\n+    try {\n+      cloudBlobStore.delete(Collections.singletonList(deleteMessageInfo));\n+      fail(\"Delete should fail with ID_Deleted StoreException\");\n+    } catch (StoreException ex) {\n+      assertEquals(\"Unexpected error code\", ex.getErrorCode(), StoreErrorCodes.ID_Deleted);\n+    }\n+    storeInfo = cloudBlobStore.get(\n+        messageWriteSet.getMessageSetInfo().stream().map(MessageInfo::getStoreKey).collect(Collectors.toList()),\n+        EnumSet.allOf(StoreGetOptions.class));\n+    assertEquals(\"Unexpected live version\", 3, storeInfo.getMessageReadSetInfo().get(0).getLifeVersion());\n+    assertTrue(\"Unexpected delete status\", storeInfo.getMessageReadSetInfo().get(0).isDeleted());\n+\n+    // Restart cloud blob store to clear cache. Deleting again with smaller life version should fail silently without updating anything.\n+    cloudBlobStore.shutdown();\n+    cloudBlobStore.start();\n+    cloudBlobStore.delete(Collections.singletonList(deleteMessageInfo));\n+    storeInfo = cloudBlobStore.get(\n+        messageWriteSet.getMessageSetInfo().stream().map(MessageInfo::getStoreKey).collect(Collectors.toList()),\n+        EnumSet.allOf(StoreGetOptions.class));\n+    assertEquals(\"Unexpected live version\", 3, storeInfo.getMessageReadSetInfo().get(0).getLifeVersion());\n+    assertTrue(\"Unexpected delete status\", storeInfo.getMessageReadSetInfo().get(0).isDeleted());\n+  }\n+\n+  /** Test {@link CloudBlobStore#delete} method from frontend. */\n+  public void testDeleteFromFrontend() throws StoreException {\n+    // First upload a blob with a life version 2\n+    MockMessageWriteSet messageWriteSet = new MockMessageWriteSet();\n+    addBlobToMessageSet(messageWriteSet, Utils.Infinite_Time, accountId, containerId, partitionId,\n+        operationTime, (short) -1);\n+    cloudBlobStore.put(messageWriteSet);\n+\n+    // verify that the blob was uploaded with expected metadata.\n+    StoreInfo storeInfo = cloudBlobStore.get(\n+        messageWriteSet.getMessageSetInfo().stream().map(MessageInfo::getStoreKey).collect(Collectors.toList()),\n+        EnumSet.allOf(StoreGetOptions.class));\n+    assertEquals(\"Unexpected live version\", 0, storeInfo.getMessageReadSetInfo().get(0).getLifeVersion());\n+    assertEquals(\"Unexpected delete status\", messageWriteSet.getMessageSetInfo().get(0).isDeleted(),\n+        storeInfo.getMessageReadSetInfo().get(0).isDeleted());\n+\n+    // Deleting again should fail with ID_Deleted exception.\n+    MessageInfo messageInfo = messageWriteSet.getMessageSetInfo().get(0);\n+    MessageInfo deleteMessageInfo =\n+        new MessageInfo(messageInfo.getStoreKey(), messageInfo.getSize(), messageInfo.isDeleted(),\n+            messageInfo.isTtlUpdated(), messageInfo.isUndeleted(), messageInfo.getExpirationTimeInMs(),\n+            messageInfo.getCrc(), messageInfo.getAccountId(), messageInfo.getContainerId(),\n+            messageInfo.getOperationTimeMs(), (short) -1);\n+    try {\n+      cloudBlobStore.delete(Collections.singletonList(deleteMessageInfo));\n+    } catch (StoreException ex) {\n+      assertEquals(\"Unexpected error code\", ex.getErrorCode(), StoreErrorCodes.ID_Deleted);\n+    }\n+    storeInfo = cloudBlobStore.get(\n+        messageWriteSet.getMessageSetInfo().stream().map(MessageInfo::getStoreKey).collect(Collectors.toList()),\n+        EnumSet.allOf(StoreGetOptions.class));\n+    assertEquals(\"Unexpected live version\", 0, storeInfo.getMessageReadSetInfo().get(0).getLifeVersion());\n+    assertTrue(\"Unexpected delete status\", storeInfo.getMessageReadSetInfo().get(0).isDeleted());\n+\n+    // Restart cloud blob store to clear cache. Deleting again should still fail with ID_Deleted Store Exception.\n+    cloudBlobStore.shutdown();\n+    cloudBlobStore.start();\n+    deleteMessageInfo = new MessageInfo(messageInfo.getStoreKey(), messageInfo.getSize(), messageInfo.isDeleted(),\n+        messageInfo.isTtlUpdated(), messageInfo.isUndeleted(), messageInfo.getExpirationTimeInMs(),\n+        messageInfo.getCrc(), messageInfo.getAccountId(), messageInfo.getContainerId(),\n+        messageInfo.getOperationTimeMs(), (short) 3);\n+    try {\n+      cloudBlobStore.delete(Collections.singletonList(deleteMessageInfo));\n+    } catch (StoreException ex) {\n+      assertEquals(\"Unexpected error code\", ex.getErrorCode(), StoreErrorCodes.ID_Deleted);\n+    }\n+    storeInfo = cloudBlobStore.get(\n+        messageWriteSet.getMessageSetInfo().stream().map(MessageInfo::getStoreKey).collect(Collectors.toList()),\n+        EnumSet.allOf(StoreGetOptions.class));\n+    assertEquals(\"Unexpected live version\", 3, storeInfo.getMessageReadSetInfo().get(0).getLifeVersion());\n+    assertTrue(\"Unexpected delete status\", storeInfo.getMessageReadSetInfo().get(0).isDeleted());\n+  }\n+\n+  /** Test {@link CloudBlobStore#undelete} method. */\n+  @Test\n+  public void testUndelete() throws StoreException {\n+    MockMessageWriteSet messageWriteSet = new MockMessageWriteSet();\n+    addBlobToMessageSet(messageWriteSet, Utils.Infinite_Time, accountId, containerId, partitionId,\n+        operationTime, initLifeVersion(isVcr));\n+    cloudBlobStore.put(messageWriteSet);\n+\n+    // Attempt to undelete a blob that is not deleted. Should fail silently for vcr and throw exception for frontend.\n+    MessageInfo messageInfo = messageWriteSet.getMessageSetInfo().get(0);\n+    MessageInfo undeleteMessageInfo =\n+        new MessageInfo(messageInfo.getStoreKey(), messageInfo.getSize(), messageInfo.isDeleted(),\n+            messageInfo.isTtlUpdated(), messageInfo.isUndeleted(), messageInfo.getExpirationTimeInMs(),\n+            messageInfo.getCrc(), messageInfo.getAccountId(), messageInfo.getContainerId(),\n+            messageInfo.getOperationTimeMs(), initLifeVersion(isVcr));\n+    try {\n+      cloudBlobStore.undelete(undeleteMessageInfo);\n+      if (!isVcr) {\n+        fail(\"Undelete from frontend of a not deleted blob should throw exception.\");\n+      }\n+    } catch (StoreException ex) {\n+      assertEquals(\"Unexpected error message\", StoreErrorCodes.ID_Not_Deleted, ex.getErrorCode());\n+    }\n+\n+    // delete the blob.\n+    MessageInfo deleteMessageInfo =\n+        new MessageInfo(messageInfo.getStoreKey(), messageInfo.getSize(), messageInfo.isDeleted(),\n+            messageInfo.isTtlUpdated(), messageInfo.isUndeleted(), messageInfo.getExpirationTimeInMs(),\n+            messageInfo.getCrc(), messageInfo.getAccountId(), messageInfo.getContainerId(),\n+            messageInfo.getOperationTimeMs(), (short) (isVcr ? 1 : -1));\n+    cloudBlobStore.delete(Collections.singletonList(deleteMessageInfo));\n+\n+    // Attempt to undelete should pass\n+    short lifeVersion = cloudBlobStore.undelete(undeleteMessageInfo);\n+    assertEquals(\"Unexpected life version after undelete\", lifeVersion, 1);\n+  }\n+\n+  /** Test {@link CloudBlobStore#updateTtl} method. */\n+  @Test\n+  public void testUpdateTtl() throws StoreException {\n+    MockMessageWriteSet messageWriteSet = new MockMessageWriteSet();\n+    StoreConfig storeConfig = new StoreConfig(verifiableProperties);\n+    CloudConfig cloudConfig = new CloudConfig(verifiableProperties);\n+    long now = System.currentTimeMillis();\n+    long expirationTimeMs = now;\n+    if (isVcr) {\n+      // vcr doesn't upload a blob that is within CloudConfig#vcrMinTtlDays of expiry.\n+      expirationTimeMs += Math.max(TimeUnit.DAYS.toMillis(cloudConfig.vcrMinTtlDays),\n+          TimeUnit.SECONDS.toMillis(storeConfig.storeTtlUpdateBufferTimeSeconds));\n+    } else {\n+      expirationTimeMs += TimeUnit.SECONDS.toMillis(storeConfig.storeTtlUpdateBufferTimeSeconds);\n+    }\n+    expirationTimeMs += 100000;\n+    addBlobToMessageSet(messageWriteSet, expirationTimeMs, accountId, containerId, partitionId,\n+        operationTime, (short) -1);\n+    cloudBlobStore.put(messageWriteSet);\n+\n+    // verify that the blob was uploaded with expected metadata.\n+    StoreInfo storeInfo = cloudBlobStore.get(\n+        messageWriteSet.getMessageSetInfo().stream().map(MessageInfo::getStoreKey).collect(Collectors.toList()),\n+        EnumSet.allOf(StoreGetOptions.class));\n+    assertFalse(\"Unexpected ttl update status\", storeInfo.getMessageReadSetInfo().get(0).isTtlUpdated());\n+    assertEquals(\"Unexpected expiration time\", expirationTimeMs,\n+        storeInfo.getMessageReadSetInfo().get(0).getExpirationTimeInMs());\n+\n+    // Do a ttl update without setting ttl update flag.\n+    MessageInfo ttlUpdateMessageInfo =\n+        new MessageInfo(messageWriteSet.getMessageSetInfo().get(0).getStoreKey(), 100, false, true, -1, accountId,\n+            containerId, now);\n+    cloudBlobStore.updateTtl(Collections.singletonList(ttlUpdateMessageInfo));\n+    storeInfo = cloudBlobStore.get(\n+        messageWriteSet.getMessageSetInfo().stream().map(MessageInfo::getStoreKey).collect(Collectors.toList()),\n+        EnumSet.allOf(StoreGetOptions.class));\n+    assertTrue(\"Unexpected ttl update status\", storeInfo.getMessageReadSetInfo().get(0).isTtlUpdated());\n+    assertEquals(\"Unexpected expiration time\", -1, storeInfo.getMessageReadSetInfo().get(0).getExpirationTimeInMs());\n+\n+    // Do a ttl update on a updated blob. It should fail silently.\n+    ttlUpdateMessageInfo =\n+        new MessageInfo(messageWriteSet.getMessageSetInfo().get(0).getStoreKey(), 100, false, true, -1, accountId,\n+            containerId, now);\n+    cloudBlobStore.updateTtl(Collections.singletonList(ttlUpdateMessageInfo));\n+    storeInfo = cloudBlobStore.get(\n+        messageWriteSet.getMessageSetInfo().stream().map(MessageInfo::getStoreKey).collect(Collectors.toList()),\n+        EnumSet.allOf(StoreGetOptions.class));\n+    assertTrue(\"Unexpected ttl update status\", storeInfo.getMessageReadSetInfo().get(0).isTtlUpdated());\n+    assertEquals(\"Unexpected expiration time\", -1, storeInfo.getMessageReadSetInfo().get(0).getExpirationTimeInMs());\n+\n+    // Clear cache by restarting blob store. Do a ttl update on a updated blob. It should fail silently.\n+    cloudBlobStore.shutdown();\n+    cloudBlobStore.start();\n+    ttlUpdateMessageInfo =\n+        new MessageInfo(messageWriteSet.getMessageSetInfo().get(0).getStoreKey(), 100, false, true, -1, accountId,\n+            containerId, now);\n+    cloudBlobStore.updateTtl(Collections.singletonList(ttlUpdateMessageInfo));\n+    storeInfo = cloudBlobStore.get(\n+        messageWriteSet.getMessageSetInfo().stream().map(MessageInfo::getStoreKey).collect(Collectors.toList()),\n+        EnumSet.allOf(StoreGetOptions.class));\n+    assertTrue(\"Unexpected ttl update status\", storeInfo.getMessageReadSetInfo().get(0).isTtlUpdated());\n+    assertEquals(\"Unexpected expiration time\", -1, storeInfo.getMessageReadSetInfo().get(0).getExpirationTimeInMs());\n+\n+    // Delete the blob.\n+    cloudBlobStore.delete(Collections.singletonList(ttlUpdateMessageInfo));\n+\n+    // ttlupdate of a deleted blob should throw ID_Delete Store Exception for frontend and fail silently for vcr.\n+    try {\n+      cloudBlobStore.updateTtl(Collections.singletonList(ttlUpdateMessageInfo));\n+      if (!isVcr) {\n+        fail(\"Update ttl of a deleted blob should fail for frontend.\");\n+      }\n+    } catch (StoreException ex) {\n+      assertEquals(\"Unexcpected error code\", ex.getErrorCode(), StoreErrorCodes.ID_Deleted);\n+    }\n+\n+    // Clear cache by restarting blob store. ttlupdate of a deleted blob should throw ID_Delete Store Exception.\n+    cloudBlobStore.shutdown();\n+    cloudBlobStore.start();\n+    try {\n+      cloudBlobStore.updateTtl(Collections.singletonList(ttlUpdateMessageInfo));\n+      if (!isVcr) {\n+        fail(\"Update ttl of a deleted blob should fail.\");\n+      }\n+    } catch (StoreException ex) {\n+      assertEquals(\"Unexpected error code\", ex.getErrorCode(), StoreErrorCodes.ID_Deleted);\n+    }\n+  }\n+\n+  /**\n+   * Cleanup the test partition by deleting all the blobs of the test partition.\n+   */\n+  private void cleanup() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "43ddd899be3828bc01b2c6e5635e5991f51951bb"}, "originalPosition": 489}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1NDk4MDM1", "url": "https://github.com/linkedin/ambry/pull/1517#pullrequestreview-425498035", "createdAt": "2020-06-05T17:41:40Z", "commit": {"oid": "43ddd899be3828bc01b2c6e5635e5991f51951bb"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNzo0MTo0MVrOGf3gpQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNzo0MTo0MVrOGf3gpQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA2ODUxNw==", "bodyText": "Shouldn't these methods be removed here?", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r436068517", "createdAt": "2020-06-05T17:41:41Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/test/java/com/github/ambry/cloud/CloudBlobStoreTest.java", "diffHunk": "@@ -873,11 +940,11 @@ public void testPutWithTtl() throws Exception {\n    * @return the generated {@link BlobId}.\n    */\n   private BlobId addBlobToSet(MockMessageWriteSet messageWriteSet, long size, long expiresAtMs, short accountId,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "43ddd899be3828bc01b2c6e5635e5991f51951bb"}, "originalPosition": 254}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "15aa9f9ded08330f2656f6ff39067ae8f28598cc", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/15aa9f9ded08330f2656f6ff39067ae8f28598cc", "committedDate": "2020-06-05T21:36:33Z", "message": "Address Rob's review comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1NjY0NTgz", "url": "https://github.com/linkedin/ambry/pull/1517#pullrequestreview-425664583", "createdAt": "2020-06-05T22:34:28Z", "commit": {"oid": "15aa9f9ded08330f2656f6ff39067ae8f28598cc"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9cd0c8edcd75ac3b00bebd886b5000a562e3eb61", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/9cd0c8edcd75ac3b00bebd886b5000a562e3eb61", "committedDate": "2020-06-05T23:04:20Z", "message": "Fix cloudblob store test"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1483, "cost": 1, "resetAt": "2021-11-01T16:19:10Z"}}}