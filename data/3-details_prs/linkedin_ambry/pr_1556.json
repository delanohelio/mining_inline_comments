{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDMxMzgyNzY5", "number": 1556, "title": "Parallelize cloud compaction", "bodyText": "", "createdAt": "2020-06-08T20:35:45Z", "url": "https://github.com/linkedin/ambry/pull/1556", "merged": true, "mergeCommit": {"oid": "88924e6712007833caec8b03d73e26696265a59e"}, "closed": true, "closedAt": "2020-06-10T23:55:27Z", "author": {"login": "ankagrawal"}, "timelineItems": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcpapmkgFqTQyNjcyNDUyMw==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcqCop3gFqTQyODUwNDM4Mg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI2NzI0NTIz", "url": "https://github.com/linkedin/ambry/pull/1556#pullrequestreview-426724523", "createdAt": "2020-06-09T01:17:12Z", "commit": {"oid": "0320d1b6d51326803c2c81dc582f84d19b25c691"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQwMToxNzoxMlrOGg1gXQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQwMToxODoxOVrOGg1hgQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA4NDI1Mw==", "bodyText": "Is the idea to wait until all the threads are done before assigning any new work?  That won't be optimal since a long running partition can keep the other threads idle for a while.", "url": "https://github.com/linkedin/ambry/pull/1556#discussion_r437084253", "createdAt": "2020-06-09T01:17:12Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudStorageCompactor.java", "diffHunk": "@@ -103,47 +106,80 @@ public int compactPartitions() {\n       logger.info(\"Skipping compaction as no partitions are assigned.\");\n       return 0;\n     }\n+    List<PartitionId> partitionSnapshot = new ArrayList<>(partitions);\n+    long compactionStartTime = System.currentTimeMillis();\n+    long timeToQuit = System.currentTimeMillis() + compactionTimeLimitMs;\n+    int compactionInProgress = 0;\n+    doneLatch.set(new CountDownLatch(1));\n+    int totalBlobsPurged = 0;\n+    int compactedPartitionCount = 0;\n+    try {\n+      while (true) {\n+        while (compactionInProgress < numThreads) {\n+          if (partitionSnapshot.isEmpty()) {\n+            break;\n+          }\n+          PartitionId partitionId = partitionSnapshot.remove(0);\n+          executorCompletionService.submit(() -> compactPartition(partitionId));\n+          compactionInProgress++;\n+        }\n+        totalBlobsPurged += executorCompletionService.take().get();\n+        compactionInProgress--;\n+        compactedPartitionCount++;\n+        if (System.currentTimeMillis() >= timeToQuit) {\n+          logger.info(\"Compaction terminated due to time limit exceeded.\");\n+          break;\n+        }\n+        if (isShuttingDown()) {\n+          logger.info(\"Compaction terminated due to shut down.\");\n+          break;\n+        }\n+        if (partitionSnapshot.isEmpty()) {\n+          break;\n+        }\n+      }\n+      while (compactionInProgress > 0) {\n+        totalBlobsPurged += executorCompletionService.take().get();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0320d1b6d51326803c2c81dc582f84d19b25c691"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA4NDU0NQ==", "bodyText": "This could be: while (!partitionSnapshot.isEmpty())", "url": "https://github.com/linkedin/ambry/pull/1556#discussion_r437084545", "createdAt": "2020-06-09T01:18:19Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudStorageCompactor.java", "diffHunk": "@@ -103,47 +106,80 @@ public int compactPartitions() {\n       logger.info(\"Skipping compaction as no partitions are assigned.\");\n       return 0;\n     }\n+    List<PartitionId> partitionSnapshot = new ArrayList<>(partitions);\n+    long compactionStartTime = System.currentTimeMillis();\n+    long timeToQuit = System.currentTimeMillis() + compactionTimeLimitMs;\n+    int compactionInProgress = 0;\n+    doneLatch.set(new CountDownLatch(1));\n+    int totalBlobsPurged = 0;\n+    int compactedPartitionCount = 0;\n+    try {\n+      while (true) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0320d1b6d51326803c2c81dc582f84d19b25c691"}, "originalPosition": 57}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI3NDQ4ODI3", "url": "https://github.com/linkedin/ambry/pull/1556#pullrequestreview-427448827", "createdAt": "2020-06-09T18:52:05Z", "commit": {"oid": "a3178926f4ba04ef42c320ddc7fadf05d9961c8e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQxODo1MjowNVrOGhX3lA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQxODo1MjowNVrOGhX3lA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY0NzI1Mg==", "bodyText": "Typo: reassigned", "url": "https://github.com/linkedin/ambry/pull/1556#discussion_r437647252", "createdAt": "2020-06-09T18:52:05Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudStorageCompactor.java", "diffHunk": "@@ -103,47 +106,77 @@ public int compactPartitions() {\n       logger.info(\"Skipping compaction as no partitions are assigned.\");\n       return 0;\n     }\n+    List<PartitionId> partitionSnapshot = new ArrayList<>(partitions);\n+    long compactionStartTime = System.currentTimeMillis();\n+    long timeToQuit = System.currentTimeMillis() + compactionTimeLimitMs;\n+    int compactionInProgress = 0;\n+    doneLatch.set(new CountDownLatch(1));\n+    int totalBlobsPurged = 0;\n+    int compactedPartitionCount = 0;\n+    try {\n+      while (!partitionSnapshot.isEmpty()) {\n+        while (compactionInProgress < numThreads) {\n+          if (partitionSnapshot.isEmpty()) {\n+            break;\n+          }\n+          PartitionId partitionId = partitionSnapshot.remove(0);\n+          executorCompletionService.submit(() -> compactPartition(partitionId));\n+          compactionInProgress++;\n+        }\n+        totalBlobsPurged += executorCompletionService.take().get();\n+        compactionInProgress--;\n+        compactedPartitionCount++;\n+        if (System.currentTimeMillis() >= timeToQuit) {\n+          logger.info(\"Compaction terminated due to time limit exceeded.\");\n+          break;\n+        }\n+        if (isShuttingDown()) {\n+          logger.info(\"Compaction terminated due to shut down.\");\n+          break;\n+        }\n+      }\n+      while (compactionInProgress > 0) {\n+        totalBlobsPurged += executorCompletionService.take().get();\n+        compactionInProgress--;\n+        compactedPartitionCount++;\n+      }\n+      doneLatch.get().countDown();\n+    } catch (Throwable th) {\n+      logger.error(\"Hit exception running compaction task\", th);\n+    } finally {\n+      long compactionTime = (System.currentTimeMillis() - compactionStartTime) / 1000;\n+      logger.info(\"Purged {} blobs in {} partitions taking {} seconds\", totalBlobsPurged, compactedPartitionCount,\n+          compactionTime);\n+    }\n+    return totalBlobsPurged;\n+  }\n+\n+  /**\n+   * Purge the inactive blobs in the specified partitions.\n+   * @param partition the {@link PartitionId} to compact.\n+   * @return the total number of blobs purged in the partition.\n+   */\n+  private int compactPartition(PartitionId partition) {\n     if (isShuttingDown()) {\n       logger.info(\"Skipping compaction due to shut down.\");\n       return 0;\n     }\n \n-    // TODO: adjust count when compaction uses multiple threads\n-    doneLatch.set(new CountDownLatch(1));\n-\n-    Set<PartitionId> partitionsSnapshot = new HashSet<>(partitions);\n-    logger.info(\"Beginning dead blob compaction for {} partitions\", partitions.size());\n-    long now = System.currentTimeMillis();\n-    long compactionStartTime = now;\n-    long timeToQuit = now + compactionTimeLimitMs;\n-    int totalBlobsPurged = 0;\n-    for (PartitionId partitionId : partitionsSnapshot) {\n-      String partitionPath = partitionId.toPathString();\n-      if (!partitions.contains(partitionId)) {\n-        // Looks like partition was reassigned since the loop started, so skip it\n-        continue;\n-      }\n+    logger.info(\"Beginning dead blob compaction for partition {}\", partition);\n \n-      try {\n-        totalBlobsPurged += cloudDestination.compactPartition(partitionPath);\n-      } catch (CloudStorageException ex) {\n-        logger.error(\"Compaction failed for partition {}\", partitionPath, ex);\n-        vcrMetrics.compactionFailureCount.inc();\n-      }\n+    String partitionPath = partition.toPathString();\n+    if (!partitions.contains(partition)) {\n+      // Looks like partition was reassigned since the loop started, so skip it\n+      logger.warn(\"Skipping compaction of Partition {} as the partition was reassgined\", partition);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3178926f4ba04ef42c320ddc7fadf05d9961c8e"}, "originalPosition": 131}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI3NDUyNjU2", "url": "https://github.com/linkedin/ambry/pull/1556#pullrequestreview-427452656", "createdAt": "2020-06-09T18:57:05Z", "commit": {"oid": "a3178926f4ba04ef42c320ddc7fadf05d9961c8e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQxODo1NzowNVrOGhYDFQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQxODo1NzowNVrOGhYDFQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY1MDE5Nw==", "bodyText": "Could we let compactPartition throw exception on error, and catch it here in the get() call?  Then we can increment compactedPartitionCount only in success case.", "url": "https://github.com/linkedin/ambry/pull/1556#discussion_r437650197", "createdAt": "2020-06-09T18:57:05Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudStorageCompactor.java", "diffHunk": "@@ -103,47 +106,77 @@ public int compactPartitions() {\n       logger.info(\"Skipping compaction as no partitions are assigned.\");\n       return 0;\n     }\n+    List<PartitionId> partitionSnapshot = new ArrayList<>(partitions);\n+    long compactionStartTime = System.currentTimeMillis();\n+    long timeToQuit = System.currentTimeMillis() + compactionTimeLimitMs;\n+    int compactionInProgress = 0;\n+    doneLatch.set(new CountDownLatch(1));\n+    int totalBlobsPurged = 0;\n+    int compactedPartitionCount = 0;\n+    try {\n+      while (!partitionSnapshot.isEmpty()) {\n+        while (compactionInProgress < numThreads) {\n+          if (partitionSnapshot.isEmpty()) {\n+            break;\n+          }\n+          PartitionId partitionId = partitionSnapshot.remove(0);\n+          executorCompletionService.submit(() -> compactPartition(partitionId));\n+          compactionInProgress++;\n+        }\n+        totalBlobsPurged += executorCompletionService.take().get();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3178926f4ba04ef42c320ddc7fadf05d9961c8e"}, "originalPosition": 66}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI3NDYyNDcw", "url": "https://github.com/linkedin/ambry/pull/1556#pullrequestreview-427462470", "createdAt": "2020-06-09T19:10:40Z", "commit": {"oid": "a3178926f4ba04ef42c320ddc7fadf05d9961c8e"}, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8f25b253c7bd0f1d170c33f2302878b7cfc385dd", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/8f25b253c7bd0f1d170c33f2302878b7cfc385dd", "committedDate": "2020-06-09T20:09:01Z", "message": "Parallelize cloud compaction"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "472691225e9ebd3124e50feb8eeacf7734ff447c", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/472691225e9ebd3124e50feb8eeacf7734ff447c", "committedDate": "2020-06-09T20:09:01Z", "message": "Address review comment."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "857a86ce481288aa3c612c81bc18362eab861876", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/857a86ce481288aa3c612c81bc18362eab861876", "committedDate": "2020-06-09T20:09:01Z", "message": "Address review comments."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fbd1e9f1619f2a2c33380e1a761239d764fe8b5c", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/fbd1e9f1619f2a2c33380e1a761239d764fe8b5c", "committedDate": "2020-06-09T20:09:01Z", "message": "Add test."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c9a01c062958df8c4731a093932aea4d9f81b726", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/c9a01c062958df8c4731a093932aea4d9f81b726", "committedDate": "2020-06-09T19:46:01Z", "message": "Address review comments."}, "afterCommit": {"oid": "fbd1e9f1619f2a2c33380e1a761239d764fe8b5c", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/fbd1e9f1619f2a2c33380e1a761239d764fe8b5c", "committedDate": "2020-06-09T20:09:01Z", "message": "Add test."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI3NTQxMDE3", "url": "https://github.com/linkedin/ambry/pull/1556#pullrequestreview-427541017", "createdAt": "2020-06-09T20:59:31Z", "commit": {"oid": "fbd1e9f1619f2a2c33380e1a761239d764fe8b5c"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDo1OTozMVrOGhcQcA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMToxNToyMFrOGhcu9A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzcxOTE1Mg==", "bodyText": "nit: remove a partition from map", "url": "https://github.com/linkedin/ambry/pull/1556#discussion_r437719152", "createdAt": "2020-06-09T20:59:31Z", "author": {"login": "jsjtzyy"}, "path": "ambry-cloud/src/test/java/com/github/ambry/cloud/CloudStorageCompactorTest.java", "diffHunk": "@@ -65,27 +64,23 @@ public void testCompactPartitions() throws Exception {\n     verify(mockDest, times(0)).purgeBlobs(any());\n     */\n \n-    // add 2 partitions to map\n-    int partition1 = 101, partition2 = 102;\n-    long compactionEndTime = System.currentTimeMillis() - TimeUnit.DAYS.toMillis(CloudConfig.DEFAULT_RETENTION_DAYS);\n-    String partitionPath1 = String.valueOf(partition1), partitionPath2 = String.valueOf(partition2);\n+    // add 100 partitions to map\n     String defaultClass = MockClusterMap.DEFAULT_PARTITION_CLASS;\n-    partitionMap.put(new MockPartitionId(partition1, defaultClass), null);\n-    partitionMap.put(new MockPartitionId(partition2, defaultClass), null);\n-\n-    when(mockDest.compactPartition(eq(partitionPath1))).thenReturn(pageSize);\n-    when(mockDest.compactPartition(eq(partitionPath2))).thenReturn(pageSize * 2);\n-    assertEquals(pageSize * 3, compactor.compactPartitions());\n+    for (int i = 0; i < 100; i++) {\n+      partitionMap.put(new MockPartitionId(i, defaultClass), null);\n+      when(mockDest.compactPartition(eq(Integer.toString(i)))).thenReturn(pageSize);\n+    }\n \n+    assertEquals(pageSize * 100, compactor.compactPartitions());\n \n-    // remove partition2 from map\n-    partitionMap.remove(new MockPartitionId(partition2, defaultClass));\n-    assertEquals(pageSize, compactor.compactPartitions());\n+    // remove a from map", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fbd1e9f1619f2a2c33380e1a761239d764fe8b5c"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzcyNjk2NA==", "bodyText": "I wonder if exception occurs in this method before we call executorCompletionService.take().get(), what will happen? Looks like it may not be captured at line 130, line 147. If it is captured by line 153 catch (Throwable th), will the whole batch compaction be terminated? What about some outstanding threads that are already assigned compaction task?", "url": "https://github.com/linkedin/ambry/pull/1556#discussion_r437726964", "createdAt": "2020-06-09T21:15:20Z", "author": {"login": "jsjtzyy"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudStorageCompactor.java", "diffHunk": "@@ -103,47 +107,84 @@ public int compactPartitions() {\n       logger.info(\"Skipping compaction as no partitions are assigned.\");\n       return 0;\n     }\n-    if (isShuttingDown()) {\n+    List<PartitionId> partitionSnapshot = new ArrayList<>(partitions);\n+    long compactionStartTime = System.currentTimeMillis();\n+    long timeToQuit = System.currentTimeMillis() + compactionTimeLimitMs;\n+    int compactionInProgress = 0;\n+    doneLatch.set(new CountDownLatch(1));\n+    int totalBlobsPurged = 0;\n+    int compactedPartitionCount = 0;\n+    try {\n+      while (!partitionSnapshot.isEmpty()) {\n+        while (compactionInProgress < numThreads) {\n+          if (partitionSnapshot.isEmpty()) {\n+            break;\n+          }\n+          PartitionId partitionId = partitionSnapshot.remove(0);\n+          executorCompletionService.submit(() -> compactPartition(partitionId));\n+          compactionInProgress++;\n+        }\n+        try {\n+          totalBlobsPurged += executorCompletionService.take().get();\n+          compactedPartitionCount++;\n+        } catch (ExecutionException ex) {\n+          vcrMetrics.compactionFailureCount.inc();\n+        }\n+        compactionInProgress--;\n+        if (System.currentTimeMillis() >= timeToQuit) {\n+          logger.info(\"Compaction terminated due to time limit exceeded.\");\n+          break;\n+        }\n+        if (isShutDown()) {\n+          logger.info(\"Compaction terminated due to shut down.\");\n+          break;\n+        }\n+      }\n+      while (compactionInProgress > 0) {\n+        try {\n+          totalBlobsPurged += executorCompletionService.take().get();\n+          compactedPartitionCount++;\n+        } catch (ExecutionException ex) {\n+          vcrMetrics.compactionFailureCount.inc();\n+        }\n+        compactionInProgress--;\n+      }\n+      doneLatch.get().countDown();\n+    } catch (Throwable th) {\n+      logger.error(\"Hit exception running compaction task\", th);\n+    } finally {\n+      long compactionTime = (System.currentTimeMillis() - compactionStartTime) / 1000;\n+      logger.info(\"Purged {} blobs in {} partitions taking {} seconds\", totalBlobsPurged, compactedPartitionCount,\n+          compactionTime);\n+    }\n+    return totalBlobsPurged;\n+  }\n+\n+  /**\n+   * Purge the inactive blobs in the specified partitions.\n+   * @param partition the {@link PartitionId} to compact.\n+   * @return the total number of blobs purged in the partition.\n+   */\n+  private int compactPartition(PartitionId partition) throws CloudStorageException {\n+    if (isShutDown()) {\n       logger.info(\"Skipping compaction due to shut down.\");\n       return 0;\n     }\n \n-    // TODO: adjust count when compaction uses multiple threads\n-    doneLatch.set(new CountDownLatch(1));\n-\n-    Set<PartitionId> partitionsSnapshot = new HashSet<>(partitions);\n-    logger.info(\"Beginning dead blob compaction for {} partitions\", partitions.size());\n-    long now = System.currentTimeMillis();\n-    long compactionStartTime = now;\n-    long timeToQuit = now + compactionTimeLimitMs;\n-    int totalBlobsPurged = 0;\n-    for (PartitionId partitionId : partitionsSnapshot) {\n-      String partitionPath = partitionId.toPathString();\n-      if (!partitions.contains(partitionId)) {\n-        // Looks like partition was reassigned since the loop started, so skip it\n-        continue;\n-      }\n+    logger.info(\"Beginning dead blob compaction for partition {}\", partition);\n \n-      try {\n-        totalBlobsPurged += cloudDestination.compactPartition(partitionPath);\n-      } catch (CloudStorageException ex) {\n-        logger.error(\"Compaction failed for partition {}\", partitionPath, ex);\n-        vcrMetrics.compactionFailureCount.inc();\n-      }\n+    String partitionPath = partition.toPathString();\n+    if (!partitions.contains(partition)) {\n+      // Looks like partition was reassigned since the loop started, so skip it\n+      logger.warn(\"Skipping compaction of Partition {} as the partition was reassigned\", partition);\n+      return 0;\n+    }\n \n-      if (System.currentTimeMillis() >= timeToQuit) {\n-        logger.info(\"Compaction terminated due to time limit exceeded.\");\n-        break;\n-      }\n-      if (isShuttingDown()) {\n-        logger.info(\"Compaction terminated due to shut down.\");\n-        break;\n-      }\n+    try {\n+      return cloudDestination.compactPartition(partitionPath);\n+    } catch (CloudStorageException ex) {\n+      logger.error(\"Compaction failed for partition {}\", partitionPath, ex);\n+      throw ex;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fbd1e9f1619f2a2c33380e1a761239d764fe8b5c"}, "originalPosition": 185}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "962bdd16ee38316558b27cba5f469d9ffcb71f10", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/962bdd16ee38316558b27cba5f469d9ffcb71f10", "committedDate": "2020-06-09T21:50:45Z", "message": "Fix a comment."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "488c2a42a7f620f4b71cde3812c25df241784d45", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/488c2a42a7f620f4b71cde3812c25df241784d45", "committedDate": "2020-06-09T21:54:47Z", "message": "Make sure to shutdown the executor service."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI3NjI0MjQ4", "url": "https://github.com/linkedin/ambry/pull/1556#pullrequestreview-427624248", "createdAt": "2020-06-10T00:00:27Z", "commit": {"oid": "488c2a42a7f620f4b71cde3812c25df241784d45"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI4NTA0Mzgy", "url": "https://github.com/linkedin/ambry/pull/1556#pullrequestreview-428504382", "createdAt": "2020-06-10T23:55:08Z", "commit": {"oid": "488c2a42a7f620f4b71cde3812c25df241784d45"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1117, "cost": 1, "resetAt": "2021-11-01T16:19:10Z"}}}