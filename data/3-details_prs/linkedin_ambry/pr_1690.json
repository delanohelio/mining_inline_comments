{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTE4NjQ3MTE0", "number": 1690, "title": "[named_blobs]Support uploading the named blobs with putBlobHandler", "bodyText": "Support the flow to upload named blob with putBlobHandler.\nChunk upload and stitch blob is under development.\nWill add more test cases.", "createdAt": "2020-11-10T17:25:28Z", "url": "https://github.com/linkedin/ambry/pull/1690", "merged": true, "mergeCommit": {"oid": "061e3fdc064d40208a523543f0fd08ca08b0a1cc"}, "closed": true, "closedAt": "2020-11-21T00:07:35Z", "author": {"login": "SophieGuo410"}, "timelineItems": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdbVeK2gBqjM5ODE5MjU3NTc=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdegeZyAFqTUzNTg1MTUwOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "46b79ff017bcaa19aeae785e2bfbc5b627d75c58", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/46b79ff017bcaa19aeae785e2bfbc5b627d75c58", "committedDate": "2020-11-10T17:22:23Z", "message": "[named_blobs]Support uploading the named blobs with putBlobHandler"}, "afterCommit": {"oid": "5c41a4d495b6856b89ade247749edf3f292904db", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/5c41a4d495b6856b89ade247749edf3f292904db", "committedDate": "2020-11-11T02:02:41Z", "message": "[named_blobs]Support uploading the named blobs with putBlobHandler"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "5c41a4d495b6856b89ade247749edf3f292904db", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/5c41a4d495b6856b89ade247749edf3f292904db", "committedDate": "2020-11-11T02:02:41Z", "message": "[named_blobs]Support uploading the named blobs with putBlobHandler"}, "afterCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5", "committedDate": "2020-11-11T07:10:02Z", "message": "[named_blobs]Support uploading the named blobs with putBlobHandler"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMxNTk3Mzc1", "url": "https://github.com/linkedin/ambry/pull/1690#pullrequestreview-531597375", "createdAt": "2020-11-16T18:33:58Z", "commit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNlQxODozMzo1OVrOH0MIlA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNlQxOTozNjowNlrOH0OXCg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQ4NjgwNA==", "bodyText": "post to put in the string above. I recommend making a constant for this (see URL_SIGNER_ENDPOINTS).", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r524486804", "createdAt": "2020-11-16T18:33:59Z", "author": {"login": "cgtz"}, "path": "ambry-api/src/main/java/com/github/ambry/config/FrontendConfig.java", "diffHunk": "@@ -133,6 +133,14 @@\n   @Default(\"true\")\n   public final boolean allowServiceIdBasedPostRequest;\n \n+  /**\n+   * Boolean indicator to specify if frontend should allow the post requests that carry serviceId used as target\n+   * account name.\n+   */\n+  @Config(\"frontend.allow.service.id.based.post.request\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQ4ODAxMw==", "bodyText": "I'm thinking that this config and code block isn't really needed. For named blobs, a PUT request without the account and container in the path will always be invalid anyways (i.e. it will fail somewhere else in the code).", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r524488013", "createdAt": "2020-11-16T18:36:07Z", "author": {"login": "cgtz"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AccountAndContainerInjector.java", "diffHunk": "@@ -84,6 +85,48 @@ public void injectAccountAndContainerForPostRequest(RestRequest restRequest, Res\n     }\n   }\n \n+  /**\n+   * Injects target {@link Account} and {@link Container} for PUT requests. This method also ensures required uri\n+   * is present for the PUT requests that can account name/container name can parse from.\n+   * @param restRequest The Put {@link RestRequest}.\n+   * @param metricsGroup The {@link RestRequestMetricsGroup} to use to set up {@link ContainerMetrics}, or {@code null}\n+   *                     if {@link ContainerMetrics} instantiation is not needed.\n+   * @throws RestServiceException\n+   */\n+  public void injectAccountAndContainerForPutRequest(RestRequest restRequest, RestRequestMetricsGroup metricsGroup)\n+      throws RestServiceException {\n+    accountAndContainerSanityCheckForNamedBlob(restRequest);\n+    if (restRequest.getUri() != null) {\n+      frontendMetrics.putWithAccountAndContainerHeaderRate.mark();\n+      injectAccountAndContainerUsingAccountAndContainerUri(restRequest, metricsGroup);\n+    } else if (frontendConfig.allowServiceIdBasedPutRequest) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQ4OTI3NQ==", "bodyText": "It seems like we will have to do this in a few places throughout open source and LI code. Can we make this into a public method in RestUtils? This can return a small class like and handle URL decoding in one place:\nclass NamedBlobPath {\n  String getAccountName();\n  String getContainerName();\n  String getBlobName();\n}", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r524489275", "createdAt": "2020-11-16T18:38:12Z", "author": {"login": "cgtz"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AccountAndContainerInjector.java", "diffHunk": "@@ -84,6 +85,48 @@ public void injectAccountAndContainerForPostRequest(RestRequest restRequest, Res\n     }\n   }\n \n+  /**\n+   * Injects target {@link Account} and {@link Container} for PUT requests. This method also ensures required uri\n+   * is present for the PUT requests that can account name/container name can parse from.\n+   * @param restRequest The Put {@link RestRequest}.\n+   * @param metricsGroup The {@link RestRequestMetricsGroup} to use to set up {@link ContainerMetrics}, or {@code null}\n+   *                     if {@link ContainerMetrics} instantiation is not needed.\n+   * @throws RestServiceException\n+   */\n+  public void injectAccountAndContainerForPutRequest(RestRequest restRequest, RestRequestMetricsGroup metricsGroup)\n+      throws RestServiceException {\n+    accountAndContainerSanityCheckForNamedBlob(restRequest);\n+    if (restRequest.getUri() != null) {\n+      frontendMetrics.putWithAccountAndContainerHeaderRate.mark();\n+      injectAccountAndContainerUsingAccountAndContainerUri(restRequest, metricsGroup);\n+    } else if (frontendConfig.allowServiceIdBasedPutRequest) {\n+      ensureRequiredHeadersOrThrow(restRequest, requiredAmbryHeadersForPutWithServiceId);\n+      frontendMetrics.putWithServiceIdForAccountNameRate.mark();\n+      String serviceId = getHeader(restRequest.getArgs(), Headers.SERVICE_ID, true);\n+      boolean isPrivate = isPrivate(restRequest.getArgs());\n+      injectAccountAndContainerUsingServiceId(restRequest, serviceId, isPrivate, metricsGroup);\n+    } else {\n+      throw new RestServiceException(\n+          \"Missing either \" + Headers.TARGET_ACCOUNT_NAME + \" or \" + Headers.TARGET_CONTAINER_NAME + \" header\",\n+          RestServiceErrorCode.BadRequest);\n+    }\n+  }\n+\n+  /**\n+   * Parse the input if it's the named blob request.\n+   * @param input the url that needs to be parsed.\n+   * @return the String array contains the\n+   */\n+  private String[] parseInput(String input) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQ5NDc0Mg==", "bodyText": "It is better to use RestUtils.getRequestPath(restRequest).getOperationOrBlobId in situations like this to ensure that any cluster name url prefixes are removed.", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r524494742", "createdAt": "2020-11-16T18:47:00Z", "author": {"login": "cgtz"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AccountAndContainerInjector.java", "diffHunk": "@@ -209,6 +252,35 @@ private void injectAccountAndContainerUsingAccountAndContainerHeaders(RestReques\n     setTargetAccountAndContainerInRestRequest(restRequest, targetAccount, targetContainer, metricsGroup);\n   }\n \n+  /**\n+   * Injects {@link Account} and {@link Container} for the PUT requests that carry the target account and container headers.\n+   * @param restRequest The {@link RestRequest} to inject {@link Account} and {@link Container} object.\n+   * @param metricsGroup The {@link RestRequestMetricsGroup} to use to set up {@link ContainerMetrics}, or {@code null}\n+   *                     if {@link ContainerMetrics} instantiation is not needed.\n+   * @throws RestServiceException if either of {@link Account} or {@link Container} object could not be found.\n+   */\n+  private void injectAccountAndContainerUsingAccountAndContainerUri(RestRequest restRequest,\n+      RestRequestMetricsGroup metricsGroup) throws RestServiceException {\n+    String[] slashFields = parseInput(restRequest.getPath());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQ5NTI2Mg==", "bodyText": "Is line 266-281 common logic that can be shared with the post request code?", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r524495262", "createdAt": "2020-11-16T18:47:51Z", "author": {"login": "cgtz"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AccountAndContainerInjector.java", "diffHunk": "@@ -209,6 +252,35 @@ private void injectAccountAndContainerUsingAccountAndContainerHeaders(RestReques\n     setTargetAccountAndContainerInRestRequest(restRequest, targetAccount, targetContainer, metricsGroup);\n   }\n \n+  /**\n+   * Injects {@link Account} and {@link Container} for the PUT requests that carry the target account and container headers.\n+   * @param restRequest The {@link RestRequest} to inject {@link Account} and {@link Container} object.\n+   * @param metricsGroup The {@link RestRequestMetricsGroup} to use to set up {@link ContainerMetrics}, or {@code null}\n+   *                     if {@link ContainerMetrics} instantiation is not needed.\n+   * @throws RestServiceException if either of {@link Account} or {@link Container} object could not be found.\n+   */\n+  private void injectAccountAndContainerUsingAccountAndContainerUri(RestRequest restRequest,\n+      RestRequestMetricsGroup metricsGroup) throws RestServiceException {\n+    String[] slashFields = parseInput(restRequest.getPath());\n+    String accountName = slashFields[2];\n+    Account targetAccount = accountService.getAccountByName(accountName);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQ5Njk0NQ==", "bodyText": "I'm a bit confused about what this line is doing. Shouldn't the comparison be directly between UNKNOWN_ACCOUNT_NAME and slashFields[2] instead of looking for a header with that account name?", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r524496945", "createdAt": "2020-11-16T18:50:34Z", "author": {"login": "cgtz"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AccountAndContainerInjector.java", "diffHunk": "@@ -233,6 +305,35 @@ private void accountAndContainerSanityCheck(RestRequest restRequest) throws Rest\n     }\n   }\n \n+  /**\n+   * Sanity check for {@link RestRequest}. This check ensures that the specified service id, account and container name,\n+   * if they exist, should not be the same as the not-allowed values. It also makes sure certain headers must not be present.\n+   * @param restRequest The {@link RestRequest} to check.\n+   * @throws RestServiceException if the specified service id, account or container name is set as system reserved value.\n+   */\n+  private void accountAndContainerSanityCheckForNamedBlob(RestRequest restRequest) throws RestServiceException {\n+    String[] slashFields = parseInput(restRequest.getPath());\n+    if (Account.UNKNOWN_ACCOUNT_NAME.equals(getHeader(restRequest.getArgs(), slashFields[2], false))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQ5ODExNQ==", "bodyText": "Apologies for not communicating this, but I changed the interface for NamedBlobDb to not require a BlobId object. (it can just take in the base64 string). This means that you don't have to pass in the clustermap to IdConverter", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r524498115", "createdAt": "2020-11-16T18:52:44Z", "author": {"login": "cgtz"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AmbryIdConverterFactory.java", "diffHunk": "@@ -73,30 +85,126 @@ public void close() {\n      */\n     @Override\n     public Future<String> convert(RestRequest restRequest, String input, Callback<String> callback) {\n-      FutureResult<String> futureResult = new FutureResult<String>();\n+      final CompletableFuture<String> future = new CompletableFuture<>();\n       String convertedId = null;\n       Exception exception = null;\n       frontendMetrics.idConverterRequestRate.mark();\n       long startTimeInMs = System.currentTimeMillis();\n-      if (!isOpen) {\n+      try {\n+        if (!isOpen) {\n+        frontendMetrics.idConverterProcessingTimeInMs.update(System.currentTimeMillis() - startTimeInMs);\n         exception = new RestServiceException(\"IdConverter is closed\", RestServiceErrorCode.ServiceUnavailable);\n-      } else {\n-        try {\n-          if (restRequest.getRestMethod().equals(RestMethod.POST)) {\n+        } else if (restRequest.getRestMethod().equals(RestMethod.POST)) {\n             convertedId = \"/\" + signIdIfRequired(restRequest, input);\n-          } else {\n-            convertedId = parseSignedIdIfRequired(restRequest, input.startsWith(\"/\") ? input.substring(1) : input);\n-          }\n-        } catch (Exception e) {\n+        } else {\n+            frontendMetrics.idConverterProcessingTimeInMs.update(System.currentTimeMillis() - startTimeInMs);\n+            convertId(input, restRequest).whenComplete(\n+                (id, throwable) -> completeConversion(id, extractCompletionExceptionCause(throwable), future, callback));\n+        }\n+      } catch (Exception e) {\n           exception = e;\n+      } finally {\n+        frontendMetrics.idConverterProcessingTimeInMs.update(System.currentTimeMillis() - startTimeInMs);\n+        if (convertedId != null || exception != null) {\n+          completeConversion(convertedId, exception, future, callback);\n         }\n       }\n-      futureResult.done(convertedId, exception);\n+      return future;\n+    }\n+\n+    /**\n+     * @param throwable a throwable to possibly wrap in an exception.\n+     * @return if the {@link Throwable} is an instance of {@link Exception}, return the throwable, otherwise return the\n+     *         throwable wrapped in an exception.\n+     */\n+    private static Exception extractCompletionExceptionCause(Throwable throwable) {\n+      if (throwable == null) {\n+        return null;\n+      }\n+      if (throwable instanceof CompletionException) {\n+        throwable = throwable.getCause();\n+      }\n+      return throwable instanceof Exception ? (Exception) throwable : new Exception(\"Encountered throwable\", throwable);\n+    }\n+\n+    /**\n+     * Completes the conversion by setting the future and invoking the callback.\n+     * @param conversionResult the conversion result.\n+     * @param exception any exception that occurred as a part of the conversion.\n+     * @param completableFuture the {@link CompletableFuture} that must be set.\n+     * @param callback the {@link Callback} that needs to be invoked. Can be null.\n+     */\n+    private <T> void completeConversion(T conversionResult, Exception exception, CompletableFuture<T> completableFuture,\n+        Callback<T> callback) {\n+      if (exception == null) {\n+        completableFuture.complete(conversionResult);\n+      } else {\n+        completableFuture.completeExceptionally(exception);\n+      }\n       if (callback != null) {\n-        callback.onCompletion(convertedId, exception);\n+        long startTime = System.currentTimeMillis();\n+        callback.onCompletion(conversionResult, exception);\n+        frontendMetrics.idConversionDownstreamCallbackTimeInMs.update(System.currentTimeMillis() - startTime);\n+      }\n+    }\n+\n+    /**\n+     * Convert the input ID to the requested output. If it's the named blob request, return the blobId from NameBlobDb,\n+     * otherwise return the input with leading slash and extension be stripped.\n+     * @param input the input blob ID.\n+     * @param restRequest the {@link RestRequest} to set arguments in.\n+     * @return the {@link CompletionStage} that will be completed with the converted ID\n+     * @throws RestServiceException\n+     */\n+    private CompletionStage<String> convertId(String input, RestRequest restRequest)\n+        throws RestServiceException, IOException {\n+      CompletionStage<String> conversionFuture;\n+      if (input.startsWith(NAMED_BLOB_PREFIX)) {\n+        String[] slashFields = parseInput(input);\n+        //will update this hack version once NamedBlobDb is in.\n+        conversionFuture = get(slashFields[2], slashFields[3], slashFields[4]);\n+      } else if (restRequest.getRestMethod().equals(RestMethod.PUT) && restRequest.getUri().startsWith(NAMED_BLOB_PREFIX)) {\n+        String[] slashFields = parseInput(restRequest.getPath());\n+        StoreKey blobId = new BlobId(RestUtils.stripSlashAndExtensionFromId(input), clusterMap);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 155}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDUwNjcyNQ==", "bodyText": "is  this a duplicate of putSecurityProcessResponse?", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r524506725", "createdAt": "2020-11-16T19:06:57Z", "author": {"login": "cgtz"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/FrontendMetrics.java", "diffHunk": "@@ -269,6 +285,25 @@ public FrontendMetrics(MetricRegistry metricRegistry) {\n     undeleteBlobSecurityProcessResponseMetrics =\n         new AsyncOperationTracker.Metrics(UndeleteHandler.class, \"securityProcessResponse\", metricRegistry);\n \n+    putSecurityProcessRequestMetrics =\n+        new AsyncOperationTracker.Metrics(PutBlobHandler.class, \"putSecurityProcessRequest\", metricRegistry);\n+    putSecurityPostProcessRequestMetrics =\n+        new AsyncOperationTracker.Metrics(PutBlobHandler.class, \"putSecurityPostProcessRequest\", metricRegistry);\n+    putReadStitchRequestMetrics =\n+        new AsyncOperationTracker.Metrics(PutBlobHandler.class, \"putReadStitchRequest\", metricRegistry);\n+    putRouterStitchBlobMetrics =\n+        new AsyncOperationTracker.Metrics(PutBlobHandler.class, \"putRouterStitchBlob\", metricRegistry);\n+    putRouterPutBlobMetrics =\n+        new AsyncOperationTracker.Metrics(PutBlobHandler.class, \"putRouterPutBlob\", metricRegistry);\n+    putIdConversionMetrics =\n+        new AsyncOperationTracker.Metrics(PutBlobHandler.class, \"putIdConversion\", metricRegistry);\n+    putSecurityProcessResponseMetrics =\n+        new AsyncOperationTracker.Metrics(PutBlobHandler.class, \"putSecurityProcessResponse\", metricRegistry);\n+    putBlobRouterMetrics =\n+        new AsyncOperationTracker.Metrics(PutBlobHandler.class, \"router\", metricRegistry);\n+    putBlobSecurityProcessResponseMetrics =\n+        new AsyncOperationTracker.Metrics(PutBlobHandler.class, \"securityProcessResponse\", metricRegistry);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDUyMTk4MA==", "bodyText": "I think this comment should be changed to indicate that it is set to a string that indicates STITCH request vs regular upload", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r524521980", "createdAt": "2020-11-16T19:33:46Z", "author": {"login": "cgtz"}, "path": "ambry-api/src/main/java/com/github/ambry/rest/RestUtils.java", "diffHunk": "@@ -201,7 +201,10 @@\n      * stitched together.\n      */\n     public static final String CHUNK_UPLOAD = \"x-ambry-chunk-upload\";\n-\n+    /**\n+     *Boolean field set to \"true\" to indicate that this is an upload of a data chunk of a stitched upload(for named blob only).", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDUyMjIyNQ==", "bodyText": "make a constant for \"STITCH\", or use an enum", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r524522225", "createdAt": "2020-11-16T19:34:14Z", "author": {"login": "cgtz"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/PutBlobHandler.java", "diffHunk": "@@ -0,0 +1,405 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.frontend;\n+\n+import com.github.ambry.account.Container;\n+import com.github.ambry.commons.BlobId;\n+import com.github.ambry.commons.Callback;\n+import com.github.ambry.commons.RetainingAsyncWritableChannel;\n+import com.github.ambry.config.FrontendConfig;\n+import com.github.ambry.messageformat.BlobInfo;\n+import com.github.ambry.messageformat.BlobProperties;\n+import com.github.ambry.rest.RequestPath;\n+import com.github.ambry.rest.RestRequest;\n+import com.github.ambry.rest.RestResponseChannel;\n+import com.github.ambry.rest.RestServiceErrorCode;\n+import com.github.ambry.rest.RestServiceException;\n+import com.github.ambry.rest.RestUtils;\n+import com.github.ambry.router.ChunkInfo;\n+import com.github.ambry.router.PutBlobOptions;\n+import com.github.ambry.router.PutBlobOptionsBuilder;\n+import com.github.ambry.router.Router;\n+import com.github.ambry.utils.Pair;\n+import com.github.ambry.utils.Time;\n+import com.github.ambry.utils.Utils;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.json.JSONObject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static com.github.ambry.frontend.FrontendUtils.*;\n+\n+\n+/**\n+ * Handler for put named blob requests. The following request types are handled by {@link PutBlobHandler}:\n+ * <h2>Direct uploads</h2>\n+ * Direct upload requests treat the body of the request as the content to upload to Ambry. The request path should be\n+ * \"/named/account_name/container_name/blob_name\". In these requests, the blob properties and user metadata are supplied as headers. See\n+ * {@link RestUtils#buildBlobProperties(Map)} and {@link RestUtils#buildBlobProperties(Map)} for more details.\n+ * <h2>Stitched uploads</h2>\n+ * Stitched upload requests allow clients to stitch together previously uploaded data chunks into a single logical blob.\n+ * The request path should be \"/named/account_name/container_name/blob_name\", This request accepts the same headers as direct\n+ * upload requests for supplying the blob properties and user metadata of the stitched blob, but, instead of the actual\n+ * blob content, accepts a UTF-8 JSON object that includes the signed IDs for the chunks to stitch, and header x-ambry-put-mode should set as \"STITCH\".\n+ * <h3>Request body format</h3>\n+ * The body of the request should be a JSON object that conforms to the format described in {@link StitchRequestSerDe}.\n+ */\n+public class PutBlobHandler {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(PutBlobHandler.class);\n+  /**\n+   * Key to represent the time at which a blob will expire in ms. Used within the metadata map in signed IDs.\n+   */\n+  static final String EXPIRATION_TIME_MS_KEY = \"et\";\n+\n+  private final SecurityService securityService;\n+  private final IdConverter idConverter;\n+  private final IdSigningService idSigningService;\n+  private final Router router;\n+  private final AccountAndContainerInjector accountAndContainerInjector;\n+  private final Time time;\n+  private final FrontendConfig frontendConfig;\n+  private final FrontendMetrics frontendMetrics;\n+  private final String clusterName;\n+\n+  /**\n+   * Constructs a handler for handling requests for uploading or stitching blobs.\n+   * @param securityService the {@link SecurityService} to use.\n+   * @param idConverter the {@link IdConverter} to use.\n+   * @param idSigningService the {@link IdSigningService} to use.\n+   * @param router the {@link Router} to use.\n+   * @param accountAndContainerInjector helper to resolve account and container for a given request.\n+   * @param time the {@link Time} instance to use.\n+   * @param frontendConfig the {@link FrontendConfig} to use.\n+   * @param frontendMetrics {@link FrontendMetrics} instance where metrics should be recorded.\n+   * @param clusterName the name of the storage cluster that the router communicates with\n+   */\n+  PutBlobHandler(SecurityService securityService, IdConverter idConverter, IdSigningService idSigningService,\n+      Router router, AccountAndContainerInjector accountAndContainerInjector, Time time, FrontendConfig frontendConfig,\n+      FrontendMetrics frontendMetrics, String clusterName) {\n+    this.securityService = securityService;\n+    this.idConverter = idConverter;\n+    this.idSigningService = idSigningService;\n+    this.router = router;\n+    this.accountAndContainerInjector = accountAndContainerInjector;\n+    this.time = time;\n+    this.frontendConfig = frontendConfig;\n+    this.frontendMetrics = frontendMetrics;\n+    this.clusterName = clusterName;\n+  }\n+\n+  /**\n+   * Handles a request for put a blob\n+   * @param restRequest the {@link RestRequest} that contains the request parameters.\n+   * @param restResponseChannel the {@link RestResponseChannel} where headers should be set.\n+   * @param callback the {@link Callback} to invoke when the response is ready (or if there is an exception).\n+   */\n+  void handle(RestRequest restRequest, RestResponseChannel restResponseChannel, Callback<Void> callback) {\n+    new PutBlobHandler.CallbackChain(restRequest, restResponseChannel, callback).start();\n+  }\n+\n+  /**\n+   * Represents the chain of actions to take. Keeps request context that is relevant to all callback stages.\n+   */\n+  private class CallbackChain {\n+    private final RestRequest restRequest;\n+    private final RestResponseChannel restResponseChannel;\n+    private final Callback<Void> finalCallback;\n+    private final String uri;\n+\n+    /**\n+     * @param restRequest the {@link RestRequest}.\n+     * @param restResponseChannel the {@link RestResponseChannel}.\n+     * @param finalCallback the {@link Callback} to call on completion.\n+     */\n+    private CallbackChain(RestRequest restRequest, RestResponseChannel restResponseChannel,\n+        Callback<Void> finalCallback) {\n+      this.restRequest = restRequest;\n+      this.restResponseChannel = restResponseChannel;\n+      this.finalCallback = finalCallback;\n+      this.uri = restRequest.getUri();\n+    }\n+\n+    /**\n+     * Start the chain by calling {@link SecurityService#processRequest}.\n+     */\n+    private void start() {\n+      restRequest.getMetricsTracker()\n+          .injectMetrics(frontendMetrics.putBlobMetricsGroup.getRestRequestMetrics(restRequest.isSslUsed(), false));\n+      //?restRequest.setArg(RestUtils.InternalKeys.KEEP_ALIVE_ON_ERROR_HINT, true);\n+      try {\n+        // Start the callback chain by parsing blob info headers and performing request security processing.\n+        BlobInfo blobInfo = getBlobInfoFromRequest();\n+        checkUploadRequirements(blobInfo.getBlobProperties());\n+        securityService.processRequest(restRequest, securityProcessRequestCallback(blobInfo));\n+      } catch (Exception e) {\n+        finalCallback.onCompletion(null, e);\n+      }\n+    }\n+\n+    /**\n+     * Parse {@link BlobInfo} from the request arguments. This method will also ensure that the correct account and\n+     * container objects are attached to the request.\n+     * @return the {@link BlobInfo} parsed from the request arguments.\n+     * @throws RestServiceException if there is an error while parsing the {@link BlobInfo} arguments.\n+     */\n+    private BlobInfo getBlobInfoFromRequest() throws RestServiceException {\n+      long propsBuildStartTime = System.currentTimeMillis();\n+      accountAndContainerInjector.injectAccountAndContainerForPutRequest(restRequest,\n+          frontendMetrics.putBlobMetricsGroup);\n+      BlobProperties blobProperties = RestUtils.buildBlobProperties(restRequest.getArgs());\n+      Container container = RestUtils.getContainerFromArgs(restRequest.getArgs());\n+      if (blobProperties.getTimeToLiveInSeconds() + TimeUnit.MILLISECONDS.toSeconds(\n+          blobProperties.getCreationTimeInMs()) > Integer.MAX_VALUE) {\n+        LOGGER.debug(\"TTL set to very large value in POST request with BlobProperties {}\", blobProperties);\n+        frontendMetrics.ttlTooLargeError.inc();\n+      } else if (container.isTtlRequired() && (blobProperties.getTimeToLiveInSeconds() == Utils.Infinite_Time\n+          || blobProperties.getTimeToLiveInSeconds() > frontendConfig.maxAcceptableTtlSecsIfTtlRequired)) {\n+        String descriptor = RestUtils.getAccountFromArgs(restRequest.getArgs()).getName() + \":\" + container.getName();\n+        if (frontendConfig.failIfTtlRequiredButNotProvided) {\n+          throw new RestServiceException(\n+              \"TTL < \" + frontendConfig.maxAcceptableTtlSecsIfTtlRequired + \" is required for upload to \" + descriptor,\n+              RestServiceErrorCode.InvalidArgs);\n+        } else {\n+          LOGGER.debug(\"{} attempted an upload with ttl {} to {}\", blobProperties.getServiceId(),\n+              blobProperties.getTimeToLiveInSeconds(), descriptor);\n+          frontendMetrics.ttlNotCompliantError.inc();\n+          restResponseChannel.setHeader(RestUtils.Headers.NON_COMPLIANCE_WARNING,\n+              \"TTL < \" + frontendConfig.maxAcceptableTtlSecsIfTtlRequired + \" will be required for future uploads\");\n+        }\n+      }\n+      // inject encryption frontendMetrics if applicable\n+      if (blobProperties.isEncrypted()) {\n+        restRequest.getMetricsTracker()\n+            .injectMetrics(frontendMetrics.postBlobMetricsGroup.getRestRequestMetrics(restRequest.isSslUsed(), true));\n+      }\n+      byte[] userMetadata = RestUtils.buildUserMetadata(restRequest.getArgs());\n+      frontendMetrics.blobPropsBuildTimeInMs.update(System.currentTimeMillis() - propsBuildStartTime);\n+      LOGGER.trace(\"Blob properties of blob being POSTed - {}\", blobProperties);\n+      return new BlobInfo(blobProperties, userMetadata);\n+    }\n+\n+    /**\n+     * Enforce any additional requirements for certain types of uploads like data chunk uploads.\n+     * @param blobProperties the {@link BlobProperties} parsed from the request.\n+     * @throws RestServiceException\n+     */\n+    private void checkUploadRequirements(BlobProperties blobProperties) throws RestServiceException {\n+      if (RestUtils.isChunkUpload(restRequest.getArgs())) {\n+        // ensure that the x-ambry-session header is present.\n+        RestUtils.getHeader(restRequest.getArgs(), RestUtils.Headers.SESSION, true);\n+        // validate that a max chunk size is set.\n+        RestUtils.getLongHeader(restRequest.getArgs(), RestUtils.Headers.MAX_UPLOAD_SIZE, true);\n+        // validate that the TTL for the chunk is set correctly.\n+        long chunkTtl = blobProperties.getTimeToLiveInSeconds();\n+        if (chunkTtl <= 0 || chunkTtl > frontendConfig.chunkUploadInitialChunkTtlSecs) {\n+          throw new RestServiceException(\"Invalid chunk upload TTL: \" + chunkTtl, RestServiceErrorCode.InvalidArgs);\n+        }\n+      }\n+    }\n+\n+    /**\n+     * After {@link SecurityService#processRequest} finishes, call {@link SecurityService#postProcessRequest} to perform\n+     * request time security checks that rely on the request being fully parsed and any additional arguments set.\n+     * @param blobInfo the {@link BlobInfo} to carry to future stages.\n+     * @return a {@link Callback} to be used with {@link SecurityService#processRequest}.\n+     */\n+    private Callback<Void> securityProcessRequestCallback(BlobInfo blobInfo) {\n+      return buildCallback(frontendMetrics.putSecurityProcessRequestMetrics,\n+          securityCheckResult -> securityService.postProcessRequest(restRequest,\n+              securityPostProcessRequestCallback(blobInfo)), uri, LOGGER, finalCallback);\n+    }\n+\n+    /**\n+     * After {@link SecurityService#postProcessRequest} finishes, call {@link Router#putBlob} to persist the blob in the\n+     * storage layer.\n+     * @param blobInfo the {@link BlobInfo} to make the router call with.\n+     * @return a {@link Callback} to be used with {@link SecurityService#postProcessRequest}.\n+     */\n+    private Callback<Void> securityPostProcessRequestCallback(BlobInfo blobInfo) {\n+      return buildCallback(frontendMetrics.postSecurityPostProcessRequestMetrics, securityCheckResult -> {\n+        if (\"STITCH\".equals(RestUtils.getHeader(restRequest.getArgs(), RestUtils.Headers.PUT_MODE, false))) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 236}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDUyMzI3NA==", "bodyText": "we can keep this for now, but I was thinking that we may not have to support chunk upload for put requests. I think those data chunks can always be uploaded as regular blobs (POST -> blob id) and then just the final stitchBlob call can be made with the put named blob API.", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r524523274", "createdAt": "2020-11-16T19:36:06Z", "author": {"login": "cgtz"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/PutBlobHandler.java", "diffHunk": "@@ -0,0 +1,405 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.frontend;\n+\n+import com.github.ambry.account.Container;\n+import com.github.ambry.commons.BlobId;\n+import com.github.ambry.commons.Callback;\n+import com.github.ambry.commons.RetainingAsyncWritableChannel;\n+import com.github.ambry.config.FrontendConfig;\n+import com.github.ambry.messageformat.BlobInfo;\n+import com.github.ambry.messageformat.BlobProperties;\n+import com.github.ambry.rest.RequestPath;\n+import com.github.ambry.rest.RestRequest;\n+import com.github.ambry.rest.RestResponseChannel;\n+import com.github.ambry.rest.RestServiceErrorCode;\n+import com.github.ambry.rest.RestServiceException;\n+import com.github.ambry.rest.RestUtils;\n+import com.github.ambry.router.ChunkInfo;\n+import com.github.ambry.router.PutBlobOptions;\n+import com.github.ambry.router.PutBlobOptionsBuilder;\n+import com.github.ambry.router.Router;\n+import com.github.ambry.utils.Pair;\n+import com.github.ambry.utils.Time;\n+import com.github.ambry.utils.Utils;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.json.JSONObject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static com.github.ambry.frontend.FrontendUtils.*;\n+\n+\n+/**\n+ * Handler for put named blob requests. The following request types are handled by {@link PutBlobHandler}:\n+ * <h2>Direct uploads</h2>\n+ * Direct upload requests treat the body of the request as the content to upload to Ambry. The request path should be\n+ * \"/named/account_name/container_name/blob_name\". In these requests, the blob properties and user metadata are supplied as headers. See\n+ * {@link RestUtils#buildBlobProperties(Map)} and {@link RestUtils#buildBlobProperties(Map)} for more details.\n+ * <h2>Stitched uploads</h2>\n+ * Stitched upload requests allow clients to stitch together previously uploaded data chunks into a single logical blob.\n+ * The request path should be \"/named/account_name/container_name/blob_name\", This request accepts the same headers as direct\n+ * upload requests for supplying the blob properties and user metadata of the stitched blob, but, instead of the actual\n+ * blob content, accepts a UTF-8 JSON object that includes the signed IDs for the chunks to stitch, and header x-ambry-put-mode should set as \"STITCH\".\n+ * <h3>Request body format</h3>\n+ * The body of the request should be a JSON object that conforms to the format described in {@link StitchRequestSerDe}.\n+ */\n+public class PutBlobHandler {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(PutBlobHandler.class);\n+  /**\n+   * Key to represent the time at which a blob will expire in ms. Used within the metadata map in signed IDs.\n+   */\n+  static final String EXPIRATION_TIME_MS_KEY = \"et\";\n+\n+  private final SecurityService securityService;\n+  private final IdConverter idConverter;\n+  private final IdSigningService idSigningService;\n+  private final Router router;\n+  private final AccountAndContainerInjector accountAndContainerInjector;\n+  private final Time time;\n+  private final FrontendConfig frontendConfig;\n+  private final FrontendMetrics frontendMetrics;\n+  private final String clusterName;\n+\n+  /**\n+   * Constructs a handler for handling requests for uploading or stitching blobs.\n+   * @param securityService the {@link SecurityService} to use.\n+   * @param idConverter the {@link IdConverter} to use.\n+   * @param idSigningService the {@link IdSigningService} to use.\n+   * @param router the {@link Router} to use.\n+   * @param accountAndContainerInjector helper to resolve account and container for a given request.\n+   * @param time the {@link Time} instance to use.\n+   * @param frontendConfig the {@link FrontendConfig} to use.\n+   * @param frontendMetrics {@link FrontendMetrics} instance where metrics should be recorded.\n+   * @param clusterName the name of the storage cluster that the router communicates with\n+   */\n+  PutBlobHandler(SecurityService securityService, IdConverter idConverter, IdSigningService idSigningService,\n+      Router router, AccountAndContainerInjector accountAndContainerInjector, Time time, FrontendConfig frontendConfig,\n+      FrontendMetrics frontendMetrics, String clusterName) {\n+    this.securityService = securityService;\n+    this.idConverter = idConverter;\n+    this.idSigningService = idSigningService;\n+    this.router = router;\n+    this.accountAndContainerInjector = accountAndContainerInjector;\n+    this.time = time;\n+    this.frontendConfig = frontendConfig;\n+    this.frontendMetrics = frontendMetrics;\n+    this.clusterName = clusterName;\n+  }\n+\n+  /**\n+   * Handles a request for put a blob\n+   * @param restRequest the {@link RestRequest} that contains the request parameters.\n+   * @param restResponseChannel the {@link RestResponseChannel} where headers should be set.\n+   * @param callback the {@link Callback} to invoke when the response is ready (or if there is an exception).\n+   */\n+  void handle(RestRequest restRequest, RestResponseChannel restResponseChannel, Callback<Void> callback) {\n+    new PutBlobHandler.CallbackChain(restRequest, restResponseChannel, callback).start();\n+  }\n+\n+  /**\n+   * Represents the chain of actions to take. Keeps request context that is relevant to all callback stages.\n+   */\n+  private class CallbackChain {\n+    private final RestRequest restRequest;\n+    private final RestResponseChannel restResponseChannel;\n+    private final Callback<Void> finalCallback;\n+    private final String uri;\n+\n+    /**\n+     * @param restRequest the {@link RestRequest}.\n+     * @param restResponseChannel the {@link RestResponseChannel}.\n+     * @param finalCallback the {@link Callback} to call on completion.\n+     */\n+    private CallbackChain(RestRequest restRequest, RestResponseChannel restResponseChannel,\n+        Callback<Void> finalCallback) {\n+      this.restRequest = restRequest;\n+      this.restResponseChannel = restResponseChannel;\n+      this.finalCallback = finalCallback;\n+      this.uri = restRequest.getUri();\n+    }\n+\n+    /**\n+     * Start the chain by calling {@link SecurityService#processRequest}.\n+     */\n+    private void start() {\n+      restRequest.getMetricsTracker()\n+          .injectMetrics(frontendMetrics.putBlobMetricsGroup.getRestRequestMetrics(restRequest.isSslUsed(), false));\n+      //?restRequest.setArg(RestUtils.InternalKeys.KEEP_ALIVE_ON_ERROR_HINT, true);\n+      try {\n+        // Start the callback chain by parsing blob info headers and performing request security processing.\n+        BlobInfo blobInfo = getBlobInfoFromRequest();\n+        checkUploadRequirements(blobInfo.getBlobProperties());\n+        securityService.processRequest(restRequest, securityProcessRequestCallback(blobInfo));\n+      } catch (Exception e) {\n+        finalCallback.onCompletion(null, e);\n+      }\n+    }\n+\n+    /**\n+     * Parse {@link BlobInfo} from the request arguments. This method will also ensure that the correct account and\n+     * container objects are attached to the request.\n+     * @return the {@link BlobInfo} parsed from the request arguments.\n+     * @throws RestServiceException if there is an error while parsing the {@link BlobInfo} arguments.\n+     */\n+    private BlobInfo getBlobInfoFromRequest() throws RestServiceException {\n+      long propsBuildStartTime = System.currentTimeMillis();\n+      accountAndContainerInjector.injectAccountAndContainerForPutRequest(restRequest,\n+          frontendMetrics.putBlobMetricsGroup);\n+      BlobProperties blobProperties = RestUtils.buildBlobProperties(restRequest.getArgs());\n+      Container container = RestUtils.getContainerFromArgs(restRequest.getArgs());\n+      if (blobProperties.getTimeToLiveInSeconds() + TimeUnit.MILLISECONDS.toSeconds(\n+          blobProperties.getCreationTimeInMs()) > Integer.MAX_VALUE) {\n+        LOGGER.debug(\"TTL set to very large value in POST request with BlobProperties {}\", blobProperties);\n+        frontendMetrics.ttlTooLargeError.inc();\n+      } else if (container.isTtlRequired() && (blobProperties.getTimeToLiveInSeconds() == Utils.Infinite_Time\n+          || blobProperties.getTimeToLiveInSeconds() > frontendConfig.maxAcceptableTtlSecsIfTtlRequired)) {\n+        String descriptor = RestUtils.getAccountFromArgs(restRequest.getArgs()).getName() + \":\" + container.getName();\n+        if (frontendConfig.failIfTtlRequiredButNotProvided) {\n+          throw new RestServiceException(\n+              \"TTL < \" + frontendConfig.maxAcceptableTtlSecsIfTtlRequired + \" is required for upload to \" + descriptor,\n+              RestServiceErrorCode.InvalidArgs);\n+        } else {\n+          LOGGER.debug(\"{} attempted an upload with ttl {} to {}\", blobProperties.getServiceId(),\n+              blobProperties.getTimeToLiveInSeconds(), descriptor);\n+          frontendMetrics.ttlNotCompliantError.inc();\n+          restResponseChannel.setHeader(RestUtils.Headers.NON_COMPLIANCE_WARNING,\n+              \"TTL < \" + frontendConfig.maxAcceptableTtlSecsIfTtlRequired + \" will be required for future uploads\");\n+        }\n+      }\n+      // inject encryption frontendMetrics if applicable\n+      if (blobProperties.isEncrypted()) {\n+        restRequest.getMetricsTracker()\n+            .injectMetrics(frontendMetrics.postBlobMetricsGroup.getRestRequestMetrics(restRequest.isSslUsed(), true));\n+      }\n+      byte[] userMetadata = RestUtils.buildUserMetadata(restRequest.getArgs());\n+      frontendMetrics.blobPropsBuildTimeInMs.update(System.currentTimeMillis() - propsBuildStartTime);\n+      LOGGER.trace(\"Blob properties of blob being POSTed - {}\", blobProperties);\n+      return new BlobInfo(blobProperties, userMetadata);\n+    }\n+\n+    /**\n+     * Enforce any additional requirements for certain types of uploads like data chunk uploads.\n+     * @param blobProperties the {@link BlobProperties} parsed from the request.\n+     * @throws RestServiceException\n+     */\n+    private void checkUploadRequirements(BlobProperties blobProperties) throws RestServiceException {\n+      if (RestUtils.isChunkUpload(restRequest.getArgs())) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 203}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3NTkyMjQ3", "url": "https://github.com/linkedin/ambry/pull/1690#pullrequestreview-527592247", "createdAt": "2020-11-10T20:44:39Z", "commit": {"oid": "46b79ff017bcaa19aeae785e2bfbc5b627d75c58"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQyMDo0NjoyM1rOHwu-Sg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QyMDoyMzo1MFrOH1Jl_g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg2MzMwNg==", "bodyText": "Is there no existing utility method that does this?  I could swear I've seen one.", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r520863306", "createdAt": "2020-11-10T20:46:23Z", "author": {"login": "lightningrob"}, "path": "ambry-api/src/main/java/com/github/ambry/rest/RestUtils.java", "diffHunk": "@@ -930,4 +933,16 @@ private static ByteRange buildByteRange(String rangeHeaderValue) throws RestServ\n     }\n     return range;\n   }\n+\n+  /**\n+   * Drops the leading slash and extension (if any) in the blob ID.\n+   * @param blobIdWithExtension the blob ID possibly with an extension.\n+   * @return {@code blobIdWithExtension} without an extension if there was one.\n+   */\n+  public static String stripSlashAndExtensionFromId(String blobIdWithExtension) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46b79ff017bcaa19aeae785e2bfbc5b627d75c58"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg5MTIyNw==", "bodyText": "I think this should be \"that account name/container name can be parsed from\"", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r520891227", "createdAt": "2020-11-10T21:40:33Z", "author": {"login": "lightningrob"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AccountAndContainerInjector.java", "diffHunk": "@@ -84,6 +85,48 @@ public void injectAccountAndContainerForPostRequest(RestRequest restRequest, Res\n     }\n   }\n \n+  /**\n+   * Injects target {@link Account} and {@link Container} for PUT requests. This method also ensures required uri\n+   * is present for the PUT requests that can account name/container name can parse from.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46b79ff017bcaa19aeae785e2bfbc5b627d75c58"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg5NDU0NQ==", "bodyText": "What is named?", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r520894545", "createdAt": "2020-11-10T21:47:08Z", "author": {"login": "lightningrob"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AccountAndContainerInjector.java", "diffHunk": "@@ -84,6 +85,48 @@ public void injectAccountAndContainerForPostRequest(RestRequest restRequest, Res\n     }\n   }\n \n+  /**\n+   * Injects target {@link Account} and {@link Container} for PUT requests. This method also ensures required uri\n+   * is present for the PUT requests that can account name/container name can parse from.\n+   * @param restRequest The Put {@link RestRequest}.\n+   * @param metricsGroup The {@link RestRequestMetricsGroup} to use to set up {@link ContainerMetrics}, or {@code null}\n+   *                     if {@link ContainerMetrics} instantiation is not needed.\n+   * @throws RestServiceException\n+   */\n+  public void injectAccountAndContainerForPutRequest(RestRequest restRequest, RestRequestMetricsGroup metricsGroup)\n+      throws RestServiceException {\n+    accountAndContainerSanityCheckForNamedBlob(restRequest);\n+    if (restRequest.getUri() != null) {\n+      frontendMetrics.putWithAccountAndContainerHeaderRate.mark();\n+      injectAccountAndContainerUsingAccountAndContainerUri(restRequest, metricsGroup);\n+    } else if (frontendConfig.allowServiceIdBasedPutRequest) {\n+      ensureRequiredHeadersOrThrow(restRequest, requiredAmbryHeadersForPutWithServiceId);\n+      frontendMetrics.putWithServiceIdForAccountNameRate.mark();\n+      String serviceId = getHeader(restRequest.getArgs(), Headers.SERVICE_ID, true);\n+      boolean isPrivate = isPrivate(restRequest.getArgs());\n+      injectAccountAndContainerUsingServiceId(restRequest, serviceId, isPrivate, metricsGroup);\n+    } else {\n+      throw new RestServiceException(\n+          \"Missing either \" + Headers.TARGET_ACCOUNT_NAME + \" or \" + Headers.TARGET_CONTAINER_NAME + \" header\",\n+          RestServiceErrorCode.BadRequest);\n+    }\n+  }\n+\n+  /**\n+   * Parse the input if it's the named blob request.\n+   * @param input the url that needs to be parsed.\n+   * @return the String array contains the\n+   */\n+  private String[] parseInput(String input) {\n+    Objects.requireNonNull(input, \"input should not be null\");\n+    String[] slashFields = input.split(\"/\");\n+    if (slashFields.length < 4) {\n+      throw new IllegalArgumentException(\n+          \"File must have name format '/<named>/<account_name>/<container_name>/blob_name'.  Received: '\" + input + \"'\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46b79ff017bcaa19aeae785e2bfbc5b627d75c58"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg5NTM5Nw==", "bodyText": "dangling sentence", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r520895397", "createdAt": "2020-11-10T21:48:52Z", "author": {"login": "lightningrob"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AccountAndContainerInjector.java", "diffHunk": "@@ -84,6 +85,48 @@ public void injectAccountAndContainerForPostRequest(RestRequest restRequest, Res\n     }\n   }\n \n+  /**\n+   * Injects target {@link Account} and {@link Container} for PUT requests. This method also ensures required uri\n+   * is present for the PUT requests that can account name/container name can parse from.\n+   * @param restRequest The Put {@link RestRequest}.\n+   * @param metricsGroup The {@link RestRequestMetricsGroup} to use to set up {@link ContainerMetrics}, or {@code null}\n+   *                     if {@link ContainerMetrics} instantiation is not needed.\n+   * @throws RestServiceException\n+   */\n+  public void injectAccountAndContainerForPutRequest(RestRequest restRequest, RestRequestMetricsGroup metricsGroup)\n+      throws RestServiceException {\n+    accountAndContainerSanityCheckForNamedBlob(restRequest);\n+    if (restRequest.getUri() != null) {\n+      frontendMetrics.putWithAccountAndContainerHeaderRate.mark();\n+      injectAccountAndContainerUsingAccountAndContainerUri(restRequest, metricsGroup);\n+    } else if (frontendConfig.allowServiceIdBasedPutRequest) {\n+      ensureRequiredHeadersOrThrow(restRequest, requiredAmbryHeadersForPutWithServiceId);\n+      frontendMetrics.putWithServiceIdForAccountNameRate.mark();\n+      String serviceId = getHeader(restRequest.getArgs(), Headers.SERVICE_ID, true);\n+      boolean isPrivate = isPrivate(restRequest.getArgs());\n+      injectAccountAndContainerUsingServiceId(restRequest, serviceId, isPrivate, metricsGroup);\n+    } else {\n+      throw new RestServiceException(\n+          \"Missing either \" + Headers.TARGET_ACCOUNT_NAME + \" or \" + Headers.TARGET_CONTAINER_NAME + \" header\",\n+          RestServiceErrorCode.BadRequest);\n+    }\n+  }\n+\n+  /**\n+   * Parse the input if it's the named blob request.\n+   * @param input the url that needs to be parsed.\n+   * @return the String array contains the", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46b79ff017bcaa19aeae785e2bfbc5b627d75c58"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwMDkwMg==", "bodyText": "Why are put requests injected differently than post requests?  Put requests contain the blobId, but that doesn't appear to be used here.", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r520900902", "createdAt": "2020-11-10T21:59:56Z", "author": {"login": "lightningrob"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AccountAndContainerInjector.java", "diffHunk": "@@ -84,6 +85,48 @@ public void injectAccountAndContainerForPostRequest(RestRequest restRequest, Res\n     }\n   }\n \n+  /**\n+   * Injects target {@link Account} and {@link Container} for PUT requests. This method also ensures required uri\n+   * is present for the PUT requests that can account name/container name can parse from.\n+   * @param restRequest The Put {@link RestRequest}.\n+   * @param metricsGroup The {@link RestRequestMetricsGroup} to use to set up {@link ContainerMetrics}, or {@code null}\n+   *                     if {@link ContainerMetrics} instantiation is not needed.\n+   * @throws RestServiceException\n+   */\n+  public void injectAccountAndContainerForPutRequest(RestRequest restRequest, RestRequestMetricsGroup metricsGroup)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46b79ff017bcaa19aeae785e2bfbc5b627d75c58"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwMjkzMg==", "bodyText": "Looks like duplicate method.", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r520902932", "createdAt": "2020-11-10T22:04:07Z", "author": {"login": "lightningrob"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AmbryIdConverterFactory.java", "diffHunk": "@@ -73,30 +86,126 @@ public void close() {\n      */\n     @Override\n     public Future<String> convert(RestRequest restRequest, String input, Callback<String> callback) {\n-      FutureResult<String> futureResult = new FutureResult<String>();\n+      final CompletableFuture<String> future = new CompletableFuture<>();\n       String convertedId = null;\n       Exception exception = null;\n       frontendMetrics.idConverterRequestRate.mark();\n       long startTimeInMs = System.currentTimeMillis();\n-      if (!isOpen) {\n+      try {\n+        if (!isOpen) {\n+        frontendMetrics.idConverterProcessingTimeInMs.update(System.currentTimeMillis() - startTimeInMs);\n         exception = new RestServiceException(\"IdConverter is closed\", RestServiceErrorCode.ServiceUnavailable);\n-      } else {\n-        try {\n-          if (restRequest.getRestMethod().equals(RestMethod.POST)) {\n+        } else if (restRequest.getRestMethod().equals(RestMethod.POST)) {\n             convertedId = \"/\" + signIdIfRequired(restRequest, input);\n-          } else {\n-            convertedId = parseSignedIdIfRequired(restRequest, input.startsWith(\"/\") ? input.substring(1) : input);\n-          }\n-        } catch (Exception e) {\n+        } else {\n+            frontendMetrics.idConverterProcessingTimeInMs.update(System.currentTimeMillis() - startTimeInMs);\n+            convertId(input, restRequest).whenComplete(\n+                (id, throwable) -> completeConversion(id, extractCompletionExceptionCause(throwable), future, callback));\n+        }\n+      } catch (Exception e) {\n           exception = e;\n+      } finally {\n+        frontendMetrics.idConverterProcessingTimeInMs.update(System.currentTimeMillis() - startTimeInMs);\n+        if (convertedId != null || exception != null) {\n+          completeConversion(convertedId, exception, future, callback);\n         }\n       }\n-      futureResult.done(convertedId, exception);\n+      return future;\n+    }\n+\n+    /**\n+     * @param throwable a throwable to possibly wrap in an exception.\n+     * @return if the {@link Throwable} is an instance of {@link Exception}, return the throwable, otherwise return the\n+     *         throwable wrapped in an exception.\n+     */\n+    private static Exception extractCompletionExceptionCause(Throwable throwable) {\n+      if (throwable == null) {\n+        return null;\n+      }\n+      if (throwable instanceof CompletionException) {\n+        throwable = throwable.getCause();\n+      }\n+      return throwable instanceof Exception ? (Exception) throwable : new Exception(\"Encountered throwable\", throwable);\n+    }\n+\n+    /**\n+     * Completes the conversion by setting the future and invoking the callback.\n+     * @param conversionResult the conversion result.\n+     * @param exception any exception that occurred as a part of the conversion.\n+     * @param completableFuture the {@link CompletableFuture} that must be set.\n+     * @param callback the {@link Callback} that needs to be invoked. Can be null.\n+     */\n+    private <T> void completeConversion(T conversionResult, Exception exception, CompletableFuture<T> completableFuture,\n+        Callback<T> callback) {\n+      if (exception == null) {\n+        completableFuture.complete(conversionResult);\n+      } else {\n+        completableFuture.completeExceptionally(exception);\n+      }\n       if (callback != null) {\n-        callback.onCompletion(convertedId, exception);\n+        long startTime = System.currentTimeMillis();\n+        callback.onCompletion(conversionResult, exception);\n+        frontendMetrics.idConversionDownstreamCallbackTimeInMs.update(System.currentTimeMillis() - startTime);\n+      }\n+    }\n+\n+    /**\n+     * Convert the input ID to the requested output. If it's the named blob request, return the blobId from NameBlobDb,\n+     * otherwise return the input with leading slash and extension be stripped.\n+     * @param input the input blob ID.\n+     * @param restRequest the {@link RestRequest} to set arguments in.\n+     * @return the {@link CompletionStage} that will be completed with the converted ID\n+     * @throws RestServiceException\n+     */\n+    private CompletionStage<String> convertId(String input, RestRequest restRequest)\n+        throws RestServiceException, IOException {\n+      CompletionStage<String> conversionFuture;\n+      if (input.startsWith(NAMED_BLOB_PREFIX)) {\n+        String[] slashFields = parseInput(input);\n+        //will update this hack version once NamedBlobDb is in.\n+        conversionFuture = get(slashFields[2], slashFields[3], slashFields[4]);\n+      } else if (restRequest.getRestMethod().equals(RestMethod.PUT) && restRequest.getUri().startsWith(NAMED_BLOB_PREFIX)) {\n+        String[] slashFields = parseInput(restRequest.getPath());\n+        StoreKey blobId = new BlobId(RestUtils.stripSlashAndExtensionFromId(input), clusterMap);\n+        conversionFuture = put(slashFields[2], slashFields[3], slashFields[4], blobId);\n+      } else {\n+        String decryptedInput = parseSignedIdIfRequired(restRequest, input.startsWith(\"/\") ? input.substring(1) : input);\n+        conversionFuture = CompletableFuture.completedFuture(RestUtils.stripSlashAndExtensionFromId(decryptedInput));\n+      }\n+      return conversionFuture;\n+    }\n+\n+    /*\n+     * will update this hack version once NamedBlobDb is in.\n+     */\n+    private CompletableFuture<String> get(String accountName, String containerName, String blobName) {\n+      CompletableFuture<String> completableFuture = new CompletableFuture<>();\n+      completableFuture.complete(accountName + containerName + blobName);\n+      return completableFuture;\n+    }\n+\n+    /*\n+     * will update this hack version once NamedBlobDb is in.\n+     */\n+    private CompletableFuture<String> put(String accountName, String containerName, String blobName, StoreKey blobId) {\n+      CompletableFuture<String> completableFuture = new CompletableFuture<>();\n+      completableFuture.complete(blobId.getID());\n+      return completableFuture;\n+    }\n+\n+    /**\n+     * Parse the input if it's the named blob request.\n+     * @param input the url that needs to be parsed.\n+     * @return the String array contains the\n+     */\n+    String[] parseInput(String input) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46b79ff017bcaa19aeae785e2bfbc5b627d75c58"}, "originalPosition": 186}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQ3MTA3Mg==", "bodyText": "I think the name should also be changed to be more specific.  I'd never have guessed what it apparently means.", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r525471072", "createdAt": "2020-11-17T20:04:52Z", "author": {"login": "lightningrob"}, "path": "ambry-api/src/main/java/com/github/ambry/rest/RestUtils.java", "diffHunk": "@@ -201,7 +201,10 @@\n      * stitched together.\n      */\n     public static final String CHUNK_UPLOAD = \"x-ambry-chunk-upload\";\n-\n+    /**\n+     *Boolean field set to \"true\" to indicate that this is an upload of a data chunk of a stitched upload(for named blob only).", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDUyMTk4MA=="}, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQ4Mzc3NA==", "bodyText": "If this is strictly for named blobs, could we call it NamedBlobPutHandler?", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r525483774", "createdAt": "2020-11-17T20:15:33Z", "author": {"login": "lightningrob"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/PutBlobHandler.java", "diffHunk": "@@ -0,0 +1,405 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.frontend;\n+\n+import com.github.ambry.account.Container;\n+import com.github.ambry.commons.BlobId;\n+import com.github.ambry.commons.Callback;\n+import com.github.ambry.commons.RetainingAsyncWritableChannel;\n+import com.github.ambry.config.FrontendConfig;\n+import com.github.ambry.messageformat.BlobInfo;\n+import com.github.ambry.messageformat.BlobProperties;\n+import com.github.ambry.rest.RequestPath;\n+import com.github.ambry.rest.RestRequest;\n+import com.github.ambry.rest.RestResponseChannel;\n+import com.github.ambry.rest.RestServiceErrorCode;\n+import com.github.ambry.rest.RestServiceException;\n+import com.github.ambry.rest.RestUtils;\n+import com.github.ambry.router.ChunkInfo;\n+import com.github.ambry.router.PutBlobOptions;\n+import com.github.ambry.router.PutBlobOptionsBuilder;\n+import com.github.ambry.router.Router;\n+import com.github.ambry.utils.Pair;\n+import com.github.ambry.utils.Time;\n+import com.github.ambry.utils.Utils;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.json.JSONObject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static com.github.ambry.frontend.FrontendUtils.*;\n+\n+\n+/**\n+ * Handler for put named blob requests. The following request types are handled by {@link PutBlobHandler}:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQ4ODkzMw==", "bodyText": "Minor: this is likely copied code, but I doubt we need to time simple in-memory operations like this.", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r525488933", "createdAt": "2020-11-17T20:19:47Z", "author": {"login": "lightningrob"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/PutBlobHandler.java", "diffHunk": "@@ -0,0 +1,405 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.frontend;\n+\n+import com.github.ambry.account.Container;\n+import com.github.ambry.commons.BlobId;\n+import com.github.ambry.commons.Callback;\n+import com.github.ambry.commons.RetainingAsyncWritableChannel;\n+import com.github.ambry.config.FrontendConfig;\n+import com.github.ambry.messageformat.BlobInfo;\n+import com.github.ambry.messageformat.BlobProperties;\n+import com.github.ambry.rest.RequestPath;\n+import com.github.ambry.rest.RestRequest;\n+import com.github.ambry.rest.RestResponseChannel;\n+import com.github.ambry.rest.RestServiceErrorCode;\n+import com.github.ambry.rest.RestServiceException;\n+import com.github.ambry.rest.RestUtils;\n+import com.github.ambry.router.ChunkInfo;\n+import com.github.ambry.router.PutBlobOptions;\n+import com.github.ambry.router.PutBlobOptionsBuilder;\n+import com.github.ambry.router.Router;\n+import com.github.ambry.utils.Pair;\n+import com.github.ambry.utils.Time;\n+import com.github.ambry.utils.Utils;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.json.JSONObject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static com.github.ambry.frontend.FrontendUtils.*;\n+\n+\n+/**\n+ * Handler for put named blob requests. The following request types are handled by {@link PutBlobHandler}:\n+ * <h2>Direct uploads</h2>\n+ * Direct upload requests treat the body of the request as the content to upload to Ambry. The request path should be\n+ * \"/named/account_name/container_name/blob_name\". In these requests, the blob properties and user metadata are supplied as headers. See\n+ * {@link RestUtils#buildBlobProperties(Map)} and {@link RestUtils#buildBlobProperties(Map)} for more details.\n+ * <h2>Stitched uploads</h2>\n+ * Stitched upload requests allow clients to stitch together previously uploaded data chunks into a single logical blob.\n+ * The request path should be \"/named/account_name/container_name/blob_name\", This request accepts the same headers as direct\n+ * upload requests for supplying the blob properties and user metadata of the stitched blob, but, instead of the actual\n+ * blob content, accepts a UTF-8 JSON object that includes the signed IDs for the chunks to stitch, and header x-ambry-put-mode should set as \"STITCH\".\n+ * <h3>Request body format</h3>\n+ * The body of the request should be a JSON object that conforms to the format described in {@link StitchRequestSerDe}.\n+ */\n+public class PutBlobHandler {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(PutBlobHandler.class);\n+  /**\n+   * Key to represent the time at which a blob will expire in ms. Used within the metadata map in signed IDs.\n+   */\n+  static final String EXPIRATION_TIME_MS_KEY = \"et\";\n+\n+  private final SecurityService securityService;\n+  private final IdConverter idConverter;\n+  private final IdSigningService idSigningService;\n+  private final Router router;\n+  private final AccountAndContainerInjector accountAndContainerInjector;\n+  private final Time time;\n+  private final FrontendConfig frontendConfig;\n+  private final FrontendMetrics frontendMetrics;\n+  private final String clusterName;\n+\n+  /**\n+   * Constructs a handler for handling requests for uploading or stitching blobs.\n+   * @param securityService the {@link SecurityService} to use.\n+   * @param idConverter the {@link IdConverter} to use.\n+   * @param idSigningService the {@link IdSigningService} to use.\n+   * @param router the {@link Router} to use.\n+   * @param accountAndContainerInjector helper to resolve account and container for a given request.\n+   * @param time the {@link Time} instance to use.\n+   * @param frontendConfig the {@link FrontendConfig} to use.\n+   * @param frontendMetrics {@link FrontendMetrics} instance where metrics should be recorded.\n+   * @param clusterName the name of the storage cluster that the router communicates with\n+   */\n+  PutBlobHandler(SecurityService securityService, IdConverter idConverter, IdSigningService idSigningService,\n+      Router router, AccountAndContainerInjector accountAndContainerInjector, Time time, FrontendConfig frontendConfig,\n+      FrontendMetrics frontendMetrics, String clusterName) {\n+    this.securityService = securityService;\n+    this.idConverter = idConverter;\n+    this.idSigningService = idSigningService;\n+    this.router = router;\n+    this.accountAndContainerInjector = accountAndContainerInjector;\n+    this.time = time;\n+    this.frontendConfig = frontendConfig;\n+    this.frontendMetrics = frontendMetrics;\n+    this.clusterName = clusterName;\n+  }\n+\n+  /**\n+   * Handles a request for put a blob\n+   * @param restRequest the {@link RestRequest} that contains the request parameters.\n+   * @param restResponseChannel the {@link RestResponseChannel} where headers should be set.\n+   * @param callback the {@link Callback} to invoke when the response is ready (or if there is an exception).\n+   */\n+  void handle(RestRequest restRequest, RestResponseChannel restResponseChannel, Callback<Void> callback) {\n+    new PutBlobHandler.CallbackChain(restRequest, restResponseChannel, callback).start();\n+  }\n+\n+  /**\n+   * Represents the chain of actions to take. Keeps request context that is relevant to all callback stages.\n+   */\n+  private class CallbackChain {\n+    private final RestRequest restRequest;\n+    private final RestResponseChannel restResponseChannel;\n+    private final Callback<Void> finalCallback;\n+    private final String uri;\n+\n+    /**\n+     * @param restRequest the {@link RestRequest}.\n+     * @param restResponseChannel the {@link RestResponseChannel}.\n+     * @param finalCallback the {@link Callback} to call on completion.\n+     */\n+    private CallbackChain(RestRequest restRequest, RestResponseChannel restResponseChannel,\n+        Callback<Void> finalCallback) {\n+      this.restRequest = restRequest;\n+      this.restResponseChannel = restResponseChannel;\n+      this.finalCallback = finalCallback;\n+      this.uri = restRequest.getUri();\n+    }\n+\n+    /**\n+     * Start the chain by calling {@link SecurityService#processRequest}.\n+     */\n+    private void start() {\n+      restRequest.getMetricsTracker()\n+          .injectMetrics(frontendMetrics.putBlobMetricsGroup.getRestRequestMetrics(restRequest.isSslUsed(), false));\n+      //?restRequest.setArg(RestUtils.InternalKeys.KEEP_ALIVE_ON_ERROR_HINT, true);\n+      try {\n+        // Start the callback chain by parsing blob info headers and performing request security processing.\n+        BlobInfo blobInfo = getBlobInfoFromRequest();\n+        checkUploadRequirements(blobInfo.getBlobProperties());\n+        securityService.processRequest(restRequest, securityProcessRequestCallback(blobInfo));\n+      } catch (Exception e) {\n+        finalCallback.onCompletion(null, e);\n+      }\n+    }\n+\n+    /**\n+     * Parse {@link BlobInfo} from the request arguments. This method will also ensure that the correct account and\n+     * container objects are attached to the request.\n+     * @return the {@link BlobInfo} parsed from the request arguments.\n+     * @throws RestServiceException if there is an error while parsing the {@link BlobInfo} arguments.\n+     */\n+    private BlobInfo getBlobInfoFromRequest() throws RestServiceException {\n+      long propsBuildStartTime = System.currentTimeMillis();\n+      accountAndContainerInjector.injectAccountAndContainerForPutRequest(restRequest,\n+          frontendMetrics.putBlobMetricsGroup);\n+      BlobProperties blobProperties = RestUtils.buildBlobProperties(restRequest.getArgs());\n+      Container container = RestUtils.getContainerFromArgs(restRequest.getArgs());\n+      if (blobProperties.getTimeToLiveInSeconds() + TimeUnit.MILLISECONDS.toSeconds(\n+          blobProperties.getCreationTimeInMs()) > Integer.MAX_VALUE) {\n+        LOGGER.debug(\"TTL set to very large value in POST request with BlobProperties {}\", blobProperties);\n+        frontendMetrics.ttlTooLargeError.inc();\n+      } else if (container.isTtlRequired() && (blobProperties.getTimeToLiveInSeconds() == Utils.Infinite_Time\n+          || blobProperties.getTimeToLiveInSeconds() > frontendConfig.maxAcceptableTtlSecsIfTtlRequired)) {\n+        String descriptor = RestUtils.getAccountFromArgs(restRequest.getArgs()).getName() + \":\" + container.getName();\n+        if (frontendConfig.failIfTtlRequiredButNotProvided) {\n+          throw new RestServiceException(\n+              \"TTL < \" + frontendConfig.maxAcceptableTtlSecsIfTtlRequired + \" is required for upload to \" + descriptor,\n+              RestServiceErrorCode.InvalidArgs);\n+        } else {\n+          LOGGER.debug(\"{} attempted an upload with ttl {} to {}\", blobProperties.getServiceId(),\n+              blobProperties.getTimeToLiveInSeconds(), descriptor);\n+          frontendMetrics.ttlNotCompliantError.inc();\n+          restResponseChannel.setHeader(RestUtils.Headers.NON_COMPLIANCE_WARNING,\n+              \"TTL < \" + frontendConfig.maxAcceptableTtlSecsIfTtlRequired + \" will be required for future uploads\");\n+        }\n+      }\n+      // inject encryption frontendMetrics if applicable\n+      if (blobProperties.isEncrypted()) {\n+        restRequest.getMetricsTracker()\n+            .injectMetrics(frontendMetrics.postBlobMetricsGroup.getRestRequestMetrics(restRequest.isSslUsed(), true));\n+      }\n+      byte[] userMetadata = RestUtils.buildUserMetadata(restRequest.getArgs());\n+      frontendMetrics.blobPropsBuildTimeInMs.update(System.currentTimeMillis() - propsBuildStartTime);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 192}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQ5Mzc1OA==", "bodyText": "There is a massive amount of code here copied from PostBlobHandler.  Please refactor.", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r525493758", "createdAt": "2020-11-17T20:23:50Z", "author": {"login": "lightningrob"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/PutBlobHandler.java", "diffHunk": "@@ -0,0 +1,405 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.frontend;\n+\n+import com.github.ambry.account.Container;\n+import com.github.ambry.commons.BlobId;\n+import com.github.ambry.commons.Callback;\n+import com.github.ambry.commons.RetainingAsyncWritableChannel;\n+import com.github.ambry.config.FrontendConfig;\n+import com.github.ambry.messageformat.BlobInfo;\n+import com.github.ambry.messageformat.BlobProperties;\n+import com.github.ambry.rest.RequestPath;\n+import com.github.ambry.rest.RestRequest;\n+import com.github.ambry.rest.RestResponseChannel;\n+import com.github.ambry.rest.RestServiceErrorCode;\n+import com.github.ambry.rest.RestServiceException;\n+import com.github.ambry.rest.RestUtils;\n+import com.github.ambry.router.ChunkInfo;\n+import com.github.ambry.router.PutBlobOptions;\n+import com.github.ambry.router.PutBlobOptionsBuilder;\n+import com.github.ambry.router.Router;\n+import com.github.ambry.utils.Pair;\n+import com.github.ambry.utils.Time;\n+import com.github.ambry.utils.Utils;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.json.JSONObject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static com.github.ambry.frontend.FrontendUtils.*;\n+\n+\n+/**\n+ * Handler for put named blob requests. The following request types are handled by {@link PutBlobHandler}:\n+ * <h2>Direct uploads</h2>\n+ * Direct upload requests treat the body of the request as the content to upload to Ambry. The request path should be\n+ * \"/named/account_name/container_name/blob_name\". In these requests, the blob properties and user metadata are supplied as headers. See\n+ * {@link RestUtils#buildBlobProperties(Map)} and {@link RestUtils#buildBlobProperties(Map)} for more details.\n+ * <h2>Stitched uploads</h2>\n+ * Stitched upload requests allow clients to stitch together previously uploaded data chunks into a single logical blob.\n+ * The request path should be \"/named/account_name/container_name/blob_name\", This request accepts the same headers as direct\n+ * upload requests for supplying the blob properties and user metadata of the stitched blob, but, instead of the actual\n+ * blob content, accepts a UTF-8 JSON object that includes the signed IDs for the chunks to stitch, and header x-ambry-put-mode should set as \"STITCH\".\n+ * <h3>Request body format</h3>\n+ * The body of the request should be a JSON object that conforms to the format described in {@link StitchRequestSerDe}.\n+ */\n+public class PutBlobHandler {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 63}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5", "committedDate": "2020-11-11T07:10:02Z", "message": "[named_blobs]Support uploading the named blobs with putBlobHandler"}, "afterCommit": {"oid": "60b8150ecb546d54d971360bea7a915d452cf1a3", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/60b8150ecb546d54d971360bea7a915d452cf1a3", "committedDate": "2020-11-19T01:08:58Z", "message": "[named_blobs]Support uploading the named blobs with putBlobHandler"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "72d45a243717990d971f2b604b0263f95df4ca65", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/72d45a243717990d971f2b604b0263f95df4ca65", "committedDate": "2020-11-19T02:25:47Z", "message": "[named_blobs]Support uploading the named blobs with putBlobHandler"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "60b8150ecb546d54d971360bea7a915d452cf1a3", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/60b8150ecb546d54d971360bea7a915d452cf1a3", "committedDate": "2020-11-19T01:08:58Z", "message": "[named_blobs]Support uploading the named blobs with putBlobHandler"}, "afterCommit": {"oid": "72d45a243717990d971f2b604b0263f95df4ca65", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/72d45a243717990d971f2b604b0263f95df4ca65", "committedDate": "2020-11-19T02:25:47Z", "message": "[named_blobs]Support uploading the named blobs with putBlobHandler"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0dcb17261309026b2a6518565d1c6d5d839b26b3", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/0dcb17261309026b2a6518565d1c6d5d839b26b3", "committedDate": "2020-11-20T01:02:43Z", "message": "Refactor code"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM1MDEwNDA5", "url": "https://github.com/linkedin/ambry/pull/1690#pullrequestreview-535010409", "createdAt": "2020-11-20T01:33:53Z", "commit": {"oid": "0dcb17261309026b2a6518565d1c6d5d839b26b3"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM1ODUxNTA4", "url": "https://github.com/linkedin/ambry/pull/1690#pullrequestreview-535851508", "createdAt": "2020-11-21T00:05:08Z", "commit": {"oid": "0dcb17261309026b2a6518565d1c6d5d839b26b3"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 993, "cost": 1, "resetAt": "2021-11-01T16:19:10Z"}}}