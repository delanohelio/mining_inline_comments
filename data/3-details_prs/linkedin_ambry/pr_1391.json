{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzc3MzI1MDM5", "number": 1391, "title": "Remove getMessageInfo from MessageStoreHardDelete interface", "bodyText": "Remove unnecessary method getMessageInfo from MessageStoreHardDelete interface.\nWhen the log files are not segmented, each delete index entry has a field \"originalMessageOffset\" pointing to the original Put record, so that when fetching content for a deleted blob, we don't have to search the Put record from the index again, we simple read the content from the Put record located by the \"originalMessageOffset\".\nThis is not true after we segmented log files and start compaction. Now a Delete index entry might not have a \"originalMessageOffset\" when the Put entry is not located in the same segment as the delete entry, so we have to search the Put entry from the index again not matter what. This totally obsolete the \"originalMessageOffset\" and thus the logic to read the content from the \"origianlMessageOffset\".", "createdAt": "2020-02-19T18:35:10Z", "url": "https://github.com/linkedin/ambry/pull/1391", "merged": true, "mergeCommit": {"oid": "d51742f6f4f13a455d68b12b0c1cc448850c85c3"}, "closed": true, "closedAt": "2020-02-27T01:30:59Z", "author": {"login": "justinlin-linkedin"}, "timelineItems": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcHhw02gFqTM2MzU5NTUwMQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcIRBBrgFqTM2NTM2MDE1Nw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzYzNTk1NTAx", "url": "https://github.com/linkedin/ambry/pull/1391#pullrequestreview-363595501", "createdAt": "2020-02-24T18:13:36Z", "commit": {"oid": "bfffc3b67916d597093580b47026c278f9bce760"}, "state": "APPROVED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQxODoxMzozNlrOFtqqxQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQxODoxODo1MVrOFtq0ZQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQyOTMxNw==", "bodyText": "isFlagSet -> isTTLUpdate", "url": "https://github.com/linkedin/ambry/pull/1391#discussion_r383429317", "createdAt": "2020-02-24T18:13:36Z", "author": {"login": "jsjtzyy"}, "path": "ambry-store/src/main/java/com.github.ambry.store/PersistentIndex.java", "diffHunk": "@@ -1055,57 +1055,20 @@ BlobReadOptions getBlobReadInfo(StoreKey id, EnumSet<StoreGetOptions> getOptions\n   private BlobReadOptions getDeletedBlobReadOptions(IndexValue value, StoreKey key,\n       ConcurrentSkipListMap<Offset, IndexSegment> indexSegments) throws StoreException {\n     BlobReadOptions readOptions;\n-    try {\n-      IndexValue putValue =\n-          findKey(key, new FileSpan(getStartOffset(indexSegments), value.getOffset()), EnumSet.of(IndexEntryType.PUT),\n-              indexSegments);\n-      if (value.getOriginalMessageOffset() != IndexValue.UNKNOWN_ORIGINAL_MESSAGE_OFFSET\n-          && value.getOriginalMessageOffset() != value.getOffset().getOffset()) {\n-        // PUT record in the same log segment.\n-        String logSegmentName = value.getOffset().getName();\n-        // The delete entry in the index might not contain the information about the size of the original blob. So we\n-        // use the Message format to read and provide the information. The range in log that we provide starts at the\n-        // original message offset and ends at the delete message's start offset (the original message surely cannot go\n-        // beyond the start offset of the delete message).\n-        MessageInfo deletedBlobInfo =\n-            hardDelete.getMessageInfo(log.getSegment(logSegmentName), value.getOriginalMessageOffset(), factory);\n-        if (putValue != null && putValue.getOffset().getName().equals(value.getOffset().getName())) {\n-          if (putValue.getOffset().getOffset() != value.getOriginalMessageOffset()) {\n-            logger.error(\n-                \"Offset in PUT index entry {} is different from original message offset in delete entry {} for key {}\",\n-                putValue.getOffset().getOffset(), value.getOriginalMessageOffset(), key);\n-            metrics.putEntryDeletedInfoMismatchCount.inc();\n-          }\n-          if (putValue.getSize() != deletedBlobInfo.getSize()) {\n-            logger.error(\"Size in PUT index entry {} is different from that in the PUT record {} for ID {}\",\n-                putValue.getSize(), deletedBlobInfo.getSize(), key);\n-            metrics.putEntryDeletedInfoMismatchCount.inc();\n-          }\n-        }\n-        Offset offset = new Offset(logSegmentName, value.getOriginalMessageOffset());\n-        // use the expiration time from the original value because it may have been updated\n-        readOptions = new BlobReadOptions(log, offset,\n-            new MessageInfo(deletedBlobInfo.getStoreKey(), deletedBlobInfo.getSize(), true,\n-                value.isFlagSet(IndexValue.Flags.Ttl_Update_Index), value.getExpiresAtMs(),\n-                deletedBlobInfo.getAccountId(), deletedBlobInfo.getContainerId(),\n-                deletedBlobInfo.getOperationTimeMs()));\n-      } else if (putValue != null) {\n-        // PUT record in a different log segment.\n-        // use the expiration time from the original value because it may have been updated\n-        readOptions = new BlobReadOptions(log, putValue.getOffset(),\n-            new MessageInfo(key, putValue.getSize(), true, value.isFlagSet(IndexValue.Flags.Ttl_Update_Index),\n-                value.getExpiresAtMs(), putValue.getAccountId(), putValue.getContainerId(),\n-                putValue.getOperationTimeInMs()));\n-      } else {\n-        // PUT record no longer available.\n-        throw new StoreException(\"Did not find PUT index entry for key [\" + key\n-            + \"] and the the original offset in value of the DELETE entry was [\" + value.getOriginalMessageOffset()\n-            + \"]\", StoreErrorCodes.ID_Deleted);\n-      }\n-    } catch (IOException e) {\n-      StoreErrorCodes errorCode = StoreException.resolveErrorCode(e);\n-      throw new StoreException(errorCode.toString() + \" when reading delete blob info from the log \" + dataDir, e,\n-          errorCode);\n+    IndexValue putValue =\n+        findKey(key, new FileSpan(getStartOffset(indexSegments), value.getOffset()), EnumSet.of(IndexEntryType.PUT),\n+            indexSegments);\n+    if (putValue != null) {\n+      // use the expiration time from the original value because it may have been updated\n+      readOptions = new BlobReadOptions(log, putValue.getOffset(),\n+          new MessageInfo(key, putValue.getSize(), true, value.isFlagSet(IndexValue.Flags.Ttl_Update_Index),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bfffc3b67916d597093580b47026c278f9bce760"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQzMTA3Ng==", "bodyText": "also, this metric can be deleted from StoreMetrics", "url": "https://github.com/linkedin/ambry/pull/1391#discussion_r383431076", "createdAt": "2020-02-24T18:17:19Z", "author": {"login": "jsjtzyy"}, "path": "ambry-store/src/main/java/com.github.ambry.store/PersistentIndex.java", "diffHunk": "@@ -1055,57 +1055,20 @@ BlobReadOptions getBlobReadInfo(StoreKey id, EnumSet<StoreGetOptions> getOptions\n   private BlobReadOptions getDeletedBlobReadOptions(IndexValue value, StoreKey key,\n       ConcurrentSkipListMap<Offset, IndexSegment> indexSegments) throws StoreException {\n     BlobReadOptions readOptions;\n-    try {\n-      IndexValue putValue =\n-          findKey(key, new FileSpan(getStartOffset(indexSegments), value.getOffset()), EnumSet.of(IndexEntryType.PUT),\n-              indexSegments);\n-      if (value.getOriginalMessageOffset() != IndexValue.UNKNOWN_ORIGINAL_MESSAGE_OFFSET\n-          && value.getOriginalMessageOffset() != value.getOffset().getOffset()) {\n-        // PUT record in the same log segment.\n-        String logSegmentName = value.getOffset().getName();\n-        // The delete entry in the index might not contain the information about the size of the original blob. So we\n-        // use the Message format to read and provide the information. The range in log that we provide starts at the\n-        // original message offset and ends at the delete message's start offset (the original message surely cannot go\n-        // beyond the start offset of the delete message).\n-        MessageInfo deletedBlobInfo =\n-            hardDelete.getMessageInfo(log.getSegment(logSegmentName), value.getOriginalMessageOffset(), factory);\n-        if (putValue != null && putValue.getOffset().getName().equals(value.getOffset().getName())) {\n-          if (putValue.getOffset().getOffset() != value.getOriginalMessageOffset()) {\n-            logger.error(\n-                \"Offset in PUT index entry {} is different from original message offset in delete entry {} for key {}\",\n-                putValue.getOffset().getOffset(), value.getOriginalMessageOffset(), key);\n-            metrics.putEntryDeletedInfoMismatchCount.inc();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bfffc3b67916d597093580b47026c278f9bce760"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQzMTc4MQ==", "bodyText": "I wonder why the error code is ID_Deleted rather than ID_Not_Found?", "url": "https://github.com/linkedin/ambry/pull/1391#discussion_r383431781", "createdAt": "2020-02-24T18:18:51Z", "author": {"login": "jsjtzyy"}, "path": "ambry-store/src/main/java/com.github.ambry.store/PersistentIndex.java", "diffHunk": "@@ -1055,57 +1055,20 @@ BlobReadOptions getBlobReadInfo(StoreKey id, EnumSet<StoreGetOptions> getOptions\n   private BlobReadOptions getDeletedBlobReadOptions(IndexValue value, StoreKey key,\n       ConcurrentSkipListMap<Offset, IndexSegment> indexSegments) throws StoreException {\n     BlobReadOptions readOptions;\n-    try {\n-      IndexValue putValue =\n-          findKey(key, new FileSpan(getStartOffset(indexSegments), value.getOffset()), EnumSet.of(IndexEntryType.PUT),\n-              indexSegments);\n-      if (value.getOriginalMessageOffset() != IndexValue.UNKNOWN_ORIGINAL_MESSAGE_OFFSET\n-          && value.getOriginalMessageOffset() != value.getOffset().getOffset()) {\n-        // PUT record in the same log segment.\n-        String logSegmentName = value.getOffset().getName();\n-        // The delete entry in the index might not contain the information about the size of the original blob. So we\n-        // use the Message format to read and provide the information. The range in log that we provide starts at the\n-        // original message offset and ends at the delete message's start offset (the original message surely cannot go\n-        // beyond the start offset of the delete message).\n-        MessageInfo deletedBlobInfo =\n-            hardDelete.getMessageInfo(log.getSegment(logSegmentName), value.getOriginalMessageOffset(), factory);\n-        if (putValue != null && putValue.getOffset().getName().equals(value.getOffset().getName())) {\n-          if (putValue.getOffset().getOffset() != value.getOriginalMessageOffset()) {\n-            logger.error(\n-                \"Offset in PUT index entry {} is different from original message offset in delete entry {} for key {}\",\n-                putValue.getOffset().getOffset(), value.getOriginalMessageOffset(), key);\n-            metrics.putEntryDeletedInfoMismatchCount.inc();\n-          }\n-          if (putValue.getSize() != deletedBlobInfo.getSize()) {\n-            logger.error(\"Size in PUT index entry {} is different from that in the PUT record {} for ID {}\",\n-                putValue.getSize(), deletedBlobInfo.getSize(), key);\n-            metrics.putEntryDeletedInfoMismatchCount.inc();\n-          }\n-        }\n-        Offset offset = new Offset(logSegmentName, value.getOriginalMessageOffset());\n-        // use the expiration time from the original value because it may have been updated\n-        readOptions = new BlobReadOptions(log, offset,\n-            new MessageInfo(deletedBlobInfo.getStoreKey(), deletedBlobInfo.getSize(), true,\n-                value.isFlagSet(IndexValue.Flags.Ttl_Update_Index), value.getExpiresAtMs(),\n-                deletedBlobInfo.getAccountId(), deletedBlobInfo.getContainerId(),\n-                deletedBlobInfo.getOperationTimeMs()));\n-      } else if (putValue != null) {\n-        // PUT record in a different log segment.\n-        // use the expiration time from the original value because it may have been updated\n-        readOptions = new BlobReadOptions(log, putValue.getOffset(),\n-            new MessageInfo(key, putValue.getSize(), true, value.isFlagSet(IndexValue.Flags.Ttl_Update_Index),\n-                value.getExpiresAtMs(), putValue.getAccountId(), putValue.getContainerId(),\n-                putValue.getOperationTimeInMs()));\n-      } else {\n-        // PUT record no longer available.\n-        throw new StoreException(\"Did not find PUT index entry for key [\" + key\n-            + \"] and the the original offset in value of the DELETE entry was [\" + value.getOriginalMessageOffset()\n-            + \"]\", StoreErrorCodes.ID_Deleted);\n-      }\n-    } catch (IOException e) {\n-      StoreErrorCodes errorCode = StoreException.resolveErrorCode(e);\n-      throw new StoreException(errorCode.toString() + \" when reading delete blob info from the log \" + dataDir, e,\n-          errorCode);\n+    IndexValue putValue =\n+        findKey(key, new FileSpan(getStartOffset(indexSegments), value.getOffset()), EnumSet.of(IndexEntryType.PUT),\n+            indexSegments);\n+    if (putValue != null) {\n+      // use the expiration time from the original value because it may have been updated\n+      readOptions = new BlobReadOptions(log, putValue.getOffset(),\n+          new MessageInfo(key, putValue.getSize(), true, value.isFlagSet(IndexValue.Flags.Ttl_Update_Index),\n+              value.getExpiresAtMs(), putValue.getAccountId(), putValue.getContainerId(),\n+              putValue.getOperationTimeInMs()));\n+    } else {\n+      // PUT record no longer available.\n+      throw new StoreException(\"Did not find PUT index entry for key [\" + key\n+          + \"] and the the original offset in value of the DELETE entry was [\" + value.getOriginalMessageOffset() + \"]\",\n+          StoreErrorCodes.ID_Deleted);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bfffc3b67916d597093580b47026c278f9bce760"}, "originalPosition": 68}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "11ef2d46fccfdfc40b6f27961be36cbb96b6d925", "author": {"user": {"login": "justinlin-linkedin", "name": "Justin Lin"}}, "url": "https://github.com/linkedin/ambry/commit/11ef2d46fccfdfc40b6f27961be36cbb96b6d925", "committedDate": "2020-02-24T21:48:54Z", "message": "Remove getMessageInfo from MessageStoreHardDelete interface"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5df0bd6e4f4d6d58b6620a9e9c646aa09a569aa9", "author": {"user": {"login": "justinlin-linkedin", "name": "Justin Lin"}}, "url": "https://github.com/linkedin/ambry/commit/5df0bd6e4f4d6d58b6620a9e9c646aa09a569aa9", "committedDate": "2020-02-24T21:53:35Z", "message": "Yingyi comemnts"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "bfffc3b67916d597093580b47026c278f9bce760", "author": {"user": {"login": "justinlin-linkedin", "name": "Justin Lin"}}, "url": "https://github.com/linkedin/ambry/commit/bfffc3b67916d597093580b47026c278f9bce760", "committedDate": "2020-02-19T18:29:35Z", "message": "Remove getMessageInfo from MessageStoreHardDelete interface"}, "afterCommit": {"oid": "5df0bd6e4f4d6d58b6620a9e9c646aa09a569aa9", "author": {"user": {"login": "justinlin-linkedin", "name": "Justin Lin"}}, "url": "https://github.com/linkedin/ambry/commit/5df0bd6e4f4d6d58b6620a9e9c646aa09a569aa9", "committedDate": "2020-02-24T21:53:35Z", "message": "Yingyi comemnts"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY1MzYwMTU3", "url": "https://github.com/linkedin/ambry/pull/1391#pullrequestreview-365360157", "createdAt": "2020-02-27T01:26:59Z", "commit": {"oid": "5df0bd6e4f4d6d58b6620a9e9c646aa09a569aa9"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1629, "cost": 1, "resetAt": "2021-11-01T16:19:10Z"}}}