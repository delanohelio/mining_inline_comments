{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDM2MTU4NDc0", "number": 1570, "title": "Change sanity check logic for undelete so recovery can work", "bodyText": "There are several changes to this PR\n\nUndelete will no longer check if the blob is expired for replication\nUndelete will now take a MessageInfo as argument in recovery, and will only use info to construct an index value, without any sanity checking.\ncopyRecords in compaction will not use markAsUndelete to check sanity, instead it will have it's own sanity check.\n\nThis would fix certain recovery and replication corner cases.\nCase 1. We have P, D, U, T for a blob. The PUT has a short ttl, so we need the last TTL_UPDATE to make it permanent. When the whole index files are gone and we are reconstructing index from log segments, we would fail on U since the P is expired in recovery. This PR would fix that.\nCase 2. We have P, D, U, D for a blob. The compaction compacts Put and first DELETE, (UNDELETE and second DELETE are in a different segment, which is not under compaction). Then we only have U and D after compaction. When the whole index files are gone and we are reconstructing index from log, we would fail on U since there is nothing prior to it. This PR would fix that.\nCase 3. We have P, D in local, and the remote has P, D, U, T. Somehow local stops for a while until P is expired. When restarting local process, it starts replicating from remote. And it will fail on applying U, since P is expired. This PR would fix that.", "createdAt": "2020-06-18T00:16:18Z", "url": "https://github.com/linkedin/ambry/pull/1570", "merged": true, "mergeCommit": {"oid": "2ab23172f04cc03efa26384db24ed66f69f48359"}, "closed": true, "closedAt": "2020-06-18T23:56:12Z", "author": {"login": "justinlin-linkedin"}, "timelineItems": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcsgazHgH2gAyNDM2MTU4NDc0OmI4ZGUxN2YzNWM1Mzc5YTVhNGY5ZmU2ZjM0NDZkZDY2M2MyN2E3ODc=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcsm5FxAFqTQzMzcwNzA0NQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "b8de17f35c5379a5a4f9fe6f3446dd663c27a787", "author": {"user": {"login": "justinlin-linkedin", "name": "Justin Lin"}}, "url": "https://github.com/linkedin/ambry/commit/b8de17f35c5379a5a4f9fe6f3446dd663c27a787", "committedDate": "2020-06-18T15:44:59Z", "message": "Change sanity check logic for undelete"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "854067eac86b6cac7d60499c195054f105d310a7", "author": {"user": {"login": "justinlin-linkedin", "name": "Justin Lin"}}, "url": "https://github.com/linkedin/ambry/commit/854067eac86b6cac7d60499c195054f105d310a7", "committedDate": "2020-06-18T15:44:59Z", "message": "Add more test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "efe7a2bc4ae8c922a640a1bf2479752b816ceff8", "author": {"user": {"login": "justinlin-linkedin", "name": "Justin Lin"}}, "url": "https://github.com/linkedin/ambry/commit/efe7a2bc4ae8c922a640a1bf2479752b816ceff8", "committedDate": "2020-06-18T15:44:59Z", "message": "typo"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "54e37b00f018131c6154d5262103c70b47fdd59d", "author": {"user": {"login": "justinlin-linkedin", "name": "Justin Lin"}}, "url": "https://github.com/linkedin/ambry/commit/54e37b00f018131c6154d5262103c70b47fdd59d", "committedDate": "2020-06-18T15:44:59Z", "message": "Fix the test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "62ccc8693af1daff936bc398c25a08fa2f3fe523", "author": {"user": {"login": "justinlin-linkedin", "name": "Justin Lin"}}, "url": "https://github.com/linkedin/ambry/commit/62ccc8693af1daff936bc398c25a08fa2f3fe523", "committedDate": "2020-06-18T17:02:40Z", "message": "Rearrange"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ccc95b2af5c39d24437cf5c726846ecdd930c768", "author": {"user": {"login": "justinlin-linkedin", "name": "Justin Lin"}}, "url": "https://github.com/linkedin/ambry/commit/ccc95b2af5c39d24437cf5c726846ecdd930c768", "committedDate": "2020-06-18T04:01:18Z", "message": "Fix the test"}, "afterCommit": {"oid": "62ccc8693af1daff936bc398c25a08fa2f3fe523", "author": {"user": {"login": "justinlin-linkedin", "name": "Justin Lin"}}, "url": "https://github.com/linkedin/ambry/commit/62ccc8693af1daff936bc398c25a08fa2f3fe523", "committedDate": "2020-06-18T17:02:40Z", "message": "Rearrange"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMzNTI0NTUx", "url": "https://github.com/linkedin/ambry/pull/1570#pullrequestreview-433524551", "createdAt": "2020-06-18T18:03:24Z", "commit": {"oid": "62ccc8693af1daff936bc398c25a08fa2f3fe523"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQxODowMzoyNVrOGl6cPg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQxODowMzoyNVrOGl6cPg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQwNzk5OA==", "bodyText": "In this case, we still recovery Undelete index, but P can't be accessed, right?", "url": "https://github.com/linkedin/ambry/pull/1570#discussion_r442407998", "createdAt": "2020-06-18T18:03:25Z", "author": {"login": "zzmao"}, "path": "ambry-store/src/main/java/com/github/ambry/store/PersistentIndex.java", "diffHunk": "@@ -980,35 +964,54 @@ IndexValue markAsPermanent(StoreKey id, FileSpan fileSpan, MessageInfo info, lon\n    * @throws StoreException if there is any problem writing the index record\n    */\n   IndexValue markAsUndeleted(StoreKey id, FileSpan fileSpan, long operationTimeMs) throws StoreException {\n-    return markAsUndeleted(id, fileSpan, operationTimeMs, MessageInfo.LIFE_VERSION_FROM_FRONTEND);\n+    return markAsUndeleted(id, fileSpan, null, operationTimeMs, MessageInfo.LIFE_VERSION_FROM_FRONTEND);\n   }\n \n   /**\n    * Marks a blob as undeleted\n    * @param id the {@link StoreKey} of the blob\n    * @param fileSpan the file span represented by this entry in the log\n    * @param operationTimeMs the time of the update operation\n+   * @param info this needs to be non-null in the case of recovery and replicateion. Can be {@code null} otherwise. Used if the PUT\n+   *             record could not be found\n    * @param lifeVersion lifeVersion of this undelete record.\n    * @return the {@link IndexValue} of the undelete record\n    * @throws StoreException if there is any problem writing the index record\n    */\n-  IndexValue markAsUndeleted(StoreKey id, FileSpan fileSpan, long operationTimeMs, short lifeVersion)\n+  IndexValue markAsUndeleted(StoreKey id, FileSpan fileSpan, MessageInfo info, long operationTimeMs, short lifeVersion)\n       throws StoreException {\n     boolean hasLifeVersion = IndexValue.hasLifeVersion(lifeVersion);\n     validateFileSpan(fileSpan, true);\n+    long size = fileSpan.getEndOffset().getOffset() - fileSpan.getStartOffset().getOffset();\n     List<IndexValue> values =\n         findAllIndexValuesForKey(id, null, EnumSet.allOf(IndexEntryType.class), validIndexSegments);\n-    validateSanityForUndelete(id, values, lifeVersion);\n-    // This value is the delete IndexValue\n-    IndexValue value = values.get(0);\n-    maybeChangeExpirationDate(value, values);\n-    lifeVersion = hasLifeVersion ? lifeVersion : (short) (value.getLifeVersion() + 1);\n-    long size = fileSpan.getEndOffset().getOffset() - fileSpan.getStartOffset().getOffset();\n-    IndexValue newValue =\n-        new IndexValue(value.getSize(), value.getOffset(), value.getFlags(), value.getExpiresAtMs(), operationTimeMs,\n-            value.getAccountId(), value.getContainerId(), lifeVersion);\n-    newValue.setNewOffset(fileSpan.getStartOffset());\n-    newValue.setNewSize(size);\n+    IndexValue newValue;\n+    if (info != null) {\n+      // This is from recovery. In recovery, we don't need to do any sanity check because\n+      // 1. we already know the IndexValue has it's source in the log.\n+      // 2. some sanity check will fail.\n+      //    assume we have P, D, U, D in the log, then a compaction cycle compacted P and first D,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62ccc8693af1daff936bc398c25a08fa2f3fe523"}, "originalPosition": 184}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMzNjYxODI4", "url": "https://github.com/linkedin/ambry/pull/1570#pullrequestreview-433661828", "createdAt": "2020-06-18T21:31:01Z", "commit": {"oid": "62ccc8693af1daff936bc398c25a08fa2f3fe523"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMzNTQ2OTgw", "url": "https://github.com/linkedin/ambry/pull/1570#pullrequestreview-433546980", "createdAt": "2020-06-18T18:35:21Z", "commit": {"oid": "62ccc8693af1daff936bc398c25a08fa2f3fe523"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQxODozNToyMlrOGl7f1A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQyMjo1NTowOVrOGmCvEA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQyNTMwMA==", "bodyText": "typo: replication", "url": "https://github.com/linkedin/ambry/pull/1570#discussion_r442425300", "createdAt": "2020-06-18T18:35:22Z", "author": {"login": "jsjtzyy"}, "path": "ambry-store/src/main/java/com/github/ambry/store/PersistentIndex.java", "diffHunk": "@@ -980,35 +964,54 @@ IndexValue markAsPermanent(StoreKey id, FileSpan fileSpan, MessageInfo info, lon\n    * @throws StoreException if there is any problem writing the index record\n    */\n   IndexValue markAsUndeleted(StoreKey id, FileSpan fileSpan, long operationTimeMs) throws StoreException {\n-    return markAsUndeleted(id, fileSpan, operationTimeMs, MessageInfo.LIFE_VERSION_FROM_FRONTEND);\n+    return markAsUndeleted(id, fileSpan, null, operationTimeMs, MessageInfo.LIFE_VERSION_FROM_FRONTEND);\n   }\n \n   /**\n    * Marks a blob as undeleted\n    * @param id the {@link StoreKey} of the blob\n    * @param fileSpan the file span represented by this entry in the log\n    * @param operationTimeMs the time of the update operation\n+   * @param info this needs to be non-null in the case of recovery and replicateion. Can be {@code null} otherwise. Used if the PUT", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62ccc8693af1daff936bc398c25a08fa2f3fe523"}, "originalPosition": 154}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjUyMDg2Nw==", "bodyText": "minor: this can be more descriptive like invalid lifeVersion -1 (although I know this exception should not happen in practice)", "url": "https://github.com/linkedin/ambry/pull/1570#discussion_r442520867", "createdAt": "2020-06-18T21:47:45Z", "author": {"login": "jsjtzyy"}, "path": "ambry-store/src/main/java/com/github/ambry/store/PersistentIndex.java", "diffHunk": "@@ -980,35 +964,54 @@ IndexValue markAsPermanent(StoreKey id, FileSpan fileSpan, MessageInfo info, lon\n    * @throws StoreException if there is any problem writing the index record\n    */\n   IndexValue markAsUndeleted(StoreKey id, FileSpan fileSpan, long operationTimeMs) throws StoreException {\n-    return markAsUndeleted(id, fileSpan, operationTimeMs, MessageInfo.LIFE_VERSION_FROM_FRONTEND);\n+    return markAsUndeleted(id, fileSpan, null, operationTimeMs, MessageInfo.LIFE_VERSION_FROM_FRONTEND);\n   }\n \n   /**\n    * Marks a blob as undeleted\n    * @param id the {@link StoreKey} of the blob\n    * @param fileSpan the file span represented by this entry in the log\n    * @param operationTimeMs the time of the update operation\n+   * @param info this needs to be non-null in the case of recovery and replicateion. Can be {@code null} otherwise. Used if the PUT\n+   *             record could not be found\n    * @param lifeVersion lifeVersion of this undelete record.\n    * @return the {@link IndexValue} of the undelete record\n    * @throws StoreException if there is any problem writing the index record\n    */\n-  IndexValue markAsUndeleted(StoreKey id, FileSpan fileSpan, long operationTimeMs, short lifeVersion)\n+  IndexValue markAsUndeleted(StoreKey id, FileSpan fileSpan, MessageInfo info, long operationTimeMs, short lifeVersion)\n       throws StoreException {\n     boolean hasLifeVersion = IndexValue.hasLifeVersion(lifeVersion);\n     validateFileSpan(fileSpan, true);\n+    long size = fileSpan.getEndOffset().getOffset() - fileSpan.getStartOffset().getOffset();\n     List<IndexValue> values =\n         findAllIndexValuesForKey(id, null, EnumSet.allOf(IndexEntryType.class), validIndexSegments);\n-    validateSanityForUndelete(id, values, lifeVersion);\n-    // This value is the delete IndexValue\n-    IndexValue value = values.get(0);\n-    maybeChangeExpirationDate(value, values);\n-    lifeVersion = hasLifeVersion ? lifeVersion : (short) (value.getLifeVersion() + 1);\n-    long size = fileSpan.getEndOffset().getOffset() - fileSpan.getStartOffset().getOffset();\n-    IndexValue newValue =\n-        new IndexValue(value.getSize(), value.getOffset(), value.getFlags(), value.getExpiresAtMs(), operationTimeMs,\n-            value.getAccountId(), value.getContainerId(), lifeVersion);\n-    newValue.setNewOffset(fileSpan.getStartOffset());\n-    newValue.setNewSize(size);\n+    IndexValue newValue;\n+    if (info != null) {\n+      // This is from recovery. In recovery, we don't need to do any sanity check because\n+      // 1. we already know the IndexValue has it's source in the log.\n+      // 2. some sanity check will fail.\n+      //    assume we have P, D, U, D in the log, then a compaction cycle compacted P and first D,\n+      //    then we only have U and second D. U in this case, will have no prior records.\n+      if (!hasLifeVersion) {\n+        throw new StoreException(\"MessageInfo of undelete carries invalid lifeVersion\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62ccc8693af1daff936bc398c25a08fa2f3fe523"}, "originalPosition": 187}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjUyNDUyNA==", "bodyText": "add a comment here to help understanding the context", "url": "https://github.com/linkedin/ambry/pull/1570#discussion_r442524524", "createdAt": "2020-06-18T21:57:12Z", "author": {"login": "jsjtzyy"}, "path": "ambry-store/src/main/java/com/github/ambry/store/PersistentIndex.java", "diffHunk": "@@ -324,15 +324,13 @@ private void recover(MessageStoreRecovery recovery) throws StoreException, IOExc\n           // removes from the tracking structure if a delete was being expected for the key\n           deleteExpectedKeys.remove(info.getStoreKey());\n         } else if (info.isUndeleted()) {\n-          markAsUndeleted(info.getStoreKey(), new FileSpan(runningOffset, infoEndOffset), info.getOperationTimeMs(),\n-              info.getLifeVersion());\n+          markAsUndeleted(info.getStoreKey(), new FileSpan(runningOffset, infoEndOffset), info,\n+              info.getOperationTimeMs(), info.getLifeVersion());\n           logger.info(\n               \"Index : {} updated message with key {} by inserting undelete entry of size {} ttl {} lifeVersion {}\",\n               dataDir, info.getStoreKey(), info.getSize(), info.getExpirationTimeInMs(), info.getLifeVersion());\n           if (value == null) {\n-            // Undelete record indicates that a put and/or a delete record were expected.\n-            throw new StoreException(\"Put record were expected but were not encountered for key: \" + info.getStoreKey(),\n-                StoreErrorCodes.Initialization_Error);\n+            deleteExpectedKeys.add(info.getStoreKey());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62ccc8693af1daff936bc398c25a08fa2f3fe523"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjUzOTAyOA==", "bodyText": "remove -> remote", "url": "https://github.com/linkedin/ambry/pull/1570#discussion_r442539028", "createdAt": "2020-06-18T22:39:21Z", "author": {"login": "jsjtzyy"}, "path": "ambry-store/src/main/java/com/github/ambry/store/PersistentIndex.java", "diffHunk": "@@ -722,15 +720,22 @@ private IndexValue findKey(StoreKey key, FileSpan fileSpan, EnumSet<IndexEntryTy\n    */\n   void validateSanityForUndelete(StoreKey key, List<IndexValue> values, short lifeVersion) throws StoreException {\n     if (values == null || values.isEmpty()) {\n-      throw new StoreException(\"Id \" + key + \" not present in index \" + dataDir, StoreErrorCodes.ID_Not_Found);\n+      throw new StoreException(\"Id \" + key + \" not found in \" + dataDir, StoreErrorCodes.ID_Not_Found);\n     }\n     if (!IndexValue.hasLifeVersion(lifeVersion)) {\n       validateSanityForUndeleteWithoutLifeVersion(key, values);\n       return;\n     }\n-    // This is from recovery or replication, make sure the last value is a put and the first value's lifeVersion is strictly\n-    // less than the given lifeVersion. We don't care about the first value's type, it can be a put, ttl_update or delete, it\n-    // can even be an undelete.\n+    // This is from replication. For replication, undelete should be permitted only when\n+    // 1. The oldest record is PUT\n+    // 2. the latest record's lifeVersion is less then undelete's lifeVersion.\n+    // 3. Replication doesn't care if the latest record is delete or not. In local, we can have a PUT record when\n+    // the remote has PUT, DELETE, UNDELETE. When replicating from remote, local has to insert UNDELETE, where\n+    // there is no prior DELETE.\n+    // 4. Replication doesn't care if the latest record is expired or not. In local, we can have a PUT record when\n+    // the remove has PUT, DELETE, UNDELETE TTL_UPDATE. When replicating from remote, PUT might already have expired.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62ccc8693af1daff936bc398c25a08fa2f3fe523"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjU0MTI3NA==", "bodyText": "This is only used for testing, right?  (Also format the file please)", "url": "https://github.com/linkedin/ambry/pull/1570#discussion_r442541274", "createdAt": "2020-06-18T22:46:18Z", "author": {"login": "jsjtzyy"}, "path": "ambry-store/src/main/java/com/github/ambry/store/IndexValue.java", "diffHunk": "@@ -362,6 +362,14 @@ void setNewOffset(Offset newOffset) {\n     setOriginalMessageOffset(oldOffset);\n   }\n \n+  /**\n+   * Updates the {@link #lifeVersion} of this {@link IndexValue}.\n+   * @param lifeVersion the new lifeVersion to set.\n+   */\n+  void setNewLifeVersion(short lifeVersion) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62ccc8693af1daff936bc398c25a08fa2f3fe523"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjU0Mzg4OA==", "bodyText": "Looks like if valueFromTgtIdx != null, we only check version and undelete state, and we still add a new index entry to tgtIndex?", "url": "https://github.com/linkedin/ambry/pull/1570#discussion_r442543888", "createdAt": "2020-06-18T22:55:09Z", "author": {"login": "jsjtzyy"}, "path": "ambry-store/src/main/java/com/github/ambry/store/BlobStoreCompactor.java", "diffHunk": "@@ -767,16 +768,27 @@ private boolean copyRecords(LogSegment logSegmentToCopy, List<IndexEntry> srcInd\n               }\n             } else if (srcValue.isUndelete()) {\n               if (valueFromTgtIdx != null) {\n-                tgtIndex.markAsUndeleted(srcIndexEntry.getKey(), fileSpan, srcValue.getOperationTimeInMs(),\n-                    srcValue.getLifeVersion());\n-              } else {\n-                IndexValue tgtValue = new IndexValue(srcValue.getSize(), fileSpan.getStartOffset(), srcValue.getFlags(),\n-                    srcValue.getExpiresAtMs(), srcValue.getOperationTimeInMs(), srcValue.getAccountId(),\n-                    srcValue.getContainerId(), srcValue.getLifeVersion());\n-                tgtValue.setFlag(IndexValue.Flags.Undelete_Index);\n-                tgtValue.clearOriginalMessageOffset();\n-                tgtIndex.addToIndex(new IndexEntry(srcIndexEntry.getKey(), tgtValue), fileSpan);\n+                // Here don't use markAsUndelete method. In markAsUndelete, multiple sanity check would be applied. But\n+                // target index might only contain incomplete blob history, which would fail sanity check.\n+                // Here we do a different check to make sure we don't insert undelete with lower lifeVersion.\n+                if (valueFromTgtIdx.isUndelete()) {\n+                  throw new StoreException(\n+                      \"Id \" + srcIndexEntry.getKey() + \" already has undelete \" + valueFromTgtIdx + \" in index \"\n+                          + dataDir, StoreErrorCodes.ID_Undeleted);\n+                }\n+                // Undelete would increase the life version\n+                if (valueFromTgtIdx.getLifeVersion() >= srcValue.getLifeVersion()) {\n+                  throw new StoreException(\n+                      \"Id \" + srcIndexEntry.getKey() + \" has bad lifeversion \" + valueFromTgtIdx + \" in index \"\n+                          + dataDir, StoreErrorCodes.Life_Version_Conflict);\n+                }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62ccc8693af1daff936bc398c25a08fa2f3fe523"}, "originalPosition": 63}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "22a2d1d93faf82c7c44829f24f5164d1be7af185", "author": {"user": {"login": "justinlin-linkedin", "name": "Justin Lin"}}, "url": "https://github.com/linkedin/ambry/commit/22a2d1d93faf82c7c44829f24f5164d1be7af185", "committedDate": "2020-06-18T23:08:50Z", "message": "Address comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMzNzA3MDQ1", "url": "https://github.com/linkedin/ambry/pull/1570#pullrequestreview-433707045", "createdAt": "2020-06-18T23:17:30Z", "commit": {"oid": "22a2d1d93faf82c7c44829f24f5164d1be7af185"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1150, "cost": 1, "resetAt": "2021-11-01T16:19:10Z"}}}