{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDk4MTEzMTU3", "number": 1646, "title": "[CLOUD_CONTAINER_DELETION] Core logic for container compaction", "bodyText": "Container deletion logic in cloud.", "createdAt": "2020-10-05T20:56:28Z", "url": "https://github.com/linkedin/ambry/pull/1646", "merged": true, "mergeCommit": {"oid": "ba801c31c5b9b2fd02bd700d6e1ba8e5a41c3d26"}, "closed": true, "closedAt": "2020-11-24T19:36:42Z", "author": {"login": "ankagrawal"}, "timelineItems": {"totalCount": 37, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdS3y4zABqjM4ODM0NDI0MTY=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdfuz8-AFqTUzNzgzMjc1Mg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c7a071124e4a26acb2d6640e0ad65ab37f49aa85", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/c7a071124e4a26acb2d6640e0ad65ab37f49aa85", "committedDate": "2020-10-06T18:25:40Z", "message": "Production code for container compaction."}, "afterCommit": {"oid": "72e3f583cf2343b2b156220843caf01456f4819f", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/72e3f583cf2343b2b156220843caf01456f4819f", "committedDate": "2020-10-15T20:24:21Z", "message": "Production code for container compaction."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "56735bb4e273bac8e8b5aade268133f92ce5212b", "author": {"user": {"login": "ankagrawal", "name": "Ankur Agrawal"}}, "url": "https://github.com/linkedin/ambry/commit/56735bb4e273bac8e8b5aade268133f92ce5212b", "committedDate": "2020-10-16T01:00:50Z", "message": "Add logic to trigger container compaction in cloud."}, "afterCommit": {"oid": "3874f5adc6f3ecb7c431bebdf3db626ccbeda43b", "author": {"user": {"login": "ankagrawal", "name": "Ankur Agrawal"}}, "url": "https://github.com/linkedin/ambry/commit/3874f5adc6f3ecb7c431bebdf3db626ccbeda43b", "committedDate": "2020-10-16T20:55:15Z", "message": "Refactor compaction code and cleanup interfaces."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTEzMjczMTc2", "url": "https://github.com/linkedin/ambry/pull/1646#pullrequestreview-513273176", "createdAt": "2020-10-21T03:03:26Z", "commit": {"oid": "3f585abb895a1492c72e3414a660f1740d633e5b"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMVQwMzowMzoyNlrOHlYehw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMVQwNDo0NzoxMlrOHlaGcQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODk2MDM5MQ==", "bodyText": "Can we start with false and deploy config to turn it on?", "url": "https://github.com/linkedin/ambry/pull/1646#discussion_r508960391", "createdAt": "2020-10-21T03:03:26Z", "author": {"login": "jsjtzyy"}, "path": "ambry-api/src/main/java/com/github/ambry/config/CloudConfig.java", "diffHunk": "@@ -198,6 +202,13 @@\n   @Default(\"true\")\n   public final boolean cloudBlobCompactionEnabled;\n \n+  /**\n+   * Whether deprecated container compaction is enabled.\n+   */\n+  @Config(CLOUD_CONTAINER_COMPACTION_ENABLED)\n+  @Default(\"true\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f585abb895a1492c72e3414a660f1740d633e5b"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODk2MDkxMg==", "bodyText": "suggest using getIntInRange", "url": "https://github.com/linkedin/ambry/pull/1646#discussion_r508960912", "createdAt": "2020-10-21T03:05:19Z", "author": {"login": "jsjtzyy"}, "path": "ambry-api/src/main/java/com/github/ambry/config/CloudConfig.java", "diffHunk": "@@ -360,8 +385,12 @@ public CloudConfig(VerifiableProperties verifiableProperties) {\n     cloudDeletedBlobRetentionDays =\n         verifiableProperties.getInt(CLOUD_DELETED_BLOB_RETENTION_DAYS, DEFAULT_RETENTION_DAYS);\n     cloudBlobCompactionEnabled = verifiableProperties.getBoolean(CLOUD_BLOB_COMPACTION_ENABLED, true);\n+    cloudContainerCompactionEnabled = verifiableProperties.getBoolean(CLOUD_CONTAINER_COMPACTION_ENABLED, true);\n     cloudBlobCompactionIntervalHours = verifiableProperties.getInt(CLOUD_BLOB_COMPACTION_INTERVAL_HOURS, 24);\n+    cloudContainerCompactionIntervalHours = verifiableProperties.getInt(CLOUD_CONTAINER_COMPACTION_INTERVAL_HOURS, 24);\n     cloudBlobCompactionStartupDelaySecs = verifiableProperties.getInt(CLOUD_BLOB_COMPACTION_STARTUP_DELAY_SECS, 600);\n+    cloudContainerCompactionStartupDelaySecs =\n+        verifiableProperties.getInt(CLOUD_CONTAINER_COMPACTION_STARTUP_DELAY_SECS, 600);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f585abb895a1492c72e3414a660f1740d633e5b"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODk4NTQ3NQ==", "bodyText": "cloudContainerCompactor.compactAssignedDeprecatedContainers will throw NullPointerException if cloud container compaction is disabled (see line 81)", "url": "https://github.com/linkedin/ambry/pull/1646#discussion_r508985475", "createdAt": "2020-10-21T04:41:28Z", "author": {"login": "jsjtzyy"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/VcrReplicationManager.java", "diffHunk": "@@ -123,19 +126,37 @@ public void onPartitionRemoved(PartitionId partitionId) {\n \n     // start background persistent thread\n     // start scheduler thread to persist index in the background\n-    scheduler.scheduleAtFixedRate(persistor, replicationConfig.replicationTokenFlushDelaySeconds,\n-        replicationConfig.replicationTokenFlushIntervalSeconds, TimeUnit.SECONDS);\n+    scheduleTask(persistor, true, replicationConfig.replicationTokenFlushDelaySeconds,\n+        replicationConfig.replicationTokenFlushIntervalSeconds, \"replica token persistor\");\n \n-    if (cloudConfig.cloudBlobCompactionEnabled) {\n-      // Schedule thread to purge dead blobs for this VCR's partitions\n-      // after delay to allow startup to finish.\n-      long delaySec = cloudConfig.cloudBlobCompactionStartupDelaySecs;\n-      long intervalSec = TimeUnit.HOURS.toSeconds(cloudConfig.cloudBlobCompactionIntervalHours);\n-      scheduler.scheduleAtFixedRate(cloudStorageCompactor, delaySec, intervalSec, TimeUnit.SECONDS);\n-      logger.info(\"Scheduled compaction task to run every {} hours starting in {} seconds.\",\n-          cloudConfig.cloudBlobCompactionIntervalHours, delaySec);\n+    // Schedule thread to purge dead blobs for this VCR's partitions\n+    // after delay to allow startup to finish.\n+    scheduleTask(cloudStorageCompactor, cloudConfig.cloudBlobCompactionEnabled,\n+        cloudConfig.cloudBlobCompactionStartupDelaySecs,\n+        TimeUnit.HOURS.toSeconds(cloudConfig.cloudBlobCompactionIntervalHours), \"cloud blob compaction\");\n+\n+    // Schedule thread to purge blobs belonging to deprecated containers for this VCR's partitions\n+    // after delay to allow startup to finish.\n+    scheduleTask(() -> cloudContainerCompactor.compactAssignedDeprecatedContainers(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f585abb895a1492c72e3414a660f1740d633e5b"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODk4NjQ5MA==", "bodyText": "According to your design, there would be several threads concurrently performing container compaction. Could you point me to the implementation?", "url": "https://github.com/linkedin/ambry/pull/1646#discussion_r508986490", "createdAt": "2020-10-21T04:45:12Z", "author": {"login": "jsjtzyy"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/VcrReplicationManager.java", "diffHunk": "@@ -123,19 +126,37 @@ public void onPartitionRemoved(PartitionId partitionId) {\n \n     // start background persistent thread\n     // start scheduler thread to persist index in the background\n-    scheduler.scheduleAtFixedRate(persistor, replicationConfig.replicationTokenFlushDelaySeconds,\n-        replicationConfig.replicationTokenFlushIntervalSeconds, TimeUnit.SECONDS);\n+    scheduleTask(persistor, true, replicationConfig.replicationTokenFlushDelaySeconds,\n+        replicationConfig.replicationTokenFlushIntervalSeconds, \"replica token persistor\");\n \n-    if (cloudConfig.cloudBlobCompactionEnabled) {\n-      // Schedule thread to purge dead blobs for this VCR's partitions\n-      // after delay to allow startup to finish.\n-      long delaySec = cloudConfig.cloudBlobCompactionStartupDelaySecs;\n-      long intervalSec = TimeUnit.HOURS.toSeconds(cloudConfig.cloudBlobCompactionIntervalHours);\n-      scheduler.scheduleAtFixedRate(cloudStorageCompactor, delaySec, intervalSec, TimeUnit.SECONDS);\n-      logger.info(\"Scheduled compaction task to run every {} hours starting in {} seconds.\",\n-          cloudConfig.cloudBlobCompactionIntervalHours, delaySec);\n+    // Schedule thread to purge dead blobs for this VCR's partitions\n+    // after delay to allow startup to finish.\n+    scheduleTask(cloudStorageCompactor, cloudConfig.cloudBlobCompactionEnabled,\n+        cloudConfig.cloudBlobCompactionStartupDelaySecs,\n+        TimeUnit.HOURS.toSeconds(cloudConfig.cloudBlobCompactionIntervalHours), \"cloud blob compaction\");\n+\n+    // Schedule thread to purge blobs belonging to deprecated containers for this VCR's partitions\n+    // after delay to allow startup to finish.\n+    scheduleTask(() -> cloudContainerCompactor.compactAssignedDeprecatedContainers(\n+        virtualReplicatorCluster.getAssignedPartitionIds()), cloudConfig.cloudContainerCompactionEnabled,\n+        cloudConfig.cloudContainerCompactionStartupDelaySecs,\n+        TimeUnit.HOURS.toSeconds(cloudConfig.cloudContainerCompactionIntervalHours), \"cloud container compaction\");\n+  }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f585abb895a1492c72e3414a660f1740d633e5b"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODk4Njk5Mw==", "bodyText": "same here, better to use getIntInRange", "url": "https://github.com/linkedin/ambry/pull/1646#discussion_r508986993", "createdAt": "2020-10-21T04:47:12Z", "author": {"login": "jsjtzyy"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/azure/AzureCloudConfig.java", "diffHunk": "@@ -135,5 +156,11 @@ public AzureCloudConfig(VerifiableProperties verifiableProperties) {\n     azureBlobContainerStrategy =\n         verifiableProperties.getString(AZURE_BLOB_CONTAINER_STRATEGY, DEFAULT_CONTAINER_STRATEGY);\n     azureNameSchemeVersion = verifiableProperties.getInt(AZURE_NAME_SCHEME_VERSION, DEFAULT_NAME_SCHEME_VERSION);\n+    cosmosContainerDeletionBatchSize =\n+        verifiableProperties.getInt(COSMOS_CONTAINER_DELETION_BATCH_SIZE, DEFAULT_COSMOS_CONTAINER_DELETION_BATCH_SIZE);\n+    containerCompactionAbsPurgeLimit =\n+        verifiableProperties.getInt(CONTAINER_COMPACTION_ABS_PURGE_LIMIT, DEFAULT_CONTAINER_COMPACTION_ABS_PURGE_LIMIT);\n+    containerCompactionCosmosQueryLimit = verifiableProperties.getInt(CONTAINER_COMPACTION_COSMOS_QUERY_LIMIT,\n+        DEFAULT_COSMOS_CONTAINER_DELETION_BATCH_SIZE);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f585abb895a1492c72e3414a660f1740d633e5b"}, "originalPosition": 63}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE0MTE0NDcz", "url": "https://github.com/linkedin/ambry/pull/1646#pullrequestreview-514114473", "createdAt": "2020-10-21T19:34:16Z", "commit": {"oid": "3f585abb895a1492c72e3414a660f1740d633e5b"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 13, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMVQxOTozNjoyNlrOHmAawQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMVQyMDo0Njo1MVrOHmEicA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTYxNDc4NQ==", "bodyText": "Seems a little odd that we need a getter for this but not the dead blob compactor, though I trust you had a reason to add it here.", "url": "https://github.com/linkedin/ambry/pull/1646#discussion_r509614785", "createdAt": "2020-10-21T19:36:26Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudDestination.java", "diffHunk": "@@ -145,4 +145,9 @@ boolean retrieveTokens(String partitionPath, String tokenFileName, OutputStream\n    * @throws {@link CloudStorageException} if the operation fails.\n    */\n   void deprecateContainers(Collection<Container> deprecatedContainers) throws CloudStorageException;\n+\n+  /**\n+   * @return {@link CloudContainerCompactor} object that would do container compaction for cloud.\n+   */\n+  CloudContainerCompactor getContainerCompactor();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f585abb895a1492c72e3414a660f1740d633e5b"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTYxOTc4Nw==", "bodyText": "Could we change this signature to return Collection instead of List?  Then no need to copy.", "url": "https://github.com/linkedin/ambry/pull/1646#discussion_r509619787", "createdAt": "2020-10-21T19:43:02Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/StaticVcrCluster.java", "diffHunk": "@@ -91,7 +91,13 @@ public void participate() throws Exception {\n \n   @Override\n   public List<? extends PartitionId> getAssignedPartitionIds() {\n-    return assignedPartitionIds;\n+    return new ArrayList<>(assignedPartitionIds);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f585abb895a1492c72e3414a660f1740d633e5b"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTYyMjQ0Nw==", "bodyText": "Nit: can we call this deprecatedContainerBlobCompactionRate, since it's rate of blob and not container compaction.", "url": "https://github.com/linkedin/ambry/pull/1646#discussion_r509622447", "createdAt": "2020-10-21T19:46:19Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/VcrMetrics.java", "diffHunk": "@@ -33,6 +33,7 @@\n   // Compaction metrics\n   // Rate of blob compaction for VCR instance\n   public final Meter blobCompactionRate;\n+  public final Meter deprecatedContainerCompactionRate;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f585abb895a1492c72e3414a660f1740d633e5b"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTYyNDc5Nw==", "bodyText": "Minor: it seems unnecessary to pass isEnabled to this method.  But I'm okay either way.", "url": "https://github.com/linkedin/ambry/pull/1646#discussion_r509624797", "createdAt": "2020-10-21T19:49:53Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/VcrReplicationManager.java", "diffHunk": "@@ -123,19 +126,37 @@ public void onPartitionRemoved(PartitionId partitionId) {\n \n     // start background persistent thread\n     // start scheduler thread to persist index in the background\n-    scheduler.scheduleAtFixedRate(persistor, replicationConfig.replicationTokenFlushDelaySeconds,\n-        replicationConfig.replicationTokenFlushIntervalSeconds, TimeUnit.SECONDS);\n+    scheduleTask(persistor, true, replicationConfig.replicationTokenFlushDelaySeconds,\n+        replicationConfig.replicationTokenFlushIntervalSeconds, \"replica token persistor\");\n \n-    if (cloudConfig.cloudBlobCompactionEnabled) {\n-      // Schedule thread to purge dead blobs for this VCR's partitions\n-      // after delay to allow startup to finish.\n-      long delaySec = cloudConfig.cloudBlobCompactionStartupDelaySecs;\n-      long intervalSec = TimeUnit.HOURS.toSeconds(cloudConfig.cloudBlobCompactionIntervalHours);\n-      scheduler.scheduleAtFixedRate(cloudStorageCompactor, delaySec, intervalSec, TimeUnit.SECONDS);\n-      logger.info(\"Scheduled compaction task to run every {} hours starting in {} seconds.\",\n-          cloudConfig.cloudBlobCompactionIntervalHours, delaySec);\n+    // Schedule thread to purge dead blobs for this VCR's partitions\n+    // after delay to allow startup to finish.\n+    scheduleTask(cloudStorageCompactor, cloudConfig.cloudBlobCompactionEnabled,\n+        cloudConfig.cloudBlobCompactionStartupDelaySecs,\n+        TimeUnit.HOURS.toSeconds(cloudConfig.cloudBlobCompactionIntervalHours), \"cloud blob compaction\");\n+\n+    // Schedule thread to purge blobs belonging to deprecated containers for this VCR's partitions\n+    // after delay to allow startup to finish.\n+    scheduleTask(() -> cloudContainerCompactor.compactAssignedDeprecatedContainers(\n+        virtualReplicatorCluster.getAssignedPartitionIds()), cloudConfig.cloudContainerCompactionEnabled,\n+        cloudConfig.cloudContainerCompactionStartupDelaySecs,\n+        TimeUnit.HOURS.toSeconds(cloudConfig.cloudContainerCompactionIntervalHours), \"cloud container compaction\");\n+  }\n+\n+  /**\n+   * Schedule the specified task if enabled with the specified delay and interval.\n+   * @param task {@link Runnable} task to be scheduled.\n+   * @param isEnabled flag indicating if the task is enabled. If false the task is not scheduled.\n+   * @param delaySec initial delay to allow startup to finish before starting task.\n+   * @param intervalSec period between successive executions.\n+   * @param taskName name of the task being scheduled.\n+   */\n+  private void scheduleTask(Runnable task, boolean isEnabled, long delaySec, long intervalSec, String taskName) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f585abb895a1492c72e3414a660f1740d633e5b"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTYyNTA2Mg==", "bodyText": "Minor: missing space", "url": "https://github.com/linkedin/ambry/pull/1646#discussion_r509625062", "createdAt": "2020-10-21T19:50:15Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/VcrReplicationManager.java", "diffHunk": "@@ -223,6 +244,9 @@ public void shutdown() throws ReplicationException {\n     if (cloudStorageCompactor != null) {\n       cloudStorageCompactor.shutdown();\n     }\n+    if(cloudContainerCompactor != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f585abb895a1492c72e3414a660f1740d633e5b"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTYzNzM5NQ==", "bodyText": "Remove or reword this TODO not to use LI things.", "url": "https://github.com/linkedin/ambry/pull/1646#discussion_r509637395", "createdAt": "2020-10-21T20:01:57Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/azure/AzureCloudDestination.java", "diffHunk": "@@ -489,10 +493,16 @@ private CloudStorageException toCloudStorageException(String message, Exception\n \n   @Override\n   public void deprecateContainers(Collection<Container> deletedContainers) throws CloudStorageException {\n+    //TODO need to set correct partition class for video cluster in call to getAllPartitionIds.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f585abb895a1492c72e3414a660f1740d633e5b"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTY0NDU3OA==", "bodyText": "Can we keep this method and make it a wrapper around the utility?  Then callers don't need to know the impl details.", "url": "https://github.com/linkedin/ambry/pull/1646#discussion_r509644578", "createdAt": "2020-10-21T20:08:45Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/azure/AzureStorageCompactor.java", "diffHunk": "@@ -264,44 +266,6 @@ private int compactPartitionBucketed(String partitionPath, String fieldName, lon\n     }\n   }\n \n-  /**\n-   * Permanently delete the specified blobs in Azure storage.\n-   * @param blobMetadataList the list of {@link CloudBlobMetadata} referencing the blobs to purge.\n-   * @return the number of blobs successfully purged.\n-   * @throws CloudStorageException if the purge operation fails for any blob.\n-   */\n-  int purgeBlobs(List<CloudBlobMetadata> blobMetadataList) throws CloudStorageException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f585abb895a1492c72e3414a660f1740d633e5b"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTY1Mjk2OQ==", "bodyText": "Can we use parameters in the new queries (like LIMIT_PARAM) to be consistent?", "url": "https://github.com/linkedin/ambry/pull/1646#discussion_r509652969", "createdAt": "2020-10-21T20:14:16Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/azure/CosmosDataAccessor.java", "diffHunk": "@@ -70,11 +72,12 @@\n   private static final String LIMIT_PARAM = \"@limit\";\n   private static final String EXPIRED_BLOBS_QUERY = constructDeadBlobsQuery(CloudBlobMetadata.FIELD_EXPIRATION_TIME);\n   private static final String DELETED_BLOBS_QUERY = constructDeadBlobsQuery(CloudBlobMetadata.FIELD_DELETION_TIME);\n+  private static final String CONTAINER_BLOBS_QUERY =\n+      \"SELECT TOP %d * FROM c WHERE c.accountId=%d and c.containerId=%d\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f585abb895a1492c72e3414a660f1740d633e5b"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTY1OTQ2MQ==", "bodyText": "The code from here down is nearly identical to getDeadBlobs.  Please refactor into a common class that take SqlQuerySpec as argument.", "url": "https://github.com/linkedin/ambry/pull/1646#discussion_r509659461", "createdAt": "2020-10-21T20:18:51Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/azure/CosmosDataAccessor.java", "diffHunk": "@@ -425,6 +428,51 @@ CloudBlobMetadata getMetadataOrNull(BlobId blobId) throws DocumentClientExceptio\n     }\n   }\n \n+  /**\n+   * Get the list of blobs in the specified partition that belong to the specified container.\n+   * @param partitionPath the partition to query.\n+   * @param accountId account id of the container.\n+   * @param containerId container id of the container.\n+   * @param queryLimit max number of blobs to return.\n+   * @return a List of {@link CloudBlobMetadata} referencing the blobs belonging to the deprecated containers.\n+   * @throws DocumentClientException in case of any error.\n+   */\n+  List<CloudBlobMetadata> getContainerBlobs(String partitionPath, short accountId, short containerId, int queryLimit)\n+      throws DocumentClientException {\n+    String query = String.format(CONTAINER_BLOBS_QUERY, accountId, containerId);\n+    SqlQuerySpec querySpec = new SqlQuerySpec(query);\n+    FeedOptions feedOptions = new FeedOptions();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f585abb895a1492c72e3414a660f1740d633e5b"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTY2MzAzMw==", "bodyText": "Also, since we aren't time bucketing the queries like dead blob compaction does, we could run into the same throttling issues that prompted the use of time bucketing there.", "url": "https://github.com/linkedin/ambry/pull/1646#discussion_r509663033", "createdAt": "2020-10-21T20:22:14Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/azure/CosmosDataAccessor.java", "diffHunk": "@@ -425,6 +428,51 @@ CloudBlobMetadata getMetadataOrNull(BlobId blobId) throws DocumentClientExceptio\n     }\n   }\n \n+  /**\n+   * Get the list of blobs in the specified partition that belong to the specified container.\n+   * @param partitionPath the partition to query.\n+   * @param accountId account id of the container.\n+   * @param containerId container id of the container.\n+   * @param queryLimit max number of blobs to return.\n+   * @return a List of {@link CloudBlobMetadata} referencing the blobs belonging to the deprecated containers.\n+   * @throws DocumentClientException in case of any error.\n+   */\n+  List<CloudBlobMetadata> getContainerBlobs(String partitionPath, short accountId, short containerId, int queryLimit)\n+      throws DocumentClientException {\n+    String query = String.format(CONTAINER_BLOBS_QUERY, accountId, containerId);\n+    SqlQuerySpec querySpec = new SqlQuerySpec(query);\n+    FeedOptions feedOptions = new FeedOptions();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTY1OTQ2MQ=="}, "originalCommit": {"oid": "3f585abb895a1492c72e3414a660f1740d633e5b"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTY2ODYxNw==", "bodyText": "A lot of this logic is very similar to updateMetadata().  Possible to reuse/combine?", "url": "https://github.com/linkedin/ambry/pull/1646#discussion_r509668617", "createdAt": "2020-10-21T20:28:55Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/azure/CosmosDataAccessor.java", "diffHunk": "@@ -559,25 +608,89 @@ public long deprecateContainers(Set<ContainerDeletionEntry> deprecatedContainers\n   }\n \n   /**\n-   * @return a {@link Set} of {@link ContainerDeletionEntry} objects from cosmosdb that are not marked as deleted.\n+   * Fetch a {@link Set} of {@link CosmosContainerDeletionEntry} objects from cosmos db that are not marked as deleted.\n+   * @param maxEntries Max number of entries to fetch on one query.\n+   * @return {@link Set} of {@link CosmosContainerDeletionEntry} objects.\n+   * @throws DocumentClientException in case of any error.\n    */\n-  public Set<ContainerDeletionEntry> getDeprecatedContainers(int maxEntries) {\n+  public Set<CosmosContainerDeletionEntry> getDeprecatedContainers(int maxEntries) throws DocumentClientException {\n     String query = String.format(DEPRECATED_CONTAINERS_QUERY, maxEntries);\n     Timer timer = new Timer();\n-    Iterator<FeedResponse<Document>> iterator =\n-        executeCosmosQuery(cosmosDeletedContainerCollectionLink, null, new SqlQuerySpec(query), new FeedOptions(),\n-            timer).getIterator();\n-    Set<ContainerDeletionEntry> containerDeletionEntries = new HashSet<>();\n-    while (iterator.hasNext()) {\n-      FeedResponse<Document> response = iterator.next();\n-      response.getResults()\n-          .iterator()\n-          .forEachRemaining(\n-              doc -> containerDeletionEntries.add(ContainerDeletionEntry.fromJson(new JSONObject(doc.toJson()))));\n+    Set<CosmosContainerDeletionEntry> containerDeletionEntries = new HashSet<>();\n+    try {\n+      Iterator<FeedResponse<Document>> iterator =\n+          executeCosmosQuery(cosmosDeletedContainerCollectionLink, null, new SqlQuerySpec(query), new FeedOptions(),\n+              timer).getIterator();\n+      while (iterator.hasNext()) {\n+        FeedResponse<Document> response = iterator.next();\n+        response.getResults()\n+            .iterator()\n+            .forEachRemaining(doc -> containerDeletionEntries.add(\n+                CosmosContainerDeletionEntry.fromJson(new JSONObject(doc.toJson()))));\n+      }\n+    } catch (RuntimeException rex) {\n+      if (rex.getCause() instanceof DocumentClientException) {\n+        logger.warn(\"Get deprecated containers query {} got {}\", query,\n+            ((DocumentClientException) rex.getCause()).getStatusCode());\n+        throw (DocumentClientException) rex.getCause();\n+      }\n+      throw rex;\n     }\n     return containerDeletionEntries;\n   }\n \n+  /**\n+   * Update the container deletion entry document in the CosmosDB collection.\n+   * @param containerId the container id for which document is replaced.\n+   * @param accountId the account id for which document is replaced.\n+   * @param updateFields {@link BiConsumer} object to use as callback to update the required fields.\n+   * @return the {@link ResourceResponse} returned by the operation, if successful.\n+   * Returns {@Null} if the field already has the specified value.\n+   * @throws DocumentClientException if the record was not found or if the operation failed.\n+   */\n+  ResourceResponse<Document> updateContainerDeletionEntry(short containerId, short accountId,\n+      BiConsumer<Document, AtomicBoolean> updateFields) throws DocumentClientException {\n+\n+    // Read the existing record\n+    String id = CosmosContainerDeletionEntry.generateContainerDeletionEntryId(accountId, containerId);\n+    String docLink = getContainerDeletionEntryDocumentLink(id);\n+    RequestOptions options = getRequestOptions(id);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f585abb895a1492c72e3414a660f1740d633e5b"}, "originalPosition": 166}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTY3MDQ0OQ==", "bodyText": "Ouch!  Obviously remove this.  We should also change the EI keys since they've been exposed.", "url": "https://github.com/linkedin/ambry/pull/1646#discussion_r509670449", "createdAt": "2020-10-21T20:31:50Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/test/resources/azure-test.properties", "diffHunk": "@@ -9,9 +9,8 @@\n # under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR\n # CONDITIONS OF ANY KIND, either express or implied.\n #\n-azure.storage.connection.string=<storage-account-credentials>\n-cosmos.endpoint=<cosmos-url>\n-cosmos.collection.link=/dbs/ambry-metadata/colls/blob-metadata\n-cosmos.key=<cosmos-key>\n-cosmos.deleted.container.collection.link=/dbs/ambry-metadata-main/colls/deleted-container-test\n-cosmos.direct.https=true\n+azure.storage.connection.string=DefaultEndpointsProtocol=https;AccountName=wus2ambryblobstore1;AccountKey=vqQbP8s6I68IGlyYeqyv1dAwsh3AXXlD+QwgGTVhbU5NEMzE6Tucv9SxS2/6AzB/8VDHjaZmIYV9MWUCWaAqTg==;EndpointSuffix=core.windows.net", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f585abb895a1492c72e3414a660f1740d633e5b"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTY4MjI4OA==", "bodyText": "Javadoc.", "url": "https://github.com/linkedin/ambry/pull/1646#discussion_r509682288", "createdAt": "2020-10-21T20:46:51Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/azure/AzureCompactionUtil.java", "diffHunk": "@@ -0,0 +1,64 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.cloud.azure;\n+\n+import com.github.ambry.cloud.CloudBlobMetadata;\n+import com.github.ambry.cloud.CloudStorageException;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+\n+public class AzureCompactionUtil {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f585abb895a1492c72e3414a660f1740d633e5b"}, "originalPosition": 22}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE0MzM5NTI2", "url": "https://github.com/linkedin/ambry/pull/1646#pullrequestreview-514339526", "createdAt": "2020-10-22T03:46:18Z", "commit": {"oid": "3f585abb895a1492c72e3414a660f1740d633e5b"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQwMzo0NjoxOVrOHmPiOA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQwNDozNzoxNVrOHmQR7A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTg2MjQ1Ng==", "bodyText": "minor: missing java doc for @param assignedPartitions", "url": "https://github.com/linkedin/ambry/pull/1646#discussion_r509862456", "createdAt": "2020-10-22T03:46:19Z", "author": {"login": "SophieGuo410"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/azure/AzureContainerCompactor.java", "diffHunk": "@@ -53,38 +66,83 @@\n    * @param azureMetrics {@link AzureMetrics} object.\n    */\n   public AzureContainerCompactor(AzureBlobDataAccessor azureBlobDataAccessor, CosmosDataAccessor cosmosDataAccessor,\n-      CloudConfig cloudConfig, VcrMetrics vcrMetrics, AzureMetrics azureMetrics) {\n+      CloudConfig cloudConfig, AzureCloudConfig azureCloudConfig, VcrMetrics vcrMetrics, AzureMetrics azureMetrics) {\n     this.azureBlobDataAccessor = azureBlobDataAccessor;\n     this.cosmosDataAccessor = cosmosDataAccessor;\n-    this.cloudConfig = cloudConfig;\n     this.vcrMetrics = vcrMetrics;\n     this.azureMetrics = azureMetrics;\n     requestAgent = new CloudRequestAgent(cloudConfig, vcrMetrics);\n+    this.queryLimit = azureCloudConfig.containerCompactionCosmosQueryLimit;\n+    this.containerDeletionQueryBatchSize = azureCloudConfig.cosmosContainerDeletionBatchSize;\n   }\n \n   /**\n    * Update newly deprecated containers from {@code deprecatedContainers} to CosmosDb since last checkpoint.\n-   * @param deprecatedContainers {@link Collection} of deprecatedd {@link Container}s.\n+   * This method is one of the two entry points in {@link AzureContainerCompactor} along with\n+   * {@link AzureContainerCompactor#compactAssignedDeprecatedContainers(List)}.\n+   * @param deprecatedContainers {@link Collection} of deprecated {@link Container}s.\n+   * @param partitionIds list of partition ids from where the containers have to be removed.\n    * @throws CloudStorageException in case of any error.\n    */\n   public void deprecateContainers(Collection<Container> deprecatedContainers, Collection<String> partitionIds)\n       throws CloudStorageException {\n-    if (deprecatedContainers.isEmpty()) {\n-      logger.info(\"Got empty set to update deprecated containers. Skipping update deprecated containers to cloud.\");\n+    if (deprecatedContainers.isEmpty() || partitionIds.isEmpty()) {\n+      logger.warn(\n+          \"Got either empty container set or empty partition list. Skipping update deprecated containers to cloud.\");\n       return;\n     }\n     long lastUpdatedContainerTimestamp = getLatestContainerDeletionTime();\n     long newLastUpdateContainerTimestamp = requestAgent.doWithRetries(() -> cosmosDataAccessor.deprecateContainers(\n         deprecatedContainers.stream()\n             .filter(container -> container.getDeleteTriggerTime() >= lastUpdatedContainerTimestamp)\n-            .map(container -> ContainerDeletionEntry.fromContainer(container, partitionIds))\n+            .map(container -> CosmosContainerDeletionEntry.fromContainer(container, partitionIds))\n             .collect(Collectors.toSet())), \"updateDeprecatedContainers\", null);\n \n     if (newLastUpdateContainerTimestamp != -1) {\n       saveLatestContainerDeletionTime(newLastUpdateContainerTimestamp);\n     }\n   }\n \n+  /**\n+   * Compact blobs of the deprecated container from cloud. This method is one of the two entry points in the\n+   * {@link AzureContainerCompactor} class along with {@link AzureContainerCompactor#deprecateContainers(Collection, Collection)}.\n+   * Note that this method is not thread safe as it is expected to run in a single thread.\n+   */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f585abb895a1492c72e3414a660f1740d633e5b"}, "originalPosition": 99}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTg2NTAwNA==", "bodyText": "minor: you can removed them since they are not been used.", "url": "https://github.com/linkedin/ambry/pull/1646#discussion_r509865004", "createdAt": "2020-10-22T03:56:33Z", "author": {"login": "SophieGuo410"}, "path": "ambry-cloud/src/test/java/com/github/ambry/cloud/azure/AzureTestUtils.java", "diffHunk": "@@ -13,9 +13,12 @@\n  */\n package com.github.ambry.cloud.azure;\n \n+import com.codahale.metrics.Timer;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f585abb895a1492c72e3414a660f1740d633e5b"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTg2NjIwNg==", "bodyText": "Not used?", "url": "https://github.com/linkedin/ambry/pull/1646#discussion_r509866206", "createdAt": "2020-10-22T04:00:52Z", "author": {"login": "SophieGuo410"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/azure/CosmosContainerDeletionEntry.java", "diffHunk": "@@ -25,34 +25,36 @@\n /**\n  * Class representing container deletion status in cloud.\n  */\n-public class ContainerDeletionEntry {\n-\n+public class CosmosContainerDeletionEntry {\n   static final String VERSION_KEY = \"version\";\n   static final String CONTAINER_ID_KEY = \"containerId\";\n   static final String ACCOUNT_ID_KEY = \"accountId\";\n-  static final String CONTAINER_DELETE_TRIGGER_TIME_KEY = \"deleteTriggerTime\";\n-  static final String IS_DELETED_KEY = \"isDeleted\";\n+  static final String CONTAINER_DELETE_TRIGGER_TIME_KEY = \"deleteTriggerTimestamp\";\n+  static final String DELETED_KEY = \"deleted\";\n   static final String DELETE_PENDING_PARTITIONS_KEY = \"deletePendingPartitions\";\n+  private static final String ID_KEY = \"id\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f585abb895a1492c72e3414a660f1740d633e5b"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTg2ODE1NQ==", "bodyText": "Seems the blobCompactedCount never been used?", "url": "https://github.com/linkedin/ambry/pull/1646#discussion_r509868155", "createdAt": "2020-10-22T04:08:42Z", "author": {"login": "SophieGuo410"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/azure/AzureContainerCompactor.java", "diffHunk": "@@ -53,38 +66,83 @@\n    * @param azureMetrics {@link AzureMetrics} object.\n    */\n   public AzureContainerCompactor(AzureBlobDataAccessor azureBlobDataAccessor, CosmosDataAccessor cosmosDataAccessor,\n-      CloudConfig cloudConfig, VcrMetrics vcrMetrics, AzureMetrics azureMetrics) {\n+      CloudConfig cloudConfig, AzureCloudConfig azureCloudConfig, VcrMetrics vcrMetrics, AzureMetrics azureMetrics) {\n     this.azureBlobDataAccessor = azureBlobDataAccessor;\n     this.cosmosDataAccessor = cosmosDataAccessor;\n-    this.cloudConfig = cloudConfig;\n     this.vcrMetrics = vcrMetrics;\n     this.azureMetrics = azureMetrics;\n     requestAgent = new CloudRequestAgent(cloudConfig, vcrMetrics);\n+    this.queryLimit = azureCloudConfig.containerCompactionCosmosQueryLimit;\n+    this.containerDeletionQueryBatchSize = azureCloudConfig.cosmosContainerDeletionBatchSize;\n   }\n \n   /**\n    * Update newly deprecated containers from {@code deprecatedContainers} to CosmosDb since last checkpoint.\n-   * @param deprecatedContainers {@link Collection} of deprecatedd {@link Container}s.\n+   * This method is one of the two entry points in {@link AzureContainerCompactor} along with\n+   * {@link AzureContainerCompactor#compactAssignedDeprecatedContainers(List)}.\n+   * @param deprecatedContainers {@link Collection} of deprecated {@link Container}s.\n+   * @param partitionIds list of partition ids from where the containers have to be removed.\n    * @throws CloudStorageException in case of any error.\n    */\n   public void deprecateContainers(Collection<Container> deprecatedContainers, Collection<String> partitionIds)\n       throws CloudStorageException {\n-    if (deprecatedContainers.isEmpty()) {\n-      logger.info(\"Got empty set to update deprecated containers. Skipping update deprecated containers to cloud.\");\n+    if (deprecatedContainers.isEmpty() || partitionIds.isEmpty()) {\n+      logger.warn(\n+          \"Got either empty container set or empty partition list. Skipping update deprecated containers to cloud.\");\n       return;\n     }\n     long lastUpdatedContainerTimestamp = getLatestContainerDeletionTime();\n     long newLastUpdateContainerTimestamp = requestAgent.doWithRetries(() -> cosmosDataAccessor.deprecateContainers(\n         deprecatedContainers.stream()\n             .filter(container -> container.getDeleteTriggerTime() >= lastUpdatedContainerTimestamp)\n-            .map(container -> ContainerDeletionEntry.fromContainer(container, partitionIds))\n+            .map(container -> CosmosContainerDeletionEntry.fromContainer(container, partitionIds))\n             .collect(Collectors.toSet())), \"updateDeprecatedContainers\", null);\n \n     if (newLastUpdateContainerTimestamp != -1) {\n       saveLatestContainerDeletionTime(newLastUpdateContainerTimestamp);\n     }\n   }\n \n+  /**\n+   * Compact blobs of the deprecated container from cloud. This method is one of the two entry points in the\n+   * {@link AzureContainerCompactor} class along with {@link AzureContainerCompactor#deprecateContainers(Collection, Collection)}.\n+   * Note that this method is not thread safe as it is expected to run in a single thread.\n+   */\n+  @Override\n+  public void compactAssignedDeprecatedContainers(List<? extends PartitionId> assignedPartitions) {\n+    try {\n+      SortedSet<CosmosContainerDeletionEntry> containerDeletionEntrySet =\n+          fetchContainerDeletionEntries(assignedPartitions);\n+      while (!containerDeletionEntrySet.isEmpty()) {\n+        CosmosContainerDeletionEntry containerDeletionEntry = containerDeletionEntrySet.first();\n+        containerDeletionEntrySet.remove(containerDeletionEntry);\n+        for (String partitionId : containerDeletionEntry.getDeletePendingPartitions()) {\n+          try {\n+            int blobCompactedCount =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f585abb895a1492c72e3414a660f1740d633e5b"}, "originalPosition": 110}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTg3NDY2OA==", "bodyText": "minor: GetDeprectedContainers -> GetDeprecatedContainers", "url": "https://github.com/linkedin/ambry/pull/1646#discussion_r509874668", "createdAt": "2020-10-22T04:37:15Z", "author": {"login": "SophieGuo410"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/azure/AzureContainerCompactor.java", "diffHunk": "@@ -131,4 +193,96 @@ private void saveLatestContainerDeletionTime(long latestContainerDeletionTimesta\n       throw e;\n     }\n   }\n+\n+  /**\n+   * Purge all blobs of the specified container from the specified partition.\n+   * @param containerId container id of the specified container.\n+   * @param accountId account oid of the specified container.\n+   * @param partitionPath partition id from which the blobs have to be deleted.\n+   * @return number of blobs purged.\n+   * @throws CloudStorageException in case of any error.\n+   */\n+  private int compactContainer(short containerId, short accountId, String partitionPath) throws CloudStorageException {\n+    int totalPurged = 0;\n+    while (!isShuttingDown()) {\n+      List<CloudBlobMetadata> blobs = requestAgent.doWithRetries(\n+          () -> cosmosDataAccessor.getContainerBlobs(partitionPath, accountId, containerId, queryLimit),\n+          \"GetDeprecatedContainerBlobs\", partitionPath);\n+\n+      if (blobs.isEmpty()) {\n+        // this means all the blobs of this container have been purged from the partition\n+        updateCompactionProgress(containerId, accountId, partitionPath);\n+        break;\n+      }\n+      if (isShuttingDown()) {\n+        break;\n+      }\n+      totalPurged += requestAgent.doWithRetries(\n+          () -> AzureCompactionUtil.purgeBlobs(blobs, azureBlobDataAccessor, azureMetrics, cosmosDataAccessor),\n+          \"PurgeBlobs\", partitionPath);\n+      vcrMetrics.deprecatedContainerCompactionRate.mark(blobs.size());\n+    }\n+    return totalPurged;\n+  }\n+\n+  /**\n+   * Update the container deletion entry of the specified container to remove the partition from which all blobs of the\n+   * container have been compacted. If there are no more partitions left to compact then mark the container deletion entry as deleted.\n+   * @param containerId container id of the container.\n+   * @param accountId account if of the container.\n+   * @param partitionPath partition id from which all blobs of the container have been deleted.\n+   * @throws CloudStorageException in case of any error.\n+   */\n+  private void updateCompactionProgress(short containerId, short accountId, String partitionPath)\n+      throws CloudStorageException {\n+    // TODO: update the cache and cosmos container deletion entry table to remove the partitionId from deletePendingPartitions list\n+    ResourceResponse<Document> updatedDocument = requestAgent.doWithRetries(\n+        () -> cosmosDataAccessor.updateContainerDeletionEntry(containerId, accountId, (document, fieldsChanged) -> {\n+          Set<String> deletePendingPartitions =\n+              (Set<String>) document.get(CosmosContainerDeletionEntry.DELETE_PENDING_PARTITIONS_KEY);\n+          fieldsChanged.set(deletePendingPartitions.remove(partitionPath));\n+          document.set(CosmosContainerDeletionEntry.DELETE_PENDING_PARTITIONS_KEY, deletePendingPartitions);\n+          if (deletePendingPartitions.isEmpty()) {\n+            document.set(CosmosContainerDeletionEntry.DELETED_KEY, true);\n+            fieldsChanged.set(true);\n+          }\n+        }), \"UpdateContainerDeletionProgress\", partitionPath);\n+  }\n+\n+  /**\n+   * Fetch the {@link CosmosContainerDeletionEntry} from cloud and create a cache with entries that have atleast one partition\n+   * assigned to current node.\n+   */\n+  private SortedSet<CosmosContainerDeletionEntry> fetchContainerDeletionEntries(\n+      List<? extends PartitionId> assignedPartitions) throws CloudStorageException {\n+    Set<CosmosContainerDeletionEntry> containerDeletionEntrySet =\n+        requestAgent.doWithRetries(() -> cosmosDataAccessor.getDeprecatedContainers(containerDeletionQueryBatchSize),\n+            \"GetDeprectedContainers\", null);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f585abb895a1492c72e3414a660f1740d633e5b"}, "originalPosition": 224}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "3f585abb895a1492c72e3414a660f1740d633e5b", "author": {"user": {"login": "ankagrawal", "name": "Ankur Agrawal"}}, "url": "https://github.com/linkedin/ambry/commit/3f585abb895a1492c72e3414a660f1740d633e5b", "committedDate": "2020-10-20T01:00:37Z", "message": "Add cleanup after tests."}, "afterCommit": {"oid": "4dcc9f19819a8c7e9f0affe0590fa79054b6a3c3", "author": {"user": {"login": "ankagrawal", "name": "Ankur Agrawal"}}, "url": "https://github.com/linkedin/ambry/commit/4dcc9f19819a8c7e9f0affe0590fa79054b6a3c3", "committedDate": "2020-11-02T20:33:58Z", "message": "cleanup"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIyMTg4MTA4", "url": "https://github.com/linkedin/ambry/pull/1646#pullrequestreview-522188108", "createdAt": "2020-11-03T04:48:58Z", "commit": {"oid": "eccc947808383b9bb41e71a1d50c7490b089f950"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QwNDo0ODo1OFrOHsgLWA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QwNDo0ODo1OFrOHsgLWA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQyNjU4NA==", "bodyText": "I think Cosmos will reject this.  \"%d\" needs to be removed, and you need the \"*\" before FROM.", "url": "https://github.com/linkedin/ambry/pull/1646#discussion_r516426584", "createdAt": "2020-11-03T04:48:58Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/azure/CosmosDataAccessor.java", "diffHunk": "@@ -70,10 +70,13 @@\n   private static final String START_TIME_PARAM = \"@startTime\";\n   private static final String END_TIME_PARAM = \"@endTime\";\n   private static final String LIMIT_PARAM = \"@limit\";\n+  private static final String ACCOUNT_ID_PARAM = \"@accountId\";\n+  private static final String CONTAINER_ID_PARAM = \"@containerId\";\n   private static final String EXPIRED_BLOBS_QUERY = constructDeadBlobsQuery(CloudBlobMetadata.FIELD_EXPIRATION_TIME);\n   private static final String DELETED_BLOBS_QUERY = constructDeadBlobsQuery(CloudBlobMetadata.FIELD_DELETION_TIME);\n   private static final String CONTAINER_BLOBS_QUERY =\n-      \"SELECT TOP %d * FROM c WHERE c.accountId=%d and c.containerId=%d\";\n+      \"SELECT TOP %d \" + LIMIT_PARAM + \" FROM c WHERE c.accountId=\" + ACCOUNT_ID_PARAM + \" and c.containerId=\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eccc947808383b9bb41e71a1d50c7490b089f950"}, "originalPosition": 10}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIyMTg4MzEz", "url": "https://github.com/linkedin/ambry/pull/1646#pullrequestreview-522188313", "createdAt": "2020-11-03T04:49:54Z", "commit": {"oid": "eccc947808383b9bb41e71a1d50c7490b089f950"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QwNDo0OTo1NFrOHsgMJw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QwNDo0OTo1NFrOHsgMJw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQyNjc5MQ==", "bodyText": "Can you change this to LIMIT_PARAM too?  I missed it earlier.", "url": "https://github.com/linkedin/ambry/pull/1646#discussion_r516426791", "createdAt": "2020-11-03T04:49:54Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/azure/CosmosDataAccessor.java", "diffHunk": "@@ -70,10 +70,13 @@\n   private static final String START_TIME_PARAM = \"@startTime\";\n   private static final String END_TIME_PARAM = \"@endTime\";\n   private static final String LIMIT_PARAM = \"@limit\";\n+  private static final String ACCOUNT_ID_PARAM = \"@accountId\";\n+  private static final String CONTAINER_ID_PARAM = \"@containerId\";\n   private static final String EXPIRED_BLOBS_QUERY = constructDeadBlobsQuery(CloudBlobMetadata.FIELD_EXPIRATION_TIME);\n   private static final String DELETED_BLOBS_QUERY = constructDeadBlobsQuery(CloudBlobMetadata.FIELD_DELETION_TIME);\n   private static final String CONTAINER_BLOBS_QUERY =\n-      \"SELECT TOP %d * FROM c WHERE c.accountId=%d and c.containerId=%d\";\n+      \"SELECT TOP %d \" + LIMIT_PARAM + \" FROM c WHERE c.accountId=\" + ACCOUNT_ID_PARAM + \" and c.containerId=\"\n+          + CONTAINER_ID_PARAM;\n   private static final String BULK_DELETE_QUERY = \"SELECT c._self FROM c WHERE c.id IN (%s)\";\n   private static final String DEPRECATED_CONTAINERS_QUERY =\n       \"SELECT TOP %d * from c WHERE c.deleted=false order by c.deleteTriggerTimestamp\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eccc947808383b9bb41e71a1d50c7490b089f950"}, "originalPosition": 14}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIyMTg4ODg0", "url": "https://github.com/linkedin/ambry/pull/1646#pullrequestreview-522188884", "createdAt": "2020-11-03T04:52:30Z", "commit": {"oid": "4dcc9f19819a8c7e9f0affe0590fa79054b6a3c3"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI2NjQ1NzU0", "url": "https://github.com/linkedin/ambry/pull/1646#pullrequestreview-526645754", "createdAt": "2020-11-09T20:54:11Z", "commit": {"oid": "d67105d3f77d6254018cbc3f098222151e8b7747"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOVQyMDo1NDoxMVrOHwBNag==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOVQyMDo1NDoxMVrOHwBNag==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDExMzUxNA==", "bodyText": "What's the difference between LIMIT and MAX_ENTRIES params?", "url": "https://github.com/linkedin/ambry/pull/1646#discussion_r520113514", "createdAt": "2020-11-09T20:54:11Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/azure/CosmosDataAccessor.java", "diffHunk": "@@ -72,15 +72,15 @@\n   private static final String LIMIT_PARAM = \"@limit\";\n   private static final String ACCOUNT_ID_PARAM = \"@accountId\";\n   private static final String CONTAINER_ID_PARAM = \"@containerId\";\n+  private static final String MAX_ENTRIES_PARAM = \"@maxEntries\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d67105d3f77d6254018cbc3f098222151e8b7747"}, "originalPosition": 4}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c847531cd6a15c6b390a814c3d80b02aad4cfd42", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/c847531cd6a15c6b390a814c3d80b02aad4cfd42", "committedDate": "2020-11-22T18:53:11Z", "message": "Initial implementation of Helix task to sync deleted containers between cloud and helix account service."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e1d180eca7de006bdf7bd1075ce1f46ec1881499", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/e1d180eca7de006bdf7bd1075ce1f46ec1881499", "committedDate": "2020-11-22T18:53:11Z", "message": "Fix tests and cleanup."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8d1c67c772ab1cd3ea48292508fac15b55736c84", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/8d1c67c772ab1cd3ea48292508fac15b55736c84", "committedDate": "2020-11-22T18:53:11Z", "message": "Fix BlobStoreCompactorTest"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f541cdae1ce7b2608a7fe0f668b6936796776632", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/f541cdae1ce7b2608a7fe0f668b6936796776632", "committedDate": "2020-11-22T18:53:11Z", "message": "Add unit tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "847b6d58d93a29aa482f8d1a29b828d1ddd79585", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/847b6d58d93a29aa482f8d1a29b828d1ddd79585", "committedDate": "2020-11-22T18:53:11Z", "message": "Integration test (WIP)"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8dcd662982ca7d25e3593c0b4b89e04d27d8a20e", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/8dcd662982ca7d25e3593c0b4b89e04d27d8a20e", "committedDate": "2020-11-22T18:53:11Z", "message": "Save ContainerDeletionEntry for deleted containers in cloud."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "90bdcad3d65f15841efb20355c89ecf22056c349", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/90bdcad3d65f15841efb20355c89ecf22056c349", "committedDate": "2020-11-22T18:53:11Z", "message": "Fix tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "94002e590a8a5575d3016391c9d895cb29b000fb", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/94002e590a8a5575d3016391c9d895cb29b000fb", "committedDate": "2020-11-22T18:53:11Z", "message": "WIP Implement the container deletion logic"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "27bd18fd1aaece668f503ad083b88df44d37cb88", "author": {"user": null}, "url": "https://github.com/linkedin/ambry/commit/27bd18fd1aaece668f503ad083b88df44d37cb88", "committedDate": "2020-11-22T18:53:11Z", "message": "Production code for container compaction."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c3dfdcd9860eca04963f5defb6c440719a98803c", "author": {"user": {"login": "ankagrawal", "name": "Ankur Agrawal"}}, "url": "https://github.com/linkedin/ambry/commit/c3dfdcd9860eca04963f5defb6c440719a98803c", "committedDate": "2020-11-22T18:53:11Z", "message": "Rebase and fix tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8c720f1dc878279b01b4ed03a631f31d24daa327", "author": {"user": {"login": "ankagrawal", "name": "Ankur Agrawal"}}, "url": "https://github.com/linkedin/ambry/commit/8c720f1dc878279b01b4ed03a631f31d24daa327", "committedDate": "2020-11-22T18:53:11Z", "message": "Add logic to trigger container compaction in cloud."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b2350429524eed828ec6b0ef1064991fe2911031", "author": {"user": {"login": "ankagrawal", "name": "Ankur Agrawal"}}, "url": "https://github.com/linkedin/ambry/commit/b2350429524eed828ec6b0ef1064991fe2911031", "committedDate": "2020-11-22T18:53:11Z", "message": "Refactor compaction code and cleanup interfaces."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fcb2f63fe362be04c12539d48ef6e9367789ab20", "author": {"user": {"login": "ankagrawal", "name": "Ankur Agrawal"}}, "url": "https://github.com/linkedin/ambry/commit/fcb2f63fe362be04c12539d48ef6e9367789ab20", "committedDate": "2020-11-22T18:53:11Z", "message": "Update container on delete"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9f3b50748ba3ed23f0bd1e67fff594603715845d", "author": {"user": {"login": "ankagrawal", "name": "Ankur Agrawal"}}, "url": "https://github.com/linkedin/ambry/commit/9f3b50748ba3ed23f0bd1e67fff594603715845d", "committedDate": "2020-11-22T18:53:11Z", "message": "Add retries to azure operations."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "42924e2a11b25375c28f7b0e4fa2656644bdde2c", "author": {"user": {"login": "ankagrawal", "name": "Ankur Agrawal"}}, "url": "https://github.com/linkedin/ambry/commit/42924e2a11b25375c28f7b0e4fa2656644bdde2c", "committedDate": "2020-11-22T18:53:11Z", "message": "Fix integration tests."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "605d93c37d81d58d6ae41b060a82eff06a9a71ae", "author": {"user": {"login": "ankagrawal", "name": "Ankur Agrawal"}}, "url": "https://github.com/linkedin/ambry/commit/605d93c37d81d58d6ae41b060a82eff06a9a71ae", "committedDate": "2020-11-22T18:53:11Z", "message": "cleanup"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5737cd6b338784feb86de7ab930dcc14c4f04a12", "author": {"user": {"login": "ankagrawal", "name": "Ankur Agrawal"}}, "url": "https://github.com/linkedin/ambry/commit/5737cd6b338784feb86de7ab930dcc14c4f04a12", "committedDate": "2020-11-22T18:53:11Z", "message": "Add cleanup after tests."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ac9b750a9be3f395c63699edfca03174cedd0107", "author": {"user": {"login": "ankagrawal", "name": "Ankur Agrawal"}}, "url": "https://github.com/linkedin/ambry/commit/ac9b750a9be3f395c63699edfca03174cedd0107", "committedDate": "2020-11-22T18:53:11Z", "message": "Address review comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bbcda12d1dae8538164b50095b1d294286886333", "author": {"user": {"login": "ankagrawal", "name": "Ankur Agrawal"}}, "url": "https://github.com/linkedin/ambry/commit/bbcda12d1dae8538164b50095b1d294286886333", "committedDate": "2020-11-22T18:53:12Z", "message": "Address review comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0d6df8c4dc37362f2dfe912631c80eade88be59c", "author": {"user": {"login": "ankagrawal", "name": "Ankur Agrawal"}}, "url": "https://github.com/linkedin/ambry/commit/0d6df8c4dc37362f2dfe912631c80eade88be59c", "committedDate": "2020-11-22T18:53:12Z", "message": "cleanup"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7f6c44c85632698194ba9031def8194c46711c97", "author": {"user": {"login": "ankagrawal", "name": "Ankur Agrawal"}}, "url": "https://github.com/linkedin/ambry/commit/7f6c44c85632698194ba9031def8194c46711c97", "committedDate": "2020-11-22T18:53:12Z", "message": "Address review comments"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d67105d3f77d6254018cbc3f098222151e8b7747", "author": {"user": {"login": "ankagrawal", "name": "Ankur Agrawal"}}, "url": "https://github.com/linkedin/ambry/commit/d67105d3f77d6254018cbc3f098222151e8b7747", "committedDate": "2020-11-09T20:15:08Z", "message": "Address review comments"}, "afterCommit": {"oid": "7f6c44c85632698194ba9031def8194c46711c97", "author": {"user": {"login": "ankagrawal", "name": "Ankur Agrawal"}}, "url": "https://github.com/linkedin/ambry/commit/7f6c44c85632698194ba9031def8194c46711c97", "committedDate": "2020-11-22T18:53:12Z", "message": "Address review comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f23c798c37ad7c327637d68734731c0198e2003a", "author": {"user": {"login": "ankagrawal", "name": "Ankur Agrawal"}}, "url": "https://github.com/linkedin/ambry/commit/f23c798c37ad7c327637d68734731c0198e2003a", "committedDate": "2020-11-23T07:20:16Z", "message": "Add integration tests for cloud container compaction."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI2NTkyODk0", "url": "https://github.com/linkedin/ambry/pull/1646#pullrequestreview-526592894", "createdAt": "2020-11-09T19:39:05Z", "commit": {"oid": "4dcc9f19819a8c7e9f0affe0590fa79054b6a3c3"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOVQxOTozOTowNlrOHv-sbg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QwNzoyMzo0OVrOH4BfMg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDA3MjMwMg==", "bodyText": "fixed.", "url": "https://github.com/linkedin/ambry/pull/1646#discussion_r520072302", "createdAt": "2020-11-09T19:39:06Z", "author": {"login": "ankagrawal"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/azure/CosmosDataAccessor.java", "diffHunk": "@@ -70,10 +70,13 @@\n   private static final String START_TIME_PARAM = \"@startTime\";\n   private static final String END_TIME_PARAM = \"@endTime\";\n   private static final String LIMIT_PARAM = \"@limit\";\n+  private static final String ACCOUNT_ID_PARAM = \"@accountId\";\n+  private static final String CONTAINER_ID_PARAM = \"@containerId\";\n   private static final String EXPIRED_BLOBS_QUERY = constructDeadBlobsQuery(CloudBlobMetadata.FIELD_EXPIRATION_TIME);\n   private static final String DELETED_BLOBS_QUERY = constructDeadBlobsQuery(CloudBlobMetadata.FIELD_DELETION_TIME);\n   private static final String CONTAINER_BLOBS_QUERY =\n-      \"SELECT TOP %d * FROM c WHERE c.accountId=%d and c.containerId=%d\";\n+      \"SELECT TOP %d \" + LIMIT_PARAM + \" FROM c WHERE c.accountId=\" + ACCOUNT_ID_PARAM + \" and c.containerId=\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQyNjU4NA=="}, "originalCommit": {"oid": "eccc947808383b9bb41e71a1d50c7490b089f950"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDA3MjQwNQ==", "bodyText": "fixed.", "url": "https://github.com/linkedin/ambry/pull/1646#discussion_r520072405", "createdAt": "2020-11-09T19:39:16Z", "author": {"login": "ankagrawal"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/azure/CosmosDataAccessor.java", "diffHunk": "@@ -70,10 +70,13 @@\n   private static final String START_TIME_PARAM = \"@startTime\";\n   private static final String END_TIME_PARAM = \"@endTime\";\n   private static final String LIMIT_PARAM = \"@limit\";\n+  private static final String ACCOUNT_ID_PARAM = \"@accountId\";\n+  private static final String CONTAINER_ID_PARAM = \"@containerId\";\n   private static final String EXPIRED_BLOBS_QUERY = constructDeadBlobsQuery(CloudBlobMetadata.FIELD_EXPIRATION_TIME);\n   private static final String DELETED_BLOBS_QUERY = constructDeadBlobsQuery(CloudBlobMetadata.FIELD_DELETION_TIME);\n   private static final String CONTAINER_BLOBS_QUERY =\n-      \"SELECT TOP %d * FROM c WHERE c.accountId=%d and c.containerId=%d\";\n+      \"SELECT TOP %d \" + LIMIT_PARAM + \" FROM c WHERE c.accountId=\" + ACCOUNT_ID_PARAM + \" and c.containerId=\"\n+          + CONTAINER_ID_PARAM;\n   private static final String BULK_DELETE_QUERY = \"SELECT c._self FROM c WHERE c.id IN (%s)\";\n   private static final String DEPRECATED_CONTAINERS_QUERY =\n       \"SELECT TOP %d * from c WHERE c.deleted=false order by c.deleteTriggerTimestamp\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQyNjc5MQ=="}, "originalCommit": {"oid": "eccc947808383b9bb41e71a1d50c7490b089f950"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODUwNjY3NA==", "bodyText": "Removed MAX_ENTRIES.", "url": "https://github.com/linkedin/ambry/pull/1646#discussion_r528506674", "createdAt": "2020-11-23T07:23:49Z", "author": {"login": "ankagrawal"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/azure/CosmosDataAccessor.java", "diffHunk": "@@ -72,15 +72,15 @@\n   private static final String LIMIT_PARAM = \"@limit\";\n   private static final String ACCOUNT_ID_PARAM = \"@accountId\";\n   private static final String CONTAINER_ID_PARAM = \"@containerId\";\n+  private static final String MAX_ENTRIES_PARAM = \"@maxEntries\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDExMzUxNA=="}, "originalCommit": {"oid": "d67105d3f77d6254018cbc3f098222151e8b7747"}, "originalPosition": 4}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9fbd36ae8f1afd3042cd614509ef1a2586edbcc1", "author": {"user": {"login": "ankagrawal", "name": "Ankur Agrawal"}}, "url": "https://github.com/linkedin/ambry/commit/9fbd36ae8f1afd3042cd614509ef1a2586edbcc1", "committedDate": "2020-11-24T19:01:12Z", "message": "Address review comments."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM3ODI1OTg3", "url": "https://github.com/linkedin/ambry/pull/1646#pullrequestreview-537825987", "createdAt": "2020-11-24T19:11:37Z", "commit": {"oid": "9fbd36ae8f1afd3042cd614509ef1a2586edbcc1"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM3ODMyNzUy", "url": "https://github.com/linkedin/ambry/pull/1646#pullrequestreview-537832752", "createdAt": "2020-11-24T19:21:16Z", "commit": {"oid": "9fbd36ae8f1afd3042cd614509ef1a2586edbcc1"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 920, "cost": 1, "resetAt": "2021-11-01T16:19:10Z"}}}