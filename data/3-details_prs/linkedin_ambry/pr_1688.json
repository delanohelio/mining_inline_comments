{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTE1OTkyNTc2", "number": 1688, "title": "[AZURE_AD_AUTH] Add refresh logic for access token in ADAuthBasedStorgeClient.", "bodyText": "Refactor code to separate out ABS calls in storage client class.\nAdd refresh token for ADAuthBasedStorageClient.", "createdAt": "2020-11-05T11:26:50Z", "url": "https://github.com/linkedin/ambry/pull/1688", "merged": true, "mergeCommit": {"oid": "ebb2f6445374c4090e65c36758c7df0f2bb254d4"}, "closed": true, "closedAt": "2020-11-12T20:15:40Z", "author": {"login": "ankagrawal"}, "timelineItems": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdZgfgXgH2gAyNTE1OTkyNTc2Ojk3ZWEyYjY5YWEyOGZlZmIyMzA2OGQyNjM5ZjEzNjExMDY0NzI1MjY=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdb3sCOAFqTUyOTQyMzAxNQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "97ea2b69aa28fefb23068d2639f1361106472526", "author": {"user": {"login": "ankagrawal", "name": "Ankur Agrawal"}}, "url": "https://github.com/linkedin/ambry/commit/97ea2b69aa28fefb23068d2639f1361106472526", "committedDate": "2020-11-05T11:16:43Z", "message": "Add refresh logic for access token in ADAuthBasedStorgeClient.\nRefactor code."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d79e254009d53d839cf5dc1f9d1e8fa533e917e9", "author": {"user": {"login": "ankagrawal", "name": "Ankur Agrawal"}}, "url": "https://github.com/linkedin/ambry/commit/d79e254009d53d839cf5dc1f9d1e8fa533e917e9", "committedDate": "2020-11-05T20:48:37Z", "message": "cleanup access token ref initialization"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3NTg5MjEy", "url": "https://github.com/linkedin/ambry/pull/1688#pullrequestreview-527589212", "createdAt": "2020-11-10T20:40:07Z", "commit": {"oid": "d79e254009d53d839cf5dc1f9d1e8fa533e917e9"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQyMDo0MDowN1rOHwuw3A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQyMDo0MDowN1rOHwuw3A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg1OTg2OA==", "bodyText": "Looks ReflectiveOperationException is good enough. Why Exception is used?", "url": "https://github.com/linkedin/ambry/pull/1688#discussion_r520859868", "createdAt": "2020-11-10T20:40:07Z", "author": {"login": "zzmao"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/azure/AzureCloudDestination.java", "diffHunk": "@@ -91,7 +91,7 @@\n    */\n   AzureCloudDestination(CloudConfig cloudConfig, AzureCloudConfig azureCloudConfig, String clusterName,\n       VcrMetrics vcrMetrics, AzureMetrics azureMetrics, AzureReplicationFeed.FeedType azureReplicationFeedType,\n-      ClusterMap clusterMap) throws ReflectiveOperationException {\n+      ClusterMap clusterMap) throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d79e254009d53d839cf5dc1f9d1e8fa533e917e9"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3NjUwMTI1", "url": "https://github.com/linkedin/ambry/pull/1688#pullrequestreview-527650125", "createdAt": "2020-11-10T22:12:37Z", "commit": {"oid": "d79e254009d53d839cf5dc1f9d1e8fa533e917e9"}, "state": "APPROVED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQyMjoxMjozN1rOHwxpdg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQwMjozMDowMVrOHw5mZQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwNzEyNg==", "bodyText": "Can reference be constructed in class constructor?", "url": "https://github.com/linkedin/ambry/pull/1688#discussion_r520907126", "createdAt": "2020-11-10T22:12:37Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/azure/ADAuthBasedStorageClient.java", "diffHunk": "@@ -29,26 +32,56 @@\n import java.time.OffsetDateTime;\n import java.util.Collections;\n import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.atomic.AtomicReference;\n+import org.apache.http.HttpStatus;\n import reactor.core.publisher.Mono;\n \n \n /**\n- * {@link StorageClientFactory} implementation for AD based authentication.\n+ * {@link StorageClient} implementation for AD based authentication.\n  */\n-public class ADAuthBasedStorageClientFactory extends StorageClientFactory {\n+public class ADAuthBasedStorageClient extends StorageClient {\n+  private AtomicReference<AccessToken> accessTokenRef;\n+\n+  /**\n+   * Constructor for {@link ADAuthBasedStorageClient} object.\n+   * @param azureCloudConfig {@link AzureCloudConfig} object.\n+   * @param cloudConfig {@link CloudConfig} object.\n+   */\n+  public ADAuthBasedStorageClient(AzureCloudConfig azureCloudConfig, CloudConfig cloudConfig,\n+      AzureBlobLayoutStrategy blobLayoutStrategy) {\n+    super(azureCloudConfig, cloudConfig, blobLayoutStrategy);\n+  }\n+\n+  /**\n+   * Constructor for {@link ADAuthBasedStorageClient} object for testing.\n+   * @param blobServiceClient {@link BlobServiceClient} object.\n+   * @param blobBatchClient {@link BlobBatchClient} object.\n+   * @param blobLayoutStrategy {@link AzureBlobLayoutStrategy} object.\n+   */\n+  public ADAuthBasedStorageClient(BlobServiceClient blobServiceClient, BlobBatchClient blobBatchClient,\n+      AzureBlobLayoutStrategy blobLayoutStrategy) {\n+    super(blobServiceClient, blobBatchClient, blobLayoutStrategy);\n+  }\n \n   @Override\n   protected BlobServiceClient buildBlobServiceClient(HttpClient httpClient, Configuration configuration,\n       RequestRetryOptions retryOptions, AzureCloudConfig azureCloudConfig)\n       throws MalformedURLException, InterruptedException, ExecutionException {\n     IAuthenticationResult iAuthenticationResult = getAccessTokenByClientCredentialGrant(azureCloudConfig);\n+    AccessToken accessToken = new AccessToken(iAuthenticationResult.accessToken(),\n+        iAuthenticationResult.expiresOnDate().toInstant().atOffset(OffsetDateTime.now().getOffset()));\n     TokenCredential tokenCredential = new TokenCredential() {\n       @Override\n       public Mono<AccessToken> getToken(TokenRequestContext request) {\n-        return Mono.just(new AccessToken(iAuthenticationResult.accessToken(),\n-            iAuthenticationResult.expiresOnDate().toInstant().atOffset(OffsetDateTime.now().getOffset())));\n+        return Mono.just(accessToken);\n       }\n     };\n+    if (accessTokenRef == null) {\n+      accessTokenRef = new AtomicReference<>(accessToken);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d79e254009d53d839cf5dc1f9d1e8fa533e917e9"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTAyODMxMA==", "bodyText": "The base class shouldn't know anything about expired tokens.", "url": "https://github.com/linkedin/ambry/pull/1688#discussion_r521028310", "createdAt": "2020-11-11T02:17:45Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/azure/StorageClient.java", "diffHunk": "@@ -0,0 +1,413 @@\n+/**\n+ * Copyright 2020  LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.cloud.azure;\n+\n+import com.azure.core.exception.UnexpectedLengthException;\n+import com.azure.core.http.HttpClient;\n+import com.azure.core.http.ProxyOptions;\n+import com.azure.core.http.netty.NettyAsyncHttpClientBuilder;\n+import com.azure.core.http.rest.Response;\n+import com.azure.core.util.Configuration;\n+import com.azure.core.util.Context;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.batch.BlobBatch;\n+import com.azure.storage.blob.batch.BlobBatchClient;\n+import com.azure.storage.blob.batch.BlobBatchClientBuilder;\n+import com.azure.storage.blob.batch.BlobBatchStorageException;\n+import com.azure.storage.blob.models.AccessTier;\n+import com.azure.storage.blob.models.BlobDownloadResponse;\n+import com.azure.storage.blob.models.BlobErrorCode;\n+import com.azure.storage.blob.models.BlobHttpHeaders;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobRange;\n+import com.azure.storage.blob.models.BlobRequestConditions;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.BlockBlobItem;\n+import com.azure.storage.blob.models.DownloadRetryOptions;\n+import com.azure.storage.blob.specialized.BlockBlobClient;\n+import com.azure.storage.common.policy.RequestRetryOptions;\n+import com.azure.storage.common.policy.RetryPolicyType;\n+import com.github.ambry.cloud.CloudBlobMetadata;\n+import com.github.ambry.commons.BlobId;\n+import com.github.ambry.config.CloudConfig;\n+import com.microsoft.azure.cosmosdb.RetryOptions;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.io.UncheckedIOException;\n+import java.net.InetSocketAddress;\n+import java.net.MalformedURLException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.atomic.AtomicReference;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Abstract class encapsulation ABS client operations.\n+ */\n+public abstract class StorageClient {\n+  Logger logger = LoggerFactory.getLogger(StorageClient.class);\n+  private final AtomicReference<BlobServiceClient> storageClientRef;\n+  private final AtomicReference<BlobBatchClient> blobBatchClientRef;\n+  private final CloudConfig cloudConfig;\n+  private final AzureCloudConfig azureCloudConfig;\n+  private final AzureBlobLayoutStrategy blobLayoutStrategy;\n+  // Containers known to exist in the storage account\n+  private final Set<String> knownContainers = ConcurrentHashMap.newKeySet();\n+\n+  /**\n+   * Constructor for {@link StorageClient}.\n+   * @param azureCloudConfig {@link AzureCloudConfig} object.\n+   * @param cloudConfig {@link CloudConfig} object.\n+   */\n+  public StorageClient(AzureCloudConfig azureCloudConfig, CloudConfig cloudConfig,\n+      AzureBlobLayoutStrategy blobLayoutStrategy) {\n+    this.azureCloudConfig = azureCloudConfig;\n+    this.cloudConfig = cloudConfig;\n+    this.blobLayoutStrategy = blobLayoutStrategy;\n+    storageClientRef = new AtomicReference<>(createBlobStorageClient());\n+    blobBatchClientRef = new AtomicReference<>(new BlobBatchClientBuilder(storageClientRef.get()).buildClient());\n+  }\n+\n+  /**\n+   * Constructor for {@link StorageClient}.\n+   * @param blobServiceClient {@link BlobServiceClient} object.\n+   * @param blobBatchClient {@link BlobBatchClient} object.\n+   */\n+  public StorageClient(BlobServiceClient blobServiceClient, BlobBatchClient blobBatchClient,\n+      AzureBlobLayoutStrategy blobLayoutStrategy) {\n+    this.storageClientRef = new AtomicReference<>(blobServiceClient);\n+    this.blobBatchClientRef = new AtomicReference<>(blobBatchClient);\n+    this.blobLayoutStrategy = blobLayoutStrategy;\n+    this.cloudConfig = null;\n+    this.azureCloudConfig = null;\n+  }\n+\n+  /**\n+   * Visible for testing.\n+   * @return the underlying {@link BlobServiceClient}.\n+   */\n+  public BlobServiceClient getStorageClient() {\n+    return storageClientRef.get();\n+  }\n+\n+  /**\n+   * Creates a new block blob, or updates the content of an existing block blob.\n+   * @param blobId {@link BlobId} of the blob to upload.\n+   * @param data The data to write to the blob.\n+   * @param length The exact length of the data. It is important that this value match precisely the length of the\n+   * data provided in the {@link InputStream}.\n+   * @param headers {@link BlobHttpHeaders}\n+   * @param metadata Metadata to associate with the blob.\n+   * @param tier {@link AccessTier} for the destination blob.\n+   * @param contentMd5 An MD5 hash of the block content.\n+   * @param requestConditions {@link BlobRequestConditions}\n+   * @param timeout An optional timeout value beyond which a {@link RuntimeException} will be raised.\n+   * @return The information of the uploaded block blob.\n+   * @throws UnexpectedLengthException when the length of data does not match the input {@code length}.\n+   * @throws NullPointerException if the input data is null.\n+   * @throws UncheckedIOException If an I/O error occurs\n+   */\n+  public Response<BlockBlobItem> uploadWithResponse(BlobId blobId, InputStream data, long length,\n+      BlobHttpHeaders headers, Map<String, String> metadata, AccessTier tier, byte[] contentMd5,\n+      BlobRequestConditions requestConditions, Duration timeout) {\n+    return doStorageClientOperation(\n+        () -> getBlockBlobClient(blobId, true).uploadWithResponse(data, length, headers, metadata, tier, contentMd5,\n+            requestConditions, timeout, Context.NONE));\n+  }\n+\n+  /**\n+   * Creates a new block blob, or updates the content of an existing block blob.\n+   * @param containerName name of the Azure container where the blob lives.\n+   * @param blobName name of the blob.\n+   * @param autoCreateContainer flag indicating whether to create the container if it does not exist.\n+   * @param data The data to write to the blob.\n+   * @param length The exact length of the data. It is important that this value match precisely the length of the\n+   * data provided in the {@link InputStream}.\n+   * @param headers {@link BlobHttpHeaders}\n+   * @param metadata Metadata to associate with the blob.\n+   * @param tier {@link AccessTier} for the destination blob.\n+   * @param contentMd5 An MD5 hash of the block content.\n+   * @param requestConditions {@link BlobRequestConditions}\n+   * @param timeout An optional timeout value beyond which a {@link RuntimeException} will be raised.\n+   * @return The information of the uploaded block blob.\n+   * @throws UnexpectedLengthException when the length of data does not match the input {@code length}.\n+   * @throws NullPointerException if the input data is null.\n+   * @throws UncheckedIOException If an I/O error occurs\n+   */\n+  public Response<BlockBlobItem> uploadWithResponse(String containerName, String blobName, boolean autoCreateContainer,\n+      InputStream data, long length, BlobHttpHeaders headers, Map<String, String> metadata, AccessTier tier,\n+      byte[] contentMd5, BlobRequestConditions requestConditions, Duration timeout) {\n+    return doStorageClientOperation(\n+        () -> getBlockBlobClient(containerName, blobName, autoCreateContainer).uploadWithResponse(data, length, headers,\n+            metadata, tier, contentMd5, requestConditions, timeout, Context.NONE));\n+  }\n+\n+  /**\n+   * Downloads a range of bytes from a blob into an output stream.\n+   * @param containerName name of the Azure container where the blob lives.\n+   * @param blobName name of the blob.\n+   * @param autoCreateContainer flag indicating whether to create the container if it does not exist.\n+   * @param stream A non-null {@link OutputStream} instance where the downloaded data will be written.\n+   * @param range {@link BlobRange}\n+   * @param options {@link DownloadRetryOptions}\n+   * @param requestConditions {@link BlobRequestConditions}\n+   * @param getRangeContentMd5 Whether the contentMD5 for the specified blob range should be returned.\n+   * @param timeout An optional timeout value beyond which a {@link RuntimeException} will be raised.\n+   * @return A response containing status code and HTTP headers.\n+   * @throws UncheckedIOException If an I/O error occurs.\n+   * @throws NullPointerException if {@code stream} is null\n+   */\n+  public BlobDownloadResponse downloadWithResponse(String containerName, String blobName, boolean autoCreateContainer,\n+      OutputStream stream, BlobRange range, DownloadRetryOptions options, BlobRequestConditions requestConditions,\n+      boolean getRangeContentMd5, Duration timeout) {\n+    // Might as well use same timeout for upload and download\n+    return doStorageClientOperation(\n+        () -> getBlockBlobClient(containerName, blobName, false).downloadWithResponse(stream, null, null,\n+            requestConditions, false, timeout, Context.NONE));\n+  }\n+\n+  /**\n+   * Delete a file from blob storage, if it exists.\n+   * @param containerName name of the container containing file to delete.\n+   * @param fileName name of the file to delete.\n+   * @return true if the file was deleted, otherwise false.\n+   * @throws BlobStorageException for any error on ABS side.\n+   */\n+  boolean deleteFile(String containerName, String fileName) throws BlobStorageException {\n+    AtomicReference<Boolean> retValRef = new AtomicReference<>(false);\n+    doStorageClientOperation(() -> {\n+      BlockBlobClient blobClient = getBlockBlobClient(containerName, fileName, false);\n+      if (blobClient.exists()) {\n+        blobClient.delete();\n+        retValRef.set(true);\n+      }\n+      return null;\n+    });\n+    return retValRef.get();\n+  }\n+\n+  /**\n+   * Perform basic connectivity test.\n+   */\n+  void testConnectivity() {\n+    storageClientRef.get()\n+        .getBlobContainerClient(\"partition-0\")\n+        .existsWithResponse(Duration.ofSeconds(5), Context.NONE);\n+  }\n+\n+  /**\n+   * Returns the blob's metadata and properties.\n+   * @param blobId {@link BlobId}\n+   * @param requestConditions {@link BlobRequestConditions}\n+   * @param timeout An optional timeout value beyond which a {@link RuntimeException} will be raised.\n+   * @return The blob properties and metadata.\n+   */\n+  public BlobProperties getPropertiesWithResponse(BlobId blobId, BlobRequestConditions requestConditions,\n+      Duration timeout) {\n+    return doStorageClientOperation(\n+        () -> getBlockBlobClient(blobId, false).getPropertiesWithResponse(requestConditions, timeout, Context.NONE)\n+            .getValue());\n+  }\n+\n+  /**\n+   * Changes a blob's metadata. The specified metadata in this method will replace existing metadata. If old values\n+   * must be preserved, they must be downloaded and included in the call to this method.\n+   * @param blobId {@link BlobId} object.\n+   * @param metadata Metadata to associate with the blob.\n+   * @param requestConditions {@link BlobRequestConditions}\n+   * @param timeout An optional timeout value beyond which a {@link RuntimeException} will be raised.\n+   * @param context Additional context that is passed through the Http pipeline during the service call.\n+   */\n+  public void setMetadataWithResponse(BlobId blobId, Map<String, String> metadata,\n+      BlobRequestConditions requestConditions, Duration timeout, Context context) {\n+    doStorageClientOperation(\n+        () -> getBlockBlobClient(blobId, false).setMetadataWithResponse(metadata, requestConditions, timeout,\n+            Context.NONE));\n+  }\n+\n+  /**\n+   * Deletes a list of blobs.\n+   * @param batchOfBlobs {@link List} of {@link CloudBlobMetadata} objects.\n+   * @param timeout An optional timeout value beyond which a {@link RuntimeException} will be raised.\n+   * @return {@link List} of {@link Response}s for the blobs in the batch.\n+   * @throws RuntimeException If the {@code timeout} duration completes before a response is returned.\n+   * @throws BlobStorageException If the batch request is malformed.\n+   * @throws BlobBatchStorageException If {@code throwOnAnyFailure} is {@code true} and any request in the\n+   * {@link BlobBatch} failed.\n+   */\n+  public List<Response<Void>> deleteBatch(List<CloudBlobMetadata> batchOfBlobs, Duration timeout) {\n+    List<Response<Void>> responseList = new ArrayList<>();\n+    doStorageClientOperation(() -> {\n+      BlobBatch blobBatch = blobBatchClientRef.get().getBlobBatch();\n+      for (CloudBlobMetadata blobMetadata : batchOfBlobs) {\n+        AzureBlobLayoutStrategy.BlobLayout blobLayout = blobLayoutStrategy.getDataBlobLayout(blobMetadata);\n+        responseList.add(blobBatch.deleteBlob(blobLayout.containerName, blobLayout.blobFilePath));\n+      }\n+      blobBatchClientRef.get().submitBatchWithResponse(blobBatch, false, timeout, Context.NONE);\n+      return null;\n+    });\n+    return responseList;\n+  }\n+\n+  /**\n+   * Get the block blob client for the supplied blobid.\n+   * @param blobId id of the blob for which {@code BlockBlobClient} is needed.\n+   * @param autoCreateContainer flag indicating whether to create the container if it does not exist.\n+   * @return {@code BlockBlobClient} reference.\n+   */\n+  private BlockBlobClient getBlockBlobClient(BlobId blobId, boolean autoCreateContainer) {\n+    AzureBlobLayoutStrategy.BlobLayout blobLayout = blobLayoutStrategy.getDataBlobLayout(blobId);\n+    return getBlockBlobClient(blobLayout.containerName, blobLayout.blobFilePath, autoCreateContainer);\n+  }\n+\n+  /**\n+   * Get the block blob client for the supplied Azure container and blob name.\n+   * @param containerName name of the Azure container where the blob lives.\n+   * @param blobName name of the blob.\n+   * @param autoCreateContainer flag indicating whether to create the container if it does not exist.\n+   * @return {@code BlockBlobClient} reference.\n+   */\n+  BlockBlobClient getBlockBlobClient(String containerName, String blobName, boolean autoCreateContainer) {\n+    BlobContainerClient containerClient = getContainer(containerName, autoCreateContainer);\n+    return containerClient.getBlobClient(blobName).getBlockBlobClient();\n+  }\n+\n+  /**\n+   * Get a reference to an Azure container, creating it if necessary.\n+   * @param containerName the container name.\n+   * @param autoCreate flag indicating whether to create the container if it does not exist.\n+   * @return the created {@link BlobContainerClient}.\n+   */\n+  private BlobContainerClient getContainer(String containerName, boolean autoCreate) {\n+    BlobContainerClient containerClient = storageClientRef.get().getBlobContainerClient(containerName);\n+    if (autoCreate) {\n+      if (!knownContainers.contains(containerName)) {\n+        try {\n+          if (!containerClient.exists()) {\n+            containerClient.create();\n+            logger.info(\"Created container {}\", containerName);\n+          }\n+        } catch (BlobStorageException ex) {\n+          if (ex.getErrorCode() != BlobErrorCode.CONTAINER_ALREADY_EXISTS) {\n+            logger.error(\"Failed to create container {}\", containerName);\n+            throw ex;\n+          }\n+        }\n+        knownContainers.add(containerName);\n+      }\n+    }\n+    return containerClient;\n+  }\n+\n+  /**\n+   * Create the {@link BlobServiceClient} object.\n+   * @param {@link CloudConfig} object.\n+   * @param {@link AzureCloudConfig} object.\n+   * @return {@link BlobServiceClient} object.\n+   */\n+  protected BlobServiceClient createBlobStorageClient() {\n+    validateABSAuthConfigs(azureCloudConfig);\n+    Configuration storageConfiguration = new Configuration();\n+    // Check for network proxy\n+    ProxyOptions proxyOptions = (cloudConfig.vcrProxyHost == null) ? null : new ProxyOptions(ProxyOptions.Type.HTTP,\n+        new InetSocketAddress(cloudConfig.vcrProxyHost, cloudConfig.vcrProxyPort));\n+    if (proxyOptions != null) {\n+      logger.info(\"Using proxy: {}:{}\", cloudConfig.vcrProxyHost, cloudConfig.vcrProxyPort);\n+    }\n+    HttpClient client = new NettyAsyncHttpClientBuilder().proxy(proxyOptions).build();\n+\n+    // Note: retry decisions are made at CloudBlobStore level.  Configure storageClient with no retries.\n+    RequestRetryOptions noRetries = new RequestRetryOptions(RetryPolicyType.FIXED, 1, null, null, null, null);\n+    try {\n+      return buildBlobServiceClient(client, storageConfiguration, noRetries, azureCloudConfig);\n+    } catch (MalformedURLException | InterruptedException | ExecutionException ex) {\n+      logger.error(\"Error building ABS blob service client: {}\", ex.getMessage());\n+      throw new IllegalStateException(ex);\n+    }\n+  }\n+\n+  /**\n+   * Set the references for storage and blob clients atomically. Note this method is not thread safe and must always be\n+   * called within a thread safe context.\n+   * @param blobServiceClient {@link BlobServiceClient} object.\n+   */\n+  protected void setClientReferences(BlobServiceClient blobServiceClient) {\n+    storageClientRef.set(blobServiceClient);\n+    blobBatchClientRef.set(new BlobBatchClientBuilder(storageClientRef.get()).buildClient());\n+  }\n+\n+  /**\n+   * Execute the storage client operation represented by {@code operation}\n+   * @param operation {@link Callable} representing the operation.\n+   * @param <T> type of return value.\n+   * @return the return value of the operation.\n+   * @throws BlobStorageException\n+   */\n+  private <T> T doStorageClientOperation(Callable<T> operation) {\n+    int attempts = 0;\n+    T result = null;\n+    while (attempts <= 1) {\n+      attempts++;\n+      try {\n+        result = operation.call();\n+        break;\n+      } catch (BlobStorageException bsEx) {\n+        if (attempts == 1 && tryHandleExceptionAndHintRetry(bsEx)) {\n+          logger.info(\"Retrying blob store operation due to expired token\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d79e254009d53d839cf5dc1f9d1e8fa533e917e9"}, "originalPosition": 376}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTAyOTQ3NQ==", "bodyText": "Not sure the word \"try\" belongs in this name.", "url": "https://github.com/linkedin/ambry/pull/1688#discussion_r521029475", "createdAt": "2020-11-11T02:19:36Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/azure/StorageClient.java", "diffHunk": "@@ -0,0 +1,413 @@\n+/**\n+ * Copyright 2020  LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.cloud.azure;\n+\n+import com.azure.core.exception.UnexpectedLengthException;\n+import com.azure.core.http.HttpClient;\n+import com.azure.core.http.ProxyOptions;\n+import com.azure.core.http.netty.NettyAsyncHttpClientBuilder;\n+import com.azure.core.http.rest.Response;\n+import com.azure.core.util.Configuration;\n+import com.azure.core.util.Context;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.batch.BlobBatch;\n+import com.azure.storage.blob.batch.BlobBatchClient;\n+import com.azure.storage.blob.batch.BlobBatchClientBuilder;\n+import com.azure.storage.blob.batch.BlobBatchStorageException;\n+import com.azure.storage.blob.models.AccessTier;\n+import com.azure.storage.blob.models.BlobDownloadResponse;\n+import com.azure.storage.blob.models.BlobErrorCode;\n+import com.azure.storage.blob.models.BlobHttpHeaders;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobRange;\n+import com.azure.storage.blob.models.BlobRequestConditions;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.BlockBlobItem;\n+import com.azure.storage.blob.models.DownloadRetryOptions;\n+import com.azure.storage.blob.specialized.BlockBlobClient;\n+import com.azure.storage.common.policy.RequestRetryOptions;\n+import com.azure.storage.common.policy.RetryPolicyType;\n+import com.github.ambry.cloud.CloudBlobMetadata;\n+import com.github.ambry.commons.BlobId;\n+import com.github.ambry.config.CloudConfig;\n+import com.microsoft.azure.cosmosdb.RetryOptions;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.io.UncheckedIOException;\n+import java.net.InetSocketAddress;\n+import java.net.MalformedURLException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.atomic.AtomicReference;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Abstract class encapsulation ABS client operations.\n+ */\n+public abstract class StorageClient {\n+  Logger logger = LoggerFactory.getLogger(StorageClient.class);\n+  private final AtomicReference<BlobServiceClient> storageClientRef;\n+  private final AtomicReference<BlobBatchClient> blobBatchClientRef;\n+  private final CloudConfig cloudConfig;\n+  private final AzureCloudConfig azureCloudConfig;\n+  private final AzureBlobLayoutStrategy blobLayoutStrategy;\n+  // Containers known to exist in the storage account\n+  private final Set<String> knownContainers = ConcurrentHashMap.newKeySet();\n+\n+  /**\n+   * Constructor for {@link StorageClient}.\n+   * @param azureCloudConfig {@link AzureCloudConfig} object.\n+   * @param cloudConfig {@link CloudConfig} object.\n+   */\n+  public StorageClient(AzureCloudConfig azureCloudConfig, CloudConfig cloudConfig,\n+      AzureBlobLayoutStrategy blobLayoutStrategy) {\n+    this.azureCloudConfig = azureCloudConfig;\n+    this.cloudConfig = cloudConfig;\n+    this.blobLayoutStrategy = blobLayoutStrategy;\n+    storageClientRef = new AtomicReference<>(createBlobStorageClient());\n+    blobBatchClientRef = new AtomicReference<>(new BlobBatchClientBuilder(storageClientRef.get()).buildClient());\n+  }\n+\n+  /**\n+   * Constructor for {@link StorageClient}.\n+   * @param blobServiceClient {@link BlobServiceClient} object.\n+   * @param blobBatchClient {@link BlobBatchClient} object.\n+   */\n+  public StorageClient(BlobServiceClient blobServiceClient, BlobBatchClient blobBatchClient,\n+      AzureBlobLayoutStrategy blobLayoutStrategy) {\n+    this.storageClientRef = new AtomicReference<>(blobServiceClient);\n+    this.blobBatchClientRef = new AtomicReference<>(blobBatchClient);\n+    this.blobLayoutStrategy = blobLayoutStrategy;\n+    this.cloudConfig = null;\n+    this.azureCloudConfig = null;\n+  }\n+\n+  /**\n+   * Visible for testing.\n+   * @return the underlying {@link BlobServiceClient}.\n+   */\n+  public BlobServiceClient getStorageClient() {\n+    return storageClientRef.get();\n+  }\n+\n+  /**\n+   * Creates a new block blob, or updates the content of an existing block blob.\n+   * @param blobId {@link BlobId} of the blob to upload.\n+   * @param data The data to write to the blob.\n+   * @param length The exact length of the data. It is important that this value match precisely the length of the\n+   * data provided in the {@link InputStream}.\n+   * @param headers {@link BlobHttpHeaders}\n+   * @param metadata Metadata to associate with the blob.\n+   * @param tier {@link AccessTier} for the destination blob.\n+   * @param contentMd5 An MD5 hash of the block content.\n+   * @param requestConditions {@link BlobRequestConditions}\n+   * @param timeout An optional timeout value beyond which a {@link RuntimeException} will be raised.\n+   * @return The information of the uploaded block blob.\n+   * @throws UnexpectedLengthException when the length of data does not match the input {@code length}.\n+   * @throws NullPointerException if the input data is null.\n+   * @throws UncheckedIOException If an I/O error occurs\n+   */\n+  public Response<BlockBlobItem> uploadWithResponse(BlobId blobId, InputStream data, long length,\n+      BlobHttpHeaders headers, Map<String, String> metadata, AccessTier tier, byte[] contentMd5,\n+      BlobRequestConditions requestConditions, Duration timeout) {\n+    return doStorageClientOperation(\n+        () -> getBlockBlobClient(blobId, true).uploadWithResponse(data, length, headers, metadata, tier, contentMd5,\n+            requestConditions, timeout, Context.NONE));\n+  }\n+\n+  /**\n+   * Creates a new block blob, or updates the content of an existing block blob.\n+   * @param containerName name of the Azure container where the blob lives.\n+   * @param blobName name of the blob.\n+   * @param autoCreateContainer flag indicating whether to create the container if it does not exist.\n+   * @param data The data to write to the blob.\n+   * @param length The exact length of the data. It is important that this value match precisely the length of the\n+   * data provided in the {@link InputStream}.\n+   * @param headers {@link BlobHttpHeaders}\n+   * @param metadata Metadata to associate with the blob.\n+   * @param tier {@link AccessTier} for the destination blob.\n+   * @param contentMd5 An MD5 hash of the block content.\n+   * @param requestConditions {@link BlobRequestConditions}\n+   * @param timeout An optional timeout value beyond which a {@link RuntimeException} will be raised.\n+   * @return The information of the uploaded block blob.\n+   * @throws UnexpectedLengthException when the length of data does not match the input {@code length}.\n+   * @throws NullPointerException if the input data is null.\n+   * @throws UncheckedIOException If an I/O error occurs\n+   */\n+  public Response<BlockBlobItem> uploadWithResponse(String containerName, String blobName, boolean autoCreateContainer,\n+      InputStream data, long length, BlobHttpHeaders headers, Map<String, String> metadata, AccessTier tier,\n+      byte[] contentMd5, BlobRequestConditions requestConditions, Duration timeout) {\n+    return doStorageClientOperation(\n+        () -> getBlockBlobClient(containerName, blobName, autoCreateContainer).uploadWithResponse(data, length, headers,\n+            metadata, tier, contentMd5, requestConditions, timeout, Context.NONE));\n+  }\n+\n+  /**\n+   * Downloads a range of bytes from a blob into an output stream.\n+   * @param containerName name of the Azure container where the blob lives.\n+   * @param blobName name of the blob.\n+   * @param autoCreateContainer flag indicating whether to create the container if it does not exist.\n+   * @param stream A non-null {@link OutputStream} instance where the downloaded data will be written.\n+   * @param range {@link BlobRange}\n+   * @param options {@link DownloadRetryOptions}\n+   * @param requestConditions {@link BlobRequestConditions}\n+   * @param getRangeContentMd5 Whether the contentMD5 for the specified blob range should be returned.\n+   * @param timeout An optional timeout value beyond which a {@link RuntimeException} will be raised.\n+   * @return A response containing status code and HTTP headers.\n+   * @throws UncheckedIOException If an I/O error occurs.\n+   * @throws NullPointerException if {@code stream} is null\n+   */\n+  public BlobDownloadResponse downloadWithResponse(String containerName, String blobName, boolean autoCreateContainer,\n+      OutputStream stream, BlobRange range, DownloadRetryOptions options, BlobRequestConditions requestConditions,\n+      boolean getRangeContentMd5, Duration timeout) {\n+    // Might as well use same timeout for upload and download\n+    return doStorageClientOperation(\n+        () -> getBlockBlobClient(containerName, blobName, false).downloadWithResponse(stream, null, null,\n+            requestConditions, false, timeout, Context.NONE));\n+  }\n+\n+  /**\n+   * Delete a file from blob storage, if it exists.\n+   * @param containerName name of the container containing file to delete.\n+   * @param fileName name of the file to delete.\n+   * @return true if the file was deleted, otherwise false.\n+   * @throws BlobStorageException for any error on ABS side.\n+   */\n+  boolean deleteFile(String containerName, String fileName) throws BlobStorageException {\n+    AtomicReference<Boolean> retValRef = new AtomicReference<>(false);\n+    doStorageClientOperation(() -> {\n+      BlockBlobClient blobClient = getBlockBlobClient(containerName, fileName, false);\n+      if (blobClient.exists()) {\n+        blobClient.delete();\n+        retValRef.set(true);\n+      }\n+      return null;\n+    });\n+    return retValRef.get();\n+  }\n+\n+  /**\n+   * Perform basic connectivity test.\n+   */\n+  void testConnectivity() {\n+    storageClientRef.get()\n+        .getBlobContainerClient(\"partition-0\")\n+        .existsWithResponse(Duration.ofSeconds(5), Context.NONE);\n+  }\n+\n+  /**\n+   * Returns the blob's metadata and properties.\n+   * @param blobId {@link BlobId}\n+   * @param requestConditions {@link BlobRequestConditions}\n+   * @param timeout An optional timeout value beyond which a {@link RuntimeException} will be raised.\n+   * @return The blob properties and metadata.\n+   */\n+  public BlobProperties getPropertiesWithResponse(BlobId blobId, BlobRequestConditions requestConditions,\n+      Duration timeout) {\n+    return doStorageClientOperation(\n+        () -> getBlockBlobClient(blobId, false).getPropertiesWithResponse(requestConditions, timeout, Context.NONE)\n+            .getValue());\n+  }\n+\n+  /**\n+   * Changes a blob's metadata. The specified metadata in this method will replace existing metadata. If old values\n+   * must be preserved, they must be downloaded and included in the call to this method.\n+   * @param blobId {@link BlobId} object.\n+   * @param metadata Metadata to associate with the blob.\n+   * @param requestConditions {@link BlobRequestConditions}\n+   * @param timeout An optional timeout value beyond which a {@link RuntimeException} will be raised.\n+   * @param context Additional context that is passed through the Http pipeline during the service call.\n+   */\n+  public void setMetadataWithResponse(BlobId blobId, Map<String, String> metadata,\n+      BlobRequestConditions requestConditions, Duration timeout, Context context) {\n+    doStorageClientOperation(\n+        () -> getBlockBlobClient(blobId, false).setMetadataWithResponse(metadata, requestConditions, timeout,\n+            Context.NONE));\n+  }\n+\n+  /**\n+   * Deletes a list of blobs.\n+   * @param batchOfBlobs {@link List} of {@link CloudBlobMetadata} objects.\n+   * @param timeout An optional timeout value beyond which a {@link RuntimeException} will be raised.\n+   * @return {@link List} of {@link Response}s for the blobs in the batch.\n+   * @throws RuntimeException If the {@code timeout} duration completes before a response is returned.\n+   * @throws BlobStorageException If the batch request is malformed.\n+   * @throws BlobBatchStorageException If {@code throwOnAnyFailure} is {@code true} and any request in the\n+   * {@link BlobBatch} failed.\n+   */\n+  public List<Response<Void>> deleteBatch(List<CloudBlobMetadata> batchOfBlobs, Duration timeout) {\n+    List<Response<Void>> responseList = new ArrayList<>();\n+    doStorageClientOperation(() -> {\n+      BlobBatch blobBatch = blobBatchClientRef.get().getBlobBatch();\n+      for (CloudBlobMetadata blobMetadata : batchOfBlobs) {\n+        AzureBlobLayoutStrategy.BlobLayout blobLayout = blobLayoutStrategy.getDataBlobLayout(blobMetadata);\n+        responseList.add(blobBatch.deleteBlob(blobLayout.containerName, blobLayout.blobFilePath));\n+      }\n+      blobBatchClientRef.get().submitBatchWithResponse(blobBatch, false, timeout, Context.NONE);\n+      return null;\n+    });\n+    return responseList;\n+  }\n+\n+  /**\n+   * Get the block blob client for the supplied blobid.\n+   * @param blobId id of the blob for which {@code BlockBlobClient} is needed.\n+   * @param autoCreateContainer flag indicating whether to create the container if it does not exist.\n+   * @return {@code BlockBlobClient} reference.\n+   */\n+  private BlockBlobClient getBlockBlobClient(BlobId blobId, boolean autoCreateContainer) {\n+    AzureBlobLayoutStrategy.BlobLayout blobLayout = blobLayoutStrategy.getDataBlobLayout(blobId);\n+    return getBlockBlobClient(blobLayout.containerName, blobLayout.blobFilePath, autoCreateContainer);\n+  }\n+\n+  /**\n+   * Get the block blob client for the supplied Azure container and blob name.\n+   * @param containerName name of the Azure container where the blob lives.\n+   * @param blobName name of the blob.\n+   * @param autoCreateContainer flag indicating whether to create the container if it does not exist.\n+   * @return {@code BlockBlobClient} reference.\n+   */\n+  BlockBlobClient getBlockBlobClient(String containerName, String blobName, boolean autoCreateContainer) {\n+    BlobContainerClient containerClient = getContainer(containerName, autoCreateContainer);\n+    return containerClient.getBlobClient(blobName).getBlockBlobClient();\n+  }\n+\n+  /**\n+   * Get a reference to an Azure container, creating it if necessary.\n+   * @param containerName the container name.\n+   * @param autoCreate flag indicating whether to create the container if it does not exist.\n+   * @return the created {@link BlobContainerClient}.\n+   */\n+  private BlobContainerClient getContainer(String containerName, boolean autoCreate) {\n+    BlobContainerClient containerClient = storageClientRef.get().getBlobContainerClient(containerName);\n+    if (autoCreate) {\n+      if (!knownContainers.contains(containerName)) {\n+        try {\n+          if (!containerClient.exists()) {\n+            containerClient.create();\n+            logger.info(\"Created container {}\", containerName);\n+          }\n+        } catch (BlobStorageException ex) {\n+          if (ex.getErrorCode() != BlobErrorCode.CONTAINER_ALREADY_EXISTS) {\n+            logger.error(\"Failed to create container {}\", containerName);\n+            throw ex;\n+          }\n+        }\n+        knownContainers.add(containerName);\n+      }\n+    }\n+    return containerClient;\n+  }\n+\n+  /**\n+   * Create the {@link BlobServiceClient} object.\n+   * @param {@link CloudConfig} object.\n+   * @param {@link AzureCloudConfig} object.\n+   * @return {@link BlobServiceClient} object.\n+   */\n+  protected BlobServiceClient createBlobStorageClient() {\n+    validateABSAuthConfigs(azureCloudConfig);\n+    Configuration storageConfiguration = new Configuration();\n+    // Check for network proxy\n+    ProxyOptions proxyOptions = (cloudConfig.vcrProxyHost == null) ? null : new ProxyOptions(ProxyOptions.Type.HTTP,\n+        new InetSocketAddress(cloudConfig.vcrProxyHost, cloudConfig.vcrProxyPort));\n+    if (proxyOptions != null) {\n+      logger.info(\"Using proxy: {}:{}\", cloudConfig.vcrProxyHost, cloudConfig.vcrProxyPort);\n+    }\n+    HttpClient client = new NettyAsyncHttpClientBuilder().proxy(proxyOptions).build();\n+\n+    // Note: retry decisions are made at CloudBlobStore level.  Configure storageClient with no retries.\n+    RequestRetryOptions noRetries = new RequestRetryOptions(RetryPolicyType.FIXED, 1, null, null, null, null);\n+    try {\n+      return buildBlobServiceClient(client, storageConfiguration, noRetries, azureCloudConfig);\n+    } catch (MalformedURLException | InterruptedException | ExecutionException ex) {\n+      logger.error(\"Error building ABS blob service client: {}\", ex.getMessage());\n+      throw new IllegalStateException(ex);\n+    }\n+  }\n+\n+  /**\n+   * Set the references for storage and blob clients atomically. Note this method is not thread safe and must always be\n+   * called within a thread safe context.\n+   * @param blobServiceClient {@link BlobServiceClient} object.\n+   */\n+  protected void setClientReferences(BlobServiceClient blobServiceClient) {\n+    storageClientRef.set(blobServiceClient);\n+    blobBatchClientRef.set(new BlobBatchClientBuilder(storageClientRef.get()).buildClient());\n+  }\n+\n+  /**\n+   * Execute the storage client operation represented by {@code operation}\n+   * @param operation {@link Callable} representing the operation.\n+   * @param <T> type of return value.\n+   * @return the return value of the operation.\n+   * @throws BlobStorageException\n+   */\n+  private <T> T doStorageClientOperation(Callable<T> operation) {\n+    int attempts = 0;\n+    T result = null;\n+    while (attempts <= 1) {\n+      attempts++;\n+      try {\n+        result = operation.call();\n+        break;\n+      } catch (BlobStorageException bsEx) {\n+        if (attempts == 1 && tryHandleExceptionAndHintRetry(bsEx)) {\n+          logger.info(\"Retrying blob store operation due to expired token\");\n+          continue;\n+        }\n+        throw bsEx;\n+      } catch (Exception ex) {\n+        // this should never happen.\n+        throw new IllegalStateException(\"Unknown blob storage exception\", ex);\n+      }\n+    }\n+    return result;\n+  }\n+\n+  /**\n+   * Validate that all the required configs for ABS authentication are present.\n+   * @param azureCloudConfig {@link AzureCloudConfig} object.\n+   */\n+  protected abstract void validateABSAuthConfigs(AzureCloudConfig azureCloudConfig);\n+\n+  /**\n+   * Build {@link BlobServiceClient}.\n+   * @param httpClient {@link HttpClient} object.\n+   * @param configuration {@link Configuration} object.\n+   * @param retryOptions {@link RetryOptions} object.\n+   * @param azureCloudConfig {@link AzureCloudConfig} object.\n+   * @return {@link BlobServiceClient} object.\n+   */\n+  protected abstract BlobServiceClient buildBlobServiceClient(HttpClient httpClient, Configuration configuration,\n+      RequestRetryOptions retryOptions, AzureCloudConfig azureCloudConfig)\n+      throws MalformedURLException, InterruptedException, ExecutionException;\n+\n+  /**\n+   * Check if the exception can be handled and return a flag indicating if it can be retried.\n+   * Note that if this method changes state of this class, then it should do it in a thread safe way.\n+   * @param blobStorageException {@link BlobStorageException} object.\n+   * @return true if the operation can be retried. false otherwise.\n+   */\n+  protected abstract boolean tryHandleExceptionAndHintRetry(BlobStorageException blobStorageException);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d79e254009d53d839cf5dc1f9d1e8fa533e917e9"}, "originalPosition": 412}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTAzMTc2NA==", "bodyText": "If the token was not expired, should we still retry?  What if it's a non-transient permission issue?", "url": "https://github.com/linkedin/ambry/pull/1688#discussion_r521031764", "createdAt": "2020-11-11T02:22:54Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/azure/ADAuthBasedStorageClient.java", "diffHunk": "@@ -87,4 +121,22 @@ private IAuthenticationResult getAccessTokenByClientCredentialGrant(AzureCloudCo\n         ClientCredentialParameters.builder(Collections.singleton(azureCloudConfig.azureStorageScope)).build();\n     return app.acquireToken(clientCredentialParam).get();\n   }\n+\n+  @Override\n+  protected boolean tryHandleExceptionAndHintRetry(BlobStorageException blobStorageException) {\n+    // If the exception has status code 403, refresh the token and create a new storage client with the new token.\n+    if (blobStorageException.getStatusCode() == HttpStatus.SC_FORBIDDEN) {\n+      synchronized (this) {\n+        // check if the access token has expired before refreshing the token. This is done to prevent multiple threads\n+        // to attempt token refresh at the same time. It is expected that as a result of token refresh, accessTokenRef\n+        // will updated with the new token.\n+        if (accessTokenRef.get().isExpired()) {\n+          BlobServiceClient blobServiceClient = createBlobStorageClient();\n+          setClientReferences(blobServiceClient);\n+        }\n+      }\n+      return true;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d79e254009d53d839cf5dc1f9d1e8fa533e917e9"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTAzMzg5NA==", "bodyText": "It's kind of unconventional to instantiate impl's instead of factories, but I'm not strongly opposed to it.", "url": "https://github.com/linkedin/ambry/pull/1688#discussion_r521033894", "createdAt": "2020-11-11T02:24:56Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/azure/AzureBlobDataAccessor.java", "diffHunk": "@@ -93,24 +84,28 @@ public AzureBlobDataAccessor(CloudConfig cloudConfig, AzureCloudConfig azureClou\n     uploadTimeout = Duration.ofMillis(cloudConfig.cloudUploadRequestTimeout);\n     batchTimeout = Duration.ofMillis(cloudConfig.cloudBatchRequestTimeout);\n \n-    StorageClientFactory storageClientFactory = Utils.getObj(azureCloudConfig.azureStorageClientFactoryClass);\n-    storageClient = storageClientFactory.createBlobStorageClient(cloudConfig, azureCloudConfig);\n-    blobBatchClient = new BlobBatchClientBuilder(storageClient).buildClient();\n+    storageClient =\n+        Utils.getObj(azureCloudConfig.azureStorageClientClass, azureCloudConfig, cloudConfig, blobLayoutStrategy);\n   }\n \n   /**\n    * Test constructor\n-   * @param storageClient the {@link BlobServiceClient} to use.\n+   * @param blobServiceClient the {@link BlobServiceClient} to use.\n    * @param blobBatchClient the {@link BlobBatchClient} to use.\n    * @param clusterName the cluster name to use.\n    * @param azureMetrics the {@link AzureMetrics} to use.\n    */\n-  AzureBlobDataAccessor(BlobServiceClient storageClient, BlobBatchClient blobBatchClient, String clusterName,\n+  AzureBlobDataAccessor(BlobServiceClient blobServiceClient, BlobBatchClient blobBatchClient, String clusterName,\n       AzureMetrics azureMetrics) {\n-    this.storageClient = storageClient;\n     this.blobLayoutStrategy = new AzureBlobLayoutStrategy(clusterName);\n+    try {\n+      this.storageClient =\n+          Utils.getObj(AzureCloudConfig.DEFAULT_AZURE_STORAGE_CLIENT_CLASS, blobServiceClient, blobBatchClient,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d79e254009d53d839cf5dc1f9d1e8fa533e917e9"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTAzNzA4NQ==", "bodyText": "ReflectiveOperationException was rethrown as IllegalStateException.  Not sure if other exceptions are thrown.", "url": "https://github.com/linkedin/ambry/pull/1688#discussion_r521037085", "createdAt": "2020-11-11T02:29:30Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/azure/AzureCloudDestination.java", "diffHunk": "@@ -91,7 +91,7 @@\n    */\n   AzureCloudDestination(CloudConfig cloudConfig, AzureCloudConfig azureCloudConfig, String clusterName,\n       VcrMetrics vcrMetrics, AzureMetrics azureMetrics, AzureReplicationFeed.FeedType azureReplicationFeedType,\n-      ClusterMap clusterMap) throws ReflectiveOperationException {\n+      ClusterMap clusterMap) throws Exception {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg1OTg2OA=="}, "originalCommit": {"oid": "d79e254009d53d839cf5dc1f9d1e8fa533e917e9"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTAzNzQxMw==", "bodyText": "Nit: cloudConfig before azureCloudConfig to be consistent.", "url": "https://github.com/linkedin/ambry/pull/1688#discussion_r521037413", "createdAt": "2020-11-11T02:30:01Z", "author": {"login": "lightningrob"}, "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/azure/ConnectionStringBasedStorageClient.java", "diffHunk": "@@ -17,13 +17,37 @@\n import com.azure.core.util.Configuration;\n import com.azure.storage.blob.BlobServiceClient;\n import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.batch.BlobBatchClient;\n+import com.azure.storage.blob.models.BlobStorageException;\n import com.azure.storage.common.policy.RequestRetryOptions;\n+import com.github.ambry.config.CloudConfig;\n \n \n /**\n- * {@link StorageClientFactory} implementation based on connection string authentication.\n+ * {@link StorageClient} implementation based on connection string authentication.\n  */\n-public class ConnectionStringBasedStorageClientFactory extends StorageClientFactory {\n+public class ConnectionStringBasedStorageClient extends StorageClient {\n+\n+  /**\n+   * Constructor for {@link ConnectionStringBasedStorageClient}.\n+   * @param azureCloudConfig {@link AzureCloudConfig} object.\n+   * @param cloudConfig {@link CloudConfig} object.\n+   */\n+  public ConnectionStringBasedStorageClient(AzureCloudConfig azureCloudConfig, CloudConfig cloudConfig,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d79e254009d53d839cf5dc1f9d1e8fa533e917e9"}, "originalPosition": 22}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2a76a3745f5f4725c841eafb6bbda9e96e323185", "author": {"user": {"login": "ankagrawal", "name": "Ankur Agrawal"}}, "url": "https://github.com/linkedin/ambry/commit/2a76a3745f5f4725c841eafb6bbda9e96e323185", "committedDate": "2020-11-11T20:57:13Z", "message": "Address review comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "85ee1f77b215135a78e28010a4321933216c26b6", "author": {"user": {"login": "ankagrawal", "name": "Ankur Agrawal"}}, "url": "https://github.com/linkedin/ambry/commit/85ee1f77b215135a78e28010a4321933216c26b6", "committedDate": "2020-11-12T08:52:22Z", "message": "Add metrics"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "16d19c4ba19a7bd0a45ae565123e0f2cce2b1d90", "author": {"user": {"login": "ankagrawal", "name": "Ankur Agrawal"}}, "url": "https://github.com/linkedin/ambry/commit/16d19c4ba19a7bd0a45ae565123e0f2cce2b1d90", "committedDate": "2020-11-12T19:16:02Z", "message": "Fix test"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI5NDIzMDE1", "url": "https://github.com/linkedin/ambry/pull/1688#pullrequestreview-529423015", "createdAt": "2020-11-12T19:26:04Z", "commit": {"oid": "16d19c4ba19a7bd0a45ae565123e0f2cce2b1d90"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 986, "cost": 1, "resetAt": "2021-11-01T16:19:10Z"}}}