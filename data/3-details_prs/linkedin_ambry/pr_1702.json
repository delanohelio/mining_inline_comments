{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTI2MDA4Mjc3", "number": 1702, "title": "[StorageQuota] Add MySql aggregation task", "bodyText": "Add mysql implementation of aggregation task and update AccountStatsStore to interface with mysql.", "createdAt": "2020-11-23T21:29:59Z", "url": "https://github.com/linkedin/ambry/pull/1702", "merged": true, "mergeCommit": {"oid": "2e1eb94c838e98876bd719e37a685dbd5efe3823"}, "closed": true, "closedAt": "2020-11-30T17:49:01Z", "author": {"login": "justinlin-linkedin"}, "timelineItems": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdftOa7AFqTUzNzczMjM3Ng==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdhfVfaAFqTU0MDYyNTY2NA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM3NzMyMzc2", "url": "https://github.com/linkedin/ambry/pull/1702#pullrequestreview-537732376", "createdAt": "2020-11-24T17:11:27Z", "commit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxNzoxMToyOFrOH5M1pg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxNzoyODozOVrOH5NjUQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTc0MTIyMg==", "bodyText": "javadoc", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r529741222", "createdAt": "2020-11-24T17:11:28Z", "author": {"login": "cgtz"}, "path": "ambry-api/src/main/java/com/github/ambry/clustermap/ClusterParticipant.java", "diffHunk": "@@ -32,10 +33,12 @@\n   /**\n    * Initiate the participation of cluster participant.\n    * @param ambryHealthReports {@link List} of {@link AmbryHealthReport} to be registered to the participant.\n+   * @param accountStatsStore", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTc0NDg0Mg==", "bodyText": "why are the account/container IDs in string format instead of Integer? Also, I remember their being another format where the stats report is grouped by partition class. Is that handled somewhere else?", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r529744842", "createdAt": "2020-11-24T17:16:49Z", "author": {"login": "cgtz"}, "path": "ambry-api/src/main/java/com/github/ambry/server/AccountStatsStore.java", "diffHunk": "@@ -0,0 +1,97 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.server;\n+\n+import java.util.Map;\n+\n+\n+/**\n+ * The interface that stores and fetches account stats, aggregated account stats.\n+ */\n+public interface AccountStatsStore {\n+  /**\n+   * Store stats in the {@link StatsWrapper}. The StatsWrapper's {@link StatsSnapshot} should include partition, account\n+   * and container. This method will be used for individual ambry server to store local stats.\n+   * @param statsWrapper The {@link StatsWrapper} that contains stats and other metadata.\n+   */\n+  void storeStats(StatsWrapper statsWrapper);\n+\n+  /**\n+   * Store aggregated stats in the {@link StatsSnapshot}. The StatsSnapshot should include account and container. This\n+   * method will be used for aggregation task to store aggregated stats.\n+   * @param snapshot The {@link StatsSnapshot} that contains aggregated container usage.\n+   * @throws Exception\n+   */\n+  void storeAggregatedStats(StatsSnapshot snapshot) throws Exception;\n+\n+  /**\n+   * Return individual ambry server's stats for the given {@code clusterName} and {@code hostname}. This is the stats\n+   * stored by method {@link #storeStats}.\n+   * @param clusterName The clusterName.\n+   * @param hostname The hostname.\n+   * @return {@link StatsWrapper} of given {@code hostname} in the {@code clusterName}.\n+   * @throws Exception\n+   */\n+  StatsWrapper queryStatsOf(String clusterName, String hostname) throws Exception;\n+\n+  /**\n+   * Return the aggregated stats for the given {@code clusterName}. This is the stats stored by method {@link #storeAggregatedStats}.\n+   * Since the {@link StatsSnapshot} passed to {@link #storeAggregatedStats} only have account and container stats, this\n+   * method returns a map back to the caller. The key of the outer map is the account id in string format, and the key of\n+   * the inner map is the container id in string format, the value of the inner map is the storage usage for this container.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTc0OTYxMg==", "bodyText": "What was the purpose of this piece of code resetting exceptionOccuredInstances for a given type again? Sorry, I'm not up to date on this.", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r529749612", "createdAt": "2020-11-24T17:23:57Z", "author": {"login": "cgtz"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixClusterAggregator.java", "diffHunk": "@@ -53,33 +54,59 @@\n    * for each partition.\n    * @throws IOException\n    */\n-  Pair<StatsSnapshot, StatsSnapshot> doWork(Map<String, String> statsWrappersJSON, StatsReportType type) throws IOException {\n+  Pair<StatsSnapshot, StatsSnapshot> doWork(Map<String, String> statsWrappersJSON, StatsReportType type)\n+      throws IOException {\n+    Map<String, StatsWrapper> statsWrappers = new HashMap<>();\n+    for (Map.Entry<String, String> statsWrapperJSON : statsWrappersJSON.entrySet()) {\n+      try {\n+        if (statsWrapperJSON != null && statsWrapperJSON.getValue() != null) {\n+          StatsWrapper snapshotWrapper = mapper.readValue(statsWrapperJSON.getValue(), StatsWrapper.class);\n+          statsWrappers.put(statsWrapperJSON.getKey(), snapshotWrapper);\n+        }\n+      } catch (Exception e) {\n+        logger.error(\"Exception occurred while processing stats from {}\", statsWrapperJSON.getKey(), e);\n+        exceptionOccurredInstances.computeIfAbsent(type, key -> new ArrayList<>()).add(statsWrapperJSON.getKey());\n+      }\n+    }\n+    return doWorkOnStatsWrapperMap(statsWrappers, type, false);\n+  }\n+\n+  Pair<StatsSnapshot, StatsSnapshot> doWorkOnStatsWrapperMap(Map<String, StatsWrapper> statsWrappers,\n+      StatsReportType type) throws IOException {\n+    return doWorkOnStatsWrapperMap(statsWrappers, type, true);\n+  }\n+\n+  Pair<StatsSnapshot, StatsSnapshot> doWorkOnStatsWrapperMap(Map<String, StatsWrapper> statsWrappers,\n+      StatsReportType type, boolean removeExceptionOnType) throws IOException {\n     StatsSnapshot partitionSnapshot = new StatsSnapshot(0L, new HashMap<>());\n     Map<String, Long> partitionTimestampMap = new HashMap<>();\n     StatsSnapshot rawPartitionSnapshot = new StatsSnapshot(0L, new HashMap<>());\n-    exceptionOccurredInstances.remove(type);\n-    for (Map.Entry<String, String> statsWrapperJSON : statsWrappersJSON.entrySet()) {\n-      if (statsWrapperJSON != null && statsWrapperJSON.getValue() != null) {\n+    if (removeExceptionOnType) {\n+      exceptionOccurredInstances.remove(type);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTc1MjkxMw==", "bodyText": "this may not be 100% accurate for a local deployment where multiple processes share the same host name but different ports.", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r529752913", "createdAt": "2020-11-24T17:28:39Z", "author": {"login": "cgtz"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/MySqlReportAggregatorTask.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.clustermap;\n+\n+import com.github.ambry.commons.Callback;\n+import com.github.ambry.config.ClusterMapConfig;\n+import com.github.ambry.server.AccountStatsStore;\n+import com.github.ambry.server.StatsReportType;\n+import com.github.ambry.server.StatsSnapshot;\n+import com.github.ambry.server.StatsWrapper;\n+import com.github.ambry.utils.Pair;\n+import com.github.ambry.utils.SystemTime;\n+import com.github.ambry.utils.Time;\n+import java.time.LocalDateTime;\n+import java.time.ZoneId;\n+import java.time.ZoneOffset;\n+import java.time.format.DateTimeFormatter;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.helix.HelixManager;\n+import org.apache.helix.task.Task;\n+import org.apache.helix.task.TaskResult;\n+import org.apache.helix.task.UserContentStore;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * MySql task to aggregate container storage usage across all storage nodes and update the aggregated stats.\n+ */\n+public class MySqlReportAggregatorTask extends UserContentStore implements Task {\n+  public static final String TASK_COMMAND_PREFIX = \"mysql_aggregate\";\n+  private static final Logger logger = LoggerFactory.getLogger(MySqlReportAggregatorTask.class);\n+  private static final ZoneOffset zoneOffset = ZoneId.systemDefault().getRules().getOffset(LocalDateTime.now());\n+  static final DateTimeFormatter TIMESTAMP_FORMATTER = DateTimeFormatter.ofPattern(\"yyyy-MM\");\n+  private final HelixClusterAggregator clusterAggregator;\n+  private final HelixManager manager;\n+  private final StatsReportType statsReportType;\n+  private final Callback<StatsSnapshot> callback;\n+  private final ClusterMapConfig clusterMapConfig;\n+  private final AccountStatsStore accountStatsStore;\n+  private final Time time;\n+\n+  /**\n+   * Instantiates {@link MySqlReportAggregatorTask}.\n+   * @param manager The {@link HelixManager} to retrieve all storage nodes.\n+   * @param relevantTimePeriodInMs relevant time period in ms within which values are considered to be valid. Values\n+   *                               outside of this period will be ignored.\n+   * @param statsReportType the type of stats report\n+   * @param accountStatsStore The {@link AccountStatsStore} to retrieve stats and store aggregated stats.\n+   * @param callback a callback which will be invoked when the aggregation report has been generated successfully.\n+   * @param clusterMapConfig the {@link ClusterMapConfig} associated with helix participant.\n+   */\n+  MySqlReportAggregatorTask(HelixManager manager, long relevantTimePeriodInMs, StatsReportType statsReportType,\n+      AccountStatsStore accountStatsStore, Callback<StatsSnapshot> callback, ClusterMapConfig clusterMapConfig) {\n+    this(manager, relevantTimePeriodInMs, statsReportType, accountStatsStore, callback, clusterMapConfig,\n+        SystemTime.getInstance());\n+  }\n+\n+  MySqlReportAggregatorTask(HelixManager manager, long relevantTimePeriodInMs, StatsReportType statsReportType,\n+      AccountStatsStore accountStatsStore, Callback<StatsSnapshot> callback, ClusterMapConfig clusterMapConfig,\n+      Time time) {\n+    this.manager = manager;\n+    clusterAggregator = new HelixClusterAggregator(relevantTimePeriodInMs);\n+    this.statsReportType = statsReportType;\n+    this.accountStatsStore = accountStatsStore;\n+    this.callback = callback;\n+    this.clusterMapConfig = clusterMapConfig;\n+    this.time = time;\n+  }\n+\n+  @Override\n+  public TaskResult run() {\n+    Pair<StatsSnapshot, StatsSnapshot> results = null;\n+    Exception exception = null;\n+    try {\n+      List<String> instanceNames = manager.getClusterManagmentTool().getInstancesInCluster(manager.getClusterName());\n+      Map<String, StatsWrapper> statsWrappers = new HashMap<>();\n+      for (String instanceName : instanceNames) {\n+        // Helix instance name would suffix port number, here let's take port number out.\n+        instanceName = stripPortNumber(instanceName);\n+        statsWrappers.put(instanceName,\n+            accountStatsStore.queryStatsOf(clusterMapConfig.clusterMapClusterName, instanceName));\n+      }\n+      results = clusterAggregator.doWorkOnStatsWrapperMap(statsWrappers, statsReportType);\n+      accountStatsStore.storeAggregatedStats(results.getSecond());\n+      // Create a base report at the beginning of each month.\n+      // Check if there is a base report for this month or not.\n+      if (clusterMapConfig.clustermapEnableAggregatedMonthlyAccountReport\n+          && statsReportType == StatsReportType.ACCOUNT_REPORT) {\n+        // Get the month, if not the same month, then copy the aggregated stats and update the month\n+        String currentMonthValue =\n+            LocalDateTime.ofEpochSecond(time.seconds(), 0, zoneOffset).format(TIMESTAMP_FORMATTER);\n+        String recordedMonthValue = accountStatsStore.queryRecordedMonth(clusterMapConfig.clusterMapClusterName);\n+        if (recordedMonthValue == null || recordedMonthValue.isEmpty() || !currentMonthValue.equals(\n+            recordedMonthValue)) {\n+          accountStatsStore.takeSnapshotOfAggregatedStatsSetMonth(clusterMapConfig.clusterMapClusterName,\n+              currentMonthValue);\n+        }\n+      }\n+      return new TaskResult(TaskResult.Status.COMPLETED, \"Aggregation success\");\n+    } catch (Exception e) {\n+      logger.error(\"Exception thrown while aggregating stats from health reports across all nodes \", e);\n+      exception = e;\n+      return new TaskResult(TaskResult.Status.FAILED, \"Exception thrown\");\n+    } finally {\n+      if (clusterMapConfig.clustermapEnableContainerDeletionAggregation && callback != null && results != null\n+          && statsReportType.equals(StatsReportType.ACCOUNT_REPORT)) {\n+        callback.onCompletion(results.getFirst(), exception);\n+      }\n+    }\n+  }\n+\n+  private String stripPortNumber(String instanceName) {\n+    return instanceName.replace(\"_\" + clusterMapConfig.clusterMapPort, \"\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 127}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM4MDcxNDAz", "url": "https://github.com/linkedin/ambry/pull/1702#pullrequestreview-538071403", "createdAt": "2020-11-25T00:31:18Z", "commit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "state": "COMMENTED", "comments": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwMDozMToxOFrOH5ekJA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwNjoxMzozOFrOH5kihw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDAzMTY1Mg==", "bodyText": "If we want to support partition class stats report in near future, can we add a stats type in the method in future PR?  (let's leave a TODO note here)", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r530031652", "createdAt": "2020-11-25T00:31:18Z", "author": {"login": "jsjtzyy"}, "path": "ambry-api/src/main/java/com/github/ambry/server/AccountStatsStore.java", "diffHunk": "@@ -0,0 +1,97 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.server;\n+\n+import java.util.Map;\n+\n+\n+/**\n+ * The interface that stores and fetches account stats, aggregated account stats.\n+ */\n+public interface AccountStatsStore {\n+  /**\n+   * Store stats in the {@link StatsWrapper}. The StatsWrapper's {@link StatsSnapshot} should include partition, account\n+   * and container. This method will be used for individual ambry server to store local stats.\n+   * @param statsWrapper The {@link StatsWrapper} that contains stats and other metadata.\n+   */\n+  void storeStats(StatsWrapper statsWrapper);\n+\n+  /**\n+   * Store aggregated stats in the {@link StatsSnapshot}. The StatsSnapshot should include account and container. This\n+   * method will be used for aggregation task to store aggregated stats.\n+   * @param snapshot The {@link StatsSnapshot} that contains aggregated container usage.\n+   * @throws Exception\n+   */\n+  void storeAggregatedStats(StatsSnapshot snapshot) throws Exception;\n+\n+  /**\n+   * Return individual ambry server's stats for the given {@code clusterName} and {@code hostname}. This is the stats\n+   * stored by method {@link #storeStats}.\n+   * @param clusterName The clusterName.\n+   * @param hostname The hostname.\n+   * @return {@link StatsWrapper} of given {@code hostname} in the {@code clusterName}.\n+   * @throws Exception\n+   */\n+  StatsWrapper queryStatsOf(String clusterName, String hostname) throws Exception;\n+\n+  /**\n+   * Return the aggregated stats for the given {@code clusterName}. This is the stats stored by method {@link #storeAggregatedStats}.\n+   * Since the {@link StatsSnapshot} passed to {@link #storeAggregatedStats} only have account and container stats, this\n+   * method returns a map back to the caller. The key of the outer map is the account id in string format, and the key of\n+   * the inner map is the container id in string format, the value of the inner map is the storage usage for this container.\n+   * <pre>\n+   *   {\n+   *     \"1001\": {\n+   *       \"1\": 10456,\n+   *       \"2\": 75637292\n+   *     },\n+   *     \"1002\": {\n+   *       \"8\": 1785385436\n+   *     }\n+   *   }\n+   * </pre>\n+   * @param clusterName The clusterName.\n+   * @return The map that represents the container storage usage.\n+   * @throws Exception\n+   */\n+  Map<String, Map<String, Long>> queryAggregatedStats(String clusterName) throws Exception;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDExNDY4MA==", "bodyText": "minor: could you give an example of return value?", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r530114680", "createdAt": "2020-11-25T05:21:28Z", "author": {"login": "jsjtzyy"}, "path": "ambry-api/src/main/java/com/github/ambry/server/AccountStatsStore.java", "diffHunk": "@@ -0,0 +1,97 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.server;\n+\n+import java.util.Map;\n+\n+\n+/**\n+ * The interface that stores and fetches account stats, aggregated account stats.\n+ */\n+public interface AccountStatsStore {\n+  /**\n+   * Store stats in the {@link StatsWrapper}. The StatsWrapper's {@link StatsSnapshot} should include partition, account\n+   * and container. This method will be used for individual ambry server to store local stats.\n+   * @param statsWrapper The {@link StatsWrapper} that contains stats and other metadata.\n+   */\n+  void storeStats(StatsWrapper statsWrapper);\n+\n+  /**\n+   * Store aggregated stats in the {@link StatsSnapshot}. The StatsSnapshot should include account and container. This\n+   * method will be used for aggregation task to store aggregated stats.\n+   * @param snapshot The {@link StatsSnapshot} that contains aggregated container usage.\n+   * @throws Exception\n+   */\n+  void storeAggregatedStats(StatsSnapshot snapshot) throws Exception;\n+\n+  /**\n+   * Return individual ambry server's stats for the given {@code clusterName} and {@code hostname}. This is the stats\n+   * stored by method {@link #storeStats}.\n+   * @param clusterName The clusterName.\n+   * @param hostname The hostname.\n+   * @return {@link StatsWrapper} of given {@code hostname} in the {@code clusterName}.\n+   * @throws Exception\n+   */\n+  StatsWrapper queryStatsOf(String clusterName, String hostname) throws Exception;\n+\n+  /**\n+   * Return the aggregated stats for the given {@code clusterName}. This is the stats stored by method {@link #storeAggregatedStats}.\n+   * Since the {@link StatsSnapshot} passed to {@link #storeAggregatedStats} only have account and container stats, this\n+   * method returns a map back to the caller. The key of the outer map is the account id in string format, and the key of\n+   * the inner map is the container id in string format, the value of the inner map is the storage usage for this container.\n+   * <pre>\n+   *   {\n+   *     \"1001\": {\n+   *       \"1\": 10456,\n+   *       \"2\": 75637292\n+   *     },\n+   *     \"1002\": {\n+   *       \"8\": 1785385436\n+   *     }\n+   *   }\n+   * </pre>\n+   * @param clusterName The clusterName.\n+   * @return The map that represents the container storage usage.\n+   * @throws Exception\n+   */\n+  Map<String, Map<String, Long>> queryAggregatedStats(String clusterName) throws Exception;\n+\n+  /**\n+   * Return the monthly aggregated stats. This method returns a map in the same format as the {@link #queryAggregatedStats}.\n+   * The only difference these two methods have is that this method's returned value only changes in the beginning of each\n+   * month. For every new month(in local zone offset), an aggregated stats will be written to storage and a snapshot will\n+   * be created. This method will return current snapshot. This method doesn't require a month value to fetch the snapshot\n+   * as this new snapshot will be override the old ones.\n+   * @param clusterName The clusterName.\n+   * @return The map thtat represents the container storage usage.\n+   * @throws Exception\n+   */\n+  Map<String, Map<String, Long>> queryMonthlyAggregatedStats(String clusterName) throws Exception;\n+\n+  /**\n+   * Return the month value of the current container storage snapshot.\n+   * @param clusterName The clusterName.\n+   * @return The month value for current snapshot.\n+   * @throws Exception\n+   */\n+  String queryRecordedMonth(String clusterName) throws Exception;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDExNTQ5Mg==", "bodyText": "Let's call this takeSnapshotOfAggregatedStatsAndUpdateMonth or takeStatsSnapshotAndUpdateMonth", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r530115492", "createdAt": "2020-11-25T05:24:39Z", "author": {"login": "jsjtzyy"}, "path": "ambry-api/src/main/java/com/github/ambry/server/AccountStatsStore.java", "diffHunk": "@@ -0,0 +1,97 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.server;\n+\n+import java.util.Map;\n+\n+\n+/**\n+ * The interface that stores and fetches account stats, aggregated account stats.\n+ */\n+public interface AccountStatsStore {\n+  /**\n+   * Store stats in the {@link StatsWrapper}. The StatsWrapper's {@link StatsSnapshot} should include partition, account\n+   * and container. This method will be used for individual ambry server to store local stats.\n+   * @param statsWrapper The {@link StatsWrapper} that contains stats and other metadata.\n+   */\n+  void storeStats(StatsWrapper statsWrapper);\n+\n+  /**\n+   * Store aggregated stats in the {@link StatsSnapshot}. The StatsSnapshot should include account and container. This\n+   * method will be used for aggregation task to store aggregated stats.\n+   * @param snapshot The {@link StatsSnapshot} that contains aggregated container usage.\n+   * @throws Exception\n+   */\n+  void storeAggregatedStats(StatsSnapshot snapshot) throws Exception;\n+\n+  /**\n+   * Return individual ambry server's stats for the given {@code clusterName} and {@code hostname}. This is the stats\n+   * stored by method {@link #storeStats}.\n+   * @param clusterName The clusterName.\n+   * @param hostname The hostname.\n+   * @return {@link StatsWrapper} of given {@code hostname} in the {@code clusterName}.\n+   * @throws Exception\n+   */\n+  StatsWrapper queryStatsOf(String clusterName, String hostname) throws Exception;\n+\n+  /**\n+   * Return the aggregated stats for the given {@code clusterName}. This is the stats stored by method {@link #storeAggregatedStats}.\n+   * Since the {@link StatsSnapshot} passed to {@link #storeAggregatedStats} only have account and container stats, this\n+   * method returns a map back to the caller. The key of the outer map is the account id in string format, and the key of\n+   * the inner map is the container id in string format, the value of the inner map is the storage usage for this container.\n+   * <pre>\n+   *   {\n+   *     \"1001\": {\n+   *       \"1\": 10456,\n+   *       \"2\": 75637292\n+   *     },\n+   *     \"1002\": {\n+   *       \"8\": 1785385436\n+   *     }\n+   *   }\n+   * </pre>\n+   * @param clusterName The clusterName.\n+   * @return The map that represents the container storage usage.\n+   * @throws Exception\n+   */\n+  Map<String, Map<String, Long>> queryAggregatedStats(String clusterName) throws Exception;\n+\n+  /**\n+   * Return the monthly aggregated stats. This method returns a map in the same format as the {@link #queryAggregatedStats}.\n+   * The only difference these two methods have is that this method's returned value only changes in the beginning of each\n+   * month. For every new month(in local zone offset), an aggregated stats will be written to storage and a snapshot will\n+   * be created. This method will return current snapshot. This method doesn't require a month value to fetch the snapshot\n+   * as this new snapshot will be override the old ones.\n+   * @param clusterName The clusterName.\n+   * @return The map thtat represents the container storage usage.\n+   * @throws Exception\n+   */\n+  Map<String, Map<String, Long>> queryMonthlyAggregatedStats(String clusterName) throws Exception;\n+\n+  /**\n+   * Return the month value of the current container storage snapshot.\n+   * @param clusterName The clusterName.\n+   * @return The month value for current snapshot.\n+   * @throws Exception\n+   */\n+  String queryRecordedMonth(String clusterName) throws Exception;\n+\n+  /**\n+   * Taking a snapshot of current aggregated stats and update the month value.\n+   * @param clusterName The clusterName.\n+   * @param monthValue The month in string format, like \"2020-01\".\n+   * @throws Exception\n+   */\n+  void takeSnapshotOfAggregatedStatsSetMonth(String clusterName, String monthValue) throws Exception;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 96}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDExNjQ1NA==", "bodyText": "minor: can be simplified to\noriginal.subMap.forEach((k, v) -> this.subMap.put(k, new StatsSnapshot(v)));", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r530116454", "createdAt": "2020-11-25T05:28:39Z", "author": {"login": "jsjtzyy"}, "path": "ambry-api/src/main/java/com/github/ambry/server/StatsSnapshot.java", "diffHunk": "@@ -62,6 +62,20 @@ public StatsSnapshot() {\n     // empty constructor for Jackson deserialization\n   }\n \n+  /**\n+   * A copy constructor.\n+   * @param original The original copy.\n+   */\n+  public StatsSnapshot(StatsSnapshot original) {\n+    this.value = original.value;\n+    if (original.subMap != null) {\n+      this.subMap = new HashMap<>(original.subMap.size());\n+      original.subMap.forEach((k, v) -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDExOTMzMA==", "bodyText": "We can consider removing this rawPartitionSnapshots.  Instead, we could add an aggregated snapshot to track physical disk capacity occupied by each account/container (including data deleted/expired but hasn't been compacted.)", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r530119330", "createdAt": "2020-11-25T05:39:18Z", "author": {"login": "jsjtzyy"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixClusterAggregator.java", "diffHunk": "@@ -53,33 +54,59 @@\n    * for each partition.\n    * @throws IOException\n    */\n-  Pair<StatsSnapshot, StatsSnapshot> doWork(Map<String, String> statsWrappersJSON, StatsReportType type) throws IOException {\n+  Pair<StatsSnapshot, StatsSnapshot> doWork(Map<String, String> statsWrappersJSON, StatsReportType type)\n+      throws IOException {\n+    Map<String, StatsWrapper> statsWrappers = new HashMap<>();\n+    for (Map.Entry<String, String> statsWrapperJSON : statsWrappersJSON.entrySet()) {\n+      try {\n+        if (statsWrapperJSON != null && statsWrapperJSON.getValue() != null) {\n+          StatsWrapper snapshotWrapper = mapper.readValue(statsWrapperJSON.getValue(), StatsWrapper.class);\n+          statsWrappers.put(statsWrapperJSON.getKey(), snapshotWrapper);\n+        }\n+      } catch (Exception e) {\n+        logger.error(\"Exception occurred while processing stats from {}\", statsWrapperJSON.getKey(), e);\n+        exceptionOccurredInstances.computeIfAbsent(type, key -> new ArrayList<>()).add(statsWrapperJSON.getKey());\n+      }\n+    }\n+    return doWorkOnStatsWrapperMap(statsWrappers, type, false);\n+  }\n+\n+  Pair<StatsSnapshot, StatsSnapshot> doWorkOnStatsWrapperMap(Map<String, StatsWrapper> statsWrappers,\n+      StatsReportType type) throws IOException {\n+    return doWorkOnStatsWrapperMap(statsWrappers, type, true);\n+  }\n+\n+  Pair<StatsSnapshot, StatsSnapshot> doWorkOnStatsWrapperMap(Map<String, StatsWrapper> statsWrappers,\n+      StatsReportType type, boolean removeExceptionOnType) throws IOException {\n     StatsSnapshot partitionSnapshot = new StatsSnapshot(0L, new HashMap<>());\n     Map<String, Long> partitionTimestampMap = new HashMap<>();\n     StatsSnapshot rawPartitionSnapshot = new StatsSnapshot(0L, new HashMap<>());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDEyMTIyMw==", "bodyText": "I added this exceptionOccurredInstances.remove(type); because same node may be chose to do aggregation twice and it resets the map for given type to clean up old data from last round.", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r530121223", "createdAt": "2020-11-25T05:45:56Z", "author": {"login": "jsjtzyy"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixClusterAggregator.java", "diffHunk": "@@ -53,33 +54,59 @@\n    * for each partition.\n    * @throws IOException\n    */\n-  Pair<StatsSnapshot, StatsSnapshot> doWork(Map<String, String> statsWrappersJSON, StatsReportType type) throws IOException {\n+  Pair<StatsSnapshot, StatsSnapshot> doWork(Map<String, String> statsWrappersJSON, StatsReportType type)\n+      throws IOException {\n+    Map<String, StatsWrapper> statsWrappers = new HashMap<>();\n+    for (Map.Entry<String, String> statsWrapperJSON : statsWrappersJSON.entrySet()) {\n+      try {\n+        if (statsWrapperJSON != null && statsWrapperJSON.getValue() != null) {\n+          StatsWrapper snapshotWrapper = mapper.readValue(statsWrapperJSON.getValue(), StatsWrapper.class);\n+          statsWrappers.put(statsWrapperJSON.getKey(), snapshotWrapper);\n+        }\n+      } catch (Exception e) {\n+        logger.error(\"Exception occurred while processing stats from {}\", statsWrapperJSON.getKey(), e);\n+        exceptionOccurredInstances.computeIfAbsent(type, key -> new ArrayList<>()).add(statsWrapperJSON.getKey());\n+      }\n+    }\n+    return doWorkOnStatsWrapperMap(statsWrappers, type, false);\n+  }\n+\n+  Pair<StatsSnapshot, StatsSnapshot> doWorkOnStatsWrapperMap(Map<String, StatsWrapper> statsWrappers,\n+      StatsReportType type) throws IOException {\n+    return doWorkOnStatsWrapperMap(statsWrappers, type, true);\n+  }\n+\n+  Pair<StatsSnapshot, StatsSnapshot> doWorkOnStatsWrapperMap(Map<String, StatsWrapper> statsWrappers,\n+      StatsReportType type, boolean removeExceptionOnType) throws IOException {\n     StatsSnapshot partitionSnapshot = new StatsSnapshot(0L, new HashMap<>());\n     Map<String, Long> partitionTimestampMap = new HashMap<>();\n     StatsSnapshot rawPartitionSnapshot = new StatsSnapshot(0L, new HashMap<>());\n-    exceptionOccurredInstances.remove(type);\n-    for (Map.Entry<String, String> statsWrapperJSON : statsWrappersJSON.entrySet()) {\n-      if (statsWrapperJSON != null && statsWrapperJSON.getValue() != null) {\n+    if (removeExceptionOnType) {\n+      exceptionOccurredInstances.remove(type);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTc0OTYxMg=="}, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDEyNTE5Mw==", "bodyText": "Minor: For MySqlAggregator, it is correct; For HelixAggregator, I would suggest putting it to the very beginning of doWork().", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r530125193", "createdAt": "2020-11-25T05:59:32Z", "author": {"login": "jsjtzyy"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixClusterAggregator.java", "diffHunk": "@@ -53,33 +54,59 @@\n    * for each partition.\n    * @throws IOException\n    */\n-  Pair<StatsSnapshot, StatsSnapshot> doWork(Map<String, String> statsWrappersJSON, StatsReportType type) throws IOException {\n+  Pair<StatsSnapshot, StatsSnapshot> doWork(Map<String, String> statsWrappersJSON, StatsReportType type)\n+      throws IOException {\n+    Map<String, StatsWrapper> statsWrappers = new HashMap<>();\n+    for (Map.Entry<String, String> statsWrapperJSON : statsWrappersJSON.entrySet()) {\n+      try {\n+        if (statsWrapperJSON != null && statsWrapperJSON.getValue() != null) {\n+          StatsWrapper snapshotWrapper = mapper.readValue(statsWrapperJSON.getValue(), StatsWrapper.class);\n+          statsWrappers.put(statsWrapperJSON.getKey(), snapshotWrapper);\n+        }\n+      } catch (Exception e) {\n+        logger.error(\"Exception occurred while processing stats from {}\", statsWrapperJSON.getKey(), e);\n+        exceptionOccurredInstances.computeIfAbsent(type, key -> new ArrayList<>()).add(statsWrapperJSON.getKey());\n+      }\n+    }\n+    return doWorkOnStatsWrapperMap(statsWrappers, type, false);\n+  }\n+\n+  Pair<StatsSnapshot, StatsSnapshot> doWorkOnStatsWrapperMap(Map<String, StatsWrapper> statsWrappers,\n+      StatsReportType type) throws IOException {\n+    return doWorkOnStatsWrapperMap(statsWrappers, type, true);\n+  }\n+\n+  Pair<StatsSnapshot, StatsSnapshot> doWorkOnStatsWrapperMap(Map<String, StatsWrapper> statsWrappers,\n+      StatsReportType type, boolean removeExceptionOnType) throws IOException {\n     StatsSnapshot partitionSnapshot = new StatsSnapshot(0L, new HashMap<>());\n     Map<String, Long> partitionTimestampMap = new HashMap<>();\n     StatsSnapshot rawPartitionSnapshot = new StatsSnapshot(0L, new HashMap<>());\n-    exceptionOccurredInstances.remove(type);\n-    for (Map.Entry<String, String> statsWrapperJSON : statsWrappersJSON.entrySet()) {\n-      if (statsWrapperJSON != null && statsWrapperJSON.getValue() != null) {\n+    if (removeExceptionOnType) {\n+      exceptionOccurredInstances.remove(type);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTc0OTYxMg=="}, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDEyNzE5NQ==", "bodyText": "minor: add java doc for accountStatsStore", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r530127195", "createdAt": "2020-11-25T06:06:02Z", "author": {"login": "jsjtzyy"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixParticipant.java", "diffHunk": "@@ -123,14 +125,14 @@ public void setInitialLocalPartitions(Collection<String> localPartitions) {\n    * @throws IOException if there is an error connecting to the Helix cluster.\n    */\n   @Override\n-  public void participate(List<AmbryHealthReport> ambryHealthReports, Callback<StatsSnapshot> callback)\n-      throws IOException {\n+  public void participate(List<AmbryHealthReport> ambryHealthReports, AccountStatsStore accountStatsStore,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDEyNzU0Ng==", "bodyText": "same here. (Also, we should consider removing the callback, this can be done in future PR)", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r530127546", "createdAt": "2020-11-25T06:07:07Z", "author": {"login": "jsjtzyy"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixParticipant.java", "diffHunk": "@@ -439,7 +441,7 @@ private void awaitDisablingPartition() throws InterruptedException {\n    * @param callback a callback which will be invoked when the aggregation report has been generated successfully.\n    */\n   private void registerHealthReportTasks(StateMachineEngine engine, List<AmbryHealthReport> healthReports,\n-      Callback<StatsSnapshot> callback) {\n+      AccountStatsStore accountStatsStore, Callback<StatsSnapshot> callback) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDEyODk4NA==", "bodyText": "Why we need to constructors here?", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r530128984", "createdAt": "2020-11-25T06:11:49Z", "author": {"login": "jsjtzyy"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/MySqlReportAggregatorTask.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.clustermap;\n+\n+import com.github.ambry.commons.Callback;\n+import com.github.ambry.config.ClusterMapConfig;\n+import com.github.ambry.server.AccountStatsStore;\n+import com.github.ambry.server.StatsReportType;\n+import com.github.ambry.server.StatsSnapshot;\n+import com.github.ambry.server.StatsWrapper;\n+import com.github.ambry.utils.Pair;\n+import com.github.ambry.utils.SystemTime;\n+import com.github.ambry.utils.Time;\n+import java.time.LocalDateTime;\n+import java.time.ZoneId;\n+import java.time.ZoneOffset;\n+import java.time.format.DateTimeFormatter;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.helix.HelixManager;\n+import org.apache.helix.task.Task;\n+import org.apache.helix.task.TaskResult;\n+import org.apache.helix.task.UserContentStore;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * MySql task to aggregate container storage usage across all storage nodes and update the aggregated stats.\n+ */\n+public class MySqlReportAggregatorTask extends UserContentStore implements Task {\n+  public static final String TASK_COMMAND_PREFIX = \"mysql_aggregate\";\n+  private static final Logger logger = LoggerFactory.getLogger(MySqlReportAggregatorTask.class);\n+  private static final ZoneOffset zoneOffset = ZoneId.systemDefault().getRules().getOffset(LocalDateTime.now());\n+  static final DateTimeFormatter TIMESTAMP_FORMATTER = DateTimeFormatter.ofPattern(\"yyyy-MM\");\n+  private final HelixClusterAggregator clusterAggregator;\n+  private final HelixManager manager;\n+  private final StatsReportType statsReportType;\n+  private final Callback<StatsSnapshot> callback;\n+  private final ClusterMapConfig clusterMapConfig;\n+  private final AccountStatsStore accountStatsStore;\n+  private final Time time;\n+\n+  /**\n+   * Instantiates {@link MySqlReportAggregatorTask}.\n+   * @param manager The {@link HelixManager} to retrieve all storage nodes.\n+   * @param relevantTimePeriodInMs relevant time period in ms within which values are considered to be valid. Values\n+   *                               outside of this period will be ignored.\n+   * @param statsReportType the type of stats report\n+   * @param accountStatsStore The {@link AccountStatsStore} to retrieve stats and store aggregated stats.\n+   * @param callback a callback which will be invoked when the aggregation report has been generated successfully.\n+   * @param clusterMapConfig the {@link ClusterMapConfig} associated with helix participant.\n+   */\n+  MySqlReportAggregatorTask(HelixManager manager, long relevantTimePeriodInMs, StatsReportType statsReportType,\n+      AccountStatsStore accountStatsStore, Callback<StatsSnapshot> callback, ClusterMapConfig clusterMapConfig) {\n+    this(manager, relevantTimePeriodInMs, statsReportType, accountStatsStore, callback, clusterMapConfig,\n+        SystemTime.getInstance());\n+  }\n+\n+  MySqlReportAggregatorTask(HelixManager manager, long relevantTimePeriodInMs, StatsReportType statsReportType,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDEyOTU0Mw==", "bodyText": "let's update this error message to reflect aggregation on mysql based stats report.", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r530129543", "createdAt": "2020-11-25T06:13:38Z", "author": {"login": "jsjtzyy"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/MySqlReportAggregatorTask.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.clustermap;\n+\n+import com.github.ambry.commons.Callback;\n+import com.github.ambry.config.ClusterMapConfig;\n+import com.github.ambry.server.AccountStatsStore;\n+import com.github.ambry.server.StatsReportType;\n+import com.github.ambry.server.StatsSnapshot;\n+import com.github.ambry.server.StatsWrapper;\n+import com.github.ambry.utils.Pair;\n+import com.github.ambry.utils.SystemTime;\n+import com.github.ambry.utils.Time;\n+import java.time.LocalDateTime;\n+import java.time.ZoneId;\n+import java.time.ZoneOffset;\n+import java.time.format.DateTimeFormatter;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.helix.HelixManager;\n+import org.apache.helix.task.Task;\n+import org.apache.helix.task.TaskResult;\n+import org.apache.helix.task.UserContentStore;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * MySql task to aggregate container storage usage across all storage nodes and update the aggregated stats.\n+ */\n+public class MySqlReportAggregatorTask extends UserContentStore implements Task {\n+  public static final String TASK_COMMAND_PREFIX = \"mysql_aggregate\";\n+  private static final Logger logger = LoggerFactory.getLogger(MySqlReportAggregatorTask.class);\n+  private static final ZoneOffset zoneOffset = ZoneId.systemDefault().getRules().getOffset(LocalDateTime.now());\n+  static final DateTimeFormatter TIMESTAMP_FORMATTER = DateTimeFormatter.ofPattern(\"yyyy-MM\");\n+  private final HelixClusterAggregator clusterAggregator;\n+  private final HelixManager manager;\n+  private final StatsReportType statsReportType;\n+  private final Callback<StatsSnapshot> callback;\n+  private final ClusterMapConfig clusterMapConfig;\n+  private final AccountStatsStore accountStatsStore;\n+  private final Time time;\n+\n+  /**\n+   * Instantiates {@link MySqlReportAggregatorTask}.\n+   * @param manager The {@link HelixManager} to retrieve all storage nodes.\n+   * @param relevantTimePeriodInMs relevant time period in ms within which values are considered to be valid. Values\n+   *                               outside of this period will be ignored.\n+   * @param statsReportType the type of stats report\n+   * @param accountStatsStore The {@link AccountStatsStore} to retrieve stats and store aggregated stats.\n+   * @param callback a callback which will be invoked when the aggregation report has been generated successfully.\n+   * @param clusterMapConfig the {@link ClusterMapConfig} associated with helix participant.\n+   */\n+  MySqlReportAggregatorTask(HelixManager manager, long relevantTimePeriodInMs, StatsReportType statsReportType,\n+      AccountStatsStore accountStatsStore, Callback<StatsSnapshot> callback, ClusterMapConfig clusterMapConfig) {\n+    this(manager, relevantTimePeriodInMs, statsReportType, accountStatsStore, callback, clusterMapConfig,\n+        SystemTime.getInstance());\n+  }\n+\n+  MySqlReportAggregatorTask(HelixManager manager, long relevantTimePeriodInMs, StatsReportType statsReportType,\n+      AccountStatsStore accountStatsStore, Callback<StatsSnapshot> callback, ClusterMapConfig clusterMapConfig,\n+      Time time) {\n+    this.manager = manager;\n+    clusterAggregator = new HelixClusterAggregator(relevantTimePeriodInMs);\n+    this.statsReportType = statsReportType;\n+    this.accountStatsStore = accountStatsStore;\n+    this.callback = callback;\n+    this.clusterMapConfig = clusterMapConfig;\n+    this.time = time;\n+  }\n+\n+  @Override\n+  public TaskResult run() {\n+    Pair<StatsSnapshot, StatsSnapshot> results = null;\n+    Exception exception = null;\n+    try {\n+      List<String> instanceNames = manager.getClusterManagmentTool().getInstancesInCluster(manager.getClusterName());\n+      Map<String, StatsWrapper> statsWrappers = new HashMap<>();\n+      for (String instanceName : instanceNames) {\n+        // Helix instance name would suffix port number, here let's take port number out.\n+        instanceName = stripPortNumber(instanceName);\n+        statsWrappers.put(instanceName,\n+            accountStatsStore.queryStatsOf(clusterMapConfig.clusterMapClusterName, instanceName));\n+      }\n+      results = clusterAggregator.doWorkOnStatsWrapperMap(statsWrappers, statsReportType);\n+      accountStatsStore.storeAggregatedStats(results.getSecond());\n+      // Create a base report at the beginning of each month.\n+      // Check if there is a base report for this month or not.\n+      if (clusterMapConfig.clustermapEnableAggregatedMonthlyAccountReport\n+          && statsReportType == StatsReportType.ACCOUNT_REPORT) {\n+        // Get the month, if not the same month, then copy the aggregated stats and update the month\n+        String currentMonthValue =\n+            LocalDateTime.ofEpochSecond(time.seconds(), 0, zoneOffset).format(TIMESTAMP_FORMATTER);\n+        String recordedMonthValue = accountStatsStore.queryRecordedMonth(clusterMapConfig.clusterMapClusterName);\n+        if (recordedMonthValue == null || recordedMonthValue.isEmpty() || !currentMonthValue.equals(\n+            recordedMonthValue)) {\n+          accountStatsStore.takeSnapshotOfAggregatedStatsSetMonth(clusterMapConfig.clusterMapClusterName,\n+              currentMonthValue);\n+        }\n+      }\n+      return new TaskResult(TaskResult.Status.COMPLETED, \"Aggregation success\");\n+    } catch (Exception e) {\n+      logger.error(\"Exception thrown while aggregating stats from health reports across all nodes \", e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 115}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM4Njg3Nzk0", "url": "https://github.com/linkedin/ambry/pull/1702#pullrequestreview-538687794", "createdAt": "2020-11-25T16:51:08Z", "commit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxNjo1MTowOFrOH58H3A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxNjo1MTowOFrOH58H3A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDUxNTkzMg==", "bodyText": "Do we want to use the latest updated storageUsage value or just the last one in order?", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r530515932", "createdAt": "2020-11-25T16:51:08Z", "author": {"login": "cgtz"}, "path": "ambry-server/src/main/java/com/github/ambry/server/mysql/AccountStatsMySqlStore.java", "diffHunk": "@@ -125,21 +137,98 @@ public void publish(StatsWrapper statsWrapper) {\n    * @return {@link StatsSnapshot} published by the given host.\n    * @throws SQLException\n    */\n-  public StatsSnapshot queryStatsSnapshotOf(String clusterName, String hostname) throws SQLException {\n+  @Override\n+  public StatsWrapper queryStatsOf(String clusterName, String hostname) throws SQLException {\n     hostname = hostnameHelper.simplifyHostname(hostname);\n     Map<String, StatsSnapshot> partitionSubMap = new HashMap<>();\n     StatsSnapshot hostSnapshot = new StatsSnapshot((long) 0, partitionSubMap);\n+    AtomicLong timestamp = new AtomicLong(0);\n     accountReportsDao.queryStorageUsageForHost(clusterName, hostname,\n-        (partitionId, accountId, containerId, storageUsage) -> {\n+        (partitionId, accountId, containerId, storageUsage, updatedAtMs) -> {\n           StatsSnapshot partitionSnapshot = hostSnapshot.getSubMap()\n               .computeIfAbsent(\"Partition[\" + partitionId + \"]\", k -> new StatsSnapshot((long) 0, new HashMap<>()));\n           StatsSnapshot accountSnapshot = partitionSnapshot.getSubMap()\n               .computeIfAbsent(\"A[\" + accountId + \"]\", k -> new StatsSnapshot((long) 0, new HashMap<>()));\n           accountSnapshot.getSubMap().put(\"C[\" + containerId + \"]\", new StatsSnapshot(storageUsage, null));\n+          timestamp.set(Math.max(timestamp.get(), updatedAtMs));\n         });\n \n     hostSnapshot.updateValue();\n-    return hostSnapshot;\n+    return new StatsWrapper(\n+        new StatsHeader(StatsHeader.StatsDescription.STORED_DATA_SIZE, timestamp.get(), partitionSubMap.size(),\n+            partitionSubMap.size(), null), hostSnapshot);\n+  }\n+\n+  /**\n+   * Store the aggregated account stats in {@link StatsSnapshot} to mysql database.\n+   * @param snapshot The aggregated account stats snapshot.\n+   */\n+  @Override\n+  public void storeAggregatedStats(StatsSnapshot snapshot) throws SQLException {\n+    int batchSize = 0;\n+    long startTimeMs = System.currentTimeMillis();\n+    for (Map.Entry<String, StatsSnapshot> accountMapEntry : snapshot.getSubMap().entrySet()) {\n+      String accountIdKey = accountMapEntry.getKey();\n+      short accountId = Short.valueOf(accountIdKey.substring(2, accountIdKey.length() - 1));\n+      StatsSnapshot containerStatsSnapshot = accountMapEntry.getValue();\n+      for (Map.Entry<String, StatsSnapshot> currContainerMapEntry : containerStatsSnapshot.getSubMap().entrySet()) {\n+        String containerIdKey = currContainerMapEntry.getKey();\n+        short containerId = Short.valueOf(containerIdKey.substring(2, containerIdKey.length() - 1));\n+        long currStorageUsage = currContainerMapEntry.getValue().getValue();\n+        aggregatedaccountReportsDao.updateStorageUsage(accountId, containerId, currStorageUsage);\n+        batchSize++;\n+      }\n+    }\n+    storeMetrics.aggregatedPublishTimeMs.update(System.currentTimeMillis() - startTimeMs);\n+    storeMetrics.aggregatedBatchSize.update(batchSize);\n+  }\n+\n+  /**\n+   * Query mysql database to get all the aggregated container storage usage for given {@code clusterName} and construct\n+   * a map from those data. The map is structured as such:\n+   * <p>Outer map's key is the string format of account id, inner map's key is the string format of container id and the\n+   * value of the inner map is the storage usage of the container.</p>\n+   * @param clusterName the clusterName.\n+   * @return A map that represents container storage usage.\n+   * @throws Exception\n+   */\n+  @Override\n+  public Map<String, Map<String, Long>> queryAggregatedStats(String clusterName) throws Exception {\n+    Map<String, Map<String, Long>> result = new HashMap<>();\n+    aggregatedaccountReportsDao.queryContainerUsageForCluster(clusterName, (accountId, containerId, storageUsage) -> {\n+      result.computeIfAbsent(String.valueOf(accountId), k -> new HashMap<>())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 139}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM4OTI0ODAz", "url": "https://github.com/linkedin/ambry/pull/1702#pullrequestreview-538924803", "createdAt": "2020-11-26T00:47:42Z", "commit": {"oid": "10db131a5660aa781b8ab732f838c486eae085a7"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQwMDo0Nzo0MlrOH6IEZQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQwMDo0Nzo0MlrOH6IEZQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDcxMTY1Mw==", "bodyText": "nit: montly -> monthly", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r530711653", "createdAt": "2020-11-26T00:47:42Z", "author": {"login": "cgtz"}, "path": "ambry-server/src/main/java/com/github/ambry/server/mysql/AggregatedAccountReportsDao.java", "diffHunk": "@@ -0,0 +1,237 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.server.mysql;\n+\n+import com.github.ambry.mysql.MySqlDataAccessor;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.util.Objects;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static com.github.ambry.mysql.MySqlDataAccessor.OperationType.*;\n+\n+\n+/**\n+ * AggregatedAccountReports Data Access Object. This object has to deal with three tables\n+ * <ol>\n+ * <li>AggregatedAccountReports</li>\n+ * <li>MonthlyAggregatedAccountReports</li>\n+ * <li>AggregatedAccountReportsMonth</li>\n+ * </ol>\n+ * <p/>\n+ * These tables have similar names, but they serve different purposes.\n+ * <ul>\n+ *   <li>AggregatedAccountReports saves the aggregated container storage usage for each cluster. It will be updated as frequent as the aggregation task is scheduled.</li>\n+ *   <li>MonthlyAggregatedAccountReports makes a copy of data from AggregatedAccountReports at the beginning of every month</li>\n+ *   <li>AggregatedAccountReportsMonth records which month the data is copied to MonthlyAggregatedAccountReports</li>\n+ * </ul>\n+ */\n+public class AggregatedAccountReportsDao {\n+  public static final String AGGREGATED_ACCOUNT_REPORTS_TABLE = \"AggregatedAccountReports\";\n+  public static final String MONTHLY_AGGREGATED_ACCOUNT_REPORTS_TABLE = \"MonthlyAggregatedAccountReports\";\n+  public static final String AGGREGATED_ACCOUNT_REPORTS_MONTH_TABLE = \"AggregatedAccountReportsMonth\";\n+  public static final String CLUSTER_NAME_COLUMN = \"clusterName\";\n+  public static final String ACCOUNT_ID_COLUMN = \"accountId\";\n+  public static final String CONTAINER_ID_COLUMN = \"containerId\";\n+  public static final String STORAGE_USAGE_COLUMN = \"storageUsage\";\n+  public static final String UPDATED_AT_COLUMN = \"updatedAt\";\n+  public static final String MONTH_COLUMN = \"month\";\n+\n+  private static final Logger logger = LoggerFactory.getLogger(AccountReportsDao.class);\n+  private static final String insertSql =\n+      String.format(\"INSERT INTO %s (%s, %s, %s, %s, %s) VALUES (?, ?, ?, ?, NOW())\", AGGREGATED_ACCOUNT_REPORTS_TABLE,\n+          CLUSTER_NAME_COLUMN, ACCOUNT_ID_COLUMN, CONTAINER_ID_COLUMN, STORAGE_USAGE_COLUMN, UPDATED_AT_COLUMN);\n+  private static final String queryUsageSqlForCluster =\n+      String.format(\"SELECT %s, %s, %s FROM %s WHERE %s = ?\", ACCOUNT_ID_COLUMN, CONTAINER_ID_COLUMN,\n+          STORAGE_USAGE_COLUMN, AGGREGATED_ACCOUNT_REPORTS_TABLE, CLUSTER_NAME_COLUMN);\n+  private static final String queryMontlyUsageSqlForCluster =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "10db131a5660aa781b8ab732f838c486eae085a7"}, "originalPosition": 60}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f507ab4360c6c2581dfe1ac85f3b1778a4f1c4e9", "author": {"user": {"login": "justinlin-linkedin", "name": "Justin Lin"}}, "url": "https://github.com/linkedin/ambry/commit/f507ab4360c6c2581dfe1ac85f3b1778a4f1c4e9", "committedDate": "2020-11-26T02:49:39Z", "message": "[StorageQuota] Add MySql aggregation task"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fe7c322abfb28ce806307598466775b46ceb85db", "author": {"user": {"login": "justinlin-linkedin", "name": "Justin Lin"}}, "url": "https://github.com/linkedin/ambry/commit/fe7c322abfb28ce806307598466775b46ceb85db", "committedDate": "2020-11-26T02:49:39Z", "message": "Fix compile and test errors"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4ff2fb2bbe05a953b1e7ec8e5a83a56e6d4dfd5e", "author": {"user": {"login": "justinlin-linkedin", "name": "Justin Lin"}}, "url": "https://github.com/linkedin/ambry/commit/4ff2fb2bbe05a953b1e7ec8e5a83a56e6d4dfd5e", "committedDate": "2020-11-26T02:49:39Z", "message": "Add more tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "346507fa65b6bd9ce1c27df1ab9080fdff4346ef", "author": {"user": {"login": "justinlin-linkedin", "name": "Justin Lin"}}, "url": "https://github.com/linkedin/ambry/commit/346507fa65b6bd9ce1c27df1ab9080fdff4346ef", "committedDate": "2020-11-26T02:49:39Z", "message": "Comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "faed6eb4b1c547d7e74ea12aed04484a528d123c", "author": {"user": {"login": "justinlin-linkedin", "name": "Justin Lin"}}, "url": "https://github.com/linkedin/ambry/commit/faed6eb4b1c547d7e74ea12aed04484a528d123c", "committedDate": "2020-11-26T02:54:29Z", "message": "Address comments"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "10db131a5660aa781b8ab732f838c486eae085a7", "author": {"user": {"login": "justinlin-linkedin", "name": "Justin Lin"}}, "url": "https://github.com/linkedin/ambry/commit/10db131a5660aa781b8ab732f838c486eae085a7", "committedDate": "2020-11-25T19:02:06Z", "message": "Comments"}, "afterCommit": {"oid": "faed6eb4b1c547d7e74ea12aed04484a528d123c", "author": {"user": {"login": "justinlin-linkedin", "name": "Justin Lin"}}, "url": "https://github.com/linkedin/ambry/commit/faed6eb4b1c547d7e74ea12aed04484a528d123c", "committedDate": "2020-11-26T02:54:29Z", "message": "Address comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQwNjI1NjY0", "url": "https://github.com/linkedin/ambry/pull/1702#pullrequestreview-540625664", "createdAt": "2020-11-30T06:27:16Z", "commit": {"oid": "faed6eb4b1c547d7e74ea12aed04484a528d123c"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1015, "cost": 1, "resetAt": "2021-11-01T16:19:10Z"}}}