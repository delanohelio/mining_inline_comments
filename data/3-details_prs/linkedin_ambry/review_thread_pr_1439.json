{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzkzODg1NDkx", "number": 1439, "reviewThreads": {"totalCount": 16, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNlQxODo1NTo0NlrODryg8g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxODoyNjo1M1rODuE8gQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ3MjQyOTk0OnYy", "diffSide": "RIGHT", "path": "ambry-network/src/main/java/com.github.ambry.network/Selector.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNlQxODo1NTo0NlrOF8V2OA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNlQxODo1NTo0NlrOF8V2OA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODgxNjgyNA==", "bodyText": "remove?", "url": "https://github.com/linkedin/ambry/pull/1439#discussion_r398816824", "createdAt": "2020-03-26T18:55:46Z", "author": {"login": "zzmao"}, "path": "ambry-network/src/main/java/com.github.ambry.network/Selector.java", "diffHunk": "@@ -788,6 +788,7 @@ private NetworkSend write(SelectionKey key, Transmission transmission) {\n     } catch (IOException e) {\n       // We have key information if we log IOException here.\n       handleReadWriteIOException(e, key);\n+      //transmission.networkSend.getPayload().release();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "06c6a6e01f9632d3c206ef1ed9cdadeabc85b8b9"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4NjkyMTI3OnYy", "diffSide": "RIGHT", "path": "ambry-router/src/main/java/com.github.ambry.router/EncryptJob.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxNTo0Mzo1MlrOF-cNKw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxNTo0Mzo1MlrOF-cNKw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTAxODE1NQ==", "bodyText": "not directly in the scope of this PR, but since you're making changes, could you make this inner class static along with DecryptJobResult.", "url": "https://github.com/linkedin/ambry/pull/1439#discussion_r401018155", "createdAt": "2020-03-31T15:43:52Z", "author": {"login": "cgtz"}, "path": "ambry-router/src/main/java/com.github.ambry.router/EncryptJob.java", "diffHunk": "@@ -103,25 +112,31 @@ public void closeJob(GeneralSecurityException gse) {\n    */\n   class EncryptJobResult {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "06c6a6e01f9632d3c206ef1ed9cdadeabc85b8b9"}, "originalPosition": 66}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4Njk0MjczOnYy", "diffSide": "RIGHT", "path": "ambry-router/src/test/java/com.github.ambry.router/ChunkFillTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxNTo0ODo0MFrOF-cbPg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQyMzoxOTo0NFrOF_WBOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTAyMTc1OA==", "bodyText": "Could this just be buf.readBytes(dest) instead of iterating through the nio buffers?", "url": "https://github.com/linkedin/ambry/pull/1439#discussion_r401021758", "createdAt": "2020-03-31T15:48:40Z", "author": {"login": "cgtz"}, "path": "ambry-router/src/test/java/com.github.ambry.router/ChunkFillTest.java", "diffHunk": "@@ -319,20 +319,20 @@ private void fillChunksAndAssertSuccess() throws Exception {\n   private void assertDataIdentity(ClusterMap clusterMap) throws IOException {\n     if (!testEncryption) {\n       ByteBuffer dest = ByteBuffer.allocate(totalSizeWritten);\n-      for (ByteBuffer buf : compositeBuffers) {\n+      for (ByteBuf buf : compositeBuffers) {\n         Assert.assertNotNull(\"All chunks should have come in\", buf);\n-        buf.flip();\n-        dest.put(buf);\n+        for (ByteBuffer buffer: buf.nioBuffers()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "06c6a6e01f9632d3c206ef1ed9cdadeabc85b8b9"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTk2NTM2OA==", "bodyText": "This is easier. dest will read all the ByteBufs in the array of compositeBuffers, so buf.readBytes(dest) would fail. We have to set limit on dest before reading bytes from buf. But in this way, we don't have to.", "url": "https://github.com/linkedin/ambry/pull/1439#discussion_r401965368", "createdAt": "2020-04-01T23:19:44Z", "author": {"login": "justinlin-linkedin"}, "path": "ambry-router/src/test/java/com.github.ambry.router/ChunkFillTest.java", "diffHunk": "@@ -319,20 +319,20 @@ private void fillChunksAndAssertSuccess() throws Exception {\n   private void assertDataIdentity(ClusterMap clusterMap) throws IOException {\n     if (!testEncryption) {\n       ByteBuffer dest = ByteBuffer.allocate(totalSizeWritten);\n-      for (ByteBuffer buf : compositeBuffers) {\n+      for (ByteBuf buf : compositeBuffers) {\n         Assert.assertNotNull(\"All chunks should have come in\", buf);\n-        buf.flip();\n-        dest.put(buf);\n+        for (ByteBuffer buffer: buf.nioBuffers()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTAyMTc1OA=="}, "originalCommit": {"oid": "06c6a6e01f9632d3c206ef1ed9cdadeabc85b8b9"}, "originalPosition": 66}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4NzA2MjIxOnYy", "diffSide": "RIGHT", "path": "ambry-router/src/test/java/com.github.ambry.router/NonBlockingRouterTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxNjoxNTo0MVrOF-dm0w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQyMzoyMTozN1rOF_WDjA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTA0MTEwNw==", "bodyText": "why was the leak helper disabled for this test case?", "url": "https://github.com/linkedin/ambry/pull/1439#discussion_r401041107", "createdAt": "2020-03-31T16:15:41Z", "author": {"login": "cgtz"}, "path": "ambry-router/src/test/java/com.github.ambry.router/NonBlockingRouterTest.java", "diffHunk": "@@ -411,6 +413,7 @@ public void testRouterNoPartitionInLocalDC() throws Exception {\n    */\n   @Test\n   public void testRequestResponseHandlerThreadExitFlow() throws Exception {\n+    nettyByteBufLeakHelper.setDisabled(true);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "06c6a6e01f9632d3c206ef1ed9cdadeabc85b8b9"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTk2NTk2NA==", "bodyText": "There are tests in NonBlockingRouterTest that needs creates new ByteBuf by putting a blob to the in memory router but never release it. Those tests are going to break the leak detector helper. That's why I disable the leak detector helper for those tests.", "url": "https://github.com/linkedin/ambry/pull/1439#discussion_r401965964", "createdAt": "2020-04-01T23:21:37Z", "author": {"login": "justinlin-linkedin"}, "path": "ambry-router/src/test/java/com.github.ambry.router/NonBlockingRouterTest.java", "diffHunk": "@@ -411,6 +413,7 @@ public void testRouterNoPartitionInLocalDC() throws Exception {\n    */\n   @Test\n   public void testRequestResponseHandlerThreadExitFlow() throws Exception {\n+    nettyByteBufLeakHelper.setDisabled(true);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTA0MTEwNw=="}, "originalCommit": {"oid": "06c6a6e01f9632d3c206ef1ed9cdadeabc85b8b9"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4NzA5OTYyOnYy", "diffSide": "RIGHT", "path": "ambry-router/src/main/java/com.github.ambry.router/PutOperation.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxNjoyNDozMVrOF-d-0Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxNjoyNDozMVrOF-d-0Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTA0NzI0OQ==", "bodyText": "nit: if less then -> is less than, than this -> then this", "url": "https://github.com/linkedin/ambry/pull/1439#discussion_r401047249", "createdAt": "2020-03-31T16:24:31Z", "author": {"login": "cgtz"}, "path": "ambry-router/src/main/java/com.github.ambry.router/PutOperation.java", "diffHunk": "@@ -562,9 +587,11 @@ void fillChunks() {\n         }\n       }\n       if (chunkFillingCompletedSuccessfully) {\n+        // If the blob size if less then 4MB or the last chunk size is less than 4MB, than this lastChunk will be", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "06c6a6e01f9632d3c206ef1ed9cdadeabc85b8b9"}, "originalPosition": 112}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4NzQ5MDAyOnYy", "diffSide": "RIGHT", "path": "ambry-router/src/main/java/com.github.ambry.router/PutOperation.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxODowMzo0M1rOF-h06g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxODowMzo0M1rOF-h06g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTExMDI1MA==", "bodyText": "there is an empty if condition here", "url": "https://github.com/linkedin/ambry/pull/1439#discussion_r401110250", "createdAt": "2020-03-31T18:03:43Z", "author": {"login": "cgtz"}, "path": "ambry-router/src/main/java/com.github.ambry.router/PutOperation.java", "diffHunk": "@@ -528,10 +551,12 @@ void fillChunks() {\n       PutChunk chunkToFill;\n       while (!isChunkFillingDone()) {\n         // Attempt to fill a chunk\n-        if (channelReadBuffer == null) {\n-          channelReadBuffer = chunkFillerChannel.getNextChunk(0);\n+        if (channelReadBuf == null) {\n+          channelReadBuf = chunkFillerChannel.getNextByteBuf(0);\n+          if (channelReadBuf != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "06c6a6e01f9632d3c206ef1ed9cdadeabc85b8b9"}, "originalPosition": 81}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4NzU4ODI5OnYy", "diffSide": "RIGHT", "path": "ambry-router/src/main/java/com.github.ambry.router/PutOperation.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxODozMDoyMlrOF-iywQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxODozMDoyMlrOF-iywQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTEyNjA4MQ==", "bodyText": "Could this be a lower log level? Or moved inside of the if (lastChunk != null) check so it only is printed if there was a chunk still being built?", "url": "https://github.com/linkedin/ambry/pull/1439#discussion_r401126081", "createdAt": "2020-03-31T18:30:22Z", "author": {"login": "cgtz"}, "path": "ambry-router/src/main/java/com.github.ambry.router/PutOperation.java", "diffHunk": "@@ -575,10 +602,21 @@ void fillChunks() {\n           }\n         }\n       }\n+      if (operationCompleted) {\n+        logger.info(\"Clear unfinished chunk since operation is completed\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "06c6a6e01f9632d3c206ef1ed9cdadeabc85b8b9"}, "originalPosition": 126}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4NzgwOTY0OnYy", "diffSide": "RIGHT", "path": "ambry-router/src/main/java/com.github.ambry.router/PutOperation.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxOToyOTowNlrOF-k8LA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQyMzoyMTo1N1rOF_WEAQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTE2MTI2MA==", "bodyText": "The clear() method does not seem like it was meant to be called from non-main threads. Is it necessary to do all of the cleanup or just call releaseBlobContent here and in fillChunks()?", "url": "https://github.com/linkedin/ambry/pull/1439#discussion_r401161260", "createdAt": "2020-03-31T19:29:06Z", "author": {"login": "cgtz"}, "path": "ambry-router/src/main/java/com.github.ambry.router/PutOperation.java", "diffHunk": "@@ -1152,42 +1147,62 @@ private void encryptChunk() {\n         logger.trace(\"Submitting encrypt job for chunk at index {}\", chunkIndex);\n         cryptoJobHandler.submitJob(\n             new EncryptJob(passedInBlobProperties.getAccountId(), passedInBlobProperties.getContainerId(),\n-                isMetadataChunk() ? null : buf, ByteBuffer.wrap(chunkUserMetadata), kms.getRandomKey(), cryptoService,\n-                kms, encryptJobMetricsTracker, (EncryptJob.EncryptJobResult result, Exception exception) -> {\n-              logger.trace(\"Processing encrypt job callback for chunk at index {}\", chunkIndex);\n-              encryptJobMetricsTracker.onJobResultProcessingStart();\n-              if (exception == null && !isOperationComplete()) {\n-                if (!isMetadataChunk()) {\n-                  buf = result.getEncryptedBlobContent();\n-                }\n-                encryptedPerBlobKey = result.getEncryptedKey();\n-                chunkUserMetadata = result.getEncryptedUserMetadata().array();\n-                logger.trace(\"Completing encrypt job result for chunk at index {}\", chunkIndex);\n-                prepareForSending();\n-                chunkReadyAtMs = time.milliseconds();\n-              } else {\n-                encryptJobMetricsTracker.incrementOperationError();\n-                if (!isOperationComplete()) {\n-                  logger.trace(\"Setting exception from encrypt of chunk at index {} \", chunkIndex, exception);\n-                  setOperationExceptionAndComplete(\n-                      new RouterException(\"Exception thrown on encrypting the content for chunk at index \" + chunkIndex,\n-                          exception, RouterErrorCode.UnexpectedInternalError));\n-                } else {\n-                  logger.trace(\n-                      \"Ignoring exception from encrypt job for chunk at index {} as operation exception {} is set already\",\n-                      chunkIndex, getOperationException(), exception);\n-                }\n-              }\n-              routerMetrics.encryptTimeMs.update(time.milliseconds() - chunkEncryptReadyAtMs);\n-              encryptJobMetricsTracker.onJobResultProcessingComplete();\n-              routerCallback.onPollReady();\n-            }));\n+                isMetadataChunk() ? null : toEncrypt.retainedDuplicate(), ByteBuffer.wrap(chunkUserMetadata),\n+                kms.getRandomKey(), cryptoService, kms, encryptJobMetricsTracker,\n+                (EncryptJob.EncryptJobResult result, Exception exception) -> {\n+                  logger.trace(\"Processing encrypt job callback for chunk at index {}\", chunkIndex);\n+                  if (!isMetadataChunk()) {\n+                    releaseBlobContent();\n+                  }\n+                  encryptJobMetricsTracker.onJobResultProcessingStart();\n+                  if (exception == null && !isOperationComplete()) {\n+                    if (!isMetadataChunk()) {\n+                      buf = result.getEncryptedBlobContent();\n+                    }\n+                    encryptedPerBlobKey = result.getEncryptedKey();\n+                    chunkUserMetadata = result.getEncryptedUserMetadata().array();\n+                    logger.trace(\"Completing encrypt job result for chunk at index {}\", chunkIndex);\n+                    prepareForSending();\n+                    chunkReadyAtMs = time.milliseconds();\n+                  } else {\n+                    encryptJobMetricsTracker.incrementOperationError();\n+                    if (!isOperationComplete()) {\n+                      logger.trace(\"Setting exception from encrypt of chunk at index {} \", chunkIndex, exception);\n+                      // If we are here, then the result is null. no need to release it.\n+                      setOperationExceptionAndComplete(new RouterException(\n+                          \"Exception thrown on encrypting the content for chunk at index \" + chunkIndex, exception,\n+                          RouterErrorCode.UnexpectedInternalError));\n+                    } else {\n+                      logger.trace(\n+                          \"Ignoring exception from encrypt job for chunk at index {} as operation exception {} is set already\",\n+                          chunkIndex, getOperationException(), exception);\n+                      // If we are here, then the operation is completed and the exception could be null, in this case,\n+                      // we have to release the content in the result.\n+                      if (result != null) {\n+                        result.release();\n+                      }\n+                    }\n+                  }\n+                  routerMetrics.encryptTimeMs.update(time.milliseconds() - chunkEncryptReadyAtMs);\n+                  encryptJobMetricsTracker.onJobResultProcessingComplete();\n+                  routerCallback.onPollReady();\n+                  // double check if the operation is not completed. If so, we have to release the buf here, since in\n+                  // main thread, chunk might already be released.\n+                  if (isOperationComplete()) {\n+                    logger.info(\"Clear put chunk in encryption callback since operation is completed\");\n+                    clear();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "06c6a6e01f9632d3c206ef1ed9cdadeabc85b8b9"}, "originalPosition": 360}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTk2NjA4MQ==", "bodyText": "make sense", "url": "https://github.com/linkedin/ambry/pull/1439#discussion_r401966081", "createdAt": "2020-04-01T23:21:57Z", "author": {"login": "justinlin-linkedin"}, "path": "ambry-router/src/main/java/com.github.ambry.router/PutOperation.java", "diffHunk": "@@ -1152,42 +1147,62 @@ private void encryptChunk() {\n         logger.trace(\"Submitting encrypt job for chunk at index {}\", chunkIndex);\n         cryptoJobHandler.submitJob(\n             new EncryptJob(passedInBlobProperties.getAccountId(), passedInBlobProperties.getContainerId(),\n-                isMetadataChunk() ? null : buf, ByteBuffer.wrap(chunkUserMetadata), kms.getRandomKey(), cryptoService,\n-                kms, encryptJobMetricsTracker, (EncryptJob.EncryptJobResult result, Exception exception) -> {\n-              logger.trace(\"Processing encrypt job callback for chunk at index {}\", chunkIndex);\n-              encryptJobMetricsTracker.onJobResultProcessingStart();\n-              if (exception == null && !isOperationComplete()) {\n-                if (!isMetadataChunk()) {\n-                  buf = result.getEncryptedBlobContent();\n-                }\n-                encryptedPerBlobKey = result.getEncryptedKey();\n-                chunkUserMetadata = result.getEncryptedUserMetadata().array();\n-                logger.trace(\"Completing encrypt job result for chunk at index {}\", chunkIndex);\n-                prepareForSending();\n-                chunkReadyAtMs = time.milliseconds();\n-              } else {\n-                encryptJobMetricsTracker.incrementOperationError();\n-                if (!isOperationComplete()) {\n-                  logger.trace(\"Setting exception from encrypt of chunk at index {} \", chunkIndex, exception);\n-                  setOperationExceptionAndComplete(\n-                      new RouterException(\"Exception thrown on encrypting the content for chunk at index \" + chunkIndex,\n-                          exception, RouterErrorCode.UnexpectedInternalError));\n-                } else {\n-                  logger.trace(\n-                      \"Ignoring exception from encrypt job for chunk at index {} as operation exception {} is set already\",\n-                      chunkIndex, getOperationException(), exception);\n-                }\n-              }\n-              routerMetrics.encryptTimeMs.update(time.milliseconds() - chunkEncryptReadyAtMs);\n-              encryptJobMetricsTracker.onJobResultProcessingComplete();\n-              routerCallback.onPollReady();\n-            }));\n+                isMetadataChunk() ? null : toEncrypt.retainedDuplicate(), ByteBuffer.wrap(chunkUserMetadata),\n+                kms.getRandomKey(), cryptoService, kms, encryptJobMetricsTracker,\n+                (EncryptJob.EncryptJobResult result, Exception exception) -> {\n+                  logger.trace(\"Processing encrypt job callback for chunk at index {}\", chunkIndex);\n+                  if (!isMetadataChunk()) {\n+                    releaseBlobContent();\n+                  }\n+                  encryptJobMetricsTracker.onJobResultProcessingStart();\n+                  if (exception == null && !isOperationComplete()) {\n+                    if (!isMetadataChunk()) {\n+                      buf = result.getEncryptedBlobContent();\n+                    }\n+                    encryptedPerBlobKey = result.getEncryptedKey();\n+                    chunkUserMetadata = result.getEncryptedUserMetadata().array();\n+                    logger.trace(\"Completing encrypt job result for chunk at index {}\", chunkIndex);\n+                    prepareForSending();\n+                    chunkReadyAtMs = time.milliseconds();\n+                  } else {\n+                    encryptJobMetricsTracker.incrementOperationError();\n+                    if (!isOperationComplete()) {\n+                      logger.trace(\"Setting exception from encrypt of chunk at index {} \", chunkIndex, exception);\n+                      // If we are here, then the result is null. no need to release it.\n+                      setOperationExceptionAndComplete(new RouterException(\n+                          \"Exception thrown on encrypting the content for chunk at index \" + chunkIndex, exception,\n+                          RouterErrorCode.UnexpectedInternalError));\n+                    } else {\n+                      logger.trace(\n+                          \"Ignoring exception from encrypt job for chunk at index {} as operation exception {} is set already\",\n+                          chunkIndex, getOperationException(), exception);\n+                      // If we are here, then the operation is completed and the exception could be null, in this case,\n+                      // we have to release the content in the result.\n+                      if (result != null) {\n+                        result.release();\n+                      }\n+                    }\n+                  }\n+                  routerMetrics.encryptTimeMs.update(time.milliseconds() - chunkEncryptReadyAtMs);\n+                  encryptJobMetricsTracker.onJobResultProcessingComplete();\n+                  routerCallback.onPollReady();\n+                  // double check if the operation is not completed. If so, we have to release the buf here, since in\n+                  // main thread, chunk might already be released.\n+                  if (isOperationComplete()) {\n+                    logger.info(\"Clear put chunk in encryption callback since operation is completed\");\n+                    clear();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTE2MTI2MA=="}, "originalCommit": {"oid": "06c6a6e01f9632d3c206ef1ed9cdadeabc85b8b9"}, "originalPosition": 360}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4NzgyMDc0OnYy", "diffSide": "RIGHT", "path": "ambry-router/src/main/java/com.github.ambry.router/PutOperation.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxOTozMjoyNVrOF-lDIg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxOTozMjoyNVrOF-lDIg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTE2MzA0Mg==", "bodyText": "This lambda is quite long. Could you move it to a helper function. e.g. void onEncryptionComplete(EncryptJobResult, Exception)?", "url": "https://github.com/linkedin/ambry/pull/1439#discussion_r401163042", "createdAt": "2020-03-31T19:32:25Z", "author": {"login": "cgtz"}, "path": "ambry-router/src/main/java/com.github.ambry.router/PutOperation.java", "diffHunk": "@@ -1152,42 +1147,62 @@ private void encryptChunk() {\n         logger.trace(\"Submitting encrypt job for chunk at index {}\", chunkIndex);\n         cryptoJobHandler.submitJob(\n             new EncryptJob(passedInBlobProperties.getAccountId(), passedInBlobProperties.getContainerId(),\n-                isMetadataChunk() ? null : buf, ByteBuffer.wrap(chunkUserMetadata), kms.getRandomKey(), cryptoService,\n-                kms, encryptJobMetricsTracker, (EncryptJob.EncryptJobResult result, Exception exception) -> {\n-              logger.trace(\"Processing encrypt job callback for chunk at index {}\", chunkIndex);\n-              encryptJobMetricsTracker.onJobResultProcessingStart();\n-              if (exception == null && !isOperationComplete()) {\n-                if (!isMetadataChunk()) {\n-                  buf = result.getEncryptedBlobContent();\n-                }\n-                encryptedPerBlobKey = result.getEncryptedKey();\n-                chunkUserMetadata = result.getEncryptedUserMetadata().array();\n-                logger.trace(\"Completing encrypt job result for chunk at index {}\", chunkIndex);\n-                prepareForSending();\n-                chunkReadyAtMs = time.milliseconds();\n-              } else {\n-                encryptJobMetricsTracker.incrementOperationError();\n-                if (!isOperationComplete()) {\n-                  logger.trace(\"Setting exception from encrypt of chunk at index {} \", chunkIndex, exception);\n-                  setOperationExceptionAndComplete(\n-                      new RouterException(\"Exception thrown on encrypting the content for chunk at index \" + chunkIndex,\n-                          exception, RouterErrorCode.UnexpectedInternalError));\n-                } else {\n-                  logger.trace(\n-                      \"Ignoring exception from encrypt job for chunk at index {} as operation exception {} is set already\",\n-                      chunkIndex, getOperationException(), exception);\n-                }\n-              }\n-              routerMetrics.encryptTimeMs.update(time.milliseconds() - chunkEncryptReadyAtMs);\n-              encryptJobMetricsTracker.onJobResultProcessingComplete();\n-              routerCallback.onPollReady();\n-            }));\n+                isMetadataChunk() ? null : toEncrypt.retainedDuplicate(), ByteBuffer.wrap(chunkUserMetadata),\n+                kms.getRandomKey(), cryptoService, kms, encryptJobMetricsTracker,\n+                (EncryptJob.EncryptJobResult result, Exception exception) -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "06c6a6e01f9632d3c206ef1ed9cdadeabc85b8b9"}, "originalPosition": 319}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4NzgzMzkzOnYy", "diffSide": "RIGHT", "path": "ambry-router/src/main/java/com.github.ambry.router/PutOperation.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxOTozNjoxNVrOF-lLTQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQyMzoyMjowOVrOF_WENg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTE2NTEzMw==", "bodyText": "It seems like this buffer is retained and then retained again with toEncrypt.retainedDuplicate() and then released at the end of this method. Could the retain from this line and release on 1204 be removed?", "url": "https://github.com/linkedin/ambry/pull/1439#discussion_r401165133", "createdAt": "2020-03-31T19:36:15Z", "author": {"login": "cgtz"}, "path": "ambry-router/src/main/java/com.github.ambry.router/PutOperation.java", "diffHunk": "@@ -1144,6 +1138,7 @@ private void prepareForSending() {\n      * Submits encrypt job for the given {@link PutChunk} and processes the callback for the same\n      */\n     private void encryptChunk() {\n+      ByteBuf toEncrypt = buf.retain();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "06c6a6e01f9632d3c206ef1ed9cdadeabc85b8b9"}, "originalPosition": 279}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTk2NjEzNA==", "bodyText": "legacy code.", "url": "https://github.com/linkedin/ambry/pull/1439#discussion_r401966134", "createdAt": "2020-04-01T23:22:09Z", "author": {"login": "justinlin-linkedin"}, "path": "ambry-router/src/main/java/com.github.ambry.router/PutOperation.java", "diffHunk": "@@ -1144,6 +1138,7 @@ private void prepareForSending() {\n      * Submits encrypt job for the given {@link PutChunk} and processes the callback for the same\n      */\n     private void encryptChunk() {\n+      ByteBuf toEncrypt = buf.retain();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTE2NTEzMw=="}, "originalCommit": {"oid": "06c6a6e01f9632d3c206ef1ed9cdadeabc85b8b9"}, "originalPosition": 279}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4Nzg1MzM5OnYy", "diffSide": "RIGHT", "path": "ambry-router/src/main/java/com.github.ambry.router/PutOperation.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxOTo0MjowM1rOF-lXnA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQyMzoyMjoyOVrOF_WElA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTE2ODI4NA==", "bodyText": "for declaringtoWrite and remaininSlice you can remove the assignment part because of each of them are assigned by all the cases afterwards", "url": "https://github.com/linkedin/ambry/pull/1439#discussion_r401168284", "createdAt": "2020-03-31T19:42:03Z", "author": {"login": "cgtz"}, "path": "ambry-router/src/main/java/com.github.ambry.router/PutOperation.java", "diffHunk": "@@ -1211,22 +1225,43 @@ void onFillComplete(boolean updateMetric) {\n     }\n \n     /**\n-     * Fill the buffer of the current chunk with the data from the given {@link ByteBuffer}.\n-     * @param channelReadBuffer the {@link ByteBuffer} from which to read data.\n+     * Fill the buffer of the current chunk with the data from the given {@link ByteBuf}.\n+     * @param channelReadBuf the {@link ByteBuf} from which to read data.\n      * @return the number of bytes transferred in this operation.\n      */\n-    int fillFrom(ByteBuffer channelReadBuffer) {\n-      int toWrite = Math.min(channelReadBuffer.remaining(), buf.remaining());\n-      if (channelReadBuffer.remaining() > buf.remaining()) {\n-        // Manipulate limit of the source buffer in order to read only enough to fill the chunk\n-        int savedLimit = channelReadBuffer.limit();\n-        channelReadBuffer.limit(channelReadBuffer.position() + buf.remaining());\n-        buf.put(channelReadBuffer);\n-        channelReadBuffer.limit(savedLimit);\n+    int fillFrom(ByteBuf channelReadBuf) {\n+      int toWrite = 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "06c6a6e01f9632d3c206ef1ed9cdadeabc85b8b9"}, "originalPosition": 405}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTk2NjIyOA==", "bodyText": "updated to new code.", "url": "https://github.com/linkedin/ambry/pull/1439#discussion_r401966228", "createdAt": "2020-04-01T23:22:29Z", "author": {"login": "justinlin-linkedin"}, "path": "ambry-router/src/main/java/com.github.ambry.router/PutOperation.java", "diffHunk": "@@ -1211,22 +1225,43 @@ void onFillComplete(boolean updateMetric) {\n     }\n \n     /**\n-     * Fill the buffer of the current chunk with the data from the given {@link ByteBuffer}.\n-     * @param channelReadBuffer the {@link ByteBuffer} from which to read data.\n+     * Fill the buffer of the current chunk with the data from the given {@link ByteBuf}.\n+     * @param channelReadBuf the {@link ByteBuf} from which to read data.\n      * @return the number of bytes transferred in this operation.\n      */\n-    int fillFrom(ByteBuffer channelReadBuffer) {\n-      int toWrite = Math.min(channelReadBuffer.remaining(), buf.remaining());\n-      if (channelReadBuffer.remaining() > buf.remaining()) {\n-        // Manipulate limit of the source buffer in order to read only enough to fill the chunk\n-        int savedLimit = channelReadBuffer.limit();\n-        channelReadBuffer.limit(channelReadBuffer.position() + buf.remaining());\n-        buf.put(channelReadBuffer);\n-        channelReadBuffer.limit(savedLimit);\n+    int fillFrom(ByteBuf channelReadBuf) {\n+      int toWrite = 0;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTE2ODI4NA=="}, "originalCommit": {"oid": "06c6a6e01f9632d3c206ef1ed9cdadeabc85b8b9"}, "originalPosition": 405}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4Nzg1NDAzOnYy", "diffSide": "RIGHT", "path": "ambry-router/src/main/java/com.github.ambry.router/PutOperation.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxOTo0MjoxNlrOF-lYBQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxOTo0MjoxNlrOF-lYBQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTE2ODM4OQ==", "bodyText": "size unused", "url": "https://github.com/linkedin/ambry/pull/1439#discussion_r401168389", "createdAt": "2020-03-31T19:42:16Z", "author": {"login": "cgtz"}, "path": "ambry-router/src/main/java/com.github.ambry.router/PutOperation.java", "diffHunk": "@@ -1211,22 +1225,43 @@ void onFillComplete(boolean updateMetric) {\n     }\n \n     /**\n-     * Fill the buffer of the current chunk with the data from the given {@link ByteBuffer}.\n-     * @param channelReadBuffer the {@link ByteBuffer} from which to read data.\n+     * Fill the buffer of the current chunk with the data from the given {@link ByteBuf}.\n+     * @param channelReadBuf the {@link ByteBuf} from which to read data.\n      * @return the number of bytes transferred in this operation.\n      */\n-    int fillFrom(ByteBuffer channelReadBuffer) {\n-      int toWrite = Math.min(channelReadBuffer.remaining(), buf.remaining());\n-      if (channelReadBuffer.remaining() > buf.remaining()) {\n-        // Manipulate limit of the source buffer in order to read only enough to fill the chunk\n-        int savedLimit = channelReadBuffer.limit();\n-        channelReadBuffer.limit(channelReadBuffer.position() + buf.remaining());\n-        buf.put(channelReadBuffer);\n-        channelReadBuffer.limit(savedLimit);\n+    int fillFrom(ByteBuf channelReadBuf) {\n+      int toWrite = 0;\n+      if (buf == null) {\n+        if (channelReadBuf.readableBytes() > routerConfig.routerMaxPutChunkSizeBytes) {\n+          toWrite = routerConfig.routerMaxPutChunkSizeBytes;\n+          buf = channelReadBuf.readRetainedSlice(routerConfig.routerMaxPutChunkSizeBytes);\n+        } else {\n+          toWrite = channelReadBuf.readableBytes();\n+          buf = channelReadBuf.readRetainedSlice(toWrite);\n+        }\n       } else {\n-        buf.put(channelReadBuffer);\n+        int remainingSize = routerConfig.routerMaxPutChunkSizeBytes - buf.readableBytes();\n+        ByteBuf remainingSlice = null;\n+        if (channelReadBuf.readableBytes() > remainingSize) {\n+          toWrite = remainingSize;\n+          remainingSlice = channelReadBuf.readRetainedSlice(remainingSize);\n+        } else {\n+          toWrite = channelReadBuf.readableBytes();\n+          remainingSlice = channelReadBuf.readRetainedSlice(toWrite);\n+        }\n+        int size = buf.readableBytes();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "06c6a6e01f9632d3c206ef1ed9cdadeabc85b8b9"}, "originalPosition": 425}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4Nzg3NDE0OnYy", "diffSide": "RIGHT", "path": "ambry-router/src/main/java/com.github.ambry.router/PutOperation.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxOTo0Nzo1NlrOF-lj7Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQyMzoyMjozN1rOF_WEtw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTE3MTQzNw==", "bodyText": "The javadocs for CompositeByteBuf recommend using the alloc.compositeBuffer() methods if possible. Probably since the allocators seem to wrap the buffer with extra leak detection stuff (see AbstractByteBufAllocator). Also, the third param is the max number of child components in the buffer, not the max size in bytes. I guess it is still valuable to raise the limit since the default limit seems to be 16 from AbstractByteBufAllocator.\nThis can probably be composite = buf.isDirect()? buf.alloc().compositeDirectBuffer(maxComponents) : buf.alloc().compositeHeapBuffer(maxComponents) instead.", "url": "https://github.com/linkedin/ambry/pull/1439#discussion_r401171437", "createdAt": "2020-03-31T19:47:56Z", "author": {"login": "cgtz"}, "path": "ambry-router/src/main/java/com.github.ambry.router/PutOperation.java", "diffHunk": "@@ -1211,22 +1225,43 @@ void onFillComplete(boolean updateMetric) {\n     }\n \n     /**\n-     * Fill the buffer of the current chunk with the data from the given {@link ByteBuffer}.\n-     * @param channelReadBuffer the {@link ByteBuffer} from which to read data.\n+     * Fill the buffer of the current chunk with the data from the given {@link ByteBuf}.\n+     * @param channelReadBuf the {@link ByteBuf} from which to read data.\n      * @return the number of bytes transferred in this operation.\n      */\n-    int fillFrom(ByteBuffer channelReadBuffer) {\n-      int toWrite = Math.min(channelReadBuffer.remaining(), buf.remaining());\n-      if (channelReadBuffer.remaining() > buf.remaining()) {\n-        // Manipulate limit of the source buffer in order to read only enough to fill the chunk\n-        int savedLimit = channelReadBuffer.limit();\n-        channelReadBuffer.limit(channelReadBuffer.position() + buf.remaining());\n-        buf.put(channelReadBuffer);\n-        channelReadBuffer.limit(savedLimit);\n+    int fillFrom(ByteBuf channelReadBuf) {\n+      int toWrite = 0;\n+      if (buf == null) {\n+        if (channelReadBuf.readableBytes() > routerConfig.routerMaxPutChunkSizeBytes) {\n+          toWrite = routerConfig.routerMaxPutChunkSizeBytes;\n+          buf = channelReadBuf.readRetainedSlice(routerConfig.routerMaxPutChunkSizeBytes);\n+        } else {\n+          toWrite = channelReadBuf.readableBytes();\n+          buf = channelReadBuf.readRetainedSlice(toWrite);\n+        }\n       } else {\n-        buf.put(channelReadBuffer);\n+        int remainingSize = routerConfig.routerMaxPutChunkSizeBytes - buf.readableBytes();\n+        ByteBuf remainingSlice = null;\n+        if (channelReadBuf.readableBytes() > remainingSize) {\n+          toWrite = remainingSize;\n+          remainingSlice = channelReadBuf.readRetainedSlice(remainingSize);\n+        } else {\n+          toWrite = channelReadBuf.readableBytes();\n+          remainingSlice = channelReadBuf.readRetainedSlice(toWrite);\n+        }\n+        int size = buf.readableBytes();\n+        // buf already has some bytes\n+        if (buf instanceof CompositeByteBuf) {\n+          // Buf is already a CompositeByteBuf, then just add the slice from\n+          ((CompositeByteBuf) buf).addComponent(true, remainingSlice);\n+        } else {\n+          CompositeByteBuf composite =\n+              new CompositeByteBuf(buf.alloc(), buf.isDirect(), routerConfig.routerMaxPutChunkSizeBytes);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "06c6a6e01f9632d3c206ef1ed9cdadeabc85b8b9"}, "originalPosition": 432}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTk2NjI2Mw==", "bodyText": "make sense.", "url": "https://github.com/linkedin/ambry/pull/1439#discussion_r401966263", "createdAt": "2020-04-01T23:22:37Z", "author": {"login": "justinlin-linkedin"}, "path": "ambry-router/src/main/java/com.github.ambry.router/PutOperation.java", "diffHunk": "@@ -1211,22 +1225,43 @@ void onFillComplete(boolean updateMetric) {\n     }\n \n     /**\n-     * Fill the buffer of the current chunk with the data from the given {@link ByteBuffer}.\n-     * @param channelReadBuffer the {@link ByteBuffer} from which to read data.\n+     * Fill the buffer of the current chunk with the data from the given {@link ByteBuf}.\n+     * @param channelReadBuf the {@link ByteBuf} from which to read data.\n      * @return the number of bytes transferred in this operation.\n      */\n-    int fillFrom(ByteBuffer channelReadBuffer) {\n-      int toWrite = Math.min(channelReadBuffer.remaining(), buf.remaining());\n-      if (channelReadBuffer.remaining() > buf.remaining()) {\n-        // Manipulate limit of the source buffer in order to read only enough to fill the chunk\n-        int savedLimit = channelReadBuffer.limit();\n-        channelReadBuffer.limit(channelReadBuffer.position() + buf.remaining());\n-        buf.put(channelReadBuffer);\n-        channelReadBuffer.limit(savedLimit);\n+    int fillFrom(ByteBuf channelReadBuf) {\n+      int toWrite = 0;\n+      if (buf == null) {\n+        if (channelReadBuf.readableBytes() > routerConfig.routerMaxPutChunkSizeBytes) {\n+          toWrite = routerConfig.routerMaxPutChunkSizeBytes;\n+          buf = channelReadBuf.readRetainedSlice(routerConfig.routerMaxPutChunkSizeBytes);\n+        } else {\n+          toWrite = channelReadBuf.readableBytes();\n+          buf = channelReadBuf.readRetainedSlice(toWrite);\n+        }\n       } else {\n-        buf.put(channelReadBuffer);\n+        int remainingSize = routerConfig.routerMaxPutChunkSizeBytes - buf.readableBytes();\n+        ByteBuf remainingSlice = null;\n+        if (channelReadBuf.readableBytes() > remainingSize) {\n+          toWrite = remainingSize;\n+          remainingSlice = channelReadBuf.readRetainedSlice(remainingSize);\n+        } else {\n+          toWrite = channelReadBuf.readableBytes();\n+          remainingSlice = channelReadBuf.readRetainedSlice(toWrite);\n+        }\n+        int size = buf.readableBytes();\n+        // buf already has some bytes\n+        if (buf instanceof CompositeByteBuf) {\n+          // Buf is already a CompositeByteBuf, then just add the slice from\n+          ((CompositeByteBuf) buf).addComponent(true, remainingSlice);\n+        } else {\n+          CompositeByteBuf composite =\n+              new CompositeByteBuf(buf.alloc(), buf.isDirect(), routerConfig.routerMaxPutChunkSizeBytes);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTE3MTQzNw=="}, "originalCommit": {"oid": "06c6a6e01f9632d3c206ef1ed9cdadeabc85b8b9"}, "originalPosition": 432}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4NzkxMDIxOnYy", "diffSide": "RIGHT", "path": "ambry-router/src/main/java/com.github.ambry.router/PutOperation.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxOTo1Nzo1OFrOF-l6Dw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wM1QyMzoxMDozOFrOGAsP5w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTE3NzEwMw==", "bodyText": "What if channelReadBuf was already a CompositeByteBuf? Would it be safer to just initialize the buffer in prepareForBuilding instead of use type checking logic here? The only thing that I think would be lost would be if the buffer came with a non-default allocator and the logic about direct vs not, but I don't think either of these will be used in practice unless the composite buffers capacity is expanded or components are squashed together inside.", "url": "https://github.com/linkedin/ambry/pull/1439#discussion_r401177103", "createdAt": "2020-03-31T19:57:58Z", "author": {"login": "cgtz"}, "path": "ambry-router/src/main/java/com.github.ambry.router/PutOperation.java", "diffHunk": "@@ -1211,22 +1225,43 @@ void onFillComplete(boolean updateMetric) {\n     }\n \n     /**\n-     * Fill the buffer of the current chunk with the data from the given {@link ByteBuffer}.\n-     * @param channelReadBuffer the {@link ByteBuffer} from which to read data.\n+     * Fill the buffer of the current chunk with the data from the given {@link ByteBuf}.\n+     * @param channelReadBuf the {@link ByteBuf} from which to read data.\n      * @return the number of bytes transferred in this operation.\n      */\n-    int fillFrom(ByteBuffer channelReadBuffer) {\n-      int toWrite = Math.min(channelReadBuffer.remaining(), buf.remaining());\n-      if (channelReadBuffer.remaining() > buf.remaining()) {\n-        // Manipulate limit of the source buffer in order to read only enough to fill the chunk\n-        int savedLimit = channelReadBuffer.limit();\n-        channelReadBuffer.limit(channelReadBuffer.position() + buf.remaining());\n-        buf.put(channelReadBuffer);\n-        channelReadBuffer.limit(savedLimit);\n+    int fillFrom(ByteBuf channelReadBuf) {\n+      int toWrite = 0;\n+      if (buf == null) {\n+        if (channelReadBuf.readableBytes() > routerConfig.routerMaxPutChunkSizeBytes) {\n+          toWrite = routerConfig.routerMaxPutChunkSizeBytes;\n+          buf = channelReadBuf.readRetainedSlice(routerConfig.routerMaxPutChunkSizeBytes);\n+        } else {\n+          toWrite = channelReadBuf.readableBytes();\n+          buf = channelReadBuf.readRetainedSlice(toWrite);\n+        }\n       } else {\n-        buf.put(channelReadBuffer);\n+        int remainingSize = routerConfig.routerMaxPutChunkSizeBytes - buf.readableBytes();\n+        ByteBuf remainingSlice = null;\n+        if (channelReadBuf.readableBytes() > remainingSize) {\n+          toWrite = remainingSize;\n+          remainingSlice = channelReadBuf.readRetainedSlice(remainingSize);\n+        } else {\n+          toWrite = channelReadBuf.readableBytes();\n+          remainingSlice = channelReadBuf.readRetainedSlice(toWrite);\n+        }\n+        int size = buf.readableBytes();\n+        // buf already has some bytes\n+        if (buf instanceof CompositeByteBuf) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "06c6a6e01f9632d3c206ef1ed9cdadeabc85b8b9"}, "originalPosition": 427}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTk2NjY2Nw==", "bodyText": "I was under the impression that channelReadBuf is passed to PutOperation from HttpContent and shouldn't be composite bytebuf. Is there cases where it will be composite bytebuf?", "url": "https://github.com/linkedin/ambry/pull/1439#discussion_r401966667", "createdAt": "2020-04-01T23:23:46Z", "author": {"login": "justinlin-linkedin"}, "path": "ambry-router/src/main/java/com.github.ambry.router/PutOperation.java", "diffHunk": "@@ -1211,22 +1225,43 @@ void onFillComplete(boolean updateMetric) {\n     }\n \n     /**\n-     * Fill the buffer of the current chunk with the data from the given {@link ByteBuffer}.\n-     * @param channelReadBuffer the {@link ByteBuffer} from which to read data.\n+     * Fill the buffer of the current chunk with the data from the given {@link ByteBuf}.\n+     * @param channelReadBuf the {@link ByteBuf} from which to read data.\n      * @return the number of bytes transferred in this operation.\n      */\n-    int fillFrom(ByteBuffer channelReadBuffer) {\n-      int toWrite = Math.min(channelReadBuffer.remaining(), buf.remaining());\n-      if (channelReadBuffer.remaining() > buf.remaining()) {\n-        // Manipulate limit of the source buffer in order to read only enough to fill the chunk\n-        int savedLimit = channelReadBuffer.limit();\n-        channelReadBuffer.limit(channelReadBuffer.position() + buf.remaining());\n-        buf.put(channelReadBuffer);\n-        channelReadBuffer.limit(savedLimit);\n+    int fillFrom(ByteBuf channelReadBuf) {\n+      int toWrite = 0;\n+      if (buf == null) {\n+        if (channelReadBuf.readableBytes() > routerConfig.routerMaxPutChunkSizeBytes) {\n+          toWrite = routerConfig.routerMaxPutChunkSizeBytes;\n+          buf = channelReadBuf.readRetainedSlice(routerConfig.routerMaxPutChunkSizeBytes);\n+        } else {\n+          toWrite = channelReadBuf.readableBytes();\n+          buf = channelReadBuf.readRetainedSlice(toWrite);\n+        }\n       } else {\n-        buf.put(channelReadBuffer);\n+        int remainingSize = routerConfig.routerMaxPutChunkSizeBytes - buf.readableBytes();\n+        ByteBuf remainingSlice = null;\n+        if (channelReadBuf.readableBytes() > remainingSize) {\n+          toWrite = remainingSize;\n+          remainingSlice = channelReadBuf.readRetainedSlice(remainingSize);\n+        } else {\n+          toWrite = channelReadBuf.readableBytes();\n+          remainingSlice = channelReadBuf.readRetainedSlice(toWrite);\n+        }\n+        int size = buf.readableBytes();\n+        // buf already has some bytes\n+        if (buf instanceof CompositeByteBuf) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTE3NzEwMw=="}, "originalCommit": {"oid": "06c6a6e01f9632d3c206ef1ed9cdadeabc85b8b9"}, "originalPosition": 427}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTk3MTE4MA==", "bodyText": "You're probably right that there are no cases in practice with the chunked HttpContents we use. I just wanted to not make too many assumptions about the input in case something changes down the line", "url": "https://github.com/linkedin/ambry/pull/1439#discussion_r401971180", "createdAt": "2020-04-01T23:38:01Z", "author": {"login": "cgtz"}, "path": "ambry-router/src/main/java/com.github.ambry.router/PutOperation.java", "diffHunk": "@@ -1211,22 +1225,43 @@ void onFillComplete(boolean updateMetric) {\n     }\n \n     /**\n-     * Fill the buffer of the current chunk with the data from the given {@link ByteBuffer}.\n-     * @param channelReadBuffer the {@link ByteBuffer} from which to read data.\n+     * Fill the buffer of the current chunk with the data from the given {@link ByteBuf}.\n+     * @param channelReadBuf the {@link ByteBuf} from which to read data.\n      * @return the number of bytes transferred in this operation.\n      */\n-    int fillFrom(ByteBuffer channelReadBuffer) {\n-      int toWrite = Math.min(channelReadBuffer.remaining(), buf.remaining());\n-      if (channelReadBuffer.remaining() > buf.remaining()) {\n-        // Manipulate limit of the source buffer in order to read only enough to fill the chunk\n-        int savedLimit = channelReadBuffer.limit();\n-        channelReadBuffer.limit(channelReadBuffer.position() + buf.remaining());\n-        buf.put(channelReadBuffer);\n-        channelReadBuffer.limit(savedLimit);\n+    int fillFrom(ByteBuf channelReadBuf) {\n+      int toWrite = 0;\n+      if (buf == null) {\n+        if (channelReadBuf.readableBytes() > routerConfig.routerMaxPutChunkSizeBytes) {\n+          toWrite = routerConfig.routerMaxPutChunkSizeBytes;\n+          buf = channelReadBuf.readRetainedSlice(routerConfig.routerMaxPutChunkSizeBytes);\n+        } else {\n+          toWrite = channelReadBuf.readableBytes();\n+          buf = channelReadBuf.readRetainedSlice(toWrite);\n+        }\n       } else {\n-        buf.put(channelReadBuffer);\n+        int remainingSize = routerConfig.routerMaxPutChunkSizeBytes - buf.readableBytes();\n+        ByteBuf remainingSlice = null;\n+        if (channelReadBuf.readableBytes() > remainingSize) {\n+          toWrite = remainingSize;\n+          remainingSlice = channelReadBuf.readRetainedSlice(remainingSize);\n+        } else {\n+          toWrite = channelReadBuf.readableBytes();\n+          remainingSlice = channelReadBuf.readRetainedSlice(toWrite);\n+        }\n+        int size = buf.readableBytes();\n+        // buf already has some bytes\n+        if (buf instanceof CompositeByteBuf) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTE3NzEwMw=="}, "originalCommit": {"oid": "06c6a6e01f9632d3c206ef1ed9cdadeabc85b8b9"}, "originalPosition": 427}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzM3ODE1MQ==", "bodyText": "If we keep this code as it's, then when the channelReadBuf is a CompositeByteBuf, then when we do channelReadBuf.readRetainedSlice, it returns a unpooled ByteBuf. I suppose the code would still operate, but just not with the optimized memory arranagement.", "url": "https://github.com/linkedin/ambry/pull/1439#discussion_r403378151", "createdAt": "2020-04-03T23:10:38Z", "author": {"login": "justinlin-linkedin"}, "path": "ambry-router/src/main/java/com.github.ambry.router/PutOperation.java", "diffHunk": "@@ -1211,22 +1225,43 @@ void onFillComplete(boolean updateMetric) {\n     }\n \n     /**\n-     * Fill the buffer of the current chunk with the data from the given {@link ByteBuffer}.\n-     * @param channelReadBuffer the {@link ByteBuffer} from which to read data.\n+     * Fill the buffer of the current chunk with the data from the given {@link ByteBuf}.\n+     * @param channelReadBuf the {@link ByteBuf} from which to read data.\n      * @return the number of bytes transferred in this operation.\n      */\n-    int fillFrom(ByteBuffer channelReadBuffer) {\n-      int toWrite = Math.min(channelReadBuffer.remaining(), buf.remaining());\n-      if (channelReadBuffer.remaining() > buf.remaining()) {\n-        // Manipulate limit of the source buffer in order to read only enough to fill the chunk\n-        int savedLimit = channelReadBuffer.limit();\n-        channelReadBuffer.limit(channelReadBuffer.position() + buf.remaining());\n-        buf.put(channelReadBuffer);\n-        channelReadBuffer.limit(savedLimit);\n+    int fillFrom(ByteBuf channelReadBuf) {\n+      int toWrite = 0;\n+      if (buf == null) {\n+        if (channelReadBuf.readableBytes() > routerConfig.routerMaxPutChunkSizeBytes) {\n+          toWrite = routerConfig.routerMaxPutChunkSizeBytes;\n+          buf = channelReadBuf.readRetainedSlice(routerConfig.routerMaxPutChunkSizeBytes);\n+        } else {\n+          toWrite = channelReadBuf.readableBytes();\n+          buf = channelReadBuf.readRetainedSlice(toWrite);\n+        }\n       } else {\n-        buf.put(channelReadBuffer);\n+        int remainingSize = routerConfig.routerMaxPutChunkSizeBytes - buf.readableBytes();\n+        ByteBuf remainingSlice = null;\n+        if (channelReadBuf.readableBytes() > remainingSize) {\n+          toWrite = remainingSize;\n+          remainingSlice = channelReadBuf.readRetainedSlice(remainingSize);\n+        } else {\n+          toWrite = channelReadBuf.readableBytes();\n+          remainingSlice = channelReadBuf.readRetainedSlice(toWrite);\n+        }\n+        int size = buf.readableBytes();\n+        // buf already has some bytes\n+        if (buf instanceof CompositeByteBuf) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTE3NzEwMw=="}, "originalCommit": {"oid": "06c6a6e01f9632d3c206ef1ed9cdadeabc85b8b9"}, "originalPosition": 427}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5NjM3MzIyOnYy", "diffSide": "RIGHT", "path": "ambry-router/src/main/java/com/github/ambry/router/CryptoJobHandler.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxODoxMzoyNFrOF_3nIQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wM1QyMzoxNjo1OVrOGAsWIg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjUxNTc0NQ==", "bodyText": "any reason to increase it?", "url": "https://github.com/linkedin/ambry/pull/1439#discussion_r402515745", "createdAt": "2020-04-02T18:13:24Z", "author": {"login": "zzmao"}, "path": "ambry-router/src/main/java/com/github/ambry/router/CryptoJobHandler.java", "diffHunk": "@@ -71,7 +71,7 @@ public void close() {\n         }\n       }\n       try {\n-        scheduler.awaitTermination(1000, TimeUnit.MILLISECONDS);\n+        scheduler.awaitTermination(10000, TimeUnit.MILLISECONDS);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "573eefe64025e2a6cc69c95eb02dd89b155b471f"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzM3OTc0Ng==", "bodyText": "for testing purpose, i will revert.", "url": "https://github.com/linkedin/ambry/pull/1439#discussion_r403379746", "createdAt": "2020-04-03T23:16:59Z", "author": {"login": "justinlin-linkedin"}, "path": "ambry-router/src/main/java/com/github/ambry/router/CryptoJobHandler.java", "diffHunk": "@@ -71,7 +71,7 @@ public void close() {\n         }\n       }\n       try {\n-        scheduler.awaitTermination(1000, TimeUnit.MILLISECONDS);\n+        scheduler.awaitTermination(10000, TimeUnit.MILLISECONDS);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjUxNTc0NQ=="}, "originalCommit": {"oid": "573eefe64025e2a6cc69c95eb02dd89b155b471f"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5NjQyMTEzOnYy", "diffSide": "RIGHT", "path": "ambry-router/src/main/java/com/github/ambry/router/PutOperation.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxODoyNjo1M1rOF_4FZg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wM1QyMzoxNjoyNlrOGAsVeQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjUyMzQ5NA==", "bodyText": "Can you explain a little bit how fillFrom triggered?  I am not familiar with this area.\nFor 1 MB blob put, will it trigger fillFrom multiple times?\nMy concern here is if this will cause many small ByteBufs in buf.", "url": "https://github.com/linkedin/ambry/pull/1439#discussion_r402523494", "createdAt": "2020-04-02T18:26:53Z", "author": {"login": "zzmao"}, "path": "ambry-router/src/main/java/com/github/ambry/router/PutOperation.java", "diffHunk": "@@ -1211,22 +1229,33 @@ void onFillComplete(boolean updateMetric) {\n     }\n \n     /**\n-     * Fill the buffer of the current chunk with the data from the given {@link ByteBuffer}.\n-     * @param channelReadBuffer the {@link ByteBuffer} from which to read data.\n+     * Fill the buffer of the current chunk with the data from the given {@link ByteBuf}.\n+     * @param channelReadBuf the {@link ByteBuf} from which to read data.\n      * @return the number of bytes transferred in this operation.\n      */\n-    int fillFrom(ByteBuffer channelReadBuffer) {\n-      int toWrite = Math.min(channelReadBuffer.remaining(), buf.remaining());\n-      if (channelReadBuffer.remaining() > buf.remaining()) {\n-        // Manipulate limit of the source buffer in order to read only enough to fill the chunk\n-        int savedLimit = channelReadBuffer.limit();\n-        channelReadBuffer.limit(channelReadBuffer.position() + buf.remaining());\n-        buf.put(channelReadBuffer);\n-        channelReadBuffer.limit(savedLimit);\n+    int fillFrom(ByteBuf channelReadBuf) {\n+      int toWrite;\n+      if (buf == null) {\n+        // If current buf is null, then only read the up to routerMaxPutChunkSizeBytes.\n+        toWrite = Math.min(channelReadBuf.readableBytes(), routerConfig.routerMaxPutChunkSizeBytes);\n+        buf = channelReadBuf.readRetainedSlice(toWrite);\n       } else {\n-        buf.put(channelReadBuffer);\n+        int remainingSize = routerConfig.routerMaxPutChunkSizeBytes - buf.readableBytes();\n+        toWrite = Math.min(channelReadBuf.readableBytes(), remainingSize);\n+        ByteBuf remainingSlice = channelReadBuf.readRetainedSlice(toWrite);\n+        // buf already has some bytes", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "573eefe64025e2a6cc69c95eb02dd89b155b471f"}, "originalPosition": 413}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzM3OTE4Nw==", "bodyText": "It depends on how the http content works. For http put request, frontend would receive a bunch of netty httpContents, each http content carries a netty bytebuf, which is channelReadBuf. PutManager has a running thread that calls fillFrom periodically.", "url": "https://github.com/linkedin/ambry/pull/1439#discussion_r403379187", "createdAt": "2020-04-03T23:14:47Z", "author": {"login": "justinlin-linkedin"}, "path": "ambry-router/src/main/java/com/github/ambry/router/PutOperation.java", "diffHunk": "@@ -1211,22 +1229,33 @@ void onFillComplete(boolean updateMetric) {\n     }\n \n     /**\n-     * Fill the buffer of the current chunk with the data from the given {@link ByteBuffer}.\n-     * @param channelReadBuffer the {@link ByteBuffer} from which to read data.\n+     * Fill the buffer of the current chunk with the data from the given {@link ByteBuf}.\n+     * @param channelReadBuf the {@link ByteBuf} from which to read data.\n      * @return the number of bytes transferred in this operation.\n      */\n-    int fillFrom(ByteBuffer channelReadBuffer) {\n-      int toWrite = Math.min(channelReadBuffer.remaining(), buf.remaining());\n-      if (channelReadBuffer.remaining() > buf.remaining()) {\n-        // Manipulate limit of the source buffer in order to read only enough to fill the chunk\n-        int savedLimit = channelReadBuffer.limit();\n-        channelReadBuffer.limit(channelReadBuffer.position() + buf.remaining());\n-        buf.put(channelReadBuffer);\n-        channelReadBuffer.limit(savedLimit);\n+    int fillFrom(ByteBuf channelReadBuf) {\n+      int toWrite;\n+      if (buf == null) {\n+        // If current buf is null, then only read the up to routerMaxPutChunkSizeBytes.\n+        toWrite = Math.min(channelReadBuf.readableBytes(), routerConfig.routerMaxPutChunkSizeBytes);\n+        buf = channelReadBuf.readRetainedSlice(toWrite);\n       } else {\n-        buf.put(channelReadBuffer);\n+        int remainingSize = routerConfig.routerMaxPutChunkSizeBytes - buf.readableBytes();\n+        toWrite = Math.min(channelReadBuf.readableBytes(), remainingSize);\n+        ByteBuf remainingSlice = channelReadBuf.readRetainedSlice(toWrite);\n+        // buf already has some bytes", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjUyMzQ5NA=="}, "originalCommit": {"oid": "573eefe64025e2a6cc69c95eb02dd89b155b471f"}, "originalPosition": 413}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzM3OTU3Nw==", "bodyText": "If we have a 1MB blob, if the frontend receives 10 100K bytebuf, then the final buf would have 10 small ByteBuf. But the important thing is this is zero-copy bytebuf. We don't have to move any bytes from one place to another.", "url": "https://github.com/linkedin/ambry/pull/1439#discussion_r403379577", "createdAt": "2020-04-03T23:16:26Z", "author": {"login": "justinlin-linkedin"}, "path": "ambry-router/src/main/java/com/github/ambry/router/PutOperation.java", "diffHunk": "@@ -1211,22 +1229,33 @@ void onFillComplete(boolean updateMetric) {\n     }\n \n     /**\n-     * Fill the buffer of the current chunk with the data from the given {@link ByteBuffer}.\n-     * @param channelReadBuffer the {@link ByteBuffer} from which to read data.\n+     * Fill the buffer of the current chunk with the data from the given {@link ByteBuf}.\n+     * @param channelReadBuf the {@link ByteBuf} from which to read data.\n      * @return the number of bytes transferred in this operation.\n      */\n-    int fillFrom(ByteBuffer channelReadBuffer) {\n-      int toWrite = Math.min(channelReadBuffer.remaining(), buf.remaining());\n-      if (channelReadBuffer.remaining() > buf.remaining()) {\n-        // Manipulate limit of the source buffer in order to read only enough to fill the chunk\n-        int savedLimit = channelReadBuffer.limit();\n-        channelReadBuffer.limit(channelReadBuffer.position() + buf.remaining());\n-        buf.put(channelReadBuffer);\n-        channelReadBuffer.limit(savedLimit);\n+    int fillFrom(ByteBuf channelReadBuf) {\n+      int toWrite;\n+      if (buf == null) {\n+        // If current buf is null, then only read the up to routerMaxPutChunkSizeBytes.\n+        toWrite = Math.min(channelReadBuf.readableBytes(), routerConfig.routerMaxPutChunkSizeBytes);\n+        buf = channelReadBuf.readRetainedSlice(toWrite);\n       } else {\n-        buf.put(channelReadBuffer);\n+        int remainingSize = routerConfig.routerMaxPutChunkSizeBytes - buf.readableBytes();\n+        toWrite = Math.min(channelReadBuf.readableBytes(), remainingSize);\n+        ByteBuf remainingSlice = channelReadBuf.readRetainedSlice(toWrite);\n+        // buf already has some bytes", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjUyMzQ5NA=="}, "originalCommit": {"oid": "573eefe64025e2a6cc69c95eb02dd89b155b471f"}, "originalPosition": 413}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1441, "cost": 1, "resetAt": "2021-11-12T20:44:06Z"}}}