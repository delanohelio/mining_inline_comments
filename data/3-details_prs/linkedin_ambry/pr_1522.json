{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE5NzM2MDAy", "number": 1522, "title": "Introduce abstraction around InstanceConfigs", "bodyText": "This PR introduces a new data object called ServerConfig and associated\nshims to convert InstanceConfig change notification into ServerConfigs.\nThis will provide a framework for future work to move away from storing\nambry specific server metadata in the InstanceConfigs, which comes with\nsome Helix performance and reliability advantages.", "createdAt": "2020-05-18T20:51:57Z", "url": "https://github.com/linkedin/ambry/pull/1522", "merged": true, "mergeCommit": {"oid": "81bec97980ae9c9ee7e85beb995b43eedbb06b6f"}, "closed": true, "closedAt": "2020-06-11T00:41:33Z", "author": {"login": "cgtz"}, "timelineItems": {"totalCount": 13, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcimo4OgBqjMzNDkxNjQwNjI=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcrqXeogFqTQzMTA4NTE1Nw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8d4dbda9808fbd3df1a70c1b3ad74b401f7935eb", "author": {"user": {"login": "cgtz", "name": "Casey Getz"}}, "url": "https://github.com/linkedin/ambry/commit/8d4dbda9808fbd3df1a70c1b3ad74b401f7935eb", "committedDate": "2020-05-18T20:49:32Z", "message": "Introduce abstraction around InstanceConfigs\n\nThis PR introduces a new data object called ServerConfig and associated\nshims to convert InstanceConfig change notification into ServerConfigs.\n\nThis will provide a framework for future work to move away from storing\nambry specific server metadata in the InstanceConfigs, which comes with\nsome Helix performance and reliability advantages."}, "afterCommit": {"oid": "f19c35f56ed450ae74e567ce6715de4703741bb7", "author": {"user": {"login": "cgtz", "name": "Casey Getz"}}, "url": "https://github.com/linkedin/ambry/commit/f19c35f56ed450ae74e567ce6715de4703741bb7", "committedDate": "2020-05-18T21:20:17Z", "message": "Introduce abstraction around InstanceConfigs\n\nThis PR introduces a new data object called ServerConfig and associated\nshims to convert InstanceConfig change notification into ServerConfigs.\n\nThis will provide a framework for future work to move away from storing\nambry specific server metadata in the InstanceConfigs, which comes with\nsome Helix performance and reliability advantages."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "25234700c53aa167bc2778334d772c4b4f08ce65", "author": {"user": {"login": "cgtz", "name": "Casey Getz"}}, "url": "https://github.com/linkedin/ambry/commit/25234700c53aa167bc2778334d772c4b4f08ce65", "committedDate": "2020-05-19T21:37:54Z", "message": "Add javadocs"}, "afterCommit": {"oid": "a4e5af74231d4bc38c92135099a5034ce8648077", "author": {"user": {"login": "cgtz", "name": "Casey Getz"}}, "url": "https://github.com/linkedin/ambry/commit/a4e5af74231d4bc38c92135099a5034ce8648077", "committedDate": "2020-05-19T23:33:19Z", "message": "Introduce abstraction around InstanceConfigs\n\nThis PR introduces a new data object called DataNodeConfig and associated\nshims to convert InstanceConfig change notification into ServerConfigs.\n\nThis will provide a framework for future work to move away from storing\nambry specific server metadata in the InstanceConfigs, which comes with\nsome Helix performance and reliability advantages."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6f3e45853c58a0de6d479c391f17ed99bdb028fe", "author": {"user": {"login": "cgtz", "name": "Casey Getz"}}, "url": "https://github.com/linkedin/ambry/commit/6f3e45853c58a0de6d479c391f17ed99bdb028fe", "committedDate": "2020-05-21T01:08:28Z", "message": "Introduce abstraction around InstanceConfigs\n\nThis PR introduces a new data object called DataNodeConfig and associated\nshims to convert InstanceConfig change notification into ServerConfigs.\n\nThis will provide a framework for future work to move away from storing\nambry specific server metadata in the InstanceConfigs, which comes with\nsome Helix performance and reliability advantages."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a4e5af74231d4bc38c92135099a5034ce8648077", "author": {"user": {"login": "cgtz", "name": "Casey Getz"}}, "url": "https://github.com/linkedin/ambry/commit/a4e5af74231d4bc38c92135099a5034ce8648077", "committedDate": "2020-05-19T23:33:19Z", "message": "Introduce abstraction around InstanceConfigs\n\nThis PR introduces a new data object called DataNodeConfig and associated\nshims to convert InstanceConfig change notification into ServerConfigs.\n\nThis will provide a framework for future work to move away from storing\nambry specific server metadata in the InstanceConfigs, which comes with\nsome Helix performance and reliability advantages."}, "afterCommit": {"oid": "6f3e45853c58a0de6d479c391f17ed99bdb028fe", "author": {"user": {"login": "cgtz", "name": "Casey Getz"}}, "url": "https://github.com/linkedin/ambry/commit/6f3e45853c58a0de6d479c391f17ed99bdb028fe", "committedDate": "2020-05-21T01:08:28Z", "message": "Introduce abstraction around InstanceConfigs\n\nThis PR introduces a new data object called DataNodeConfig and associated\nshims to convert InstanceConfig change notification into ServerConfigs.\n\nThis will provide a framework for future work to move away from storing\nambry specific server metadata in the InstanceConfigs, which comes with\nsome Helix performance and reliability advantages."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE2Mjc4OTI1", "url": "https://github.com/linkedin/ambry/pull/1522#pullrequestreview-416278925", "createdAt": "2020-05-21T15:58:33Z", "commit": {"oid": "6f3e45853c58a0de6d479c391f17ed99bdb028fe"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQxNTo1ODozM1rOGY41Cg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQxNTo1ODozM1rOGY41Cg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc1MDA5MA==", "bodyText": "Nice written to use observe pattern so that when DataNodeConfig changes state, the clusterChangeHandler are notified and updated through onDataNodeConfigChange!", "url": "https://github.com/linkedin/ambry/pull/1522#discussion_r428750090", "createdAt": "2020-05-21T15:58:33Z", "author": {"login": "SophieGuo410"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/InstanceConfigToDataNodeConfigAdapter.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *\n+ */\n+\n+package com.github.ambry.clustermap;\n+\n+import com.github.ambry.config.ClusterMapConfig;\n+import java.util.Objects;\n+import org.apache.helix.HelixManager;\n+import org.apache.helix.api.listeners.InstanceConfigChangeListener;\n+import org.apache.helix.model.InstanceConfig;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static com.github.ambry.clustermap.ClusterMapUtils.*;\n+\n+\n+/**\n+ * An implementation of {@link DataNodeConfigSource} that converts between {@link InstanceConfig}s received by an\n+ * {@link InstanceConfigChangeListener} and {@link DataNodeConfig}s.\n+ */\n+public class InstanceConfigToDataNodeConfigAdapter implements DataNodeConfigSource {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(InstanceConfigToDataNodeConfigAdapter.class);\n+  private final HelixManager helixManager;\n+  private final ClusterMapConfig clusterMapConfig;\n+\n+  /**\n+   * @param helixManager the {@link HelixManager} to use as the source of truth for {@link InstanceConfig}s.\n+   * @param clusterMapConfig the {@link ClusterMapConfig} to use.\n+   */\n+  public InstanceConfigToDataNodeConfigAdapter(HelixManager helixManager, ClusterMapConfig clusterMapConfig) {\n+    this.helixManager = helixManager;\n+    this.clusterMapConfig = clusterMapConfig;\n+  }\n+\n+  @Override\n+  public void addServerConfigChangeListener(DataNodeConfigChangeListener listener) throws Exception {\n+    helixManager.addInstanceConfigChangeListener((InstanceConfigChangeListener) (instanceConfigs, context) -> {\n+      Iterable<DataNodeConfig> dataNodeConfigs =\n+          () -> instanceConfigs.stream().map(this::convert).filter(Objects::nonNull).iterator();\n+      listener.onDataNodeConfigChange(dataNodeConfigs);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6f3e45853c58a0de6d479c391f17ed99bdb028fe"}, "originalPosition": 52}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE3ODMwNDM0", "url": "https://github.com/linkedin/ambry/pull/1522#pullrequestreview-417830434", "createdAt": "2020-05-25T18:00:06Z", "commit": {"oid": "6f3e45853c58a0de6d479c391f17ed99bdb028fe"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNVQxODowMDowNlrOGaHPZA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNVQxODowMDowNlrOGaHPZA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDAzNDc4OA==", "bodyText": "I will introduce another list of disabledReplicas in InstanceConfig (and will be migrated to DataNodeConfig in near future). Could you add a set of disabled replicas as a placeholder here?  For now it should be empty and no router logic depends on it. The purpose of disabledReplicas is to allow server to disable replicas on bad disk (also triggers state transition) and to automatically re-enable these replicas when disk is replaced and server is restarted.", "url": "https://github.com/linkedin/ambry/pull/1522#discussion_r430034788", "createdAt": "2020-05-25T18:00:06Z", "author": {"login": "jsjtzyy"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfig.java", "diffHunk": "@@ -0,0 +1,229 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *\n+ */\n+\n+package com.github.ambry.clustermap;\n+\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+\n+\n+/**\n+ * A data object for configs scoped to a single data node.\n+ */\n+class DataNodeConfig {\n+  private final String instanceName;\n+  private final String hostName;\n+  private final int port;\n+  private final String datacenterName;\n+  private final Integer sslPort;\n+  private final Integer http2Port;\n+  private final String rackId;\n+  private final long xid;\n+  private final Set<String> sealedReplicas = new HashSet<>();\n+  private final Set<String> stoppedReplicas = new HashSet<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6f3e45853c58a0de6d479c391f17ed99bdb028fe"}, "originalPosition": 37}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIyMTc4MzE3", "url": "https://github.com/linkedin/ambry/pull/1522#pullrequestreview-422178317", "createdAt": "2020-06-01T21:00:17Z", "commit": {"oid": "6f3e45853c58a0de6d479c391f17ed99bdb028fe"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMVQyMTowMDoxN1rOGdZ9og==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMVQyMTowMDoxN1rOGdZ9og==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzQ4NzI2Ng==", "bodyText": "I wonder why these two sets are mutable?", "url": "https://github.com/linkedin/ambry/pull/1522#discussion_r433487266", "createdAt": "2020-06-01T21:00:17Z", "author": {"login": "jsjtzyy"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfig.java", "diffHunk": "@@ -0,0 +1,229 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *\n+ */\n+\n+package com.github.ambry.clustermap;\n+\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+\n+\n+/**\n+ * A data object for configs scoped to a single data node.\n+ */\n+class DataNodeConfig {\n+  private final String instanceName;\n+  private final String hostName;\n+  private final int port;\n+  private final String datacenterName;\n+  private final Integer sslPort;\n+  private final Integer http2Port;\n+  private final String rackId;\n+  private final long xid;\n+  private final Set<String> sealedReplicas = new HashSet<>();\n+  private final Set<String> stoppedReplicas = new HashSet<>();\n+  private final Map<String, DiskConfig> diskConfigs = new HashMap<>();\n+\n+  /**\n+   * @param instanceName a name that can be used as a unique key for this server.\n+   * @param hostName the host name of the server.\n+   * @param port the port of the server.\n+   * @param datacenterName the datacenter this server is in.\n+   * @param sslPort the ssl port, or {@code null} if the server does not have one.\n+   * @param http2Port the HTTP2 port, or {@code null} if the server does not have one.\n+   * @param rackId an identifier for the rack or cabinet that the server is in for computing failure domains.\n+   * @param xid  the xid for this server.\n+   */\n+  DataNodeConfig(String instanceName, String hostName, int port, String datacenterName, Integer sslPort,\n+      Integer http2Port, String rackId, long xid) {\n+    this.instanceName = instanceName;\n+    this.hostName = hostName;\n+    this.port = port;\n+    this.datacenterName = datacenterName;\n+    this.sslPort = sslPort;\n+    this.http2Port = http2Port;\n+    this.rackId = rackId;\n+    this.xid = xid;\n+  }\n+\n+  /**\n+    * @return a name that can be used as a unique key for this server.\n+   */\n+  String getInstanceName() {\n+    return instanceName;\n+  }\n+\n+  /**\n+   * @return the host name of the server.\n+   */\n+  String getHostName() {\n+    return hostName;\n+  }\n+\n+  /**\n+   * @return the port of the server.\n+   */\n+  int getPort() {\n+    return port;\n+  }\n+\n+  /**\n+   * @return the datacenter this server is in.\n+   */\n+  String getDatacenterName() {\n+    return datacenterName;\n+  }\n+\n+  /**\n+   * @return the ssl port, or {@code null} if the server does not have one.\n+   */\n+  Integer getSslPort() {\n+    return sslPort;\n+  }\n+\n+  /**\n+   * @return the HTTP2 port, or {@code null} if the server does not have one.\n+   */\n+  Integer getHttp2Port() {\n+    return http2Port;\n+  }\n+\n+  /**\n+   * @return an identifier for the rack or cabinet that the server is in for computing failure domains.\n+   */\n+  String getRackId() {\n+    return rackId;\n+  }\n+\n+  /**\n+   * @return the xid for this server. After {@link SimpleClusterChangeHandler} is retired, this field will be removed.\n+   */\n+  long getXid() {\n+    return xid;\n+  }\n+\n+  /**\n+   * @return the set of sealed replicas on this server. This set is mutable.\n+   */\n+  Set<String> getSealedReplicas() {\n+    return sealedReplicas;\n+  }\n+\n+  /**\n+   * @return the set of stopped replicas on this server. This set is mutable.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6f3e45853c58a0de6d479c391f17ed99bdb028fe"}, "originalPosition": 126}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f77253fbd2c0c342617c1cff8dce8330265eebab", "author": {"user": {"login": "cgtz", "name": "Casey Getz"}}, "url": "https://github.com/linkedin/ambry/commit/f77253fbd2c0c342617c1cff8dce8330265eebab", "committedDate": "2020-06-08T18:40:29Z", "message": "Add placeholder for disabled replics"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "6d9c5deb9465ec3cc3088e5f9b73e06a56ab9dba", "author": {"user": {"login": "cgtz", "name": "Casey Getz"}}, "url": "https://github.com/linkedin/ambry/commit/6d9c5deb9465ec3cc3088e5f9b73e06a56ab9dba", "committedDate": "2020-06-08T18:39:11Z", "message": "Add placeholder for disabled replics"}, "afterCommit": {"oid": "f77253fbd2c0c342617c1cff8dce8330265eebab", "author": {"user": {"login": "cgtz", "name": "Casey Getz"}}, "url": "https://github.com/linkedin/ambry/commit/f77253fbd2c0c342617c1cff8dce8330265eebab", "committedDate": "2020-06-08T18:40:29Z", "message": "Add placeholder for disabled replics"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI3Mzc2NjY5", "url": "https://github.com/linkedin/ambry/pull/1522#pullrequestreview-427376669", "createdAt": "2020-06-09T17:16:05Z", "commit": {"oid": "f77253fbd2c0c342617c1cff8dce8330265eebab"}, "state": "APPROVED", "comments": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQxNzoxNjowNVrOGhUe7w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMzo1MToxNVrOGhgOJA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzU5MTc5MQ==", "bodyText": "nit: format this file", "url": "https://github.com/linkedin/ambry/pull/1522#discussion_r437591791", "createdAt": "2020-06-09T17:16:05Z", "author": {"login": "jsjtzyy"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfig.java", "diffHunk": "@@ -0,0 +1,237 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *\n+ */\n+\n+package com.github.ambry.clustermap;\n+\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+\n+\n+/**\n+ * A data object for configs scoped to a single data node.\n+ */\n+class DataNodeConfig {\n+  private final String instanceName;\n+  private final String hostName;\n+  private final int port;\n+  private final String datacenterName;\n+  private final Integer sslPort;\n+  private final Integer http2Port;\n+  private final String rackId;\n+  private final long xid;\n+  private final Set<String> sealedReplicas = new HashSet<>();\n+  private final Set<String> stoppedReplicas = new HashSet<>();\n+  private final Set<String> disabledReplicas = new HashSet<>();\n+  private final Map<String, DiskConfig> diskConfigs = new HashMap<>();\n+\n+  /**\n+   * @param instanceName a name that can be used as a unique key for this server.\n+   * @param hostName the host name of the server.\n+   * @param port the port of the server.\n+   * @param datacenterName the datacenter this server is in.\n+   * @param sslPort the ssl port, or {@code null} if the server does not have one.\n+   * @param http2Port the HTTP2 port, or {@code null} if the server does not have one.\n+   * @param rackId an identifier for the rack or cabinet that the server is in for computing failure domains.\n+   * @param xid  the xid for this server.\n+   */\n+  DataNodeConfig(String instanceName, String hostName, int port, String datacenterName, Integer sslPort,\n+      Integer http2Port, String rackId, long xid) {\n+    this.instanceName = instanceName;\n+    this.hostName = hostName;\n+    this.port = port;\n+    this.datacenterName = datacenterName;\n+    this.sslPort = sslPort;\n+    this.http2Port = http2Port;\n+    this.rackId = rackId;\n+    this.xid = xid;\n+  }\n+\n+  /**\n+    * @return a name that can be used as a unique key for this server.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f77253fbd2c0c342617c1cff8dce8330265eebab"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzYyNDc1Mg==", "bodyText": "typo: replicas", "url": "https://github.com/linkedin/ambry/pull/1522#discussion_r437624752", "createdAt": "2020-06-09T18:12:36Z", "author": {"login": "jsjtzyy"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfig.java", "diffHunk": "@@ -0,0 +1,237 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *\n+ */\n+\n+package com.github.ambry.clustermap;\n+\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+\n+\n+/**\n+ * A data object for configs scoped to a single data node.\n+ */\n+class DataNodeConfig {\n+  private final String instanceName;\n+  private final String hostName;\n+  private final int port;\n+  private final String datacenterName;\n+  private final Integer sslPort;\n+  private final Integer http2Port;\n+  private final String rackId;\n+  private final long xid;\n+  private final Set<String> sealedReplicas = new HashSet<>();\n+  private final Set<String> stoppedReplicas = new HashSet<>();\n+  private final Set<String> disabledReplicas = new HashSet<>();\n+  private final Map<String, DiskConfig> diskConfigs = new HashMap<>();\n+\n+  /**\n+   * @param instanceName a name that can be used as a unique key for this server.\n+   * @param hostName the host name of the server.\n+   * @param port the port of the server.\n+   * @param datacenterName the datacenter this server is in.\n+   * @param sslPort the ssl port, or {@code null} if the server does not have one.\n+   * @param http2Port the HTTP2 port, or {@code null} if the server does not have one.\n+   * @param rackId an identifier for the rack or cabinet that the server is in for computing failure domains.\n+   * @param xid  the xid for this server.\n+   */\n+  DataNodeConfig(String instanceName, String hostName, int port, String datacenterName, Integer sslPort,\n+      Integer http2Port, String rackId, long xid) {\n+    this.instanceName = instanceName;\n+    this.hostName = hostName;\n+    this.port = port;\n+    this.datacenterName = datacenterName;\n+    this.sslPort = sslPort;\n+    this.http2Port = http2Port;\n+    this.rackId = rackId;\n+    this.xid = xid;\n+  }\n+\n+  /**\n+    * @return a name that can be used as a unique key for this server.\n+   */\n+  String getInstanceName() {\n+    return instanceName;\n+  }\n+\n+  /**\n+   * @return the host name of the server.\n+   */\n+  String getHostName() {\n+    return hostName;\n+  }\n+\n+  /**\n+   * @return the port of the server.\n+   */\n+  int getPort() {\n+    return port;\n+  }\n+\n+  /**\n+   * @return the datacenter this server is in.\n+   */\n+  String getDatacenterName() {\n+    return datacenterName;\n+  }\n+\n+  /**\n+   * @return the ssl port, or {@code null} if the server does not have one.\n+   */\n+  Integer getSslPort() {\n+    return sslPort;\n+  }\n+\n+  /**\n+   * @return the HTTP2 port, or {@code null} if the server does not have one.\n+   */\n+  Integer getHttp2Port() {\n+    return http2Port;\n+  }\n+\n+  /**\n+   * @return an identifier for the rack or cabinet that the server is in for computing failure domains.\n+   */\n+  String getRackId() {\n+    return rackId;\n+  }\n+\n+  /**\n+   * @return the xid for this server. After {@link SimpleClusterChangeHandler} is retired, this field will be removed.\n+   */\n+  long getXid() {\n+    return xid;\n+  }\n+\n+  /**\n+   * @return the set of sealed replicas on this server. This set is mutable.\n+   */\n+  Set<String> getSealedReplicas() {\n+    return sealedReplicas;\n+  }\n+\n+  /**\n+   * @return the set of stopped replicas on this server. This set is mutable.\n+   */\n+  Set<String> getStoppedReplicas() {\n+    return stoppedReplicas;\n+  }\n+\n+  /**\n+   * @return the set of disabled replicas on this server. This set is mutable.\n+   */\n+  Set<String> getDisabledReplicas() {\n+    return disabledReplicas;\n+  }\n+\n+  /**\n+   * @return a map from mount path to {@link DiskConfig} for all the disks on the server. This map is mutable.\n+   */\n+  Map<String, DiskConfig> getDiskConfigs() {\n+    return diskConfigs;\n+  }\n+\n+  @Override\n+  public String toString() {\n+    return \"ServerConfig{\" + \"instanceName='\" + instanceName + '\\'' + \", hostName='\" + hostName + '\\'' + \", port=\"\n+        + port + \", datacenterName='\" + datacenterName + '\\'' + \", sslPort=\" + sslPort + \", http2Port=\" + http2Port\n+        + \", rackId='\" + rackId + '\\'' + \", xid=\" + xid + \", sealedReplicas=\" + sealedReplicas + \", stoppedReplicas=\"\n+        + stoppedReplicas + \", diskConfigs=\" + diskConfigs + '}';\n+  }\n+\n+  /**\n+   * Configuration scoped to a single disk on a server.\n+   */\n+  static class DiskConfig {\n+    private final HardwareState state;\n+    private final long diskCapacity;\n+    private final Map<String, ReplicaConfig> replicaConfigs = new HashMap<>();\n+\n+    /**\n+     * @param state the configured {@link HardwareState} of the disk.\n+     * @param diskCapacity the capacity of the disk in bytes.\n+     */\n+    DiskConfig(HardwareState state, long diskCapacity) {\n+      this.state = state;\n+      this.diskCapacity = diskCapacity;\n+    }\n+\n+    /**\n+     * @return the configured {@link HardwareState} of the disk.\n+     */\n+    HardwareState getState() {\n+      return state;\n+    }\n+\n+    /**\n+     * @return the capacity of the disk in bytes.\n+     */\n+    long getDiskCapacity() {\n+      return diskCapacity;\n+    }\n+\n+    /**\n+     * @return a map from partition name to {@link ReplicaConfig} for all the repliccas on the server.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f77253fbd2c0c342617c1cff8dce8330265eebab"}, "originalPosition": 187}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzYyNjcwNA==", "bodyText": "minor:  could you add disabledReplicas as well?", "url": "https://github.com/linkedin/ambry/pull/1522#discussion_r437626704", "createdAt": "2020-06-09T18:16:01Z", "author": {"login": "jsjtzyy"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfig.java", "diffHunk": "@@ -0,0 +1,237 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *\n+ */\n+\n+package com.github.ambry.clustermap;\n+\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+\n+\n+/**\n+ * A data object for configs scoped to a single data node.\n+ */\n+class DataNodeConfig {\n+  private final String instanceName;\n+  private final String hostName;\n+  private final int port;\n+  private final String datacenterName;\n+  private final Integer sslPort;\n+  private final Integer http2Port;\n+  private final String rackId;\n+  private final long xid;\n+  private final Set<String> sealedReplicas = new HashSet<>();\n+  private final Set<String> stoppedReplicas = new HashSet<>();\n+  private final Set<String> disabledReplicas = new HashSet<>();\n+  private final Map<String, DiskConfig> diskConfigs = new HashMap<>();\n+\n+  /**\n+   * @param instanceName a name that can be used as a unique key for this server.\n+   * @param hostName the host name of the server.\n+   * @param port the port of the server.\n+   * @param datacenterName the datacenter this server is in.\n+   * @param sslPort the ssl port, or {@code null} if the server does not have one.\n+   * @param http2Port the HTTP2 port, or {@code null} if the server does not have one.\n+   * @param rackId an identifier for the rack or cabinet that the server is in for computing failure domains.\n+   * @param xid  the xid for this server.\n+   */\n+  DataNodeConfig(String instanceName, String hostName, int port, String datacenterName, Integer sslPort,\n+      Integer http2Port, String rackId, long xid) {\n+    this.instanceName = instanceName;\n+    this.hostName = hostName;\n+    this.port = port;\n+    this.datacenterName = datacenterName;\n+    this.sslPort = sslPort;\n+    this.http2Port = http2Port;\n+    this.rackId = rackId;\n+    this.xid = xid;\n+  }\n+\n+  /**\n+    * @return a name that can be used as a unique key for this server.\n+   */\n+  String getInstanceName() {\n+    return instanceName;\n+  }\n+\n+  /**\n+   * @return the host name of the server.\n+   */\n+  String getHostName() {\n+    return hostName;\n+  }\n+\n+  /**\n+   * @return the port of the server.\n+   */\n+  int getPort() {\n+    return port;\n+  }\n+\n+  /**\n+   * @return the datacenter this server is in.\n+   */\n+  String getDatacenterName() {\n+    return datacenterName;\n+  }\n+\n+  /**\n+   * @return the ssl port, or {@code null} if the server does not have one.\n+   */\n+  Integer getSslPort() {\n+    return sslPort;\n+  }\n+\n+  /**\n+   * @return the HTTP2 port, or {@code null} if the server does not have one.\n+   */\n+  Integer getHttp2Port() {\n+    return http2Port;\n+  }\n+\n+  /**\n+   * @return an identifier for the rack or cabinet that the server is in for computing failure domains.\n+   */\n+  String getRackId() {\n+    return rackId;\n+  }\n+\n+  /**\n+   * @return the xid for this server. After {@link SimpleClusterChangeHandler} is retired, this field will be removed.\n+   */\n+  long getXid() {\n+    return xid;\n+  }\n+\n+  /**\n+   * @return the set of sealed replicas on this server. This set is mutable.\n+   */\n+  Set<String> getSealedReplicas() {\n+    return sealedReplicas;\n+  }\n+\n+  /**\n+   * @return the set of stopped replicas on this server. This set is mutable.\n+   */\n+  Set<String> getStoppedReplicas() {\n+    return stoppedReplicas;\n+  }\n+\n+  /**\n+   * @return the set of disabled replicas on this server. This set is mutable.\n+   */\n+  Set<String> getDisabledReplicas() {\n+    return disabledReplicas;\n+  }\n+\n+  /**\n+   * @return a map from mount path to {@link DiskConfig} for all the disks on the server. This map is mutable.\n+   */\n+  Map<String, DiskConfig> getDiskConfigs() {\n+    return diskConfigs;\n+  }\n+\n+  @Override\n+  public String toString() {\n+    return \"ServerConfig{\" + \"instanceName='\" + instanceName + '\\'' + \", hostName='\" + hostName + '\\'' + \", port=\"\n+        + port + \", datacenterName='\" + datacenterName + '\\'' + \", sslPort=\" + sslPort + \", http2Port=\" + http2Port\n+        + \", rackId='\" + rackId + '\\'' + \", xid=\" + xid + \", sealedReplicas=\" + sealedReplicas + \", stoppedReplicas=\"\n+        + stoppedReplicas + \", diskConfigs=\" + diskConfigs + '}';", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f77253fbd2c0c342617c1cff8dce8330265eebab"}, "originalPosition": 152}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzYyODMxNQ==", "bodyText": "Can we rename diskCapacity to diskCapacityInBytes?  Same for replicaCapacity.", "url": "https://github.com/linkedin/ambry/pull/1522#discussion_r437628315", "createdAt": "2020-06-09T18:18:52Z", "author": {"login": "jsjtzyy"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfig.java", "diffHunk": "@@ -0,0 +1,237 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *\n+ */\n+\n+package com.github.ambry.clustermap;\n+\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+\n+\n+/**\n+ * A data object for configs scoped to a single data node.\n+ */\n+class DataNodeConfig {\n+  private final String instanceName;\n+  private final String hostName;\n+  private final int port;\n+  private final String datacenterName;\n+  private final Integer sslPort;\n+  private final Integer http2Port;\n+  private final String rackId;\n+  private final long xid;\n+  private final Set<String> sealedReplicas = new HashSet<>();\n+  private final Set<String> stoppedReplicas = new HashSet<>();\n+  private final Set<String> disabledReplicas = new HashSet<>();\n+  private final Map<String, DiskConfig> diskConfigs = new HashMap<>();\n+\n+  /**\n+   * @param instanceName a name that can be used as a unique key for this server.\n+   * @param hostName the host name of the server.\n+   * @param port the port of the server.\n+   * @param datacenterName the datacenter this server is in.\n+   * @param sslPort the ssl port, or {@code null} if the server does not have one.\n+   * @param http2Port the HTTP2 port, or {@code null} if the server does not have one.\n+   * @param rackId an identifier for the rack or cabinet that the server is in for computing failure domains.\n+   * @param xid  the xid for this server.\n+   */\n+  DataNodeConfig(String instanceName, String hostName, int port, String datacenterName, Integer sslPort,\n+      Integer http2Port, String rackId, long xid) {\n+    this.instanceName = instanceName;\n+    this.hostName = hostName;\n+    this.port = port;\n+    this.datacenterName = datacenterName;\n+    this.sslPort = sslPort;\n+    this.http2Port = http2Port;\n+    this.rackId = rackId;\n+    this.xid = xid;\n+  }\n+\n+  /**\n+    * @return a name that can be used as a unique key for this server.\n+   */\n+  String getInstanceName() {\n+    return instanceName;\n+  }\n+\n+  /**\n+   * @return the host name of the server.\n+   */\n+  String getHostName() {\n+    return hostName;\n+  }\n+\n+  /**\n+   * @return the port of the server.\n+   */\n+  int getPort() {\n+    return port;\n+  }\n+\n+  /**\n+   * @return the datacenter this server is in.\n+   */\n+  String getDatacenterName() {\n+    return datacenterName;\n+  }\n+\n+  /**\n+   * @return the ssl port, or {@code null} if the server does not have one.\n+   */\n+  Integer getSslPort() {\n+    return sslPort;\n+  }\n+\n+  /**\n+   * @return the HTTP2 port, or {@code null} if the server does not have one.\n+   */\n+  Integer getHttp2Port() {\n+    return http2Port;\n+  }\n+\n+  /**\n+   * @return an identifier for the rack or cabinet that the server is in for computing failure domains.\n+   */\n+  String getRackId() {\n+    return rackId;\n+  }\n+\n+  /**\n+   * @return the xid for this server. After {@link SimpleClusterChangeHandler} is retired, this field will be removed.\n+   */\n+  long getXid() {\n+    return xid;\n+  }\n+\n+  /**\n+   * @return the set of sealed replicas on this server. This set is mutable.\n+   */\n+  Set<String> getSealedReplicas() {\n+    return sealedReplicas;\n+  }\n+\n+  /**\n+   * @return the set of stopped replicas on this server. This set is mutable.\n+   */\n+  Set<String> getStoppedReplicas() {\n+    return stoppedReplicas;\n+  }\n+\n+  /**\n+   * @return the set of disabled replicas on this server. This set is mutable.\n+   */\n+  Set<String> getDisabledReplicas() {\n+    return disabledReplicas;\n+  }\n+\n+  /**\n+   * @return a map from mount path to {@link DiskConfig} for all the disks on the server. This map is mutable.\n+   */\n+  Map<String, DiskConfig> getDiskConfigs() {\n+    return diskConfigs;\n+  }\n+\n+  @Override\n+  public String toString() {\n+    return \"ServerConfig{\" + \"instanceName='\" + instanceName + '\\'' + \", hostName='\" + hostName + '\\'' + \", port=\"\n+        + port + \", datacenterName='\" + datacenterName + '\\'' + \", sslPort=\" + sslPort + \", http2Port=\" + http2Port\n+        + \", rackId='\" + rackId + '\\'' + \", xid=\" + xid + \", sealedReplicas=\" + sealedReplicas + \", stoppedReplicas=\"\n+        + stoppedReplicas + \", diskConfigs=\" + diskConfigs + '}';\n+  }\n+\n+  /**\n+   * Configuration scoped to a single disk on a server.\n+   */\n+  static class DiskConfig {\n+    private final HardwareState state;\n+    private final long diskCapacity;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f77253fbd2c0c342617c1cff8dce8330265eebab"}, "originalPosition": 160}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc1MzYwMQ==", "bodyText": "rename to addDataNodeConfigChangeListener?", "url": "https://github.com/linkedin/ambry/pull/1522#discussion_r437753601", "createdAt": "2020-06-09T22:18:00Z", "author": {"login": "jsjtzyy"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfigSource.java", "diffHunk": "@@ -0,0 +1,28 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *\n+ */\n+\n+package com.github.ambry.clustermap;\n+\n+/**\n+ * A source of {@link DataNodeConfig}s for a cluster. Can be used for config change notification and administration.\n+ */\n+interface DataNodeConfigSource {\n+  /**\n+   * Attach a listener that will be notified when there are new or updated {@link DataNodeConfig}s.\n+   * @param listener the {@link DataNodeConfigChangeListener} to attach.\n+   */\n+  void addServerConfigChangeListener(DataNodeConfigChangeListener listener) throws Exception;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f77253fbd2c0c342617c1cff8dce8330265eebab"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3MTk0Nw==", "bodyText": "minor: based on {@link DataNodeConfig}(s)", "url": "https://github.com/linkedin/ambry/pull/1522#discussion_r437771947", "createdAt": "2020-06-09T23:11:41Z", "author": {"login": "jsjtzyy"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/DynamicClusterChangeHandler.java", "diffHunk": "@@ -275,25 +275,19 @@ public void registerClusterMapListener(ClusterMapChangeListener clusterMapChange\n   }\n \n   /**\n-   * Add new instance or update existing instance based on {@link InstanceConfig}(s). This may also invoke callbacks in\n-   * some clustermap change listeners (i.e. {@link PartitionSelectionHelper}, ReplicationManager)\n-   * @param instanceConfigs the {@link InstanceConfig}(s) used to update in-mem cluster map.\n-   * @throws Exception\n+   * Add new instances or update existing instances based on {@link InstanceConfig}(s). This may also invoke callbacks", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f77253fbd2c0c342617c1cff8dce8330265eebab"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3NjcyMw==", "bodyText": "minor: {@link DataNodeConfig}", "url": "https://github.com/linkedin/ambry/pull/1522#discussion_r437776723", "createdAt": "2020-06-09T23:26:37Z", "author": {"login": "jsjtzyy"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/DynamicClusterChangeHandler.java", "diffHunk": "@@ -433,22 +425,22 @@ private void updateReplicaStateAndOverrideIfNeeded(AmbryReplica replica, List<St\n \n   /**\n    * Create a new instance(node) and initialize disks/replicas on it.\n-   * @param instanceConfig the {@link InstanceConfig} to create new instance\n+   * @param dataNodeConfig the {@link InstanceConfig} to create new instance", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f77253fbd2c0c342617c1cff8dce8330265eebab"}, "originalPosition": 223}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3NzI2Ng==", "bodyText": "same here, {@link DataNodeConfig}", "url": "https://github.com/linkedin/ambry/pull/1522#discussion_r437777266", "createdAt": "2020-06-09T23:28:27Z", "author": {"login": "jsjtzyy"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/DynamicClusterChangeHandler.java", "diffHunk": "@@ -458,67 +450,52 @@ private void updateReplicaStateAndOverrideIfNeeded(AmbryReplica replica, List<St\n    * that partition is being constructed. If partition override is enabled, the seal state of replica is determined by\n    * partition info in HelixPropertyStore, if disabled, the seal state is determined by instanceConfig.\n    * @param datanode the {@link AmbryDataNode} that is being initialized.\n-   * @param instanceConfig the {@link InstanceConfig} associated with this datanode.\n+   * @param dataNodeConfig the {@link InstanceConfig} associated with this datanode.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f77253fbd2c0c342617c1cff8dce8330265eebab"}, "originalPosition": 254}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc4MzkwMQ==", "bodyText": "can remove this comment", "url": "https://github.com/linkedin/ambry/pull/1522#discussion_r437783901", "createdAt": "2020-06-09T23:50:35Z", "author": {"login": "jsjtzyy"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/SimpleClusterChangeHandler.java", "diffHunk": "@@ -270,86 +268,71 @@ public void registerClusterMapListener(ClusterMapChangeListener clusterMapChange\n   /**\n    * Populate the initial data from the admin connection. Create nodes, disks, partitions and replicas for the entire\n    * cluster. An {@link InstanceConfig} will only be looked at if the xid in it is <= currentXid.\n-   * @param instanceConfigs the list of {@link InstanceConfig}s containing the information about the sealed states of replicas.\n+   * @param dataNodeConfigs the list of {@link DataNodeConfig}s containing the information about the sealed states of\n+   *                        replicas.\n    * @throws Exception if creation of {@link AmbryDataNode}s or {@link AmbryDisk}s throw an Exception.\n    */\n-  private void initializeInstances(List<InstanceConfig> instanceConfigs) throws Exception {\n+  private void initializeInstances(Iterable<DataNodeConfig> dataNodeConfigs) throws Exception {\n     logger.info(\"Initializing cluster information from {}\", dcName);\n-    for (InstanceConfig instanceConfig : instanceConfigs) {\n-      int schemaVersion = getSchemaVersion(instanceConfig);\n-      switch (schemaVersion) {\n-        case 0:\n-          String instanceName = instanceConfig.getInstanceName();\n-          long instanceXid = getXid(instanceConfig);\n-          if (instanceName.equals(selfInstanceName) || instanceXid <= currentXid.get()) {\n-            logger.info(\"Adding node {} and its disks and replicas\", instanceName);\n-            // HTTP2 port null for now, until it's populated to Helix\n-            AmbryDataNode datanode =\n-                new AmbryServerDataNode(getDcName(instanceConfig), clusterMapConfig, instanceConfig.getHostName(),\n-                    Integer.parseInt(instanceConfig.getPort()), getRackId(instanceConfig),\n-                    getSslPortStr(instanceConfig), getHttp2PortStr(instanceConfig), instanceXid,\n-                    helixClusterManagerCallback);\n-            initializeDisksAndReplicasOnNode(datanode, instanceConfig);\n-            instanceNameToAmbryDataNode.put(instanceName, datanode);\n-          } else {\n-            logger.info(\n-                \"Ignoring instanceConfig for {} because the xid associated with it ({}) is later than current xid ({})\",\n-                instanceName, instanceXid, currentXid.get());\n-            helixClusterManagerMetrics.ignoredUpdatesCount.inc();\n-          }\n-          break;\n-        default:\n-          logger.error(\"Unknown InstanceConfig schema version: {}, ignoring.\", schemaVersion);\n-          break;\n+    for (DataNodeConfig dataNodeConfig : dataNodeConfigs) {\n+      String instanceName = dataNodeConfig.getInstanceName();\n+      long instanceXid = dataNodeConfig.getXid();\n+      if (instanceName.equals(selfInstanceName) || instanceXid <= currentXid.get()) {\n+        logger.info(\"Adding node {} and its disks and replicas\", instanceName);\n+        // HTTP2 port null for now, until it's populated to Helix", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f77253fbd2c0c342617c1cff8dce8330265eebab"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc4NDEwMA==", "bodyText": "the given list of {@link DataNodeConfig}", "url": "https://github.com/linkedin/ambry/pull/1522#discussion_r437784100", "createdAt": "2020-06-09T23:51:15Z", "author": {"login": "jsjtzyy"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/SimpleClusterChangeHandler.java", "diffHunk": "@@ -270,86 +268,71 @@ public void registerClusterMapListener(ClusterMapChangeListener clusterMapChange\n   /**\n    * Populate the initial data from the admin connection. Create nodes, disks, partitions and replicas for the entire\n    * cluster. An {@link InstanceConfig} will only be looked at if the xid in it is <= currentXid.\n-   * @param instanceConfigs the list of {@link InstanceConfig}s containing the information about the sealed states of replicas.\n+   * @param dataNodeConfigs the list of {@link DataNodeConfig}s containing the information about the sealed states of\n+   *                        replicas.\n    * @throws Exception if creation of {@link AmbryDataNode}s or {@link AmbryDisk}s throw an Exception.\n    */\n-  private void initializeInstances(List<InstanceConfig> instanceConfigs) throws Exception {\n+  private void initializeInstances(Iterable<DataNodeConfig> dataNodeConfigs) throws Exception {\n     logger.info(\"Initializing cluster information from {}\", dcName);\n-    for (InstanceConfig instanceConfig : instanceConfigs) {\n-      int schemaVersion = getSchemaVersion(instanceConfig);\n-      switch (schemaVersion) {\n-        case 0:\n-          String instanceName = instanceConfig.getInstanceName();\n-          long instanceXid = getXid(instanceConfig);\n-          if (instanceName.equals(selfInstanceName) || instanceXid <= currentXid.get()) {\n-            logger.info(\"Adding node {} and its disks and replicas\", instanceName);\n-            // HTTP2 port null for now, until it's populated to Helix\n-            AmbryDataNode datanode =\n-                new AmbryServerDataNode(getDcName(instanceConfig), clusterMapConfig, instanceConfig.getHostName(),\n-                    Integer.parseInt(instanceConfig.getPort()), getRackId(instanceConfig),\n-                    getSslPortStr(instanceConfig), getHttp2PortStr(instanceConfig), instanceXid,\n-                    helixClusterManagerCallback);\n-            initializeDisksAndReplicasOnNode(datanode, instanceConfig);\n-            instanceNameToAmbryDataNode.put(instanceName, datanode);\n-          } else {\n-            logger.info(\n-                \"Ignoring instanceConfig for {} because the xid associated with it ({}) is later than current xid ({})\",\n-                instanceName, instanceXid, currentXid.get());\n-            helixClusterManagerMetrics.ignoredUpdatesCount.inc();\n-          }\n-          break;\n-        default:\n-          logger.error(\"Unknown InstanceConfig schema version: {}, ignoring.\", schemaVersion);\n-          break;\n+    for (DataNodeConfig dataNodeConfig : dataNodeConfigs) {\n+      String instanceName = dataNodeConfig.getInstanceName();\n+      long instanceXid = dataNodeConfig.getXid();\n+      if (instanceName.equals(selfInstanceName) || instanceXid <= currentXid.get()) {\n+        logger.info(\"Adding node {} and its disks and replicas\", instanceName);\n+        // HTTP2 port null for now, until it's populated to Helix\n+        AmbryDataNode datanode =\n+            new AmbryServerDataNode(dataNodeConfig.getDatacenterName(), clusterMapConfig, dataNodeConfig.getHostName(),\n+                dataNodeConfig.getPort(), dataNodeConfig.getRackId(), dataNodeConfig.getSslPort(),\n+                dataNodeConfig.getHttp2Port(), instanceXid, helixClusterManagerCallback);\n+        initializeDisksAndReplicasOnNode(datanode, dataNodeConfig);\n+        instanceNameToAmbryDataNode.put(instanceName, datanode);\n+      } else {\n+        logger.info(\n+            \"Ignoring instanceConfig for {} because the xid associated with it ({}) is later than current xid ({})\",\n+            instanceName, instanceXid, currentXid.get());\n+        helixClusterManagerMetrics.ignoredUpdatesCount.inc();\n       }\n     }\n     logger.info(\"Initialized cluster information from {}\", dcName);\n   }\n \n   /**\n    * Go over the given list of {@link InstanceConfig}s and update the both sealed and stopped states of replicas.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f77253fbd2c0c342617c1cff8dce8330265eebab"}, "originalPosition": 79}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI3NjI0MTEz", "url": "https://github.com/linkedin/ambry/pull/1522#pullrequestreview-427624113", "createdAt": "2020-06-10T00:00:01Z", "commit": {"oid": "f77253fbd2c0c342617c1cff8dce8330265eebab"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7fbf11f5177df6a8750ffffd86f8fb30296d4cce", "author": {"user": {"login": "cgtz", "name": "Casey Getz"}}, "url": "https://github.com/linkedin/ambry/commit/7fbf11f5177df6a8750ffffd86f8fb30296d4cce", "committedDate": "2020-06-10T15:39:47Z", "message": "Address comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMxMDg1MTU3", "url": "https://github.com/linkedin/ambry/pull/1522#pullrequestreview-431085157", "createdAt": "2020-06-16T00:46:29Z", "commit": {"oid": "7fbf11f5177df6a8750ffffd86f8fb30296d4cce"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQwMDo0NjoyOVrOGkHa2g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQwMDo0NjoyOVrOGkHa2g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDUyMzQ4Mg==", "bodyText": "Sorry, I didn't catch this when I was reviewing the code. It mistakenly assigned StoppedReplicas to sealedReplicas", "url": "https://github.com/linkedin/ambry/pull/1522#discussion_r440523482", "createdAt": "2020-06-16T00:46:29Z", "author": {"login": "jsjtzyy"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/DynamicClusterChangeHandler.java", "diffHunk": "@@ -310,81 +303,79 @@ private void addOrUpdateInstanceInfos(List<InstanceConfig> instanceConfigs) thro\n   /**\n    * Update info of an existing instance. This may happen in following cases: (1) new replica is added; (2) old replica\n    * is removed; (3) replica's state has changed (i.e. becomes seal/unseal).\n-   * @param instanceConfig the {@link InstanceConfig} used to update info of instance.\n+   * @param dataNodeConfig the {@link DataNodeConfig} used to update info of instance.\n    * @return a pair of lists: (1) new added replicas; (2) removed old replicas, during this update.\n    */\n-  private Pair<List<ReplicaId>, List<ReplicaId>> updateInstanceInfo(InstanceConfig instanceConfig) throws Exception {\n+  private Pair<List<ReplicaId>, List<ReplicaId>> updateInstanceInfo(DataNodeConfig dataNodeConfig) throws Exception {\n     final List<ReplicaId> addedReplicas = new ArrayList<>();\n     final List<ReplicaId> removedReplicas = new ArrayList<>();\n-    String instanceName = instanceConfig.getInstanceName();\n+    String instanceName = dataNodeConfig.getInstanceName();\n     logger.info(\"Updating replicas info for existing node {}\", instanceName);\n-    List<String> sealedReplicas = getSealedReplicas(instanceConfig);\n-    List<String> stoppedReplicas = getStoppedReplicas(instanceConfig);\n+    Set<String> sealedReplicas = dataNodeConfig.getStoppedReplicas();\n+    Set<String> stoppedReplicas = dataNodeConfig.getSealedReplicas();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7fbf11f5177df6a8750ffffd86f8fb30296d4cce"}, "originalPosition": 100}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1494, "cost": 1, "resetAt": "2021-11-01T16:19:10Z"}}}