{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTE4NjQ3MTE0", "number": 1690, "reviewThreads": {"totalCount": 20, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQyMDo0NjoyM1rOE3aA8w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QyMDoyMzo1MFrOE6N6gg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI2NTMzMzYzOnYy", "diffSide": "RIGHT", "path": "ambry-api/src/main/java/com/github/ambry/rest/RestUtils.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQyMDo0NjoyM1rOHwu-Sg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMToyNDoxOVrOH2I4zg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg2MzMwNg==", "bodyText": "Is there no existing utility method that does this?  I could swear I've seen one.", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r520863306", "createdAt": "2020-11-10T20:46:23Z", "author": {"login": "lightningrob"}, "path": "ambry-api/src/main/java/com/github/ambry/rest/RestUtils.java", "diffHunk": "@@ -930,4 +933,16 @@ private static ByteRange buildByteRange(String rangeHeaderValue) throws RestServ\n     }\n     return range;\n   }\n+\n+  /**\n+   * Drops the leading slash and extension (if any) in the blob ID.\n+   * @param blobIdWithExtension the blob ID possibly with an extension.\n+   * @return {@code blobIdWithExtension} without an extension if there was one.\n+   */\n+  public static String stripSlashAndExtensionFromId(String blobIdWithExtension) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46b79ff017bcaa19aeae785e2bfbc5b627d75c58"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzMDc2Ng==", "bodyText": "There's one in close source UtilLI which I can't use in open source side. I'm planning to replace the close source one in the future rb.", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r526530766", "createdAt": "2020-11-19T01:24:19Z", "author": {"login": "SophieGuo410"}, "path": "ambry-api/src/main/java/com/github/ambry/rest/RestUtils.java", "diffHunk": "@@ -930,4 +933,16 @@ private static ByteRange buildByteRange(String rangeHeaderValue) throws RestServ\n     }\n     return range;\n   }\n+\n+  /**\n+   * Drops the leading slash and extension (if any) in the blob ID.\n+   * @param blobIdWithExtension the blob ID possibly with an extension.\n+   * @return {@code blobIdWithExtension} without an extension if there was one.\n+   */\n+  public static String stripSlashAndExtensionFromId(String blobIdWithExtension) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg2MzMwNg=="}, "originalCommit": {"oid": "46b79ff017bcaa19aeae785e2bfbc5b627d75c58"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI2NTUxMTU1OnYy", "diffSide": "RIGHT", "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AccountAndContainerInjector.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQyMTo0MDozM1rOHwwrWw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMToyNToxM1rOH2I59A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg5MTIyNw==", "bodyText": "I think this should be \"that account name/container name can be parsed from\"", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r520891227", "createdAt": "2020-11-10T21:40:33Z", "author": {"login": "lightningrob"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AccountAndContainerInjector.java", "diffHunk": "@@ -84,6 +85,48 @@ public void injectAccountAndContainerForPostRequest(RestRequest restRequest, Res\n     }\n   }\n \n+  /**\n+   * Injects target {@link Account} and {@link Container} for PUT requests. This method also ensures required uri\n+   * is present for the PUT requests that can account name/container name can parse from.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46b79ff017bcaa19aeae785e2bfbc5b627d75c58"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzMTA2MA==", "bodyText": "Updated.", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r526531060", "createdAt": "2020-11-19T01:25:13Z", "author": {"login": "SophieGuo410"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AccountAndContainerInjector.java", "diffHunk": "@@ -84,6 +85,48 @@ public void injectAccountAndContainerForPostRequest(RestRequest restRequest, Res\n     }\n   }\n \n+  /**\n+   * Injects target {@link Account} and {@link Container} for PUT requests. This method also ensures required uri\n+   * is present for the PUT requests that can account name/container name can parse from.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg5MTIyNw=="}, "originalCommit": {"oid": "46b79ff017bcaa19aeae785e2bfbc5b627d75c58"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI2NTUzMjM2OnYy", "diffSide": "RIGHT", "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AccountAndContainerInjector.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQyMTo0NzowOFrOHww4UQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQwMTozMDoyM1rOH26DgQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg5NDU0NQ==", "bodyText": "What is named?", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r520894545", "createdAt": "2020-11-10T21:47:08Z", "author": {"login": "lightningrob"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AccountAndContainerInjector.java", "diffHunk": "@@ -84,6 +85,48 @@ public void injectAccountAndContainerForPostRequest(RestRequest restRequest, Res\n     }\n   }\n \n+  /**\n+   * Injects target {@link Account} and {@link Container} for PUT requests. This method also ensures required uri\n+   * is present for the PUT requests that can account name/container name can parse from.\n+   * @param restRequest The Put {@link RestRequest}.\n+   * @param metricsGroup The {@link RestRequestMetricsGroup} to use to set up {@link ContainerMetrics}, or {@code null}\n+   *                     if {@link ContainerMetrics} instantiation is not needed.\n+   * @throws RestServiceException\n+   */\n+  public void injectAccountAndContainerForPutRequest(RestRequest restRequest, RestRequestMetricsGroup metricsGroup)\n+      throws RestServiceException {\n+    accountAndContainerSanityCheckForNamedBlob(restRequest);\n+    if (restRequest.getUri() != null) {\n+      frontendMetrics.putWithAccountAndContainerHeaderRate.mark();\n+      injectAccountAndContainerUsingAccountAndContainerUri(restRequest, metricsGroup);\n+    } else if (frontendConfig.allowServiceIdBasedPutRequest) {\n+      ensureRequiredHeadersOrThrow(restRequest, requiredAmbryHeadersForPutWithServiceId);\n+      frontendMetrics.putWithServiceIdForAccountNameRate.mark();\n+      String serviceId = getHeader(restRequest.getArgs(), Headers.SERVICE_ID, true);\n+      boolean isPrivate = isPrivate(restRequest.getArgs());\n+      injectAccountAndContainerUsingServiceId(restRequest, serviceId, isPrivate, metricsGroup);\n+    } else {\n+      throw new RestServiceException(\n+          \"Missing either \" + Headers.TARGET_ACCOUNT_NAME + \" or \" + Headers.TARGET_CONTAINER_NAME + \" header\",\n+          RestServiceErrorCode.BadRequest);\n+    }\n+  }\n+\n+  /**\n+   * Parse the input if it's the named blob request.\n+   * @param input the url that needs to be parsed.\n+   * @return the String array contains the\n+   */\n+  private String[] parseInput(String input) {\n+    Objects.requireNonNull(input, \"input should not be null\");\n+    String[] slashFields = input.split(\"/\");\n+    if (slashFields.length < 4) {\n+      throw new IllegalArgumentException(\n+          \"File must have name format '/<named>/<account_name>/<container_name>/blob_name'.  Received: '\" + input + \"'\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46b79ff017bcaa19aeae785e2bfbc5b627d75c58"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzMTMxNA==", "bodyText": "It's the prefix of the namedBlob url which helps us identify it's the namedBlob request.", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r526531314", "createdAt": "2020-11-19T01:25:55Z", "author": {"login": "SophieGuo410"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AccountAndContainerInjector.java", "diffHunk": "@@ -84,6 +85,48 @@ public void injectAccountAndContainerForPostRequest(RestRequest restRequest, Res\n     }\n   }\n \n+  /**\n+   * Injects target {@link Account} and {@link Container} for PUT requests. This method also ensures required uri\n+   * is present for the PUT requests that can account name/container name can parse from.\n+   * @param restRequest The Put {@link RestRequest}.\n+   * @param metricsGroup The {@link RestRequestMetricsGroup} to use to set up {@link ContainerMetrics}, or {@code null}\n+   *                     if {@link ContainerMetrics} instantiation is not needed.\n+   * @throws RestServiceException\n+   */\n+  public void injectAccountAndContainerForPutRequest(RestRequest restRequest, RestRequestMetricsGroup metricsGroup)\n+      throws RestServiceException {\n+    accountAndContainerSanityCheckForNamedBlob(restRequest);\n+    if (restRequest.getUri() != null) {\n+      frontendMetrics.putWithAccountAndContainerHeaderRate.mark();\n+      injectAccountAndContainerUsingAccountAndContainerUri(restRequest, metricsGroup);\n+    } else if (frontendConfig.allowServiceIdBasedPutRequest) {\n+      ensureRequiredHeadersOrThrow(restRequest, requiredAmbryHeadersForPutWithServiceId);\n+      frontendMetrics.putWithServiceIdForAccountNameRate.mark();\n+      String serviceId = getHeader(restRequest.getArgs(), Headers.SERVICE_ID, true);\n+      boolean isPrivate = isPrivate(restRequest.getArgs());\n+      injectAccountAndContainerUsingServiceId(restRequest, serviceId, isPrivate, metricsGroup);\n+    } else {\n+      throw new RestServiceException(\n+          \"Missing either \" + Headers.TARGET_ACCOUNT_NAME + \" or \" + Headers.TARGET_CONTAINER_NAME + \" header\",\n+          RestServiceErrorCode.BadRequest);\n+    }\n+  }\n+\n+  /**\n+   * Parse the input if it's the named blob request.\n+   * @param input the url that needs to be parsed.\n+   * @return the String array contains the\n+   */\n+  private String[] parseInput(String input) {\n+    Objects.requireNonNull(input, \"input should not be null\");\n+    String[] slashFields = input.split(\"/\");\n+    if (slashFields.length < 4) {\n+      throw new IllegalArgumentException(\n+          \"File must have name format '/<named>/<account_name>/<container_name>/blob_name'.  Received: '\" + input + \"'\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg5NDU0NQ=="}, "originalCommit": {"oid": "46b79ff017bcaa19aeae785e2bfbc5b627d75c58"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzMzNjMyMQ==", "bodyText": "Got it.  Don't really need brackets around that since it is a string literal, but no big deal.", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r527336321", "createdAt": "2020-11-20T01:30:23Z", "author": {"login": "lightningrob"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AccountAndContainerInjector.java", "diffHunk": "@@ -84,6 +85,48 @@ public void injectAccountAndContainerForPostRequest(RestRequest restRequest, Res\n     }\n   }\n \n+  /**\n+   * Injects target {@link Account} and {@link Container} for PUT requests. This method also ensures required uri\n+   * is present for the PUT requests that can account name/container name can parse from.\n+   * @param restRequest The Put {@link RestRequest}.\n+   * @param metricsGroup The {@link RestRequestMetricsGroup} to use to set up {@link ContainerMetrics}, or {@code null}\n+   *                     if {@link ContainerMetrics} instantiation is not needed.\n+   * @throws RestServiceException\n+   */\n+  public void injectAccountAndContainerForPutRequest(RestRequest restRequest, RestRequestMetricsGroup metricsGroup)\n+      throws RestServiceException {\n+    accountAndContainerSanityCheckForNamedBlob(restRequest);\n+    if (restRequest.getUri() != null) {\n+      frontendMetrics.putWithAccountAndContainerHeaderRate.mark();\n+      injectAccountAndContainerUsingAccountAndContainerUri(restRequest, metricsGroup);\n+    } else if (frontendConfig.allowServiceIdBasedPutRequest) {\n+      ensureRequiredHeadersOrThrow(restRequest, requiredAmbryHeadersForPutWithServiceId);\n+      frontendMetrics.putWithServiceIdForAccountNameRate.mark();\n+      String serviceId = getHeader(restRequest.getArgs(), Headers.SERVICE_ID, true);\n+      boolean isPrivate = isPrivate(restRequest.getArgs());\n+      injectAccountAndContainerUsingServiceId(restRequest, serviceId, isPrivate, metricsGroup);\n+    } else {\n+      throw new RestServiceException(\n+          \"Missing either \" + Headers.TARGET_ACCOUNT_NAME + \" or \" + Headers.TARGET_CONTAINER_NAME + \" header\",\n+          RestServiceErrorCode.BadRequest);\n+    }\n+  }\n+\n+  /**\n+   * Parse the input if it's the named blob request.\n+   * @param input the url that needs to be parsed.\n+   * @return the String array contains the\n+   */\n+  private String[] parseInput(String input) {\n+    Objects.requireNonNull(input, \"input should not be null\");\n+    String[] slashFields = input.split(\"/\");\n+    if (slashFields.length < 4) {\n+      throw new IllegalArgumentException(\n+          \"File must have name format '/<named>/<account_name>/<container_name>/blob_name'.  Received: '\" + input + \"'\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg5NDU0NQ=="}, "originalCommit": {"oid": "46b79ff017bcaa19aeae785e2bfbc5b627d75c58"}, "originalPosition": 49}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI2NTUzNzg4OnYy", "diffSide": "RIGHT", "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AccountAndContainerInjector.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQyMTo0ODo1MlrOHww7pQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMToyNjozMVrOH2I7vQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg5NTM5Nw==", "bodyText": "dangling sentence", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r520895397", "createdAt": "2020-11-10T21:48:52Z", "author": {"login": "lightningrob"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AccountAndContainerInjector.java", "diffHunk": "@@ -84,6 +85,48 @@ public void injectAccountAndContainerForPostRequest(RestRequest restRequest, Res\n     }\n   }\n \n+  /**\n+   * Injects target {@link Account} and {@link Container} for PUT requests. This method also ensures required uri\n+   * is present for the PUT requests that can account name/container name can parse from.\n+   * @param restRequest The Put {@link RestRequest}.\n+   * @param metricsGroup The {@link RestRequestMetricsGroup} to use to set up {@link ContainerMetrics}, or {@code null}\n+   *                     if {@link ContainerMetrics} instantiation is not needed.\n+   * @throws RestServiceException\n+   */\n+  public void injectAccountAndContainerForPutRequest(RestRequest restRequest, RestRequestMetricsGroup metricsGroup)\n+      throws RestServiceException {\n+    accountAndContainerSanityCheckForNamedBlob(restRequest);\n+    if (restRequest.getUri() != null) {\n+      frontendMetrics.putWithAccountAndContainerHeaderRate.mark();\n+      injectAccountAndContainerUsingAccountAndContainerUri(restRequest, metricsGroup);\n+    } else if (frontendConfig.allowServiceIdBasedPutRequest) {\n+      ensureRequiredHeadersOrThrow(restRequest, requiredAmbryHeadersForPutWithServiceId);\n+      frontendMetrics.putWithServiceIdForAccountNameRate.mark();\n+      String serviceId = getHeader(restRequest.getArgs(), Headers.SERVICE_ID, true);\n+      boolean isPrivate = isPrivate(restRequest.getArgs());\n+      injectAccountAndContainerUsingServiceId(restRequest, serviceId, isPrivate, metricsGroup);\n+    } else {\n+      throw new RestServiceException(\n+          \"Missing either \" + Headers.TARGET_ACCOUNT_NAME + \" or \" + Headers.TARGET_CONTAINER_NAME + \" header\",\n+          RestServiceErrorCode.BadRequest);\n+    }\n+  }\n+\n+  /**\n+   * Parse the input if it's the named blob request.\n+   * @param input the url that needs to be parsed.\n+   * @return the String array contains the", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46b79ff017bcaa19aeae785e2bfbc5b627d75c58"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzMTUxNw==", "bodyText": "Sorry about that. Fix it.", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r526531517", "createdAt": "2020-11-19T01:26:31Z", "author": {"login": "SophieGuo410"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AccountAndContainerInjector.java", "diffHunk": "@@ -84,6 +85,48 @@ public void injectAccountAndContainerForPostRequest(RestRequest restRequest, Res\n     }\n   }\n \n+  /**\n+   * Injects target {@link Account} and {@link Container} for PUT requests. This method also ensures required uri\n+   * is present for the PUT requests that can account name/container name can parse from.\n+   * @param restRequest The Put {@link RestRequest}.\n+   * @param metricsGroup The {@link RestRequestMetricsGroup} to use to set up {@link ContainerMetrics}, or {@code null}\n+   *                     if {@link ContainerMetrics} instantiation is not needed.\n+   * @throws RestServiceException\n+   */\n+  public void injectAccountAndContainerForPutRequest(RestRequest restRequest, RestRequestMetricsGroup metricsGroup)\n+      throws RestServiceException {\n+    accountAndContainerSanityCheckForNamedBlob(restRequest);\n+    if (restRequest.getUri() != null) {\n+      frontendMetrics.putWithAccountAndContainerHeaderRate.mark();\n+      injectAccountAndContainerUsingAccountAndContainerUri(restRequest, metricsGroup);\n+    } else if (frontendConfig.allowServiceIdBasedPutRequest) {\n+      ensureRequiredHeadersOrThrow(restRequest, requiredAmbryHeadersForPutWithServiceId);\n+      frontendMetrics.putWithServiceIdForAccountNameRate.mark();\n+      String serviceId = getHeader(restRequest.getArgs(), Headers.SERVICE_ID, true);\n+      boolean isPrivate = isPrivate(restRequest.getArgs());\n+      injectAccountAndContainerUsingServiceId(restRequest, serviceId, isPrivate, metricsGroup);\n+    } else {\n+      throw new RestServiceException(\n+          \"Missing either \" + Headers.TARGET_ACCOUNT_NAME + \" or \" + Headers.TARGET_CONTAINER_NAME + \" header\",\n+          RestServiceErrorCode.BadRequest);\n+    }\n+  }\n+\n+  /**\n+   * Parse the input if it's the named blob request.\n+   * @param input the url that needs to be parsed.\n+   * @return the String array contains the", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg5NTM5Nw=="}, "originalCommit": {"oid": "46b79ff017bcaa19aeae785e2bfbc5b627d75c58"}, "originalPosition": 42}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI2NTU3MzQwOnYy", "diffSide": "RIGHT", "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AccountAndContainerInjector.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQyMTo1OTo1NlrOHwxRJg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQwMTozMToxNlrOH26Etw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwMDkwMg==", "bodyText": "Why are put requests injected differently than post requests?  Put requests contain the blobId, but that doesn't appear to be used here.", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r520900902", "createdAt": "2020-11-10T21:59:56Z", "author": {"login": "lightningrob"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AccountAndContainerInjector.java", "diffHunk": "@@ -84,6 +85,48 @@ public void injectAccountAndContainerForPostRequest(RestRequest restRequest, Res\n     }\n   }\n \n+  /**\n+   * Injects target {@link Account} and {@link Container} for PUT requests. This method also ensures required uri\n+   * is present for the PUT requests that can account name/container name can parse from.\n+   * @param restRequest The Put {@link RestRequest}.\n+   * @param metricsGroup The {@link RestRequestMetricsGroup} to use to set up {@link ContainerMetrics}, or {@code null}\n+   *                     if {@link ContainerMetrics} instantiation is not needed.\n+   * @throws RestServiceException\n+   */\n+  public void injectAccountAndContainerForPutRequest(RestRequest restRequest, RestRequestMetricsGroup metricsGroup)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46b79ff017bcaa19aeae785e2bfbc5b627d75c58"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzNDIwNg==", "bodyText": "For named blob put request, the source of truth is the blob url which looks like \"/named/accountName/containerName/blobName\", so client don't need to provide any accountName/containerName headers/blobId. Similar like post request, it will call router.putBlob first to get the blobId, and pass it to Id convertor. And the difference between the post request is post request will return blobId as a location header but in this put nameBlob case there's no need to return anything. So after discuss with @cgtz , we decided to generate the putBlobHandler to handler this case. And already named it as NamedBlobPutHandler. Feel free to let me know if you have any concern.", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r526534206", "createdAt": "2020-11-19T01:34:55Z", "author": {"login": "SophieGuo410"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AccountAndContainerInjector.java", "diffHunk": "@@ -84,6 +85,48 @@ public void injectAccountAndContainerForPostRequest(RestRequest restRequest, Res\n     }\n   }\n \n+  /**\n+   * Injects target {@link Account} and {@link Container} for PUT requests. This method also ensures required uri\n+   * is present for the PUT requests that can account name/container name can parse from.\n+   * @param restRequest The Put {@link RestRequest}.\n+   * @param metricsGroup The {@link RestRequestMetricsGroup} to use to set up {@link ContainerMetrics}, or {@code null}\n+   *                     if {@link ContainerMetrics} instantiation is not needed.\n+   * @throws RestServiceException\n+   */\n+  public void injectAccountAndContainerForPutRequest(RestRequest restRequest, RestRequestMetricsGroup metricsGroup)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwMDkwMg=="}, "originalCommit": {"oid": "46b79ff017bcaa19aeae785e2bfbc5b627d75c58"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzMzNjYzMQ==", "bodyText": "Okay thanks for explaining.", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r527336631", "createdAt": "2020-11-20T01:31:16Z", "author": {"login": "lightningrob"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AccountAndContainerInjector.java", "diffHunk": "@@ -84,6 +85,48 @@ public void injectAccountAndContainerForPostRequest(RestRequest restRequest, Res\n     }\n   }\n \n+  /**\n+   * Injects target {@link Account} and {@link Container} for PUT requests. This method also ensures required uri\n+   * is present for the PUT requests that can account name/container name can parse from.\n+   * @param restRequest The Put {@link RestRequest}.\n+   * @param metricsGroup The {@link RestRequestMetricsGroup} to use to set up {@link ContainerMetrics}, or {@code null}\n+   *                     if {@link ContainerMetrics} instantiation is not needed.\n+   * @throws RestServiceException\n+   */\n+  public void injectAccountAndContainerForPutRequest(RestRequest restRequest, RestRequestMetricsGroup metricsGroup)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwMDkwMg=="}, "originalCommit": {"oid": "46b79ff017bcaa19aeae785e2bfbc5b627d75c58"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI2NTU4NjEwOnYy", "diffSide": "RIGHT", "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AmbryIdConverterFactory.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQyMjowNDowN1rOHwxZFA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMTozNTozMVrOH2JG_g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwMjkzMg==", "bodyText": "Looks like duplicate method.", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r520902932", "createdAt": "2020-11-10T22:04:07Z", "author": {"login": "lightningrob"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AmbryIdConverterFactory.java", "diffHunk": "@@ -73,30 +86,126 @@ public void close() {\n      */\n     @Override\n     public Future<String> convert(RestRequest restRequest, String input, Callback<String> callback) {\n-      FutureResult<String> futureResult = new FutureResult<String>();\n+      final CompletableFuture<String> future = new CompletableFuture<>();\n       String convertedId = null;\n       Exception exception = null;\n       frontendMetrics.idConverterRequestRate.mark();\n       long startTimeInMs = System.currentTimeMillis();\n-      if (!isOpen) {\n+      try {\n+        if (!isOpen) {\n+        frontendMetrics.idConverterProcessingTimeInMs.update(System.currentTimeMillis() - startTimeInMs);\n         exception = new RestServiceException(\"IdConverter is closed\", RestServiceErrorCode.ServiceUnavailable);\n-      } else {\n-        try {\n-          if (restRequest.getRestMethod().equals(RestMethod.POST)) {\n+        } else if (restRequest.getRestMethod().equals(RestMethod.POST)) {\n             convertedId = \"/\" + signIdIfRequired(restRequest, input);\n-          } else {\n-            convertedId = parseSignedIdIfRequired(restRequest, input.startsWith(\"/\") ? input.substring(1) : input);\n-          }\n-        } catch (Exception e) {\n+        } else {\n+            frontendMetrics.idConverterProcessingTimeInMs.update(System.currentTimeMillis() - startTimeInMs);\n+            convertId(input, restRequest).whenComplete(\n+                (id, throwable) -> completeConversion(id, extractCompletionExceptionCause(throwable), future, callback));\n+        }\n+      } catch (Exception e) {\n           exception = e;\n+      } finally {\n+        frontendMetrics.idConverterProcessingTimeInMs.update(System.currentTimeMillis() - startTimeInMs);\n+        if (convertedId != null || exception != null) {\n+          completeConversion(convertedId, exception, future, callback);\n         }\n       }\n-      futureResult.done(convertedId, exception);\n+      return future;\n+    }\n+\n+    /**\n+     * @param throwable a throwable to possibly wrap in an exception.\n+     * @return if the {@link Throwable} is an instance of {@link Exception}, return the throwable, otherwise return the\n+     *         throwable wrapped in an exception.\n+     */\n+    private static Exception extractCompletionExceptionCause(Throwable throwable) {\n+      if (throwable == null) {\n+        return null;\n+      }\n+      if (throwable instanceof CompletionException) {\n+        throwable = throwable.getCause();\n+      }\n+      return throwable instanceof Exception ? (Exception) throwable : new Exception(\"Encountered throwable\", throwable);\n+    }\n+\n+    /**\n+     * Completes the conversion by setting the future and invoking the callback.\n+     * @param conversionResult the conversion result.\n+     * @param exception any exception that occurred as a part of the conversion.\n+     * @param completableFuture the {@link CompletableFuture} that must be set.\n+     * @param callback the {@link Callback} that needs to be invoked. Can be null.\n+     */\n+    private <T> void completeConversion(T conversionResult, Exception exception, CompletableFuture<T> completableFuture,\n+        Callback<T> callback) {\n+      if (exception == null) {\n+        completableFuture.complete(conversionResult);\n+      } else {\n+        completableFuture.completeExceptionally(exception);\n+      }\n       if (callback != null) {\n-        callback.onCompletion(convertedId, exception);\n+        long startTime = System.currentTimeMillis();\n+        callback.onCompletion(conversionResult, exception);\n+        frontendMetrics.idConversionDownstreamCallbackTimeInMs.update(System.currentTimeMillis() - startTime);\n+      }\n+    }\n+\n+    /**\n+     * Convert the input ID to the requested output. If it's the named blob request, return the blobId from NameBlobDb,\n+     * otherwise return the input with leading slash and extension be stripped.\n+     * @param input the input blob ID.\n+     * @param restRequest the {@link RestRequest} to set arguments in.\n+     * @return the {@link CompletionStage} that will be completed with the converted ID\n+     * @throws RestServiceException\n+     */\n+    private CompletionStage<String> convertId(String input, RestRequest restRequest)\n+        throws RestServiceException, IOException {\n+      CompletionStage<String> conversionFuture;\n+      if (input.startsWith(NAMED_BLOB_PREFIX)) {\n+        String[] slashFields = parseInput(input);\n+        //will update this hack version once NamedBlobDb is in.\n+        conversionFuture = get(slashFields[2], slashFields[3], slashFields[4]);\n+      } else if (restRequest.getRestMethod().equals(RestMethod.PUT) && restRequest.getUri().startsWith(NAMED_BLOB_PREFIX)) {\n+        String[] slashFields = parseInput(restRequest.getPath());\n+        StoreKey blobId = new BlobId(RestUtils.stripSlashAndExtensionFromId(input), clusterMap);\n+        conversionFuture = put(slashFields[2], slashFields[3], slashFields[4], blobId);\n+      } else {\n+        String decryptedInput = parseSignedIdIfRequired(restRequest, input.startsWith(\"/\") ? input.substring(1) : input);\n+        conversionFuture = CompletableFuture.completedFuture(RestUtils.stripSlashAndExtensionFromId(decryptedInput));\n+      }\n+      return conversionFuture;\n+    }\n+\n+    /*\n+     * will update this hack version once NamedBlobDb is in.\n+     */\n+    private CompletableFuture<String> get(String accountName, String containerName, String blobName) {\n+      CompletableFuture<String> completableFuture = new CompletableFuture<>();\n+      completableFuture.complete(accountName + containerName + blobName);\n+      return completableFuture;\n+    }\n+\n+    /*\n+     * will update this hack version once NamedBlobDb is in.\n+     */\n+    private CompletableFuture<String> put(String accountName, String containerName, String blobName, StoreKey blobId) {\n+      CompletableFuture<String> completableFuture = new CompletableFuture<>();\n+      completableFuture.complete(blobId.getID());\n+      return completableFuture;\n+    }\n+\n+    /**\n+     * Parse the input if it's the named blob request.\n+     * @param input the url that needs to be parsed.\n+     * @return the String array contains the\n+     */\n+    String[] parseInput(String input) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46b79ff017bcaa19aeae785e2bfbc5b627d75c58"}, "originalPosition": 186}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzNDM5OA==", "bodyText": "Moved this method to RestUtil.", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r526534398", "createdAt": "2020-11-19T01:35:31Z", "author": {"login": "SophieGuo410"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AmbryIdConverterFactory.java", "diffHunk": "@@ -73,30 +86,126 @@ public void close() {\n      */\n     @Override\n     public Future<String> convert(RestRequest restRequest, String input, Callback<String> callback) {\n-      FutureResult<String> futureResult = new FutureResult<String>();\n+      final CompletableFuture<String> future = new CompletableFuture<>();\n       String convertedId = null;\n       Exception exception = null;\n       frontendMetrics.idConverterRequestRate.mark();\n       long startTimeInMs = System.currentTimeMillis();\n-      if (!isOpen) {\n+      try {\n+        if (!isOpen) {\n+        frontendMetrics.idConverterProcessingTimeInMs.update(System.currentTimeMillis() - startTimeInMs);\n         exception = new RestServiceException(\"IdConverter is closed\", RestServiceErrorCode.ServiceUnavailable);\n-      } else {\n-        try {\n-          if (restRequest.getRestMethod().equals(RestMethod.POST)) {\n+        } else if (restRequest.getRestMethod().equals(RestMethod.POST)) {\n             convertedId = \"/\" + signIdIfRequired(restRequest, input);\n-          } else {\n-            convertedId = parseSignedIdIfRequired(restRequest, input.startsWith(\"/\") ? input.substring(1) : input);\n-          }\n-        } catch (Exception e) {\n+        } else {\n+            frontendMetrics.idConverterProcessingTimeInMs.update(System.currentTimeMillis() - startTimeInMs);\n+            convertId(input, restRequest).whenComplete(\n+                (id, throwable) -> completeConversion(id, extractCompletionExceptionCause(throwable), future, callback));\n+        }\n+      } catch (Exception e) {\n           exception = e;\n+      } finally {\n+        frontendMetrics.idConverterProcessingTimeInMs.update(System.currentTimeMillis() - startTimeInMs);\n+        if (convertedId != null || exception != null) {\n+          completeConversion(convertedId, exception, future, callback);\n         }\n       }\n-      futureResult.done(convertedId, exception);\n+      return future;\n+    }\n+\n+    /**\n+     * @param throwable a throwable to possibly wrap in an exception.\n+     * @return if the {@link Throwable} is an instance of {@link Exception}, return the throwable, otherwise return the\n+     *         throwable wrapped in an exception.\n+     */\n+    private static Exception extractCompletionExceptionCause(Throwable throwable) {\n+      if (throwable == null) {\n+        return null;\n+      }\n+      if (throwable instanceof CompletionException) {\n+        throwable = throwable.getCause();\n+      }\n+      return throwable instanceof Exception ? (Exception) throwable : new Exception(\"Encountered throwable\", throwable);\n+    }\n+\n+    /**\n+     * Completes the conversion by setting the future and invoking the callback.\n+     * @param conversionResult the conversion result.\n+     * @param exception any exception that occurred as a part of the conversion.\n+     * @param completableFuture the {@link CompletableFuture} that must be set.\n+     * @param callback the {@link Callback} that needs to be invoked. Can be null.\n+     */\n+    private <T> void completeConversion(T conversionResult, Exception exception, CompletableFuture<T> completableFuture,\n+        Callback<T> callback) {\n+      if (exception == null) {\n+        completableFuture.complete(conversionResult);\n+      } else {\n+        completableFuture.completeExceptionally(exception);\n+      }\n       if (callback != null) {\n-        callback.onCompletion(convertedId, exception);\n+        long startTime = System.currentTimeMillis();\n+        callback.onCompletion(conversionResult, exception);\n+        frontendMetrics.idConversionDownstreamCallbackTimeInMs.update(System.currentTimeMillis() - startTime);\n+      }\n+    }\n+\n+    /**\n+     * Convert the input ID to the requested output. If it's the named blob request, return the blobId from NameBlobDb,\n+     * otherwise return the input with leading slash and extension be stripped.\n+     * @param input the input blob ID.\n+     * @param restRequest the {@link RestRequest} to set arguments in.\n+     * @return the {@link CompletionStage} that will be completed with the converted ID\n+     * @throws RestServiceException\n+     */\n+    private CompletionStage<String> convertId(String input, RestRequest restRequest)\n+        throws RestServiceException, IOException {\n+      CompletionStage<String> conversionFuture;\n+      if (input.startsWith(NAMED_BLOB_PREFIX)) {\n+        String[] slashFields = parseInput(input);\n+        //will update this hack version once NamedBlobDb is in.\n+        conversionFuture = get(slashFields[2], slashFields[3], slashFields[4]);\n+      } else if (restRequest.getRestMethod().equals(RestMethod.PUT) && restRequest.getUri().startsWith(NAMED_BLOB_PREFIX)) {\n+        String[] slashFields = parseInput(restRequest.getPath());\n+        StoreKey blobId = new BlobId(RestUtils.stripSlashAndExtensionFromId(input), clusterMap);\n+        conversionFuture = put(slashFields[2], slashFields[3], slashFields[4], blobId);\n+      } else {\n+        String decryptedInput = parseSignedIdIfRequired(restRequest, input.startsWith(\"/\") ? input.substring(1) : input);\n+        conversionFuture = CompletableFuture.completedFuture(RestUtils.stripSlashAndExtensionFromId(decryptedInput));\n+      }\n+      return conversionFuture;\n+    }\n+\n+    /*\n+     * will update this hack version once NamedBlobDb is in.\n+     */\n+    private CompletableFuture<String> get(String accountName, String containerName, String blobName) {\n+      CompletableFuture<String> completableFuture = new CompletableFuture<>();\n+      completableFuture.complete(accountName + containerName + blobName);\n+      return completableFuture;\n+    }\n+\n+    /*\n+     * will update this hack version once NamedBlobDb is in.\n+     */\n+    private CompletableFuture<String> put(String accountName, String containerName, String blobName, StoreKey blobId) {\n+      CompletableFuture<String> completableFuture = new CompletableFuture<>();\n+      completableFuture.complete(blobId.getID());\n+      return completableFuture;\n+    }\n+\n+    /**\n+     * Parse the input if it's the named blob request.\n+     * @param input the url that needs to be parsed.\n+     * @return the String array contains the\n+     */\n+    String[] parseInput(String input) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwMjkzMg=="}, "originalCommit": {"oid": "46b79ff017bcaa19aeae785e2bfbc5b627d75c58"}, "originalPosition": 186}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI4ODU2OTYwOnYy", "diffSide": "RIGHT", "path": "ambry-api/src/main/java/com/github/ambry/config/FrontendConfig.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNlQxODozMzo1OVrOH0MIlA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMToxMToxMFrOH2IomQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQ4NjgwNA==", "bodyText": "post to put in the string above. I recommend making a constant for this (see URL_SIGNER_ENDPOINTS).", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r524486804", "createdAt": "2020-11-16T18:33:59Z", "author": {"login": "cgtz"}, "path": "ambry-api/src/main/java/com/github/ambry/config/FrontendConfig.java", "diffHunk": "@@ -133,6 +133,14 @@\n   @Default(\"true\")\n   public final boolean allowServiceIdBasedPostRequest;\n \n+  /**\n+   * Boolean indicator to specify if frontend should allow the post requests that carry serviceId used as target\n+   * account name.\n+   */\n+  @Config(\"frontend.allow.service.id.based.post.request\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUyNjYxNw==", "bodyText": "Removed this config.", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r526526617", "createdAt": "2020-11-19T01:11:10Z", "author": {"login": "SophieGuo410"}, "path": "ambry-api/src/main/java/com/github/ambry/config/FrontendConfig.java", "diffHunk": "@@ -133,6 +133,14 @@\n   @Default(\"true\")\n   public final boolean allowServiceIdBasedPostRequest;\n \n+  /**\n+   * Boolean indicator to specify if frontend should allow the post requests that carry serviceId used as target\n+   * account name.\n+   */\n+  @Config(\"frontend.allow.service.id.based.post.request\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQ4NjgwNA=="}, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 8}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI4ODU3NzA1OnYy", "diffSide": "RIGHT", "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AccountAndContainerInjector.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNlQxODozNjowN1rOH0MNTQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMToxMjowMFrOH2Ipug==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQ4ODAxMw==", "bodyText": "I'm thinking that this config and code block isn't really needed. For named blobs, a PUT request without the account and container in the path will always be invalid anyways (i.e. it will fail somewhere else in the code).", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r524488013", "createdAt": "2020-11-16T18:36:07Z", "author": {"login": "cgtz"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AccountAndContainerInjector.java", "diffHunk": "@@ -84,6 +85,48 @@ public void injectAccountAndContainerForPostRequest(RestRequest restRequest, Res\n     }\n   }\n \n+  /**\n+   * Injects target {@link Account} and {@link Container} for PUT requests. This method also ensures required uri\n+   * is present for the PUT requests that can account name/container name can parse from.\n+   * @param restRequest The Put {@link RestRequest}.\n+   * @param metricsGroup The {@link RestRequestMetricsGroup} to use to set up {@link ContainerMetrics}, or {@code null}\n+   *                     if {@link ContainerMetrics} instantiation is not needed.\n+   * @throws RestServiceException\n+   */\n+  public void injectAccountAndContainerForPutRequest(RestRequest restRequest, RestRequestMetricsGroup metricsGroup)\n+      throws RestServiceException {\n+    accountAndContainerSanityCheckForNamedBlob(restRequest);\n+    if (restRequest.getUri() != null) {\n+      frontendMetrics.putWithAccountAndContainerHeaderRate.mark();\n+      injectAccountAndContainerUsingAccountAndContainerUri(restRequest, metricsGroup);\n+    } else if (frontendConfig.allowServiceIdBasedPutRequest) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUyNjkwNg==", "bodyText": "You are right, removed this config and related logic.", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r526526906", "createdAt": "2020-11-19T01:12:00Z", "author": {"login": "SophieGuo410"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AccountAndContainerInjector.java", "diffHunk": "@@ -84,6 +85,48 @@ public void injectAccountAndContainerForPostRequest(RestRequest restRequest, Res\n     }\n   }\n \n+  /**\n+   * Injects target {@link Account} and {@link Container} for PUT requests. This method also ensures required uri\n+   * is present for the PUT requests that can account name/container name can parse from.\n+   * @param restRequest The Put {@link RestRequest}.\n+   * @param metricsGroup The {@link RestRequestMetricsGroup} to use to set up {@link ContainerMetrics}, or {@code null}\n+   *                     if {@link ContainerMetrics} instantiation is not needed.\n+   * @throws RestServiceException\n+   */\n+  public void injectAccountAndContainerForPutRequest(RestRequest restRequest, RestRequestMetricsGroup metricsGroup)\n+      throws RestServiceException {\n+    accountAndContainerSanityCheckForNamedBlob(restRequest);\n+    if (restRequest.getUri() != null) {\n+      frontendMetrics.putWithAccountAndContainerHeaderRate.mark();\n+      injectAccountAndContainerUsingAccountAndContainerUri(restRequest, metricsGroup);\n+    } else if (frontendConfig.allowServiceIdBasedPutRequest) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQ4ODAxMw=="}, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI4ODU4NDY1OnYy", "diffSide": "RIGHT", "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AccountAndContainerInjector.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNlQxODozODoxMlrOH0MSOw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMToxMjoyMFrOH2IqNA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQ4OTI3NQ==", "bodyText": "It seems like we will have to do this in a few places throughout open source and LI code. Can we make this into a public method in RestUtils? This can return a small class like and handle URL decoding in one place:\nclass NamedBlobPath {\n  String getAccountName();\n  String getContainerName();\n  String getBlobName();\n}", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r524489275", "createdAt": "2020-11-16T18:38:12Z", "author": {"login": "cgtz"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AccountAndContainerInjector.java", "diffHunk": "@@ -84,6 +85,48 @@ public void injectAccountAndContainerForPostRequest(RestRequest restRequest, Res\n     }\n   }\n \n+  /**\n+   * Injects target {@link Account} and {@link Container} for PUT requests. This method also ensures required uri\n+   * is present for the PUT requests that can account name/container name can parse from.\n+   * @param restRequest The Put {@link RestRequest}.\n+   * @param metricsGroup The {@link RestRequestMetricsGroup} to use to set up {@link ContainerMetrics}, or {@code null}\n+   *                     if {@link ContainerMetrics} instantiation is not needed.\n+   * @throws RestServiceException\n+   */\n+  public void injectAccountAndContainerForPutRequest(RestRequest restRequest, RestRequestMetricsGroup metricsGroup)\n+      throws RestServiceException {\n+    accountAndContainerSanityCheckForNamedBlob(restRequest);\n+    if (restRequest.getUri() != null) {\n+      frontendMetrics.putWithAccountAndContainerHeaderRate.mark();\n+      injectAccountAndContainerUsingAccountAndContainerUri(restRequest, metricsGroup);\n+    } else if (frontendConfig.allowServiceIdBasedPutRequest) {\n+      ensureRequiredHeadersOrThrow(restRequest, requiredAmbryHeadersForPutWithServiceId);\n+      frontendMetrics.putWithServiceIdForAccountNameRate.mark();\n+      String serviceId = getHeader(restRequest.getArgs(), Headers.SERVICE_ID, true);\n+      boolean isPrivate = isPrivate(restRequest.getArgs());\n+      injectAccountAndContainerUsingServiceId(restRequest, serviceId, isPrivate, metricsGroup);\n+    } else {\n+      throw new RestServiceException(\n+          \"Missing either \" + Headers.TARGET_ACCOUNT_NAME + \" or \" + Headers.TARGET_CONTAINER_NAME + \" header\",\n+          RestServiceErrorCode.BadRequest);\n+    }\n+  }\n+\n+  /**\n+   * Parse the input if it's the named blob request.\n+   * @param input the url that needs to be parsed.\n+   * @return the String array contains the\n+   */\n+  private String[] parseInput(String input) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUyNzAyOA==", "bodyText": "That's a great idea. Updated it.", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r526527028", "createdAt": "2020-11-19T01:12:20Z", "author": {"login": "SophieGuo410"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AccountAndContainerInjector.java", "diffHunk": "@@ -84,6 +85,48 @@ public void injectAccountAndContainerForPostRequest(RestRequest restRequest, Res\n     }\n   }\n \n+  /**\n+   * Injects target {@link Account} and {@link Container} for PUT requests. This method also ensures required uri\n+   * is present for the PUT requests that can account name/container name can parse from.\n+   * @param restRequest The Put {@link RestRequest}.\n+   * @param metricsGroup The {@link RestRequestMetricsGroup} to use to set up {@link ContainerMetrics}, or {@code null}\n+   *                     if {@link ContainerMetrics} instantiation is not needed.\n+   * @throws RestServiceException\n+   */\n+  public void injectAccountAndContainerForPutRequest(RestRequest restRequest, RestRequestMetricsGroup metricsGroup)\n+      throws RestServiceException {\n+    accountAndContainerSanityCheckForNamedBlob(restRequest);\n+    if (restRequest.getUri() != null) {\n+      frontendMetrics.putWithAccountAndContainerHeaderRate.mark();\n+      injectAccountAndContainerUsingAccountAndContainerUri(restRequest, metricsGroup);\n+    } else if (frontendConfig.allowServiceIdBasedPutRequest) {\n+      ensureRequiredHeadersOrThrow(restRequest, requiredAmbryHeadersForPutWithServiceId);\n+      frontendMetrics.putWithServiceIdForAccountNameRate.mark();\n+      String serviceId = getHeader(restRequest.getArgs(), Headers.SERVICE_ID, true);\n+      boolean isPrivate = isPrivate(restRequest.getArgs());\n+      injectAccountAndContainerUsingServiceId(restRequest, serviceId, isPrivate, metricsGroup);\n+    } else {\n+      throw new RestServiceException(\n+          \"Missing either \" + Headers.TARGET_ACCOUNT_NAME + \" or \" + Headers.TARGET_CONTAINER_NAME + \" header\",\n+          RestServiceErrorCode.BadRequest);\n+    }\n+  }\n+\n+  /**\n+   * Parse the input if it's the named blob request.\n+   * @param input the url that needs to be parsed.\n+   * @return the String array contains the\n+   */\n+  private String[] parseInput(String input) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQ4OTI3NQ=="}, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 44}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI4ODYxOTkzOnYy", "diffSide": "RIGHT", "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AccountAndContainerInjector.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNlQxODo0NzowMFrOH0Mnlg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMToxMjo0NFrOH2IqqA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQ5NDc0Mg==", "bodyText": "It is better to use RestUtils.getRequestPath(restRequest).getOperationOrBlobId in situations like this to ensure that any cluster name url prefixes are removed.", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r524494742", "createdAt": "2020-11-16T18:47:00Z", "author": {"login": "cgtz"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AccountAndContainerInjector.java", "diffHunk": "@@ -209,6 +252,35 @@ private void injectAccountAndContainerUsingAccountAndContainerHeaders(RestReques\n     setTargetAccountAndContainerInRestRequest(restRequest, targetAccount, targetContainer, metricsGroup);\n   }\n \n+  /**\n+   * Injects {@link Account} and {@link Container} for the PUT requests that carry the target account and container headers.\n+   * @param restRequest The {@link RestRequest} to inject {@link Account} and {@link Container} object.\n+   * @param metricsGroup The {@link RestRequestMetricsGroup} to use to set up {@link ContainerMetrics}, or {@code null}\n+   *                     if {@link ContainerMetrics} instantiation is not needed.\n+   * @throws RestServiceException if either of {@link Account} or {@link Container} object could not be found.\n+   */\n+  private void injectAccountAndContainerUsingAccountAndContainerUri(RestRequest restRequest,\n+      RestRequestMetricsGroup metricsGroup) throws RestServiceException {\n+    String[] slashFields = parseInput(restRequest.getPath());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUyNzE0NA==", "bodyText": "Updated it in both close source and open source side.", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r526527144", "createdAt": "2020-11-19T01:12:44Z", "author": {"login": "SophieGuo410"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AccountAndContainerInjector.java", "diffHunk": "@@ -209,6 +252,35 @@ private void injectAccountAndContainerUsingAccountAndContainerHeaders(RestReques\n     setTargetAccountAndContainerInRestRequest(restRequest, targetAccount, targetContainer, metricsGroup);\n   }\n \n+  /**\n+   * Injects {@link Account} and {@link Container} for the PUT requests that carry the target account and container headers.\n+   * @param restRequest The {@link RestRequest} to inject {@link Account} and {@link Container} object.\n+   * @param metricsGroup The {@link RestRequestMetricsGroup} to use to set up {@link ContainerMetrics}, or {@code null}\n+   *                     if {@link ContainerMetrics} instantiation is not needed.\n+   * @throws RestServiceException if either of {@link Account} or {@link Container} object could not be found.\n+   */\n+  private void injectAccountAndContainerUsingAccountAndContainerUri(RestRequest restRequest,\n+      RestRequestMetricsGroup metricsGroup) throws RestServiceException {\n+    String[] slashFields = parseInput(restRequest.getPath());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQ5NDc0Mg=="}, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 70}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI4ODYyMzQ0OnYy", "diffSide": "RIGHT", "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AccountAndContainerInjector.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNlQxODo0Nzo1MVrOH0Mpng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMToxMzoxN1rOH2IrVg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQ5NTI2Mg==", "bodyText": "Is line 266-281 common logic that can be shared with the post request code?", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r524495262", "createdAt": "2020-11-16T18:47:51Z", "author": {"login": "cgtz"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AccountAndContainerInjector.java", "diffHunk": "@@ -209,6 +252,35 @@ private void injectAccountAndContainerUsingAccountAndContainerHeaders(RestReques\n     setTargetAccountAndContainerInRestRequest(restRequest, targetAccount, targetContainer, metricsGroup);\n   }\n \n+  /**\n+   * Injects {@link Account} and {@link Container} for the PUT requests that carry the target account and container headers.\n+   * @param restRequest The {@link RestRequest} to inject {@link Account} and {@link Container} object.\n+   * @param metricsGroup The {@link RestRequestMetricsGroup} to use to set up {@link ContainerMetrics}, or {@code null}\n+   *                     if {@link ContainerMetrics} instantiation is not needed.\n+   * @throws RestServiceException if either of {@link Account} or {@link Container} object could not be found.\n+   */\n+  private void injectAccountAndContainerUsingAccountAndContainerUri(RestRequest restRequest,\n+      RestRequestMetricsGroup metricsGroup) throws RestServiceException {\n+    String[] slashFields = parseInput(restRequest.getPath());\n+    String accountName = slashFields[2];\n+    Account targetAccount = accountService.getAccountByName(accountName);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUyNzMxOA==", "bodyText": "Updated it.", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r526527318", "createdAt": "2020-11-19T01:13:17Z", "author": {"login": "SophieGuo410"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AccountAndContainerInjector.java", "diffHunk": "@@ -209,6 +252,35 @@ private void injectAccountAndContainerUsingAccountAndContainerHeaders(RestReques\n     setTargetAccountAndContainerInRestRequest(restRequest, targetAccount, targetContainer, metricsGroup);\n   }\n \n+  /**\n+   * Injects {@link Account} and {@link Container} for the PUT requests that carry the target account and container headers.\n+   * @param restRequest The {@link RestRequest} to inject {@link Account} and {@link Container} object.\n+   * @param metricsGroup The {@link RestRequestMetricsGroup} to use to set up {@link ContainerMetrics}, or {@code null}\n+   *                     if {@link ContainerMetrics} instantiation is not needed.\n+   * @throws RestServiceException if either of {@link Account} or {@link Container} object could not be found.\n+   */\n+  private void injectAccountAndContainerUsingAccountAndContainerUri(RestRequest restRequest,\n+      RestRequestMetricsGroup metricsGroup) throws RestServiceException {\n+    String[] slashFields = parseInput(restRequest.getPath());\n+    String accountName = slashFields[2];\n+    Account targetAccount = accountService.getAccountByName(accountName);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQ5NTI2Mg=="}, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 72}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI4ODYzNTAxOnYy", "diffSide": "RIGHT", "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AccountAndContainerInjector.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNlQxODo1MDozNFrOH0MwMQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNlQxODo1MDozNFrOH0MwMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQ5Njk0NQ==", "bodyText": "I'm a bit confused about what this line is doing. Shouldn't the comparison be directly between UNKNOWN_ACCOUNT_NAME and slashFields[2] instead of looking for a header with that account name?", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r524496945", "createdAt": "2020-11-16T18:50:34Z", "author": {"login": "cgtz"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AccountAndContainerInjector.java", "diffHunk": "@@ -233,6 +305,35 @@ private void accountAndContainerSanityCheck(RestRequest restRequest) throws Rest\n     }\n   }\n \n+  /**\n+   * Sanity check for {@link RestRequest}. This check ensures that the specified service id, account and container name,\n+   * if they exist, should not be the same as the not-allowed values. It also makes sure certain headers must not be present.\n+   * @param restRequest The {@link RestRequest} to check.\n+   * @throws RestServiceException if the specified service id, account or container name is set as system reserved value.\n+   */\n+  private void accountAndContainerSanityCheckForNamedBlob(RestRequest restRequest) throws RestServiceException {\n+    String[] slashFields = parseInput(restRequest.getPath());\n+    if (Account.UNKNOWN_ACCOUNT_NAME.equals(getHeader(restRequest.getArgs(), slashFields[2], false))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 105}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI4ODY0MjMxOnYy", "diffSide": "RIGHT", "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AmbryIdConverterFactory.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNlQxODo1Mjo0NFrOH0M0ww==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMToxMzo1NVrOH2IsFg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQ5ODExNQ==", "bodyText": "Apologies for not communicating this, but I changed the interface for NamedBlobDb to not require a BlobId object. (it can just take in the base64 string). This means that you don't have to pass in the clustermap to IdConverter", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r524498115", "createdAt": "2020-11-16T18:52:44Z", "author": {"login": "cgtz"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AmbryIdConverterFactory.java", "diffHunk": "@@ -73,30 +85,126 @@ public void close() {\n      */\n     @Override\n     public Future<String> convert(RestRequest restRequest, String input, Callback<String> callback) {\n-      FutureResult<String> futureResult = new FutureResult<String>();\n+      final CompletableFuture<String> future = new CompletableFuture<>();\n       String convertedId = null;\n       Exception exception = null;\n       frontendMetrics.idConverterRequestRate.mark();\n       long startTimeInMs = System.currentTimeMillis();\n-      if (!isOpen) {\n+      try {\n+        if (!isOpen) {\n+        frontendMetrics.idConverterProcessingTimeInMs.update(System.currentTimeMillis() - startTimeInMs);\n         exception = new RestServiceException(\"IdConverter is closed\", RestServiceErrorCode.ServiceUnavailable);\n-      } else {\n-        try {\n-          if (restRequest.getRestMethod().equals(RestMethod.POST)) {\n+        } else if (restRequest.getRestMethod().equals(RestMethod.POST)) {\n             convertedId = \"/\" + signIdIfRequired(restRequest, input);\n-          } else {\n-            convertedId = parseSignedIdIfRequired(restRequest, input.startsWith(\"/\") ? input.substring(1) : input);\n-          }\n-        } catch (Exception e) {\n+        } else {\n+            frontendMetrics.idConverterProcessingTimeInMs.update(System.currentTimeMillis() - startTimeInMs);\n+            convertId(input, restRequest).whenComplete(\n+                (id, throwable) -> completeConversion(id, extractCompletionExceptionCause(throwable), future, callback));\n+        }\n+      } catch (Exception e) {\n           exception = e;\n+      } finally {\n+        frontendMetrics.idConverterProcessingTimeInMs.update(System.currentTimeMillis() - startTimeInMs);\n+        if (convertedId != null || exception != null) {\n+          completeConversion(convertedId, exception, future, callback);\n         }\n       }\n-      futureResult.done(convertedId, exception);\n+      return future;\n+    }\n+\n+    /**\n+     * @param throwable a throwable to possibly wrap in an exception.\n+     * @return if the {@link Throwable} is an instance of {@link Exception}, return the throwable, otherwise return the\n+     *         throwable wrapped in an exception.\n+     */\n+    private static Exception extractCompletionExceptionCause(Throwable throwable) {\n+      if (throwable == null) {\n+        return null;\n+      }\n+      if (throwable instanceof CompletionException) {\n+        throwable = throwable.getCause();\n+      }\n+      return throwable instanceof Exception ? (Exception) throwable : new Exception(\"Encountered throwable\", throwable);\n+    }\n+\n+    /**\n+     * Completes the conversion by setting the future and invoking the callback.\n+     * @param conversionResult the conversion result.\n+     * @param exception any exception that occurred as a part of the conversion.\n+     * @param completableFuture the {@link CompletableFuture} that must be set.\n+     * @param callback the {@link Callback} that needs to be invoked. Can be null.\n+     */\n+    private <T> void completeConversion(T conversionResult, Exception exception, CompletableFuture<T> completableFuture,\n+        Callback<T> callback) {\n+      if (exception == null) {\n+        completableFuture.complete(conversionResult);\n+      } else {\n+        completableFuture.completeExceptionally(exception);\n+      }\n       if (callback != null) {\n-        callback.onCompletion(convertedId, exception);\n+        long startTime = System.currentTimeMillis();\n+        callback.onCompletion(conversionResult, exception);\n+        frontendMetrics.idConversionDownstreamCallbackTimeInMs.update(System.currentTimeMillis() - startTime);\n+      }\n+    }\n+\n+    /**\n+     * Convert the input ID to the requested output. If it's the named blob request, return the blobId from NameBlobDb,\n+     * otherwise return the input with leading slash and extension be stripped.\n+     * @param input the input blob ID.\n+     * @param restRequest the {@link RestRequest} to set arguments in.\n+     * @return the {@link CompletionStage} that will be completed with the converted ID\n+     * @throws RestServiceException\n+     */\n+    private CompletionStage<String> convertId(String input, RestRequest restRequest)\n+        throws RestServiceException, IOException {\n+      CompletionStage<String> conversionFuture;\n+      if (input.startsWith(NAMED_BLOB_PREFIX)) {\n+        String[] slashFields = parseInput(input);\n+        //will update this hack version once NamedBlobDb is in.\n+        conversionFuture = get(slashFields[2], slashFields[3], slashFields[4]);\n+      } else if (restRequest.getRestMethod().equals(RestMethod.PUT) && restRequest.getUri().startsWith(NAMED_BLOB_PREFIX)) {\n+        String[] slashFields = parseInput(restRequest.getPath());\n+        StoreKey blobId = new BlobId(RestUtils.stripSlashAndExtensionFromId(input), clusterMap);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 155}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUyNzUxMA==", "bodyText": "That's nice. Updated it which only provide the String of blobId.", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r526527510", "createdAt": "2020-11-19T01:13:55Z", "author": {"login": "SophieGuo410"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/AmbryIdConverterFactory.java", "diffHunk": "@@ -73,30 +85,126 @@ public void close() {\n      */\n     @Override\n     public Future<String> convert(RestRequest restRequest, String input, Callback<String> callback) {\n-      FutureResult<String> futureResult = new FutureResult<String>();\n+      final CompletableFuture<String> future = new CompletableFuture<>();\n       String convertedId = null;\n       Exception exception = null;\n       frontendMetrics.idConverterRequestRate.mark();\n       long startTimeInMs = System.currentTimeMillis();\n-      if (!isOpen) {\n+      try {\n+        if (!isOpen) {\n+        frontendMetrics.idConverterProcessingTimeInMs.update(System.currentTimeMillis() - startTimeInMs);\n         exception = new RestServiceException(\"IdConverter is closed\", RestServiceErrorCode.ServiceUnavailable);\n-      } else {\n-        try {\n-          if (restRequest.getRestMethod().equals(RestMethod.POST)) {\n+        } else if (restRequest.getRestMethod().equals(RestMethod.POST)) {\n             convertedId = \"/\" + signIdIfRequired(restRequest, input);\n-          } else {\n-            convertedId = parseSignedIdIfRequired(restRequest, input.startsWith(\"/\") ? input.substring(1) : input);\n-          }\n-        } catch (Exception e) {\n+        } else {\n+            frontendMetrics.idConverterProcessingTimeInMs.update(System.currentTimeMillis() - startTimeInMs);\n+            convertId(input, restRequest).whenComplete(\n+                (id, throwable) -> completeConversion(id, extractCompletionExceptionCause(throwable), future, callback));\n+        }\n+      } catch (Exception e) {\n           exception = e;\n+      } finally {\n+        frontendMetrics.idConverterProcessingTimeInMs.update(System.currentTimeMillis() - startTimeInMs);\n+        if (convertedId != null || exception != null) {\n+          completeConversion(convertedId, exception, future, callback);\n         }\n       }\n-      futureResult.done(convertedId, exception);\n+      return future;\n+    }\n+\n+    /**\n+     * @param throwable a throwable to possibly wrap in an exception.\n+     * @return if the {@link Throwable} is an instance of {@link Exception}, return the throwable, otherwise return the\n+     *         throwable wrapped in an exception.\n+     */\n+    private static Exception extractCompletionExceptionCause(Throwable throwable) {\n+      if (throwable == null) {\n+        return null;\n+      }\n+      if (throwable instanceof CompletionException) {\n+        throwable = throwable.getCause();\n+      }\n+      return throwable instanceof Exception ? (Exception) throwable : new Exception(\"Encountered throwable\", throwable);\n+    }\n+\n+    /**\n+     * Completes the conversion by setting the future and invoking the callback.\n+     * @param conversionResult the conversion result.\n+     * @param exception any exception that occurred as a part of the conversion.\n+     * @param completableFuture the {@link CompletableFuture} that must be set.\n+     * @param callback the {@link Callback} that needs to be invoked. Can be null.\n+     */\n+    private <T> void completeConversion(T conversionResult, Exception exception, CompletableFuture<T> completableFuture,\n+        Callback<T> callback) {\n+      if (exception == null) {\n+        completableFuture.complete(conversionResult);\n+      } else {\n+        completableFuture.completeExceptionally(exception);\n+      }\n       if (callback != null) {\n-        callback.onCompletion(convertedId, exception);\n+        long startTime = System.currentTimeMillis();\n+        callback.onCompletion(conversionResult, exception);\n+        frontendMetrics.idConversionDownstreamCallbackTimeInMs.update(System.currentTimeMillis() - startTime);\n+      }\n+    }\n+\n+    /**\n+     * Convert the input ID to the requested output. If it's the named blob request, return the blobId from NameBlobDb,\n+     * otherwise return the input with leading slash and extension be stripped.\n+     * @param input the input blob ID.\n+     * @param restRequest the {@link RestRequest} to set arguments in.\n+     * @return the {@link CompletionStage} that will be completed with the converted ID\n+     * @throws RestServiceException\n+     */\n+    private CompletionStage<String> convertId(String input, RestRequest restRequest)\n+        throws RestServiceException, IOException {\n+      CompletionStage<String> conversionFuture;\n+      if (input.startsWith(NAMED_BLOB_PREFIX)) {\n+        String[] slashFields = parseInput(input);\n+        //will update this hack version once NamedBlobDb is in.\n+        conversionFuture = get(slashFields[2], slashFields[3], slashFields[4]);\n+      } else if (restRequest.getRestMethod().equals(RestMethod.PUT) && restRequest.getUri().startsWith(NAMED_BLOB_PREFIX)) {\n+        String[] slashFields = parseInput(restRequest.getPath());\n+        StoreKey blobId = new BlobId(RestUtils.stripSlashAndExtensionFromId(input), clusterMap);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQ5ODExNQ=="}, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 155}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI4ODY5ODk1OnYy", "diffSide": "RIGHT", "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/FrontendMetrics.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNlQxOTowNjo1N1rOH0NWZQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMToxNDo0MVrOH2ItGQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDUwNjcyNQ==", "bodyText": "is  this a duplicate of putSecurityProcessResponse?", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r524506725", "createdAt": "2020-11-16T19:06:57Z", "author": {"login": "cgtz"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/FrontendMetrics.java", "diffHunk": "@@ -269,6 +285,25 @@ public FrontendMetrics(MetricRegistry metricRegistry) {\n     undeleteBlobSecurityProcessResponseMetrics =\n         new AsyncOperationTracker.Metrics(UndeleteHandler.class, \"securityProcessResponse\", metricRegistry);\n \n+    putSecurityProcessRequestMetrics =\n+        new AsyncOperationTracker.Metrics(PutBlobHandler.class, \"putSecurityProcessRequest\", metricRegistry);\n+    putSecurityPostProcessRequestMetrics =\n+        new AsyncOperationTracker.Metrics(PutBlobHandler.class, \"putSecurityPostProcessRequest\", metricRegistry);\n+    putReadStitchRequestMetrics =\n+        new AsyncOperationTracker.Metrics(PutBlobHandler.class, \"putReadStitchRequest\", metricRegistry);\n+    putRouterStitchBlobMetrics =\n+        new AsyncOperationTracker.Metrics(PutBlobHandler.class, \"putRouterStitchBlob\", metricRegistry);\n+    putRouterPutBlobMetrics =\n+        new AsyncOperationTracker.Metrics(PutBlobHandler.class, \"putRouterPutBlob\", metricRegistry);\n+    putIdConversionMetrics =\n+        new AsyncOperationTracker.Metrics(PutBlobHandler.class, \"putIdConversion\", metricRegistry);\n+    putSecurityProcessResponseMetrics =\n+        new AsyncOperationTracker.Metrics(PutBlobHandler.class, \"putSecurityProcessResponse\", metricRegistry);\n+    putBlobRouterMetrics =\n+        new AsyncOperationTracker.Metrics(PutBlobHandler.class, \"router\", metricRegistry);\n+    putBlobSecurityProcessResponseMetrics =\n+        new AsyncOperationTracker.Metrics(PutBlobHandler.class, \"securityProcessResponse\", metricRegistry);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUyNzc2OQ==", "bodyText": "Thanks for catching that. Removed the duplicate one.", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r526527769", "createdAt": "2020-11-19T01:14:41Z", "author": {"login": "SophieGuo410"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/FrontendMetrics.java", "diffHunk": "@@ -269,6 +285,25 @@ public FrontendMetrics(MetricRegistry metricRegistry) {\n     undeleteBlobSecurityProcessResponseMetrics =\n         new AsyncOperationTracker.Metrics(UndeleteHandler.class, \"securityProcessResponse\", metricRegistry);\n \n+    putSecurityProcessRequestMetrics =\n+        new AsyncOperationTracker.Metrics(PutBlobHandler.class, \"putSecurityProcessRequest\", metricRegistry);\n+    putSecurityPostProcessRequestMetrics =\n+        new AsyncOperationTracker.Metrics(PutBlobHandler.class, \"putSecurityPostProcessRequest\", metricRegistry);\n+    putReadStitchRequestMetrics =\n+        new AsyncOperationTracker.Metrics(PutBlobHandler.class, \"putReadStitchRequest\", metricRegistry);\n+    putRouterStitchBlobMetrics =\n+        new AsyncOperationTracker.Metrics(PutBlobHandler.class, \"putRouterStitchBlob\", metricRegistry);\n+    putRouterPutBlobMetrics =\n+        new AsyncOperationTracker.Metrics(PutBlobHandler.class, \"putRouterPutBlob\", metricRegistry);\n+    putIdConversionMetrics =\n+        new AsyncOperationTracker.Metrics(PutBlobHandler.class, \"putIdConversion\", metricRegistry);\n+    putSecurityProcessResponseMetrics =\n+        new AsyncOperationTracker.Metrics(PutBlobHandler.class, \"putSecurityProcessResponse\", metricRegistry);\n+    putBlobRouterMetrics =\n+        new AsyncOperationTracker.Metrics(PutBlobHandler.class, \"router\", metricRegistry);\n+    putBlobSecurityProcessResponseMetrics =\n+        new AsyncOperationTracker.Metrics(PutBlobHandler.class, \"securityProcessResponse\", metricRegistry);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDUwNjcyNQ=="}, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 83}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI4ODc5NjA4OnYy", "diffSide": "RIGHT", "path": "ambry-api/src/main/java/com/github/ambry/rest/RestUtils.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNlQxOTozMzo0NlrOH0OR_A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMToxNTozNVrOH2IuXg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDUyMTk4MA==", "bodyText": "I think this comment should be changed to indicate that it is set to a string that indicates STITCH request vs regular upload", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r524521980", "createdAt": "2020-11-16T19:33:46Z", "author": {"login": "cgtz"}, "path": "ambry-api/src/main/java/com/github/ambry/rest/RestUtils.java", "diffHunk": "@@ -201,7 +201,10 @@\n      * stitched together.\n      */\n     public static final String CHUNK_UPLOAD = \"x-ambry-chunk-upload\";\n-\n+    /**\n+     *Boolean field set to \"true\" to indicate that this is an upload of a data chunk of a stitched upload(for named blob only).", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQ3MTA3Mg==", "bodyText": "I think the name should also be changed to be more specific.  I'd never have guessed what it apparently means.", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r525471072", "createdAt": "2020-11-17T20:04:52Z", "author": {"login": "lightningrob"}, "path": "ambry-api/src/main/java/com/github/ambry/rest/RestUtils.java", "diffHunk": "@@ -201,7 +201,10 @@\n      * stitched together.\n      */\n     public static final String CHUNK_UPLOAD = \"x-ambry-chunk-upload\";\n-\n+    /**\n+     *Boolean field set to \"true\" to indicate that this is an upload of a data chunk of a stitched upload(for named blob only).", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDUyMTk4MA=="}, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUyODA5NA==", "bodyText": "Changed the name to UPLOAD_NAMED_BLOB_MODE and updated the comments as well.", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r526528094", "createdAt": "2020-11-19T01:15:35Z", "author": {"login": "SophieGuo410"}, "path": "ambry-api/src/main/java/com/github/ambry/rest/RestUtils.java", "diffHunk": "@@ -201,7 +201,10 @@\n      * stitched together.\n      */\n     public static final String CHUNK_UPLOAD = \"x-ambry-chunk-upload\";\n-\n+    /**\n+     *Boolean field set to \"true\" to indicate that this is an upload of a data chunk of a stitched upload(for named blob only).", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDUyMTk4MA=="}, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI4ODc5NzQzOnYy", "diffSide": "RIGHT", "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/PutBlobHandler.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNlQxOTozNDoxNFrOH0OS8Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMToyMDo1NVrOH2I01w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDUyMjIyNQ==", "bodyText": "make a constant for \"STITCH\", or use an enum", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r524522225", "createdAt": "2020-11-16T19:34:14Z", "author": {"login": "cgtz"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/PutBlobHandler.java", "diffHunk": "@@ -0,0 +1,405 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.frontend;\n+\n+import com.github.ambry.account.Container;\n+import com.github.ambry.commons.BlobId;\n+import com.github.ambry.commons.Callback;\n+import com.github.ambry.commons.RetainingAsyncWritableChannel;\n+import com.github.ambry.config.FrontendConfig;\n+import com.github.ambry.messageformat.BlobInfo;\n+import com.github.ambry.messageformat.BlobProperties;\n+import com.github.ambry.rest.RequestPath;\n+import com.github.ambry.rest.RestRequest;\n+import com.github.ambry.rest.RestResponseChannel;\n+import com.github.ambry.rest.RestServiceErrorCode;\n+import com.github.ambry.rest.RestServiceException;\n+import com.github.ambry.rest.RestUtils;\n+import com.github.ambry.router.ChunkInfo;\n+import com.github.ambry.router.PutBlobOptions;\n+import com.github.ambry.router.PutBlobOptionsBuilder;\n+import com.github.ambry.router.Router;\n+import com.github.ambry.utils.Pair;\n+import com.github.ambry.utils.Time;\n+import com.github.ambry.utils.Utils;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.json.JSONObject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static com.github.ambry.frontend.FrontendUtils.*;\n+\n+\n+/**\n+ * Handler for put named blob requests. The following request types are handled by {@link PutBlobHandler}:\n+ * <h2>Direct uploads</h2>\n+ * Direct upload requests treat the body of the request as the content to upload to Ambry. The request path should be\n+ * \"/named/account_name/container_name/blob_name\". In these requests, the blob properties and user metadata are supplied as headers. See\n+ * {@link RestUtils#buildBlobProperties(Map)} and {@link RestUtils#buildBlobProperties(Map)} for more details.\n+ * <h2>Stitched uploads</h2>\n+ * Stitched upload requests allow clients to stitch together previously uploaded data chunks into a single logical blob.\n+ * The request path should be \"/named/account_name/container_name/blob_name\", This request accepts the same headers as direct\n+ * upload requests for supplying the blob properties and user metadata of the stitched blob, but, instead of the actual\n+ * blob content, accepts a UTF-8 JSON object that includes the signed IDs for the chunks to stitch, and header x-ambry-put-mode should set as \"STITCH\".\n+ * <h3>Request body format</h3>\n+ * The body of the request should be a JSON object that conforms to the format described in {@link StitchRequestSerDe}.\n+ */\n+public class PutBlobHandler {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(PutBlobHandler.class);\n+  /**\n+   * Key to represent the time at which a blob will expire in ms. Used within the metadata map in signed IDs.\n+   */\n+  static final String EXPIRATION_TIME_MS_KEY = \"et\";\n+\n+  private final SecurityService securityService;\n+  private final IdConverter idConverter;\n+  private final IdSigningService idSigningService;\n+  private final Router router;\n+  private final AccountAndContainerInjector accountAndContainerInjector;\n+  private final Time time;\n+  private final FrontendConfig frontendConfig;\n+  private final FrontendMetrics frontendMetrics;\n+  private final String clusterName;\n+\n+  /**\n+   * Constructs a handler for handling requests for uploading or stitching blobs.\n+   * @param securityService the {@link SecurityService} to use.\n+   * @param idConverter the {@link IdConverter} to use.\n+   * @param idSigningService the {@link IdSigningService} to use.\n+   * @param router the {@link Router} to use.\n+   * @param accountAndContainerInjector helper to resolve account and container for a given request.\n+   * @param time the {@link Time} instance to use.\n+   * @param frontendConfig the {@link FrontendConfig} to use.\n+   * @param frontendMetrics {@link FrontendMetrics} instance where metrics should be recorded.\n+   * @param clusterName the name of the storage cluster that the router communicates with\n+   */\n+  PutBlobHandler(SecurityService securityService, IdConverter idConverter, IdSigningService idSigningService,\n+      Router router, AccountAndContainerInjector accountAndContainerInjector, Time time, FrontendConfig frontendConfig,\n+      FrontendMetrics frontendMetrics, String clusterName) {\n+    this.securityService = securityService;\n+    this.idConverter = idConverter;\n+    this.idSigningService = idSigningService;\n+    this.router = router;\n+    this.accountAndContainerInjector = accountAndContainerInjector;\n+    this.time = time;\n+    this.frontendConfig = frontendConfig;\n+    this.frontendMetrics = frontendMetrics;\n+    this.clusterName = clusterName;\n+  }\n+\n+  /**\n+   * Handles a request for put a blob\n+   * @param restRequest the {@link RestRequest} that contains the request parameters.\n+   * @param restResponseChannel the {@link RestResponseChannel} where headers should be set.\n+   * @param callback the {@link Callback} to invoke when the response is ready (or if there is an exception).\n+   */\n+  void handle(RestRequest restRequest, RestResponseChannel restResponseChannel, Callback<Void> callback) {\n+    new PutBlobHandler.CallbackChain(restRequest, restResponseChannel, callback).start();\n+  }\n+\n+  /**\n+   * Represents the chain of actions to take. Keeps request context that is relevant to all callback stages.\n+   */\n+  private class CallbackChain {\n+    private final RestRequest restRequest;\n+    private final RestResponseChannel restResponseChannel;\n+    private final Callback<Void> finalCallback;\n+    private final String uri;\n+\n+    /**\n+     * @param restRequest the {@link RestRequest}.\n+     * @param restResponseChannel the {@link RestResponseChannel}.\n+     * @param finalCallback the {@link Callback} to call on completion.\n+     */\n+    private CallbackChain(RestRequest restRequest, RestResponseChannel restResponseChannel,\n+        Callback<Void> finalCallback) {\n+      this.restRequest = restRequest;\n+      this.restResponseChannel = restResponseChannel;\n+      this.finalCallback = finalCallback;\n+      this.uri = restRequest.getUri();\n+    }\n+\n+    /**\n+     * Start the chain by calling {@link SecurityService#processRequest}.\n+     */\n+    private void start() {\n+      restRequest.getMetricsTracker()\n+          .injectMetrics(frontendMetrics.putBlobMetricsGroup.getRestRequestMetrics(restRequest.isSslUsed(), false));\n+      //?restRequest.setArg(RestUtils.InternalKeys.KEEP_ALIVE_ON_ERROR_HINT, true);\n+      try {\n+        // Start the callback chain by parsing blob info headers and performing request security processing.\n+        BlobInfo blobInfo = getBlobInfoFromRequest();\n+        checkUploadRequirements(blobInfo.getBlobProperties());\n+        securityService.processRequest(restRequest, securityProcessRequestCallback(blobInfo));\n+      } catch (Exception e) {\n+        finalCallback.onCompletion(null, e);\n+      }\n+    }\n+\n+    /**\n+     * Parse {@link BlobInfo} from the request arguments. This method will also ensure that the correct account and\n+     * container objects are attached to the request.\n+     * @return the {@link BlobInfo} parsed from the request arguments.\n+     * @throws RestServiceException if there is an error while parsing the {@link BlobInfo} arguments.\n+     */\n+    private BlobInfo getBlobInfoFromRequest() throws RestServiceException {\n+      long propsBuildStartTime = System.currentTimeMillis();\n+      accountAndContainerInjector.injectAccountAndContainerForPutRequest(restRequest,\n+          frontendMetrics.putBlobMetricsGroup);\n+      BlobProperties blobProperties = RestUtils.buildBlobProperties(restRequest.getArgs());\n+      Container container = RestUtils.getContainerFromArgs(restRequest.getArgs());\n+      if (blobProperties.getTimeToLiveInSeconds() + TimeUnit.MILLISECONDS.toSeconds(\n+          blobProperties.getCreationTimeInMs()) > Integer.MAX_VALUE) {\n+        LOGGER.debug(\"TTL set to very large value in POST request with BlobProperties {}\", blobProperties);\n+        frontendMetrics.ttlTooLargeError.inc();\n+      } else if (container.isTtlRequired() && (blobProperties.getTimeToLiveInSeconds() == Utils.Infinite_Time\n+          || blobProperties.getTimeToLiveInSeconds() > frontendConfig.maxAcceptableTtlSecsIfTtlRequired)) {\n+        String descriptor = RestUtils.getAccountFromArgs(restRequest.getArgs()).getName() + \":\" + container.getName();\n+        if (frontendConfig.failIfTtlRequiredButNotProvided) {\n+          throw new RestServiceException(\n+              \"TTL < \" + frontendConfig.maxAcceptableTtlSecsIfTtlRequired + \" is required for upload to \" + descriptor,\n+              RestServiceErrorCode.InvalidArgs);\n+        } else {\n+          LOGGER.debug(\"{} attempted an upload with ttl {} to {}\", blobProperties.getServiceId(),\n+              blobProperties.getTimeToLiveInSeconds(), descriptor);\n+          frontendMetrics.ttlNotCompliantError.inc();\n+          restResponseChannel.setHeader(RestUtils.Headers.NON_COMPLIANCE_WARNING,\n+              \"TTL < \" + frontendConfig.maxAcceptableTtlSecsIfTtlRequired + \" will be required for future uploads\");\n+        }\n+      }\n+      // inject encryption frontendMetrics if applicable\n+      if (blobProperties.isEncrypted()) {\n+        restRequest.getMetricsTracker()\n+            .injectMetrics(frontendMetrics.postBlobMetricsGroup.getRestRequestMetrics(restRequest.isSslUsed(), true));\n+      }\n+      byte[] userMetadata = RestUtils.buildUserMetadata(restRequest.getArgs());\n+      frontendMetrics.blobPropsBuildTimeInMs.update(System.currentTimeMillis() - propsBuildStartTime);\n+      LOGGER.trace(\"Blob properties of blob being POSTed - {}\", blobProperties);\n+      return new BlobInfo(blobProperties, userMetadata);\n+    }\n+\n+    /**\n+     * Enforce any additional requirements for certain types of uploads like data chunk uploads.\n+     * @param blobProperties the {@link BlobProperties} parsed from the request.\n+     * @throws RestServiceException\n+     */\n+    private void checkUploadRequirements(BlobProperties blobProperties) throws RestServiceException {\n+      if (RestUtils.isChunkUpload(restRequest.getArgs())) {\n+        // ensure that the x-ambry-session header is present.\n+        RestUtils.getHeader(restRequest.getArgs(), RestUtils.Headers.SESSION, true);\n+        // validate that a max chunk size is set.\n+        RestUtils.getLongHeader(restRequest.getArgs(), RestUtils.Headers.MAX_UPLOAD_SIZE, true);\n+        // validate that the TTL for the chunk is set correctly.\n+        long chunkTtl = blobProperties.getTimeToLiveInSeconds();\n+        if (chunkTtl <= 0 || chunkTtl > frontendConfig.chunkUploadInitialChunkTtlSecs) {\n+          throw new RestServiceException(\"Invalid chunk upload TTL: \" + chunkTtl, RestServiceErrorCode.InvalidArgs);\n+        }\n+      }\n+    }\n+\n+    /**\n+     * After {@link SecurityService#processRequest} finishes, call {@link SecurityService#postProcessRequest} to perform\n+     * request time security checks that rely on the request being fully parsed and any additional arguments set.\n+     * @param blobInfo the {@link BlobInfo} to carry to future stages.\n+     * @return a {@link Callback} to be used with {@link SecurityService#processRequest}.\n+     */\n+    private Callback<Void> securityProcessRequestCallback(BlobInfo blobInfo) {\n+      return buildCallback(frontendMetrics.putSecurityProcessRequestMetrics,\n+          securityCheckResult -> securityService.postProcessRequest(restRequest,\n+              securityPostProcessRequestCallback(blobInfo)), uri, LOGGER, finalCallback);\n+    }\n+\n+    /**\n+     * After {@link SecurityService#postProcessRequest} finishes, call {@link Router#putBlob} to persist the blob in the\n+     * storage layer.\n+     * @param blobInfo the {@link BlobInfo} to make the router call with.\n+     * @return a {@link Callback} to be used with {@link SecurityService#postProcessRequest}.\n+     */\n+    private Callback<Void> securityPostProcessRequestCallback(BlobInfo blobInfo) {\n+      return buildCallback(frontendMetrics.postSecurityPostProcessRequestMetrics, securityCheckResult -> {\n+        if (\"STITCH\".equals(RestUtils.getHeader(restRequest.getArgs(), RestUtils.Headers.PUT_MODE, false))) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 236}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUyOTc1MQ==", "bodyText": "Change it to constant.", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r526529751", "createdAt": "2020-11-19T01:20:55Z", "author": {"login": "SophieGuo410"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/PutBlobHandler.java", "diffHunk": "@@ -0,0 +1,405 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.frontend;\n+\n+import com.github.ambry.account.Container;\n+import com.github.ambry.commons.BlobId;\n+import com.github.ambry.commons.Callback;\n+import com.github.ambry.commons.RetainingAsyncWritableChannel;\n+import com.github.ambry.config.FrontendConfig;\n+import com.github.ambry.messageformat.BlobInfo;\n+import com.github.ambry.messageformat.BlobProperties;\n+import com.github.ambry.rest.RequestPath;\n+import com.github.ambry.rest.RestRequest;\n+import com.github.ambry.rest.RestResponseChannel;\n+import com.github.ambry.rest.RestServiceErrorCode;\n+import com.github.ambry.rest.RestServiceException;\n+import com.github.ambry.rest.RestUtils;\n+import com.github.ambry.router.ChunkInfo;\n+import com.github.ambry.router.PutBlobOptions;\n+import com.github.ambry.router.PutBlobOptionsBuilder;\n+import com.github.ambry.router.Router;\n+import com.github.ambry.utils.Pair;\n+import com.github.ambry.utils.Time;\n+import com.github.ambry.utils.Utils;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.json.JSONObject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static com.github.ambry.frontend.FrontendUtils.*;\n+\n+\n+/**\n+ * Handler for put named blob requests. The following request types are handled by {@link PutBlobHandler}:\n+ * <h2>Direct uploads</h2>\n+ * Direct upload requests treat the body of the request as the content to upload to Ambry. The request path should be\n+ * \"/named/account_name/container_name/blob_name\". In these requests, the blob properties and user metadata are supplied as headers. See\n+ * {@link RestUtils#buildBlobProperties(Map)} and {@link RestUtils#buildBlobProperties(Map)} for more details.\n+ * <h2>Stitched uploads</h2>\n+ * Stitched upload requests allow clients to stitch together previously uploaded data chunks into a single logical blob.\n+ * The request path should be \"/named/account_name/container_name/blob_name\", This request accepts the same headers as direct\n+ * upload requests for supplying the blob properties and user metadata of the stitched blob, but, instead of the actual\n+ * blob content, accepts a UTF-8 JSON object that includes the signed IDs for the chunks to stitch, and header x-ambry-put-mode should set as \"STITCH\".\n+ * <h3>Request body format</h3>\n+ * The body of the request should be a JSON object that conforms to the format described in {@link StitchRequestSerDe}.\n+ */\n+public class PutBlobHandler {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(PutBlobHandler.class);\n+  /**\n+   * Key to represent the time at which a blob will expire in ms. Used within the metadata map in signed IDs.\n+   */\n+  static final String EXPIRATION_TIME_MS_KEY = \"et\";\n+\n+  private final SecurityService securityService;\n+  private final IdConverter idConverter;\n+  private final IdSigningService idSigningService;\n+  private final Router router;\n+  private final AccountAndContainerInjector accountAndContainerInjector;\n+  private final Time time;\n+  private final FrontendConfig frontendConfig;\n+  private final FrontendMetrics frontendMetrics;\n+  private final String clusterName;\n+\n+  /**\n+   * Constructs a handler for handling requests for uploading or stitching blobs.\n+   * @param securityService the {@link SecurityService} to use.\n+   * @param idConverter the {@link IdConverter} to use.\n+   * @param idSigningService the {@link IdSigningService} to use.\n+   * @param router the {@link Router} to use.\n+   * @param accountAndContainerInjector helper to resolve account and container for a given request.\n+   * @param time the {@link Time} instance to use.\n+   * @param frontendConfig the {@link FrontendConfig} to use.\n+   * @param frontendMetrics {@link FrontendMetrics} instance where metrics should be recorded.\n+   * @param clusterName the name of the storage cluster that the router communicates with\n+   */\n+  PutBlobHandler(SecurityService securityService, IdConverter idConverter, IdSigningService idSigningService,\n+      Router router, AccountAndContainerInjector accountAndContainerInjector, Time time, FrontendConfig frontendConfig,\n+      FrontendMetrics frontendMetrics, String clusterName) {\n+    this.securityService = securityService;\n+    this.idConverter = idConverter;\n+    this.idSigningService = idSigningService;\n+    this.router = router;\n+    this.accountAndContainerInjector = accountAndContainerInjector;\n+    this.time = time;\n+    this.frontendConfig = frontendConfig;\n+    this.frontendMetrics = frontendMetrics;\n+    this.clusterName = clusterName;\n+  }\n+\n+  /**\n+   * Handles a request for put a blob\n+   * @param restRequest the {@link RestRequest} that contains the request parameters.\n+   * @param restResponseChannel the {@link RestResponseChannel} where headers should be set.\n+   * @param callback the {@link Callback} to invoke when the response is ready (or if there is an exception).\n+   */\n+  void handle(RestRequest restRequest, RestResponseChannel restResponseChannel, Callback<Void> callback) {\n+    new PutBlobHandler.CallbackChain(restRequest, restResponseChannel, callback).start();\n+  }\n+\n+  /**\n+   * Represents the chain of actions to take. Keeps request context that is relevant to all callback stages.\n+   */\n+  private class CallbackChain {\n+    private final RestRequest restRequest;\n+    private final RestResponseChannel restResponseChannel;\n+    private final Callback<Void> finalCallback;\n+    private final String uri;\n+\n+    /**\n+     * @param restRequest the {@link RestRequest}.\n+     * @param restResponseChannel the {@link RestResponseChannel}.\n+     * @param finalCallback the {@link Callback} to call on completion.\n+     */\n+    private CallbackChain(RestRequest restRequest, RestResponseChannel restResponseChannel,\n+        Callback<Void> finalCallback) {\n+      this.restRequest = restRequest;\n+      this.restResponseChannel = restResponseChannel;\n+      this.finalCallback = finalCallback;\n+      this.uri = restRequest.getUri();\n+    }\n+\n+    /**\n+     * Start the chain by calling {@link SecurityService#processRequest}.\n+     */\n+    private void start() {\n+      restRequest.getMetricsTracker()\n+          .injectMetrics(frontendMetrics.putBlobMetricsGroup.getRestRequestMetrics(restRequest.isSslUsed(), false));\n+      //?restRequest.setArg(RestUtils.InternalKeys.KEEP_ALIVE_ON_ERROR_HINT, true);\n+      try {\n+        // Start the callback chain by parsing blob info headers and performing request security processing.\n+        BlobInfo blobInfo = getBlobInfoFromRequest();\n+        checkUploadRequirements(blobInfo.getBlobProperties());\n+        securityService.processRequest(restRequest, securityProcessRequestCallback(blobInfo));\n+      } catch (Exception e) {\n+        finalCallback.onCompletion(null, e);\n+      }\n+    }\n+\n+    /**\n+     * Parse {@link BlobInfo} from the request arguments. This method will also ensure that the correct account and\n+     * container objects are attached to the request.\n+     * @return the {@link BlobInfo} parsed from the request arguments.\n+     * @throws RestServiceException if there is an error while parsing the {@link BlobInfo} arguments.\n+     */\n+    private BlobInfo getBlobInfoFromRequest() throws RestServiceException {\n+      long propsBuildStartTime = System.currentTimeMillis();\n+      accountAndContainerInjector.injectAccountAndContainerForPutRequest(restRequest,\n+          frontendMetrics.putBlobMetricsGroup);\n+      BlobProperties blobProperties = RestUtils.buildBlobProperties(restRequest.getArgs());\n+      Container container = RestUtils.getContainerFromArgs(restRequest.getArgs());\n+      if (blobProperties.getTimeToLiveInSeconds() + TimeUnit.MILLISECONDS.toSeconds(\n+          blobProperties.getCreationTimeInMs()) > Integer.MAX_VALUE) {\n+        LOGGER.debug(\"TTL set to very large value in POST request with BlobProperties {}\", blobProperties);\n+        frontendMetrics.ttlTooLargeError.inc();\n+      } else if (container.isTtlRequired() && (blobProperties.getTimeToLiveInSeconds() == Utils.Infinite_Time\n+          || blobProperties.getTimeToLiveInSeconds() > frontendConfig.maxAcceptableTtlSecsIfTtlRequired)) {\n+        String descriptor = RestUtils.getAccountFromArgs(restRequest.getArgs()).getName() + \":\" + container.getName();\n+        if (frontendConfig.failIfTtlRequiredButNotProvided) {\n+          throw new RestServiceException(\n+              \"TTL < \" + frontendConfig.maxAcceptableTtlSecsIfTtlRequired + \" is required for upload to \" + descriptor,\n+              RestServiceErrorCode.InvalidArgs);\n+        } else {\n+          LOGGER.debug(\"{} attempted an upload with ttl {} to {}\", blobProperties.getServiceId(),\n+              blobProperties.getTimeToLiveInSeconds(), descriptor);\n+          frontendMetrics.ttlNotCompliantError.inc();\n+          restResponseChannel.setHeader(RestUtils.Headers.NON_COMPLIANCE_WARNING,\n+              \"TTL < \" + frontendConfig.maxAcceptableTtlSecsIfTtlRequired + \" will be required for future uploads\");\n+        }\n+      }\n+      // inject encryption frontendMetrics if applicable\n+      if (blobProperties.isEncrypted()) {\n+        restRequest.getMetricsTracker()\n+            .injectMetrics(frontendMetrics.postBlobMetricsGroup.getRestRequestMetrics(restRequest.isSslUsed(), true));\n+      }\n+      byte[] userMetadata = RestUtils.buildUserMetadata(restRequest.getArgs());\n+      frontendMetrics.blobPropsBuildTimeInMs.update(System.currentTimeMillis() - propsBuildStartTime);\n+      LOGGER.trace(\"Blob properties of blob being POSTed - {}\", blobProperties);\n+      return new BlobInfo(blobProperties, userMetadata);\n+    }\n+\n+    /**\n+     * Enforce any additional requirements for certain types of uploads like data chunk uploads.\n+     * @param blobProperties the {@link BlobProperties} parsed from the request.\n+     * @throws RestServiceException\n+     */\n+    private void checkUploadRequirements(BlobProperties blobProperties) throws RestServiceException {\n+      if (RestUtils.isChunkUpload(restRequest.getArgs())) {\n+        // ensure that the x-ambry-session header is present.\n+        RestUtils.getHeader(restRequest.getArgs(), RestUtils.Headers.SESSION, true);\n+        // validate that a max chunk size is set.\n+        RestUtils.getLongHeader(restRequest.getArgs(), RestUtils.Headers.MAX_UPLOAD_SIZE, true);\n+        // validate that the TTL for the chunk is set correctly.\n+        long chunkTtl = blobProperties.getTimeToLiveInSeconds();\n+        if (chunkTtl <= 0 || chunkTtl > frontendConfig.chunkUploadInitialChunkTtlSecs) {\n+          throw new RestServiceException(\"Invalid chunk upload TTL: \" + chunkTtl, RestServiceErrorCode.InvalidArgs);\n+        }\n+      }\n+    }\n+\n+    /**\n+     * After {@link SecurityService#processRequest} finishes, call {@link SecurityService#postProcessRequest} to perform\n+     * request time security checks that rely on the request being fully parsed and any additional arguments set.\n+     * @param blobInfo the {@link BlobInfo} to carry to future stages.\n+     * @return a {@link Callback} to be used with {@link SecurityService#processRequest}.\n+     */\n+    private Callback<Void> securityProcessRequestCallback(BlobInfo blobInfo) {\n+      return buildCallback(frontendMetrics.putSecurityProcessRequestMetrics,\n+          securityCheckResult -> securityService.postProcessRequest(restRequest,\n+              securityPostProcessRequestCallback(blobInfo)), uri, LOGGER, finalCallback);\n+    }\n+\n+    /**\n+     * After {@link SecurityService#postProcessRequest} finishes, call {@link Router#putBlob} to persist the blob in the\n+     * storage layer.\n+     * @param blobInfo the {@link BlobInfo} to make the router call with.\n+     * @return a {@link Callback} to be used with {@link SecurityService#postProcessRequest}.\n+     */\n+    private Callback<Void> securityPostProcessRequestCallback(BlobInfo blobInfo) {\n+      return buildCallback(frontendMetrics.postSecurityPostProcessRequestMetrics, securityCheckResult -> {\n+        if (\"STITCH\".equals(RestUtils.getHeader(restRequest.getArgs(), RestUtils.Headers.PUT_MODE, false))) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDUyMjIyNQ=="}, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 236}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI4ODgwNDIxOnYy", "diffSide": "RIGHT", "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/PutBlobHandler.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNlQxOTozNjowNlrOH0OXCg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMToyMTozMFrOH2I1hA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDUyMzI3NA==", "bodyText": "we can keep this for now, but I was thinking that we may not have to support chunk upload for put requests. I think those data chunks can always be uploaded as regular blobs (POST -> blob id) and then just the final stitchBlob call can be made with the put named blob API.", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r524523274", "createdAt": "2020-11-16T19:36:06Z", "author": {"login": "cgtz"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/PutBlobHandler.java", "diffHunk": "@@ -0,0 +1,405 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.frontend;\n+\n+import com.github.ambry.account.Container;\n+import com.github.ambry.commons.BlobId;\n+import com.github.ambry.commons.Callback;\n+import com.github.ambry.commons.RetainingAsyncWritableChannel;\n+import com.github.ambry.config.FrontendConfig;\n+import com.github.ambry.messageformat.BlobInfo;\n+import com.github.ambry.messageformat.BlobProperties;\n+import com.github.ambry.rest.RequestPath;\n+import com.github.ambry.rest.RestRequest;\n+import com.github.ambry.rest.RestResponseChannel;\n+import com.github.ambry.rest.RestServiceErrorCode;\n+import com.github.ambry.rest.RestServiceException;\n+import com.github.ambry.rest.RestUtils;\n+import com.github.ambry.router.ChunkInfo;\n+import com.github.ambry.router.PutBlobOptions;\n+import com.github.ambry.router.PutBlobOptionsBuilder;\n+import com.github.ambry.router.Router;\n+import com.github.ambry.utils.Pair;\n+import com.github.ambry.utils.Time;\n+import com.github.ambry.utils.Utils;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.json.JSONObject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static com.github.ambry.frontend.FrontendUtils.*;\n+\n+\n+/**\n+ * Handler for put named blob requests. The following request types are handled by {@link PutBlobHandler}:\n+ * <h2>Direct uploads</h2>\n+ * Direct upload requests treat the body of the request as the content to upload to Ambry. The request path should be\n+ * \"/named/account_name/container_name/blob_name\". In these requests, the blob properties and user metadata are supplied as headers. See\n+ * {@link RestUtils#buildBlobProperties(Map)} and {@link RestUtils#buildBlobProperties(Map)} for more details.\n+ * <h2>Stitched uploads</h2>\n+ * Stitched upload requests allow clients to stitch together previously uploaded data chunks into a single logical blob.\n+ * The request path should be \"/named/account_name/container_name/blob_name\", This request accepts the same headers as direct\n+ * upload requests for supplying the blob properties and user metadata of the stitched blob, but, instead of the actual\n+ * blob content, accepts a UTF-8 JSON object that includes the signed IDs for the chunks to stitch, and header x-ambry-put-mode should set as \"STITCH\".\n+ * <h3>Request body format</h3>\n+ * The body of the request should be a JSON object that conforms to the format described in {@link StitchRequestSerDe}.\n+ */\n+public class PutBlobHandler {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(PutBlobHandler.class);\n+  /**\n+   * Key to represent the time at which a blob will expire in ms. Used within the metadata map in signed IDs.\n+   */\n+  static final String EXPIRATION_TIME_MS_KEY = \"et\";\n+\n+  private final SecurityService securityService;\n+  private final IdConverter idConverter;\n+  private final IdSigningService idSigningService;\n+  private final Router router;\n+  private final AccountAndContainerInjector accountAndContainerInjector;\n+  private final Time time;\n+  private final FrontendConfig frontendConfig;\n+  private final FrontendMetrics frontendMetrics;\n+  private final String clusterName;\n+\n+  /**\n+   * Constructs a handler for handling requests for uploading or stitching blobs.\n+   * @param securityService the {@link SecurityService} to use.\n+   * @param idConverter the {@link IdConverter} to use.\n+   * @param idSigningService the {@link IdSigningService} to use.\n+   * @param router the {@link Router} to use.\n+   * @param accountAndContainerInjector helper to resolve account and container for a given request.\n+   * @param time the {@link Time} instance to use.\n+   * @param frontendConfig the {@link FrontendConfig} to use.\n+   * @param frontendMetrics {@link FrontendMetrics} instance where metrics should be recorded.\n+   * @param clusterName the name of the storage cluster that the router communicates with\n+   */\n+  PutBlobHandler(SecurityService securityService, IdConverter idConverter, IdSigningService idSigningService,\n+      Router router, AccountAndContainerInjector accountAndContainerInjector, Time time, FrontendConfig frontendConfig,\n+      FrontendMetrics frontendMetrics, String clusterName) {\n+    this.securityService = securityService;\n+    this.idConverter = idConverter;\n+    this.idSigningService = idSigningService;\n+    this.router = router;\n+    this.accountAndContainerInjector = accountAndContainerInjector;\n+    this.time = time;\n+    this.frontendConfig = frontendConfig;\n+    this.frontendMetrics = frontendMetrics;\n+    this.clusterName = clusterName;\n+  }\n+\n+  /**\n+   * Handles a request for put a blob\n+   * @param restRequest the {@link RestRequest} that contains the request parameters.\n+   * @param restResponseChannel the {@link RestResponseChannel} where headers should be set.\n+   * @param callback the {@link Callback} to invoke when the response is ready (or if there is an exception).\n+   */\n+  void handle(RestRequest restRequest, RestResponseChannel restResponseChannel, Callback<Void> callback) {\n+    new PutBlobHandler.CallbackChain(restRequest, restResponseChannel, callback).start();\n+  }\n+\n+  /**\n+   * Represents the chain of actions to take. Keeps request context that is relevant to all callback stages.\n+   */\n+  private class CallbackChain {\n+    private final RestRequest restRequest;\n+    private final RestResponseChannel restResponseChannel;\n+    private final Callback<Void> finalCallback;\n+    private final String uri;\n+\n+    /**\n+     * @param restRequest the {@link RestRequest}.\n+     * @param restResponseChannel the {@link RestResponseChannel}.\n+     * @param finalCallback the {@link Callback} to call on completion.\n+     */\n+    private CallbackChain(RestRequest restRequest, RestResponseChannel restResponseChannel,\n+        Callback<Void> finalCallback) {\n+      this.restRequest = restRequest;\n+      this.restResponseChannel = restResponseChannel;\n+      this.finalCallback = finalCallback;\n+      this.uri = restRequest.getUri();\n+    }\n+\n+    /**\n+     * Start the chain by calling {@link SecurityService#processRequest}.\n+     */\n+    private void start() {\n+      restRequest.getMetricsTracker()\n+          .injectMetrics(frontendMetrics.putBlobMetricsGroup.getRestRequestMetrics(restRequest.isSslUsed(), false));\n+      //?restRequest.setArg(RestUtils.InternalKeys.KEEP_ALIVE_ON_ERROR_HINT, true);\n+      try {\n+        // Start the callback chain by parsing blob info headers and performing request security processing.\n+        BlobInfo blobInfo = getBlobInfoFromRequest();\n+        checkUploadRequirements(blobInfo.getBlobProperties());\n+        securityService.processRequest(restRequest, securityProcessRequestCallback(blobInfo));\n+      } catch (Exception e) {\n+        finalCallback.onCompletion(null, e);\n+      }\n+    }\n+\n+    /**\n+     * Parse {@link BlobInfo} from the request arguments. This method will also ensure that the correct account and\n+     * container objects are attached to the request.\n+     * @return the {@link BlobInfo} parsed from the request arguments.\n+     * @throws RestServiceException if there is an error while parsing the {@link BlobInfo} arguments.\n+     */\n+    private BlobInfo getBlobInfoFromRequest() throws RestServiceException {\n+      long propsBuildStartTime = System.currentTimeMillis();\n+      accountAndContainerInjector.injectAccountAndContainerForPutRequest(restRequest,\n+          frontendMetrics.putBlobMetricsGroup);\n+      BlobProperties blobProperties = RestUtils.buildBlobProperties(restRequest.getArgs());\n+      Container container = RestUtils.getContainerFromArgs(restRequest.getArgs());\n+      if (blobProperties.getTimeToLiveInSeconds() + TimeUnit.MILLISECONDS.toSeconds(\n+          blobProperties.getCreationTimeInMs()) > Integer.MAX_VALUE) {\n+        LOGGER.debug(\"TTL set to very large value in POST request with BlobProperties {}\", blobProperties);\n+        frontendMetrics.ttlTooLargeError.inc();\n+      } else if (container.isTtlRequired() && (blobProperties.getTimeToLiveInSeconds() == Utils.Infinite_Time\n+          || blobProperties.getTimeToLiveInSeconds() > frontendConfig.maxAcceptableTtlSecsIfTtlRequired)) {\n+        String descriptor = RestUtils.getAccountFromArgs(restRequest.getArgs()).getName() + \":\" + container.getName();\n+        if (frontendConfig.failIfTtlRequiredButNotProvided) {\n+          throw new RestServiceException(\n+              \"TTL < \" + frontendConfig.maxAcceptableTtlSecsIfTtlRequired + \" is required for upload to \" + descriptor,\n+              RestServiceErrorCode.InvalidArgs);\n+        } else {\n+          LOGGER.debug(\"{} attempted an upload with ttl {} to {}\", blobProperties.getServiceId(),\n+              blobProperties.getTimeToLiveInSeconds(), descriptor);\n+          frontendMetrics.ttlNotCompliantError.inc();\n+          restResponseChannel.setHeader(RestUtils.Headers.NON_COMPLIANCE_WARNING,\n+              \"TTL < \" + frontendConfig.maxAcceptableTtlSecsIfTtlRequired + \" will be required for future uploads\");\n+        }\n+      }\n+      // inject encryption frontendMetrics if applicable\n+      if (blobProperties.isEncrypted()) {\n+        restRequest.getMetricsTracker()\n+            .injectMetrics(frontendMetrics.postBlobMetricsGroup.getRestRequestMetrics(restRequest.isSslUsed(), true));\n+      }\n+      byte[] userMetadata = RestUtils.buildUserMetadata(restRequest.getArgs());\n+      frontendMetrics.blobPropsBuildTimeInMs.update(System.currentTimeMillis() - propsBuildStartTime);\n+      LOGGER.trace(\"Blob properties of blob being POSTed - {}\", blobProperties);\n+      return new BlobInfo(blobProperties, userMetadata);\n+    }\n+\n+    /**\n+     * Enforce any additional requirements for certain types of uploads like data chunk uploads.\n+     * @param blobProperties the {@link BlobProperties} parsed from the request.\n+     * @throws RestServiceException\n+     */\n+    private void checkUploadRequirements(BlobProperties blobProperties) throws RestServiceException {\n+      if (RestUtils.isChunkUpload(restRequest.getArgs())) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 203}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUyOTkyNA==", "bodyText": "Sorry I forgot to remove this part. Removed it.", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r526529924", "createdAt": "2020-11-19T01:21:30Z", "author": {"login": "SophieGuo410"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/PutBlobHandler.java", "diffHunk": "@@ -0,0 +1,405 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.frontend;\n+\n+import com.github.ambry.account.Container;\n+import com.github.ambry.commons.BlobId;\n+import com.github.ambry.commons.Callback;\n+import com.github.ambry.commons.RetainingAsyncWritableChannel;\n+import com.github.ambry.config.FrontendConfig;\n+import com.github.ambry.messageformat.BlobInfo;\n+import com.github.ambry.messageformat.BlobProperties;\n+import com.github.ambry.rest.RequestPath;\n+import com.github.ambry.rest.RestRequest;\n+import com.github.ambry.rest.RestResponseChannel;\n+import com.github.ambry.rest.RestServiceErrorCode;\n+import com.github.ambry.rest.RestServiceException;\n+import com.github.ambry.rest.RestUtils;\n+import com.github.ambry.router.ChunkInfo;\n+import com.github.ambry.router.PutBlobOptions;\n+import com.github.ambry.router.PutBlobOptionsBuilder;\n+import com.github.ambry.router.Router;\n+import com.github.ambry.utils.Pair;\n+import com.github.ambry.utils.Time;\n+import com.github.ambry.utils.Utils;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.json.JSONObject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static com.github.ambry.frontend.FrontendUtils.*;\n+\n+\n+/**\n+ * Handler for put named blob requests. The following request types are handled by {@link PutBlobHandler}:\n+ * <h2>Direct uploads</h2>\n+ * Direct upload requests treat the body of the request as the content to upload to Ambry. The request path should be\n+ * \"/named/account_name/container_name/blob_name\". In these requests, the blob properties and user metadata are supplied as headers. See\n+ * {@link RestUtils#buildBlobProperties(Map)} and {@link RestUtils#buildBlobProperties(Map)} for more details.\n+ * <h2>Stitched uploads</h2>\n+ * Stitched upload requests allow clients to stitch together previously uploaded data chunks into a single logical blob.\n+ * The request path should be \"/named/account_name/container_name/blob_name\", This request accepts the same headers as direct\n+ * upload requests for supplying the blob properties and user metadata of the stitched blob, but, instead of the actual\n+ * blob content, accepts a UTF-8 JSON object that includes the signed IDs for the chunks to stitch, and header x-ambry-put-mode should set as \"STITCH\".\n+ * <h3>Request body format</h3>\n+ * The body of the request should be a JSON object that conforms to the format described in {@link StitchRequestSerDe}.\n+ */\n+public class PutBlobHandler {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(PutBlobHandler.class);\n+  /**\n+   * Key to represent the time at which a blob will expire in ms. Used within the metadata map in signed IDs.\n+   */\n+  static final String EXPIRATION_TIME_MS_KEY = \"et\";\n+\n+  private final SecurityService securityService;\n+  private final IdConverter idConverter;\n+  private final IdSigningService idSigningService;\n+  private final Router router;\n+  private final AccountAndContainerInjector accountAndContainerInjector;\n+  private final Time time;\n+  private final FrontendConfig frontendConfig;\n+  private final FrontendMetrics frontendMetrics;\n+  private final String clusterName;\n+\n+  /**\n+   * Constructs a handler for handling requests for uploading or stitching blobs.\n+   * @param securityService the {@link SecurityService} to use.\n+   * @param idConverter the {@link IdConverter} to use.\n+   * @param idSigningService the {@link IdSigningService} to use.\n+   * @param router the {@link Router} to use.\n+   * @param accountAndContainerInjector helper to resolve account and container for a given request.\n+   * @param time the {@link Time} instance to use.\n+   * @param frontendConfig the {@link FrontendConfig} to use.\n+   * @param frontendMetrics {@link FrontendMetrics} instance where metrics should be recorded.\n+   * @param clusterName the name of the storage cluster that the router communicates with\n+   */\n+  PutBlobHandler(SecurityService securityService, IdConverter idConverter, IdSigningService idSigningService,\n+      Router router, AccountAndContainerInjector accountAndContainerInjector, Time time, FrontendConfig frontendConfig,\n+      FrontendMetrics frontendMetrics, String clusterName) {\n+    this.securityService = securityService;\n+    this.idConverter = idConverter;\n+    this.idSigningService = idSigningService;\n+    this.router = router;\n+    this.accountAndContainerInjector = accountAndContainerInjector;\n+    this.time = time;\n+    this.frontendConfig = frontendConfig;\n+    this.frontendMetrics = frontendMetrics;\n+    this.clusterName = clusterName;\n+  }\n+\n+  /**\n+   * Handles a request for put a blob\n+   * @param restRequest the {@link RestRequest} that contains the request parameters.\n+   * @param restResponseChannel the {@link RestResponseChannel} where headers should be set.\n+   * @param callback the {@link Callback} to invoke when the response is ready (or if there is an exception).\n+   */\n+  void handle(RestRequest restRequest, RestResponseChannel restResponseChannel, Callback<Void> callback) {\n+    new PutBlobHandler.CallbackChain(restRequest, restResponseChannel, callback).start();\n+  }\n+\n+  /**\n+   * Represents the chain of actions to take. Keeps request context that is relevant to all callback stages.\n+   */\n+  private class CallbackChain {\n+    private final RestRequest restRequest;\n+    private final RestResponseChannel restResponseChannel;\n+    private final Callback<Void> finalCallback;\n+    private final String uri;\n+\n+    /**\n+     * @param restRequest the {@link RestRequest}.\n+     * @param restResponseChannel the {@link RestResponseChannel}.\n+     * @param finalCallback the {@link Callback} to call on completion.\n+     */\n+    private CallbackChain(RestRequest restRequest, RestResponseChannel restResponseChannel,\n+        Callback<Void> finalCallback) {\n+      this.restRequest = restRequest;\n+      this.restResponseChannel = restResponseChannel;\n+      this.finalCallback = finalCallback;\n+      this.uri = restRequest.getUri();\n+    }\n+\n+    /**\n+     * Start the chain by calling {@link SecurityService#processRequest}.\n+     */\n+    private void start() {\n+      restRequest.getMetricsTracker()\n+          .injectMetrics(frontendMetrics.putBlobMetricsGroup.getRestRequestMetrics(restRequest.isSslUsed(), false));\n+      //?restRequest.setArg(RestUtils.InternalKeys.KEEP_ALIVE_ON_ERROR_HINT, true);\n+      try {\n+        // Start the callback chain by parsing blob info headers and performing request security processing.\n+        BlobInfo blobInfo = getBlobInfoFromRequest();\n+        checkUploadRequirements(blobInfo.getBlobProperties());\n+        securityService.processRequest(restRequest, securityProcessRequestCallback(blobInfo));\n+      } catch (Exception e) {\n+        finalCallback.onCompletion(null, e);\n+      }\n+    }\n+\n+    /**\n+     * Parse {@link BlobInfo} from the request arguments. This method will also ensure that the correct account and\n+     * container objects are attached to the request.\n+     * @return the {@link BlobInfo} parsed from the request arguments.\n+     * @throws RestServiceException if there is an error while parsing the {@link BlobInfo} arguments.\n+     */\n+    private BlobInfo getBlobInfoFromRequest() throws RestServiceException {\n+      long propsBuildStartTime = System.currentTimeMillis();\n+      accountAndContainerInjector.injectAccountAndContainerForPutRequest(restRequest,\n+          frontendMetrics.putBlobMetricsGroup);\n+      BlobProperties blobProperties = RestUtils.buildBlobProperties(restRequest.getArgs());\n+      Container container = RestUtils.getContainerFromArgs(restRequest.getArgs());\n+      if (blobProperties.getTimeToLiveInSeconds() + TimeUnit.MILLISECONDS.toSeconds(\n+          blobProperties.getCreationTimeInMs()) > Integer.MAX_VALUE) {\n+        LOGGER.debug(\"TTL set to very large value in POST request with BlobProperties {}\", blobProperties);\n+        frontendMetrics.ttlTooLargeError.inc();\n+      } else if (container.isTtlRequired() && (blobProperties.getTimeToLiveInSeconds() == Utils.Infinite_Time\n+          || blobProperties.getTimeToLiveInSeconds() > frontendConfig.maxAcceptableTtlSecsIfTtlRequired)) {\n+        String descriptor = RestUtils.getAccountFromArgs(restRequest.getArgs()).getName() + \":\" + container.getName();\n+        if (frontendConfig.failIfTtlRequiredButNotProvided) {\n+          throw new RestServiceException(\n+              \"TTL < \" + frontendConfig.maxAcceptableTtlSecsIfTtlRequired + \" is required for upload to \" + descriptor,\n+              RestServiceErrorCode.InvalidArgs);\n+        } else {\n+          LOGGER.debug(\"{} attempted an upload with ttl {} to {}\", blobProperties.getServiceId(),\n+              blobProperties.getTimeToLiveInSeconds(), descriptor);\n+          frontendMetrics.ttlNotCompliantError.inc();\n+          restResponseChannel.setHeader(RestUtils.Headers.NON_COMPLIANCE_WARNING,\n+              \"TTL < \" + frontendConfig.maxAcceptableTtlSecsIfTtlRequired + \" will be required for future uploads\");\n+        }\n+      }\n+      // inject encryption frontendMetrics if applicable\n+      if (blobProperties.isEncrypted()) {\n+        restRequest.getMetricsTracker()\n+            .injectMetrics(frontendMetrics.postBlobMetricsGroup.getRestRequestMetrics(restRequest.isSslUsed(), true));\n+      }\n+      byte[] userMetadata = RestUtils.buildUserMetadata(restRequest.getArgs());\n+      frontendMetrics.blobPropsBuildTimeInMs.update(System.currentTimeMillis() - propsBuildStartTime);\n+      LOGGER.trace(\"Blob properties of blob being POSTed - {}\", blobProperties);\n+      return new BlobInfo(blobProperties, userMetadata);\n+    }\n+\n+    /**\n+     * Enforce any additional requirements for certain types of uploads like data chunk uploads.\n+     * @param blobProperties the {@link BlobProperties} parsed from the request.\n+     * @throws RestServiceException\n+     */\n+    private void checkUploadRequirements(BlobProperties blobProperties) throws RestServiceException {\n+      if (RestUtils.isChunkUpload(restRequest.getArgs())) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDUyMzI3NA=="}, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 203}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI5NDc1MjEwOnYy", "diffSide": "RIGHT", "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/PutBlobHandler.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QyMDoxNTozM1rOH1I-_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMTozNTo0NFrOH2JHRQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQ4Mzc3NA==", "bodyText": "If this is strictly for named blobs, could we call it NamedBlobPutHandler?", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r525483774", "createdAt": "2020-11-17T20:15:33Z", "author": {"login": "lightningrob"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/PutBlobHandler.java", "diffHunk": "@@ -0,0 +1,405 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.frontend;\n+\n+import com.github.ambry.account.Container;\n+import com.github.ambry.commons.BlobId;\n+import com.github.ambry.commons.Callback;\n+import com.github.ambry.commons.RetainingAsyncWritableChannel;\n+import com.github.ambry.config.FrontendConfig;\n+import com.github.ambry.messageformat.BlobInfo;\n+import com.github.ambry.messageformat.BlobProperties;\n+import com.github.ambry.rest.RequestPath;\n+import com.github.ambry.rest.RestRequest;\n+import com.github.ambry.rest.RestResponseChannel;\n+import com.github.ambry.rest.RestServiceErrorCode;\n+import com.github.ambry.rest.RestServiceException;\n+import com.github.ambry.rest.RestUtils;\n+import com.github.ambry.router.ChunkInfo;\n+import com.github.ambry.router.PutBlobOptions;\n+import com.github.ambry.router.PutBlobOptionsBuilder;\n+import com.github.ambry.router.Router;\n+import com.github.ambry.utils.Pair;\n+import com.github.ambry.utils.Time;\n+import com.github.ambry.utils.Utils;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.json.JSONObject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static com.github.ambry.frontend.FrontendUtils.*;\n+\n+\n+/**\n+ * Handler for put named blob requests. The following request types are handled by {@link PutBlobHandler}:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzNDQ2OQ==", "bodyText": "Done.", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r526534469", "createdAt": "2020-11-19T01:35:44Z", "author": {"login": "SophieGuo410"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/PutBlobHandler.java", "diffHunk": "@@ -0,0 +1,405 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.frontend;\n+\n+import com.github.ambry.account.Container;\n+import com.github.ambry.commons.BlobId;\n+import com.github.ambry.commons.Callback;\n+import com.github.ambry.commons.RetainingAsyncWritableChannel;\n+import com.github.ambry.config.FrontendConfig;\n+import com.github.ambry.messageformat.BlobInfo;\n+import com.github.ambry.messageformat.BlobProperties;\n+import com.github.ambry.rest.RequestPath;\n+import com.github.ambry.rest.RestRequest;\n+import com.github.ambry.rest.RestResponseChannel;\n+import com.github.ambry.rest.RestServiceErrorCode;\n+import com.github.ambry.rest.RestServiceException;\n+import com.github.ambry.rest.RestUtils;\n+import com.github.ambry.router.ChunkInfo;\n+import com.github.ambry.router.PutBlobOptions;\n+import com.github.ambry.router.PutBlobOptionsBuilder;\n+import com.github.ambry.router.Router;\n+import com.github.ambry.utils.Pair;\n+import com.github.ambry.utils.Time;\n+import com.github.ambry.utils.Utils;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.json.JSONObject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static com.github.ambry.frontend.FrontendUtils.*;\n+\n+\n+/**\n+ * Handler for put named blob requests. The following request types are handled by {@link PutBlobHandler}:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQ4Mzc3NA=="}, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 50}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI5NDc4MTQ5OnYy", "diffSide": "RIGHT", "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/PutBlobHandler.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QyMDoxOTo0N1rOH1JTJQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxNzoyMDo0MVrOH2pYPg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQ4ODkzMw==", "bodyText": "Minor: this is likely copied code, but I doubt we need to time simple in-memory operations like this.", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r525488933", "createdAt": "2020-11-17T20:19:47Z", "author": {"login": "lightningrob"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/PutBlobHandler.java", "diffHunk": "@@ -0,0 +1,405 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.frontend;\n+\n+import com.github.ambry.account.Container;\n+import com.github.ambry.commons.BlobId;\n+import com.github.ambry.commons.Callback;\n+import com.github.ambry.commons.RetainingAsyncWritableChannel;\n+import com.github.ambry.config.FrontendConfig;\n+import com.github.ambry.messageformat.BlobInfo;\n+import com.github.ambry.messageformat.BlobProperties;\n+import com.github.ambry.rest.RequestPath;\n+import com.github.ambry.rest.RestRequest;\n+import com.github.ambry.rest.RestResponseChannel;\n+import com.github.ambry.rest.RestServiceErrorCode;\n+import com.github.ambry.rest.RestServiceException;\n+import com.github.ambry.rest.RestUtils;\n+import com.github.ambry.router.ChunkInfo;\n+import com.github.ambry.router.PutBlobOptions;\n+import com.github.ambry.router.PutBlobOptionsBuilder;\n+import com.github.ambry.router.Router;\n+import com.github.ambry.utils.Pair;\n+import com.github.ambry.utils.Time;\n+import com.github.ambry.utils.Utils;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.json.JSONObject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static com.github.ambry.frontend.FrontendUtils.*;\n+\n+\n+/**\n+ * Handler for put named blob requests. The following request types are handled by {@link PutBlobHandler}:\n+ * <h2>Direct uploads</h2>\n+ * Direct upload requests treat the body of the request as the content to upload to Ambry. The request path should be\n+ * \"/named/account_name/container_name/blob_name\". In these requests, the blob properties and user metadata are supplied as headers. See\n+ * {@link RestUtils#buildBlobProperties(Map)} and {@link RestUtils#buildBlobProperties(Map)} for more details.\n+ * <h2>Stitched uploads</h2>\n+ * Stitched upload requests allow clients to stitch together previously uploaded data chunks into a single logical blob.\n+ * The request path should be \"/named/account_name/container_name/blob_name\", This request accepts the same headers as direct\n+ * upload requests for supplying the blob properties and user metadata of the stitched blob, but, instead of the actual\n+ * blob content, accepts a UTF-8 JSON object that includes the signed IDs for the chunks to stitch, and header x-ambry-put-mode should set as \"STITCH\".\n+ * <h3>Request body format</h3>\n+ * The body of the request should be a JSON object that conforms to the format described in {@link StitchRequestSerDe}.\n+ */\n+public class PutBlobHandler {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(PutBlobHandler.class);\n+  /**\n+   * Key to represent the time at which a blob will expire in ms. Used within the metadata map in signed IDs.\n+   */\n+  static final String EXPIRATION_TIME_MS_KEY = \"et\";\n+\n+  private final SecurityService securityService;\n+  private final IdConverter idConverter;\n+  private final IdSigningService idSigningService;\n+  private final Router router;\n+  private final AccountAndContainerInjector accountAndContainerInjector;\n+  private final Time time;\n+  private final FrontendConfig frontendConfig;\n+  private final FrontendMetrics frontendMetrics;\n+  private final String clusterName;\n+\n+  /**\n+   * Constructs a handler for handling requests for uploading or stitching blobs.\n+   * @param securityService the {@link SecurityService} to use.\n+   * @param idConverter the {@link IdConverter} to use.\n+   * @param idSigningService the {@link IdSigningService} to use.\n+   * @param router the {@link Router} to use.\n+   * @param accountAndContainerInjector helper to resolve account and container for a given request.\n+   * @param time the {@link Time} instance to use.\n+   * @param frontendConfig the {@link FrontendConfig} to use.\n+   * @param frontendMetrics {@link FrontendMetrics} instance where metrics should be recorded.\n+   * @param clusterName the name of the storage cluster that the router communicates with\n+   */\n+  PutBlobHandler(SecurityService securityService, IdConverter idConverter, IdSigningService idSigningService,\n+      Router router, AccountAndContainerInjector accountAndContainerInjector, Time time, FrontendConfig frontendConfig,\n+      FrontendMetrics frontendMetrics, String clusterName) {\n+    this.securityService = securityService;\n+    this.idConverter = idConverter;\n+    this.idSigningService = idSigningService;\n+    this.router = router;\n+    this.accountAndContainerInjector = accountAndContainerInjector;\n+    this.time = time;\n+    this.frontendConfig = frontendConfig;\n+    this.frontendMetrics = frontendMetrics;\n+    this.clusterName = clusterName;\n+  }\n+\n+  /**\n+   * Handles a request for put a blob\n+   * @param restRequest the {@link RestRequest} that contains the request parameters.\n+   * @param restResponseChannel the {@link RestResponseChannel} where headers should be set.\n+   * @param callback the {@link Callback} to invoke when the response is ready (or if there is an exception).\n+   */\n+  void handle(RestRequest restRequest, RestResponseChannel restResponseChannel, Callback<Void> callback) {\n+    new PutBlobHandler.CallbackChain(restRequest, restResponseChannel, callback).start();\n+  }\n+\n+  /**\n+   * Represents the chain of actions to take. Keeps request context that is relevant to all callback stages.\n+   */\n+  private class CallbackChain {\n+    private final RestRequest restRequest;\n+    private final RestResponseChannel restResponseChannel;\n+    private final Callback<Void> finalCallback;\n+    private final String uri;\n+\n+    /**\n+     * @param restRequest the {@link RestRequest}.\n+     * @param restResponseChannel the {@link RestResponseChannel}.\n+     * @param finalCallback the {@link Callback} to call on completion.\n+     */\n+    private CallbackChain(RestRequest restRequest, RestResponseChannel restResponseChannel,\n+        Callback<Void> finalCallback) {\n+      this.restRequest = restRequest;\n+      this.restResponseChannel = restResponseChannel;\n+      this.finalCallback = finalCallback;\n+      this.uri = restRequest.getUri();\n+    }\n+\n+    /**\n+     * Start the chain by calling {@link SecurityService#processRequest}.\n+     */\n+    private void start() {\n+      restRequest.getMetricsTracker()\n+          .injectMetrics(frontendMetrics.putBlobMetricsGroup.getRestRequestMetrics(restRequest.isSslUsed(), false));\n+      //?restRequest.setArg(RestUtils.InternalKeys.KEEP_ALIVE_ON_ERROR_HINT, true);\n+      try {\n+        // Start the callback chain by parsing blob info headers and performing request security processing.\n+        BlobInfo blobInfo = getBlobInfoFromRequest();\n+        checkUploadRequirements(blobInfo.getBlobProperties());\n+        securityService.processRequest(restRequest, securityProcessRequestCallback(blobInfo));\n+      } catch (Exception e) {\n+        finalCallback.onCompletion(null, e);\n+      }\n+    }\n+\n+    /**\n+     * Parse {@link BlobInfo} from the request arguments. This method will also ensure that the correct account and\n+     * container objects are attached to the request.\n+     * @return the {@link BlobInfo} parsed from the request arguments.\n+     * @throws RestServiceException if there is an error while parsing the {@link BlobInfo} arguments.\n+     */\n+    private BlobInfo getBlobInfoFromRequest() throws RestServiceException {\n+      long propsBuildStartTime = System.currentTimeMillis();\n+      accountAndContainerInjector.injectAccountAndContainerForPutRequest(restRequest,\n+          frontendMetrics.putBlobMetricsGroup);\n+      BlobProperties blobProperties = RestUtils.buildBlobProperties(restRequest.getArgs());\n+      Container container = RestUtils.getContainerFromArgs(restRequest.getArgs());\n+      if (blobProperties.getTimeToLiveInSeconds() + TimeUnit.MILLISECONDS.toSeconds(\n+          blobProperties.getCreationTimeInMs()) > Integer.MAX_VALUE) {\n+        LOGGER.debug(\"TTL set to very large value in POST request with BlobProperties {}\", blobProperties);\n+        frontendMetrics.ttlTooLargeError.inc();\n+      } else if (container.isTtlRequired() && (blobProperties.getTimeToLiveInSeconds() == Utils.Infinite_Time\n+          || blobProperties.getTimeToLiveInSeconds() > frontendConfig.maxAcceptableTtlSecsIfTtlRequired)) {\n+        String descriptor = RestUtils.getAccountFromArgs(restRequest.getArgs()).getName() + \":\" + container.getName();\n+        if (frontendConfig.failIfTtlRequiredButNotProvided) {\n+          throw new RestServiceException(\n+              \"TTL < \" + frontendConfig.maxAcceptableTtlSecsIfTtlRequired + \" is required for upload to \" + descriptor,\n+              RestServiceErrorCode.InvalidArgs);\n+        } else {\n+          LOGGER.debug(\"{} attempted an upload with ttl {} to {}\", blobProperties.getServiceId(),\n+              blobProperties.getTimeToLiveInSeconds(), descriptor);\n+          frontendMetrics.ttlNotCompliantError.inc();\n+          restResponseChannel.setHeader(RestUtils.Headers.NON_COMPLIANCE_WARNING,\n+              \"TTL < \" + frontendConfig.maxAcceptableTtlSecsIfTtlRequired + \" will be required for future uploads\");\n+        }\n+      }\n+      // inject encryption frontendMetrics if applicable\n+      if (blobProperties.isEncrypted()) {\n+        restRequest.getMetricsTracker()\n+            .injectMetrics(frontendMetrics.postBlobMetricsGroup.getRestRequestMetrics(restRequest.isSslUsed(), true));\n+      }\n+      byte[] userMetadata = RestUtils.buildUserMetadata(restRequest.getArgs());\n+      frontendMetrics.blobPropsBuildTimeInMs.update(System.currentTimeMillis() - propsBuildStartTime);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 192}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU1NzE4NA==", "bodyText": "I added another metric for the NamedBlob blobPropsBuildTime. This is what we have in PostBlobHandler. But if you think it's unnecessary, I can remove on both side?", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r526557184", "createdAt": "2020-11-19T02:45:57Z", "author": {"login": "SophieGuo410"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/PutBlobHandler.java", "diffHunk": "@@ -0,0 +1,405 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.frontend;\n+\n+import com.github.ambry.account.Container;\n+import com.github.ambry.commons.BlobId;\n+import com.github.ambry.commons.Callback;\n+import com.github.ambry.commons.RetainingAsyncWritableChannel;\n+import com.github.ambry.config.FrontendConfig;\n+import com.github.ambry.messageformat.BlobInfo;\n+import com.github.ambry.messageformat.BlobProperties;\n+import com.github.ambry.rest.RequestPath;\n+import com.github.ambry.rest.RestRequest;\n+import com.github.ambry.rest.RestResponseChannel;\n+import com.github.ambry.rest.RestServiceErrorCode;\n+import com.github.ambry.rest.RestServiceException;\n+import com.github.ambry.rest.RestUtils;\n+import com.github.ambry.router.ChunkInfo;\n+import com.github.ambry.router.PutBlobOptions;\n+import com.github.ambry.router.PutBlobOptionsBuilder;\n+import com.github.ambry.router.Router;\n+import com.github.ambry.utils.Pair;\n+import com.github.ambry.utils.Time;\n+import com.github.ambry.utils.Utils;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.json.JSONObject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static com.github.ambry.frontend.FrontendUtils.*;\n+\n+\n+/**\n+ * Handler for put named blob requests. The following request types are handled by {@link PutBlobHandler}:\n+ * <h2>Direct uploads</h2>\n+ * Direct upload requests treat the body of the request as the content to upload to Ambry. The request path should be\n+ * \"/named/account_name/container_name/blob_name\". In these requests, the blob properties and user metadata are supplied as headers. See\n+ * {@link RestUtils#buildBlobProperties(Map)} and {@link RestUtils#buildBlobProperties(Map)} for more details.\n+ * <h2>Stitched uploads</h2>\n+ * Stitched upload requests allow clients to stitch together previously uploaded data chunks into a single logical blob.\n+ * The request path should be \"/named/account_name/container_name/blob_name\", This request accepts the same headers as direct\n+ * upload requests for supplying the blob properties and user metadata of the stitched blob, but, instead of the actual\n+ * blob content, accepts a UTF-8 JSON object that includes the signed IDs for the chunks to stitch, and header x-ambry-put-mode should set as \"STITCH\".\n+ * <h3>Request body format</h3>\n+ * The body of the request should be a JSON object that conforms to the format described in {@link StitchRequestSerDe}.\n+ */\n+public class PutBlobHandler {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(PutBlobHandler.class);\n+  /**\n+   * Key to represent the time at which a blob will expire in ms. Used within the metadata map in signed IDs.\n+   */\n+  static final String EXPIRATION_TIME_MS_KEY = \"et\";\n+\n+  private final SecurityService securityService;\n+  private final IdConverter idConverter;\n+  private final IdSigningService idSigningService;\n+  private final Router router;\n+  private final AccountAndContainerInjector accountAndContainerInjector;\n+  private final Time time;\n+  private final FrontendConfig frontendConfig;\n+  private final FrontendMetrics frontendMetrics;\n+  private final String clusterName;\n+\n+  /**\n+   * Constructs a handler for handling requests for uploading or stitching blobs.\n+   * @param securityService the {@link SecurityService} to use.\n+   * @param idConverter the {@link IdConverter} to use.\n+   * @param idSigningService the {@link IdSigningService} to use.\n+   * @param router the {@link Router} to use.\n+   * @param accountAndContainerInjector helper to resolve account and container for a given request.\n+   * @param time the {@link Time} instance to use.\n+   * @param frontendConfig the {@link FrontendConfig} to use.\n+   * @param frontendMetrics {@link FrontendMetrics} instance where metrics should be recorded.\n+   * @param clusterName the name of the storage cluster that the router communicates with\n+   */\n+  PutBlobHandler(SecurityService securityService, IdConverter idConverter, IdSigningService idSigningService,\n+      Router router, AccountAndContainerInjector accountAndContainerInjector, Time time, FrontendConfig frontendConfig,\n+      FrontendMetrics frontendMetrics, String clusterName) {\n+    this.securityService = securityService;\n+    this.idConverter = idConverter;\n+    this.idSigningService = idSigningService;\n+    this.router = router;\n+    this.accountAndContainerInjector = accountAndContainerInjector;\n+    this.time = time;\n+    this.frontendConfig = frontendConfig;\n+    this.frontendMetrics = frontendMetrics;\n+    this.clusterName = clusterName;\n+  }\n+\n+  /**\n+   * Handles a request for put a blob\n+   * @param restRequest the {@link RestRequest} that contains the request parameters.\n+   * @param restResponseChannel the {@link RestResponseChannel} where headers should be set.\n+   * @param callback the {@link Callback} to invoke when the response is ready (or if there is an exception).\n+   */\n+  void handle(RestRequest restRequest, RestResponseChannel restResponseChannel, Callback<Void> callback) {\n+    new PutBlobHandler.CallbackChain(restRequest, restResponseChannel, callback).start();\n+  }\n+\n+  /**\n+   * Represents the chain of actions to take. Keeps request context that is relevant to all callback stages.\n+   */\n+  private class CallbackChain {\n+    private final RestRequest restRequest;\n+    private final RestResponseChannel restResponseChannel;\n+    private final Callback<Void> finalCallback;\n+    private final String uri;\n+\n+    /**\n+     * @param restRequest the {@link RestRequest}.\n+     * @param restResponseChannel the {@link RestResponseChannel}.\n+     * @param finalCallback the {@link Callback} to call on completion.\n+     */\n+    private CallbackChain(RestRequest restRequest, RestResponseChannel restResponseChannel,\n+        Callback<Void> finalCallback) {\n+      this.restRequest = restRequest;\n+      this.restResponseChannel = restResponseChannel;\n+      this.finalCallback = finalCallback;\n+      this.uri = restRequest.getUri();\n+    }\n+\n+    /**\n+     * Start the chain by calling {@link SecurityService#processRequest}.\n+     */\n+    private void start() {\n+      restRequest.getMetricsTracker()\n+          .injectMetrics(frontendMetrics.putBlobMetricsGroup.getRestRequestMetrics(restRequest.isSslUsed(), false));\n+      //?restRequest.setArg(RestUtils.InternalKeys.KEEP_ALIVE_ON_ERROR_HINT, true);\n+      try {\n+        // Start the callback chain by parsing blob info headers and performing request security processing.\n+        BlobInfo blobInfo = getBlobInfoFromRequest();\n+        checkUploadRequirements(blobInfo.getBlobProperties());\n+        securityService.processRequest(restRequest, securityProcessRequestCallback(blobInfo));\n+      } catch (Exception e) {\n+        finalCallback.onCompletion(null, e);\n+      }\n+    }\n+\n+    /**\n+     * Parse {@link BlobInfo} from the request arguments. This method will also ensure that the correct account and\n+     * container objects are attached to the request.\n+     * @return the {@link BlobInfo} parsed from the request arguments.\n+     * @throws RestServiceException if there is an error while parsing the {@link BlobInfo} arguments.\n+     */\n+    private BlobInfo getBlobInfoFromRequest() throws RestServiceException {\n+      long propsBuildStartTime = System.currentTimeMillis();\n+      accountAndContainerInjector.injectAccountAndContainerForPutRequest(restRequest,\n+          frontendMetrics.putBlobMetricsGroup);\n+      BlobProperties blobProperties = RestUtils.buildBlobProperties(restRequest.getArgs());\n+      Container container = RestUtils.getContainerFromArgs(restRequest.getArgs());\n+      if (blobProperties.getTimeToLiveInSeconds() + TimeUnit.MILLISECONDS.toSeconds(\n+          blobProperties.getCreationTimeInMs()) > Integer.MAX_VALUE) {\n+        LOGGER.debug(\"TTL set to very large value in POST request with BlobProperties {}\", blobProperties);\n+        frontendMetrics.ttlTooLargeError.inc();\n+      } else if (container.isTtlRequired() && (blobProperties.getTimeToLiveInSeconds() == Utils.Infinite_Time\n+          || blobProperties.getTimeToLiveInSeconds() > frontendConfig.maxAcceptableTtlSecsIfTtlRequired)) {\n+        String descriptor = RestUtils.getAccountFromArgs(restRequest.getArgs()).getName() + \":\" + container.getName();\n+        if (frontendConfig.failIfTtlRequiredButNotProvided) {\n+          throw new RestServiceException(\n+              \"TTL < \" + frontendConfig.maxAcceptableTtlSecsIfTtlRequired + \" is required for upload to \" + descriptor,\n+              RestServiceErrorCode.InvalidArgs);\n+        } else {\n+          LOGGER.debug(\"{} attempted an upload with ttl {} to {}\", blobProperties.getServiceId(),\n+              blobProperties.getTimeToLiveInSeconds(), descriptor);\n+          frontendMetrics.ttlNotCompliantError.inc();\n+          restResponseChannel.setHeader(RestUtils.Headers.NON_COMPLIANCE_WARNING,\n+              \"TTL < \" + frontendConfig.maxAcceptableTtlSecsIfTtlRequired + \" will be required for future uploads\");\n+        }\n+      }\n+      // inject encryption frontendMetrics if applicable\n+      if (blobProperties.isEncrypted()) {\n+        restRequest.getMetricsTracker()\n+            .injectMetrics(frontendMetrics.postBlobMetricsGroup.getRestRequestMetrics(restRequest.isSslUsed(), true));\n+      }\n+      byte[] userMetadata = RestUtils.buildUserMetadata(restRequest.getArgs());\n+      frontendMetrics.blobPropsBuildTimeInMs.update(System.currentTimeMillis() - propsBuildStartTime);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQ4ODkzMw=="}, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 192}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzA2MzEwMg==", "bodyText": "It's okay for now, we should probably go over the metrics at some point and remove the ones that are not useful.", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r527063102", "createdAt": "2020-11-19T17:20:41Z", "author": {"login": "lightningrob"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/PutBlobHandler.java", "diffHunk": "@@ -0,0 +1,405 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.frontend;\n+\n+import com.github.ambry.account.Container;\n+import com.github.ambry.commons.BlobId;\n+import com.github.ambry.commons.Callback;\n+import com.github.ambry.commons.RetainingAsyncWritableChannel;\n+import com.github.ambry.config.FrontendConfig;\n+import com.github.ambry.messageformat.BlobInfo;\n+import com.github.ambry.messageformat.BlobProperties;\n+import com.github.ambry.rest.RequestPath;\n+import com.github.ambry.rest.RestRequest;\n+import com.github.ambry.rest.RestResponseChannel;\n+import com.github.ambry.rest.RestServiceErrorCode;\n+import com.github.ambry.rest.RestServiceException;\n+import com.github.ambry.rest.RestUtils;\n+import com.github.ambry.router.ChunkInfo;\n+import com.github.ambry.router.PutBlobOptions;\n+import com.github.ambry.router.PutBlobOptionsBuilder;\n+import com.github.ambry.router.Router;\n+import com.github.ambry.utils.Pair;\n+import com.github.ambry.utils.Time;\n+import com.github.ambry.utils.Utils;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.json.JSONObject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static com.github.ambry.frontend.FrontendUtils.*;\n+\n+\n+/**\n+ * Handler for put named blob requests. The following request types are handled by {@link PutBlobHandler}:\n+ * <h2>Direct uploads</h2>\n+ * Direct upload requests treat the body of the request as the content to upload to Ambry. The request path should be\n+ * \"/named/account_name/container_name/blob_name\". In these requests, the blob properties and user metadata are supplied as headers. See\n+ * {@link RestUtils#buildBlobProperties(Map)} and {@link RestUtils#buildBlobProperties(Map)} for more details.\n+ * <h2>Stitched uploads</h2>\n+ * Stitched upload requests allow clients to stitch together previously uploaded data chunks into a single logical blob.\n+ * The request path should be \"/named/account_name/container_name/blob_name\", This request accepts the same headers as direct\n+ * upload requests for supplying the blob properties and user metadata of the stitched blob, but, instead of the actual\n+ * blob content, accepts a UTF-8 JSON object that includes the signed IDs for the chunks to stitch, and header x-ambry-put-mode should set as \"STITCH\".\n+ * <h3>Request body format</h3>\n+ * The body of the request should be a JSON object that conforms to the format described in {@link StitchRequestSerDe}.\n+ */\n+public class PutBlobHandler {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(PutBlobHandler.class);\n+  /**\n+   * Key to represent the time at which a blob will expire in ms. Used within the metadata map in signed IDs.\n+   */\n+  static final String EXPIRATION_TIME_MS_KEY = \"et\";\n+\n+  private final SecurityService securityService;\n+  private final IdConverter idConverter;\n+  private final IdSigningService idSigningService;\n+  private final Router router;\n+  private final AccountAndContainerInjector accountAndContainerInjector;\n+  private final Time time;\n+  private final FrontendConfig frontendConfig;\n+  private final FrontendMetrics frontendMetrics;\n+  private final String clusterName;\n+\n+  /**\n+   * Constructs a handler for handling requests for uploading or stitching blobs.\n+   * @param securityService the {@link SecurityService} to use.\n+   * @param idConverter the {@link IdConverter} to use.\n+   * @param idSigningService the {@link IdSigningService} to use.\n+   * @param router the {@link Router} to use.\n+   * @param accountAndContainerInjector helper to resolve account and container for a given request.\n+   * @param time the {@link Time} instance to use.\n+   * @param frontendConfig the {@link FrontendConfig} to use.\n+   * @param frontendMetrics {@link FrontendMetrics} instance where metrics should be recorded.\n+   * @param clusterName the name of the storage cluster that the router communicates with\n+   */\n+  PutBlobHandler(SecurityService securityService, IdConverter idConverter, IdSigningService idSigningService,\n+      Router router, AccountAndContainerInjector accountAndContainerInjector, Time time, FrontendConfig frontendConfig,\n+      FrontendMetrics frontendMetrics, String clusterName) {\n+    this.securityService = securityService;\n+    this.idConverter = idConverter;\n+    this.idSigningService = idSigningService;\n+    this.router = router;\n+    this.accountAndContainerInjector = accountAndContainerInjector;\n+    this.time = time;\n+    this.frontendConfig = frontendConfig;\n+    this.frontendMetrics = frontendMetrics;\n+    this.clusterName = clusterName;\n+  }\n+\n+  /**\n+   * Handles a request for put a blob\n+   * @param restRequest the {@link RestRequest} that contains the request parameters.\n+   * @param restResponseChannel the {@link RestResponseChannel} where headers should be set.\n+   * @param callback the {@link Callback} to invoke when the response is ready (or if there is an exception).\n+   */\n+  void handle(RestRequest restRequest, RestResponseChannel restResponseChannel, Callback<Void> callback) {\n+    new PutBlobHandler.CallbackChain(restRequest, restResponseChannel, callback).start();\n+  }\n+\n+  /**\n+   * Represents the chain of actions to take. Keeps request context that is relevant to all callback stages.\n+   */\n+  private class CallbackChain {\n+    private final RestRequest restRequest;\n+    private final RestResponseChannel restResponseChannel;\n+    private final Callback<Void> finalCallback;\n+    private final String uri;\n+\n+    /**\n+     * @param restRequest the {@link RestRequest}.\n+     * @param restResponseChannel the {@link RestResponseChannel}.\n+     * @param finalCallback the {@link Callback} to call on completion.\n+     */\n+    private CallbackChain(RestRequest restRequest, RestResponseChannel restResponseChannel,\n+        Callback<Void> finalCallback) {\n+      this.restRequest = restRequest;\n+      this.restResponseChannel = restResponseChannel;\n+      this.finalCallback = finalCallback;\n+      this.uri = restRequest.getUri();\n+    }\n+\n+    /**\n+     * Start the chain by calling {@link SecurityService#processRequest}.\n+     */\n+    private void start() {\n+      restRequest.getMetricsTracker()\n+          .injectMetrics(frontendMetrics.putBlobMetricsGroup.getRestRequestMetrics(restRequest.isSslUsed(), false));\n+      //?restRequest.setArg(RestUtils.InternalKeys.KEEP_ALIVE_ON_ERROR_HINT, true);\n+      try {\n+        // Start the callback chain by parsing blob info headers and performing request security processing.\n+        BlobInfo blobInfo = getBlobInfoFromRequest();\n+        checkUploadRequirements(blobInfo.getBlobProperties());\n+        securityService.processRequest(restRequest, securityProcessRequestCallback(blobInfo));\n+      } catch (Exception e) {\n+        finalCallback.onCompletion(null, e);\n+      }\n+    }\n+\n+    /**\n+     * Parse {@link BlobInfo} from the request arguments. This method will also ensure that the correct account and\n+     * container objects are attached to the request.\n+     * @return the {@link BlobInfo} parsed from the request arguments.\n+     * @throws RestServiceException if there is an error while parsing the {@link BlobInfo} arguments.\n+     */\n+    private BlobInfo getBlobInfoFromRequest() throws RestServiceException {\n+      long propsBuildStartTime = System.currentTimeMillis();\n+      accountAndContainerInjector.injectAccountAndContainerForPutRequest(restRequest,\n+          frontendMetrics.putBlobMetricsGroup);\n+      BlobProperties blobProperties = RestUtils.buildBlobProperties(restRequest.getArgs());\n+      Container container = RestUtils.getContainerFromArgs(restRequest.getArgs());\n+      if (blobProperties.getTimeToLiveInSeconds() + TimeUnit.MILLISECONDS.toSeconds(\n+          blobProperties.getCreationTimeInMs()) > Integer.MAX_VALUE) {\n+        LOGGER.debug(\"TTL set to very large value in POST request with BlobProperties {}\", blobProperties);\n+        frontendMetrics.ttlTooLargeError.inc();\n+      } else if (container.isTtlRequired() && (blobProperties.getTimeToLiveInSeconds() == Utils.Infinite_Time\n+          || blobProperties.getTimeToLiveInSeconds() > frontendConfig.maxAcceptableTtlSecsIfTtlRequired)) {\n+        String descriptor = RestUtils.getAccountFromArgs(restRequest.getArgs()).getName() + \":\" + container.getName();\n+        if (frontendConfig.failIfTtlRequiredButNotProvided) {\n+          throw new RestServiceException(\n+              \"TTL < \" + frontendConfig.maxAcceptableTtlSecsIfTtlRequired + \" is required for upload to \" + descriptor,\n+              RestServiceErrorCode.InvalidArgs);\n+        } else {\n+          LOGGER.debug(\"{} attempted an upload with ttl {} to {}\", blobProperties.getServiceId(),\n+              blobProperties.getTimeToLiveInSeconds(), descriptor);\n+          frontendMetrics.ttlNotCompliantError.inc();\n+          restResponseChannel.setHeader(RestUtils.Headers.NON_COMPLIANCE_WARNING,\n+              \"TTL < \" + frontendConfig.maxAcceptableTtlSecsIfTtlRequired + \" will be required for future uploads\");\n+        }\n+      }\n+      // inject encryption frontendMetrics if applicable\n+      if (blobProperties.isEncrypted()) {\n+        restRequest.getMetricsTracker()\n+            .injectMetrics(frontendMetrics.postBlobMetricsGroup.getRestRequestMetrics(restRequest.isSslUsed(), true));\n+      }\n+      byte[] userMetadata = RestUtils.buildUserMetadata(restRequest.getArgs());\n+      frontendMetrics.blobPropsBuildTimeInMs.update(System.currentTimeMillis() - propsBuildStartTime);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQ4ODkzMw=="}, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 192}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI5NDgwODM0OnYy", "diffSide": "RIGHT", "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/PutBlobHandler.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QyMDoyMzo1MFrOH1Jl_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxNzoyNDozOFrOH2piPQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQ5Mzc1OA==", "bodyText": "There is a massive amount of code here copied from PostBlobHandler.  Please refactor.", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r525493758", "createdAt": "2020-11-17T20:23:50Z", "author": {"login": "lightningrob"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/PutBlobHandler.java", "diffHunk": "@@ -0,0 +1,405 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.frontend;\n+\n+import com.github.ambry.account.Container;\n+import com.github.ambry.commons.BlobId;\n+import com.github.ambry.commons.Callback;\n+import com.github.ambry.commons.RetainingAsyncWritableChannel;\n+import com.github.ambry.config.FrontendConfig;\n+import com.github.ambry.messageformat.BlobInfo;\n+import com.github.ambry.messageformat.BlobProperties;\n+import com.github.ambry.rest.RequestPath;\n+import com.github.ambry.rest.RestRequest;\n+import com.github.ambry.rest.RestResponseChannel;\n+import com.github.ambry.rest.RestServiceErrorCode;\n+import com.github.ambry.rest.RestServiceException;\n+import com.github.ambry.rest.RestUtils;\n+import com.github.ambry.router.ChunkInfo;\n+import com.github.ambry.router.PutBlobOptions;\n+import com.github.ambry.router.PutBlobOptionsBuilder;\n+import com.github.ambry.router.Router;\n+import com.github.ambry.utils.Pair;\n+import com.github.ambry.utils.Time;\n+import com.github.ambry.utils.Utils;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.json.JSONObject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static com.github.ambry.frontend.FrontendUtils.*;\n+\n+\n+/**\n+ * Handler for put named blob requests. The following request types are handled by {@link PutBlobHandler}:\n+ * <h2>Direct uploads</h2>\n+ * Direct upload requests treat the body of the request as the content to upload to Ambry. The request path should be\n+ * \"/named/account_name/container_name/blob_name\". In these requests, the blob properties and user metadata are supplied as headers. See\n+ * {@link RestUtils#buildBlobProperties(Map)} and {@link RestUtils#buildBlobProperties(Map)} for more details.\n+ * <h2>Stitched uploads</h2>\n+ * Stitched upload requests allow clients to stitch together previously uploaded data chunks into a single logical blob.\n+ * The request path should be \"/named/account_name/container_name/blob_name\", This request accepts the same headers as direct\n+ * upload requests for supplying the blob properties and user metadata of the stitched blob, but, instead of the actual\n+ * blob content, accepts a UTF-8 JSON object that includes the signed IDs for the chunks to stitch, and header x-ambry-put-mode should set as \"STITCH\".\n+ * <h3>Request body format</h3>\n+ * The body of the request should be a JSON object that conforms to the format described in {@link StitchRequestSerDe}.\n+ */\n+public class PutBlobHandler {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzA2NTY2MQ==", "bodyText": "I've done part of the refactor, will keep working on that.", "url": "https://github.com/linkedin/ambry/pull/1690#discussion_r527065661", "createdAt": "2020-11-19T17:24:38Z", "author": {"login": "SophieGuo410"}, "path": "ambry-frontend/src/main/java/com/github/ambry/frontend/PutBlobHandler.java", "diffHunk": "@@ -0,0 +1,405 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.frontend;\n+\n+import com.github.ambry.account.Container;\n+import com.github.ambry.commons.BlobId;\n+import com.github.ambry.commons.Callback;\n+import com.github.ambry.commons.RetainingAsyncWritableChannel;\n+import com.github.ambry.config.FrontendConfig;\n+import com.github.ambry.messageformat.BlobInfo;\n+import com.github.ambry.messageformat.BlobProperties;\n+import com.github.ambry.rest.RequestPath;\n+import com.github.ambry.rest.RestRequest;\n+import com.github.ambry.rest.RestResponseChannel;\n+import com.github.ambry.rest.RestServiceErrorCode;\n+import com.github.ambry.rest.RestServiceException;\n+import com.github.ambry.rest.RestUtils;\n+import com.github.ambry.router.ChunkInfo;\n+import com.github.ambry.router.PutBlobOptions;\n+import com.github.ambry.router.PutBlobOptionsBuilder;\n+import com.github.ambry.router.Router;\n+import com.github.ambry.utils.Pair;\n+import com.github.ambry.utils.Time;\n+import com.github.ambry.utils.Utils;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.json.JSONObject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static com.github.ambry.frontend.FrontendUtils.*;\n+\n+\n+/**\n+ * Handler for put named blob requests. The following request types are handled by {@link PutBlobHandler}:\n+ * <h2>Direct uploads</h2>\n+ * Direct upload requests treat the body of the request as the content to upload to Ambry. The request path should be\n+ * \"/named/account_name/container_name/blob_name\". In these requests, the blob properties and user metadata are supplied as headers. See\n+ * {@link RestUtils#buildBlobProperties(Map)} and {@link RestUtils#buildBlobProperties(Map)} for more details.\n+ * <h2>Stitched uploads</h2>\n+ * Stitched upload requests allow clients to stitch together previously uploaded data chunks into a single logical blob.\n+ * The request path should be \"/named/account_name/container_name/blob_name\", This request accepts the same headers as direct\n+ * upload requests for supplying the blob properties and user metadata of the stitched blob, but, instead of the actual\n+ * blob content, accepts a UTF-8 JSON object that includes the signed IDs for the chunks to stitch, and header x-ambry-put-mode should set as \"STITCH\".\n+ * <h3>Request body format</h3>\n+ * The body of the request should be a JSON object that conforms to the format described in {@link StitchRequestSerDe}.\n+ */\n+public class PutBlobHandler {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQ5Mzc1OA=="}, "originalCommit": {"oid": "bf4b166bdf60f0178a3e46b2de7dbc301eae0ff5"}, "originalPosition": 63}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1123, "cost": 1, "resetAt": "2021-11-12T20:44:06Z"}}}