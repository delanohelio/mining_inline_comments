{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDA3NDAxNTIw", "number": 1484, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQxODozMjoyMVrOD057mQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yM1QxNzo1NToyM1rOD1Zttg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU2ODAxNjg5OnYy", "diffSide": "RIGHT", "path": "ambry-store/src/main/java/com/github/ambry/store/PersistentIndex.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQxODozMjoyMVrOGKFDfQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yM1QwMDoyMjoxOVrOGKRN1g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzIyMTc1Nw==", "bodyText": "nit: Now we are no this, I think we can do a de-dup before going through the for loop.", "url": "https://github.com/linkedin/ambry/pull/1484#discussion_r413221757", "createdAt": "2020-04-22T18:32:21Z", "author": {"login": "justinlin-linkedin"}, "path": "ambry-store/src/main/java/com/github/ambry/store/PersistentIndex.java", "diffHunk": "@@ -1162,14 +1167,12 @@ FindInfo findEntriesSince(FindToken token, long maxTotalSizeOfEntries) throws St\n                   + entries.size());\n           Offset offsetEnd = offsetToStart;\n           long currentTotalSizeOfEntries = 0;\n+          Offset endOffsetOfSnapshot = getCurrentEndOffset(indexSegments);\n           for (JournalEntry entry : entries) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3136b78331d4108fa2af717258d10fd9d2862cdb"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzQyMTAxNA==", "bodyText": "addressed this with caching of messageinfos", "url": "https://github.com/linkedin/ambry/pull/1484#discussion_r413421014", "createdAt": "2020-04-23T00:22:19Z", "author": {"login": "cgtz"}, "path": "ambry-store/src/main/java/com/github/ambry/store/PersistentIndex.java", "diffHunk": "@@ -1162,14 +1167,12 @@ FindInfo findEntriesSince(FindToken token, long maxTotalSizeOfEntries) throws St\n                   + entries.size());\n           Offset offsetEnd = offsetToStart;\n           long currentTotalSizeOfEntries = 0;\n+          Offset endOffsetOfSnapshot = getCurrentEndOffset(indexSegments);\n           for (JournalEntry entry : entries) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzIyMTc1Nw=="}, "originalCommit": {"oid": "3136b78331d4108fa2af717258d10fd9d2862cdb"}, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU2ODI2NTg1OnYy", "diffSide": "RIGHT", "path": "ambry-store/src/main/java/com/github/ambry/store/PersistentIndex.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQxOToyOTo0MVrOGKHZkA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQxOToyOTo0MVrOGKHZkA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzI2MDE3Ng==", "bodyText": "nit: ttlUpdate or undelete", "url": "https://github.com/linkedin/ambry/pull/1484#discussion_r413260176", "createdAt": "2020-04-22T19:29:41Z", "author": {"login": "jsjtzyy"}, "path": "ambry-store/src/main/java/com/github/ambry/store/PersistentIndex.java", "diffHunk": "@@ -1574,6 +1575,41 @@ private StoreFindToken findEntriesFromSegmentStartOffset(Offset initialSegmentSt\n     }\n   }\n \n+  /**\n+   * Helper method for getting a {@link MessageInfo} and an estimate of fetch size corresponding to the provided\n+   * {@link JournalEntry}. This size may include the size of the put record if the put record is at or past the offset\n+   * in the journal entry and the latest value in the index is a delete or undelete. In this case, we can make a safe", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3136b78331d4108fa2af717258d10fd9d2862cdb"}, "originalPosition": 74}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU2ODMxOTI5OnYy", "diffSide": "RIGHT", "path": "ambry-store/src/test/java/com/github/ambry/store/IndexTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQxOTozOTo0M1rOGKH65Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQxOTozOTo0M1rOGKH65Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzI2ODcwOQ==", "bodyText": "removed?", "url": "https://github.com/linkedin/ambry/pull/1484#discussion_r413268709", "createdAt": "2020-04-22T19:39:43Z", "author": {"login": "jsjtzyy"}, "path": "ambry-store/src/test/java/com/github/ambry/store/IndexTest.java", "diffHunk": "@@ -2455,6 +2457,7 @@ private void doFindEntriesSinceTest(StoreFindToken startToken, long maxTotalSize\n       StoreFindToken expectedEndToken) throws StoreException {\n     FindInfo findInfo = state.index.findEntriesSince(startToken, maxTotalSizeOfEntries);\n     StoreFindToken token = (StoreFindToken) findInfo.getFindToken();\n+    System.out.println(\"GOT token: \" + token);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3136b78331d4108fa2af717258d10fd9d2862cdb"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU3MzIyNDIyOnYy", "diffSide": "RIGHT", "path": "ambry-store/src/main/java/com/github/ambry/store/PersistentIndex.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yM1QxNzo1NToyM1rOGK03QA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yM1QyMzoyMDoxMlrOGK_-Mw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDAwNTA1Ng==", "bodyText": "Logic looks good. I just need some clarification on PUT. If current entry is a PUT, how can we avoid its size being added to currentTotalSizeOfEntries twice ?", "url": "https://github.com/linkedin/ambry/pull/1484#discussion_r414005056", "createdAt": "2020-04-23T17:55:23Z", "author": {"login": "jsjtzyy"}, "path": "ambry-store/src/main/java/com/github/ambry/store/PersistentIndex.java", "diffHunk": "@@ -1574,6 +1573,52 @@ private StoreFindToken findEntriesFromSegmentStartOffset(Offset initialSegmentSt\n     }\n   }\n \n+  /**\n+   * Helper method for getting a {@link MessageInfo} and an estimate of fetch size corresponding to the provided\n+   * {@link JournalEntry} and adding it to the list of messages. This size added to currentTotalSizeOfEntries may\n+   * include the size of the put record if the put record is at or past the offset in the journal entry and the latest\n+   * value in the index is a ttlUpdate or undelete. In this case, we can make a safe guess that the original blob also\n+   * has to be fetched by a replicator anyways and should be counted towards the size limit.\n+   * @param entry the {@link JournalEntry} to look up in the index.\n+   * @param endOffsetOfSearchRange the end of the range to search in the index.\n+   * @param indexSegments the index snapshot to search.\n+   * @param messageInfoCache a cache to store previous find results for a key. Queries from an earlier offset will\n+   *                         return the same latest value, so there is no need to search the index a second time for\n+   *                         keys with multiple journal entries.\n+   * @param messageEntries the list of {@link MessageInfo} being constructed. This list will be added to.\n+   * @param currentTotalSizeOfEntries a counter for the size in bytes of the entries returned in the query.\n+   * @throws StoreException on index search errors.\n+   */\n+  private void addMessageInfoForJournalEntry(JournalEntry entry, Offset endOffsetOfSearchRange,\n+      ConcurrentSkipListMap<Offset, IndexSegment> indexSegments, Map<StoreKey, MessageInfo> messageInfoCache,\n+      List<MessageInfo> messageEntries, AtomicLong currentTotalSizeOfEntries) throws StoreException {\n+    MessageInfo messageInfo = messageInfoCache.get(entry.getKey());\n+    if (messageInfo == null) {\n+      // we only need to do an index lookup once per key since the following method will honor any index\n+      // values for the key past entry.getOffset()\n+      List<IndexValue> valuesInRange =\n+          findAllIndexValuesForKey(entry.getKey(), new FileSpan(entry.getOffset(), endOffsetOfSearchRange),\n+              EnumSet.allOf(IndexEntryType.class), indexSegments);\n+\n+      IndexValue latestValue = valuesInRange.get(0);\n+      if (valuesInRange.size() > 1 && (latestValue.isTtlUpdate() || latestValue.isUndelete())) {\n+        IndexValue earliestValue = valuesInRange.get(valuesInRange.size() - 1);\n+        if (earliestValue.isPut() && earliestValue.getOffset().compareTo(entry.getOffset()) >= 0) {\n+          currentTotalSizeOfEntries.addAndGet(earliestValue.getSize());\n+        }\n+      }\n+      messageInfo =\n+          new MessageInfo(entry.getKey(), latestValue.getSize(), latestValue.isDelete(), latestValue.isTtlUpdate(),\n+              latestValue.isUndelete(), latestValue.getExpiresAtMs(), null, latestValue.getAccountId(),\n+              latestValue.getContainerId(), latestValue.getOperationTimeInMs(), latestValue.getLifeVersion());\n+      messageInfoCache.put(entry.getKey(), messageInfo);\n+    }\n+    // We may add duplicate MessageInfos to the list here since the ordering of the list is used to calculate\n+    // bytes read for the token. The duplicates will be cleaned up by eliminateDuplicates.\n+    currentTotalSizeOfEntries.addAndGet(messageInfo.getSize());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "70c607d61397471da497c9f8122189abb1d4114a"}, "originalPosition": 132}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDE1MTMyMg==", "bodyText": "Sorry, I missed this question this morning. If the most recent entry is a put, the check on line 1604 will be false, so the size will only be accounted for once. The only case where extra size will be added if there are more than one entry found past entry.getOffset() and the latest entry is a TTL update or undelete and the earliest value at or past the journal entry is a put (e.g. not something else that doesn't indicate a need for blob fetching like a delete).", "url": "https://github.com/linkedin/ambry/pull/1484#discussion_r414151322", "createdAt": "2020-04-23T21:57:05Z", "author": {"login": "cgtz"}, "path": "ambry-store/src/main/java/com/github/ambry/store/PersistentIndex.java", "diffHunk": "@@ -1574,6 +1573,52 @@ private StoreFindToken findEntriesFromSegmentStartOffset(Offset initialSegmentSt\n     }\n   }\n \n+  /**\n+   * Helper method for getting a {@link MessageInfo} and an estimate of fetch size corresponding to the provided\n+   * {@link JournalEntry} and adding it to the list of messages. This size added to currentTotalSizeOfEntries may\n+   * include the size of the put record if the put record is at or past the offset in the journal entry and the latest\n+   * value in the index is a ttlUpdate or undelete. In this case, we can make a safe guess that the original blob also\n+   * has to be fetched by a replicator anyways and should be counted towards the size limit.\n+   * @param entry the {@link JournalEntry} to look up in the index.\n+   * @param endOffsetOfSearchRange the end of the range to search in the index.\n+   * @param indexSegments the index snapshot to search.\n+   * @param messageInfoCache a cache to store previous find results for a key. Queries from an earlier offset will\n+   *                         return the same latest value, so there is no need to search the index a second time for\n+   *                         keys with multiple journal entries.\n+   * @param messageEntries the list of {@link MessageInfo} being constructed. This list will be added to.\n+   * @param currentTotalSizeOfEntries a counter for the size in bytes of the entries returned in the query.\n+   * @throws StoreException on index search errors.\n+   */\n+  private void addMessageInfoForJournalEntry(JournalEntry entry, Offset endOffsetOfSearchRange,\n+      ConcurrentSkipListMap<Offset, IndexSegment> indexSegments, Map<StoreKey, MessageInfo> messageInfoCache,\n+      List<MessageInfo> messageEntries, AtomicLong currentTotalSizeOfEntries) throws StoreException {\n+    MessageInfo messageInfo = messageInfoCache.get(entry.getKey());\n+    if (messageInfo == null) {\n+      // we only need to do an index lookup once per key since the following method will honor any index\n+      // values for the key past entry.getOffset()\n+      List<IndexValue> valuesInRange =\n+          findAllIndexValuesForKey(entry.getKey(), new FileSpan(entry.getOffset(), endOffsetOfSearchRange),\n+              EnumSet.allOf(IndexEntryType.class), indexSegments);\n+\n+      IndexValue latestValue = valuesInRange.get(0);\n+      if (valuesInRange.size() > 1 && (latestValue.isTtlUpdate() || latestValue.isUndelete())) {\n+        IndexValue earliestValue = valuesInRange.get(valuesInRange.size() - 1);\n+        if (earliestValue.isPut() && earliestValue.getOffset().compareTo(entry.getOffset()) >= 0) {\n+          currentTotalSizeOfEntries.addAndGet(earliestValue.getSize());\n+        }\n+      }\n+      messageInfo =\n+          new MessageInfo(entry.getKey(), latestValue.getSize(), latestValue.isDelete(), latestValue.isTtlUpdate(),\n+              latestValue.isUndelete(), latestValue.getExpiresAtMs(), null, latestValue.getAccountId(),\n+              latestValue.getContainerId(), latestValue.getOperationTimeInMs(), latestValue.getLifeVersion());\n+      messageInfoCache.put(entry.getKey(), messageInfo);\n+    }\n+    // We may add duplicate MessageInfos to the list here since the ordering of the list is used to calculate\n+    // bytes read for the token. The duplicates will be cleaned up by eliminateDuplicates.\n+    currentTotalSizeOfEntries.addAndGet(messageInfo.getSize());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDAwNTA1Ng=="}, "originalCommit": {"oid": "70c607d61397471da497c9f8122189abb1d4114a"}, "originalPosition": 132}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDE4NzA1OQ==", "bodyText": "got it", "url": "https://github.com/linkedin/ambry/pull/1484#discussion_r414187059", "createdAt": "2020-04-23T23:20:12Z", "author": {"login": "jsjtzyy"}, "path": "ambry-store/src/main/java/com/github/ambry/store/PersistentIndex.java", "diffHunk": "@@ -1574,6 +1573,52 @@ private StoreFindToken findEntriesFromSegmentStartOffset(Offset initialSegmentSt\n     }\n   }\n \n+  /**\n+   * Helper method for getting a {@link MessageInfo} and an estimate of fetch size corresponding to the provided\n+   * {@link JournalEntry} and adding it to the list of messages. This size added to currentTotalSizeOfEntries may\n+   * include the size of the put record if the put record is at or past the offset in the journal entry and the latest\n+   * value in the index is a ttlUpdate or undelete. In this case, we can make a safe guess that the original blob also\n+   * has to be fetched by a replicator anyways and should be counted towards the size limit.\n+   * @param entry the {@link JournalEntry} to look up in the index.\n+   * @param endOffsetOfSearchRange the end of the range to search in the index.\n+   * @param indexSegments the index snapshot to search.\n+   * @param messageInfoCache a cache to store previous find results for a key. Queries from an earlier offset will\n+   *                         return the same latest value, so there is no need to search the index a second time for\n+   *                         keys with multiple journal entries.\n+   * @param messageEntries the list of {@link MessageInfo} being constructed. This list will be added to.\n+   * @param currentTotalSizeOfEntries a counter for the size in bytes of the entries returned in the query.\n+   * @throws StoreException on index search errors.\n+   */\n+  private void addMessageInfoForJournalEntry(JournalEntry entry, Offset endOffsetOfSearchRange,\n+      ConcurrentSkipListMap<Offset, IndexSegment> indexSegments, Map<StoreKey, MessageInfo> messageInfoCache,\n+      List<MessageInfo> messageEntries, AtomicLong currentTotalSizeOfEntries) throws StoreException {\n+    MessageInfo messageInfo = messageInfoCache.get(entry.getKey());\n+    if (messageInfo == null) {\n+      // we only need to do an index lookup once per key since the following method will honor any index\n+      // values for the key past entry.getOffset()\n+      List<IndexValue> valuesInRange =\n+          findAllIndexValuesForKey(entry.getKey(), new FileSpan(entry.getOffset(), endOffsetOfSearchRange),\n+              EnumSet.allOf(IndexEntryType.class), indexSegments);\n+\n+      IndexValue latestValue = valuesInRange.get(0);\n+      if (valuesInRange.size() > 1 && (latestValue.isTtlUpdate() || latestValue.isUndelete())) {\n+        IndexValue earliestValue = valuesInRange.get(valuesInRange.size() - 1);\n+        if (earliestValue.isPut() && earliestValue.getOffset().compareTo(entry.getOffset()) >= 0) {\n+          currentTotalSizeOfEntries.addAndGet(earliestValue.getSize());\n+        }\n+      }\n+      messageInfo =\n+          new MessageInfo(entry.getKey(), latestValue.getSize(), latestValue.isDelete(), latestValue.isTtlUpdate(),\n+              latestValue.isUndelete(), latestValue.getExpiresAtMs(), null, latestValue.getAccountId(),\n+              latestValue.getContainerId(), latestValue.getOperationTimeInMs(), latestValue.getLifeVersion());\n+      messageInfoCache.put(entry.getKey(), messageInfo);\n+    }\n+    // We may add duplicate MessageInfos to the list here since the ordering of the list is used to calculate\n+    // bytes read for the token. The duplicates will be cleaned up by eliminateDuplicates.\n+    currentTotalSizeOfEntries.addAndGet(messageInfo.getSize());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDAwNTA1Ng=="}, "originalCommit": {"oid": "70c607d61397471da497c9f8122189abb1d4114a"}, "originalPosition": 132}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1518, "cost": 1, "resetAt": "2021-11-12T20:44:06Z"}}}