{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTQ1NDkwMjk1", "number": 1739, "title": "HelixBootstrapTool changes to support InstanceConfig-To-PropertyStore migration", "bodyText": "Ambry will eventually migrate datanode info (i.e. disk, replica) from InstanceConfig to PropertyStore in Helix. This PR makes several changes in HelixBootstrapUpgradeTool to support both. User should be able to specify which DataNodeConfigSource type to use and the tool will update Helix accordingly.", "createdAt": "2020-12-25T01:21:40Z", "url": "https://github.com/linkedin/ambry/pull/1739", "merged": true, "mergeCommit": {"oid": "27ab4078b123a4ae79962cef31ab8c4721bd55e0"}, "closed": true, "closedAt": "2021-02-01T20:27:06Z", "author": {"login": "jsjtzyy"}, "timelineItems": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdpd4LGAH2gAyNTQ1NDkwMjk1OjdlNjE5NTkzYmZlY2QzY2I5NmRlN2QzYmZkNDhiYTNiOTU1Y2QzZDg=", "endCursor": "Y3Vyc29yOnYyOpPPAAABd19G0sgFqTU4MDczNTk3OA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "7e619593bfecd3cb96de7d3bfd48ba3b955cd3d8", "author": {"user": {"login": "jsjtzyy", "name": "Yingyi Zhang"}}, "url": "https://github.com/linkedin/ambry/commit/7e619593bfecd3cb96de7d3bfd48ba3b955cd3d8", "committedDate": "2020-12-25T01:16:44Z", "message": "HelixBootstrapTool changes to support InstanceConfig-To-PropertyStore migration\n\nAmbry will eventually migrate datanode info (i.e. disk, replica) from InstanceConfig to PropertyStore in Helix. This PR makes\nseveral changes in HelixBootstrapUpgradeTool to support both. User should be able to specify which DataNodeConfigSource type\nto use and the tool will update Helix accordingly."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8cd6dfa2656684c0fe7465bbef771f05f0296563", "author": {"user": {"login": "jsjtzyy", "name": "Yingyi Zhang"}}, "url": "https://github.com/linkedin/ambry/commit/8cd6dfa2656684c0fe7465bbef771f05f0296563", "committedDate": "2020-12-25T07:00:49Z", "message": "make listSealedPartition and validateCluster support dataNodeConfig in PropertyStore"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e21a7e0dcb4826945f2186175ba1d62bc3391034", "author": {"user": {"login": "jsjtzyy", "name": "Yingyi Zhang"}}, "url": "https://github.com/linkedin/ambry/commit/e21a7e0dcb4826945f2186175ba1d62bc3391034", "committedDate": "2020-12-27T07:24:12Z", "message": "changes in unit test and integration test"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYzOTEzMDc0", "url": "https://github.com/linkedin/ambry/pull/1739#pullrequestreview-563913074", "createdAt": "2021-01-07T23:56:58Z", "commit": {"oid": "e21a7e0dcb4826945f2186175ba1d62bc3391034"}, "state": "APPROVED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wN1QyMzo1Njo1OVrOIQA1ZQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQyMTo1NzowOVrOIZ8KsQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzY2MTc5Nw==", "bodyText": "commented?", "url": "https://github.com/linkedin/ambry/pull/1739#discussion_r553661797", "createdAt": "2021-01-07T23:56:59Z", "author": {"login": "cgtz"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixParticipant.java", "diffHunk": "@@ -366,7 +366,7 @@ private boolean addNewReplicaInfo(ReplicaId replicaId) {\n       newReplicaInfoAdded = true;\n     }\n     if (newReplicaInfoAdded) {\n-      logger.info(\"Updating config: {} in Helix by adding partition {}\", dataNodeConfig, partitionName);\n+      //logger.info(\"Updating config: {} in Helix by adding partition {}\", dataNodeConfig, partitionName);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e21a7e0dcb4826945f2186175ba1d62bc3391034"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzY2MjE0Nw==", "bodyText": "how about having this return a boolean like the set method?", "url": "https://github.com/linkedin/ambry/pull/1739#discussion_r553662147", "createdAt": "2021-01-07T23:58:06Z", "author": {"login": "cgtz"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/PropertyStoreToDataNodeConfigAdapter.java", "diffHunk": "@@ -88,6 +88,22 @@ public void close() {\n     propertyStore.stop();\n   }\n \n+  /**\n+   * Remove data config from property store\n+   * @param instanceName the name of instance\n+   */\n+  public void remove(String instanceName) {\n+    propertyStore.remove(CONFIG_PATH + \"/\" + instanceName, AccessOption.PERSISTENT);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e21a7e0dcb4826945f2186175ba1d62bc3391034"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzY2MzU1OQ==", "bodyText": "is the sorting for readability/ease of debugging?", "url": "https://github.com/linkedin/ambry/pull/1739#discussion_r553663559", "createdAt": "2021-01-08T00:02:55Z", "author": {"login": "cgtz"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfig.java", "diffHunk": "@@ -37,7 +38,7 @@\n   private final Set<String> sealedReplicas = new HashSet<>();\n   private final Set<String> stoppedReplicas = new HashSet<>();\n   private final Set<String> disabledReplicas = new HashSet<>();\n-  private final Map<String, DiskConfig> diskConfigs = new HashMap<>();\n+  private final Map<String, DiskConfig> diskConfigs = new TreeMap<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e21a7e0dcb4826945f2186175ba1d62bc3391034"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDA3MTA4OQ==", "bodyText": "Maybe we could move this method into DataNodeConfig\npublic boolean equals(DataNodeConfig other, boolean ignorePartitionStateConfigs) (or whatever name you feel is best for the sealed/stopped/disabled fields)", "url": "https://github.com/linkedin/ambry/pull/1739#discussion_r564071089", "createdAt": "2021-01-25T21:57:09Z", "author": {"login": "cgtz"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixBootstrapUpgradeUtil.java", "diffHunk": "@@ -929,90 +942,185 @@ private void updateClusterMapInHelix(boolean startValidatingClusterManager) thro\n    *                                  given datacenter.\n    */\n   private void addUpdateInstances(String dcName, Map<String, Set<String>> partitionsToInstancesInDc) {\n-    HelixAdmin dcAdmin = adminForDc.get(dcName);\n-    info(\"[{}] Getting list of instances in {}\", dcName.toUpperCase(), dcName);\n-    Set<String> instancesInHelix = new HashSet<>(dcAdmin.getInstancesInCluster(clusterName));\n-    Set<String> instancesInStatic = dcToInstanceNameToDataNodeId.get(dcName) == null ? new HashSet<>()\n-        : new HashSet<>(dcToInstanceNameToDataNodeId.get(dcName).keySet());\n-    Set<String> instancesInBoth = new HashSet<>(instancesInHelix);\n-    // set instances in both correctly.\n-    instancesInBoth.retainAll(instancesInStatic);\n-    // set instances in Helix only correctly.\n-    instancesInHelix.removeAll(instancesInBoth);\n-    // set instances in Static only correctly.\n-    instancesInStatic.removeAll(instancesInBoth);\n-    int totalInstances = instancesInBoth.size() + instancesInHelix.size() + instancesInStatic.size();\n-    for (String instanceName : instancesInBoth) {\n-      InstanceConfig instanceConfigInHelix = dcAdmin.getInstanceConfig(clusterName, instanceName);\n-      InstanceConfig instanceConfigFromStatic =\n-          createInstanceConfigFromStaticInfo(dcToInstanceNameToDataNodeId.get(dcName).get(instanceName),\n-              partitionsToInstancesInDc, instanceToDiskReplicasMap, instanceConfigInHelix);\n-      if (!instanceConfigFromStatic.getRecord().equals(instanceConfigInHelix.getRecord())) {\n-        if (helixAdminOperation == HelixAdminOperation.BootstrapCluster) {\n+    ClusterMapConfig config = getClusterMapConfig(clusterName, dcName, null);\n+    String zkConnectStr = dataCenterToZkAddress.get(dcName).getZkConnectStrs().get(0);\n+    try (PropertyStoreToDataNodeConfigAdapter propertyStoreAdapter = new PropertyStoreToDataNodeConfigAdapter(\n+        zkConnectStr, config)) {\n+      InstanceConfigToDataNodeConfigAdapter.Converter instanceConfigConverter =\n+          new InstanceConfigToDataNodeConfigAdapter.Converter(config);\n+      info(\"[{}] Getting list of instances in {}\", dcName.toUpperCase(), dcName);\n+      Set<String> instancesInHelix = new HashSet<>(getInstanceNamesInHelix(dcName, propertyStoreAdapter));\n+      Set<String> instancesInStatic = dcToInstanceNameToDataNodeId.get(dcName) == null ? new HashSet<>() : new HashSet<>(dcToInstanceNameToDataNodeId.get(dcName).keySet());\n+      Set<String> instancesInBoth = new HashSet<>(instancesInHelix);\n+      // set instances in both correctly.\n+      instancesInBoth.retainAll(instancesInStatic);\n+      // set instances in Helix only correctly.\n+      instancesInHelix.removeAll(instancesInBoth);\n+      // set instances in Static only correctly.\n+      instancesInStatic.removeAll(instancesInBoth);\n+      int totalInstances = instancesInBoth.size() + instancesInHelix.size() + instancesInStatic.size();\n+      for (String instanceName : instancesInBoth) {\n+        DataNodeConfig nodeConfigFromHelix = getDataNodeConfigFromHelix(dcName, instanceName, propertyStoreAdapter, instanceConfigConverter);\n+        DataNodeConfig nodeConfigFromStatic =\n+            createDataNodeConfigFromStatic(dcName, instanceName, nodeConfigFromHelix, partitionsToInstancesInDc,\n+                instanceConfigConverter);\n+        if (!areDataNodeConfigsEquivalent(nodeConfigFromStatic, nodeConfigFromHelix, !overrideReplicaStatus)) {\n+          if (helixAdminOperation == HelixAdminOperation.BootstrapCluster) {\n+            if (!dryRun) {\n+              info(\n+                  \"[{}] Instance {} already present in Helix {}, but config has changed, updating. Remaining instances: {}\",\n+                  dcName.toUpperCase(), instanceName, dataNodeConfigSourceType.name(), --totalInstances);\n+              // Continuing on the note above, if there is indeed a change, we must make a call on whether RO/RW, replica\n+              // availability and so on should be updated at all (if not, nodeConfigFromStatic should be replaced with\n+              // the appropriate dataNodeConfig that is constructed with the correct values from both).\n+              // For now, only bootstrapping cluster is allowed to directly change DataNodeConfig\n+              setDataNodeConfigInHelix(dcName, instanceName, nodeConfigFromStatic, propertyStoreAdapter,\n+                  instanceConfigConverter);\n+            } else {\n+              info(\n+                  \"[{}] Instance {} already present in Helix {}, but config has changed, no action as dry run. Remaining instances: {}\",\n+                  dcName.toUpperCase(), instanceName, dataNodeConfigSourceType.name(), --totalInstances);\n+              logger.debug(\"[{}] Previous config: {} \\n New config: {}\", dcName.toUpperCase(),\n+                  nodeConfigFromHelix, nodeConfigFromStatic);\n+            }\n+            // for dryRun, we update counter but don't really change the DataNodeConfig in Helix\n+            instancesUpdated.getAndIncrement();\n+          }\n+        } else {\n           if (!dryRun) {\n-            info(\n-                \"[{}] Instance {} already present in Helix, but InstanceConfig has changed, updating. Remaining instances: {}\",\n-                dcName.toUpperCase(), instanceName, --totalInstances);\n-            // Continuing on the note above, if there is indeed a change, we must make a call on whether RO/RW, replica\n-            // availability and so on should be updated at all (if not, instanceConfigFromStatic should be replaced with\n-            // the appropriate instanceConfig that is constructed with the correct values from both).\n-            // For now, only bootstrapping cluster is allowed to directly change InstanceConfig\n-            dcAdmin.setInstanceConfig(clusterName, instanceName, instanceConfigFromStatic);\n-          } else {\n-            info(\n-                \"[{}] Instance {} already present in Helix, but InstanceConfig has changed, no action as dry run. Remaining instances: {}\",\n-                dcName.toUpperCase(), instanceName, --totalInstances);\n-            logger.debug(\"[{}] Previous instanceConfig: {} \\n New InstanceConfig: {}\", dcName.toUpperCase(),\n-                instanceConfigInHelix.getRecord(), instanceConfigFromStatic.getRecord());\n+            info(\"[{}] Instance {} already present in Helix {}, with same Data, skipping. Remaining instances: {}\", dcName.toUpperCase(), instanceName, --totalInstances);\n           }\n-          // for dryRun, we update counter but don't really change the InstanceConfig in Helix\n-          instancesUpdated.getAndIncrement();\n-        }\n-      } else {\n-        if (!dryRun) {\n-          info(\"[{}] Instance {} already present in Helix, with same InstanceConfig, skipping. Remaining instances: {}\",\n-              dcName.toUpperCase(), instanceName, --totalInstances);\n         }\n       }\n-    }\n \n-    for (String instanceName : instancesInStatic) {\n-      InstanceConfig instanceConfigFromStatic =\n-          createInstanceConfigFromStaticInfo(dcToInstanceNameToDataNodeId.get(dcName).get(instanceName),\n-              partitionsToInstancesInDc, instanceToDiskReplicasMap, null);\n-      info(\"[{}] Instance {} is new, {}. Remaining instances: {}\", dcName.toUpperCase(), instanceName,\n-          dryRun ? \"no action as dry run\" : \"adding to Helix\", --totalInstances);\n-      // Note: for now, if we want to move replica to new instance (not present in cluster yet), we should take two steps:\n-      // step1: add new instance (empty) to cluster, which is a regular bootstrap; step2: add replica to IdealState\n-      // Helix controller will notify new instance to perform replica addition.\n-      if (helixAdminOperation == HelixAdminOperation.BootstrapCluster) {\n-        if (!dryRun) {\n-          dcAdmin.addInstance(clusterName, instanceConfigFromStatic);\n+      for (String instanceName : instancesInStatic) {\n+        DataNodeConfig nodeConfigFromStatic =\n+            createDataNodeConfigFromStatic(dcName, instanceName, null, partitionsToInstancesInDc,\n+                instanceConfigConverter);\n+        info(\"[{}] Instance {} is new, {}. Remaining instances: {}\", dcName.toUpperCase(), instanceName,\n+            dryRun ? \"no action as dry run\" : \"adding to Helix \" + dataNodeConfigSourceType.name(), --totalInstances);\n+        // Note: if we want to move replica to new instance (not present in cluster yet), we can prepare a transient\n+        // clustermap in which we keep existing replicas and add new replicas/instances. We should be able to upgrade cluster\n+        // normally (update both datanode configs and IdealState). Helix controller will notify new instance to perform\n+        // replica addition.\n+        if (helixAdminOperation == HelixAdminOperation.BootstrapCluster) {\n+          if (!dryRun) {\n+            addDataNodeConfigToHelix(dcName, nodeConfigFromStatic, propertyStoreAdapter, instanceConfigConverter);\n+          }\n+          instancesAdded.getAndIncrement();\n         }\n-        instancesAdded.getAndIncrement();\n       }\n-    }\n \n-    for (String instanceName : instancesInHelix) {\n-      if (forceRemove) {\n-        info(\"[{}] Instance {} is in Helix, but not in static. {}. Remaining instances: {}\", dcName.toUpperCase(),\n-            instanceName, dryRun ? \"No action as dry run\" : \"Forcefully removing\", --totalInstances);\n-        if (helixAdminOperation == HelixAdminOperation.BootstrapCluster) {\n-          if (!dryRun) {\n-            dcAdmin.dropInstance(clusterName, new InstanceConfig(instanceName));\n+      for (String instanceName : instancesInHelix) {\n+        if (forceRemove) {\n+          info(\"[{}] Instance {} is in Helix {}, but not in static. {}. Remaining instances: {}\", dcName.toUpperCase(),\n+              instanceName, dataNodeConfigSourceType.name(), dryRun ? \"No action as dry run\" : \"Forcefully removing\",\n+              --totalInstances);\n+          if (helixAdminOperation == HelixAdminOperation.BootstrapCluster) {\n+            if (!dryRun) {\n+              removeDataNodeConfigFromHelix(dcName, instanceName, propertyStoreAdapter);\n+            }\n+            instancesDropped.getAndIncrement();\n           }\n-          instancesDropped.getAndIncrement();\n+        } else {\n+          info(\n+              \"[{}] Instance {} is in Helix {}, but not in static. Ignoring for now (use --forceRemove to forcefully remove). \"\n+                  + \"Remaining instances: {}\", dcName.toUpperCase(), instanceName, dataNodeConfigSourceType.name(),\n+              --totalInstances);\n+          expectMoreInHelixDuringValidate = true;\n+          instancesNotForceRemovedByDc.computeIfAbsent(dcName, k -> ConcurrentHashMap.newKeySet()).add(instanceName);\n         }\n-      } else {\n-        info(\n-            \"[{}] Instance {} is in Helix, but not in static. Ignoring for now (use --forceRemove to forcefully remove). \"\n-                + \"Remaining instances: {}\", dcName.toUpperCase(), instanceName, --totalInstances);\n-        expectMoreInHelixDuringValidate = true;\n-        instancesNotForceRemovedByDc.computeIfAbsent(dcName, k -> ConcurrentHashMap.newKeySet()).add(instanceName);\n       }\n     }\n   }\n \n+  private List<String> getInstanceNamesInHelix(String dcName, PropertyStoreToDataNodeConfigAdapter adapter) {\n+    List<String> instanceNames;\n+    if (dataNodeConfigSourceType == DataNodeConfigSourceType.PROPERTY_STORE) {\n+      instanceNames = adapter.getAllDataNodeNames();\n+    } else {\n+      instanceNames = adminForDc.get(dcName).getInstancesInCluster(clusterName);\n+    }\n+    return instanceNames;\n+  }\n+\n+  private DataNodeConfig createDataNodeConfigFromStatic(String dcName, String instanceName,\n+      DataNodeConfig referenceConfig, Map<String, Set<String>> partitionsToInstancesInDc,\n+      InstanceConfigToDataNodeConfigAdapter.Converter converter) {\n+    InstanceConfig referenceInstanceConfig =\n+        overrideReplicaStatus || referenceConfig == null ? null : converter.convert(referenceConfig);\n+    return converter.convert(\n+        createInstanceConfigFromStaticInfo(dcToInstanceNameToDataNodeId.get(dcName).get(instanceName),\n+            partitionsToInstancesInDc, instanceToDiskReplicasMap, referenceInstanceConfig));\n+  }\n+\n+  private DataNodeConfig getDataNodeConfigFromHelix(String dcName, String instanceName,\n+      PropertyStoreToDataNodeConfigAdapter adapter, InstanceConfigToDataNodeConfigAdapter.Converter converter) {\n+    DataNodeConfig dataNodeConfig;\n+    if (dataNodeConfigSourceType == DataNodeConfigSourceType.PROPERTY_STORE) {\n+      dataNodeConfig = adapter.get(instanceName);\n+    } else {\n+      dataNodeConfig = converter.convert(adminForDc.get(dcName).getInstanceConfig(clusterName, instanceName));\n+    }\n+    return dataNodeConfig;\n+  }\n+\n+  private boolean areDataNodeConfigsEquivalent(DataNodeConfig configInStatic, DataNodeConfig configInHelix,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e21a7e0dcb4826945f2186175ba1d62bc3391034"}, "originalPosition": 345}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6b450651cfced56f46ae2b6163bab2a1d8ca2e35", "author": {"user": {"login": "jsjtzyy", "name": "Yingyi Zhang"}}, "url": "https://github.com/linkedin/ambry/commit/6b450651cfced56f46ae2b6163bab2a1d8ca2e35", "committedDate": "2021-02-01T18:52:17Z", "message": "address comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTgwNzIzODI4", "url": "https://github.com/linkedin/ambry/pull/1739#pullrequestreview-580723828", "createdAt": "2021-02-01T20:10:48Z", "commit": {"oid": "6b450651cfced56f46ae2b6163bab2a1d8ca2e35"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTgwNzM1OTc4", "url": "https://github.com/linkedin/ambry/pull/1739#pullrequestreview-580735978", "createdAt": "2021-02-01T20:26:53Z", "commit": {"oid": "6b450651cfced56f46ae2b6163bab2a1d8ca2e35"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1069, "cost": 1, "resetAt": "2021-11-01T16:19:10Z"}}}