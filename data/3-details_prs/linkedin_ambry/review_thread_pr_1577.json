{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDM5NTQ1NzU3", "number": 1577, "reviewThreads": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwNDo0MzoyNVrOEPZL0Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwNToyODoxMlrOEPZopA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NTc2NzIxOnYy", "diffSide": "RIGHT", "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixFactory.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwNDo0MzoyNVrOGzFKAQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxNzo1MTowM1rOGzb8Gw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjIxNTA0MQ==", "bodyText": "I was thinking to use concurrent hashmap for this part but then realized that handling exception in lambda expression would be complicated (we might have to implement ThrowBiFunction and convert exception to runtime exception which is not elegant).", "url": "https://github.com/linkedin/ambry/pull/1577#discussion_r456215041", "createdAt": "2020-07-17T04:43:25Z", "author": {"login": "jsjtzyy"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixFactory.java", "diffHunk": "@@ -33,15 +40,73 @@\n    */\n   public HelixManager getZKHelixManager(String clusterName, String instanceName, InstanceType instanceType,\n       String zkAddr) {\n-    return HelixManagerFactory.getZKHelixManager(clusterName, instanceName, instanceType, zkAddr);\n+    ManagerKey managerKey = new ManagerKey(clusterName, instanceName, instanceType, zkAddr);\n+    return helixManagers.computeIfAbsent(managerKey,\n+        k -> HelixManagerFactory.getZKHelixManager(clusterName, instanceName, instanceType, zkAddr));\n   }\n \n   /**\n-   * Get a reference to a {@link HelixAdmin}\n+   * Get a reference to a {@link HelixManager} and connect to it, if not already connected\n+   * @param clusterName the name of the cluster for which the manager is to be gotten.\n+   * @param instanceName the name of the instance on whose behalf the manager is to be gotten.\n+   * @param instanceType the {@link InstanceType} of the requester.\n    * @param zkAddr the address identifying the zk service to which this request is to be made.\n-   * @return the constructed {@link HelixAdmin}.\n+   * @return the constructed and connected {@link HelixManager}.\n+   * @throws Exception if connecting failed.\n+   */\n+  public HelixManager getZkHelixManagerAndConnect(String clusterName, String instanceName, InstanceType instanceType,\n+      String zkAddr) throws Exception {\n+    HelixManager manager = getZKHelixManager(clusterName, instanceName, instanceType, zkAddr);\n+    synchronized (manager) {\n+      if (!manager.isConnected()) {\n+        LOGGER.info(\"Connecting to HelixManager at {}\", zkAddr);\n+        manager.connect();\n+        LOGGER.info(\"Established connection to HelixManager at {}\", zkAddr);\n+      } else {\n+        LOGGER.info(\"HelixManager at {} already connected\", zkAddr);\n+      }\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "22705eeb8f9c757bc367e4a626171842f9029e29"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjIxNjk0NQ==", "bodyText": "Is there any case where two threads are attempting connecting same HelixManager concurrently?", "url": "https://github.com/linkedin/ambry/pull/1577#discussion_r456216945", "createdAt": "2020-07-17T04:51:03Z", "author": {"login": "jsjtzyy"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixFactory.java", "diffHunk": "@@ -33,15 +40,73 @@\n    */\n   public HelixManager getZKHelixManager(String clusterName, String instanceName, InstanceType instanceType,\n       String zkAddr) {\n-    return HelixManagerFactory.getZKHelixManager(clusterName, instanceName, instanceType, zkAddr);\n+    ManagerKey managerKey = new ManagerKey(clusterName, instanceName, instanceType, zkAddr);\n+    return helixManagers.computeIfAbsent(managerKey,\n+        k -> HelixManagerFactory.getZKHelixManager(clusterName, instanceName, instanceType, zkAddr));\n   }\n \n   /**\n-   * Get a reference to a {@link HelixAdmin}\n+   * Get a reference to a {@link HelixManager} and connect to it, if not already connected\n+   * @param clusterName the name of the cluster for which the manager is to be gotten.\n+   * @param instanceName the name of the instance on whose behalf the manager is to be gotten.\n+   * @param instanceType the {@link InstanceType} of the requester.\n    * @param zkAddr the address identifying the zk service to which this request is to be made.\n-   * @return the constructed {@link HelixAdmin}.\n+   * @return the constructed and connected {@link HelixManager}.\n+   * @throws Exception if connecting failed.\n+   */\n+  public HelixManager getZkHelixManagerAndConnect(String clusterName, String instanceName, InstanceType instanceType,\n+      String zkAddr) throws Exception {\n+    HelixManager manager = getZKHelixManager(clusterName, instanceName, instanceType, zkAddr);\n+    synchronized (manager) {\n+      if (!manager.isConnected()) {\n+        LOGGER.info(\"Connecting to HelixManager at {}\", zkAddr);\n+        manager.connect();\n+        LOGGER.info(\"Established connection to HelixManager at {}\", zkAddr);\n+      } else {\n+        LOGGER.info(\"HelixManager at {} already connected\", zkAddr);\n+      }\n+    }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjIxNTA0MQ=="}, "originalCommit": {"oid": "22705eeb8f9c757bc367e4a626171842f9029e29"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjUzNjUwMg==", "bodyText": "There should not be such a case in production since we would never start HelixClusterManager and HelixFactory in parallel. I put this here since there is nothing that strictly guarantees that will always be the case. If you feel that this is unneeded for now I could take it out.\nWe could move this into a Map.compute lambda, but I felt that this approach allowed for finer grained locking as we don't need the construction and connection to be atomic, we just need to make sure that after construction and adding to the map, only one thread does the check connected, connect sequence at a time.", "url": "https://github.com/linkedin/ambry/pull/1577#discussion_r456536502", "createdAt": "2020-07-17T16:07:20Z", "author": {"login": "cgtz"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixFactory.java", "diffHunk": "@@ -33,15 +40,73 @@\n    */\n   public HelixManager getZKHelixManager(String clusterName, String instanceName, InstanceType instanceType,\n       String zkAddr) {\n-    return HelixManagerFactory.getZKHelixManager(clusterName, instanceName, instanceType, zkAddr);\n+    ManagerKey managerKey = new ManagerKey(clusterName, instanceName, instanceType, zkAddr);\n+    return helixManagers.computeIfAbsent(managerKey,\n+        k -> HelixManagerFactory.getZKHelixManager(clusterName, instanceName, instanceType, zkAddr));\n   }\n \n   /**\n-   * Get a reference to a {@link HelixAdmin}\n+   * Get a reference to a {@link HelixManager} and connect to it, if not already connected\n+   * @param clusterName the name of the cluster for which the manager is to be gotten.\n+   * @param instanceName the name of the instance on whose behalf the manager is to be gotten.\n+   * @param instanceType the {@link InstanceType} of the requester.\n    * @param zkAddr the address identifying the zk service to which this request is to be made.\n-   * @return the constructed {@link HelixAdmin}.\n+   * @return the constructed and connected {@link HelixManager}.\n+   * @throws Exception if connecting failed.\n+   */\n+  public HelixManager getZkHelixManagerAndConnect(String clusterName, String instanceName, InstanceType instanceType,\n+      String zkAddr) throws Exception {\n+    HelixManager manager = getZKHelixManager(clusterName, instanceName, instanceType, zkAddr);\n+    synchronized (manager) {\n+      if (!manager.isConnected()) {\n+        LOGGER.info(\"Connecting to HelixManager at {}\", zkAddr);\n+        manager.connect();\n+        LOGGER.info(\"Established connection to HelixManager at {}\", zkAddr);\n+      } else {\n+        LOGGER.info(\"HelixManager at {} already connected\", zkAddr);\n+      }\n+    }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjIxNTA0MQ=="}, "originalCommit": {"oid": "22705eeb8f9c757bc367e4a626171842f9029e29"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU4ODMxNQ==", "bodyText": "I am okay with this approach after more clarification. Let's keep it as it is.", "url": "https://github.com/linkedin/ambry/pull/1577#discussion_r456588315", "createdAt": "2020-07-17T17:51:03Z", "author": {"login": "jsjtzyy"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixFactory.java", "diffHunk": "@@ -33,15 +40,73 @@\n    */\n   public HelixManager getZKHelixManager(String clusterName, String instanceName, InstanceType instanceType,\n       String zkAddr) {\n-    return HelixManagerFactory.getZKHelixManager(clusterName, instanceName, instanceType, zkAddr);\n+    ManagerKey managerKey = new ManagerKey(clusterName, instanceName, instanceType, zkAddr);\n+    return helixManagers.computeIfAbsent(managerKey,\n+        k -> HelixManagerFactory.getZKHelixManager(clusterName, instanceName, instanceType, zkAddr));\n   }\n \n   /**\n-   * Get a reference to a {@link HelixAdmin}\n+   * Get a reference to a {@link HelixManager} and connect to it, if not already connected\n+   * @param clusterName the name of the cluster for which the manager is to be gotten.\n+   * @param instanceName the name of the instance on whose behalf the manager is to be gotten.\n+   * @param instanceType the {@link InstanceType} of the requester.\n    * @param zkAddr the address identifying the zk service to which this request is to be made.\n-   * @return the constructed {@link HelixAdmin}.\n+   * @return the constructed and connected {@link HelixManager}.\n+   * @throws Exception if connecting failed.\n+   */\n+  public HelixManager getZkHelixManagerAndConnect(String clusterName, String instanceName, InstanceType instanceType,\n+      String zkAddr) throws Exception {\n+    HelixManager manager = getZKHelixManager(clusterName, instanceName, instanceType, zkAddr);\n+    synchronized (manager) {\n+      if (!manager.isConnected()) {\n+        LOGGER.info(\"Connecting to HelixManager at {}\", zkAddr);\n+        manager.connect();\n+        LOGGER.info(\"Established connection to HelixManager at {}\", zkAddr);\n+      } else {\n+        LOGGER.info(\"HelixManager at {} already connected\", zkAddr);\n+      }\n+    }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjIxNTA0MQ=="}, "originalCommit": {"oid": "22705eeb8f9c757bc367e4a626171842f9029e29"}, "originalPosition": 57}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NTc4MjU1OnYy", "diffSide": "RIGHT", "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixParticipant.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwNDo1Mjo0MFrOGzFSyQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwNDo1Mjo0MFrOGzFSyQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjIxNzI4OQ==", "bodyText": "nit: formate this file, thanks", "url": "https://github.com/linkedin/ambry/pull/1577#discussion_r456217289", "createdAt": "2020-07-17T04:52:40Z", "author": {"login": "jsjtzyy"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixParticipant.java", "diffHunk": "@@ -21,7 +21,6 @@\n import com.github.ambry.utils.Utils;\n import java.io.IOException;\n import java.util.ArrayList;\n-import java.util.Arrays;\n import java.util.Collection;\n import java.util.Collections;\n import java.util.HashMap;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "22705eeb8f9c757bc367e4a626171842f9029e29"}, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NTgyODM0OnYy", "diffSide": "RIGHT", "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixParticipant.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwNToyMDo1NFrOGzFtOA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwNToyMDo1NFrOGzFtOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjIyNDA1Ng==", "bodyText": "minor: skipping removing it from config in Helix.\"", "url": "https://github.com/linkedin/ambry/pull/1577#discussion_r456224056", "createdAt": "2020-07-17T05:20:54Z", "author": {"login": "jsjtzyy"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixParticipant.java", "diffHunk": "@@ -279,135 +278,81 @@ public void setReplicaDisabledState(ReplicaId replicaId, boolean disable) {\n \n       // 3. set InstanceConfig in Helix to persist replica disabled state\n       helixAdmin.setInstanceConfig(clusterName, instanceName, instanceConfig);\n+      // TODO Have this method use DataNodeConfig for disabled replicas and InstanceConfig for enabled instances.\n       logger.info(\"Disabled state of partition {} is updated\", partitionName);\n     }\n   }\n \n   /**\n+   * Exposed for testing\n    * @return {@link HelixAdmin} that manages current data node.\n    */\n   public HelixAdmin getHelixAdmin() {\n     return helixAdmin;\n   }\n \n   /**\n-   * Add new replica info into {@link InstanceConfig} of current data node.\n-   * @param replicaId new replica whose info should be added into {@link InstanceConfig}.\n-   * @param instanceConfig the {@link InstanceConfig} to update.\n+   * Add new replica info into {@link DataNodeConfig} of current data node.\n+   * @param replicaId new replica whose info should be added into {@link DataNodeConfig}.\n+   * @param dataNodeConfig the {@link DataNodeConfig} to update.\n    * @return {@code true} replica info is successfully added. {@code false} otherwise.\n    */\n-  private boolean addNewReplicaInfo(ReplicaId replicaId, InstanceConfig instanceConfig) {\n+  private boolean addNewReplicaInfo(ReplicaId replicaId, DataNodeConfig dataNodeConfig) {\n     boolean additionResult = true;\n     String partitionName = replicaId.getPartitionId().toPathString();\n-    String newReplicaInfo =\n-        String.join(REPLICAS_STR_SEPARATOR, partitionName, String.valueOf(replicaId.getCapacityInBytes()),\n-            replicaId.getPartitionId().getPartitionClass()) + REPLICAS_DELIM_STR;\n-    Map<String, Map<String, String>> mountPathToDiskInfos = instanceConfig.getRecord().getMapFields();\n-    Map<String, String> diskInfo = mountPathToDiskInfos.get(replicaId.getMountPath());\n+    DataNodeConfig.ReplicaConfig replicaConfigToAdd = new DataNodeConfig.ReplicaConfig(replicaId.getCapacityInBytes(),\n+        replicaId.getPartitionId().getPartitionClass());\n+    DataNodeConfig.DiskConfig diskConfig = dataNodeConfig.getDiskConfigs().get(replicaId.getMountPath());\n     boolean newReplicaInfoAdded = false;\n-    boolean duplicateFound = false;\n-    if (diskInfo != null) {\n-      // add replica to an existing disk (need to sort replicas by partition id)\n-      String replicasStr = diskInfo.get(REPLICAS_STR);\n-      String[] replicaInfos = replicasStr.split(REPLICAS_DELIM_STR);\n-      StringBuilder replicasStrBuilder = new StringBuilder();\n-      long idToAdd = Long.parseLong(partitionName);\n-      for (String replicaInfo : replicaInfos) {\n-        String[] infos = replicaInfo.split(REPLICAS_STR_SEPARATOR);\n-        long currentId = Long.parseLong(infos[0]);\n-        if (currentId == idToAdd) {\n-          logger.info(\"Partition {} is already on instance {}, skipping adding it into InstanceConfig in Helix.\",\n-              partitionName, instanceName);\n-          duplicateFound = true;\n-          break;\n-        } else if (currentId < idToAdd || newReplicaInfoAdded) {\n-          replicasStrBuilder.append(replicaInfo).append(REPLICAS_DELIM_STR);\n-        } else {\n-          // newReplicaInfo already contains delimiter, no need to append REPLICAS_DELIM_STR\n-          replicasStrBuilder.append(newReplicaInfo);\n-          replicasStrBuilder.append(replicaInfo).append(REPLICAS_DELIM_STR);\n-          newReplicaInfoAdded = true;\n-        }\n-      }\n-      if (!duplicateFound && !newReplicaInfoAdded) {\n-        // this means new replica id is larger than all existing replicas' ids\n-        replicasStrBuilder.append(newReplicaInfo);\n+    if (diskConfig != null) {\n+      // add replica to an existing disk\n+      if (diskConfig.getReplicaConfigs().containsKey(partitionName)) {\n+        logger.info(\"Partition {} is already on instance {}, skipping adding it into configs in Helix.\", partitionName,\n+            instanceName);\n+      } else {\n+        diskConfig.getReplicaConfigs().put(partitionName, replicaConfigToAdd);\n         newReplicaInfoAdded = true;\n       }\n-      if (newReplicaInfoAdded) {\n-        diskInfo.put(REPLICAS_STR, replicasStrBuilder.toString());\n-        mountPathToDiskInfos.put(replicaId.getMountPath(), diskInfo);\n-      }\n     } else {\n       // add replica onto a brand new disk\n       logger.info(\"Adding info of new replica {} to the new disk {}\", replicaId.getPartitionId().toPathString(),\n           replicaId.getDiskId());\n-      Map<String, String> diskInfoToAdd = new HashMap<>();\n-      diskInfoToAdd.put(DISK_CAPACITY_STR, Long.toString(replicaId.getDiskId().getRawCapacityInBytes()));\n-      diskInfoToAdd.put(DISK_STATE, AVAILABLE_STR);\n-      diskInfoToAdd.put(REPLICAS_STR, newReplicaInfo);\n-      mountPathToDiskInfos.put(replicaId.getMountPath(), diskInfoToAdd);\n+      DataNodeConfig.DiskConfig diskConfigToAdd =\n+          new DataNodeConfig.DiskConfig(HardwareState.AVAILABLE, replicaId.getDiskId().getRawCapacityInBytes());\n+      diskConfigToAdd.getReplicaConfigs().put(partitionName, replicaConfigToAdd);\n+      dataNodeConfig.getDiskConfigs().put(replicaId.getMountPath(), diskConfigToAdd);\n       newReplicaInfoAdded = true;\n     }\n     if (newReplicaInfoAdded) {\n-      // we update InstanceConfig only when new replica info is added (skip updating if replica is already present)\n-      instanceConfig.getRecord().setMapFields(mountPathToDiskInfos);\n-      logger.info(\"Updating config: {} in Helix by adding partition {}\", instanceConfig, partitionName);\n-      additionResult = helixAdmin.setInstanceConfig(clusterName, instanceName, instanceConfig);\n+      logger.info(\"Updating config: {} in Helix by adding partition {}\", dataNodeConfig, partitionName);\n+      additionResult = dataNodeConfigSource.set(dataNodeConfig);\n     }\n     return additionResult;\n   }\n \n   /**\n-   * Remove old/existing replica info from {@link InstanceConfig} that associates with current data node.\n+   * Remove old/existing replica info from {@link DataNodeConfig} that associates with current data node.\n    * @param replicaId the {@link ReplicaId} whose info should be removed.\n-   * @param instanceConfig {@link InstanceConfig} to update.\n+   * @param dataNodeConfig {@link DataNodeConfig} to update.\n    * @return {@code true} replica info is successfully removed. {@code false} otherwise.\n    */\n-  private boolean removeOldReplicaInfo(ReplicaId replicaId, InstanceConfig instanceConfig) {\n+  private boolean removeOldReplicaInfo(ReplicaId replicaId, DataNodeConfig dataNodeConfig) {\n     boolean removalResult = true;\n-    boolean instanceConfigUpdated = false;\n-    boolean replicaFound;\n+    boolean dataNodeConfigUpdated = false;\n     String partitionName = replicaId.getPartitionId().toPathString();\n-    List<String> stoppedReplicas = instanceConfig.getRecord().getListField(STOPPED_REPLICAS_STR);\n-    List<String> sealedReplicas = instanceConfig.getRecord().getListField(SEALED_STR);\n-    stoppedReplicas = stoppedReplicas == null ? new ArrayList<>() : stoppedReplicas;\n-    sealedReplicas = sealedReplicas == null ? new ArrayList<>() : sealedReplicas;\n-    if (stoppedReplicas.remove(partitionName) || sealedReplicas.remove(partitionName)) {\n+    boolean removedFromStopped = dataNodeConfig.getStoppedReplicas().remove(partitionName);\n+    boolean removedFromSealed = dataNodeConfig.getSealedReplicas().remove(partitionName);\n+    if (removedFromStopped || removedFromSealed) {\n       logger.info(\"Removing partition {} from stopped and sealed list\", partitionName);\n-      instanceConfig.getRecord().setListField(STOPPED_REPLICAS_STR, stoppedReplicas);\n-      instanceConfig.getRecord().setListField(SEALED_STR, sealedReplicas);\n-      instanceConfigUpdated = true;\n+      dataNodeConfigUpdated = true;\n     }\n-    Map<String, Map<String, String>> mountPathToDiskInfos = instanceConfig.getRecord().getMapFields();\n-    Map<String, String> diskInfo = mountPathToDiskInfos.get(replicaId.getMountPath());\n-    if (diskInfo != null) {\n-      String replicasStr = diskInfo.get(REPLICAS_STR);\n-      if (!replicasStr.isEmpty()) {\n-        List<String> replicaInfos = new ArrayList<>(Arrays.asList(replicasStr.split(REPLICAS_DELIM_STR)));\n-        // if any element is removed, that means old replica is found in replicasStr.\n-        replicaFound = replicaInfos.removeIf(info -> (info.split(REPLICAS_STR_SEPARATOR)[0]).equals(partitionName));\n-\n-        // We update InstanceConfig only when replica is found in current instanceConfig. (This is to avoid unnecessary\n-        // notification traffic due to InstanceConfig change)\n-        if (replicaFound) {\n-          StringBuilder newReplicasStrBuilder = new StringBuilder();\n-          // note that old replica info has been removed from \"replicaInfos\"\n-          for (String replicaInfo : replicaInfos) {\n-            newReplicasStrBuilder.append(replicaInfo).append(REPLICAS_DELIM_STR);\n-          }\n-          // update diskInfo and MountPathToDisk map\n-          diskInfo.put(REPLICAS_STR, newReplicasStrBuilder.toString());\n-          mountPathToDiskInfos.put(replicaId.getMountPath(), diskInfo);\n-          // update InstanceConfig\n-          instanceConfig.getRecord().setMapFields(mountPathToDiskInfos);\n-          instanceConfigUpdated = true;\n-        }\n-      }\n+    DataNodeConfig.DiskConfig diskConfig = dataNodeConfig.getDiskConfigs().get(replicaId.getMountPath());\n+    if (diskConfig != null) {\n+      dataNodeConfigUpdated = diskConfig.getReplicaConfigs().remove(partitionName) != null;\n     }\n-    if (instanceConfigUpdated) {\n-      logger.info(\"Updating config: {} in Helix by removing partition {}\", instanceConfig, partitionName);\n-      removalResult = helixAdmin.setInstanceConfig(clusterName, instanceName, instanceConfig);\n+    if (dataNodeConfigUpdated) {\n+      logger.info(\"Updating config: {} in Helix by removing partition {}\", dataNodeConfig, partitionName);\n+      removalResult = dataNodeConfigSource.set(dataNodeConfig);\n     } else {\n       logger.warn(\"Partition {} is not found on instance {}, skipping removing it from InstanceConfig in Helix.\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "22705eeb8f9c757bc367e4a626171842f9029e29"}, "originalPosition": 317}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NTgzODMyOnYy", "diffSide": "RIGHT", "path": "ambry-clustermap/src/test/java/com/github/ambry/clustermap/InstanceConfigToDataNodeConfigAdapterTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwNToyNjoyMlrOGzFzFQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwNToyNjoyMlrOGzFzFQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjIyNTU1Nw==", "bodyText": "minor: new line", "url": "https://github.com/linkedin/ambry/pull/1577#discussion_r456225557", "createdAt": "2020-07-17T05:26:22Z", "author": {"login": "jsjtzyy"}, "path": "ambry-clustermap/src/test/java/com/github/ambry/clustermap/InstanceConfigToDataNodeConfigAdapterTest.java", "diffHunk": "@@ -109,10 +108,5 @@ public void testSetGetListener() throws Exception {\n       assertEquals(\"get() call returned incorrect result\", config, source.get(config.getInstanceName()));\n     }\n     assertNull(\"Should not receive non-existent instance\", source.get(\"abc\"));\n-\n-    source.setHelixAdmin(null);\n-    TestUtils.assertException(NullPointerException.class, () -> source.set(createConfig(1, 1)), null);\n-    String firstInstance = allConfigs.iterator().next().getInstanceName();\n-    TestUtils.assertException(NullPointerException.class, () -> source.get(firstInstance), null);\n   }\n }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "22705eeb8f9c757bc367e4a626171842f9029e29"}, "originalPosition": 18}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NTg0MTAwOnYy", "diffSide": "RIGHT", "path": "ambry-clustermap/src/test/java/com/github/ambry/clustermap/MockHelixAdmin.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwNToyODoxMlrOGzF0ww==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwNToyODoxMlrOGzF0ww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjIyNTk4Nw==", "bodyText": "Package private? (If this method will be called in int-test, just ignore this comment)", "url": "https://github.com/linkedin/ambry/pull/1577#discussion_r456225987", "createdAt": "2020-07-17T05:28:12Z", "author": {"login": "jsjtzyy"}, "path": "ambry-clustermap/src/test/java/com/github/ambry/clustermap/MockHelixAdmin.java", "diffHunk": "@@ -398,6 +400,13 @@ long getTotalDiskCapacity() {\n     return totalDiskCapacity;\n   }\n \n+  /**\n+   * @return the number of calls to the {@link #setInstanceConfig} method.\n+   */\n+  public int getSetInstanceConfigCallCount() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "22705eeb8f9c757bc367e4a626171842f9029e29"}, "originalPosition": 23}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1297, "cost": 1, "resetAt": "2021-11-12T20:44:06Z"}}}