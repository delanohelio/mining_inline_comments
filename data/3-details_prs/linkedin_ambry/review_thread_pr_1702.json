{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTI2MDA4Mjc3", "number": 1702, "reviewThreads": {"totalCount": 15, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxNzoxMToyN1rOE81oaw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQwMDo0Nzo0MlrOE9b8RA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyMjI4NzE1OnYy", "diffSide": "RIGHT", "path": "ambry-api/src/main/java/com/github/ambry/clustermap/ClusterParticipant.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxNzoxMToyOFrOH5M1pg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxNzoxMToyOFrOH5M1pg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTc0MTIyMg==", "bodyText": "javadoc", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r529741222", "createdAt": "2020-11-24T17:11:28Z", "author": {"login": "cgtz"}, "path": "ambry-api/src/main/java/com/github/ambry/clustermap/ClusterParticipant.java", "diffHunk": "@@ -32,10 +33,12 @@\n   /**\n    * Initiate the participation of cluster participant.\n    * @param ambryHealthReports {@link List} of {@link AmbryHealthReport} to be registered to the participant.\n+   * @param accountStatsStore", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyMjMxMDI4OnYy", "diffSide": "RIGHT", "path": "ambry-api/src/main/java/com/github/ambry/server/AccountStatsStore.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxNzoxNjo0OVrOH5NDyg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxOToxOTowOFrOH6A8Mg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTc0NDg0Mg==", "bodyText": "why are the account/container IDs in string format instead of Integer? Also, I remember their being another format where the stats report is grouped by partition class. Is that handled somewhere else?", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r529744842", "createdAt": "2020-11-24T17:16:49Z", "author": {"login": "cgtz"}, "path": "ambry-api/src/main/java/com/github/ambry/server/AccountStatsStore.java", "diffHunk": "@@ -0,0 +1,97 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.server;\n+\n+import java.util.Map;\n+\n+\n+/**\n+ * The interface that stores and fetches account stats, aggregated account stats.\n+ */\n+public interface AccountStatsStore {\n+  /**\n+   * Store stats in the {@link StatsWrapper}. The StatsWrapper's {@link StatsSnapshot} should include partition, account\n+   * and container. This method will be used for individual ambry server to store local stats.\n+   * @param statsWrapper The {@link StatsWrapper} that contains stats and other metadata.\n+   */\n+  void storeStats(StatsWrapper statsWrapper);\n+\n+  /**\n+   * Store aggregated stats in the {@link StatsSnapshot}. The StatsSnapshot should include account and container. This\n+   * method will be used for aggregation task to store aggregated stats.\n+   * @param snapshot The {@link StatsSnapshot} that contains aggregated container usage.\n+   * @throws Exception\n+   */\n+  void storeAggregatedStats(StatsSnapshot snapshot) throws Exception;\n+\n+  /**\n+   * Return individual ambry server's stats for the given {@code clusterName} and {@code hostname}. This is the stats\n+   * stored by method {@link #storeStats}.\n+   * @param clusterName The clusterName.\n+   * @param hostname The hostname.\n+   * @return {@link StatsWrapper} of given {@code hostname} in the {@code clusterName}.\n+   * @throws Exception\n+   */\n+  StatsWrapper queryStatsOf(String clusterName, String hostname) throws Exception;\n+\n+  /**\n+   * Return the aggregated stats for the given {@code clusterName}. This is the stats stored by method {@link #storeAggregatedStats}.\n+   * Since the {@link StatsSnapshot} passed to {@link #storeAggregatedStats} only have account and container stats, this\n+   * method returns a map back to the caller. The key of the outer map is the account id in string format, and the key of\n+   * the inner map is the container id in string format, the value of the inner map is the storage usage for this container.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDAyMzUyOA==", "bodyText": "I think it's because  the subMap in StatsSnapshot uses String type key (account/container and partition Id are converted to String when doing aggregation.)\nTalked with Justin offline, in the interest of time, partition class stats report won't be migrated this quarter. We probably will take this up next year.", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r530023528", "createdAt": "2020-11-25T00:06:41Z", "author": {"login": "jsjtzyy"}, "path": "ambry-api/src/main/java/com/github/ambry/server/AccountStatsStore.java", "diffHunk": "@@ -0,0 +1,97 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.server;\n+\n+import java.util.Map;\n+\n+\n+/**\n+ * The interface that stores and fetches account stats, aggregated account stats.\n+ */\n+public interface AccountStatsStore {\n+  /**\n+   * Store stats in the {@link StatsWrapper}. The StatsWrapper's {@link StatsSnapshot} should include partition, account\n+   * and container. This method will be used for individual ambry server to store local stats.\n+   * @param statsWrapper The {@link StatsWrapper} that contains stats and other metadata.\n+   */\n+  void storeStats(StatsWrapper statsWrapper);\n+\n+  /**\n+   * Store aggregated stats in the {@link StatsSnapshot}. The StatsSnapshot should include account and container. This\n+   * method will be used for aggregation task to store aggregated stats.\n+   * @param snapshot The {@link StatsSnapshot} that contains aggregated container usage.\n+   * @throws Exception\n+   */\n+  void storeAggregatedStats(StatsSnapshot snapshot) throws Exception;\n+\n+  /**\n+   * Return individual ambry server's stats for the given {@code clusterName} and {@code hostname}. This is the stats\n+   * stored by method {@link #storeStats}.\n+   * @param clusterName The clusterName.\n+   * @param hostname The hostname.\n+   * @return {@link StatsWrapper} of given {@code hostname} in the {@code clusterName}.\n+   * @throws Exception\n+   */\n+  StatsWrapper queryStatsOf(String clusterName, String hostname) throws Exception;\n+\n+  /**\n+   * Return the aggregated stats for the given {@code clusterName}. This is the stats stored by method {@link #storeAggregatedStats}.\n+   * Since the {@link StatsSnapshot} passed to {@link #storeAggregatedStats} only have account and container stats, this\n+   * method returns a map back to the caller. The key of the outer map is the account id in string format, and the key of\n+   * the inner map is the container id in string format, the value of the inner map is the storage usage for this container.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTc0NDg0Mg=="}, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDU5NDg2Ng==", "bodyText": "Second Yingyi's comments. The partition class stats will be handled next quarter.", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r530594866", "createdAt": "2020-11-25T19:19:08Z", "author": {"login": "justinlin-linkedin"}, "path": "ambry-api/src/main/java/com/github/ambry/server/AccountStatsStore.java", "diffHunk": "@@ -0,0 +1,97 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.server;\n+\n+import java.util.Map;\n+\n+\n+/**\n+ * The interface that stores and fetches account stats, aggregated account stats.\n+ */\n+public interface AccountStatsStore {\n+  /**\n+   * Store stats in the {@link StatsWrapper}. The StatsWrapper's {@link StatsSnapshot} should include partition, account\n+   * and container. This method will be used for individual ambry server to store local stats.\n+   * @param statsWrapper The {@link StatsWrapper} that contains stats and other metadata.\n+   */\n+  void storeStats(StatsWrapper statsWrapper);\n+\n+  /**\n+   * Store aggregated stats in the {@link StatsSnapshot}. The StatsSnapshot should include account and container. This\n+   * method will be used for aggregation task to store aggregated stats.\n+   * @param snapshot The {@link StatsSnapshot} that contains aggregated container usage.\n+   * @throws Exception\n+   */\n+  void storeAggregatedStats(StatsSnapshot snapshot) throws Exception;\n+\n+  /**\n+   * Return individual ambry server's stats for the given {@code clusterName} and {@code hostname}. This is the stats\n+   * stored by method {@link #storeStats}.\n+   * @param clusterName The clusterName.\n+   * @param hostname The hostname.\n+   * @return {@link StatsWrapper} of given {@code hostname} in the {@code clusterName}.\n+   * @throws Exception\n+   */\n+  StatsWrapper queryStatsOf(String clusterName, String hostname) throws Exception;\n+\n+  /**\n+   * Return the aggregated stats for the given {@code clusterName}. This is the stats stored by method {@link #storeAggregatedStats}.\n+   * Since the {@link StatsSnapshot} passed to {@link #storeAggregatedStats} only have account and container stats, this\n+   * method returns a map back to the caller. The key of the outer map is the account id in string format, and the key of\n+   * the inner map is the container id in string format, the value of the inner map is the storage usage for this container.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTc0NDg0Mg=="}, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyMjM0MDQ5OnYy", "diffSide": "RIGHT", "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixClusterAggregator.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxNzoyMzo1N1rOH5NWbA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxOToxOTozNlrOH6A9Fg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTc0OTYxMg==", "bodyText": "What was the purpose of this piece of code resetting exceptionOccuredInstances for a given type again? Sorry, I'm not up to date on this.", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r529749612", "createdAt": "2020-11-24T17:23:57Z", "author": {"login": "cgtz"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixClusterAggregator.java", "diffHunk": "@@ -53,33 +54,59 @@\n    * for each partition.\n    * @throws IOException\n    */\n-  Pair<StatsSnapshot, StatsSnapshot> doWork(Map<String, String> statsWrappersJSON, StatsReportType type) throws IOException {\n+  Pair<StatsSnapshot, StatsSnapshot> doWork(Map<String, String> statsWrappersJSON, StatsReportType type)\n+      throws IOException {\n+    Map<String, StatsWrapper> statsWrappers = new HashMap<>();\n+    for (Map.Entry<String, String> statsWrapperJSON : statsWrappersJSON.entrySet()) {\n+      try {\n+        if (statsWrapperJSON != null && statsWrapperJSON.getValue() != null) {\n+          StatsWrapper snapshotWrapper = mapper.readValue(statsWrapperJSON.getValue(), StatsWrapper.class);\n+          statsWrappers.put(statsWrapperJSON.getKey(), snapshotWrapper);\n+        }\n+      } catch (Exception e) {\n+        logger.error(\"Exception occurred while processing stats from {}\", statsWrapperJSON.getKey(), e);\n+        exceptionOccurredInstances.computeIfAbsent(type, key -> new ArrayList<>()).add(statsWrapperJSON.getKey());\n+      }\n+    }\n+    return doWorkOnStatsWrapperMap(statsWrappers, type, false);\n+  }\n+\n+  Pair<StatsSnapshot, StatsSnapshot> doWorkOnStatsWrapperMap(Map<String, StatsWrapper> statsWrappers,\n+      StatsReportType type) throws IOException {\n+    return doWorkOnStatsWrapperMap(statsWrappers, type, true);\n+  }\n+\n+  Pair<StatsSnapshot, StatsSnapshot> doWorkOnStatsWrapperMap(Map<String, StatsWrapper> statsWrappers,\n+      StatsReportType type, boolean removeExceptionOnType) throws IOException {\n     StatsSnapshot partitionSnapshot = new StatsSnapshot(0L, new HashMap<>());\n     Map<String, Long> partitionTimestampMap = new HashMap<>();\n     StatsSnapshot rawPartitionSnapshot = new StatsSnapshot(0L, new HashMap<>());\n-    exceptionOccurredInstances.remove(type);\n-    for (Map.Entry<String, String> statsWrapperJSON : statsWrappersJSON.entrySet()) {\n-      if (statsWrapperJSON != null && statsWrapperJSON.getValue() != null) {\n+    if (removeExceptionOnType) {\n+      exceptionOccurredInstances.remove(type);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDEyMTIyMw==", "bodyText": "I added this exceptionOccurredInstances.remove(type); because same node may be chose to do aggregation twice and it resets the map for given type to clean up old data from last round.", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r530121223", "createdAt": "2020-11-25T05:45:56Z", "author": {"login": "jsjtzyy"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixClusterAggregator.java", "diffHunk": "@@ -53,33 +54,59 @@\n    * for each partition.\n    * @throws IOException\n    */\n-  Pair<StatsSnapshot, StatsSnapshot> doWork(Map<String, String> statsWrappersJSON, StatsReportType type) throws IOException {\n+  Pair<StatsSnapshot, StatsSnapshot> doWork(Map<String, String> statsWrappersJSON, StatsReportType type)\n+      throws IOException {\n+    Map<String, StatsWrapper> statsWrappers = new HashMap<>();\n+    for (Map.Entry<String, String> statsWrapperJSON : statsWrappersJSON.entrySet()) {\n+      try {\n+        if (statsWrapperJSON != null && statsWrapperJSON.getValue() != null) {\n+          StatsWrapper snapshotWrapper = mapper.readValue(statsWrapperJSON.getValue(), StatsWrapper.class);\n+          statsWrappers.put(statsWrapperJSON.getKey(), snapshotWrapper);\n+        }\n+      } catch (Exception e) {\n+        logger.error(\"Exception occurred while processing stats from {}\", statsWrapperJSON.getKey(), e);\n+        exceptionOccurredInstances.computeIfAbsent(type, key -> new ArrayList<>()).add(statsWrapperJSON.getKey());\n+      }\n+    }\n+    return doWorkOnStatsWrapperMap(statsWrappers, type, false);\n+  }\n+\n+  Pair<StatsSnapshot, StatsSnapshot> doWorkOnStatsWrapperMap(Map<String, StatsWrapper> statsWrappers,\n+      StatsReportType type) throws IOException {\n+    return doWorkOnStatsWrapperMap(statsWrappers, type, true);\n+  }\n+\n+  Pair<StatsSnapshot, StatsSnapshot> doWorkOnStatsWrapperMap(Map<String, StatsWrapper> statsWrappers,\n+      StatsReportType type, boolean removeExceptionOnType) throws IOException {\n     StatsSnapshot partitionSnapshot = new StatsSnapshot(0L, new HashMap<>());\n     Map<String, Long> partitionTimestampMap = new HashMap<>();\n     StatsSnapshot rawPartitionSnapshot = new StatsSnapshot(0L, new HashMap<>());\n-    exceptionOccurredInstances.remove(type);\n-    for (Map.Entry<String, String> statsWrapperJSON : statsWrappersJSON.entrySet()) {\n-      if (statsWrapperJSON != null && statsWrapperJSON.getValue() != null) {\n+    if (removeExceptionOnType) {\n+      exceptionOccurredInstances.remove(type);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTc0OTYxMg=="}, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDEyNTE5Mw==", "bodyText": "Minor: For MySqlAggregator, it is correct; For HelixAggregator, I would suggest putting it to the very beginning of doWork().", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r530125193", "createdAt": "2020-11-25T05:59:32Z", "author": {"login": "jsjtzyy"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixClusterAggregator.java", "diffHunk": "@@ -53,33 +54,59 @@\n    * for each partition.\n    * @throws IOException\n    */\n-  Pair<StatsSnapshot, StatsSnapshot> doWork(Map<String, String> statsWrappersJSON, StatsReportType type) throws IOException {\n+  Pair<StatsSnapshot, StatsSnapshot> doWork(Map<String, String> statsWrappersJSON, StatsReportType type)\n+      throws IOException {\n+    Map<String, StatsWrapper> statsWrappers = new HashMap<>();\n+    for (Map.Entry<String, String> statsWrapperJSON : statsWrappersJSON.entrySet()) {\n+      try {\n+        if (statsWrapperJSON != null && statsWrapperJSON.getValue() != null) {\n+          StatsWrapper snapshotWrapper = mapper.readValue(statsWrapperJSON.getValue(), StatsWrapper.class);\n+          statsWrappers.put(statsWrapperJSON.getKey(), snapshotWrapper);\n+        }\n+      } catch (Exception e) {\n+        logger.error(\"Exception occurred while processing stats from {}\", statsWrapperJSON.getKey(), e);\n+        exceptionOccurredInstances.computeIfAbsent(type, key -> new ArrayList<>()).add(statsWrapperJSON.getKey());\n+      }\n+    }\n+    return doWorkOnStatsWrapperMap(statsWrappers, type, false);\n+  }\n+\n+  Pair<StatsSnapshot, StatsSnapshot> doWorkOnStatsWrapperMap(Map<String, StatsWrapper> statsWrappers,\n+      StatsReportType type) throws IOException {\n+    return doWorkOnStatsWrapperMap(statsWrappers, type, true);\n+  }\n+\n+  Pair<StatsSnapshot, StatsSnapshot> doWorkOnStatsWrapperMap(Map<String, StatsWrapper> statsWrappers,\n+      StatsReportType type, boolean removeExceptionOnType) throws IOException {\n     StatsSnapshot partitionSnapshot = new StatsSnapshot(0L, new HashMap<>());\n     Map<String, Long> partitionTimestampMap = new HashMap<>();\n     StatsSnapshot rawPartitionSnapshot = new StatsSnapshot(0L, new HashMap<>());\n-    exceptionOccurredInstances.remove(type);\n-    for (Map.Entry<String, String> statsWrapperJSON : statsWrappersJSON.entrySet()) {\n-      if (statsWrapperJSON != null && statsWrapperJSON.getValue() != null) {\n+    if (removeExceptionOnType) {\n+      exceptionOccurredInstances.remove(type);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTc0OTYxMg=="}, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDU5NTA5NA==", "bodyText": "Trying to not change anywhere unnecessary to this PR.", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r530595094", "createdAt": "2020-11-25T19:19:36Z", "author": {"login": "justinlin-linkedin"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixClusterAggregator.java", "diffHunk": "@@ -53,33 +54,59 @@\n    * for each partition.\n    * @throws IOException\n    */\n-  Pair<StatsSnapshot, StatsSnapshot> doWork(Map<String, String> statsWrappersJSON, StatsReportType type) throws IOException {\n+  Pair<StatsSnapshot, StatsSnapshot> doWork(Map<String, String> statsWrappersJSON, StatsReportType type)\n+      throws IOException {\n+    Map<String, StatsWrapper> statsWrappers = new HashMap<>();\n+    for (Map.Entry<String, String> statsWrapperJSON : statsWrappersJSON.entrySet()) {\n+      try {\n+        if (statsWrapperJSON != null && statsWrapperJSON.getValue() != null) {\n+          StatsWrapper snapshotWrapper = mapper.readValue(statsWrapperJSON.getValue(), StatsWrapper.class);\n+          statsWrappers.put(statsWrapperJSON.getKey(), snapshotWrapper);\n+        }\n+      } catch (Exception e) {\n+        logger.error(\"Exception occurred while processing stats from {}\", statsWrapperJSON.getKey(), e);\n+        exceptionOccurredInstances.computeIfAbsent(type, key -> new ArrayList<>()).add(statsWrapperJSON.getKey());\n+      }\n+    }\n+    return doWorkOnStatsWrapperMap(statsWrappers, type, false);\n+  }\n+\n+  Pair<StatsSnapshot, StatsSnapshot> doWorkOnStatsWrapperMap(Map<String, StatsWrapper> statsWrappers,\n+      StatsReportType type) throws IOException {\n+    return doWorkOnStatsWrapperMap(statsWrappers, type, true);\n+  }\n+\n+  Pair<StatsSnapshot, StatsSnapshot> doWorkOnStatsWrapperMap(Map<String, StatsWrapper> statsWrappers,\n+      StatsReportType type, boolean removeExceptionOnType) throws IOException {\n     StatsSnapshot partitionSnapshot = new StatsSnapshot(0L, new HashMap<>());\n     Map<String, Long> partitionTimestampMap = new HashMap<>();\n     StatsSnapshot rawPartitionSnapshot = new StatsSnapshot(0L, new HashMap<>());\n-    exceptionOccurredInstances.remove(type);\n-    for (Map.Entry<String, String> statsWrapperJSON : statsWrappersJSON.entrySet()) {\n-      if (statsWrapperJSON != null && statsWrapperJSON.getValue() != null) {\n+    if (removeExceptionOnType) {\n+      exceptionOccurredInstances.remove(type);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTc0OTYxMg=="}, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 44}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyMjM2MTk2OnYy", "diffSide": "RIGHT", "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/MySqlReportAggregatorTask.java", "isResolved": false, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxNzoyODozOVrOH5NjUQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQwMjo0ODowOVrOH6KA6g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTc1MjkxMw==", "bodyText": "this may not be 100% accurate for a local deployment where multiple processes share the same host name but different ports.", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r529752913", "createdAt": "2020-11-24T17:28:39Z", "author": {"login": "cgtz"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/MySqlReportAggregatorTask.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.clustermap;\n+\n+import com.github.ambry.commons.Callback;\n+import com.github.ambry.config.ClusterMapConfig;\n+import com.github.ambry.server.AccountStatsStore;\n+import com.github.ambry.server.StatsReportType;\n+import com.github.ambry.server.StatsSnapshot;\n+import com.github.ambry.server.StatsWrapper;\n+import com.github.ambry.utils.Pair;\n+import com.github.ambry.utils.SystemTime;\n+import com.github.ambry.utils.Time;\n+import java.time.LocalDateTime;\n+import java.time.ZoneId;\n+import java.time.ZoneOffset;\n+import java.time.format.DateTimeFormatter;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.helix.HelixManager;\n+import org.apache.helix.task.Task;\n+import org.apache.helix.task.TaskResult;\n+import org.apache.helix.task.UserContentStore;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * MySql task to aggregate container storage usage across all storage nodes and update the aggregated stats.\n+ */\n+public class MySqlReportAggregatorTask extends UserContentStore implements Task {\n+  public static final String TASK_COMMAND_PREFIX = \"mysql_aggregate\";\n+  private static final Logger logger = LoggerFactory.getLogger(MySqlReportAggregatorTask.class);\n+  private static final ZoneOffset zoneOffset = ZoneId.systemDefault().getRules().getOffset(LocalDateTime.now());\n+  static final DateTimeFormatter TIMESTAMP_FORMATTER = DateTimeFormatter.ofPattern(\"yyyy-MM\");\n+  private final HelixClusterAggregator clusterAggregator;\n+  private final HelixManager manager;\n+  private final StatsReportType statsReportType;\n+  private final Callback<StatsSnapshot> callback;\n+  private final ClusterMapConfig clusterMapConfig;\n+  private final AccountStatsStore accountStatsStore;\n+  private final Time time;\n+\n+  /**\n+   * Instantiates {@link MySqlReportAggregatorTask}.\n+   * @param manager The {@link HelixManager} to retrieve all storage nodes.\n+   * @param relevantTimePeriodInMs relevant time period in ms within which values are considered to be valid. Values\n+   *                               outside of this period will be ignored.\n+   * @param statsReportType the type of stats report\n+   * @param accountStatsStore The {@link AccountStatsStore} to retrieve stats and store aggregated stats.\n+   * @param callback a callback which will be invoked when the aggregation report has been generated successfully.\n+   * @param clusterMapConfig the {@link ClusterMapConfig} associated with helix participant.\n+   */\n+  MySqlReportAggregatorTask(HelixManager manager, long relevantTimePeriodInMs, StatsReportType statsReportType,\n+      AccountStatsStore accountStatsStore, Callback<StatsSnapshot> callback, ClusterMapConfig clusterMapConfig) {\n+    this(manager, relevantTimePeriodInMs, statsReportType, accountStatsStore, callback, clusterMapConfig,\n+        SystemTime.getInstance());\n+  }\n+\n+  MySqlReportAggregatorTask(HelixManager manager, long relevantTimePeriodInMs, StatsReportType statsReportType,\n+      AccountStatsStore accountStatsStore, Callback<StatsSnapshot> callback, ClusterMapConfig clusterMapConfig,\n+      Time time) {\n+    this.manager = manager;\n+    clusterAggregator = new HelixClusterAggregator(relevantTimePeriodInMs);\n+    this.statsReportType = statsReportType;\n+    this.accountStatsStore = accountStatsStore;\n+    this.callback = callback;\n+    this.clusterMapConfig = clusterMapConfig;\n+    this.time = time;\n+  }\n+\n+  @Override\n+  public TaskResult run() {\n+    Pair<StatsSnapshot, StatsSnapshot> results = null;\n+    Exception exception = null;\n+    try {\n+      List<String> instanceNames = manager.getClusterManagmentTool().getInstancesInCluster(manager.getClusterName());\n+      Map<String, StatsWrapper> statsWrappers = new HashMap<>();\n+      for (String instanceName : instanceNames) {\n+        // Helix instance name would suffix port number, here let's take port number out.\n+        instanceName = stripPortNumber(instanceName);\n+        statsWrappers.put(instanceName,\n+            accountStatsStore.queryStatsOf(clusterMapConfig.clusterMapClusterName, instanceName));\n+      }\n+      results = clusterAggregator.doWorkOnStatsWrapperMap(statsWrappers, statsReportType);\n+      accountStatsStore.storeAggregatedStats(results.getSecond());\n+      // Create a base report at the beginning of each month.\n+      // Check if there is a base report for this month or not.\n+      if (clusterMapConfig.clustermapEnableAggregatedMonthlyAccountReport\n+          && statsReportType == StatsReportType.ACCOUNT_REPORT) {\n+        // Get the month, if not the same month, then copy the aggregated stats and update the month\n+        String currentMonthValue =\n+            LocalDateTime.ofEpochSecond(time.seconds(), 0, zoneOffset).format(TIMESTAMP_FORMATTER);\n+        String recordedMonthValue = accountStatsStore.queryRecordedMonth(clusterMapConfig.clusterMapClusterName);\n+        if (recordedMonthValue == null || recordedMonthValue.isEmpty() || !currentMonthValue.equals(\n+            recordedMonthValue)) {\n+          accountStatsStore.takeSnapshotOfAggregatedStatsSetMonth(clusterMapConfig.clusterMapClusterName,\n+              currentMonthValue);\n+        }\n+      }\n+      return new TaskResult(TaskResult.Status.COMPLETED, \"Aggregation success\");\n+    } catch (Exception e) {\n+      logger.error(\"Exception thrown while aggregating stats from health reports across all nodes \", e);\n+      exception = e;\n+      return new TaskResult(TaskResult.Status.FAILED, \"Exception thrown\");\n+    } finally {\n+      if (clusterMapConfig.clustermapEnableContainerDeletionAggregation && callback != null && results != null\n+          && statsReportType.equals(StatsReportType.ACCOUNT_REPORT)) {\n+        callback.onCompletion(results.getFirst(), exception);\n+      }\n+    }\n+  }\n+\n+  private String stripPortNumber(String instanceName) {\n+    return instanceName.replace(\"_\" + clusterMapConfig.clusterMapPort, \"\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 127}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDU5NjQzMQ==", "bodyText": "This method is just trying to get the hostname. I will append the port number later in the database method. So in helix the  instance name looks something like this ltx1-app12345.prod.linkedin.com_15999, but in the database, the hostname looks like ltx1-app12345.prod_15999. So I have to get the hostname first, remove the domain name and then append the port number. Even if we have several processes running at the same host, as long as their port numbers are different, it will be fine for database.", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r530596431", "createdAt": "2020-11-25T19:22:24Z", "author": {"login": "justinlin-linkedin"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/MySqlReportAggregatorTask.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.clustermap;\n+\n+import com.github.ambry.commons.Callback;\n+import com.github.ambry.config.ClusterMapConfig;\n+import com.github.ambry.server.AccountStatsStore;\n+import com.github.ambry.server.StatsReportType;\n+import com.github.ambry.server.StatsSnapshot;\n+import com.github.ambry.server.StatsWrapper;\n+import com.github.ambry.utils.Pair;\n+import com.github.ambry.utils.SystemTime;\n+import com.github.ambry.utils.Time;\n+import java.time.LocalDateTime;\n+import java.time.ZoneId;\n+import java.time.ZoneOffset;\n+import java.time.format.DateTimeFormatter;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.helix.HelixManager;\n+import org.apache.helix.task.Task;\n+import org.apache.helix.task.TaskResult;\n+import org.apache.helix.task.UserContentStore;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * MySql task to aggregate container storage usage across all storage nodes and update the aggregated stats.\n+ */\n+public class MySqlReportAggregatorTask extends UserContentStore implements Task {\n+  public static final String TASK_COMMAND_PREFIX = \"mysql_aggregate\";\n+  private static final Logger logger = LoggerFactory.getLogger(MySqlReportAggregatorTask.class);\n+  private static final ZoneOffset zoneOffset = ZoneId.systemDefault().getRules().getOffset(LocalDateTime.now());\n+  static final DateTimeFormatter TIMESTAMP_FORMATTER = DateTimeFormatter.ofPattern(\"yyyy-MM\");\n+  private final HelixClusterAggregator clusterAggregator;\n+  private final HelixManager manager;\n+  private final StatsReportType statsReportType;\n+  private final Callback<StatsSnapshot> callback;\n+  private final ClusterMapConfig clusterMapConfig;\n+  private final AccountStatsStore accountStatsStore;\n+  private final Time time;\n+\n+  /**\n+   * Instantiates {@link MySqlReportAggregatorTask}.\n+   * @param manager The {@link HelixManager} to retrieve all storage nodes.\n+   * @param relevantTimePeriodInMs relevant time period in ms within which values are considered to be valid. Values\n+   *                               outside of this period will be ignored.\n+   * @param statsReportType the type of stats report\n+   * @param accountStatsStore The {@link AccountStatsStore} to retrieve stats and store aggregated stats.\n+   * @param callback a callback which will be invoked when the aggregation report has been generated successfully.\n+   * @param clusterMapConfig the {@link ClusterMapConfig} associated with helix participant.\n+   */\n+  MySqlReportAggregatorTask(HelixManager manager, long relevantTimePeriodInMs, StatsReportType statsReportType,\n+      AccountStatsStore accountStatsStore, Callback<StatsSnapshot> callback, ClusterMapConfig clusterMapConfig) {\n+    this(manager, relevantTimePeriodInMs, statsReportType, accountStatsStore, callback, clusterMapConfig,\n+        SystemTime.getInstance());\n+  }\n+\n+  MySqlReportAggregatorTask(HelixManager manager, long relevantTimePeriodInMs, StatsReportType statsReportType,\n+      AccountStatsStore accountStatsStore, Callback<StatsSnapshot> callback, ClusterMapConfig clusterMapConfig,\n+      Time time) {\n+    this.manager = manager;\n+    clusterAggregator = new HelixClusterAggregator(relevantTimePeriodInMs);\n+    this.statsReportType = statsReportType;\n+    this.accountStatsStore = accountStatsStore;\n+    this.callback = callback;\n+    this.clusterMapConfig = clusterMapConfig;\n+    this.time = time;\n+  }\n+\n+  @Override\n+  public TaskResult run() {\n+    Pair<StatsSnapshot, StatsSnapshot> results = null;\n+    Exception exception = null;\n+    try {\n+      List<String> instanceNames = manager.getClusterManagmentTool().getInstancesInCluster(manager.getClusterName());\n+      Map<String, StatsWrapper> statsWrappers = new HashMap<>();\n+      for (String instanceName : instanceNames) {\n+        // Helix instance name would suffix port number, here let's take port number out.\n+        instanceName = stripPortNumber(instanceName);\n+        statsWrappers.put(instanceName,\n+            accountStatsStore.queryStatsOf(clusterMapConfig.clusterMapClusterName, instanceName));\n+      }\n+      results = clusterAggregator.doWorkOnStatsWrapperMap(statsWrappers, statsReportType);\n+      accountStatsStore.storeAggregatedStats(results.getSecond());\n+      // Create a base report at the beginning of each month.\n+      // Check if there is a base report for this month or not.\n+      if (clusterMapConfig.clustermapEnableAggregatedMonthlyAccountReport\n+          && statsReportType == StatsReportType.ACCOUNT_REPORT) {\n+        // Get the month, if not the same month, then copy the aggregated stats and update the month\n+        String currentMonthValue =\n+            LocalDateTime.ofEpochSecond(time.seconds(), 0, zoneOffset).format(TIMESTAMP_FORMATTER);\n+        String recordedMonthValue = accountStatsStore.queryRecordedMonth(clusterMapConfig.clusterMapClusterName);\n+        if (recordedMonthValue == null || recordedMonthValue.isEmpty() || !currentMonthValue.equals(\n+            recordedMonthValue)) {\n+          accountStatsStore.takeSnapshotOfAggregatedStatsSetMonth(clusterMapConfig.clusterMapClusterName,\n+              currentMonthValue);\n+        }\n+      }\n+      return new TaskResult(TaskResult.Status.COMPLETED, \"Aggregation success\");\n+    } catch (Exception e) {\n+      logger.error(\"Exception thrown while aggregating stats from health reports across all nodes \", e);\n+      exception = e;\n+      return new TaskResult(TaskResult.Status.FAILED, \"Exception thrown\");\n+    } finally {\n+      if (clusterMapConfig.clustermapEnableContainerDeletionAggregation && callback != null && results != null\n+          && statsReportType.equals(StatsReportType.ACCOUNT_REPORT)) {\n+        callback.onCompletion(results.getFirst(), exception);\n+      }\n+    }\n+  }\n+\n+  private String stripPortNumber(String instanceName) {\n+    return instanceName.replace(\"_\" + clusterMapConfig.clusterMapPort, \"\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTc1MjkxMw=="}, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 127}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDY1MjI0OQ==", "bodyText": "This seems like this would have problems removing the port number if different hosts in the cluster have different ports. For example, let's say the cluster has host1_1234 and host2_2345 and clusterMapConfig.clusterMapPort is set to 1234. Then, this method would work correctly for host1, but return host2_2345 for host2.\nMaybe it is better to split by underscore and take the first part of it.", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r530652249", "createdAt": "2020-11-25T21:30:56Z", "author": {"login": "cgtz"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/MySqlReportAggregatorTask.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.clustermap;\n+\n+import com.github.ambry.commons.Callback;\n+import com.github.ambry.config.ClusterMapConfig;\n+import com.github.ambry.server.AccountStatsStore;\n+import com.github.ambry.server.StatsReportType;\n+import com.github.ambry.server.StatsSnapshot;\n+import com.github.ambry.server.StatsWrapper;\n+import com.github.ambry.utils.Pair;\n+import com.github.ambry.utils.SystemTime;\n+import com.github.ambry.utils.Time;\n+import java.time.LocalDateTime;\n+import java.time.ZoneId;\n+import java.time.ZoneOffset;\n+import java.time.format.DateTimeFormatter;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.helix.HelixManager;\n+import org.apache.helix.task.Task;\n+import org.apache.helix.task.TaskResult;\n+import org.apache.helix.task.UserContentStore;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * MySql task to aggregate container storage usage across all storage nodes and update the aggregated stats.\n+ */\n+public class MySqlReportAggregatorTask extends UserContentStore implements Task {\n+  public static final String TASK_COMMAND_PREFIX = \"mysql_aggregate\";\n+  private static final Logger logger = LoggerFactory.getLogger(MySqlReportAggregatorTask.class);\n+  private static final ZoneOffset zoneOffset = ZoneId.systemDefault().getRules().getOffset(LocalDateTime.now());\n+  static final DateTimeFormatter TIMESTAMP_FORMATTER = DateTimeFormatter.ofPattern(\"yyyy-MM\");\n+  private final HelixClusterAggregator clusterAggregator;\n+  private final HelixManager manager;\n+  private final StatsReportType statsReportType;\n+  private final Callback<StatsSnapshot> callback;\n+  private final ClusterMapConfig clusterMapConfig;\n+  private final AccountStatsStore accountStatsStore;\n+  private final Time time;\n+\n+  /**\n+   * Instantiates {@link MySqlReportAggregatorTask}.\n+   * @param manager The {@link HelixManager} to retrieve all storage nodes.\n+   * @param relevantTimePeriodInMs relevant time period in ms within which values are considered to be valid. Values\n+   *                               outside of this period will be ignored.\n+   * @param statsReportType the type of stats report\n+   * @param accountStatsStore The {@link AccountStatsStore} to retrieve stats and store aggregated stats.\n+   * @param callback a callback which will be invoked when the aggregation report has been generated successfully.\n+   * @param clusterMapConfig the {@link ClusterMapConfig} associated with helix participant.\n+   */\n+  MySqlReportAggregatorTask(HelixManager manager, long relevantTimePeriodInMs, StatsReportType statsReportType,\n+      AccountStatsStore accountStatsStore, Callback<StatsSnapshot> callback, ClusterMapConfig clusterMapConfig) {\n+    this(manager, relevantTimePeriodInMs, statsReportType, accountStatsStore, callback, clusterMapConfig,\n+        SystemTime.getInstance());\n+  }\n+\n+  MySqlReportAggregatorTask(HelixManager manager, long relevantTimePeriodInMs, StatsReportType statsReportType,\n+      AccountStatsStore accountStatsStore, Callback<StatsSnapshot> callback, ClusterMapConfig clusterMapConfig,\n+      Time time) {\n+    this.manager = manager;\n+    clusterAggregator = new HelixClusterAggregator(relevantTimePeriodInMs);\n+    this.statsReportType = statsReportType;\n+    this.accountStatsStore = accountStatsStore;\n+    this.callback = callback;\n+    this.clusterMapConfig = clusterMapConfig;\n+    this.time = time;\n+  }\n+\n+  @Override\n+  public TaskResult run() {\n+    Pair<StatsSnapshot, StatsSnapshot> results = null;\n+    Exception exception = null;\n+    try {\n+      List<String> instanceNames = manager.getClusterManagmentTool().getInstancesInCluster(manager.getClusterName());\n+      Map<String, StatsWrapper> statsWrappers = new HashMap<>();\n+      for (String instanceName : instanceNames) {\n+        // Helix instance name would suffix port number, here let's take port number out.\n+        instanceName = stripPortNumber(instanceName);\n+        statsWrappers.put(instanceName,\n+            accountStatsStore.queryStatsOf(clusterMapConfig.clusterMapClusterName, instanceName));\n+      }\n+      results = clusterAggregator.doWorkOnStatsWrapperMap(statsWrappers, statsReportType);\n+      accountStatsStore.storeAggregatedStats(results.getSecond());\n+      // Create a base report at the beginning of each month.\n+      // Check if there is a base report for this month or not.\n+      if (clusterMapConfig.clustermapEnableAggregatedMonthlyAccountReport\n+          && statsReportType == StatsReportType.ACCOUNT_REPORT) {\n+        // Get the month, if not the same month, then copy the aggregated stats and update the month\n+        String currentMonthValue =\n+            LocalDateTime.ofEpochSecond(time.seconds(), 0, zoneOffset).format(TIMESTAMP_FORMATTER);\n+        String recordedMonthValue = accountStatsStore.queryRecordedMonth(clusterMapConfig.clusterMapClusterName);\n+        if (recordedMonthValue == null || recordedMonthValue.isEmpty() || !currentMonthValue.equals(\n+            recordedMonthValue)) {\n+          accountStatsStore.takeSnapshotOfAggregatedStatsSetMonth(clusterMapConfig.clusterMapClusterName,\n+              currentMonthValue);\n+        }\n+      }\n+      return new TaskResult(TaskResult.Status.COMPLETED, \"Aggregation success\");\n+    } catch (Exception e) {\n+      logger.error(\"Exception thrown while aggregating stats from health reports across all nodes \", e);\n+      exception = e;\n+      return new TaskResult(TaskResult.Status.FAILED, \"Exception thrown\");\n+    } finally {\n+      if (clusterMapConfig.clustermapEnableContainerDeletionAggregation && callback != null && results != null\n+          && statsReportType.equals(StatsReportType.ACCOUNT_REPORT)) {\n+        callback.onCompletion(results.getFirst(), exception);\n+      }\n+    }\n+  }\n+\n+  private String stripPortNumber(String instanceName) {\n+    return instanceName.replace(\"_\" + clusterMapConfig.clusterMapPort, \"\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTc1MjkxMw=="}, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 127}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDY1NzgzMA==", "bodyText": "But in different ambry server process, the port number in clustermap should be the port number that this process registered with helix cluster. If the cluster has host1_1234 and host2_2345, then the clustermap port number in host1 would be 1234 and the clustermap port number in host2 would be 2345.", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r530657830", "createdAt": "2020-11-25T21:45:47Z", "author": {"login": "justinlin-linkedin"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/MySqlReportAggregatorTask.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.clustermap;\n+\n+import com.github.ambry.commons.Callback;\n+import com.github.ambry.config.ClusterMapConfig;\n+import com.github.ambry.server.AccountStatsStore;\n+import com.github.ambry.server.StatsReportType;\n+import com.github.ambry.server.StatsSnapshot;\n+import com.github.ambry.server.StatsWrapper;\n+import com.github.ambry.utils.Pair;\n+import com.github.ambry.utils.SystemTime;\n+import com.github.ambry.utils.Time;\n+import java.time.LocalDateTime;\n+import java.time.ZoneId;\n+import java.time.ZoneOffset;\n+import java.time.format.DateTimeFormatter;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.helix.HelixManager;\n+import org.apache.helix.task.Task;\n+import org.apache.helix.task.TaskResult;\n+import org.apache.helix.task.UserContentStore;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * MySql task to aggregate container storage usage across all storage nodes and update the aggregated stats.\n+ */\n+public class MySqlReportAggregatorTask extends UserContentStore implements Task {\n+  public static final String TASK_COMMAND_PREFIX = \"mysql_aggregate\";\n+  private static final Logger logger = LoggerFactory.getLogger(MySqlReportAggregatorTask.class);\n+  private static final ZoneOffset zoneOffset = ZoneId.systemDefault().getRules().getOffset(LocalDateTime.now());\n+  static final DateTimeFormatter TIMESTAMP_FORMATTER = DateTimeFormatter.ofPattern(\"yyyy-MM\");\n+  private final HelixClusterAggregator clusterAggregator;\n+  private final HelixManager manager;\n+  private final StatsReportType statsReportType;\n+  private final Callback<StatsSnapshot> callback;\n+  private final ClusterMapConfig clusterMapConfig;\n+  private final AccountStatsStore accountStatsStore;\n+  private final Time time;\n+\n+  /**\n+   * Instantiates {@link MySqlReportAggregatorTask}.\n+   * @param manager The {@link HelixManager} to retrieve all storage nodes.\n+   * @param relevantTimePeriodInMs relevant time period in ms within which values are considered to be valid. Values\n+   *                               outside of this period will be ignored.\n+   * @param statsReportType the type of stats report\n+   * @param accountStatsStore The {@link AccountStatsStore} to retrieve stats and store aggregated stats.\n+   * @param callback a callback which will be invoked when the aggregation report has been generated successfully.\n+   * @param clusterMapConfig the {@link ClusterMapConfig} associated with helix participant.\n+   */\n+  MySqlReportAggregatorTask(HelixManager manager, long relevantTimePeriodInMs, StatsReportType statsReportType,\n+      AccountStatsStore accountStatsStore, Callback<StatsSnapshot> callback, ClusterMapConfig clusterMapConfig) {\n+    this(manager, relevantTimePeriodInMs, statsReportType, accountStatsStore, callback, clusterMapConfig,\n+        SystemTime.getInstance());\n+  }\n+\n+  MySqlReportAggregatorTask(HelixManager manager, long relevantTimePeriodInMs, StatsReportType statsReportType,\n+      AccountStatsStore accountStatsStore, Callback<StatsSnapshot> callback, ClusterMapConfig clusterMapConfig,\n+      Time time) {\n+    this.manager = manager;\n+    clusterAggregator = new HelixClusterAggregator(relevantTimePeriodInMs);\n+    this.statsReportType = statsReportType;\n+    this.accountStatsStore = accountStatsStore;\n+    this.callback = callback;\n+    this.clusterMapConfig = clusterMapConfig;\n+    this.time = time;\n+  }\n+\n+  @Override\n+  public TaskResult run() {\n+    Pair<StatsSnapshot, StatsSnapshot> results = null;\n+    Exception exception = null;\n+    try {\n+      List<String> instanceNames = manager.getClusterManagmentTool().getInstancesInCluster(manager.getClusterName());\n+      Map<String, StatsWrapper> statsWrappers = new HashMap<>();\n+      for (String instanceName : instanceNames) {\n+        // Helix instance name would suffix port number, here let's take port number out.\n+        instanceName = stripPortNumber(instanceName);\n+        statsWrappers.put(instanceName,\n+            accountStatsStore.queryStatsOf(clusterMapConfig.clusterMapClusterName, instanceName));\n+      }\n+      results = clusterAggregator.doWorkOnStatsWrapperMap(statsWrappers, statsReportType);\n+      accountStatsStore.storeAggregatedStats(results.getSecond());\n+      // Create a base report at the beginning of each month.\n+      // Check if there is a base report for this month or not.\n+      if (clusterMapConfig.clustermapEnableAggregatedMonthlyAccountReport\n+          && statsReportType == StatsReportType.ACCOUNT_REPORT) {\n+        // Get the month, if not the same month, then copy the aggregated stats and update the month\n+        String currentMonthValue =\n+            LocalDateTime.ofEpochSecond(time.seconds(), 0, zoneOffset).format(TIMESTAMP_FORMATTER);\n+        String recordedMonthValue = accountStatsStore.queryRecordedMonth(clusterMapConfig.clusterMapClusterName);\n+        if (recordedMonthValue == null || recordedMonthValue.isEmpty() || !currentMonthValue.equals(\n+            recordedMonthValue)) {\n+          accountStatsStore.takeSnapshotOfAggregatedStatsSetMonth(clusterMapConfig.clusterMapClusterName,\n+              currentMonthValue);\n+        }\n+      }\n+      return new TaskResult(TaskResult.Status.COMPLETED, \"Aggregation success\");\n+    } catch (Exception e) {\n+      logger.error(\"Exception thrown while aggregating stats from health reports across all nodes \", e);\n+      exception = e;\n+      return new TaskResult(TaskResult.Status.FAILED, \"Exception thrown\");\n+    } finally {\n+      if (clusterMapConfig.clustermapEnableContainerDeletionAggregation && callback != null && results != null\n+          && statsReportType.equals(StatsReportType.ACCOUNT_REPORT)) {\n+        callback.onCompletion(results.getFirst(), exception);\n+      }\n+    }\n+  }\n+\n+  private String stripPortNumber(String instanceName) {\n+    return instanceName.replace(\"_\" + clusterMapConfig.clusterMapPort, \"\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTc1MjkxMw=="}, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 127}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDcwNTQ3Nw==", "bodyText": "Maybe I am misreading this, but it seems like stripPortNumber is called for all hosts in a cluster (line 86), but clusterMapConfig.clusterMapPort is static and only represents this host's port number.", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r530705477", "createdAt": "2020-11-26T00:22:10Z", "author": {"login": "cgtz"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/MySqlReportAggregatorTask.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.clustermap;\n+\n+import com.github.ambry.commons.Callback;\n+import com.github.ambry.config.ClusterMapConfig;\n+import com.github.ambry.server.AccountStatsStore;\n+import com.github.ambry.server.StatsReportType;\n+import com.github.ambry.server.StatsSnapshot;\n+import com.github.ambry.server.StatsWrapper;\n+import com.github.ambry.utils.Pair;\n+import com.github.ambry.utils.SystemTime;\n+import com.github.ambry.utils.Time;\n+import java.time.LocalDateTime;\n+import java.time.ZoneId;\n+import java.time.ZoneOffset;\n+import java.time.format.DateTimeFormatter;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.helix.HelixManager;\n+import org.apache.helix.task.Task;\n+import org.apache.helix.task.TaskResult;\n+import org.apache.helix.task.UserContentStore;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * MySql task to aggregate container storage usage across all storage nodes and update the aggregated stats.\n+ */\n+public class MySqlReportAggregatorTask extends UserContentStore implements Task {\n+  public static final String TASK_COMMAND_PREFIX = \"mysql_aggregate\";\n+  private static final Logger logger = LoggerFactory.getLogger(MySqlReportAggregatorTask.class);\n+  private static final ZoneOffset zoneOffset = ZoneId.systemDefault().getRules().getOffset(LocalDateTime.now());\n+  static final DateTimeFormatter TIMESTAMP_FORMATTER = DateTimeFormatter.ofPattern(\"yyyy-MM\");\n+  private final HelixClusterAggregator clusterAggregator;\n+  private final HelixManager manager;\n+  private final StatsReportType statsReportType;\n+  private final Callback<StatsSnapshot> callback;\n+  private final ClusterMapConfig clusterMapConfig;\n+  private final AccountStatsStore accountStatsStore;\n+  private final Time time;\n+\n+  /**\n+   * Instantiates {@link MySqlReportAggregatorTask}.\n+   * @param manager The {@link HelixManager} to retrieve all storage nodes.\n+   * @param relevantTimePeriodInMs relevant time period in ms within which values are considered to be valid. Values\n+   *                               outside of this period will be ignored.\n+   * @param statsReportType the type of stats report\n+   * @param accountStatsStore The {@link AccountStatsStore} to retrieve stats and store aggregated stats.\n+   * @param callback a callback which will be invoked when the aggregation report has been generated successfully.\n+   * @param clusterMapConfig the {@link ClusterMapConfig} associated with helix participant.\n+   */\n+  MySqlReportAggregatorTask(HelixManager manager, long relevantTimePeriodInMs, StatsReportType statsReportType,\n+      AccountStatsStore accountStatsStore, Callback<StatsSnapshot> callback, ClusterMapConfig clusterMapConfig) {\n+    this(manager, relevantTimePeriodInMs, statsReportType, accountStatsStore, callback, clusterMapConfig,\n+        SystemTime.getInstance());\n+  }\n+\n+  MySqlReportAggregatorTask(HelixManager manager, long relevantTimePeriodInMs, StatsReportType statsReportType,\n+      AccountStatsStore accountStatsStore, Callback<StatsSnapshot> callback, ClusterMapConfig clusterMapConfig,\n+      Time time) {\n+    this.manager = manager;\n+    clusterAggregator = new HelixClusterAggregator(relevantTimePeriodInMs);\n+    this.statsReportType = statsReportType;\n+    this.accountStatsStore = accountStatsStore;\n+    this.callback = callback;\n+    this.clusterMapConfig = clusterMapConfig;\n+    this.time = time;\n+  }\n+\n+  @Override\n+  public TaskResult run() {\n+    Pair<StatsSnapshot, StatsSnapshot> results = null;\n+    Exception exception = null;\n+    try {\n+      List<String> instanceNames = manager.getClusterManagmentTool().getInstancesInCluster(manager.getClusterName());\n+      Map<String, StatsWrapper> statsWrappers = new HashMap<>();\n+      for (String instanceName : instanceNames) {\n+        // Helix instance name would suffix port number, here let's take port number out.\n+        instanceName = stripPortNumber(instanceName);\n+        statsWrappers.put(instanceName,\n+            accountStatsStore.queryStatsOf(clusterMapConfig.clusterMapClusterName, instanceName));\n+      }\n+      results = clusterAggregator.doWorkOnStatsWrapperMap(statsWrappers, statsReportType);\n+      accountStatsStore.storeAggregatedStats(results.getSecond());\n+      // Create a base report at the beginning of each month.\n+      // Check if there is a base report for this month or not.\n+      if (clusterMapConfig.clustermapEnableAggregatedMonthlyAccountReport\n+          && statsReportType == StatsReportType.ACCOUNT_REPORT) {\n+        // Get the month, if not the same month, then copy the aggregated stats and update the month\n+        String currentMonthValue =\n+            LocalDateTime.ofEpochSecond(time.seconds(), 0, zoneOffset).format(TIMESTAMP_FORMATTER);\n+        String recordedMonthValue = accountStatsStore.queryRecordedMonth(clusterMapConfig.clusterMapClusterName);\n+        if (recordedMonthValue == null || recordedMonthValue.isEmpty() || !currentMonthValue.equals(\n+            recordedMonthValue)) {\n+          accountStatsStore.takeSnapshotOfAggregatedStatsSetMonth(clusterMapConfig.clusterMapClusterName,\n+              currentMonthValue);\n+        }\n+      }\n+      return new TaskResult(TaskResult.Status.COMPLETED, \"Aggregation success\");\n+    } catch (Exception e) {\n+      logger.error(\"Exception thrown while aggregating stats from health reports across all nodes \", e);\n+      exception = e;\n+      return new TaskResult(TaskResult.Status.FAILED, \"Exception thrown\");\n+    } finally {\n+      if (clusterMapConfig.clustermapEnableContainerDeletionAggregation && callback != null && results != null\n+          && statsReportType.equals(StatsReportType.ACCOUNT_REPORT)) {\n+        callback.onCompletion(results.getFirst(), exception);\n+      }\n+    }\n+  }\n+\n+  private String stripPortNumber(String instanceName) {\n+    return instanceName.replace(\"_\" + clusterMapConfig.clusterMapPort, \"\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTc1MjkxMw=="}, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 127}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDc0MzUzMA==", "bodyText": "oh, you are absolutely right, I was just being stupid, will update.", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r530743530", "createdAt": "2020-11-26T02:48:09Z", "author": {"login": "justinlin-linkedin"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/MySqlReportAggregatorTask.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.clustermap;\n+\n+import com.github.ambry.commons.Callback;\n+import com.github.ambry.config.ClusterMapConfig;\n+import com.github.ambry.server.AccountStatsStore;\n+import com.github.ambry.server.StatsReportType;\n+import com.github.ambry.server.StatsSnapshot;\n+import com.github.ambry.server.StatsWrapper;\n+import com.github.ambry.utils.Pair;\n+import com.github.ambry.utils.SystemTime;\n+import com.github.ambry.utils.Time;\n+import java.time.LocalDateTime;\n+import java.time.ZoneId;\n+import java.time.ZoneOffset;\n+import java.time.format.DateTimeFormatter;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.helix.HelixManager;\n+import org.apache.helix.task.Task;\n+import org.apache.helix.task.TaskResult;\n+import org.apache.helix.task.UserContentStore;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * MySql task to aggregate container storage usage across all storage nodes and update the aggregated stats.\n+ */\n+public class MySqlReportAggregatorTask extends UserContentStore implements Task {\n+  public static final String TASK_COMMAND_PREFIX = \"mysql_aggregate\";\n+  private static final Logger logger = LoggerFactory.getLogger(MySqlReportAggregatorTask.class);\n+  private static final ZoneOffset zoneOffset = ZoneId.systemDefault().getRules().getOffset(LocalDateTime.now());\n+  static final DateTimeFormatter TIMESTAMP_FORMATTER = DateTimeFormatter.ofPattern(\"yyyy-MM\");\n+  private final HelixClusterAggregator clusterAggregator;\n+  private final HelixManager manager;\n+  private final StatsReportType statsReportType;\n+  private final Callback<StatsSnapshot> callback;\n+  private final ClusterMapConfig clusterMapConfig;\n+  private final AccountStatsStore accountStatsStore;\n+  private final Time time;\n+\n+  /**\n+   * Instantiates {@link MySqlReportAggregatorTask}.\n+   * @param manager The {@link HelixManager} to retrieve all storage nodes.\n+   * @param relevantTimePeriodInMs relevant time period in ms within which values are considered to be valid. Values\n+   *                               outside of this period will be ignored.\n+   * @param statsReportType the type of stats report\n+   * @param accountStatsStore The {@link AccountStatsStore} to retrieve stats and store aggregated stats.\n+   * @param callback a callback which will be invoked when the aggregation report has been generated successfully.\n+   * @param clusterMapConfig the {@link ClusterMapConfig} associated with helix participant.\n+   */\n+  MySqlReportAggregatorTask(HelixManager manager, long relevantTimePeriodInMs, StatsReportType statsReportType,\n+      AccountStatsStore accountStatsStore, Callback<StatsSnapshot> callback, ClusterMapConfig clusterMapConfig) {\n+    this(manager, relevantTimePeriodInMs, statsReportType, accountStatsStore, callback, clusterMapConfig,\n+        SystemTime.getInstance());\n+  }\n+\n+  MySqlReportAggregatorTask(HelixManager manager, long relevantTimePeriodInMs, StatsReportType statsReportType,\n+      AccountStatsStore accountStatsStore, Callback<StatsSnapshot> callback, ClusterMapConfig clusterMapConfig,\n+      Time time) {\n+    this.manager = manager;\n+    clusterAggregator = new HelixClusterAggregator(relevantTimePeriodInMs);\n+    this.statsReportType = statsReportType;\n+    this.accountStatsStore = accountStatsStore;\n+    this.callback = callback;\n+    this.clusterMapConfig = clusterMapConfig;\n+    this.time = time;\n+  }\n+\n+  @Override\n+  public TaskResult run() {\n+    Pair<StatsSnapshot, StatsSnapshot> results = null;\n+    Exception exception = null;\n+    try {\n+      List<String> instanceNames = manager.getClusterManagmentTool().getInstancesInCluster(manager.getClusterName());\n+      Map<String, StatsWrapper> statsWrappers = new HashMap<>();\n+      for (String instanceName : instanceNames) {\n+        // Helix instance name would suffix port number, here let's take port number out.\n+        instanceName = stripPortNumber(instanceName);\n+        statsWrappers.put(instanceName,\n+            accountStatsStore.queryStatsOf(clusterMapConfig.clusterMapClusterName, instanceName));\n+      }\n+      results = clusterAggregator.doWorkOnStatsWrapperMap(statsWrappers, statsReportType);\n+      accountStatsStore.storeAggregatedStats(results.getSecond());\n+      // Create a base report at the beginning of each month.\n+      // Check if there is a base report for this month or not.\n+      if (clusterMapConfig.clustermapEnableAggregatedMonthlyAccountReport\n+          && statsReportType == StatsReportType.ACCOUNT_REPORT) {\n+        // Get the month, if not the same month, then copy the aggregated stats and update the month\n+        String currentMonthValue =\n+            LocalDateTime.ofEpochSecond(time.seconds(), 0, zoneOffset).format(TIMESTAMP_FORMATTER);\n+        String recordedMonthValue = accountStatsStore.queryRecordedMonth(clusterMapConfig.clusterMapClusterName);\n+        if (recordedMonthValue == null || recordedMonthValue.isEmpty() || !currentMonthValue.equals(\n+            recordedMonthValue)) {\n+          accountStatsStore.takeSnapshotOfAggregatedStatsSetMonth(clusterMapConfig.clusterMapClusterName,\n+              currentMonthValue);\n+        }\n+      }\n+      return new TaskResult(TaskResult.Status.COMPLETED, \"Aggregation success\");\n+    } catch (Exception e) {\n+      logger.error(\"Exception thrown while aggregating stats from health reports across all nodes \", e);\n+      exception = e;\n+      return new TaskResult(TaskResult.Status.FAILED, \"Exception thrown\");\n+    } finally {\n+      if (clusterMapConfig.clustermapEnableContainerDeletionAggregation && callback != null && results != null\n+          && statsReportType.equals(StatsReportType.ACCOUNT_REPORT)) {\n+        callback.onCompletion(results.getFirst(), exception);\n+      }\n+    }\n+  }\n+\n+  private String stripPortNumber(String instanceName) {\n+    return instanceName.replace(\"_\" + clusterMapConfig.clusterMapPort, \"\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTc1MjkxMw=="}, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 127}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyNDEyNjg1OnYy", "diffSide": "RIGHT", "path": "ambry-api/src/main/java/com/github/ambry/server/AccountStatsStore.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwMDozMToxOFrOH5ekJA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwMDozMToxOFrOH5ekJA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDAzMTY1Mg==", "bodyText": "If we want to support partition class stats report in near future, can we add a stats type in the method in future PR?  (let's leave a TODO note here)", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r530031652", "createdAt": "2020-11-25T00:31:18Z", "author": {"login": "jsjtzyy"}, "path": "ambry-api/src/main/java/com/github/ambry/server/AccountStatsStore.java", "diffHunk": "@@ -0,0 +1,97 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.server;\n+\n+import java.util.Map;\n+\n+\n+/**\n+ * The interface that stores and fetches account stats, aggregated account stats.\n+ */\n+public interface AccountStatsStore {\n+  /**\n+   * Store stats in the {@link StatsWrapper}. The StatsWrapper's {@link StatsSnapshot} should include partition, account\n+   * and container. This method will be used for individual ambry server to store local stats.\n+   * @param statsWrapper The {@link StatsWrapper} that contains stats and other metadata.\n+   */\n+  void storeStats(StatsWrapper statsWrapper);\n+\n+  /**\n+   * Store aggregated stats in the {@link StatsSnapshot}. The StatsSnapshot should include account and container. This\n+   * method will be used for aggregation task to store aggregated stats.\n+   * @param snapshot The {@link StatsSnapshot} that contains aggregated container usage.\n+   * @throws Exception\n+   */\n+  void storeAggregatedStats(StatsSnapshot snapshot) throws Exception;\n+\n+  /**\n+   * Return individual ambry server's stats for the given {@code clusterName} and {@code hostname}. This is the stats\n+   * stored by method {@link #storeStats}.\n+   * @param clusterName The clusterName.\n+   * @param hostname The hostname.\n+   * @return {@link StatsWrapper} of given {@code hostname} in the {@code clusterName}.\n+   * @throws Exception\n+   */\n+  StatsWrapper queryStatsOf(String clusterName, String hostname) throws Exception;\n+\n+  /**\n+   * Return the aggregated stats for the given {@code clusterName}. This is the stats stored by method {@link #storeAggregatedStats}.\n+   * Since the {@link StatsSnapshot} passed to {@link #storeAggregatedStats} only have account and container stats, this\n+   * method returns a map back to the caller. The key of the outer map is the account id in string format, and the key of\n+   * the inner map is the container id in string format, the value of the inner map is the storage usage for this container.\n+   * <pre>\n+   *   {\n+   *     \"1001\": {\n+   *       \"1\": 10456,\n+   *       \"2\": 75637292\n+   *     },\n+   *     \"1002\": {\n+   *       \"8\": 1785385436\n+   *     }\n+   *   }\n+   * </pre>\n+   * @param clusterName The clusterName.\n+   * @return The map that represents the container storage usage.\n+   * @throws Exception\n+   */\n+  Map<String, Map<String, Long>> queryAggregatedStats(String clusterName) throws Exception;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 68}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyNDY5NzIxOnYy", "diffSide": "RIGHT", "path": "ambry-api/src/main/java/com/github/ambry/server/AccountStatsStore.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwNToyMToyOFrOH5joeA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwNToyMToyOFrOH5joeA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDExNDY4MA==", "bodyText": "minor: could you give an example of return value?", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r530114680", "createdAt": "2020-11-25T05:21:28Z", "author": {"login": "jsjtzyy"}, "path": "ambry-api/src/main/java/com/github/ambry/server/AccountStatsStore.java", "diffHunk": "@@ -0,0 +1,97 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.server;\n+\n+import java.util.Map;\n+\n+\n+/**\n+ * The interface that stores and fetches account stats, aggregated account stats.\n+ */\n+public interface AccountStatsStore {\n+  /**\n+   * Store stats in the {@link StatsWrapper}. The StatsWrapper's {@link StatsSnapshot} should include partition, account\n+   * and container. This method will be used for individual ambry server to store local stats.\n+   * @param statsWrapper The {@link StatsWrapper} that contains stats and other metadata.\n+   */\n+  void storeStats(StatsWrapper statsWrapper);\n+\n+  /**\n+   * Store aggregated stats in the {@link StatsSnapshot}. The StatsSnapshot should include account and container. This\n+   * method will be used for aggregation task to store aggregated stats.\n+   * @param snapshot The {@link StatsSnapshot} that contains aggregated container usage.\n+   * @throws Exception\n+   */\n+  void storeAggregatedStats(StatsSnapshot snapshot) throws Exception;\n+\n+  /**\n+   * Return individual ambry server's stats for the given {@code clusterName} and {@code hostname}. This is the stats\n+   * stored by method {@link #storeStats}.\n+   * @param clusterName The clusterName.\n+   * @param hostname The hostname.\n+   * @return {@link StatsWrapper} of given {@code hostname} in the {@code clusterName}.\n+   * @throws Exception\n+   */\n+  StatsWrapper queryStatsOf(String clusterName, String hostname) throws Exception;\n+\n+  /**\n+   * Return the aggregated stats for the given {@code clusterName}. This is the stats stored by method {@link #storeAggregatedStats}.\n+   * Since the {@link StatsSnapshot} passed to {@link #storeAggregatedStats} only have account and container stats, this\n+   * method returns a map back to the caller. The key of the outer map is the account id in string format, and the key of\n+   * the inner map is the container id in string format, the value of the inner map is the storage usage for this container.\n+   * <pre>\n+   *   {\n+   *     \"1001\": {\n+   *       \"1\": 10456,\n+   *       \"2\": 75637292\n+   *     },\n+   *     \"1002\": {\n+   *       \"8\": 1785385436\n+   *     }\n+   *   }\n+   * </pre>\n+   * @param clusterName The clusterName.\n+   * @return The map that represents the container storage usage.\n+   * @throws Exception\n+   */\n+  Map<String, Map<String, Long>> queryAggregatedStats(String clusterName) throws Exception;\n+\n+  /**\n+   * Return the monthly aggregated stats. This method returns a map in the same format as the {@link #queryAggregatedStats}.\n+   * The only difference these two methods have is that this method's returned value only changes in the beginning of each\n+   * month. For every new month(in local zone offset), an aggregated stats will be written to storage and a snapshot will\n+   * be created. This method will return current snapshot. This method doesn't require a month value to fetch the snapshot\n+   * as this new snapshot will be override the old ones.\n+   * @param clusterName The clusterName.\n+   * @return The map thtat represents the container storage usage.\n+   * @throws Exception\n+   */\n+  Map<String, Map<String, Long>> queryMonthlyAggregatedStats(String clusterName) throws Exception;\n+\n+  /**\n+   * Return the month value of the current container storage snapshot.\n+   * @param clusterName The clusterName.\n+   * @return The month value for current snapshot.\n+   * @throws Exception\n+   */\n+  String queryRecordedMonth(String clusterName) throws Exception;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 88}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyNDcwMjkzOnYy", "diffSide": "RIGHT", "path": "ambry-api/src/main/java/com/github/ambry/server/AccountStatsStore.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwNToyNDozOVrOH5jrpA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwNToyNDozOVrOH5jrpA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDExNTQ5Mg==", "bodyText": "Let's call this takeSnapshotOfAggregatedStatsAndUpdateMonth or takeStatsSnapshotAndUpdateMonth", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r530115492", "createdAt": "2020-11-25T05:24:39Z", "author": {"login": "jsjtzyy"}, "path": "ambry-api/src/main/java/com/github/ambry/server/AccountStatsStore.java", "diffHunk": "@@ -0,0 +1,97 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.server;\n+\n+import java.util.Map;\n+\n+\n+/**\n+ * The interface that stores and fetches account stats, aggregated account stats.\n+ */\n+public interface AccountStatsStore {\n+  /**\n+   * Store stats in the {@link StatsWrapper}. The StatsWrapper's {@link StatsSnapshot} should include partition, account\n+   * and container. This method will be used for individual ambry server to store local stats.\n+   * @param statsWrapper The {@link StatsWrapper} that contains stats and other metadata.\n+   */\n+  void storeStats(StatsWrapper statsWrapper);\n+\n+  /**\n+   * Store aggregated stats in the {@link StatsSnapshot}. The StatsSnapshot should include account and container. This\n+   * method will be used for aggregation task to store aggregated stats.\n+   * @param snapshot The {@link StatsSnapshot} that contains aggregated container usage.\n+   * @throws Exception\n+   */\n+  void storeAggregatedStats(StatsSnapshot snapshot) throws Exception;\n+\n+  /**\n+   * Return individual ambry server's stats for the given {@code clusterName} and {@code hostname}. This is the stats\n+   * stored by method {@link #storeStats}.\n+   * @param clusterName The clusterName.\n+   * @param hostname The hostname.\n+   * @return {@link StatsWrapper} of given {@code hostname} in the {@code clusterName}.\n+   * @throws Exception\n+   */\n+  StatsWrapper queryStatsOf(String clusterName, String hostname) throws Exception;\n+\n+  /**\n+   * Return the aggregated stats for the given {@code clusterName}. This is the stats stored by method {@link #storeAggregatedStats}.\n+   * Since the {@link StatsSnapshot} passed to {@link #storeAggregatedStats} only have account and container stats, this\n+   * method returns a map back to the caller. The key of the outer map is the account id in string format, and the key of\n+   * the inner map is the container id in string format, the value of the inner map is the storage usage for this container.\n+   * <pre>\n+   *   {\n+   *     \"1001\": {\n+   *       \"1\": 10456,\n+   *       \"2\": 75637292\n+   *     },\n+   *     \"1002\": {\n+   *       \"8\": 1785385436\n+   *     }\n+   *   }\n+   * </pre>\n+   * @param clusterName The clusterName.\n+   * @return The map that represents the container storage usage.\n+   * @throws Exception\n+   */\n+  Map<String, Map<String, Long>> queryAggregatedStats(String clusterName) throws Exception;\n+\n+  /**\n+   * Return the monthly aggregated stats. This method returns a map in the same format as the {@link #queryAggregatedStats}.\n+   * The only difference these two methods have is that this method's returned value only changes in the beginning of each\n+   * month. For every new month(in local zone offset), an aggregated stats will be written to storage and a snapshot will\n+   * be created. This method will return current snapshot. This method doesn't require a month value to fetch the snapshot\n+   * as this new snapshot will be override the old ones.\n+   * @param clusterName The clusterName.\n+   * @return The map thtat represents the container storage usage.\n+   * @throws Exception\n+   */\n+  Map<String, Map<String, Long>> queryMonthlyAggregatedStats(String clusterName) throws Exception;\n+\n+  /**\n+   * Return the month value of the current container storage snapshot.\n+   * @param clusterName The clusterName.\n+   * @return The month value for current snapshot.\n+   * @throws Exception\n+   */\n+  String queryRecordedMonth(String clusterName) throws Exception;\n+\n+  /**\n+   * Taking a snapshot of current aggregated stats and update the month value.\n+   * @param clusterName The clusterName.\n+   * @param monthValue The month in string format, like \"2020-01\".\n+   * @throws Exception\n+   */\n+  void takeSnapshotOfAggregatedStatsSetMonth(String clusterName, String monthValue) throws Exception;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 96}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyNDcwOTYzOnYy", "diffSide": "RIGHT", "path": "ambry-api/src/main/java/com/github/ambry/server/StatsSnapshot.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwNToyODozOVrOH5jvZg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwNToyODozOVrOH5jvZg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDExNjQ1NA==", "bodyText": "minor: can be simplified to\noriginal.subMap.forEach((k, v) -> this.subMap.put(k, new StatsSnapshot(v)));", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r530116454", "createdAt": "2020-11-25T05:28:39Z", "author": {"login": "jsjtzyy"}, "path": "ambry-api/src/main/java/com/github/ambry/server/StatsSnapshot.java", "diffHunk": "@@ -62,6 +62,20 @@ public StatsSnapshot() {\n     // empty constructor for Jackson deserialization\n   }\n \n+  /**\n+   * A copy constructor.\n+   * @param original The original copy.\n+   */\n+  public StatsSnapshot(StatsSnapshot original) {\n+    this.value = original.value;\n+    if (original.subMap != null) {\n+      this.subMap = new HashMap<>(original.subMap.size());\n+      original.subMap.forEach((k, v) -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyNDcyOTM1OnYy", "diffSide": "RIGHT", "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixClusterAggregator.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwNTozOToxOFrOH5j6og==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxOToyMzowMlrOH6BDZA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDExOTMzMA==", "bodyText": "We can consider removing this rawPartitionSnapshots.  Instead, we could add an aggregated snapshot to track physical disk capacity occupied by each account/container (including data deleted/expired but hasn't been compacted.)", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r530119330", "createdAt": "2020-11-25T05:39:18Z", "author": {"login": "jsjtzyy"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixClusterAggregator.java", "diffHunk": "@@ -53,33 +54,59 @@\n    * for each partition.\n    * @throws IOException\n    */\n-  Pair<StatsSnapshot, StatsSnapshot> doWork(Map<String, String> statsWrappersJSON, StatsReportType type) throws IOException {\n+  Pair<StatsSnapshot, StatsSnapshot> doWork(Map<String, String> statsWrappersJSON, StatsReportType type)\n+      throws IOException {\n+    Map<String, StatsWrapper> statsWrappers = new HashMap<>();\n+    for (Map.Entry<String, String> statsWrapperJSON : statsWrappersJSON.entrySet()) {\n+      try {\n+        if (statsWrapperJSON != null && statsWrapperJSON.getValue() != null) {\n+          StatsWrapper snapshotWrapper = mapper.readValue(statsWrapperJSON.getValue(), StatsWrapper.class);\n+          statsWrappers.put(statsWrapperJSON.getKey(), snapshotWrapper);\n+        }\n+      } catch (Exception e) {\n+        logger.error(\"Exception occurred while processing stats from {}\", statsWrapperJSON.getKey(), e);\n+        exceptionOccurredInstances.computeIfAbsent(type, key -> new ArrayList<>()).add(statsWrapperJSON.getKey());\n+      }\n+    }\n+    return doWorkOnStatsWrapperMap(statsWrappers, type, false);\n+  }\n+\n+  Pair<StatsSnapshot, StatsSnapshot> doWorkOnStatsWrapperMap(Map<String, StatsWrapper> statsWrappers,\n+      StatsReportType type) throws IOException {\n+    return doWorkOnStatsWrapperMap(statsWrappers, type, true);\n+  }\n+\n+  Pair<StatsSnapshot, StatsSnapshot> doWorkOnStatsWrapperMap(Map<String, StatsWrapper> statsWrappers,\n+      StatsReportType type, boolean removeExceptionOnType) throws IOException {\n     StatsSnapshot partitionSnapshot = new StatsSnapshot(0L, new HashMap<>());\n     Map<String, Long> partitionTimestampMap = new HashMap<>();\n     StatsSnapshot rawPartitionSnapshot = new StatsSnapshot(0L, new HashMap<>());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDU5NjcwOA==", "bodyText": "Trying to avoid unnecessary change as much as possible. We can do this later.", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r530596708", "createdAt": "2020-11-25T19:23:02Z", "author": {"login": "justinlin-linkedin"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixClusterAggregator.java", "diffHunk": "@@ -53,33 +54,59 @@\n    * for each partition.\n    * @throws IOException\n    */\n-  Pair<StatsSnapshot, StatsSnapshot> doWork(Map<String, String> statsWrappersJSON, StatsReportType type) throws IOException {\n+  Pair<StatsSnapshot, StatsSnapshot> doWork(Map<String, String> statsWrappersJSON, StatsReportType type)\n+      throws IOException {\n+    Map<String, StatsWrapper> statsWrappers = new HashMap<>();\n+    for (Map.Entry<String, String> statsWrapperJSON : statsWrappersJSON.entrySet()) {\n+      try {\n+        if (statsWrapperJSON != null && statsWrapperJSON.getValue() != null) {\n+          StatsWrapper snapshotWrapper = mapper.readValue(statsWrapperJSON.getValue(), StatsWrapper.class);\n+          statsWrappers.put(statsWrapperJSON.getKey(), snapshotWrapper);\n+        }\n+      } catch (Exception e) {\n+        logger.error(\"Exception occurred while processing stats from {}\", statsWrapperJSON.getKey(), e);\n+        exceptionOccurredInstances.computeIfAbsent(type, key -> new ArrayList<>()).add(statsWrapperJSON.getKey());\n+      }\n+    }\n+    return doWorkOnStatsWrapperMap(statsWrappers, type, false);\n+  }\n+\n+  Pair<StatsSnapshot, StatsSnapshot> doWorkOnStatsWrapperMap(Map<String, StatsWrapper> statsWrappers,\n+      StatsReportType type) throws IOException {\n+    return doWorkOnStatsWrapperMap(statsWrappers, type, true);\n+  }\n+\n+  Pair<StatsSnapshot, StatsSnapshot> doWorkOnStatsWrapperMap(Map<String, StatsWrapper> statsWrappers,\n+      StatsReportType type, boolean removeExceptionOnType) throws IOException {\n     StatsSnapshot partitionSnapshot = new StatsSnapshot(0L, new HashMap<>());\n     Map<String, Long> partitionTimestampMap = new HashMap<>();\n     StatsSnapshot rawPartitionSnapshot = new StatsSnapshot(0L, new HashMap<>());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDExOTMzMA=="}, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 39}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyNDc4MTc5OnYy", "diffSide": "RIGHT", "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixParticipant.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwNjowNjowMlrOH5kZWw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwNjowNjowMlrOH5kZWw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDEyNzE5NQ==", "bodyText": "minor: add java doc for accountStatsStore", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r530127195", "createdAt": "2020-11-25T06:06:02Z", "author": {"login": "jsjtzyy"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixParticipant.java", "diffHunk": "@@ -123,14 +125,14 @@ public void setInitialLocalPartitions(Collection<String> localPartitions) {\n    * @throws IOException if there is an error connecting to the Helix cluster.\n    */\n   @Override\n-  public void participate(List<AmbryHealthReport> ambryHealthReports, Callback<StatsSnapshot> callback)\n-      throws IOException {\n+  public void participate(List<AmbryHealthReport> ambryHealthReports, AccountStatsStore accountStatsStore,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 16}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyNDc4NDIyOnYy", "diffSide": "RIGHT", "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixParticipant.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwNjowNzowN1rOH5kaug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwNjowNzowN1rOH5kaug==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDEyNzU0Ng==", "bodyText": "same here. (Also, we should consider removing the callback, this can be done in future PR)", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r530127546", "createdAt": "2020-11-25T06:07:07Z", "author": {"login": "jsjtzyy"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixParticipant.java", "diffHunk": "@@ -439,7 +441,7 @@ private void awaitDisablingPartition() throws InterruptedException {\n    * @param callback a callback which will be invoked when the aggregation report has been generated successfully.\n    */\n   private void registerHealthReportTasks(StateMachineEngine engine, List<AmbryHealthReport> healthReports,\n-      Callback<StatsSnapshot> callback) {\n+      AccountStatsStore accountStatsStore, Callback<StatsSnapshot> callback) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyNDc5NDIxOnYy", "diffSide": "RIGHT", "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/MySqlReportAggregatorTask.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwNjoxMTo0OVrOH5kgWA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxOToyMzo1N1rOH6BE4Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDEyODk4NA==", "bodyText": "Why we need to constructors here?", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r530128984", "createdAt": "2020-11-25T06:11:49Z", "author": {"login": "jsjtzyy"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/MySqlReportAggregatorTask.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.clustermap;\n+\n+import com.github.ambry.commons.Callback;\n+import com.github.ambry.config.ClusterMapConfig;\n+import com.github.ambry.server.AccountStatsStore;\n+import com.github.ambry.server.StatsReportType;\n+import com.github.ambry.server.StatsSnapshot;\n+import com.github.ambry.server.StatsWrapper;\n+import com.github.ambry.utils.Pair;\n+import com.github.ambry.utils.SystemTime;\n+import com.github.ambry.utils.Time;\n+import java.time.LocalDateTime;\n+import java.time.ZoneId;\n+import java.time.ZoneOffset;\n+import java.time.format.DateTimeFormatter;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.helix.HelixManager;\n+import org.apache.helix.task.Task;\n+import org.apache.helix.task.TaskResult;\n+import org.apache.helix.task.UserContentStore;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * MySql task to aggregate container storage usage across all storage nodes and update the aggregated stats.\n+ */\n+public class MySqlReportAggregatorTask extends UserContentStore implements Task {\n+  public static final String TASK_COMMAND_PREFIX = \"mysql_aggregate\";\n+  private static final Logger logger = LoggerFactory.getLogger(MySqlReportAggregatorTask.class);\n+  private static final ZoneOffset zoneOffset = ZoneId.systemDefault().getRules().getOffset(LocalDateTime.now());\n+  static final DateTimeFormatter TIMESTAMP_FORMATTER = DateTimeFormatter.ofPattern(\"yyyy-MM\");\n+  private final HelixClusterAggregator clusterAggregator;\n+  private final HelixManager manager;\n+  private final StatsReportType statsReportType;\n+  private final Callback<StatsSnapshot> callback;\n+  private final ClusterMapConfig clusterMapConfig;\n+  private final AccountStatsStore accountStatsStore;\n+  private final Time time;\n+\n+  /**\n+   * Instantiates {@link MySqlReportAggregatorTask}.\n+   * @param manager The {@link HelixManager} to retrieve all storage nodes.\n+   * @param relevantTimePeriodInMs relevant time period in ms within which values are considered to be valid. Values\n+   *                               outside of this period will be ignored.\n+   * @param statsReportType the type of stats report\n+   * @param accountStatsStore The {@link AccountStatsStore} to retrieve stats and store aggregated stats.\n+   * @param callback a callback which will be invoked when the aggregation report has been generated successfully.\n+   * @param clusterMapConfig the {@link ClusterMapConfig} associated with helix participant.\n+   */\n+  MySqlReportAggregatorTask(HelixManager manager, long relevantTimePeriodInMs, StatsReportType statsReportType,\n+      AccountStatsStore accountStatsStore, Callback<StatsSnapshot> callback, ClusterMapConfig clusterMapConfig) {\n+    this(manager, relevantTimePeriodInMs, statsReportType, accountStatsStore, callback, clusterMapConfig,\n+        SystemTime.getInstance());\n+  }\n+\n+  MySqlReportAggregatorTask(HelixManager manager, long relevantTimePeriodInMs, StatsReportType statsReportType,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDU5NzA4OQ==", "bodyText": "This constructor is for testing, but i realize the tests are redundant, removed this constructor.", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r530597089", "createdAt": "2020-11-25T19:23:57Z", "author": {"login": "justinlin-linkedin"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/MySqlReportAggregatorTask.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.clustermap;\n+\n+import com.github.ambry.commons.Callback;\n+import com.github.ambry.config.ClusterMapConfig;\n+import com.github.ambry.server.AccountStatsStore;\n+import com.github.ambry.server.StatsReportType;\n+import com.github.ambry.server.StatsSnapshot;\n+import com.github.ambry.server.StatsWrapper;\n+import com.github.ambry.utils.Pair;\n+import com.github.ambry.utils.SystemTime;\n+import com.github.ambry.utils.Time;\n+import java.time.LocalDateTime;\n+import java.time.ZoneId;\n+import java.time.ZoneOffset;\n+import java.time.format.DateTimeFormatter;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.helix.HelixManager;\n+import org.apache.helix.task.Task;\n+import org.apache.helix.task.TaskResult;\n+import org.apache.helix.task.UserContentStore;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * MySql task to aggregate container storage usage across all storage nodes and update the aggregated stats.\n+ */\n+public class MySqlReportAggregatorTask extends UserContentStore implements Task {\n+  public static final String TASK_COMMAND_PREFIX = \"mysql_aggregate\";\n+  private static final Logger logger = LoggerFactory.getLogger(MySqlReportAggregatorTask.class);\n+  private static final ZoneOffset zoneOffset = ZoneId.systemDefault().getRules().getOffset(LocalDateTime.now());\n+  static final DateTimeFormatter TIMESTAMP_FORMATTER = DateTimeFormatter.ofPattern(\"yyyy-MM\");\n+  private final HelixClusterAggregator clusterAggregator;\n+  private final HelixManager manager;\n+  private final StatsReportType statsReportType;\n+  private final Callback<StatsSnapshot> callback;\n+  private final ClusterMapConfig clusterMapConfig;\n+  private final AccountStatsStore accountStatsStore;\n+  private final Time time;\n+\n+  /**\n+   * Instantiates {@link MySqlReportAggregatorTask}.\n+   * @param manager The {@link HelixManager} to retrieve all storage nodes.\n+   * @param relevantTimePeriodInMs relevant time period in ms within which values are considered to be valid. Values\n+   *                               outside of this period will be ignored.\n+   * @param statsReportType the type of stats report\n+   * @param accountStatsStore The {@link AccountStatsStore} to retrieve stats and store aggregated stats.\n+   * @param callback a callback which will be invoked when the aggregation report has been generated successfully.\n+   * @param clusterMapConfig the {@link ClusterMapConfig} associated with helix participant.\n+   */\n+  MySqlReportAggregatorTask(HelixManager manager, long relevantTimePeriodInMs, StatsReportType statsReportType,\n+      AccountStatsStore accountStatsStore, Callback<StatsSnapshot> callback, ClusterMapConfig clusterMapConfig) {\n+    this(manager, relevantTimePeriodInMs, statsReportType, accountStatsStore, callback, clusterMapConfig,\n+        SystemTime.getInstance());\n+  }\n+\n+  MySqlReportAggregatorTask(HelixManager manager, long relevantTimePeriodInMs, StatsReportType statsReportType,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDEyODk4NA=="}, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 72}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyNDc5Nzc5OnYy", "diffSide": "RIGHT", "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/MySqlReportAggregatorTask.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwNjoxMzozOFrOH5kihw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwNjoxMzozOFrOH5kihw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDEyOTU0Mw==", "bodyText": "let's update this error message to reflect aggregation on mysql based stats report.", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r530129543", "createdAt": "2020-11-25T06:13:38Z", "author": {"login": "jsjtzyy"}, "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/MySqlReportAggregatorTask.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.clustermap;\n+\n+import com.github.ambry.commons.Callback;\n+import com.github.ambry.config.ClusterMapConfig;\n+import com.github.ambry.server.AccountStatsStore;\n+import com.github.ambry.server.StatsReportType;\n+import com.github.ambry.server.StatsSnapshot;\n+import com.github.ambry.server.StatsWrapper;\n+import com.github.ambry.utils.Pair;\n+import com.github.ambry.utils.SystemTime;\n+import com.github.ambry.utils.Time;\n+import java.time.LocalDateTime;\n+import java.time.ZoneId;\n+import java.time.ZoneOffset;\n+import java.time.format.DateTimeFormatter;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.helix.HelixManager;\n+import org.apache.helix.task.Task;\n+import org.apache.helix.task.TaskResult;\n+import org.apache.helix.task.UserContentStore;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * MySql task to aggregate container storage usage across all storage nodes and update the aggregated stats.\n+ */\n+public class MySqlReportAggregatorTask extends UserContentStore implements Task {\n+  public static final String TASK_COMMAND_PREFIX = \"mysql_aggregate\";\n+  private static final Logger logger = LoggerFactory.getLogger(MySqlReportAggregatorTask.class);\n+  private static final ZoneOffset zoneOffset = ZoneId.systemDefault().getRules().getOffset(LocalDateTime.now());\n+  static final DateTimeFormatter TIMESTAMP_FORMATTER = DateTimeFormatter.ofPattern(\"yyyy-MM\");\n+  private final HelixClusterAggregator clusterAggregator;\n+  private final HelixManager manager;\n+  private final StatsReportType statsReportType;\n+  private final Callback<StatsSnapshot> callback;\n+  private final ClusterMapConfig clusterMapConfig;\n+  private final AccountStatsStore accountStatsStore;\n+  private final Time time;\n+\n+  /**\n+   * Instantiates {@link MySqlReportAggregatorTask}.\n+   * @param manager The {@link HelixManager} to retrieve all storage nodes.\n+   * @param relevantTimePeriodInMs relevant time period in ms within which values are considered to be valid. Values\n+   *                               outside of this period will be ignored.\n+   * @param statsReportType the type of stats report\n+   * @param accountStatsStore The {@link AccountStatsStore} to retrieve stats and store aggregated stats.\n+   * @param callback a callback which will be invoked when the aggregation report has been generated successfully.\n+   * @param clusterMapConfig the {@link ClusterMapConfig} associated with helix participant.\n+   */\n+  MySqlReportAggregatorTask(HelixManager manager, long relevantTimePeriodInMs, StatsReportType statsReportType,\n+      AccountStatsStore accountStatsStore, Callback<StatsSnapshot> callback, ClusterMapConfig clusterMapConfig) {\n+    this(manager, relevantTimePeriodInMs, statsReportType, accountStatsStore, callback, clusterMapConfig,\n+        SystemTime.getInstance());\n+  }\n+\n+  MySqlReportAggregatorTask(HelixManager manager, long relevantTimePeriodInMs, StatsReportType statsReportType,\n+      AccountStatsStore accountStatsStore, Callback<StatsSnapshot> callback, ClusterMapConfig clusterMapConfig,\n+      Time time) {\n+    this.manager = manager;\n+    clusterAggregator = new HelixClusterAggregator(relevantTimePeriodInMs);\n+    this.statsReportType = statsReportType;\n+    this.accountStatsStore = accountStatsStore;\n+    this.callback = callback;\n+    this.clusterMapConfig = clusterMapConfig;\n+    this.time = time;\n+  }\n+\n+  @Override\n+  public TaskResult run() {\n+    Pair<StatsSnapshot, StatsSnapshot> results = null;\n+    Exception exception = null;\n+    try {\n+      List<String> instanceNames = manager.getClusterManagmentTool().getInstancesInCluster(manager.getClusterName());\n+      Map<String, StatsWrapper> statsWrappers = new HashMap<>();\n+      for (String instanceName : instanceNames) {\n+        // Helix instance name would suffix port number, here let's take port number out.\n+        instanceName = stripPortNumber(instanceName);\n+        statsWrappers.put(instanceName,\n+            accountStatsStore.queryStatsOf(clusterMapConfig.clusterMapClusterName, instanceName));\n+      }\n+      results = clusterAggregator.doWorkOnStatsWrapperMap(statsWrappers, statsReportType);\n+      accountStatsStore.storeAggregatedStats(results.getSecond());\n+      // Create a base report at the beginning of each month.\n+      // Check if there is a base report for this month or not.\n+      if (clusterMapConfig.clustermapEnableAggregatedMonthlyAccountReport\n+          && statsReportType == StatsReportType.ACCOUNT_REPORT) {\n+        // Get the month, if not the same month, then copy the aggregated stats and update the month\n+        String currentMonthValue =\n+            LocalDateTime.ofEpochSecond(time.seconds(), 0, zoneOffset).format(TIMESTAMP_FORMATTER);\n+        String recordedMonthValue = accountStatsStore.queryRecordedMonth(clusterMapConfig.clusterMapClusterName);\n+        if (recordedMonthValue == null || recordedMonthValue.isEmpty() || !currentMonthValue.equals(\n+            recordedMonthValue)) {\n+          accountStatsStore.takeSnapshotOfAggregatedStatsSetMonth(clusterMapConfig.clusterMapClusterName,\n+              currentMonthValue);\n+        }\n+      }\n+      return new TaskResult(TaskResult.Status.COMPLETED, \"Aggregation success\");\n+    } catch (Exception e) {\n+      logger.error(\"Exception thrown while aggregating stats from health reports across all nodes \", e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 115}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyNzI4NTY0OnYy", "diffSide": "RIGHT", "path": "ambry-server/src/main/java/com/github/ambry/server/mysql/AccountStatsMySqlStore.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxNjo1MTowOFrOH58H3A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxOToyNDo0OVrOH6BGhg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDUxNTkzMg==", "bodyText": "Do we want to use the latest updated storageUsage value or just the last one in order?", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r530515932", "createdAt": "2020-11-25T16:51:08Z", "author": {"login": "cgtz"}, "path": "ambry-server/src/main/java/com/github/ambry/server/mysql/AccountStatsMySqlStore.java", "diffHunk": "@@ -125,21 +137,98 @@ public void publish(StatsWrapper statsWrapper) {\n    * @return {@link StatsSnapshot} published by the given host.\n    * @throws SQLException\n    */\n-  public StatsSnapshot queryStatsSnapshotOf(String clusterName, String hostname) throws SQLException {\n+  @Override\n+  public StatsWrapper queryStatsOf(String clusterName, String hostname) throws SQLException {\n     hostname = hostnameHelper.simplifyHostname(hostname);\n     Map<String, StatsSnapshot> partitionSubMap = new HashMap<>();\n     StatsSnapshot hostSnapshot = new StatsSnapshot((long) 0, partitionSubMap);\n+    AtomicLong timestamp = new AtomicLong(0);\n     accountReportsDao.queryStorageUsageForHost(clusterName, hostname,\n-        (partitionId, accountId, containerId, storageUsage) -> {\n+        (partitionId, accountId, containerId, storageUsage, updatedAtMs) -> {\n           StatsSnapshot partitionSnapshot = hostSnapshot.getSubMap()\n               .computeIfAbsent(\"Partition[\" + partitionId + \"]\", k -> new StatsSnapshot((long) 0, new HashMap<>()));\n           StatsSnapshot accountSnapshot = partitionSnapshot.getSubMap()\n               .computeIfAbsent(\"A[\" + accountId + \"]\", k -> new StatsSnapshot((long) 0, new HashMap<>()));\n           accountSnapshot.getSubMap().put(\"C[\" + containerId + \"]\", new StatsSnapshot(storageUsage, null));\n+          timestamp.set(Math.max(timestamp.get(), updatedAtMs));\n         });\n \n     hostSnapshot.updateValue();\n-    return hostSnapshot;\n+    return new StatsWrapper(\n+        new StatsHeader(StatsHeader.StatsDescription.STORED_DATA_SIZE, timestamp.get(), partitionSubMap.size(),\n+            partitionSubMap.size(), null), hostSnapshot);\n+  }\n+\n+  /**\n+   * Store the aggregated account stats in {@link StatsSnapshot} to mysql database.\n+   * @param snapshot The aggregated account stats snapshot.\n+   */\n+  @Override\n+  public void storeAggregatedStats(StatsSnapshot snapshot) throws SQLException {\n+    int batchSize = 0;\n+    long startTimeMs = System.currentTimeMillis();\n+    for (Map.Entry<String, StatsSnapshot> accountMapEntry : snapshot.getSubMap().entrySet()) {\n+      String accountIdKey = accountMapEntry.getKey();\n+      short accountId = Short.valueOf(accountIdKey.substring(2, accountIdKey.length() - 1));\n+      StatsSnapshot containerStatsSnapshot = accountMapEntry.getValue();\n+      for (Map.Entry<String, StatsSnapshot> currContainerMapEntry : containerStatsSnapshot.getSubMap().entrySet()) {\n+        String containerIdKey = currContainerMapEntry.getKey();\n+        short containerId = Short.valueOf(containerIdKey.substring(2, containerIdKey.length() - 1));\n+        long currStorageUsage = currContainerMapEntry.getValue().getValue();\n+        aggregatedaccountReportsDao.updateStorageUsage(accountId, containerId, currStorageUsage);\n+        batchSize++;\n+      }\n+    }\n+    storeMetrics.aggregatedPublishTimeMs.update(System.currentTimeMillis() - startTimeMs);\n+    storeMetrics.aggregatedBatchSize.update(batchSize);\n+  }\n+\n+  /**\n+   * Query mysql database to get all the aggregated container storage usage for given {@code clusterName} and construct\n+   * a map from those data. The map is structured as such:\n+   * <p>Outer map's key is the string format of account id, inner map's key is the string format of container id and the\n+   * value of the inner map is the storage usage of the container.</p>\n+   * @param clusterName the clusterName.\n+   * @return A map that represents container storage usage.\n+   * @throws Exception\n+   */\n+  @Override\n+  public Map<String, Map<String, Long>> queryAggregatedStats(String clusterName) throws Exception {\n+    Map<String, Map<String, Long>> result = new HashMap<>();\n+    aggregatedaccountReportsDao.queryContainerUsageForCluster(clusterName, (accountId, containerId, storageUsage) -> {\n+      result.computeIfAbsent(String.valueOf(accountId), k -> new HashMap<>())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 139}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDU5NzUxMA==", "bodyText": "For aggregated stats, there is only one storage usage. When there is a new value, it will override the old ones in database.", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r530597510", "createdAt": "2020-11-25T19:24:49Z", "author": {"login": "justinlin-linkedin"}, "path": "ambry-server/src/main/java/com/github/ambry/server/mysql/AccountStatsMySqlStore.java", "diffHunk": "@@ -125,21 +137,98 @@ public void publish(StatsWrapper statsWrapper) {\n    * @return {@link StatsSnapshot} published by the given host.\n    * @throws SQLException\n    */\n-  public StatsSnapshot queryStatsSnapshotOf(String clusterName, String hostname) throws SQLException {\n+  @Override\n+  public StatsWrapper queryStatsOf(String clusterName, String hostname) throws SQLException {\n     hostname = hostnameHelper.simplifyHostname(hostname);\n     Map<String, StatsSnapshot> partitionSubMap = new HashMap<>();\n     StatsSnapshot hostSnapshot = new StatsSnapshot((long) 0, partitionSubMap);\n+    AtomicLong timestamp = new AtomicLong(0);\n     accountReportsDao.queryStorageUsageForHost(clusterName, hostname,\n-        (partitionId, accountId, containerId, storageUsage) -> {\n+        (partitionId, accountId, containerId, storageUsage, updatedAtMs) -> {\n           StatsSnapshot partitionSnapshot = hostSnapshot.getSubMap()\n               .computeIfAbsent(\"Partition[\" + partitionId + \"]\", k -> new StatsSnapshot((long) 0, new HashMap<>()));\n           StatsSnapshot accountSnapshot = partitionSnapshot.getSubMap()\n               .computeIfAbsent(\"A[\" + accountId + \"]\", k -> new StatsSnapshot((long) 0, new HashMap<>()));\n           accountSnapshot.getSubMap().put(\"C[\" + containerId + \"]\", new StatsSnapshot(storageUsage, null));\n+          timestamp.set(Math.max(timestamp.get(), updatedAtMs));\n         });\n \n     hostSnapshot.updateValue();\n-    return hostSnapshot;\n+    return new StatsWrapper(\n+        new StatsHeader(StatsHeader.StatsDescription.STORED_DATA_SIZE, timestamp.get(), partitionSubMap.size(),\n+            partitionSubMap.size(), null), hostSnapshot);\n+  }\n+\n+  /**\n+   * Store the aggregated account stats in {@link StatsSnapshot} to mysql database.\n+   * @param snapshot The aggregated account stats snapshot.\n+   */\n+  @Override\n+  public void storeAggregatedStats(StatsSnapshot snapshot) throws SQLException {\n+    int batchSize = 0;\n+    long startTimeMs = System.currentTimeMillis();\n+    for (Map.Entry<String, StatsSnapshot> accountMapEntry : snapshot.getSubMap().entrySet()) {\n+      String accountIdKey = accountMapEntry.getKey();\n+      short accountId = Short.valueOf(accountIdKey.substring(2, accountIdKey.length() - 1));\n+      StatsSnapshot containerStatsSnapshot = accountMapEntry.getValue();\n+      for (Map.Entry<String, StatsSnapshot> currContainerMapEntry : containerStatsSnapshot.getSubMap().entrySet()) {\n+        String containerIdKey = currContainerMapEntry.getKey();\n+        short containerId = Short.valueOf(containerIdKey.substring(2, containerIdKey.length() - 1));\n+        long currStorageUsage = currContainerMapEntry.getValue().getValue();\n+        aggregatedaccountReportsDao.updateStorageUsage(accountId, containerId, currStorageUsage);\n+        batchSize++;\n+      }\n+    }\n+    storeMetrics.aggregatedPublishTimeMs.update(System.currentTimeMillis() - startTimeMs);\n+    storeMetrics.aggregatedBatchSize.update(batchSize);\n+  }\n+\n+  /**\n+   * Query mysql database to get all the aggregated container storage usage for given {@code clusterName} and construct\n+   * a map from those data. The map is structured as such:\n+   * <p>Outer map's key is the string format of account id, inner map's key is the string format of container id and the\n+   * value of the inner map is the storage usage of the container.</p>\n+   * @param clusterName the clusterName.\n+   * @return A map that represents container storage usage.\n+   * @throws Exception\n+   */\n+  @Override\n+  public Map<String, Map<String, Long>> queryAggregatedStats(String clusterName) throws Exception {\n+    Map<String, Map<String, Long>> result = new HashMap<>();\n+    aggregatedaccountReportsDao.queryContainerUsageForCluster(clusterName, (accountId, containerId, storageUsage) -> {\n+      result.computeIfAbsent(String.valueOf(accountId), k -> new HashMap<>())", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDUxNTkzMg=="}, "originalCommit": {"oid": "d0b0dd1056da7d83842274b817d2376a9f5a5177"}, "originalPosition": 139}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyODU2Mzg4OnYy", "diffSide": "RIGHT", "path": "ambry-server/src/main/java/com/github/ambry/server/mysql/AggregatedAccountReportsDao.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQwMDo0Nzo0MlrOH6IEZQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQwMDo0Nzo0MlrOH6IEZQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDcxMTY1Mw==", "bodyText": "nit: montly -> monthly", "url": "https://github.com/linkedin/ambry/pull/1702#discussion_r530711653", "createdAt": "2020-11-26T00:47:42Z", "author": {"login": "cgtz"}, "path": "ambry-server/src/main/java/com/github/ambry/server/mysql/AggregatedAccountReportsDao.java", "diffHunk": "@@ -0,0 +1,237 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.server.mysql;\n+\n+import com.github.ambry.mysql.MySqlDataAccessor;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.util.Objects;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static com.github.ambry.mysql.MySqlDataAccessor.OperationType.*;\n+\n+\n+/**\n+ * AggregatedAccountReports Data Access Object. This object has to deal with three tables\n+ * <ol>\n+ * <li>AggregatedAccountReports</li>\n+ * <li>MonthlyAggregatedAccountReports</li>\n+ * <li>AggregatedAccountReportsMonth</li>\n+ * </ol>\n+ * <p/>\n+ * These tables have similar names, but they serve different purposes.\n+ * <ul>\n+ *   <li>AggregatedAccountReports saves the aggregated container storage usage for each cluster. It will be updated as frequent as the aggregation task is scheduled.</li>\n+ *   <li>MonthlyAggregatedAccountReports makes a copy of data from AggregatedAccountReports at the beginning of every month</li>\n+ *   <li>AggregatedAccountReportsMonth records which month the data is copied to MonthlyAggregatedAccountReports</li>\n+ * </ul>\n+ */\n+public class AggregatedAccountReportsDao {\n+  public static final String AGGREGATED_ACCOUNT_REPORTS_TABLE = \"AggregatedAccountReports\";\n+  public static final String MONTHLY_AGGREGATED_ACCOUNT_REPORTS_TABLE = \"MonthlyAggregatedAccountReports\";\n+  public static final String AGGREGATED_ACCOUNT_REPORTS_MONTH_TABLE = \"AggregatedAccountReportsMonth\";\n+  public static final String CLUSTER_NAME_COLUMN = \"clusterName\";\n+  public static final String ACCOUNT_ID_COLUMN = \"accountId\";\n+  public static final String CONTAINER_ID_COLUMN = \"containerId\";\n+  public static final String STORAGE_USAGE_COLUMN = \"storageUsage\";\n+  public static final String UPDATED_AT_COLUMN = \"updatedAt\";\n+  public static final String MONTH_COLUMN = \"month\";\n+\n+  private static final Logger logger = LoggerFactory.getLogger(AccountReportsDao.class);\n+  private static final String insertSql =\n+      String.format(\"INSERT INTO %s (%s, %s, %s, %s, %s) VALUES (?, ?, ?, ?, NOW())\", AGGREGATED_ACCOUNT_REPORTS_TABLE,\n+          CLUSTER_NAME_COLUMN, ACCOUNT_ID_COLUMN, CONTAINER_ID_COLUMN, STORAGE_USAGE_COLUMN, UPDATED_AT_COLUMN);\n+  private static final String queryUsageSqlForCluster =\n+      String.format(\"SELECT %s, %s, %s FROM %s WHERE %s = ?\", ACCOUNT_ID_COLUMN, CONTAINER_ID_COLUMN,\n+          STORAGE_USAGE_COLUMN, AGGREGATED_ACCOUNT_REPORTS_TABLE, CLUSTER_NAME_COLUMN);\n+  private static final String queryMontlyUsageSqlForCluster =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "10db131a5660aa781b8ab732f838c486eae085a7"}, "originalPosition": 60}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1142, "cost": 1, "resetAt": "2021-11-12T20:44:06Z"}}}