{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzY3NzY3NjU5", "number": 1368, "reviewThreads": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QxNzozMTo1NFrODcttXA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwMDozODoyN1rODdLTwg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxNDM1NjEyOnYy", "diffSide": "RIGHT", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/StaticClusterManager.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QxNzozMTo1NFrOFk5rTQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMFQxNzozODoyNFrOFnvO4g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIzODAyOQ==", "bodyText": "Since we dont really support, do you think throwing an exception might work here?", "url": "https://github.com/linkedin/ambry/pull/1368#discussion_r374238029", "createdAt": "2020-02-03T17:31:54Z", "author": {"login": "ankagrawal"}, "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/StaticClusterManager.java", "diffHunk": "@@ -153,6 +153,11 @@ public MetricRegistry getMetricRegistry() {\n     return metricRegistry;\n   }\n \n+  @Override\n+  public void registerClusterMapListener(ClusterMapChangeListener clusterMapChangeListener) {\n+    // no op for static cluster map.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eb970c85dffe8ec29ab97ceeac61368a13df65c7"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDM0MzIzNA==", "bodyText": "sure, will make the change", "url": "https://github.com/linkedin/ambry/pull/1368#discussion_r374343234", "createdAt": "2020-02-03T21:11:57Z", "author": {"login": "jsjtzyy"}, "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/StaticClusterManager.java", "diffHunk": "@@ -153,6 +153,11 @@ public MetricRegistry getMetricRegistry() {\n     return metricRegistry;\n   }\n \n+  @Override\n+  public void registerClusterMapListener(ClusterMapChangeListener clusterMapChangeListener) {\n+    // no op for static cluster map.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIzODAyOQ=="}, "originalCommit": {"oid": "eb970c85dffe8ec29ab97ceeac61368a13df65c7"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzIxMjY0Mg==", "bodyText": "I think this isnt addressed yet.", "url": "https://github.com/linkedin/ambry/pull/1368#discussion_r377212642", "createdAt": "2020-02-10T17:38:24Z", "author": {"login": "ankagrawal"}, "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/StaticClusterManager.java", "diffHunk": "@@ -153,6 +153,11 @@ public MetricRegistry getMetricRegistry() {\n     return metricRegistry;\n   }\n \n+  @Override\n+  public void registerClusterMapListener(ClusterMapChangeListener clusterMapChangeListener) {\n+    // no op for static cluster map.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIzODAyOQ=="}, "originalCommit": {"oid": "eb970c85dffe8ec29ab97ceeac61368a13df65c7"}, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxNDQyNDI1OnYy", "diffSide": "RIGHT", "path": "ambry-replication/src/main/java/com.github.ambry.replication/ReplicationManager.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QxNzo1NDoxNlrOFk6V-Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQwMjo0NDo1OVrOFmNyRQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI0ODk1Mw==", "bodyText": "If startupLatch is interrupted, could we might miss a replica event?  If yes, then should we throw an exception?", "url": "https://github.com/linkedin/ambry/pull/1368#discussion_r374248953", "createdAt": "2020-02-03T17:54:16Z", "author": {"login": "ankagrawal"}, "path": "ambry-replication/src/main/java/com.github.ambry.replication/ReplicationManager.java", "diffHunk": "@@ -115,8 +127,89 @@ public void start() throws ReplicationException {\n         this.scheduler.scheduleAtFixedRate(persistor, replicationConfig.replicationTokenFlushDelaySeconds,\n             replicationConfig.replicationTokenFlushIntervalSeconds, TimeUnit.SECONDS);\n       }\n+      started = true;\n     } catch (IOException e) {\n       logger.error(\"IO error while starting replication\", e);\n+    } finally {\n+      startupLatch.countDown();\n+    }\n+  }\n+\n+  /**\n+   * {@inheritDoc}\n+   * Note that, this method should be thread-safe because multiple threads (from different cluster change handlers) may\n+   * concurrently update remote replica infos.\n+   */\n+  @Override\n+  public void onReplicaAddedOrRemoved(List<ReplicaId> addedReplicas, List<ReplicaId> removedReplicas) {\n+    // 1. wait for start() to complete\n+    try {\n+      startupLatch.await();\n+    } catch (InterruptedException e) {\n+      logger.warn(\"Waiting for startup is interrupted.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eb970c85dffe8ec29ab97ceeac61368a13df65c7"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTYxNjA2OQ==", "bodyText": "Will throw an IllegalStateException here. Note that, it doesn't help catch up missed event because next time this method is invoked, the pass-in parameters have changed. (For replication manager this is not critical, we still allow whole server to serve traffic temporarily. Missed replica event eventually will generate some error logs and then we can restart this node)", "url": "https://github.com/linkedin/ambry/pull/1368#discussion_r375616069", "createdAt": "2020-02-06T02:44:59Z", "author": {"login": "jsjtzyy"}, "path": "ambry-replication/src/main/java/com.github.ambry.replication/ReplicationManager.java", "diffHunk": "@@ -115,8 +127,89 @@ public void start() throws ReplicationException {\n         this.scheduler.scheduleAtFixedRate(persistor, replicationConfig.replicationTokenFlushDelaySeconds,\n             replicationConfig.replicationTokenFlushIntervalSeconds, TimeUnit.SECONDS);\n       }\n+      started = true;\n     } catch (IOException e) {\n       logger.error(\"IO error while starting replication\", e);\n+    } finally {\n+      startupLatch.countDown();\n+    }\n+  }\n+\n+  /**\n+   * {@inheritDoc}\n+   * Note that, this method should be thread-safe because multiple threads (from different cluster change handlers) may\n+   * concurrently update remote replica infos.\n+   */\n+  @Override\n+  public void onReplicaAddedOrRemoved(List<ReplicaId> addedReplicas, List<ReplicaId> removedReplicas) {\n+    // 1. wait for start() to complete\n+    try {\n+      startupLatch.await();\n+    } catch (InterruptedException e) {\n+      logger.warn(\"Waiting for startup is interrupted.\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI0ODk1Mw=="}, "originalCommit": {"oid": "eb970c85dffe8ec29ab97ceeac61368a13df65c7"}, "originalPosition": 69}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxNDQzMjE2OnYy", "diffSide": "RIGHT", "path": "ambry-replication/src/main/java/com.github.ambry.replication/ReplicationManager.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QxNzo1Njo1NlrOFk6bEw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQyMjoyODo1MFrOFmsawg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI1MDI1OQ==", "bodyText": "Is it possible that we add a replica for a pre-existing store (maybe as a retry, or re-assignment of a partition)? In that case maybe we can read any existing replica token.", "url": "https://github.com/linkedin/ambry/pull/1368#discussion_r374250259", "createdAt": "2020-02-03T17:56:56Z", "author": {"login": "ankagrawal"}, "path": "ambry-replication/src/main/java/com.github.ambry.replication/ReplicationManager.java", "diffHunk": "@@ -115,8 +127,89 @@ public void start() throws ReplicationException {\n         this.scheduler.scheduleAtFixedRate(persistor, replicationConfig.replicationTokenFlushDelaySeconds,\n             replicationConfig.replicationTokenFlushIntervalSeconds, TimeUnit.SECONDS);\n       }\n+      started = true;\n     } catch (IOException e) {\n       logger.error(\"IO error while starting replication\", e);\n+    } finally {\n+      startupLatch.countDown();\n+    }\n+  }\n+\n+  /**\n+   * {@inheritDoc}\n+   * Note that, this method should be thread-safe because multiple threads (from different cluster change handlers) may\n+   * concurrently update remote replica infos.\n+   */\n+  @Override\n+  public void onReplicaAddedOrRemoved(List<ReplicaId> addedReplicas, List<ReplicaId> removedReplicas) {\n+    // 1. wait for start() to complete\n+    try {\n+      startupLatch.await();\n+    } catch (InterruptedException e) {\n+      logger.warn(\"Waiting for startup is interrupted.\");\n+    }\n+    if (started) {\n+      // Read-write lock avoids contention between addReplica()/removeReplica() and onReplicaAddedOrRemoved() methods.\n+      // Read lock for current method should suffice because multiple threads from cluster change handlers should be able\n+      // to access partitionToPartitionInfo map. Each thead only updates PartitionInfo of certain partition and synchronization\n+      // is only required within PartitionInfo. Also, addRemoteReplicaInfoToReplicaThread() is thread-safe which allows\n+      // several threads from cluster change handlers to add remoteReplicaInfo\n+      rwLock.readLock().lock();\n+      try {\n+        // 2. determine if added/removed replicas have peer replica on local node.\n+        //    We skip the replica on current node because it should already be added/removed by state transition thread.\n+        Set<ReplicaId> addedPeerReplicas = addedReplicas.stream()\n+            .filter(r -> partitionToPartitionInfo.containsKey(r.getPartitionId()) && r.getDataNodeId() != currentNode)\n+            .collect(Collectors.toSet());\n+        Set<ReplicaId> removedPeerReplicas = removedReplicas.stream()\n+            .filter(r -> partitionToPartitionInfo.containsKey(r.getPartitionId()) && r.getDataNodeId() != currentNode)\n+            .collect(Collectors.toSet());\n+\n+        // No additional synchronization is required because cluster change handler of each dc only updates replica-threads\n+        // belonging to certain dc. Hence, there is only one thread adding/removing remote replicas within a certain dc.\n+\n+        // 3. create replicaInfo for new remote replicas and assign them to replica-threads.\n+        List<RemoteReplicaInfo> replicaInfosToAdd = new ArrayList<>();\n+        for (ReplicaId remoteReplica : addedPeerReplicas) {\n+          PartitionInfo partitionInfo = partitionToPartitionInfo.get(remoteReplica.getPartitionId());\n+          // create findToken, remoteReplicaInfo\n+          FindToken findToken =\n+              this.tokenHelper.getFindTokenFactoryFromReplicaType(remoteReplica.getReplicaType()).getNewFindToken();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eb970c85dffe8ec29ab97ceeac61368a13df65c7"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjExNzk1NA==", "bodyText": "This is a good point. For now, let's start with creating a brand new replica token because dynamically adding/removing remote replicas should be infrequent. I will keep your point in mind when merging this with PR #1355 .", "url": "https://github.com/linkedin/ambry/pull/1368#discussion_r376117954", "createdAt": "2020-02-06T22:28:50Z", "author": {"login": "jsjtzyy"}, "path": "ambry-replication/src/main/java/com.github.ambry.replication/ReplicationManager.java", "diffHunk": "@@ -115,8 +127,89 @@ public void start() throws ReplicationException {\n         this.scheduler.scheduleAtFixedRate(persistor, replicationConfig.replicationTokenFlushDelaySeconds,\n             replicationConfig.replicationTokenFlushIntervalSeconds, TimeUnit.SECONDS);\n       }\n+      started = true;\n     } catch (IOException e) {\n       logger.error(\"IO error while starting replication\", e);\n+    } finally {\n+      startupLatch.countDown();\n+    }\n+  }\n+\n+  /**\n+   * {@inheritDoc}\n+   * Note that, this method should be thread-safe because multiple threads (from different cluster change handlers) may\n+   * concurrently update remote replica infos.\n+   */\n+  @Override\n+  public void onReplicaAddedOrRemoved(List<ReplicaId> addedReplicas, List<ReplicaId> removedReplicas) {\n+    // 1. wait for start() to complete\n+    try {\n+      startupLatch.await();\n+    } catch (InterruptedException e) {\n+      logger.warn(\"Waiting for startup is interrupted.\");\n+    }\n+    if (started) {\n+      // Read-write lock avoids contention between addReplica()/removeReplica() and onReplicaAddedOrRemoved() methods.\n+      // Read lock for current method should suffice because multiple threads from cluster change handlers should be able\n+      // to access partitionToPartitionInfo map. Each thead only updates PartitionInfo of certain partition and synchronization\n+      // is only required within PartitionInfo. Also, addRemoteReplicaInfoToReplicaThread() is thread-safe which allows\n+      // several threads from cluster change handlers to add remoteReplicaInfo\n+      rwLock.readLock().lock();\n+      try {\n+        // 2. determine if added/removed replicas have peer replica on local node.\n+        //    We skip the replica on current node because it should already be added/removed by state transition thread.\n+        Set<ReplicaId> addedPeerReplicas = addedReplicas.stream()\n+            .filter(r -> partitionToPartitionInfo.containsKey(r.getPartitionId()) && r.getDataNodeId() != currentNode)\n+            .collect(Collectors.toSet());\n+        Set<ReplicaId> removedPeerReplicas = removedReplicas.stream()\n+            .filter(r -> partitionToPartitionInfo.containsKey(r.getPartitionId()) && r.getDataNodeId() != currentNode)\n+            .collect(Collectors.toSet());\n+\n+        // No additional synchronization is required because cluster change handler of each dc only updates replica-threads\n+        // belonging to certain dc. Hence, there is only one thread adding/removing remote replicas within a certain dc.\n+\n+        // 3. create replicaInfo for new remote replicas and assign them to replica-threads.\n+        List<RemoteReplicaInfo> replicaInfosToAdd = new ArrayList<>();\n+        for (ReplicaId remoteReplica : addedPeerReplicas) {\n+          PartitionInfo partitionInfo = partitionToPartitionInfo.get(remoteReplica.getPartitionId());\n+          // create findToken, remoteReplicaInfo\n+          FindToken findToken =\n+              this.tokenHelper.getFindTokenFactoryFromReplicaType(remoteReplica.getReplicaType()).getNewFindToken();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI1MDI1OQ=="}, "originalCommit": {"oid": "eb970c85dffe8ec29ab97ceeac61368a13df65c7"}, "originalPosition": 97}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxNDQ0ODAxOnYy", "diffSide": "RIGHT", "path": "ambry-replication/src/main/java/com.github.ambry.replication/ReplicationManager.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QxODowMjoxNVrOFk6lFQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQyMjo0MToyMlrOFmstmw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI1MjgyMQ==", "bodyText": "Looks like this method will be called either for replicas being added or removed. We should use a boolean then (e.g, isRemove), instead of two lists.", "url": "https://github.com/linkedin/ambry/pull/1368#discussion_r374252821", "createdAt": "2020-02-03T18:02:15Z", "author": {"login": "ankagrawal"}, "path": "ambry-replication/src/main/java/com.github.ambry.replication/ReplicationManager.java", "diffHunk": "@@ -115,8 +127,89 @@ public void start() throws ReplicationException {\n         this.scheduler.scheduleAtFixedRate(persistor, replicationConfig.replicationTokenFlushDelaySeconds,\n             replicationConfig.replicationTokenFlushIntervalSeconds, TimeUnit.SECONDS);\n       }\n+      started = true;\n     } catch (IOException e) {\n       logger.error(\"IO error while starting replication\", e);\n+    } finally {\n+      startupLatch.countDown();\n+    }\n+  }\n+\n+  /**\n+   * {@inheritDoc}\n+   * Note that, this method should be thread-safe because multiple threads (from different cluster change handlers) may\n+   * concurrently update remote replica infos.\n+   */\n+  @Override\n+  public void onReplicaAddedOrRemoved(List<ReplicaId> addedReplicas, List<ReplicaId> removedReplicas) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eb970c85dffe8ec29ab97ceeac61368a13df65c7"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjEyMjc3OQ==", "bodyText": "I see your point but the method is invoked by InstanceConfig change and there could be both added and removed replica within a single InstanceConfig change. We pass in two lists (can be empty) and let replication manager handle both cases at the same time.", "url": "https://github.com/linkedin/ambry/pull/1368#discussion_r376122779", "createdAt": "2020-02-06T22:41:22Z", "author": {"login": "jsjtzyy"}, "path": "ambry-replication/src/main/java/com.github.ambry.replication/ReplicationManager.java", "diffHunk": "@@ -115,8 +127,89 @@ public void start() throws ReplicationException {\n         this.scheduler.scheduleAtFixedRate(persistor, replicationConfig.replicationTokenFlushDelaySeconds,\n             replicationConfig.replicationTokenFlushIntervalSeconds, TimeUnit.SECONDS);\n       }\n+      started = true;\n     } catch (IOException e) {\n       logger.error(\"IO error while starting replication\", e);\n+    } finally {\n+      startupLatch.countDown();\n+    }\n+  }\n+\n+  /**\n+   * {@inheritDoc}\n+   * Note that, this method should be thread-safe because multiple threads (from different cluster change handlers) may\n+   * concurrently update remote replica infos.\n+   */\n+  @Override\n+  public void onReplicaAddedOrRemoved(List<ReplicaId> addedReplicas, List<ReplicaId> removedReplicas) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI1MjgyMQ=="}, "originalCommit": {"oid": "eb970c85dffe8ec29ab97ceeac61368a13df65c7"}, "originalPosition": 64}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxNDQ2NjQ0OnYy", "diffSide": "RIGHT", "path": "ambry-replication/src/main/java/com.github.ambry.replication/ReplicationManager.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QxODowODo1NlrOFk6wlA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQyMjozNDo1M1rOFmskNg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI1NTc2NA==", "bodyText": "Also it looks like we have some duplicate code between this method and addReplica/removeReplica methods. Can we try to refactor?", "url": "https://github.com/linkedin/ambry/pull/1368#discussion_r374255764", "createdAt": "2020-02-03T18:08:56Z", "author": {"login": "ankagrawal"}, "path": "ambry-replication/src/main/java/com.github.ambry.replication/ReplicationManager.java", "diffHunk": "@@ -115,8 +127,89 @@ public void start() throws ReplicationException {\n         this.scheduler.scheduleAtFixedRate(persistor, replicationConfig.replicationTokenFlushDelaySeconds,\n             replicationConfig.replicationTokenFlushIntervalSeconds, TimeUnit.SECONDS);\n       }\n+      started = true;\n     } catch (IOException e) {\n       logger.error(\"IO error while starting replication\", e);\n+    } finally {\n+      startupLatch.countDown();\n+    }\n+  }\n+\n+  /**\n+   * {@inheritDoc}\n+   * Note that, this method should be thread-safe because multiple threads (from different cluster change handlers) may\n+   * concurrently update remote replica infos.\n+   */\n+  @Override\n+  public void onReplicaAddedOrRemoved(List<ReplicaId> addedReplicas, List<ReplicaId> removedReplicas) {\n+    // 1. wait for start() to complete\n+    try {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eb970c85dffe8ec29ab97ceeac61368a13df65c7"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjEyMDM3NA==", "bodyText": "addReplica(), removeReplica() are methods for changing replicas on local node. They create a new PartitionInfo along with all peer RemoteReplicaInfos. onReplicaAddedOrRemoved() basically modifies existing PartitionInfo by adding/removing certain RemoteReplicaInfo. Refactoring will be considered in a separate PR after we have verified functionality of this change.", "url": "https://github.com/linkedin/ambry/pull/1368#discussion_r376120374", "createdAt": "2020-02-06T22:34:53Z", "author": {"login": "jsjtzyy"}, "path": "ambry-replication/src/main/java/com.github.ambry.replication/ReplicationManager.java", "diffHunk": "@@ -115,8 +127,89 @@ public void start() throws ReplicationException {\n         this.scheduler.scheduleAtFixedRate(persistor, replicationConfig.replicationTokenFlushDelaySeconds,\n             replicationConfig.replicationTokenFlushIntervalSeconds, TimeUnit.SECONDS);\n       }\n+      started = true;\n     } catch (IOException e) {\n       logger.error(\"IO error while starting replication\", e);\n+    } finally {\n+      startupLatch.countDown();\n+    }\n+  }\n+\n+  /**\n+   * {@inheritDoc}\n+   * Note that, this method should be thread-safe because multiple threads (from different cluster change handlers) may\n+   * concurrently update remote replica infos.\n+   */\n+  @Override\n+  public void onReplicaAddedOrRemoved(List<ReplicaId> addedReplicas, List<ReplicaId> removedReplicas) {\n+    // 1. wait for start() to complete\n+    try {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI1NTc2NA=="}, "originalCommit": {"oid": "eb970c85dffe8ec29ab97ceeac61368a13df65c7"}, "originalPosition": 66}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxOTExMzcyOnYy", "diffSide": "RIGHT", "path": "ambry-replication/src/main/java/com.github.ambry.replication/ReplicationManager.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQyMzo0NzowNlrOFlne4g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQyMjo1NDo1M1rOFmtB0Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDk4ODUxNA==", "bodyText": "I suggest adding a private class to serve as the implementation of ClusterMapChangeListener, just like PartitionStateChangeListener.", "url": "https://github.com/linkedin/ambry/pull/1368#discussion_r374988514", "createdAt": "2020-02-04T23:47:06Z", "author": {"login": "justinlin-linkedin"}, "path": "ambry-replication/src/main/java/com.github.ambry.replication/ReplicationManager.java", "diffHunk": "@@ -115,8 +127,89 @@ public void start() throws ReplicationException {\n         this.scheduler.scheduleAtFixedRate(persistor, replicationConfig.replicationTokenFlushDelaySeconds,\n             replicationConfig.replicationTokenFlushIntervalSeconds, TimeUnit.SECONDS);\n       }\n+      started = true;\n     } catch (IOException e) {\n       logger.error(\"IO error while starting replication\", e);\n+    } finally {\n+      startupLatch.countDown();\n+    }\n+  }\n+\n+  /**\n+   * {@inheritDoc}\n+   * Note that, this method should be thread-safe because multiple threads (from different cluster change handlers) may\n+   * concurrently update remote replica infos.\n+   */\n+  @Override\n+  public void onReplicaAddedOrRemoved(List<ReplicaId> addedReplicas, List<ReplicaId> removedReplicas) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eb970c85dffe8ec29ab97ceeac61368a13df65c7"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjEyNzk1Mw==", "bodyText": "Any benefits we can get by doing so? One probably reason I come up with is: when unifying all existing replication managers into a general replication manager, it requires 2 clustermap change listeners taking actions against changes in VCR and regular Ambry cluster. Feel free to add more thoughts here.", "url": "https://github.com/linkedin/ambry/pull/1368#discussion_r376127953", "createdAt": "2020-02-06T22:54:53Z", "author": {"login": "jsjtzyy"}, "path": "ambry-replication/src/main/java/com.github.ambry.replication/ReplicationManager.java", "diffHunk": "@@ -115,8 +127,89 @@ public void start() throws ReplicationException {\n         this.scheduler.scheduleAtFixedRate(persistor, replicationConfig.replicationTokenFlushDelaySeconds,\n             replicationConfig.replicationTokenFlushIntervalSeconds, TimeUnit.SECONDS);\n       }\n+      started = true;\n     } catch (IOException e) {\n       logger.error(\"IO error while starting replication\", e);\n+    } finally {\n+      startupLatch.countDown();\n+    }\n+  }\n+\n+  /**\n+   * {@inheritDoc}\n+   * Note that, this method should be thread-safe because multiple threads (from different cluster change handlers) may\n+   * concurrently update remote replica infos.\n+   */\n+  @Override\n+  public void onReplicaAddedOrRemoved(List<ReplicaId> addedReplicas, List<ReplicaId> removedReplicas) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDk4ODUxNA=="}, "originalCommit": {"oid": "eb970c85dffe8ec29ab97ceeac61368a13df65c7"}, "originalPosition": 64}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxOTE3NjY2OnYy", "diffSide": "RIGHT", "path": "ambry-replication/src/main/java/com.github.ambry.replication/PartitionInfo.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwMDoyMTozNlrOFloFXg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQyMjo1MDoyNlrOFms7Gw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDk5ODM2Ng==", "bodyText": "please lock getRemoveReplicaInfos method as well, this lock is protecting remoteReplicas list, we should lock it everywhere we use it.", "url": "https://github.com/linkedin/ambry/pull/1368#discussion_r374998366", "createdAt": "2020-02-05T00:21:36Z", "author": {"login": "justinlin-linkedin"}, "path": "ambry-replication/src/main/java/com.github.ambry.replication/PartitionInfo.java", "diffHunk": "@@ -50,6 +53,44 @@ public ReplicaId getLocalReplicaId() {\n     return this.localReplicaId;\n   }\n \n+  /**\n+   * Add {@link RemoteReplicaInfo} to this {@link PartitionInfo} if it is previously absent.\n+   * @param remoteReplicaInfo the {@link RemoteReplicaInfo} to add.\n+   * @return {@code true} if remote replica info is added. {@code false} if it is already present\n+   */\n+  boolean addReplicaInfoIfAbsent(RemoteReplicaInfo remoteReplicaInfo) {\n+    lock.lock();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eb970c85dffe8ec29ab97ceeac61368a13df65c7"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjEyNjIzNQ==", "bodyText": "make sense, i will use read-write lock instead", "url": "https://github.com/linkedin/ambry/pull/1368#discussion_r376126235", "createdAt": "2020-02-06T22:50:26Z", "author": {"login": "jsjtzyy"}, "path": "ambry-replication/src/main/java/com.github.ambry.replication/PartitionInfo.java", "diffHunk": "@@ -50,6 +53,44 @@ public ReplicaId getLocalReplicaId() {\n     return this.localReplicaId;\n   }\n \n+  /**\n+   * Add {@link RemoteReplicaInfo} to this {@link PartitionInfo} if it is previously absent.\n+   * @param remoteReplicaInfo the {@link RemoteReplicaInfo} to add.\n+   * @return {@code true} if remote replica info is added. {@code false} if it is already present\n+   */\n+  boolean addReplicaInfoIfAbsent(RemoteReplicaInfo remoteReplicaInfo) {\n+    lock.lock();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDk5ODM2Ng=="}, "originalCommit": {"oid": "eb970c85dffe8ec29ab97ceeac61368a13df65c7"}, "originalPosition": 27}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxOTE4NjQxOnYy", "diffSide": "RIGHT", "path": "ambry-replication/src/main/java/com.github.ambry.replication/ReplicationManager.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwMDoyNzoyNVrOFloLTA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQyMzo1Mzo1N1rOFmuO1g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDk5OTg4NA==", "bodyText": "we should only add remoteReplicaInfo to the \"toAdd\" list when it was successfully added to partitionInfo, so we should move this statement in the if-else statement above.", "url": "https://github.com/linkedin/ambry/pull/1368#discussion_r374999884", "createdAt": "2020-02-05T00:27:25Z", "author": {"login": "justinlin-linkedin"}, "path": "ambry-replication/src/main/java/com.github.ambry.replication/ReplicationManager.java", "diffHunk": "@@ -115,8 +127,89 @@ public void start() throws ReplicationException {\n         this.scheduler.scheduleAtFixedRate(persistor, replicationConfig.replicationTokenFlushDelaySeconds,\n             replicationConfig.replicationTokenFlushIntervalSeconds, TimeUnit.SECONDS);\n       }\n+      started = true;\n     } catch (IOException e) {\n       logger.error(\"IO error while starting replication\", e);\n+    } finally {\n+      startupLatch.countDown();\n+    }\n+  }\n+\n+  /**\n+   * {@inheritDoc}\n+   * Note that, this method should be thread-safe because multiple threads (from different cluster change handlers) may\n+   * concurrently update remote replica infos.\n+   */\n+  @Override\n+  public void onReplicaAddedOrRemoved(List<ReplicaId> addedReplicas, List<ReplicaId> removedReplicas) {\n+    // 1. wait for start() to complete\n+    try {\n+      startupLatch.await();\n+    } catch (InterruptedException e) {\n+      logger.warn(\"Waiting for startup is interrupted.\");\n+    }\n+    if (started) {\n+      // Read-write lock avoids contention between addReplica()/removeReplica() and onReplicaAddedOrRemoved() methods.\n+      // Read lock for current method should suffice because multiple threads from cluster change handlers should be able\n+      // to access partitionToPartitionInfo map. Each thead only updates PartitionInfo of certain partition and synchronization\n+      // is only required within PartitionInfo. Also, addRemoteReplicaInfoToReplicaThread() is thread-safe which allows\n+      // several threads from cluster change handlers to add remoteReplicaInfo\n+      rwLock.readLock().lock();\n+      try {\n+        // 2. determine if added/removed replicas have peer replica on local node.\n+        //    We skip the replica on current node because it should already be added/removed by state transition thread.\n+        Set<ReplicaId> addedPeerReplicas = addedReplicas.stream()\n+            .filter(r -> partitionToPartitionInfo.containsKey(r.getPartitionId()) && r.getDataNodeId() != currentNode)\n+            .collect(Collectors.toSet());\n+        Set<ReplicaId> removedPeerReplicas = removedReplicas.stream()\n+            .filter(r -> partitionToPartitionInfo.containsKey(r.getPartitionId()) && r.getDataNodeId() != currentNode)\n+            .collect(Collectors.toSet());\n+\n+        // No additional synchronization is required because cluster change handler of each dc only updates replica-threads\n+        // belonging to certain dc. Hence, there is only one thread adding/removing remote replicas within a certain dc.\n+\n+        // 3. create replicaInfo for new remote replicas and assign them to replica-threads.\n+        List<RemoteReplicaInfo> replicaInfosToAdd = new ArrayList<>();\n+        for (ReplicaId remoteReplica : addedPeerReplicas) {\n+          PartitionInfo partitionInfo = partitionToPartitionInfo.get(remoteReplica.getPartitionId());\n+          // create findToken, remoteReplicaInfo\n+          FindToken findToken =\n+              this.tokenHelper.getFindTokenFactoryFromReplicaType(remoteReplica.getReplicaType()).getNewFindToken();\n+          RemoteReplicaInfo remoteReplicaInfo =\n+              new RemoteReplicaInfo(remoteReplica, partitionInfo.getLocalReplicaId(), partitionInfo.getStore(),\n+                  findToken,\n+                  TimeUnit.SECONDS.toMillis(storeConfig.storeDataFlushIntervalSeconds) * Replication_Delay_Multiplier,\n+                  SystemTime.getInstance(), remoteReplica.getDataNodeId().getPortToConnectTo());\n+          logger.info(\"Adding remote replica {} on {} to partition info.\", remoteReplica.getReplicaPath(),\n+              remoteReplica.getDataNodeId());\n+          if (partitionInfo.addReplicaInfoIfAbsent(remoteReplicaInfo)) {\n+            replicationMetrics.addMetricsForRemoteReplicaInfo(remoteReplicaInfo);\n+          }\n+          replicaInfosToAdd.add(remoteReplicaInfo);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eb970c85dffe8ec29ab97ceeac61368a13df65c7"}, "originalPosition": 108}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjE0NzY3MA==", "bodyText": "Correct, will fix this.", "url": "https://github.com/linkedin/ambry/pull/1368#discussion_r376147670", "createdAt": "2020-02-06T23:53:57Z", "author": {"login": "jsjtzyy"}, "path": "ambry-replication/src/main/java/com.github.ambry.replication/ReplicationManager.java", "diffHunk": "@@ -115,8 +127,89 @@ public void start() throws ReplicationException {\n         this.scheduler.scheduleAtFixedRate(persistor, replicationConfig.replicationTokenFlushDelaySeconds,\n             replicationConfig.replicationTokenFlushIntervalSeconds, TimeUnit.SECONDS);\n       }\n+      started = true;\n     } catch (IOException e) {\n       logger.error(\"IO error while starting replication\", e);\n+    } finally {\n+      startupLatch.countDown();\n+    }\n+  }\n+\n+  /**\n+   * {@inheritDoc}\n+   * Note that, this method should be thread-safe because multiple threads (from different cluster change handlers) may\n+   * concurrently update remote replica infos.\n+   */\n+  @Override\n+  public void onReplicaAddedOrRemoved(List<ReplicaId> addedReplicas, List<ReplicaId> removedReplicas) {\n+    // 1. wait for start() to complete\n+    try {\n+      startupLatch.await();\n+    } catch (InterruptedException e) {\n+      logger.warn(\"Waiting for startup is interrupted.\");\n+    }\n+    if (started) {\n+      // Read-write lock avoids contention between addReplica()/removeReplica() and onReplicaAddedOrRemoved() methods.\n+      // Read lock for current method should suffice because multiple threads from cluster change handlers should be able\n+      // to access partitionToPartitionInfo map. Each thead only updates PartitionInfo of certain partition and synchronization\n+      // is only required within PartitionInfo. Also, addRemoteReplicaInfoToReplicaThread() is thread-safe which allows\n+      // several threads from cluster change handlers to add remoteReplicaInfo\n+      rwLock.readLock().lock();\n+      try {\n+        // 2. determine if added/removed replicas have peer replica on local node.\n+        //    We skip the replica on current node because it should already be added/removed by state transition thread.\n+        Set<ReplicaId> addedPeerReplicas = addedReplicas.stream()\n+            .filter(r -> partitionToPartitionInfo.containsKey(r.getPartitionId()) && r.getDataNodeId() != currentNode)\n+            .collect(Collectors.toSet());\n+        Set<ReplicaId> removedPeerReplicas = removedReplicas.stream()\n+            .filter(r -> partitionToPartitionInfo.containsKey(r.getPartitionId()) && r.getDataNodeId() != currentNode)\n+            .collect(Collectors.toSet());\n+\n+        // No additional synchronization is required because cluster change handler of each dc only updates replica-threads\n+        // belonging to certain dc. Hence, there is only one thread adding/removing remote replicas within a certain dc.\n+\n+        // 3. create replicaInfo for new remote replicas and assign them to replica-threads.\n+        List<RemoteReplicaInfo> replicaInfosToAdd = new ArrayList<>();\n+        for (ReplicaId remoteReplica : addedPeerReplicas) {\n+          PartitionInfo partitionInfo = partitionToPartitionInfo.get(remoteReplica.getPartitionId());\n+          // create findToken, remoteReplicaInfo\n+          FindToken findToken =\n+              this.tokenHelper.getFindTokenFactoryFromReplicaType(remoteReplica.getReplicaType()).getNewFindToken();\n+          RemoteReplicaInfo remoteReplicaInfo =\n+              new RemoteReplicaInfo(remoteReplica, partitionInfo.getLocalReplicaId(), partitionInfo.getStore(),\n+                  findToken,\n+                  TimeUnit.SECONDS.toMillis(storeConfig.storeDataFlushIntervalSeconds) * Replication_Delay_Multiplier,\n+                  SystemTime.getInstance(), remoteReplica.getDataNodeId().getPortToConnectTo());\n+          logger.info(\"Adding remote replica {} on {} to partition info.\", remoteReplica.getReplicaPath(),\n+              remoteReplica.getDataNodeId());\n+          if (partitionInfo.addReplicaInfoIfAbsent(remoteReplicaInfo)) {\n+            replicationMetrics.addMetricsForRemoteReplicaInfo(remoteReplicaInfo);\n+          }\n+          replicaInfosToAdd.add(remoteReplicaInfo);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDk5OTg4NA=="}, "originalCommit": {"oid": "eb970c85dffe8ec29ab97ceeac61368a13df65c7"}, "originalPosition": 108}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxOTIwNDAwOnYy", "diffSide": "RIGHT", "path": "ambry-replication/src/main/java/com.github.ambry.replication/ReplicationManager.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwMDozNzo0M1rOFloVhg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QwMDoyNzoyOFrOFmuyvg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAwMjUwMg==", "bodyText": "why do we need this? we can just change the PartitionInfo's remove method to take a replica id as parameter, and looping the list in PartitionInfo, it's more aligned with addReplicaInfo.", "url": "https://github.com/linkedin/ambry/pull/1368#discussion_r375002502", "createdAt": "2020-02-05T00:37:43Z", "author": {"login": "justinlin-linkedin"}, "path": "ambry-replication/src/main/java/com.github.ambry.replication/ReplicationManager.java", "diffHunk": "@@ -115,8 +127,89 @@ public void start() throws ReplicationException {\n         this.scheduler.scheduleAtFixedRate(persistor, replicationConfig.replicationTokenFlushDelaySeconds,\n             replicationConfig.replicationTokenFlushIntervalSeconds, TimeUnit.SECONDS);\n       }\n+      started = true;\n     } catch (IOException e) {\n       logger.error(\"IO error while starting replication\", e);\n+    } finally {\n+      startupLatch.countDown();\n+    }\n+  }\n+\n+  /**\n+   * {@inheritDoc}\n+   * Note that, this method should be thread-safe because multiple threads (from different cluster change handlers) may\n+   * concurrently update remote replica infos.\n+   */\n+  @Override\n+  public void onReplicaAddedOrRemoved(List<ReplicaId> addedReplicas, List<ReplicaId> removedReplicas) {\n+    // 1. wait for start() to complete\n+    try {\n+      startupLatch.await();\n+    } catch (InterruptedException e) {\n+      logger.warn(\"Waiting for startup is interrupted.\");\n+    }\n+    if (started) {\n+      // Read-write lock avoids contention between addReplica()/removeReplica() and onReplicaAddedOrRemoved() methods.\n+      // Read lock for current method should suffice because multiple threads from cluster change handlers should be able\n+      // to access partitionToPartitionInfo map. Each thead only updates PartitionInfo of certain partition and synchronization\n+      // is only required within PartitionInfo. Also, addRemoteReplicaInfoToReplicaThread() is thread-safe which allows\n+      // several threads from cluster change handlers to add remoteReplicaInfo\n+      rwLock.readLock().lock();\n+      try {\n+        // 2. determine if added/removed replicas have peer replica on local node.\n+        //    We skip the replica on current node because it should already be added/removed by state transition thread.\n+        Set<ReplicaId> addedPeerReplicas = addedReplicas.stream()\n+            .filter(r -> partitionToPartitionInfo.containsKey(r.getPartitionId()) && r.getDataNodeId() != currentNode)\n+            .collect(Collectors.toSet());\n+        Set<ReplicaId> removedPeerReplicas = removedReplicas.stream()\n+            .filter(r -> partitionToPartitionInfo.containsKey(r.getPartitionId()) && r.getDataNodeId() != currentNode)\n+            .collect(Collectors.toSet());\n+\n+        // No additional synchronization is required because cluster change handler of each dc only updates replica-threads\n+        // belonging to certain dc. Hence, there is only one thread adding/removing remote replicas within a certain dc.\n+\n+        // 3. create replicaInfo for new remote replicas and assign them to replica-threads.\n+        List<RemoteReplicaInfo> replicaInfosToAdd = new ArrayList<>();\n+        for (ReplicaId remoteReplica : addedPeerReplicas) {\n+          PartitionInfo partitionInfo = partitionToPartitionInfo.get(remoteReplica.getPartitionId());\n+          // create findToken, remoteReplicaInfo\n+          FindToken findToken =\n+              this.tokenHelper.getFindTokenFactoryFromReplicaType(remoteReplica.getReplicaType()).getNewFindToken();\n+          RemoteReplicaInfo remoteReplicaInfo =\n+              new RemoteReplicaInfo(remoteReplica, partitionInfo.getLocalReplicaId(), partitionInfo.getStore(),\n+                  findToken,\n+                  TimeUnit.SECONDS.toMillis(storeConfig.storeDataFlushIntervalSeconds) * Replication_Delay_Multiplier,\n+                  SystemTime.getInstance(), remoteReplica.getDataNodeId().getPortToConnectTo());\n+          logger.info(\"Adding remote replica {} on {} to partition info.\", remoteReplica.getReplicaPath(),\n+              remoteReplica.getDataNodeId());\n+          if (partitionInfo.addReplicaInfoIfAbsent(remoteReplicaInfo)) {\n+            replicationMetrics.addMetricsForRemoteReplicaInfo(remoteReplicaInfo);\n+          }\n+          replicaInfosToAdd.add(remoteReplicaInfo);\n+        }\n+        addRemoteReplicaInfoToReplicaThread(replicaInfosToAdd, true);\n+\n+        // 4. remove replicaInfo from existing partitionInfo and replica-threads\n+        List<RemoteReplicaInfo> replicaInfosToRemove = new ArrayList<>();\n+        for (ReplicaId remoteReplica : removedPeerReplicas) {\n+          PartitionInfo partitionInfo = partitionToPartitionInfo.get(remoteReplica.getPartitionId());\n+          List<RemoteReplicaInfo> remoteReplicaInfos = new ArrayList<>(partitionInfo.getRemoteReplicaInfos());\n+          for (RemoteReplicaInfo remoteReplicaInfo : remoteReplicaInfos) {\n+            if (remoteReplicaInfo.getReplicaId().getDataNodeId() == remoteReplica.getDataNodeId()) {\n+              logger.info(\"Removing remote replica {} on {} from replica threads.\", remoteReplica.getReplicaPath(),\n+                  remoteReplica.getDataNodeId());\n+              replicaInfosToRemove.add(remoteReplicaInfo);\n+              if (partitionInfo.removeRelicaInfoIfPresent(remoteReplicaInfo)) {\n+                replicationMetrics.removeMetricsForRemoteReplicaInfo(remoteReplicaInfo);\n+              }\n+              break;\n+            }\n+          }\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eb970c85dffe8ec29ab97ceeac61368a13df65c7"}, "originalPosition": 128}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjE1Njg2Mg==", "bodyText": "right, will change removeRelicaInfoIfPresent", "url": "https://github.com/linkedin/ambry/pull/1368#discussion_r376156862", "createdAt": "2020-02-07T00:27:28Z", "author": {"login": "jsjtzyy"}, "path": "ambry-replication/src/main/java/com.github.ambry.replication/ReplicationManager.java", "diffHunk": "@@ -115,8 +127,89 @@ public void start() throws ReplicationException {\n         this.scheduler.scheduleAtFixedRate(persistor, replicationConfig.replicationTokenFlushDelaySeconds,\n             replicationConfig.replicationTokenFlushIntervalSeconds, TimeUnit.SECONDS);\n       }\n+      started = true;\n     } catch (IOException e) {\n       logger.error(\"IO error while starting replication\", e);\n+    } finally {\n+      startupLatch.countDown();\n+    }\n+  }\n+\n+  /**\n+   * {@inheritDoc}\n+   * Note that, this method should be thread-safe because multiple threads (from different cluster change handlers) may\n+   * concurrently update remote replica infos.\n+   */\n+  @Override\n+  public void onReplicaAddedOrRemoved(List<ReplicaId> addedReplicas, List<ReplicaId> removedReplicas) {\n+    // 1. wait for start() to complete\n+    try {\n+      startupLatch.await();\n+    } catch (InterruptedException e) {\n+      logger.warn(\"Waiting for startup is interrupted.\");\n+    }\n+    if (started) {\n+      // Read-write lock avoids contention between addReplica()/removeReplica() and onReplicaAddedOrRemoved() methods.\n+      // Read lock for current method should suffice because multiple threads from cluster change handlers should be able\n+      // to access partitionToPartitionInfo map. Each thead only updates PartitionInfo of certain partition and synchronization\n+      // is only required within PartitionInfo. Also, addRemoteReplicaInfoToReplicaThread() is thread-safe which allows\n+      // several threads from cluster change handlers to add remoteReplicaInfo\n+      rwLock.readLock().lock();\n+      try {\n+        // 2. determine if added/removed replicas have peer replica on local node.\n+        //    We skip the replica on current node because it should already be added/removed by state transition thread.\n+        Set<ReplicaId> addedPeerReplicas = addedReplicas.stream()\n+            .filter(r -> partitionToPartitionInfo.containsKey(r.getPartitionId()) && r.getDataNodeId() != currentNode)\n+            .collect(Collectors.toSet());\n+        Set<ReplicaId> removedPeerReplicas = removedReplicas.stream()\n+            .filter(r -> partitionToPartitionInfo.containsKey(r.getPartitionId()) && r.getDataNodeId() != currentNode)\n+            .collect(Collectors.toSet());\n+\n+        // No additional synchronization is required because cluster change handler of each dc only updates replica-threads\n+        // belonging to certain dc. Hence, there is only one thread adding/removing remote replicas within a certain dc.\n+\n+        // 3. create replicaInfo for new remote replicas and assign them to replica-threads.\n+        List<RemoteReplicaInfo> replicaInfosToAdd = new ArrayList<>();\n+        for (ReplicaId remoteReplica : addedPeerReplicas) {\n+          PartitionInfo partitionInfo = partitionToPartitionInfo.get(remoteReplica.getPartitionId());\n+          // create findToken, remoteReplicaInfo\n+          FindToken findToken =\n+              this.tokenHelper.getFindTokenFactoryFromReplicaType(remoteReplica.getReplicaType()).getNewFindToken();\n+          RemoteReplicaInfo remoteReplicaInfo =\n+              new RemoteReplicaInfo(remoteReplica, partitionInfo.getLocalReplicaId(), partitionInfo.getStore(),\n+                  findToken,\n+                  TimeUnit.SECONDS.toMillis(storeConfig.storeDataFlushIntervalSeconds) * Replication_Delay_Multiplier,\n+                  SystemTime.getInstance(), remoteReplica.getDataNodeId().getPortToConnectTo());\n+          logger.info(\"Adding remote replica {} on {} to partition info.\", remoteReplica.getReplicaPath(),\n+              remoteReplica.getDataNodeId());\n+          if (partitionInfo.addReplicaInfoIfAbsent(remoteReplicaInfo)) {\n+            replicationMetrics.addMetricsForRemoteReplicaInfo(remoteReplicaInfo);\n+          }\n+          replicaInfosToAdd.add(remoteReplicaInfo);\n+        }\n+        addRemoteReplicaInfoToReplicaThread(replicaInfosToAdd, true);\n+\n+        // 4. remove replicaInfo from existing partitionInfo and replica-threads\n+        List<RemoteReplicaInfo> replicaInfosToRemove = new ArrayList<>();\n+        for (ReplicaId remoteReplica : removedPeerReplicas) {\n+          PartitionInfo partitionInfo = partitionToPartitionInfo.get(remoteReplica.getPartitionId());\n+          List<RemoteReplicaInfo> remoteReplicaInfos = new ArrayList<>(partitionInfo.getRemoteReplicaInfos());\n+          for (RemoteReplicaInfo remoteReplicaInfo : remoteReplicaInfos) {\n+            if (remoteReplicaInfo.getReplicaId().getDataNodeId() == remoteReplica.getDataNodeId()) {\n+              logger.info(\"Removing remote replica {} on {} from replica threads.\", remoteReplica.getReplicaPath(),\n+                  remoteReplica.getDataNodeId());\n+              replicaInfosToRemove.add(remoteReplicaInfo);\n+              if (partitionInfo.removeRelicaInfoIfPresent(remoteReplicaInfo)) {\n+                replicationMetrics.removeMetricsForRemoteReplicaInfo(remoteReplicaInfo);\n+              }\n+              break;\n+            }\n+          }\n+        }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAwMjUwMg=="}, "originalCommit": {"oid": "eb970c85dffe8ec29ab97ceeac61368a13df65c7"}, "originalPosition": 128}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxOTIwNTc4OnYy", "diffSide": "RIGHT", "path": "ambry-replication/src/main/java/com.github.ambry.replication/ReplicationManager.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwMDozODoyN1rOFloWdw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQyMzo1NDo1OVrOFmuP2g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAwMjc0Mw==", "bodyText": "And we should put this statement within if-else statement as well.", "url": "https://github.com/linkedin/ambry/pull/1368#discussion_r375002743", "createdAt": "2020-02-05T00:38:27Z", "author": {"login": "justinlin-linkedin"}, "path": "ambry-replication/src/main/java/com.github.ambry.replication/ReplicationManager.java", "diffHunk": "@@ -115,8 +127,89 @@ public void start() throws ReplicationException {\n         this.scheduler.scheduleAtFixedRate(persistor, replicationConfig.replicationTokenFlushDelaySeconds,\n             replicationConfig.replicationTokenFlushIntervalSeconds, TimeUnit.SECONDS);\n       }\n+      started = true;\n     } catch (IOException e) {\n       logger.error(\"IO error while starting replication\", e);\n+    } finally {\n+      startupLatch.countDown();\n+    }\n+  }\n+\n+  /**\n+   * {@inheritDoc}\n+   * Note that, this method should be thread-safe because multiple threads (from different cluster change handlers) may\n+   * concurrently update remote replica infos.\n+   */\n+  @Override\n+  public void onReplicaAddedOrRemoved(List<ReplicaId> addedReplicas, List<ReplicaId> removedReplicas) {\n+    // 1. wait for start() to complete\n+    try {\n+      startupLatch.await();\n+    } catch (InterruptedException e) {\n+      logger.warn(\"Waiting for startup is interrupted.\");\n+    }\n+    if (started) {\n+      // Read-write lock avoids contention between addReplica()/removeReplica() and onReplicaAddedOrRemoved() methods.\n+      // Read lock for current method should suffice because multiple threads from cluster change handlers should be able\n+      // to access partitionToPartitionInfo map. Each thead only updates PartitionInfo of certain partition and synchronization\n+      // is only required within PartitionInfo. Also, addRemoteReplicaInfoToReplicaThread() is thread-safe which allows\n+      // several threads from cluster change handlers to add remoteReplicaInfo\n+      rwLock.readLock().lock();\n+      try {\n+        // 2. determine if added/removed replicas have peer replica on local node.\n+        //    We skip the replica on current node because it should already be added/removed by state transition thread.\n+        Set<ReplicaId> addedPeerReplicas = addedReplicas.stream()\n+            .filter(r -> partitionToPartitionInfo.containsKey(r.getPartitionId()) && r.getDataNodeId() != currentNode)\n+            .collect(Collectors.toSet());\n+        Set<ReplicaId> removedPeerReplicas = removedReplicas.stream()\n+            .filter(r -> partitionToPartitionInfo.containsKey(r.getPartitionId()) && r.getDataNodeId() != currentNode)\n+            .collect(Collectors.toSet());\n+\n+        // No additional synchronization is required because cluster change handler of each dc only updates replica-threads\n+        // belonging to certain dc. Hence, there is only one thread adding/removing remote replicas within a certain dc.\n+\n+        // 3. create replicaInfo for new remote replicas and assign them to replica-threads.\n+        List<RemoteReplicaInfo> replicaInfosToAdd = new ArrayList<>();\n+        for (ReplicaId remoteReplica : addedPeerReplicas) {\n+          PartitionInfo partitionInfo = partitionToPartitionInfo.get(remoteReplica.getPartitionId());\n+          // create findToken, remoteReplicaInfo\n+          FindToken findToken =\n+              this.tokenHelper.getFindTokenFactoryFromReplicaType(remoteReplica.getReplicaType()).getNewFindToken();\n+          RemoteReplicaInfo remoteReplicaInfo =\n+              new RemoteReplicaInfo(remoteReplica, partitionInfo.getLocalReplicaId(), partitionInfo.getStore(),\n+                  findToken,\n+                  TimeUnit.SECONDS.toMillis(storeConfig.storeDataFlushIntervalSeconds) * Replication_Delay_Multiplier,\n+                  SystemTime.getInstance(), remoteReplica.getDataNodeId().getPortToConnectTo());\n+          logger.info(\"Adding remote replica {} on {} to partition info.\", remoteReplica.getReplicaPath(),\n+              remoteReplica.getDataNodeId());\n+          if (partitionInfo.addReplicaInfoIfAbsent(remoteReplicaInfo)) {\n+            replicationMetrics.addMetricsForRemoteReplicaInfo(remoteReplicaInfo);\n+          }\n+          replicaInfosToAdd.add(remoteReplicaInfo);\n+        }\n+        addRemoteReplicaInfoToReplicaThread(replicaInfosToAdd, true);\n+\n+        // 4. remove replicaInfo from existing partitionInfo and replica-threads\n+        List<RemoteReplicaInfo> replicaInfosToRemove = new ArrayList<>();\n+        for (ReplicaId remoteReplica : removedPeerReplicas) {\n+          PartitionInfo partitionInfo = partitionToPartitionInfo.get(remoteReplica.getPartitionId());\n+          List<RemoteReplicaInfo> remoteReplicaInfos = new ArrayList<>(partitionInfo.getRemoteReplicaInfos());\n+          for (RemoteReplicaInfo remoteReplicaInfo : remoteReplicaInfos) {\n+            if (remoteReplicaInfo.getReplicaId().getDataNodeId() == remoteReplica.getDataNodeId()) {\n+              logger.info(\"Removing remote replica {} on {} from replica threads.\", remoteReplica.getReplicaPath(),\n+                  remoteReplica.getDataNodeId());\n+              replicaInfosToRemove.add(remoteReplicaInfo);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eb970c85dffe8ec29ab97ceeac61368a13df65c7"}, "originalPosition": 121}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjE0NzkzMA==", "bodyText": "will fix", "url": "https://github.com/linkedin/ambry/pull/1368#discussion_r376147930", "createdAt": "2020-02-06T23:54:59Z", "author": {"login": "jsjtzyy"}, "path": "ambry-replication/src/main/java/com.github.ambry.replication/ReplicationManager.java", "diffHunk": "@@ -115,8 +127,89 @@ public void start() throws ReplicationException {\n         this.scheduler.scheduleAtFixedRate(persistor, replicationConfig.replicationTokenFlushDelaySeconds,\n             replicationConfig.replicationTokenFlushIntervalSeconds, TimeUnit.SECONDS);\n       }\n+      started = true;\n     } catch (IOException e) {\n       logger.error(\"IO error while starting replication\", e);\n+    } finally {\n+      startupLatch.countDown();\n+    }\n+  }\n+\n+  /**\n+   * {@inheritDoc}\n+   * Note that, this method should be thread-safe because multiple threads (from different cluster change handlers) may\n+   * concurrently update remote replica infos.\n+   */\n+  @Override\n+  public void onReplicaAddedOrRemoved(List<ReplicaId> addedReplicas, List<ReplicaId> removedReplicas) {\n+    // 1. wait for start() to complete\n+    try {\n+      startupLatch.await();\n+    } catch (InterruptedException e) {\n+      logger.warn(\"Waiting for startup is interrupted.\");\n+    }\n+    if (started) {\n+      // Read-write lock avoids contention between addReplica()/removeReplica() and onReplicaAddedOrRemoved() methods.\n+      // Read lock for current method should suffice because multiple threads from cluster change handlers should be able\n+      // to access partitionToPartitionInfo map. Each thead only updates PartitionInfo of certain partition and synchronization\n+      // is only required within PartitionInfo. Also, addRemoteReplicaInfoToReplicaThread() is thread-safe which allows\n+      // several threads from cluster change handlers to add remoteReplicaInfo\n+      rwLock.readLock().lock();\n+      try {\n+        // 2. determine if added/removed replicas have peer replica on local node.\n+        //    We skip the replica on current node because it should already be added/removed by state transition thread.\n+        Set<ReplicaId> addedPeerReplicas = addedReplicas.stream()\n+            .filter(r -> partitionToPartitionInfo.containsKey(r.getPartitionId()) && r.getDataNodeId() != currentNode)\n+            .collect(Collectors.toSet());\n+        Set<ReplicaId> removedPeerReplicas = removedReplicas.stream()\n+            .filter(r -> partitionToPartitionInfo.containsKey(r.getPartitionId()) && r.getDataNodeId() != currentNode)\n+            .collect(Collectors.toSet());\n+\n+        // No additional synchronization is required because cluster change handler of each dc only updates replica-threads\n+        // belonging to certain dc. Hence, there is only one thread adding/removing remote replicas within a certain dc.\n+\n+        // 3. create replicaInfo for new remote replicas and assign them to replica-threads.\n+        List<RemoteReplicaInfo> replicaInfosToAdd = new ArrayList<>();\n+        for (ReplicaId remoteReplica : addedPeerReplicas) {\n+          PartitionInfo partitionInfo = partitionToPartitionInfo.get(remoteReplica.getPartitionId());\n+          // create findToken, remoteReplicaInfo\n+          FindToken findToken =\n+              this.tokenHelper.getFindTokenFactoryFromReplicaType(remoteReplica.getReplicaType()).getNewFindToken();\n+          RemoteReplicaInfo remoteReplicaInfo =\n+              new RemoteReplicaInfo(remoteReplica, partitionInfo.getLocalReplicaId(), partitionInfo.getStore(),\n+                  findToken,\n+                  TimeUnit.SECONDS.toMillis(storeConfig.storeDataFlushIntervalSeconds) * Replication_Delay_Multiplier,\n+                  SystemTime.getInstance(), remoteReplica.getDataNodeId().getPortToConnectTo());\n+          logger.info(\"Adding remote replica {} on {} to partition info.\", remoteReplica.getReplicaPath(),\n+              remoteReplica.getDataNodeId());\n+          if (partitionInfo.addReplicaInfoIfAbsent(remoteReplicaInfo)) {\n+            replicationMetrics.addMetricsForRemoteReplicaInfo(remoteReplicaInfo);\n+          }\n+          replicaInfosToAdd.add(remoteReplicaInfo);\n+        }\n+        addRemoteReplicaInfoToReplicaThread(replicaInfosToAdd, true);\n+\n+        // 4. remove replicaInfo from existing partitionInfo and replica-threads\n+        List<RemoteReplicaInfo> replicaInfosToRemove = new ArrayList<>();\n+        for (ReplicaId remoteReplica : removedPeerReplicas) {\n+          PartitionInfo partitionInfo = partitionToPartitionInfo.get(remoteReplica.getPartitionId());\n+          List<RemoteReplicaInfo> remoteReplicaInfos = new ArrayList<>(partitionInfo.getRemoteReplicaInfos());\n+          for (RemoteReplicaInfo remoteReplicaInfo : remoteReplicaInfos) {\n+            if (remoteReplicaInfo.getReplicaId().getDataNodeId() == remoteReplica.getDataNodeId()) {\n+              logger.info(\"Removing remote replica {} on {} from replica threads.\", remoteReplica.getReplicaPath(),\n+                  remoteReplica.getDataNodeId());\n+              replicaInfosToRemove.add(remoteReplicaInfo);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAwMjc0Mw=="}, "originalCommit": {"oid": "eb970c85dffe8ec29ab97ceeac61368a13df65c7"}, "originalPosition": 121}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1674, "cost": 1, "resetAt": "2021-11-12T20:44:06Z"}}}