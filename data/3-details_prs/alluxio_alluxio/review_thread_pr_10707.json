{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzYwMTc3NzEy", "number": 10707, "reviewThreads": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wN1QyMToyNTo1NVrODWX6GQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMVQwMDoyMTowNlrODXTPbA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI0Nzg2OTY5OnYy", "diffSide": "RIGHT", "path": "core/client/fs/src/main/java/alluxio/client/file/cache/LocalCacheFileSystem.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wN1QyMToyNTo1NVrOFbGQMA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wOFQxODoyNjoxM1rOFbfxNw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzk1ODMyMA==", "bodyText": "I don't feel very good about this constructor. It seems counter-intuitive to have the fsContext as an argument here.\nThere is already an fsContext embededed within the fs object. Is there a better way to access it?", "url": "https://github.com/Alluxio/alluxio/pull/10707#discussion_r363958320", "createdAt": "2020-01-07T21:25:55Z", "author": {"login": "ZacBlanco"}, "path": "core/client/fs/src/main/java/alluxio/client/file/cache/LocalCacheFileSystem.java", "diffHunk": "@@ -23,14 +24,16 @@\n public class LocalCacheFileSystem extends DelegatingFileSystem {\n \n   private final LocalCacheManager mLocalCacheManager;\n+  private final FileSystemContext mFsContext;\n \n   /**\n    * @param fs a FileSystem instance to query on local cache miss\n    */\n-  public LocalCacheFileSystem(FileSystem fs) {\n+  public LocalCacheFileSystem(FileSystem fs, FileSystemContext fsContext) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "685ebe7a66030e81b56d88237fc7434668c306b1"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDM3NjM3NQ==", "bodyText": "I don't see a way to access it unless we expose it from the FileSystem interface.", "url": "https://github.com/Alluxio/alluxio/pull/10707#discussion_r364376375", "createdAt": "2020-01-08T18:26:13Z", "author": {"login": "bf8086"}, "path": "core/client/fs/src/main/java/alluxio/client/file/cache/LocalCacheFileSystem.java", "diffHunk": "@@ -23,14 +24,16 @@\n public class LocalCacheFileSystem extends DelegatingFileSystem {\n \n   private final LocalCacheManager mLocalCacheManager;\n+  private final FileSystemContext mFsContext;\n \n   /**\n    * @param fs a FileSystem instance to query on local cache miss\n    */\n-  public LocalCacheFileSystem(FileSystem fs) {\n+  public LocalCacheFileSystem(FileSystem fs, FileSystemContext fsContext) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzk1ODMyMA=="}, "originalCommit": {"oid": "685ebe7a66030e81b56d88237fc7434668c306b1"}, "originalPosition": 18}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI0NzkzOTU1OnYy", "diffSide": "RIGHT", "path": "core/client/fs/src/main/java/alluxio/client/file/cache/LocalCacheManager.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wN1QyMTo1Mzo0NFrOFbG8GA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wOVQwMTo1MjoxMVrOFbpA5Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzk2OTU2MA==", "bodyText": "do we ever need to make this configurable?", "url": "https://github.com/Alluxio/alluxio/pull/10707#discussion_r363969560", "createdAt": "2020-01-07T21:53:44Z", "author": {"login": "ZacBlanco"}, "path": "core/client/fs/src/main/java/alluxio/client/file/cache/LocalCacheManager.java", "diffHunk": "@@ -11,74 +11,251 @@\n \n package alluxio.client.file.cache;\n \n+import alluxio.client.file.FileSystemContext;\n+import alluxio.collections.Pair;\n+import alluxio.conf.PropertyKey;\n+import alluxio.resource.LockResource;\n+import alluxio.util.io.BufferUtils;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Preconditions;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import java.io.ByteArrayInputStream;\n+import java.io.ByteArrayOutputStream;\n import java.io.IOException;\n+import java.nio.channels.Channels;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.util.Arrays;\n+import java.util.concurrent.locks.ReadWriteLock;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n \n+import javax.annotation.concurrent.GuardedBy;\n import javax.annotation.concurrent.ThreadSafe;\n \n /**\n- * A class to manage cached pages. This class will\n- * 1. Ensure thread-safety\n- * 2. Bookkeep Cache Replacement Alg\n+ * A class to manage cached pages. This class coordinates different components to respond for\n+ * thread-safety and operate cache replacement policies.\n  *\n+ * Lock hierarchy in this class: All operations must follow this order to operate on pages:\n+ * <ul>\n+ * <li>1. Acquire page lock</li>\n+ * <li>2. Acquire metastore lock mMetaLock</li>\n+ * <li>3. Release metastore lock mMetaLock</li>\n+ * <li>4. Release page lock</li>\n+ * </ul>\n  */\n @ThreadSafe\n public class LocalCacheManager {\n   private static final Logger LOG = LoggerFactory.getLogger(LocalCacheManager.class);\n+  /** Number of page locks to strip. */\n+  private static int PAGE_LOCK_SIZE = 256;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "685ebe7a66030e81b56d88237fc7434668c306b1"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDM3NTk1Nw==", "bodyText": "Doesn't hurt to add a property.", "url": "https://github.com/Alluxio/alluxio/pull/10707#discussion_r364375957", "createdAt": "2020-01-08T18:25:13Z", "author": {"login": "bf8086"}, "path": "core/client/fs/src/main/java/alluxio/client/file/cache/LocalCacheManager.java", "diffHunk": "@@ -11,74 +11,251 @@\n \n package alluxio.client.file.cache;\n \n+import alluxio.client.file.FileSystemContext;\n+import alluxio.collections.Pair;\n+import alluxio.conf.PropertyKey;\n+import alluxio.resource.LockResource;\n+import alluxio.util.io.BufferUtils;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Preconditions;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import java.io.ByteArrayInputStream;\n+import java.io.ByteArrayOutputStream;\n import java.io.IOException;\n+import java.nio.channels.Channels;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.util.Arrays;\n+import java.util.concurrent.locks.ReadWriteLock;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n \n+import javax.annotation.concurrent.GuardedBy;\n import javax.annotation.concurrent.ThreadSafe;\n \n /**\n- * A class to manage cached pages. This class will\n- * 1. Ensure thread-safety\n- * 2. Bookkeep Cache Replacement Alg\n+ * A class to manage cached pages. This class coordinates different components to respond for\n+ * thread-safety and operate cache replacement policies.\n  *\n+ * Lock hierarchy in this class: All operations must follow this order to operate on pages:\n+ * <ul>\n+ * <li>1. Acquire page lock</li>\n+ * <li>2. Acquire metastore lock mMetaLock</li>\n+ * <li>3. Release metastore lock mMetaLock</li>\n+ * <li>4. Release page lock</li>\n+ * </ul>\n  */\n @ThreadSafe\n public class LocalCacheManager {\n   private static final Logger LOG = LoggerFactory.getLogger(LocalCacheManager.class);\n+  /** Number of page locks to strip. */\n+  private static int PAGE_LOCK_SIZE = 256;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzk2OTU2MA=="}, "originalCommit": {"oid": "685ebe7a66030e81b56d88237fc7434668c306b1"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDUyNzg0NQ==", "bodyText": "this is a very internal config and I don't expect the users to tune this value.\nGiven we have already too many configuration keys, I would leave this a constant large enough, e.g., a few thousands.", "url": "https://github.com/Alluxio/alluxio/pull/10707#discussion_r364527845", "createdAt": "2020-01-09T01:52:11Z", "author": {"login": "apc999"}, "path": "core/client/fs/src/main/java/alluxio/client/file/cache/LocalCacheManager.java", "diffHunk": "@@ -11,74 +11,251 @@\n \n package alluxio.client.file.cache;\n \n+import alluxio.client.file.FileSystemContext;\n+import alluxio.collections.Pair;\n+import alluxio.conf.PropertyKey;\n+import alluxio.resource.LockResource;\n+import alluxio.util.io.BufferUtils;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Preconditions;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import java.io.ByteArrayInputStream;\n+import java.io.ByteArrayOutputStream;\n import java.io.IOException;\n+import java.nio.channels.Channels;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.util.Arrays;\n+import java.util.concurrent.locks.ReadWriteLock;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n \n+import javax.annotation.concurrent.GuardedBy;\n import javax.annotation.concurrent.ThreadSafe;\n \n /**\n- * A class to manage cached pages. This class will\n- * 1. Ensure thread-safety\n- * 2. Bookkeep Cache Replacement Alg\n+ * A class to manage cached pages. This class coordinates different components to respond for\n+ * thread-safety and operate cache replacement policies.\n  *\n+ * Lock hierarchy in this class: All operations must follow this order to operate on pages:\n+ * <ul>\n+ * <li>1. Acquire page lock</li>\n+ * <li>2. Acquire metastore lock mMetaLock</li>\n+ * <li>3. Release metastore lock mMetaLock</li>\n+ * <li>4. Release page lock</li>\n+ * </ul>\n  */\n @ThreadSafe\n public class LocalCacheManager {\n   private static final Logger LOG = LoggerFactory.getLogger(LocalCacheManager.class);\n+  /** Number of page locks to strip. */\n+  private static int PAGE_LOCK_SIZE = 256;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzk2OTU2MA=="}, "originalCommit": {"oid": "685ebe7a66030e81b56d88237fc7434668c306b1"}, "originalPosition": 47}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI0ODY3MjE3OnYy", "diffSide": "RIGHT", "path": "core/client/fs/src/main/java/alluxio/client/file/cache/LocalCacheManager.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wOFQwNjo0NToxOFrOFbN3rA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wOFQyMDo1NTo0MlrOFbjlmg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDA4MzExNg==", "bodyText": "shouldn't it be mPageStore.size() based on my convo with @ZacBlanco", "url": "https://github.com/Alluxio/alluxio/pull/10707#discussion_r364083116", "createdAt": "2020-01-08T06:45:18Z", "author": {"login": "apc999"}, "path": "core/client/fs/src/main/java/alluxio/client/file/cache/LocalCacheManager.java", "diffHunk": "@@ -11,74 +11,253 @@\n \n package alluxio.client.file.cache;\n \n+import alluxio.client.file.FileSystemContext;\n+import alluxio.collections.Pair;\n+import alluxio.conf.PropertyKey;\n+import alluxio.resource.LockResource;\n+import alluxio.util.io.BufferUtils;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Preconditions;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import java.io.ByteArrayInputStream;\n+import java.io.ByteArrayOutputStream;\n import java.io.IOException;\n+import java.nio.channels.Channels;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.util.Arrays;\n+import java.util.concurrent.locks.ReadWriteLock;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n \n+import javax.annotation.concurrent.GuardedBy;\n import javax.annotation.concurrent.ThreadSafe;\n \n /**\n- * A class to manage cached pages. This class will\n- * 1. Ensure thread-safety\n- * 2. Bookkeep Cache Replacement Alg\n+ * A class to manage cached pages. This class coordinates different components to respond for\n+ * thread-safety and operate cache replacement policies.\n  *\n+ * Lock hierarchy in this class: All operations must follow this order to operate on pages:\n+ * <ul>\n+ * <li>1. Acquire page lock</li>\n+ * <li>2. Acquire metastore lock mMetaLock</li>\n+ * <li>3. Release metastore lock mMetaLock</li>\n+ * <li>4. Release page lock</li>\n+ * </ul>\n  */\n @ThreadSafe\n public class LocalCacheManager {\n   private static final Logger LOG = LoggerFactory.getLogger(LocalCacheManager.class);\n \n-  private final CacheEvictor mEvictor = CacheEvictor.create();\n-  private final PageStore mPageStore = PageStore.create();\n-  private final MetaStore mMetaStore = new MetaStore();\n+  private final int mPageSize;\n+  private final long mCacheSize;\n+  private final int mLockSize;\n+  private final CacheEvictor mEvictor;\n+  /** A readwrite lock pool to guard individual pages based on striping. */\n+  private final ReadWriteLock[] mPageLocks;\n+  private final PageStore mPageStore;\n+  /** A readwrite lock to guard metadata operations. */\n+  private final ReadWriteLock mMetaLock = new ReentrantReadWriteLock();\n+  @GuardedBy(\"mMetaLock\")\n+  private final MetaStore mMetaStore;\n+  private final FileSystemContext mFsContext;\n+\n+  /**\n+   * @param fsContext filesystem context\n+   */\n+  public LocalCacheManager(FileSystemContext fsContext) {\n+    this(fsContext, new MetaStore(), PageStore.create(), CacheEvictor.create());\n+  }\n \n-  public LocalCacheManager() {\n+  /**\n+   * @param fsContext filesystem context\n+   */\n+  @VisibleForTesting\n+  LocalCacheManager(FileSystemContext fsContext, MetaStore metaStore,\n+                    PageStore pageStore, CacheEvictor evictor) {\n+    mFsContext = fsContext;\n+    mMetaStore = metaStore;\n+    mPageStore = pageStore;\n+    mEvictor = evictor;\n+    mPageSize = (int) mFsContext.getClusterConf().getBytes(PropertyKey.USER_CLIENT_CACHE_PAGE_SIZE);\n+    mCacheSize = mFsContext.getClusterConf().getBytes(PropertyKey.USER_CLIENT_CACHE_SIZE);\n+    mLockSize = mFsContext.getClusterConf().getInt(PropertyKey.USER_CLIENT_CACHE_LOCK_SIZE);\n+    mPageLocks = new ReentrantReadWriteLock[mLockSize];\n+    for (int i = 0; i < mLockSize; i++) {\n+      mPageLocks[i] = new ReentrantReadWriteLock();\n+    }\n+  }\n+\n+  /**\n+   * Gets the lock for a particular page. Note that multiple pages may share the same lock as lock\n+   * striping is used to reduce resource overhead for locks.\n+   *\n+   * @param fileId file identifier\n+   * @param pageIndex index of the page within the file\n+   * @return the corresponding page lock\n+   */\n+  private ReadWriteLock getPageLock(long fileId, long pageIndex) {\n+    return mPageLocks[(int) (fileId + pageIndex) % mLockSize];\n+  }\n+\n+  /**\n+   * Gets a pair of locks to operate two given pages. One MUST acquire the first lock followed by\n+   * the second lock.\n+   *\n+   * @param fileId file identifier\n+   * @param pageIndex index of the page within the file\n+   * @param fileId2 file identifier\n+   * @param pageIndex2 index of the page within the file\n+   * @return the corresponding page lock pair\n+   */\n+  private Pair<ReadWriteLock, ReadWriteLock> getPageLockPair(long fileId, long pageIndex,\n+      long fileId2, long pageIndex2) {\n+    if (fileId + pageIndex < fileId2 + pageIndex2) {\n+      return new Pair<>(getPageLock(fileId, pageIndex), getPageLock(fileId2, pageIndex2));\n+    } else {\n+      return new Pair<>(getPageLock(fileId2, pageIndex2), getPageLock(fileId, pageIndex));\n+    }\n   }\n \n   /**\n-   * Writes a new page from a source channel to the store.\n+   * Writes a new page from a source channel with best effort.\n    *\n-   * @param pageId page ID\n+   * @param fileId file identifier\n+   * @param pageIndex index of the page within the file\n    * @param src source channel to read this new page\n    * @throws IOException\n    * @return the number of bytes written\n    */\n-  int put(long pageId, ReadableByteChannel src) throws IOException {\n-    mMetaStore.addPage(pageId);\n-    mPageStore.put(pageId, src);\n-    return 0;\n+  public int put(long fileId, long pageIndex, ReadableByteChannel src) throws IOException {\n+    long victimFileId = 0;\n+    long victimPageIndex = 0;\n+\n+    ReadWriteLock pageLock = getPageLock(fileId, pageIndex);\n+    try (LockResource r = new LockResource(pageLock.writeLock())) {\n+      boolean alreadyCached;\n+      boolean needEvict = false;\n+      try (LockResource r2 = new LockResource(mMetaLock.writeLock())) {\n+        alreadyCached = mMetaStore.hasPage(fileId, pageIndex);\n+        if (!alreadyCached) {\n+          needEvict = (mPageSize + mMetaStore.size()) > mCacheSize;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3d77abf0fa9d247dcc8a8f6d10035a34907486e5"}, "originalPosition": 147}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDM4MzczOA==", "bodyText": "I don't see it on the PageStore interface yet. Should I go ahead and add it?", "url": "https://github.com/Alluxio/alluxio/pull/10707#discussion_r364383738", "createdAt": "2020-01-08T18:43:20Z", "author": {"login": "bf8086"}, "path": "core/client/fs/src/main/java/alluxio/client/file/cache/LocalCacheManager.java", "diffHunk": "@@ -11,74 +11,253 @@\n \n package alluxio.client.file.cache;\n \n+import alluxio.client.file.FileSystemContext;\n+import alluxio.collections.Pair;\n+import alluxio.conf.PropertyKey;\n+import alluxio.resource.LockResource;\n+import alluxio.util.io.BufferUtils;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Preconditions;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import java.io.ByteArrayInputStream;\n+import java.io.ByteArrayOutputStream;\n import java.io.IOException;\n+import java.nio.channels.Channels;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.util.Arrays;\n+import java.util.concurrent.locks.ReadWriteLock;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n \n+import javax.annotation.concurrent.GuardedBy;\n import javax.annotation.concurrent.ThreadSafe;\n \n /**\n- * A class to manage cached pages. This class will\n- * 1. Ensure thread-safety\n- * 2. Bookkeep Cache Replacement Alg\n+ * A class to manage cached pages. This class coordinates different components to respond for\n+ * thread-safety and operate cache replacement policies.\n  *\n+ * Lock hierarchy in this class: All operations must follow this order to operate on pages:\n+ * <ul>\n+ * <li>1. Acquire page lock</li>\n+ * <li>2. Acquire metastore lock mMetaLock</li>\n+ * <li>3. Release metastore lock mMetaLock</li>\n+ * <li>4. Release page lock</li>\n+ * </ul>\n  */\n @ThreadSafe\n public class LocalCacheManager {\n   private static final Logger LOG = LoggerFactory.getLogger(LocalCacheManager.class);\n \n-  private final CacheEvictor mEvictor = CacheEvictor.create();\n-  private final PageStore mPageStore = PageStore.create();\n-  private final MetaStore mMetaStore = new MetaStore();\n+  private final int mPageSize;\n+  private final long mCacheSize;\n+  private final int mLockSize;\n+  private final CacheEvictor mEvictor;\n+  /** A readwrite lock pool to guard individual pages based on striping. */\n+  private final ReadWriteLock[] mPageLocks;\n+  private final PageStore mPageStore;\n+  /** A readwrite lock to guard metadata operations. */\n+  private final ReadWriteLock mMetaLock = new ReentrantReadWriteLock();\n+  @GuardedBy(\"mMetaLock\")\n+  private final MetaStore mMetaStore;\n+  private final FileSystemContext mFsContext;\n+\n+  /**\n+   * @param fsContext filesystem context\n+   */\n+  public LocalCacheManager(FileSystemContext fsContext) {\n+    this(fsContext, new MetaStore(), PageStore.create(), CacheEvictor.create());\n+  }\n \n-  public LocalCacheManager() {\n+  /**\n+   * @param fsContext filesystem context\n+   */\n+  @VisibleForTesting\n+  LocalCacheManager(FileSystemContext fsContext, MetaStore metaStore,\n+                    PageStore pageStore, CacheEvictor evictor) {\n+    mFsContext = fsContext;\n+    mMetaStore = metaStore;\n+    mPageStore = pageStore;\n+    mEvictor = evictor;\n+    mPageSize = (int) mFsContext.getClusterConf().getBytes(PropertyKey.USER_CLIENT_CACHE_PAGE_SIZE);\n+    mCacheSize = mFsContext.getClusterConf().getBytes(PropertyKey.USER_CLIENT_CACHE_SIZE);\n+    mLockSize = mFsContext.getClusterConf().getInt(PropertyKey.USER_CLIENT_CACHE_LOCK_SIZE);\n+    mPageLocks = new ReentrantReadWriteLock[mLockSize];\n+    for (int i = 0; i < mLockSize; i++) {\n+      mPageLocks[i] = new ReentrantReadWriteLock();\n+    }\n+  }\n+\n+  /**\n+   * Gets the lock for a particular page. Note that multiple pages may share the same lock as lock\n+   * striping is used to reduce resource overhead for locks.\n+   *\n+   * @param fileId file identifier\n+   * @param pageIndex index of the page within the file\n+   * @return the corresponding page lock\n+   */\n+  private ReadWriteLock getPageLock(long fileId, long pageIndex) {\n+    return mPageLocks[(int) (fileId + pageIndex) % mLockSize];\n+  }\n+\n+  /**\n+   * Gets a pair of locks to operate two given pages. One MUST acquire the first lock followed by\n+   * the second lock.\n+   *\n+   * @param fileId file identifier\n+   * @param pageIndex index of the page within the file\n+   * @param fileId2 file identifier\n+   * @param pageIndex2 index of the page within the file\n+   * @return the corresponding page lock pair\n+   */\n+  private Pair<ReadWriteLock, ReadWriteLock> getPageLockPair(long fileId, long pageIndex,\n+      long fileId2, long pageIndex2) {\n+    if (fileId + pageIndex < fileId2 + pageIndex2) {\n+      return new Pair<>(getPageLock(fileId, pageIndex), getPageLock(fileId2, pageIndex2));\n+    } else {\n+      return new Pair<>(getPageLock(fileId2, pageIndex2), getPageLock(fileId, pageIndex));\n+    }\n   }\n \n   /**\n-   * Writes a new page from a source channel to the store.\n+   * Writes a new page from a source channel with best effort.\n    *\n-   * @param pageId page ID\n+   * @param fileId file identifier\n+   * @param pageIndex index of the page within the file\n    * @param src source channel to read this new page\n    * @throws IOException\n    * @return the number of bytes written\n    */\n-  int put(long pageId, ReadableByteChannel src) throws IOException {\n-    mMetaStore.addPage(pageId);\n-    mPageStore.put(pageId, src);\n-    return 0;\n+  public int put(long fileId, long pageIndex, ReadableByteChannel src) throws IOException {\n+    long victimFileId = 0;\n+    long victimPageIndex = 0;\n+\n+    ReadWriteLock pageLock = getPageLock(fileId, pageIndex);\n+    try (LockResource r = new LockResource(pageLock.writeLock())) {\n+      boolean alreadyCached;\n+      boolean needEvict = false;\n+      try (LockResource r2 = new LockResource(mMetaLock.writeLock())) {\n+        alreadyCached = mMetaStore.hasPage(fileId, pageIndex);\n+        if (!alreadyCached) {\n+          needEvict = (mPageSize + mMetaStore.size()) > mCacheSize;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDA4MzExNg=="}, "originalCommit": {"oid": "3d77abf0fa9d247dcc8a8f6d10035a34907486e5"}, "originalPosition": 147}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDQzODkzOA==", "bodyText": "Refactored the method to PageStore.", "url": "https://github.com/Alluxio/alluxio/pull/10707#discussion_r364438938", "createdAt": "2020-01-08T20:55:42Z", "author": {"login": "bf8086"}, "path": "core/client/fs/src/main/java/alluxio/client/file/cache/LocalCacheManager.java", "diffHunk": "@@ -11,74 +11,253 @@\n \n package alluxio.client.file.cache;\n \n+import alluxio.client.file.FileSystemContext;\n+import alluxio.collections.Pair;\n+import alluxio.conf.PropertyKey;\n+import alluxio.resource.LockResource;\n+import alluxio.util.io.BufferUtils;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Preconditions;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import java.io.ByteArrayInputStream;\n+import java.io.ByteArrayOutputStream;\n import java.io.IOException;\n+import java.nio.channels.Channels;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.util.Arrays;\n+import java.util.concurrent.locks.ReadWriteLock;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n \n+import javax.annotation.concurrent.GuardedBy;\n import javax.annotation.concurrent.ThreadSafe;\n \n /**\n- * A class to manage cached pages. This class will\n- * 1. Ensure thread-safety\n- * 2. Bookkeep Cache Replacement Alg\n+ * A class to manage cached pages. This class coordinates different components to respond for\n+ * thread-safety and operate cache replacement policies.\n  *\n+ * Lock hierarchy in this class: All operations must follow this order to operate on pages:\n+ * <ul>\n+ * <li>1. Acquire page lock</li>\n+ * <li>2. Acquire metastore lock mMetaLock</li>\n+ * <li>3. Release metastore lock mMetaLock</li>\n+ * <li>4. Release page lock</li>\n+ * </ul>\n  */\n @ThreadSafe\n public class LocalCacheManager {\n   private static final Logger LOG = LoggerFactory.getLogger(LocalCacheManager.class);\n \n-  private final CacheEvictor mEvictor = CacheEvictor.create();\n-  private final PageStore mPageStore = PageStore.create();\n-  private final MetaStore mMetaStore = new MetaStore();\n+  private final int mPageSize;\n+  private final long mCacheSize;\n+  private final int mLockSize;\n+  private final CacheEvictor mEvictor;\n+  /** A readwrite lock pool to guard individual pages based on striping. */\n+  private final ReadWriteLock[] mPageLocks;\n+  private final PageStore mPageStore;\n+  /** A readwrite lock to guard metadata operations. */\n+  private final ReadWriteLock mMetaLock = new ReentrantReadWriteLock();\n+  @GuardedBy(\"mMetaLock\")\n+  private final MetaStore mMetaStore;\n+  private final FileSystemContext mFsContext;\n+\n+  /**\n+   * @param fsContext filesystem context\n+   */\n+  public LocalCacheManager(FileSystemContext fsContext) {\n+    this(fsContext, new MetaStore(), PageStore.create(), CacheEvictor.create());\n+  }\n \n-  public LocalCacheManager() {\n+  /**\n+   * @param fsContext filesystem context\n+   */\n+  @VisibleForTesting\n+  LocalCacheManager(FileSystemContext fsContext, MetaStore metaStore,\n+                    PageStore pageStore, CacheEvictor evictor) {\n+    mFsContext = fsContext;\n+    mMetaStore = metaStore;\n+    mPageStore = pageStore;\n+    mEvictor = evictor;\n+    mPageSize = (int) mFsContext.getClusterConf().getBytes(PropertyKey.USER_CLIENT_CACHE_PAGE_SIZE);\n+    mCacheSize = mFsContext.getClusterConf().getBytes(PropertyKey.USER_CLIENT_CACHE_SIZE);\n+    mLockSize = mFsContext.getClusterConf().getInt(PropertyKey.USER_CLIENT_CACHE_LOCK_SIZE);\n+    mPageLocks = new ReentrantReadWriteLock[mLockSize];\n+    for (int i = 0; i < mLockSize; i++) {\n+      mPageLocks[i] = new ReentrantReadWriteLock();\n+    }\n+  }\n+\n+  /**\n+   * Gets the lock for a particular page. Note that multiple pages may share the same lock as lock\n+   * striping is used to reduce resource overhead for locks.\n+   *\n+   * @param fileId file identifier\n+   * @param pageIndex index of the page within the file\n+   * @return the corresponding page lock\n+   */\n+  private ReadWriteLock getPageLock(long fileId, long pageIndex) {\n+    return mPageLocks[(int) (fileId + pageIndex) % mLockSize];\n+  }\n+\n+  /**\n+   * Gets a pair of locks to operate two given pages. One MUST acquire the first lock followed by\n+   * the second lock.\n+   *\n+   * @param fileId file identifier\n+   * @param pageIndex index of the page within the file\n+   * @param fileId2 file identifier\n+   * @param pageIndex2 index of the page within the file\n+   * @return the corresponding page lock pair\n+   */\n+  private Pair<ReadWriteLock, ReadWriteLock> getPageLockPair(long fileId, long pageIndex,\n+      long fileId2, long pageIndex2) {\n+    if (fileId + pageIndex < fileId2 + pageIndex2) {\n+      return new Pair<>(getPageLock(fileId, pageIndex), getPageLock(fileId2, pageIndex2));\n+    } else {\n+      return new Pair<>(getPageLock(fileId2, pageIndex2), getPageLock(fileId, pageIndex));\n+    }\n   }\n \n   /**\n-   * Writes a new page from a source channel to the store.\n+   * Writes a new page from a source channel with best effort.\n    *\n-   * @param pageId page ID\n+   * @param fileId file identifier\n+   * @param pageIndex index of the page within the file\n    * @param src source channel to read this new page\n    * @throws IOException\n    * @return the number of bytes written\n    */\n-  int put(long pageId, ReadableByteChannel src) throws IOException {\n-    mMetaStore.addPage(pageId);\n-    mPageStore.put(pageId, src);\n-    return 0;\n+  public int put(long fileId, long pageIndex, ReadableByteChannel src) throws IOException {\n+    long victimFileId = 0;\n+    long victimPageIndex = 0;\n+\n+    ReadWriteLock pageLock = getPageLock(fileId, pageIndex);\n+    try (LockResource r = new LockResource(pageLock.writeLock())) {\n+      boolean alreadyCached;\n+      boolean needEvict = false;\n+      try (LockResource r2 = new LockResource(mMetaLock.writeLock())) {\n+        alreadyCached = mMetaStore.hasPage(fileId, pageIndex);\n+        if (!alreadyCached) {\n+          needEvict = (mPageSize + mMetaStore.size()) > mCacheSize;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDA4MzExNg=="}, "originalCommit": {"oid": "3d77abf0fa9d247dcc8a8f6d10035a34907486e5"}, "originalPosition": 147}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1MTUwOTE3OnYy", "diffSide": "RIGHT", "path": "core/client/fs/src/main/java/alluxio/client/file/cache/LocalCacheFileSystem.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wOVQwMTo1Njo1M1rOFbpEkg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wOVQyMDo0OTo0N1rOFcC-vg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDUyODc4Ng==", "bodyText": "this local cache manager should be shared across multiple different LocalCacheFileSystem instances (e.g., different thread may init their own instances). in other words, we don't want to have multiple instances of this manager or they will race on reading/writing files. As a result, we may want to introduce the instance ofLocalCacheManager as a singleton in the context.", "url": "https://github.com/Alluxio/alluxio/pull/10707#discussion_r364528786", "createdAt": "2020-01-09T01:56:53Z", "author": {"login": "apc999"}, "path": "core/client/fs/src/main/java/alluxio/client/file/cache/LocalCacheFileSystem.java", "diffHunk": "@@ -23,14 +24,17 @@\n public class LocalCacheFileSystem extends DelegatingFileSystem {\n \n   private final LocalCacheManager mLocalCacheManager;\n+  private final FileSystemContext mFsContext;\n \n   /**\n    * @param fs a FileSystem instance to query on local cache miss\n+   * @param fsContext file system context\n    */\n-  public LocalCacheFileSystem(FileSystem fs) {\n+  public LocalCacheFileSystem(FileSystem fs, FileSystemContext fsContext) {\n     super(fs);\n+    mFsContext = fsContext;\n     // needs to be moved outside FileSystem constructor\n-    mLocalCacheManager = new LocalCacheManager();\n+    mLocalCacheManager = new LocalCacheManager(mFsContext);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e68d1f47d06d274afd6b1d1bd40ae94f87244df6"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDk1MzI3OA==", "bodyText": "Done. For initial implementation the local cache manager is global to all file system clients.", "url": "https://github.com/Alluxio/alluxio/pull/10707#discussion_r364953278", "createdAt": "2020-01-09T20:49:47Z", "author": {"login": "bf8086"}, "path": "core/client/fs/src/main/java/alluxio/client/file/cache/LocalCacheFileSystem.java", "diffHunk": "@@ -23,14 +24,17 @@\n public class LocalCacheFileSystem extends DelegatingFileSystem {\n \n   private final LocalCacheManager mLocalCacheManager;\n+  private final FileSystemContext mFsContext;\n \n   /**\n    * @param fs a FileSystem instance to query on local cache miss\n+   * @param fsContext file system context\n    */\n-  public LocalCacheFileSystem(FileSystem fs) {\n+  public LocalCacheFileSystem(FileSystem fs, FileSystemContext fsContext) {\n     super(fs);\n+    mFsContext = fsContext;\n     // needs to be moved outside FileSystem constructor\n-    mLocalCacheManager = new LocalCacheManager();\n+    mLocalCacheManager = new LocalCacheManager(mFsContext);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDUyODc4Ng=="}, "originalCommit": {"oid": "e68d1f47d06d274afd6b1d1bd40ae94f87244df6"}, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1MTUyMjc1OnYy", "diffSide": "RIGHT", "path": "core/client/fs/src/main/java/alluxio/client/file/cache/PageStore.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wOVQwMjowNzo1MFrOFbpMrA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wOVQwMjowNzo1MFrOFbpMrA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDUzMDg2MA==", "bodyText": "why throwing IOException here?", "url": "https://github.com/Alluxio/alluxio/pull/10707#discussion_r364530860", "createdAt": "2020-01-09T02:07:50Z", "author": {"login": "apc999"}, "path": "core/client/fs/src/main/java/alluxio/client/file/cache/PageStore.java", "diffHunk": "@@ -56,9 +56,14 @@ static PageStore create() {\n    * Deletes a page from the store.\n    *\n    * @param fileId file identifier\n-   * @param pageIndex index of page within the file.\n+   * @param pageIndex index of page within the file\n    * @return if the page was deleted\n    * @throws IOException\n    */\n   boolean delete(long fileId, long pageIndex) throws IOException;\n+\n+  /**\n+   * @return size of the data in store\n+   */\n+  long size() throws IOException;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e68d1f47d06d274afd6b1d1bd40ae94f87244df6"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1NzU0MDg0OnYy", "diffSide": "RIGHT", "path": "core/client/fs/src/main/java/alluxio/client/file/cache/CacheEvictor.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQyMzozNTozMVrOFcimRw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMVQwNTozNDozMlrOFckcYw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQ3MTMwMw==", "bodyText": "Given how often we use the fileId, pageIndex pair, it might be worth creating an explicit object.", "url": "https://github.com/Alluxio/alluxio/pull/10707#discussion_r365471303", "createdAt": "2020-01-10T23:35:31Z", "author": {"login": "calvinjia"}, "path": "core/client/fs/src/main/java/alluxio/client/file/cache/CacheEvictor.java", "diffHunk": "@@ -24,10 +27,34 @@ static CacheEvictor create() {\n     return null;\n   }\n \n-  void updateOnGet(long pageId);\n+  /**\n+   * Updates evictor after a get operation.\n+   *\n+   * @param fileId ID of the file\n+   * @param pageIndex index of the page within the file\n+   */\n+  void updateOnGet(long fileId, long pageIndex);\n \n-  void updateOnPut(long pageId);\n+  /**\n+   * Updates evictor after a put operation.\n+   *\n+   * @param fileId ID of the file\n+   * @param pageIndex index of the page within the file\n+   */\n+  void updateOnPut(long fileId, long pageIndex);\n \n-  List<Long> getPagesToEvict(int pages);\n+  /**\n+   * Updates evictor after a delete operation.\n+   *\n+   * @param fileId ID of the file\n+   * @param pageIndex index of the page within the file\n+   */\n+  void updateOnDelete(long fileId, long pageIndex);\n \n+  /**\n+   * Find a page to evict.\n+   *\n+   * @return a pair of long values representing (fileId, pageIndex)\n+   */\n+  Pair<Long, Long> evict();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cadc31fb47fcdbcd1a3b401bcbd8a82c3049d60c"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTUwMTUzOQ==", "bodyText": "Refactored.", "url": "https://github.com/Alluxio/alluxio/pull/10707#discussion_r365501539", "createdAt": "2020-01-11T05:34:32Z", "author": {"login": "bf8086"}, "path": "core/client/fs/src/main/java/alluxio/client/file/cache/CacheEvictor.java", "diffHunk": "@@ -24,10 +27,34 @@ static CacheEvictor create() {\n     return null;\n   }\n \n-  void updateOnGet(long pageId);\n+  /**\n+   * Updates evictor after a get operation.\n+   *\n+   * @param fileId ID of the file\n+   * @param pageIndex index of the page within the file\n+   */\n+  void updateOnGet(long fileId, long pageIndex);\n \n-  void updateOnPut(long pageId);\n+  /**\n+   * Updates evictor after a put operation.\n+   *\n+   * @param fileId ID of the file\n+   * @param pageIndex index of the page within the file\n+   */\n+  void updateOnPut(long fileId, long pageIndex);\n \n-  List<Long> getPagesToEvict(int pages);\n+  /**\n+   * Updates evictor after a delete operation.\n+   *\n+   * @param fileId ID of the file\n+   * @param pageIndex index of the page within the file\n+   */\n+  void updateOnDelete(long fileId, long pageIndex);\n \n+  /**\n+   * Find a page to evict.\n+   *\n+   * @return a pair of long values representing (fileId, pageIndex)\n+   */\n+  Pair<Long, Long> evict();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQ3MTMwMw=="}, "originalCommit": {"oid": "cadc31fb47fcdbcd1a3b401bcbd8a82c3049d60c"}, "originalPosition": 49}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1NzU4MjA1OnYy", "diffSide": "RIGHT", "path": "core/client/fs/src/main/java/alluxio/client/file/cache/CacheManager.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMVQwMDoxMToyNlrOFci_cw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMVQwMTowOTowMlrOFcjfoQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQ3Nzc0Nw==", "bodyText": "@Nullable\nReadableByteChannel get(long fileId, long pageIndex) throws IOException;", "url": "https://github.com/Alluxio/alluxio/pull/10707#discussion_r365477747", "createdAt": "2020-01-11T00:11:26Z", "author": {"login": "apc999"}, "path": "core/client/fs/src/main/java/alluxio/client/file/cache/CacheManager.java", "diffHunk": "@@ -1,37 +1,73 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n package alluxio.client.file.cache;\n \n-import alluxio.client.file.cache.store.PageNotFoundException;\n+import alluxio.client.file.FileSystemContext;\n \n import java.io.IOException;\n import java.nio.channels.ReadableByteChannel;\n \n-interface CacheManager {\n+/**\n+ * Interface for managing cached pages.\n+ */\n+public interface CacheManager {\n+  /**\n+   * @param fsContext filesystem context\n+   * @return an instance of {@link CacheManager}\n+   */\n+  static CacheManager create(FileSystemContext fsContext) {\n+    return new LocalCacheManager(fsContext);\n+  }\n \n   /**\n-   * Writes a new page from a source channel to the store.\n+   * Writes a new page from a source channel with best effort.\n    *\n-   * @param fileId file ID\n-   * @param pageId page ID\n+   * @param fileId file identifier\n+   * @param pageIndex index of the page within the file\n    * @param page page data\n-   * @return the number of bytes written\n+   * @throws IOException\n+   */\n+  void put(long fileId, long pageIndex, byte[] page) throws IOException;\n+\n+  /**\n+   * Reads a page to the destination channel.\n+   *\n+   * @param fileId file identifier\n+   * @param pageIndex index of the page within the file\n+   * @throws PageNotFoundException if page is not found in the store\n+   * @return the number of bytes read\n    */\n-  int put(long fileId, long pageId, byte[] page) throws IOException;\n+  ReadableByteChannel get(long fileId, long pageIndex) throws IOException,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cadc31fb47fcdbcd1a3b401bcbd8a82c3049d60c"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQ4NTk4NQ==", "bodyText": "Updated.", "url": "https://github.com/Alluxio/alluxio/pull/10707#discussion_r365485985", "createdAt": "2020-01-11T01:09:02Z", "author": {"login": "bf8086"}, "path": "core/client/fs/src/main/java/alluxio/client/file/cache/CacheManager.java", "diffHunk": "@@ -1,37 +1,73 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n package alluxio.client.file.cache;\n \n-import alluxio.client.file.cache.store.PageNotFoundException;\n+import alluxio.client.file.FileSystemContext;\n \n import java.io.IOException;\n import java.nio.channels.ReadableByteChannel;\n \n-interface CacheManager {\n+/**\n+ * Interface for managing cached pages.\n+ */\n+public interface CacheManager {\n+  /**\n+   * @param fsContext filesystem context\n+   * @return an instance of {@link CacheManager}\n+   */\n+  static CacheManager create(FileSystemContext fsContext) {\n+    return new LocalCacheManager(fsContext);\n+  }\n \n   /**\n-   * Writes a new page from a source channel to the store.\n+   * Writes a new page from a source channel with best effort.\n    *\n-   * @param fileId file ID\n-   * @param pageId page ID\n+   * @param fileId file identifier\n+   * @param pageIndex index of the page within the file\n    * @param page page data\n-   * @return the number of bytes written\n+   * @throws IOException\n+   */\n+  void put(long fileId, long pageIndex, byte[] page) throws IOException;\n+\n+  /**\n+   * Reads a page to the destination channel.\n+   *\n+   * @param fileId file identifier\n+   * @param pageIndex index of the page within the file\n+   * @throws PageNotFoundException if page is not found in the store\n+   * @return the number of bytes read\n    */\n-  int put(long fileId, long pageId, byte[] page) throws IOException;\n+  ReadableByteChannel get(long fileId, long pageIndex) throws IOException,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQ3Nzc0Nw=="}, "originalCommit": {"oid": "cadc31fb47fcdbcd1a3b401bcbd8a82c3049d60c"}, "originalPosition": 56}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1NzU4MzY3OnYy", "diffSide": "RIGHT", "path": "core/client/fs/src/main/java/alluxio/client/file/cache/CacheManager.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMVQwMDoxMzoyOVrOFcjAhw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMVQwMToyMjo1OFrOFcjkeg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQ3ODAyMw==", "bodyText": "Does the length parameter help underlying implementations? For the caller, length is not important since they have control over how many bytes are being read.", "url": "https://github.com/Alluxio/alluxio/pull/10707#discussion_r365478023", "createdAt": "2020-01-11T00:13:29Z", "author": {"login": "calvinjia"}, "path": "core/client/fs/src/main/java/alluxio/client/file/cache/CacheManager.java", "diffHunk": "@@ -1,37 +1,73 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n package alluxio.client.file.cache;\n \n-import alluxio.client.file.cache.store.PageNotFoundException;\n+import alluxio.client.file.FileSystemContext;\n \n import java.io.IOException;\n import java.nio.channels.ReadableByteChannel;\n \n-interface CacheManager {\n+/**\n+ * Interface for managing cached pages.\n+ */\n+public interface CacheManager {\n+  /**\n+   * @param fsContext filesystem context\n+   * @return an instance of {@link CacheManager}\n+   */\n+  static CacheManager create(FileSystemContext fsContext) {\n+    return new LocalCacheManager(fsContext);\n+  }\n \n   /**\n-   * Writes a new page from a source channel to the store.\n+   * Writes a new page from a source channel with best effort.\n    *\n-   * @param fileId file ID\n-   * @param pageId page ID\n+   * @param fileId file identifier\n+   * @param pageIndex index of the page within the file\n    * @param page page data\n-   * @return the number of bytes written\n+   * @throws IOException\n+   */\n+  void put(long fileId, long pageIndex, byte[] page) throws IOException;\n+\n+  /**\n+   * Reads a page to the destination channel.\n+   *\n+   * @param fileId file identifier\n+   * @param pageIndex index of the page within the file\n+   * @throws PageNotFoundException if page is not found in the store\n+   * @return the number of bytes read\n    */\n-  int put(long fileId, long pageId, byte[] page) throws IOException;\n+  ReadableByteChannel get(long fileId, long pageIndex) throws IOException,\n+      PageNotFoundException;\n \n   /**\n-   * Gets a page from the store to the destination channel.\n+   * Reads a part of a page to the destination channel.\n    *\n-   * @param fileId file ID\n-   * @param pageId page ID\n-   * @return a channel to read the page\n+   * @param fileId file identifier\n+   * @param pageIndex index of the page within the file\n+   * @param pageOffset offset into the page\n+   * @param length length to read\n+   * @throws PageNotFoundException if page is not found in the store\n+   * @return the number of bytes read\n    */\n-  ReadableByteChannel get(long fileId, long pageId) throws IOException;\n+  ReadableByteChannel get(long fileId, long pageIndex, int pageOffset, int length)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cadc31fb47fcdbcd1a3b401bcbd8a82c3049d60c"}, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQ4MDAwMQ==", "bodyText": "Shouldn't be much difference in the underlying implementation.", "url": "https://github.com/Alluxio/alluxio/pull/10707#discussion_r365480001", "createdAt": "2020-01-11T00:26:33Z", "author": {"login": "bf8086"}, "path": "core/client/fs/src/main/java/alluxio/client/file/cache/CacheManager.java", "diffHunk": "@@ -1,37 +1,73 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n package alluxio.client.file.cache;\n \n-import alluxio.client.file.cache.store.PageNotFoundException;\n+import alluxio.client.file.FileSystemContext;\n \n import java.io.IOException;\n import java.nio.channels.ReadableByteChannel;\n \n-interface CacheManager {\n+/**\n+ * Interface for managing cached pages.\n+ */\n+public interface CacheManager {\n+  /**\n+   * @param fsContext filesystem context\n+   * @return an instance of {@link CacheManager}\n+   */\n+  static CacheManager create(FileSystemContext fsContext) {\n+    return new LocalCacheManager(fsContext);\n+  }\n \n   /**\n-   * Writes a new page from a source channel to the store.\n+   * Writes a new page from a source channel with best effort.\n    *\n-   * @param fileId file ID\n-   * @param pageId page ID\n+   * @param fileId file identifier\n+   * @param pageIndex index of the page within the file\n    * @param page page data\n-   * @return the number of bytes written\n+   * @throws IOException\n+   */\n+  void put(long fileId, long pageIndex, byte[] page) throws IOException;\n+\n+  /**\n+   * Reads a page to the destination channel.\n+   *\n+   * @param fileId file identifier\n+   * @param pageIndex index of the page within the file\n+   * @throws PageNotFoundException if page is not found in the store\n+   * @return the number of bytes read\n    */\n-  int put(long fileId, long pageId, byte[] page) throws IOException;\n+  ReadableByteChannel get(long fileId, long pageIndex) throws IOException,\n+      PageNotFoundException;\n \n   /**\n-   * Gets a page from the store to the destination channel.\n+   * Reads a part of a page to the destination channel.\n    *\n-   * @param fileId file ID\n-   * @param pageId page ID\n-   * @return a channel to read the page\n+   * @param fileId file identifier\n+   * @param pageIndex index of the page within the file\n+   * @param pageOffset offset into the page\n+   * @param length length to read\n+   * @throws PageNotFoundException if page is not found in the store\n+   * @return the number of bytes read\n    */\n-  ReadableByteChannel get(long fileId, long pageId) throws IOException;\n+  ReadableByteChannel get(long fileId, long pageIndex, int pageOffset, int length)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQ3ODAyMw=="}, "originalCommit": {"oid": "cadc31fb47fcdbcd1a3b401bcbd8a82c3049d60c"}, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQ4MDQ0Ng==", "bodyText": "In that case I don't think we need to specify length?", "url": "https://github.com/Alluxio/alluxio/pull/10707#discussion_r365480446", "createdAt": "2020-01-11T00:29:14Z", "author": {"login": "calvinjia"}, "path": "core/client/fs/src/main/java/alluxio/client/file/cache/CacheManager.java", "diffHunk": "@@ -1,37 +1,73 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n package alluxio.client.file.cache;\n \n-import alluxio.client.file.cache.store.PageNotFoundException;\n+import alluxio.client.file.FileSystemContext;\n \n import java.io.IOException;\n import java.nio.channels.ReadableByteChannel;\n \n-interface CacheManager {\n+/**\n+ * Interface for managing cached pages.\n+ */\n+public interface CacheManager {\n+  /**\n+   * @param fsContext filesystem context\n+   * @return an instance of {@link CacheManager}\n+   */\n+  static CacheManager create(FileSystemContext fsContext) {\n+    return new LocalCacheManager(fsContext);\n+  }\n \n   /**\n-   * Writes a new page from a source channel to the store.\n+   * Writes a new page from a source channel with best effort.\n    *\n-   * @param fileId file ID\n-   * @param pageId page ID\n+   * @param fileId file identifier\n+   * @param pageIndex index of the page within the file\n    * @param page page data\n-   * @return the number of bytes written\n+   * @throws IOException\n+   */\n+  void put(long fileId, long pageIndex, byte[] page) throws IOException;\n+\n+  /**\n+   * Reads a page to the destination channel.\n+   *\n+   * @param fileId file identifier\n+   * @param pageIndex index of the page within the file\n+   * @throws PageNotFoundException if page is not found in the store\n+   * @return the number of bytes read\n    */\n-  int put(long fileId, long pageId, byte[] page) throws IOException;\n+  ReadableByteChannel get(long fileId, long pageIndex) throws IOException,\n+      PageNotFoundException;\n \n   /**\n-   * Gets a page from the store to the destination channel.\n+   * Reads a part of a page to the destination channel.\n    *\n-   * @param fileId file ID\n-   * @param pageId page ID\n-   * @return a channel to read the page\n+   * @param fileId file identifier\n+   * @param pageIndex index of the page within the file\n+   * @param pageOffset offset into the page\n+   * @param length length to read\n+   * @throws PageNotFoundException if page is not found in the store\n+   * @return the number of bytes read\n    */\n-  ReadableByteChannel get(long fileId, long pageId) throws IOException;\n+  ReadableByteChannel get(long fileId, long pageIndex, int pageOffset, int length)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQ3ODAyMw=="}, "originalCommit": {"oid": "cadc31fb47fcdbcd1a3b401bcbd8a82c3049d60c"}, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQ4NzIyNg==", "bodyText": "Removed.", "url": "https://github.com/Alluxio/alluxio/pull/10707#discussion_r365487226", "createdAt": "2020-01-11T01:22:58Z", "author": {"login": "bf8086"}, "path": "core/client/fs/src/main/java/alluxio/client/file/cache/CacheManager.java", "diffHunk": "@@ -1,37 +1,73 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n package alluxio.client.file.cache;\n \n-import alluxio.client.file.cache.store.PageNotFoundException;\n+import alluxio.client.file.FileSystemContext;\n \n import java.io.IOException;\n import java.nio.channels.ReadableByteChannel;\n \n-interface CacheManager {\n+/**\n+ * Interface for managing cached pages.\n+ */\n+public interface CacheManager {\n+  /**\n+   * @param fsContext filesystem context\n+   * @return an instance of {@link CacheManager}\n+   */\n+  static CacheManager create(FileSystemContext fsContext) {\n+    return new LocalCacheManager(fsContext);\n+  }\n \n   /**\n-   * Writes a new page from a source channel to the store.\n+   * Writes a new page from a source channel with best effort.\n    *\n-   * @param fileId file ID\n-   * @param pageId page ID\n+   * @param fileId file identifier\n+   * @param pageIndex index of the page within the file\n    * @param page page data\n-   * @return the number of bytes written\n+   * @throws IOException\n+   */\n+  void put(long fileId, long pageIndex, byte[] page) throws IOException;\n+\n+  /**\n+   * Reads a page to the destination channel.\n+   *\n+   * @param fileId file identifier\n+   * @param pageIndex index of the page within the file\n+   * @throws PageNotFoundException if page is not found in the store\n+   * @return the number of bytes read\n    */\n-  int put(long fileId, long pageId, byte[] page) throws IOException;\n+  ReadableByteChannel get(long fileId, long pageIndex) throws IOException,\n+      PageNotFoundException;\n \n   /**\n-   * Gets a page from the store to the destination channel.\n+   * Reads a part of a page to the destination channel.\n    *\n-   * @param fileId file ID\n-   * @param pageId page ID\n-   * @return a channel to read the page\n+   * @param fileId file identifier\n+   * @param pageIndex index of the page within the file\n+   * @param pageOffset offset into the page\n+   * @param length length to read\n+   * @throws PageNotFoundException if page is not found in the store\n+   * @return the number of bytes read\n    */\n-  ReadableByteChannel get(long fileId, long pageId) throws IOException;\n+  ReadableByteChannel get(long fileId, long pageIndex, int pageOffset, int length)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQ3ODAyMw=="}, "originalCommit": {"oid": "cadc31fb47fcdbcd1a3b401bcbd8a82c3049d60c"}, "originalPosition": 74}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1NzU4NDc0OnYy", "diffSide": "RIGHT", "path": "core/client/fs/src/main/java/alluxio/client/file/cache/LocalCacheFileInStream.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMVQwMDoxNDo0MlrOFcjBNQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMVQwMTowODoxNVrOFcjfOg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQ3ODE5Nw==", "bodyText": "Use try-with-catch?", "url": "https://github.com/Alluxio/alluxio/pull/10707#discussion_r365478197", "createdAt": "2020-01-11T00:14:42Z", "author": {"login": "apc999"}, "path": "core/client/fs/src/main/java/alluxio/client/file/cache/LocalCacheFileInStream.java", "diffHunk": "@@ -106,21 +106,30 @@ public int read(byte[] b, int off, int len) throws IOException {\n       int currentPageOffset = (int) (mPosition % PAGE_SIZE);\n       int bytesLeftInPage = (int) Math.min(PAGE_SIZE - currentPageOffset, len - bytesRead);\n       // TODO(calvin): Update this to take page offset when API is updated\n-      ReadableByteChannel cachedData = mCacheManager.get(mStatus.getFileId(), currentPage);\n+      ReadableByteChannel cachedData = null;\n+      try {\n+        cachedData = mCacheManager.get(mStatus.getFileId(), currentPage);\n+      } catch (PageNotFoundException e) {\n+        // ignore exception and continue to read remote data\n+      }\n       if (cachedData != null) { // cache hit\n         // wrap return byte array in a bytebuffer and set the pos/limit for the page read\n-        ByteBuffer buf = ByteBuffer.wrap(b);\n-        buf.position(off + bytesRead);\n-        buf.limit(off + bytesRead + bytesLeftInPage);\n-        // read data from cache\n-        while (buf.position() != buf.limit()) {\n-          if (cachedData.read(buf) == -1) {\n-            break;\n+        try {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cadc31fb47fcdbcd1a3b401bcbd8a82c3049d60c"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQ4NTg4Mg==", "bodyText": "Done.", "url": "https://github.com/Alluxio/alluxio/pull/10707#discussion_r365485882", "createdAt": "2020-01-11T01:08:15Z", "author": {"login": "bf8086"}, "path": "core/client/fs/src/main/java/alluxio/client/file/cache/LocalCacheFileInStream.java", "diffHunk": "@@ -106,21 +106,30 @@ public int read(byte[] b, int off, int len) throws IOException {\n       int currentPageOffset = (int) (mPosition % PAGE_SIZE);\n       int bytesLeftInPage = (int) Math.min(PAGE_SIZE - currentPageOffset, len - bytesRead);\n       // TODO(calvin): Update this to take page offset when API is updated\n-      ReadableByteChannel cachedData = mCacheManager.get(mStatus.getFileId(), currentPage);\n+      ReadableByteChannel cachedData = null;\n+      try {\n+        cachedData = mCacheManager.get(mStatus.getFileId(), currentPage);\n+      } catch (PageNotFoundException e) {\n+        // ignore exception and continue to read remote data\n+      }\n       if (cachedData != null) { // cache hit\n         // wrap return byte array in a bytebuffer and set the pos/limit for the page read\n-        ByteBuffer buf = ByteBuffer.wrap(b);\n-        buf.position(off + bytesRead);\n-        buf.limit(off + bytesRead + bytesLeftInPage);\n-        // read data from cache\n-        while (buf.position() != buf.limit()) {\n-          if (cachedData.read(buf) == -1) {\n-            break;\n+        try {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQ3ODE5Nw=="}, "originalCommit": {"oid": "cadc31fb47fcdbcd1a3b401bcbd8a82c3049d60c"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1NzU4NDgwOnYy", "diffSide": "RIGHT", "path": "core/client/fs/src/main/java/alluxio/client/file/cache/LocalCacheManager.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMVQwMDoxNDo0NVrOFcjBPQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMVQwMDoxODowMFrOFcjDMA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQ3ODIwNQ==", "bodyText": "Should we do something in this error case, it doesn't seem safe to proceed?", "url": "https://github.com/Alluxio/alluxio/pull/10707#discussion_r365478205", "createdAt": "2020-01-11T00:14:45Z", "author": {"login": "calvinjia"}, "path": "core/client/fs/src/main/java/alluxio/client/file/cache/LocalCacheManager.java", "diffHunk": "@@ -11,53 +11,240 @@\n \n package alluxio.client.file.cache;\n \n-import alluxio.client.file.cache.store.PageNotFoundException;\n+import alluxio.client.file.FileSystemContext;\n+import alluxio.collections.Pair;\n+import alluxio.conf.PropertyKey;\n+import alluxio.resource.LockResource;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Preconditions;\n+import org.apache.zookeeper.server.ByteBufferInputStream;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.Channels;\n import java.nio.channels.ReadableByteChannel;\n+import java.util.concurrent.locks.ReadWriteLock;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n \n+import javax.annotation.concurrent.GuardedBy;\n import javax.annotation.concurrent.ThreadSafe;\n \n /**\n- * A class to manage cached pages. This class will\n- * 1. Ensure thread-safety\n- * 2. Bookkeep Cache Replacement Alg\n+ * A class to manage cached pages. This class coordinates different components to respond for\n+ * thread-safety and operate cache replacement policies.\n  *\n+ * Lock hierarchy in this class: All operations must follow this order to operate on pages:\n+ * <ul>\n+ * <li>1. Acquire page lock</li>\n+ * <li>2. Acquire metastore lock mMetaLock</li>\n+ * <li>3. Release metastore lock mMetaLock</li>\n+ * <li>4. Release page lock</li>\n+ * </ul>\n  */\n @ThreadSafe\n public class LocalCacheManager implements CacheManager {\n   private static final Logger LOG = LoggerFactory.getLogger(LocalCacheManager.class);\n \n-  private final CacheEvictor mEvictor = CacheEvictor.create();\n-  private final PageStore mPageStore = PageStore.create();\n-  private final MetaStore mMetaStore = new MetaStore();\n+  private static final int LOCK_SIZE = 1024;\n+  private final int mPageSize;\n+  private final long mCacheSize;\n+  private final CacheEvictor mEvictor;\n+  /** A readwrite lock pool to guard individual pages based on striping. */\n+  private final ReadWriteLock[] mPageLocks = new ReentrantReadWriteLock[LOCK_SIZE];\n+  private final PageStore mPageStore;\n+  /** A readwrite lock to guard metadata operations. */\n+  private final ReadWriteLock mMetaLock = new ReentrantReadWriteLock();\n+  @GuardedBy(\"mMetaLock\")\n+  private final MetaStore mMetaStore;\n+  private final FileSystemContext mFsContext;\n \n-  public LocalCacheManager() {\n+  /**\n+   * @param fsContext filesystem context\n+   */\n+  public LocalCacheManager(FileSystemContext fsContext) {\n+    this(fsContext, new MetaStore(), PageStore.create(), CacheEvictor.create());\n   }\n \n-  @Override\n-  public int put(long fileId, long pageId, byte[] page) throws IOException {\n-    mMetaStore.addPage(pageId);\n-    mPageStore.put(fileId, pageId, page);\n-    return 0;\n+  /**\n+   * @param fsContext filesystem context\n+   */\n+  @VisibleForTesting\n+  LocalCacheManager(FileSystemContext fsContext, MetaStore metaStore,\n+                    PageStore pageStore, CacheEvictor evictor) {\n+    mFsContext = fsContext;\n+    mMetaStore = metaStore;\n+    mPageStore = pageStore;\n+    mEvictor = evictor;\n+    mPageSize = (int) mFsContext.getClusterConf().getBytes(PropertyKey.USER_CLIENT_CACHE_PAGE_SIZE);\n+    mCacheSize = mFsContext.getClusterConf().getBytes(PropertyKey.USER_CLIENT_CACHE_SIZE)\n+        / mPageSize;\n+    for (int i = 0; i < LOCK_SIZE; i++) {\n+      mPageLocks[i] = new ReentrantReadWriteLock();\n+    }\n+  }\n+\n+  /**\n+   * Gets the lock for a particular page. Note that multiple pages may share the same lock as lock\n+   * striping is used to reduce resource overhead for locks.\n+   *\n+   * @param fileId file identifier\n+   * @param pageIndex index of the page within the file\n+   * @return the corresponding page lock\n+   */\n+  private ReadWriteLock getPageLock(long fileId, long pageIndex) {\n+    return mPageLocks[(int) (fileId + pageIndex) % LOCK_SIZE];\n+  }\n+\n+  /**\n+   * Gets a pair of locks to operate two given pages. One MUST acquire the first lock followed by\n+   * the second lock.\n+   *\n+   * @param fileId file identifier\n+   * @param pageIndex index of the page within the file\n+   * @param fileId2 file identifier\n+   * @param pageIndex2 index of the page within the file\n+   * @return the corresponding page lock pair\n+   */\n+  private Pair<ReadWriteLock, ReadWriteLock> getPageLockPair(long fileId, long pageIndex,\n+      long fileId2, long pageIndex2) {\n+    if (fileId + pageIndex < fileId2 + pageIndex2) {\n+      return new Pair<>(getPageLock(fileId, pageIndex), getPageLock(fileId2, pageIndex2));\n+    } else {\n+      return new Pair<>(getPageLock(fileId2, pageIndex2), getPageLock(fileId, pageIndex));\n+    }\n   }\n \n   @Override\n-  public ReadableByteChannel get(long fileId, long pageId) throws IOException {\n-    if (!mMetaStore.hasPage(pageId)) {\n+  public void put(long fileId, long pageIndex, byte[] page) throws IOException {\n+    long victimFileId = 0;\n+    long victimPageIndex = 0;\n \n+    ReadWriteLock pageLock = getPageLock(fileId, pageIndex);\n+    try (LockResource r = new LockResource(pageLock.writeLock())) {\n+      boolean alreadyCached;\n+      boolean needEvict = false;\n+      try (LockResource r2 = new LockResource(mMetaLock.writeLock())) {\n+        alreadyCached = mMetaStore.hasPage(fileId, pageIndex);\n+        if (!alreadyCached) {\n+          needEvict = mPageStore.size() + 1 > mCacheSize;\n+          if (needEvict) {\n+            Pair<Long, Long> victim = mEvictor.evict();\n+            victimFileId = victim.getFirst();\n+            victimPageIndex = victim.getSecond();\n+          } else {\n+            mMetaStore.addPage(fileId, pageIndex);\n+          }\n+        }\n+      }\n+      if (alreadyCached) {\n+        try {\n+          mPageStore.delete(fileId, pageIndex);\n+        } catch (PageNotFoundException e) {\n+          // this should never happen with proper locking\n+          LOG.error(\"failed to delete page {} {} from page store\", fileId, pageIndex, e);\n+        }\n+        mEvictor.updateOnPut(fileId, pageIndex);\n+        mPageStore.put(fileId, pageIndex, page);\n+      } else if (!needEvict) {\n+        mEvictor.updateOnPut(fileId, pageIndex);\n+        mPageStore.put(fileId, pageIndex, page);\n+      }\n     }\n-    mEvictor.updateOnGet(pageId);\n-    return null;\n+\n+    Pair<ReadWriteLock, ReadWriteLock> pageLockPair =\n+        getPageLockPair(fileId, pageIndex, victimFileId, victimPageIndex);\n+    try (LockResource r1 = new LockResource(pageLockPair.getFirst().writeLock());\n+        LockResource r2 = new LockResource(pageLockPair.getSecond().writeLock())) {\n+      try (LockResource r3 = new LockResource(mMetaLock.writeLock())) {\n+        if (mMetaStore.hasPage(fileId, pageIndex)) {\n+          LOG.warn(\"fileId {} pageIndex {} is already inserted by a racing thread\",\n+              fileId, pageIndex);\n+          return;\n+        }\n+        if (!mMetaStore.hasPage(victimFileId, victimPageIndex)) {\n+          LOG.warn(\"fileId {} pageIndex {} is already evicted by a racing thread\",\n+              fileId, pageIndex);\n+          return;\n+        }\n+        try {\n+          mMetaStore.removePage(victimFileId, victimPageIndex);\n+        } catch (PageNotFoundException e) {\n+          // this should never happen with proper locking\n+          LOG.error(\"failed to remove page {} {} from meta store\",\n+              victimFileId, victimPageIndex, e);\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cadc31fb47fcdbcd1a3b401bcbd8a82c3049d60c"}, "originalPosition": 185}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQ3ODcwNA==", "bodyText": "Yeah we can throw IllegalStateException instead.", "url": "https://github.com/Alluxio/alluxio/pull/10707#discussion_r365478704", "createdAt": "2020-01-11T00:18:00Z", "author": {"login": "bf8086"}, "path": "core/client/fs/src/main/java/alluxio/client/file/cache/LocalCacheManager.java", "diffHunk": "@@ -11,53 +11,240 @@\n \n package alluxio.client.file.cache;\n \n-import alluxio.client.file.cache.store.PageNotFoundException;\n+import alluxio.client.file.FileSystemContext;\n+import alluxio.collections.Pair;\n+import alluxio.conf.PropertyKey;\n+import alluxio.resource.LockResource;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Preconditions;\n+import org.apache.zookeeper.server.ByteBufferInputStream;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.Channels;\n import java.nio.channels.ReadableByteChannel;\n+import java.util.concurrent.locks.ReadWriteLock;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n \n+import javax.annotation.concurrent.GuardedBy;\n import javax.annotation.concurrent.ThreadSafe;\n \n /**\n- * A class to manage cached pages. This class will\n- * 1. Ensure thread-safety\n- * 2. Bookkeep Cache Replacement Alg\n+ * A class to manage cached pages. This class coordinates different components to respond for\n+ * thread-safety and operate cache replacement policies.\n  *\n+ * Lock hierarchy in this class: All operations must follow this order to operate on pages:\n+ * <ul>\n+ * <li>1. Acquire page lock</li>\n+ * <li>2. Acquire metastore lock mMetaLock</li>\n+ * <li>3. Release metastore lock mMetaLock</li>\n+ * <li>4. Release page lock</li>\n+ * </ul>\n  */\n @ThreadSafe\n public class LocalCacheManager implements CacheManager {\n   private static final Logger LOG = LoggerFactory.getLogger(LocalCacheManager.class);\n \n-  private final CacheEvictor mEvictor = CacheEvictor.create();\n-  private final PageStore mPageStore = PageStore.create();\n-  private final MetaStore mMetaStore = new MetaStore();\n+  private static final int LOCK_SIZE = 1024;\n+  private final int mPageSize;\n+  private final long mCacheSize;\n+  private final CacheEvictor mEvictor;\n+  /** A readwrite lock pool to guard individual pages based on striping. */\n+  private final ReadWriteLock[] mPageLocks = new ReentrantReadWriteLock[LOCK_SIZE];\n+  private final PageStore mPageStore;\n+  /** A readwrite lock to guard metadata operations. */\n+  private final ReadWriteLock mMetaLock = new ReentrantReadWriteLock();\n+  @GuardedBy(\"mMetaLock\")\n+  private final MetaStore mMetaStore;\n+  private final FileSystemContext mFsContext;\n \n-  public LocalCacheManager() {\n+  /**\n+   * @param fsContext filesystem context\n+   */\n+  public LocalCacheManager(FileSystemContext fsContext) {\n+    this(fsContext, new MetaStore(), PageStore.create(), CacheEvictor.create());\n   }\n \n-  @Override\n-  public int put(long fileId, long pageId, byte[] page) throws IOException {\n-    mMetaStore.addPage(pageId);\n-    mPageStore.put(fileId, pageId, page);\n-    return 0;\n+  /**\n+   * @param fsContext filesystem context\n+   */\n+  @VisibleForTesting\n+  LocalCacheManager(FileSystemContext fsContext, MetaStore metaStore,\n+                    PageStore pageStore, CacheEvictor evictor) {\n+    mFsContext = fsContext;\n+    mMetaStore = metaStore;\n+    mPageStore = pageStore;\n+    mEvictor = evictor;\n+    mPageSize = (int) mFsContext.getClusterConf().getBytes(PropertyKey.USER_CLIENT_CACHE_PAGE_SIZE);\n+    mCacheSize = mFsContext.getClusterConf().getBytes(PropertyKey.USER_CLIENT_CACHE_SIZE)\n+        / mPageSize;\n+    for (int i = 0; i < LOCK_SIZE; i++) {\n+      mPageLocks[i] = new ReentrantReadWriteLock();\n+    }\n+  }\n+\n+  /**\n+   * Gets the lock for a particular page. Note that multiple pages may share the same lock as lock\n+   * striping is used to reduce resource overhead for locks.\n+   *\n+   * @param fileId file identifier\n+   * @param pageIndex index of the page within the file\n+   * @return the corresponding page lock\n+   */\n+  private ReadWriteLock getPageLock(long fileId, long pageIndex) {\n+    return mPageLocks[(int) (fileId + pageIndex) % LOCK_SIZE];\n+  }\n+\n+  /**\n+   * Gets a pair of locks to operate two given pages. One MUST acquire the first lock followed by\n+   * the second lock.\n+   *\n+   * @param fileId file identifier\n+   * @param pageIndex index of the page within the file\n+   * @param fileId2 file identifier\n+   * @param pageIndex2 index of the page within the file\n+   * @return the corresponding page lock pair\n+   */\n+  private Pair<ReadWriteLock, ReadWriteLock> getPageLockPair(long fileId, long pageIndex,\n+      long fileId2, long pageIndex2) {\n+    if (fileId + pageIndex < fileId2 + pageIndex2) {\n+      return new Pair<>(getPageLock(fileId, pageIndex), getPageLock(fileId2, pageIndex2));\n+    } else {\n+      return new Pair<>(getPageLock(fileId2, pageIndex2), getPageLock(fileId, pageIndex));\n+    }\n   }\n \n   @Override\n-  public ReadableByteChannel get(long fileId, long pageId) throws IOException {\n-    if (!mMetaStore.hasPage(pageId)) {\n+  public void put(long fileId, long pageIndex, byte[] page) throws IOException {\n+    long victimFileId = 0;\n+    long victimPageIndex = 0;\n \n+    ReadWriteLock pageLock = getPageLock(fileId, pageIndex);\n+    try (LockResource r = new LockResource(pageLock.writeLock())) {\n+      boolean alreadyCached;\n+      boolean needEvict = false;\n+      try (LockResource r2 = new LockResource(mMetaLock.writeLock())) {\n+        alreadyCached = mMetaStore.hasPage(fileId, pageIndex);\n+        if (!alreadyCached) {\n+          needEvict = mPageStore.size() + 1 > mCacheSize;\n+          if (needEvict) {\n+            Pair<Long, Long> victim = mEvictor.evict();\n+            victimFileId = victim.getFirst();\n+            victimPageIndex = victim.getSecond();\n+          } else {\n+            mMetaStore.addPage(fileId, pageIndex);\n+          }\n+        }\n+      }\n+      if (alreadyCached) {\n+        try {\n+          mPageStore.delete(fileId, pageIndex);\n+        } catch (PageNotFoundException e) {\n+          // this should never happen with proper locking\n+          LOG.error(\"failed to delete page {} {} from page store\", fileId, pageIndex, e);\n+        }\n+        mEvictor.updateOnPut(fileId, pageIndex);\n+        mPageStore.put(fileId, pageIndex, page);\n+      } else if (!needEvict) {\n+        mEvictor.updateOnPut(fileId, pageIndex);\n+        mPageStore.put(fileId, pageIndex, page);\n+      }\n     }\n-    mEvictor.updateOnGet(pageId);\n-    return null;\n+\n+    Pair<ReadWriteLock, ReadWriteLock> pageLockPair =\n+        getPageLockPair(fileId, pageIndex, victimFileId, victimPageIndex);\n+    try (LockResource r1 = new LockResource(pageLockPair.getFirst().writeLock());\n+        LockResource r2 = new LockResource(pageLockPair.getSecond().writeLock())) {\n+      try (LockResource r3 = new LockResource(mMetaLock.writeLock())) {\n+        if (mMetaStore.hasPage(fileId, pageIndex)) {\n+          LOG.warn(\"fileId {} pageIndex {} is already inserted by a racing thread\",\n+              fileId, pageIndex);\n+          return;\n+        }\n+        if (!mMetaStore.hasPage(victimFileId, victimPageIndex)) {\n+          LOG.warn(\"fileId {} pageIndex {} is already evicted by a racing thread\",\n+              fileId, pageIndex);\n+          return;\n+        }\n+        try {\n+          mMetaStore.removePage(victimFileId, victimPageIndex);\n+        } catch (PageNotFoundException e) {\n+          // this should never happen with proper locking\n+          LOG.error(\"failed to remove page {} {} from meta store\",\n+              victimFileId, victimPageIndex, e);\n+        }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQ3ODIwNQ=="}, "originalCommit": {"oid": "cadc31fb47fcdbcd1a3b401bcbd8a82c3049d60c"}, "originalPosition": 185}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1NzU4NjUyOnYy", "diffSide": "RIGHT", "path": "core/client/fs/src/main/java/alluxio/client/file/cache/LocalCacheManager.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMVQwMDoxNjoyN1rOFcjCVQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMVQwMTowMToyMlrOFcjb2A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQ3ODQ4NQ==", "bodyText": "incorrect javadoc with missing params", "url": "https://github.com/Alluxio/alluxio/pull/10707#discussion_r365478485", "createdAt": "2020-01-11T00:16:27Z", "author": {"login": "apc999"}, "path": "core/client/fs/src/main/java/alluxio/client/file/cache/LocalCacheManager.java", "diffHunk": "@@ -11,53 +11,240 @@\n \n package alluxio.client.file.cache;\n \n-import alluxio.client.file.cache.store.PageNotFoundException;\n+import alluxio.client.file.FileSystemContext;\n+import alluxio.collections.Pair;\n+import alluxio.conf.PropertyKey;\n+import alluxio.resource.LockResource;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Preconditions;\n+import org.apache.zookeeper.server.ByteBufferInputStream;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.Channels;\n import java.nio.channels.ReadableByteChannel;\n+import java.util.concurrent.locks.ReadWriteLock;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n \n+import javax.annotation.concurrent.GuardedBy;\n import javax.annotation.concurrent.ThreadSafe;\n \n /**\n- * A class to manage cached pages. This class will\n- * 1. Ensure thread-safety\n- * 2. Bookkeep Cache Replacement Alg\n+ * A class to manage cached pages. This class coordinates different components to respond for\n+ * thread-safety and operate cache replacement policies.\n  *\n+ * Lock hierarchy in this class: All operations must follow this order to operate on pages:\n+ * <ul>\n+ * <li>1. Acquire page lock</li>\n+ * <li>2. Acquire metastore lock mMetaLock</li>\n+ * <li>3. Release metastore lock mMetaLock</li>\n+ * <li>4. Release page lock</li>\n+ * </ul>\n  */\n @ThreadSafe\n public class LocalCacheManager implements CacheManager {\n   private static final Logger LOG = LoggerFactory.getLogger(LocalCacheManager.class);\n \n-  private final CacheEvictor mEvictor = CacheEvictor.create();\n-  private final PageStore mPageStore = PageStore.create();\n-  private final MetaStore mMetaStore = new MetaStore();\n+  private static final int LOCK_SIZE = 1024;\n+  private final int mPageSize;\n+  private final long mCacheSize;\n+  private final CacheEvictor mEvictor;\n+  /** A readwrite lock pool to guard individual pages based on striping. */\n+  private final ReadWriteLock[] mPageLocks = new ReentrantReadWriteLock[LOCK_SIZE];\n+  private final PageStore mPageStore;\n+  /** A readwrite lock to guard metadata operations. */\n+  private final ReadWriteLock mMetaLock = new ReentrantReadWriteLock();\n+  @GuardedBy(\"mMetaLock\")\n+  private final MetaStore mMetaStore;\n+  private final FileSystemContext mFsContext;\n \n-  public LocalCacheManager() {\n+  /**\n+   * @param fsContext filesystem context\n+   */\n+  public LocalCacheManager(FileSystemContext fsContext) {\n+    this(fsContext, new MetaStore(), PageStore.create(), CacheEvictor.create());\n   }\n \n-  @Override\n-  public int put(long fileId, long pageId, byte[] page) throws IOException {\n-    mMetaStore.addPage(pageId);\n-    mPageStore.put(fileId, pageId, page);\n-    return 0;\n+  /**\n+   * @param fsContext filesystem context", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cadc31fb47fcdbcd1a3b401bcbd8a82c3049d60c"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQ4NTAxNg==", "bodyText": "Fixed.", "url": "https://github.com/Alluxio/alluxio/pull/10707#discussion_r365485016", "createdAt": "2020-01-11T01:01:22Z", "author": {"login": "bf8086"}, "path": "core/client/fs/src/main/java/alluxio/client/file/cache/LocalCacheManager.java", "diffHunk": "@@ -11,53 +11,240 @@\n \n package alluxio.client.file.cache;\n \n-import alluxio.client.file.cache.store.PageNotFoundException;\n+import alluxio.client.file.FileSystemContext;\n+import alluxio.collections.Pair;\n+import alluxio.conf.PropertyKey;\n+import alluxio.resource.LockResource;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Preconditions;\n+import org.apache.zookeeper.server.ByteBufferInputStream;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.Channels;\n import java.nio.channels.ReadableByteChannel;\n+import java.util.concurrent.locks.ReadWriteLock;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n \n+import javax.annotation.concurrent.GuardedBy;\n import javax.annotation.concurrent.ThreadSafe;\n \n /**\n- * A class to manage cached pages. This class will\n- * 1. Ensure thread-safety\n- * 2. Bookkeep Cache Replacement Alg\n+ * A class to manage cached pages. This class coordinates different components to respond for\n+ * thread-safety and operate cache replacement policies.\n  *\n+ * Lock hierarchy in this class: All operations must follow this order to operate on pages:\n+ * <ul>\n+ * <li>1. Acquire page lock</li>\n+ * <li>2. Acquire metastore lock mMetaLock</li>\n+ * <li>3. Release metastore lock mMetaLock</li>\n+ * <li>4. Release page lock</li>\n+ * </ul>\n  */\n @ThreadSafe\n public class LocalCacheManager implements CacheManager {\n   private static final Logger LOG = LoggerFactory.getLogger(LocalCacheManager.class);\n \n-  private final CacheEvictor mEvictor = CacheEvictor.create();\n-  private final PageStore mPageStore = PageStore.create();\n-  private final MetaStore mMetaStore = new MetaStore();\n+  private static final int LOCK_SIZE = 1024;\n+  private final int mPageSize;\n+  private final long mCacheSize;\n+  private final CacheEvictor mEvictor;\n+  /** A readwrite lock pool to guard individual pages based on striping. */\n+  private final ReadWriteLock[] mPageLocks = new ReentrantReadWriteLock[LOCK_SIZE];\n+  private final PageStore mPageStore;\n+  /** A readwrite lock to guard metadata operations. */\n+  private final ReadWriteLock mMetaLock = new ReentrantReadWriteLock();\n+  @GuardedBy(\"mMetaLock\")\n+  private final MetaStore mMetaStore;\n+  private final FileSystemContext mFsContext;\n \n-  public LocalCacheManager() {\n+  /**\n+   * @param fsContext filesystem context\n+   */\n+  public LocalCacheManager(FileSystemContext fsContext) {\n+    this(fsContext, new MetaStore(), PageStore.create(), CacheEvictor.create());\n   }\n \n-  @Override\n-  public int put(long fileId, long pageId, byte[] page) throws IOException {\n-    mMetaStore.addPage(pageId);\n-    mPageStore.put(fileId, pageId, page);\n-    return 0;\n+  /**\n+   * @param fsContext filesystem context", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQ3ODQ4NQ=="}, "originalCommit": {"oid": "cadc31fb47fcdbcd1a3b401bcbd8a82c3049d60c"}, "originalPosition": 75}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1NzU4OTc4OnYy", "diffSide": "RIGHT", "path": "core/client/fs/src/main/java/alluxio/client/file/cache/LocalCacheManager.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMVQwMDoxOTo1NVrOFcjEVA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMVQwMTowMjowOVrOFcjcVA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQ3ODk5Ng==", "bodyText": "Could you update the page size constant used in LocalCacheFileInStream?", "url": "https://github.com/Alluxio/alluxio/pull/10707#discussion_r365478996", "createdAt": "2020-01-11T00:19:55Z", "author": {"login": "calvinjia"}, "path": "core/client/fs/src/main/java/alluxio/client/file/cache/LocalCacheManager.java", "diffHunk": "@@ -11,53 +11,240 @@\n \n package alluxio.client.file.cache;\n \n-import alluxio.client.file.cache.store.PageNotFoundException;\n+import alluxio.client.file.FileSystemContext;\n+import alluxio.collections.Pair;\n+import alluxio.conf.PropertyKey;\n+import alluxio.resource.LockResource;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Preconditions;\n+import org.apache.zookeeper.server.ByteBufferInputStream;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.Channels;\n import java.nio.channels.ReadableByteChannel;\n+import java.util.concurrent.locks.ReadWriteLock;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n \n+import javax.annotation.concurrent.GuardedBy;\n import javax.annotation.concurrent.ThreadSafe;\n \n /**\n- * A class to manage cached pages. This class will\n- * 1. Ensure thread-safety\n- * 2. Bookkeep Cache Replacement Alg\n+ * A class to manage cached pages. This class coordinates different components to respond for\n+ * thread-safety and operate cache replacement policies.\n  *\n+ * Lock hierarchy in this class: All operations must follow this order to operate on pages:\n+ * <ul>\n+ * <li>1. Acquire page lock</li>\n+ * <li>2. Acquire metastore lock mMetaLock</li>\n+ * <li>3. Release metastore lock mMetaLock</li>\n+ * <li>4. Release page lock</li>\n+ * </ul>\n  */\n @ThreadSafe\n public class LocalCacheManager implements CacheManager {\n   private static final Logger LOG = LoggerFactory.getLogger(LocalCacheManager.class);\n \n-  private final CacheEvictor mEvictor = CacheEvictor.create();\n-  private final PageStore mPageStore = PageStore.create();\n-  private final MetaStore mMetaStore = new MetaStore();\n+  private static final int LOCK_SIZE = 1024;\n+  private final int mPageSize;\n+  private final long mCacheSize;\n+  private final CacheEvictor mEvictor;\n+  /** A readwrite lock pool to guard individual pages based on striping. */\n+  private final ReadWriteLock[] mPageLocks = new ReentrantReadWriteLock[LOCK_SIZE];\n+  private final PageStore mPageStore;\n+  /** A readwrite lock to guard metadata operations. */\n+  private final ReadWriteLock mMetaLock = new ReentrantReadWriteLock();\n+  @GuardedBy(\"mMetaLock\")\n+  private final MetaStore mMetaStore;\n+  private final FileSystemContext mFsContext;\n \n-  public LocalCacheManager() {\n+  /**\n+   * @param fsContext filesystem context\n+   */\n+  public LocalCacheManager(FileSystemContext fsContext) {\n+    this(fsContext, new MetaStore(), PageStore.create(), CacheEvictor.create());\n   }\n \n-  @Override\n-  public int put(long fileId, long pageId, byte[] page) throws IOException {\n-    mMetaStore.addPage(pageId);\n-    mPageStore.put(fileId, pageId, page);\n-    return 0;\n+  /**\n+   * @param fsContext filesystem context\n+   */\n+  @VisibleForTesting\n+  LocalCacheManager(FileSystemContext fsContext, MetaStore metaStore,\n+                    PageStore pageStore, CacheEvictor evictor) {\n+    mFsContext = fsContext;\n+    mMetaStore = metaStore;\n+    mPageStore = pageStore;\n+    mEvictor = evictor;\n+    mPageSize = (int) mFsContext.getClusterConf().getBytes(PropertyKey.USER_CLIENT_CACHE_PAGE_SIZE);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cadc31fb47fcdbcd1a3b401bcbd8a82c3049d60c"}, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQ4NTE0MA==", "bodyText": "Updated.", "url": "https://github.com/Alluxio/alluxio/pull/10707#discussion_r365485140", "createdAt": "2020-01-11T01:02:09Z", "author": {"login": "bf8086"}, "path": "core/client/fs/src/main/java/alluxio/client/file/cache/LocalCacheManager.java", "diffHunk": "@@ -11,53 +11,240 @@\n \n package alluxio.client.file.cache;\n \n-import alluxio.client.file.cache.store.PageNotFoundException;\n+import alluxio.client.file.FileSystemContext;\n+import alluxio.collections.Pair;\n+import alluxio.conf.PropertyKey;\n+import alluxio.resource.LockResource;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Preconditions;\n+import org.apache.zookeeper.server.ByteBufferInputStream;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.Channels;\n import java.nio.channels.ReadableByteChannel;\n+import java.util.concurrent.locks.ReadWriteLock;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n \n+import javax.annotation.concurrent.GuardedBy;\n import javax.annotation.concurrent.ThreadSafe;\n \n /**\n- * A class to manage cached pages. This class will\n- * 1. Ensure thread-safety\n- * 2. Bookkeep Cache Replacement Alg\n+ * A class to manage cached pages. This class coordinates different components to respond for\n+ * thread-safety and operate cache replacement policies.\n  *\n+ * Lock hierarchy in this class: All operations must follow this order to operate on pages:\n+ * <ul>\n+ * <li>1. Acquire page lock</li>\n+ * <li>2. Acquire metastore lock mMetaLock</li>\n+ * <li>3. Release metastore lock mMetaLock</li>\n+ * <li>4. Release page lock</li>\n+ * </ul>\n  */\n @ThreadSafe\n public class LocalCacheManager implements CacheManager {\n   private static final Logger LOG = LoggerFactory.getLogger(LocalCacheManager.class);\n \n-  private final CacheEvictor mEvictor = CacheEvictor.create();\n-  private final PageStore mPageStore = PageStore.create();\n-  private final MetaStore mMetaStore = new MetaStore();\n+  private static final int LOCK_SIZE = 1024;\n+  private final int mPageSize;\n+  private final long mCacheSize;\n+  private final CacheEvictor mEvictor;\n+  /** A readwrite lock pool to guard individual pages based on striping. */\n+  private final ReadWriteLock[] mPageLocks = new ReentrantReadWriteLock[LOCK_SIZE];\n+  private final PageStore mPageStore;\n+  /** A readwrite lock to guard metadata operations. */\n+  private final ReadWriteLock mMetaLock = new ReentrantReadWriteLock();\n+  @GuardedBy(\"mMetaLock\")\n+  private final MetaStore mMetaStore;\n+  private final FileSystemContext mFsContext;\n \n-  public LocalCacheManager() {\n+  /**\n+   * @param fsContext filesystem context\n+   */\n+  public LocalCacheManager(FileSystemContext fsContext) {\n+    this(fsContext, new MetaStore(), PageStore.create(), CacheEvictor.create());\n   }\n \n-  @Override\n-  public int put(long fileId, long pageId, byte[] page) throws IOException {\n-    mMetaStore.addPage(pageId);\n-    mPageStore.put(fileId, pageId, page);\n-    return 0;\n+  /**\n+   * @param fsContext filesystem context\n+   */\n+  @VisibleForTesting\n+  LocalCacheManager(FileSystemContext fsContext, MetaStore metaStore,\n+                    PageStore pageStore, CacheEvictor evictor) {\n+    mFsContext = fsContext;\n+    mMetaStore = metaStore;\n+    mPageStore = pageStore;\n+    mEvictor = evictor;\n+    mPageSize = (int) mFsContext.getClusterConf().getBytes(PropertyKey.USER_CLIENT_CACHE_PAGE_SIZE);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQ3ODk5Ng=="}, "originalCommit": {"oid": "cadc31fb47fcdbcd1a3b401bcbd8a82c3049d60c"}, "originalPosition": 84}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1NzU4OTg5OnYy", "diffSide": "RIGHT", "path": "core/client/fs/src/main/java/alluxio/client/file/cache/LocalCacheManager.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMVQwMDoyMDowM1rOFcjEZg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMVQwMTowMToxMlrOFcjbwA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQ3OTAxNA==", "bodyText": "return null. using Exceptions for control flow is undesired.", "url": "https://github.com/Alluxio/alluxio/pull/10707#discussion_r365479014", "createdAt": "2020-01-11T00:20:03Z", "author": {"login": "apc999"}, "path": "core/client/fs/src/main/java/alluxio/client/file/cache/LocalCacheManager.java", "diffHunk": "@@ -11,53 +11,240 @@\n \n package alluxio.client.file.cache;\n \n-import alluxio.client.file.cache.store.PageNotFoundException;\n+import alluxio.client.file.FileSystemContext;\n+import alluxio.collections.Pair;\n+import alluxio.conf.PropertyKey;\n+import alluxio.resource.LockResource;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Preconditions;\n+import org.apache.zookeeper.server.ByteBufferInputStream;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.Channels;\n import java.nio.channels.ReadableByteChannel;\n+import java.util.concurrent.locks.ReadWriteLock;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n \n+import javax.annotation.concurrent.GuardedBy;\n import javax.annotation.concurrent.ThreadSafe;\n \n /**\n- * A class to manage cached pages. This class will\n- * 1. Ensure thread-safety\n- * 2. Bookkeep Cache Replacement Alg\n+ * A class to manage cached pages. This class coordinates different components to respond for\n+ * thread-safety and operate cache replacement policies.\n  *\n+ * Lock hierarchy in this class: All operations must follow this order to operate on pages:\n+ * <ul>\n+ * <li>1. Acquire page lock</li>\n+ * <li>2. Acquire metastore lock mMetaLock</li>\n+ * <li>3. Release metastore lock mMetaLock</li>\n+ * <li>4. Release page lock</li>\n+ * </ul>\n  */\n @ThreadSafe\n public class LocalCacheManager implements CacheManager {\n   private static final Logger LOG = LoggerFactory.getLogger(LocalCacheManager.class);\n \n-  private final CacheEvictor mEvictor = CacheEvictor.create();\n-  private final PageStore mPageStore = PageStore.create();\n-  private final MetaStore mMetaStore = new MetaStore();\n+  private static final int LOCK_SIZE = 1024;\n+  private final int mPageSize;\n+  private final long mCacheSize;\n+  private final CacheEvictor mEvictor;\n+  /** A readwrite lock pool to guard individual pages based on striping. */\n+  private final ReadWriteLock[] mPageLocks = new ReentrantReadWriteLock[LOCK_SIZE];\n+  private final PageStore mPageStore;\n+  /** A readwrite lock to guard metadata operations. */\n+  private final ReadWriteLock mMetaLock = new ReentrantReadWriteLock();\n+  @GuardedBy(\"mMetaLock\")\n+  private final MetaStore mMetaStore;\n+  private final FileSystemContext mFsContext;\n \n-  public LocalCacheManager() {\n+  /**\n+   * @param fsContext filesystem context\n+   */\n+  public LocalCacheManager(FileSystemContext fsContext) {\n+    this(fsContext, new MetaStore(), PageStore.create(), CacheEvictor.create());\n   }\n \n-  @Override\n-  public int put(long fileId, long pageId, byte[] page) throws IOException {\n-    mMetaStore.addPage(pageId);\n-    mPageStore.put(fileId, pageId, page);\n-    return 0;\n+  /**\n+   * @param fsContext filesystem context\n+   */\n+  @VisibleForTesting\n+  LocalCacheManager(FileSystemContext fsContext, MetaStore metaStore,\n+                    PageStore pageStore, CacheEvictor evictor) {\n+    mFsContext = fsContext;\n+    mMetaStore = metaStore;\n+    mPageStore = pageStore;\n+    mEvictor = evictor;\n+    mPageSize = (int) mFsContext.getClusterConf().getBytes(PropertyKey.USER_CLIENT_CACHE_PAGE_SIZE);\n+    mCacheSize = mFsContext.getClusterConf().getBytes(PropertyKey.USER_CLIENT_CACHE_SIZE)\n+        / mPageSize;\n+    for (int i = 0; i < LOCK_SIZE; i++) {\n+      mPageLocks[i] = new ReentrantReadWriteLock();\n+    }\n+  }\n+\n+  /**\n+   * Gets the lock for a particular page. Note that multiple pages may share the same lock as lock\n+   * striping is used to reduce resource overhead for locks.\n+   *\n+   * @param fileId file identifier\n+   * @param pageIndex index of the page within the file\n+   * @return the corresponding page lock\n+   */\n+  private ReadWriteLock getPageLock(long fileId, long pageIndex) {\n+    return mPageLocks[(int) (fileId + pageIndex) % LOCK_SIZE];\n+  }\n+\n+  /**\n+   * Gets a pair of locks to operate two given pages. One MUST acquire the first lock followed by\n+   * the second lock.\n+   *\n+   * @param fileId file identifier\n+   * @param pageIndex index of the page within the file\n+   * @param fileId2 file identifier\n+   * @param pageIndex2 index of the page within the file\n+   * @return the corresponding page lock pair\n+   */\n+  private Pair<ReadWriteLock, ReadWriteLock> getPageLockPair(long fileId, long pageIndex,\n+      long fileId2, long pageIndex2) {\n+    if (fileId + pageIndex < fileId2 + pageIndex2) {\n+      return new Pair<>(getPageLock(fileId, pageIndex), getPageLock(fileId2, pageIndex2));\n+    } else {\n+      return new Pair<>(getPageLock(fileId2, pageIndex2), getPageLock(fileId, pageIndex));\n+    }\n   }\n \n   @Override\n-  public ReadableByteChannel get(long fileId, long pageId) throws IOException {\n-    if (!mMetaStore.hasPage(pageId)) {\n+  public void put(long fileId, long pageIndex, byte[] page) throws IOException {\n+    long victimFileId = 0;\n+    long victimPageIndex = 0;\n \n+    ReadWriteLock pageLock = getPageLock(fileId, pageIndex);\n+    try (LockResource r = new LockResource(pageLock.writeLock())) {\n+      boolean alreadyCached;\n+      boolean needEvict = false;\n+      try (LockResource r2 = new LockResource(mMetaLock.writeLock())) {\n+        alreadyCached = mMetaStore.hasPage(fileId, pageIndex);\n+        if (!alreadyCached) {\n+          needEvict = mPageStore.size() + 1 > mCacheSize;\n+          if (needEvict) {\n+            Pair<Long, Long> victim = mEvictor.evict();\n+            victimFileId = victim.getFirst();\n+            victimPageIndex = victim.getSecond();\n+          } else {\n+            mMetaStore.addPage(fileId, pageIndex);\n+          }\n+        }\n+      }\n+      if (alreadyCached) {\n+        try {\n+          mPageStore.delete(fileId, pageIndex);\n+        } catch (PageNotFoundException e) {\n+          // this should never happen with proper locking\n+          LOG.error(\"failed to delete page {} {} from page store\", fileId, pageIndex, e);\n+        }\n+        mEvictor.updateOnPut(fileId, pageIndex);\n+        mPageStore.put(fileId, pageIndex, page);\n+      } else if (!needEvict) {\n+        mEvictor.updateOnPut(fileId, pageIndex);\n+        mPageStore.put(fileId, pageIndex, page);\n+      }\n     }\n-    mEvictor.updateOnGet(pageId);\n-    return null;\n+\n+    Pair<ReadWriteLock, ReadWriteLock> pageLockPair =\n+        getPageLockPair(fileId, pageIndex, victimFileId, victimPageIndex);\n+    try (LockResource r1 = new LockResource(pageLockPair.getFirst().writeLock());\n+        LockResource r2 = new LockResource(pageLockPair.getSecond().writeLock())) {\n+      try (LockResource r3 = new LockResource(mMetaLock.writeLock())) {\n+        if (mMetaStore.hasPage(fileId, pageIndex)) {\n+          LOG.warn(\"fileId {} pageIndex {} is already inserted by a racing thread\",\n+              fileId, pageIndex);\n+          return;\n+        }\n+        if (!mMetaStore.hasPage(victimFileId, victimPageIndex)) {\n+          LOG.warn(\"fileId {} pageIndex {} is already evicted by a racing thread\",\n+              fileId, pageIndex);\n+          return;\n+        }\n+        try {\n+          mMetaStore.removePage(victimFileId, victimPageIndex);\n+        } catch (PageNotFoundException e) {\n+          // this should never happen with proper locking\n+          LOG.error(\"failed to remove page {} {} from meta store\",\n+              victimFileId, victimPageIndex, e);\n+        }\n+        mEvictor.updateOnDelete(victimFileId, victimPageIndex);\n+        mMetaStore.addPage(fileId, pageIndex);\n+        mEvictor.updateOnPut(fileId, pageIndex);\n+      }\n+      try {\n+        mPageStore.delete(victimFileId, victimPageIndex);\n+      } catch (PageNotFoundException e) {\n+        // this should never happen with proper locking\n+        LOG.error(\"failed to delete page {} {} from page store\", victimFileId, victimPageIndex, e);\n+      }\n+      mPageStore.put(fileId, pageIndex, page);\n+    }\n+  }\n+\n+  @Override\n+  public ReadableByteChannel get(long fileId, long pageIndex) throws IOException,\n+      PageNotFoundException {\n+    return get(fileId, pageIndex, 0, mPageSize);\n   }\n \n   @Override\n-  public boolean delete(long fileId, long pageId) throws IOException, PageNotFoundException {\n-    mMetaStore.removePage(pageId);\n-    mPageStore.delete(fileId, pageId);\n-    return false;\n+  public ReadableByteChannel get(long fileId, long pageIndex, int pageOffset, int length)\n+      throws IOException, PageNotFoundException {\n+    Preconditions.checkArgument(pageOffset + length <= mPageSize,\n+        \"Read exceeds page boundary: offset=%s length=%s, size=%s\", pageOffset, length, mPageSize);\n+    ReadableByteChannel ret;\n+    boolean hasPage;\n+    ReadWriteLock pageLock = getPageLock(fileId, pageIndex);\n+    try (LockResource r = new LockResource(pageLock.readLock())) {\n+      try (LockResource r2 = new LockResource(mMetaLock.readLock())) {\n+        hasPage = mMetaStore.hasPage(fileId, pageIndex);\n+      }\n+      if (!hasPage) {\n+        throw new PageNotFoundException(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cadc31fb47fcdbcd1a3b401bcbd8a82c3049d60c"}, "originalPosition": 223}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQ4NDk5Mg==", "bodyText": "Refactored.", "url": "https://github.com/Alluxio/alluxio/pull/10707#discussion_r365484992", "createdAt": "2020-01-11T01:01:12Z", "author": {"login": "bf8086"}, "path": "core/client/fs/src/main/java/alluxio/client/file/cache/LocalCacheManager.java", "diffHunk": "@@ -11,53 +11,240 @@\n \n package alluxio.client.file.cache;\n \n-import alluxio.client.file.cache.store.PageNotFoundException;\n+import alluxio.client.file.FileSystemContext;\n+import alluxio.collections.Pair;\n+import alluxio.conf.PropertyKey;\n+import alluxio.resource.LockResource;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Preconditions;\n+import org.apache.zookeeper.server.ByteBufferInputStream;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.Channels;\n import java.nio.channels.ReadableByteChannel;\n+import java.util.concurrent.locks.ReadWriteLock;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n \n+import javax.annotation.concurrent.GuardedBy;\n import javax.annotation.concurrent.ThreadSafe;\n \n /**\n- * A class to manage cached pages. This class will\n- * 1. Ensure thread-safety\n- * 2. Bookkeep Cache Replacement Alg\n+ * A class to manage cached pages. This class coordinates different components to respond for\n+ * thread-safety and operate cache replacement policies.\n  *\n+ * Lock hierarchy in this class: All operations must follow this order to operate on pages:\n+ * <ul>\n+ * <li>1. Acquire page lock</li>\n+ * <li>2. Acquire metastore lock mMetaLock</li>\n+ * <li>3. Release metastore lock mMetaLock</li>\n+ * <li>4. Release page lock</li>\n+ * </ul>\n  */\n @ThreadSafe\n public class LocalCacheManager implements CacheManager {\n   private static final Logger LOG = LoggerFactory.getLogger(LocalCacheManager.class);\n \n-  private final CacheEvictor mEvictor = CacheEvictor.create();\n-  private final PageStore mPageStore = PageStore.create();\n-  private final MetaStore mMetaStore = new MetaStore();\n+  private static final int LOCK_SIZE = 1024;\n+  private final int mPageSize;\n+  private final long mCacheSize;\n+  private final CacheEvictor mEvictor;\n+  /** A readwrite lock pool to guard individual pages based on striping. */\n+  private final ReadWriteLock[] mPageLocks = new ReentrantReadWriteLock[LOCK_SIZE];\n+  private final PageStore mPageStore;\n+  /** A readwrite lock to guard metadata operations. */\n+  private final ReadWriteLock mMetaLock = new ReentrantReadWriteLock();\n+  @GuardedBy(\"mMetaLock\")\n+  private final MetaStore mMetaStore;\n+  private final FileSystemContext mFsContext;\n \n-  public LocalCacheManager() {\n+  /**\n+   * @param fsContext filesystem context\n+   */\n+  public LocalCacheManager(FileSystemContext fsContext) {\n+    this(fsContext, new MetaStore(), PageStore.create(), CacheEvictor.create());\n   }\n \n-  @Override\n-  public int put(long fileId, long pageId, byte[] page) throws IOException {\n-    mMetaStore.addPage(pageId);\n-    mPageStore.put(fileId, pageId, page);\n-    return 0;\n+  /**\n+   * @param fsContext filesystem context\n+   */\n+  @VisibleForTesting\n+  LocalCacheManager(FileSystemContext fsContext, MetaStore metaStore,\n+                    PageStore pageStore, CacheEvictor evictor) {\n+    mFsContext = fsContext;\n+    mMetaStore = metaStore;\n+    mPageStore = pageStore;\n+    mEvictor = evictor;\n+    mPageSize = (int) mFsContext.getClusterConf().getBytes(PropertyKey.USER_CLIENT_CACHE_PAGE_SIZE);\n+    mCacheSize = mFsContext.getClusterConf().getBytes(PropertyKey.USER_CLIENT_CACHE_SIZE)\n+        / mPageSize;\n+    for (int i = 0; i < LOCK_SIZE; i++) {\n+      mPageLocks[i] = new ReentrantReadWriteLock();\n+    }\n+  }\n+\n+  /**\n+   * Gets the lock for a particular page. Note that multiple pages may share the same lock as lock\n+   * striping is used to reduce resource overhead for locks.\n+   *\n+   * @param fileId file identifier\n+   * @param pageIndex index of the page within the file\n+   * @return the corresponding page lock\n+   */\n+  private ReadWriteLock getPageLock(long fileId, long pageIndex) {\n+    return mPageLocks[(int) (fileId + pageIndex) % LOCK_SIZE];\n+  }\n+\n+  /**\n+   * Gets a pair of locks to operate two given pages. One MUST acquire the first lock followed by\n+   * the second lock.\n+   *\n+   * @param fileId file identifier\n+   * @param pageIndex index of the page within the file\n+   * @param fileId2 file identifier\n+   * @param pageIndex2 index of the page within the file\n+   * @return the corresponding page lock pair\n+   */\n+  private Pair<ReadWriteLock, ReadWriteLock> getPageLockPair(long fileId, long pageIndex,\n+      long fileId2, long pageIndex2) {\n+    if (fileId + pageIndex < fileId2 + pageIndex2) {\n+      return new Pair<>(getPageLock(fileId, pageIndex), getPageLock(fileId2, pageIndex2));\n+    } else {\n+      return new Pair<>(getPageLock(fileId2, pageIndex2), getPageLock(fileId, pageIndex));\n+    }\n   }\n \n   @Override\n-  public ReadableByteChannel get(long fileId, long pageId) throws IOException {\n-    if (!mMetaStore.hasPage(pageId)) {\n+  public void put(long fileId, long pageIndex, byte[] page) throws IOException {\n+    long victimFileId = 0;\n+    long victimPageIndex = 0;\n \n+    ReadWriteLock pageLock = getPageLock(fileId, pageIndex);\n+    try (LockResource r = new LockResource(pageLock.writeLock())) {\n+      boolean alreadyCached;\n+      boolean needEvict = false;\n+      try (LockResource r2 = new LockResource(mMetaLock.writeLock())) {\n+        alreadyCached = mMetaStore.hasPage(fileId, pageIndex);\n+        if (!alreadyCached) {\n+          needEvict = mPageStore.size() + 1 > mCacheSize;\n+          if (needEvict) {\n+            Pair<Long, Long> victim = mEvictor.evict();\n+            victimFileId = victim.getFirst();\n+            victimPageIndex = victim.getSecond();\n+          } else {\n+            mMetaStore.addPage(fileId, pageIndex);\n+          }\n+        }\n+      }\n+      if (alreadyCached) {\n+        try {\n+          mPageStore.delete(fileId, pageIndex);\n+        } catch (PageNotFoundException e) {\n+          // this should never happen with proper locking\n+          LOG.error(\"failed to delete page {} {} from page store\", fileId, pageIndex, e);\n+        }\n+        mEvictor.updateOnPut(fileId, pageIndex);\n+        mPageStore.put(fileId, pageIndex, page);\n+      } else if (!needEvict) {\n+        mEvictor.updateOnPut(fileId, pageIndex);\n+        mPageStore.put(fileId, pageIndex, page);\n+      }\n     }\n-    mEvictor.updateOnGet(pageId);\n-    return null;\n+\n+    Pair<ReadWriteLock, ReadWriteLock> pageLockPair =\n+        getPageLockPair(fileId, pageIndex, victimFileId, victimPageIndex);\n+    try (LockResource r1 = new LockResource(pageLockPair.getFirst().writeLock());\n+        LockResource r2 = new LockResource(pageLockPair.getSecond().writeLock())) {\n+      try (LockResource r3 = new LockResource(mMetaLock.writeLock())) {\n+        if (mMetaStore.hasPage(fileId, pageIndex)) {\n+          LOG.warn(\"fileId {} pageIndex {} is already inserted by a racing thread\",\n+              fileId, pageIndex);\n+          return;\n+        }\n+        if (!mMetaStore.hasPage(victimFileId, victimPageIndex)) {\n+          LOG.warn(\"fileId {} pageIndex {} is already evicted by a racing thread\",\n+              fileId, pageIndex);\n+          return;\n+        }\n+        try {\n+          mMetaStore.removePage(victimFileId, victimPageIndex);\n+        } catch (PageNotFoundException e) {\n+          // this should never happen with proper locking\n+          LOG.error(\"failed to remove page {} {} from meta store\",\n+              victimFileId, victimPageIndex, e);\n+        }\n+        mEvictor.updateOnDelete(victimFileId, victimPageIndex);\n+        mMetaStore.addPage(fileId, pageIndex);\n+        mEvictor.updateOnPut(fileId, pageIndex);\n+      }\n+      try {\n+        mPageStore.delete(victimFileId, victimPageIndex);\n+      } catch (PageNotFoundException e) {\n+        // this should never happen with proper locking\n+        LOG.error(\"failed to delete page {} {} from page store\", victimFileId, victimPageIndex, e);\n+      }\n+      mPageStore.put(fileId, pageIndex, page);\n+    }\n+  }\n+\n+  @Override\n+  public ReadableByteChannel get(long fileId, long pageIndex) throws IOException,\n+      PageNotFoundException {\n+    return get(fileId, pageIndex, 0, mPageSize);\n   }\n \n   @Override\n-  public boolean delete(long fileId, long pageId) throws IOException, PageNotFoundException {\n-    mMetaStore.removePage(pageId);\n-    mPageStore.delete(fileId, pageId);\n-    return false;\n+  public ReadableByteChannel get(long fileId, long pageIndex, int pageOffset, int length)\n+      throws IOException, PageNotFoundException {\n+    Preconditions.checkArgument(pageOffset + length <= mPageSize,\n+        \"Read exceeds page boundary: offset=%s length=%s, size=%s\", pageOffset, length, mPageSize);\n+    ReadableByteChannel ret;\n+    boolean hasPage;\n+    ReadWriteLock pageLock = getPageLock(fileId, pageIndex);\n+    try (LockResource r = new LockResource(pageLock.readLock())) {\n+      try (LockResource r2 = new LockResource(mMetaLock.readLock())) {\n+        hasPage = mMetaStore.hasPage(fileId, pageIndex);\n+      }\n+      if (!hasPage) {\n+        throw new PageNotFoundException(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQ3OTAxNA=="}, "originalCommit": {"oid": "cadc31fb47fcdbcd1a3b401bcbd8a82c3049d60c"}, "originalPosition": 223}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1NzU5MDg0OnYy", "diffSide": "RIGHT", "path": "core/client/fs/src/main/java/alluxio/client/file/cache/PageNotFoundException.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMVQwMDoyMTowN1rOFcjFBw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMVQwMDo1OTo0OFrOFcjbLg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQ3OTE3NQ==", "bodyText": "we typically put all Alluxio exceptions together rather than leaving them  in different packages.", "url": "https://github.com/Alluxio/alluxio/pull/10707#discussion_r365479175", "createdAt": "2020-01-11T00:21:07Z", "author": {"login": "apc999"}, "path": "core/client/fs/src/main/java/alluxio/client/file/cache/PageNotFoundException.java", "diffHunk": "@@ -10,7 +10,7 @@\n  *\n  */\n \n-package alluxio.client.file.cache.store;\n+package alluxio.client.file.cache;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cadc31fb47fcdbcd1a3b401bcbd8a82c3049d60c"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQ4NDg0Ng==", "bodyText": "Moved.", "url": "https://github.com/Alluxio/alluxio/pull/10707#discussion_r365484846", "createdAt": "2020-01-11T00:59:48Z", "author": {"login": "bf8086"}, "path": "core/client/fs/src/main/java/alluxio/client/file/cache/PageNotFoundException.java", "diffHunk": "@@ -10,7 +10,7 @@\n  *\n  */\n \n-package alluxio.client.file.cache.store;\n+package alluxio.client.file.cache;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQ3OTE3NQ=="}, "originalCommit": {"oid": "cadc31fb47fcdbcd1a3b401bcbd8a82c3049d60c"}, "originalPosition": 5}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2199, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}