{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTAxMDczOTI5", "number": 12230, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QwMzozNDo1NFrOEs2i2g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QwMzozNjozN1rOEs2kCw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE1NDY2NDU4OnYy", "diffSide": "RIGHT", "path": "docs/en/cloud/Alibaba-Cloud-ACK.md", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QwMzozNDo1NFrOHgUM1Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QwODoxMDo1NFrOHgajeA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzY0NzQ0NQ==", "bodyText": "from alluxio master node to alluxio?", "url": "https://github.com/Alluxio/alluxio/pull/12230#discussion_r503647445", "createdAt": "2020-10-13T03:34:54Z", "author": {"login": "LuQQiu"}, "path": "docs/en/cloud/Alibaba-Cloud-ACK.md", "diffHunk": "@@ -106,40 +106,49 @@ After the download is complete, unzip the package and set env \"`SPARK_HOME`\":\n $ tar -xf spark-2.4.6-bin-hadoop2.7.tgz\n $ export SPARK_HOME=$(pwd)/spark-2.4.6-bin-hadoop2.7\n ```\n-The spark docker image is the image we used when submitting the spark task. This image needs to include the alluxio client jar package. Use the following command to obtain the alluxio client jar package:\n+\n+The spark docker image is the image we used when submitting the Spark task. \n+This image needs to include the Alluxio client jar package. \n+You can obtain the Alluxio client jar package as follows:\n ```console\n-$ id=$(docker create alluxio/alluxio-enterprise:2.2.1-1.4)\n-$ docker cp $id:/opt/alluxio/client/alluxio-enterprise-2.2.1-1.4-client.jar \\\n-\t$SPARK_HOME/jars/alluxio-enterprise-2.2.1-1.4-client.jar\n+$ id=$(docker create alluxio/alluxio:{{site.ALLUXIO_VERSION_STRING}})\n+$ docker cp $id:/opt/alluxio/client/alluxio-{{site.ALLUXIO_VERSION_STRING}}-client.jar \\\n+\t$SPARK_HOME/jars/alluxio-{{site.ALLUXIO_VERSION_STRING}}-client.jar\n $ docker rm -v $id 1>/dev/null\n ```\n-After the alluxio client jar package is ready, start building the image:\n+\n+After the Alluxio client jar package is ready, start building the image:\n ```console\n $ docker build -t \\\n   spark-alluxio:2.4.6 -f $SPARK_HOME/kubernetes/dockerfiles/spark/Dockerfile $SPARK_HOME\n ```\n-After the image is built, there are two ways to process the image:\n+You can find more details about running Alluxio with Spark on Kubernetes [here]({{ '/en/compute/Spark-On-Kubernetes.html' | relativize_url }}).\n+\n+After the image is built, there are two ways to distribute the image:\n \n-* If there is a private image warehouse, push the image to the private image warehouse, and ensure that the k8s cluster node can pull the image.\n-* If there is no private image warehouse, you need to use the docker save command to export the image, and then scp to each node of the k8s cluster, use the docker load command on each node to import the image, so that you can ensure that each node exists The mirror.\n+* If there is a private image warehouse, push the image to the private image warehouse, and ensure that the K8s cluster node can pull the image.\n+* If there is no private image warehouse, you need to use the `docker save` command to export the image, then scp the image to each node of the K8s cluster, use the `docker load` command on each node to load the image.\n  {% endcollapsible %}\n \n  {% collapsible Upload files to Alluxio %}\n-As mentioned at the beginning of the document: This experiment is to submit a spark job to k8s and the goal of the spark job is to count the number of occurrences of each word for a certain file. Now you need to upload the file to the alluxio storage. Here, for convenience, you can directly upload the file `/opt/alluxio-{{site.ALLUXIO_VERSION_STRING}}/LICENSE` in the alluxio master (the file path may be slightly different due to the alluxio version) to alluxio.\n+As mentioned at the beginning: In this experiment we will submit a Spark job to K8s. \n+The Spark job will perform a word count calculation on a certain file. \n+Before we kick off the Spark job, we need to upload the file to the Alluxio storage. \n+Here, for convenience, we directly upload the file `/opt/alluxio-{{site.ALLUXIO_VERSION_STRING}}/LICENSE` from the Alluxio master node (the file path may be slightly different due to the Alluxio version) to Alluxio.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "70c553314ff278062bf2832f171dd26247c64553"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzc1MTU0NA==", "bodyText": "What about from the Alluxio master node to the Alluxio namespace? It means copyFromLocal from the node into Alluxio.", "url": "https://github.com/Alluxio/alluxio/pull/12230#discussion_r503751544", "createdAt": "2020-10-13T08:10:54Z", "author": {"login": "jiacheliu3"}, "path": "docs/en/cloud/Alibaba-Cloud-ACK.md", "diffHunk": "@@ -106,40 +106,49 @@ After the download is complete, unzip the package and set env \"`SPARK_HOME`\":\n $ tar -xf spark-2.4.6-bin-hadoop2.7.tgz\n $ export SPARK_HOME=$(pwd)/spark-2.4.6-bin-hadoop2.7\n ```\n-The spark docker image is the image we used when submitting the spark task. This image needs to include the alluxio client jar package. Use the following command to obtain the alluxio client jar package:\n+\n+The spark docker image is the image we used when submitting the Spark task. \n+This image needs to include the Alluxio client jar package. \n+You can obtain the Alluxio client jar package as follows:\n ```console\n-$ id=$(docker create alluxio/alluxio-enterprise:2.2.1-1.4)\n-$ docker cp $id:/opt/alluxio/client/alluxio-enterprise-2.2.1-1.4-client.jar \\\n-\t$SPARK_HOME/jars/alluxio-enterprise-2.2.1-1.4-client.jar\n+$ id=$(docker create alluxio/alluxio:{{site.ALLUXIO_VERSION_STRING}})\n+$ docker cp $id:/opt/alluxio/client/alluxio-{{site.ALLUXIO_VERSION_STRING}}-client.jar \\\n+\t$SPARK_HOME/jars/alluxio-{{site.ALLUXIO_VERSION_STRING}}-client.jar\n $ docker rm -v $id 1>/dev/null\n ```\n-After the alluxio client jar package is ready, start building the image:\n+\n+After the Alluxio client jar package is ready, start building the image:\n ```console\n $ docker build -t \\\n   spark-alluxio:2.4.6 -f $SPARK_HOME/kubernetes/dockerfiles/spark/Dockerfile $SPARK_HOME\n ```\n-After the image is built, there are two ways to process the image:\n+You can find more details about running Alluxio with Spark on Kubernetes [here]({{ '/en/compute/Spark-On-Kubernetes.html' | relativize_url }}).\n+\n+After the image is built, there are two ways to distribute the image:\n \n-* If there is a private image warehouse, push the image to the private image warehouse, and ensure that the k8s cluster node can pull the image.\n-* If there is no private image warehouse, you need to use the docker save command to export the image, and then scp to each node of the k8s cluster, use the docker load command on each node to import the image, so that you can ensure that each node exists The mirror.\n+* If there is a private image warehouse, push the image to the private image warehouse, and ensure that the K8s cluster node can pull the image.\n+* If there is no private image warehouse, you need to use the `docker save` command to export the image, then scp the image to each node of the K8s cluster, use the `docker load` command on each node to load the image.\n  {% endcollapsible %}\n \n  {% collapsible Upload files to Alluxio %}\n-As mentioned at the beginning of the document: This experiment is to submit a spark job to k8s and the goal of the spark job is to count the number of occurrences of each word for a certain file. Now you need to upload the file to the alluxio storage. Here, for convenience, you can directly upload the file `/opt/alluxio-{{site.ALLUXIO_VERSION_STRING}}/LICENSE` in the alluxio master (the file path may be slightly different due to the alluxio version) to alluxio.\n+As mentioned at the beginning: In this experiment we will submit a Spark job to K8s. \n+The Spark job will perform a word count calculation on a certain file. \n+Before we kick off the Spark job, we need to upload the file to the Alluxio storage. \n+Here, for convenience, we directly upload the file `/opt/alluxio-{{site.ALLUXIO_VERSION_STRING}}/LICENSE` from the Alluxio master node (the file path may be slightly different due to the Alluxio version) to Alluxio.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzY0NzQ0NQ=="}, "originalCommit": {"oid": "70c553314ff278062bf2832f171dd26247c64553"}, "originalPosition": 87}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE1NDY2NjQ2OnYy", "diffSide": "RIGHT", "path": "docs/en/cloud/Alibaba-Cloud-ACK.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QwMzozNTo1N1rOHgUN3A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QwMzozNTo1N1rOHgUN3A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzY0NzcwOA==", "bodyText": "better to use backstick around 192.168.8.17", "url": "https://github.com/Alluxio/alluxio/pull/12230#discussion_r503647708", "createdAt": "2020-10-13T03:35:57Z", "author": {"login": "LuQQiu"}, "path": "docs/en/cloud/Alibaba-Cloud-ACK.md", "diffHunk": "@@ -148,9 +157,9 @@ Containing the following blocks:\n BlockInfo{id=16777216, length=27040, locations=[BlockLocation{workerId=8217561227881498090, address=WorkerNetAddress{host=192.168.8.17, containerHost=, rpcPort=29999, dataPort=29999, webPort=30000, domainSocketPath=, tieredIdentity=TieredIdentity (node=192.168.8.17, rack=null)}, tierAlias=MEM, mediumType=MEM}]}\n ```\n \n-As shown, this `LICENSE` file has only one block whose id is 16777216,  placed on the k8s node of **192.168.8.17**.\n+As shown, this `LICENSE` file has only one block whose id is 16777216,  placed on the K8s node **192.168.8.17**.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "70c553314ff278062bf2832f171dd26247c64553"}, "originalPosition": 114}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE1NDY2Njk4OnYy", "diffSide": "RIGHT", "path": "docs/en/cloud/Alibaba-Cloud-ACK.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QwMzozNjoxM1rOHgUOJw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QwMzozNjoxM1rOHgUOJw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzY0Nzc4Mw==", "bodyText": "may be better to use backstick around cn-beijing.192.168.8.17", "url": "https://github.com/Alluxio/alluxio/pull/12230#discussion_r503647783", "createdAt": "2020-10-13T03:36:13Z", "author": {"login": "LuQQiu"}, "path": "docs/en/cloud/Alibaba-Cloud-ACK.md", "diffHunk": "@@ -148,9 +157,9 @@ Containing the following blocks:\n BlockInfo{id=16777216, length=27040, locations=[BlockLocation{workerId=8217561227881498090, address=WorkerNetAddress{host=192.168.8.17, containerHost=, rpcPort=29999, dataPort=29999, webPort=30000, domainSocketPath=, tieredIdentity=TieredIdentity (node=192.168.8.17, rack=null)}, tierAlias=MEM, mediumType=MEM}]}\n ```\n \n-As shown, this `LICENSE` file has only one block whose id is 16777216,  placed on the k8s node of **192.168.8.17**.\n+As shown, this `LICENSE` file has only one block whose id is 16777216,  placed on the K8s node **192.168.8.17**.\n \n-We use `kubectl` to find out that the node name is **cn-beijing.192.168.8.17**:\n+We use `kubectl` to identify that the node name is **cn-beijing.192.168.8.17**:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "70c553314ff278062bf2832f171dd26247c64553"}, "originalPosition": 117}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE1NDY2NzYzOnYy", "diffSide": "RIGHT", "path": "docs/en/cloud/Alibaba-Cloud-ACK.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QwMzozNjozN1rOHgUOhw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QwMzozNjozN1rOHgUOhw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzY0Nzg3OQ==", "bodyText": "LICENSE", "url": "https://github.com/Alluxio/alluxio/pull/12230#discussion_r503647879", "createdAt": "2020-10-13T03:36:37Z", "author": {"login": "LuQQiu"}, "path": "docs/en/cloud/Alibaba-Cloud-ACK.md", "diffHunk": "@@ -165,13 +174,20 @@ cn-beijing.192.168.8.17  192.168.8.17\n   {% endcollapsible %}\n \n   {% collapsible Submit Spark job %}\n-The following steps will submit a spark job to the k8s cluster. The job is mainly to count the number of occurrences of each word in the `/LICENSE` file in alluxio.\n+The following steps will submit a Spark job to the K8s cluster. \n+The job is mainly to count the number of occurrences of each word in the `/LICENSE` file in Alluxio.\n \n-In step 5.3, we obtained that the blocks contained in the LICENSE file are all on the node cn-beijing.192.168.8.17. In this experiment, we specified the node selector to let the spark driver and spark executor run on the node cn-beijing. 192.168.8.17, verify that the communication between spark executor and alluxio worker is completed through the domain socket when alluxio's short-circuit function is turned on.\n+In the previous step, we see that the blocks contained in the LICENSE file are all on the node `cn-beijing.192.168.8.17`. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "70c553314ff278062bf2832f171dd26247c64553"}, "originalPosition": 130}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1124, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}