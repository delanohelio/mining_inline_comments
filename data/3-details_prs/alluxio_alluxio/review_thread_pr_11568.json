{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDM1MDU3MzQ4", "number": 11568, "reviewThreads": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQwODozMDoyMlrOEF1iBw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QwMjowNDo0NFrOEGKusA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc0NTU1Mzk5OnYy", "diffSide": "RIGHT", "path": "shell/src/main/java/alluxio/cli/validation/hdfs/SecureHdfsValidationTask.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQwODozMDoyMlrOGkQ2YA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQwODozMDoyMlrOGkQ2YA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDY3Nzk4NA==", "bodyText": "Changed to a more lenient format following https://github.com/cloudera/hadoop-common/blob/ca2ff489eb805da4700fb15fa49e539f1c195b89/src/java/org/apache/hadoop/security/KerberosName.java#L53 and the implementation of zookeeper org.apache.zookeeper.server.auth.KerberosName.\nThe previous pattern does not allow dot in the realm like @ALLUXIO.COM", "url": "https://github.com/Alluxio/alluxio/pull/11568#discussion_r440677984", "createdAt": "2020-06-16T08:30:22Z", "author": {"login": "jiacheliu3"}, "path": "shell/src/main/java/alluxio/cli/validation/hdfs/SecureHdfsValidationTask.java", "diffHunk": "@@ -39,7 +38,7 @@\n    * for more details.\n    */\n   private static final Pattern PRINCIPAL_PATTERN =\n-      Pattern.compile(\"(?<primary>[\\\\w][\\\\w-]*\\\\$?)(/(?<instance>[\\\\w]+))?(@(?<realm>[\\\\w]+))?\");\n+      Pattern.compile(\"(?<primary>[^/@]*)(/(?<instance>[^/@]*))?@(?<realm>[^/@]*)\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ce6dbc2f0e5407883f2d78ad74dc15607f13c96"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc0OTAwNzM1OnYy", "diffSide": "RIGHT", "path": "shell/src/main/java/alluxio/cli/validation/hdfs/SecureHdfsValidationTask.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QwMTo1Mjo0MFrOGky4fQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QwNTowMzowOFrOGk1tcw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTIzNTU4MQ==", "bodyText": "Can we use org.apache.hadoop.fs.CommonConfigurationKeysPublic#HADOOP_SECURITY_AUTHORIZATION instead?", "url": "https://github.com/Alluxio/alluxio/pull/11568#discussion_r441235581", "createdAt": "2020-06-17T01:52:40Z", "author": {"login": "bf8086"}, "path": "shell/src/main/java/alluxio/cli/validation/hdfs/SecureHdfsValidationTask.java", "diffHunk": "@@ -51,6 +50,13 @@\n       PRINCIPAL_MAP_MASTER_KEY, PropertyKey.MASTER_KEYTAB_KEY_FILE,\n       PRINCIPAL_MAP_WORKER_KEY, PropertyKey.WORKER_KEYTAB_FILE);\n \n+  private static final String HDFS_AUTHORIZATION_KEY = \"hadoop.security.authorization\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ce6dbc2f0e5407883f2d78ad74dc15607f13c96"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTI1MjA3OA==", "bodyText": "I'm a bit concerned this introduces hadoop-common to shell/ and might lead to us shading jars to not break the downstream. @LuQQiu What do you think? If it's okay we add hadoop common directly to shell, i'll make this change. Otherwise I prefer to leave a TODO here and revisit it after 2.3.", "url": "https://github.com/Alluxio/alluxio/pull/11568#discussion_r441252078", "createdAt": "2020-06-17T02:56:40Z", "author": {"login": "jiacheliu3"}, "path": "shell/src/main/java/alluxio/cli/validation/hdfs/SecureHdfsValidationTask.java", "diffHunk": "@@ -51,6 +50,13 @@\n       PRINCIPAL_MAP_MASTER_KEY, PropertyKey.MASTER_KEYTAB_KEY_FILE,\n       PRINCIPAL_MAP_WORKER_KEY, PropertyKey.WORKER_KEYTAB_FILE);\n \n+  private static final String HDFS_AUTHORIZATION_KEY = \"hadoop.security.authorization\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTIzNTU4MQ=="}, "originalCommit": {"oid": "3ce6dbc2f0e5407883f2d78ad74dc15607f13c96"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTI4MTkwNw==", "bodyText": "Discussed with @LuQQiu. Since there's no quick way to verify if we have to shade it in shell/, I added a TODO.", "url": "https://github.com/Alluxio/alluxio/pull/11568#discussion_r441281907", "createdAt": "2020-06-17T05:03:08Z", "author": {"login": "jiacheliu3"}, "path": "shell/src/main/java/alluxio/cli/validation/hdfs/SecureHdfsValidationTask.java", "diffHunk": "@@ -51,6 +50,13 @@\n       PRINCIPAL_MAP_MASTER_KEY, PropertyKey.MASTER_KEYTAB_KEY_FILE,\n       PRINCIPAL_MAP_WORKER_KEY, PropertyKey.WORKER_KEYTAB_FILE);\n \n+  private static final String HDFS_AUTHORIZATION_KEY = \"hadoop.security.authorization\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTIzNTU4MQ=="}, "originalCommit": {"oid": "3ce6dbc2f0e5407883f2d78ad74dc15607f13c96"}, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc0OTAwODQ3OnYy", "diffSide": "RIGHT", "path": "shell/src/main/java/alluxio/cli/validation/hdfs/SecureHdfsValidationTask.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QwMTo1MzoyMFrOGky5MA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QwMTo1MzoyMFrOGky5MA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTIzNTc2MA==", "bodyText": "Same here.", "url": "https://github.com/Alluxio/alluxio/pull/11568#discussion_r441235760", "createdAt": "2020-06-17T01:53:20Z", "author": {"login": "bf8086"}, "path": "shell/src/main/java/alluxio/cli/validation/hdfs/SecureHdfsValidationTask.java", "diffHunk": "@@ -51,6 +50,13 @@\n       PRINCIPAL_MAP_MASTER_KEY, PropertyKey.MASTER_KEYTAB_KEY_FILE,\n       PRINCIPAL_MAP_WORKER_KEY, PropertyKey.WORKER_KEYTAB_FILE);\n \n+  private static final String HDFS_AUTHORIZATION_KEY = \"hadoop.security.authorization\";\n+  private static final String HDFS_AUTHORIZATION_VALUE = \"true\";\n+  private static final String HDFS_AUTHENTICATION_KEY = \"hadoop.security.authentication\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ce6dbc2f0e5407883f2d78ad74dc15607f13c96"}, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc0OTAxMzcxOnYy", "diffSide": "RIGHT", "path": "shell/src/main/java/alluxio/cli/validation/hdfs/SecureHdfsValidationTask.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QwMTo1Njo1MlrOGky8ig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QwMTo1Njo1MlrOGky8ig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTIzNjYxOA==", "bodyText": "StringUtils.capitalize(mProcess)?", "url": "https://github.com/Alluxio/alluxio/pull/11568#discussion_r441236618", "createdAt": "2020-06-17T01:56:52Z", "author": {"login": "bf8086"}, "path": "shell/src/main/java/alluxio/cli/validation/hdfs/SecureHdfsValidationTask.java", "diffHunk": "@@ -79,36 +86,72 @@ public SecureHdfsValidationTask(String process, String path, AlluxioConfiguratio\n \n   @Override\n   public String getName() {\n-    return String.format(\"ValidateKerberosForSecureHdfs%s\", mProcess.toUpperCase());\n+    // Convert the first char to upper case\n+    char first = Character.toUpperCase(mProcess.charAt(0));\n+    return String.format(\"ValidateKerberosForSecureHdfs%s\", first + mProcess.substring(1));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ce6dbc2f0e5407883f2d78ad74dc15607f13c96"}, "originalPosition": 55}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc0OTAyNDY5OnYy", "diffSide": "RIGHT", "path": "shell/src/main/java/alluxio/cli/validation/hdfs/SecureHdfsValidationTask.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QwMjowMzoxNlrOGkzDGQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QwMjo1OTo0N1rOGkz8Dw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTIzODI5Nw==", "bodyText": "These properties are not bound to be enabled at the same time, you can have authentication set to \"simple\" but have the authorization on.", "url": "https://github.com/Alluxio/alluxio/pull/11568#discussion_r441238297", "createdAt": "2020-06-17T02:03:16Z", "author": {"login": "bf8086"}, "path": "shell/src/main/java/alluxio/cli/validation/hdfs/SecureHdfsValidationTask.java", "diffHunk": "@@ -79,36 +86,72 @@ public SecureHdfsValidationTask(String process, String path, AlluxioConfiguratio\n \n   @Override\n   public String getName() {\n-    return String.format(\"ValidateKerberosForSecureHdfs%s\", mProcess.toUpperCase());\n+    // Convert the first char to upper case\n+    char first = Character.toUpperCase(mProcess.charAt(0));\n+    return String.format(\"ValidateKerberosForSecureHdfs%s\", first + mProcess.substring(1));\n   }\n \n   @Override\n   public ValidationUtils.TaskResult validate(Map<String, String> optionsMap) {\n-    if (shouldSkip()) {\n+    if (!HdfsConfValidationTask.isHdfsScheme(mPath)) {\n+      mMsg.append(\"Skip this check as the UFS is not HDFS.\\n\");\n       return new ValidationUtils.TaskResult(ValidationUtils.State.SKIPPED, getName(),\n               mMsg.toString(), mAdvice.toString());\n     }\n+\n+    ValidationUtils.TaskResult loadConfig = loadHdfsConfig();\n+    if (loadConfig.getState() != ValidationUtils.State.OK) {\n+      return loadConfig;\n+    }\n+\n+    // The state is OK when the HDFS is secured\n+    ValidationUtils.TaskResult hdfsSecured = validateSecureHdfs();\n+    if (hdfsSecured.getState() != ValidationUtils.State.OK) {\n+      return hdfsSecured;\n+    }\n+\n     return validatePrincipalLogin();\n   }\n \n-  protected boolean shouldSkip() {\n-    if (!HdfsConfValidationTask.isHdfsScheme(mPath)) {\n-      mMsg.append(\"Skip this check as the UFS is not HDFS.\\n\");\n-      return true;\n-    }\n-    String principal = null;\n-    if (mConf.isSet(mPrincipalProperty)) {\n-      principal = mConf.get(mPrincipalProperty);\n+  private ValidationUtils.TaskResult validateSecureHdfs() {\n+    // Skipped if HDFS is not Kerberized\n+    // Ref: https://docs.cloudera.com/documentation/enterprise/5-16-x/topics\n+    // /cdh_sg_hadoop_security_enable.html\n+    String hadoopAuthentication = mCoreConf.getOrDefault(HDFS_AUTHENTICATION_KEY, \"\");\n+    boolean authenticationEnabled =\n+            hadoopAuthentication.equalsIgnoreCase(HDFS_AUTHENTICATION_VALUE);\n+    String hadoopAuthorization = mCoreConf.getOrDefault(HDFS_AUTHORIZATION_KEY, \"\");\n+    boolean authorizationEnabled = hadoopAuthorization.equals(HDFS_AUTHORIZATION_VALUE);\n+    if (!authenticationEnabled && !authorizationEnabled) {\n+      mMsg.append(\"HDFS is not Kerberized. Skip this test.\");\n+      return new ValidationUtils.TaskResult(ValidationUtils.State.SKIPPED, getName(),\n+              mMsg.toString(), mAdvice.toString());\n     }\n-    if (principal == null || principal.isEmpty()) {\n-      mMsg.append(String.format(\"Skip validation for secure HDFS. %s is not specified.%n\",\n-          PRINCIPAL_MAP.get(mProcess).getName()));\n-      return true;\n+\n+    // Issue an error if the secured HDFS is not configured properly\n+    if (!authenticationEnabled || !authorizationEnabled) {\n+      mMsg.append(String.format(\"Found inconsistent configuration for Hadoop security.\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ce6dbc2f0e5407883f2d78ad74dc15607f13c96"}, "originalPosition": 110}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTI1Mjg3OQ==", "bodyText": "OK. Removed the authorization check as only authentication matters in this check", "url": "https://github.com/Alluxio/alluxio/pull/11568#discussion_r441252879", "createdAt": "2020-06-17T02:59:47Z", "author": {"login": "jiacheliu3"}, "path": "shell/src/main/java/alluxio/cli/validation/hdfs/SecureHdfsValidationTask.java", "diffHunk": "@@ -79,36 +86,72 @@ public SecureHdfsValidationTask(String process, String path, AlluxioConfiguratio\n \n   @Override\n   public String getName() {\n-    return String.format(\"ValidateKerberosForSecureHdfs%s\", mProcess.toUpperCase());\n+    // Convert the first char to upper case\n+    char first = Character.toUpperCase(mProcess.charAt(0));\n+    return String.format(\"ValidateKerberosForSecureHdfs%s\", first + mProcess.substring(1));\n   }\n \n   @Override\n   public ValidationUtils.TaskResult validate(Map<String, String> optionsMap) {\n-    if (shouldSkip()) {\n+    if (!HdfsConfValidationTask.isHdfsScheme(mPath)) {\n+      mMsg.append(\"Skip this check as the UFS is not HDFS.\\n\");\n       return new ValidationUtils.TaskResult(ValidationUtils.State.SKIPPED, getName(),\n               mMsg.toString(), mAdvice.toString());\n     }\n+\n+    ValidationUtils.TaskResult loadConfig = loadHdfsConfig();\n+    if (loadConfig.getState() != ValidationUtils.State.OK) {\n+      return loadConfig;\n+    }\n+\n+    // The state is OK when the HDFS is secured\n+    ValidationUtils.TaskResult hdfsSecured = validateSecureHdfs();\n+    if (hdfsSecured.getState() != ValidationUtils.State.OK) {\n+      return hdfsSecured;\n+    }\n+\n     return validatePrincipalLogin();\n   }\n \n-  protected boolean shouldSkip() {\n-    if (!HdfsConfValidationTask.isHdfsScheme(mPath)) {\n-      mMsg.append(\"Skip this check as the UFS is not HDFS.\\n\");\n-      return true;\n-    }\n-    String principal = null;\n-    if (mConf.isSet(mPrincipalProperty)) {\n-      principal = mConf.get(mPrincipalProperty);\n+  private ValidationUtils.TaskResult validateSecureHdfs() {\n+    // Skipped if HDFS is not Kerberized\n+    // Ref: https://docs.cloudera.com/documentation/enterprise/5-16-x/topics\n+    // /cdh_sg_hadoop_security_enable.html\n+    String hadoopAuthentication = mCoreConf.getOrDefault(HDFS_AUTHENTICATION_KEY, \"\");\n+    boolean authenticationEnabled =\n+            hadoopAuthentication.equalsIgnoreCase(HDFS_AUTHENTICATION_VALUE);\n+    String hadoopAuthorization = mCoreConf.getOrDefault(HDFS_AUTHORIZATION_KEY, \"\");\n+    boolean authorizationEnabled = hadoopAuthorization.equals(HDFS_AUTHORIZATION_VALUE);\n+    if (!authenticationEnabled && !authorizationEnabled) {\n+      mMsg.append(\"HDFS is not Kerberized. Skip this test.\");\n+      return new ValidationUtils.TaskResult(ValidationUtils.State.SKIPPED, getName(),\n+              mMsg.toString(), mAdvice.toString());\n     }\n-    if (principal == null || principal.isEmpty()) {\n-      mMsg.append(String.format(\"Skip validation for secure HDFS. %s is not specified.%n\",\n-          PRINCIPAL_MAP.get(mProcess).getName()));\n-      return true;\n+\n+    // Issue an error if the secured HDFS is not configured properly\n+    if (!authenticationEnabled || !authorizationEnabled) {\n+      mMsg.append(String.format(\"Found inconsistent configuration for Hadoop security.\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTIzODI5Nw=="}, "originalCommit": {"oid": "3ce6dbc2f0e5407883f2d78ad74dc15607f13c96"}, "originalPosition": 110}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc0OTAyNzA0OnYy", "diffSide": "RIGHT", "path": "shell/src/main/java/alluxio/cli/validation/hdfs/SecureHdfsValidationTask.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QwMjowNDo0NFrOGkzEjA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QwMjowNDo0NFrOGkzEjA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTIzODY2OA==", "bodyText": "Would be nice to be more specific on which property is missing.", "url": "https://github.com/Alluxio/alluxio/pull/11568#discussion_r441238668", "createdAt": "2020-06-17T02:04:44Z", "author": {"login": "bf8086"}, "path": "shell/src/main/java/alluxio/cli/validation/hdfs/SecureHdfsValidationTask.java", "diffHunk": "@@ -79,36 +86,72 @@ public SecureHdfsValidationTask(String process, String path, AlluxioConfiguratio\n \n   @Override\n   public String getName() {\n-    return String.format(\"ValidateKerberosForSecureHdfs%s\", mProcess.toUpperCase());\n+    // Convert the first char to upper case\n+    char first = Character.toUpperCase(mProcess.charAt(0));\n+    return String.format(\"ValidateKerberosForSecureHdfs%s\", first + mProcess.substring(1));\n   }\n \n   @Override\n   public ValidationUtils.TaskResult validate(Map<String, String> optionsMap) {\n-    if (shouldSkip()) {\n+    if (!HdfsConfValidationTask.isHdfsScheme(mPath)) {\n+      mMsg.append(\"Skip this check as the UFS is not HDFS.\\n\");\n       return new ValidationUtils.TaskResult(ValidationUtils.State.SKIPPED, getName(),\n               mMsg.toString(), mAdvice.toString());\n     }\n+\n+    ValidationUtils.TaskResult loadConfig = loadHdfsConfig();\n+    if (loadConfig.getState() != ValidationUtils.State.OK) {\n+      return loadConfig;\n+    }\n+\n+    // The state is OK when the HDFS is secured\n+    ValidationUtils.TaskResult hdfsSecured = validateSecureHdfs();\n+    if (hdfsSecured.getState() != ValidationUtils.State.OK) {\n+      return hdfsSecured;\n+    }\n+\n     return validatePrincipalLogin();\n   }\n \n-  protected boolean shouldSkip() {\n-    if (!HdfsConfValidationTask.isHdfsScheme(mPath)) {\n-      mMsg.append(\"Skip this check as the UFS is not HDFS.\\n\");\n-      return true;\n-    }\n-    String principal = null;\n-    if (mConf.isSet(mPrincipalProperty)) {\n-      principal = mConf.get(mPrincipalProperty);\n+  private ValidationUtils.TaskResult validateSecureHdfs() {\n+    // Skipped if HDFS is not Kerberized\n+    // Ref: https://docs.cloudera.com/documentation/enterprise/5-16-x/topics\n+    // /cdh_sg_hadoop_security_enable.html\n+    String hadoopAuthentication = mCoreConf.getOrDefault(HDFS_AUTHENTICATION_KEY, \"\");\n+    boolean authenticationEnabled =\n+            hadoopAuthentication.equalsIgnoreCase(HDFS_AUTHENTICATION_VALUE);\n+    String hadoopAuthorization = mCoreConf.getOrDefault(HDFS_AUTHORIZATION_KEY, \"\");\n+    boolean authorizationEnabled = hadoopAuthorization.equals(HDFS_AUTHORIZATION_VALUE);\n+    if (!authenticationEnabled && !authorizationEnabled) {\n+      mMsg.append(\"HDFS is not Kerberized. Skip this test.\");\n+      return new ValidationUtils.TaskResult(ValidationUtils.State.SKIPPED, getName(),\n+              mMsg.toString(), mAdvice.toString());\n     }\n-    if (principal == null || principal.isEmpty()) {\n-      mMsg.append(String.format(\"Skip validation for secure HDFS. %s is not specified.%n\",\n-          PRINCIPAL_MAP.get(mProcess).getName()));\n-      return true;\n+\n+    // Issue an error if the secured HDFS is not configured properly\n+    if (!authenticationEnabled || !authorizationEnabled) {\n+      mMsg.append(String.format(\"Found inconsistent configuration for Hadoop security.\"\n+                      + \" %s=%s but %s=%s.%n\", HDFS_AUTHENTICATION_KEY, hadoopAuthentication,\n+              HDFS_AUTHORIZATION_KEY, hadoopAuthorization));\n+      mAdvice.append(String.format(\"Please enable Hadoop security by setting %s=%s and %s=%s%n.\",\n+              HDFS_AUTHENTICATION_KEY, HDFS_AUTHENTICATION_VALUE, HDFS_AUTHORIZATION_KEY,\n+              HDFS_AUTHORIZATION_VALUE));\n+      return new ValidationUtils.TaskResult(ValidationUtils.State.FAILED, getName(),\n+              mMsg.toString(), mAdvice.toString());\n     }\n-    return false;\n+    return new ValidationUtils.TaskResult(ValidationUtils.State.OK, getName(),\n+            mMsg.toString(), mAdvice.toString());\n   }\n \n   private ValidationUtils.TaskResult validatePrincipalLogin() {\n+    if (!mConf.isSet(mPrincipalProperty) || !mConf.isSet(mKeytabProperty)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ce6dbc2f0e5407883f2d78ad74dc15607f13c96"}, "originalPosition": 125}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1638, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}