{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg4NTQyNDcw", "number": 11169, "reviewThreads": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQwNTowOToxOFrODoMHPA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQwNToxMzoyN1rODoMJZg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzNDY4MDkyOnYy", "diffSide": "RIGHT", "path": "docs/check.go", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQwNTowOToxOFrOF2lsvw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQxODoyNjo1OFrOF3A1jw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjc4NTA4Nw==", "bodyText": "I think we should make a struct and parse YAML instead of using this string manipulation", "url": "https://github.com/Alluxio/alluxio/pull/11169#discussion_r392785087", "createdAt": "2020-03-16T05:09:18Z", "author": {"login": "ZacBlanco"}, "path": "docs/check.go", "diffHunk": "@@ -0,0 +1,294 @@\n+package main\n+\n+import (\n+\t\"bufio\"\n+\t\"fmt\"\n+\t\"log\"\n+\t\"os\"\n+\t\"path/filepath\"\n+\t\"strings\"\n+\t\"regexp\"\n+)\n+\n+func main() {\n+\tif err := run(); err != nil {\n+\t\tlog.Fatalln(err)\n+\t}\n+\tlog.Println(\"Documentation check succeeded\")\n+}\n+\n+type checkContext struct {\n+\t// inputs\n+\tcategoryNames StringSet // category or group names defined in _config.yml\n+\tdocsPath      string    // path to docs directory in repository\n+\n+\t// intermediate\n+\tknownFiles    StringSet                  // file paths of files that can be referenced by markdown files\n+\tmarkdownLinks map[string][]*relativeLink // list of relative links found in each markdown file\n+\n+\t// outputs\n+\tmarkdownErrors map[string][]string // list of errors found in each markdown file\n+}\n+\n+type relativeLink struct {\n+\tline int\n+\tpath string\n+}\n+\n+func (ctx *checkContext) addError(mdFile string, lineNum int, format string, args ...interface{}) {\n+\tmsg := fmt.Sprintf(\"%d: \", lineNum) + fmt.Sprintf(format, args...)\n+\tctx.markdownErrors[mdFile] = append(ctx.markdownErrors[mdFile], msg)\n+}\n+\n+func run() error {\n+\t// check that script is being run from repo root\n+\tconst docsDir, configYml = \"docs\", \"_config.yml\"\n+\trepoRoot, err := os.Getwd()\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"could not get current working directory: %v\", err)\n+\t}\n+\tdocsPath, err := filepath.Abs(filepath.Join(repoRoot, docsDir))\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"could not get absolute path of %v: %v\", filepath.Join(repoRoot, docsDir), err)\n+\t}\n+\tconfigPath := filepath.Join(docsPath, configYml)\n+\tif _, err := os.Stat(configPath); os.IsNotExist(err) {\n+\t\treturn fmt.Errorf(\"expected to find %s in %s; script should be executed from repository root\", configYml, docsDir)\n+\t}\n+\n+\t// parse category names from config file\n+\tcategoryNames, err := parseCategoryNames(configPath)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"error parsing category names: %v\", err)\n+\t}\n+\n+\tctx := &checkContext{\n+\t\tcategoryNames:  categoryNames,\n+\t\tdocsPath:       docsPath,\n+\t\tknownFiles:     StringSet{},\n+\t\tmarkdownLinks:  map[string][]*relativeLink{},\n+\t\tmarkdownErrors: map[string][]string{},\n+\t}\n+\n+\t// scan through markdown files\n+\tfor _, langDir := range []string{\"en\", \"cn\"} {\n+\t\tif err := filepath.Walk(filepath.Join(docsPath, langDir),\n+\t\t\tfunc(p string, info os.FileInfo, err error) error {\n+\t\t\t\tif err != nil {\n+\t\t\t\t\treturn err\n+\t\t\t\t}\n+\t\t\t\tif info.IsDir() {\n+\t\t\t\t\treturn nil\n+\t\t\t\t}\n+\t\t\t\tif strings.HasSuffix(info.Name(), \".md\") {\n+\t\t\t\t\tif err := checkFile(p, ctx); err != nil {\n+\t\t\t\t\t\treturn err\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t\treturn nil\n+\t\t\t},\n+\t\t); err != nil {\n+\t\t\treturn fmt.Errorf(\"error traversing through md files in %v: %v\", filepath.Join(docsPath, langDir), err)\n+\t\t}\n+\t}\n+\t// scan through img and resources directories to update known files\n+\tfor _, dir := range []string{\"img\", \"resources\"} {\n+\t\tif err := filepath.Walk(filepath.Join(docsPath, dir),\n+\t\t\tfunc(p string, info os.FileInfo, err error) error {\n+\t\t\t\tif err != nil {\n+\t\t\t\t\treturn err\n+\t\t\t\t}\n+\t\t\t\tif info.IsDir() {\n+\t\t\t\t\treturn nil\n+\t\t\t\t}\n+\t\t\t\tctx.knownFiles.Add(strings.TrimPrefix(p, docsPath))\n+\t\t\t\treturn nil\n+\t\t\t},\n+\t\t); err != nil {\n+\t\t\treturn fmt.Errorf(\"error traversing through files in %v: %v\", filepath.Join(docsPath, dir), err)\n+\t\t}\n+\t}\n+\n+\tctx.checkLinks()\n+\n+\tif len(ctx.markdownErrors) > 0 {\n+\t\terrLines := []string{\"Errors found in documentation markdown\"}\n+\t\tfor f, errs := range ctx.markdownErrors {\n+\t\t\terrLines = append(errLines, fmt.Sprintf(\"  %v:\", strings.TrimPrefix(f, repoRoot)))\n+\t\t\tfor _, err := range errs {\n+\t\t\t\terrLines = append(errLines, fmt.Sprintf(\"    %s\", err))\n+\t\t\t}\n+\t\t}\n+\t\treturn fmt.Errorf(\"%v\", strings.Join(errLines, \"\\n\"))\n+\t}\n+\n+\treturn nil\n+}\n+\n+// parseCategoryNames parses the given config file for the list of category names\n+func parseCategoryNames(configPath string) (StringSet, error) {\n+\tf, err := os.Open(configPath)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"error opening file at %v: %v\", configPath, err)\n+\t}\n+\tdefer f.Close()\n+\n+\tconst categoryListLine, categoryPrefix = \"categoryList:\", \"  - \"\n+\tcategoryNames := StringSet{}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a1d6b087ef956c7a638fbe407a3a4f783a99bb83"}, "originalPosition": 137}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjc5MTA0Mw==", "bodyText": "parsing yaml -> vendoring code -> need to set GOPATH to execute\nthe generate tarball code needs to do the lattermost because it consists of several files, but i've been of the opinion of keeping go code in this repo as scripts. i want to avoid vendoring code unless we're completely on board with integrating all of the go code here into its own module as opposed to one-off scripts", "url": "https://github.com/Alluxio/alluxio/pull/11169#discussion_r392791043", "createdAt": "2020-03-16T05:38:09Z", "author": {"login": "Xenorith"}, "path": "docs/check.go", "diffHunk": "@@ -0,0 +1,294 @@\n+package main\n+\n+import (\n+\t\"bufio\"\n+\t\"fmt\"\n+\t\"log\"\n+\t\"os\"\n+\t\"path/filepath\"\n+\t\"strings\"\n+\t\"regexp\"\n+)\n+\n+func main() {\n+\tif err := run(); err != nil {\n+\t\tlog.Fatalln(err)\n+\t}\n+\tlog.Println(\"Documentation check succeeded\")\n+}\n+\n+type checkContext struct {\n+\t// inputs\n+\tcategoryNames StringSet // category or group names defined in _config.yml\n+\tdocsPath      string    // path to docs directory in repository\n+\n+\t// intermediate\n+\tknownFiles    StringSet                  // file paths of files that can be referenced by markdown files\n+\tmarkdownLinks map[string][]*relativeLink // list of relative links found in each markdown file\n+\n+\t// outputs\n+\tmarkdownErrors map[string][]string // list of errors found in each markdown file\n+}\n+\n+type relativeLink struct {\n+\tline int\n+\tpath string\n+}\n+\n+func (ctx *checkContext) addError(mdFile string, lineNum int, format string, args ...interface{}) {\n+\tmsg := fmt.Sprintf(\"%d: \", lineNum) + fmt.Sprintf(format, args...)\n+\tctx.markdownErrors[mdFile] = append(ctx.markdownErrors[mdFile], msg)\n+}\n+\n+func run() error {\n+\t// check that script is being run from repo root\n+\tconst docsDir, configYml = \"docs\", \"_config.yml\"\n+\trepoRoot, err := os.Getwd()\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"could not get current working directory: %v\", err)\n+\t}\n+\tdocsPath, err := filepath.Abs(filepath.Join(repoRoot, docsDir))\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"could not get absolute path of %v: %v\", filepath.Join(repoRoot, docsDir), err)\n+\t}\n+\tconfigPath := filepath.Join(docsPath, configYml)\n+\tif _, err := os.Stat(configPath); os.IsNotExist(err) {\n+\t\treturn fmt.Errorf(\"expected to find %s in %s; script should be executed from repository root\", configYml, docsDir)\n+\t}\n+\n+\t// parse category names from config file\n+\tcategoryNames, err := parseCategoryNames(configPath)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"error parsing category names: %v\", err)\n+\t}\n+\n+\tctx := &checkContext{\n+\t\tcategoryNames:  categoryNames,\n+\t\tdocsPath:       docsPath,\n+\t\tknownFiles:     StringSet{},\n+\t\tmarkdownLinks:  map[string][]*relativeLink{},\n+\t\tmarkdownErrors: map[string][]string{},\n+\t}\n+\n+\t// scan through markdown files\n+\tfor _, langDir := range []string{\"en\", \"cn\"} {\n+\t\tif err := filepath.Walk(filepath.Join(docsPath, langDir),\n+\t\t\tfunc(p string, info os.FileInfo, err error) error {\n+\t\t\t\tif err != nil {\n+\t\t\t\t\treturn err\n+\t\t\t\t}\n+\t\t\t\tif info.IsDir() {\n+\t\t\t\t\treturn nil\n+\t\t\t\t}\n+\t\t\t\tif strings.HasSuffix(info.Name(), \".md\") {\n+\t\t\t\t\tif err := checkFile(p, ctx); err != nil {\n+\t\t\t\t\t\treturn err\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t\treturn nil\n+\t\t\t},\n+\t\t); err != nil {\n+\t\t\treturn fmt.Errorf(\"error traversing through md files in %v: %v\", filepath.Join(docsPath, langDir), err)\n+\t\t}\n+\t}\n+\t// scan through img and resources directories to update known files\n+\tfor _, dir := range []string{\"img\", \"resources\"} {\n+\t\tif err := filepath.Walk(filepath.Join(docsPath, dir),\n+\t\t\tfunc(p string, info os.FileInfo, err error) error {\n+\t\t\t\tif err != nil {\n+\t\t\t\t\treturn err\n+\t\t\t\t}\n+\t\t\t\tif info.IsDir() {\n+\t\t\t\t\treturn nil\n+\t\t\t\t}\n+\t\t\t\tctx.knownFiles.Add(strings.TrimPrefix(p, docsPath))\n+\t\t\t\treturn nil\n+\t\t\t},\n+\t\t); err != nil {\n+\t\t\treturn fmt.Errorf(\"error traversing through files in %v: %v\", filepath.Join(docsPath, dir), err)\n+\t\t}\n+\t}\n+\n+\tctx.checkLinks()\n+\n+\tif len(ctx.markdownErrors) > 0 {\n+\t\terrLines := []string{\"Errors found in documentation markdown\"}\n+\t\tfor f, errs := range ctx.markdownErrors {\n+\t\t\terrLines = append(errLines, fmt.Sprintf(\"  %v:\", strings.TrimPrefix(f, repoRoot)))\n+\t\t\tfor _, err := range errs {\n+\t\t\t\terrLines = append(errLines, fmt.Sprintf(\"    %s\", err))\n+\t\t\t}\n+\t\t}\n+\t\treturn fmt.Errorf(\"%v\", strings.Join(errLines, \"\\n\"))\n+\t}\n+\n+\treturn nil\n+}\n+\n+// parseCategoryNames parses the given config file for the list of category names\n+func parseCategoryNames(configPath string) (StringSet, error) {\n+\tf, err := os.Open(configPath)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"error opening file at %v: %v\", configPath, err)\n+\t}\n+\tdefer f.Close()\n+\n+\tconst categoryListLine, categoryPrefix = \"categoryList:\", \"  - \"\n+\tcategoryNames := StringSet{}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjc4NTA4Nw=="}, "originalCommit": {"oid": "a1d6b087ef956c7a638fbe407a3a4f783a99bb83"}, "originalPosition": 137}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkwNDUyMQ==", "bodyText": "I would prefer to remove the go code if possible. Since the docs use jekyll, it would probably be easier (assuming you know ruby) to write a verification program that can run as a plugin.", "url": "https://github.com/Alluxio/alluxio/pull/11169#discussion_r392904521", "createdAt": "2020-03-16T10:08:17Z", "author": {"login": "ZacBlanco"}, "path": "docs/check.go", "diffHunk": "@@ -0,0 +1,294 @@\n+package main\n+\n+import (\n+\t\"bufio\"\n+\t\"fmt\"\n+\t\"log\"\n+\t\"os\"\n+\t\"path/filepath\"\n+\t\"strings\"\n+\t\"regexp\"\n+)\n+\n+func main() {\n+\tif err := run(); err != nil {\n+\t\tlog.Fatalln(err)\n+\t}\n+\tlog.Println(\"Documentation check succeeded\")\n+}\n+\n+type checkContext struct {\n+\t// inputs\n+\tcategoryNames StringSet // category or group names defined in _config.yml\n+\tdocsPath      string    // path to docs directory in repository\n+\n+\t// intermediate\n+\tknownFiles    StringSet                  // file paths of files that can be referenced by markdown files\n+\tmarkdownLinks map[string][]*relativeLink // list of relative links found in each markdown file\n+\n+\t// outputs\n+\tmarkdownErrors map[string][]string // list of errors found in each markdown file\n+}\n+\n+type relativeLink struct {\n+\tline int\n+\tpath string\n+}\n+\n+func (ctx *checkContext) addError(mdFile string, lineNum int, format string, args ...interface{}) {\n+\tmsg := fmt.Sprintf(\"%d: \", lineNum) + fmt.Sprintf(format, args...)\n+\tctx.markdownErrors[mdFile] = append(ctx.markdownErrors[mdFile], msg)\n+}\n+\n+func run() error {\n+\t// check that script is being run from repo root\n+\tconst docsDir, configYml = \"docs\", \"_config.yml\"\n+\trepoRoot, err := os.Getwd()\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"could not get current working directory: %v\", err)\n+\t}\n+\tdocsPath, err := filepath.Abs(filepath.Join(repoRoot, docsDir))\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"could not get absolute path of %v: %v\", filepath.Join(repoRoot, docsDir), err)\n+\t}\n+\tconfigPath := filepath.Join(docsPath, configYml)\n+\tif _, err := os.Stat(configPath); os.IsNotExist(err) {\n+\t\treturn fmt.Errorf(\"expected to find %s in %s; script should be executed from repository root\", configYml, docsDir)\n+\t}\n+\n+\t// parse category names from config file\n+\tcategoryNames, err := parseCategoryNames(configPath)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"error parsing category names: %v\", err)\n+\t}\n+\n+\tctx := &checkContext{\n+\t\tcategoryNames:  categoryNames,\n+\t\tdocsPath:       docsPath,\n+\t\tknownFiles:     StringSet{},\n+\t\tmarkdownLinks:  map[string][]*relativeLink{},\n+\t\tmarkdownErrors: map[string][]string{},\n+\t}\n+\n+\t// scan through markdown files\n+\tfor _, langDir := range []string{\"en\", \"cn\"} {\n+\t\tif err := filepath.Walk(filepath.Join(docsPath, langDir),\n+\t\t\tfunc(p string, info os.FileInfo, err error) error {\n+\t\t\t\tif err != nil {\n+\t\t\t\t\treturn err\n+\t\t\t\t}\n+\t\t\t\tif info.IsDir() {\n+\t\t\t\t\treturn nil\n+\t\t\t\t}\n+\t\t\t\tif strings.HasSuffix(info.Name(), \".md\") {\n+\t\t\t\t\tif err := checkFile(p, ctx); err != nil {\n+\t\t\t\t\t\treturn err\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t\treturn nil\n+\t\t\t},\n+\t\t); err != nil {\n+\t\t\treturn fmt.Errorf(\"error traversing through md files in %v: %v\", filepath.Join(docsPath, langDir), err)\n+\t\t}\n+\t}\n+\t// scan through img and resources directories to update known files\n+\tfor _, dir := range []string{\"img\", \"resources\"} {\n+\t\tif err := filepath.Walk(filepath.Join(docsPath, dir),\n+\t\t\tfunc(p string, info os.FileInfo, err error) error {\n+\t\t\t\tif err != nil {\n+\t\t\t\t\treturn err\n+\t\t\t\t}\n+\t\t\t\tif info.IsDir() {\n+\t\t\t\t\treturn nil\n+\t\t\t\t}\n+\t\t\t\tctx.knownFiles.Add(strings.TrimPrefix(p, docsPath))\n+\t\t\t\treturn nil\n+\t\t\t},\n+\t\t); err != nil {\n+\t\t\treturn fmt.Errorf(\"error traversing through files in %v: %v\", filepath.Join(docsPath, dir), err)\n+\t\t}\n+\t}\n+\n+\tctx.checkLinks()\n+\n+\tif len(ctx.markdownErrors) > 0 {\n+\t\terrLines := []string{\"Errors found in documentation markdown\"}\n+\t\tfor f, errs := range ctx.markdownErrors {\n+\t\t\terrLines = append(errLines, fmt.Sprintf(\"  %v:\", strings.TrimPrefix(f, repoRoot)))\n+\t\t\tfor _, err := range errs {\n+\t\t\t\terrLines = append(errLines, fmt.Sprintf(\"    %s\", err))\n+\t\t\t}\n+\t\t}\n+\t\treturn fmt.Errorf(\"%v\", strings.Join(errLines, \"\\n\"))\n+\t}\n+\n+\treturn nil\n+}\n+\n+// parseCategoryNames parses the given config file for the list of category names\n+func parseCategoryNames(configPath string) (StringSet, error) {\n+\tf, err := os.Open(configPath)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"error opening file at %v: %v\", configPath, err)\n+\t}\n+\tdefer f.Close()\n+\n+\tconst categoryListLine, categoryPrefix = \"categoryList:\", \"  - \"\n+\tcategoryNames := StringSet{}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjc4NTA4Nw=="}, "originalCommit": {"oid": "a1d6b087ef956c7a638fbe407a3a4f783a99bb83"}, "originalPosition": 137}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzIyOTcxMQ==", "bodyText": "never written ruby...", "url": "https://github.com/Alluxio/alluxio/pull/11169#discussion_r393229711", "createdAt": "2020-03-16T18:26:58Z", "author": {"login": "Xenorith"}, "path": "docs/check.go", "diffHunk": "@@ -0,0 +1,294 @@\n+package main\n+\n+import (\n+\t\"bufio\"\n+\t\"fmt\"\n+\t\"log\"\n+\t\"os\"\n+\t\"path/filepath\"\n+\t\"strings\"\n+\t\"regexp\"\n+)\n+\n+func main() {\n+\tif err := run(); err != nil {\n+\t\tlog.Fatalln(err)\n+\t}\n+\tlog.Println(\"Documentation check succeeded\")\n+}\n+\n+type checkContext struct {\n+\t// inputs\n+\tcategoryNames StringSet // category or group names defined in _config.yml\n+\tdocsPath      string    // path to docs directory in repository\n+\n+\t// intermediate\n+\tknownFiles    StringSet                  // file paths of files that can be referenced by markdown files\n+\tmarkdownLinks map[string][]*relativeLink // list of relative links found in each markdown file\n+\n+\t// outputs\n+\tmarkdownErrors map[string][]string // list of errors found in each markdown file\n+}\n+\n+type relativeLink struct {\n+\tline int\n+\tpath string\n+}\n+\n+func (ctx *checkContext) addError(mdFile string, lineNum int, format string, args ...interface{}) {\n+\tmsg := fmt.Sprintf(\"%d: \", lineNum) + fmt.Sprintf(format, args...)\n+\tctx.markdownErrors[mdFile] = append(ctx.markdownErrors[mdFile], msg)\n+}\n+\n+func run() error {\n+\t// check that script is being run from repo root\n+\tconst docsDir, configYml = \"docs\", \"_config.yml\"\n+\trepoRoot, err := os.Getwd()\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"could not get current working directory: %v\", err)\n+\t}\n+\tdocsPath, err := filepath.Abs(filepath.Join(repoRoot, docsDir))\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"could not get absolute path of %v: %v\", filepath.Join(repoRoot, docsDir), err)\n+\t}\n+\tconfigPath := filepath.Join(docsPath, configYml)\n+\tif _, err := os.Stat(configPath); os.IsNotExist(err) {\n+\t\treturn fmt.Errorf(\"expected to find %s in %s; script should be executed from repository root\", configYml, docsDir)\n+\t}\n+\n+\t// parse category names from config file\n+\tcategoryNames, err := parseCategoryNames(configPath)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"error parsing category names: %v\", err)\n+\t}\n+\n+\tctx := &checkContext{\n+\t\tcategoryNames:  categoryNames,\n+\t\tdocsPath:       docsPath,\n+\t\tknownFiles:     StringSet{},\n+\t\tmarkdownLinks:  map[string][]*relativeLink{},\n+\t\tmarkdownErrors: map[string][]string{},\n+\t}\n+\n+\t// scan through markdown files\n+\tfor _, langDir := range []string{\"en\", \"cn\"} {\n+\t\tif err := filepath.Walk(filepath.Join(docsPath, langDir),\n+\t\t\tfunc(p string, info os.FileInfo, err error) error {\n+\t\t\t\tif err != nil {\n+\t\t\t\t\treturn err\n+\t\t\t\t}\n+\t\t\t\tif info.IsDir() {\n+\t\t\t\t\treturn nil\n+\t\t\t\t}\n+\t\t\t\tif strings.HasSuffix(info.Name(), \".md\") {\n+\t\t\t\t\tif err := checkFile(p, ctx); err != nil {\n+\t\t\t\t\t\treturn err\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t\treturn nil\n+\t\t\t},\n+\t\t); err != nil {\n+\t\t\treturn fmt.Errorf(\"error traversing through md files in %v: %v\", filepath.Join(docsPath, langDir), err)\n+\t\t}\n+\t}\n+\t// scan through img and resources directories to update known files\n+\tfor _, dir := range []string{\"img\", \"resources\"} {\n+\t\tif err := filepath.Walk(filepath.Join(docsPath, dir),\n+\t\t\tfunc(p string, info os.FileInfo, err error) error {\n+\t\t\t\tif err != nil {\n+\t\t\t\t\treturn err\n+\t\t\t\t}\n+\t\t\t\tif info.IsDir() {\n+\t\t\t\t\treturn nil\n+\t\t\t\t}\n+\t\t\t\tctx.knownFiles.Add(strings.TrimPrefix(p, docsPath))\n+\t\t\t\treturn nil\n+\t\t\t},\n+\t\t); err != nil {\n+\t\t\treturn fmt.Errorf(\"error traversing through files in %v: %v\", filepath.Join(docsPath, dir), err)\n+\t\t}\n+\t}\n+\n+\tctx.checkLinks()\n+\n+\tif len(ctx.markdownErrors) > 0 {\n+\t\terrLines := []string{\"Errors found in documentation markdown\"}\n+\t\tfor f, errs := range ctx.markdownErrors {\n+\t\t\terrLines = append(errLines, fmt.Sprintf(\"  %v:\", strings.TrimPrefix(f, repoRoot)))\n+\t\t\tfor _, err := range errs {\n+\t\t\t\terrLines = append(errLines, fmt.Sprintf(\"    %s\", err))\n+\t\t\t}\n+\t\t}\n+\t\treturn fmt.Errorf(\"%v\", strings.Join(errLines, \"\\n\"))\n+\t}\n+\n+\treturn nil\n+}\n+\n+// parseCategoryNames parses the given config file for the list of category names\n+func parseCategoryNames(configPath string) (StringSet, error) {\n+\tf, err := os.Open(configPath)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"error opening file at %v: %v\", configPath, err)\n+\t}\n+\tdefer f.Close()\n+\n+\tconst categoryListLine, categoryPrefix = \"categoryList:\", \"  - \"\n+\tcategoryNames := StringSet{}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjc4NTA4Nw=="}, "originalCommit": {"oid": "a1d6b087ef956c7a638fbe407a3a4f783a99bb83"}, "originalPosition": 137}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzNDY4MTM1OnYy", "diffSide": "RIGHT", "path": "docs/cn/Overview.md", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQwNTowOTo0MFrOF2ls-g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xN1QwMjoyNzoxOFrOF3L3uw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjc4NTE0Ng==", "bodyText": "cn docs should link to cn pages?", "url": "https://github.com/Alluxio/alluxio/pull/11169#discussion_r392785146", "createdAt": "2020-03-16T05:09:40Z", "author": {"login": "ZacBlanco"}, "path": "docs/cn/Overview.md", "diffHunk": "@@ -58,7 +58,7 @@ Alluxio \u5c06\u4e09\u4e2a\u5173\u952e\u9886\u57df\u7684\u521b\u65b0\u7ed3\u5408\u5728\u4e00\u8d77\uff0c\u63d0\u4f9b\u4e86\u4e00\u5957\u72ec\u7279\u7684\n 1. **\u667a\u80fd\u591a\u5c42\u7ea7\u7f13\u5b58**\uff1aAlluxio \u96c6\u7fa4\u80fd\u591f\u5145\u5f53\u5e95\u5c42\u5b58\u50a8\u7cfb\u7edf\u4e2d\u6570\u636e\u7684\u8bfb\u5199\u7f13\u5b58\u3002\u53ef\u914d\u7f6e\u81ea\u52a8\u4f18\u5316\u6570\u636e\u653e\u7f6e\u7b56\u7565\uff0c\u4ee5\u5b9e\u73b0\u8de8\u5185\u5b58\u548c\u78c1\u76d8\uff08SSD/HDD\uff09\u7684\u6027\u80fd\u548c\u53ef\u9760\u6027\u3002\u7f13\u5b58\u5bf9\u7528\u6237\u662f\u900f\u660e\u7684\uff0c\u4f7f\u7528\u7f13\u51b2\u6765\u4fdd\u6301\u4e0e\u6301\u4e45\u5b58\u50a8\u7684\u4e00\u81f4\u6027\u3002\u6709\u5173\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605 [\u7f13\u5b58\u529f\u80fd\u6587\u6863]({{ '/cn/core-services/Caching.html' | relativize_url }})\u3002\n 1. **\u670d\u52a1\u5668\u7aef API \u7ffb\u8bd1\u8f6c\u6362**\uff1aAlluxio\u652f\u6301\u5de5\u4e1a\u754c\u573a\u666f\u7684API\u63a5\u53e3\uff0c\u4f8b\u5982HDFS API, S3 API, FUSE API, REST API\u3002\u5b83\u80fd\u591f\u900f\u660e\u5730\u4ece\u6807\u51c6\u5ba2\u6237\u7aef\u63a5\u53e3\u8f6c\u6362\u5230\u4efb\u4f55\u5b58\u50a8\u63a5\u53e3\u3002Alluxio \u8d1f\u8d23\u7ba1\u7406\u5e94\u7528\u7a0b\u5e8f\u548c\u6587\u4ef6\u6216\u5bf9\u8c61\u5b58\u50a8\u4e4b\u95f4\u7684\u901a\u4fe1\uff0c\u4ece\u800c\u6d88\u9664\u4e86\u5bf9\u590d\u6742\u7cfb\u7edf\u8fdb\u884c\u914d\u7f6e\u548c\u7ba1\u7406\u7684\u9700\u6c42\u3002\u6587\u4ef6\u6570\u636e\u53ef\u4ee5\u770b\u8d77\u6765\u50cf\u5bf9\u8c61\u6570\u636e\uff0c\u53cd\u4e4b\u4ea6\u7136\u3002\n \n-\u8981\u4e86\u89e3\u6709\u5173 Alluxio \u5185\u90e8\u7684\u66f4\u591a\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u9605\u8bfb [Alluxio \u67b6\u6784\u548c\u6570\u636e\u6d41]({{ '/cn/overview/Architecture.html' | relativize_url }})\u3002\n+\u8981\u4e86\u89e3\u6709\u5173 Alluxio \u5185\u90e8\u7684\u66f4\u591a\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u9605\u8bfb [Alluxio \u67b6\u6784\u548c\u6570\u636e\u6d41]({{ '/en/overview/Architecture.html' | relativize_url }})\u3002", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a1d6b087ef956c7a638fbe407a3a4f783a99bb83"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjc5MTMzMw==", "bodyText": "there is no cn page for this, thus being caught by the check", "url": "https://github.com/Alluxio/alluxio/pull/11169#discussion_r392791333", "createdAt": "2020-03-16T05:39:36Z", "author": {"login": "Xenorith"}, "path": "docs/cn/Overview.md", "diffHunk": "@@ -58,7 +58,7 @@ Alluxio \u5c06\u4e09\u4e2a\u5173\u952e\u9886\u57df\u7684\u521b\u65b0\u7ed3\u5408\u5728\u4e00\u8d77\uff0c\u63d0\u4f9b\u4e86\u4e00\u5957\u72ec\u7279\u7684\n 1. **\u667a\u80fd\u591a\u5c42\u7ea7\u7f13\u5b58**\uff1aAlluxio \u96c6\u7fa4\u80fd\u591f\u5145\u5f53\u5e95\u5c42\u5b58\u50a8\u7cfb\u7edf\u4e2d\u6570\u636e\u7684\u8bfb\u5199\u7f13\u5b58\u3002\u53ef\u914d\u7f6e\u81ea\u52a8\u4f18\u5316\u6570\u636e\u653e\u7f6e\u7b56\u7565\uff0c\u4ee5\u5b9e\u73b0\u8de8\u5185\u5b58\u548c\u78c1\u76d8\uff08SSD/HDD\uff09\u7684\u6027\u80fd\u548c\u53ef\u9760\u6027\u3002\u7f13\u5b58\u5bf9\u7528\u6237\u662f\u900f\u660e\u7684\uff0c\u4f7f\u7528\u7f13\u51b2\u6765\u4fdd\u6301\u4e0e\u6301\u4e45\u5b58\u50a8\u7684\u4e00\u81f4\u6027\u3002\u6709\u5173\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605 [\u7f13\u5b58\u529f\u80fd\u6587\u6863]({{ '/cn/core-services/Caching.html' | relativize_url }})\u3002\n 1. **\u670d\u52a1\u5668\u7aef API \u7ffb\u8bd1\u8f6c\u6362**\uff1aAlluxio\u652f\u6301\u5de5\u4e1a\u754c\u573a\u666f\u7684API\u63a5\u53e3\uff0c\u4f8b\u5982HDFS API, S3 API, FUSE API, REST API\u3002\u5b83\u80fd\u591f\u900f\u660e\u5730\u4ece\u6807\u51c6\u5ba2\u6237\u7aef\u63a5\u53e3\u8f6c\u6362\u5230\u4efb\u4f55\u5b58\u50a8\u63a5\u53e3\u3002Alluxio \u8d1f\u8d23\u7ba1\u7406\u5e94\u7528\u7a0b\u5e8f\u548c\u6587\u4ef6\u6216\u5bf9\u8c61\u5b58\u50a8\u4e4b\u95f4\u7684\u901a\u4fe1\uff0c\u4ece\u800c\u6d88\u9664\u4e86\u5bf9\u590d\u6742\u7cfb\u7edf\u8fdb\u884c\u914d\u7f6e\u548c\u7ba1\u7406\u7684\u9700\u6c42\u3002\u6587\u4ef6\u6570\u636e\u53ef\u4ee5\u770b\u8d77\u6765\u50cf\u5bf9\u8c61\u6570\u636e\uff0c\u53cd\u4e4b\u4ea6\u7136\u3002\n \n-\u8981\u4e86\u89e3\u6709\u5173 Alluxio \u5185\u90e8\u7684\u66f4\u591a\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u9605\u8bfb [Alluxio \u67b6\u6784\u548c\u6570\u636e\u6d41]({{ '/cn/overview/Architecture.html' | relativize_url }})\u3002\n+\u8981\u4e86\u89e3\u6709\u5173 Alluxio \u5185\u90e8\u7684\u66f4\u591a\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u9605\u8bfb [Alluxio \u67b6\u6784\u548c\u6570\u636e\u6d41]({{ '/en/overview/Architecture.html' | relativize_url }})\u3002", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjc4NTE0Ng=="}, "originalCommit": {"oid": "a1d6b087ef956c7a638fbe407a3a4f783a99bb83"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkwMTU2Mw==", "bodyText": "we shouldn't link to the en side here. I recommend finding another page to link to", "url": "https://github.com/Alluxio/alluxio/pull/11169#discussion_r392901563", "createdAt": "2020-03-16T10:02:40Z", "author": {"login": "ZacBlanco"}, "path": "docs/cn/Overview.md", "diffHunk": "@@ -58,7 +58,7 @@ Alluxio \u5c06\u4e09\u4e2a\u5173\u952e\u9886\u57df\u7684\u521b\u65b0\u7ed3\u5408\u5728\u4e00\u8d77\uff0c\u63d0\u4f9b\u4e86\u4e00\u5957\u72ec\u7279\u7684\n 1. **\u667a\u80fd\u591a\u5c42\u7ea7\u7f13\u5b58**\uff1aAlluxio \u96c6\u7fa4\u80fd\u591f\u5145\u5f53\u5e95\u5c42\u5b58\u50a8\u7cfb\u7edf\u4e2d\u6570\u636e\u7684\u8bfb\u5199\u7f13\u5b58\u3002\u53ef\u914d\u7f6e\u81ea\u52a8\u4f18\u5316\u6570\u636e\u653e\u7f6e\u7b56\u7565\uff0c\u4ee5\u5b9e\u73b0\u8de8\u5185\u5b58\u548c\u78c1\u76d8\uff08SSD/HDD\uff09\u7684\u6027\u80fd\u548c\u53ef\u9760\u6027\u3002\u7f13\u5b58\u5bf9\u7528\u6237\u662f\u900f\u660e\u7684\uff0c\u4f7f\u7528\u7f13\u51b2\u6765\u4fdd\u6301\u4e0e\u6301\u4e45\u5b58\u50a8\u7684\u4e00\u81f4\u6027\u3002\u6709\u5173\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605 [\u7f13\u5b58\u529f\u80fd\u6587\u6863]({{ '/cn/core-services/Caching.html' | relativize_url }})\u3002\n 1. **\u670d\u52a1\u5668\u7aef API \u7ffb\u8bd1\u8f6c\u6362**\uff1aAlluxio\u652f\u6301\u5de5\u4e1a\u754c\u573a\u666f\u7684API\u63a5\u53e3\uff0c\u4f8b\u5982HDFS API, S3 API, FUSE API, REST API\u3002\u5b83\u80fd\u591f\u900f\u660e\u5730\u4ece\u6807\u51c6\u5ba2\u6237\u7aef\u63a5\u53e3\u8f6c\u6362\u5230\u4efb\u4f55\u5b58\u50a8\u63a5\u53e3\u3002Alluxio \u8d1f\u8d23\u7ba1\u7406\u5e94\u7528\u7a0b\u5e8f\u548c\u6587\u4ef6\u6216\u5bf9\u8c61\u5b58\u50a8\u4e4b\u95f4\u7684\u901a\u4fe1\uff0c\u4ece\u800c\u6d88\u9664\u4e86\u5bf9\u590d\u6742\u7cfb\u7edf\u8fdb\u884c\u914d\u7f6e\u548c\u7ba1\u7406\u7684\u9700\u6c42\u3002\u6587\u4ef6\u6570\u636e\u53ef\u4ee5\u770b\u8d77\u6765\u50cf\u5bf9\u8c61\u6570\u636e\uff0c\u53cd\u4e4b\u4ea6\u7136\u3002\n \n-\u8981\u4e86\u89e3\u6709\u5173 Alluxio \u5185\u90e8\u7684\u66f4\u591a\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u9605\u8bfb [Alluxio \u67b6\u6784\u548c\u6570\u636e\u6d41]({{ '/cn/overview/Architecture.html' | relativize_url }})\u3002\n+\u8981\u4e86\u89e3\u6709\u5173 Alluxio \u5185\u90e8\u7684\u66f4\u591a\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u9605\u8bfb [Alluxio \u67b6\u6784\u548c\u6570\u636e\u6d41]({{ '/en/overview/Architecture.html' | relativize_url }})\u3002", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjc4NTE0Ng=="}, "originalCommit": {"oid": "a1d6b087ef956c7a638fbe407a3a4f783a99bb83"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzIyNzM5MQ==", "bodyText": "@LuQQiu can you suggest a similar page to link to or does one not exist? otherwise the alternative left is to delete the sentence", "url": "https://github.com/Alluxio/alluxio/pull/11169#discussion_r393227391", "createdAt": "2020-03-16T18:22:48Z", "author": {"login": "Xenorith"}, "path": "docs/cn/Overview.md", "diffHunk": "@@ -58,7 +58,7 @@ Alluxio \u5c06\u4e09\u4e2a\u5173\u952e\u9886\u57df\u7684\u521b\u65b0\u7ed3\u5408\u5728\u4e00\u8d77\uff0c\u63d0\u4f9b\u4e86\u4e00\u5957\u72ec\u7279\u7684\n 1. **\u667a\u80fd\u591a\u5c42\u7ea7\u7f13\u5b58**\uff1aAlluxio \u96c6\u7fa4\u80fd\u591f\u5145\u5f53\u5e95\u5c42\u5b58\u50a8\u7cfb\u7edf\u4e2d\u6570\u636e\u7684\u8bfb\u5199\u7f13\u5b58\u3002\u53ef\u914d\u7f6e\u81ea\u52a8\u4f18\u5316\u6570\u636e\u653e\u7f6e\u7b56\u7565\uff0c\u4ee5\u5b9e\u73b0\u8de8\u5185\u5b58\u548c\u78c1\u76d8\uff08SSD/HDD\uff09\u7684\u6027\u80fd\u548c\u53ef\u9760\u6027\u3002\u7f13\u5b58\u5bf9\u7528\u6237\u662f\u900f\u660e\u7684\uff0c\u4f7f\u7528\u7f13\u51b2\u6765\u4fdd\u6301\u4e0e\u6301\u4e45\u5b58\u50a8\u7684\u4e00\u81f4\u6027\u3002\u6709\u5173\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605 [\u7f13\u5b58\u529f\u80fd\u6587\u6863]({{ '/cn/core-services/Caching.html' | relativize_url }})\u3002\n 1. **\u670d\u52a1\u5668\u7aef API \u7ffb\u8bd1\u8f6c\u6362**\uff1aAlluxio\u652f\u6301\u5de5\u4e1a\u754c\u573a\u666f\u7684API\u63a5\u53e3\uff0c\u4f8b\u5982HDFS API, S3 API, FUSE API, REST API\u3002\u5b83\u80fd\u591f\u900f\u660e\u5730\u4ece\u6807\u51c6\u5ba2\u6237\u7aef\u63a5\u53e3\u8f6c\u6362\u5230\u4efb\u4f55\u5b58\u50a8\u63a5\u53e3\u3002Alluxio \u8d1f\u8d23\u7ba1\u7406\u5e94\u7528\u7a0b\u5e8f\u548c\u6587\u4ef6\u6216\u5bf9\u8c61\u5b58\u50a8\u4e4b\u95f4\u7684\u901a\u4fe1\uff0c\u4ece\u800c\u6d88\u9664\u4e86\u5bf9\u590d\u6742\u7cfb\u7edf\u8fdb\u884c\u914d\u7f6e\u548c\u7ba1\u7406\u7684\u9700\u6c42\u3002\u6587\u4ef6\u6570\u636e\u53ef\u4ee5\u770b\u8d77\u6765\u50cf\u5bf9\u8c61\u6570\u636e\uff0c\u53cd\u4e4b\u4ea6\u7136\u3002\n \n-\u8981\u4e86\u89e3\u6709\u5173 Alluxio \u5185\u90e8\u7684\u66f4\u591a\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u9605\u8bfb [Alluxio \u67b6\u6784\u548c\u6570\u636e\u6d41]({{ '/cn/overview/Architecture.html' | relativize_url }})\u3002\n+\u8981\u4e86\u89e3\u6709\u5173 Alluxio \u5185\u90e8\u7684\u66f4\u591a\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u9605\u8bfb [Alluxio \u67b6\u6784\u548c\u6570\u636e\u6d41]({{ '/en/overview/Architecture.html' | relativize_url }})\u3002", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjc4NTE0Ng=="}, "originalCommit": {"oid": "a1d6b087ef956c7a638fbe407a3a4f783a99bb83"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzQxMDQ5MQ==", "bodyText": "Emm... I didn't find any page similar to architecture page... do you consider deleting this line?", "url": "https://github.com/Alluxio/alluxio/pull/11169#discussion_r393410491", "createdAt": "2020-03-17T02:27:18Z", "author": {"login": "LuQQiu"}, "path": "docs/cn/Overview.md", "diffHunk": "@@ -58,7 +58,7 @@ Alluxio \u5c06\u4e09\u4e2a\u5173\u952e\u9886\u57df\u7684\u521b\u65b0\u7ed3\u5408\u5728\u4e00\u8d77\uff0c\u63d0\u4f9b\u4e86\u4e00\u5957\u72ec\u7279\u7684\n 1. **\u667a\u80fd\u591a\u5c42\u7ea7\u7f13\u5b58**\uff1aAlluxio \u96c6\u7fa4\u80fd\u591f\u5145\u5f53\u5e95\u5c42\u5b58\u50a8\u7cfb\u7edf\u4e2d\u6570\u636e\u7684\u8bfb\u5199\u7f13\u5b58\u3002\u53ef\u914d\u7f6e\u81ea\u52a8\u4f18\u5316\u6570\u636e\u653e\u7f6e\u7b56\u7565\uff0c\u4ee5\u5b9e\u73b0\u8de8\u5185\u5b58\u548c\u78c1\u76d8\uff08SSD/HDD\uff09\u7684\u6027\u80fd\u548c\u53ef\u9760\u6027\u3002\u7f13\u5b58\u5bf9\u7528\u6237\u662f\u900f\u660e\u7684\uff0c\u4f7f\u7528\u7f13\u51b2\u6765\u4fdd\u6301\u4e0e\u6301\u4e45\u5b58\u50a8\u7684\u4e00\u81f4\u6027\u3002\u6709\u5173\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605 [\u7f13\u5b58\u529f\u80fd\u6587\u6863]({{ '/cn/core-services/Caching.html' | relativize_url }})\u3002\n 1. **\u670d\u52a1\u5668\u7aef API \u7ffb\u8bd1\u8f6c\u6362**\uff1aAlluxio\u652f\u6301\u5de5\u4e1a\u754c\u573a\u666f\u7684API\u63a5\u53e3\uff0c\u4f8b\u5982HDFS API, S3 API, FUSE API, REST API\u3002\u5b83\u80fd\u591f\u900f\u660e\u5730\u4ece\u6807\u51c6\u5ba2\u6237\u7aef\u63a5\u53e3\u8f6c\u6362\u5230\u4efb\u4f55\u5b58\u50a8\u63a5\u53e3\u3002Alluxio \u8d1f\u8d23\u7ba1\u7406\u5e94\u7528\u7a0b\u5e8f\u548c\u6587\u4ef6\u6216\u5bf9\u8c61\u5b58\u50a8\u4e4b\u95f4\u7684\u901a\u4fe1\uff0c\u4ece\u800c\u6d88\u9664\u4e86\u5bf9\u590d\u6742\u7cfb\u7edf\u8fdb\u884c\u914d\u7f6e\u548c\u7ba1\u7406\u7684\u9700\u6c42\u3002\u6587\u4ef6\u6570\u636e\u53ef\u4ee5\u770b\u8d77\u6765\u50cf\u5bf9\u8c61\u6570\u636e\uff0c\u53cd\u4e4b\u4ea6\u7136\u3002\n \n-\u8981\u4e86\u89e3\u6709\u5173 Alluxio \u5185\u90e8\u7684\u66f4\u591a\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u9605\u8bfb [Alluxio \u67b6\u6784\u548c\u6570\u636e\u6d41]({{ '/cn/overview/Architecture.html' | relativize_url }})\u3002\n+\u8981\u4e86\u89e3\u6709\u5173 Alluxio \u5185\u90e8\u7684\u66f4\u591a\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u9605\u8bfb [Alluxio \u67b6\u6784\u548c\u6570\u636e\u6d41]({{ '/en/overview/Architecture.html' | relativize_url }})\u3002", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjc4NTE0Ng=="}, "originalCommit": {"oid": "a1d6b087ef956c7a638fbe407a3a4f783a99bb83"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzNDY4MzU0OnYy", "diffSide": "RIGHT", "path": "docs/check.go", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQwNToxMTowNVrOF2luQA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQwNTozODoyNVrOF2mEOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjc4NTQ3Mg==", "bodyText": "Is this only for links that link to other doc pages?\nFor external links this doesn't capture all possible scenarios", "url": "https://github.com/Alluxio/alluxio/pull/11169#discussion_r392785472", "createdAt": "2020-03-16T05:11:05Z", "author": {"login": "ZacBlanco"}, "path": "docs/check.go", "diffHunk": "@@ -0,0 +1,294 @@\n+package main\n+\n+import (\n+\t\"bufio\"\n+\t\"fmt\"\n+\t\"log\"\n+\t\"os\"\n+\t\"path/filepath\"\n+\t\"strings\"\n+\t\"regexp\"\n+)\n+\n+func main() {\n+\tif err := run(); err != nil {\n+\t\tlog.Fatalln(err)\n+\t}\n+\tlog.Println(\"Documentation check succeeded\")\n+}\n+\n+type checkContext struct {\n+\t// inputs\n+\tcategoryNames StringSet // category or group names defined in _config.yml\n+\tdocsPath      string    // path to docs directory in repository\n+\n+\t// intermediate\n+\tknownFiles    StringSet                  // file paths of files that can be referenced by markdown files\n+\tmarkdownLinks map[string][]*relativeLink // list of relative links found in each markdown file\n+\n+\t// outputs\n+\tmarkdownErrors map[string][]string // list of errors found in each markdown file\n+}\n+\n+type relativeLink struct {\n+\tline int\n+\tpath string\n+}\n+\n+func (ctx *checkContext) addError(mdFile string, lineNum int, format string, args ...interface{}) {\n+\tmsg := fmt.Sprintf(\"%d: \", lineNum) + fmt.Sprintf(format, args...)\n+\tctx.markdownErrors[mdFile] = append(ctx.markdownErrors[mdFile], msg)\n+}\n+\n+func run() error {\n+\t// check that script is being run from repo root\n+\tconst docsDir, configYml = \"docs\", \"_config.yml\"\n+\trepoRoot, err := os.Getwd()\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"could not get current working directory: %v\", err)\n+\t}\n+\tdocsPath, err := filepath.Abs(filepath.Join(repoRoot, docsDir))\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"could not get absolute path of %v: %v\", filepath.Join(repoRoot, docsDir), err)\n+\t}\n+\tconfigPath := filepath.Join(docsPath, configYml)\n+\tif _, err := os.Stat(configPath); os.IsNotExist(err) {\n+\t\treturn fmt.Errorf(\"expected to find %s in %s; script should be executed from repository root\", configYml, docsDir)\n+\t}\n+\n+\t// parse category names from config file\n+\tcategoryNames, err := parseCategoryNames(configPath)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"error parsing category names: %v\", err)\n+\t}\n+\n+\tctx := &checkContext{\n+\t\tcategoryNames:  categoryNames,\n+\t\tdocsPath:       docsPath,\n+\t\tknownFiles:     StringSet{},\n+\t\tmarkdownLinks:  map[string][]*relativeLink{},\n+\t\tmarkdownErrors: map[string][]string{},\n+\t}\n+\n+\t// scan through markdown files\n+\tfor _, langDir := range []string{\"en\", \"cn\"} {\n+\t\tif err := filepath.Walk(filepath.Join(docsPath, langDir),\n+\t\t\tfunc(p string, info os.FileInfo, err error) error {\n+\t\t\t\tif err != nil {\n+\t\t\t\t\treturn err\n+\t\t\t\t}\n+\t\t\t\tif info.IsDir() {\n+\t\t\t\t\treturn nil\n+\t\t\t\t}\n+\t\t\t\tif strings.HasSuffix(info.Name(), \".md\") {\n+\t\t\t\t\tif err := checkFile(p, ctx); err != nil {\n+\t\t\t\t\t\treturn err\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t\treturn nil\n+\t\t\t},\n+\t\t); err != nil {\n+\t\t\treturn fmt.Errorf(\"error traversing through md files in %v: %v\", filepath.Join(docsPath, langDir), err)\n+\t\t}\n+\t}\n+\t// scan through img and resources directories to update known files\n+\tfor _, dir := range []string{\"img\", \"resources\"} {\n+\t\tif err := filepath.Walk(filepath.Join(docsPath, dir),\n+\t\t\tfunc(p string, info os.FileInfo, err error) error {\n+\t\t\t\tif err != nil {\n+\t\t\t\t\treturn err\n+\t\t\t\t}\n+\t\t\t\tif info.IsDir() {\n+\t\t\t\t\treturn nil\n+\t\t\t\t}\n+\t\t\t\tctx.knownFiles.Add(strings.TrimPrefix(p, docsPath))\n+\t\t\t\treturn nil\n+\t\t\t},\n+\t\t); err != nil {\n+\t\t\treturn fmt.Errorf(\"error traversing through files in %v: %v\", filepath.Join(docsPath, dir), err)\n+\t\t}\n+\t}\n+\n+\tctx.checkLinks()\n+\n+\tif len(ctx.markdownErrors) > 0 {\n+\t\terrLines := []string{\"Errors found in documentation markdown\"}\n+\t\tfor f, errs := range ctx.markdownErrors {\n+\t\t\terrLines = append(errLines, fmt.Sprintf(\"  %v:\", strings.TrimPrefix(f, repoRoot)))\n+\t\t\tfor _, err := range errs {\n+\t\t\t\terrLines = append(errLines, fmt.Sprintf(\"    %s\", err))\n+\t\t\t}\n+\t\t}\n+\t\treturn fmt.Errorf(\"%v\", strings.Join(errLines, \"\\n\"))\n+\t}\n+\n+\treturn nil\n+}\n+\n+// parseCategoryNames parses the given config file for the list of category names\n+func parseCategoryNames(configPath string) (StringSet, error) {\n+\tf, err := os.Open(configPath)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"error opening file at %v: %v\", configPath, err)\n+\t}\n+\tdefer f.Close()\n+\n+\tconst categoryListLine, categoryPrefix = \"categoryList:\", \"  - \"\n+\tcategoryNames := StringSet{}\n+\n+\tfound := false\n+\tscanner := bufio.NewScanner(f)\n+\tfor scanner.Scan() {\n+\t\tl := scanner.Text()\n+\t\tif l == categoryListLine {\n+\t\t\tfound = true\n+\t\t\tcontinue\n+\t\t}\n+\t\tif found {\n+\t\t\tif !strings.HasPrefix(l, categoryPrefix) {\n+\t\t\t\tfound = false\n+\t\t\t\tcontinue\n+\t\t\t}\n+\t\t\tcategoryNames.Add(strings.TrimPrefix(l, categoryPrefix))\n+\t\t}\n+\t}\n+\tif err := scanner.Err(); err != nil {\n+\t\treturn nil, fmt.Errorf(\"error scanning file: %v\", err)\n+\t}\n+\treturn categoryNames, nil\n+}\n+\n+var (\n+\t// general format of a relative link, where the link will be computed by a jekyll function encapsulated in {{ }}\n+\trelativeLinkRe = regexp.MustCompile(`\\[.+\\]\\({{.*}}\\)`)\n+\t// path encapsulated in ' ' could have an optional search query \"?q=queryStr\" and/or an optional anchor reference \"#anchor\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a1d6b087ef956c7a638fbe407a3a4f783a99bb83"}, "originalPosition": 164}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjc5MTA5Ng==", "bodyText": "yes i do not want to validate any external links in a PR build", "url": "https://github.com/Alluxio/alluxio/pull/11169#discussion_r392791096", "createdAt": "2020-03-16T05:38:25Z", "author": {"login": "Xenorith"}, "path": "docs/check.go", "diffHunk": "@@ -0,0 +1,294 @@\n+package main\n+\n+import (\n+\t\"bufio\"\n+\t\"fmt\"\n+\t\"log\"\n+\t\"os\"\n+\t\"path/filepath\"\n+\t\"strings\"\n+\t\"regexp\"\n+)\n+\n+func main() {\n+\tif err := run(); err != nil {\n+\t\tlog.Fatalln(err)\n+\t}\n+\tlog.Println(\"Documentation check succeeded\")\n+}\n+\n+type checkContext struct {\n+\t// inputs\n+\tcategoryNames StringSet // category or group names defined in _config.yml\n+\tdocsPath      string    // path to docs directory in repository\n+\n+\t// intermediate\n+\tknownFiles    StringSet                  // file paths of files that can be referenced by markdown files\n+\tmarkdownLinks map[string][]*relativeLink // list of relative links found in each markdown file\n+\n+\t// outputs\n+\tmarkdownErrors map[string][]string // list of errors found in each markdown file\n+}\n+\n+type relativeLink struct {\n+\tline int\n+\tpath string\n+}\n+\n+func (ctx *checkContext) addError(mdFile string, lineNum int, format string, args ...interface{}) {\n+\tmsg := fmt.Sprintf(\"%d: \", lineNum) + fmt.Sprintf(format, args...)\n+\tctx.markdownErrors[mdFile] = append(ctx.markdownErrors[mdFile], msg)\n+}\n+\n+func run() error {\n+\t// check that script is being run from repo root\n+\tconst docsDir, configYml = \"docs\", \"_config.yml\"\n+\trepoRoot, err := os.Getwd()\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"could not get current working directory: %v\", err)\n+\t}\n+\tdocsPath, err := filepath.Abs(filepath.Join(repoRoot, docsDir))\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"could not get absolute path of %v: %v\", filepath.Join(repoRoot, docsDir), err)\n+\t}\n+\tconfigPath := filepath.Join(docsPath, configYml)\n+\tif _, err := os.Stat(configPath); os.IsNotExist(err) {\n+\t\treturn fmt.Errorf(\"expected to find %s in %s; script should be executed from repository root\", configYml, docsDir)\n+\t}\n+\n+\t// parse category names from config file\n+\tcategoryNames, err := parseCategoryNames(configPath)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"error parsing category names: %v\", err)\n+\t}\n+\n+\tctx := &checkContext{\n+\t\tcategoryNames:  categoryNames,\n+\t\tdocsPath:       docsPath,\n+\t\tknownFiles:     StringSet{},\n+\t\tmarkdownLinks:  map[string][]*relativeLink{},\n+\t\tmarkdownErrors: map[string][]string{},\n+\t}\n+\n+\t// scan through markdown files\n+\tfor _, langDir := range []string{\"en\", \"cn\"} {\n+\t\tif err := filepath.Walk(filepath.Join(docsPath, langDir),\n+\t\t\tfunc(p string, info os.FileInfo, err error) error {\n+\t\t\t\tif err != nil {\n+\t\t\t\t\treturn err\n+\t\t\t\t}\n+\t\t\t\tif info.IsDir() {\n+\t\t\t\t\treturn nil\n+\t\t\t\t}\n+\t\t\t\tif strings.HasSuffix(info.Name(), \".md\") {\n+\t\t\t\t\tif err := checkFile(p, ctx); err != nil {\n+\t\t\t\t\t\treturn err\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t\treturn nil\n+\t\t\t},\n+\t\t); err != nil {\n+\t\t\treturn fmt.Errorf(\"error traversing through md files in %v: %v\", filepath.Join(docsPath, langDir), err)\n+\t\t}\n+\t}\n+\t// scan through img and resources directories to update known files\n+\tfor _, dir := range []string{\"img\", \"resources\"} {\n+\t\tif err := filepath.Walk(filepath.Join(docsPath, dir),\n+\t\t\tfunc(p string, info os.FileInfo, err error) error {\n+\t\t\t\tif err != nil {\n+\t\t\t\t\treturn err\n+\t\t\t\t}\n+\t\t\t\tif info.IsDir() {\n+\t\t\t\t\treturn nil\n+\t\t\t\t}\n+\t\t\t\tctx.knownFiles.Add(strings.TrimPrefix(p, docsPath))\n+\t\t\t\treturn nil\n+\t\t\t},\n+\t\t); err != nil {\n+\t\t\treturn fmt.Errorf(\"error traversing through files in %v: %v\", filepath.Join(docsPath, dir), err)\n+\t\t}\n+\t}\n+\n+\tctx.checkLinks()\n+\n+\tif len(ctx.markdownErrors) > 0 {\n+\t\terrLines := []string{\"Errors found in documentation markdown\"}\n+\t\tfor f, errs := range ctx.markdownErrors {\n+\t\t\terrLines = append(errLines, fmt.Sprintf(\"  %v:\", strings.TrimPrefix(f, repoRoot)))\n+\t\t\tfor _, err := range errs {\n+\t\t\t\terrLines = append(errLines, fmt.Sprintf(\"    %s\", err))\n+\t\t\t}\n+\t\t}\n+\t\treturn fmt.Errorf(\"%v\", strings.Join(errLines, \"\\n\"))\n+\t}\n+\n+\treturn nil\n+}\n+\n+// parseCategoryNames parses the given config file for the list of category names\n+func parseCategoryNames(configPath string) (StringSet, error) {\n+\tf, err := os.Open(configPath)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"error opening file at %v: %v\", configPath, err)\n+\t}\n+\tdefer f.Close()\n+\n+\tconst categoryListLine, categoryPrefix = \"categoryList:\", \"  - \"\n+\tcategoryNames := StringSet{}\n+\n+\tfound := false\n+\tscanner := bufio.NewScanner(f)\n+\tfor scanner.Scan() {\n+\t\tl := scanner.Text()\n+\t\tif l == categoryListLine {\n+\t\t\tfound = true\n+\t\t\tcontinue\n+\t\t}\n+\t\tif found {\n+\t\t\tif !strings.HasPrefix(l, categoryPrefix) {\n+\t\t\t\tfound = false\n+\t\t\t\tcontinue\n+\t\t\t}\n+\t\t\tcategoryNames.Add(strings.TrimPrefix(l, categoryPrefix))\n+\t\t}\n+\t}\n+\tif err := scanner.Err(); err != nil {\n+\t\treturn nil, fmt.Errorf(\"error scanning file: %v\", err)\n+\t}\n+\treturn categoryNames, nil\n+}\n+\n+var (\n+\t// general format of a relative link, where the link will be computed by a jekyll function encapsulated in {{ }}\n+\trelativeLinkRe = regexp.MustCompile(`\\[.+\\]\\({{.*}}\\)`)\n+\t// path encapsulated in ' ' could have an optional search query \"?q=queryStr\" and/or an optional anchor reference \"#anchor\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjc4NTQ3Mg=="}, "originalCommit": {"oid": "a1d6b087ef956c7a638fbe407a3a4f783a99bb83"}, "originalPosition": 164}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzNDY4NTM1OnYy", "diffSide": "RIGHT", "path": "docs/check.go", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQwNToxMjozM1rOF2lvaA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQwNTozODo0NFrOF2mEdg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjc4NTc2OA==", "bodyText": "is this not supposed to be quoted?", "url": "https://github.com/Alluxio/alluxio/pull/11169#discussion_r392785768", "createdAt": "2020-03-16T05:12:33Z", "author": {"login": "ZacBlanco"}, "path": "docs/check.go", "diffHunk": "@@ -0,0 +1,294 @@\n+package main\n+\n+import (\n+\t\"bufio\"\n+\t\"fmt\"\n+\t\"log\"\n+\t\"os\"\n+\t\"path/filepath\"\n+\t\"strings\"\n+\t\"regexp\"\n+)\n+\n+func main() {\n+\tif err := run(); err != nil {\n+\t\tlog.Fatalln(err)\n+\t}\n+\tlog.Println(\"Documentation check succeeded\")\n+}\n+\n+type checkContext struct {\n+\t// inputs\n+\tcategoryNames StringSet // category or group names defined in _config.yml\n+\tdocsPath      string    // path to docs directory in repository\n+\n+\t// intermediate\n+\tknownFiles    StringSet                  // file paths of files that can be referenced by markdown files\n+\tmarkdownLinks map[string][]*relativeLink // list of relative links found in each markdown file\n+\n+\t// outputs\n+\tmarkdownErrors map[string][]string // list of errors found in each markdown file\n+}\n+\n+type relativeLink struct {\n+\tline int\n+\tpath string\n+}\n+\n+func (ctx *checkContext) addError(mdFile string, lineNum int, format string, args ...interface{}) {\n+\tmsg := fmt.Sprintf(\"%d: \", lineNum) + fmt.Sprintf(format, args...)\n+\tctx.markdownErrors[mdFile] = append(ctx.markdownErrors[mdFile], msg)\n+}\n+\n+func run() error {\n+\t// check that script is being run from repo root\n+\tconst docsDir, configYml = \"docs\", \"_config.yml\"\n+\trepoRoot, err := os.Getwd()\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"could not get current working directory: %v\", err)\n+\t}\n+\tdocsPath, err := filepath.Abs(filepath.Join(repoRoot, docsDir))\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"could not get absolute path of %v: %v\", filepath.Join(repoRoot, docsDir), err)\n+\t}\n+\tconfigPath := filepath.Join(docsPath, configYml)\n+\tif _, err := os.Stat(configPath); os.IsNotExist(err) {\n+\t\treturn fmt.Errorf(\"expected to find %s in %s; script should be executed from repository root\", configYml, docsDir)\n+\t}\n+\n+\t// parse category names from config file\n+\tcategoryNames, err := parseCategoryNames(configPath)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"error parsing category names: %v\", err)\n+\t}\n+\n+\tctx := &checkContext{\n+\t\tcategoryNames:  categoryNames,\n+\t\tdocsPath:       docsPath,\n+\t\tknownFiles:     StringSet{},\n+\t\tmarkdownLinks:  map[string][]*relativeLink{},\n+\t\tmarkdownErrors: map[string][]string{},\n+\t}\n+\n+\t// scan through markdown files\n+\tfor _, langDir := range []string{\"en\", \"cn\"} {\n+\t\tif err := filepath.Walk(filepath.Join(docsPath, langDir),\n+\t\t\tfunc(p string, info os.FileInfo, err error) error {\n+\t\t\t\tif err != nil {\n+\t\t\t\t\treturn err\n+\t\t\t\t}\n+\t\t\t\tif info.IsDir() {\n+\t\t\t\t\treturn nil\n+\t\t\t\t}\n+\t\t\t\tif strings.HasSuffix(info.Name(), \".md\") {\n+\t\t\t\t\tif err := checkFile(p, ctx); err != nil {\n+\t\t\t\t\t\treturn err\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t\treturn nil\n+\t\t\t},\n+\t\t); err != nil {\n+\t\t\treturn fmt.Errorf(\"error traversing through md files in %v: %v\", filepath.Join(docsPath, langDir), err)\n+\t\t}\n+\t}\n+\t// scan through img and resources directories to update known files\n+\tfor _, dir := range []string{\"img\", \"resources\"} {\n+\t\tif err := filepath.Walk(filepath.Join(docsPath, dir),\n+\t\t\tfunc(p string, info os.FileInfo, err error) error {\n+\t\t\t\tif err != nil {\n+\t\t\t\t\treturn err\n+\t\t\t\t}\n+\t\t\t\tif info.IsDir() {\n+\t\t\t\t\treturn nil\n+\t\t\t\t}\n+\t\t\t\tctx.knownFiles.Add(strings.TrimPrefix(p, docsPath))\n+\t\t\t\treturn nil\n+\t\t\t},\n+\t\t); err != nil {\n+\t\t\treturn fmt.Errorf(\"error traversing through files in %v: %v\", filepath.Join(docsPath, dir), err)\n+\t\t}\n+\t}\n+\n+\tctx.checkLinks()\n+\n+\tif len(ctx.markdownErrors) > 0 {\n+\t\terrLines := []string{\"Errors found in documentation markdown\"}\n+\t\tfor f, errs := range ctx.markdownErrors {\n+\t\t\terrLines = append(errLines, fmt.Sprintf(\"  %v:\", strings.TrimPrefix(f, repoRoot)))\n+\t\t\tfor _, err := range errs {\n+\t\t\t\terrLines = append(errLines, fmt.Sprintf(\"    %s\", err))\n+\t\t\t}\n+\t\t}\n+\t\treturn fmt.Errorf(\"%v\", strings.Join(errLines, \"\\n\"))\n+\t}\n+\n+\treturn nil\n+}\n+\n+// parseCategoryNames parses the given config file for the list of category names\n+func parseCategoryNames(configPath string) (StringSet, error) {\n+\tf, err := os.Open(configPath)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"error opening file at %v: %v\", configPath, err)\n+\t}\n+\tdefer f.Close()\n+\n+\tconst categoryListLine, categoryPrefix = \"categoryList:\", \"  - \"\n+\tcategoryNames := StringSet{}\n+\n+\tfound := false\n+\tscanner := bufio.NewScanner(f)\n+\tfor scanner.Scan() {\n+\t\tl := scanner.Text()\n+\t\tif l == categoryListLine {\n+\t\t\tfound = true\n+\t\t\tcontinue\n+\t\t}\n+\t\tif found {\n+\t\t\tif !strings.HasPrefix(l, categoryPrefix) {\n+\t\t\t\tfound = false\n+\t\t\t\tcontinue\n+\t\t\t}\n+\t\t\tcategoryNames.Add(strings.TrimPrefix(l, categoryPrefix))\n+\t\t}\n+\t}\n+\tif err := scanner.Err(); err != nil {\n+\t\treturn nil, fmt.Errorf(\"error scanning file: %v\", err)\n+\t}\n+\treturn categoryNames, nil\n+}\n+\n+var (\n+\t// general format of a relative link, where the link will be computed by a jekyll function encapsulated in {{ }}\n+\trelativeLinkRe = regexp.MustCompile(`\\[.+\\]\\({{.*}}\\)`)\n+\t// path encapsulated in ' ' could have an optional search query \"?q=queryStr\" and/or an optional anchor reference \"#anchor\"\n+\trelativeLinkPagePathRe = regexp.MustCompile(`\\[.+\\]\\({{ '(?P<path>[\\w-./]+)(\\?q=\\w+)?(#.+)?' | relativize_url }}\\)`)\n+)\n+\n+// checkFile parses the given markdown file and appends errors found in its contents\n+func checkFile(mdFile string, ctx *checkContext) error {\n+\tf, err := os.Open(mdFile)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"error opening file at %v: %v\", mdFile, err)\n+\t}\n+\tdefer f.Close()\n+\n+\tvar headers []string\n+\tvar relativeLinks []*relativeLink\n+\tinHeaderSection := true\n+\tscanner := bufio.NewScanner(f)\n+\tfor i := 1; scanner.Scan(); i++ {\n+\t\tl := scanner.Text()\n+\t\tif inHeaderSection {\n+\t\t\t// first empty line ends the header section\n+\t\t\tif l == \"\" {\n+\t\t\t\tinHeaderSection = false\n+\t\t\t} else {\n+\t\t\t\theaders = append(headers, l)\n+\t\t\t}\n+\t\t}\n+\t\tif relativeLinkRe.MatchString(l) {\n+\t\t\tfor _, lineMatches := range relativeLinkRe.FindAllStringSubmatch(l, -1) {\n+\t\t\t\tif len(lineMatches) != 1 {\n+\t\t\t\t\treturn fmt.Errorf(\"expected to find exactly one string submatch but found %d in line %v\", len(lineMatches), l)\n+\t\t\t\t}\n+\t\t\t\trelativeLinkStr := lineMatches[0]\n+\t\t\t\tif !relativeLinkPagePathRe.MatchString(relativeLinkStr) {\n+\t\t\t\t\tctx.addError(mdFile, i, \"relative link did not match expected pattern %q\", relativeLinkStr)\n+\t\t\t\t\tcontinue\n+\t\t\t\t}\n+\t\t\t\tlinkMatches := relativeLinkPagePathRe.FindStringSubmatch(relativeLinkStr)\n+\t\t\t\tif len(linkMatches) < 2 {\n+\t\t\t\t\treturn fmt.Errorf(\"expected to find at least two string submatches but found %d = %v in link %v\", len(linkMatches), linkMatches, relativeLinkStr)\n+\t\t\t\t}\n+\t\t\t\t// note that first is the full match, second is the named match\n+\t\t\t\tnamedMatch := linkMatches[1]\n+\t\t\t\tif namedMatch == \"\" {\n+\t\t\t\t\treturn fmt.Errorf(\"encountered empty named match when parsing link from %v\", relativeLinkStr)\n+\t\t\t\t}\n+\t\t\t\trelativeLinks = append(relativeLinks, &relativeLink{\n+\t\t\t\t\tline: i,\n+\t\t\t\t\tpath: namedMatch,\n+\t\t\t\t})\n+\t\t\t}\n+\t\t}\n+\t}\n+\tif err := scanner.Err(); err != nil {\n+\t\treturn fmt.Errorf(\"error scanning file: %v\", err)\n+\t}\n+\n+\tctx.checkHeader(headers, mdFile)\n+\tctx.addRelativeLinks(relativeLinks, mdFile)\n+\n+\treturn nil\n+}\n+\n+const groupKey = \"group\"\n+\n+var headerKeys = StringSet{\n+\t\"layout\":   {},\n+\t\"title\":    {},\n+\t\"nickname\": {},\n+\tgroupKey:   {},", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a1d6b087ef956c7a638fbe407a3a4f783a99bb83"}, "originalPosition": 232}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjc5MTE1OA==", "bodyText": "it's a reference to the above constant", "url": "https://github.com/Alluxio/alluxio/pull/11169#discussion_r392791158", "createdAt": "2020-03-16T05:38:44Z", "author": {"login": "Xenorith"}, "path": "docs/check.go", "diffHunk": "@@ -0,0 +1,294 @@\n+package main\n+\n+import (\n+\t\"bufio\"\n+\t\"fmt\"\n+\t\"log\"\n+\t\"os\"\n+\t\"path/filepath\"\n+\t\"strings\"\n+\t\"regexp\"\n+)\n+\n+func main() {\n+\tif err := run(); err != nil {\n+\t\tlog.Fatalln(err)\n+\t}\n+\tlog.Println(\"Documentation check succeeded\")\n+}\n+\n+type checkContext struct {\n+\t// inputs\n+\tcategoryNames StringSet // category or group names defined in _config.yml\n+\tdocsPath      string    // path to docs directory in repository\n+\n+\t// intermediate\n+\tknownFiles    StringSet                  // file paths of files that can be referenced by markdown files\n+\tmarkdownLinks map[string][]*relativeLink // list of relative links found in each markdown file\n+\n+\t// outputs\n+\tmarkdownErrors map[string][]string // list of errors found in each markdown file\n+}\n+\n+type relativeLink struct {\n+\tline int\n+\tpath string\n+}\n+\n+func (ctx *checkContext) addError(mdFile string, lineNum int, format string, args ...interface{}) {\n+\tmsg := fmt.Sprintf(\"%d: \", lineNum) + fmt.Sprintf(format, args...)\n+\tctx.markdownErrors[mdFile] = append(ctx.markdownErrors[mdFile], msg)\n+}\n+\n+func run() error {\n+\t// check that script is being run from repo root\n+\tconst docsDir, configYml = \"docs\", \"_config.yml\"\n+\trepoRoot, err := os.Getwd()\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"could not get current working directory: %v\", err)\n+\t}\n+\tdocsPath, err := filepath.Abs(filepath.Join(repoRoot, docsDir))\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"could not get absolute path of %v: %v\", filepath.Join(repoRoot, docsDir), err)\n+\t}\n+\tconfigPath := filepath.Join(docsPath, configYml)\n+\tif _, err := os.Stat(configPath); os.IsNotExist(err) {\n+\t\treturn fmt.Errorf(\"expected to find %s in %s; script should be executed from repository root\", configYml, docsDir)\n+\t}\n+\n+\t// parse category names from config file\n+\tcategoryNames, err := parseCategoryNames(configPath)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"error parsing category names: %v\", err)\n+\t}\n+\n+\tctx := &checkContext{\n+\t\tcategoryNames:  categoryNames,\n+\t\tdocsPath:       docsPath,\n+\t\tknownFiles:     StringSet{},\n+\t\tmarkdownLinks:  map[string][]*relativeLink{},\n+\t\tmarkdownErrors: map[string][]string{},\n+\t}\n+\n+\t// scan through markdown files\n+\tfor _, langDir := range []string{\"en\", \"cn\"} {\n+\t\tif err := filepath.Walk(filepath.Join(docsPath, langDir),\n+\t\t\tfunc(p string, info os.FileInfo, err error) error {\n+\t\t\t\tif err != nil {\n+\t\t\t\t\treturn err\n+\t\t\t\t}\n+\t\t\t\tif info.IsDir() {\n+\t\t\t\t\treturn nil\n+\t\t\t\t}\n+\t\t\t\tif strings.HasSuffix(info.Name(), \".md\") {\n+\t\t\t\t\tif err := checkFile(p, ctx); err != nil {\n+\t\t\t\t\t\treturn err\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t\treturn nil\n+\t\t\t},\n+\t\t); err != nil {\n+\t\t\treturn fmt.Errorf(\"error traversing through md files in %v: %v\", filepath.Join(docsPath, langDir), err)\n+\t\t}\n+\t}\n+\t// scan through img and resources directories to update known files\n+\tfor _, dir := range []string{\"img\", \"resources\"} {\n+\t\tif err := filepath.Walk(filepath.Join(docsPath, dir),\n+\t\t\tfunc(p string, info os.FileInfo, err error) error {\n+\t\t\t\tif err != nil {\n+\t\t\t\t\treturn err\n+\t\t\t\t}\n+\t\t\t\tif info.IsDir() {\n+\t\t\t\t\treturn nil\n+\t\t\t\t}\n+\t\t\t\tctx.knownFiles.Add(strings.TrimPrefix(p, docsPath))\n+\t\t\t\treturn nil\n+\t\t\t},\n+\t\t); err != nil {\n+\t\t\treturn fmt.Errorf(\"error traversing through files in %v: %v\", filepath.Join(docsPath, dir), err)\n+\t\t}\n+\t}\n+\n+\tctx.checkLinks()\n+\n+\tif len(ctx.markdownErrors) > 0 {\n+\t\terrLines := []string{\"Errors found in documentation markdown\"}\n+\t\tfor f, errs := range ctx.markdownErrors {\n+\t\t\terrLines = append(errLines, fmt.Sprintf(\"  %v:\", strings.TrimPrefix(f, repoRoot)))\n+\t\t\tfor _, err := range errs {\n+\t\t\t\terrLines = append(errLines, fmt.Sprintf(\"    %s\", err))\n+\t\t\t}\n+\t\t}\n+\t\treturn fmt.Errorf(\"%v\", strings.Join(errLines, \"\\n\"))\n+\t}\n+\n+\treturn nil\n+}\n+\n+// parseCategoryNames parses the given config file for the list of category names\n+func parseCategoryNames(configPath string) (StringSet, error) {\n+\tf, err := os.Open(configPath)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"error opening file at %v: %v\", configPath, err)\n+\t}\n+\tdefer f.Close()\n+\n+\tconst categoryListLine, categoryPrefix = \"categoryList:\", \"  - \"\n+\tcategoryNames := StringSet{}\n+\n+\tfound := false\n+\tscanner := bufio.NewScanner(f)\n+\tfor scanner.Scan() {\n+\t\tl := scanner.Text()\n+\t\tif l == categoryListLine {\n+\t\t\tfound = true\n+\t\t\tcontinue\n+\t\t}\n+\t\tif found {\n+\t\t\tif !strings.HasPrefix(l, categoryPrefix) {\n+\t\t\t\tfound = false\n+\t\t\t\tcontinue\n+\t\t\t}\n+\t\t\tcategoryNames.Add(strings.TrimPrefix(l, categoryPrefix))\n+\t\t}\n+\t}\n+\tif err := scanner.Err(); err != nil {\n+\t\treturn nil, fmt.Errorf(\"error scanning file: %v\", err)\n+\t}\n+\treturn categoryNames, nil\n+}\n+\n+var (\n+\t// general format of a relative link, where the link will be computed by a jekyll function encapsulated in {{ }}\n+\trelativeLinkRe = regexp.MustCompile(`\\[.+\\]\\({{.*}}\\)`)\n+\t// path encapsulated in ' ' could have an optional search query \"?q=queryStr\" and/or an optional anchor reference \"#anchor\"\n+\trelativeLinkPagePathRe = regexp.MustCompile(`\\[.+\\]\\({{ '(?P<path>[\\w-./]+)(\\?q=\\w+)?(#.+)?' | relativize_url }}\\)`)\n+)\n+\n+// checkFile parses the given markdown file and appends errors found in its contents\n+func checkFile(mdFile string, ctx *checkContext) error {\n+\tf, err := os.Open(mdFile)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"error opening file at %v: %v\", mdFile, err)\n+\t}\n+\tdefer f.Close()\n+\n+\tvar headers []string\n+\tvar relativeLinks []*relativeLink\n+\tinHeaderSection := true\n+\tscanner := bufio.NewScanner(f)\n+\tfor i := 1; scanner.Scan(); i++ {\n+\t\tl := scanner.Text()\n+\t\tif inHeaderSection {\n+\t\t\t// first empty line ends the header section\n+\t\t\tif l == \"\" {\n+\t\t\t\tinHeaderSection = false\n+\t\t\t} else {\n+\t\t\t\theaders = append(headers, l)\n+\t\t\t}\n+\t\t}\n+\t\tif relativeLinkRe.MatchString(l) {\n+\t\t\tfor _, lineMatches := range relativeLinkRe.FindAllStringSubmatch(l, -1) {\n+\t\t\t\tif len(lineMatches) != 1 {\n+\t\t\t\t\treturn fmt.Errorf(\"expected to find exactly one string submatch but found %d in line %v\", len(lineMatches), l)\n+\t\t\t\t}\n+\t\t\t\trelativeLinkStr := lineMatches[0]\n+\t\t\t\tif !relativeLinkPagePathRe.MatchString(relativeLinkStr) {\n+\t\t\t\t\tctx.addError(mdFile, i, \"relative link did not match expected pattern %q\", relativeLinkStr)\n+\t\t\t\t\tcontinue\n+\t\t\t\t}\n+\t\t\t\tlinkMatches := relativeLinkPagePathRe.FindStringSubmatch(relativeLinkStr)\n+\t\t\t\tif len(linkMatches) < 2 {\n+\t\t\t\t\treturn fmt.Errorf(\"expected to find at least two string submatches but found %d = %v in link %v\", len(linkMatches), linkMatches, relativeLinkStr)\n+\t\t\t\t}\n+\t\t\t\t// note that first is the full match, second is the named match\n+\t\t\t\tnamedMatch := linkMatches[1]\n+\t\t\t\tif namedMatch == \"\" {\n+\t\t\t\t\treturn fmt.Errorf(\"encountered empty named match when parsing link from %v\", relativeLinkStr)\n+\t\t\t\t}\n+\t\t\t\trelativeLinks = append(relativeLinks, &relativeLink{\n+\t\t\t\t\tline: i,\n+\t\t\t\t\tpath: namedMatch,\n+\t\t\t\t})\n+\t\t\t}\n+\t\t}\n+\t}\n+\tif err := scanner.Err(); err != nil {\n+\t\treturn fmt.Errorf(\"error scanning file: %v\", err)\n+\t}\n+\n+\tctx.checkHeader(headers, mdFile)\n+\tctx.addRelativeLinks(relativeLinks, mdFile)\n+\n+\treturn nil\n+}\n+\n+const groupKey = \"group\"\n+\n+var headerKeys = StringSet{\n+\t\"layout\":   {},\n+\t\"title\":    {},\n+\t\"nickname\": {},\n+\tgroupKey:   {},", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjc4NTc2OA=="}, "originalCommit": {"oid": "a1d6b087ef956c7a638fbe407a3a4f783a99bb83"}, "originalPosition": 232}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzNDY4NjQ2OnYy", "diffSide": "RIGHT", "path": "docs/check.go", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQwNToxMzoyN1rOF2lwIA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQwNTozOTowMFrOF2mEvQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjc4NTk1Mg==", "bodyText": "All content between --- is yaml. We should use built-in deserializers if possible.", "url": "https://github.com/Alluxio/alluxio/pull/11169#discussion_r392785952", "createdAt": "2020-03-16T05:13:27Z", "author": {"login": "ZacBlanco"}, "path": "docs/check.go", "diffHunk": "@@ -0,0 +1,294 @@\n+package main\n+\n+import (\n+\t\"bufio\"\n+\t\"fmt\"\n+\t\"log\"\n+\t\"os\"\n+\t\"path/filepath\"\n+\t\"strings\"\n+\t\"regexp\"\n+)\n+\n+func main() {\n+\tif err := run(); err != nil {\n+\t\tlog.Fatalln(err)\n+\t}\n+\tlog.Println(\"Documentation check succeeded\")\n+}\n+\n+type checkContext struct {\n+\t// inputs\n+\tcategoryNames StringSet // category or group names defined in _config.yml\n+\tdocsPath      string    // path to docs directory in repository\n+\n+\t// intermediate\n+\tknownFiles    StringSet                  // file paths of files that can be referenced by markdown files\n+\tmarkdownLinks map[string][]*relativeLink // list of relative links found in each markdown file\n+\n+\t// outputs\n+\tmarkdownErrors map[string][]string // list of errors found in each markdown file\n+}\n+\n+type relativeLink struct {\n+\tline int\n+\tpath string\n+}\n+\n+func (ctx *checkContext) addError(mdFile string, lineNum int, format string, args ...interface{}) {\n+\tmsg := fmt.Sprintf(\"%d: \", lineNum) + fmt.Sprintf(format, args...)\n+\tctx.markdownErrors[mdFile] = append(ctx.markdownErrors[mdFile], msg)\n+}\n+\n+func run() error {\n+\t// check that script is being run from repo root\n+\tconst docsDir, configYml = \"docs\", \"_config.yml\"\n+\trepoRoot, err := os.Getwd()\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"could not get current working directory: %v\", err)\n+\t}\n+\tdocsPath, err := filepath.Abs(filepath.Join(repoRoot, docsDir))\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"could not get absolute path of %v: %v\", filepath.Join(repoRoot, docsDir), err)\n+\t}\n+\tconfigPath := filepath.Join(docsPath, configYml)\n+\tif _, err := os.Stat(configPath); os.IsNotExist(err) {\n+\t\treturn fmt.Errorf(\"expected to find %s in %s; script should be executed from repository root\", configYml, docsDir)\n+\t}\n+\n+\t// parse category names from config file\n+\tcategoryNames, err := parseCategoryNames(configPath)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"error parsing category names: %v\", err)\n+\t}\n+\n+\tctx := &checkContext{\n+\t\tcategoryNames:  categoryNames,\n+\t\tdocsPath:       docsPath,\n+\t\tknownFiles:     StringSet{},\n+\t\tmarkdownLinks:  map[string][]*relativeLink{},\n+\t\tmarkdownErrors: map[string][]string{},\n+\t}\n+\n+\t// scan through markdown files\n+\tfor _, langDir := range []string{\"en\", \"cn\"} {\n+\t\tif err := filepath.Walk(filepath.Join(docsPath, langDir),\n+\t\t\tfunc(p string, info os.FileInfo, err error) error {\n+\t\t\t\tif err != nil {\n+\t\t\t\t\treturn err\n+\t\t\t\t}\n+\t\t\t\tif info.IsDir() {\n+\t\t\t\t\treturn nil\n+\t\t\t\t}\n+\t\t\t\tif strings.HasSuffix(info.Name(), \".md\") {\n+\t\t\t\t\tif err := checkFile(p, ctx); err != nil {\n+\t\t\t\t\t\treturn err\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t\treturn nil\n+\t\t\t},\n+\t\t); err != nil {\n+\t\t\treturn fmt.Errorf(\"error traversing through md files in %v: %v\", filepath.Join(docsPath, langDir), err)\n+\t\t}\n+\t}\n+\t// scan through img and resources directories to update known files\n+\tfor _, dir := range []string{\"img\", \"resources\"} {\n+\t\tif err := filepath.Walk(filepath.Join(docsPath, dir),\n+\t\t\tfunc(p string, info os.FileInfo, err error) error {\n+\t\t\t\tif err != nil {\n+\t\t\t\t\treturn err\n+\t\t\t\t}\n+\t\t\t\tif info.IsDir() {\n+\t\t\t\t\treturn nil\n+\t\t\t\t}\n+\t\t\t\tctx.knownFiles.Add(strings.TrimPrefix(p, docsPath))\n+\t\t\t\treturn nil\n+\t\t\t},\n+\t\t); err != nil {\n+\t\t\treturn fmt.Errorf(\"error traversing through files in %v: %v\", filepath.Join(docsPath, dir), err)\n+\t\t}\n+\t}\n+\n+\tctx.checkLinks()\n+\n+\tif len(ctx.markdownErrors) > 0 {\n+\t\terrLines := []string{\"Errors found in documentation markdown\"}\n+\t\tfor f, errs := range ctx.markdownErrors {\n+\t\t\terrLines = append(errLines, fmt.Sprintf(\"  %v:\", strings.TrimPrefix(f, repoRoot)))\n+\t\t\tfor _, err := range errs {\n+\t\t\t\terrLines = append(errLines, fmt.Sprintf(\"    %s\", err))\n+\t\t\t}\n+\t\t}\n+\t\treturn fmt.Errorf(\"%v\", strings.Join(errLines, \"\\n\"))\n+\t}\n+\n+\treturn nil\n+}\n+\n+// parseCategoryNames parses the given config file for the list of category names\n+func parseCategoryNames(configPath string) (StringSet, error) {\n+\tf, err := os.Open(configPath)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"error opening file at %v: %v\", configPath, err)\n+\t}\n+\tdefer f.Close()\n+\n+\tconst categoryListLine, categoryPrefix = \"categoryList:\", \"  - \"\n+\tcategoryNames := StringSet{}\n+\n+\tfound := false\n+\tscanner := bufio.NewScanner(f)\n+\tfor scanner.Scan() {\n+\t\tl := scanner.Text()\n+\t\tif l == categoryListLine {\n+\t\t\tfound = true\n+\t\t\tcontinue\n+\t\t}\n+\t\tif found {\n+\t\t\tif !strings.HasPrefix(l, categoryPrefix) {\n+\t\t\t\tfound = false\n+\t\t\t\tcontinue\n+\t\t\t}\n+\t\t\tcategoryNames.Add(strings.TrimPrefix(l, categoryPrefix))\n+\t\t}\n+\t}\n+\tif err := scanner.Err(); err != nil {\n+\t\treturn nil, fmt.Errorf(\"error scanning file: %v\", err)\n+\t}\n+\treturn categoryNames, nil\n+}\n+\n+var (\n+\t// general format of a relative link, where the link will be computed by a jekyll function encapsulated in {{ }}\n+\trelativeLinkRe = regexp.MustCompile(`\\[.+\\]\\({{.*}}\\)`)\n+\t// path encapsulated in ' ' could have an optional search query \"?q=queryStr\" and/or an optional anchor reference \"#anchor\"\n+\trelativeLinkPagePathRe = regexp.MustCompile(`\\[.+\\]\\({{ '(?P<path>[\\w-./]+)(\\?q=\\w+)?(#.+)?' | relativize_url }}\\)`)\n+)\n+\n+// checkFile parses the given markdown file and appends errors found in its contents\n+func checkFile(mdFile string, ctx *checkContext) error {\n+\tf, err := os.Open(mdFile)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"error opening file at %v: %v\", mdFile, err)\n+\t}\n+\tdefer f.Close()\n+\n+\tvar headers []string\n+\tvar relativeLinks []*relativeLink\n+\tinHeaderSection := true\n+\tscanner := bufio.NewScanner(f)\n+\tfor i := 1; scanner.Scan(); i++ {\n+\t\tl := scanner.Text()\n+\t\tif inHeaderSection {\n+\t\t\t// first empty line ends the header section\n+\t\t\tif l == \"\" {\n+\t\t\t\tinHeaderSection = false\n+\t\t\t} else {\n+\t\t\t\theaders = append(headers, l)\n+\t\t\t}\n+\t\t}\n+\t\tif relativeLinkRe.MatchString(l) {\n+\t\t\tfor _, lineMatches := range relativeLinkRe.FindAllStringSubmatch(l, -1) {\n+\t\t\t\tif len(lineMatches) != 1 {\n+\t\t\t\t\treturn fmt.Errorf(\"expected to find exactly one string submatch but found %d in line %v\", len(lineMatches), l)\n+\t\t\t\t}\n+\t\t\t\trelativeLinkStr := lineMatches[0]\n+\t\t\t\tif !relativeLinkPagePathRe.MatchString(relativeLinkStr) {\n+\t\t\t\t\tctx.addError(mdFile, i, \"relative link did not match expected pattern %q\", relativeLinkStr)\n+\t\t\t\t\tcontinue\n+\t\t\t\t}\n+\t\t\t\tlinkMatches := relativeLinkPagePathRe.FindStringSubmatch(relativeLinkStr)\n+\t\t\t\tif len(linkMatches) < 2 {\n+\t\t\t\t\treturn fmt.Errorf(\"expected to find at least two string submatches but found %d = %v in link %v\", len(linkMatches), linkMatches, relativeLinkStr)\n+\t\t\t\t}\n+\t\t\t\t// note that first is the full match, second is the named match\n+\t\t\t\tnamedMatch := linkMatches[1]\n+\t\t\t\tif namedMatch == \"\" {\n+\t\t\t\t\treturn fmt.Errorf(\"encountered empty named match when parsing link from %v\", relativeLinkStr)\n+\t\t\t\t}\n+\t\t\t\trelativeLinks = append(relativeLinks, &relativeLink{\n+\t\t\t\t\tline: i,\n+\t\t\t\t\tpath: namedMatch,\n+\t\t\t\t})\n+\t\t\t}\n+\t\t}\n+\t}\n+\tif err := scanner.Err(); err != nil {\n+\t\treturn fmt.Errorf(\"error scanning file: %v\", err)\n+\t}\n+\n+\tctx.checkHeader(headers, mdFile)\n+\tctx.addRelativeLinks(relativeLinks, mdFile)\n+\n+\treturn nil\n+}\n+\n+const groupKey = \"group\"\n+\n+var headerKeys = StringSet{\n+\t\"layout\":   {},\n+\t\"title\":    {},\n+\t\"nickname\": {},\n+\tgroupKey:   {},\n+\t\"priority\": {},\n+}\n+\n+// checkHeader validates the header lines\n+func (ctx *checkContext) checkHeader(headers []string, mdFile string) {\n+\tfor i := 0; i < len(headers); i++ {\n+\t\tl := headers[i]\n+\t\tif i == 0 || i == len(headers)-1 {\n+\t\t\tif l != \"---\" {\n+\t\t\t\tctx.addError(mdFile, i, \"header section should be surrounded by --- but was %v\", l)\n+\t\t\t}\n+\t\t\tcontinue\n+\t\t}\n+\t\tsplit := strings.Split(l, \": \")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a1d6b087ef956c7a638fbe407a3a4f783a99bb83"}, "originalPosition": 246}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjc5MTIyOQ==", "bodyText": "same comment as above", "url": "https://github.com/Alluxio/alluxio/pull/11169#discussion_r392791229", "createdAt": "2020-03-16T05:39:00Z", "author": {"login": "Xenorith"}, "path": "docs/check.go", "diffHunk": "@@ -0,0 +1,294 @@\n+package main\n+\n+import (\n+\t\"bufio\"\n+\t\"fmt\"\n+\t\"log\"\n+\t\"os\"\n+\t\"path/filepath\"\n+\t\"strings\"\n+\t\"regexp\"\n+)\n+\n+func main() {\n+\tif err := run(); err != nil {\n+\t\tlog.Fatalln(err)\n+\t}\n+\tlog.Println(\"Documentation check succeeded\")\n+}\n+\n+type checkContext struct {\n+\t// inputs\n+\tcategoryNames StringSet // category or group names defined in _config.yml\n+\tdocsPath      string    // path to docs directory in repository\n+\n+\t// intermediate\n+\tknownFiles    StringSet                  // file paths of files that can be referenced by markdown files\n+\tmarkdownLinks map[string][]*relativeLink // list of relative links found in each markdown file\n+\n+\t// outputs\n+\tmarkdownErrors map[string][]string // list of errors found in each markdown file\n+}\n+\n+type relativeLink struct {\n+\tline int\n+\tpath string\n+}\n+\n+func (ctx *checkContext) addError(mdFile string, lineNum int, format string, args ...interface{}) {\n+\tmsg := fmt.Sprintf(\"%d: \", lineNum) + fmt.Sprintf(format, args...)\n+\tctx.markdownErrors[mdFile] = append(ctx.markdownErrors[mdFile], msg)\n+}\n+\n+func run() error {\n+\t// check that script is being run from repo root\n+\tconst docsDir, configYml = \"docs\", \"_config.yml\"\n+\trepoRoot, err := os.Getwd()\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"could not get current working directory: %v\", err)\n+\t}\n+\tdocsPath, err := filepath.Abs(filepath.Join(repoRoot, docsDir))\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"could not get absolute path of %v: %v\", filepath.Join(repoRoot, docsDir), err)\n+\t}\n+\tconfigPath := filepath.Join(docsPath, configYml)\n+\tif _, err := os.Stat(configPath); os.IsNotExist(err) {\n+\t\treturn fmt.Errorf(\"expected to find %s in %s; script should be executed from repository root\", configYml, docsDir)\n+\t}\n+\n+\t// parse category names from config file\n+\tcategoryNames, err := parseCategoryNames(configPath)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"error parsing category names: %v\", err)\n+\t}\n+\n+\tctx := &checkContext{\n+\t\tcategoryNames:  categoryNames,\n+\t\tdocsPath:       docsPath,\n+\t\tknownFiles:     StringSet{},\n+\t\tmarkdownLinks:  map[string][]*relativeLink{},\n+\t\tmarkdownErrors: map[string][]string{},\n+\t}\n+\n+\t// scan through markdown files\n+\tfor _, langDir := range []string{\"en\", \"cn\"} {\n+\t\tif err := filepath.Walk(filepath.Join(docsPath, langDir),\n+\t\t\tfunc(p string, info os.FileInfo, err error) error {\n+\t\t\t\tif err != nil {\n+\t\t\t\t\treturn err\n+\t\t\t\t}\n+\t\t\t\tif info.IsDir() {\n+\t\t\t\t\treturn nil\n+\t\t\t\t}\n+\t\t\t\tif strings.HasSuffix(info.Name(), \".md\") {\n+\t\t\t\t\tif err := checkFile(p, ctx); err != nil {\n+\t\t\t\t\t\treturn err\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t\treturn nil\n+\t\t\t},\n+\t\t); err != nil {\n+\t\t\treturn fmt.Errorf(\"error traversing through md files in %v: %v\", filepath.Join(docsPath, langDir), err)\n+\t\t}\n+\t}\n+\t// scan through img and resources directories to update known files\n+\tfor _, dir := range []string{\"img\", \"resources\"} {\n+\t\tif err := filepath.Walk(filepath.Join(docsPath, dir),\n+\t\t\tfunc(p string, info os.FileInfo, err error) error {\n+\t\t\t\tif err != nil {\n+\t\t\t\t\treturn err\n+\t\t\t\t}\n+\t\t\t\tif info.IsDir() {\n+\t\t\t\t\treturn nil\n+\t\t\t\t}\n+\t\t\t\tctx.knownFiles.Add(strings.TrimPrefix(p, docsPath))\n+\t\t\t\treturn nil\n+\t\t\t},\n+\t\t); err != nil {\n+\t\t\treturn fmt.Errorf(\"error traversing through files in %v: %v\", filepath.Join(docsPath, dir), err)\n+\t\t}\n+\t}\n+\n+\tctx.checkLinks()\n+\n+\tif len(ctx.markdownErrors) > 0 {\n+\t\terrLines := []string{\"Errors found in documentation markdown\"}\n+\t\tfor f, errs := range ctx.markdownErrors {\n+\t\t\terrLines = append(errLines, fmt.Sprintf(\"  %v:\", strings.TrimPrefix(f, repoRoot)))\n+\t\t\tfor _, err := range errs {\n+\t\t\t\terrLines = append(errLines, fmt.Sprintf(\"    %s\", err))\n+\t\t\t}\n+\t\t}\n+\t\treturn fmt.Errorf(\"%v\", strings.Join(errLines, \"\\n\"))\n+\t}\n+\n+\treturn nil\n+}\n+\n+// parseCategoryNames parses the given config file for the list of category names\n+func parseCategoryNames(configPath string) (StringSet, error) {\n+\tf, err := os.Open(configPath)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"error opening file at %v: %v\", configPath, err)\n+\t}\n+\tdefer f.Close()\n+\n+\tconst categoryListLine, categoryPrefix = \"categoryList:\", \"  - \"\n+\tcategoryNames := StringSet{}\n+\n+\tfound := false\n+\tscanner := bufio.NewScanner(f)\n+\tfor scanner.Scan() {\n+\t\tl := scanner.Text()\n+\t\tif l == categoryListLine {\n+\t\t\tfound = true\n+\t\t\tcontinue\n+\t\t}\n+\t\tif found {\n+\t\t\tif !strings.HasPrefix(l, categoryPrefix) {\n+\t\t\t\tfound = false\n+\t\t\t\tcontinue\n+\t\t\t}\n+\t\t\tcategoryNames.Add(strings.TrimPrefix(l, categoryPrefix))\n+\t\t}\n+\t}\n+\tif err := scanner.Err(); err != nil {\n+\t\treturn nil, fmt.Errorf(\"error scanning file: %v\", err)\n+\t}\n+\treturn categoryNames, nil\n+}\n+\n+var (\n+\t// general format of a relative link, where the link will be computed by a jekyll function encapsulated in {{ }}\n+\trelativeLinkRe = regexp.MustCompile(`\\[.+\\]\\({{.*}}\\)`)\n+\t// path encapsulated in ' ' could have an optional search query \"?q=queryStr\" and/or an optional anchor reference \"#anchor\"\n+\trelativeLinkPagePathRe = regexp.MustCompile(`\\[.+\\]\\({{ '(?P<path>[\\w-./]+)(\\?q=\\w+)?(#.+)?' | relativize_url }}\\)`)\n+)\n+\n+// checkFile parses the given markdown file and appends errors found in its contents\n+func checkFile(mdFile string, ctx *checkContext) error {\n+\tf, err := os.Open(mdFile)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"error opening file at %v: %v\", mdFile, err)\n+\t}\n+\tdefer f.Close()\n+\n+\tvar headers []string\n+\tvar relativeLinks []*relativeLink\n+\tinHeaderSection := true\n+\tscanner := bufio.NewScanner(f)\n+\tfor i := 1; scanner.Scan(); i++ {\n+\t\tl := scanner.Text()\n+\t\tif inHeaderSection {\n+\t\t\t// first empty line ends the header section\n+\t\t\tif l == \"\" {\n+\t\t\t\tinHeaderSection = false\n+\t\t\t} else {\n+\t\t\t\theaders = append(headers, l)\n+\t\t\t}\n+\t\t}\n+\t\tif relativeLinkRe.MatchString(l) {\n+\t\t\tfor _, lineMatches := range relativeLinkRe.FindAllStringSubmatch(l, -1) {\n+\t\t\t\tif len(lineMatches) != 1 {\n+\t\t\t\t\treturn fmt.Errorf(\"expected to find exactly one string submatch but found %d in line %v\", len(lineMatches), l)\n+\t\t\t\t}\n+\t\t\t\trelativeLinkStr := lineMatches[0]\n+\t\t\t\tif !relativeLinkPagePathRe.MatchString(relativeLinkStr) {\n+\t\t\t\t\tctx.addError(mdFile, i, \"relative link did not match expected pattern %q\", relativeLinkStr)\n+\t\t\t\t\tcontinue\n+\t\t\t\t}\n+\t\t\t\tlinkMatches := relativeLinkPagePathRe.FindStringSubmatch(relativeLinkStr)\n+\t\t\t\tif len(linkMatches) < 2 {\n+\t\t\t\t\treturn fmt.Errorf(\"expected to find at least two string submatches but found %d = %v in link %v\", len(linkMatches), linkMatches, relativeLinkStr)\n+\t\t\t\t}\n+\t\t\t\t// note that first is the full match, second is the named match\n+\t\t\t\tnamedMatch := linkMatches[1]\n+\t\t\t\tif namedMatch == \"\" {\n+\t\t\t\t\treturn fmt.Errorf(\"encountered empty named match when parsing link from %v\", relativeLinkStr)\n+\t\t\t\t}\n+\t\t\t\trelativeLinks = append(relativeLinks, &relativeLink{\n+\t\t\t\t\tline: i,\n+\t\t\t\t\tpath: namedMatch,\n+\t\t\t\t})\n+\t\t\t}\n+\t\t}\n+\t}\n+\tif err := scanner.Err(); err != nil {\n+\t\treturn fmt.Errorf(\"error scanning file: %v\", err)\n+\t}\n+\n+\tctx.checkHeader(headers, mdFile)\n+\tctx.addRelativeLinks(relativeLinks, mdFile)\n+\n+\treturn nil\n+}\n+\n+const groupKey = \"group\"\n+\n+var headerKeys = StringSet{\n+\t\"layout\":   {},\n+\t\"title\":    {},\n+\t\"nickname\": {},\n+\tgroupKey:   {},\n+\t\"priority\": {},\n+}\n+\n+// checkHeader validates the header lines\n+func (ctx *checkContext) checkHeader(headers []string, mdFile string) {\n+\tfor i := 0; i < len(headers); i++ {\n+\t\tl := headers[i]\n+\t\tif i == 0 || i == len(headers)-1 {\n+\t\t\tif l != \"---\" {\n+\t\t\t\tctx.addError(mdFile, i, \"header section should be surrounded by --- but was %v\", l)\n+\t\t\t}\n+\t\t\tcontinue\n+\t\t}\n+\t\tsplit := strings.Split(l, \": \")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjc4NTk1Mg=="}, "originalCommit": {"oid": "a1d6b087ef956c7a638fbe407a3a4f783a99bb83"}, "originalPosition": 246}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1946, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}