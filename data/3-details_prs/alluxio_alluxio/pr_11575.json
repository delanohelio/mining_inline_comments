{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDM1NTM5Njk5", "number": 11575, "title": "Clean up files in parallel to avoid large recursive delete", "bodyText": "", "createdAt": "2020-06-17T00:52:57Z", "url": "https://github.com/Alluxio/alluxio/pull/11575", "merged": true, "mergeCommit": {"oid": "1cc29d37efcdf8714883feeac199c0a465d8588d"}, "closed": true, "closedAt": "2020-06-18T23:39:48Z", "author": {"login": "gpang"}, "timelineItems": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcr85smgH2gAyNDM1NTM5Njk5OmNhYWQ1ZmNlZjk4ZjJhMDU1YTUyMDI5YzA3NWM4YzdlZDVkMDU3M2Q=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcslEFfAFqTQzMzYzNzQ4MQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "caad5fcef98f2a055a52029c075c8c7ed5d0573d", "author": {"user": {"login": "gpang", "name": "Gene Pang"}}, "url": "https://github.com/Alluxio/alluxio/commit/caad5fcef98f2a055a52029c075c8c7ed5d0573d", "committedDate": "2020-06-16T22:22:09Z", "message": "Clean up files in parallel"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b73c2948edd25e79879a80ab39978c1252442387", "author": {"user": {"login": "gpang", "name": "Gene Pang"}}, "url": "https://github.com/Alluxio/alluxio/commit/b73c2948edd25e79879a80ab39978c1252442387", "committedDate": "2020-06-16T22:57:26Z", "message": "Handle empty directories"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "045a22ae2bed96a3aa5353d18053a8280bf910f5", "author": {"user": {"login": "gpang", "name": "Gene Pang"}}, "url": "https://github.com/Alluxio/alluxio/commit/045a22ae2bed96a3aa5353d18053a8280bf910f5", "committedDate": "2020-06-17T00:51:33Z", "message": "Don't wait too long"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMzNTUxMjM1", "url": "https://github.com/Alluxio/alluxio/pull/11575#pullrequestreview-433551235", "createdAt": "2020-06-18T18:41:32Z", "commit": {"oid": "045a22ae2bed96a3aa5353d18053a8280bf910f5"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQxODo0MTozMlrOGl7smg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQxODo1NzozOFrOGl8O5w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQyODU3MA==", "bodyText": "Is this correct for this to happen for every subdir?", "url": "https://github.com/Alluxio/alluxio/pull/11575#discussion_r442428570", "createdAt": "2020-06-18T18:41:32Z", "author": {"login": "bradyoo"}, "path": "stress/shell/src/main/java/alluxio/stress/cli/StressMasterBench.java", "diffHunk": "@@ -130,6 +135,76 @@ public void prepare() throws Exception {\n     }\n   }\n \n+  private void deletePaths(FileSystem fs, Path basePath) throws Exception {\n+    // the base dir has sub directories per task id\n+    if (!fs.exists(basePath)) {\n+      return;\n+    }\n+    FileStatus[] subDirs = fs.listStatus(basePath);\n+    if (subDirs.length == 0) {\n+      return;\n+    }\n+\n+    // determine the fixed portion size\n+    int fixedSize = fs.listStatus(new Path(subDirs[0].getPath(), \"fixed\")).length;\n+\n+    long batchSize = 50_000;\n+    int deleteThreads = 256;\n+    ExecutorService service =\n+        ExecutorServiceFactories.fixedThreadPool(\"bench-delete-thread\", deleteThreads).create();\n+\n+    for (FileStatus subDir : subDirs) {\n+      LOG.info(\"Cleaning up all files in: {}\", subDir.getPath());\n+      AtomicLong globalCounter = new AtomicLong();\n+      Path fixedBase = new Path(subDir.getPath(), \"fixed\");\n+      long runningLimit = 0;\n+\n+      // delete individual files in batches, to avoid the recursive-delete problem\n+      while (!Thread.currentThread().isInterrupted()) {\n+        AtomicLong success = new AtomicLong();\n+        runningLimit += batchSize;\n+        long limit = runningLimit;\n+\n+        List<Callable<Void>> callables = new ArrayList<>(deleteThreads);\n+        for (int i = 0; i < deleteThreads; i++) {\n+          callables.add(() -> {\n+            while (!Thread.currentThread().isInterrupted()) {\n+              long counter = globalCounter.getAndIncrement();\n+              if (counter >= limit) {\n+                globalCounter.getAndDecrement();\n+                return null;\n+              }\n+              Path deletePath;\n+              if (counter < fixedSize) {\n+                deletePath = new Path(fixedBase, Long.toString(counter));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "045a22ae2bed96a3aa5353d18053a8280bf910f5"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQzMTQ2Ng==", "bodyText": "This design definitely misses some files because the 1 minute could end and the code could be in between globalCounter.getAndIncrement and delete. Is that okay?", "url": "https://github.com/Alluxio/alluxio/pull/11575#discussion_r442431466", "createdAt": "2020-06-18T18:46:59Z", "author": {"login": "bradyoo"}, "path": "stress/shell/src/main/java/alluxio/stress/cli/StressMasterBench.java", "diffHunk": "@@ -130,6 +135,76 @@ public void prepare() throws Exception {\n     }\n   }\n \n+  private void deletePaths(FileSystem fs, Path basePath) throws Exception {\n+    // the base dir has sub directories per task id\n+    if (!fs.exists(basePath)) {\n+      return;\n+    }\n+    FileStatus[] subDirs = fs.listStatus(basePath);\n+    if (subDirs.length == 0) {\n+      return;\n+    }\n+\n+    // determine the fixed portion size\n+    int fixedSize = fs.listStatus(new Path(subDirs[0].getPath(), \"fixed\")).length;\n+\n+    long batchSize = 50_000;\n+    int deleteThreads = 256;\n+    ExecutorService service =\n+        ExecutorServiceFactories.fixedThreadPool(\"bench-delete-thread\", deleteThreads).create();\n+\n+    for (FileStatus subDir : subDirs) {\n+      LOG.info(\"Cleaning up all files in: {}\", subDir.getPath());\n+      AtomicLong globalCounter = new AtomicLong();\n+      Path fixedBase = new Path(subDir.getPath(), \"fixed\");\n+      long runningLimit = 0;\n+\n+      // delete individual files in batches, to avoid the recursive-delete problem\n+      while (!Thread.currentThread().isInterrupted()) {\n+        AtomicLong success = new AtomicLong();\n+        runningLimit += batchSize;\n+        long limit = runningLimit;\n+\n+        List<Callable<Void>> callables = new ArrayList<>(deleteThreads);\n+        for (int i = 0; i < deleteThreads; i++) {\n+          callables.add(() -> {\n+            while (!Thread.currentThread().isInterrupted()) {\n+              long counter = globalCounter.getAndIncrement();\n+              if (counter >= limit) {\n+                globalCounter.getAndDecrement();\n+                return null;\n+              }\n+              Path deletePath;\n+              if (counter < fixedSize) {\n+                deletePath = new Path(fixedBase, Long.toString(counter));\n+              } else {\n+                deletePath = new Path(subDir.getPath(), Long.toString(counter));\n+              }\n+              if (fs.delete(deletePath, true)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "045a22ae2bed96a3aa5353d18053a8280bf910f5"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQzNTUxNQ==", "bodyText": "Should this later be moved to some cleanup step? (As opposed to prepare step)", "url": "https://github.com/Alluxio/alluxio/pull/11575#discussion_r442435515", "createdAt": "2020-06-18T18:54:29Z", "author": {"login": "bradyoo"}, "path": "stress/shell/src/main/java/alluxio/stress/cli/StressMasterBench.java", "diffHunk": "@@ -98,7 +100,10 @@ public void prepare() throws Exception {\n \n       if (mParameters.mOperation == Operation.CreateFile\n           || mParameters.mOperation == Operation.CreateDir) {\n-        prepareFs.delete(basePath, true);\n+        long start = CommonUtils.getCurrentMs();\n+        deletePaths(prepareFs, basePath);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "045a22ae2bed96a3aa5353d18053a8280bf910f5"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQzNzM1MQ==", "bodyText": "Despite what the doc seems to say, invokeAll doesn't necessarily guarantee that all the futures are done. So I think here, we should be checking if all of the futures are done. Log if some are not done and shutdown/reconfigure the service on every loop.", "url": "https://github.com/Alluxio/alluxio/pull/11575#discussion_r442437351", "createdAt": "2020-06-18T18:57:38Z", "author": {"login": "bradyoo"}, "path": "stress/shell/src/main/java/alluxio/stress/cli/StressMasterBench.java", "diffHunk": "@@ -130,6 +135,76 @@ public void prepare() throws Exception {\n     }\n   }\n \n+  private void deletePaths(FileSystem fs, Path basePath) throws Exception {\n+    // the base dir has sub directories per task id\n+    if (!fs.exists(basePath)) {\n+      return;\n+    }\n+    FileStatus[] subDirs = fs.listStatus(basePath);\n+    if (subDirs.length == 0) {\n+      return;\n+    }\n+\n+    // determine the fixed portion size\n+    int fixedSize = fs.listStatus(new Path(subDirs[0].getPath(), \"fixed\")).length;\n+\n+    long batchSize = 50_000;\n+    int deleteThreads = 256;\n+    ExecutorService service =\n+        ExecutorServiceFactories.fixedThreadPool(\"bench-delete-thread\", deleteThreads).create();\n+\n+    for (FileStatus subDir : subDirs) {\n+      LOG.info(\"Cleaning up all files in: {}\", subDir.getPath());\n+      AtomicLong globalCounter = new AtomicLong();\n+      Path fixedBase = new Path(subDir.getPath(), \"fixed\");\n+      long runningLimit = 0;\n+\n+      // delete individual files in batches, to avoid the recursive-delete problem\n+      while (!Thread.currentThread().isInterrupted()) {\n+        AtomicLong success = new AtomicLong();\n+        runningLimit += batchSize;\n+        long limit = runningLimit;\n+\n+        List<Callable<Void>> callables = new ArrayList<>(deleteThreads);\n+        for (int i = 0; i < deleteThreads; i++) {\n+          callables.add(() -> {\n+            while (!Thread.currentThread().isInterrupted()) {\n+              long counter = globalCounter.getAndIncrement();\n+              if (counter >= limit) {\n+                globalCounter.getAndDecrement();\n+                return null;\n+              }\n+              Path deletePath;\n+              if (counter < fixedSize) {\n+                deletePath = new Path(fixedBase, Long.toString(counter));\n+              } else {\n+                deletePath = new Path(subDir.getPath(), Long.toString(counter));\n+              }\n+              if (fs.delete(deletePath, true)) {\n+                success.getAndIncrement();\n+              }\n+            }\n+            return null;\n+          });\n+        }\n+        service.invokeAll(callables, 1, TimeUnit.MINUTES);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "045a22ae2bed96a3aa5353d18053a8280bf910f5"}, "originalPosition": 77}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMzNTY2Njc3", "url": "https://github.com/Alluxio/alluxio/pull/11575#pullrequestreview-433566677", "createdAt": "2020-06-18T19:03:18Z", "commit": {"oid": "045a22ae2bed96a3aa5353d18053a8280bf910f5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQxOTowMzoxOVrOGl8a_A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQxOTowMzoxOVrOGl8a_A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQ0MDQ0NA==", "bodyText": "I guess this covers the case of skips.", "url": "https://github.com/Alluxio/alluxio/pull/11575#discussion_r442440444", "createdAt": "2020-06-18T19:03:19Z", "author": {"login": "bradyoo"}, "path": "stress/shell/src/main/java/alluxio/stress/cli/StressMasterBench.java", "diffHunk": "@@ -130,6 +135,76 @@ public void prepare() throws Exception {\n     }\n   }\n \n+  private void deletePaths(FileSystem fs, Path basePath) throws Exception {\n+    // the base dir has sub directories per task id\n+    if (!fs.exists(basePath)) {\n+      return;\n+    }\n+    FileStatus[] subDirs = fs.listStatus(basePath);\n+    if (subDirs.length == 0) {\n+      return;\n+    }\n+\n+    // determine the fixed portion size\n+    int fixedSize = fs.listStatus(new Path(subDirs[0].getPath(), \"fixed\")).length;\n+\n+    long batchSize = 50_000;\n+    int deleteThreads = 256;\n+    ExecutorService service =\n+        ExecutorServiceFactories.fixedThreadPool(\"bench-delete-thread\", deleteThreads).create();\n+\n+    for (FileStatus subDir : subDirs) {\n+      LOG.info(\"Cleaning up all files in: {}\", subDir.getPath());\n+      AtomicLong globalCounter = new AtomicLong();\n+      Path fixedBase = new Path(subDir.getPath(), \"fixed\");\n+      long runningLimit = 0;\n+\n+      // delete individual files in batches, to avoid the recursive-delete problem\n+      while (!Thread.currentThread().isInterrupted()) {\n+        AtomicLong success = new AtomicLong();\n+        runningLimit += batchSize;\n+        long limit = runningLimit;\n+\n+        List<Callable<Void>> callables = new ArrayList<>(deleteThreads);\n+        for (int i = 0; i < deleteThreads; i++) {\n+          callables.add(() -> {\n+            while (!Thread.currentThread().isInterrupted()) {\n+              long counter = globalCounter.getAndIncrement();\n+              if (counter >= limit) {\n+                globalCounter.getAndDecrement();\n+                return null;\n+              }\n+              Path deletePath;\n+              if (counter < fixedSize) {\n+                deletePath = new Path(fixedBase, Long.toString(counter));\n+              } else {\n+                deletePath = new Path(subDir.getPath(), Long.toString(counter));\n+              }\n+              if (fs.delete(deletePath, true)) {\n+                success.getAndIncrement();\n+              }\n+            }\n+            return null;\n+          });\n+        }\n+        service.invokeAll(callables, 1, TimeUnit.MINUTES);\n+\n+        if (success.get() == 0) {\n+          // stop deleting one-by-one if none of the batch succeeded.\n+          break;\n+        }\n+        LOG.info(\"Removed {} files\", success.get());\n+      }\n+    }\n+\n+    service.shutdownNow();\n+    service.awaitTermination(10, TimeUnit.SECONDS);\n+\n+    // Cleanup the rest recursively, which should be empty or much smaller than the full tree.\n+    LOG.info(\"Deleting base directory: {}\", basePath);\n+    fs.delete(basePath, true);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "045a22ae2bed96a3aa5353d18053a8280bf910f5"}, "originalPosition": 92}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b34baa0d842347e6cff8c80c09f5b5c8418b6ff1", "author": {"user": {"login": "gpang", "name": "Gene Pang"}}, "url": "https://github.com/Alluxio/alluxio/commit/b34baa0d842347e6cff8c80c09f5b5c8418b6ff1", "committedDate": "2020-06-18T21:09:14Z", "message": "Update comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMzNjM3NDgx", "url": "https://github.com/Alluxio/alluxio/pull/11575#pullrequestreview-433637481", "createdAt": "2020-06-18T20:51:00Z", "commit": {"oid": "045a22ae2bed96a3aa5353d18053a8280bf910f5"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQyMDo1MTowMVrOGl_wmQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQyMTowNjoyN1rOGmANxg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQ5NTEyOQ==", "bodyText": "We actually don't want to cleanup all the time, since some operations like listDir uses the results of CreateFile. That is why we don't delete when the operation is listDir.", "url": "https://github.com/Alluxio/alluxio/pull/11575#discussion_r442495129", "createdAt": "2020-06-18T20:51:01Z", "author": {"login": "gpang"}, "path": "stress/shell/src/main/java/alluxio/stress/cli/StressMasterBench.java", "diffHunk": "@@ -98,7 +100,10 @@ public void prepare() throws Exception {\n \n       if (mParameters.mOperation == Operation.CreateFile\n           || mParameters.mOperation == Operation.CreateDir) {\n-        prepareFs.delete(basePath, true);\n+        long start = CommonUtils.getCurrentMs();\n+        deletePaths(prepareFs, basePath);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQzNTUxNQ=="}, "originalCommit": {"oid": "045a22ae2bed96a3aa5353d18053a8280bf910f5"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQ5NTI2Mg==", "bodyText": "Yes, each sub-dir has a fixed portion.", "url": "https://github.com/Alluxio/alluxio/pull/11575#discussion_r442495262", "createdAt": "2020-06-18T20:51:17Z", "author": {"login": "gpang"}, "path": "stress/shell/src/main/java/alluxio/stress/cli/StressMasterBench.java", "diffHunk": "@@ -130,6 +135,76 @@ public void prepare() throws Exception {\n     }\n   }\n \n+  private void deletePaths(FileSystem fs, Path basePath) throws Exception {\n+    // the base dir has sub directories per task id\n+    if (!fs.exists(basePath)) {\n+      return;\n+    }\n+    FileStatus[] subDirs = fs.listStatus(basePath);\n+    if (subDirs.length == 0) {\n+      return;\n+    }\n+\n+    // determine the fixed portion size\n+    int fixedSize = fs.listStatus(new Path(subDirs[0].getPath(), \"fixed\")).length;\n+\n+    long batchSize = 50_000;\n+    int deleteThreads = 256;\n+    ExecutorService service =\n+        ExecutorServiceFactories.fixedThreadPool(\"bench-delete-thread\", deleteThreads).create();\n+\n+    for (FileStatus subDir : subDirs) {\n+      LOG.info(\"Cleaning up all files in: {}\", subDir.getPath());\n+      AtomicLong globalCounter = new AtomicLong();\n+      Path fixedBase = new Path(subDir.getPath(), \"fixed\");\n+      long runningLimit = 0;\n+\n+      // delete individual files in batches, to avoid the recursive-delete problem\n+      while (!Thread.currentThread().isInterrupted()) {\n+        AtomicLong success = new AtomicLong();\n+        runningLimit += batchSize;\n+        long limit = runningLimit;\n+\n+        List<Callable<Void>> callables = new ArrayList<>(deleteThreads);\n+        for (int i = 0; i < deleteThreads; i++) {\n+          callables.add(() -> {\n+            while (!Thread.currentThread().isInterrupted()) {\n+              long counter = globalCounter.getAndIncrement();\n+              if (counter >= limit) {\n+                globalCounter.getAndDecrement();\n+                return null;\n+              }\n+              Path deletePath;\n+              if (counter < fixedSize) {\n+                deletePath = new Path(fixedBase, Long.toString(counter));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQyODU3MA=="}, "originalCommit": {"oid": "045a22ae2bed96a3aa5353d18053a8280bf910f5"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQ5NjQwNw==", "bodyText": "This is ok. The goal for the parallel delete is reduce the size of the recursive delete later.", "url": "https://github.com/Alluxio/alluxio/pull/11575#discussion_r442496407", "createdAt": "2020-06-18T20:53:43Z", "author": {"login": "gpang"}, "path": "stress/shell/src/main/java/alluxio/stress/cli/StressMasterBench.java", "diffHunk": "@@ -130,6 +135,76 @@ public void prepare() throws Exception {\n     }\n   }\n \n+  private void deletePaths(FileSystem fs, Path basePath) throws Exception {\n+    // the base dir has sub directories per task id\n+    if (!fs.exists(basePath)) {\n+      return;\n+    }\n+    FileStatus[] subDirs = fs.listStatus(basePath);\n+    if (subDirs.length == 0) {\n+      return;\n+    }\n+\n+    // determine the fixed portion size\n+    int fixedSize = fs.listStatus(new Path(subDirs[0].getPath(), \"fixed\")).length;\n+\n+    long batchSize = 50_000;\n+    int deleteThreads = 256;\n+    ExecutorService service =\n+        ExecutorServiceFactories.fixedThreadPool(\"bench-delete-thread\", deleteThreads).create();\n+\n+    for (FileStatus subDir : subDirs) {\n+      LOG.info(\"Cleaning up all files in: {}\", subDir.getPath());\n+      AtomicLong globalCounter = new AtomicLong();\n+      Path fixedBase = new Path(subDir.getPath(), \"fixed\");\n+      long runningLimit = 0;\n+\n+      // delete individual files in batches, to avoid the recursive-delete problem\n+      while (!Thread.currentThread().isInterrupted()) {\n+        AtomicLong success = new AtomicLong();\n+        runningLimit += batchSize;\n+        long limit = runningLimit;\n+\n+        List<Callable<Void>> callables = new ArrayList<>(deleteThreads);\n+        for (int i = 0; i < deleteThreads; i++) {\n+          callables.add(() -> {\n+            while (!Thread.currentThread().isInterrupted()) {\n+              long counter = globalCounter.getAndIncrement();\n+              if (counter >= limit) {\n+                globalCounter.getAndDecrement();\n+                return null;\n+              }\n+              Path deletePath;\n+              if (counter < fixedSize) {\n+                deletePath = new Path(fixedBase, Long.toString(counter));\n+              } else {\n+                deletePath = new Path(subDir.getPath(), Long.toString(counter));\n+              }\n+              if (fs.delete(deletePath, true)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQzMTQ2Ng=="}, "originalCommit": {"oid": "045a22ae2bed96a3aa5353d18053a8280bf910f5"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQ5Njc3OA==", "bodyText": "Yes, this recursive delete takes care of the the base directory itself, as well as any straggler files.", "url": "https://github.com/Alluxio/alluxio/pull/11575#discussion_r442496778", "createdAt": "2020-06-18T20:54:29Z", "author": {"login": "gpang"}, "path": "stress/shell/src/main/java/alluxio/stress/cli/StressMasterBench.java", "diffHunk": "@@ -130,6 +135,76 @@ public void prepare() throws Exception {\n     }\n   }\n \n+  private void deletePaths(FileSystem fs, Path basePath) throws Exception {\n+    // the base dir has sub directories per task id\n+    if (!fs.exists(basePath)) {\n+      return;\n+    }\n+    FileStatus[] subDirs = fs.listStatus(basePath);\n+    if (subDirs.length == 0) {\n+      return;\n+    }\n+\n+    // determine the fixed portion size\n+    int fixedSize = fs.listStatus(new Path(subDirs[0].getPath(), \"fixed\")).length;\n+\n+    long batchSize = 50_000;\n+    int deleteThreads = 256;\n+    ExecutorService service =\n+        ExecutorServiceFactories.fixedThreadPool(\"bench-delete-thread\", deleteThreads).create();\n+\n+    for (FileStatus subDir : subDirs) {\n+      LOG.info(\"Cleaning up all files in: {}\", subDir.getPath());\n+      AtomicLong globalCounter = new AtomicLong();\n+      Path fixedBase = new Path(subDir.getPath(), \"fixed\");\n+      long runningLimit = 0;\n+\n+      // delete individual files in batches, to avoid the recursive-delete problem\n+      while (!Thread.currentThread().isInterrupted()) {\n+        AtomicLong success = new AtomicLong();\n+        runningLimit += batchSize;\n+        long limit = runningLimit;\n+\n+        List<Callable<Void>> callables = new ArrayList<>(deleteThreads);\n+        for (int i = 0; i < deleteThreads; i++) {\n+          callables.add(() -> {\n+            while (!Thread.currentThread().isInterrupted()) {\n+              long counter = globalCounter.getAndIncrement();\n+              if (counter >= limit) {\n+                globalCounter.getAndDecrement();\n+                return null;\n+              }\n+              Path deletePath;\n+              if (counter < fixedSize) {\n+                deletePath = new Path(fixedBase, Long.toString(counter));\n+              } else {\n+                deletePath = new Path(subDir.getPath(), Long.toString(counter));\n+              }\n+              if (fs.delete(deletePath, true)) {\n+                success.getAndIncrement();\n+              }\n+            }\n+            return null;\n+          });\n+        }\n+        service.invokeAll(callables, 1, TimeUnit.MINUTES);\n+\n+        if (success.get() == 0) {\n+          // stop deleting one-by-one if none of the batch succeeded.\n+          break;\n+        }\n+        LOG.info(\"Removed {} files\", success.get());\n+      }\n+    }\n+\n+    service.shutdownNow();\n+    service.awaitTermination(10, TimeUnit.SECONDS);\n+\n+    // Cleanup the rest recursively, which should be empty or much smaller than the full tree.\n+    LOG.info(\"Deleting base directory: {}\", basePath);\n+    fs.delete(basePath, true);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQ0MDQ0NA=="}, "originalCommit": {"oid": "045a22ae2bed96a3aa5353d18053a8280bf910f5"}, "originalPosition": 92}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjUwMjU5OA==", "bodyText": "This is ok. If this times out, it cancels all remaining tasks. That is fine, because the next round will just create more tasks, and any remaining tasks will be taken care of the final recursive delete.", "url": "https://github.com/Alluxio/alluxio/pull/11575#discussion_r442502598", "createdAt": "2020-06-18T21:06:27Z", "author": {"login": "gpang"}, "path": "stress/shell/src/main/java/alluxio/stress/cli/StressMasterBench.java", "diffHunk": "@@ -130,6 +135,76 @@ public void prepare() throws Exception {\n     }\n   }\n \n+  private void deletePaths(FileSystem fs, Path basePath) throws Exception {\n+    // the base dir has sub directories per task id\n+    if (!fs.exists(basePath)) {\n+      return;\n+    }\n+    FileStatus[] subDirs = fs.listStatus(basePath);\n+    if (subDirs.length == 0) {\n+      return;\n+    }\n+\n+    // determine the fixed portion size\n+    int fixedSize = fs.listStatus(new Path(subDirs[0].getPath(), \"fixed\")).length;\n+\n+    long batchSize = 50_000;\n+    int deleteThreads = 256;\n+    ExecutorService service =\n+        ExecutorServiceFactories.fixedThreadPool(\"bench-delete-thread\", deleteThreads).create();\n+\n+    for (FileStatus subDir : subDirs) {\n+      LOG.info(\"Cleaning up all files in: {}\", subDir.getPath());\n+      AtomicLong globalCounter = new AtomicLong();\n+      Path fixedBase = new Path(subDir.getPath(), \"fixed\");\n+      long runningLimit = 0;\n+\n+      // delete individual files in batches, to avoid the recursive-delete problem\n+      while (!Thread.currentThread().isInterrupted()) {\n+        AtomicLong success = new AtomicLong();\n+        runningLimit += batchSize;\n+        long limit = runningLimit;\n+\n+        List<Callable<Void>> callables = new ArrayList<>(deleteThreads);\n+        for (int i = 0; i < deleteThreads; i++) {\n+          callables.add(() -> {\n+            while (!Thread.currentThread().isInterrupted()) {\n+              long counter = globalCounter.getAndIncrement();\n+              if (counter >= limit) {\n+                globalCounter.getAndDecrement();\n+                return null;\n+              }\n+              Path deletePath;\n+              if (counter < fixedSize) {\n+                deletePath = new Path(fixedBase, Long.toString(counter));\n+              } else {\n+                deletePath = new Path(subDir.getPath(), Long.toString(counter));\n+              }\n+              if (fs.delete(deletePath, true)) {\n+                success.getAndIncrement();\n+              }\n+            }\n+            return null;\n+          });\n+        }\n+        service.invokeAll(callables, 1, TimeUnit.MINUTES);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQzNzM1MQ=="}, "originalCommit": {"oid": "045a22ae2bed96a3aa5353d18053a8280bf910f5"}, "originalPosition": 77}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4530, "cost": 1, "resetAt": "2021-10-29T17:30:11Z"}}}