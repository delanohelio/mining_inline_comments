{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDIxMDk1NTk4", "number": 11458, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQwMTozODoyN1rOD-cjUQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQyMTo1NTozOVrOD_3EAg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2ODA2MDk3OnYy", "diffSide": "RIGHT", "path": "core/server/worker/src/main/java/alluxio/worker/block/management/ManagementTaskCoordinator.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQwMTozODoyN1rOGYjZSQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQwMTozODoyN1rOGYjZSQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODM5ODkyMQ==", "bodyText": "Remove this.", "url": "https://github.com/Alluxio/alluxio/pull/11458#discussion_r428398921", "createdAt": "2020-05-21T01:38:27Z", "author": {"login": "ggezer"}, "path": "core/server/worker/src/main/java/alluxio/worker/block/management/ManagementTaskCoordinator.java", "diffHunk": "@@ -187,6 +187,7 @@ private void runManagement() {\n               e);\n         }\n         LOG.debug(\"Management task finished: {}\", currentTask.getClass().getSimpleName());\n+        Thread.sleep(mLoadDetectionCoolDownMs);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1cb1ced342ec0e621ab33fe37d7680c39a9989ae"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4Mjg4NTc3OnYy", "diffSide": "RIGHT", "path": "core/server/worker/src/main/java/alluxio/worker/block/management/BlockTransferPartitioner.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQyMTo1Mzo0OVrOGaxnhg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQyMTo1Mzo0OVrOGaxnhg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcyOTA5NA==", "bodyText": "Prefer Hashmap over Hashtable, unless there is a reason we need the concurrency guarantees for Hashtable?", "url": "https://github.com/Alluxio/alluxio/pull/11458#discussion_r430729094", "createdAt": "2020-05-26T21:53:49Z", "author": {"login": "calvinjia"}, "path": "core/server/worker/src/main/java/alluxio/worker/block/management/BlockTransferPartitioner.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n+package alluxio.worker.block.management;\n+\n+import alluxio.worker.block.BlockStoreLocation;\n+import alluxio.worker.block.evictor.BlockTransferInfo;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Comparator;\n+import java.util.HashSet;\n+import java.util.Hashtable;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Used to partition transfers for concurrent execution.\n+ */\n+public class BlockTransferPartitioner {\n+  private static final Logger LOG = LoggerFactory.getLogger(BlockTransferPartitioner.class);\n+\n+  /**\n+   * It greedily partitions given transfers into sub-lists.\n+   *\n+   * @param transferInfos list of transfers to partition\n+   * @param maxPartitionCount max partition count\n+   * @return transfers partitioned into sub-lists\n+   */\n+  public List<List<BlockTransferInfo>> partitionTransfers(List<BlockTransferInfo> transferInfos,\n+      int maxPartitionCount) {\n+    // Bucketing is possible if source or destination has exact location.\n+    // Those allocated locations will be bucket key[s].\n+    TransferPartitionKey key = findTransferBucketKey(transferInfos);\n+    // Can't bucketize transfers.\n+    if (key == TransferPartitionKey.NONE) {\n+      LOG.debug(\"Un-optimizable transfer list encountered.\");\n+      return new ArrayList<List<BlockTransferInfo>>() {\n+        {\n+          add(transferInfos);\n+        }\n+      };\n+    }\n+\n+    Hashtable<BlockStoreLocation, List<BlockTransferInfo>> transferBuckets = new Hashtable<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a0894d6c397b77db722ca4aef6865c0de16ee124"}, "originalPosition": 59}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4Mjg4ODAyOnYy", "diffSide": "RIGHT", "path": "core/server/worker/src/main/java/alluxio/worker/block/management/BlockTransferPartitioner.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQyMTo1NDo0OVrOGaxo_Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxNzoyNzo0MFrOGbVfXw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcyOTQ2OQ==", "bodyText": "Do we want to count ANY_DIRs?", "url": "https://github.com/Alluxio/alluxio/pull/11458#discussion_r430729469", "createdAt": "2020-05-26T21:54:49Z", "author": {"login": "calvinjia"}, "path": "core/server/worker/src/main/java/alluxio/worker/block/management/BlockTransferPartitioner.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n+package alluxio.worker.block.management;\n+\n+import alluxio.worker.block.BlockStoreLocation;\n+import alluxio.worker.block.evictor.BlockTransferInfo;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Comparator;\n+import java.util.HashSet;\n+import java.util.Hashtable;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Used to partition transfers for concurrent execution.\n+ */\n+public class BlockTransferPartitioner {\n+  private static final Logger LOG = LoggerFactory.getLogger(BlockTransferPartitioner.class);\n+\n+  /**\n+   * It greedily partitions given transfers into sub-lists.\n+   *\n+   * @param transferInfos list of transfers to partition\n+   * @param maxPartitionCount max partition count\n+   * @return transfers partitioned into sub-lists\n+   */\n+  public List<List<BlockTransferInfo>> partitionTransfers(List<BlockTransferInfo> transferInfos,\n+      int maxPartitionCount) {\n+    // Bucketing is possible if source or destination has exact location.\n+    // Those allocated locations will be bucket key[s].\n+    TransferPartitionKey key = findTransferBucketKey(transferInfos);\n+    // Can't bucketize transfers.\n+    if (key == TransferPartitionKey.NONE) {\n+      LOG.debug(\"Un-optimizable transfer list encountered.\");\n+      return new ArrayList<List<BlockTransferInfo>>() {\n+        {\n+          add(transferInfos);\n+        }\n+      };\n+    }\n+\n+    Hashtable<BlockStoreLocation, List<BlockTransferInfo>> transferBuckets = new Hashtable<>();\n+    for (BlockTransferInfo transferInfo : transferInfos) {\n+      BlockStoreLocation keyLoc;\n+      switch (key) {\n+        case SRC:\n+          keyLoc = transferInfo.getSrcLocation();\n+          break;\n+        case DST:\n+          keyLoc = transferInfo.getDstLocation();\n+          break;\n+        default:\n+          throw new IllegalStateException(\n+              String.format(\"Unsupported key type for bucketing transfer infos: %s\", key.name()));\n+      }\n+\n+      if (!transferBuckets.containsKey(keyLoc)) {\n+        transferBuckets.put(keyLoc, new LinkedList<>());\n+      }\n+\n+      transferBuckets.get(keyLoc).add(transferInfo);\n+    }\n+\n+    List<List<BlockTransferInfo>> balancedPartitions = balancePartitions(\n+        transferBuckets.values().stream().collect(Collectors.toList()), maxPartitionCount);\n+\n+    // Log partition details.\n+    if (LOG.isDebugEnabled()) {\n+      StringBuilder partitionDbgStr = new StringBuilder();\n+      partitionDbgStr\n+          .append(String.format(\"Bucketed %d transfers into %d partitions using key:%s.%n\",\n+              transferInfos.size(), balancedPartitions.size(), key.name()));\n+      // List each partition content.\n+      for (int i = 0; i < balancedPartitions.size(); i++) {\n+        partitionDbgStr.append(String.format(\"Partition-%d:%n ->%s%n\", i, balancedPartitions.get(i)\n+            .stream().map(Objects::toString).collect(Collectors.joining(\"\\n ->\"))));\n+      }\n+      LOG.debug(partitionDbgStr.toString());\n+    }\n+    return balancedPartitions;\n+  }\n+\n+  /**\n+   * Used to balance partitions into given bucket count. It greedily tries to achieve each bucket\n+   * having close count of tasks.\n+   */\n+  private List<List<BlockTransferInfo>> balancePartitions(\n+      List<List<BlockTransferInfo>> transferPartitions, int partitionLimit) {\n+    // Return as is if less than requested bucket count.\n+    if (transferPartitions.size() <= partitionLimit) {\n+      return transferPartitions;\n+    }\n+\n+    // TODO(ggezer): Support partitioning that considers block sizes.\n+    // Greedily build a balanced partitions by transfer count.\n+    Collections.sort(transferPartitions, Comparator.comparingInt(List::size));\n+\n+    // Initialize balanced partitions.\n+    List<List<BlockTransferInfo>> balancedPartitions = new ArrayList<>(partitionLimit);\n+    for (int i = 0; i < partitionLimit; i++) {\n+      balancedPartitions.add(new LinkedList<>());\n+    }\n+    // Greedily place transfer partitions into balanced partitions.\n+    for (List<BlockTransferInfo> transferPartition : transferPartitions) {\n+      // Find the balanced partition with the least element size.\n+      int selectedPartitionIdx = Integer.MAX_VALUE;\n+      int selectedPartitionCount = Integer.MAX_VALUE;\n+      for (int i = 0; i < partitionLimit; i++) {\n+        if (balancedPartitions.get(i).size() < selectedPartitionCount) {\n+          selectedPartitionIdx = i;\n+          selectedPartitionCount = balancedPartitions.get(i).size();\n+        }\n+      }\n+      balancedPartitions.get(selectedPartitionIdx).addAll(transferPartition);\n+    }\n+\n+    return balancedPartitions;\n+  }\n+\n+  /**\n+   * Used to determine right partitioning key by inspecting list of transfers.\n+   */\n+  private TransferPartitionKey findTransferBucketKey(List<BlockTransferInfo> transferInfos) {\n+    // How many src/dst locations are fully identified.\n+    int srcAllocatedCount = 0;\n+    int dstAllocatedCount = 0;\n+    // How many unique src/dst locations are seen.\n+    Set<BlockStoreLocation> srcLocations = new HashSet<>();\n+    Set<BlockStoreLocation> dstLocations = new HashSet<>();\n+    // Iterate and process all transfers.\n+    for (BlockTransferInfo transferInfo : transferInfos) {\n+      if (transferInfo.getSrcLocation().dir() != BlockStoreLocation.ANY_DIR) {\n+        srcAllocatedCount++;\n+      }\n+      if (transferInfo.getDstLocation().dir() != BlockStoreLocation.ANY_DIR) {\n+        dstAllocatedCount++;\n+      }\n+      srcLocations.add(transferInfo.getSrcLocation());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a0894d6c397b77db722ca4aef6865c0de16ee124"}, "originalPosition": 155}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDczNzc5NA==", "bodyText": "No, ANY_DIR means unallocated in this context, directory being the allocation unit. If a directory is not known, then it's not right to account it for dir level optimizations.", "url": "https://github.com/Alluxio/alluxio/pull/11458#discussion_r430737794", "createdAt": "2020-05-26T22:16:10Z", "author": {"login": "ggezer"}, "path": "core/server/worker/src/main/java/alluxio/worker/block/management/BlockTransferPartitioner.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n+package alluxio.worker.block.management;\n+\n+import alluxio.worker.block.BlockStoreLocation;\n+import alluxio.worker.block.evictor.BlockTransferInfo;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Comparator;\n+import java.util.HashSet;\n+import java.util.Hashtable;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Used to partition transfers for concurrent execution.\n+ */\n+public class BlockTransferPartitioner {\n+  private static final Logger LOG = LoggerFactory.getLogger(BlockTransferPartitioner.class);\n+\n+  /**\n+   * It greedily partitions given transfers into sub-lists.\n+   *\n+   * @param transferInfos list of transfers to partition\n+   * @param maxPartitionCount max partition count\n+   * @return transfers partitioned into sub-lists\n+   */\n+  public List<List<BlockTransferInfo>> partitionTransfers(List<BlockTransferInfo> transferInfos,\n+      int maxPartitionCount) {\n+    // Bucketing is possible if source or destination has exact location.\n+    // Those allocated locations will be bucket key[s].\n+    TransferPartitionKey key = findTransferBucketKey(transferInfos);\n+    // Can't bucketize transfers.\n+    if (key == TransferPartitionKey.NONE) {\n+      LOG.debug(\"Un-optimizable transfer list encountered.\");\n+      return new ArrayList<List<BlockTransferInfo>>() {\n+        {\n+          add(transferInfos);\n+        }\n+      };\n+    }\n+\n+    Hashtable<BlockStoreLocation, List<BlockTransferInfo>> transferBuckets = new Hashtable<>();\n+    for (BlockTransferInfo transferInfo : transferInfos) {\n+      BlockStoreLocation keyLoc;\n+      switch (key) {\n+        case SRC:\n+          keyLoc = transferInfo.getSrcLocation();\n+          break;\n+        case DST:\n+          keyLoc = transferInfo.getDstLocation();\n+          break;\n+        default:\n+          throw new IllegalStateException(\n+              String.format(\"Unsupported key type for bucketing transfer infos: %s\", key.name()));\n+      }\n+\n+      if (!transferBuckets.containsKey(keyLoc)) {\n+        transferBuckets.put(keyLoc, new LinkedList<>());\n+      }\n+\n+      transferBuckets.get(keyLoc).add(transferInfo);\n+    }\n+\n+    List<List<BlockTransferInfo>> balancedPartitions = balancePartitions(\n+        transferBuckets.values().stream().collect(Collectors.toList()), maxPartitionCount);\n+\n+    // Log partition details.\n+    if (LOG.isDebugEnabled()) {\n+      StringBuilder partitionDbgStr = new StringBuilder();\n+      partitionDbgStr\n+          .append(String.format(\"Bucketed %d transfers into %d partitions using key:%s.%n\",\n+              transferInfos.size(), balancedPartitions.size(), key.name()));\n+      // List each partition content.\n+      for (int i = 0; i < balancedPartitions.size(); i++) {\n+        partitionDbgStr.append(String.format(\"Partition-%d:%n ->%s%n\", i, balancedPartitions.get(i)\n+            .stream().map(Objects::toString).collect(Collectors.joining(\"\\n ->\"))));\n+      }\n+      LOG.debug(partitionDbgStr.toString());\n+    }\n+    return balancedPartitions;\n+  }\n+\n+  /**\n+   * Used to balance partitions into given bucket count. It greedily tries to achieve each bucket\n+   * having close count of tasks.\n+   */\n+  private List<List<BlockTransferInfo>> balancePartitions(\n+      List<List<BlockTransferInfo>> transferPartitions, int partitionLimit) {\n+    // Return as is if less than requested bucket count.\n+    if (transferPartitions.size() <= partitionLimit) {\n+      return transferPartitions;\n+    }\n+\n+    // TODO(ggezer): Support partitioning that considers block sizes.\n+    // Greedily build a balanced partitions by transfer count.\n+    Collections.sort(transferPartitions, Comparator.comparingInt(List::size));\n+\n+    // Initialize balanced partitions.\n+    List<List<BlockTransferInfo>> balancedPartitions = new ArrayList<>(partitionLimit);\n+    for (int i = 0; i < partitionLimit; i++) {\n+      balancedPartitions.add(new LinkedList<>());\n+    }\n+    // Greedily place transfer partitions into balanced partitions.\n+    for (List<BlockTransferInfo> transferPartition : transferPartitions) {\n+      // Find the balanced partition with the least element size.\n+      int selectedPartitionIdx = Integer.MAX_VALUE;\n+      int selectedPartitionCount = Integer.MAX_VALUE;\n+      for (int i = 0; i < partitionLimit; i++) {\n+        if (balancedPartitions.get(i).size() < selectedPartitionCount) {\n+          selectedPartitionIdx = i;\n+          selectedPartitionCount = balancedPartitions.get(i).size();\n+        }\n+      }\n+      balancedPartitions.get(selectedPartitionIdx).addAll(transferPartition);\n+    }\n+\n+    return balancedPartitions;\n+  }\n+\n+  /**\n+   * Used to determine right partitioning key by inspecting list of transfers.\n+   */\n+  private TransferPartitionKey findTransferBucketKey(List<BlockTransferInfo> transferInfos) {\n+    // How many src/dst locations are fully identified.\n+    int srcAllocatedCount = 0;\n+    int dstAllocatedCount = 0;\n+    // How many unique src/dst locations are seen.\n+    Set<BlockStoreLocation> srcLocations = new HashSet<>();\n+    Set<BlockStoreLocation> dstLocations = new HashSet<>();\n+    // Iterate and process all transfers.\n+    for (BlockTransferInfo transferInfo : transferInfos) {\n+      if (transferInfo.getSrcLocation().dir() != BlockStoreLocation.ANY_DIR) {\n+        srcAllocatedCount++;\n+      }\n+      if (transferInfo.getDstLocation().dir() != BlockStoreLocation.ANY_DIR) {\n+        dstAllocatedCount++;\n+      }\n+      srcLocations.add(transferInfo.getSrcLocation());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcyOTQ2OQ=="}, "originalCommit": {"oid": "a0894d6c397b77db722ca4aef6865c0de16ee124"}, "originalPosition": 155}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTMxNjgzMQ==", "bodyText": "I meant if we should be adding ANY_DIR to src/dstLocations?", "url": "https://github.com/Alluxio/alluxio/pull/11458#discussion_r431316831", "createdAt": "2020-05-27T17:27:40Z", "author": {"login": "calvinjia"}, "path": "core/server/worker/src/main/java/alluxio/worker/block/management/BlockTransferPartitioner.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n+package alluxio.worker.block.management;\n+\n+import alluxio.worker.block.BlockStoreLocation;\n+import alluxio.worker.block.evictor.BlockTransferInfo;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Comparator;\n+import java.util.HashSet;\n+import java.util.Hashtable;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Used to partition transfers for concurrent execution.\n+ */\n+public class BlockTransferPartitioner {\n+  private static final Logger LOG = LoggerFactory.getLogger(BlockTransferPartitioner.class);\n+\n+  /**\n+   * It greedily partitions given transfers into sub-lists.\n+   *\n+   * @param transferInfos list of transfers to partition\n+   * @param maxPartitionCount max partition count\n+   * @return transfers partitioned into sub-lists\n+   */\n+  public List<List<BlockTransferInfo>> partitionTransfers(List<BlockTransferInfo> transferInfos,\n+      int maxPartitionCount) {\n+    // Bucketing is possible if source or destination has exact location.\n+    // Those allocated locations will be bucket key[s].\n+    TransferPartitionKey key = findTransferBucketKey(transferInfos);\n+    // Can't bucketize transfers.\n+    if (key == TransferPartitionKey.NONE) {\n+      LOG.debug(\"Un-optimizable transfer list encountered.\");\n+      return new ArrayList<List<BlockTransferInfo>>() {\n+        {\n+          add(transferInfos);\n+        }\n+      };\n+    }\n+\n+    Hashtable<BlockStoreLocation, List<BlockTransferInfo>> transferBuckets = new Hashtable<>();\n+    for (BlockTransferInfo transferInfo : transferInfos) {\n+      BlockStoreLocation keyLoc;\n+      switch (key) {\n+        case SRC:\n+          keyLoc = transferInfo.getSrcLocation();\n+          break;\n+        case DST:\n+          keyLoc = transferInfo.getDstLocation();\n+          break;\n+        default:\n+          throw new IllegalStateException(\n+              String.format(\"Unsupported key type for bucketing transfer infos: %s\", key.name()));\n+      }\n+\n+      if (!transferBuckets.containsKey(keyLoc)) {\n+        transferBuckets.put(keyLoc, new LinkedList<>());\n+      }\n+\n+      transferBuckets.get(keyLoc).add(transferInfo);\n+    }\n+\n+    List<List<BlockTransferInfo>> balancedPartitions = balancePartitions(\n+        transferBuckets.values().stream().collect(Collectors.toList()), maxPartitionCount);\n+\n+    // Log partition details.\n+    if (LOG.isDebugEnabled()) {\n+      StringBuilder partitionDbgStr = new StringBuilder();\n+      partitionDbgStr\n+          .append(String.format(\"Bucketed %d transfers into %d partitions using key:%s.%n\",\n+              transferInfos.size(), balancedPartitions.size(), key.name()));\n+      // List each partition content.\n+      for (int i = 0; i < balancedPartitions.size(); i++) {\n+        partitionDbgStr.append(String.format(\"Partition-%d:%n ->%s%n\", i, balancedPartitions.get(i)\n+            .stream().map(Objects::toString).collect(Collectors.joining(\"\\n ->\"))));\n+      }\n+      LOG.debug(partitionDbgStr.toString());\n+    }\n+    return balancedPartitions;\n+  }\n+\n+  /**\n+   * Used to balance partitions into given bucket count. It greedily tries to achieve each bucket\n+   * having close count of tasks.\n+   */\n+  private List<List<BlockTransferInfo>> balancePartitions(\n+      List<List<BlockTransferInfo>> transferPartitions, int partitionLimit) {\n+    // Return as is if less than requested bucket count.\n+    if (transferPartitions.size() <= partitionLimit) {\n+      return transferPartitions;\n+    }\n+\n+    // TODO(ggezer): Support partitioning that considers block sizes.\n+    // Greedily build a balanced partitions by transfer count.\n+    Collections.sort(transferPartitions, Comparator.comparingInt(List::size));\n+\n+    // Initialize balanced partitions.\n+    List<List<BlockTransferInfo>> balancedPartitions = new ArrayList<>(partitionLimit);\n+    for (int i = 0; i < partitionLimit; i++) {\n+      balancedPartitions.add(new LinkedList<>());\n+    }\n+    // Greedily place transfer partitions into balanced partitions.\n+    for (List<BlockTransferInfo> transferPartition : transferPartitions) {\n+      // Find the balanced partition with the least element size.\n+      int selectedPartitionIdx = Integer.MAX_VALUE;\n+      int selectedPartitionCount = Integer.MAX_VALUE;\n+      for (int i = 0; i < partitionLimit; i++) {\n+        if (balancedPartitions.get(i).size() < selectedPartitionCount) {\n+          selectedPartitionIdx = i;\n+          selectedPartitionCount = balancedPartitions.get(i).size();\n+        }\n+      }\n+      balancedPartitions.get(selectedPartitionIdx).addAll(transferPartition);\n+    }\n+\n+    return balancedPartitions;\n+  }\n+\n+  /**\n+   * Used to determine right partitioning key by inspecting list of transfers.\n+   */\n+  private TransferPartitionKey findTransferBucketKey(List<BlockTransferInfo> transferInfos) {\n+    // How many src/dst locations are fully identified.\n+    int srcAllocatedCount = 0;\n+    int dstAllocatedCount = 0;\n+    // How many unique src/dst locations are seen.\n+    Set<BlockStoreLocation> srcLocations = new HashSet<>();\n+    Set<BlockStoreLocation> dstLocations = new HashSet<>();\n+    // Iterate and process all transfers.\n+    for (BlockTransferInfo transferInfo : transferInfos) {\n+      if (transferInfo.getSrcLocation().dir() != BlockStoreLocation.ANY_DIR) {\n+        srcAllocatedCount++;\n+      }\n+      if (transferInfo.getDstLocation().dir() != BlockStoreLocation.ANY_DIR) {\n+        dstAllocatedCount++;\n+      }\n+      srcLocations.add(transferInfo.getSrcLocation());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcyOTQ2OQ=="}, "originalCommit": {"oid": "a0894d6c397b77db722ca4aef6865c0de16ee124"}, "originalPosition": 155}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4Mjg5MDI2OnYy", "diffSide": "RIGHT", "path": "core/server/worker/src/main/java/alluxio/worker/block/management/BlockTransferPartitioner.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQyMTo1NTo0MFrOGaxqWQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQyMjoyNDozNFrOGayVYg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcyOTgxNw==", "bodyText": "This comment is not always true right? Since we don't check == transferInfo.size?", "url": "https://github.com/Alluxio/alluxio/pull/11458#discussion_r430729817", "createdAt": "2020-05-26T21:55:40Z", "author": {"login": "calvinjia"}, "path": "core/server/worker/src/main/java/alluxio/worker/block/management/BlockTransferPartitioner.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n+package alluxio.worker.block.management;\n+\n+import alluxio.worker.block.BlockStoreLocation;\n+import alluxio.worker.block.evictor.BlockTransferInfo;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Comparator;\n+import java.util.HashSet;\n+import java.util.Hashtable;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Used to partition transfers for concurrent execution.\n+ */\n+public class BlockTransferPartitioner {\n+  private static final Logger LOG = LoggerFactory.getLogger(BlockTransferPartitioner.class);\n+\n+  /**\n+   * It greedily partitions given transfers into sub-lists.\n+   *\n+   * @param transferInfos list of transfers to partition\n+   * @param maxPartitionCount max partition count\n+   * @return transfers partitioned into sub-lists\n+   */\n+  public List<List<BlockTransferInfo>> partitionTransfers(List<BlockTransferInfo> transferInfos,\n+      int maxPartitionCount) {\n+    // Bucketing is possible if source or destination has exact location.\n+    // Those allocated locations will be bucket key[s].\n+    TransferPartitionKey key = findTransferBucketKey(transferInfos);\n+    // Can't bucketize transfers.\n+    if (key == TransferPartitionKey.NONE) {\n+      LOG.debug(\"Un-optimizable transfer list encountered.\");\n+      return new ArrayList<List<BlockTransferInfo>>() {\n+        {\n+          add(transferInfos);\n+        }\n+      };\n+    }\n+\n+    Hashtable<BlockStoreLocation, List<BlockTransferInfo>> transferBuckets = new Hashtable<>();\n+    for (BlockTransferInfo transferInfo : transferInfos) {\n+      BlockStoreLocation keyLoc;\n+      switch (key) {\n+        case SRC:\n+          keyLoc = transferInfo.getSrcLocation();\n+          break;\n+        case DST:\n+          keyLoc = transferInfo.getDstLocation();\n+          break;\n+        default:\n+          throw new IllegalStateException(\n+              String.format(\"Unsupported key type for bucketing transfer infos: %s\", key.name()));\n+      }\n+\n+      if (!transferBuckets.containsKey(keyLoc)) {\n+        transferBuckets.put(keyLoc, new LinkedList<>());\n+      }\n+\n+      transferBuckets.get(keyLoc).add(transferInfo);\n+    }\n+\n+    List<List<BlockTransferInfo>> balancedPartitions = balancePartitions(\n+        transferBuckets.values().stream().collect(Collectors.toList()), maxPartitionCount);\n+\n+    // Log partition details.\n+    if (LOG.isDebugEnabled()) {\n+      StringBuilder partitionDbgStr = new StringBuilder();\n+      partitionDbgStr\n+          .append(String.format(\"Bucketed %d transfers into %d partitions using key:%s.%n\",\n+              transferInfos.size(), balancedPartitions.size(), key.name()));\n+      // List each partition content.\n+      for (int i = 0; i < balancedPartitions.size(); i++) {\n+        partitionDbgStr.append(String.format(\"Partition-%d:%n ->%s%n\", i, balancedPartitions.get(i)\n+            .stream().map(Objects::toString).collect(Collectors.joining(\"\\n ->\"))));\n+      }\n+      LOG.debug(partitionDbgStr.toString());\n+    }\n+    return balancedPartitions;\n+  }\n+\n+  /**\n+   * Used to balance partitions into given bucket count. It greedily tries to achieve each bucket\n+   * having close count of tasks.\n+   */\n+  private List<List<BlockTransferInfo>> balancePartitions(\n+      List<List<BlockTransferInfo>> transferPartitions, int partitionLimit) {\n+    // Return as is if less than requested bucket count.\n+    if (transferPartitions.size() <= partitionLimit) {\n+      return transferPartitions;\n+    }\n+\n+    // TODO(ggezer): Support partitioning that considers block sizes.\n+    // Greedily build a balanced partitions by transfer count.\n+    Collections.sort(transferPartitions, Comparator.comparingInt(List::size));\n+\n+    // Initialize balanced partitions.\n+    List<List<BlockTransferInfo>> balancedPartitions = new ArrayList<>(partitionLimit);\n+    for (int i = 0; i < partitionLimit; i++) {\n+      balancedPartitions.add(new LinkedList<>());\n+    }\n+    // Greedily place transfer partitions into balanced partitions.\n+    for (List<BlockTransferInfo> transferPartition : transferPartitions) {\n+      // Find the balanced partition with the least element size.\n+      int selectedPartitionIdx = Integer.MAX_VALUE;\n+      int selectedPartitionCount = Integer.MAX_VALUE;\n+      for (int i = 0; i < partitionLimit; i++) {\n+        if (balancedPartitions.get(i).size() < selectedPartitionCount) {\n+          selectedPartitionIdx = i;\n+          selectedPartitionCount = balancedPartitions.get(i).size();\n+        }\n+      }\n+      balancedPartitions.get(selectedPartitionIdx).addAll(transferPartition);\n+    }\n+\n+    return balancedPartitions;\n+  }\n+\n+  /**\n+   * Used to determine right partitioning key by inspecting list of transfers.\n+   */\n+  private TransferPartitionKey findTransferBucketKey(List<BlockTransferInfo> transferInfos) {\n+    // How many src/dst locations are fully identified.\n+    int srcAllocatedCount = 0;\n+    int dstAllocatedCount = 0;\n+    // How many unique src/dst locations are seen.\n+    Set<BlockStoreLocation> srcLocations = new HashSet<>();\n+    Set<BlockStoreLocation> dstLocations = new HashSet<>();\n+    // Iterate and process all transfers.\n+    for (BlockTransferInfo transferInfo : transferInfos) {\n+      if (transferInfo.getSrcLocation().dir() != BlockStoreLocation.ANY_DIR) {\n+        srcAllocatedCount++;\n+      }\n+      if (transferInfo.getDstLocation().dir() != BlockStoreLocation.ANY_DIR) {\n+        dstAllocatedCount++;\n+      }\n+      srcLocations.add(transferInfo.getSrcLocation());\n+      dstLocations.add(transferInfo.getDstLocation());\n+    }\n+\n+    // Find the desired partitioning key.\n+    if (srcAllocatedCount == dstAllocatedCount) { // All locations are fully identified.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a0894d6c397b77db722ca4aef6865c0de16ee124"}, "originalPosition": 160}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDc0MDgzNA==", "bodyText": "Refactored the whole flow.", "url": "https://github.com/Alluxio/alluxio/pull/11458#discussion_r430740834", "createdAt": "2020-05-26T22:24:34Z", "author": {"login": "ggezer"}, "path": "core/server/worker/src/main/java/alluxio/worker/block/management/BlockTransferPartitioner.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n+package alluxio.worker.block.management;\n+\n+import alluxio.worker.block.BlockStoreLocation;\n+import alluxio.worker.block.evictor.BlockTransferInfo;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Comparator;\n+import java.util.HashSet;\n+import java.util.Hashtable;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Used to partition transfers for concurrent execution.\n+ */\n+public class BlockTransferPartitioner {\n+  private static final Logger LOG = LoggerFactory.getLogger(BlockTransferPartitioner.class);\n+\n+  /**\n+   * It greedily partitions given transfers into sub-lists.\n+   *\n+   * @param transferInfos list of transfers to partition\n+   * @param maxPartitionCount max partition count\n+   * @return transfers partitioned into sub-lists\n+   */\n+  public List<List<BlockTransferInfo>> partitionTransfers(List<BlockTransferInfo> transferInfos,\n+      int maxPartitionCount) {\n+    // Bucketing is possible if source or destination has exact location.\n+    // Those allocated locations will be bucket key[s].\n+    TransferPartitionKey key = findTransferBucketKey(transferInfos);\n+    // Can't bucketize transfers.\n+    if (key == TransferPartitionKey.NONE) {\n+      LOG.debug(\"Un-optimizable transfer list encountered.\");\n+      return new ArrayList<List<BlockTransferInfo>>() {\n+        {\n+          add(transferInfos);\n+        }\n+      };\n+    }\n+\n+    Hashtable<BlockStoreLocation, List<BlockTransferInfo>> transferBuckets = new Hashtable<>();\n+    for (BlockTransferInfo transferInfo : transferInfos) {\n+      BlockStoreLocation keyLoc;\n+      switch (key) {\n+        case SRC:\n+          keyLoc = transferInfo.getSrcLocation();\n+          break;\n+        case DST:\n+          keyLoc = transferInfo.getDstLocation();\n+          break;\n+        default:\n+          throw new IllegalStateException(\n+              String.format(\"Unsupported key type for bucketing transfer infos: %s\", key.name()));\n+      }\n+\n+      if (!transferBuckets.containsKey(keyLoc)) {\n+        transferBuckets.put(keyLoc, new LinkedList<>());\n+      }\n+\n+      transferBuckets.get(keyLoc).add(transferInfo);\n+    }\n+\n+    List<List<BlockTransferInfo>> balancedPartitions = balancePartitions(\n+        transferBuckets.values().stream().collect(Collectors.toList()), maxPartitionCount);\n+\n+    // Log partition details.\n+    if (LOG.isDebugEnabled()) {\n+      StringBuilder partitionDbgStr = new StringBuilder();\n+      partitionDbgStr\n+          .append(String.format(\"Bucketed %d transfers into %d partitions using key:%s.%n\",\n+              transferInfos.size(), balancedPartitions.size(), key.name()));\n+      // List each partition content.\n+      for (int i = 0; i < balancedPartitions.size(); i++) {\n+        partitionDbgStr.append(String.format(\"Partition-%d:%n ->%s%n\", i, balancedPartitions.get(i)\n+            .stream().map(Objects::toString).collect(Collectors.joining(\"\\n ->\"))));\n+      }\n+      LOG.debug(partitionDbgStr.toString());\n+    }\n+    return balancedPartitions;\n+  }\n+\n+  /**\n+   * Used to balance partitions into given bucket count. It greedily tries to achieve each bucket\n+   * having close count of tasks.\n+   */\n+  private List<List<BlockTransferInfo>> balancePartitions(\n+      List<List<BlockTransferInfo>> transferPartitions, int partitionLimit) {\n+    // Return as is if less than requested bucket count.\n+    if (transferPartitions.size() <= partitionLimit) {\n+      return transferPartitions;\n+    }\n+\n+    // TODO(ggezer): Support partitioning that considers block sizes.\n+    // Greedily build a balanced partitions by transfer count.\n+    Collections.sort(transferPartitions, Comparator.comparingInt(List::size));\n+\n+    // Initialize balanced partitions.\n+    List<List<BlockTransferInfo>> balancedPartitions = new ArrayList<>(partitionLimit);\n+    for (int i = 0; i < partitionLimit; i++) {\n+      balancedPartitions.add(new LinkedList<>());\n+    }\n+    // Greedily place transfer partitions into balanced partitions.\n+    for (List<BlockTransferInfo> transferPartition : transferPartitions) {\n+      // Find the balanced partition with the least element size.\n+      int selectedPartitionIdx = Integer.MAX_VALUE;\n+      int selectedPartitionCount = Integer.MAX_VALUE;\n+      for (int i = 0; i < partitionLimit; i++) {\n+        if (balancedPartitions.get(i).size() < selectedPartitionCount) {\n+          selectedPartitionIdx = i;\n+          selectedPartitionCount = balancedPartitions.get(i).size();\n+        }\n+      }\n+      balancedPartitions.get(selectedPartitionIdx).addAll(transferPartition);\n+    }\n+\n+    return balancedPartitions;\n+  }\n+\n+  /**\n+   * Used to determine right partitioning key by inspecting list of transfers.\n+   */\n+  private TransferPartitionKey findTransferBucketKey(List<BlockTransferInfo> transferInfos) {\n+    // How many src/dst locations are fully identified.\n+    int srcAllocatedCount = 0;\n+    int dstAllocatedCount = 0;\n+    // How many unique src/dst locations are seen.\n+    Set<BlockStoreLocation> srcLocations = new HashSet<>();\n+    Set<BlockStoreLocation> dstLocations = new HashSet<>();\n+    // Iterate and process all transfers.\n+    for (BlockTransferInfo transferInfo : transferInfos) {\n+      if (transferInfo.getSrcLocation().dir() != BlockStoreLocation.ANY_DIR) {\n+        srcAllocatedCount++;\n+      }\n+      if (transferInfo.getDstLocation().dir() != BlockStoreLocation.ANY_DIR) {\n+        dstAllocatedCount++;\n+      }\n+      srcLocations.add(transferInfo.getSrcLocation());\n+      dstLocations.add(transferInfo.getDstLocation());\n+    }\n+\n+    // Find the desired partitioning key.\n+    if (srcAllocatedCount == dstAllocatedCount) { // All locations are fully identified.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcyOTgxNw=="}, "originalCommit": {"oid": "a0894d6c397b77db722ca4aef6865c0de16ee124"}, "originalPosition": 160}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1542, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}