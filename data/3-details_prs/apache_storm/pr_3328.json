{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDc3NDk5OTU3", "number": 3328, "title": "[STORM-3691] Refactor Resource Aware Strategies.", "bodyText": "What is the purpose of the change\nRefactor BaseResourceAwareStrategy, DefaultResourceAwareStrategy and GenericResourceAwareStrategy to remove duplicated code and incompatibilities.\nHow was the change tested\nNew test classes to check backward compatibility and modifications to current tests.", "createdAt": "2020-09-02T01:22:08Z", "url": "https://github.com/apache/storm/pull/3328", "merged": true, "mergeCommit": {"oid": "6e2e46bcf21584cb111bd5254912b2a6410eccb7"}, "closed": true, "closedAt": "2020-09-18T15:04:53Z", "author": {"login": "bipinprasad"}, "timelineItems": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdExfucAH2gAyNDc3NDk5OTU3OjQyNmY2ZjFiYmI1NGRkMWRkMWRmYzU5MjZhNjRhMmI3M2MwMWU1Y2M=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdKGnpmgFqTQ5MTUyNzE5Ng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "426f6f1bbb54dd1dd1dfc5926a64a2b73c01e5cc", "author": {"user": null}, "url": "https://github.com/apache/storm/commit/426f6f1bbb54dd1dd1dfc5926a64a2b73c01e5cc", "committedDate": "2020-09-02T01:12:56Z", "message": "[STORM-3691] Refactor Refactor Resource Aware Strategies."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "37b21cbad83559db03ddb002422724a1a9328f3e", "author": {"user": null}, "url": "https://github.com/apache/storm/commit/37b21cbad83559db03ddb002422724a1a9328f3e", "committedDate": "2020-09-02T14:52:29Z", "message": "[STORM-3691] Fix test TestConstraintSolverStrategy.testZeroExecutorScheduling()"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDgxMTc3NjYy", "url": "https://github.com/apache/storm/pull/3328#pullrequestreview-481177662", "createdAt": "2020-09-02T18:57:38Z", "commit": {"oid": "37b21cbad83559db03ddb002422724a1a9328f3e"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQxODo1NzozOVrOHL91Vw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQxOTowMDowMFrOHL993A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjMwOTQ2Mw==", "bodyText": "Where was this used before that we are now deprecating it?  It looks like this is added?", "url": "https://github.com/apache/storm/pull/3328#discussion_r482309463", "createdAt": "2020-09-02T18:57:39Z", "author": {"login": "agresch"}, "path": "storm-client/src/jvm/org/apache/storm/Config.java", "diffHunk": "@@ -346,6 +345,14 @@\n      */\n     @IsExactlyOneOf(valueValidatorClasses = { ListOfListOfStringValidator.class, RasConstraintsTypeValidator.class })\n     public static final String TOPOLOGY_RAS_CONSTRAINTS = \"topology.ras.constraints\";\n+    /**\n+     * Declare scheduling constraints for a topology.\n+     * @deprecated please use TOPOLOGY_RAS_CONSTRAINTS.\n+     */\n+    @Deprecated\n+    @CustomValidator(validatorClass = ListOfListOfStringValidator.class)\n+    public static final String TOPOLOGY_CONSTRAINTS = \"topology.constraints\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "37b21cbad83559db03ddb002422724a1a9328f3e"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjMxMTY0NA==", "bodyText": "same comment on these....", "url": "https://github.com/apache/storm/pull/3328#discussion_r482311644", "createdAt": "2020-09-02T19:00:00Z", "author": {"login": "agresch"}, "path": "storm-client/src/jvm/org/apache/storm/Config.java", "diffHunk": "@@ -355,12 +362,30 @@\n     @IsStringList\n     public static final String TOPOLOGY_SPREAD_COMPONENTS = \"topology.spread.components\";\n     /**\n-     * The maximum number of states that will be searched looking for a solution in the constraint solver strategy.\n+     * The maximum number of states that will be searched looking for a solution in resource aware strategies, e.g.\n+     * in BaseResourceAwareStrategy.\n      */\n     @IsInteger\n     @IsPositiveNumber\n     public static final String TOPOLOGY_RAS_CONSTRAINT_MAX_STATE_SEARCH = \"topology.ras.constraint.max.state.search\";\n     /**\n+     * The maximum number of states that will be searched looking for a solution in resource aware strategies, e.g.\n+     * in BaseResourceAwareStrategy. Backward compatibility config value for old topologies.\n+     * @deprecated please use {@link Config#TOPOLOGY_RAS_CONSTRAINT_MAX_STATE_SEARCH}\n+     */\n+    @IsInteger\n+    @IsPositiveNumber\n+    @Deprecated\n+    public static final String TOPOLOGY_RAS_CONSTRAINT_MAX_STATE_TRAVERSAL = \"topology.ras.constraint.max.state.traversal\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "37b21cbad83559db03ddb002422724a1a9328f3e"}, "originalPosition": 46}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "90fa85f44b32c34a6f519af3b4d419daf7354c69", "author": {"user": null}, "url": "https://github.com/apache/storm/commit/90fa85f44b32c34a6f519af3b4d419daf7354c69", "committedDate": "2020-09-02T19:43:48Z", "message": "[STORM-3691] Remove new but deprecated Config.TOPOLOGY_RAS_CONSTRAINT_MAX_STATE_SEARCH and Config,TOPOLOGY_CONSTRAINTS"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDgxODkwMzUx", "url": "https://github.com/apache/storm/pull/3328#pullrequestreview-481890351", "createdAt": "2020-09-03T14:22:05Z", "commit": {"oid": "90fa85f44b32c34a6f519af3b4d419daf7354c69"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxNDoyMjowNlrOHMo-kw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxNDoyMjowNlrOHMo-kw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzAxNjMzOQ==", "bodyText": "is this another new deprecation?", "url": "https://github.com/apache/storm/pull/3328#discussion_r483016339", "createdAt": "2020-09-03T14:22:06Z", "author": {"login": "agresch"}, "path": "storm-client/src/jvm/org/apache/storm/Config.java", "diffHunk": "@@ -355,12 +355,21 @@\n     @IsStringList\n     public static final String TOPOLOGY_SPREAD_COMPONENTS = \"topology.spread.components\";\n     /**\n-     * The maximum number of states that will be searched looking for a solution in the constraint solver strategy.\n+     * The maximum number of states that will be searched looking for a solution in resource aware strategies, e.g.\n+     * in BaseResourceAwareStrategy.\n      */\n     @IsInteger\n     @IsPositiveNumber\n     public static final String TOPOLOGY_RAS_CONSTRAINT_MAX_STATE_SEARCH = \"topology.ras.constraint.max.state.search\";\n     /**\n+     * Declare max traversal depth for find solutions that satisfy constraints.\n+     * @deprecated please use {@link Config#TOPOLOGY_RAS_CONSTRAINT_MAX_STATE_SEARCH}\n+     */\n+    @IsInteger\n+    @IsPositiveNumber\n+    @Deprecated\n+    public static final String TOPOLOGY_CONSTRAINTS_MAX_DEPTH_TRAVERSAL = \"topology.constraints.max.depth.traversal\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "90fa85f44b32c34a6f519af3b4d419daf7354c69"}, "originalPosition": 38}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "50e7cded75648a0ee2fddea697f522f630c817ed", "author": {"user": null}, "url": "https://github.com/apache/storm/commit/50e7cded75648a0ee2fddea697f522f630c817ed", "committedDate": "2020-09-03T15:26:55Z", "message": "[STORM-3691] Removed deprecated Config.TOPOLOGY_CONSTRAINTS_MAX_DEPTH_TRAVERSAL."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDkwNjc3MTUx", "url": "https://github.com/apache/storm/pull/3328#pullrequestreview-490677151", "createdAt": "2020-09-17T14:44:30Z", "commit": {"oid": "50e7cded75648a0ee2fddea697f522f630c817ed"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QxNDo0NDozMFrOHTl87A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QxNDo1NjoyMVrOHTmusA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDMwNjc5Ng==", "bodyText": "This should be removed.", "url": "https://github.com/apache/storm/pull/3328#discussion_r490306796", "createdAt": "2020-09-17T14:44:30Z", "author": {"login": "Ethanlm"}, "path": "storm-server/src/main/java/org/apache/storm/scheduler/resource/strategies/scheduling/BaseResourceAwareStrategy.java", "diffHunk": "@@ -50,709 +37,308 @@\n import org.apache.storm.scheduler.resource.RasNodes;\n import org.apache.storm.scheduler.resource.SchedulingResult;\n import org.apache.storm.scheduler.resource.SchedulingStatus;\n-import org.apache.storm.scheduler.resource.normalization.NormalizedResourceOffer;\n-import org.apache.storm.scheduler.resource.normalization.NormalizedResourceRequest;\n-import org.apache.storm.shade.com.google.common.annotations.VisibleForTesting;\n-import org.apache.storm.shade.com.google.common.collect.Sets;\n+import org.apache.storm.scheduler.resource.strategies.scheduling.sorter.ExecSorterByConnectionCount;\n+import org.apache.storm.scheduler.resource.strategies.scheduling.sorter.ExecSorterByProximity;\n+import org.apache.storm.scheduler.resource.strategies.scheduling.sorter.IExecSorter;\n+import org.apache.storm.scheduler.resource.strategies.scheduling.sorter.INodeSorter;\n+import org.apache.storm.scheduler.resource.strategies.scheduling.sorter.NodeSorter;\n import org.apache.storm.utils.ObjectReader;\n+import org.apache.storm.utils.Time;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n public abstract class BaseResourceAwareStrategy implements IStrategy {\n     private static final Logger LOG = LoggerFactory.getLogger(BaseResourceAwareStrategy.class);\n-    protected Cluster cluster;\n-    // Rack id to list of host names in that rack\n-    private Map<String, List<String>> networkTopography;\n-    private final Map<String, String> superIdToRack = new HashMap<>();\n-    private final Map<String, String> superIdToHostname = new HashMap<>();\n-    private final Map<String, List<RasNode>> hostnameToNodes = new HashMap<>();\n-    private final Map<String, List<RasNode>> rackIdToNodes = new HashMap<>();\n-    protected RasNodes nodes;\n \n-    @VisibleForTesting\n-    void prepare(Cluster cluster) {\n-        this.cluster = cluster;\n-        nodes = new RasNodes(cluster);\n-        networkTopography = cluster.getNetworkTopography();\n-        Map<String, String> hostToRack = new HashMap<>();\n-        for (Map.Entry<String, List<String>> entry : networkTopography.entrySet()) {\n-            String rackId = entry.getKey();\n-            for (String hostName: entry.getValue()) {\n-                hostToRack.put(hostName, rackId);\n-            }\n-        }\n-        for (RasNode node: nodes.getNodes()) {\n-            String superId = node.getId();\n-            String hostName = node.getHostname();\n-            String rackId = hostToRack.getOrDefault(hostName, DNSToSwitchMapping.DEFAULT_RACK);\n-            superIdToHostname.put(superId, hostName);\n-            superIdToRack.put(superId, rackId);\n-            hostnameToNodes.computeIfAbsent(hostName, (hn) -> new ArrayList<>()).add(node);\n-            rackIdToNodes.computeIfAbsent(rackId, (hn) -> new ArrayList<>()).add(node);\n-        }\n-        logClusterInfo();\n+    /**\n+     * Different node sorting types available. Two of these are for backward compatibility.\n+     * The last one (COMMON) is the new sorting type used across the board.\n+     * Refer to {@link NodeSorter#NodeSorter(Cluster, TopologyDetails, NodeSortType)} for more details.\n+     */\n+    public enum NodeSortType {\n+        GENERIC_RAS, // for deprecation, Used by GenericResourceAwareStrategyOld\n+        DEFAULT_RAS, // for deprecation, Used by DefaultResourceAwareStrategyOld\n+        COMMON       // new and only node sorting type going forward\n     }\n \n-    @Override\n-    public void prepare(Map<String, Object> config) {\n-        //NOOP\n-    }\n+    // instance variables from class instantiation\n+    protected final boolean sortNodesForEachExecutor;\n+    protected final NodeSortType nodeSortType;\n+\n+    // instance variable set by two IStrategy methods\n+    protected Map<String, Object> config;\n+    protected Cluster cluster;\n+    protected TopologyDetails topologyDetails;\n \n-    protected SchedulingResult mkNotEnoughResources(TopologyDetails td) {\n-        return  SchedulingResult.failure(\n-            SchedulingStatus.FAIL_NOT_ENOUGH_RESOURCES,\n-            td.getExecutors().size() + \" executors not scheduled\");\n+    // Instance variables derived from Cluster.\n+    protected RasNodes nodes;\n+    private Map<String, List<String>> networkTopography;\n+    private Map<String, List<RasNode>> hostnameToNodes;\n+\n+    // Instance variables derived from TopologyDetails\n+    protected String topoName;\n+    protected Map<String, Set<ExecutorDetails>> compToExecs;\n+    protected Map<ExecutorDetails, String> execToComp;\n+    protected boolean orderExecutorsByProximity;\n+    private long maxSchedulingTimeMs;\n+\n+    // Instance variables from Cluster and TopologyDetails.\n+    Set<ExecutorDetails> unassignedExecutors;\n+    private int maxStateSearch;\n+    protected SchedulingSearcherState searcherState;\n+    protected IExecSorter execSorter;\n+    protected INodeSorter nodeSorter;\n+\n+    public BaseResourceAwareStrategy() {\n+        this(true, NodeSortType.COMMON);\n     }\n \n     /**\n-     * Schedule executor exec from topology td.\n+     * Initialize for the default implementation of schedule().\n      *\n-     * @param exec           the executor to schedule\n-     * @param td             the topology executor exec is a part of\n-     * @param scheduledTasks executors that have been scheduled\n-     * @return true if scheduled successfully, else false.\n+     * @param sortNodesForEachExecutor Sort nodes before scheduling each executor.\n+     * @param nodeSortType type of sorting to be applied to object resource collection {@link NodeSortType}.\n      */\n-    protected boolean scheduleExecutor(\n-            ExecutorDetails exec, TopologyDetails td, Collection<ExecutorDetails> scheduledTasks, Iterable<String> sortedNodes) {\n-        WorkerSlot targetSlot = findWorkerForExec(exec, td, sortedNodes);\n-        if (targetSlot != null) {\n-            RasNode targetNode = idToNode(targetSlot.getNodeId());\n-            targetNode.assignSingleExecutor(targetSlot, exec, td);\n-            scheduledTasks.add(exec);\n-            LOG.debug(\n-                \"TASK {} assigned to Node: {} avail [ mem: {} cpu: {} ] total [ mem: {} cpu: {} ] on \"\n-                + \"slot: {} on Rack: {}\",\n-                exec,\n-                targetNode.getHostname(),\n-                targetNode.getAvailableMemoryResources(),\n-                targetNode.getAvailableCpuResources(),\n-                targetNode.getTotalMemoryResources(),\n-                targetNode.getTotalCpuResources(),\n-                targetSlot,\n-                nodeToRack(targetNode));\n-            return true;\n-        } else {\n-            String comp = td.getExecutorToComponent().get(exec);\n-            NormalizedResourceRequest requestedResources = td.getTotalResources(exec);\n-            LOG.warn(\"Not Enough Resources to schedule Task {} - {} {}\", exec, comp, requestedResources);\n-            return false;\n-        }\n+    public BaseResourceAwareStrategy(boolean sortNodesForEachExecutor, NodeSortType nodeSortType) {\n+        this.sortNodesForEachExecutor = sortNodesForEachExecutor;\n+        this.nodeSortType = nodeSortType;\n     }\n \n-    protected abstract TreeSet<ObjectResources> sortObjectResources(\n-        AllResources allResources, ExecutorDetails exec, TopologyDetails topologyDetails,\n-        ExistingScheduleFunc existingScheduleFunc\n-    );\n-\n-    /**\n-     * Find a worker to schedule executor exec on.\n-     *\n-     * @param exec the executor to schedule\n-     * @param td   the topology that the executor is a part of\n-     * @return a worker to assign exec on. Returns null if a worker cannot be successfully found in cluster\n-     */\n-    protected WorkerSlot findWorkerForExec(ExecutorDetails exec, TopologyDetails td, Iterable<String> sortedNodes) {\n-        for (String id : sortedNodes) {\n-            RasNode node = nodes.getNodeById(id);\n-            if (node.couldEverFit(exec, td)) {\n-                for (WorkerSlot ws : node.getSlotsAvailableToScheduleOn()) {\n-                    if (node.wouldFit(ws, exec, td)) {\n-                        return ws;\n-                    }\n-                }\n-            }\n-        }\n-        return null;\n+    @Override\n+    public void prepare(Map<String, Object> config) {\n+        this.config = config;\n     }\n \n     /**\n-     * Nodes are sorted by two criteria.\n+     * Note that this method is not thread-safe.\n+     * Several instance variables are generated from supplied\n+     * parameters. In addition, the following instance variables are set to complete scheduling:\n+     *  <li>{@link #searcherState}</li>\n+     *  <li>{@link #execSorter} to sort executors</li>\n+     *  <li>{@link #nodeSorter} to sort nodes</li>\n+     * <p>\n+     * Scheduling consists of three main steps:\n+     *  <li>{@link #prepareForScheduling(Cluster, TopologyDetails)}</li>\n+     *  <li>{@link #checkSchedulingFeasibility()}, and</li>\n+     *  <li>{@link #scheduleExecutorsOnNodes(List, Iterable)}</li>\n+     * </p><p>\n+     * The executors and nodes are sorted in the order most conducive to scheduling for the strategy.\n+     * Those interfaces may be overridden by subclasses using mutators:\n+     *  <li>{@link #setExecSorter(IExecSorter)} and</li>\n+     *  <li>{@link #setNodeSorter(INodeSorter)}</li>\n+     *</p>\n      *\n-     * <p>1) the number executors of the topology that needs to be scheduled is already on the node in\n-     * descending order. The reasoning to sort based on criterion 1 is so we schedule the rest of a topology on the same node as the\n-     * existing executors of the topology.\n-     *\n-     * <p>2) the subordinate/subservient resource availability percentage of a node in descending\n-     * order We calculate the resource availability percentage by dividing the resource availability that have exhausted or little of one of\n-     * the resources mentioned above will be ranked after on the node by the resource availability of the entire rack By doing this\n-     * calculation, nodes nodes that have more balanced resource availability. So we will be less likely to pick a node that have a lot of\n-     * one resource but a low amount of another.\n-     *\n-     * @param availNodes a list of all the nodes we want to sort\n-     * @param rackId     the rack id availNodes are a part of\n-     * @return a sorted list of nodes.\n+     * @param cluster on which executors will be scheduled.\n+     * @param td the topology to schedule for.\n+     * @return result of scheduling (success, failure, or null when interrupted).\n      */\n-    protected TreeSet<ObjectResources> sortNodes(\n-            List<RasNode> availNodes, ExecutorDetails exec, TopologyDetails topologyDetails, String rackId,\n-            Map<String, AtomicInteger> scheduledCount) {\n-        AllResources allRackResources = new AllResources(\"RACK\");\n-        List<ObjectResources> nodes = allRackResources.objectResources;\n-\n-        for (RasNode rasNode : availNodes) {\n-            String superId = rasNode.getId();\n-            ObjectResources node = new ObjectResources(superId);\n-\n-            node.availableResources = rasNode.getTotalAvailableResources();\n-            node.totalResources = rasNode.getTotalResources();\n-\n-            nodes.add(node);\n-            allRackResources.availableResourcesOverall.add(node.availableResources);\n-            allRackResources.totalResourcesOverall.add(node.totalResources);\n-\n-        }\n-\n-        LOG.debug(\n-            \"Rack {}: Overall Avail [ {} ] Total [ {} ]\",\n-            rackId,\n-            allRackResources.availableResourcesOverall,\n-            allRackResources.totalResourcesOverall);\n-\n-        return sortObjectResources(\n-            allRackResources,\n-            exec,\n-            topologyDetails,\n-            (superId) -> {\n-                AtomicInteger count = scheduledCount.get(superId);\n-                if (count == null) {\n-                    return 0;\n-                }\n-                return count.get();\n-            });\n-    }\n-\n-    protected List<String> makeHostToNodeIds(List<String> hosts) {\n-        if (hosts == null) {\n-            return Collections.emptyList();\n-        }\n-        List<String> ret = new ArrayList<>(hosts.size());\n-        for (String host: hosts) {\n-            List<RasNode> nodes = hostnameToNodes.get(host);\n-            if (nodes != null) {\n-                for (RasNode node : nodes) {\n-                    ret.add(node.getId());\n-                }\n-            }\n-        }\n-        return ret;\n-    }\n-\n-    private static class LazyNodeSortingIterator implements Iterator<String> {\n-        private final LazyNodeSorting parent;\n-        private final Iterator<ObjectResources> rackIterator;\n-        private Iterator<ObjectResources> nodeIterator;\n-        private String nextValueFromNode = null;\n-        private final Iterator<String> pre;\n-        private final Iterator<String> post;\n-        private final Set<String> skip;\n-\n-        LazyNodeSortingIterator(LazyNodeSorting parent,\n-                                       TreeSet<ObjectResources> sortedRacks) {\n-            this.parent = parent;\n-            rackIterator = sortedRacks.iterator();\n-            pre = parent.favoredNodeIds.iterator();\n-            post = Stream.concat(parent.unFavoredNodeIds.stream(), parent.greyListedSupervisorIds.stream())\n-                            .collect(Collectors.toList())\n-                            .iterator();\n-            skip = parent.skippedNodeIds;\n-        }\n-\n-        private Iterator<ObjectResources> getNodeIterator() {\n-            if (nodeIterator != null && nodeIterator.hasNext()) {\n-                return nodeIterator;\n-            }\n-            //need to get the next node iterator\n-            if (rackIterator.hasNext()) {\n-                ObjectResources rack = rackIterator.next();\n-                final String rackId = rack.id;\n-                nodeIterator = parent.getSortedNodesFor(rackId).iterator();\n-                return nodeIterator;\n-            }\n-\n-            return null;\n-        }\n-\n-        @Override\n-        public boolean hasNext() {\n-            if (pre.hasNext()) {\n-                return true;\n-            }\n-            if (nextValueFromNode != null) {\n-                return true;\n-            }\n-            while (true) {\n-                //For the node we don't know if we have another one unless we look at the contents\n-                Iterator<ObjectResources> nodeIterator = getNodeIterator();\n-                if (nodeIterator == null || !nodeIterator.hasNext()) {\n-                    break;\n-                }\n-                String tmp = nodeIterator.next().id;\n-                if (!skip.contains(tmp)) {\n-                    nextValueFromNode = tmp;\n-                    return true;\n-                }\n-            }\n-            if (post.hasNext()) {\n-                return true;\n-            }\n-            return false;\n-        }\n-\n-        @Override\n-        public String next() {\n-            if (!hasNext()) {\n-                throw new NoSuchElementException();\n-            }\n-            if (pre.hasNext()) {\n-                return pre.next();\n-            }\n-            if (nextValueFromNode != null) {\n-                String tmp = nextValueFromNode;\n-                nextValueFromNode = null;\n-                return tmp;\n-            }\n-            return post.next();\n-        }\n-    }\n-\n-    private class LazyNodeSorting implements Iterable<String> {\n-        private final Map<String, AtomicInteger> perNodeScheduledCount = new HashMap<>();\n-        private final TreeSet<ObjectResources> sortedRacks;\n-        private final Map<String, TreeSet<ObjectResources>> cachedNodes = new HashMap<>();\n-        private final ExecutorDetails exec;\n-        private final TopologyDetails td;\n-        private final List<String> favoredNodeIds;\n-        private final List<String> unFavoredNodeIds;\n-        private final List<String> greyListedSupervisorIds;\n-        private final Set<String> skippedNodeIds = new HashSet<>();\n-\n-        LazyNodeSorting(TopologyDetails td, ExecutorDetails exec,\n-                               List<String> favoredNodeIds, List<String> unFavoredNodeIds) {\n-            this.favoredNodeIds = favoredNodeIds;\n-            this.unFavoredNodeIds = unFavoredNodeIds;\n-            this.greyListedSupervisorIds = cluster.getGreyListedSupervisors();\n-            this.unFavoredNodeIds.removeAll(favoredNodeIds);\n-            this.favoredNodeIds.removeAll(greyListedSupervisorIds);\n-            this.unFavoredNodeIds.removeAll(greyListedSupervisorIds);\n-            skippedNodeIds.addAll(favoredNodeIds);\n-            skippedNodeIds.addAll(unFavoredNodeIds);\n-            skippedNodeIds.addAll(greyListedSupervisorIds);\n-\n-            this.td = td;\n-            this.exec = exec;\n-            String topoId = td.getId();\n-            SchedulerAssignment assignment = cluster.getAssignmentById(topoId);\n-            if (assignment != null) {\n-                for (Map.Entry<WorkerSlot, Collection<ExecutorDetails>> entry :\n-                    assignment.getSlotToExecutors().entrySet()) {\n-                    String superId = entry.getKey().getNodeId();\n-                    perNodeScheduledCount.computeIfAbsent(superId, (sid) -> new AtomicInteger(0))\n-                        .getAndAdd(entry.getValue().size());\n-                }\n-            }\n-            sortedRacks = sortRacks(exec, td);\n-        }\n-\n-        private TreeSet<ObjectResources> getSortedNodesFor(String rackId) {\n-            return cachedNodes.computeIfAbsent(rackId,\n-                (rid) -> sortNodes(rackIdToNodes.getOrDefault(rid, Collections.emptyList()), exec, td, rid, perNodeScheduledCount));\n-        }\n-\n-        @Override\n-        public Iterator<String> iterator() {\n-            return new LazyNodeSortingIterator(this, sortedRacks);\n-        }\n-    }\n-\n-    protected Iterable<String> sortAllNodes(TopologyDetails td, ExecutorDetails exec,\n-                                            List<String> favoredNodeIds, List<String> unFavoredNodeIds) {\n-        return new LazyNodeSorting(td, exec, favoredNodeIds, unFavoredNodeIds);\n-    }\n-\n-    private AllResources createClusterAllResources() {\n-        AllResources allResources = new AllResources(\"Cluster\");\n-        List<ObjectResources> racks = allResources.objectResources;\n-\n-        //This is the first time so initialize the resources.\n-        for (Map.Entry<String, List<String>> entry : networkTopography.entrySet()) {\n-            String rackId = entry.getKey();\n-            List<String> nodeHosts = entry.getValue();\n-            ObjectResources rack = new ObjectResources(rackId);\n-            racks.add(rack);\n-            for (String nodeHost : nodeHosts) {\n-                for (RasNode node : hostnameToNodes(nodeHost)) {\n-                    rack.availableResources.add(node.getTotalAvailableResources());\n-                    rack.totalResources.add(node.getTotalAvailableResources());\n-                }\n-            }\n-\n-            allResources.totalResourcesOverall.add(rack.totalResources);\n-            allResources.availableResourcesOverall.add(rack.availableResources);\n+    @Override\n+    public SchedulingResult schedule(Cluster cluster, TopologyDetails td) {\n+        prepareForScheduling(cluster, td);\n+        // early detection of success or failure\n+        SchedulingResult earlyResult = checkSchedulingFeasibility();\n+        if (earlyResult != null) {\n+            return earlyResult;\n         }\n \n-        LOG.debug(\n-            \"Cluster Overall Avail [ {} ] Total [ {} ]\",\n-            allResources.availableResourcesOverall,\n-            allResources.totalResourcesOverall);\n-        return allResources;\n-    }\n+        LOG.debug(\"Topology {} {} Number of ExecutorsNeedScheduling: {}\", topoName, topologyDetails.getId(), unassignedExecutors.size());\n \n-    private Map<String, AtomicInteger> getScheduledCount(TopologyDetails topologyDetails) {\n-        String topoId = topologyDetails.getId();\n-        SchedulerAssignment assignment = cluster.getAssignmentById(topoId);\n-        Map<String, AtomicInteger> scheduledCount = new HashMap<>();\n-        if (assignment != null) {\n-            for (Map.Entry<WorkerSlot, Collection<ExecutorDetails>> entry :\n-                assignment.getSlotToExecutors().entrySet()) {\n-                String superId = entry.getKey().getNodeId();\n-                String rackId = superIdToRack.get(superId);\n-                scheduledCount.computeIfAbsent(rackId, (rid) -> new AtomicInteger(0))\n-                    .getAndAdd(entry.getValue().size());\n-            }\n+        //order executors to be scheduled\n+        List<ExecutorDetails> orderedExecutors = execSorter.sortExecutors(unassignedExecutors);\n+        Iterable<String> sortedNodes = null;\n+        if (!this.sortNodesForEachExecutor) {\n+            sortedNodes = nodeSorter.sortAllNodes(null);\n         }\n-        return scheduledCount;\n+        return scheduleExecutorsOnNodes(orderedExecutors, sortedNodes);\n     }\n \n     /**\n-     * Racks are sorted by two criteria.\n-     *\n-     * <p>1) the number executors of the topology that needs to be scheduled is already on the rack in descending order.\n-     * The reasoning to sort based on criterion 1 is so we schedule the rest of a topology on the same rack as the existing executors of the\n-     * topology.\n+     * Initialize instance variables as the first step in {@link #schedule(Cluster, TopologyDetails)}.\n+     * This method may be extended by subclasses to initialize additional variables as in\n+     * {@link ConstraintSolverStrategy#prepareForScheduling(Cluster, TopologyDetails)}.\n      *\n-     * <p>2) the subordinate/subservient resource availability percentage of a rack in descending order We calculate\n-     * the resource availability percentage by dividing the resource availability on the rack by the resource availability of the  entire\n-     * cluster By doing this calculation, racks that have exhausted or little of one of the resources mentioned above will be ranked after\n-     * racks that have more balanced resource availability. So we will be less likely to pick a rack that have a lot of one resource but a\n-     * low amount of another.\n-     *\n-     * @return a sorted list of racks\n+     * @param cluster on which executors will be scheduled.\n+     * @param topologyDetails to be scheduled.\n      */\n-    @VisibleForTesting\n-    TreeSet<ObjectResources> sortRacks(ExecutorDetails exec, TopologyDetails topologyDetails) {\n-\n-        final AllResources allResources = createClusterAllResources();\n-        final Map<String, AtomicInteger> scheduledCount = getScheduledCount(topologyDetails);\n-\n-        return sortObjectResources(\n-            allResources,\n-            exec,\n-            topologyDetails,\n-            (rackId) -> {\n-                AtomicInteger count = scheduledCount.get(rackId);\n-                if (count == null) {\n-                    return 0;\n-                }\n-                return count.get();\n-            });\n+    protected void prepareForScheduling(Cluster cluster, TopologyDetails topologyDetails) {\n+        this.cluster = cluster;\n+        this.topologyDetails = topologyDetails;\n+\n+        // from Cluster\n+        this.nodes = new RasNodes(cluster);\n+        networkTopography = cluster.getNetworkTopography();\n+        hostnameToNodes = this.nodes.getHostnameToNodes();\n+\n+        // from TopologyDetails\n+        topoName = topologyDetails.getName();\n+        execToComp = topologyDetails.getExecutorToComponent();\n+        compToExecs = topologyDetails.getComponentToExecutors();\n+        Map<String, Object> topoConf = topologyDetails.getConf();\n+        orderExecutorsByProximity = isOrderByProximity(topoConf);\n+        maxSchedulingTimeMs = computeMaxSchedulingTimeMs(topoConf);\n+\n+        // From Cluster and TopologyDetails - and cleaned-up\n+        unassignedExecutors = Collections.unmodifiableSet(new HashSet<>(cluster.getUnassignedExecutors(topologyDetails)));\n+        int confMaxStateSearch = getMaxStateSearchFromTopoConf(topologyDetails.getConf());\n+        int daemonMaxStateSearch = ObjectReader.getInt(cluster.getConf().get(DaemonConfig.RESOURCE_AWARE_SCHEDULER_MAX_STATE_SEARCH));\n+        maxStateSearch = Math.min(daemonMaxStateSearch, confMaxStateSearch);\n+        LOG.debug(\"The max state search configured by topology {} is {}\", topologyDetails.getId(), confMaxStateSearch);\n+        LOG.debug(\"The max state search that will be used by topology {} is {}\", topologyDetails.getId(), maxStateSearch);\n+\n+        searcherState = createSearcherState();\n+        setNodeSorter(new NodeSorter(cluster, topologyDetails, nodeSortType));\n+        setExecSorter(orderExecutorsByProximity\n+                ? new ExecSorterByProximity(topologyDetails)\n+                : new ExecSorterByConnectionCount(topologyDetails));\n+\n+        logClusterInfo();\n     }\n \n     /**\n-     * Get the rack on which a node is a part of.\n+     * Set the pluggable sorter for ExecutorDetails.\n      *\n-     * @param node the node to find out which rack its on\n-     * @return the rack id\n+     * @param execSorter to use for sorting executorDetails when scheduling.\n      */\n-    protected String nodeToRack(RasNode node) {\n-        return superIdToRack.get(node.getId());\n+    protected void setExecSorter(IExecSorter execSorter) {\n+        this.execSorter = execSorter;\n     }\n \n     /**\n-     * sort components by the number of in and out connections that need to be made, in descending order.\n+     * Set the pluggable sorter for Nodes.\n      *\n-     * @param componentMap The components that need to be sorted\n-     * @return a sorted set of components\n+     * @param nodeSorter to use for sorting nodes when scheduling.\n      */\n-    private Set<Component> sortComponents(final Map<String, Component> componentMap) {\n-        Set<Component> sortedComponents =\n-            new TreeSet<>((o1, o2) -> {\n-                int connections1 = 0;\n-                int connections2 = 0;\n-\n-                for (String childId : Sets.union(o1.getChildren(), o1.getParents())) {\n-                    connections1 +=\n-                        (componentMap.get(childId).getExecs().size() * o1.getExecs().size());\n-                }\n-\n-                for (String childId : Sets.union(o2.getChildren(), o2.getParents())) {\n-                    connections2 +=\n-                        (componentMap.get(childId).getExecs().size() * o2.getExecs().size());\n-                }\n-\n-                if (connections1 > connections2) {\n-                    return -1;\n-                } else if (connections1 < connections2) {\n-                    return 1;\n-                } else {\n-                    return o1.getId().compareTo(o2.getId());\n-                }\n-            });\n-        sortedComponents.addAll(componentMap.values());\n-        return sortedComponents;\n+    protected void setNodeSorter(INodeSorter nodeSorter) {\n+        this.nodeSorter = nodeSorter;\n     }\n \n-    /**\n-     * Sort a component's neighbors by the number of connections it needs to make with this component.\n-     *\n-     * @param thisComp     the component that we need to sort its neighbors\n-     * @param componentMap all the components to sort\n-     * @return a sorted set of components\n-     */\n-    private Set<Component> sortNeighbors(\n-        final Component thisComp, final Map<String, Component> componentMap) {\n-        Set<Component> sortedComponents =\n-            new TreeSet<>((o1, o2) -> {\n-                int connections1 = o1.getExecs().size() * thisComp.getExecs().size();\n-                int connections2 = o2.getExecs().size() * thisComp.getExecs().size();\n-                if (connections1 < connections2) {\n-                    return -1;\n-                } else if (connections1 > connections2) {\n-                    return 1;\n-                } else {\n-                    return o1.getId().compareTo(o2.getId());\n-                }\n-            });\n-        sortedComponents.addAll(componentMap.values());\n-        return sortedComponents;\n+    private static long computeMaxSchedulingTimeMs(Map<String, Object> topoConf) {\n+        // expect to be killed by DaemonConfig.SCHEDULING_TIMEOUT_SECONDS_PER_TOPOLOGY seconds, terminate slightly before\n+        int daemonMaxTimeSec = ObjectReader.getInt(topoConf.get(DaemonConfig.SCHEDULING_TIMEOUT_SECONDS_PER_TOPOLOGY), 60);\n+        int confMaxTimeSec = ObjectReader.getInt(topoConf.get(Config.TOPOLOGY_RAS_CONSTRAINT_MAX_TIME_SECS), daemonMaxTimeSec);\n+        return (confMaxTimeSec >= daemonMaxTimeSec) ? daemonMaxTimeSec * 1000L - 200L :  confMaxTimeSec * 1000L;\n     }\n \n-    protected List<ExecutorDetails> orderExecutors(\n-        TopologyDetails td, Collection<ExecutorDetails> unassignedExecutors) {\n-        Boolean orderByProximity = ObjectReader.getBoolean(\n-            td.getConf().get(Config.TOPOLOGY_RAS_ORDER_EXECUTORS_BY_PROXIMITY_NEEDS), false);\n-        if (!orderByProximity) {\n-            return orderExecutorsDefault(td, unassignedExecutors);\n+    public static int getMaxStateSearchFromTopoConf(Map<String, Object> topoConf) {\n+        int confMaxStateSearch;\n+        if (topoConf.containsKey(Config.TOPOLOGY_RAS_CONSTRAINT_MAX_STATE_SEARCH)) {\n+            //this config is always set for topologies of 2.0 or newer versions since it is in defaults.yaml file\n+            //topologies of older versions can also use it if configures it explicitly\n+            confMaxStateSearch = ObjectReader.getInt(topoConf.get(Config.TOPOLOGY_RAS_CONSTRAINT_MAX_STATE_SEARCH));\n         } else {\n-            LOG.info(\"{} is set to true\", Config.TOPOLOGY_RAS_ORDER_EXECUTORS_BY_PROXIMITY_NEEDS);\n-            return orderExecutorsByProximityNeeds(td, unassignedExecutors);\n+            // For backwards compatibility\n+            confMaxStateSearch = 10_000;\n         }\n+        return confMaxStateSearch;\n     }\n \n-    /**\n-     * Order executors based on how many in and out connections it will potentially need to make, in descending order. First order\n-     * components by the number of in and out connections it will have.  Then iterate through the sorted list of components. For each\n-     * component sort the neighbors of that component by how many connections it will have to make with that component. Add an executor from\n-     * this component and then from each neighboring component in sorted order. Do this until there is nothing left to schedule.\n-     *\n-     * @param td                  The topology the executors belong to\n-     * @param unassignedExecutors a collection of unassigned executors that need to be assigned. Should only try to assign executors from\n-     *                            this list\n-     * @return a list of executors in sorted order\n-     */\n-    private List<ExecutorDetails> orderExecutorsDefault(\n-        TopologyDetails td, Collection<ExecutorDetails> unassignedExecutors) {\n-        Map<String, Component> componentMap = td.getComponents();\n-        List<ExecutorDetails> execsScheduled = new LinkedList<>();\n-\n-        Map<String, Queue<ExecutorDetails>> compToExecsToSchedule = new HashMap<>();\n-        for (Component component : componentMap.values()) {\n-            compToExecsToSchedule.put(component.getId(), new LinkedList<>());\n-            for (ExecutorDetails exec : component.getExecs()) {\n-                if (unassignedExecutors.contains(exec)) {\n-                    compToExecsToSchedule.get(component.getId()).add(exec);\n-                }\n+    public static boolean isOrderByProximity(Map<String, Object> topoConf) {\n+        Boolean orderByProximity = (Boolean) topoConf.get(Config.TOPOLOGY_RAS_ORDER_EXECUTORS_BY_PROXIMITY_NEEDS);\n+        if (orderByProximity == null) {\n+            orderByProximity = (Boolean) topoConf.get(EXPERIMENTAL_TOPOLOGY_RAS_ORDER_EXECUTORS_BY_PROXIMITY_NEEDS);\n+            if (orderByProximity == null) {\n+                orderByProximity = false;\n+            } else {\n+                LOG.warn(\"{} is deprecated; please use {} instead\", EXPERIMENTAL_TOPOLOGY_RAS_ORDER_EXECUTORS_BY_PROXIMITY_NEEDS,\n+                        Config.TOPOLOGY_RAS_ORDER_EXECUTORS_BY_PROXIMITY_NEEDS);\n             }\n         }\n-\n-        Set<Component> sortedComponents = sortComponents(componentMap);\n-        sortedComponents.addAll(componentMap.values());\n-\n-        for (Component currComp : sortedComponents) {\n-            Map<String, Component> neighbors = new HashMap<>();\n-            for (String compId : Sets.union(currComp.getChildren(), currComp.getParents())) {\n-                neighbors.put(compId, componentMap.get(compId));\n-            }\n-            Set<Component> sortedNeighbors = sortNeighbors(currComp, neighbors);\n-            Queue<ExecutorDetails> currCompExesToSched = compToExecsToSchedule.get(currComp.getId());\n-\n-            boolean flag = false;\n-            do {\n-                flag = false;\n-                if (!currCompExesToSched.isEmpty()) {\n-                    execsScheduled.add(currCompExesToSched.poll());\n-                    flag = true;\n-                }\n-\n-                for (Component neighborComp : sortedNeighbors) {\n-                    Queue<ExecutorDetails> neighborCompExesToSched =\n-                        compToExecsToSchedule.get(neighborComp.getId());\n-                    if (!neighborCompExesToSched.isEmpty()) {\n-                        execsScheduled.add(neighborCompExesToSched.poll());\n-                        flag = true;\n-                    }\n-                }\n-            } while (flag);\n-        }\n-        return execsScheduled;\n+        return orderByProximity;\n     }\n \n     /**\n-     * Order executors by network proximity needs.\n-     * @param td The topology the executors belong to\n-     * @param unassignedExecutors a collection of unassigned executors that need to be unassigned. Should only try to\n-     *     assign executors from this list\n-     * @return a list of executors in sorted order\n+     * Create an instance of {@link SchedulingSearcherState}. This method is called by\n+     * {@link #prepareForScheduling(Cluster, TopologyDetails)} and depends on variables initialized therein prior.\n+     *\n+     * @return a new instance of {@link SchedulingSearcherState}.\n      */\n-    private List<ExecutorDetails> orderExecutorsByProximityNeeds(\n-        TopologyDetails td, Collection<ExecutorDetails> unassignedExecutors) {\n-        Map<String, Component> componentMap = td.getComponents();\n-        List<ExecutorDetails> execsScheduled = new LinkedList<>();\n-\n-        Map<String, Queue<ExecutorDetails>> compToExecsToSchedule = new HashMap<>();\n-        for (Component component : componentMap.values()) {\n-            compToExecsToSchedule.put(component.getId(), new LinkedList<>());\n-            for (ExecutorDetails exec : component.getExecs()) {\n-                if (unassignedExecutors.contains(exec)) {\n-                    compToExecsToSchedule.get(component.getId()).add(exec);\n-                }\n-            }\n-        }\n-\n-        List<Component> sortedComponents = topologicalSortComponents(componentMap);\n-\n-        for (Component currComp: sortedComponents) {\n-            int numExecs = compToExecsToSchedule.get(currComp.getId()).size();\n-            for (int i = 0; i < numExecs; i++) {\n-                execsScheduled.addAll(takeExecutors(currComp, componentMap, compToExecsToSchedule));\n-            }\n+    private SchedulingSearcherState createSearcherState() {\n+        Map<WorkerSlot, Map<String, Integer>> workerCompCnts = new HashMap<>();\n+        Map<RasNode, Map<String, Integer>> nodeCompCnts = new HashMap<>();\n+\n+        //populate with existing assignments\n+        SchedulerAssignment existingAssignment = cluster.getAssignmentById(topologyDetails.getId());\n+        if (existingAssignment != null) {\n+            existingAssignment.getExecutorToSlot().forEach((exec, ws) -> {\n+                String compId = execToComp.get(exec);\n+                RasNode node = nodes.getNodeById(ws.getNodeId());\n+                Map<String, Integer> compCnts = nodeCompCnts.computeIfAbsent(node, (k) -> new HashMap<>());\n+                compCnts.put(compId, compCnts.getOrDefault(compId, 0) + 1); // increment\n+                //populate worker to comp assignments\n+                compCnts = workerCompCnts.computeIfAbsent(ws, (k) -> new HashMap<>());\n+                compCnts.put(compId, compCnts.getOrDefault(compId, 0) + 1); // increment\n+            });\n         }\n \n-        return execsScheduled;\n+        return new SchedulingSearcherState(workerCompCnts, nodeCompCnts,\n+                maxStateSearch, maxSchedulingTimeMs, new ArrayList<>(unassignedExecutors), topologyDetails, execToComp);\n     }\n \n     /**\n-     * Sort components topologically.\n-     * @param componentMap The map of component Id to Component Object.\n-     * @return The sorted components\n+     * Check scheduling feasibility for a quick failure as the second step in {@link #schedule(Cluster, TopologyDetails)}.\n+     * If scheduling is not possible, then return a SchedulingStatus object with a failure status.\n+     * If fully scheduled then return a successful SchedulingStatus.\n+     * This method can be extended by subclasses {@link ConstraintSolverStrategy#checkSchedulingFeasibility()}\n+     * to check for additional failure conditions.\n+     *\n+     * @return A non-null {@link SchedulingResult} to terminate scheduling, otherwise return null to continue scheduling.\n      */\n-    private List<Component> topologicalSortComponents(final Map<String, Component> componentMap) {\n-        List<Component> sortedComponents = new ArrayList<>();\n-        boolean[] visited = new boolean[componentMap.size()];\n-        int[] inDegree = new int[componentMap.size()];\n-        List<String> componentIds = new ArrayList<>(componentMap.keySet());\n-        Map<String, Integer> compIdToIndex = new HashMap<>();\n-        for (int i = 0; i < componentIds.size(); i++) {\n-            compIdToIndex.put(componentIds.get(i), i);\n-        }\n-        //initialize the in-degree array\n-        for (int i = 0; i < inDegree.length; i++) {\n-            String compId = componentIds.get(i);\n-            Component comp = componentMap.get(compId);\n-            for (String childId : comp.getChildren()) {\n-                inDegree[compIdToIndex.get(childId)] += 1;\n-            }\n-        }\n-        //sorting components topologically\n-        for (int t = 0; t < inDegree.length; t++) {\n-            for (int i = 0; i < inDegree.length; i++) {\n-                if (inDegree[i] == 0 && !visited[i]) {\n-                    String compId = componentIds.get(i);\n-                    Component comp = componentMap.get(compId);\n-                    sortedComponents.add(comp);\n-                    visited[i] = true;\n-                    for (String childId : comp.getChildren()) {\n-                        inDegree[compIdToIndex.get(childId)]--;\n-                    }\n-                    break;\n-                }\n-            }\n+    protected SchedulingResult checkSchedulingFeasibility() {\n+        if (unassignedExecutors.isEmpty()) {\n+            return SchedulingResult.success(\"Fully Scheduled by \" + this.getClass().getSimpleName());\n         }\n-        return sortedComponents;\n-    }\n \n-    /**\n-     * Take unscheduled executors from current and all its downstream components in a particular order.\n-     * First, take one executor from the current component;\n-     * then for every child (direct downstream component) of this component,\n-     *     if it's shuffle grouping from the current component to this child,\n-     *         the number of executors to take from this child is the max of\n-     *         1 and (the number of unscheduled executors this child has / the number of unscheduled executors the current component has);\n-     *     otherwise, the number of executors to take is 1;\n-     *     for every executor to take from this child, call takeExecutors(...).\n-     * @param currComp The current component.\n-     * @param componentMap The map from component Id to component object.\n-     * @param compToExecsToSchedule The map from component Id to unscheduled executors.\n-     * @return The executors to schedule in order.\n-     */\n-    private List<ExecutorDetails> takeExecutors(Component currComp,\n-                                                final Map<String, Component> componentMap,\n-                                                final Map<String, Queue<ExecutorDetails>> compToExecsToSchedule) {\n-        List<ExecutorDetails> execsScheduled = new ArrayList<>();\n-        Queue<ExecutorDetails> currQueue = compToExecsToSchedule.get(currComp.getId());\n-        int currUnscheduledNumExecs = currQueue.size();\n-        //Just for defensive programming as this won't actually happen.\n-        if (currUnscheduledNumExecs == 0) {\n-            return execsScheduled;\n-        }\n-        execsScheduled.add(currQueue.poll());\n-        Set<String> sortedChildren = getSortedChildren(currComp, componentMap);\n-        for (String childId: sortedChildren) {\n-            Component childComponent = componentMap.get(childId);\n-            Queue<ExecutorDetails> childQueue = compToExecsToSchedule.get(childId);\n-            int childUnscheduledNumExecs = childQueue.size();\n-            if (childUnscheduledNumExecs == 0) {\n-                continue;\n-            }\n-            int numExecsToTake = 1;\n-            if (hasShuffleGroupingFromParentToChild(currComp, childComponent)) {\n-                // if it's shuffle grouping, truncate\n-                numExecsToTake = Math.max(1, childUnscheduledNumExecs / currUnscheduledNumExecs);\n-            } // otherwise, one-by-one\n-            for (int i = 0; i < numExecsToTake; i++) {\n-                execsScheduled.addAll(takeExecutors(childComponent, componentMap, compToExecsToSchedule));\n-            }\n+        String err;\n+        if (nodes.getNodes().size() <= 0) {\n+            err = \"No available nodes to schedule tasks on!\";\n+            LOG.warn(\"Topology {}:{}\", topoName, err);\n+            return SchedulingResult.failure(SchedulingStatus.FAIL_NOT_ENOUGH_RESOURCES, err);\n         }\n-        return execsScheduled;\n-    }\n \n-    private Set<String> getSortedChildren(Component component, final Map<String, Component> componentMap) {\n-        Set<String> children = component.getChildren();\n-        Set<String> sortedChildren =\n-            new TreeSet<>((o1, o2) -> {\n-                Component child1 = componentMap.get(o1);\n-                Component child2 = componentMap.get(o2);\n-                boolean child1IsShuffle = hasShuffleGroupingFromParentToChild(component, child1);\n-                boolean child2IsShuffle = hasShuffleGroupingFromParentToChild(component, child2);\n-                if (child1IsShuffle && child2IsShuffle) {\n-                    return o1.compareTo(o2);\n-                } else if (child1IsShuffle) {\n-                    return 1;\n-                } else {\n-                    return -1;\n-                }\n-            });\n-        sortedChildren.addAll(children);\n-        return sortedChildren;\n-    }\n+        if (!topologyDetails.hasSpouts()) {\n+            err = \"Cannot find a Spout!\";\n+            LOG.error(\"Topology {}:{}\", topoName, err);\n+            return SchedulingResult.failure(SchedulingStatus.FAIL_INVALID_TOPOLOGY, err);\n+        }\n \n-    private boolean hasShuffleGroupingFromParentToChild(Component parent, Component child) {\n-        for (Map.Entry<GlobalStreamId, Grouping> inputEntry: child.getInputs().entrySet()) {\n-            GlobalStreamId globalStreamId = inputEntry.getKey();\n-            Grouping grouping = inputEntry.getValue();\n-            if (globalStreamId.get_componentId().equals(parent.getId())\n-                && (inputEntry.getValue().is_set_local_or_shuffle() || grouping.is_set_shuffle())) {\n-                return true;\n-            }\n+        int execCnt = unassignedExecutors.size();\n+        if (execCnt >= maxStateSearch) {\n+            err = String.format(\"Unassignerd Executor count (%d) is greater than searchable state count %d\", execCnt, maxStateSearch);\n+            LOG.error(\"Topology {}:{}\", topoName, err);\n+            return SchedulingResult.failure(SchedulingStatus.FAIL_OTHER, err);\n         }\n-        return false;\n+\n+        return null;\n     }\n \n     /**\n-     * Get a list of all the spouts in the topology.\n+     * Check if the assignment of the executor to the worker is valid. In simple cases,\n+     * this is simply a check of {@link RasNode#wouldFit(WorkerSlot, ExecutorDetails, TopologyDetails)}.\n+     * This method may be extended by subclasses to add additional checks,\n+     * see {@link ConstraintSolverStrategy#isExecAssignmentToWorkerValid(ExecutorDetails, WorkerSlot)}.\n      *\n-     * @param td topology to get spouts from\n-     * @return a list of spouts\n+     * @param exec being scheduled.\n+     * @param worker on which to schedule.\n+     * @return true if executor can be assigned to the worker, false otherwise.\n      */\n-    protected List<Component> getSpouts(TopologyDetails td) {\n-        List<Component> spouts = new ArrayList<>();\n-\n-        for (Component c : td.getComponents().values()) {\n-            if (c.getType() == ComponentType.SPOUT) {\n-                spouts.add(c);\n-            }\n+    protected boolean isExecAssignmentToWorkerValid(ExecutorDetails exec, WorkerSlot worker) {\n+        //check resources\n+        RasNode node = nodes.getNodeById(worker.getNodeId());\n+        if (!node.wouldFit(worker, exec, topologyDetails)) {\n+            LOG.trace(\"Topology {}, executor {} would not fit in resources available on worker {}\", topoName, exec, worker);\n+            return false;\n         }\n-        return spouts;\n+        return true;\n     }\n \n+    /**\n+     * If this config is set to true, unassigned executors will be sorted by topological order with network proximity needs.\n+     * @deprecated Use {@link Config#TOPOLOGY_RAS_ORDER_EXECUTORS_BY_PROXIMITY_NEEDS} instead.\n+     */\n+    @Deprecated\n+    public static final String EXPERIMENTAL_TOPOLOGY_RAS_ORDER_EXECUTORS_BY_PROXIMITY_NEEDS", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "50e7cded75648a0ee2fddea697f522f630c817ed"}, "originalPosition": 962}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDMxOTUzNg==", "bodyText": "ObjectResourceSortType doesn't exist.", "url": "https://github.com/apache/storm/pull/3328#discussion_r490319536", "createdAt": "2020-09-17T14:56:21Z", "author": {"login": "Ethanlm"}, "path": "storm-server/src/main/java/org/apache/storm/scheduler/resource/strategies/scheduling/IStrategy.java", "diffHunk": "@@ -19,21 +19,29 @@\n \n /**\n  * An interface to for implementing different scheduling strategies for the resource aware scheduling.\n+ * Scheduler should call {@link #prepare(Map)} followed by {@link #schedule(Cluster, TopologyDetails)}.\n+ * <p>\n+ *     A fully functioning implementation is in the abstract class {@link BaseResourceAwareStrategy}.\n+ *     Subclasses classes should extend {@link BaseResourceAwareStrategy#BaseResourceAwareStrategy(boolean, ObjectResourceSortType)}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "50e7cded75648a0ee2fddea697f522f630c817ed"}, "originalPosition": 7}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8b47ccf6211f21b35e0c3f42a3a1dbf447a2cab5", "author": {"user": null}, "url": "https://github.com/apache/storm/commit/8b47ccf6211f21b35e0c3f42a3a1dbf447a2cab5", "committedDate": "2020-09-18T02:07:36Z", "message": "[STORM-3691] Fix javadoc and remove EXPERIMENTAL_TOPOLOGY_RAS_ORDER_EXECUTORS_BY_PROXIMITY_NEEDS."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "1f90ca39b25c3718ef9cebf7bacaf99f8aead836", "author": {"user": null}, "url": "https://github.com/apache/storm/commit/1f90ca39b25c3718ef9cebf7bacaf99f8aead836", "committedDate": "2020-09-17T23:42:12Z", "message": "[STORM-3691] Fix javadoc and remove EXPERIMENTAL_TOPOLOGY_RAS_ORDER_EXECUTORS_BY_PROXIMITY_NEEDS."}, "afterCommit": {"oid": "8b47ccf6211f21b35e0c3f42a3a1dbf447a2cab5", "author": {"user": null}, "url": "https://github.com/apache/storm/commit/8b47ccf6211f21b35e0c3f42a3a1dbf447a2cab5", "committedDate": "2020-09-18T02:07:36Z", "message": "[STORM-3691] Fix javadoc and remove EXPERIMENTAL_TOPOLOGY_RAS_ORDER_EXECUTORS_BY_PROXIMITY_NEEDS."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDkxNDc3NTY3", "url": "https://github.com/apache/storm/pull/3328#pullrequestreview-491477567", "createdAt": "2020-09-18T13:44:08Z", "commit": {"oid": "8b47ccf6211f21b35e0c3f42a3a1dbf447a2cab5"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDkxNTI3MTk2", "url": "https://github.com/apache/storm/pull/3328#pullrequestreview-491527196", "createdAt": "2020-09-18T14:39:13Z", "commit": {"oid": "8b47ccf6211f21b35e0c3f42a3a1dbf447a2cab5"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4919, "cost": 1, "resetAt": "2021-11-01T11:59:11Z"}}}