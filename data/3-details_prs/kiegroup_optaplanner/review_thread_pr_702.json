{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzc4OTQwMDU3", "number": 702, "reviewThreads": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQxMToyOTowMlrODiS0Gg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQxNTo0NToyMFrODiX_HQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3Mjg2NDI2OnYy", "diffSide": "RIGHT", "path": "optaplanner-core/src/main/java/org/optaplanner/core/api/score/stream/bi/BiConstraintStream.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQxMToyOTowMlrOFtdeDQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQxNTozNDoyN1rOFtk_2A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzIxMzA2OQ==", "bodyText": "I do not know how we missed this, but until now, filtering joiners were not supported for tri/quad joins. (The API allowed it, but threw a runtime exception.) Filtering joiners only ever worked with bi joins.\nThis PR adds test coverage that uncovered the problem, and so I also add the fix. The fix is to bring the code to functional equivalence with bi joins.", "url": "https://github.com/kiegroup/optaplanner/pull/702#discussion_r383213069", "createdAt": "2020-02-24T11:29:02Z", "author": {"login": "triceo"}, "path": "optaplanner-core/src/main/java/org/optaplanner/core/api/score/stream/bi/BiConstraintStream.java", "diffHunk": "@@ -196,7 +198,42 @@\n      * {@link TriJoiner joiners} are true\n      */\n     default <C> TriConstraintStream<A, B, C> join(Class<C> otherClass, TriJoiner<A, B, C>... joiners) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dc4d32fdd887477a1847fea9ba9d0de553e24a00"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzIyNzI5Mg==", "bodyText": "Would they Sonar test coverage report allowed us to detect this test coverage gap? If so it might be worth checking if all api classes have any uncovered lines that matter enough to warren test coverage.", "url": "https://github.com/kiegroup/optaplanner/pull/702#discussion_r383227292", "createdAt": "2020-02-24T12:04:18Z", "author": {"login": "ge0ffrey"}, "path": "optaplanner-core/src/main/java/org/optaplanner/core/api/score/stream/bi/BiConstraintStream.java", "diffHunk": "@@ -196,7 +198,42 @@\n      * {@link TriJoiner joiners} are true\n      */\n     default <C> TriConstraintStream<A, B, C> join(Class<C> otherClass, TriJoiner<A, B, C>... joiners) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzIxMzA2OQ=="}, "originalCommit": {"oid": "dc4d32fdd887477a1847fea9ba9d0de553e24a00"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzMzNjQwOA==", "bodyText": "Yeah, this would have been caught if we had that test. We do now.", "url": "https://github.com/kiegroup/optaplanner/pull/702#discussion_r383336408", "createdAt": "2020-02-24T15:34:27Z", "author": {"login": "triceo"}, "path": "optaplanner-core/src/main/java/org/optaplanner/core/api/score/stream/bi/BiConstraintStream.java", "diffHunk": "@@ -196,7 +198,42 @@\n      * {@link TriJoiner joiners} are true\n      */\n     default <C> TriConstraintStream<A, B, C> join(Class<C> otherClass, TriJoiner<A, B, C>... joiners) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzIxMzA2OQ=="}, "originalCommit": {"oid": "dc4d32fdd887477a1847fea9ba9d0de553e24a00"}, "originalPosition": 46}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3Mjg2NDkyOnYy", "diffSide": "RIGHT", "path": "optaplanner-core/src/main/java/org/optaplanner/core/api/score/stream/tri/TriConstraintStream.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQxMToyOToyM1rOFtdegw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQxMToyOToyM1rOFtdegw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzIxMzE4Nw==", "bodyText": "Ditto.", "url": "https://github.com/kiegroup/optaplanner/pull/702#discussion_r383213187", "createdAt": "2020-02-24T11:29:23Z", "author": {"login": "triceo"}, "path": "optaplanner-core/src/main/java/org/optaplanner/core/api/score/stream/tri/TriConstraintStream.java", "diffHunk": "@@ -197,7 +199,42 @@\n      * {@link QuadJoiner joiners} are true\n      */\n     default <D> QuadConstraintStream<A, B, C, D> join(Class<D> otherClass, QuadJoiner<A, B, C, D>... joiners) {\n-        return join(otherClass, AbstractQuadJoiner.merge(joiners));\n+        int joinerCount = joiners.length;\n+        int indexOfFirstFilter = -1;\n+        // Make sure all indexing joiners, if any, come before filtering joiners. This is necessary for performance.\n+        for (int i = 0; i < joinerCount; i++) {\n+            QuadJoiner<A, B, C, D> joiner = joiners[i];\n+            if (indexOfFirstFilter >= 0) {\n+                if (!(joiner instanceof FilteringQuadJoiner)) {\n+                    throw new IllegalStateException(\"Indexing joiner (\" + joiner + \") must not follow \" +\n+                            \"a filtering joiner (\" + joiners[indexOfFirstFilter] + \").\\n\" +\n+                            \"Maybe reorder the joiners such that filtering() joiners are later in the parameter list.\");\n+                }\n+            } else {\n+                if (joiner instanceof FilteringQuadJoiner) { // From now on, we only allow filtering joiners.\n+                    indexOfFirstFilter = i;\n+                }\n+            }\n+        }\n+        if (indexOfFirstFilter < 0) { // Only found indexing joiners.\n+            return join(otherClass, AbstractQuadJoiner.merge(joiners));\n+        }\n+        // Assemble the join stream that may be followed by filter stream.\n+        QuadConstraintStream<A, B, C, D> joined = indexOfFirstFilter == 0 ?\n+                join(otherClass) :\n+                join(otherClass, Arrays.copyOf(joiners, indexOfFirstFilter));\n+        int filterCount = joinerCount - indexOfFirstFilter;\n+        if (filterCount == 0) { // No filters, return the original join stream.\n+            return joined;\n+        }\n+        // We merge all filters into one, so that we don't pay the penalty for lack of indexing more than once.\n+        FilteringQuadJoiner<A, B, C, D> filteringJoiner = (FilteringQuadJoiner<A, B, C, D>) joiners[indexOfFirstFilter];\n+        QuadPredicate<A, B, C, D> resultingFilter = filteringJoiner.getFilter();\n+        for (int i = indexOfFirstFilter + 1; i < joinerCount; i++) {\n+            FilteringQuadJoiner<A, B, C, D> anoterFilteringJoiner = (FilteringQuadJoiner<A, B, C, D>) joiners[i];\n+            resultingFilter = resultingFilter.and(anoterFilteringJoiner.getFilter());\n+        }\n+        return joined.filter(resultingFilter);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dc4d32fdd887477a1847fea9ba9d0de553e24a00"}, "originalPosition": 83}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3Mjk4Mjk5OnYy", "diffSide": "RIGHT", "path": "optaplanner-core/src/test/java/org/optaplanner/core/api/score/stream/AdvancedGroupByConstraintStreamTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQxMjoxNDowN1rOFtekpw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQxMjoxNDowN1rOFtekpw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzIzMTE0Mw==", "bodyText": "These 3 methods belong in PlannerTestUtils", "url": "https://github.com/kiegroup/optaplanner/pull/702#discussion_r383231143", "createdAt": "2020-02-24T12:14:07Z", "author": {"login": "ge0ffrey"}, "path": "optaplanner-core/src/test/java/org/optaplanner/core/api/score/stream/AdvancedGroupByConstraintStreamTest.java", "diffHunk": "@@ -251,4 +341,21 @@ public void groupByAfterExists() {\n                 assertMatchWithScore(-2, solution.getFirstEntityGroup(), 2));\n     }\n \n+    private static <X> Set<X> asSet(X... x) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dc4d32fdd887477a1847fea9ba9d0de553e24a00"}, "originalPosition": 269}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3Mjk4NDE0OnYy", "diffSide": "RIGHT", "path": "optaplanner-core/src/test/java/org/optaplanner/core/api/score/stream/AdvancedGroupByConstraintStreamTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQxMjoxNDozN1rOFtelYQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQxMzowODozMFrOFtf-PA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzIzMTMyOQ==", "bodyText": "Still ignored? If so, can we mention why?", "url": "https://github.com/kiegroup/optaplanner/pull/702#discussion_r383231329", "createdAt": "2020-02-24T12:14:37Z", "author": {"login": "ge0ffrey"}, "path": "optaplanner-core/src/test/java/org/optaplanner/core/api/score/stream/AdvancedGroupByConstraintStreamTest.java", "diffHunk": "@@ -71,80 +86,155 @@ public void collectedAndFiltered() {\n     }\n \n     @Test\n-    @Ignore(\"Regrouping not yet supported.\")\n     public void collectedFilteredRecollected() {\n         assumeDrools();\n-        TestdataLavishSolution solution = TestdataLavishSolution.generateSolution(2, 5, 1, 7);\n-        TestdataLavishEntityGroup entityGroup1 = new TestdataLavishEntityGroup(\"MyEntityGroup\");\n-        solution.getEntityGroupList().add(entityGroup1);\n-        TestdataLavishEntity entity1 = new TestdataLavishEntity(\"MyEntity 1\", entityGroup1, solution.getFirstValue());\n-        solution.getEntityList().add(entity1);\n-        TestdataLavishEntity entity2 = new TestdataLavishEntity(\"MyEntity 2\", entityGroup1, solution.getFirstValue());\n-        solution.getEntityList().add(entity2);\n-        TestdataLavishEntity entity3 = new TestdataLavishEntity(\"MyEntity 3\", solution.getFirstEntityGroup(),\n-                solution.getFirstValue());\n-        solution.getEntityList().add(entity3);\n+        TestdataLavishSolution solution = TestdataLavishSolution.generateSolution(2, 2, 2, 2);\n \n         InnerScoreDirector<TestdataLavishSolution> scoreDirector = buildScoreDirector((factory) -> {\n             return factory.from(TestdataLavishEntity.class)\n-                    .groupBy(ConstraintCollectors.count())\n-                    .filter(count -> count == 10)\n-                    .groupBy(ConstraintCollectors.count())\n-                    .penalize(TEST_CONSTRAINT_NAME, SimpleScore.ONE);\n+                    .groupBy(toSet())\n+                    .groupBy(sum(Set::size))\n+                    .penalize(TEST_CONSTRAINT_NAME, SimpleScore.ONE, count -> count);\n         });\n \n         // From scratch\n         scoreDirector.setWorkingSolution(solution);\n+        assertScore(scoreDirector, assertMatchWithScore(-2, 2));\n+\n+        // Incremental\n+        TestdataLavishEntity entity = solution.getFirstEntity();\n+        scoreDirector.beforeEntityRemoved(entity);\n+        solution.getEntityList().remove(entity);\n+        scoreDirector.afterEntityRemoved(entity);\n         assertScore(scoreDirector, assertMatchWithScore(-1, 1));\n+    }\n+\n+    @Test\n+    public void uniGroupByRecollected() {\n+        assumeDrools();\n+        TestdataLavishSolution solution = TestdataLavishSolution.generateSolution(2, 2, 2, 2);\n+\n+        InnerScoreDirector<TestdataLavishSolution> scoreDirector = buildScoreDirector((factory) -> {\n+            return factory.from(TestdataLavishEntity.class)\n+                    .groupBy(TestdataLavishEntity::getEntityGroup)\n+                    .groupBy(toSet())\n+                    .penalize(TEST_CONSTRAINT_NAME, SimpleScore.ONE, Set::size);\n+        });\n+\n+        TestdataLavishEntity entity1 = solution.getFirstEntity();\n+        TestdataLavishEntity entity2 = solution.getEntityList().get(1);\n+\n+        // From scratch\n+        scoreDirector.setWorkingSolution(solution);\n+        assertScore(scoreDirector,\n+                assertMatchWithScore(-2, asSet(entity1.getEntityGroup(), entity2.getEntityGroup())));\n \n         // Incremental\n-        Stream.of(entity1, entity2).forEach(entity -> {\n-            scoreDirector.beforeEntityRemoved(entity);\n-            solution.getEntityList().remove(entity);\n-            scoreDirector.afterEntityRemoved(entity);\n+        scoreDirector.beforeEntityRemoved(entity1);\n+        solution.getEntityList().remove(entity1);\n+        scoreDirector.afterEntityRemoved(entity1);\n+        assertScore(scoreDirector,\n+                assertMatchWithScore(-1, asSet(entity2.getEntityGroup())));\n+    }\n+\n+    @Test\n+    public void biGroupByRecollected() {\n+        assumeDrools();\n+        TestdataLavishSolution solution = TestdataLavishSolution.generateSolution(2, 3, 2, 5);\n+\n+        InnerScoreDirector<TestdataLavishSolution> scoreDirector = buildScoreDirector((factory) -> {\n+            return factory.fromUniquePair(TestdataLavishEntity.class, equal(TestdataLavishEntity::getEntityGroup))\n+                    // Stream of all unique entity bi tuples that share a group\n+                    .groupBy((entityA, entityB) -> entityA.getEntityGroup(), countBi())\n+                    .groupBy(toMap((g, c) -> g, (g, c) -> c, Integer::sum))\n+                    .penalize(TEST_CONSTRAINT_NAME, SimpleScore.ONE);\n         });\n-        assertScore(scoreDirector); // There is less than 10 entities, and therefore there are no penalties.\n+\n+        // From scratch\n+        scoreDirector.setWorkingSolution(solution);\n+        assertScore(scoreDirector,\n+                assertMatchWithScore(-1,\n+                        asMap(solution.getFirstEntityGroup(), 3, solution.getEntityGroupList().get(1), 1)));\n+\n+        // Incremental\n+        TestdataLavishEntity entity = solution.getFirstEntity();\n+        scoreDirector.beforeEntityRemoved(entity);\n+        solution.getEntityList().remove(entity);\n+        scoreDirector.afterEntityRemoved(entity);\n+        assertScore(scoreDirector,\n+                assertMatchWithScore(-1,\n+                        asMap(solution.getFirstEntityGroup(), 1, solution.getEntityGroupList().get(1), 1)));\n     }\n \n     @Test\n-    @Ignore(\"Regrouping not yet supported.\")\n-    public void bigroupBiregrouped() {\n+    public void triGroupByRecollected() {\n         assumeDrools();\n-        TestdataLavishSolution solution = TestdataLavishSolution.generateSolution(2, 5, 1, 7);\n-        TestdataLavishEntityGroup entityGroup1 = new TestdataLavishEntityGroup(\"MyEntityGroup\");\n-        solution.getEntityGroupList().add(entityGroup1);\n-        TestdataLavishEntity entity1 = new TestdataLavishEntity(\"MyEntity 1\", entityGroup1, solution.getFirstValue());\n-        solution.getEntityList().add(entity1);\n-        TestdataLavishEntity entity2 = new TestdataLavishEntity(\"MyEntity 2\", entityGroup1, solution.getFirstValue());\n-        solution.getEntityList().add(entity2);\n-        TestdataLavishEntity entity3 = new TestdataLavishEntity(\"MyEntity 3\", solution.getFirstEntityGroup(),\n-                solution.getFirstValue());\n-        solution.getEntityList().add(entity3);\n+        TestdataLavishSolution solution = TestdataLavishSolution.generateSolution(2, 3, 2, 6);\n \n         InnerScoreDirector<TestdataLavishSolution> scoreDirector = buildScoreDirector((factory) -> {\n             return factory.fromUniquePair(TestdataLavishEntity.class, equal(TestdataLavishEntity::getEntityGroup))\n-                    .groupBy((entityA, entityB) -> entityA.getEntityGroup())\n-                    .groupBy(Function.identity(), ConstraintCollectors.count())\n+                    .join(TestdataLavishEntity.class,\n+                            equal((a, b) -> a.getEntityGroup(), TestdataLavishEntity::getEntityGroup),\n+                            filtering((a, b, c) -> !Objects.equals(a, c) && !Objects.equals(b, c)))\n+                    // Stream of all unique entity tri tuples that share a group\n+                    .groupBy((entityA, entityB, entityC) -> entityA.getEntityGroup(), countTri())\n+                    .groupBy(toMap((g, c) -> g, (g, c) -> c, Integer::sum))\n                     .penalize(TEST_CONSTRAINT_NAME, SimpleScore.ONE);\n         });\n \n         // From scratch\n         scoreDirector.setWorkingSolution(solution);\n         assertScore(scoreDirector,\n-                assertMatchWithScore(-1, entityGroup1, 1),\n-                assertMatchWithScore(-1, solution.getFirstEntityGroup(), 1));\n+                assertMatchWithScore(-1,\n+                        asMap(solution.getFirstEntityGroup(), 3, solution.getEntityGroupList().get(1), 3)));\n \n         // Incremental\n-        Stream.of(entity1, entity2).forEach(entity -> {\n-            scoreDirector.beforeEntityRemoved(entity);\n-            solution.getEntityList().remove(entity);\n-            scoreDirector.afterEntityRemoved(entity);\n+        TestdataLavishEntity entity = solution.getFirstEntity();\n+        scoreDirector.beforeEntityRemoved(entity);\n+        solution.getEntityList().remove(entity);\n+        scoreDirector.afterEntityRemoved(entity);\n+        assertScore(scoreDirector,\n+                assertMatchWithScore(-1,\n+                        asMap(solution.getEntityGroupList().get(1), 3)));\n+    }\n+\n+    @Test\n+    public void quadGroupByRecollected() {\n+        assumeDrools();\n+        TestdataLavishSolution solution = TestdataLavishSolution.generateSolution(2, 3, 2, 8);\n+\n+        InnerScoreDirector<TestdataLavishSolution> scoreDirector = buildScoreDirector((factory) -> {\n+            return factory.fromUniquePair(TestdataLavishEntity.class, equal(TestdataLavishEntity::getEntityGroup))\n+                    .join(TestdataLavishEntity.class,\n+                            equal((a, b) -> a.getEntityGroup(), TestdataLavishEntity::getEntityGroup),\n+                            filtering((a, b, c) -> !Objects.equals(a, c) && !Objects.equals(b, c)))\n+                    .join(TestdataLavishEntity.class,\n+                            equal((a, b, c) -> a.getEntityGroup(), TestdataLavishEntity::getEntityGroup),\n+                            filtering((a, b, c, d) -> !Objects.equals(a, d) && !Objects.equals(b, d) && !Objects.equals(c, d)))\n+                    // Stream of all unique entity quad tuples that share a group\n+                    .groupBy((entityA, entityB, entityC, entityD) -> entityA.getEntityGroup(), countQuad())\n+                    .groupBy(toMap((g, c) -> g, (g, c) -> c, Integer::sum))\n+                    .penalize(TEST_CONSTRAINT_NAME, SimpleScore.ONE);\n         });\n-        assertScore(scoreDirector, assertMatchWithScore(-1, solution.getFirstEntityGroup(), 1));\n+\n+        // From scratch\n+        scoreDirector.setWorkingSolution(solution);\n+        assertScore(scoreDirector,\n+                assertMatchWithScore(-1,\n+                        asMap(solution.getFirstEntityGroup(), 12, solution.getEntityGroupList().get(1), 12)));\n+\n+        // Incremental\n+        TestdataLavishEntity entity = solution.getFirstEntity();\n+        scoreDirector.beforeEntityRemoved(entity);\n+        solution.getEntityList().remove(entity);\n+        scoreDirector.afterEntityRemoved(entity);\n+        assertScore(scoreDirector,\n+                assertMatchWithScore(-1,\n+                        asMap(solution.getEntityGroupList().get(1), 12)));\n     }\n \n     @Test\n-    @Ignore(\"Regrouping not yet supported.\")\n+    @Ignore", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dc4d32fdd887477a1847fea9ba9d0de553e24a00"}, "originalPosition": 234}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzI1NDA3Ng==", "bodyText": "The PR is not yet complete. This will be fixed soon.", "url": "https://github.com/kiegroup/optaplanner/pull/702#discussion_r383254076", "createdAt": "2020-02-24T13:08:30Z", "author": {"login": "triceo"}, "path": "optaplanner-core/src/test/java/org/optaplanner/core/api/score/stream/AdvancedGroupByConstraintStreamTest.java", "diffHunk": "@@ -71,80 +86,155 @@ public void collectedAndFiltered() {\n     }\n \n     @Test\n-    @Ignore(\"Regrouping not yet supported.\")\n     public void collectedFilteredRecollected() {\n         assumeDrools();\n-        TestdataLavishSolution solution = TestdataLavishSolution.generateSolution(2, 5, 1, 7);\n-        TestdataLavishEntityGroup entityGroup1 = new TestdataLavishEntityGroup(\"MyEntityGroup\");\n-        solution.getEntityGroupList().add(entityGroup1);\n-        TestdataLavishEntity entity1 = new TestdataLavishEntity(\"MyEntity 1\", entityGroup1, solution.getFirstValue());\n-        solution.getEntityList().add(entity1);\n-        TestdataLavishEntity entity2 = new TestdataLavishEntity(\"MyEntity 2\", entityGroup1, solution.getFirstValue());\n-        solution.getEntityList().add(entity2);\n-        TestdataLavishEntity entity3 = new TestdataLavishEntity(\"MyEntity 3\", solution.getFirstEntityGroup(),\n-                solution.getFirstValue());\n-        solution.getEntityList().add(entity3);\n+        TestdataLavishSolution solution = TestdataLavishSolution.generateSolution(2, 2, 2, 2);\n \n         InnerScoreDirector<TestdataLavishSolution> scoreDirector = buildScoreDirector((factory) -> {\n             return factory.from(TestdataLavishEntity.class)\n-                    .groupBy(ConstraintCollectors.count())\n-                    .filter(count -> count == 10)\n-                    .groupBy(ConstraintCollectors.count())\n-                    .penalize(TEST_CONSTRAINT_NAME, SimpleScore.ONE);\n+                    .groupBy(toSet())\n+                    .groupBy(sum(Set::size))\n+                    .penalize(TEST_CONSTRAINT_NAME, SimpleScore.ONE, count -> count);\n         });\n \n         // From scratch\n         scoreDirector.setWorkingSolution(solution);\n+        assertScore(scoreDirector, assertMatchWithScore(-2, 2));\n+\n+        // Incremental\n+        TestdataLavishEntity entity = solution.getFirstEntity();\n+        scoreDirector.beforeEntityRemoved(entity);\n+        solution.getEntityList().remove(entity);\n+        scoreDirector.afterEntityRemoved(entity);\n         assertScore(scoreDirector, assertMatchWithScore(-1, 1));\n+    }\n+\n+    @Test\n+    public void uniGroupByRecollected() {\n+        assumeDrools();\n+        TestdataLavishSolution solution = TestdataLavishSolution.generateSolution(2, 2, 2, 2);\n+\n+        InnerScoreDirector<TestdataLavishSolution> scoreDirector = buildScoreDirector((factory) -> {\n+            return factory.from(TestdataLavishEntity.class)\n+                    .groupBy(TestdataLavishEntity::getEntityGroup)\n+                    .groupBy(toSet())\n+                    .penalize(TEST_CONSTRAINT_NAME, SimpleScore.ONE, Set::size);\n+        });\n+\n+        TestdataLavishEntity entity1 = solution.getFirstEntity();\n+        TestdataLavishEntity entity2 = solution.getEntityList().get(1);\n+\n+        // From scratch\n+        scoreDirector.setWorkingSolution(solution);\n+        assertScore(scoreDirector,\n+                assertMatchWithScore(-2, asSet(entity1.getEntityGroup(), entity2.getEntityGroup())));\n \n         // Incremental\n-        Stream.of(entity1, entity2).forEach(entity -> {\n-            scoreDirector.beforeEntityRemoved(entity);\n-            solution.getEntityList().remove(entity);\n-            scoreDirector.afterEntityRemoved(entity);\n+        scoreDirector.beforeEntityRemoved(entity1);\n+        solution.getEntityList().remove(entity1);\n+        scoreDirector.afterEntityRemoved(entity1);\n+        assertScore(scoreDirector,\n+                assertMatchWithScore(-1, asSet(entity2.getEntityGroup())));\n+    }\n+\n+    @Test\n+    public void biGroupByRecollected() {\n+        assumeDrools();\n+        TestdataLavishSolution solution = TestdataLavishSolution.generateSolution(2, 3, 2, 5);\n+\n+        InnerScoreDirector<TestdataLavishSolution> scoreDirector = buildScoreDirector((factory) -> {\n+            return factory.fromUniquePair(TestdataLavishEntity.class, equal(TestdataLavishEntity::getEntityGroup))\n+                    // Stream of all unique entity bi tuples that share a group\n+                    .groupBy((entityA, entityB) -> entityA.getEntityGroup(), countBi())\n+                    .groupBy(toMap((g, c) -> g, (g, c) -> c, Integer::sum))\n+                    .penalize(TEST_CONSTRAINT_NAME, SimpleScore.ONE);\n         });\n-        assertScore(scoreDirector); // There is less than 10 entities, and therefore there are no penalties.\n+\n+        // From scratch\n+        scoreDirector.setWorkingSolution(solution);\n+        assertScore(scoreDirector,\n+                assertMatchWithScore(-1,\n+                        asMap(solution.getFirstEntityGroup(), 3, solution.getEntityGroupList().get(1), 1)));\n+\n+        // Incremental\n+        TestdataLavishEntity entity = solution.getFirstEntity();\n+        scoreDirector.beforeEntityRemoved(entity);\n+        solution.getEntityList().remove(entity);\n+        scoreDirector.afterEntityRemoved(entity);\n+        assertScore(scoreDirector,\n+                assertMatchWithScore(-1,\n+                        asMap(solution.getFirstEntityGroup(), 1, solution.getEntityGroupList().get(1), 1)));\n     }\n \n     @Test\n-    @Ignore(\"Regrouping not yet supported.\")\n-    public void bigroupBiregrouped() {\n+    public void triGroupByRecollected() {\n         assumeDrools();\n-        TestdataLavishSolution solution = TestdataLavishSolution.generateSolution(2, 5, 1, 7);\n-        TestdataLavishEntityGroup entityGroup1 = new TestdataLavishEntityGroup(\"MyEntityGroup\");\n-        solution.getEntityGroupList().add(entityGroup1);\n-        TestdataLavishEntity entity1 = new TestdataLavishEntity(\"MyEntity 1\", entityGroup1, solution.getFirstValue());\n-        solution.getEntityList().add(entity1);\n-        TestdataLavishEntity entity2 = new TestdataLavishEntity(\"MyEntity 2\", entityGroup1, solution.getFirstValue());\n-        solution.getEntityList().add(entity2);\n-        TestdataLavishEntity entity3 = new TestdataLavishEntity(\"MyEntity 3\", solution.getFirstEntityGroup(),\n-                solution.getFirstValue());\n-        solution.getEntityList().add(entity3);\n+        TestdataLavishSolution solution = TestdataLavishSolution.generateSolution(2, 3, 2, 6);\n \n         InnerScoreDirector<TestdataLavishSolution> scoreDirector = buildScoreDirector((factory) -> {\n             return factory.fromUniquePair(TestdataLavishEntity.class, equal(TestdataLavishEntity::getEntityGroup))\n-                    .groupBy((entityA, entityB) -> entityA.getEntityGroup())\n-                    .groupBy(Function.identity(), ConstraintCollectors.count())\n+                    .join(TestdataLavishEntity.class,\n+                            equal((a, b) -> a.getEntityGroup(), TestdataLavishEntity::getEntityGroup),\n+                            filtering((a, b, c) -> !Objects.equals(a, c) && !Objects.equals(b, c)))\n+                    // Stream of all unique entity tri tuples that share a group\n+                    .groupBy((entityA, entityB, entityC) -> entityA.getEntityGroup(), countTri())\n+                    .groupBy(toMap((g, c) -> g, (g, c) -> c, Integer::sum))\n                     .penalize(TEST_CONSTRAINT_NAME, SimpleScore.ONE);\n         });\n \n         // From scratch\n         scoreDirector.setWorkingSolution(solution);\n         assertScore(scoreDirector,\n-                assertMatchWithScore(-1, entityGroup1, 1),\n-                assertMatchWithScore(-1, solution.getFirstEntityGroup(), 1));\n+                assertMatchWithScore(-1,\n+                        asMap(solution.getFirstEntityGroup(), 3, solution.getEntityGroupList().get(1), 3)));\n \n         // Incremental\n-        Stream.of(entity1, entity2).forEach(entity -> {\n-            scoreDirector.beforeEntityRemoved(entity);\n-            solution.getEntityList().remove(entity);\n-            scoreDirector.afterEntityRemoved(entity);\n+        TestdataLavishEntity entity = solution.getFirstEntity();\n+        scoreDirector.beforeEntityRemoved(entity);\n+        solution.getEntityList().remove(entity);\n+        scoreDirector.afterEntityRemoved(entity);\n+        assertScore(scoreDirector,\n+                assertMatchWithScore(-1,\n+                        asMap(solution.getEntityGroupList().get(1), 3)));\n+    }\n+\n+    @Test\n+    public void quadGroupByRecollected() {\n+        assumeDrools();\n+        TestdataLavishSolution solution = TestdataLavishSolution.generateSolution(2, 3, 2, 8);\n+\n+        InnerScoreDirector<TestdataLavishSolution> scoreDirector = buildScoreDirector((factory) -> {\n+            return factory.fromUniquePair(TestdataLavishEntity.class, equal(TestdataLavishEntity::getEntityGroup))\n+                    .join(TestdataLavishEntity.class,\n+                            equal((a, b) -> a.getEntityGroup(), TestdataLavishEntity::getEntityGroup),\n+                            filtering((a, b, c) -> !Objects.equals(a, c) && !Objects.equals(b, c)))\n+                    .join(TestdataLavishEntity.class,\n+                            equal((a, b, c) -> a.getEntityGroup(), TestdataLavishEntity::getEntityGroup),\n+                            filtering((a, b, c, d) -> !Objects.equals(a, d) && !Objects.equals(b, d) && !Objects.equals(c, d)))\n+                    // Stream of all unique entity quad tuples that share a group\n+                    .groupBy((entityA, entityB, entityC, entityD) -> entityA.getEntityGroup(), countQuad())\n+                    .groupBy(toMap((g, c) -> g, (g, c) -> c, Integer::sum))\n+                    .penalize(TEST_CONSTRAINT_NAME, SimpleScore.ONE);\n         });\n-        assertScore(scoreDirector, assertMatchWithScore(-1, solution.getFirstEntityGroup(), 1));\n+\n+        // From scratch\n+        scoreDirector.setWorkingSolution(solution);\n+        assertScore(scoreDirector,\n+                assertMatchWithScore(-1,\n+                        asMap(solution.getFirstEntityGroup(), 12, solution.getEntityGroupList().get(1), 12)));\n+\n+        // Incremental\n+        TestdataLavishEntity entity = solution.getFirstEntity();\n+        scoreDirector.beforeEntityRemoved(entity);\n+        solution.getEntityList().remove(entity);\n+        scoreDirector.afterEntityRemoved(entity);\n+        assertScore(scoreDirector,\n+                assertMatchWithScore(-1,\n+                        asMap(solution.getEntityGroupList().get(1), 12)));\n     }\n \n     @Test\n-    @Ignore(\"Regrouping not yet supported.\")\n+    @Ignore", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzIzMTMyOQ=="}, "originalCommit": {"oid": "dc4d32fdd887477a1847fea9ba9d0de553e24a00"}, "originalPosition": 234}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3MzY1NjEyOnYy", "diffSide": "RIGHT", "path": "optaplanner-core/src/main/java/org/optaplanner/core/impl/score/stream/common/ConstraintStreamHelper.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQxNTozMjoxNFrOFtk6IA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQxNTozMjoxNFrOFtk6IA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzMzNDk0NA==", "bodyText": "I expect a lively discussion about this. :-)\nThis exists so that I can reuse JoinerUtils.join(...) across all the streams. It may be a lot of code for such a simple purpose, but it's just a level of abstraction. The code that is being shared thanks to this is complicated and needs to be kept identical across all the streams, so I think it's worth it.", "url": "https://github.com/kiegroup/optaplanner/pull/702#discussion_r383334944", "createdAt": "2020-02-24T15:32:14Z", "author": {"login": "triceo"}, "path": "optaplanner-core/src/main/java/org/optaplanner/core/impl/score/stream/common/ConstraintStreamHelper.java", "diffHunk": "@@ -0,0 +1,37 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.optaplanner.core.impl.score.stream.common;\n+\n+interface ConstraintStreamHelper<Right, JoinedStream, Joiner, Predicate> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "804f35673a29e7710620b400e0efce430cd83f1c"}, "originalPosition": 19}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3MzcwMzY4OnYy", "diffSide": "RIGHT", "path": "optaplanner-core/src/main/java/org/optaplanner/core/impl/score/stream/common/BiConstraintStreamDescriptor.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQxNTo0MzoyM1rOFtlWyA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQxNTo0MzoyM1rOFtlWyA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzM0MjI4MA==", "bodyText": "Need the same name, except for Bi", "url": "https://github.com/kiegroup/optaplanner/pull/702#discussion_r383342280", "createdAt": "2020-02-24T15:43:23Z", "author": {"login": "ge0ffrey"}, "path": "optaplanner-core/src/main/java/org/optaplanner/core/impl/score/stream/common/BiConstraintStreamDescriptor.java", "diffHunk": "@@ -0,0 +1,75 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.optaplanner.core.impl.score.stream.common;\n+\n+import java.util.function.BiPredicate;\n+\n+import org.optaplanner.core.api.score.stream.bi.BiConstraintStream;\n+import org.optaplanner.core.api.score.stream.bi.BiJoiner;\n+import org.optaplanner.core.api.score.stream.uni.UniConstraintStream;\n+import org.optaplanner.core.impl.score.stream.bi.AbstractBiJoiner;\n+import org.optaplanner.core.impl.score.stream.bi.FilteringBiJoiner;\n+\n+final class BiConstraintStreamDescriptor<A, B>\n+        implements ConstraintStreamHelper<B, BiConstraintStream<A, B>, BiJoiner<A, B>, BiPredicate<A, B>> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "804f35673a29e7710620b400e0efce430cd83f1c"}, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3MzcxMTY1OnYy", "diffSide": "RIGHT", "path": "optaplanner-core/src/main/java/org/optaplanner/core/impl/score/stream/common/JoinerUtils.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQxNTo0NToyMFrOFtlbrQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQxNTo0NToyMFrOFtlbrQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzM0MzUzMw==", "bodyText": "variable name", "url": "https://github.com/kiegroup/optaplanner/pull/702#discussion_r383343533", "createdAt": "2020-02-24T15:45:20Z", "author": {"login": "ge0ffrey"}, "path": "optaplanner-core/src/main/java/org/optaplanner/core/impl/score/stream/common/JoinerUtils.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.optaplanner.core.impl.score.stream.common;\n+\n+import java.util.Arrays;\n+\n+import org.optaplanner.core.api.score.stream.ConstraintStream;\n+import org.optaplanner.core.api.score.stream.bi.BiConstraintStream;\n+import org.optaplanner.core.api.score.stream.bi.BiJoiner;\n+import org.optaplanner.core.api.score.stream.quad.QuadConstraintStream;\n+import org.optaplanner.core.api.score.stream.quad.QuadJoiner;\n+import org.optaplanner.core.api.score.stream.tri.TriConstraintStream;\n+import org.optaplanner.core.api.score.stream.tri.TriJoiner;\n+import org.optaplanner.core.api.score.stream.uni.UniConstraintStream;\n+\n+public final class JoinerUtils {\n+\n+    public static <A, B> BiConstraintStream<A, B> join(UniConstraintStream<A> stream, Class<B> otherClass,\n+            BiJoiner<A, B>... joiners) {\n+        return join(new BiConstraintStreamDescriptor<>(stream), otherClass, joiners);\n+    }\n+\n+    public static <A, B, C> TriConstraintStream<A, B, C> join(BiConstraintStream<A, B> stream, Class<C> otherClass,\n+            TriJoiner<A, B, C>... joiners) {\n+        return join(new TriConstraintStreamDescriptor<>(stream), otherClass, joiners);\n+    }\n+\n+    public static <A, B, C, D> QuadConstraintStream<A, B, C, D> join(TriConstraintStream<A, B, C> stream,\n+            Class<D> otherClass, QuadJoiner<A, B, C, D>... joiners) {\n+        return join(new QuadConstraintStreamDescriptor<>(stream), otherClass, joiners);\n+    }\n+\n+    private static <Right, JoinedStream extends ConstraintStream, Joiner, Predicate> JoinedStream join(\n+            ConstraintStreamHelper<Right, JoinedStream, Joiner, Predicate> constraintStreamDescriptor,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "804f35673a29e7710620b400e0efce430cd83f1c"}, "originalPosition": 48}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4432, "cost": 1, "resetAt": "2021-11-12T20:44:06Z"}}}