{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTMxNDc4NDQx", "number": 13470, "title": "[BEAM-10114] Convert PubsubLiteIO read to use SplittableDoFn.", "bodyText": "Thank you for your contribution! Follow this checklist to help us incorporate your contribution quickly and easily:\n\n Choose reviewer(s) and mention them in a comment (R: @username).\n Format the pull request title like [BEAM-XXX] Fixes bug in ApproximateQuantiles, where you replace BEAM-XXX with the appropriate JIRA issue, if applicable. This will automatically link the pull request to the issue.\n Update CHANGES.md with noteworthy changes.\n If this contribution is large, please file an Apache Individual Contributor License Agreement.\n\nSee the Contributor Guide for more tips on how to make review process smoother.\nPost-Commit Tests Status (on master branch)\n\n\n\nLang\nSDK\nDataflow\nFlink\nSamza\nSpark\nTwister2\n\n\n\n\nGo\n\n---\n\n---\n\n---\n\n\nJava\n\n\n\n\n\n\n\n\nPython\n\n\n\n---\n\n---\n\n\nXLang\n\n\n\n---\n\n---\n\n\n\nPre-Commit Tests Status (on master branch)\n\n\n\n---\nJava\nPython\nGo\nWebsite\nWhitespace\nTypescript\n\n\n\n\nNon-portable\n\n \n\n\n\n\n\n\nPortable\n---\n\n---\n---\n---\n---\n\n\n\nSee .test-infra/jenkins/README for trigger phrase, status and link of all Jenkins jobs.\nGitHub Actions Tests Status (on master branch)\n\n\n\nSee CI.md for more information about GitHub Actions CI.", "createdAt": "2020-12-03T04:58:23Z", "url": "https://github.com/apache/beam/pull/13470", "merged": true, "mergeCommit": {"oid": "f87c984edad74ba1212e90708c14ff362ef0b55c"}, "closed": true, "closedAt": "2020-12-16T04:32:34Z", "author": {"login": "dpcollins-google"}, "timelineItems": {"totalCount": 19, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdjBHl9gFqTU0NTM1MzAyMQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdmlv9pAH2gAyNTMxNDc4NDQxOmE0MzJlOGYwNWZmYWQ3ZGI4NWNkYjY5MGUyNzdiNWFlYjNlMTBiYTg=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ1MzUzMDIx", "url": "https://github.com/apache/beam/pull/13470#pullrequestreview-545353021", "createdAt": "2020-12-04T23:00:18Z", "commit": {"oid": "e4ba623c7fb6cc3935558a861444583496a413cf"}, "state": "COMMENTED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQyMzowMDoxOFrOH_lU5g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwMDoxNDoyNFrOH_mryg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQzMzg5NA==", "bodyText": "If lastClaimed == Long.MAX_VALUE, you will get overflow here.", "url": "https://github.com/apache/beam/pull/13470#discussion_r536433894", "createdAt": "2020-12-04T23:00:18Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/OffsetByteRangeTracker.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.proto.ComputeMessageStatsResponse;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker.HasProgress;\n+import org.apache.beam.sdk.transforms.splittabledofn.SplitResult;\n+\n+public class OffsetByteRangeTracker extends RestrictionTracker<OffsetRange, OffsetByteProgress>\n+    implements HasProgress {\n+  private final TopicBacklogReader backlogReader;\n+  private OffsetRange range;\n+  private @Nullable Long lastClaimed;\n+  private long byteCount = 0;\n+\n+  public OffsetByteRangeTracker(OffsetRange range, TopicBacklogReader backlogReader) {\n+    checkArgument(range.getTo() == Long.MAX_VALUE);\n+    this.backlogReader = backlogReader;\n+    this.range = range;\n+  }\n+\n+  @Override\n+  public IsBounded isBounded() {\n+    return IsBounded.UNBOUNDED;\n+  }\n+\n+  @Override\n+  public boolean tryClaim(OffsetByteProgress position) {\n+    long toClaim = position.lastOffset().value();\n+    checkArgument(\n+        lastClaimed == null || toClaim > lastClaimed,\n+        \"Trying to claim offset %s while last attempted was %s\",\n+        position.lastOffset().value(),\n+        lastClaimed);\n+    checkArgument(\n+        toClaim >= range.getFrom(),\n+        \"Trying to claim offset %s before start of the range %s\",\n+        toClaim,\n+        range);\n+    // split() has already been called, truncating this range. No more offsets may be claimed.\n+    if (range.getTo() != Long.MAX_VALUE) {\n+      boolean isRangeEmpty = range.getTo() == range.getFrom();\n+      boolean isValidClosedRange = nextOffset() == range.getTo();\n+      checkState(\n+          isRangeEmpty || isValidClosedRange,\n+          \"Violated class precondition: offset range improperly split. Please report a beam bug.\");\n+      return false;\n+    }\n+    lastClaimed = toClaim;\n+    byteCount += position.batchBytes();\n+    return true;\n+  }\n+\n+  @Override\n+  public OffsetRange currentRestriction() {\n+    return range;\n+  }\n+\n+  private long nextOffset() {\n+    return lastClaimed == null ? currentRestriction().getFrom() : lastClaimed + 1;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4ba623c7fb6cc3935558a861444583496a413cf"}, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQzNDg2OA==", "bodyText": "If something goes wrong before we reaching to checkDone, we will have resource leak on backlogReader.", "url": "https://github.com/apache/beam/pull/13470#discussion_r536434868", "createdAt": "2020-12-04T23:02:52Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/OffsetByteRangeTracker.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.proto.ComputeMessageStatsResponse;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker.HasProgress;\n+import org.apache.beam.sdk.transforms.splittabledofn.SplitResult;\n+\n+public class OffsetByteRangeTracker extends RestrictionTracker<OffsetRange, OffsetByteProgress>\n+    implements HasProgress {\n+  private final TopicBacklogReader backlogReader;\n+  private OffsetRange range;\n+  private @Nullable Long lastClaimed;\n+  private long byteCount = 0;\n+\n+  public OffsetByteRangeTracker(OffsetRange range, TopicBacklogReader backlogReader) {\n+    checkArgument(range.getTo() == Long.MAX_VALUE);\n+    this.backlogReader = backlogReader;\n+    this.range = range;\n+  }\n+\n+  @Override\n+  public IsBounded isBounded() {\n+    return IsBounded.UNBOUNDED;\n+  }\n+\n+  @Override\n+  public boolean tryClaim(OffsetByteProgress position) {\n+    long toClaim = position.lastOffset().value();\n+    checkArgument(\n+        lastClaimed == null || toClaim > lastClaimed,\n+        \"Trying to claim offset %s while last attempted was %s\",\n+        position.lastOffset().value(),\n+        lastClaimed);\n+    checkArgument(\n+        toClaim >= range.getFrom(),\n+        \"Trying to claim offset %s before start of the range %s\",\n+        toClaim,\n+        range);\n+    // split() has already been called, truncating this range. No more offsets may be claimed.\n+    if (range.getTo() != Long.MAX_VALUE) {\n+      boolean isRangeEmpty = range.getTo() == range.getFrom();\n+      boolean isValidClosedRange = nextOffset() == range.getTo();\n+      checkState(\n+          isRangeEmpty || isValidClosedRange,\n+          \"Violated class precondition: offset range improperly split. Please report a beam bug.\");\n+      return false;\n+    }\n+    lastClaimed = toClaim;\n+    byteCount += position.batchBytes();\n+    return true;\n+  }\n+\n+  @Override\n+  public OffsetRange currentRestriction() {\n+    return range;\n+  }\n+\n+  private long nextOffset() {\n+    return lastClaimed == null ? currentRestriction().getFrom() : lastClaimed + 1;\n+  }\n+\n+  @Override\n+  public @Nullable SplitResult<OffsetRange> trySplit(double fractionOfRemainder) {\n+    // Cannot split a bounded range. This should already be completely claimed.\n+    if (range.getTo() != Long.MAX_VALUE) return null;\n+    range = new OffsetRange(currentRestriction().getFrom(), nextOffset());\n+    return SplitResult.of(this.range, new OffsetRange(nextOffset(), Long.MAX_VALUE));\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"unboxing.of.nullable\")\n+  public void checkDone() throws IllegalStateException {\n+    backlogReader.close();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4ba623c7fb6cc3935558a861444583496a413cf"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQzODkyNQ==", "bodyText": "Please add some javadoc to this tracker, especially about the assumption around range.getTo() == Long.MAX_VALUE and you ignore the fractionOfRemainder in trySplit", "url": "https://github.com/apache/beam/pull/13470#discussion_r536438925", "createdAt": "2020-12-04T23:14:33Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/OffsetByteRangeTracker.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.proto.ComputeMessageStatsResponse;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker.HasProgress;\n+import org.apache.beam.sdk.transforms.splittabledofn.SplitResult;\n+\n+public class OffsetByteRangeTracker extends RestrictionTracker<OffsetRange, OffsetByteProgress>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4ba623c7fb6cc3935558a861444583496a413cf"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0MTY0Mg==", "bodyText": "I think you may also want to track watermark by implementing watermark related APIs: https://beam.apache.org/documentation/programming-guide/#watermark-estimation", "url": "https://github.com/apache/beam/pull/13470#discussion_r536441642", "createdAt": "2020-12-04T23:23:11Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PerPartitionSdf.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.Partition;\n+import com.google.cloud.pubsublite.internal.PullSubscriber;\n+import com.google.cloud.pubsublite.internal.wire.Committer;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import com.google.common.flogger.GoogleLogger;\n+import com.google.protobuf.util.Timestamps;\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.SerializableBiFunction;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.util.Sleeper;\n+import org.joda.time.Duration;\n+import org.joda.time.Instant;\n+\n+class PerPartitionSdf extends DoFn<Partition, SequencedMessage> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4ba623c7fb6cc3935558a861444583496a413cf"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0NTM4Mw==", "bodyText": "Please file a JIRA and add a TODO here which talks about the improvement you are going to make.", "url": "https://github.com/apache/beam/pull/13470#discussion_r536445383", "createdAt": "2020-12-04T23:35:17Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/OffsetByteRangeTracker.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.proto.ComputeMessageStatsResponse;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker.HasProgress;\n+import org.apache.beam.sdk.transforms.splittabledofn.SplitResult;\n+\n+public class OffsetByteRangeTracker extends RestrictionTracker<OffsetRange, OffsetByteProgress>\n+    implements HasProgress {\n+  private final TopicBacklogReader backlogReader;\n+  private OffsetRange range;\n+  private @Nullable Long lastClaimed;\n+  private long byteCount = 0;\n+\n+  public OffsetByteRangeTracker(OffsetRange range, TopicBacklogReader backlogReader) {\n+    checkArgument(range.getTo() == Long.MAX_VALUE);\n+    this.backlogReader = backlogReader;\n+    this.range = range;\n+  }\n+\n+  @Override\n+  public IsBounded isBounded() {\n+    return IsBounded.UNBOUNDED;\n+  }\n+\n+  @Override\n+  public boolean tryClaim(OffsetByteProgress position) {\n+    long toClaim = position.lastOffset().value();\n+    checkArgument(\n+        lastClaimed == null || toClaim > lastClaimed,\n+        \"Trying to claim offset %s while last attempted was %s\",\n+        position.lastOffset().value(),\n+        lastClaimed);\n+    checkArgument(\n+        toClaim >= range.getFrom(),\n+        \"Trying to claim offset %s before start of the range %s\",\n+        toClaim,\n+        range);\n+    // split() has already been called, truncating this range. No more offsets may be claimed.\n+    if (range.getTo() != Long.MAX_VALUE) {\n+      boolean isRangeEmpty = range.getTo() == range.getFrom();\n+      boolean isValidClosedRange = nextOffset() == range.getTo();\n+      checkState(\n+          isRangeEmpty || isValidClosedRange,\n+          \"Violated class precondition: offset range improperly split. Please report a beam bug.\");\n+      return false;\n+    }\n+    lastClaimed = toClaim;\n+    byteCount += position.batchBytes();\n+    return true;\n+  }\n+\n+  @Override\n+  public OffsetRange currentRestriction() {\n+    return range;\n+  }\n+\n+  private long nextOffset() {\n+    return lastClaimed == null ? currentRestriction().getFrom() : lastClaimed + 1;\n+  }\n+\n+  @Override\n+  public @Nullable SplitResult<OffsetRange> trySplit(double fractionOfRemainder) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4ba623c7fb6cc3935558a861444583496a413cf"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0NjU4NA==", "bodyText": "I'm wondering how a partition can locate a read, I would image we at least need a topic. Is it plumped through by subscriberFactory  during construction time?", "url": "https://github.com/apache/beam/pull/13470#discussion_r536446584", "createdAt": "2020-12-04T23:39:24Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PerPartitionSdf.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.Partition;\n+import com.google.cloud.pubsublite.internal.PullSubscriber;\n+import com.google.cloud.pubsublite.internal.wire.Committer;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import com.google.common.flogger.GoogleLogger;\n+import com.google.protobuf.util.Timestamps;\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.SerializableBiFunction;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.util.Sleeper;\n+import org.joda.time.Duration;\n+import org.joda.time.Instant;\n+\n+class PerPartitionSdf extends DoFn<Partition, SequencedMessage> {\n+  private static final GoogleLogger logger = GoogleLogger.forEnclosingClass();\n+  private final Duration maxSleepTime;\n+  private final SerializableBiFunction<Partition, Offset, PullSubscriber<SequencedMessage>>\n+      subscriberFactory;\n+  private final SerializableFunction<Partition, Committer> committerFactory;\n+  private final SerializableSupplier<Sleeper> sleeperSupplier;\n+  private final SerializableFunction<Partition, InitialOffsetReader> offsetReaderFactory;\n+  private final SerializableBiFunction<\n+          Partition, OffsetRange, RestrictionTracker<OffsetRange, OffsetByteProgress>>\n+      trackerFactory;\n+\n+  Duration sleepTimeRemaining;\n+\n+  PerPartitionSdf(\n+      Duration maxSleepTime,\n+      SerializableBiFunction<Partition, Offset, PullSubscriber<SequencedMessage>> subscriberFactory,\n+      SerializableFunction<Partition, Committer> committerFactory,\n+      SerializableSupplier<Sleeper> sleeperSupplier,\n+      SerializableFunction<Partition, InitialOffsetReader> offsetReaderFactory,\n+      SerializableBiFunction<\n+              Partition, OffsetRange, RestrictionTracker<OffsetRange, OffsetByteProgress>>\n+          trackerFactory) {\n+    this.maxSleepTime = maxSleepTime;\n+    this.sleepTimeRemaining = maxSleepTime;\n+    this.subscriberFactory = subscriberFactory;\n+    this.committerFactory = committerFactory;\n+    this.sleeperSupplier = sleeperSupplier;\n+    this.offsetReaderFactory = offsetReaderFactory;\n+    this.trackerFactory = trackerFactory;\n+  }\n+\n+  private List<SequencedMessage> doPoll(PullSubscriber<SequencedMessage> subscriber)\n+      throws Exception {\n+    Sleeper sleeper = sleeperSupplier.get();\n+    while (sleepTimeRemaining.isLongerThan(Duration.ZERO)) {\n+      List<SequencedMessage> messages = subscriber.pull();\n+      if (!messages.isEmpty()) {\n+        return messages;\n+      }\n+      Duration sleepTime =\n+          Collections.min(ImmutableList.of(sleepTimeRemaining, Duration.millis(50)));\n+      sleepTimeRemaining = sleepTimeRemaining.minus(sleepTime);\n+      sleeper.sleep(sleepTime.getMillis());\n+    }\n+    return ImmutableList.of();\n+  }\n+\n+  @ProcessElement\n+  public ProcessContinuation processElement(\n+      RestrictionTracker<OffsetRange, OffsetByteProgress> tracker,\n+      @Element Partition partition,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4ba623c7fb6cc3935558a861444583496a413cf"}, "originalPosition": 91}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ1MTczMA==", "bodyText": "It seems like the PubsubLiteIO.read() is for reading one topic(subscription). Do we have a plan to have PubsubLiteIO expose readAll() API to read from multiple topics/subscriptions?", "url": "https://github.com/apache/beam/pull/13470#discussion_r536451730", "createdAt": "2020-12-04T23:57:44Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PubsubLiteIO.java", "diffHunk": "@@ -64,8 +64,8 @@ private PubsubLiteIO() {}\n    *     .build()), \"read\");\n    * }</pre>\n    */\n-  public static Read.Unbounded<SequencedMessage> read(SubscriberOptions options) {\n-    return Read.from(new PubsubLiteUnboundedSource(options));\n+  public static PTransform<PBegin, PCollection<SequencedMessage>> read(SubscriberOptions options) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4ba623c7fb6cc3935558a861444583496a413cf"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ1Mjk4NQ==", "bodyText": "I'm thinking about whether it makes sense to have PerPartitionSdf to read from a SubscriberOptions or something that can locate a read(topic + partition + something else). It will also help us to enable readAll() API I mentioned above. Also the PerPartitionSdf will also be able to read from subscriptions/partitions that are created during pipeline execution time.\nOne major feature request for Kafka IO is to read from new added topics/partitions dynamically, which I think PubsubLiteIO might have the similar customer needs.", "url": "https://github.com/apache/beam/pull/13470#discussion_r536452985", "createdAt": "2020-12-05T00:02:15Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/SubscribeTransform.java", "diffHunk": "@@ -0,0 +1,85 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import static com.google.cloud.pubsublite.internal.ExtractStatus.toCanonical;\n+\n+import com.google.api.gax.rpc.ApiException;\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.Partition;\n+import com.google.cloud.pubsublite.internal.BufferingPullSubscriber;\n+import com.google.cloud.pubsublite.internal.PullSubscriber;\n+import com.google.cloud.pubsublite.proto.Cursor;\n+import com.google.cloud.pubsublite.proto.SeekRequest;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.Reshuffle;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.util.Sleeper;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.joda.time.Duration;\n+\n+class SubscribeTransform extends PTransform<PBegin, PCollection<SequencedMessage>> {\n+  private static final Duration MAX_SLEEP_TIME = Duration.standardMinutes(1);\n+\n+  private final SubscriberOptions options;\n+\n+  SubscribeTransform(SubscriberOptions options) {\n+    this.options = options;\n+  }\n+\n+  private PullSubscriber<SequencedMessage> newPullSubscriber(Partition partition, Offset offset)\n+      throws ApiException {\n+    try {\n+      return new TranslatingPullSubscriber(\n+          new BufferingPullSubscriber(\n+              options.getSubscriberFactory(partition),\n+              options.flowControlSettings(),\n+              SeekRequest.newBuilder()\n+                  .setCursor(Cursor.newBuilder().setOffset(offset.value()))\n+                  .build()));\n+    } catch (Throwable t) {\n+      throw toCanonical(t).underlying;\n+    }\n+  }\n+\n+  private RestrictionTracker<OffsetRange, OffsetByteProgress> newRestrictionTracker(\n+      Partition partition, OffsetRange initial) {\n+    return new OffsetByteRangeTracker(initial, options.getBacklogReader(partition));\n+  }\n+\n+  @Override\n+  public PCollection<SequencedMessage> expand(PBegin input) {\n+    PCollection<Partition> partitions = Create.of(options.partitions()).expand(input);\n+    // Prevent fusion between Create and read.\n+    PCollection<Partition> shuffledPartitions = partitions.apply(Reshuffle.viaRandomKey());\n+    return shuffledPartitions.apply(\n+        ParDo.of(\n+            new PerPartitionSdf(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4ba623c7fb6cc3935558a861444583496a413cf"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ1NjEzOA==", "bodyText": "What'e the effect of committing offset? Are we able to read from that offset again if it's committed?", "url": "https://github.com/apache/beam/pull/13470#discussion_r536456138", "createdAt": "2020-12-05T00:14:24Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PerPartitionSdf.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.Partition;\n+import com.google.cloud.pubsublite.internal.PullSubscriber;\n+import com.google.cloud.pubsublite.internal.wire.Committer;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import com.google.common.flogger.GoogleLogger;\n+import com.google.protobuf.util.Timestamps;\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.SerializableBiFunction;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.util.Sleeper;\n+import org.joda.time.Duration;\n+import org.joda.time.Instant;\n+\n+class PerPartitionSdf extends DoFn<Partition, SequencedMessage> {\n+  private static final GoogleLogger logger = GoogleLogger.forEnclosingClass();\n+  private final Duration maxSleepTime;\n+  private final SerializableBiFunction<Partition, Offset, PullSubscriber<SequencedMessage>>\n+      subscriberFactory;\n+  private final SerializableFunction<Partition, Committer> committerFactory;\n+  private final SerializableSupplier<Sleeper> sleeperSupplier;\n+  private final SerializableFunction<Partition, InitialOffsetReader> offsetReaderFactory;\n+  private final SerializableBiFunction<\n+          Partition, OffsetRange, RestrictionTracker<OffsetRange, OffsetByteProgress>>\n+      trackerFactory;\n+\n+  Duration sleepTimeRemaining;\n+\n+  PerPartitionSdf(\n+      Duration maxSleepTime,\n+      SerializableBiFunction<Partition, Offset, PullSubscriber<SequencedMessage>> subscriberFactory,\n+      SerializableFunction<Partition, Committer> committerFactory,\n+      SerializableSupplier<Sleeper> sleeperSupplier,\n+      SerializableFunction<Partition, InitialOffsetReader> offsetReaderFactory,\n+      SerializableBiFunction<\n+              Partition, OffsetRange, RestrictionTracker<OffsetRange, OffsetByteProgress>>\n+          trackerFactory) {\n+    this.maxSleepTime = maxSleepTime;\n+    this.sleepTimeRemaining = maxSleepTime;\n+    this.subscriberFactory = subscriberFactory;\n+    this.committerFactory = committerFactory;\n+    this.sleeperSupplier = sleeperSupplier;\n+    this.offsetReaderFactory = offsetReaderFactory;\n+    this.trackerFactory = trackerFactory;\n+  }\n+\n+  private List<SequencedMessage> doPoll(PullSubscriber<SequencedMessage> subscriber)\n+      throws Exception {\n+    Sleeper sleeper = sleeperSupplier.get();\n+    while (sleepTimeRemaining.isLongerThan(Duration.ZERO)) {\n+      List<SequencedMessage> messages = subscriber.pull();\n+      if (!messages.isEmpty()) {\n+        return messages;\n+      }\n+      Duration sleepTime =\n+          Collections.min(ImmutableList.of(sleepTimeRemaining, Duration.millis(50)));\n+      sleepTimeRemaining = sleepTimeRemaining.minus(sleepTime);\n+      sleeper.sleep(sleepTime.getMillis());\n+    }\n+    return ImmutableList.of();\n+  }\n+\n+  @ProcessElement\n+  public ProcessContinuation processElement(\n+      RestrictionTracker<OffsetRange, OffsetByteProgress> tracker,\n+      @Element Partition partition,\n+      OutputReceiver<SequencedMessage> receiver)\n+      throws Exception {\n+    logger.atInfo().log(\"Starting processing for partition \" + partition);\n+    sleepTimeRemaining = maxSleepTime;\n+    Committer committer = committerFactory.apply(partition);\n+    committer.startAsync().awaitRunning();\n+    try (PullSubscriber<SequencedMessage> subscriber =\n+        subscriberFactory.apply(partition, Offset.of(tracker.currentRestriction().getFrom()))) {\n+      while (true) {\n+        List<SequencedMessage> messages = doPoll(subscriber);\n+        // We polled for as long as possible, yield to the runtime to allow it to reschedule us on\n+        // a new task.\n+        if (messages.isEmpty()) {\n+          logger.atInfo().log(\"Yielding due to timeout on partition \" + partition);\n+          return ProcessContinuation.resume();\n+        }\n+        Offset lastOffset = Offset.of(Iterables.getLast(messages).getCursor().getOffset());\n+        long byteSize = messages.stream().mapToLong(SequencedMessage::getSizeBytes).sum();\n+        if (tracker.tryClaim(OffsetByteProgress.of(lastOffset, byteSize))) {\n+          messages.forEach(\n+              message ->\n+                  receiver.outputWithTimestamp(\n+                      message, new Instant(Timestamps.toMillis(message.getPublishTime()))));\n+          committer.commitOffset(Offset.of(lastOffset.value() + 1)).get();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4ba623c7fb6cc3935558a861444583496a413cf"}, "originalPosition": 115}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e4ba623c7fb6cc3935558a861444583496a413cf", "author": {"user": {"login": "dpcollins-google", "name": null}}, "url": "https://github.com/apache/beam/commit/e4ba623c7fb6cc3935558a861444583496a413cf", "committedDate": "2020-12-04T15:54:48Z", "message": "fix: Testing issues"}, "afterCommit": {"oid": "c0fd31a800c721e50faf3ff2d8934bef8f0e467f", "author": {"user": {"login": "dpcollins-google", "name": null}}, "url": "https://github.com/apache/beam/commit/c0fd31a800c721e50faf3ff2d8934bef8f0e467f", "committedDate": "2020-12-09T17:48:28Z", "message": "[BEAM-10114] Convert PubsubLiteIO to use an SDF for reads."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "31dcd532d447aaf8bba8916a016fb263ccd5f4d0", "author": {"user": {"login": "dpcollins-google", "name": null}}, "url": "https://github.com/apache/beam/commit/31dcd532d447aaf8bba8916a016fb263ccd5f4d0", "committedDate": "2020-12-10T04:33:59Z", "message": "[BEAM-10114] Convert PubsubLiteIO read to use SplittableDoFn.\n\nAlso bump the Pub/Sub Lite version and make the requisite changes, and simplify options."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ec3efe20bbd75a8add3c26a4377430b15d73d9dc", "author": {"user": {"login": "dpcollins-google", "name": null}}, "url": "https://github.com/apache/beam/commit/ec3efe20bbd75a8add3c26a4377430b15d73d9dc", "committedDate": "2020-12-10T04:33:59Z", "message": "Fix test."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d3336fe45c838f5b05fcb4b83e4b92c572b49fcc", "author": {"user": {"login": "dpcollins-google", "name": null}}, "url": "https://github.com/apache/beam/commit/d3336fe45c838f5b05fcb4b83e4b92c572b49fcc", "committedDate": "2020-12-10T04:33:59Z", "message": "fix: Testing issues"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8892c1c809694cdc839502b42869bc30b24d93a2", "author": {"user": {"login": "dpcollins-google", "name": null}}, "url": "https://github.com/apache/beam/commit/8892c1c809694cdc839502b42869bc30b24d93a2", "committedDate": "2020-12-10T04:33:59Z", "message": "[BEAM-10114] Convert PubsubLiteIO to use an SDF for reads."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f5c61088f90d7ad98d513fde47cc4ac85ff09760", "author": {"user": {"login": "dpcollins-google", "name": null}}, "url": "https://github.com/apache/beam/commit/f5c61088f90d7ad98d513fde47cc4ac85ff09760", "committedDate": "2020-12-10T04:33:59Z", "message": "[BEAM-10114] Add byte and time limiting"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "2ef19bfe1ec5b9851b59f428608a3e4e2aa425cd", "author": {"user": {"login": "dpcollins-google", "name": null}}, "url": "https://github.com/apache/beam/commit/2ef19bfe1ec5b9851b59f428608a3e4e2aa425cd", "committedDate": "2020-12-10T04:28:05Z", "message": "[BEAM-10114] Add byte and time limiting"}, "afterCommit": {"oid": "f5c61088f90d7ad98d513fde47cc4ac85ff09760", "author": {"user": {"login": "dpcollins-google", "name": null}}, "url": "https://github.com/apache/beam/commit/f5c61088f90d7ad98d513fde47cc4ac85ff09760", "committedDate": "2020-12-10T04:33:59Z", "message": "[BEAM-10114] Add byte and time limiting"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6d8c0a9f2491013336ef7301678f2ecd2b666c4e", "author": {"user": {"login": "dpcollins-google", "name": null}}, "url": "https://github.com/apache/beam/commit/6d8c0a9f2491013336ef7301678f2ecd2b666c4e", "committedDate": "2020-12-10T04:46:25Z", "message": "[BEAM-10114] Add byte and time limiting"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "762b7ba066cdc9895e18d4821696fb090dbd9a19", "author": {"user": {"login": "dpcollins-google", "name": null}}, "url": "https://github.com/apache/beam/commit/762b7ba066cdc9895e18d4821696fb090dbd9a19", "committedDate": "2020-12-10T07:31:54Z", "message": "[BEAM-10114] Add byte and time limiting"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "65b2c42a1916dc68b8bb75438f26e752ecb6f854", "author": {"user": {"login": "dpcollins-google", "name": null}}, "url": "https://github.com/apache/beam/commit/65b2c42a1916dc68b8bb75438f26e752ecb6f854", "committedDate": "2020-12-10T07:36:00Z", "message": "[BEAM-10114] Add byte and time limiting"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "418b3ac6d14384d191cf861866bd009d79b58f6e", "author": {"user": {"login": "dpcollins-google", "name": null}}, "url": "https://github.com/apache/beam/commit/418b3ac6d14384d191cf861866bd009d79b58f6e", "committedDate": "2020-12-10T07:40:25Z", "message": "[BEAM-10114] Add byte and time limiting"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "843fc4a6cecc00818246c7d8a84c33458f71d801", "author": {"user": {"login": "dpcollins-google", "name": null}}, "url": "https://github.com/apache/beam/commit/843fc4a6cecc00818246c7d8a84c33458f71d801", "committedDate": "2020-12-10T07:52:10Z", "message": "[BEAM-10114] Add byte and time limiting"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fa3fc2dbcb1f426de1c71062a10143d15f48192c", "author": {"user": {"login": "dpcollins-google", "name": null}}, "url": "https://github.com/apache/beam/commit/fa3fc2dbcb1f426de1c71062a10143d15f48192c", "committedDate": "2020-12-14T17:30:44Z", "message": "fix: Linter issues"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ea33f9ec500d4710386dacc00b885e5a1334c659", "author": {"user": {"login": "dpcollins-google", "name": null}}, "url": "https://github.com/apache/beam/commit/ea33f9ec500d4710386dacc00b885e5a1334c659", "committedDate": "2020-12-14T17:41:19Z", "message": "fix: linters"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "88a30211fe9046969e36f6934dd00f971836ac4b", "author": {"user": {"login": "dpcollins-google", "name": null}}, "url": "https://github.com/apache/beam/commit/88a30211fe9046969e36f6934dd00f971836ac4b", "committedDate": "2020-12-14T19:40:17Z", "message": "fix: linters"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUzMTcyODk4", "url": "https://github.com/apache/beam/pull/13470#pullrequestreview-553172898", "createdAt": "2020-12-16T00:28:56Z", "commit": {"oid": "88a30211fe9046969e36f6934dd00f971836ac4b"}, "state": "COMMENTED", "comments": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQwMDoyODo1NlrOIGmHrw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQwMToxMjoyMVrOIGnIfQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mzc4NjkyNw==", "bodyText": "You also want to return null when fractionOfRemainder > 0.0", "url": "https://github.com/apache/beam/pull/13470#discussion_r543786927", "createdAt": "2020-12-16T00:28:56Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/OffsetByteRangeTracker.java", "diffHunk": "@@ -0,0 +1,172 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.proto.ComputeMessageStatsResponse;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker.HasProgress;\n+import org.apache.beam.sdk.transforms.splittabledofn.SplitResult;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Stopwatch;\n+import org.joda.time.Duration;\n+\n+/**\n+ * OffsetByteRangeTracker is an unbounded restriction tracker for Pub/Sub lite partitions that\n+ * tracks offsets for checkpointing and bytes for progress.\n+ *\n+ * <p>Any valid instance of an OffsetByteRangeTracker tracks one of exactly two types of ranges: -\n+ * Unbounded ranges whose last offset is Long.MAX_VALUE - Completed ranges that are either empty\n+ * (From == To) or fully claimed (lastClaimed == To - 1)\n+ *\n+ * <p>Also prevents splitting until minTrackingTime has passed or minBytesReceived have been\n+ * received. IMPORTANT: minTrackingTime must be strictly smaller than the SDF read timeout when it\n+ * would return ProcessContinuation.resume().\n+ */\n+class OffsetByteRangeTracker extends RestrictionTracker<OffsetRange, OffsetByteProgress>\n+    implements HasProgress {\n+  private final TopicBacklogReader backlogReader;\n+  private final Duration minTrackingTime;\n+  private final long minBytesReceived;\n+  private final Stopwatch stopwatch;\n+  private OffsetRange range;\n+  private @Nullable Long lastClaimed;\n+  private long byteCount = 0;\n+\n+  public OffsetByteRangeTracker(\n+      OffsetRange range,\n+      TopicBacklogReader backlogReader,\n+      Stopwatch stopwatch,\n+      Duration minTrackingTime,\n+      long minBytesReceived) {\n+    checkArgument(range.getTo() == Long.MAX_VALUE);\n+    this.backlogReader = backlogReader;\n+    this.minTrackingTime = minTrackingTime;\n+    this.minBytesReceived = minBytesReceived;\n+    this.stopwatch = stopwatch.reset().start();\n+    this.range = range;\n+  }\n+\n+  @Override\n+  public void finalize() {\n+    this.backlogReader.close();\n+  }\n+\n+  @Override\n+  public IsBounded isBounded() {\n+    return IsBounded.UNBOUNDED;\n+  }\n+\n+  @Override\n+  public boolean tryClaim(OffsetByteProgress position) {\n+    long toClaim = position.lastOffset().value();\n+    checkArgument(\n+        lastClaimed == null || toClaim > lastClaimed,\n+        \"Trying to claim offset %s while last attempted was %s\",\n+        position.lastOffset().value(),\n+        lastClaimed);\n+    checkArgument(\n+        toClaim >= range.getFrom(),\n+        \"Trying to claim offset %s before start of the range %s\",\n+        toClaim,\n+        range);\n+    // split() has already been called, truncating this range. No more offsets may be claimed.\n+    if (range.getTo() != Long.MAX_VALUE) {\n+      boolean isRangeEmpty = range.getTo() == range.getFrom();\n+      boolean isValidClosedRange = nextOffset() == range.getTo();\n+      checkState(\n+          isRangeEmpty || isValidClosedRange,\n+          \"Violated class precondition: offset range improperly split. Please report a beam bug.\");\n+      return false;\n+    }\n+    lastClaimed = toClaim;\n+    byteCount += position.batchBytes();\n+    return true;\n+  }\n+\n+  @Override\n+  public OffsetRange currentRestriction() {\n+    return range;\n+  }\n+\n+  private long nextOffset() {\n+    checkState(lastClaimed == null || lastClaimed < Long.MAX_VALUE);\n+    return lastClaimed == null ? currentRestriction().getFrom() : lastClaimed + 1;\n+  }\n+\n+  /**\n+   * Whether the tracker has received enough data/been running for enough time that it can\n+   * checkpoint and be confident it can get sufficient throughput.\n+   */\n+  private boolean receivedEnough() {\n+    Duration duration = Duration.millis(stopwatch.elapsed(TimeUnit.MILLISECONDS));\n+    if (duration.isLongerThan(minTrackingTime)) {\n+      return true;\n+    }\n+    if (byteCount >= minBytesReceived) {\n+      return true;\n+    }\n+    return false;\n+  }\n+\n+  @Override\n+  public @Nullable SplitResult<OffsetRange> trySplit(double fractionOfRemainder) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "88a30211fe9046969e36f6934dd00f971836ac4b"}, "originalPosition": 134}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mzc4OTEyOA==", "bodyText": "SubscriptionPartitionFactory?", "url": "https://github.com/apache/beam/pull/13470#discussion_r543789128", "createdAt": "2020-12-16T00:34:33Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PartitionProcessorFactory.java", "diffHunk": "@@ -0,0 +1,33 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import java.io.Serializable;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.DoFn.OutputReceiver;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+\n+interface PartitionProcessorFactory extends Serializable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "88a30211fe9046969e36f6934dd00f971836ac4b"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mzc4OTI4Mw==", "bodyText": "SubscriptionPartitionProcessor?", "url": "https://github.com/apache/beam/pull/13470#discussion_r543789283", "createdAt": "2020-12-16T00:34:55Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PartitionProcessor.java", "diffHunk": "@@ -17,12 +17,12 @@\n  */\n package org.apache.beam.sdk.io.gcp.pubsublite;\n \n-import com.google.cloud.pubsublite.Offset;\n-import com.google.cloud.pubsublite.Partition;\n import com.google.cloud.pubsublite.internal.CheckedApiException;\n-import java.util.Map;\n+import org.apache.beam.sdk.transforms.DoFn.ProcessContinuation;\n+import org.joda.time.Duration;\n \n-/** An internal interface for finalizing offsets. */\n-interface OffsetFinalizer {\n-  void finalizeOffsets(Map<Partition, Offset> offsets) throws CheckedApiException;\n+interface PartitionProcessor extends AutoCloseable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "88a30211fe9046969e36f6934dd00f971836ac4b"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mzc4OTQ2Mg==", "bodyText": "SubscriptionPartitionProcessorImpl?", "url": "https://github.com/apache/beam/pull/13470#discussion_r543789462", "createdAt": "2020-12-16T00:35:26Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PartitionProcessorImpl.java", "diffHunk": "@@ -0,0 +1,143 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import com.google.api.core.ApiService.Listener;\n+import com.google.api.core.ApiService.State;\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.cloudpubsub.FlowControlSettings;\n+import com.google.cloud.pubsublite.internal.CheckedApiException;\n+import com.google.cloud.pubsublite.internal.ExtractStatus;\n+import com.google.cloud.pubsublite.internal.wire.Subscriber;\n+import com.google.cloud.pubsublite.proto.Cursor;\n+import com.google.cloud.pubsublite.proto.FlowControlRequest;\n+import com.google.cloud.pubsublite.proto.SeekRequest;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import com.google.protobuf.util.Timestamps;\n+import java.util.List;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.DoFn.OutputReceiver;\n+import org.apache.beam.sdk.transforms.DoFn.ProcessContinuation;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Iterables;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.util.concurrent.MoreExecutors;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.util.concurrent.SettableFuture;\n+import org.joda.time.Duration;\n+import org.joda.time.Instant;\n+\n+class PartitionProcessorImpl extends Listener implements PartitionProcessor {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "88a30211fe9046969e36f6934dd00f971836ac4b"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mzc5MDQzOQ==", "bodyText": "PerSubscriptionPartitionSdf?", "url": "https://github.com/apache/beam/pull/13470#discussion_r543790439", "createdAt": "2020-12-16T00:37:57Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PerPartitionSdf.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.internal.wire.Committer;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import java.util.Optional;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.SerializableBiFunction;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.transforms.splittabledofn.SplitResult;\n+import org.apache.beam.sdk.transforms.splittabledofn.WatermarkEstimators.MonotonicallyIncreasing;\n+import org.joda.time.Duration;\n+import org.joda.time.Instant;\n+\n+class PerPartitionSdf extends DoFn<SubscriptionPartition, SequencedMessage> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "88a30211fe9046969e36f6934dd00f971836ac4b"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mzc5MjcxMw==", "bodyText": "When you have got the result from processor.waitForCompletion(maxSleepTime), the tracker.currentRestriction().getTo() will be the lastClaimed you want.", "url": "https://github.com/apache/beam/pull/13470#discussion_r543792713", "createdAt": "2020-12-16T00:43:52Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PerPartitionSdf.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.internal.wire.Committer;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import java.util.Optional;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.SerializableBiFunction;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.transforms.splittabledofn.SplitResult;\n+import org.apache.beam.sdk.transforms.splittabledofn.WatermarkEstimators.MonotonicallyIncreasing;\n+import org.joda.time.Duration;\n+import org.joda.time.Instant;\n+\n+class PerPartitionSdf extends DoFn<SubscriptionPartition, SequencedMessage> {\n+  private final Duration maxSleepTime;\n+  private final PartitionProcessorFactory processorFactory;\n+  private final SerializableFunction<SubscriptionPartition, InitialOffsetReader>\n+      offsetReaderFactory;\n+  private final SerializableBiFunction<\n+          SubscriptionPartition, OffsetRange, RestrictionTracker<OffsetRange, OffsetByteProgress>>\n+      trackerFactory;\n+  private final SerializableFunction<SubscriptionPartition, Committer> committerFactory;\n+\n+  PerPartitionSdf(\n+      Duration maxSleepTime,\n+      SerializableFunction<SubscriptionPartition, InitialOffsetReader> offsetReaderFactory,\n+      SerializableBiFunction<\n+              SubscriptionPartition,\n+              OffsetRange,\n+              RestrictionTracker<OffsetRange, OffsetByteProgress>>\n+          trackerFactory,\n+      PartitionProcessorFactory processorFactory,\n+      SerializableFunction<SubscriptionPartition, Committer> committerFactory) {\n+    this.maxSleepTime = maxSleepTime;\n+    this.processorFactory = processorFactory;\n+    this.offsetReaderFactory = offsetReaderFactory;\n+    this.trackerFactory = trackerFactory;\n+    this.committerFactory = committerFactory;\n+  }\n+\n+  private static final class WrappedTracker\n+      extends RestrictionTracker<OffsetRange, OffsetByteProgress> {\n+    private final RestrictionTracker<OffsetRange, OffsetByteProgress> underlying;\n+    Optional<Offset> lastClaimed;\n+\n+    WrappedTracker(RestrictionTracker<OffsetRange, OffsetByteProgress> underlying) {\n+      this.underlying = underlying;\n+      this.lastClaimed = Optional.empty();\n+    }\n+\n+    @Override\n+    public boolean tryClaim(OffsetByteProgress position) {\n+      boolean claimed = underlying.tryClaim(position);\n+      if (claimed) {\n+        lastClaimed = Optional.of(position.lastOffset());\n+      }\n+      return claimed;\n+    }\n+\n+    @Override\n+    public OffsetRange currentRestriction() {\n+      return underlying.currentRestriction();\n+    }\n+\n+    @Override\n+    public @Nullable SplitResult<OffsetRange> trySplit(double fractionOfRemainder) {\n+      return underlying.trySplit(fractionOfRemainder);\n+    }\n+\n+    @Override\n+    public void checkDone() throws IllegalStateException {\n+      underlying.checkDone();\n+    }\n+\n+    @Override\n+    public IsBounded isBounded() {\n+      return underlying.isBounded();\n+    }\n+  }\n+\n+  @GetInitialWatermarkEstimatorState\n+  Instant getInitialWatermarkState() {\n+    return Instant.EPOCH;\n+  }\n+\n+  @NewWatermarkEstimator\n+  MonotonicallyIncreasing newWatermarkEstimator(@WatermarkEstimatorState Instant state) {\n+    return new MonotonicallyIncreasing(state);\n+  }\n+\n+  @ProcessElement\n+  public ProcessContinuation processElement(\n+      RestrictionTracker<OffsetRange, OffsetByteProgress> tracker,\n+      @Element SubscriptionPartition subscriptionPartition,\n+      OutputReceiver<SequencedMessage> receiver,\n+      BundleFinalizer finalizer)\n+      throws Exception {\n+    WrappedTracker wrapped = new WrappedTracker(tracker);\n+    try (PartitionProcessor processor =\n+        processorFactory.newProcessor(subscriptionPartition, wrapped, receiver)) {\n+      processor.start();\n+      ProcessContinuation result = processor.waitForCompletion(maxSleepTime);\n+      wrapped.lastClaimed.ifPresent(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "88a30211fe9046969e36f6934dd00f971836ac4b"}, "originalPosition": 124}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mzc5NjAyNQ==", "bodyText": "I don'y think inserting a Reshuffle is necessary.", "url": "https://github.com/apache/beam/pull/13470#discussion_r543796025", "createdAt": "2020-12-16T00:52:41Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/SubscribeTransform.java", "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import static com.google.cloud.pubsublite.internal.ExtractStatus.toCanonical;\n+import static com.google.cloud.pubsublite.internal.UncheckedApiPreconditions.checkArgument;\n+\n+import com.google.api.gax.rpc.ApiException;\n+import com.google.cloud.pubsublite.Partition;\n+import com.google.cloud.pubsublite.internal.wire.Committer;\n+import com.google.cloud.pubsublite.internal.wire.Subscriber;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import java.util.List;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.transforms.DoFn.OutputReceiver;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.Reshuffle;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Stopwatch;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.math.LongMath;\n+import org.joda.time.Duration;\n+\n+class SubscribeTransform extends PTransform<PBegin, PCollection<SequencedMessage>> {\n+  private static final Duration MAX_SLEEP_TIME = Duration.standardMinutes(1);\n+\n+  private final SubscriberOptions options;\n+\n+  SubscribeTransform(SubscriberOptions options) {\n+    this.options = options;\n+  }\n+\n+  private void checkSubscription(SubscriptionPartition subscriptionPartition) throws ApiException {\n+    checkArgument(subscriptionPartition.subscription().equals(options.subscriptionPath()));\n+  }\n+\n+  private Subscriber newSubscriber(Partition partition, Consumer<List<SequencedMessage>> consumer) {\n+    try {\n+      return options\n+          .getSubscriberFactory(partition)\n+          .newSubscriber(\n+              messages ->\n+                  consumer.accept(\n+                      messages.stream()\n+                          .map(message -> message.toProto())\n+                          .collect(Collectors.toList())));\n+    } catch (Throwable t) {\n+      throw toCanonical(t).underlying;\n+    }\n+  }\n+\n+  private PartitionProcessor newPartitionProcessor(\n+      SubscriptionPartition subscriptionPartition,\n+      RestrictionTracker<OffsetRange, OffsetByteProgress> tracker,\n+      OutputReceiver<SequencedMessage> receiver)\n+      throws ApiException {\n+    checkSubscription(subscriptionPartition);\n+    return new PartitionProcessorImpl(\n+        tracker,\n+        receiver,\n+        consumer -> newSubscriber(subscriptionPartition.partition(), consumer),\n+        options.flowControlSettings());\n+  }\n+\n+  private RestrictionTracker<OffsetRange, OffsetByteProgress> newRestrictionTracker(\n+      SubscriptionPartition subscriptionPartition, OffsetRange initial) {\n+    checkSubscription(subscriptionPartition);\n+    return new OffsetByteRangeTracker(\n+        initial,\n+        options.getBacklogReader(subscriptionPartition.partition()),\n+        Stopwatch.createUnstarted(),\n+        MAX_SLEEP_TIME.multipliedBy(3).dividedBy(4),\n+        LongMath.saturatedMultiply(options.flowControlSettings().bytesOutstanding(), 10));\n+  }\n+\n+  private InitialOffsetReader newInitialOffsetReader(SubscriptionPartition subscriptionPartition) {\n+    checkSubscription(subscriptionPartition);\n+    return options.getInitialOffsetReader(subscriptionPartition.partition());\n+  }\n+\n+  private Committer newCommitter(SubscriptionPartition subscriptionPartition) {\n+    checkSubscription(subscriptionPartition);\n+    return options.getCommitter(subscriptionPartition.partition());\n+  }\n+\n+  @Override\n+  public PCollection<SequencedMessage> expand(PBegin input) {\n+    PCollection<SubscriptionPartition> partitions =\n+        Create.of(\n+                options.partitions().stream()\n+                    .map(\n+                        partition ->\n+                            SubscriptionPartition.of(options.subscriptionPath(), partition))\n+                    .collect(Collectors.toList()))\n+            .expand(input);\n+    // Prevent fusion between Create and read.\n+    PCollection<SubscriptionPartition> shuffledPartitions =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "88a30211fe9046969e36f6934dd00f971836ac4b"}, "originalPosition": 117}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzgwMDIyNQ==", "bodyText": "I'm curious why we need a trackerFactory here instead of returning your OffsetByteRangeTracker directly. Do you expect your SDF user to implement their own restriction tracker?", "url": "https://github.com/apache/beam/pull/13470#discussion_r543800225", "createdAt": "2020-12-16T01:03:53Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PerPartitionSdf.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.internal.wire.Committer;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import java.util.Optional;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.SerializableBiFunction;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.transforms.splittabledofn.SplitResult;\n+import org.apache.beam.sdk.transforms.splittabledofn.WatermarkEstimators.MonotonicallyIncreasing;\n+import org.joda.time.Duration;\n+import org.joda.time.Instant;\n+\n+class PerPartitionSdf extends DoFn<SubscriptionPartition, SequencedMessage> {\n+  private final Duration maxSleepTime;\n+  private final PartitionProcessorFactory processorFactory;\n+  private final SerializableFunction<SubscriptionPartition, InitialOffsetReader>\n+      offsetReaderFactory;\n+  private final SerializableBiFunction<\n+          SubscriptionPartition, OffsetRange, RestrictionTracker<OffsetRange, OffsetByteProgress>>\n+      trackerFactory;\n+  private final SerializableFunction<SubscriptionPartition, Committer> committerFactory;\n+\n+  PerPartitionSdf(\n+      Duration maxSleepTime,\n+      SerializableFunction<SubscriptionPartition, InitialOffsetReader> offsetReaderFactory,\n+      SerializableBiFunction<\n+              SubscriptionPartition,\n+              OffsetRange,\n+              RestrictionTracker<OffsetRange, OffsetByteProgress>>\n+          trackerFactory,\n+      PartitionProcessorFactory processorFactory,\n+      SerializableFunction<SubscriptionPartition, Committer> committerFactory) {\n+    this.maxSleepTime = maxSleepTime;\n+    this.processorFactory = processorFactory;\n+    this.offsetReaderFactory = offsetReaderFactory;\n+    this.trackerFactory = trackerFactory;\n+    this.committerFactory = committerFactory;\n+  }\n+\n+  private static final class WrappedTracker\n+      extends RestrictionTracker<OffsetRange, OffsetByteProgress> {\n+    private final RestrictionTracker<OffsetRange, OffsetByteProgress> underlying;\n+    Optional<Offset> lastClaimed;\n+\n+    WrappedTracker(RestrictionTracker<OffsetRange, OffsetByteProgress> underlying) {\n+      this.underlying = underlying;\n+      this.lastClaimed = Optional.empty();\n+    }\n+\n+    @Override\n+    public boolean tryClaim(OffsetByteProgress position) {\n+      boolean claimed = underlying.tryClaim(position);\n+      if (claimed) {\n+        lastClaimed = Optional.of(position.lastOffset());\n+      }\n+      return claimed;\n+    }\n+\n+    @Override\n+    public OffsetRange currentRestriction() {\n+      return underlying.currentRestriction();\n+    }\n+\n+    @Override\n+    public @Nullable SplitResult<OffsetRange> trySplit(double fractionOfRemainder) {\n+      return underlying.trySplit(fractionOfRemainder);\n+    }\n+\n+    @Override\n+    public void checkDone() throws IllegalStateException {\n+      underlying.checkDone();\n+    }\n+\n+    @Override\n+    public IsBounded isBounded() {\n+      return underlying.isBounded();\n+    }\n+  }\n+\n+  @GetInitialWatermarkEstimatorState\n+  Instant getInitialWatermarkState() {\n+    return Instant.EPOCH;\n+  }\n+\n+  @NewWatermarkEstimator\n+  MonotonicallyIncreasing newWatermarkEstimator(@WatermarkEstimatorState Instant state) {\n+    return new MonotonicallyIncreasing(state);\n+  }\n+\n+  @ProcessElement\n+  public ProcessContinuation processElement(\n+      RestrictionTracker<OffsetRange, OffsetByteProgress> tracker,\n+      @Element SubscriptionPartition subscriptionPartition,\n+      OutputReceiver<SequencedMessage> receiver,\n+      BundleFinalizer finalizer)\n+      throws Exception {\n+    WrappedTracker wrapped = new WrappedTracker(tracker);\n+    try (PartitionProcessor processor =\n+        processorFactory.newProcessor(subscriptionPartition, wrapped, receiver)) {\n+      processor.start();\n+      ProcessContinuation result = processor.waitForCompletion(maxSleepTime);\n+      wrapped.lastClaimed.ifPresent(\n+          lastClaimedOffset ->\n+              finalizer.afterBundleCommit(\n+                  Instant.ofEpochMilli(Long.MAX_VALUE),\n+                  () -> {\n+                    Committer committer = committerFactory.apply(subscriptionPartition);\n+                    committer.startAsync().awaitRunning();\n+                    // Commit the next-to-deliver offset.\n+                    committer.commitOffset(Offset.of(lastClaimedOffset.value() + 1)).get();\n+                    committer.stopAsync().awaitTerminated();\n+                  }));\n+      return result;\n+    }\n+  }\n+\n+  @GetInitialRestriction\n+  public OffsetRange getInitialRestriction(@Element SubscriptionPartition subscriptionPartition) {\n+    try (InitialOffsetReader reader = offsetReaderFactory.apply(subscriptionPartition)) {\n+      Offset offset = reader.read();\n+      return new OffsetRange(offset.value(), Long.MAX_VALUE /* open interval */);\n+    }\n+  }\n+\n+  @NewTracker\n+  public RestrictionTracker<OffsetRange, OffsetByteProgress> newTracker(\n+      @Element SubscriptionPartition subscriptionPartition, @Restriction OffsetRange range) {\n+    return trackerFactory.apply(subscriptionPartition, range);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "88a30211fe9046969e36f6934dd00f971836ac4b"}, "originalPosition": 150}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzgwMTk0OQ==", "bodyText": "Can the PerPartitionSdf take the SubscriberOptions  as the constructor? Then the PerParittionSdf can construct  Committer, PartitionProcessor and InitialOffsetReader by itself, instead of asking the caller to do so?", "url": "https://github.com/apache/beam/pull/13470#discussion_r543801949", "createdAt": "2020-12-16T01:08:11Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/SubscribeTransform.java", "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import static com.google.cloud.pubsublite.internal.ExtractStatus.toCanonical;\n+import static com.google.cloud.pubsublite.internal.UncheckedApiPreconditions.checkArgument;\n+\n+import com.google.api.gax.rpc.ApiException;\n+import com.google.cloud.pubsublite.Partition;\n+import com.google.cloud.pubsublite.internal.wire.Committer;\n+import com.google.cloud.pubsublite.internal.wire.Subscriber;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import java.util.List;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.transforms.DoFn.OutputReceiver;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.Reshuffle;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Stopwatch;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.math.LongMath;\n+import org.joda.time.Duration;\n+\n+class SubscribeTransform extends PTransform<PBegin, PCollection<SequencedMessage>> {\n+  private static final Duration MAX_SLEEP_TIME = Duration.standardMinutes(1);\n+\n+  private final SubscriberOptions options;\n+\n+  SubscribeTransform(SubscriberOptions options) {\n+    this.options = options;\n+  }\n+\n+  private void checkSubscription(SubscriptionPartition subscriptionPartition) throws ApiException {\n+    checkArgument(subscriptionPartition.subscription().equals(options.subscriptionPath()));\n+  }\n+\n+  private Subscriber newSubscriber(Partition partition, Consumer<List<SequencedMessage>> consumer) {\n+    try {\n+      return options\n+          .getSubscriberFactory(partition)\n+          .newSubscriber(\n+              messages ->\n+                  consumer.accept(\n+                      messages.stream()\n+                          .map(message -> message.toProto())\n+                          .collect(Collectors.toList())));\n+    } catch (Throwable t) {\n+      throw toCanonical(t).underlying;\n+    }\n+  }\n+\n+  private PartitionProcessor newPartitionProcessor(\n+      SubscriptionPartition subscriptionPartition,\n+      RestrictionTracker<OffsetRange, OffsetByteProgress> tracker,\n+      OutputReceiver<SequencedMessage> receiver)\n+      throws ApiException {\n+    checkSubscription(subscriptionPartition);\n+    return new PartitionProcessorImpl(\n+        tracker,\n+        receiver,\n+        consumer -> newSubscriber(subscriptionPartition.partition(), consumer),\n+        options.flowControlSettings());\n+  }\n+\n+  private RestrictionTracker<OffsetRange, OffsetByteProgress> newRestrictionTracker(\n+      SubscriptionPartition subscriptionPartition, OffsetRange initial) {\n+    checkSubscription(subscriptionPartition);\n+    return new OffsetByteRangeTracker(\n+        initial,\n+        options.getBacklogReader(subscriptionPartition.partition()),\n+        Stopwatch.createUnstarted(),\n+        MAX_SLEEP_TIME.multipliedBy(3).dividedBy(4),\n+        LongMath.saturatedMultiply(options.flowControlSettings().bytesOutstanding(), 10));\n+  }\n+\n+  private InitialOffsetReader newInitialOffsetReader(SubscriptionPartition subscriptionPartition) {\n+    checkSubscription(subscriptionPartition);\n+    return options.getInitialOffsetReader(subscriptionPartition.partition());\n+  }\n+\n+  private Committer newCommitter(SubscriptionPartition subscriptionPartition) {\n+    checkSubscription(subscriptionPartition);\n+    return options.getCommitter(subscriptionPartition.partition());\n+  }\n+\n+  @Override\n+  public PCollection<SequencedMessage> expand(PBegin input) {\n+    PCollection<SubscriptionPartition> partitions =\n+        Create.of(\n+                options.partitions().stream()\n+                    .map(\n+                        partition ->\n+                            SubscriptionPartition.of(options.subscriptionPath(), partition))\n+                    .collect(Collectors.toList()))\n+            .expand(input);\n+    // Prevent fusion between Create and read.\n+    PCollection<SubscriptionPartition> shuffledPartitions =\n+        partitions.apply(Reshuffle.viaRandomKey());\n+    return shuffledPartitions.apply(\n+        ParDo.of(\n+            new PerPartitionSdf(\n+                MAX_SLEEP_TIME,\n+                this::newInitialOffsetReader,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "88a30211fe9046969e36f6934dd00f971836ac4b"}, "originalPosition": 123}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzgwMjUyMw==", "bodyText": "Have you consider the x-lang usage, where you may want to use Schema to represent your element?", "url": "https://github.com/apache/beam/pull/13470#discussion_r543802523", "createdAt": "2020-12-16T01:09:49Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/SubscriptionPartitionCoder.java", "diffHunk": "@@ -0,0 +1,66 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import com.google.cloud.pubsublite.Partition;\n+import com.google.cloud.pubsublite.SubscriptionPath;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import org.apache.beam.sdk.coders.AtomicCoder;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.CoderProvider;\n+import org.apache.beam.sdk.coders.CoderProviders;\n+import org.apache.beam.sdk.coders.DelegateCoder;\n+import org.apache.beam.sdk.coders.KvCoder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.coders.VarLongCoder;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.TypeDescriptor;\n+\n+public class SubscriptionPartitionCoder extends AtomicCoder<SubscriptionPartition> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "88a30211fe9046969e36f6934dd00f971836ac4b"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzgwMzUxNw==", "bodyText": "Why not put the whole logic into PubSubLiteIO?", "url": "https://github.com/apache/beam/pull/13470#discussion_r543803517", "createdAt": "2020-12-16T01:12:21Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/SubscribeTransform.java", "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import static com.google.cloud.pubsublite.internal.ExtractStatus.toCanonical;\n+import static com.google.cloud.pubsublite.internal.UncheckedApiPreconditions.checkArgument;\n+\n+import com.google.api.gax.rpc.ApiException;\n+import com.google.cloud.pubsublite.Partition;\n+import com.google.cloud.pubsublite.internal.wire.Committer;\n+import com.google.cloud.pubsublite.internal.wire.Subscriber;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import java.util.List;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.transforms.DoFn.OutputReceiver;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.Reshuffle;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Stopwatch;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.math.LongMath;\n+import org.joda.time.Duration;\n+\n+class SubscribeTransform extends PTransform<PBegin, PCollection<SequencedMessage>> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "88a30211fe9046969e36f6934dd00f971836ac4b"}, "originalPosition": 44}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b731da8a2cf8fc8c227e33e23955333da19adbbd", "author": {"user": {"login": "dpcollins-google", "name": null}}, "url": "https://github.com/apache/beam/commit/b731da8a2cf8fc8c227e33e23955333da19adbbd", "committedDate": "2020-12-16T01:27:09Z", "message": "fix: Remove unnecessary shuffle."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a432e8f05ffad7db85cdb690e277b5aeb3e10ba8", "author": {"user": {"login": "dpcollins-google", "name": null}}, "url": "https://github.com/apache/beam/commit/a432e8f05ffad7db85cdb690e277b5aeb3e10ba8", "committedDate": "2020-12-16T02:45:14Z", "message": "fix: Address comments"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4305, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}