{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzk2MjY3OTcw", "number": 11274, "reviewThreads": {"totalCount": 23, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQwODozNTo1NlrOD0Huvw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wOFQxNDo0MjowOFrOD6qjrw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU1OTc5MTk5OnYy", "diffSide": "RIGHT", "path": ".test-infra/jenkins/job_PerformanceTests_PubsubIO_Python.groovy", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQwODozNTo1NlrOGI5rQg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQwODozNTo1NlrOGI5rQg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTk4Njc1NA==", "bodyText": "I believe BigQueryIO should be replaced by PubsubIO", "url": "https://github.com/apache/beam/pull/11274#discussion_r411986754", "createdAt": "2020-04-21T08:35:56Z", "author": {"login": "kamilwu"}, "path": ".test-infra/jenkins/job_PerformanceTests_PubsubIO_Python.groovy", "diffHunk": "@@ -0,0 +1,92 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+def now = new Date().format(\"MMddHHmmss\", TimeZone.getTimeZone('UTC'))\n+\n+def psio_read_test = [\n+        title          : 'PubsubIO Read Performance Test Python 100000 messages',\n+        test           : 'apache_beam.io.gcp.pubsub_read_perf_test',\n+        runner         : CommonTestProperties.Runner.DATAFLOW,\n+        pipelineOptions: [\n+                job_name             : 'performance-tests-psio-read-python-100000-msgs' + now,\n+                project              : 'apache-beam-testing',\n+                temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n+                publish_to_big_query : true,\n+                metrics_dataset      : 'beam_performance',\n+                metrics_table        : 'psio_read_100000msg_results',\n+                // Pubsub PublishRequest can have max 10'000'000 bytes\n+                input_options        : '\\'{\"num_records\": 100000}\\'',\n+                num_workers          : 5,\n+                autoscaling_algorithm: 'NONE',  // Disable autoscale the worker pool.\n+                timeout              : 3600,\n+        ]\n+]\n+\n+def psio_write_test = [\n+        title          : 'PubsubIO Write Performance Test Python 100000 messages',\n+        test           : 'apache_beam.io.gcp.pubsub_write_perf_test',\n+        runner         : CommonTestProperties.Runner.DATAFLOW,\n+        pipelineOptions: [\n+                job_name             : 'performance-tests-psio-write-python-100000-msgs' + now,\n+                project              : 'apache-beam-testing',\n+                temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n+                publish_to_big_query : true,\n+                metrics_dataset      : 'beam_performance',\n+                metrics_table        : 'psio_write_100000msg_results',\n+                // Pubsub PublishRequest can have max 10'000'000 bytes\n+                input_options        : '\\'{' +\n+                        '\"num_records\": 100000,' +\n+                        '\"key_size\": 1,' +\n+                        '\"value_size\": 16}\\'',\n+                num_workers          : 5,\n+                autoscaling_algorithm: 'NONE',  // Disable autoscale the worker pool.\n+                timeout              : 3600,\n+        ]\n+]\n+\n+def executeJob = { scope, testConfig ->\n+    commonJobProperties.setTopLevelMainJobProperties(scope, 'master', 240)\n+\n+    loadTestsBuilder.loadTest(scope, testConfig.title, testConfig.runner, CommonTestProperties.SDK.PYTHON, testConfig.pipelineOptions, testConfig.test)\n+}\n+\n+PhraseTriggeringPostCommitBuilder.postCommitJob(\n+        'beam_PubsubIO_Read_Performance_Test_Python',\n+        'Run PubsubIO Read Performance Test Python',\n+        'PubsubIO Read Performance Test Python',\n+        this\n+) {\n+    executeJob(delegate, psio_read_test)\n+}\n+\n+CronJobBuilder.cronJob('beam_PubsubIO_Read_Performance_Test_Python', 'H 15 * * *', this) {\n+    executeJob(delegate, psio_read_test)\n+}\n+\n+PhraseTriggeringPostCommitBuilder.postCommitJob(\n+        'beam_PubsubIO_Write_Performance_Test_Python',\n+        'Run PubsubIO Write Performance Test Python',\n+        'BigQueryIO Write Performance Test Python',", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db2ed59ed67eccc35569a2cd3e4e73ae411bb1c5"}, "originalPosition": 84}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU1OTgxMjY2OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/pubsub_read_perf_test.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQwODo0MDoxNVrOGI54Cw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQxMDowMzo1MVrOGI9jJg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTk5MDAyNw==", "bodyText": "You cannot import multiple objects from a module in a single line. Out pylint will complain. Split this into multiple lines or use something like this in your code: beam.io.ReadFromPubSub", "url": "https://github.com/apache/beam/pull/11274#discussion_r411990027", "createdAt": "2020-04-21T08:40:15Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_read_perf_test.py", "diffHunk": "@@ -0,0 +1,153 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Read operation.\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_read_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner\n+    --sdk_location=.../dist/apache-beam-x.x.x.dev0.tar.gz\n+    --project=<GCP_PROJECT_ID>\n+    --temp_location=gs://<BUCKET_NAME>/tmp\n+    --staging_location=gs://<BUCKET_NAME>/staging\n+    --timeout=<TIME_IN_SECONDS>\n+    --publish_to_big_query=<OPTIONAL><true/false>\n+    --metrics_dataset=<OPTIONAL>\n+    --metrics_table=<OPTIONAL>\n+    --dataflow_worker_jar=<OPTIONAL>\n+    --input_options='{\n+    \\\"num_records\\\": <SIZE_OF_INPUT>\n+    }'\"\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import sys\n+import uuid\n+\n+from hamcrest import all_of\n+\n+import apache_beam as beam\n+from apache_beam.io import ReadFromPubSub, WriteToPubSub, PubsubMessage", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db2ed59ed67eccc35569a2cd3e4e73ae411bb1c5"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjA1MDIxNA==", "bodyText": "Done", "url": "https://github.com/apache/beam/pull/11274#discussion_r412050214", "createdAt": "2020-04-21T10:03:51Z", "author": {"login": "piotr-szuberski"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_read_perf_test.py", "diffHunk": "@@ -0,0 +1,153 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Read operation.\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_read_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner\n+    --sdk_location=.../dist/apache-beam-x.x.x.dev0.tar.gz\n+    --project=<GCP_PROJECT_ID>\n+    --temp_location=gs://<BUCKET_NAME>/tmp\n+    --staging_location=gs://<BUCKET_NAME>/staging\n+    --timeout=<TIME_IN_SECONDS>\n+    --publish_to_big_query=<OPTIONAL><true/false>\n+    --metrics_dataset=<OPTIONAL>\n+    --metrics_table=<OPTIONAL>\n+    --dataflow_worker_jar=<OPTIONAL>\n+    --input_options='{\n+    \\\"num_records\\\": <SIZE_OF_INPUT>\n+    }'\"\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import sys\n+import uuid\n+\n+from hamcrest import all_of\n+\n+import apache_beam as beam\n+from apache_beam.io import ReadFromPubSub, WriteToPubSub, PubsubMessage", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTk5MDAyNw=="}, "originalCommit": {"oid": "db2ed59ed67eccc35569a2cd3e4e73ae411bb1c5"}, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU1OTgzOTQyOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/pubsub_read_perf_test.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQwODo0NTozNVrOGI6IBA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQxMDowNDo0MFrOGI9lDQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTk5NDExNg==", "bodyText": "Unless you need to, let's move this line to the beginning of the file.", "url": "https://github.com/apache/beam/pull/11274#discussion_r411994116", "createdAt": "2020-04-21T08:45:35Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_read_perf_test.py", "diffHunk": "@@ -0,0 +1,153 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Read operation.\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_read_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner\n+    --sdk_location=.../dist/apache-beam-x.x.x.dev0.tar.gz\n+    --project=<GCP_PROJECT_ID>\n+    --temp_location=gs://<BUCKET_NAME>/tmp\n+    --staging_location=gs://<BUCKET_NAME>/staging\n+    --timeout=<TIME_IN_SECONDS>\n+    --publish_to_big_query=<OPTIONAL><true/false>\n+    --metrics_dataset=<OPTIONAL>\n+    --metrics_table=<OPTIONAL>\n+    --dataflow_worker_jar=<OPTIONAL>\n+    --input_options='{\n+    \\\"num_records\\\": <SIZE_OF_INPUT>\n+    }'\"\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import sys\n+import uuid\n+\n+from hamcrest import all_of\n+\n+import apache_beam as beam\n+from apache_beam.io import ReadFromPubSub, WriteToPubSub, PubsubMessage\n+from apache_beam.io.gcp.tests.pubsub_matcher import PubSubMessageMatcher\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.testing import test_utils\n+from apache_beam.testing.load_tests.load_test import LoadTest\n+from apache_beam.testing.load_tests.load_test_metrics_utils import MeasureTime\n+from apache_beam.testing.test_pipeline import TestPipeline\n+\n+PUBSUB_NAME = 'pubsub_read_performance'\n+\n+\n+class PubsubReadPerfTest(LoadTest):\n+\n+  def __init__(self):\n+    super(PubsubReadPerfTest, self).__init__()\n+    self._setup_env()\n+    self._setup_pubsub()\n+    self._setup_pipeline()\n+\n+  def test(self):\n+    (\n+        self.pipeline\n+        | 'Read from pubsub' >> ReadFromPubSub(\n+            subscription=self.subscription.name,\n+            with_attributes=True,\n+            id_label='ack_id')\n+        | 'Measure time' >> beam.ParDo(MeasureTime(self.metrics_namespace))\n+    )\n+\n+  def cleanup(self):\n+    test_utils.cleanup_subscriptions(\n+      self.sub_client, [self.subscription, self.matcher_subscription])\n+    test_utils.cleanup_topics(\n+      self.pub_client, [self.topic])\n+\n+  def _setup_env(self):\n+    if not self.pipeline.get_option('timeout'):\n+      logging.error('--timeout argument is required.')\n+      sys.exit(1)\n+\n+    self.num_of_messages = int(self.input_options.get('num_records'))\n+    self.timeout = int(self.pipeline.get_option('timeout'))\n+\n+  def _setup_pubsub(self):\n+    def init_input(number_of_messages):\n+      for n in range(number_of_messages):\n+        message = PubsubMessage(\n+          bytes(str(n), 'utf-8'),\n+          {'ack_id': bytes(str(n), 'utf-8')})\n+        bytes_message = WriteToPubSub.to_proto_str(message)\n+        self.pub_client.publish(self.topic.name, bytes_message)\n+\n+    from google.cloud import pubsub", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db2ed59ed67eccc35569a2cd3e4e73ae411bb1c5"}, "originalPosition": 104}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjA1MDcwMQ==", "bodyText": "It was done like that in the other pubsub examples. But I think it's a better idea to do as you suggest.", "url": "https://github.com/apache/beam/pull/11274#discussion_r412050701", "createdAt": "2020-04-21T10:04:40Z", "author": {"login": "piotr-szuberski"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_read_perf_test.py", "diffHunk": "@@ -0,0 +1,153 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Read operation.\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_read_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner\n+    --sdk_location=.../dist/apache-beam-x.x.x.dev0.tar.gz\n+    --project=<GCP_PROJECT_ID>\n+    --temp_location=gs://<BUCKET_NAME>/tmp\n+    --staging_location=gs://<BUCKET_NAME>/staging\n+    --timeout=<TIME_IN_SECONDS>\n+    --publish_to_big_query=<OPTIONAL><true/false>\n+    --metrics_dataset=<OPTIONAL>\n+    --metrics_table=<OPTIONAL>\n+    --dataflow_worker_jar=<OPTIONAL>\n+    --input_options='{\n+    \\\"num_records\\\": <SIZE_OF_INPUT>\n+    }'\"\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import sys\n+import uuid\n+\n+from hamcrest import all_of\n+\n+import apache_beam as beam\n+from apache_beam.io import ReadFromPubSub, WriteToPubSub, PubsubMessage\n+from apache_beam.io.gcp.tests.pubsub_matcher import PubSubMessageMatcher\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.testing import test_utils\n+from apache_beam.testing.load_tests.load_test import LoadTest\n+from apache_beam.testing.load_tests.load_test_metrics_utils import MeasureTime\n+from apache_beam.testing.test_pipeline import TestPipeline\n+\n+PUBSUB_NAME = 'pubsub_read_performance'\n+\n+\n+class PubsubReadPerfTest(LoadTest):\n+\n+  def __init__(self):\n+    super(PubsubReadPerfTest, self).__init__()\n+    self._setup_env()\n+    self._setup_pubsub()\n+    self._setup_pipeline()\n+\n+  def test(self):\n+    (\n+        self.pipeline\n+        | 'Read from pubsub' >> ReadFromPubSub(\n+            subscription=self.subscription.name,\n+            with_attributes=True,\n+            id_label='ack_id')\n+        | 'Measure time' >> beam.ParDo(MeasureTime(self.metrics_namespace))\n+    )\n+\n+  def cleanup(self):\n+    test_utils.cleanup_subscriptions(\n+      self.sub_client, [self.subscription, self.matcher_subscription])\n+    test_utils.cleanup_topics(\n+      self.pub_client, [self.topic])\n+\n+  def _setup_env(self):\n+    if not self.pipeline.get_option('timeout'):\n+      logging.error('--timeout argument is required.')\n+      sys.exit(1)\n+\n+    self.num_of_messages = int(self.input_options.get('num_records'))\n+    self.timeout = int(self.pipeline.get_option('timeout'))\n+\n+  def _setup_pubsub(self):\n+    def init_input(number_of_messages):\n+      for n in range(number_of_messages):\n+        message = PubsubMessage(\n+          bytes(str(n), 'utf-8'),\n+          {'ack_id': bytes(str(n), 'utf-8')})\n+        bytes_message = WriteToPubSub.to_proto_str(message)\n+        self.pub_client.publish(self.topic.name, bytes_message)\n+\n+    from google.cloud import pubsub", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTk5NDExNg=="}, "originalCommit": {"oid": "db2ed59ed67eccc35569a2cd3e4e73ae411bb1c5"}, "originalPosition": 104}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU1OTg4MzQ3OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/pubsub_read_perf_test.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQwODo1NDowMFrOGI6hsA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQxMTozODowNlrOGJBFZg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjAwMDY4OA==", "bodyText": "This will fail in Python 2.7, because bytes is an alias to str, and str() takes at most 1 argument.\nIf you need to convert string to bytes, use encode method which works both in Python 2.7 and 3.x", "url": "https://github.com/apache/beam/pull/11274#discussion_r412000688", "createdAt": "2020-04-21T08:54:00Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_read_perf_test.py", "diffHunk": "@@ -0,0 +1,153 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Read operation.\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_read_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner\n+    --sdk_location=.../dist/apache-beam-x.x.x.dev0.tar.gz\n+    --project=<GCP_PROJECT_ID>\n+    --temp_location=gs://<BUCKET_NAME>/tmp\n+    --staging_location=gs://<BUCKET_NAME>/staging\n+    --timeout=<TIME_IN_SECONDS>\n+    --publish_to_big_query=<OPTIONAL><true/false>\n+    --metrics_dataset=<OPTIONAL>\n+    --metrics_table=<OPTIONAL>\n+    --dataflow_worker_jar=<OPTIONAL>\n+    --input_options='{\n+    \\\"num_records\\\": <SIZE_OF_INPUT>\n+    }'\"\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import sys\n+import uuid\n+\n+from hamcrest import all_of\n+\n+import apache_beam as beam\n+from apache_beam.io import ReadFromPubSub, WriteToPubSub, PubsubMessage\n+from apache_beam.io.gcp.tests.pubsub_matcher import PubSubMessageMatcher\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.testing import test_utils\n+from apache_beam.testing.load_tests.load_test import LoadTest\n+from apache_beam.testing.load_tests.load_test_metrics_utils import MeasureTime\n+from apache_beam.testing.test_pipeline import TestPipeline\n+\n+PUBSUB_NAME = 'pubsub_read_performance'\n+\n+\n+class PubsubReadPerfTest(LoadTest):\n+\n+  def __init__(self):\n+    super(PubsubReadPerfTest, self).__init__()\n+    self._setup_env()\n+    self._setup_pubsub()\n+    self._setup_pipeline()\n+\n+  def test(self):\n+    (\n+        self.pipeline\n+        | 'Read from pubsub' >> ReadFromPubSub(\n+            subscription=self.subscription.name,\n+            with_attributes=True,\n+            id_label='ack_id')\n+        | 'Measure time' >> beam.ParDo(MeasureTime(self.metrics_namespace))\n+    )\n+\n+  def cleanup(self):\n+    test_utils.cleanup_subscriptions(\n+      self.sub_client, [self.subscription, self.matcher_subscription])\n+    test_utils.cleanup_topics(\n+      self.pub_client, [self.topic])\n+\n+  def _setup_env(self):\n+    if not self.pipeline.get_option('timeout'):\n+      logging.error('--timeout argument is required.')\n+      sys.exit(1)\n+\n+    self.num_of_messages = int(self.input_options.get('num_records'))\n+    self.timeout = int(self.pipeline.get_option('timeout'))\n+\n+  def _setup_pubsub(self):\n+    def init_input(number_of_messages):\n+      for n in range(number_of_messages):\n+        message = PubsubMessage(\n+          bytes(str(n), 'utf-8'),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db2ed59ed67eccc35569a2cd3e4e73ae411bb1c5"}, "originalPosition": 99}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjEwODEzNA==", "bodyText": "Done", "url": "https://github.com/apache/beam/pull/11274#discussion_r412108134", "createdAt": "2020-04-21T11:38:06Z", "author": {"login": "piotr-szuberski"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_read_perf_test.py", "diffHunk": "@@ -0,0 +1,153 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Read operation.\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_read_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner\n+    --sdk_location=.../dist/apache-beam-x.x.x.dev0.tar.gz\n+    --project=<GCP_PROJECT_ID>\n+    --temp_location=gs://<BUCKET_NAME>/tmp\n+    --staging_location=gs://<BUCKET_NAME>/staging\n+    --timeout=<TIME_IN_SECONDS>\n+    --publish_to_big_query=<OPTIONAL><true/false>\n+    --metrics_dataset=<OPTIONAL>\n+    --metrics_table=<OPTIONAL>\n+    --dataflow_worker_jar=<OPTIONAL>\n+    --input_options='{\n+    \\\"num_records\\\": <SIZE_OF_INPUT>\n+    }'\"\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import sys\n+import uuid\n+\n+from hamcrest import all_of\n+\n+import apache_beam as beam\n+from apache_beam.io import ReadFromPubSub, WriteToPubSub, PubsubMessage\n+from apache_beam.io.gcp.tests.pubsub_matcher import PubSubMessageMatcher\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.testing import test_utils\n+from apache_beam.testing.load_tests.load_test import LoadTest\n+from apache_beam.testing.load_tests.load_test_metrics_utils import MeasureTime\n+from apache_beam.testing.test_pipeline import TestPipeline\n+\n+PUBSUB_NAME = 'pubsub_read_performance'\n+\n+\n+class PubsubReadPerfTest(LoadTest):\n+\n+  def __init__(self):\n+    super(PubsubReadPerfTest, self).__init__()\n+    self._setup_env()\n+    self._setup_pubsub()\n+    self._setup_pipeline()\n+\n+  def test(self):\n+    (\n+        self.pipeline\n+        | 'Read from pubsub' >> ReadFromPubSub(\n+            subscription=self.subscription.name,\n+            with_attributes=True,\n+            id_label='ack_id')\n+        | 'Measure time' >> beam.ParDo(MeasureTime(self.metrics_namespace))\n+    )\n+\n+  def cleanup(self):\n+    test_utils.cleanup_subscriptions(\n+      self.sub_client, [self.subscription, self.matcher_subscription])\n+    test_utils.cleanup_topics(\n+      self.pub_client, [self.topic])\n+\n+  def _setup_env(self):\n+    if not self.pipeline.get_option('timeout'):\n+      logging.error('--timeout argument is required.')\n+      sys.exit(1)\n+\n+    self.num_of_messages = int(self.input_options.get('num_records'))\n+    self.timeout = int(self.pipeline.get_option('timeout'))\n+\n+  def _setup_pubsub(self):\n+    def init_input(number_of_messages):\n+      for n in range(number_of_messages):\n+        message = PubsubMessage(\n+          bytes(str(n), 'utf-8'),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjAwMDY4OA=="}, "originalCommit": {"oid": "db2ed59ed67eccc35569a2cd3e4e73ae411bb1c5"}, "originalPosition": 99}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU1OTk5ODUzOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/pubsub_read_perf_test.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQwOToxODozMVrOGI7nHw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQxMDo1NToxMFrOGI_ggA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjAxODQ2Mw==", "bodyText": "You don't have to create PipelineOptions and ArgumentParser objects. This should be enough:\nargs = self.pipeline.get_full_options_as_args(**extra_opts)\nself.pipeline = TestPipeline(argv=args)", "url": "https://github.com/apache/beam/pull/11274#discussion_r412018463", "createdAt": "2020-04-21T09:18:31Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_read_perf_test.py", "diffHunk": "@@ -0,0 +1,153 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Read operation.\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_read_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner\n+    --sdk_location=.../dist/apache-beam-x.x.x.dev0.tar.gz\n+    --project=<GCP_PROJECT_ID>\n+    --temp_location=gs://<BUCKET_NAME>/tmp\n+    --staging_location=gs://<BUCKET_NAME>/staging\n+    --timeout=<TIME_IN_SECONDS>\n+    --publish_to_big_query=<OPTIONAL><true/false>\n+    --metrics_dataset=<OPTIONAL>\n+    --metrics_table=<OPTIONAL>\n+    --dataflow_worker_jar=<OPTIONAL>\n+    --input_options='{\n+    \\\"num_records\\\": <SIZE_OF_INPUT>\n+    }'\"\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import sys\n+import uuid\n+\n+from hamcrest import all_of\n+\n+import apache_beam as beam\n+from apache_beam.io import ReadFromPubSub, WriteToPubSub, PubsubMessage\n+from apache_beam.io.gcp.tests.pubsub_matcher import PubSubMessageMatcher\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.testing import test_utils\n+from apache_beam.testing.load_tests.load_test import LoadTest\n+from apache_beam.testing.load_tests.load_test_metrics_utils import MeasureTime\n+from apache_beam.testing.test_pipeline import TestPipeline\n+\n+PUBSUB_NAME = 'pubsub_read_performance'\n+\n+\n+class PubsubReadPerfTest(LoadTest):\n+\n+  def __init__(self):\n+    super(PubsubReadPerfTest, self).__init__()\n+    self._setup_env()\n+    self._setup_pubsub()\n+    self._setup_pipeline()\n+\n+  def test(self):\n+    (\n+        self.pipeline\n+        | 'Read from pubsub' >> ReadFromPubSub(\n+            subscription=self.subscription.name,\n+            with_attributes=True,\n+            id_label='ack_id')\n+        | 'Measure time' >> beam.ParDo(MeasureTime(self.metrics_namespace))\n+    )\n+\n+  def cleanup(self):\n+    test_utils.cleanup_subscriptions(\n+      self.sub_client, [self.subscription, self.matcher_subscription])\n+    test_utils.cleanup_topics(\n+      self.pub_client, [self.topic])\n+\n+  def _setup_env(self):\n+    if not self.pipeline.get_option('timeout'):\n+      logging.error('--timeout argument is required.')\n+      sys.exit(1)\n+\n+    self.num_of_messages = int(self.input_options.get('num_records'))\n+    self.timeout = int(self.pipeline.get_option('timeout'))\n+\n+  def _setup_pubsub(self):\n+    def init_input(number_of_messages):\n+      for n in range(number_of_messages):\n+        message = PubsubMessage(\n+          bytes(str(n), 'utf-8'),\n+          {'ack_id': bytes(str(n), 'utf-8')})\n+        bytes_message = WriteToPubSub.to_proto_str(message)\n+        self.pub_client.publish(self.topic.name, bytes_message)\n+\n+    from google.cloud import pubsub\n+\n+    self.uuid = str(uuid.uuid4())\n+\n+    self.pub_client = pubsub.PublisherClient()\n+    self.topic = self.pub_client.create_topic(\n+      self.pub_client.topic_path(self.project_id, PUBSUB_NAME + self.uuid)\n+    )\n+\n+    self.sub_client = pubsub.SubscriberClient()\n+    self.subscription = self.sub_client.create_subscription(\n+      self.sub_client.subscription_path(self.project_id, PUBSUB_NAME + self.uuid),\n+      self.topic.name\n+    )\n+    self.matcher_subscription = self.sub_client.create_subscription(\n+      self.sub_client.subscription_path(self.project_id, PUBSUB_NAME + '_matcher_' + self.uuid),\n+      self.topic.name\n+    )\n+\n+    init_input(self.num_of_messages)\n+\n+\n+  def _setup_pipeline(self):\n+    pubsub_msg_verifier = PubSubMessageMatcher(\n+        self.project_id,\n+        self.matcher_subscription.name,\n+        expected_msg_len=self.num_of_messages,\n+        timeout=self.timeout\n+    )\n+\n+    self.extra_opts = {\n+        'on_success_matcher': all_of(pubsub_msg_verifier),\n+        'wait_until_finish_duration': self.timeout * 1000,\n+        'streaming': True,\n+        'save_main_session': True\n+    }\n+\n+    args = self.pipeline.get_full_options_as_args(**self.extra_opts)\n+\n+    parser = argparse.ArgumentParser()\n+    _, pipeline_args = parser.parse_known_args(args)\n+\n+    pipeline_options = PipelineOptions(pipeline_args)\n+\n+    self.pipeline = TestPipeline(options=pipeline_options)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db2ed59ed67eccc35569a2cd3e4e73ae411bb1c5"}, "originalPosition": 148}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjA4MjMwNA==", "bodyText": "For some reason passing args does not set streaming option. On the other hand it works correctly with creating options like this. But I definitely can get rid of the parser.", "url": "https://github.com/apache/beam/pull/11274#discussion_r412082304", "createdAt": "2020-04-21T10:55:10Z", "author": {"login": "piotr-szuberski"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_read_perf_test.py", "diffHunk": "@@ -0,0 +1,153 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Read operation.\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_read_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner\n+    --sdk_location=.../dist/apache-beam-x.x.x.dev0.tar.gz\n+    --project=<GCP_PROJECT_ID>\n+    --temp_location=gs://<BUCKET_NAME>/tmp\n+    --staging_location=gs://<BUCKET_NAME>/staging\n+    --timeout=<TIME_IN_SECONDS>\n+    --publish_to_big_query=<OPTIONAL><true/false>\n+    --metrics_dataset=<OPTIONAL>\n+    --metrics_table=<OPTIONAL>\n+    --dataflow_worker_jar=<OPTIONAL>\n+    --input_options='{\n+    \\\"num_records\\\": <SIZE_OF_INPUT>\n+    }'\"\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import sys\n+import uuid\n+\n+from hamcrest import all_of\n+\n+import apache_beam as beam\n+from apache_beam.io import ReadFromPubSub, WriteToPubSub, PubsubMessage\n+from apache_beam.io.gcp.tests.pubsub_matcher import PubSubMessageMatcher\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.testing import test_utils\n+from apache_beam.testing.load_tests.load_test import LoadTest\n+from apache_beam.testing.load_tests.load_test_metrics_utils import MeasureTime\n+from apache_beam.testing.test_pipeline import TestPipeline\n+\n+PUBSUB_NAME = 'pubsub_read_performance'\n+\n+\n+class PubsubReadPerfTest(LoadTest):\n+\n+  def __init__(self):\n+    super(PubsubReadPerfTest, self).__init__()\n+    self._setup_env()\n+    self._setup_pubsub()\n+    self._setup_pipeline()\n+\n+  def test(self):\n+    (\n+        self.pipeline\n+        | 'Read from pubsub' >> ReadFromPubSub(\n+            subscription=self.subscription.name,\n+            with_attributes=True,\n+            id_label='ack_id')\n+        | 'Measure time' >> beam.ParDo(MeasureTime(self.metrics_namespace))\n+    )\n+\n+  def cleanup(self):\n+    test_utils.cleanup_subscriptions(\n+      self.sub_client, [self.subscription, self.matcher_subscription])\n+    test_utils.cleanup_topics(\n+      self.pub_client, [self.topic])\n+\n+  def _setup_env(self):\n+    if not self.pipeline.get_option('timeout'):\n+      logging.error('--timeout argument is required.')\n+      sys.exit(1)\n+\n+    self.num_of_messages = int(self.input_options.get('num_records'))\n+    self.timeout = int(self.pipeline.get_option('timeout'))\n+\n+  def _setup_pubsub(self):\n+    def init_input(number_of_messages):\n+      for n in range(number_of_messages):\n+        message = PubsubMessage(\n+          bytes(str(n), 'utf-8'),\n+          {'ack_id': bytes(str(n), 'utf-8')})\n+        bytes_message = WriteToPubSub.to_proto_str(message)\n+        self.pub_client.publish(self.topic.name, bytes_message)\n+\n+    from google.cloud import pubsub\n+\n+    self.uuid = str(uuid.uuid4())\n+\n+    self.pub_client = pubsub.PublisherClient()\n+    self.topic = self.pub_client.create_topic(\n+      self.pub_client.topic_path(self.project_id, PUBSUB_NAME + self.uuid)\n+    )\n+\n+    self.sub_client = pubsub.SubscriberClient()\n+    self.subscription = self.sub_client.create_subscription(\n+      self.sub_client.subscription_path(self.project_id, PUBSUB_NAME + self.uuid),\n+      self.topic.name\n+    )\n+    self.matcher_subscription = self.sub_client.create_subscription(\n+      self.sub_client.subscription_path(self.project_id, PUBSUB_NAME + '_matcher_' + self.uuid),\n+      self.topic.name\n+    )\n+\n+    init_input(self.num_of_messages)\n+\n+\n+  def _setup_pipeline(self):\n+    pubsub_msg_verifier = PubSubMessageMatcher(\n+        self.project_id,\n+        self.matcher_subscription.name,\n+        expected_msg_len=self.num_of_messages,\n+        timeout=self.timeout\n+    )\n+\n+    self.extra_opts = {\n+        'on_success_matcher': all_of(pubsub_msg_verifier),\n+        'wait_until_finish_duration': self.timeout * 1000,\n+        'streaming': True,\n+        'save_main_session': True\n+    }\n+\n+    args = self.pipeline.get_full_options_as_args(**self.extra_opts)\n+\n+    parser = argparse.ArgumentParser()\n+    _, pipeline_args = parser.parse_known_args(args)\n+\n+    pipeline_options = PipelineOptions(pipeline_args)\n+\n+    self.pipeline = TestPipeline(options=pipeline_options)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjAxODQ2Mw=="}, "originalCommit": {"oid": "db2ed59ed67eccc35569a2cd3e4e73ae411bb1c5"}, "originalPosition": 148}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU2MDAxMDA4OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/pubsub_read_perf_test.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQwOToyMToxMFrOGI7uNw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQwOToyMToxMFrOGI7uNw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjAyMDI3OQ==", "bodyText": "I think since we don't use self.extra_opts anywhere else, the assignment to self is redundant.", "url": "https://github.com/apache/beam/pull/11274#discussion_r412020279", "createdAt": "2020-04-21T09:21:10Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_read_perf_test.py", "diffHunk": "@@ -0,0 +1,153 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Read operation.\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_read_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner\n+    --sdk_location=.../dist/apache-beam-x.x.x.dev0.tar.gz\n+    --project=<GCP_PROJECT_ID>\n+    --temp_location=gs://<BUCKET_NAME>/tmp\n+    --staging_location=gs://<BUCKET_NAME>/staging\n+    --timeout=<TIME_IN_SECONDS>\n+    --publish_to_big_query=<OPTIONAL><true/false>\n+    --metrics_dataset=<OPTIONAL>\n+    --metrics_table=<OPTIONAL>\n+    --dataflow_worker_jar=<OPTIONAL>\n+    --input_options='{\n+    \\\"num_records\\\": <SIZE_OF_INPUT>\n+    }'\"\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import sys\n+import uuid\n+\n+from hamcrest import all_of\n+\n+import apache_beam as beam\n+from apache_beam.io import ReadFromPubSub, WriteToPubSub, PubsubMessage\n+from apache_beam.io.gcp.tests.pubsub_matcher import PubSubMessageMatcher\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.testing import test_utils\n+from apache_beam.testing.load_tests.load_test import LoadTest\n+from apache_beam.testing.load_tests.load_test_metrics_utils import MeasureTime\n+from apache_beam.testing.test_pipeline import TestPipeline\n+\n+PUBSUB_NAME = 'pubsub_read_performance'\n+\n+\n+class PubsubReadPerfTest(LoadTest):\n+\n+  def __init__(self):\n+    super(PubsubReadPerfTest, self).__init__()\n+    self._setup_env()\n+    self._setup_pubsub()\n+    self._setup_pipeline()\n+\n+  def test(self):\n+    (\n+        self.pipeline\n+        | 'Read from pubsub' >> ReadFromPubSub(\n+            subscription=self.subscription.name,\n+            with_attributes=True,\n+            id_label='ack_id')\n+        | 'Measure time' >> beam.ParDo(MeasureTime(self.metrics_namespace))\n+    )\n+\n+  def cleanup(self):\n+    test_utils.cleanup_subscriptions(\n+      self.sub_client, [self.subscription, self.matcher_subscription])\n+    test_utils.cleanup_topics(\n+      self.pub_client, [self.topic])\n+\n+  def _setup_env(self):\n+    if not self.pipeline.get_option('timeout'):\n+      logging.error('--timeout argument is required.')\n+      sys.exit(1)\n+\n+    self.num_of_messages = int(self.input_options.get('num_records'))\n+    self.timeout = int(self.pipeline.get_option('timeout'))\n+\n+  def _setup_pubsub(self):\n+    def init_input(number_of_messages):\n+      for n in range(number_of_messages):\n+        message = PubsubMessage(\n+          bytes(str(n), 'utf-8'),\n+          {'ack_id': bytes(str(n), 'utf-8')})\n+        bytes_message = WriteToPubSub.to_proto_str(message)\n+        self.pub_client.publish(self.topic.name, bytes_message)\n+\n+    from google.cloud import pubsub\n+\n+    self.uuid = str(uuid.uuid4())\n+\n+    self.pub_client = pubsub.PublisherClient()\n+    self.topic = self.pub_client.create_topic(\n+      self.pub_client.topic_path(self.project_id, PUBSUB_NAME + self.uuid)\n+    )\n+\n+    self.sub_client = pubsub.SubscriberClient()\n+    self.subscription = self.sub_client.create_subscription(\n+      self.sub_client.subscription_path(self.project_id, PUBSUB_NAME + self.uuid),\n+      self.topic.name\n+    )\n+    self.matcher_subscription = self.sub_client.create_subscription(\n+      self.sub_client.subscription_path(self.project_id, PUBSUB_NAME + '_matcher_' + self.uuid),\n+      self.topic.name\n+    )\n+\n+    init_input(self.num_of_messages)\n+\n+\n+  def _setup_pipeline(self):\n+    pubsub_msg_verifier = PubSubMessageMatcher(\n+        self.project_id,\n+        self.matcher_subscription.name,\n+        expected_msg_len=self.num_of_messages,\n+        timeout=self.timeout\n+    )\n+\n+    self.extra_opts = {\n+        'on_success_matcher': all_of(pubsub_msg_verifier),\n+        'wait_until_finish_duration': self.timeout * 1000,\n+        'streaming': True,\n+        'save_main_session': True\n+    }\n+\n+    args = self.pipeline.get_full_options_as_args(**self.extra_opts)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db2ed59ed67eccc35569a2cd3e4e73ae411bb1c5"}, "originalPosition": 141}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU2MDAzNDExOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/pubsub_read_perf_test.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQwOToyNjoxNFrOGI79KQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQxMTozNzozOVrOGJBEZQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjAyNDEwNQ==", "bodyText": "I would put emphasis on that the runner must be TestDataflowRunner, not DataflowRunner. This is very important information for anyone who would run this code.", "url": "https://github.com/apache/beam/pull/11274#discussion_r412024105", "createdAt": "2020-04-21T09:26:14Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_read_perf_test.py", "diffHunk": "@@ -0,0 +1,153 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Read operation.\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_read_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db2ed59ed67eccc35569a2cd3e4e73ae411bb1c5"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjEwNzg3Nw==", "bodyText": "Done", "url": "https://github.com/apache/beam/pull/11274#discussion_r412107877", "createdAt": "2020-04-21T11:37:39Z", "author": {"login": "piotr-szuberski"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_read_perf_test.py", "diffHunk": "@@ -0,0 +1,153 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Read operation.\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_read_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjAyNDEwNQ=="}, "originalCommit": {"oid": "db2ed59ed67eccc35569a2cd3e4e73ae411bb1c5"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU2MDA0NjU4OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/pubsub_read_perf_test.py", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQwOToyODo0OVrOGI8EuA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQxNDoyODoxMFrOGJIyiA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjAyNjA0MA==", "bodyText": "If you don't use a closure, I think you can make this function a top-level one. It would be easier to understand the program flow.", "url": "https://github.com/apache/beam/pull/11274#discussion_r412026040", "createdAt": "2020-04-21T09:28:49Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_read_perf_test.py", "diffHunk": "@@ -0,0 +1,153 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Read operation.\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_read_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner\n+    --sdk_location=.../dist/apache-beam-x.x.x.dev0.tar.gz\n+    --project=<GCP_PROJECT_ID>\n+    --temp_location=gs://<BUCKET_NAME>/tmp\n+    --staging_location=gs://<BUCKET_NAME>/staging\n+    --timeout=<TIME_IN_SECONDS>\n+    --publish_to_big_query=<OPTIONAL><true/false>\n+    --metrics_dataset=<OPTIONAL>\n+    --metrics_table=<OPTIONAL>\n+    --dataflow_worker_jar=<OPTIONAL>\n+    --input_options='{\n+    \\\"num_records\\\": <SIZE_OF_INPUT>\n+    }'\"\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import sys\n+import uuid\n+\n+from hamcrest import all_of\n+\n+import apache_beam as beam\n+from apache_beam.io import ReadFromPubSub, WriteToPubSub, PubsubMessage\n+from apache_beam.io.gcp.tests.pubsub_matcher import PubSubMessageMatcher\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.testing import test_utils\n+from apache_beam.testing.load_tests.load_test import LoadTest\n+from apache_beam.testing.load_tests.load_test_metrics_utils import MeasureTime\n+from apache_beam.testing.test_pipeline import TestPipeline\n+\n+PUBSUB_NAME = 'pubsub_read_performance'\n+\n+\n+class PubsubReadPerfTest(LoadTest):\n+\n+  def __init__(self):\n+    super(PubsubReadPerfTest, self).__init__()\n+    self._setup_env()\n+    self._setup_pubsub()\n+    self._setup_pipeline()\n+\n+  def test(self):\n+    (\n+        self.pipeline\n+        | 'Read from pubsub' >> ReadFromPubSub(\n+            subscription=self.subscription.name,\n+            with_attributes=True,\n+            id_label='ack_id')\n+        | 'Measure time' >> beam.ParDo(MeasureTime(self.metrics_namespace))\n+    )\n+\n+  def cleanup(self):\n+    test_utils.cleanup_subscriptions(\n+      self.sub_client, [self.subscription, self.matcher_subscription])\n+    test_utils.cleanup_topics(\n+      self.pub_client, [self.topic])\n+\n+  def _setup_env(self):\n+    if not self.pipeline.get_option('timeout'):\n+      logging.error('--timeout argument is required.')\n+      sys.exit(1)\n+\n+    self.num_of_messages = int(self.input_options.get('num_records'))\n+    self.timeout = int(self.pipeline.get_option('timeout'))\n+\n+  def _setup_pubsub(self):\n+    def init_input(number_of_messages):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db2ed59ed67eccc35569a2cd3e4e73ae411bb1c5"}, "originalPosition": 96}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjA5MTA1MQ==", "bodyText": "@kamilwu do you mean  init_input function? Would it be preferable to start it with underscore to indicate it shouldn't be used outside of the class?", "url": "https://github.com/apache/beam/pull/11274#discussion_r412091051", "createdAt": "2020-04-21T11:09:41Z", "author": {"login": "piotr-szuberski"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_read_perf_test.py", "diffHunk": "@@ -0,0 +1,153 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Read operation.\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_read_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner\n+    --sdk_location=.../dist/apache-beam-x.x.x.dev0.tar.gz\n+    --project=<GCP_PROJECT_ID>\n+    --temp_location=gs://<BUCKET_NAME>/tmp\n+    --staging_location=gs://<BUCKET_NAME>/staging\n+    --timeout=<TIME_IN_SECONDS>\n+    --publish_to_big_query=<OPTIONAL><true/false>\n+    --metrics_dataset=<OPTIONAL>\n+    --metrics_table=<OPTIONAL>\n+    --dataflow_worker_jar=<OPTIONAL>\n+    --input_options='{\n+    \\\"num_records\\\": <SIZE_OF_INPUT>\n+    }'\"\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import sys\n+import uuid\n+\n+from hamcrest import all_of\n+\n+import apache_beam as beam\n+from apache_beam.io import ReadFromPubSub, WriteToPubSub, PubsubMessage\n+from apache_beam.io.gcp.tests.pubsub_matcher import PubSubMessageMatcher\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.testing import test_utils\n+from apache_beam.testing.load_tests.load_test import LoadTest\n+from apache_beam.testing.load_tests.load_test_metrics_utils import MeasureTime\n+from apache_beam.testing.test_pipeline import TestPipeline\n+\n+PUBSUB_NAME = 'pubsub_read_performance'\n+\n+\n+class PubsubReadPerfTest(LoadTest):\n+\n+  def __init__(self):\n+    super(PubsubReadPerfTest, self).__init__()\n+    self._setup_env()\n+    self._setup_pubsub()\n+    self._setup_pipeline()\n+\n+  def test(self):\n+    (\n+        self.pipeline\n+        | 'Read from pubsub' >> ReadFromPubSub(\n+            subscription=self.subscription.name,\n+            with_attributes=True,\n+            id_label='ack_id')\n+        | 'Measure time' >> beam.ParDo(MeasureTime(self.metrics_namespace))\n+    )\n+\n+  def cleanup(self):\n+    test_utils.cleanup_subscriptions(\n+      self.sub_client, [self.subscription, self.matcher_subscription])\n+    test_utils.cleanup_topics(\n+      self.pub_client, [self.topic])\n+\n+  def _setup_env(self):\n+    if not self.pipeline.get_option('timeout'):\n+      logging.error('--timeout argument is required.')\n+      sys.exit(1)\n+\n+    self.num_of_messages = int(self.input_options.get('num_records'))\n+    self.timeout = int(self.pipeline.get_option('timeout'))\n+\n+  def _setup_pubsub(self):\n+    def init_input(number_of_messages):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjAyNjA0MA=="}, "originalCommit": {"oid": "db2ed59ed67eccc35569a2cd3e4e73ae411bb1c5"}, "originalPosition": 96}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjIyODE1MQ==", "bodyText": "Yes, I meant init_input function. Let's add an underscore.", "url": "https://github.com/apache/beam/pull/11274#discussion_r412228151", "createdAt": "2020-04-21T14:20:57Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_read_perf_test.py", "diffHunk": "@@ -0,0 +1,153 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Read operation.\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_read_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner\n+    --sdk_location=.../dist/apache-beam-x.x.x.dev0.tar.gz\n+    --project=<GCP_PROJECT_ID>\n+    --temp_location=gs://<BUCKET_NAME>/tmp\n+    --staging_location=gs://<BUCKET_NAME>/staging\n+    --timeout=<TIME_IN_SECONDS>\n+    --publish_to_big_query=<OPTIONAL><true/false>\n+    --metrics_dataset=<OPTIONAL>\n+    --metrics_table=<OPTIONAL>\n+    --dataflow_worker_jar=<OPTIONAL>\n+    --input_options='{\n+    \\\"num_records\\\": <SIZE_OF_INPUT>\n+    }'\"\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import sys\n+import uuid\n+\n+from hamcrest import all_of\n+\n+import apache_beam as beam\n+from apache_beam.io import ReadFromPubSub, WriteToPubSub, PubsubMessage\n+from apache_beam.io.gcp.tests.pubsub_matcher import PubSubMessageMatcher\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.testing import test_utils\n+from apache_beam.testing.load_tests.load_test import LoadTest\n+from apache_beam.testing.load_tests.load_test_metrics_utils import MeasureTime\n+from apache_beam.testing.test_pipeline import TestPipeline\n+\n+PUBSUB_NAME = 'pubsub_read_performance'\n+\n+\n+class PubsubReadPerfTest(LoadTest):\n+\n+  def __init__(self):\n+    super(PubsubReadPerfTest, self).__init__()\n+    self._setup_env()\n+    self._setup_pubsub()\n+    self._setup_pipeline()\n+\n+  def test(self):\n+    (\n+        self.pipeline\n+        | 'Read from pubsub' >> ReadFromPubSub(\n+            subscription=self.subscription.name,\n+            with_attributes=True,\n+            id_label='ack_id')\n+        | 'Measure time' >> beam.ParDo(MeasureTime(self.metrics_namespace))\n+    )\n+\n+  def cleanup(self):\n+    test_utils.cleanup_subscriptions(\n+      self.sub_client, [self.subscription, self.matcher_subscription])\n+    test_utils.cleanup_topics(\n+      self.pub_client, [self.topic])\n+\n+  def _setup_env(self):\n+    if not self.pipeline.get_option('timeout'):\n+      logging.error('--timeout argument is required.')\n+      sys.exit(1)\n+\n+    self.num_of_messages = int(self.input_options.get('num_records'))\n+    self.timeout = int(self.pipeline.get_option('timeout'))\n+\n+  def _setup_pubsub(self):\n+    def init_input(number_of_messages):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjAyNjA0MA=="}, "originalCommit": {"oid": "db2ed59ed67eccc35569a2cd3e4e73ae411bb1c5"}, "originalPosition": 96}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjIzMTExMg==", "bodyText": "What about changing the name of this function so it would be more descriptive? What do you think about _inject_input_data?", "url": "https://github.com/apache/beam/pull/11274#discussion_r412231112", "createdAt": "2020-04-21T14:24:22Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_read_perf_test.py", "diffHunk": "@@ -0,0 +1,153 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Read operation.\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_read_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner\n+    --sdk_location=.../dist/apache-beam-x.x.x.dev0.tar.gz\n+    --project=<GCP_PROJECT_ID>\n+    --temp_location=gs://<BUCKET_NAME>/tmp\n+    --staging_location=gs://<BUCKET_NAME>/staging\n+    --timeout=<TIME_IN_SECONDS>\n+    --publish_to_big_query=<OPTIONAL><true/false>\n+    --metrics_dataset=<OPTIONAL>\n+    --metrics_table=<OPTIONAL>\n+    --dataflow_worker_jar=<OPTIONAL>\n+    --input_options='{\n+    \\\"num_records\\\": <SIZE_OF_INPUT>\n+    }'\"\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import sys\n+import uuid\n+\n+from hamcrest import all_of\n+\n+import apache_beam as beam\n+from apache_beam.io import ReadFromPubSub, WriteToPubSub, PubsubMessage\n+from apache_beam.io.gcp.tests.pubsub_matcher import PubSubMessageMatcher\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.testing import test_utils\n+from apache_beam.testing.load_tests.load_test import LoadTest\n+from apache_beam.testing.load_tests.load_test_metrics_utils import MeasureTime\n+from apache_beam.testing.test_pipeline import TestPipeline\n+\n+PUBSUB_NAME = 'pubsub_read_performance'\n+\n+\n+class PubsubReadPerfTest(LoadTest):\n+\n+  def __init__(self):\n+    super(PubsubReadPerfTest, self).__init__()\n+    self._setup_env()\n+    self._setup_pubsub()\n+    self._setup_pipeline()\n+\n+  def test(self):\n+    (\n+        self.pipeline\n+        | 'Read from pubsub' >> ReadFromPubSub(\n+            subscription=self.subscription.name,\n+            with_attributes=True,\n+            id_label='ack_id')\n+        | 'Measure time' >> beam.ParDo(MeasureTime(self.metrics_namespace))\n+    )\n+\n+  def cleanup(self):\n+    test_utils.cleanup_subscriptions(\n+      self.sub_client, [self.subscription, self.matcher_subscription])\n+    test_utils.cleanup_topics(\n+      self.pub_client, [self.topic])\n+\n+  def _setup_env(self):\n+    if not self.pipeline.get_option('timeout'):\n+      logging.error('--timeout argument is required.')\n+      sys.exit(1)\n+\n+    self.num_of_messages = int(self.input_options.get('num_records'))\n+    self.timeout = int(self.pipeline.get_option('timeout'))\n+\n+  def _setup_pubsub(self):\n+    def init_input(number_of_messages):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjAyNjA0MA=="}, "originalCommit": {"oid": "db2ed59ed67eccc35569a2cd3e4e73ae411bb1c5"}, "originalPosition": 96}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjIzNDM3Ng==", "bodyText": "Good idea!", "url": "https://github.com/apache/beam/pull/11274#discussion_r412234376", "createdAt": "2020-04-21T14:28:10Z", "author": {"login": "piotr-szuberski"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_read_perf_test.py", "diffHunk": "@@ -0,0 +1,153 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Read operation.\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_read_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner\n+    --sdk_location=.../dist/apache-beam-x.x.x.dev0.tar.gz\n+    --project=<GCP_PROJECT_ID>\n+    --temp_location=gs://<BUCKET_NAME>/tmp\n+    --staging_location=gs://<BUCKET_NAME>/staging\n+    --timeout=<TIME_IN_SECONDS>\n+    --publish_to_big_query=<OPTIONAL><true/false>\n+    --metrics_dataset=<OPTIONAL>\n+    --metrics_table=<OPTIONAL>\n+    --dataflow_worker_jar=<OPTIONAL>\n+    --input_options='{\n+    \\\"num_records\\\": <SIZE_OF_INPUT>\n+    }'\"\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import sys\n+import uuid\n+\n+from hamcrest import all_of\n+\n+import apache_beam as beam\n+from apache_beam.io import ReadFromPubSub, WriteToPubSub, PubsubMessage\n+from apache_beam.io.gcp.tests.pubsub_matcher import PubSubMessageMatcher\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.testing import test_utils\n+from apache_beam.testing.load_tests.load_test import LoadTest\n+from apache_beam.testing.load_tests.load_test_metrics_utils import MeasureTime\n+from apache_beam.testing.test_pipeline import TestPipeline\n+\n+PUBSUB_NAME = 'pubsub_read_performance'\n+\n+\n+class PubsubReadPerfTest(LoadTest):\n+\n+  def __init__(self):\n+    super(PubsubReadPerfTest, self).__init__()\n+    self._setup_env()\n+    self._setup_pubsub()\n+    self._setup_pipeline()\n+\n+  def test(self):\n+    (\n+        self.pipeline\n+        | 'Read from pubsub' >> ReadFromPubSub(\n+            subscription=self.subscription.name,\n+            with_attributes=True,\n+            id_label='ack_id')\n+        | 'Measure time' >> beam.ParDo(MeasureTime(self.metrics_namespace))\n+    )\n+\n+  def cleanup(self):\n+    test_utils.cleanup_subscriptions(\n+      self.sub_client, [self.subscription, self.matcher_subscription])\n+    test_utils.cleanup_topics(\n+      self.pub_client, [self.topic])\n+\n+  def _setup_env(self):\n+    if not self.pipeline.get_option('timeout'):\n+      logging.error('--timeout argument is required.')\n+      sys.exit(1)\n+\n+    self.num_of_messages = int(self.input_options.get('num_records'))\n+    self.timeout = int(self.pipeline.get_option('timeout'))\n+\n+  def _setup_pubsub(self):\n+    def init_input(number_of_messages):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjAyNjA0MA=="}, "originalCommit": {"oid": "db2ed59ed67eccc35569a2cd3e4e73ae411bb1c5"}, "originalPosition": 96}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU2MDA2NDgwOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/pubsub_write_perf_test.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQwOTozMjo0OVrOGI8Puw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQxMTowNzo0NVrOGI_-SA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjAyODg1OQ==", "bodyText": "The same incompatibility error I mentioned earlier.", "url": "https://github.com/apache/beam/pull/11274#discussion_r412028859", "createdAt": "2020-04-21T09:32:49Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_write_perf_test.py", "diffHunk": "@@ -0,0 +1,153 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Write operation.\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_read_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner\n+    --sdk_location=.../dist/apache-beam-x.x.x.dev0.tar.gz\n+    --project=<GCP_PROJECT_ID>\n+    --temp_location=gs://<BUCKET_NAME>/tmp\n+    --staging_location=gs://<BUCKET_NAME>/staging\n+    --timeout=<TIME_IN_SECONDS>\n+    --publish_to_big_query=<OPTIONAL><true/false>\n+    --metrics_dataset=<OPTIONAL>\n+    --metrics_table=<OPTIONAL>\n+    --dataflow_worker_jar=<OPTIONAL>\n+    --input_options='{\n+    \\\"num_records\\\": <SIZE_OF_INPUT>,\n+    \\\"key_size\\\": 1,\n+    \\\"value_size\\\": <VALUE_SIZE>,\n+    }'\"\n+\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import sys\n+import uuid\n+\n+from hamcrest import all_of\n+\n+import apache_beam as beam\n+from apache_beam.io import WriteToPubSub, PubsubMessage, Read\n+from apache_beam.io.gcp.tests.pubsub_matcher import PubSubMessageMatcher\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.runners import PipelineState\n+from apache_beam.testing import test_utils\n+from apache_beam.testing.load_tests.load_test import LoadTest\n+from apache_beam.testing.load_tests.load_test_metrics_utils import MeasureTime, CountMessages\n+from apache_beam.testing.pipeline_verifiers import PipelineStateMatcher\n+from apache_beam.testing.synthetic_pipeline import SyntheticSource\n+from apache_beam.testing.test_pipeline import TestPipeline\n+\n+PUBSUB_NAME = 'pubsub_write_performance'\n+\n+\n+class PubsubWritePerfTest(LoadTest):\n+\n+  def __init__(self):\n+    super(PubsubWritePerfTest, self).__init__()\n+    self._setup_env()\n+    self._setup_pubsub()\n+    self._setup_pipeline()\n+\n+  def test(self):\n+\n+    class ToPubsubMessage(beam.DoFn):\n+      counter = 0\n+\n+      def process(self, element):\n+        self.counter += 1\n+        from apache_beam.io import WriteToPubSub, PubsubMessage\n+        message = PubsubMessage(\n+          data=element[1],\n+          attributes={'ack_id': bytes(str(self.counter), 'utf-8')})", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db2ed59ed67eccc35569a2cd3e4e73ae411bb1c5"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjA4OTkyOA==", "bodyText": "Done", "url": "https://github.com/apache/beam/pull/11274#discussion_r412089928", "createdAt": "2020-04-21T11:07:45Z", "author": {"login": "piotr-szuberski"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_write_perf_test.py", "diffHunk": "@@ -0,0 +1,153 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Write operation.\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_read_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner\n+    --sdk_location=.../dist/apache-beam-x.x.x.dev0.tar.gz\n+    --project=<GCP_PROJECT_ID>\n+    --temp_location=gs://<BUCKET_NAME>/tmp\n+    --staging_location=gs://<BUCKET_NAME>/staging\n+    --timeout=<TIME_IN_SECONDS>\n+    --publish_to_big_query=<OPTIONAL><true/false>\n+    --metrics_dataset=<OPTIONAL>\n+    --metrics_table=<OPTIONAL>\n+    --dataflow_worker_jar=<OPTIONAL>\n+    --input_options='{\n+    \\\"num_records\\\": <SIZE_OF_INPUT>,\n+    \\\"key_size\\\": 1,\n+    \\\"value_size\\\": <VALUE_SIZE>,\n+    }'\"\n+\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import sys\n+import uuid\n+\n+from hamcrest import all_of\n+\n+import apache_beam as beam\n+from apache_beam.io import WriteToPubSub, PubsubMessage, Read\n+from apache_beam.io.gcp.tests.pubsub_matcher import PubSubMessageMatcher\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.runners import PipelineState\n+from apache_beam.testing import test_utils\n+from apache_beam.testing.load_tests.load_test import LoadTest\n+from apache_beam.testing.load_tests.load_test_metrics_utils import MeasureTime, CountMessages\n+from apache_beam.testing.pipeline_verifiers import PipelineStateMatcher\n+from apache_beam.testing.synthetic_pipeline import SyntheticSource\n+from apache_beam.testing.test_pipeline import TestPipeline\n+\n+PUBSUB_NAME = 'pubsub_write_performance'\n+\n+\n+class PubsubWritePerfTest(LoadTest):\n+\n+  def __init__(self):\n+    super(PubsubWritePerfTest, self).__init__()\n+    self._setup_env()\n+    self._setup_pubsub()\n+    self._setup_pipeline()\n+\n+  def test(self):\n+\n+    class ToPubsubMessage(beam.DoFn):\n+      counter = 0\n+\n+      def process(self, element):\n+        self.counter += 1\n+        from apache_beam.io import WriteToPubSub, PubsubMessage\n+        message = PubsubMessage(\n+          data=element[1],\n+          attributes={'ack_id': bytes(str(self.counter), 'utf-8')})", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjAyODg1OQ=="}, "originalCommit": {"oid": "db2ed59ed67eccc35569a2cd3e4e73ae411bb1c5"}, "originalPosition": 87}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU2MDEyNjIyOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/pubsub_write_perf_test.py", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQwOTo0NzowMFrOGI81zQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQxNDoyNTo1OVrOGJIq6A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjAzODYwNQ==", "bodyText": "For trivial DoFn's, you can also define a simple function instead of DoFn. Then, if it's a generator function, you can use a beam.FlatMap in the pipeline. Here are some examples: https://beam.apache.org/documentation/transforms/python/elementwise/flatmap/", "url": "https://github.com/apache/beam/pull/11274#discussion_r412038605", "createdAt": "2020-04-21T09:47:00Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_write_perf_test.py", "diffHunk": "@@ -0,0 +1,155 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Write operation.\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_read_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner\n+    --sdk_location=.../dist/apache-beam-x.x.x.dev0.tar.gz\n+    --project=<GCP_PROJECT_ID>\n+    --temp_location=gs://<BUCKET_NAME>/tmp\n+    --staging_location=gs://<BUCKET_NAME>/staging\n+    --timeout=<TIME_IN_SECONDS>\n+    --publish_to_big_query=<OPTIONAL><true/false>\n+    --metrics_dataset=<OPTIONAL>\n+    --metrics_table=<OPTIONAL>\n+    --dataflow_worker_jar=<OPTIONAL>\n+    --input_options='{\n+    \\\"num_records\\\": <SIZE_OF_INPUT>,\n+    \\\"key_size\\\": 1,\n+    \\\"value_size\\\": <VALUE_SIZE>,\n+    }'\"\n+\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import sys\n+import uuid\n+\n+from hamcrest import all_of\n+\n+import apache_beam as beam\n+from apache_beam.io import WriteToPubSub, PubsubMessage, Read\n+from apache_beam.io.gcp.tests.pubsub_matcher import PubSubMessageMatcher\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.runners import PipelineState\n+from apache_beam.testing import test_utils\n+from apache_beam.testing.load_tests.load_test import LoadTest\n+from apache_beam.testing.load_tests.load_test_metrics_utils import MeasureTime, CountMessages\n+from apache_beam.testing.pipeline_verifiers import PipelineStateMatcher\n+from apache_beam.testing.synthetic_pipeline import SyntheticSource\n+from apache_beam.testing.test_pipeline import TestPipeline\n+\n+PUBSUB_NAME = 'pubsub_write_performance'\n+\n+\n+class PubsubWritePerfTest(LoadTest):\n+\n+  def __init__(self):\n+    super(PubsubWritePerfTest, self).__init__()\n+    self._setup_env()\n+    self._setup_pubsub()\n+    self._setup_pipeline()\n+\n+  def test(self):\n+\n+    class ToPubsubMessage(beam.DoFn):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "450da7a7dfb952310dffcdc35a7a95b6011144bf"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjE3ODk2OA==", "bodyText": "I'm not sure whether I'm able to assign an incrementing id to the elements using FlatMap. The point of using DoFn was to hold a counter as an id generator to ensure its uniqueness.", "url": "https://github.com/apache/beam/pull/11274#discussion_r412178968", "createdAt": "2020-04-21T13:21:43Z", "author": {"login": "piotr-szuberski"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_write_perf_test.py", "diffHunk": "@@ -0,0 +1,155 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Write operation.\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_read_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner\n+    --sdk_location=.../dist/apache-beam-x.x.x.dev0.tar.gz\n+    --project=<GCP_PROJECT_ID>\n+    --temp_location=gs://<BUCKET_NAME>/tmp\n+    --staging_location=gs://<BUCKET_NAME>/staging\n+    --timeout=<TIME_IN_SECONDS>\n+    --publish_to_big_query=<OPTIONAL><true/false>\n+    --metrics_dataset=<OPTIONAL>\n+    --metrics_table=<OPTIONAL>\n+    --dataflow_worker_jar=<OPTIONAL>\n+    --input_options='{\n+    \\\"num_records\\\": <SIZE_OF_INPUT>,\n+    \\\"key_size\\\": 1,\n+    \\\"value_size\\\": <VALUE_SIZE>,\n+    }'\"\n+\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import sys\n+import uuid\n+\n+from hamcrest import all_of\n+\n+import apache_beam as beam\n+from apache_beam.io import WriteToPubSub, PubsubMessage, Read\n+from apache_beam.io.gcp.tests.pubsub_matcher import PubSubMessageMatcher\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.runners import PipelineState\n+from apache_beam.testing import test_utils\n+from apache_beam.testing.load_tests.load_test import LoadTest\n+from apache_beam.testing.load_tests.load_test_metrics_utils import MeasureTime, CountMessages\n+from apache_beam.testing.pipeline_verifiers import PipelineStateMatcher\n+from apache_beam.testing.synthetic_pipeline import SyntheticSource\n+from apache_beam.testing.test_pipeline import TestPipeline\n+\n+PUBSUB_NAME = 'pubsub_write_performance'\n+\n+\n+class PubsubWritePerfTest(LoadTest):\n+\n+  def __init__(self):\n+    super(PubsubWritePerfTest, self).__init__()\n+    self._setup_env()\n+    self._setup_pubsub()\n+    self._setup_pipeline()\n+\n+  def test(self):\n+\n+    class ToPubsubMessage(beam.DoFn):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjAzODYwNQ=="}, "originalCommit": {"oid": "450da7a7dfb952310dffcdc35a7a95b6011144bf"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjIzMjQyNA==", "bodyText": "Oh yes, I overlooked that variable. Let's keep as it is.", "url": "https://github.com/apache/beam/pull/11274#discussion_r412232424", "createdAt": "2020-04-21T14:25:59Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_write_perf_test.py", "diffHunk": "@@ -0,0 +1,155 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Write operation.\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_read_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner\n+    --sdk_location=.../dist/apache-beam-x.x.x.dev0.tar.gz\n+    --project=<GCP_PROJECT_ID>\n+    --temp_location=gs://<BUCKET_NAME>/tmp\n+    --staging_location=gs://<BUCKET_NAME>/staging\n+    --timeout=<TIME_IN_SECONDS>\n+    --publish_to_big_query=<OPTIONAL><true/false>\n+    --metrics_dataset=<OPTIONAL>\n+    --metrics_table=<OPTIONAL>\n+    --dataflow_worker_jar=<OPTIONAL>\n+    --input_options='{\n+    \\\"num_records\\\": <SIZE_OF_INPUT>,\n+    \\\"key_size\\\": 1,\n+    \\\"value_size\\\": <VALUE_SIZE>,\n+    }'\"\n+\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import sys\n+import uuid\n+\n+from hamcrest import all_of\n+\n+import apache_beam as beam\n+from apache_beam.io import WriteToPubSub, PubsubMessage, Read\n+from apache_beam.io.gcp.tests.pubsub_matcher import PubSubMessageMatcher\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.runners import PipelineState\n+from apache_beam.testing import test_utils\n+from apache_beam.testing.load_tests.load_test import LoadTest\n+from apache_beam.testing.load_tests.load_test_metrics_utils import MeasureTime, CountMessages\n+from apache_beam.testing.pipeline_verifiers import PipelineStateMatcher\n+from apache_beam.testing.synthetic_pipeline import SyntheticSource\n+from apache_beam.testing.test_pipeline import TestPipeline\n+\n+PUBSUB_NAME = 'pubsub_write_performance'\n+\n+\n+class PubsubWritePerfTest(LoadTest):\n+\n+  def __init__(self):\n+    super(PubsubWritePerfTest, self).__init__()\n+    self._setup_env()\n+    self._setup_pubsub()\n+    self._setup_pipeline()\n+\n+  def test(self):\n+\n+    class ToPubsubMessage(beam.DoFn):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjAzODYwNQ=="}, "originalCommit": {"oid": "450da7a7dfb952310dffcdc35a7a95b6011144bf"}, "originalPosition": 79}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU2MTQ1ODI1OnYy", "diffSide": "RIGHT", "path": ".test-infra/jenkins/job_PerformanceTests_PubsubIO_Python.groovy", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQxNDozNjoxNlrOGJJOMA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQxNDozNjoxNlrOGJJOMA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjI0MTQ1Ng==", "bodyText": "Recently, we've migrated Load Tests and BigQuery perf tests to Python 3.7. It would be good to keep using Python 3.7 in PubSub perf tests as well.", "url": "https://github.com/apache/beam/pull/11274#discussion_r412241456", "createdAt": "2020-04-21T14:36:16Z", "author": {"login": "kamilwu"}, "path": ".test-infra/jenkins/job_PerformanceTests_PubsubIO_Python.groovy", "diffHunk": "@@ -0,0 +1,93 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+def now = new Date().format(\"MMddHHmmss\", TimeZone.getTimeZone('UTC'))\n+\n+def psio_read_test = [\n+        title          : 'PubsubIO Read Performance Test Python 900000 messages',\n+        test           : 'apache_beam.io.gcp.pubsub_read_perf_test',\n+        runner         : CommonTestProperties.Runner.DATAFLOW,\n+        pipelineOptions: [\n+                job_name             : 'performance-tests-psio-read-python-900000-msgs' + now,\n+                project              : 'apache-beam-testing',\n+                temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n+                publish_to_big_query : true,\n+                metrics_dataset      : 'beam_performance',\n+                metrics_table        : 'psio_read_900000msg_results',\n+                // Pubsub PublishRequest can have max 10'000'000 bytes\n+                input_options        : '\\'{\"num_records\": 900000}\\'',\n+                num_workers          : 5,\n+                autoscaling_algorithm: 'NONE',  // Disable autoscale the worker pool.\n+                timeout              : 3600,\n+        ]\n+]\n+\n+def psio_write_test = [\n+        title          : 'PubsubIO Write Performance Test Python 900000 messages',\n+        test           : 'apache_beam.io.gcp.pubsub_write_perf_test',\n+        runner         : CommonTestProperties.Runner.DATAFLOW,\n+        pipelineOptions: [\n+                job_name             : 'performance-tests-psio-write-python-900000-msgs' + now,\n+                project              : 'apache-beam-testing',\n+                temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n+                publish_to_big_query : true,\n+                metrics_dataset      : 'beam_performance',\n+                metrics_table        : 'psio_write_900000msg_results',\n+                // Pubsub PublishRequest can have max 10'000'000 bytes\n+                input_options        : '\\'{' +\n+                        '\"num_records\": 900000,' +\n+                        '\"key_size\": 1,' +\n+                        '\"value_size\": 1}\\'',\n+                num_workers          : 5,\n+                autoscaling_algorithm: 'NONE',  // Disable autoscale the worker pool.\n+                timeout              : 3600,\n+        ]\n+]\n+\n+def executeJob = { scope, testConfig ->\n+    commonJobProperties.setTopLevelMainJobProperties(scope, 'master', 240)\n+\n+    loadTestsBuilder.loadTest(scope, testConfig.title, testConfig.runner,\n+            CommonTestProperties.SDK.PYTHON, testConfig.pipelineOptions, testConfig.test)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4df286c34697ccf7e6139a2c593292d023ec80b8"}, "originalPosition": 66}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU2MTQ3MzUyOnYy", "diffSide": "LEFT", "path": "sdks/python/apache_beam/io/gcp/tests/pubsub_matcher.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQxNDozOTowMFrOGJJXig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQxNDozOTowMFrOGJJXig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjI0Mzg1MA==", "bodyText": "We can rename this constant to DEFAULT_MAX_MESSAGES_IN_ONE_PULL and use as a default parameter value.", "url": "https://github.com/apache/beam/pull/11274#discussion_r412243850", "createdAt": "2020-04-21T14:39:00Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/tests/pubsub_matcher.py", "diffHunk": "@@ -38,7 +38,6 @@\n   pubsub = None\n \n DEFAULT_TIMEOUT = 5 * 60\n-MAX_MESSAGES_IN_ONE_PULL = 50", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4df286c34697ccf7e6139a2c593292d023ec80b8"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU2MTQ4MjM1OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/tests/pubsub_matcher.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQxNDo0MDo0M1rOGJJdCw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQxNDo0MDo0M1rOGJJdCw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjI0NTI1OQ==", "bodyText": "I'm fine with additional parameters, but we need to update a docstring.", "url": "https://github.com/apache/beam/pull/11274#discussion_r412245259", "createdAt": "2020-04-21T14:40:43Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/tests/pubsub_matcher.py", "diffHunk": "@@ -57,7 +56,9 @@ def __init__(\n       expected_msg_len=None,\n       timeout=DEFAULT_TIMEOUT,\n       with_attributes=False,\n-      strip_attributes=None):\n+      strip_attributes=None,\n+      sleep_time=1,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4df286c34697ccf7e6139a2c593292d023ec80b8"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5NTc3MzAzOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/pubsub_write_perf_test.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQwOTo0MzowMFrOGN3UQA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxMDozMjo1MlrOGP6yyw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzE5MDk3Ng==", "bodyText": "How about creating a subscription for reading messages in the read test? I'm\u00a0pretty sure the write test does not need it.", "url": "https://github.com/apache/beam/pull/11274#discussion_r417190976", "createdAt": "2020-04-29T09:43:00Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_write_perf_test.py", "diffHunk": "@@ -0,0 +1,104 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Write operation.\n+\n+Caution: only test runners (e.g. TestDataflowRunner) support matchers\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_read_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner\n+    --sdk_location=.../dist/apache-beam-x.x.x.dev0.tar.gz\n+    --project=<GCP_PROJECT_ID>\n+    --temp_location=gs://<BUCKET_NAME>/tmp\n+    --staging_location=gs://<BUCKET_NAME>/staging\n+    --timeout=<TIME_IN_SECONDS>\n+    --pubsub_name=<PUBSUB_NAME_TO_BE_CREATED>\n+    --publish_to_big_query=<OPTIONAL><true/false>\n+    --metrics_dataset=<OPTIONAL>\n+    --metrics_table=<OPTIONAL>\n+    --dataflow_worker_jar=<OPTIONAL>\n+    --input_options='{\n+    \\\"num_records\\\": <SIZE_OF_INPUT>,\n+    \\\"key_size\\\": 1,\n+    \\\"value_size\\\": <VALUE_SIZE>,\n+    }'\"\n+\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import logging\n+\n+import apache_beam as beam\n+from apache_beam.io import Read\n+from apache_beam.io.gcp.pubsub_perf_test import PubsubPerfTest\n+from apache_beam.testing.load_tests.load_test_metrics_utils import MeasureTime\n+from apache_beam.testing.synthetic_pipeline import SyntheticSource\n+\n+\n+class PubsubWritePerfTest(PubsubPerfTest):\n+  def __init__(self):\n+    super(PubsubWritePerfTest, self).__init__()\n+    self._setup_env()\n+    self._setup_pubsub()\n+    self._setup_pipeline(self.write_matcher_sub_name)\n+\n+  def test(self):\n+    def to_pubsub_message(element):\n+      import uuid\n+      from apache_beam.io import PubsubMessage\n+      return PubsubMessage(\n+          data=element[1],\n+          attributes={'id': str(uuid.uuid1()).encode('utf-8')},\n+      )\n+\n+    _ = (\n+        self.pipeline\n+        | 'Create input' >> Read(\n+            SyntheticSource(self.parse_synthetic_source_options()))\n+        | 'Format to pubsub message in bytes' >> beam.Map(to_pubsub_message)\n+        | 'Measure time' >> beam.ParDo(MeasureTime(self.metrics_namespace))\n+        | 'Write to Pubsub' >> beam.io.WriteToPubSub(\n+            self.topic_name, with_attributes=True, id_label='id'))\n+\n+  def _setup_pubsub(self):\n+    super(PubsubWritePerfTest, self)._setup_pubsub()\n+\n+    def make_subscription(sub_name):\n+      _ = self.sub_client.create_subscription(\n+          sub_name,\n+          self.topic_name,\n+          ack_deadline_seconds=300,\n+          timeout=1200,\n+          retain_acked_messages=True,\n+      )\n+\n+    _ = self.pub_client.create_topic(self.topic_name)\n+    make_subscription(self.write_matcher_sub_name)\n+    make_subscription(self.read_sub_name)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bea3df016b63c2be50ca792e71f5538ac63ac44b"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTM0NTA5OQ==", "bodyText": "It is needed because the subscription must exists when the messages are being published. If I move it to the read test then the subscription will be empty.", "url": "https://github.com/apache/beam/pull/11274#discussion_r419345099", "createdAt": "2020-05-04T10:32:52Z", "author": {"login": "piotr-szuberski"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_write_perf_test.py", "diffHunk": "@@ -0,0 +1,104 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Write operation.\n+\n+Caution: only test runners (e.g. TestDataflowRunner) support matchers\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_read_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner\n+    --sdk_location=.../dist/apache-beam-x.x.x.dev0.tar.gz\n+    --project=<GCP_PROJECT_ID>\n+    --temp_location=gs://<BUCKET_NAME>/tmp\n+    --staging_location=gs://<BUCKET_NAME>/staging\n+    --timeout=<TIME_IN_SECONDS>\n+    --pubsub_name=<PUBSUB_NAME_TO_BE_CREATED>\n+    --publish_to_big_query=<OPTIONAL><true/false>\n+    --metrics_dataset=<OPTIONAL>\n+    --metrics_table=<OPTIONAL>\n+    --dataflow_worker_jar=<OPTIONAL>\n+    --input_options='{\n+    \\\"num_records\\\": <SIZE_OF_INPUT>,\n+    \\\"key_size\\\": 1,\n+    \\\"value_size\\\": <VALUE_SIZE>,\n+    }'\"\n+\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import logging\n+\n+import apache_beam as beam\n+from apache_beam.io import Read\n+from apache_beam.io.gcp.pubsub_perf_test import PubsubPerfTest\n+from apache_beam.testing.load_tests.load_test_metrics_utils import MeasureTime\n+from apache_beam.testing.synthetic_pipeline import SyntheticSource\n+\n+\n+class PubsubWritePerfTest(PubsubPerfTest):\n+  def __init__(self):\n+    super(PubsubWritePerfTest, self).__init__()\n+    self._setup_env()\n+    self._setup_pubsub()\n+    self._setup_pipeline(self.write_matcher_sub_name)\n+\n+  def test(self):\n+    def to_pubsub_message(element):\n+      import uuid\n+      from apache_beam.io import PubsubMessage\n+      return PubsubMessage(\n+          data=element[1],\n+          attributes={'id': str(uuid.uuid1()).encode('utf-8')},\n+      )\n+\n+    _ = (\n+        self.pipeline\n+        | 'Create input' >> Read(\n+            SyntheticSource(self.parse_synthetic_source_options()))\n+        | 'Format to pubsub message in bytes' >> beam.Map(to_pubsub_message)\n+        | 'Measure time' >> beam.ParDo(MeasureTime(self.metrics_namespace))\n+        | 'Write to Pubsub' >> beam.io.WriteToPubSub(\n+            self.topic_name, with_attributes=True, id_label='id'))\n+\n+  def _setup_pubsub(self):\n+    super(PubsubWritePerfTest, self)._setup_pubsub()\n+\n+    def make_subscription(sub_name):\n+      _ = self.sub_client.create_subscription(\n+          sub_name,\n+          self.topic_name,\n+          ack_deadline_seconds=300,\n+          timeout=1200,\n+          retain_acked_messages=True,\n+      )\n+\n+    _ = self.pub_client.create_topic(self.topic_name)\n+    make_subscription(self.write_matcher_sub_name)\n+    make_subscription(self.read_sub_name)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzE5MDk3Ng=="}, "originalCommit": {"oid": "bea3df016b63c2be50ca792e71f5538ac63ac44b"}, "originalPosition": 98}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5NTc3OTY3OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/pubsub_write_perf_test.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQwOTo0NDo1MVrOGN3YRg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQwOTo0NDo1MVrOGN3YRg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzE5MjAwNg==", "bodyText": "The same situation as above.", "url": "https://github.com/apache/beam/pull/11274#discussion_r417192006", "createdAt": "2020-04-29T09:44:51Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_write_perf_test.py", "diffHunk": "@@ -0,0 +1,104 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Write operation.\n+\n+Caution: only test runners (e.g. TestDataflowRunner) support matchers\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_read_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner\n+    --sdk_location=.../dist/apache-beam-x.x.x.dev0.tar.gz\n+    --project=<GCP_PROJECT_ID>\n+    --temp_location=gs://<BUCKET_NAME>/tmp\n+    --staging_location=gs://<BUCKET_NAME>/staging\n+    --timeout=<TIME_IN_SECONDS>\n+    --pubsub_name=<PUBSUB_NAME_TO_BE_CREATED>\n+    --publish_to_big_query=<OPTIONAL><true/false>\n+    --metrics_dataset=<OPTIONAL>\n+    --metrics_table=<OPTIONAL>\n+    --dataflow_worker_jar=<OPTIONAL>\n+    --input_options='{\n+    \\\"num_records\\\": <SIZE_OF_INPUT>,\n+    \\\"key_size\\\": 1,\n+    \\\"value_size\\\": <VALUE_SIZE>,\n+    }'\"\n+\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import logging\n+\n+import apache_beam as beam\n+from apache_beam.io import Read\n+from apache_beam.io.gcp.pubsub_perf_test import PubsubPerfTest\n+from apache_beam.testing.load_tests.load_test_metrics_utils import MeasureTime\n+from apache_beam.testing.synthetic_pipeline import SyntheticSource\n+\n+\n+class PubsubWritePerfTest(PubsubPerfTest):\n+  def __init__(self):\n+    super(PubsubWritePerfTest, self).__init__()\n+    self._setup_env()\n+    self._setup_pubsub()\n+    self._setup_pipeline(self.write_matcher_sub_name)\n+\n+  def test(self):\n+    def to_pubsub_message(element):\n+      import uuid\n+      from apache_beam.io import PubsubMessage\n+      return PubsubMessage(\n+          data=element[1],\n+          attributes={'id': str(uuid.uuid1()).encode('utf-8')},\n+      )\n+\n+    _ = (\n+        self.pipeline\n+        | 'Create input' >> Read(\n+            SyntheticSource(self.parse_synthetic_source_options()))\n+        | 'Format to pubsub message in bytes' >> beam.Map(to_pubsub_message)\n+        | 'Measure time' >> beam.ParDo(MeasureTime(self.metrics_namespace))\n+        | 'Write to Pubsub' >> beam.io.WriteToPubSub(\n+            self.topic_name, with_attributes=True, id_label='id'))\n+\n+  def _setup_pubsub(self):\n+    super(PubsubWritePerfTest, self)._setup_pubsub()\n+\n+    def make_subscription(sub_name):\n+      _ = self.sub_client.create_subscription(\n+          sub_name,\n+          self.topic_name,\n+          ack_deadline_seconds=300,\n+          timeout=1200,\n+          retain_acked_messages=True,\n+      )\n+\n+    _ = self.pub_client.create_topic(self.topic_name)\n+    make_subscription(self.write_matcher_sub_name)\n+    make_subscription(self.read_sub_name)\n+    make_subscription(self.read_matcher_sub_name)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bea3df016b63c2be50ca792e71f5538ac63ac44b"}, "originalPosition": 99}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5NTgwMjEzOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/pubsub_write_perf_test.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQwOTo1MToyOVrOGN3mYw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQwOTo1MToyOVrOGN3mYw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzE5NTYxOQ==", "bodyText": "Can we shift the responsibility of cleaning up this subscription onto this test? Remember that both tests can be executed independently, without Jenkins.", "url": "https://github.com/apache/beam/pull/11274#discussion_r417195619", "createdAt": "2020-04-29T09:51:29Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_write_perf_test.py", "diffHunk": "@@ -0,0 +1,104 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Write operation.\n+\n+Caution: only test runners (e.g. TestDataflowRunner) support matchers\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_read_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner\n+    --sdk_location=.../dist/apache-beam-x.x.x.dev0.tar.gz\n+    --project=<GCP_PROJECT_ID>\n+    --temp_location=gs://<BUCKET_NAME>/tmp\n+    --staging_location=gs://<BUCKET_NAME>/staging\n+    --timeout=<TIME_IN_SECONDS>\n+    --pubsub_name=<PUBSUB_NAME_TO_BE_CREATED>\n+    --publish_to_big_query=<OPTIONAL><true/false>\n+    --metrics_dataset=<OPTIONAL>\n+    --metrics_table=<OPTIONAL>\n+    --dataflow_worker_jar=<OPTIONAL>\n+    --input_options='{\n+    \\\"num_records\\\": <SIZE_OF_INPUT>,\n+    \\\"key_size\\\": 1,\n+    \\\"value_size\\\": <VALUE_SIZE>,\n+    }'\"\n+\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import logging\n+\n+import apache_beam as beam\n+from apache_beam.io import Read\n+from apache_beam.io.gcp.pubsub_perf_test import PubsubPerfTest\n+from apache_beam.testing.load_tests.load_test_metrics_utils import MeasureTime\n+from apache_beam.testing.synthetic_pipeline import SyntheticSource\n+\n+\n+class PubsubWritePerfTest(PubsubPerfTest):\n+  def __init__(self):\n+    super(PubsubWritePerfTest, self).__init__()\n+    self._setup_env()\n+    self._setup_pubsub()\n+    self._setup_pipeline(self.write_matcher_sub_name)\n+\n+  def test(self):\n+    def to_pubsub_message(element):\n+      import uuid\n+      from apache_beam.io import PubsubMessage\n+      return PubsubMessage(\n+          data=element[1],\n+          attributes={'id': str(uuid.uuid1()).encode('utf-8')},\n+      )\n+\n+    _ = (\n+        self.pipeline\n+        | 'Create input' >> Read(\n+            SyntheticSource(self.parse_synthetic_source_options()))\n+        | 'Format to pubsub message in bytes' >> beam.Map(to_pubsub_message)\n+        | 'Measure time' >> beam.ParDo(MeasureTime(self.metrics_namespace))\n+        | 'Write to Pubsub' >> beam.io.WriteToPubSub(\n+            self.topic_name, with_attributes=True, id_label='id'))\n+\n+  def _setup_pubsub(self):\n+    super(PubsubWritePerfTest, self)._setup_pubsub()\n+\n+    def make_subscription(sub_name):\n+      _ = self.sub_client.create_subscription(\n+          sub_name,\n+          self.topic_name,\n+          ack_deadline_seconds=300,\n+          timeout=1200,\n+          retain_acked_messages=True,\n+      )\n+\n+    _ = self.pub_client.create_topic(self.topic_name)\n+    make_subscription(self.write_matcher_sub_name)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bea3df016b63c2be50ca792e71f5538ac63ac44b"}, "originalPosition": 97}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5NTgxMjc5OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/pubsub_read_perf_test.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQwOTo1NDo0N1rOGN3tIQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxMDozNzo0OVrOGP67dw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzE5NzM0NQ==", "bodyText": "It would be good to notice that the input topic must already exist before executing the test.", "url": "https://github.com/apache/beam/pull/11274#discussion_r417197345", "createdAt": "2020-04-29T09:54:47Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_read_perf_test.py", "diffHunk": "@@ -0,0 +1,80 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Read operation.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bea3df016b63c2be50ca792e71f5538ac63ac44b"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTM0NzMxOQ==", "bodyText": "Sure, but still the read subscriptions can't be cleaned here so overall I would suggest making  one write-read test instead of splitting them", "url": "https://github.com/apache/beam/pull/11274#discussion_r419347319", "createdAt": "2020-05-04T10:37:49Z", "author": {"login": "piotr-szuberski"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_read_perf_test.py", "diffHunk": "@@ -0,0 +1,80 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Read operation.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzE5NzM0NQ=="}, "originalCommit": {"oid": "bea3df016b63c2be50ca792e71f5538ac63ac44b"}, "originalPosition": 19}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5NTg1MTAzOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/pubsub_read_perf_test.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQxMDowNjoyNFrOGN4FXA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxMDo0OTozNlrOGP7Pmg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzIwMzU0OA==", "bodyText": "This parameter is not used. I think we can remove this. Please also remove the code that checks if --input_option is present at the base class.", "url": "https://github.com/apache/beam/pull/11274#discussion_r417203548", "createdAt": "2020-04-29T10:06:24Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_read_perf_test.py", "diffHunk": "@@ -0,0 +1,80 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Read operation.\n+\n+Caution: only test runners (e.g. TestDataflowRunner) support matchers\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_read_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner\n+    --sdk_location=.../dist/apache-beam-x.x.x.dev0.tar.gz\n+    --project=<GCP_PROJECT_ID>\n+    --temp_location=gs://<BUCKET_NAME>/tmp\n+    --staging_location=gs://<BUCKET_NAME>/staging\n+    --timeout=<TIME_IN_SECONDS>\n+    --pubsub_name=<PUBSUB_NAME_TO_BE_CREATED>\n+    --publish_to_big_query=<OPTIONAL><true/false>\n+    --metrics_dataset=<OPTIONAL>\n+    --metrics_table=<OPTIONAL>\n+    --dataflow_worker_jar=<OPTIONAL>\n+    --input_options='{", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bea3df016b63c2be50ca792e71f5538ac63ac44b"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTM1MjQ3NA==", "bodyText": "input options is used for the synthetic source in write, it specifies the number of messages and the size of each message. It can be not used and some num_of_messages and length_of_messages can be used instead, but it can as well stay as it is", "url": "https://github.com/apache/beam/pull/11274#discussion_r419352474", "createdAt": "2020-05-04T10:49:36Z", "author": {"login": "piotr-szuberski"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_read_perf_test.py", "diffHunk": "@@ -0,0 +1,80 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Read operation.\n+\n+Caution: only test runners (e.g. TestDataflowRunner) support matchers\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_read_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner\n+    --sdk_location=.../dist/apache-beam-x.x.x.dev0.tar.gz\n+    --project=<GCP_PROJECT_ID>\n+    --temp_location=gs://<BUCKET_NAME>/tmp\n+    --staging_location=gs://<BUCKET_NAME>/staging\n+    --timeout=<TIME_IN_SECONDS>\n+    --pubsub_name=<PUBSUB_NAME_TO_BE_CREATED>\n+    --publish_to_big_query=<OPTIONAL><true/false>\n+    --metrics_dataset=<OPTIONAL>\n+    --metrics_table=<OPTIONAL>\n+    --dataflow_worker_jar=<OPTIONAL>\n+    --input_options='{", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzIwMzU0OA=="}, "originalCommit": {"oid": "bea3df016b63c2be50ca792e71f5538ac63ac44b"}, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5NTg3MTEzOnYy", "diffSide": "RIGHT", "path": ".test-infra/jenkins/job_PerformanceTests_PubsubIO_Python.groovy", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQxMDoxMjoxN1rOGN4RnQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxMjoxMjo1NlrOGP9k2A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzIwNjY4NQ==", "bodyText": "I like the idea of reusing output topic for the purpose of the read test. But, in that case, you have to make sure that the write test is executed first. At the moment, both tests start independently at the same hour ('H 15 * * *'), which can cause some issues.", "url": "https://github.com/apache/beam/pull/11274#discussion_r417206685", "createdAt": "2020-04-29T10:12:17Z", "author": {"login": "kamilwu"}, "path": ".test-infra/jenkins/job_PerformanceTests_PubsubIO_Python.groovy", "diffHunk": "@@ -0,0 +1,106 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+import CommonJobProperties as commonJobProperties\n+import LoadTestsBuilder as loadTestsBuilder\n+import PhraseTriggeringPostCommitBuilder\n+\n+import static java.util.UUID.randomUUID\n+\n+def now = new Date().format(\"MMddHHmmss\", TimeZone.getTimeZone('UTC'))\n+def timeout = 60 * 60\n+\n+def pubsubId = randomUUID()\n+def pubsubName = \"pubsub_io_performance_${pubsubId}\"\n+\n+def psio_write_test = [\n+        title          : 'PubsubIO Write Performance Test Python 2GB',\n+        test           : 'apache_beam.io.gcp.pubsub_write_perf_test',\n+        runner         : CommonTestProperties.Runner.DATAFLOW,\n+        pipelineOptions: [\n+                job_name             : 'performance-tests-psio-write-python-2gb' + now,\n+                project              : 'apache-beam-testing',\n+                temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n+                publish_to_big_query : true,\n+                metrics_dataset      : 'beam_performance',\n+                metrics_table        : 'psio_write_2GB_msg_results',\n+                input_options        : '\\'{' +\n+                        '\"num_records\": 2097152,' +\n+                        '\"key_size\": 1,' +\n+                        '\"value_size\": 1024}\\'',\n+                num_workers          : 5,\n+                autoscaling_algorithm: 'NONE',  // Disable autoscale the worker pool.\n+                pubsub_name          : pubsubName,\n+                timeout              : timeout,\n+        ]\n+]\n+\n+def psio_read_test = [\n+        title          : 'PubsubIO Read Performance Test Python 2GB',\n+        test           : 'apache_beam.io.gcp.pubsub_read_perf_test',\n+        runner         : CommonTestProperties.Runner.DATAFLOW,\n+        pipelineOptions: [\n+                job_name             : 'performance-tests-psio-read-python-2gb' + now,\n+                project              : 'apache-beam-testing',\n+                temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n+                publish_to_big_query : true,\n+                metrics_dataset      : 'beam_performance',\n+                metrics_table        : 'psio_read_2GB_msg_results',\n+                input_options        : '\\'{' +\n+                        '\"num_records\": 2097152,' +\n+                        '\"key_size\": 1,' +\n+                        '\"value_size\": 1024}\\'',\n+                num_workers          : 5,\n+                autoscaling_algorithm: 'NONE',  // Disable autoscale the worker pool.\n+                pubsub_name          : pubsubName,\n+                timeout              : timeout,\n+        ]\n+]\n+\n+def executeJob = { scope, testConfig ->\n+    commonJobProperties.setTopLevelMainJobProperties(scope, 'master', 240)\n+\n+    loadTestsBuilder.loadTest(scope, testConfig.title, testConfig.runner,\n+            CommonTestProperties.SDK.PYTHON_37, testConfig.pipelineOptions, testConfig.test)\n+}\n+\n+PhraseTriggeringPostCommitBuilder.postCommitJob(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bea3df016b63c2be50ca792e71f5538ac63ac44b"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTM5MDY4MA==", "bodyText": "I moved both tests to one file so now it'll be impossible to run them separately. They were so tightly bounded that it made no sense to run them individually", "url": "https://github.com/apache/beam/pull/11274#discussion_r419390680", "createdAt": "2020-05-04T12:12:56Z", "author": {"login": "piotr-szuberski"}, "path": ".test-infra/jenkins/job_PerformanceTests_PubsubIO_Python.groovy", "diffHunk": "@@ -0,0 +1,106 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+import CommonJobProperties as commonJobProperties\n+import LoadTestsBuilder as loadTestsBuilder\n+import PhraseTriggeringPostCommitBuilder\n+\n+import static java.util.UUID.randomUUID\n+\n+def now = new Date().format(\"MMddHHmmss\", TimeZone.getTimeZone('UTC'))\n+def timeout = 60 * 60\n+\n+def pubsubId = randomUUID()\n+def pubsubName = \"pubsub_io_performance_${pubsubId}\"\n+\n+def psio_write_test = [\n+        title          : 'PubsubIO Write Performance Test Python 2GB',\n+        test           : 'apache_beam.io.gcp.pubsub_write_perf_test',\n+        runner         : CommonTestProperties.Runner.DATAFLOW,\n+        pipelineOptions: [\n+                job_name             : 'performance-tests-psio-write-python-2gb' + now,\n+                project              : 'apache-beam-testing',\n+                temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n+                publish_to_big_query : true,\n+                metrics_dataset      : 'beam_performance',\n+                metrics_table        : 'psio_write_2GB_msg_results',\n+                input_options        : '\\'{' +\n+                        '\"num_records\": 2097152,' +\n+                        '\"key_size\": 1,' +\n+                        '\"value_size\": 1024}\\'',\n+                num_workers          : 5,\n+                autoscaling_algorithm: 'NONE',  // Disable autoscale the worker pool.\n+                pubsub_name          : pubsubName,\n+                timeout              : timeout,\n+        ]\n+]\n+\n+def psio_read_test = [\n+        title          : 'PubsubIO Read Performance Test Python 2GB',\n+        test           : 'apache_beam.io.gcp.pubsub_read_perf_test',\n+        runner         : CommonTestProperties.Runner.DATAFLOW,\n+        pipelineOptions: [\n+                job_name             : 'performance-tests-psio-read-python-2gb' + now,\n+                project              : 'apache-beam-testing',\n+                temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n+                publish_to_big_query : true,\n+                metrics_dataset      : 'beam_performance',\n+                metrics_table        : 'psio_read_2GB_msg_results',\n+                input_options        : '\\'{' +\n+                        '\"num_records\": 2097152,' +\n+                        '\"key_size\": 1,' +\n+                        '\"value_size\": 1024}\\'',\n+                num_workers          : 5,\n+                autoscaling_algorithm: 'NONE',  // Disable autoscale the worker pool.\n+                pubsub_name          : pubsubName,\n+                timeout              : timeout,\n+        ]\n+]\n+\n+def executeJob = { scope, testConfig ->\n+    commonJobProperties.setTopLevelMainJobProperties(scope, 'master', 240)\n+\n+    loadTestsBuilder.loadTest(scope, testConfig.title, testConfig.runner,\n+            CommonTestProperties.SDK.PYTHON_37, testConfig.pipelineOptions, testConfig.test)\n+}\n+\n+PhraseTriggeringPostCommitBuilder.postCommitJob(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzIwNjY4NQ=="}, "originalCommit": {"oid": "bea3df016b63c2be50ca792e71f5538ac63ac44b"}, "originalPosition": 82}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYxNDI0OTI3OnYy", "diffSide": "RIGHT", "path": ".test-infra/jenkins/job_PerformanceTests_PubsubIO_Python.groovy", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQwOTowMTozMFrOGQgfGg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQwOTowMTozMFrOGQgfGg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTk2MjY1MA==", "bodyText": "There are two spaces between PubsubIO and Performance. Could you fix that?", "url": "https://github.com/apache/beam/pull/11274#discussion_r419962650", "createdAt": "2020-05-05T09:01:30Z", "author": {"login": "kamilwu"}, "path": ".test-infra/jenkins/job_PerformanceTests_PubsubIO_Python.groovy", "diffHunk": "@@ -0,0 +1,72 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+import CommonJobProperties as commonJobProperties\n+import LoadTestsBuilder as loadTestsBuilder\n+import PhraseTriggeringPostCommitBuilder\n+\n+import static java.util.UUID.randomUUID\n+\n+def now = new Date().format(\"MMddHHmmss\", TimeZone.getTimeZone('UTC'))\n+def timeout = 60 * 60\n+\n+def pubsubId = randomUUID()\n+def pubsubName = \"pubsub_io_performance_${pubsubId}\"\n+\n+def psio_test = [\n+        title          : 'PubsubIO Write Performance Test Python 2GB',\n+        test           : 'apache_beam.io.gcp.pubsub_io_perf_test',\n+        runner         : CommonTestProperties.Runner.DATAFLOW,\n+        pipelineOptions: [\n+                job_name             : 'performance-tests-psio-python-2gb' + now,\n+                project              : 'apache-beam-testing',\n+                temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n+                publish_to_big_query : true,\n+                metrics_dataset      : 'beam_performance',\n+                metrics_table        : 'psio_io_2GB_msg_results',\n+                input_options        : '\\'{' +\n+                        '\"num_records\": 2097152,' +\n+                        '\"key_size\": 1,' +\n+                        '\"value_size\": 1024}\\'',\n+                num_workers          : 5,\n+                autoscaling_algorithm: 'NONE',  // Disable autoscale the worker pool.\n+                pubsub_name          : pubsubName,\n+                timeout              : timeout,\n+        ]\n+]\n+\n+\n+def executeJob = { scope, testConfig ->\n+    commonJobProperties.setTopLevelMainJobProperties(scope, 'master', 240)\n+\n+    loadTestsBuilder.loadTest(scope, testConfig.title, testConfig.runner,\n+            CommonTestProperties.SDK.PYTHON_37, testConfig.pipelineOptions, testConfig.test)\n+}\n+\n+PhraseTriggeringPostCommitBuilder.postCommitJob(\n+        'beam_PubsubIO_Performance_Test_Python',\n+        'Run PubsubIO  Performance Test Python',", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a155f9a1e2468adbd558cc1e9c80a58a3ba47139"}, "originalPosition": 63}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYxNDI2OTM0OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/pubsub_io_perf_test.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQwOTowNzo0MVrOGQgsCw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQwOTowNzo0MVrOGQgsCw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTk2NTk2Mw==", "bodyText": "It'd good to put emphasis on what is being created with this name. I suggest renaming this option to topic_name.", "url": "https://github.com/apache/beam/pull/11274#discussion_r419965963", "createdAt": "2020-05-05T09:07:41Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_io_perf_test.py", "diffHunk": "@@ -0,0 +1,195 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Write/Read operations.\n+\n+Caution: only test runners (e.g. TestDataflowRunner) support matchers\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_io_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner\n+    --sdk_location=.../dist/apache-beam-x.x.x.dev0.tar.gz\n+    --project=<GCP_PROJECT_ID>\n+    --temp_location=gs://<BUCKET_NAME>/tmp\n+    --staging_location=gs://<BUCKET_NAME>/staging\n+    --timeout=<TIME_IN_SECONDS>\n+    --pubsub_name=<PUBSUB_NAME_TO_BE_CREATED>\n+    --publish_to_big_query=<OPTIONAL><true/false>\n+    --metrics_dataset=<OPTIONAL>\n+    --metrics_table=<OPTIONAL>\n+    --dataflow_worker_jar=<OPTIONAL>\n+    --input_options='{\n+      \\\"num_records\\\": <SIZE_OF_INPUT>\n+      \\\"key_size\\\": 1\n+      \\\"value_size\\\": <SIZE_OF_EACH_MESSAGE>\n+    }'\"\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import logging\n+import sys\n+\n+from hamcrest import all_of\n+\n+import apache_beam as beam\n+from apache_beam.io import Read\n+from apache_beam.io import ReadFromPubSub\n+from apache_beam.io.gcp.tests.pubsub_matcher import PubSubMessageMatcher\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.testing.load_tests.load_test import LoadTest\n+from apache_beam.testing.load_tests.load_test_metrics_utils import MeasureTime\n+from apache_beam.testing.synthetic_pipeline import SyntheticSource\n+from apache_beam.testing.test_pipeline import TestPipeline\n+\n+# pylint: disable=wrong-import-order, wrong-import-position\n+try:\n+  from google.cloud import pubsub\n+except ImportError:\n+  pubsub = None\n+# pylint: enable=wrong-import-order, wrong-import-position\n+\n+\n+class PubsubIOPerfTest(LoadTest):\n+  def _setup_env(self):\n+    def check_option(name):\n+      if not self.pipeline.get_option(name):\n+        logging.error('--%s argument is required.', name)\n+        sys.exit(1)\n+\n+    check_option('timeout')\n+    check_option('pubsub_name')\n+\n+    self.num_of_messages = int(self.input_options.get('num_records'))\n+    self.size_of_messages = int(self.input_options.get('value_size'))\n+    self.timeout = int(self.pipeline.get_option('timeout'))\n+    self.pubsub_name = self.pipeline.get_option('pubsub_name')", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a155f9a1e2468adbd558cc1e9c80a58a3ba47139"}, "originalPosition": 85}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYxNDM2NDY4OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/pubsub_io_perf_test.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQwOTozNDozM1rOGQhmdg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQwOTozNTozMFrOGQhorg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTk4MDkxOA==", "bodyText": "It's totally fine to write all metrics to the same BigQuery table. That's how all IO IT tests in Java SDK works, where we have two types of metric: \"read_time\" and \"write_time\". The only thing you have to do is to change the argument that MeasureTime's constructor takes (it's self.metrics_namespace now, which is BigQuery table, but you wanna change that to, say, 'read_time' in PubsubReadPerfTest and 'write_time' in PubsubWritePerfTest)", "url": "https://github.com/apache/beam/pull/11274#discussion_r419980918", "createdAt": "2020-05-05T09:34:33Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_io_perf_test.py", "diffHunk": "@@ -0,0 +1,195 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Write/Read operations.\n+\n+Caution: only test runners (e.g. TestDataflowRunner) support matchers\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_io_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner\n+    --sdk_location=.../dist/apache-beam-x.x.x.dev0.tar.gz\n+    --project=<GCP_PROJECT_ID>\n+    --temp_location=gs://<BUCKET_NAME>/tmp\n+    --staging_location=gs://<BUCKET_NAME>/staging\n+    --timeout=<TIME_IN_SECONDS>\n+    --pubsub_name=<PUBSUB_NAME_TO_BE_CREATED>\n+    --publish_to_big_query=<OPTIONAL><true/false>\n+    --metrics_dataset=<OPTIONAL>\n+    --metrics_table=<OPTIONAL>\n+    --dataflow_worker_jar=<OPTIONAL>\n+    --input_options='{\n+      \\\"num_records\\\": <SIZE_OF_INPUT>\n+      \\\"key_size\\\": 1\n+      \\\"value_size\\\": <SIZE_OF_EACH_MESSAGE>\n+    }'\"\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import logging\n+import sys\n+\n+from hamcrest import all_of\n+\n+import apache_beam as beam\n+from apache_beam.io import Read\n+from apache_beam.io import ReadFromPubSub\n+from apache_beam.io.gcp.tests.pubsub_matcher import PubSubMessageMatcher\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.testing.load_tests.load_test import LoadTest\n+from apache_beam.testing.load_tests.load_test_metrics_utils import MeasureTime\n+from apache_beam.testing.synthetic_pipeline import SyntheticSource\n+from apache_beam.testing.test_pipeline import TestPipeline\n+\n+# pylint: disable=wrong-import-order, wrong-import-position\n+try:\n+  from google.cloud import pubsub\n+except ImportError:\n+  pubsub = None\n+# pylint: enable=wrong-import-order, wrong-import-position\n+\n+\n+class PubsubIOPerfTest(LoadTest):\n+  def _setup_env(self):\n+    def check_option(name):\n+      if not self.pipeline.get_option(name):\n+        logging.error('--%s argument is required.', name)\n+        sys.exit(1)\n+\n+    check_option('timeout')\n+    check_option('pubsub_name')\n+\n+    self.num_of_messages = int(self.input_options.get('num_records'))\n+    self.size_of_messages = int(self.input_options.get('value_size'))\n+    self.timeout = int(self.pipeline.get_option('timeout'))\n+    self.pubsub_name = self.pipeline.get_option('pubsub_name')\n+\n+  def _setup_pubsub(self):\n+    self.pub_client = pubsub.PublisherClient()\n+    self.topic_name = self.pub_client.topic_path(\n+        self.project_id, self.pubsub_name)\n+\n+    self.sub_client = pubsub.SubscriberClient()\n+    self.read_sub_name = self.sub_client.subscription_path(\n+        self.project_id,\n+        self.pubsub_name + '_read',\n+    )\n+    self.read_matcher_sub_name = self.sub_client.subscription_path(\n+        self.project_id,\n+        self.pubsub_name + '_read_matcher',\n+    )\n+    self.write_matcher_sub_name = self.sub_client.subscription_path(\n+        self.project_id,\n+        self.pubsub_name + '_write_matcher',\n+    )\n+\n+  def _setup_pipeline(self, subscription_name):\n+    pubsub_msg_verifier = PubSubMessageMatcher(\n+        self.project_id,\n+        subscription_name,\n+        expected_msg_len=self.num_of_messages,\n+        timeout=self.timeout,\n+        sleep_time=0,\n+        max_messages_in_one_pull=1000,\n+        pull_timeout=1200)\n+\n+    extra_opts = {\n+        'on_success_matcher': all_of(pubsub_msg_verifier),\n+        'wait_until_finish_duration': self.timeout * 1000,\n+        'streaming': True,\n+        'save_main_session': True\n+    }\n+\n+    args = self.pipeline.get_full_options_as_args(**extra_opts)\n+    self.pipeline = TestPipeline(options=PipelineOptions(args))\n+\n+\n+class PubsubWritePerfTest(PubsubIOPerfTest):\n+  def __init__(self):\n+    super(PubsubWritePerfTest, self).__init__('_write')\n+    self._setup_env()\n+    self._setup_pubsub()\n+    self._setup_pipeline(self.write_matcher_sub_name)\n+\n+  def test(self):\n+    def to_pubsub_message(element):\n+      import uuid\n+      from apache_beam.io import PubsubMessage\n+      return PubsubMessage(\n+          data=element[1],\n+          attributes={'id': str(uuid.uuid1()).encode('utf-8')},\n+      )\n+\n+    _ = (\n+        self.pipeline\n+        | 'Create input' >> Read(\n+            SyntheticSource(self.parse_synthetic_source_options()))\n+        | 'Format to pubsub message in bytes' >> beam.Map(to_pubsub_message)\n+        | 'Measure time' >> beam.ParDo(MeasureTime(self.metrics_namespace))\n+        | 'Write to Pubsub' >> beam.io.WriteToPubSub(\n+            self.topic_name, with_attributes=True, id_label='id'))\n+\n+  def _setup_pubsub(self):\n+    super(PubsubWritePerfTest, self)._setup_pubsub()\n+\n+    def make_subscription(sub_name):\n+      _ = self.sub_client.create_subscription(\n+          sub_name,\n+          self.topic_name,\n+          ack_deadline_seconds=300,\n+          timeout=1200,\n+      )\n+\n+    _ = self.pub_client.create_topic(self.topic_name)\n+    make_subscription(self.write_matcher_sub_name)\n+    make_subscription(self.read_sub_name)\n+    make_subscription(self.read_matcher_sub_name)\n+\n+\n+class PubsubReadPerfTest(PubsubIOPerfTest):\n+  def __init__(self):\n+    super(PubsubReadPerfTest, self).__init__('_read')", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a155f9a1e2468adbd558cc1e9c80a58a3ba47139"}, "originalPosition": 171}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTk4MTQ4Ng==", "bodyText": "Thanks to that, your changes to the base class will be unnecessary.", "url": "https://github.com/apache/beam/pull/11274#discussion_r419981486", "createdAt": "2020-05-05T09:35:30Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_io_perf_test.py", "diffHunk": "@@ -0,0 +1,195 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Write/Read operations.\n+\n+Caution: only test runners (e.g. TestDataflowRunner) support matchers\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_io_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner\n+    --sdk_location=.../dist/apache-beam-x.x.x.dev0.tar.gz\n+    --project=<GCP_PROJECT_ID>\n+    --temp_location=gs://<BUCKET_NAME>/tmp\n+    --staging_location=gs://<BUCKET_NAME>/staging\n+    --timeout=<TIME_IN_SECONDS>\n+    --pubsub_name=<PUBSUB_NAME_TO_BE_CREATED>\n+    --publish_to_big_query=<OPTIONAL><true/false>\n+    --metrics_dataset=<OPTIONAL>\n+    --metrics_table=<OPTIONAL>\n+    --dataflow_worker_jar=<OPTIONAL>\n+    --input_options='{\n+      \\\"num_records\\\": <SIZE_OF_INPUT>\n+      \\\"key_size\\\": 1\n+      \\\"value_size\\\": <SIZE_OF_EACH_MESSAGE>\n+    }'\"\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import logging\n+import sys\n+\n+from hamcrest import all_of\n+\n+import apache_beam as beam\n+from apache_beam.io import Read\n+from apache_beam.io import ReadFromPubSub\n+from apache_beam.io.gcp.tests.pubsub_matcher import PubSubMessageMatcher\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.testing.load_tests.load_test import LoadTest\n+from apache_beam.testing.load_tests.load_test_metrics_utils import MeasureTime\n+from apache_beam.testing.synthetic_pipeline import SyntheticSource\n+from apache_beam.testing.test_pipeline import TestPipeline\n+\n+# pylint: disable=wrong-import-order, wrong-import-position\n+try:\n+  from google.cloud import pubsub\n+except ImportError:\n+  pubsub = None\n+# pylint: enable=wrong-import-order, wrong-import-position\n+\n+\n+class PubsubIOPerfTest(LoadTest):\n+  def _setup_env(self):\n+    def check_option(name):\n+      if not self.pipeline.get_option(name):\n+        logging.error('--%s argument is required.', name)\n+        sys.exit(1)\n+\n+    check_option('timeout')\n+    check_option('pubsub_name')\n+\n+    self.num_of_messages = int(self.input_options.get('num_records'))\n+    self.size_of_messages = int(self.input_options.get('value_size'))\n+    self.timeout = int(self.pipeline.get_option('timeout'))\n+    self.pubsub_name = self.pipeline.get_option('pubsub_name')\n+\n+  def _setup_pubsub(self):\n+    self.pub_client = pubsub.PublisherClient()\n+    self.topic_name = self.pub_client.topic_path(\n+        self.project_id, self.pubsub_name)\n+\n+    self.sub_client = pubsub.SubscriberClient()\n+    self.read_sub_name = self.sub_client.subscription_path(\n+        self.project_id,\n+        self.pubsub_name + '_read',\n+    )\n+    self.read_matcher_sub_name = self.sub_client.subscription_path(\n+        self.project_id,\n+        self.pubsub_name + '_read_matcher',\n+    )\n+    self.write_matcher_sub_name = self.sub_client.subscription_path(\n+        self.project_id,\n+        self.pubsub_name + '_write_matcher',\n+    )\n+\n+  def _setup_pipeline(self, subscription_name):\n+    pubsub_msg_verifier = PubSubMessageMatcher(\n+        self.project_id,\n+        subscription_name,\n+        expected_msg_len=self.num_of_messages,\n+        timeout=self.timeout,\n+        sleep_time=0,\n+        max_messages_in_one_pull=1000,\n+        pull_timeout=1200)\n+\n+    extra_opts = {\n+        'on_success_matcher': all_of(pubsub_msg_verifier),\n+        'wait_until_finish_duration': self.timeout * 1000,\n+        'streaming': True,\n+        'save_main_session': True\n+    }\n+\n+    args = self.pipeline.get_full_options_as_args(**extra_opts)\n+    self.pipeline = TestPipeline(options=PipelineOptions(args))\n+\n+\n+class PubsubWritePerfTest(PubsubIOPerfTest):\n+  def __init__(self):\n+    super(PubsubWritePerfTest, self).__init__('_write')\n+    self._setup_env()\n+    self._setup_pubsub()\n+    self._setup_pipeline(self.write_matcher_sub_name)\n+\n+  def test(self):\n+    def to_pubsub_message(element):\n+      import uuid\n+      from apache_beam.io import PubsubMessage\n+      return PubsubMessage(\n+          data=element[1],\n+          attributes={'id': str(uuid.uuid1()).encode('utf-8')},\n+      )\n+\n+    _ = (\n+        self.pipeline\n+        | 'Create input' >> Read(\n+            SyntheticSource(self.parse_synthetic_source_options()))\n+        | 'Format to pubsub message in bytes' >> beam.Map(to_pubsub_message)\n+        | 'Measure time' >> beam.ParDo(MeasureTime(self.metrics_namespace))\n+        | 'Write to Pubsub' >> beam.io.WriteToPubSub(\n+            self.topic_name, with_attributes=True, id_label='id'))\n+\n+  def _setup_pubsub(self):\n+    super(PubsubWritePerfTest, self)._setup_pubsub()\n+\n+    def make_subscription(sub_name):\n+      _ = self.sub_client.create_subscription(\n+          sub_name,\n+          self.topic_name,\n+          ack_deadline_seconds=300,\n+          timeout=1200,\n+      )\n+\n+    _ = self.pub_client.create_topic(self.topic_name)\n+    make_subscription(self.write_matcher_sub_name)\n+    make_subscription(self.read_sub_name)\n+    make_subscription(self.read_matcher_sub_name)\n+\n+\n+class PubsubReadPerfTest(PubsubIOPerfTest):\n+  def __init__(self):\n+    super(PubsubReadPerfTest, self).__init__('_read')", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTk4MDkxOA=="}, "originalCommit": {"oid": "a155f9a1e2468adbd558cc1e9c80a58a3ba47139"}, "originalPosition": 171}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYyODQxMjYzOnYy", "diffSide": "RIGHT", "path": ".test-infra/jenkins/job_PerformanceTests_PubsubIO_Python.groovy", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wOFQxNDo0MjowOFrOGSoAjA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wOFQxNToxNTo0M1rOGSpMKQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjE4MzA1Mg==", "bodyText": "Why did you remove that comma?", "url": "https://github.com/apache/beam/pull/11274#discussion_r422183052", "createdAt": "2020-05-08T14:42:08Z", "author": {"login": "kamilwu"}, "path": ".test-infra/jenkins/job_PerformanceTests_PubsubIO_Python.groovy", "diffHunk": "@@ -41,7 +42,7 @@ def psio_test = [\n                 metrics_dataset      : 'beam_performance',\n                 metrics_table        : 'psio_io_2GB_msg_results',\n                 input_options        : '\\'{' +\n-                        '\"num_records\": 2097152,' +\n+                        '\"num_records\": 2097152' +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cd8c8cd6f8588b1fe4439c7e1f656657c9160de4"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjIwMjQwOQ==", "bodyText": "It sounds stupid but my cat went through my keyboard and I deleted too many digits and overlooked it", "url": "https://github.com/apache/beam/pull/11274#discussion_r422202409", "createdAt": "2020-05-08T15:15:43Z", "author": {"login": "piotr-szuberski"}, "path": ".test-infra/jenkins/job_PerformanceTests_PubsubIO_Python.groovy", "diffHunk": "@@ -41,7 +42,7 @@ def psio_test = [\n                 metrics_dataset      : 'beam_performance',\n                 metrics_table        : 'psio_io_2GB_msg_results',\n                 input_options        : '\\'{' +\n-                        '\"num_records\": 2097152,' +\n+                        '\"num_records\": 2097152' +", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjE4MzA1Mg=="}, "originalCommit": {"oid": "cd8c8cd6f8588b1fe4439c7e1f656657c9160de4"}, "originalPosition": 13}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1589, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}