{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTE3MDUxNzA0", "number": 13282, "title": "[BEAM-11172] Enable KafkaIO performance test for Dataflow runner v2 with SDF.", "bodyText": "Current KafkaIO Performance test runs in batch mode on Dataflow java production worker.\nThis PR adds 2 more test target into this performance suite:\n\n\nKafkaIO runs on Dataflow runner v2 with SDF unbounded wrapper\n\n\nKafka read SDF implementation runs on Dataflow runner v2.\n\n\nr: @aromanenko-dev\nr: @tysonjh Could you please help review changes related to google-could-dataflow?\ncc: @kennknowles\nThank you for your contribution! Follow this checklist to help us incorporate your contribution quickly and easily:\n\n Choose reviewer(s) and mention them in a comment (R: @username).\n Format the pull request title like [BEAM-XXX] Fixes bug in ApproximateQuantiles, where you replace BEAM-XXX with the appropriate JIRA issue, if applicable. This will automatically link the pull request to the issue.\n Update CHANGES.md with noteworthy changes.\n If this contribution is large, please file an Apache Individual Contributor License Agreement.\n\nSee the Contributor Guide for more tips on how to make review process smoother.\nPost-Commit Tests Status (on master branch)\n\n\n\nLang\nSDK\nDataflow\nFlink\nSamza\nSpark\nTwister2\n\n\n\n\nGo\n\n---\n\n---\n\n---\n\n\nJava\n\n\n\n\n\n\n\n\nPython\n\n\n\n---\n\n---\n\n\nXLang\n\n---\n\n---\n\n---\n\n\n\nPre-Commit Tests Status (on master branch)\n\n\n\n---\nJava\nPython\nGo\nWebsite\nWhitespace\nTypescript\n\n\n\n\nNon-portable\n\n \n\n\n\n\n\n\nPortable\n---\n\n---\n---\n---\n---\n\n\n\nSee .test-infra/jenkins/README for trigger phrase, status and link of all Jenkins jobs.\nGitHub Actions Tests Status (on master branch)\n\n\n\nSee CI.md for more information about GitHub Actions CI.", "createdAt": "2020-11-07T01:37:04Z", "url": "https://github.com/apache/beam/pull/13282", "merged": true, "mergeCommit": {"oid": "17beb66858b6fc21dcd52215e8407286faf4b535"}, "closed": true, "closedAt": "2020-11-13T11:40:08Z", "author": {"login": "boyuanzz"}, "timelineItems": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdbLs1XgFqTUyNzM1NTI5Nw==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdcFm8xgFqTUyOTk5MjE4Nw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3MzU1Mjk3", "url": "https://github.com/apache/beam/pull/13282#pullrequestreview-527355297", "createdAt": "2020-11-10T16:01:20Z", "commit": {"oid": "cbdcd5a110bc2f38ddf014d8886154637fc89cb7"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxNjowMToyMFrOHwjn2Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxNjowNjo0NlrOHwj4CQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDY3NzMzNw==", "bodyText": "What actually \"runner v2\" is?", "url": "https://github.com/apache/beam/pull/13282#discussion_r520677337", "createdAt": "2020-11-10T16:01:20Z", "author": {"login": "aromanenko-dev"}, "path": ".test-infra/jenkins/job_PerformanceTests_KafkaIO_IT.groovy", "diffHunk": "@@ -61,14 +61,38 @@ job(jobName) {\n     autoscalingAlgorithm         : 'NONE'\n   ]\n \n+  Map runnerV2SdfWrapperPipelineOptions = pipelineOptions + [\n+    kafkaTopic                   : 'beam-runnerv2',\n+    bigQueryTable                : 'kafkaioit_results_sdf_wrapper',\n+    influxMeasurement            : 'kafkaioit_results_sdf_wrapper',\n+    experiments                  : 'beam_fn_api,use_runner_v2,use_unified_worker',\n+  ]\n+\n+  Map runnerV2SdfPipelineOptions = pipelineOptions + [\n+    kafkaTopic                   : 'beam-sdf',\n+    bigQueryTable                : 'kafkaioit_results_runner_v2',\n+    influxMeasurement            : 'kafkaioit_results_runner_v2',\n+    experiments                  : 'beam_fn_api,use_runner_v2,use_unified_worker,use_sdf_kafka_read',\n+  ]\n+\n   steps {\n     gradle {\n       rootBuildScriptDir(common.checkoutDir)\n       common.setGradleSwitches(delegate)\n       switches(\"--info\")\n-      switches(\"-DintegrationTestPipelineOptions=\\'${common.joinOptionsWithNestedJsonValues(pipelineOptions)}\\'\")\n+      switches(\"-DintegrationTestPipelineOptions=\\'${common.joinOptionsWithNestedJsonValues(runnerV2SdfWrapperPipelineOptions)}\\'\")\n+      switches(\"-DintegrationTestRunner=dataflow\")\n+      switches(\"-Dexperiment=use_runner_v2\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cbdcd5a110bc2f38ddf014d8886154637fc89cb7"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDY3OTA0Mw==", "bodyText": "Why do we need this function? Is it possible to have a timestamp out of window bounds?", "url": "https://github.com/apache/beam/pull/13282#discussion_r520679043", "createdAt": "2020-11-10T16:03:33Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/ReadFromKafkaDoFn.java", "diffHunk": "@@ -407,4 +408,13 @@ public double getTotalSize(double numRecords) {\n       return avgRecordSize.get() * numRecords / (1 + avgRecordGap.get());\n     }\n   }\n+\n+  private static Instant ensureTimestampWithinBounds(Instant timestamp) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cbdcd5a110bc2f38ddf014d8886154637fc89cb7"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDY4MTQ4MQ==", "bodyText": "Why not to use metrics for counting?", "url": "https://github.com/apache/beam/pull/13282#discussion_r520681481", "createdAt": "2020-11-10T16:06:46Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/kafka/src/test/java/org/apache/beam/sdk/io/kafka/KafkaIOIT.java", "diffHunk": "@@ -115,6 +122,43 @@ public static void setup() throws IOException {\n             .get();\n   }\n \n+  @Test\n+  public void testKafkaIOWithRunnerV2() throws IOException {\n+    writePipeline\n+        .apply(\"Generate records\", Read.from(new SyntheticBoundedSource(sourceOptions)))\n+        .apply(\"Measure write time\", ParDo.of(new TimeMonitor<>(NAMESPACE, WRITE_TIME_METRIC_NAME)))\n+        .apply(\"Write to Kafka\", writeToKafka());\n+\n+    readPipeline.getOptions().as(Options.class).setStreaming(true);\n+    PCollection<Integer> elementCount =\n+        readPipeline\n+            .apply(\"Read from Runner V2 Kafka\", readFromKafka())\n+            .apply(\n+                \"Measure read time\", ParDo.of(new TimeMonitor<>(NAMESPACE, READ_TIME_METRIC_NAME)))\n+            .apply(\"Map records to strings\", MapElements.via(new MapKafkaRecordsToStrings()))\n+            .apply(\n+                \"Keyed by empty key\",\n+                MapElements.into(new TypeDescriptor<KV<byte[], String>>() {})\n+                    .via(element -> KV.of(new byte[0], element)))\n+            .apply(\n+                \"Counting elements\", ParDo.of(new CountingElementFn(options.getNumberOfRecords())));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cbdcd5a110bc2f38ddf014d8886154637fc89cb7"}, "originalPosition": 48}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3MzY4OTM2", "url": "https://github.com/apache/beam/pull/13282#pullrequestreview-527368936", "createdAt": "2020-11-10T16:14:29Z", "commit": {"oid": "cbdcd5a110bc2f38ddf014d8886154637fc89cb7"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "165c02648ff3216850dfba44d39124ac853e9ecb", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/165c02648ff3216850dfba44d39124ac853e9ecb", "committedDate": "2020-11-11T03:53:19Z", "message": "Update tests."}, "afterCommit": {"oid": "013a8784b6740bba589daa28cb3d1c4e4ac07937", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/013a8784b6740bba589daa28cb3d1c4e4ac07937", "committedDate": "2020-11-11T04:30:32Z", "message": "Update tests."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e722085bb3a8ebb943960edb790153515d9909a8", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/e722085bb3a8ebb943960edb790153515d9909a8", "committedDate": "2020-11-11T06:01:11Z", "message": "Update tests."}, "afterCommit": {"oid": "c8729f3589903700f3e266833e1ffc391cb7ec35", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/c8729f3589903700f3e266833e1ffc391cb7ec35", "committedDate": "2020-11-11T18:39:51Z", "message": "Update test setup"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI4NDkwODgy", "url": "https://github.com/apache/beam/pull/13282#pullrequestreview-528490882", "createdAt": "2020-11-11T19:57:39Z", "commit": {"oid": "c8729f3589903700f3e266833e1ffc391cb7ec35"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQxOTo1NzozOVrOHxcKvg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQyMDozNjo0OFrOHxdYBw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYwMzc3NA==", "bodyText": "Maybe including the word 'Dataflow' would be informative for these configs.", "url": "https://github.com/apache/beam/pull/13282#discussion_r521603774", "createdAt": "2020-11-11T19:57:39Z", "author": {"login": "tysonjh"}, "path": ".test-infra/jenkins/job_PerformanceTests_KafkaIO_IT.groovy", "diffHunk": "@@ -61,14 +61,60 @@ job(jobName) {\n     autoscalingAlgorithm         : 'NONE'\n   ]\n \n+  Map runnerV2SdfWrapperPipelineOptions = pipelineOptions + [", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c8729f3589903700f3e266833e1ffc391cb7ec35"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYxODkxOQ==", "bodyText": "Adding an 'experiment' flag here could be confused with the pipelineOptions experiment flag. Maybe instead of this, it would be better to inspect the pipelineOptions instead?", "url": "https://github.com/apache/beam/pull/13282#discussion_r521618919", "createdAt": "2020-11-11T20:27:31Z", "author": {"login": "tysonjh"}, "path": "buildSrc/src/main/groovy/org/apache/beam/gradle/BeamModulePlugin.groovy", "diffHunk": "@@ -233,6 +233,8 @@ class BeamModulePlugin implements Plugin<Project> {\n \n     // Required. Pipeline options to be used by the tested pipeline.\n     String integrationTestPipelineOptions = System.getProperty('integrationTestPipelineOptions')\n+\n+    String experiment = System.getProperty('experiment', '')", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c8729f3589903700f3e266833e1ffc391cb7ec35"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYyMzU1OQ==", "bodyText": "I'm not very familiar with this file, but it seems like we're now configuring runnerv2 tasks (e.g. cleanup tasks, building container images) based on various settings (e.g. pipelineOptions, the gradle 'experiment' flag) here and also in various build.gradle files.\nShould we be picking one over the other? For example, the PR you're reviewing of mine that contains IT tests for examples, configures the tests in the build.gradle file. It seems strikingly similar to what is going on here though.", "url": "https://github.com/apache/beam/pull/13282#discussion_r521623559", "createdAt": "2020-11-11T20:36:48Z", "author": {"login": "tysonjh"}, "path": "buildSrc/src/main/groovy/org/apache/beam/gradle/BeamModulePlugin.groovy", "diffHunk": "@@ -1442,7 +1447,7 @@ class BeamModulePlugin implements Plugin<Project> {\n       JavaPerformanceTestConfiguration configuration = it ? it as JavaPerformanceTestConfiguration : new JavaPerformanceTestConfiguration()\n \n       // Task for running integration tests\n-      project.task('integrationTest', type: Test) {\n+      def itTask = project.task('integrationTest', type: Test) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c8729f3589903700f3e266833e1ffc391cb7ec35"}, "originalPosition": 24}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI4NTQ1NDMy", "url": "https://github.com/apache/beam/pull/13282#pullrequestreview-528545432", "createdAt": "2020-11-11T21:24:44Z", "commit": {"oid": "c8729f3589903700f3e266833e1ffc391cb7ec35"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQyMToyNDo0NFrOHxe0tQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQyMToyNDo0NFrOHxe0tQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTY0NzI4NQ==", "bodyText": "Instead of naming the test after the runner, is it possible to name the test after the behavior that is being tested and use the configuration to ensure it runs on the appropriate runners? Is there a reason to have both this test and testKafkaReadsAndWritesProperly?\nIf so, it would be good to understand the difference through the test naming. From what I can tell the material difference is that this test uses a streaming pipeline to read where testKafkaReadsAndWritesProperly uses a batch one.", "url": "https://github.com/apache/beam/pull/13282#discussion_r521647285", "createdAt": "2020-11-11T21:24:44Z", "author": {"login": "tysonjh"}, "path": "sdks/java/io/kafka/src/test/java/org/apache/beam/sdk/io/kafka/KafkaIOIT.java", "diffHunk": "@@ -115,16 +116,55 @@ public static void setup() throws IOException {\n             .get();\n   }\n \n+  @Test\n+  public void testKafkaIOWithRunnerV2() throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c8729f3589903700f3e266833e1ffc391cb7ec35"}, "originalPosition": 53}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI4NjI1ODI2", "url": "https://github.com/apache/beam/pull/13282#pullrequestreview-528625826", "createdAt": "2020-11-11T23:44:10Z", "commit": {"oid": "ae9e4b9c567a1e6700b7b430f3ec0774df2fed0a"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ae9e4b9c567a1e6700b7b430f3ec0774df2fed0a", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/ae9e4b9c567a1e6700b7b430f3ec0774df2fed0a", "committedDate": "2020-11-11T23:26:23Z", "message": "Address comments"}, "afterCommit": {"oid": "d32629a17b3cda161f6be81459f6749a6d64499e", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/d32629a17b3cda161f6be81459f6749a6d64499e", "committedDate": "2020-11-12T01:06:55Z", "message": "Enable KafkaIO performance test for runner v2 with SDF."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI5MTkyMjE1", "url": "https://github.com/apache/beam/pull/13282#pullrequestreview-529192215", "createdAt": "2020-11-12T15:18:23Z", "commit": {"oid": "d32629a17b3cda161f6be81459f6749a6d64499e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxNToxODoyM1rOHx_qCQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxNToxODoyM1rOHx_qCQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjE4NTIyNQ==", "bodyText": "nit: Please, remove \"Runner V2\"", "url": "https://github.com/apache/beam/pull/13282#discussion_r522185225", "createdAt": "2020-11-12T15:18:23Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/kafka/src/test/java/org/apache/beam/sdk/io/kafka/KafkaIOIT.java", "diffHunk": "@@ -116,15 +117,54 @@ public static void setup() throws IOException {\n   }\n \n   @Test\n-  public void testKafkaIOReadsAndWritesCorrectly() throws IOException {\n+  public void testKafkaIOReadsAndWritesCorrectlyInStreaming() throws IOException {\n+    // Use batch pipeline to write records.\n+    writePipeline\n+        .apply(\"Generate records\", Read.from(new SyntheticBoundedSource(sourceOptions)))\n+        .apply(\"Measure write time\", ParDo.of(new TimeMonitor<>(NAMESPACE, WRITE_TIME_METRIC_NAME)))\n+        .apply(\"Write to Kafka\", writeToKafka());\n+\n+    // Use streaming pipeline to read Kafka records.\n+    readPipeline.getOptions().as(Options.class).setStreaming(true);\n+    readPipeline\n+        .apply(\"Read from Runner V2 Kafka\", readFromKafka())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d32629a17b3cda161f6be81459f6749a6d64499e"}, "originalPosition": 63}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "730e7c064a878facbb6b5d3560445d2c513742ae", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/730e7c064a878facbb6b5d3560445d2c513742ae", "committedDate": "2020-11-12T19:13:49Z", "message": "[BEAM-11172] Enable KafkaIO performance test for runner v2 with SDF."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d32629a17b3cda161f6be81459f6749a6d64499e", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/d32629a17b3cda161f6be81459f6749a6d64499e", "committedDate": "2020-11-12T01:06:55Z", "message": "Enable KafkaIO performance test for runner v2 with SDF."}, "afterCommit": {"oid": "730e7c064a878facbb6b5d3560445d2c513742ae", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/730e7c064a878facbb6b5d3560445d2c513742ae", "committedDate": "2020-11-12T19:13:49Z", "message": "[BEAM-11172] Enable KafkaIO performance test for runner v2 with SDF."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI5OTkyMTg3", "url": "https://github.com/apache/beam/pull/13282#pullrequestreview-529992187", "createdAt": "2020-11-13T11:39:11Z", "commit": {"oid": "730e7c064a878facbb6b5d3560445d2c513742ae"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4725, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}