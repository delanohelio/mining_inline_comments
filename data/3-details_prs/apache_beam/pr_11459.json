{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDA1NDIzMzE4", "number": 11459, "title": "[BEAM-2546] Add InfluxDbIO", "bodyText": "Please add a meaningful description for your change here\n\nThank you for your contribution! Follow this checklist to help us incorporate your contribution quickly and easily:\n\n Choose reviewer(s) and mention them in a comment (R: @iemejia ).\n Format the pull request title like [BEAM-XXX] Fixes bug in ApproximateQuantiles, where you replace BEAM-XXX with the appropriate JIRA issue, if applicable. This will automatically link the pull request to the issue.\n Update CHANGES.md with noteworthy changes.\n If this contribution is large, please file an Apache Individual Contributor License Agreement.\n\nSee the Contributor Guide for more tips on how to make review process smoother.\nPost-Commit Tests Status (on master branch)\n\n\n\nLang\nSDK\nApex\nDataflow\nFlink\nGearpump\nSamza\nSpark\n\n\n\n\nGo\n\n---\n---\n\n---\n---\n\n\n\nJava\n\n\n\n\n\n\n\n\n\nPython\n\n---\n\n\n---\n---\n\n\n\nXLang\n---\n---\n---\n\n---\n---\n\n\n\n\nPre-Commit Tests Status (on master branch)\n\n\n\n---\nJava\nPython\nGo\nWebsite\n\n\n\n\nNon-portable\n\n\n\n\n\n\nPortable\n---\n\n---\n---\n\n\n\nSee .test-infra/jenkins/README for trigger phrase, status and link of all Jenkins jobs.", "createdAt": "2020-04-18T01:21:14Z", "url": "https://github.com/apache/beam/pull/11459", "merged": true, "mergeCommit": {"oid": "d2e03ed47385dd07ffa42a282785fdc8bd099ed0"}, "closed": true, "closedAt": "2020-09-22T15:42:37Z", "author": {"login": "bipinupd"}, "timelineItems": {"totalCount": 37, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcxWlFFgFqTQ0MjQzNTI3OQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdLHOdiAFqTQ5Mjg1MTk5MA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQyNDM1Mjc5", "url": "https://github.com/apache/beam/pull/11459#pullrequestreview-442435279", "createdAt": "2020-07-03T14:05:16Z", "commit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 26, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNDowNToxN1rOGsxb1Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNjo1NzozMlrOGs1EwA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYwMDQ2OQ==", "bodyText": "Please, extract it as entity of project.ext.library in BeamModulePlugin.groovy", "url": "https://github.com/apache/beam/pull/11459#discussion_r449600469", "createdAt": "2020-07-03T14:05:17Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/build.gradle", "diffHunk": "@@ -0,0 +1,34 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one\n+* or more contributor license agreements.  See the NOTICE file\n+* distributed with this work for additional information\n+* regarding copyright ownership.  The ASF licenses this file\n+* to you under the Apache License, Version 2.0 (the\n+* License); you may not use this file except in compliance\n+* with the License.  You may obtain a copy of the License at\n+*\n+*     http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an AS IS BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+ \n+plugins { id 'org.apache.beam.module' }\n+applyJavaNature(automaticModuleName: 'org.apache.beam.sdk.io.influxdb')\n+provideIntegrationTestingDependencies()\n+enableJavaPerformanceTesting()\n+\n+description = \"Apache Beam :: SDKs :: Java :: IO :: InfluxDB\"\n+ext.summary = \"IO to read and write on InfluxDB\"\n+\n+dependencies {\n+  compile project(path: \":sdks:java:core\", configuration: \"shadow\")\n+  compile 'org.influxdb:influxdb-java:2.17'", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYwMTEwOQ==", "bodyText": "testRuntimeOnly project(path: \":runners:direct-java\", configuration: \"shadow\")", "url": "https://github.com/apache/beam/pull/11459#discussion_r449601109", "createdAt": "2020-07-03T14:06:43Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/build.gradle", "diffHunk": "@@ -0,0 +1,34 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one\n+* or more contributor license agreements.  See the NOTICE file\n+* distributed with this work for additional information\n+* regarding copyright ownership.  The ASF licenses this file\n+* to you under the Apache License, Version 2.0 (the\n+* License); you may not use this file except in compliance\n+* with the License.  You may obtain a copy of the License at\n+*\n+*     http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an AS IS BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+ \n+plugins { id 'org.apache.beam.module' }\n+applyJavaNature(automaticModuleName: 'org.apache.beam.sdk.io.influxdb')\n+provideIntegrationTestingDependencies()\n+enableJavaPerformanceTesting()\n+\n+description = \"Apache Beam :: SDKs :: Java :: IO :: InfluxDB\"\n+ext.summary = \"IO to read and write on InfluxDB\"\n+\n+dependencies {\n+  compile project(path: \":sdks:java:core\", configuration: \"shadow\")\n+  compile 'org.influxdb:influxdb-java:2.17'\n+  testCompile library.java.junit\n+  testRuntimeOnly project(\":runners:direct-java\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYwMjc4Ng==", "bodyText": "I don't think it's needed. Please, remove", "url": "https://github.com/apache/beam/pull/11459#discussion_r449602786", "createdAt": "2020-07-03T14:10:21Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/build.gradle", "diffHunk": "@@ -0,0 +1,34 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one\n+* or more contributor license agreements.  See the NOTICE file\n+* distributed with this work for additional information\n+* regarding copyright ownership.  The ASF licenses this file\n+* to you under the Apache License, Version 2.0 (the\n+* License); you may not use this file except in compliance\n+* with the License.  You may obtain a copy of the License at\n+*\n+*     http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an AS IS BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+ \n+plugins { id 'org.apache.beam.module' }\n+applyJavaNature(automaticModuleName: 'org.apache.beam.sdk.io.influxdb')\n+provideIntegrationTestingDependencies()\n+enableJavaPerformanceTesting()\n+\n+description = \"Apache Beam :: SDKs :: Java :: IO :: InfluxDB\"\n+ext.summary = \"IO to read and write on InfluxDB\"\n+\n+dependencies {\n+  compile project(path: \":sdks:java:core\", configuration: \"shadow\")\n+  compile 'org.influxdb:influxdb-java:2.17'\n+  testCompile library.java.junit\n+  testRuntimeOnly project(\":runners:direct-java\")\n+  testCompile group: 'org.apache.beam', name: 'beam-runners-direct-java', version: '2.15.0'", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYwMzEzMA==", "bodyText": "Add class Javadoc and remove public", "url": "https://github.com/apache/beam/pull/11459#discussion_r449603130", "createdAt": "2020-07-03T14:11:05Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/DBShardInformation.java", "diffHunk": "@@ -0,0 +1,48 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.influxdb.dto.QueryResult.Series;\n+\n+public class DBShardInformation {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYwMzMwNw==", "bodyText": "Please, add class Javadoc", "url": "https://github.com/apache/beam/pull/11459#discussion_r449603307", "createdAt": "2020-07-03T14:11:31Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/LineProtocolConvertable.java", "diffHunk": "@@ -0,0 +1,22 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+public interface LineProtocolConvertable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYwMzM2Mw==", "bodyText": "Please, add class Javadoc", "url": "https://github.com/apache/beam/pull/11459#discussion_r449603363", "createdAt": "2020-07-03T14:11:40Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/ShardInformation.java", "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import java.util.List;\n+import java.util.Objects;\n+import org.joda.time.DateTime;\n+\n+public class ShardInformation implements Comparable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYwNTUwMQ==", "bodyText": "Please, rename the class name to InfluxDbIO to be compatible with other IOs, like MongoDbIO", "url": "https://github.com/apache/beam/pull/11459#discussion_r449605501", "createdAt": "2020-07-03T14:16:37Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 127}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYwNjg0Mw==", "bodyText": "nit: \"You have ...\"", "url": "https://github.com/apache/beam/pull/11459#discussion_r449606843", "createdAt": "2020-07-03T14:19:42Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYxMzcwMA==", "bodyText": "Is it a blocking operation?", "url": "https://github.com/apache/beam/pull/11459#discussion_r449613700", "createdAt": "2020-07-03T14:35:50Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueItr = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (noOfBlocksValueItr.hasNext() && sizeOfBlocksValueItr.hasNext()) {\n+        size = size + (noOfBlocksValueItr.next() * sizeOfBlocksValueItr.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    if (spec.query() == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        return String.format(\n+            \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+            spec.retentionPolicy(),\n+            String.join(\",\", spec.metrics()),\n+            spec.toDateTime(),\n+            spec.fromDateTime());\n+      } else {\n+        return String.format(\n+            \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+      }\n+    }\n+    return spec.query();\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDBIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List current;\n+\n+    public BoundedInfluxDbReader(InfluxDBIO.InfluxDBSource source) {\n+      this.source = source;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDBIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        if (spec.database() != null) {\n+          influxDB.setDatabase(spec.database());\n+        }\n+        if (spec.retentionPolicy() != null) {\n+          influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        }\n+        String query = getQueryToRun(spec);\n+        QueryResult queryResult = influxDB.query(new Query(query, spec.database()));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          seriesIterator = resultIterator.next().getSeries().iterator();\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkArgument(dataSourceConfiguration() != null, \"withConfiguration() is required\");\n+      checkArgument(database() != null && !database().isEmpty(), \"withDatabase() is required\");\n+      checkArgument(\n+          checkDatabase(\n+              database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+      builder.addIfNotNull(DisplayData.item(\"noOfElementsToBatch\", noOfElementsToBatch()));\n+      builder.addIfNotNull(DisplayData.item(\"flushDuration\", flushDuration()));\n+    }\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String retentionPolicy();\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract boolean sslEnabled();\n+\n+    abstract int noOfElementsToBatch();\n+\n+    abstract int flushDuration();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setNoOfElementsToBatch(int noOfElementsToBatch);\n+\n+      abstract Builder setFlushDuration(int flushDuration);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Write build();\n+    }\n+\n+    public Write withConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    public Write withDatabase(String database) {\n+      return builder().setDatabase(database).build();\n+    }\n+\n+    public Write withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Write withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Write withNoOfElementsToBatch(int noOfElementsToBatch) {\n+      return builder().setNoOfElementsToBatch(noOfElementsToBatch).build();\n+    }\n+\n+    public Write withFlushDuration(int flushDuration) {\n+      return builder().setFlushDuration(flushDuration).build();\n+    }\n+\n+    public Write withRetentionPolicy(String rp) {\n+      return builder().setRetentionPolicy(rp).build();\n+    }\n+\n+    private class InfluxWriterFn<T> extends DoFn<T, Void> {\n+\n+      private final Write spec;\n+      private InfluxDB connection;\n+\n+      InfluxWriterFn(Write write) {\n+        this.spec = write;\n+      }\n+\n+      @Setup\n+      public void setup() {\n+        connection =\n+            getConnection(\n+                spec.dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled());\n+        int flushDuration = spec.flushDuration();\n+        int noOfBatchPoints = spec.noOfElementsToBatch();\n+        connection.enableBatch(\n+            BatchOptions.DEFAULTS.actions(noOfBatchPoints).flushDuration(flushDuration));\n+        connection.setRetentionPolicy(spec.retentionPolicy());\n+        connection.setDatabase(spec.database());\n+      }\n+\n+      @ProcessElement\n+      public void processElement(ProcessContext c) {\n+        connection.write(c.element().toString());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 598}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY0MTE2MQ==", "bodyText": "Would it make sense to take as input a PCollection of LineProtocolConvertable (instead of just String) or create own wrapper class, something like InfluxDbRecord implements LineProtocolConvertable?", "url": "https://github.com/apache/beam/pull/11459#discussion_r449641161", "createdAt": "2020-07-03T15:47:37Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueItr = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (noOfBlocksValueItr.hasNext() && sizeOfBlocksValueItr.hasNext()) {\n+        size = size + (noOfBlocksValueItr.next() * sizeOfBlocksValueItr.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    if (spec.query() == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        return String.format(\n+            \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+            spec.retentionPolicy(),\n+            String.join(\",\", spec.metrics()),\n+            spec.toDateTime(),\n+            spec.fromDateTime());\n+      } else {\n+        return String.format(\n+            \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+      }\n+    }\n+    return spec.query();\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDBIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List current;\n+\n+    public BoundedInfluxDbReader(InfluxDBIO.InfluxDBSource source) {\n+      this.source = source;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDBIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        if (spec.database() != null) {\n+          influxDB.setDatabase(spec.database());\n+        }\n+        if (spec.retentionPolicy() != null) {\n+          influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        }\n+        String query = getQueryToRun(spec);\n+        QueryResult queryResult = influxDB.query(new Query(query, spec.database()));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          seriesIterator = resultIterator.next().getSeries().iterator();\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 478}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY0MTgyMA==", "bodyText": "What is a case when user would need to set it to true? It could be potential security issue.", "url": "https://github.com/apache/beam/pull/11459#discussion_r449641820", "createdAt": "2020-07-03T15:49:41Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 251}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1MTk1Mw==", "bodyText": "This class can be package-private.", "url": "https://github.com/apache/beam/pull/11459#discussion_r449651953", "createdAt": "2020-07-03T16:24:18Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/DBShardInformation.java", "diffHunk": "@@ -0,0 +1,48 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.influxdb.dto.QueryResult.Series;\n+\n+public class DBShardInformation {\n+\n+  private Map<String, List<ShardInformation>> shardInformation = new HashMap<>();\n+\n+  public DBShardInformation() {}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1MjkxMg==", "bodyText": "nit: checkState", "url": "https://github.com/apache/beam/pull/11459#discussion_r449652912", "createdAt": "2020-07-03T16:28:09Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 268}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1MzIxOQ==", "bodyText": "nit: numOfBlocksValue", "url": "https://github.com/apache/beam/pull/11459#discussion_r449653219", "createdAt": "2020-07-03T16:29:34Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 302}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1Mzc4Mw==", "bodyText": "How big this result can be in terms of amount of returned data?", "url": "https://github.com/apache/beam/pull/11459#discussion_r449653783", "createdAt": "2020-07-03T16:31:43Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 316}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1NDgyMw==", "bodyText": "nit: numOfBlocks", "url": "https://github.com/apache/beam/pull/11459#discussion_r449654823", "createdAt": "2020-07-03T16:35:57Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 300}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1NjI0MA==", "bodyText": "nit: numOfBlocksValueIterator", "url": "https://github.com/apache/beam/pull/11459#discussion_r449656240", "createdAt": "2020-07-03T16:41:27Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 332}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1NjMzNQ==", "bodyText": "nit: sizeOfBlocksValueIterator", "url": "https://github.com/apache/beam/pull/11459#discussion_r449656335", "createdAt": "2020-07-03T16:41:48Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueItr = sizeOfBlocksValue.iterator();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 333}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1Njk1OQ==", "bodyText": "It's not possible to split with query?", "url": "https://github.com/apache/beam/pull/11459#discussion_r449656959", "createdAt": "2020-07-03T16:44:19Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueItr = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (noOfBlocksValueItr.hasNext() && sizeOfBlocksValueItr.hasNext()) {\n+        size = size + (noOfBlocksValueItr.next() * sizeOfBlocksValueItr.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 363}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1NzgwOQ==", "bodyText": "Is it needed to allow user to configure this? Can we set just sufficient default value?", "url": "https://github.com/apache/beam/pull/11459#discussion_r449657809", "createdAt": "2020-07-03T16:47:42Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueItr = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (noOfBlocksValueItr.hasNext() && sizeOfBlocksValueItr.hasNext()) {\n+        size = size + (noOfBlocksValueItr.next() * sizeOfBlocksValueItr.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    if (spec.query() == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        return String.format(\n+            \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+            spec.retentionPolicy(),\n+            String.join(\",\", spec.metrics()),\n+            spec.toDateTime(),\n+            spec.fromDateTime());\n+      } else {\n+        return String.format(\n+            \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+      }\n+    }\n+    return spec.query();\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDBIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List current;\n+\n+    public BoundedInfluxDbReader(InfluxDBIO.InfluxDBSource source) {\n+      this.source = source;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDBIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        if (spec.database() != null) {\n+          influxDB.setDatabase(spec.database());\n+        }\n+        if (spec.retentionPolicy() != null) {\n+          influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        }\n+        String query = getQueryToRun(spec);\n+        QueryResult queryResult = influxDB.query(new Query(query, spec.database()));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          seriesIterator = resultIterator.next().getSeries().iterator();\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkArgument(dataSourceConfiguration() != null, \"withConfiguration() is required\");\n+      checkArgument(database() != null && !database().isEmpty(), \"withDatabase() is required\");\n+      checkArgument(\n+          checkDatabase(\n+              database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+      builder.addIfNotNull(DisplayData.item(\"noOfElementsToBatch\", noOfElementsToBatch()));\n+      builder.addIfNotNull(DisplayData.item(\"flushDuration\", flushDuration()));\n+    }\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String retentionPolicy();\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract boolean sslEnabled();\n+\n+    abstract int noOfElementsToBatch();\n+\n+    abstract int flushDuration();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setNoOfElementsToBatch(int noOfElementsToBatch);\n+\n+      abstract Builder setFlushDuration(int flushDuration);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Write build();\n+    }\n+\n+    public Write withConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    public Write withDatabase(String database) {\n+      return builder().setDatabase(database).build();\n+    }\n+\n+    public Write withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Write withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Write withNoOfElementsToBatch(int noOfElementsToBatch) {\n+      return builder().setNoOfElementsToBatch(noOfElementsToBatch).build();\n+    }\n+\n+    public Write withFlushDuration(int flushDuration) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 566}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1NzkxNQ==", "bodyText": "nit: numOfElementsToBatch", "url": "https://github.com/apache/beam/pull/11459#discussion_r449657915", "createdAt": "2020-07-03T16:48:12Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueItr = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (noOfBlocksValueItr.hasNext() && sizeOfBlocksValueItr.hasNext()) {\n+        size = size + (noOfBlocksValueItr.next() * sizeOfBlocksValueItr.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    if (spec.query() == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        return String.format(\n+            \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+            spec.retentionPolicy(),\n+            String.join(\",\", spec.metrics()),\n+            spec.toDateTime(),\n+            spec.fromDateTime());\n+      } else {\n+        return String.format(\n+            \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+      }\n+    }\n+    return spec.query();\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDBIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List current;\n+\n+    public BoundedInfluxDbReader(InfluxDBIO.InfluxDBSource source) {\n+      this.source = source;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDBIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        if (spec.database() != null) {\n+          influxDB.setDatabase(spec.database());\n+        }\n+        if (spec.retentionPolicy() != null) {\n+          influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        }\n+        String query = getQueryToRun(spec);\n+        QueryResult queryResult = influxDB.query(new Query(query, spec.database()));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          seriesIterator = resultIterator.next().getSeries().iterator();\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkArgument(dataSourceConfiguration() != null, \"withConfiguration() is required\");\n+      checkArgument(database() != null && !database().isEmpty(), \"withDatabase() is required\");\n+      checkArgument(\n+          checkDatabase(\n+              database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+      builder.addIfNotNull(DisplayData.item(\"noOfElementsToBatch\", noOfElementsToBatch()));\n+      builder.addIfNotNull(DisplayData.item(\"flushDuration\", flushDuration()));\n+    }\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String retentionPolicy();\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract boolean sslEnabled();\n+\n+    abstract int noOfElementsToBatch();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 517}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1ODE5OA==", "bodyText": "What is a reason to have unsafe https client?", "url": "https://github.com/apache/beam/pull/11459#discussion_r449658198", "createdAt": "2020-07-03T16:49:26Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueItr = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (noOfBlocksValueItr.hasNext() && sizeOfBlocksValueItr.hasNext()) {\n+        size = size + (noOfBlocksValueItr.next() * sizeOfBlocksValueItr.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    if (spec.query() == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        return String.format(\n+            \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+            spec.retentionPolicy(),\n+            String.join(\",\", spec.metrics()),\n+            spec.toDateTime(),\n+            spec.fromDateTime());\n+      } else {\n+        return String.format(\n+            \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+      }\n+    }\n+    return spec.query();\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDBIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List current;\n+\n+    public BoundedInfluxDbReader(InfluxDBIO.InfluxDBSource source) {\n+      this.source = source;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDBIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        if (spec.database() != null) {\n+          influxDB.setDatabase(spec.database());\n+        }\n+        if (spec.retentionPolicy() != null) {\n+          influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        }\n+        String query = getQueryToRun(spec);\n+        QueryResult queryResult = influxDB.query(new Query(query, spec.database()));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          seriesIterator = resultIterator.next().getSeries().iterator();\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkArgument(dataSourceConfiguration() != null, \"withConfiguration() is required\");\n+      checkArgument(database() != null && !database().isEmpty(), \"withDatabase() is required\");\n+      checkArgument(\n+          checkDatabase(\n+              database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+      builder.addIfNotNull(DisplayData.item(\"noOfElementsToBatch\", noOfElementsToBatch()));\n+      builder.addIfNotNull(DisplayData.item(\"flushDuration\", flushDuration()));\n+    }\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String retentionPolicy();\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract boolean sslEnabled();\n+\n+    abstract int noOfElementsToBatch();\n+\n+    abstract int flushDuration();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setNoOfElementsToBatch(int noOfElementsToBatch);\n+\n+      abstract Builder setFlushDuration(int flushDuration);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Write build();\n+    }\n+\n+    public Write withConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    public Write withDatabase(String database) {\n+      return builder().setDatabase(database).build();\n+    }\n+\n+    public Write withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Write withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Write withNoOfElementsToBatch(int noOfElementsToBatch) {\n+      return builder().setNoOfElementsToBatch(noOfElementsToBatch).build();\n+    }\n+\n+    public Write withFlushDuration(int flushDuration) {\n+      return builder().setFlushDuration(flushDuration).build();\n+    }\n+\n+    public Write withRetentionPolicy(String rp) {\n+      return builder().setRetentionPolicy(rp).build();\n+    }\n+\n+    private class InfluxWriterFn<T> extends DoFn<T, Void> {\n+\n+      private final Write spec;\n+      private InfluxDB connection;\n+\n+      InfluxWriterFn(Write write) {\n+        this.spec = write;\n+      }\n+\n+      @Setup\n+      public void setup() {\n+        connection =\n+            getConnection(\n+                spec.dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled());\n+        int flushDuration = spec.flushDuration();\n+        int noOfBatchPoints = spec.noOfElementsToBatch();\n+        connection.enableBatch(\n+            BatchOptions.DEFAULTS.actions(noOfBatchPoints).flushDuration(flushDuration));\n+        connection.setRetentionPolicy(spec.retentionPolicy());\n+        connection.setDatabase(spec.database());\n+      }\n+\n+      @ProcessElement\n+      public void processElement(ProcessContext c) {\n+        connection.write(c.element().toString());\n+      }\n+\n+      @FinishBundle\n+      public void finishBundle() {\n+        connection.flush();\n+      }\n+\n+      @Teardown\n+      public void tearDown() {\n+        if (connection != null) {\n+          connection.flush();\n+          connection.close();\n+          connection = null;\n+        }\n+      }\n+\n+      @Override\n+      public void populateDisplayData(DisplayData.Builder builder) {\n+        builder.delegate(Write.this);\n+      }\n+    }\n+  }\n+\n+  private static OkHttpClient.Builder getUnsafeOkHttpClient() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 622}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1ODI0Ng==", "bodyText": "Is it needed to allow user to configure this? Can we set just sufficient default value?", "url": "https://github.com/apache/beam/pull/11459#discussion_r449658246", "createdAt": "2020-07-03T16:49:41Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueItr = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (noOfBlocksValueItr.hasNext() && sizeOfBlocksValueItr.hasNext()) {\n+        size = size + (noOfBlocksValueItr.next() * sizeOfBlocksValueItr.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    if (spec.query() == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        return String.format(\n+            \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+            spec.retentionPolicy(),\n+            String.join(\",\", spec.metrics()),\n+            spec.toDateTime(),\n+            spec.fromDateTime());\n+      } else {\n+        return String.format(\n+            \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+      }\n+    }\n+    return spec.query();\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDBIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List current;\n+\n+    public BoundedInfluxDbReader(InfluxDBIO.InfluxDBSource source) {\n+      this.source = source;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDBIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        if (spec.database() != null) {\n+          influxDB.setDatabase(spec.database());\n+        }\n+        if (spec.retentionPolicy() != null) {\n+          influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        }\n+        String query = getQueryToRun(spec);\n+        QueryResult queryResult = influxDB.query(new Query(query, spec.database()));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          seriesIterator = resultIterator.next().getSeries().iterator();\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkArgument(dataSourceConfiguration() != null, \"withConfiguration() is required\");\n+      checkArgument(database() != null && !database().isEmpty(), \"withDatabase() is required\");\n+      checkArgument(\n+          checkDatabase(\n+              database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+      builder.addIfNotNull(DisplayData.item(\"noOfElementsToBatch\", noOfElementsToBatch()));\n+      builder.addIfNotNull(DisplayData.item(\"flushDuration\", flushDuration()));\n+    }\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String retentionPolicy();\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract boolean sslEnabled();\n+\n+    abstract int noOfElementsToBatch();\n+\n+    abstract int flushDuration();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setNoOfElementsToBatch(int noOfElementsToBatch);\n+\n+      abstract Builder setFlushDuration(int flushDuration);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Write build();\n+    }\n+\n+    public Write withConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    public Write withDatabase(String database) {\n+      return builder().setDatabase(database).build();\n+    }\n+\n+    public Write withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Write withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Write withNoOfElementsToBatch(int noOfElementsToBatch) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 562}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1ODM4OQ==", "bodyText": "nit: numOfBatchPoints", "url": "https://github.com/apache/beam/pull/11459#discussion_r449658389", "createdAt": "2020-07-03T16:50:17Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueItr = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (noOfBlocksValueItr.hasNext() && sizeOfBlocksValueItr.hasNext()) {\n+        size = size + (noOfBlocksValueItr.next() * sizeOfBlocksValueItr.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    if (spec.query() == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        return String.format(\n+            \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+            spec.retentionPolicy(),\n+            String.join(\",\", spec.metrics()),\n+            spec.toDateTime(),\n+            spec.fromDateTime());\n+      } else {\n+        return String.format(\n+            \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+      }\n+    }\n+    return spec.query();\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDBIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List current;\n+\n+    public BoundedInfluxDbReader(InfluxDBIO.InfluxDBSource source) {\n+      this.source = source;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDBIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        if (spec.database() != null) {\n+          influxDB.setDatabase(spec.database());\n+        }\n+        if (spec.retentionPolicy() != null) {\n+          influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        }\n+        String query = getQueryToRun(spec);\n+        QueryResult queryResult = influxDB.query(new Query(query, spec.database()));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          seriesIterator = resultIterator.next().getSeries().iterator();\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkArgument(dataSourceConfiguration() != null, \"withConfiguration() is required\");\n+      checkArgument(database() != null && !database().isEmpty(), \"withDatabase() is required\");\n+      checkArgument(\n+          checkDatabase(\n+              database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+      builder.addIfNotNull(DisplayData.item(\"noOfElementsToBatch\", noOfElementsToBatch()));\n+      builder.addIfNotNull(DisplayData.item(\"flushDuration\", flushDuration()));\n+    }\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String retentionPolicy();\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract boolean sslEnabled();\n+\n+    abstract int noOfElementsToBatch();\n+\n+    abstract int flushDuration();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setNoOfElementsToBatch(int noOfElementsToBatch);\n+\n+      abstract Builder setFlushDuration(int flushDuration);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Write build();\n+    }\n+\n+    public Write withConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    public Write withDatabase(String database) {\n+      return builder().setDatabase(database).build();\n+    }\n+\n+    public Write withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Write withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Write withNoOfElementsToBatch(int noOfElementsToBatch) {\n+      return builder().setNoOfElementsToBatch(noOfElementsToBatch).build();\n+    }\n+\n+    public Write withFlushDuration(int flushDuration) {\n+      return builder().setFlushDuration(flushDuration).build();\n+    }\n+\n+    public Write withRetentionPolicy(String rp) {\n+      return builder().setRetentionPolicy(rp).build();\n+    }\n+\n+    private class InfluxWriterFn<T> extends DoFn<T, Void> {\n+\n+      private final Write spec;\n+      private InfluxDB connection;\n+\n+      InfluxWriterFn(Write write) {\n+        this.spec = write;\n+      }\n+\n+      @Setup\n+      public void setup() {\n+        connection =\n+            getConnection(\n+                spec.dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled());\n+        int flushDuration = spec.flushDuration();\n+        int noOfBatchPoints = spec.noOfElementsToBatch();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 589}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1OTE0Mg==", "bodyText": "If InfluxDB  is not serialisable then it should be transient.", "url": "https://github.com/apache/beam/pull/11459#discussion_r449659142", "createdAt": "2020-07-03T16:53:31Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueItr = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (noOfBlocksValueItr.hasNext() && sizeOfBlocksValueItr.hasNext()) {\n+        size = size + (noOfBlocksValueItr.next() * sizeOfBlocksValueItr.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    if (spec.query() == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        return String.format(\n+            \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+            spec.retentionPolicy(),\n+            String.join(\",\", spec.metrics()),\n+            spec.toDateTime(),\n+            spec.fromDateTime());\n+      } else {\n+        return String.format(\n+            \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+      }\n+    }\n+    return spec.query();\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDBIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List current;\n+\n+    public BoundedInfluxDbReader(InfluxDBIO.InfluxDBSource source) {\n+      this.source = source;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDBIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        if (spec.database() != null) {\n+          influxDB.setDatabase(spec.database());\n+        }\n+        if (spec.retentionPolicy() != null) {\n+          influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        }\n+        String query = getQueryToRun(spec);\n+        QueryResult queryResult = influxDB.query(new Query(query, spec.database()));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          seriesIterator = resultIterator.next().getSeries().iterator();\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkArgument(dataSourceConfiguration() != null, \"withConfiguration() is required\");\n+      checkArgument(database() != null && !database().isEmpty(), \"withDatabase() is required\");\n+      checkArgument(\n+          checkDatabase(\n+              database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+      builder.addIfNotNull(DisplayData.item(\"noOfElementsToBatch\", noOfElementsToBatch()));\n+      builder.addIfNotNull(DisplayData.item(\"flushDuration\", flushDuration()));\n+    }\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String retentionPolicy();\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract boolean sslEnabled();\n+\n+    abstract int noOfElementsToBatch();\n+\n+    abstract int flushDuration();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setNoOfElementsToBatch(int noOfElementsToBatch);\n+\n+      abstract Builder setFlushDuration(int flushDuration);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Write build();\n+    }\n+\n+    public Write withConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    public Write withDatabase(String database) {\n+      return builder().setDatabase(database).build();\n+    }\n+\n+    public Write withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Write withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Write withNoOfElementsToBatch(int noOfElementsToBatch) {\n+      return builder().setNoOfElementsToBatch(noOfElementsToBatch).build();\n+    }\n+\n+    public Write withFlushDuration(int flushDuration) {\n+      return builder().setFlushDuration(flushDuration).build();\n+    }\n+\n+    public Write withRetentionPolicy(String rp) {\n+      return builder().setRetentionPolicy(rp).build();\n+    }\n+\n+    private class InfluxWriterFn<T> extends DoFn<T, Void> {\n+\n+      private final Write spec;\n+      private InfluxDB connection;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 577}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY2MDA5Ng==", "bodyText": "Do we need to handle for every connection.query() an empty result  (if possible) or any exceptions if they can happen?", "url": "https://github.com/apache/beam/pull/11459#discussion_r449660096", "createdAt": "2020-07-03T16:57:32Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueItr = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (noOfBlocksValueItr.hasNext() && sizeOfBlocksValueItr.hasNext()) {\n+        size = size + (noOfBlocksValueItr.next() * sizeOfBlocksValueItr.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    if (spec.query() == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        return String.format(\n+            \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+            spec.retentionPolicy(),\n+            String.join(\",\", spec.metrics()),\n+            spec.toDateTime(),\n+            spec.fromDateTime());\n+      } else {\n+        return String.format(\n+            \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+      }\n+    }\n+    return spec.query();\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDBIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List current;\n+\n+    public BoundedInfluxDbReader(InfluxDBIO.InfluxDBSource source) {\n+      this.source = source;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDBIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        if (spec.database() != null) {\n+          influxDB.setDatabase(spec.database());\n+        }\n+        if (spec.retentionPolicy() != null) {\n+          influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        }\n+        String query = getQueryToRun(spec);\n+        QueryResult queryResult = influxDB.query(new Query(query, spec.database()));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          seriesIterator = resultIterator.next().getSeries().iterator();\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkArgument(dataSourceConfiguration() != null, \"withConfiguration() is required\");\n+      checkArgument(database() != null && !database().isEmpty(), \"withDatabase() is required\");\n+      checkArgument(\n+          checkDatabase(\n+              database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+      builder.addIfNotNull(DisplayData.item(\"noOfElementsToBatch\", noOfElementsToBatch()));\n+      builder.addIfNotNull(DisplayData.item(\"flushDuration\", flushDuration()));\n+    }\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String retentionPolicy();\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract boolean sslEnabled();\n+\n+    abstract int noOfElementsToBatch();\n+\n+    abstract int flushDuration();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setNoOfElementsToBatch(int noOfElementsToBatch);\n+\n+      abstract Builder setFlushDuration(int flushDuration);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Write build();\n+    }\n+\n+    public Write withConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    public Write withDatabase(String database) {\n+      return builder().setDatabase(database).build();\n+    }\n+\n+    public Write withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Write withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Write withNoOfElementsToBatch(int noOfElementsToBatch) {\n+      return builder().setNoOfElementsToBatch(noOfElementsToBatch).build();\n+    }\n+\n+    public Write withFlushDuration(int flushDuration) {\n+      return builder().setFlushDuration(flushDuration).build();\n+    }\n+\n+    public Write withRetentionPolicy(String rp) {\n+      return builder().setRetentionPolicy(rp).build();\n+    }\n+\n+    private class InfluxWriterFn<T> extends DoFn<T, Void> {\n+\n+      private final Write spec;\n+      private InfluxDB connection;\n+\n+      InfluxWriterFn(Write write) {\n+        this.spec = write;\n+      }\n+\n+      @Setup\n+      public void setup() {\n+        connection =\n+            getConnection(\n+                spec.dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled());\n+        int flushDuration = spec.flushDuration();\n+        int noOfBatchPoints = spec.noOfElementsToBatch();\n+        connection.enableBatch(\n+            BatchOptions.DEFAULTS.actions(noOfBatchPoints).flushDuration(flushDuration));\n+        connection.setRetentionPolicy(spec.retentionPolicy());\n+        connection.setDatabase(spec.database());\n+      }\n+\n+      @ProcessElement\n+      public void processElement(ProcessContext c) {\n+        connection.write(c.element().toString());\n+      }\n+\n+      @FinishBundle\n+      public void finishBundle() {\n+        connection.flush();\n+      }\n+\n+      @Teardown\n+      public void tearDown() {\n+        if (connection != null) {\n+          connection.flush();\n+          connection.close();\n+          connection = null;\n+        }\n+      }\n+\n+      @Override\n+      public void populateDisplayData(DisplayData.Builder builder) {\n+        builder.delegate(Write.this);\n+      }\n+    }\n+  }\n+\n+  private static OkHttpClient.Builder getUnsafeOkHttpClient() {\n+    try {\n+      // Create a trust manager that does not validate certificate chains\n+      final TrustManager[] trustAllCerts =\n+          new TrustManager[] {\n+            new X509TrustManager() {\n+              @Override\n+              public void checkClientTrusted(\n+                  java.security.cert.X509Certificate[] chain, String authType) {}\n+\n+              @Override\n+              public void checkServerTrusted(\n+                  java.security.cert.X509Certificate[] chain, String authType) {}\n+\n+              @Override\n+              public java.security.cert.X509Certificate[] getAcceptedIssuers() {\n+                return new java.security.cert.X509Certificate[] {};\n+              }\n+            }\n+          };\n+\n+      // Install the all-trusting trust manager\n+      final SSLContext sslContext = SSLContext.getInstance(\"SSL\");\n+      sslContext.init(null, trustAllCerts, new java.security.SecureRandom());\n+      // Create an ssl socket factory with our all-trusting manager\n+      final SSLSocketFactory sslSocketFactory = sslContext.getSocketFactory();\n+\n+      OkHttpClient.Builder builder = new OkHttpClient.Builder();\n+      builder.sslSocketFactory(sslSocketFactory, (X509TrustManager) trustAllCerts[0]);\n+      builder.hostnameVerifier((hostname, session) -> true);\n+      return builder;\n+    } catch (Exception e) {\n+      throw new RuntimeException(e);\n+    }\n+  }\n+  /** A POJO describing a DataSourceConfiguration such as URL, userName and password. */\n+  @AutoValue\n+  public abstract static class DataSourceConfiguration implements Serializable {\n+\n+    @Nullable\n+    abstract ValueProvider<String> url();\n+\n+    @Nullable\n+    abstract ValueProvider<String> userName();\n+\n+    @Nullable\n+    abstract ValueProvider<String> password();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+\n+      abstract Builder setUrl(ValueProvider<String> url);\n+\n+      abstract Builder setUserName(ValueProvider<String> userName);\n+\n+      abstract Builder setPassword(ValueProvider<String> password);\n+\n+      abstract DataSourceConfiguration build();\n+    }\n+\n+    public static DataSourceConfiguration create(String url, String userName, String password) {\n+      checkArgument(url != null, \"url can not be null\");\n+      checkArgument(userName != null, \"userName can not be null\");\n+      checkArgument(password != null, \"password can not be null\");\n+\n+      return create(\n+          ValueProvider.StaticValueProvider.of(url),\n+          ValueProvider.StaticValueProvider.of(userName),\n+          ValueProvider.StaticValueProvider.of(password));\n+    }\n+\n+    public static DataSourceConfiguration create(\n+        ValueProvider<String> url, ValueProvider<String> userName, ValueProvider<String> password) {\n+      checkArgument(url != null, \"url can not be null\");\n+      checkArgument(userName != null, \"userName can not be null\");\n+      checkArgument(password != null, \"password can not be null\");\n+\n+      return new AutoValue_InfluxDBIO_DataSourceConfiguration.Builder()\n+          .setUrl(url)\n+          .setUserName(userName)\n+          .setPassword(password)\n+          .build();\n+    }\n+\n+    public DataSourceConfiguration withUsername(String userName) {\n+      return withUsername(ValueProvider.StaticValueProvider.of(userName));\n+    }\n+\n+    public DataSourceConfiguration withUsername(ValueProvider<String> userName) {\n+      return builder().setUserName(userName).build();\n+    }\n+\n+    public DataSourceConfiguration withPassword(String password) {\n+      return withPassword(ValueProvider.StaticValueProvider.of(password));\n+    }\n+\n+    public DataSourceConfiguration withPassword(ValueProvider<String> password) {\n+      return builder().setPassword(password).build();\n+    }\n+\n+    public DataSourceConfiguration withUrl(String url) {\n+      return withPassword(ValueProvider.StaticValueProvider.of(url));\n+    }\n+\n+    public DataSourceConfiguration withUrl(ValueProvider<String> url) {\n+      return builder().setPassword(url).build();\n+    }\n+\n+    void populateDisplayData(DisplayData.Builder builder) {\n+\n+      builder.addIfNotNull(DisplayData.item(\"url\", url()));\n+      builder.addIfNotNull(DisplayData.item(\"userName\", userName()));\n+      builder.addIfNotNull(DisplayData.item(\"password\", password()));\n+    }\n+  }\n+\n+  private static class DataSourceProviderFromDataSourceConfiguration\n+      implements SerializableFunction<Void, DataSourceConfiguration>, HasDisplayData {\n+    private final DataSourceConfiguration config;\n+    private static DataSourceProviderFromDataSourceConfiguration instance;\n+\n+    private DataSourceProviderFromDataSourceConfiguration(DataSourceConfiguration config) {\n+      this.config = config;\n+    }\n+\n+    public static SerializableFunction<Void, DataSourceConfiguration> of(\n+        DataSourceConfiguration config) {\n+      if (instance == null) {\n+        instance = new DataSourceProviderFromDataSourceConfiguration(config);\n+      }\n+      return instance;\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      config.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public DataSourceConfiguration apply(Void input) {\n+      return config;\n+    }\n+  }\n+\n+  private static List<ShardInformation> getDBShardedInformation(\n+      String database,\n+      DataSourceConfiguration configuration,\n+      boolean sslInvalidHostNameAllowed,\n+      boolean sslEnabled) {\n+    String query = \"show shards\";\n+    DBShardInformation dbInfo = new DBShardInformation();\n+    try (InfluxDB connection =\n+        getConnection(configuration, sslInvalidHostNameAllowed, sslEnabled)) {\n+      QueryResult result = connection.query(new Query(query));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 777}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUwNzQ3Njg4", "url": "https://github.com/apache/beam/pull/11459#pullrequestreview-450747688", "createdAt": "2020-07-17T15:21:37Z", "commit": {"oid": "1670ecb173d554f58e250265484e6a89ab23a5b9"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxNToyMTozOFrOGzXNQw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxNjowNjo1NFrOGzYxCg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjUxMDc4Nw==", "bodyText": "Please, add Javadoc to this class.", "url": "https://github.com/apache/beam/pull/11459#discussion_r456510787", "createdAt": "2020-07-17T15:21:38Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/DBShardInformation.java", "diffHunk": "@@ -0,0 +1,48 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.influxdb.dto.QueryResult.Series;\n+\n+class DBShardInformation {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1670ecb173d554f58e250265484e6a89ab23a5b9"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjUxMTg5Mw==", "bodyText": "Please, add class Javadoc", "url": "https://github.com/apache/beam/pull/11459#discussion_r456511893", "createdAt": "2020-07-17T15:23:30Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/ShardInformation.java", "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import java.util.List;\n+import java.util.Objects;\n+import org.joda.time.DateTime;\n+\n+class ShardInformation implements Comparable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1670ecb173d554f58e250265484e6a89ab23a5b9"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjUyMTY2OA==", "bodyText": "Beam tends to reduce number of knobs exposed to user API.\nIs it quite possible that it will be required to change? Can we check in a loop (with a quite large timeout to prevent infinite loop) that everything was flushed?", "url": "https://github.com/apache/beam/pull/11459#discussion_r456521668", "createdAt": "2020-07-17T15:40:31Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueItr = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (noOfBlocksValueItr.hasNext() && sizeOfBlocksValueItr.hasNext()) {\n+        size = size + (noOfBlocksValueItr.next() * sizeOfBlocksValueItr.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    if (spec.query() == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        return String.format(\n+            \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+            spec.retentionPolicy(),\n+            String.join(\",\", spec.metrics()),\n+            spec.toDateTime(),\n+            spec.fromDateTime());\n+      } else {\n+        return String.format(\n+            \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+      }\n+    }\n+    return spec.query();\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDBIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List current;\n+\n+    public BoundedInfluxDbReader(InfluxDBIO.InfluxDBSource source) {\n+      this.source = source;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDBIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        if (spec.database() != null) {\n+          influxDB.setDatabase(spec.database());\n+        }\n+        if (spec.retentionPolicy() != null) {\n+          influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        }\n+        String query = getQueryToRun(spec);\n+        QueryResult queryResult = influxDB.query(new Query(query, spec.database()));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          seriesIterator = resultIterator.next().getSeries().iterator();\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkArgument(dataSourceConfiguration() != null, \"withConfiguration() is required\");\n+      checkArgument(database() != null && !database().isEmpty(), \"withDatabase() is required\");\n+      checkArgument(\n+          checkDatabase(\n+              database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+      builder.addIfNotNull(DisplayData.item(\"noOfElementsToBatch\", noOfElementsToBatch()));\n+      builder.addIfNotNull(DisplayData.item(\"flushDuration\", flushDuration()));\n+    }\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String retentionPolicy();\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract boolean sslEnabled();\n+\n+    abstract int noOfElementsToBatch();\n+\n+    abstract int flushDuration();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setNoOfElementsToBatch(int noOfElementsToBatch);\n+\n+      abstract Builder setFlushDuration(int flushDuration);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Write build();\n+    }\n+\n+    public Write withConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    public Write withDatabase(String database) {\n+      return builder().setDatabase(database).build();\n+    }\n+\n+    public Write withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Write withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Write withNoOfElementsToBatch(int noOfElementsToBatch) {\n+      return builder().setNoOfElementsToBatch(noOfElementsToBatch).build();\n+    }\n+\n+    public Write withFlushDuration(int flushDuration) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1NzgwOQ=="}, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 566}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjUyNjIxMA==", "bodyText": "I don't think that we have to expose it into user API and implement it inside IO. Can we just allow user to provide a custom client implementation for this case?", "url": "https://github.com/apache/beam/pull/11459#discussion_r456526210", "createdAt": "2020-07-17T15:48:33Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueItr = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (noOfBlocksValueItr.hasNext() && sizeOfBlocksValueItr.hasNext()) {\n+        size = size + (noOfBlocksValueItr.next() * sizeOfBlocksValueItr.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    if (spec.query() == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        return String.format(\n+            \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+            spec.retentionPolicy(),\n+            String.join(\",\", spec.metrics()),\n+            spec.toDateTime(),\n+            spec.fromDateTime());\n+      } else {\n+        return String.format(\n+            \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+      }\n+    }\n+    return spec.query();\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDBIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List current;\n+\n+    public BoundedInfluxDbReader(InfluxDBIO.InfluxDBSource source) {\n+      this.source = source;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDBIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        if (spec.database() != null) {\n+          influxDB.setDatabase(spec.database());\n+        }\n+        if (spec.retentionPolicy() != null) {\n+          influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        }\n+        String query = getQueryToRun(spec);\n+        QueryResult queryResult = influxDB.query(new Query(query, spec.database()));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          seriesIterator = resultIterator.next().getSeries().iterator();\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkArgument(dataSourceConfiguration() != null, \"withConfiguration() is required\");\n+      checkArgument(database() != null && !database().isEmpty(), \"withDatabase() is required\");\n+      checkArgument(\n+          checkDatabase(\n+              database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+      builder.addIfNotNull(DisplayData.item(\"noOfElementsToBatch\", noOfElementsToBatch()));\n+      builder.addIfNotNull(DisplayData.item(\"flushDuration\", flushDuration()));\n+    }\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String retentionPolicy();\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract boolean sslEnabled();\n+\n+    abstract int noOfElementsToBatch();\n+\n+    abstract int flushDuration();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setNoOfElementsToBatch(int noOfElementsToBatch);\n+\n+      abstract Builder setFlushDuration(int flushDuration);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Write build();\n+    }\n+\n+    public Write withConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    public Write withDatabase(String database) {\n+      return builder().setDatabase(database).build();\n+    }\n+\n+    public Write withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Write withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Write withNoOfElementsToBatch(int noOfElementsToBatch) {\n+      return builder().setNoOfElementsToBatch(noOfElementsToBatch).build();\n+    }\n+\n+    public Write withFlushDuration(int flushDuration) {\n+      return builder().setFlushDuration(flushDuration).build();\n+    }\n+\n+    public Write withRetentionPolicy(String rp) {\n+      return builder().setRetentionPolicy(rp).build();\n+    }\n+\n+    private class InfluxWriterFn<T> extends DoFn<T, Void> {\n+\n+      private final Write spec;\n+      private InfluxDB connection;\n+\n+      InfluxWriterFn(Write write) {\n+        this.spec = write;\n+      }\n+\n+      @Setup\n+      public void setup() {\n+        connection =\n+            getConnection(\n+                spec.dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled());\n+        int flushDuration = spec.flushDuration();\n+        int noOfBatchPoints = spec.noOfElementsToBatch();\n+        connection.enableBatch(\n+            BatchOptions.DEFAULTS.actions(noOfBatchPoints).flushDuration(flushDuration));\n+        connection.setRetentionPolicy(spec.retentionPolicy());\n+        connection.setDatabase(spec.database());\n+      }\n+\n+      @ProcessElement\n+      public void processElement(ProcessContext c) {\n+        connection.write(c.element().toString());\n+      }\n+\n+      @FinishBundle\n+      public void finishBundle() {\n+        connection.flush();\n+      }\n+\n+      @Teardown\n+      public void tearDown() {\n+        if (connection != null) {\n+          connection.flush();\n+          connection.close();\n+          connection = null;\n+        }\n+      }\n+\n+      @Override\n+      public void populateDisplayData(DisplayData.Builder builder) {\n+        builder.delegate(Write.this);\n+      }\n+    }\n+  }\n+\n+  private static OkHttpClient.Builder getUnsafeOkHttpClient() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1ODE5OA=="}, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 622}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjUyNzgwNw==", "bodyText": "The latest version is 2.19. Could you bump it?", "url": "https://github.com/apache/beam/pull/11459#discussion_r456527807", "createdAt": "2020-07-17T15:51:26Z", "author": {"login": "aromanenko-dev"}, "path": "buildSrc/src/main/groovy/org/apache/beam/gradle/BeamModulePlugin.groovy", "diffHunk": "@@ -387,6 +387,7 @@ class BeamModulePlugin implements Plugin<Project> {\n     def guava_version = \"25.1-jre\"\n     def hadoop_version = \"2.8.5\"\n     def hamcrest_version = \"2.1\"\n+    def influxdb_version = \"2.17\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1670ecb173d554f58e250265484e6a89ab23a5b9"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjUzMzM1MQ==", "bodyText": "I believe it would be better to provide for user a way to create custom client with ClientProvider implementation (see KinesisIO.Read withAWSClientsProvider(AWSClientsProvider), for example).", "url": "https://github.com/apache/beam/pull/11459#discussion_r456533351", "createdAt": "2020-07-17T16:01:24Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,830 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>You have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database. InfluxDB line protocol reference\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDbIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDbIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDbIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNumOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDbIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkState(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1670ecb173d554f58e250265484e6a89ab23a5b9"}, "originalPosition": 246}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjUzNTk3OA==", "bodyText": "Does it just put a record into output queue when it will be flushed later?", "url": "https://github.com/apache/beam/pull/11459#discussion_r456535978", "createdAt": "2020-07-17T16:06:11Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,830 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>You have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database. InfluxDB line protocol reference\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDbIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDbIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDbIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNumOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDbIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkState(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkState(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkState(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkState(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String numOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> numOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(numOfBlocks)) {\n+                numOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> numOfBlocksValueIterator = numOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueIterator = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (numOfBlocksValueIterator.hasNext() && sizeOfBlocksValueIterator.hasNext()) {\n+        size = size + (numOfBlocksValueIterator.next() * sizeOfBlocksValueIterator.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    if (spec.query() == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        String retVal =\n+            String.format(\n+                \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+                spec.retentionPolicy(),\n+                String.join(\",\", spec.metrics()),\n+                spec.toDateTime(),\n+                spec.fromDateTime());\n+        return retVal;\n+      } else {\n+        return String.format(\n+            \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+      }\n+    }\n+    return spec.query();\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDbIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List current;\n+\n+    public BoundedInfluxDbReader(InfluxDbIO.InfluxDBSource source) {\n+      this.source = source;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDbIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        if (spec.database() != null) {\n+          influxDB.setDatabase(spec.database());\n+        }\n+        if (spec.retentionPolicy() != null) {\n+          influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        }\n+        String query = getQueryToRun(spec);\n+        QueryResult queryResult = influxDB.query(new Query(query, spec.database()));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          seriesIterator = resultIterator.next().getSeries().iterator();\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkState(dataSourceConfiguration() != null, \"withConfiguration() is required\");\n+      checkState(database() != null && !database().isEmpty(), \"withDatabase() is required\");\n+      checkState(\n+          checkDatabase(\n+              database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+      builder.addIfNotNull(DisplayData.item(\"numOfElementsToBatch\", numOfElementsToBatch()));\n+      builder.addIfNotNull(DisplayData.item(\"flushDuration\", flushDuration()));\n+    }\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String retentionPolicy();\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract boolean sslEnabled();\n+\n+    abstract int numOfElementsToBatch();\n+\n+    abstract int flushDuration();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setNumOfElementsToBatch(int numOfElementsToBatch);\n+\n+      abstract Builder setFlushDuration(int flushDuration);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Write build();\n+    }\n+\n+    public Write withConfiguration(DataSourceConfiguration configuration) {\n+      checkState(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    public Write withDatabase(String database) {\n+      return builder().setDatabase(database).build();\n+    }\n+\n+    public Write withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Write withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Write withNumOfElementsToBatch(int numOfElementsToBatch) {\n+      return builder().setNumOfElementsToBatch(numOfElementsToBatch).build();\n+    }\n+\n+    public Write withFlushDuration(int flushDuration) {\n+      return builder().setFlushDuration(flushDuration).build();\n+    }\n+\n+    public Write withRetentionPolicy(String rp) {\n+      return builder().setRetentionPolicy(rp).build();\n+    }\n+\n+    private class InfluxWriterFn extends DoFn<String, Void> {\n+\n+      private final Write spec;\n+      private transient InfluxDB connection;\n+\n+      InfluxWriterFn(Write write) {\n+        this.spec = write;\n+      }\n+\n+      @Setup\n+      public void setup() {\n+        connection =\n+            getConnection(\n+                spec.dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled());\n+        int flushDuration = spec.flushDuration();\n+        int numOfBatchPoints = spec.numOfElementsToBatch();\n+        connection.enableBatch(\n+            BatchOptions.DEFAULTS.actions(numOfBatchPoints).flushDuration(flushDuration));\n+        connection.setRetentionPolicy(spec.retentionPolicy());\n+        connection.setDatabase(spec.database());\n+      }\n+\n+      @ProcessElement\n+      public void processElement(ProcessContext c) {\n+        connection.write(c.element());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1670ecb173d554f58e250265484e6a89ab23a5b9"}, "originalPosition": 599}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjUzNjMzMA==", "bodyText": "Does it guarantee that all records were flushed properly?", "url": "https://github.com/apache/beam/pull/11459#discussion_r456536330", "createdAt": "2020-07-17T16:06:54Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,830 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>You have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database. InfluxDB line protocol reference\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDbIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDbIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDbIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNumOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDbIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkState(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkState(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkState(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkState(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String numOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> numOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(numOfBlocks)) {\n+                numOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> numOfBlocksValueIterator = numOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueIterator = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (numOfBlocksValueIterator.hasNext() && sizeOfBlocksValueIterator.hasNext()) {\n+        size = size + (numOfBlocksValueIterator.next() * sizeOfBlocksValueIterator.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    if (spec.query() == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        String retVal =\n+            String.format(\n+                \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+                spec.retentionPolicy(),\n+                String.join(\",\", spec.metrics()),\n+                spec.toDateTime(),\n+                spec.fromDateTime());\n+        return retVal;\n+      } else {\n+        return String.format(\n+            \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+      }\n+    }\n+    return spec.query();\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDbIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List current;\n+\n+    public BoundedInfluxDbReader(InfluxDbIO.InfluxDBSource source) {\n+      this.source = source;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDbIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        if (spec.database() != null) {\n+          influxDB.setDatabase(spec.database());\n+        }\n+        if (spec.retentionPolicy() != null) {\n+          influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        }\n+        String query = getQueryToRun(spec);\n+        QueryResult queryResult = influxDB.query(new Query(query, spec.database()));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          seriesIterator = resultIterator.next().getSeries().iterator();\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkState(dataSourceConfiguration() != null, \"withConfiguration() is required\");\n+      checkState(database() != null && !database().isEmpty(), \"withDatabase() is required\");\n+      checkState(\n+          checkDatabase(\n+              database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+      builder.addIfNotNull(DisplayData.item(\"numOfElementsToBatch\", numOfElementsToBatch()));\n+      builder.addIfNotNull(DisplayData.item(\"flushDuration\", flushDuration()));\n+    }\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String retentionPolicy();\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract boolean sslEnabled();\n+\n+    abstract int numOfElementsToBatch();\n+\n+    abstract int flushDuration();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setNumOfElementsToBatch(int numOfElementsToBatch);\n+\n+      abstract Builder setFlushDuration(int flushDuration);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Write build();\n+    }\n+\n+    public Write withConfiguration(DataSourceConfiguration configuration) {\n+      checkState(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    public Write withDatabase(String database) {\n+      return builder().setDatabase(database).build();\n+    }\n+\n+    public Write withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Write withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Write withNumOfElementsToBatch(int numOfElementsToBatch) {\n+      return builder().setNumOfElementsToBatch(numOfElementsToBatch).build();\n+    }\n+\n+    public Write withFlushDuration(int flushDuration) {\n+      return builder().setFlushDuration(flushDuration).build();\n+    }\n+\n+    public Write withRetentionPolicy(String rp) {\n+      return builder().setRetentionPolicy(rp).build();\n+    }\n+\n+    private class InfluxWriterFn extends DoFn<String, Void> {\n+\n+      private final Write spec;\n+      private transient InfluxDB connection;\n+\n+      InfluxWriterFn(Write write) {\n+        this.spec = write;\n+      }\n+\n+      @Setup\n+      public void setup() {\n+        connection =\n+            getConnection(\n+                spec.dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled());\n+        int flushDuration = spec.flushDuration();\n+        int numOfBatchPoints = spec.numOfElementsToBatch();\n+        connection.enableBatch(\n+            BatchOptions.DEFAULTS.actions(numOfBatchPoints).flushDuration(flushDuration));\n+        connection.setRetentionPolicy(spec.retentionPolicy());\n+        connection.setDatabase(spec.database());\n+      }\n+\n+      @ProcessElement\n+      public void processElement(ProcessContext c) {\n+        connection.write(c.element());\n+      }\n+\n+      @FinishBundle\n+      public void finishBundle() {\n+        connection.flush();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1670ecb173d554f58e250265484e6a89ab23a5b9"}, "originalPosition": 604}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "2805c54c1a4ba6d7c532f59fe967dbba81297115", "author": {"user": {"login": "bipinupd", "name": "Bipin Upadhyaya"}}, "url": "https://github.com/apache/beam/commit/2805c54c1a4ba6d7c532f59fe967dbba81297115", "committedDate": "2020-09-01T16:02:34Z", "message": "Adding changes"}, "afterCommit": {"oid": "5932a90028dd0ec7525d61cf07c37bd590e6be47", "author": {"user": {"login": "bipinupd", "name": "Bipin Upadhyaya"}}, "url": "https://github.com/apache/beam/commit/5932a90028dd0ec7525d61cf07c37bd590e6be47", "committedDate": "2020-09-01T20:39:05Z", "message": "IT test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3471d89cec3c8a6ab44112c3edc058ca5cb48d1f", "author": {"user": {"login": "bipinupd", "name": "Bipin Upadhyaya"}}, "url": "https://github.com/apache/beam/commit/3471d89cec3c8a6ab44112c3edc058ca5cb48d1f", "committedDate": "2020-09-03T13:00:40Z", "message": "BEAM-2546 Initial Commit"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7bc05ebaf40bfde7213f6728fb2b8fde83b8dd86", "author": {"user": {"login": "bipinupd", "name": "Bipin Upadhyaya"}}, "url": "https://github.com/apache/beam/commit/7bc05ebaf40bfde7213f6728fb2b8fde83b8dd86", "committedDate": "2020-09-03T13:00:40Z", "message": "Added yml file for IT test and related script"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f33d91644762ae548d9019daf38966a00fd92ca6", "author": {"user": {"login": "bipinupd", "name": "Bipin Upadhyaya"}}, "url": "https://github.com/apache/beam/commit/f33d91644762ae548d9019daf38966a00fd92ca6", "committedDate": "2020-09-03T13:00:40Z", "message": "Checkstyles, clean the build file and removed unused codes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "308a41b15d627b5463a58515d719ac53f969f6d7", "author": {"user": {"login": "bipinupd", "name": "Bipin Upadhyaya"}}, "url": "https://github.com/apache/beam/commit/308a41b15d627b5463a58515d719ac53f969f6d7", "committedDate": "2020-09-03T13:00:40Z", "message": "BEAM-2546 Initial Commit"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "be45fa20ec3d46b1c9c92960e362be65be77ddd5", "author": {"user": {"login": "bipinupd", "name": "Bipin Upadhyaya"}}, "url": "https://github.com/apache/beam/commit/be45fa20ec3d46b1c9c92960e362be65be77ddd5", "committedDate": "2020-09-03T13:00:40Z", "message": "Checkstyles, clean the build file and removed unused codes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2a8e293f0125cc283580cd7d5e5000886b0bf876", "author": {"user": {"login": "bipinupd", "name": "Bipin Upadhyaya"}}, "url": "https://github.com/apache/beam/commit/2a8e293f0125cc283580cd7d5e5000886b0bf876", "committedDate": "2020-09-03T13:00:40Z", "message": "adding influxdb in settings"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "136ae5f86959e361da6ff8a5c4b919cc95435586", "author": {"user": {"login": "bipinupd", "name": "Bipin Upadhyaya"}}, "url": "https://github.com/apache/beam/commit/136ae5f86959e361da6ff8a5c4b919cc95435586", "committedDate": "2020-09-03T13:00:40Z", "message": "Addressing the comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2ba23192a8a8980317065ea8922972e69df799ac", "author": {"user": {"login": "bipinupd", "name": "Bipin Upadhyaya"}}, "url": "https://github.com/apache/beam/commit/2ba23192a8a8980317065ea8922972e69df799ac", "committedDate": "2020-09-03T13:00:40Z", "message": "Apply spotlessApply check"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2b6360e7045b2492e12576f03f8766db2d5bdae9", "author": {"user": {"login": "bipinupd", "name": "Bipin Upadhyaya"}}, "url": "https://github.com/apache/beam/commit/2b6360e7045b2492e12576f03f8766db2d5bdae9", "committedDate": "2020-09-03T13:00:40Z", "message": "Removing duplicate entry"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "542c1aaa1eb6f03992d73a8316c849a0cbcb8918", "author": {"user": {"login": "bipinupd", "name": "Bipin Upadhyaya"}}, "url": "https://github.com/apache/beam/commit/542c1aaa1eb6f03992d73a8316c849a0cbcb8918", "committedDate": "2020-09-03T13:00:40Z", "message": "Update influxdb.yml"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "19ace7cdc99419c360cac974baceb45cbd0e73e6", "author": {"user": {"login": "bipinupd", "name": "Bipin Upadhyaya"}}, "url": "https://github.com/apache/beam/commit/19ace7cdc99419c360cac974baceb45cbd0e73e6", "committedDate": "2020-09-03T13:00:40Z", "message": "Update build.gradle"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0c8d2aafeae0e2fabcfc019dd45addaeef20eef3", "author": {"user": {"login": "bipinupd", "name": "Bipin Upadhyaya"}}, "url": "https://github.com/apache/beam/commit/0c8d2aafeae0e2fabcfc019dd45addaeef20eef3", "committedDate": "2020-09-03T13:00:40Z", "message": "Addressing the comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "82628b8d4f277a6411930454c918762637870094", "author": {"user": {"login": "bipinupd", "name": "Bipin Upadhyaya"}}, "url": "https://github.com/apache/beam/commit/82628b8d4f277a6411930454c918762637870094", "committedDate": "2020-09-03T13:00:40Z", "message": "Performance test for InfluxDB"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c395a24b440a77d701a9aa0eb44e51f1ab8357d0", "author": {"user": {"login": "bipinupd", "name": "Bipin Upadhyaya"}}, "url": "https://github.com/apache/beam/commit/c395a24b440a77d701a9aa0eb44e51f1ab8357d0", "committedDate": "2020-09-03T13:00:40Z", "message": "spotlessCheck"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "08497b15cce444a202c847e292bb9958ed834776", "author": {"user": {"login": "bipinupd", "name": "Bipin Upadhyaya"}}, "url": "https://github.com/apache/beam/commit/08497b15cce444a202c847e292bb9958ed834776", "committedDate": "2020-09-03T13:00:40Z", "message": "Adding external dependency in BeamModulePlugin"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "248381901aae31b1609dec5651a4f9174ddd33b7", "author": {"user": {"login": "bipinupd", "name": "Bipin Upadhyaya"}}, "url": "https://github.com/apache/beam/commit/248381901aae31b1609dec5651a4f9174ddd33b7", "committedDate": "2020-09-03T13:00:40Z", "message": "Formatting BeamModulePlugin.groovy"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "500c7f685e3c6ede8a34df55ff5fe4d8492a4003", "author": {"user": {"login": "bipinupd", "name": "Bipin Upadhyaya"}}, "url": "https://github.com/apache/beam/commit/500c7f685e3c6ede8a34df55ff5fe4d8492a4003", "committedDate": "2020-09-03T13:00:40Z", "message": "adding influxdb in settings"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "605c48acfede19cca6af2a355351a40bb0efaf0f", "author": {"user": {"login": "bipinupd", "name": "Bipin Upadhyaya"}}, "url": "https://github.com/apache/beam/commit/605c48acfede19cca6af2a355351a40bb0efaf0f", "committedDate": "2020-09-03T13:00:40Z", "message": "Removing duplicate entry"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d14ba125acd108c506b4700febbd9e086e5fc0df", "author": {"user": {"login": "bipinupd", "name": "Bipin Upadhyaya"}}, "url": "https://github.com/apache/beam/commit/d14ba125acd108c506b4700febbd9e086e5fc0df", "committedDate": "2020-09-03T13:00:41Z", "message": "Merging conflicts"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "25a69101934b54a593a37a6d1774080ac41fc690", "author": {"user": {"login": "bipinupd", "name": "Bipin Upadhyaya"}}, "url": "https://github.com/apache/beam/commit/25a69101934b54a593a37a6d1774080ac41fc690", "committedDate": "2020-09-03T13:00:41Z", "message": "spotlessCheck"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b68363b789471158237eff699b608bf448e8119c", "author": {"user": {"login": "bipinupd", "name": "Bipin Upadhyaya"}}, "url": "https://github.com/apache/beam/commit/b68363b789471158237eff699b608bf448e8119c", "committedDate": "2020-09-03T13:00:41Z", "message": "Update influxdb version"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a4358eac7bbed0faefbae81a18195271ede34f72", "author": {"user": {"login": "bipinupd", "name": "Bipin Upadhyaya"}}, "url": "https://github.com/apache/beam/commit/a4358eac7bbed0faefbae81a18195271ede34f72", "committedDate": "2020-09-03T13:00:41Z", "message": "Resolving merge conflicts"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1fb4ab38db94e4e4c020e21a3b472df6e6b6478a", "author": {"user": {"login": "bipinupd", "name": "Bipin Upadhyaya"}}, "url": "https://github.com/apache/beam/commit/1fb4ab38db94e4e4c020e21a3b472df6e6b6478a", "committedDate": "2020-09-03T13:00:41Z", "message": "IT test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6828ac9993ec0aa11f92ceaf4b58abf62c2826b9", "author": {"user": {"login": "bipinupd", "name": "Bipin Upadhyaya"}}, "url": "https://github.com/apache/beam/commit/6828ac9993ec0aa11f92ceaf4b58abf62c2826b9", "committedDate": "2020-09-03T13:00:41Z", "message": "additional IT test and null checks"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6ee9a269dcbb988f5b6aeb44546abd10bf4d3282", "author": {"user": {"login": "bipinupd", "name": "Bipin Upadhyaya"}}, "url": "https://github.com/apache/beam/commit/6ee9a269dcbb988f5b6aeb44546abd10bf4d3282", "committedDate": "2020-09-03T13:00:41Z", "message": "infrastructure setup and teardown"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "598131a299283129d110099a1c54cf3e5ef1ac61", "author": {"user": {"login": "bipinupd", "name": "Bipin Upadhyaya"}}, "url": "https://github.com/apache/beam/commit/598131a299283129d110099a1c54cf3e5ef1ac61", "committedDate": "2020-09-03T13:00:41Z", "message": "Apply Whitespacelint"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "dff1997cdb23cafc626ccb0e41efd3db11ce9c54", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/dff1997cdb23cafc626ccb0e41efd3db11ce9c54", "committedDate": "2020-09-03T13:08:23Z", "message": "[BEAM-10567] Add LICENSE for pbr (#12765)"}, "afterCommit": {"oid": "b84df0a7b81f46236489e2a02006f76e4f282c13", "author": {"user": {"login": "robertwb", "name": "Robert Bradshaw"}}, "url": "https://github.com/apache/beam/commit/b84df0a7b81f46236489e2a02006f76e4f282c13", "committedDate": "2020-09-04T00:10:38Z", "message": "More logging for missing next work index. (#12718)"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg0MjY5MDE0", "url": "https://github.com/apache/beam/pull/11459#pullrequestreview-484269014", "createdAt": "2020-09-08T15:41:38Z", "commit": {"oid": "fada15c2d1a3fe10b3d9e3ba54820a4533c831f2"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxNTo0MTozOVrOHOjNVw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxNjoyNToxMVrOHOk7_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTAxODk2Nw==", "bodyText": "nit: InfluxDbIO.read()", "url": "https://github.com/apache/beam/pull/11459#discussion_r485018967", "createdAt": "2020-09-08T15:41:39Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDbIO.java", "diffHunk": "@@ -0,0 +1,662 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.annotations.Experimental.Kind;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.options.ValueProvider.StaticValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.checkerframework.checker.nullness.qual.Nullable;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDB.ConsistencyLevel;\n+import org.influxdb.InfluxDBException;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write from InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDB return a bounded collection of String as {@code PCollection<String>}. The String\n+ * follows the line protocol\n+ * (https://docs.influxdata.com/influxdb/v1.8/write_protocols/line_protocol_tutorial/). To Configure\n+ * the InfluxDB source, you whave to provide the connection URL, the credentials to connect to\n+ * InfluxDB and the Database name\n+ *\n+ * <pre>{@code\n+ *  pipeline.apply(\n+ *    InfluxDB.read(\"https://influxdb\", \"userName\", \"password\", \"database\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fada15c2d1a3fe10b3d9e3ba54820a4533c831f2"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTAxOTE2MA==", "bodyText": "nit: InfluxDbIO.write()", "url": "https://github.com/apache/beam/pull/11459#discussion_r485019160", "createdAt": "2020-09-08T15:41:54Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDbIO.java", "diffHunk": "@@ -0,0 +1,662 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.annotations.Experimental.Kind;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.options.ValueProvider.StaticValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.checkerframework.checker.nullness.qual.Nullable;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDB.ConsistencyLevel;\n+import org.influxdb.InfluxDBException;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write from InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDB return a bounded collection of String as {@code PCollection<String>}. The String\n+ * follows the line protocol\n+ * (https://docs.influxdata.com/influxdb/v1.8/write_protocols/line_protocol_tutorial/). To Configure\n+ * the InfluxDB source, you whave to provide the connection URL, the credentials to connect to\n+ * InfluxDB and the Database name\n+ *\n+ * <pre>{@code\n+ *  pipeline.apply(\n+ *    InfluxDB.read(\"https://influxdb\", \"userName\", \"password\", \"database\")\n+ *      .withQuery(\"select * from metric\");\n+ *      //Reads data based on the query from the InfluxDB\n+ * }\n+ *\n+ * <p> The source also accepts optional configuration: {@code withRetentionPolicy()}  an</p>\n+ *\n+ *\n+ * <h3>Writing to InfluxDB</h3>\n+ *\n+ * <p>InfluxDB sink supports writing data (as line protocol)  to InfluxDB\n+ * To configure a InfluxDB sink, you must specify a URL {@code InfluxDBURL}, {@code userName}, {@code password}, {@code database}\n+ * <pre>{@code\n+ * pipeleine\n+ *    .apply(...)\n+ *    .appply(InfluxDB.write(https://influxdb\", \"userName\", \"password\", \"database\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fada15c2d1a3fe10b3d9e3ba54820a4533c831f2"}, "originalPosition": 90}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTAyMTM4OA==", "bodyText": "nit: DEFAULT_RETENTION_POLICY since it's a constant string", "url": "https://github.com/apache/beam/pull/11459#discussion_r485021388", "createdAt": "2020-09-08T15:45:18Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDbIO.java", "diffHunk": "@@ -0,0 +1,662 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.annotations.Experimental.Kind;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.options.ValueProvider.StaticValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.checkerframework.checker.nullness.qual.Nullable;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDB.ConsistencyLevel;\n+import org.influxdb.InfluxDBException;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write from InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDB return a bounded collection of String as {@code PCollection<String>}. The String\n+ * follows the line protocol\n+ * (https://docs.influxdata.com/influxdb/v1.8/write_protocols/line_protocol_tutorial/). To Configure\n+ * the InfluxDB source, you whave to provide the connection URL, the credentials to connect to\n+ * InfluxDB and the Database name\n+ *\n+ * <pre>{@code\n+ *  pipeline.apply(\n+ *    InfluxDB.read(\"https://influxdb\", \"userName\", \"password\", \"database\")\n+ *      .withQuery(\"select * from metric\");\n+ *      //Reads data based on the query from the InfluxDB\n+ * }\n+ *\n+ * <p> The source also accepts optional configuration: {@code withRetentionPolicy()}  an</p>\n+ *\n+ *\n+ * <h3>Writing to InfluxDB</h3>\n+ *\n+ * <p>InfluxDB sink supports writing data (as line protocol)  to InfluxDB\n+ * To configure a InfluxDB sink, you must specify a URL {@code InfluxDBURL}, {@code userName}, {@code password}, {@code database}\n+ * <pre>{@code\n+ * pipeleine\n+ *    .apply(...)\n+ *    .appply(InfluxDB.write(https://influxdb\", \"userName\", \"password\", \"database\")\n+ *\n+ * }\n+ * </pre>\n+ * </pre>\n+ */\n+@Experimental(Kind.SOURCE_SINK)\n+public class InfluxDbIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDbIO.class);\n+\n+  private static final String defaultRetentionPolicy = \"autogen\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fada15c2d1a3fe10b3d9e3ba54820a4533c831f2"}, "originalPosition": 100}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTAyMjQwNg==", "bodyText": "Are these real or fake credentials?", "url": "https://github.com/apache/beam/pull/11459#discussion_r485022406", "createdAt": "2020-09-08T15:46:51Z", "author": {"login": "aromanenko-dev"}, "path": ".test-infra/kubernetes/influxdb/influxdb.yml", "diffHunk": "@@ -0,0 +1,76 @@\n+#    Licensed to the Apache Software Foundation (ASF) under one or more\n+#    contributor license agreements.  See the NOTICE file distributed with\n+#    this work for additional information regarding copyright ownership.\n+#    The ASF licenses this file to You under the Apache License, Version 2.0\n+#    (the \"License\"); you may not use this file except in compliance with\n+#    the License.  You may obtain a copy of the License at\n+#\n+#       http://www.apache.org/licenses/LICENSE-2.0\n+#\n+#    Unless required by applicable law or agreed to in writing, software\n+#    distributed under the License is distributed on an \"AS IS\" BASIS,\n+#    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+#    See the License for the specific language governing permissions and\n+#    limitations under the License.\n+\n+apiVersion: v1\n+kind: Secret\n+metadata:\n+  name: influxdb-creds\n+data:\n+  INFLUXDB_USER: c3VwZXJzYWRtaW4=\n+  INFLUXDB_USER_PASSWORD: c3VwZXJzZWNyZXRwYXNzd29yZA==", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fada15c2d1a3fe10b3d9e3ba54820a4533c831f2"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTAyNTMzNQ==", "bodyText": "nit: remove  an in the end of the sentence.", "url": "https://github.com/apache/beam/pull/11459#discussion_r485025335", "createdAt": "2020-09-08T15:51:07Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDbIO.java", "diffHunk": "@@ -0,0 +1,662 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.annotations.Experimental.Kind;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.options.ValueProvider.StaticValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.checkerframework.checker.nullness.qual.Nullable;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDB.ConsistencyLevel;\n+import org.influxdb.InfluxDBException;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write from InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDB return a bounded collection of String as {@code PCollection<String>}. The String\n+ * follows the line protocol\n+ * (https://docs.influxdata.com/influxdb/v1.8/write_protocols/line_protocol_tutorial/). To Configure\n+ * the InfluxDB source, you whave to provide the connection URL, the credentials to connect to\n+ * InfluxDB and the Database name\n+ *\n+ * <pre>{@code\n+ *  pipeline.apply(\n+ *    InfluxDB.read(\"https://influxdb\", \"userName\", \"password\", \"database\")\n+ *      .withQuery(\"select * from metric\");\n+ *      //Reads data based on the query from the InfluxDB\n+ * }\n+ *\n+ * <p> The source also accepts optional configuration: {@code withRetentionPolicy()}  an</p>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fada15c2d1a3fe10b3d9e3ba54820a4533c831f2"}, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTAzNDcwMg==", "bodyText": "Please, keep write() method without arguments for consistency with other IOs and add withDataSourceConfiguration(DataSourceConfiguration conf), which will be required to configure data source, and withDatabase(String) to set database name (see JdbcIO.write() as an example).\nSo, for the user it would be something like:\nInfluxDbIO.write().withDataSourceConfiguration(DataSourceConfiguration.create(...)).withDatabase(\"...\");", "url": "https://github.com/apache/beam/pull/11459#discussion_r485034702", "createdAt": "2020-09-08T16:04:59Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDbIO.java", "diffHunk": "@@ -0,0 +1,662 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.annotations.Experimental.Kind;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.options.ValueProvider.StaticValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.checkerframework.checker.nullness.qual.Nullable;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDB.ConsistencyLevel;\n+import org.influxdb.InfluxDBException;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write from InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDB return a bounded collection of String as {@code PCollection<String>}. The String\n+ * follows the line protocol\n+ * (https://docs.influxdata.com/influxdb/v1.8/write_protocols/line_protocol_tutorial/). To Configure\n+ * the InfluxDB source, you whave to provide the connection URL, the credentials to connect to\n+ * InfluxDB and the Database name\n+ *\n+ * <pre>{@code\n+ *  pipeline.apply(\n+ *    InfluxDB.read(\"https://influxdb\", \"userName\", \"password\", \"database\")\n+ *      .withQuery(\"select * from metric\");\n+ *      //Reads data based on the query from the InfluxDB\n+ * }\n+ *\n+ * <p> The source also accepts optional configuration: {@code withRetentionPolicy()}  an</p>\n+ *\n+ *\n+ * <h3>Writing to InfluxDB</h3>\n+ *\n+ * <p>InfluxDB sink supports writing data (as line protocol)  to InfluxDB\n+ * To configure a InfluxDB sink, you must specify a URL {@code InfluxDBURL}, {@code userName}, {@code password}, {@code database}\n+ * <pre>{@code\n+ * pipeleine\n+ *    .apply(...)\n+ *    .appply(InfluxDB.write(https://influxdb\", \"userName\", \"password\", \"database\")\n+ *\n+ * }\n+ * </pre>\n+ * </pre>\n+ */\n+@Experimental(Kind.SOURCE_SINK)\n+public class InfluxDbIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDbIO.class);\n+\n+  private static final String defaultRetentionPolicy = \"autogen\";\n+\n+  /** Disallow construction of utility class. */\n+  private InfluxDbIO() {}\n+\n+  public static Write write(String influxDbUrl, String username, String password, String database) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fada15c2d1a3fe10b3d9e3ba54820a4533c831f2"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTAzNzc4OQ==", "bodyText": "The same recommendation as for write() method above - please, make read() without arguments.", "url": "https://github.com/apache/beam/pull/11459#discussion_r485037789", "createdAt": "2020-09-08T16:09:54Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDbIO.java", "diffHunk": "@@ -0,0 +1,662 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.annotations.Experimental.Kind;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.options.ValueProvider.StaticValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.checkerframework.checker.nullness.qual.Nullable;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDB.ConsistencyLevel;\n+import org.influxdb.InfluxDBException;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write from InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDB return a bounded collection of String as {@code PCollection<String>}. The String\n+ * follows the line protocol\n+ * (https://docs.influxdata.com/influxdb/v1.8/write_protocols/line_protocol_tutorial/). To Configure\n+ * the InfluxDB source, you whave to provide the connection URL, the credentials to connect to\n+ * InfluxDB and the Database name\n+ *\n+ * <pre>{@code\n+ *  pipeline.apply(\n+ *    InfluxDB.read(\"https://influxdb\", \"userName\", \"password\", \"database\")\n+ *      .withQuery(\"select * from metric\");\n+ *      //Reads data based on the query from the InfluxDB\n+ * }\n+ *\n+ * <p> The source also accepts optional configuration: {@code withRetentionPolicy()}  an</p>\n+ *\n+ *\n+ * <h3>Writing to InfluxDB</h3>\n+ *\n+ * <p>InfluxDB sink supports writing data (as line protocol)  to InfluxDB\n+ * To configure a InfluxDB sink, you must specify a URL {@code InfluxDBURL}, {@code userName}, {@code password}, {@code database}\n+ * <pre>{@code\n+ * pipeleine\n+ *    .apply(...)\n+ *    .appply(InfluxDB.write(https://influxdb\", \"userName\", \"password\", \"database\")\n+ *\n+ * }\n+ * </pre>\n+ * </pre>\n+ */\n+@Experimental(Kind.SOURCE_SINK)\n+public class InfluxDbIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDbIO.class);\n+\n+  private static final String defaultRetentionPolicy = \"autogen\";\n+\n+  /** Disallow construction of utility class. */\n+  private InfluxDbIO() {}\n+\n+  public static Write write(String influxDbUrl, String username, String password, String database) {\n+    return new AutoValue_InfluxDbIO_Write.Builder()\n+        .setDataSourceConfiguration(\n+            DataSourceConfiguration.create(\n+                StaticValueProvider.of(influxDbUrl),\n+                StaticValueProvider.of(username),\n+                StaticValueProvider.of(password)))\n+        .setDatabase(database)\n+        .setRetentionPolicy(defaultRetentionPolicy)\n+        .setDisableCertificateValidation(false)\n+        .setBatchSize(DEFAULT_BUFFER_LIMIT)\n+        .setConsistencyLevel(ConsistencyLevel.QUORUM)\n+        .build();\n+  }\n+\n+  public static Read read(String influxDbUrl, String username, String password, String database) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fada15c2d1a3fe10b3d9e3ba54820a4533c831f2"}, "originalPosition": 120}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0MDY1OQ==", "bodyText": "Do we really want to display credentials in plain text mode?", "url": "https://github.com/apache/beam/pull/11459#discussion_r485040659", "createdAt": "2020-09-08T16:14:33Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDbIO.java", "diffHunk": "@@ -0,0 +1,662 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.annotations.Experimental.Kind;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.options.ValueProvider.StaticValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.checkerframework.checker.nullness.qual.Nullable;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDB.ConsistencyLevel;\n+import org.influxdb.InfluxDBException;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write from InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDB return a bounded collection of String as {@code PCollection<String>}. The String\n+ * follows the line protocol\n+ * (https://docs.influxdata.com/influxdb/v1.8/write_protocols/line_protocol_tutorial/). To Configure\n+ * the InfluxDB source, you whave to provide the connection URL, the credentials to connect to\n+ * InfluxDB and the Database name\n+ *\n+ * <pre>{@code\n+ *  pipeline.apply(\n+ *    InfluxDB.read(\"https://influxdb\", \"userName\", \"password\", \"database\")\n+ *      .withQuery(\"select * from metric\");\n+ *      //Reads data based on the query from the InfluxDB\n+ * }\n+ *\n+ * <p> The source also accepts optional configuration: {@code withRetentionPolicy()}  an</p>\n+ *\n+ *\n+ * <h3>Writing to InfluxDB</h3>\n+ *\n+ * <p>InfluxDB sink supports writing data (as line protocol)  to InfluxDB\n+ * To configure a InfluxDB sink, you must specify a URL {@code InfluxDBURL}, {@code userName}, {@code password}, {@code database}\n+ * <pre>{@code\n+ * pipeleine\n+ *    .apply(...)\n+ *    .appply(InfluxDB.write(https://influxdb\", \"userName\", \"password\", \"database\")\n+ *\n+ * }\n+ * </pre>\n+ * </pre>\n+ */\n+@Experimental(Kind.SOURCE_SINK)\n+public class InfluxDbIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDbIO.class);\n+\n+  private static final String defaultRetentionPolicy = \"autogen\";\n+\n+  /** Disallow construction of utility class. */\n+  private InfluxDbIO() {}\n+\n+  public static Write write(String influxDbUrl, String username, String password, String database) {\n+    return new AutoValue_InfluxDbIO_Write.Builder()\n+        .setDataSourceConfiguration(\n+            DataSourceConfiguration.create(\n+                StaticValueProvider.of(influxDbUrl),\n+                StaticValueProvider.of(username),\n+                StaticValueProvider.of(password)))\n+        .setDatabase(database)\n+        .setRetentionPolicy(defaultRetentionPolicy)\n+        .setDisableCertificateValidation(false)\n+        .setBatchSize(DEFAULT_BUFFER_LIMIT)\n+        .setConsistencyLevel(ConsistencyLevel.QUORUM)\n+        .build();\n+  }\n+\n+  public static Read read(String influxDbUrl, String username, String password, String database) {\n+    return new AutoValue_InfluxDbIO_Read.Builder()\n+        .setDataSourceConfiguration(\n+            DataSourceConfiguration.create(\n+                StaticValueProvider.of(influxDbUrl),\n+                StaticValueProvider.of(username),\n+                StaticValueProvider.of(password)))\n+        .setDatabase(database)\n+        .setDisableCertificateValidation(false)\n+        .setRetentionPolicy(defaultRetentionPolicy)\n+        .build();\n+  }\n+\n+  ///////////////////////// Read  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n+\n+  /**\n+   * A {@link PTransform} to read from InfluxDB metric or data related to query. See {@link\n+   * InfluxDB} for more information on usage and configuration.\n+   */\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract String retentionPolicy();\n+\n+    abstract String database();\n+\n+    abstract @Nullable String query();\n+\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract @Nullable String metric();\n+\n+    abstract @Nullable String fromDateTime();\n+\n+    abstract @Nullable String toDateTime();\n+\n+    abstract boolean disableCertificateValidation();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(String toDateTime);\n+\n+      public abstract Builder setDisableCertificateValidation(boolean value);\n+\n+      abstract Builder setFromDateTime(String fromDateTime);\n+\n+      abstract Builder setMetric(@Nullable String metric);\n+\n+      abstract Read build();\n+    }\n+    /** Read metric data till the toDateTime. * */\n+    public Read withToDateTime(String toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+    /** Read metric data from the fromDateTime. * */\n+    public Read withFromDateTime(String fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+    /** Sets the metric to use. * */\n+    public Read withMetric(@Nullable String metric) {\n+      return builder().setMetric(metric).build();\n+    }\n+    /** Disable SSL certification validation. * */\n+    public Read withDisableCertificateValidation(boolean disableCertificateValidation) {\n+      return builder().setDisableCertificateValidation(disableCertificateValidation).build();\n+    }\n+    /** Sets the retention policy to use. * */\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+    /** Sets the query to use. * */\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      dataSourceConfiguration().populateDisplayData(builder);\n+      builder.addIfNotNull(DisplayData.item(\"metric\", metric()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"fromDateTime\", fromDateTime()));\n+      builder.addIfNotNull(DisplayData.item(\"toDateTime\", toDateTime()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"disableCertificateValidation\", disableCertificateValidation()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+    }\n+  }\n+  /** A InfluxDb {@link BoundedSource} reading {@link String} from a given instance. */\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String numOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> numOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(spec.dataSourceConfiguration(), spec.disableCertificateValidation())) {\n+        String query = spec.query();\n+        final String db = spec.database();\n+        if (query == null) {\n+          checkState(spec.metric() != null, \"Both query and metrics are empty\");\n+          query = String.format(\"SELECT * FROM %s.%s\", spec.retentionPolicy(), spec.metric());\n+        }\n+        QueryResult result = connection.query(new Query(\"EXPLAIN \" + query, db));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(numOfBlocks)) {\n+                numOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> numOfBlocksValueIterator = numOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueIterator = sizeOfBlocksValue.iterator();\n+      long size = 0L;\n+      while (numOfBlocksValueIterator.hasNext() && sizeOfBlocksValueIterator.hasNext()) {\n+        size = size + (numOfBlocksValueIterator.next() * sizeOfBlocksValueIterator.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) throws Exception {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(), spec.dataSourceConfiguration(), spec.disableCertificateValidation());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      String metric = spec.metric();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          sources.add(\n+              new InfluxDBSource(\n+                  spec.withMetric(metric)\n+                      .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                      .withToDateTime(sInfo.getStartTime())\n+                      .withFromDateTime(sInfo.getEndTime())));\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    String query = spec.query();\n+    if (query == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        String retVal =\n+            String.format(\n+                \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+                spec.retentionPolicy(), spec.metric(), spec.toDateTime(), spec.fromDateTime());\n+        return retVal;\n+      } else {\n+        return String.format(\"SELECT * FROM %s.%s\", spec.retentionPolicy(), spec.metric());\n+      }\n+    } else {\n+      return query;\n+    }\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDbIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List<Object> current;\n+\n+    public BoundedInfluxDbReader(InfluxDbIO.InfluxDBSource source) {\n+      this.source = source;\n+      this.seriesIterator = Collections.emptyIterator();\n+      this.resultIterator = Collections.emptyIterator();\n+      this.valuesIterator = Collections.emptyIterator();\n+      this.current = Collections.EMPTY_LIST;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDbIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(spec.dataSourceConfiguration(), spec.disableCertificateValidation())) {\n+        final String db = spec.database();\n+        influxDB.setDatabase(spec.database());\n+        influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        String query = getQueryToRun(spec);\n+        final QueryResult queryResult = influxDB.query(new Query(query, db));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          Result result = resultIterator.next();\n+          if (result != null && result.getSeries() != null) {\n+            seriesIterator = result.getSeries().iterator();\n+          }\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource<String> getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  /** A {@link PTransform} to write to a InfluxDB datasource. */\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkState(\n+          checkDatabase(database(), dataSourceConfiguration(), disableCertificateValidation()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"batchSize\", batchSize()));\n+      builder.addIfNotNull(DisplayData.item(\"consistencyLevel\", consistencyLevel().value()));\n+    }\n+\n+    abstract String database();\n+\n+    abstract String retentionPolicy();\n+\n+    abstract int batchSize();\n+\n+    abstract boolean disableCertificateValidation();\n+\n+    abstract ConsistencyLevel consistencyLevel();\n+\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setBatchSize(int batchSize);\n+\n+      abstract Builder setConsistencyLevel(ConsistencyLevel consistencyLevel);\n+\n+      public abstract Builder setDisableCertificateValidation(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Write build();\n+    }\n+    /** Number of elements to batch. * */\n+    public Write withBatchSize(int batchSize) {\n+      return builder().setBatchSize(batchSize).build();\n+    }\n+    /** Disable SSL certification validation. * */\n+    public Write withDisableCertificateValidation(boolean disableCertificateValidation) {\n+      return builder().setDisableCertificateValidation(disableCertificateValidation).build();\n+    }\n+    /** Sets the retention policy to use. * */\n+    public Write withRetentionPolicy(String rp) {\n+      return builder().setRetentionPolicy(rp).build();\n+    }\n+    /**\n+     * Sets the consistency level to use. ALL(\"all\") Write succeeds only if write reached all\n+     * cluster members. ANY(\"any\") Write succeeds if write reached at least one cluster members.\n+     * ONE(\"one\") Write succeeds if write reached at least one cluster members. QUORUM(\"quorum\")\n+     * Write succeeds only if write reached a quorum of cluster members.\n+     */\n+    public Write withConsistencyLevel(ConsistencyLevel consistencyLevel) {\n+      return builder().setConsistencyLevel(consistencyLevel).build();\n+    }\n+\n+    static class InfluxWriterFn extends DoFn<String, Void> {\n+\n+      private final Write spec;\n+      private List<String> batch;\n+\n+      InfluxWriterFn(Write write) {\n+        this.spec = write;\n+      }\n+\n+      @StartBundle\n+      public void startBundle() {\n+        batch = new ArrayList<>();\n+      }\n+\n+      @ProcessElement\n+      public void processElement(ProcessContext context) {\n+        batch.add(context.element());\n+        if (batch.size() >= spec.batchSize()) {\n+          flush();\n+        }\n+      }\n+\n+      @FinishBundle\n+      public void finishBundle() {\n+        flush();\n+      }\n+\n+      @Teardown\n+      public void tearDown() {\n+        flush();\n+      }\n+\n+      private void flush() {\n+        if (batch.isEmpty()) {\n+          return;\n+        }\n+        try (InfluxDB connection =\n+            getConnection(spec.dataSourceConfiguration(), spec.disableCertificateValidation())) {\n+          connection.setDatabase(spec.database());\n+          connection.enableBatch();\n+          connection.setConsistency(spec.consistencyLevel());\n+          connection.write(batch);\n+        } catch (InfluxDBException exception) {\n+          throw exception;\n+        }\n+        batch.clear();\n+      }\n+    }\n+  }\n+\n+  /** A POJO describing a DataSourceConfiguration such as URL, userName and password. */\n+  @AutoValue\n+  public abstract static class DataSourceConfiguration implements Serializable {\n+\n+    abstract ValueProvider<String> url();\n+\n+    abstract ValueProvider<String> userName();\n+\n+    abstract ValueProvider<String> password();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+\n+      abstract Builder setUrl(ValueProvider<String> url);\n+\n+      abstract Builder setUserName(ValueProvider<String> userName);\n+\n+      abstract Builder setPassword(ValueProvider<String> password);\n+\n+      abstract DataSourceConfiguration build();\n+    }\n+\n+    public static DataSourceConfiguration create(\n+        ValueProvider<String> url, ValueProvider<String> userName, ValueProvider<String> password) {\n+      return new AutoValue_InfluxDbIO_DataSourceConfiguration.Builder()\n+          .setUrl(url)\n+          .setUserName(userName)\n+          .setPassword(password)\n+          .build();\n+    }\n+\n+    void populateDisplayData(DisplayData.Builder builder) {\n+      builder.add(DisplayData.item(\"url\", url()));\n+      builder.add(DisplayData.item(\"userName\", userName()));\n+      builder.add(DisplayData.item(\"password\", password()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fada15c2d1a3fe10b3d9e3ba54820a4533c831f2"}, "originalPosition": 568}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0MjkxMw==", "bodyText": "What s states for? Please, name it explicitly.", "url": "https://github.com/apache/beam/pull/11459#discussion_r485042913", "createdAt": "2020-09-08T16:17:56Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDbIO.java", "diffHunk": "@@ -0,0 +1,662 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.annotations.Experimental.Kind;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.options.ValueProvider.StaticValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.checkerframework.checker.nullness.qual.Nullable;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDB.ConsistencyLevel;\n+import org.influxdb.InfluxDBException;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write from InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDB return a bounded collection of String as {@code PCollection<String>}. The String\n+ * follows the line protocol\n+ * (https://docs.influxdata.com/influxdb/v1.8/write_protocols/line_protocol_tutorial/). To Configure\n+ * the InfluxDB source, you whave to provide the connection URL, the credentials to connect to\n+ * InfluxDB and the Database name\n+ *\n+ * <pre>{@code\n+ *  pipeline.apply(\n+ *    InfluxDB.read(\"https://influxdb\", \"userName\", \"password\", \"database\")\n+ *      .withQuery(\"select * from metric\");\n+ *      //Reads data based on the query from the InfluxDB\n+ * }\n+ *\n+ * <p> The source also accepts optional configuration: {@code withRetentionPolicy()}  an</p>\n+ *\n+ *\n+ * <h3>Writing to InfluxDB</h3>\n+ *\n+ * <p>InfluxDB sink supports writing data (as line protocol)  to InfluxDB\n+ * To configure a InfluxDB sink, you must specify a URL {@code InfluxDBURL}, {@code userName}, {@code password}, {@code database}\n+ * <pre>{@code\n+ * pipeleine\n+ *    .apply(...)\n+ *    .appply(InfluxDB.write(https://influxdb\", \"userName\", \"password\", \"database\")\n+ *\n+ * }\n+ * </pre>\n+ * </pre>\n+ */\n+@Experimental(Kind.SOURCE_SINK)\n+public class InfluxDbIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDbIO.class);\n+\n+  private static final String defaultRetentionPolicy = \"autogen\";\n+\n+  /** Disallow construction of utility class. */\n+  private InfluxDbIO() {}\n+\n+  public static Write write(String influxDbUrl, String username, String password, String database) {\n+    return new AutoValue_InfluxDbIO_Write.Builder()\n+        .setDataSourceConfiguration(\n+            DataSourceConfiguration.create(\n+                StaticValueProvider.of(influxDbUrl),\n+                StaticValueProvider.of(username),\n+                StaticValueProvider.of(password)))\n+        .setDatabase(database)\n+        .setRetentionPolicy(defaultRetentionPolicy)\n+        .setDisableCertificateValidation(false)\n+        .setBatchSize(DEFAULT_BUFFER_LIMIT)\n+        .setConsistencyLevel(ConsistencyLevel.QUORUM)\n+        .build();\n+  }\n+\n+  public static Read read(String influxDbUrl, String username, String password, String database) {\n+    return new AutoValue_InfluxDbIO_Read.Builder()\n+        .setDataSourceConfiguration(\n+            DataSourceConfiguration.create(\n+                StaticValueProvider.of(influxDbUrl),\n+                StaticValueProvider.of(username),\n+                StaticValueProvider.of(password)))\n+        .setDatabase(database)\n+        .setDisableCertificateValidation(false)\n+        .setRetentionPolicy(defaultRetentionPolicy)\n+        .build();\n+  }\n+\n+  ///////////////////////// Read  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n+\n+  /**\n+   * A {@link PTransform} to read from InfluxDB metric or data related to query. See {@link\n+   * InfluxDB} for more information on usage and configuration.\n+   */\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract String retentionPolicy();\n+\n+    abstract String database();\n+\n+    abstract @Nullable String query();\n+\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract @Nullable String metric();\n+\n+    abstract @Nullable String fromDateTime();\n+\n+    abstract @Nullable String toDateTime();\n+\n+    abstract boolean disableCertificateValidation();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(String toDateTime);\n+\n+      public abstract Builder setDisableCertificateValidation(boolean value);\n+\n+      abstract Builder setFromDateTime(String fromDateTime);\n+\n+      abstract Builder setMetric(@Nullable String metric);\n+\n+      abstract Read build();\n+    }\n+    /** Read metric data till the toDateTime. * */\n+    public Read withToDateTime(String toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+    /** Read metric data from the fromDateTime. * */\n+    public Read withFromDateTime(String fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+    /** Sets the metric to use. * */\n+    public Read withMetric(@Nullable String metric) {\n+      return builder().setMetric(metric).build();\n+    }\n+    /** Disable SSL certification validation. * */\n+    public Read withDisableCertificateValidation(boolean disableCertificateValidation) {\n+      return builder().setDisableCertificateValidation(disableCertificateValidation).build();\n+    }\n+    /** Sets the retention policy to use. * */\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+    /** Sets the query to use. * */\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      dataSourceConfiguration().populateDisplayData(builder);\n+      builder.addIfNotNull(DisplayData.item(\"metric\", metric()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"fromDateTime\", fromDateTime()));\n+      builder.addIfNotNull(DisplayData.item(\"toDateTime\", toDateTime()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"disableCertificateValidation\", disableCertificateValidation()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+    }\n+  }\n+  /** A InfluxDb {@link BoundedSource} reading {@link String} from a given instance. */\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String numOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> numOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(spec.dataSourceConfiguration(), spec.disableCertificateValidation())) {\n+        String query = spec.query();\n+        final String db = spec.database();\n+        if (query == null) {\n+          checkState(spec.metric() != null, \"Both query and metrics are empty\");\n+          query = String.format(\"SELECT * FROM %s.%s\", spec.retentionPolicy(), spec.metric());\n+        }\n+        QueryResult result = connection.query(new Query(\"EXPLAIN \" + query, db));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fada15c2d1a3fe10b3d9e3ba54820a4533c831f2"}, "originalPosition": 251}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0NzI5Mw==", "bodyText": "nit: rename Result result", "url": "https://github.com/apache/beam/pull/11459#discussion_r485047293", "createdAt": "2020-09-08T16:25:11Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDbIO.java", "diffHunk": "@@ -0,0 +1,662 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.annotations.Experimental.Kind;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.options.ValueProvider.StaticValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.checkerframework.checker.nullness.qual.Nullable;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDB.ConsistencyLevel;\n+import org.influxdb.InfluxDBException;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write from InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDB return a bounded collection of String as {@code PCollection<String>}. The String\n+ * follows the line protocol\n+ * (https://docs.influxdata.com/influxdb/v1.8/write_protocols/line_protocol_tutorial/). To Configure\n+ * the InfluxDB source, you whave to provide the connection URL, the credentials to connect to\n+ * InfluxDB and the Database name\n+ *\n+ * <pre>{@code\n+ *  pipeline.apply(\n+ *    InfluxDB.read(\"https://influxdb\", \"userName\", \"password\", \"database\")\n+ *      .withQuery(\"select * from metric\");\n+ *      //Reads data based on the query from the InfluxDB\n+ * }\n+ *\n+ * <p> The source also accepts optional configuration: {@code withRetentionPolicy()}  an</p>\n+ *\n+ *\n+ * <h3>Writing to InfluxDB</h3>\n+ *\n+ * <p>InfluxDB sink supports writing data (as line protocol)  to InfluxDB\n+ * To configure a InfluxDB sink, you must specify a URL {@code InfluxDBURL}, {@code userName}, {@code password}, {@code database}\n+ * <pre>{@code\n+ * pipeleine\n+ *    .apply(...)\n+ *    .appply(InfluxDB.write(https://influxdb\", \"userName\", \"password\", \"database\")\n+ *\n+ * }\n+ * </pre>\n+ * </pre>\n+ */\n+@Experimental(Kind.SOURCE_SINK)\n+public class InfluxDbIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDbIO.class);\n+\n+  private static final String defaultRetentionPolicy = \"autogen\";\n+\n+  /** Disallow construction of utility class. */\n+  private InfluxDbIO() {}\n+\n+  public static Write write(String influxDbUrl, String username, String password, String database) {\n+    return new AutoValue_InfluxDbIO_Write.Builder()\n+        .setDataSourceConfiguration(\n+            DataSourceConfiguration.create(\n+                StaticValueProvider.of(influxDbUrl),\n+                StaticValueProvider.of(username),\n+                StaticValueProvider.of(password)))\n+        .setDatabase(database)\n+        .setRetentionPolicy(defaultRetentionPolicy)\n+        .setDisableCertificateValidation(false)\n+        .setBatchSize(DEFAULT_BUFFER_LIMIT)\n+        .setConsistencyLevel(ConsistencyLevel.QUORUM)\n+        .build();\n+  }\n+\n+  public static Read read(String influxDbUrl, String username, String password, String database) {\n+    return new AutoValue_InfluxDbIO_Read.Builder()\n+        .setDataSourceConfiguration(\n+            DataSourceConfiguration.create(\n+                StaticValueProvider.of(influxDbUrl),\n+                StaticValueProvider.of(username),\n+                StaticValueProvider.of(password)))\n+        .setDatabase(database)\n+        .setDisableCertificateValidation(false)\n+        .setRetentionPolicy(defaultRetentionPolicy)\n+        .build();\n+  }\n+\n+  ///////////////////////// Read  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n+\n+  /**\n+   * A {@link PTransform} to read from InfluxDB metric or data related to query. See {@link\n+   * InfluxDB} for more information on usage and configuration.\n+   */\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract String retentionPolicy();\n+\n+    abstract String database();\n+\n+    abstract @Nullable String query();\n+\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract @Nullable String metric();\n+\n+    abstract @Nullable String fromDateTime();\n+\n+    abstract @Nullable String toDateTime();\n+\n+    abstract boolean disableCertificateValidation();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(String toDateTime);\n+\n+      public abstract Builder setDisableCertificateValidation(boolean value);\n+\n+      abstract Builder setFromDateTime(String fromDateTime);\n+\n+      abstract Builder setMetric(@Nullable String metric);\n+\n+      abstract Read build();\n+    }\n+    /** Read metric data till the toDateTime. * */\n+    public Read withToDateTime(String toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+    /** Read metric data from the fromDateTime. * */\n+    public Read withFromDateTime(String fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+    /** Sets the metric to use. * */\n+    public Read withMetric(@Nullable String metric) {\n+      return builder().setMetric(metric).build();\n+    }\n+    /** Disable SSL certification validation. * */\n+    public Read withDisableCertificateValidation(boolean disableCertificateValidation) {\n+      return builder().setDisableCertificateValidation(disableCertificateValidation).build();\n+    }\n+    /** Sets the retention policy to use. * */\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+    /** Sets the query to use. * */\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      dataSourceConfiguration().populateDisplayData(builder);\n+      builder.addIfNotNull(DisplayData.item(\"metric\", metric()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"fromDateTime\", fromDateTime()));\n+      builder.addIfNotNull(DisplayData.item(\"toDateTime\", toDateTime()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"disableCertificateValidation\", disableCertificateValidation()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+    }\n+  }\n+  /** A InfluxDb {@link BoundedSource} reading {@link String} from a given instance. */\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String numOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> numOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(spec.dataSourceConfiguration(), spec.disableCertificateValidation())) {\n+        String query = spec.query();\n+        final String db = spec.database();\n+        if (query == null) {\n+          checkState(spec.metric() != null, \"Both query and metrics are empty\");\n+          query = String.format(\"SELECT * FROM %s.%s\", spec.retentionPolicy(), spec.metric());\n+        }\n+        QueryResult result = connection.query(new Query(\"EXPLAIN \" + query, db));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(numOfBlocks)) {\n+                numOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> numOfBlocksValueIterator = numOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueIterator = sizeOfBlocksValue.iterator();\n+      long size = 0L;\n+      while (numOfBlocksValueIterator.hasNext() && sizeOfBlocksValueIterator.hasNext()) {\n+        size = size + (numOfBlocksValueIterator.next() * sizeOfBlocksValueIterator.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) throws Exception {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(), spec.dataSourceConfiguration(), spec.disableCertificateValidation());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      String metric = spec.metric();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          sources.add(\n+              new InfluxDBSource(\n+                  spec.withMetric(metric)\n+                      .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                      .withToDateTime(sInfo.getStartTime())\n+                      .withFromDateTime(sInfo.getEndTime())));\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    String query = spec.query();\n+    if (query == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        String retVal =\n+            String.format(\n+                \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+                spec.retentionPolicy(), spec.metric(), spec.toDateTime(), spec.fromDateTime());\n+        return retVal;\n+      } else {\n+        return String.format(\"SELECT * FROM %s.%s\", spec.retentionPolicy(), spec.metric());\n+      }\n+    } else {\n+      return query;\n+    }\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDbIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List<Object> current;\n+\n+    public BoundedInfluxDbReader(InfluxDbIO.InfluxDBSource source) {\n+      this.source = source;\n+      this.seriesIterator = Collections.emptyIterator();\n+      this.resultIterator = Collections.emptyIterator();\n+      this.valuesIterator = Collections.emptyIterator();\n+      this.current = Collections.EMPTY_LIST;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDbIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(spec.dataSourceConfiguration(), spec.disableCertificateValidation())) {\n+        final String db = spec.database();\n+        influxDB.setDatabase(spec.database());\n+        influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        String query = getQueryToRun(spec);\n+        final QueryResult queryResult = influxDB.query(new Query(query, db));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          Result result = resultIterator.next();\n+          if (result != null && result.getSeries() != null) {\n+            seriesIterator = result.getSeries().iterator();\n+          }\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource<String> getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  /** A {@link PTransform} to write to a InfluxDB datasource. */\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkState(\n+          checkDatabase(database(), dataSourceConfiguration(), disableCertificateValidation()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"batchSize\", batchSize()));\n+      builder.addIfNotNull(DisplayData.item(\"consistencyLevel\", consistencyLevel().value()));\n+    }\n+\n+    abstract String database();\n+\n+    abstract String retentionPolicy();\n+\n+    abstract int batchSize();\n+\n+    abstract boolean disableCertificateValidation();\n+\n+    abstract ConsistencyLevel consistencyLevel();\n+\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setBatchSize(int batchSize);\n+\n+      abstract Builder setConsistencyLevel(ConsistencyLevel consistencyLevel);\n+\n+      public abstract Builder setDisableCertificateValidation(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Write build();\n+    }\n+    /** Number of elements to batch. * */\n+    public Write withBatchSize(int batchSize) {\n+      return builder().setBatchSize(batchSize).build();\n+    }\n+    /** Disable SSL certification validation. * */\n+    public Write withDisableCertificateValidation(boolean disableCertificateValidation) {\n+      return builder().setDisableCertificateValidation(disableCertificateValidation).build();\n+    }\n+    /** Sets the retention policy to use. * */\n+    public Write withRetentionPolicy(String rp) {\n+      return builder().setRetentionPolicy(rp).build();\n+    }\n+    /**\n+     * Sets the consistency level to use. ALL(\"all\") Write succeeds only if write reached all\n+     * cluster members. ANY(\"any\") Write succeeds if write reached at least one cluster members.\n+     * ONE(\"one\") Write succeeds if write reached at least one cluster members. QUORUM(\"quorum\")\n+     * Write succeeds only if write reached a quorum of cluster members.\n+     */\n+    public Write withConsistencyLevel(ConsistencyLevel consistencyLevel) {\n+      return builder().setConsistencyLevel(consistencyLevel).build();\n+    }\n+\n+    static class InfluxWriterFn extends DoFn<String, Void> {\n+\n+      private final Write spec;\n+      private List<String> batch;\n+\n+      InfluxWriterFn(Write write) {\n+        this.spec = write;\n+      }\n+\n+      @StartBundle\n+      public void startBundle() {\n+        batch = new ArrayList<>();\n+      }\n+\n+      @ProcessElement\n+      public void processElement(ProcessContext context) {\n+        batch.add(context.element());\n+        if (batch.size() >= spec.batchSize()) {\n+          flush();\n+        }\n+      }\n+\n+      @FinishBundle\n+      public void finishBundle() {\n+        flush();\n+      }\n+\n+      @Teardown\n+      public void tearDown() {\n+        flush();\n+      }\n+\n+      private void flush() {\n+        if (batch.isEmpty()) {\n+          return;\n+        }\n+        try (InfluxDB connection =\n+            getConnection(spec.dataSourceConfiguration(), spec.disableCertificateValidation())) {\n+          connection.setDatabase(spec.database());\n+          connection.enableBatch();\n+          connection.setConsistency(spec.consistencyLevel());\n+          connection.write(batch);\n+        } catch (InfluxDBException exception) {\n+          throw exception;\n+        }\n+        batch.clear();\n+      }\n+    }\n+  }\n+\n+  /** A POJO describing a DataSourceConfiguration such as URL, userName and password. */\n+  @AutoValue\n+  public abstract static class DataSourceConfiguration implements Serializable {\n+\n+    abstract ValueProvider<String> url();\n+\n+    abstract ValueProvider<String> userName();\n+\n+    abstract ValueProvider<String> password();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+\n+      abstract Builder setUrl(ValueProvider<String> url);\n+\n+      abstract Builder setUserName(ValueProvider<String> userName);\n+\n+      abstract Builder setPassword(ValueProvider<String> password);\n+\n+      abstract DataSourceConfiguration build();\n+    }\n+\n+    public static DataSourceConfiguration create(\n+        ValueProvider<String> url, ValueProvider<String> userName, ValueProvider<String> password) {\n+      return new AutoValue_InfluxDbIO_DataSourceConfiguration.Builder()\n+          .setUrl(url)\n+          .setUserName(userName)\n+          .setPassword(password)\n+          .build();\n+    }\n+\n+    void populateDisplayData(DisplayData.Builder builder) {\n+      builder.add(DisplayData.item(\"url\", url()));\n+      builder.add(DisplayData.item(\"userName\", userName()));\n+      builder.add(DisplayData.item(\"password\", password()));\n+    }\n+  }\n+\n+  private static List<ShardInformation> getDBShardedInformation(\n+      String database, DataSourceConfiguration configuration, boolean disableCertificateValidation)\n+      throws Exception {\n+    String query = \"SHOW SHARDS\";\n+    DBShardInformation dbInfo = new DBShardInformation();\n+    try (InfluxDB connection = getConnection(configuration, disableCertificateValidation)) {\n+      QueryResult result = connection.query(new Query(query));\n+      List<Result> results = result.getResults();\n+      for (Result res : results) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fada15c2d1a3fe10b3d9e3ba54820a4533c831f2"}, "originalPosition": 580}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4b81f1b57c0fa9bbceeed93e016af21e1cd04a67", "author": {"user": {"login": "bipinupd", "name": "Bipin Upadhyaya"}}, "url": "https://github.com/apache/beam/commit/4b81f1b57c0fa9bbceeed93e016af21e1cd04a67", "committedDate": "2020-09-17T14:29:12Z", "message": "Addressing the comments"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "fada15c2d1a3fe10b3d9e3ba54820a4533c831f2", "author": {"user": {"login": "bipinupd", "name": "Bipin Upadhyaya"}}, "url": "https://github.com/apache/beam/commit/fada15c2d1a3fe10b3d9e3ba54820a4533c831f2", "committedDate": "2020-09-04T02:43:42Z", "message": "Fix whitespace"}, "afterCommit": {"oid": "4b81f1b57c0fa9bbceeed93e016af21e1cd04a67", "author": {"user": {"login": "bipinupd", "name": "Bipin Upadhyaya"}}, "url": "https://github.com/apache/beam/commit/4b81f1b57c0fa9bbceeed93e016af21e1cd04a67", "committedDate": "2020-09-17T14:29:12Z", "message": "Addressing the comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "70b073fa91ebf2af6fa2ef42b3a96b3a77257832", "author": {"user": {"login": "bipinupd", "name": "Bipin Upadhyaya"}}, "url": "https://github.com/apache/beam/commit/70b073fa91ebf2af6fa2ef42b3a96b3a77257832", "committedDate": "2020-09-17T14:37:04Z", "message": "InfluxDBIO"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ddc47edd0d5455824f02c8ecbce3e8c1d84fde5a", "author": {"user": {"login": "bipinupd", "name": "Bipin Upadhyaya"}}, "url": "https://github.com/apache/beam/commit/ddc47edd0d5455824f02c8ecbce3e8c1d84fde5a", "committedDate": "2020-09-17T14:39:31Z", "message": "InfluxDBIO spotlessApply"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fbd981c2b14e08da6df639b8d1d24adb2cabfefe", "author": {"user": {"login": "bipinupd", "name": "Bipin Upadhyaya"}}, "url": "https://github.com/apache/beam/commit/fbd981c2b14e08da6df639b8d1d24adb2cabfefe", "committedDate": "2020-09-21T17:47:09Z", "message": "Removing display for password and typos in docs"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDkyODUxOTkw", "url": "https://github.com/apache/beam/pull/11459#pullrequestreview-492851990", "createdAt": "2020-09-21T17:55:32Z", "commit": {"oid": "fbd981c2b14e08da6df639b8d1d24adb2cabfefe"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4316, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}