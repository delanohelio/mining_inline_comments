{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzY1NTc5OTEw", "number": 10648, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQyMTo0Nzo0MlrODZ_Klg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQyMTo0OTowM1rODZ_L_w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI4NTc1ODk0OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/dataflow/dataflow_runner.py", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQyMTo0Nzo0M1rOFgsIgA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yM1QwMDoxNzo1MFrOFgvakw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTgyMTgyNA==", "bodyText": "Please file a JIRA to get to the root of this discrepancy.", "url": "https://github.com/apache/beam/pull/10648#discussion_r369821824", "createdAt": "2020-01-22T21:47:43Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/runners/dataflow/dataflow_runner.py", "diffHunk": "@@ -320,24 +320,32 @@ def visit_transform(self, transform_node):\n           for ix, side_input in enumerate(transform_node.side_inputs):\n             access_pattern = side_input._side_input_data().access_pattern\n             if access_pattern == common_urns.side_inputs.ITERABLE.urn:\n-              # Add a map to ('', value) as Dataflow currently only handles\n-              # keyed side inputs.\n-              pipeline = side_input.pvalue.pipeline\n-              new_side_input = _DataflowIterableSideInput(side_input)\n-              new_side_input.pvalue = beam.pvalue.PCollection(\n-                  pipeline,\n-                  element_type=typehints.KV[\n-                      bytes, side_input.pvalue.element_type],\n-                  is_bounded=side_input.pvalue.is_bounded)\n-              parent = transform_node.parent or pipeline._root_transform()\n-              map_to_void_key = beam.pipeline.AppliedPTransform(\n-                  pipeline,\n-                  beam.Map(lambda x: (b'', x)),\n-                  transform_node.full_label + '/MapToVoidKey%s' % ix,\n-                  (side_input.pvalue,))\n-              new_side_input.pvalue.producer = map_to_void_key\n-              map_to_void_key.add_output(new_side_input.pvalue)\n-              parent.add_part(map_to_void_key)\n+              if use_unified_worker:\n+                # Patch up the access pattern to appease Dataflow when using", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "95ac61e854bf9d3f3d4085a94dd7ce8b19b91a0e"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTg3NDQwOQ==", "bodyText": "Filed BEAM-9173", "url": "https://github.com/apache/beam/pull/10648#discussion_r369874409", "createdAt": "2020-01-23T00:13:18Z", "author": {"login": "lukecwik"}, "path": "sdks/python/apache_beam/runners/dataflow/dataflow_runner.py", "diffHunk": "@@ -320,24 +320,32 @@ def visit_transform(self, transform_node):\n           for ix, side_input in enumerate(transform_node.side_inputs):\n             access_pattern = side_input._side_input_data().access_pattern\n             if access_pattern == common_urns.side_inputs.ITERABLE.urn:\n-              # Add a map to ('', value) as Dataflow currently only handles\n-              # keyed side inputs.\n-              pipeline = side_input.pvalue.pipeline\n-              new_side_input = _DataflowIterableSideInput(side_input)\n-              new_side_input.pvalue = beam.pvalue.PCollection(\n-                  pipeline,\n-                  element_type=typehints.KV[\n-                      bytes, side_input.pvalue.element_type],\n-                  is_bounded=side_input.pvalue.is_bounded)\n-              parent = transform_node.parent or pipeline._root_transform()\n-              map_to_void_key = beam.pipeline.AppliedPTransform(\n-                  pipeline,\n-                  beam.Map(lambda x: (b'', x)),\n-                  transform_node.full_label + '/MapToVoidKey%s' % ix,\n-                  (side_input.pvalue,))\n-              new_side_input.pvalue.producer = map_to_void_key\n-              map_to_void_key.add_output(new_side_input.pvalue)\n-              parent.add_part(map_to_void_key)\n+              if use_unified_worker:\n+                # Patch up the access pattern to appease Dataflow when using", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTgyMTgyNA=="}, "originalCommit": {"oid": "95ac61e854bf9d3f3d4085a94dd7ce8b19b91a0e"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTg3NTYwMw==", "bodyText": "Added link in follow-up #10667", "url": "https://github.com/apache/beam/pull/10648#discussion_r369875603", "createdAt": "2020-01-23T00:17:50Z", "author": {"login": "lukecwik"}, "path": "sdks/python/apache_beam/runners/dataflow/dataflow_runner.py", "diffHunk": "@@ -320,24 +320,32 @@ def visit_transform(self, transform_node):\n           for ix, side_input in enumerate(transform_node.side_inputs):\n             access_pattern = side_input._side_input_data().access_pattern\n             if access_pattern == common_urns.side_inputs.ITERABLE.urn:\n-              # Add a map to ('', value) as Dataflow currently only handles\n-              # keyed side inputs.\n-              pipeline = side_input.pvalue.pipeline\n-              new_side_input = _DataflowIterableSideInput(side_input)\n-              new_side_input.pvalue = beam.pvalue.PCollection(\n-                  pipeline,\n-                  element_type=typehints.KV[\n-                      bytes, side_input.pvalue.element_type],\n-                  is_bounded=side_input.pvalue.is_bounded)\n-              parent = transform_node.parent or pipeline._root_transform()\n-              map_to_void_key = beam.pipeline.AppliedPTransform(\n-                  pipeline,\n-                  beam.Map(lambda x: (b'', x)),\n-                  transform_node.full_label + '/MapToVoidKey%s' % ix,\n-                  (side_input.pvalue,))\n-              new_side_input.pvalue.producer = map_to_void_key\n-              map_to_void_key.add_output(new_side_input.pvalue)\n-              parent.add_part(map_to_void_key)\n+              if use_unified_worker:\n+                # Patch up the access pattern to appease Dataflow when using", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTgyMTgyNA=="}, "originalCommit": {"oid": "95ac61e854bf9d3f3d4085a94dd7ce8b19b91a0e"}, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI4NTc2MjU1OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/dataflow/dataflow_runner.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQyMTo0OTowM1rOFgsKxA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yM1QwMDowODowNFrOFgvQjg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTgyMjQwNA==", "bodyText": "Why is a special _DataflowIterableSideInput needed?", "url": "https://github.com/apache/beam/pull/10648#discussion_r369822404", "createdAt": "2020-01-22T21:49:03Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/runners/dataflow/dataflow_runner.py", "diffHunk": "@@ -320,24 +320,32 @@ def visit_transform(self, transform_node):\n           for ix, side_input in enumerate(transform_node.side_inputs):\n             access_pattern = side_input._side_input_data().access_pattern\n             if access_pattern == common_urns.side_inputs.ITERABLE.urn:\n-              # Add a map to ('', value) as Dataflow currently only handles\n-              # keyed side inputs.\n-              pipeline = side_input.pvalue.pipeline\n-              new_side_input = _DataflowIterableSideInput(side_input)\n-              new_side_input.pvalue = beam.pvalue.PCollection(\n-                  pipeline,\n-                  element_type=typehints.KV[\n-                      bytes, side_input.pvalue.element_type],\n-                  is_bounded=side_input.pvalue.is_bounded)\n-              parent = transform_node.parent or pipeline._root_transform()\n-              map_to_void_key = beam.pipeline.AppliedPTransform(\n-                  pipeline,\n-                  beam.Map(lambda x: (b'', x)),\n-                  transform_node.full_label + '/MapToVoidKey%s' % ix,\n-                  (side_input.pvalue,))\n-              new_side_input.pvalue.producer = map_to_void_key\n-              map_to_void_key.add_output(new_side_input.pvalue)\n-              parent.add_part(map_to_void_key)\n+              if use_unified_worker:\n+                # Patch up the access pattern to appease Dataflow when using\n+                # the UW and hardcode the output type to be Any since\n+                # the Dataflow JSON and pipeline proto can differ in coders\n+                # which leads to encoding/decoding issues within the runner.\n+                side_input.pvalue.element_type = typehints.Any\n+                new_side_input = _DataflowIterableSideInput(side_input)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "95ac61e854bf9d3f3d4085a94dd7ce8b19b91a0e"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTg3MzAzOA==", "bodyText": "The dataflow translation logic relies on specific field names for the side input which differ from a Beam side input.", "url": "https://github.com/apache/beam/pull/10648#discussion_r369873038", "createdAt": "2020-01-23T00:08:04Z", "author": {"login": "lukecwik"}, "path": "sdks/python/apache_beam/runners/dataflow/dataflow_runner.py", "diffHunk": "@@ -320,24 +320,32 @@ def visit_transform(self, transform_node):\n           for ix, side_input in enumerate(transform_node.side_inputs):\n             access_pattern = side_input._side_input_data().access_pattern\n             if access_pattern == common_urns.side_inputs.ITERABLE.urn:\n-              # Add a map to ('', value) as Dataflow currently only handles\n-              # keyed side inputs.\n-              pipeline = side_input.pvalue.pipeline\n-              new_side_input = _DataflowIterableSideInput(side_input)\n-              new_side_input.pvalue = beam.pvalue.PCollection(\n-                  pipeline,\n-                  element_type=typehints.KV[\n-                      bytes, side_input.pvalue.element_type],\n-                  is_bounded=side_input.pvalue.is_bounded)\n-              parent = transform_node.parent or pipeline._root_transform()\n-              map_to_void_key = beam.pipeline.AppliedPTransform(\n-                  pipeline,\n-                  beam.Map(lambda x: (b'', x)),\n-                  transform_node.full_label + '/MapToVoidKey%s' % ix,\n-                  (side_input.pvalue,))\n-              new_side_input.pvalue.producer = map_to_void_key\n-              map_to_void_key.add_output(new_side_input.pvalue)\n-              parent.add_part(map_to_void_key)\n+              if use_unified_worker:\n+                # Patch up the access pattern to appease Dataflow when using\n+                # the UW and hardcode the output type to be Any since\n+                # the Dataflow JSON and pipeline proto can differ in coders\n+                # which leads to encoding/decoding issues within the runner.\n+                side_input.pvalue.element_type = typehints.Any\n+                new_side_input = _DataflowIterableSideInput(side_input)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTgyMjQwNA=="}, "originalCommit": {"oid": "95ac61e854bf9d3f3d4085a94dd7ce8b19b91a0e"}, "originalPosition": 37}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2227, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}