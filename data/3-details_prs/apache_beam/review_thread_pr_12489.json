{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDY0Mjk1NzEx", "number": 12489, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQwMTo0OToxM1rOEXBhug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQwMTo1MDozOVrOEXBiqw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyNTc3NzIyOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQwMTo0OToxM1rOG-lirg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxOTo1MDozNVrOG_G3VA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODI3OTk4Mg==", "bodyText": "Seems like this will conflict with #12485 ?", "url": "https://github.com/apache/beam/pull/12489#discussion_r468279982", "createdAt": "2020-08-11T01:49:13Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -304,6 +308,8 @@ def compute_table_name(row):\n NOTE: This job name template does not have backwards compatibility guarantees.\n \"\"\"\n BQ_JOB_NAME_TEMPLATE = \"beam_bq_job_{job_type}_{job_id}_{step_id}{random}\"\n+\"\"\"The number of shards per destination when writing via streaming inserts.\"\"\"\n+DEFAULT_SHARDS_PER_DESTINATION = 500", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4eddac06c587854fa853f404c75f0974b9a8a9c4"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODgyNTk0MA==", "bodyText": "yeah, this needs to fix conflicts with them.", "url": "https://github.com/apache/beam/pull/12489#discussion_r468825940", "createdAt": "2020-08-11T19:50:35Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -304,6 +308,8 @@ def compute_table_name(row):\n NOTE: This job name template does not have backwards compatibility guarantees.\n \"\"\"\n BQ_JOB_NAME_TEMPLATE = \"beam_bq_job_{job_type}_{job_id}_{step_id}{random}\"\n+\"\"\"The number of shards per destination when writing via streaming inserts.\"\"\"\n+DEFAULT_SHARDS_PER_DESTINATION = 500", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODI3OTk4Mg=="}, "originalCommit": {"oid": "4eddac06c587854fa853f404c75f0974b9a8a9c4"}, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyNTc3OTYzOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQwMTo1MDozOVrOG-lkFQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQyMDoyNDozNFrOG_H6cg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODI4MDM0MQ==", "bodyText": "Let's refer to 'https://cloud.google.com/bigquery/streaming-data-into-bigquery#disabling_best_effort_de-duplication' similar to Java.", "url": "https://github.com/apache/beam/pull/12489#discussion_r468280341", "createdAt": "2020-08-11T01:50:39Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -1048,6 +1055,11 @@ def __init__(\n         to be passed when creating a BigQuery table. These are passed when\n         triggering a load job for FILE_LOADS, and when creating a new table for\n         STREAMING_INSERTS.\n+      with_insert_ids: When using the STREAMING_INSERTS method to write data to", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4eddac06c587854fa853f404c75f0974b9a8a9c4"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODg0MzEyMg==", "bodyText": "I've renamed the option to match the name in Java SDK", "url": "https://github.com/apache/beam/pull/12489#discussion_r468843122", "createdAt": "2020-08-11T20:24:34Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -1048,6 +1055,11 @@ def __init__(\n         to be passed when creating a BigQuery table. These are passed when\n         triggering a load job for FILE_LOADS, and when creating a new table for\n         STREAMING_INSERTS.\n+      with_insert_ids: When using the STREAMING_INSERTS method to write data to", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODI4MDM0MQ=="}, "originalCommit": {"oid": "4eddac06c587854fa853f404c75f0974b9a8a9c4"}, "originalPosition": 53}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 856, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}